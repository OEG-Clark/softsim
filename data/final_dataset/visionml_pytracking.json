{"home.repos.pwc.inspect_result.visionml_pytracking.pytracking.run_webcam.run_webcam": [[12, 23], ["pytracking.evaluation.Tracker", "pytracking.evaluation.Tracker.run_webcam"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.run_webcam"], ["def", "run_webcam", "(", "tracker_name", ",", "tracker_param", ",", "debug", "=", "None", ",", "visdom_info", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run the tracker on your webcam.\n    args:\n        tracker_name: Name of tracking method.\n        tracker_param: Name of parameter file.\n        debug: Debug level.\n        visdom_info: Dict optionally containing 'use_visdom', 'server' and 'port' for Visdom visualization.\n    \"\"\"", "\n", "visdom_info", "=", "{", "}", "if", "visdom_info", "is", "None", "else", "visdom_info", "\n", "tracker", "=", "Tracker", "(", "tracker_name", ",", "tracker_param", ")", "\n", "tracker", ".", "run_webcam", "(", "debug", ",", "visdom_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.pytracking.run_webcam.main": [[25, 38], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "run_webcam.run_webcam"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.run_webcam"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Run the tracker on your webcam.'", ")", "\n", "parser", ".", "add_argument", "(", "'tracker_name'", ",", "type", "=", "str", ",", "help", "=", "'Name of tracking method.'", ")", "\n", "parser", ".", "add_argument", "(", "'tracker_param'", ",", "type", "=", "str", ",", "help", "=", "'Name of parameter file.'", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Debug level.'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_visdom'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'Flag to enable visdom'", ")", "\n", "parser", ".", "add_argument", "(", "'--visdom_server'", ",", "type", "=", "str", ",", "default", "=", "'127.0.0.1'", ",", "help", "=", "'Server for visdom'", ")", "\n", "parser", ".", "add_argument", "(", "'--visdom_port'", ",", "type", "=", "int", ",", "default", "=", "8097", ",", "help", "=", "'Port for visdom'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "visdom_info", "=", "{", "'use_visdom'", ":", "args", ".", "use_visdom", ",", "'server'", ":", "args", ".", "visdom_server", ",", "'port'", ":", "args", ".", "visdom_port", "}", "\n", "run_webcam", "(", "args", ".", "tracker_name", ",", "args", ".", "tracker_param", ",", "args", ".", "debug", ",", "visdom_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.pytracking.run_video.run_video": [[12, 21], ["pytracking.evaluation.Tracker", "pytracking.evaluation.Tracker.run_video"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.run_video"], ["def", "run_video", "(", "tracker_name", ",", "tracker_param", ",", "videofile", ",", "optional_box", "=", "None", ",", "debug", "=", "None", ",", "save_results", "=", "False", ")", ":", "\n", "    ", "\"\"\"Run the tracker on your webcam.\n    args:\n        tracker_name: Name of tracking method.\n        tracker_param: Name of parameter file.\n        debug: Debug level.\n    \"\"\"", "\n", "tracker", "=", "Tracker", "(", "tracker_name", ",", "tracker_param", ")", "\n", "tracker", ".", "run_video", "(", "videofilepath", "=", "videofile", ",", "optional_box", "=", "optional_box", ",", "debug", "=", "debug", ",", "save_results", "=", "save_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.pytracking.run_video.main": [[22, 35], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.set_defaults", "argparse.ArgumentParser.parse_args", "run_video.run_video"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.run_video"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Run the tracker on your webcam.'", ")", "\n", "parser", ".", "add_argument", "(", "'tracker_name'", ",", "type", "=", "str", ",", "help", "=", "'Name of tracking method.'", ")", "\n", "parser", ".", "add_argument", "(", "'tracker_param'", ",", "type", "=", "str", ",", "help", "=", "'Name of parameter file.'", ")", "\n", "parser", ".", "add_argument", "(", "'videofile'", ",", "type", "=", "str", ",", "help", "=", "'path to a video file.'", ")", "\n", "parser", ".", "add_argument", "(", "'--optional_box'", ",", "type", "=", "float", ",", "default", "=", "None", ",", "nargs", "=", "\"+\"", ",", "help", "=", "'optional_box with format x y w h.'", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Debug level.'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_results'", ",", "dest", "=", "'save_results'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Save bounding boxes'", ")", "\n", "parser", ".", "set_defaults", "(", "save_results", "=", "False", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "run_video", "(", "args", ".", "tracker_name", ",", "args", ".", "tracker_param", ",", "args", ".", "videofile", ",", "args", ".", "optional_box", ",", "args", ".", "debug", ",", "args", ".", "save_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.pytracking.run_vot.run_vot2020": [[12, 15], ["pytracking.evaluation.Tracker", "pytracking.evaluation.Tracker.run_vot2020"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.run_vot2020"], ["def", "run_vot2020", "(", "tracker_name", ",", "tracker_param", ",", "run_id", "=", "None", ",", "debug", "=", "0", ",", "visdom_info", "=", "None", ")", ":", "\n", "    ", "tracker", "=", "Tracker", "(", "tracker_name", ",", "tracker_param", ",", "run_id", ")", "\n", "tracker", ".", "run_vot2020", "(", "debug", ",", "visdom_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.pytracking.run_vot.run_vot": [[17, 20], ["pytracking.evaluation.Tracker", "pytracking.evaluation.Tracker.run_vot"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.run_vot"], ["", "def", "run_vot", "(", "tracker_name", ",", "tracker_param", ",", "run_id", "=", "None", ")", ":", "\n", "    ", "tracker", "=", "Tracker", "(", "tracker_name", ",", "tracker_param", ",", "run_id", ")", "\n", "tracker", ".", "run_vot", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.pytracking.run_vot.main": [[22, 31], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "run_vot.run_vot"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.run_vot"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Run VOT.'", ")", "\n", "parser", ".", "add_argument", "(", "'tracker_name'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'tracker_param'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--run_id'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "run_vot", "(", "args", ".", "tracker_name", ",", "args", ".", "tracker_param", ",", "args", ".", "run_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.pytracking.run_experiment.run_experiment": [[13, 26], ["importlib.import_module", "getattr", "getattr.", "print", "pytracking.evaluation.running.run_dataset"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.running.run_dataset"], ["def", "run_experiment", "(", "experiment_module", ":", "str", ",", "experiment_name", ":", "str", ",", "debug", "=", "0", ",", "threads", "=", "0", ")", ":", "\n", "    ", "\"\"\"Run experiment.\n    args:\n        experiment_module: Name of experiment module in the experiments/ folder.\n        experiment_name: Name of the experiment function.\n        debug: Debug level.\n        threads: Number of threads.\n    \"\"\"", "\n", "expr_module", "=", "importlib", ".", "import_module", "(", "'pytracking.experiments.{}'", ".", "format", "(", "experiment_module", ")", ")", "\n", "expr_func", "=", "getattr", "(", "expr_module", ",", "experiment_name", ")", "\n", "trackers", ",", "dataset", "=", "expr_func", "(", ")", "\n", "print", "(", "'Running:  {}  {}'", ".", "format", "(", "experiment_module", ",", "experiment_name", ")", ")", "\n", "run_dataset", "(", "dataset", ",", "trackers", ",", "debug", ",", "threads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.pytracking.run_experiment.main": [[28, 38], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "run_experiment.run_experiment"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.pytracking.run_experiment.run_experiment"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Run tracker.'", ")", "\n", "parser", ".", "add_argument", "(", "'experiment_module'", ",", "type", "=", "str", ",", "help", "=", "'Name of experiment module in the experiments/ folder.'", ")", "\n", "parser", ".", "add_argument", "(", "'experiment_name'", ",", "type", "=", "str", ",", "help", "=", "'Name of the experiment function.'", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Debug level.'", ")", "\n", "parser", ".", "add_argument", "(", "'--threads'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Number of threads.'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "run_experiment", "(", "args", ".", "experiment_module", ",", "args", ".", "experiment_name", ",", "args", ".", "debug", ",", "args", ".", "threads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.pytracking.run_tracker.run_tracker": [[14, 38], ["pytracking.evaluation.get_dataset", "pytracking.evaluation.running.run_dataset", "pytracking.evaluation.Tracker"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.datasets.get_dataset", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.running.run_dataset"], ["def", "run_tracker", "(", "tracker_name", ",", "tracker_param", ",", "run_id", "=", "None", ",", "dataset_name", "=", "'otb'", ",", "sequence", "=", "None", ",", "debug", "=", "0", ",", "threads", "=", "0", ",", "\n", "visdom_info", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run tracker on sequence or dataset.\n    args:\n        tracker_name: Name of tracking method.\n        tracker_param: Name of parameter file.\n        run_id: The run id.\n        dataset_name: Name of dataset (otb, nfs, uav, tpl, vot, tn, gott, gotv, lasot).\n        sequence: Sequence number or name.\n        debug: Debug level.\n        threads: Number of threads.\n        visdom_info: Dict optionally containing 'use_visdom', 'server' and 'port' for Visdom visualization.\n    \"\"\"", "\n", "\n", "visdom_info", "=", "{", "}", "if", "visdom_info", "is", "None", "else", "visdom_info", "\n", "\n", "dataset", "=", "get_dataset", "(", "dataset_name", ")", "\n", "\n", "if", "sequence", "is", "not", "None", ":", "\n", "        ", "dataset", "=", "[", "dataset", "[", "sequence", "]", "]", "\n", "\n", "", "trackers", "=", "[", "Tracker", "(", "tracker_name", ",", "tracker_param", ",", "run_id", ")", "]", "\n", "\n", "run_dataset", "(", "dataset", ",", "trackers", ",", "debug", ",", "threads", ",", "visdom_info", "=", "visdom_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.pytracking.run_tracker.main": [[40, 62], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "run_tracker.run_tracker", "int"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.run_tracker"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Run tracker on sequence or dataset.'", ")", "\n", "parser", ".", "add_argument", "(", "'tracker_name'", ",", "type", "=", "str", ",", "help", "=", "'Name of tracking method.'", ")", "\n", "parser", ".", "add_argument", "(", "'tracker_param'", ",", "type", "=", "str", ",", "help", "=", "'Name of parameter file.'", ")", "\n", "parser", ".", "add_argument", "(", "'--runid'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "'The run id.'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_name'", ",", "type", "=", "str", ",", "default", "=", "'otb'", ",", "help", "=", "'Name of dataset (otb, nfs, uav, tpl, vot, tn, gott, gotv, lasot).'", ")", "\n", "parser", ".", "add_argument", "(", "'--sequence'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "'Sequence number or name.'", ")", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Debug level.'", ")", "\n", "parser", ".", "add_argument", "(", "'--threads'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Number of threads.'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_visdom'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'Flag to enable visdom.'", ")", "\n", "parser", ".", "add_argument", "(", "'--visdom_server'", ",", "type", "=", "str", ",", "default", "=", "'127.0.0.1'", ",", "help", "=", "'Server for visdom.'", ")", "\n", "parser", ".", "add_argument", "(", "'--visdom_port'", ",", "type", "=", "int", ",", "default", "=", "8097", ",", "help", "=", "'Port for visdom.'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "try", ":", "\n", "        ", "seq_name", "=", "int", "(", "args", ".", "sequence", ")", "\n", "", "except", ":", "\n", "        ", "seq_name", "=", "args", ".", "sequence", "\n", "\n", "", "run_tracker", "(", "args", ".", "tracker_name", ",", "args", ".", "tracker_param", ",", "args", ".", "runid", ",", "args", ".", "dataset_name", ",", "seq_name", ",", "args", ".", "debug", ",", "\n", "args", ".", "threads", ",", "{", "'use_visdom'", ":", "args", ".", "use_visdom", ",", "'server'", ":", "args", ".", "visdom_server", ",", "'port'", ":", "args", ".", "visdom_port", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.VOT.vot.VOT.__init__": [[27, 58], ["trax.Server", "vot.VOT._trax.wait", "isinstance", "vot.VOT._trax.status", "Polygon", "Rectangle", "str", "len", "vot.VOT.image.items", "Point", "vot.VOT.region.bounds", "Exception"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "region_format", ",", "channels", "=", "None", ")", ":", "\n", "        ", "\"\"\" Constructor\n\n        Args:\n            region_format: Region format options\n        \"\"\"", "\n", "assert", "(", "region_format", "in", "[", "trax", ".", "Region", ".", "RECTANGLE", ",", "trax", ".", "Region", ".", "POLYGON", "]", ")", "\n", "\n", "if", "channels", "is", "None", ":", "\n", "            ", "channels", "=", "[", "'color'", "]", "\n", "", "elif", "channels", "==", "'rgbd'", ":", "\n", "            ", "channels", "=", "[", "'color'", ",", "'depth'", "]", "\n", "", "elif", "channels", "==", "'rgbt'", ":", "\n", "            ", "channels", "=", "[", "'color'", ",", "'ir'", "]", "\n", "", "elif", "channels", "==", "'ir'", ":", "\n", "            ", "channels", "=", "[", "'ir'", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Illegal configuration {}.'", ".", "format", "(", "channels", ")", ")", "\n", "\n", "", "self", ".", "_trax", "=", "trax", ".", "Server", "(", "[", "region_format", "]", ",", "[", "trax", ".", "Image", ".", "PATH", "]", ",", "channels", ")", "\n", "\n", "request", "=", "self", ".", "_trax", ".", "wait", "(", ")", "\n", "assert", "(", "request", ".", "type", "==", "'initialize'", ")", "\n", "if", "isinstance", "(", "request", ".", "region", ",", "trax", ".", "Polygon", ")", ":", "\n", "            ", "self", ".", "_region", "=", "Polygon", "(", "[", "Point", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", "for", "x", "in", "request", ".", "region", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_region", "=", "Rectangle", "(", "*", "request", ".", "region", ".", "bounds", "(", ")", ")", "\n", "", "self", ".", "_image", "=", "[", "str", "(", "x", ")", "for", "k", ",", "x", "in", "request", ".", "image", ".", "items", "(", ")", "]", "\n", "if", "len", "(", "self", ".", "_image", ")", "==", "1", ":", "\n", "            ", "self", ".", "_image", "=", "self", ".", "_image", "[", "0", "]", "\n", "", "self", ".", "_trax", ".", "status", "(", "request", ".", "region", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.VOT.vot.VOT.region": [[59, 69], ["None"], "methods", ["None"], ["", "def", "region", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Send configuration message to the client and receive the initialization\n        region and the path of the first image\n\n        Returns:\n            initialization region\n        \"\"\"", "\n", "\n", "return", "self", ".", "_region", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.VOT.vot.VOT.report": [[70, 86], ["isinstance", "vot.VOT._trax.status", "isinstance", "isinstance", "trax.Polygon.create", "trax.Rectangle.create"], "methods", ["None"], ["", "def", "report", "(", "self", ",", "region", ",", "confidence", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Report the tracking results to the client\n\n        Arguments:\n            region: region for the frame\n        \"\"\"", "\n", "assert", "(", "isinstance", "(", "region", ",", "Rectangle", ")", "or", "isinstance", "(", "region", ",", "Polygon", ")", ")", "\n", "if", "isinstance", "(", "region", ",", "Polygon", ")", ":", "\n", "            ", "tregion", "=", "trax", ".", "Polygon", ".", "create", "(", "[", "(", "x", ".", "x", ",", "x", ".", "y", ")", "for", "x", "in", "region", ".", "points", "]", ")", "\n", "", "else", ":", "\n", "            ", "tregion", "=", "trax", ".", "Rectangle", ".", "create", "(", "region", ".", "x", ",", "region", ".", "y", ",", "region", ".", "width", ",", "region", ".", "height", ")", "\n", "", "properties", "=", "{", "}", "\n", "if", "not", "confidence", "is", "None", ":", "\n", "            ", "properties", "[", "'confidence'", "]", "=", "confidence", "\n", "", "self", ".", "_trax", ".", "status", "(", "tregion", ",", "properties", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.VOT.vot.VOT.frame": [[87, 108], ["hasattr", "vot.VOT._trax.wait", "tuple", "tuple", "str", "len", "vot.VOT.image.items"], "methods", ["None"], ["", "def", "frame", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get a frame (image path) from client\n\n        Returns:\n            absolute path of the image\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ",", "\"_image\"", ")", ":", "\n", "            ", "image", "=", "self", ".", "_image", "\n", "del", "self", ".", "_image", "\n", "return", "tuple", "(", "image", ")", "\n", "\n", "", "request", "=", "self", ".", "_trax", ".", "wait", "(", ")", "\n", "\n", "if", "request", ".", "type", "==", "'frame'", ":", "\n", "            ", "image", "=", "[", "str", "(", "x", ")", "for", "k", ",", "x", "in", "request", ".", "image", ".", "items", "(", ")", "]", "\n", "if", "len", "(", "image", ")", "==", "1", ":", "\n", "                ", "image", "=", "image", "[", "0", "]", "\n", "", "return", "tuple", "(", "image", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.VOT.vot.VOT.quit": [[110, 113], ["hasattr", "vot.VOT._trax.quit"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.quit"], ["", "", "def", "quit", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "'_trax'", ")", ":", "\n", "            ", "self", ".", "_trax", ".", "quit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.VOT.vot.VOT.__del__": [[114, 116], ["vot.VOT.quit"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.quit"], ["", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "quit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.draw_figure": [[7, 11], ["fig.canvas.draw", "fig.canvas.flush_events", "matplotlib.pause"], "function", ["None"], ["def", "draw_figure", "(", "fig", ")", ":", "\n", "    ", "fig", ".", "canvas", ".", "draw", "(", ")", "\n", "fig", ".", "canvas", ".", "flush_events", "(", ")", "\n", "plt", ".", "pause", "(", "0.001", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_tensor": [[13, 41], ["a.squeeze().cpu().clone().detach().numpy", "numpy.transpose", "matplotlib.figure", "matplotlib.tight_layout", "matplotlib.cla", "matplotlib.imshow", "matplotlib.axis", "matplotlib.axis", "plotting.draw_figure", "ax.cla", "ax.imshow", "ax.set_axis_off", "ax.axis", "plotting.draw_figure", "a.squeeze().cpu().clone().detach", "matplotlib.title", "ax.set_title", "matplotlib.gcf", "a.squeeze().cpu().clone", "a.squeeze().cpu", "a.squeeze"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.draw_figure", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.draw_figure"], ["", "def", "show_tensor", "(", "a", ":", "torch", ".", "Tensor", ",", "fig_num", "=", "None", ",", "title", "=", "None", ",", "range", "=", "(", "None", ",", "None", ")", ",", "ax", "=", "None", ")", ":", "\n", "    ", "\"\"\"Display a 2D tensor.\n    args:\n        fig_num: Figure number.\n        title: Title of figure.\n    \"\"\"", "\n", "a_np", "=", "a", ".", "squeeze", "(", ")", ".", "cpu", "(", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "if", "a_np", ".", "ndim", "==", "3", ":", "\n", "        ", "a_np", "=", "np", ".", "transpose", "(", "a_np", ",", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "\n", "", "if", "ax", "is", "None", ":", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "fig_num", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "cla", "(", ")", "\n", "plt", ".", "imshow", "(", "a_np", ",", "vmin", "=", "range", "[", "0", "]", ",", "vmax", "=", "range", "[", "1", "]", ")", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "plt", ".", "axis", "(", "'equal'", ")", "\n", "if", "title", "is", "not", "None", ":", "\n", "            ", "plt", ".", "title", "(", "title", ")", "\n", "", "draw_figure", "(", "fig", ")", "\n", "", "else", ":", "\n", "        ", "ax", ".", "cla", "(", ")", "\n", "ax", ".", "imshow", "(", "a_np", ",", "vmin", "=", "range", "[", "0", "]", ",", "vmax", "=", "range", "[", "1", "]", ")", "\n", "ax", ".", "set_axis_off", "(", ")", "\n", "ax", ".", "axis", "(", "'equal'", ")", "\n", "if", "title", "is", "not", "None", ":", "\n", "            ", "ax", ".", "set_title", "(", "title", ")", "\n", "", "draw_figure", "(", "plt", ".", "gcf", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph": [[43, 59], ["a.squeeze().cpu().clone().detach().numpy", "matplotlib.figure", "matplotlib.cla", "matplotlib.plot", "plotting.draw_figure", "matplotlib.title", "a.squeeze().cpu().clone().detach", "a.squeeze().cpu().clone", "a.squeeze().cpu", "a.squeeze"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.draw_figure"], ["", "", "def", "plot_graph", "(", "a", ":", "torch", ".", "Tensor", ",", "fig_num", "=", "None", ",", "title", "=", "None", ")", ":", "\n", "    ", "\"\"\"Plot graph. Data is a 1D tensor.\n    args:\n        fig_num: Figure number.\n        title: Title of figure.\n    \"\"\"", "\n", "a_np", "=", "a", ".", "squeeze", "(", ")", ".", "cpu", "(", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "if", "a_np", ".", "ndim", ">", "1", ":", "\n", "        ", "raise", "ValueError", "\n", "", "fig", "=", "plt", ".", "figure", "(", "fig_num", ")", "\n", "# plt.tight_layout()", "\n", "plt", ".", "cla", "(", ")", "\n", "plt", ".", "plot", "(", "a_np", ")", "\n", "if", "title", "is", "not", "None", ":", "\n", "        ", "plt", ".", "title", "(", "title", ")", "\n", "", "draw_figure", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_image_with_boxes": [[61, 83], ["im.clone().cpu().squeeze().numpy", "numpy.ascontiguousarray", "boxes.view().cpu().numpy().round().astype.view().cpu().numpy().round().astype", "range", "torch.from_numpy().float", "np.ascontiguousarray.transpose().astype", "im.clone().cpu().squeeze", "boxes.view().cpu().numpy().round().astype.view().cpu().numpy().round", "cv2.rectangle", "torch.from_numpy", "np.ascontiguousarray.transpose", "cv2.putText", "np.ascontiguousarray.transpose", "im.clone().cpu", "boxes.view().cpu().numpy().round().astype.view().cpu().numpy", "im.clone", "boxes.view().cpu().numpy().round().astype.view().cpu", "boxes.view().cpu().numpy().round().astype.view"], "function", ["None"], ["", "def", "show_image_with_boxes", "(", "im", ",", "boxes", ",", "iou_pred", "=", "None", ",", "disp_ids", "=", "None", ")", ":", "\n", "    ", "im_np", "=", "im", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "squeeze", "(", ")", ".", "numpy", "(", ")", "\n", "im_np", "=", "np", ".", "ascontiguousarray", "(", "im_np", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "\n", "boxes", "=", "boxes", ".", "view", "(", "-", "1", ",", "4", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "round", "(", ")", ".", "astype", "(", "int", ")", "\n", "\n", "# Draw proposals", "\n", "for", "i_", "in", "range", "(", "boxes", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "if", "disp_ids", "is", "None", "or", "disp_ids", "[", "i_", "]", ":", "\n", "            ", "bb", "=", "boxes", "[", "i_", ",", ":", "]", "\n", "disp_color", "=", "(", "i_", "*", "38", "%", "256", ",", "(", "255", "-", "i_", "*", "97", ")", "%", "256", ",", "(", "123", "+", "i_", "*", "66", ")", "%", "256", ")", "\n", "cv2", ".", "rectangle", "(", "im_np", ",", "(", "bb", "[", "0", "]", ",", "bb", "[", "1", "]", ")", ",", "(", "bb", "[", "0", "]", "+", "bb", "[", "2", "]", ",", "bb", "[", "1", "]", "+", "bb", "[", "3", "]", ")", ",", "\n", "disp_color", ",", "1", ")", "\n", "\n", "if", "iou_pred", "is", "not", "None", ":", "\n", "                ", "text_pos", "=", "(", "bb", "[", "0", "]", ",", "bb", "[", "1", "]", "-", "5", ")", "\n", "cv2", ".", "putText", "(", "im_np", ",", "'ID={} IOU = {:3.2f}'", ".", "format", "(", "i_", ",", "iou_pred", "[", "i_", "]", ")", ",", "text_pos", ",", "\n", "cv2", ".", "FONT_HERSHEY_SIMPLEX", ",", "0.5", ",", "(", "0", ",", "255", ",", "0", ")", ",", "1", ",", "bottomLeftOrigin", "=", "False", ")", "\n", "\n", "", "", "", "im_tensor", "=", "torch", ".", "from_numpy", "(", "im_np", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ")", ".", "float", "(", ")", "\n", "\n", "return", "im_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting._pascal_color_map": [[86, 111], ["numpy.zeros", "range", "range", "numpy.array", "plotting._pascal_color_map.bitget"], "function", ["None"], ["", "def", "_pascal_color_map", "(", "N", "=", "256", ",", "normalized", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Python implementation of the color map function for the PASCAL VOC data set.\n    Official Matlab version can be found in the PASCAL VOC devkit\n    http://host.robots.ox.ac.uk/pascal/VOC/voc2012/index.html#devkit\n    \"\"\"", "\n", "\n", "def", "bitget", "(", "byteval", ",", "idx", ")", ":", "\n", "        ", "return", "(", "byteval", "&", "(", "1", "<<", "idx", ")", ")", "!=", "0", "\n", "\n", "", "dtype", "=", "'float32'", "if", "normalized", "else", "'uint8'", "\n", "cmap", "=", "np", ".", "zeros", "(", "(", "N", ",", "3", ")", ",", "dtype", "=", "dtype", ")", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "        ", "r", "=", "g", "=", "b", "=", "0", "\n", "c", "=", "i", "\n", "for", "j", "in", "range", "(", "8", ")", ":", "\n", "            ", "r", "=", "r", "|", "(", "bitget", "(", "c", ",", "0", ")", "<<", "7", "-", "j", ")", "\n", "g", "=", "g", "|", "(", "bitget", "(", "c", ",", "1", ")", "<<", "7", "-", "j", ")", "\n", "b", "=", "b", "|", "(", "bitget", "(", "c", ",", "2", ")", "<<", "7", "-", "j", ")", "\n", "c", "=", "c", ">>", "3", "\n", "\n", "", "cmap", "[", "i", "]", "=", "np", ".", "array", "(", "[", "r", ",", "g", ",", "b", "]", ")", "\n", "\n", "", "cmap", "=", "cmap", "/", "255", "if", "normalized", "else", "cmap", "\n", "return", "cmap", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.overlay_mask": [[113, 156], ["numpy.asarray", "im.copy", "numpy.asarray", "numpy.asarray", "ValueError", "ValueError", "plotting._pascal_color_map", "numpy.unique", "cv2.drawContours", "cv2.findContours", "colors[].tolist"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting._pascal_color_map"], ["", "def", "overlay_mask", "(", "im", ",", "ann", ",", "alpha", "=", "0.5", ",", "colors", "=", "None", ",", "contour_thickness", "=", "None", ")", ":", "\n", "    ", "\"\"\" Overlay mask over image.\n    Source: https://github.com/albertomontesg/davis-interactive/blob/master/davisinteractive/utils/visualization.py\n    This function allows you to overlay a mask over an image with some\n    transparency.\n    # Arguments\n        im: Numpy Array. Array with the image. The shape must be (H, W, 3) and\n            the pixels must be represented as `np.uint8` data type.\n        ann: Numpy Array. Array with the mask. The shape must be (H, W) and the\n            values must be integers\n        alpha: Float. Proportion of alpha to apply at the overlaid mask.\n        colors: Numpy Array. Optional custom colormap. It must have shape (N, 3)\n            being N the maximum number of colors to represent.\n        contour_thickness: Integer. Thickness of each object index contour draw\n            over the overlay. This function requires to have installed the\n            package `opencv-python`.\n    # Returns\n        Numpy Array: Image of the overlay with shape (H, W, 3) and data type\n            `np.uint8`.\n    \"\"\"", "\n", "im", ",", "ann", "=", "np", ".", "asarray", "(", "im", ",", "dtype", "=", "np", ".", "uint8", ")", ",", "np", ".", "asarray", "(", "ann", ",", "dtype", "=", "np", ".", "int", ")", "\n", "if", "im", ".", "shape", "[", ":", "-", "1", "]", "!=", "ann", ".", "shape", ":", "\n", "        ", "raise", "ValueError", "(", "'First two dimensions of `im` and `ann` must match'", ")", "\n", "", "if", "im", ".", "shape", "[", "-", "1", "]", "!=", "3", ":", "\n", "        ", "raise", "ValueError", "(", "'im must have three channels at the 3 dimension'", ")", "\n", "\n", "", "colors", "=", "colors", "or", "_pascal_color_map", "(", ")", "\n", "colors", "=", "np", ".", "asarray", "(", "colors", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "mask", "=", "colors", "[", "ann", "]", "\n", "fg", "=", "im", "*", "alpha", "+", "(", "1", "-", "alpha", ")", "*", "mask", "\n", "\n", "img", "=", "im", ".", "copy", "(", ")", "\n", "img", "[", "ann", ">", "0", "]", "=", "fg", "[", "ann", ">", "0", "]", "\n", "\n", "if", "contour_thickness", ":", "# pragma: no cover", "\n", "        ", "import", "cv2", "\n", "for", "obj_id", "in", "np", ".", "unique", "(", "ann", "[", "ann", ">", "0", "]", ")", ":", "\n", "            ", "contours", "=", "cv2", ".", "findContours", "(", "(", "ann", "==", "obj_id", ")", ".", "astype", "(", "\n", "np", ".", "uint8", ")", ",", "cv2", ".", "RETR_TREE", ",", "cv2", ".", "CHAIN_APPROX_SIMPLE", ")", "[", "-", "2", ":", "]", "\n", "cv2", ".", "drawContours", "(", "img", ",", "contours", "[", "0", "]", ",", "-", "1", ",", "colors", "[", "obj_id", "]", ".", "tolist", "(", ")", ",", "\n", "contour_thickness", ")", "\n", "", "", "return", "img", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBase.__init__": [[13, 18], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "visdom", ",", "show_data", ",", "title", ")", ":", "\n", "        ", "self", ".", "visdom", "=", "visdom", "\n", "self", ".", "show_data", "=", "show_data", "\n", "self", ".", "title", "=", "title", "\n", "self", ".", "raw_data", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBase.update": [[19, 24], ["visdom.VisBase.save_data", "visdom.VisBase.save_data", "visdom.VisBase.draw_data", "visdom.VisBase.draw_data"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.save_data", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.save_data", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.draw_data", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.draw_data"], ["", "def", "update", "(", "self", ",", "data", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "save_data", "(", "data", ",", "**", "kwargs", ")", "\n", "\n", "if", "self", ".", "show_data", ":", "\n", "            ", "self", ".", "draw_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBase.save_data": [[25, 27], ["None"], "methods", ["None"], ["", "", "def", "save_data", "(", "self", ",", "data", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBase.draw_data": [[28, 30], ["None"], "methods", ["None"], ["", "def", "draw_data", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBase.toggle_display": [[31, 41], ["visdom.VisBase.draw_data", "visdom.VisBase.draw_data", "visdom.VisBase.visdom.close", "visdom.VisBase.visdom.close"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.draw_data", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.draw_data"], ["", "def", "toggle_display", "(", "self", ",", "new_mode", "=", "None", ")", ":", "\n", "        ", "if", "new_mode", "is", "not", "None", ":", "\n", "            ", "self", ".", "show_data", "=", "new_mode", "\n", "", "else", ":", "\n", "            ", "self", ".", "show_data", "=", "not", "self", ".", "show_data", "\n", "\n", "", "if", "self", ".", "show_data", ":", "\n", "            ", "self", ".", "draw_data", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "visdom", ".", "close", "(", "self", ".", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisImage.__init__": [[44, 46], ["visdom.VisBase.__init__", "visdom.VisBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "visdom", ",", "show_data", ",", "title", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "visdom", ",", "show_data", ",", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisImage.save_data": [[47, 50], ["data.float.float.float"], "methods", ["None"], ["", "def", "save_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "data", "=", "data", ".", "float", "(", ")", "\n", "self", ".", "raw_data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisImage.draw_data": [[51, 53], ["visdom.VisImage.visdom.image", "visdom.VisImage.visdom.image", "visdom.VisImage.raw_data.clone", "visdom.VisImage.raw_data.clone"], "methods", ["None"], ["", "def", "draw_data", "(", "self", ")", ":", "\n", "        ", "self", ".", "visdom", ".", "image", "(", "self", ".", "raw_data", ".", "clone", "(", ")", ",", "opts", "=", "{", "'title'", ":", "self", ".", "title", "}", ",", "win", "=", "self", ".", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisHeatmap.__init__": [[56, 58], ["visdom.VisBase.__init__", "visdom.VisBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "visdom", ",", "show_data", ",", "title", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "visdom", ",", "show_data", ",", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisHeatmap.save_data": [[59, 62], ["data.squeeze().flip.squeeze().flip.squeeze().flip", "data.squeeze().flip.squeeze().flip.squeeze"], "methods", ["None"], ["", "def", "save_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "data", "=", "data", ".", "squeeze", "(", ")", ".", "flip", "(", "0", ")", "\n", "self", ".", "raw_data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisHeatmap.draw_data": [[63, 65], ["visdom.VisHeatmap.visdom.heatmap", "visdom.VisHeatmap.visdom.heatmap", "visdom.VisHeatmap.raw_data.clone", "visdom.VisHeatmap.raw_data.clone"], "methods", ["None"], ["", "def", "draw_data", "(", "self", ")", ":", "\n", "        ", "self", ".", "visdom", ".", "heatmap", "(", "self", ".", "raw_data", ".", "clone", "(", ")", ",", "opts", "=", "{", "'title'", ":", "self", ".", "title", "}", ",", "win", "=", "self", ".", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisFeaturemap.__init__": [[68, 71], ["visdom.VisBase.__init__", "visdom.VisBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "visdom", ",", "show_data", ",", "title", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "visdom", ",", "show_data", ",", "title", ")", "\n", "self", ".", "block_list", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisFeaturemap.block_list_callback_handler": [[72, 76], ["visdom.VisFeaturemap.visdom.properties", "visdom.VisFeaturemap.visdom.properties", "visdom.VisFeaturemap.draw_data", "visdom.VisFeaturemap.draw_data"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.draw_data", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.draw_data"], ["", "def", "block_list_callback_handler", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "block_list", "[", "data", "[", "'propertyId'", "]", "]", "[", "'value'", "]", "=", "data", "[", "'value'", "]", "\n", "self", ".", "visdom", ".", "properties", "(", "self", ".", "block_list", ",", "opts", "=", "{", "'title'", ":", "'Featuremap UI'", "}", ",", "win", "=", "'featuremap_ui'", ")", "\n", "self", ".", "draw_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisFeaturemap.save_data": [[77, 90], ["data.flip.flip.view", "data.flip.flip.flip", "range", "visdom.VisFeaturemap.visdom.properties", "visdom.VisFeaturemap.visdom.properties", "visdom.VisFeaturemap.visdom.register_event_handler", "visdom.VisFeaturemap.visdom.register_event_handler", "visdom.VisFeaturemap.block_list.append", "visdom.VisFeaturemap.block_list.append"], "methods", ["None"], ["", "def", "save_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "data", "=", "data", ".", "view", "(", "-", "1", ",", "*", "data", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "data", "=", "data", ".", "flip", "(", "1", ")", "\n", "if", "self", ".", "block_list", "is", "None", ":", "\n", "            ", "self", ".", "block_list", "=", "[", "]", "\n", "self", ".", "draw_feat", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "data", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "self", ".", "block_list", ".", "append", "(", "{", "'type'", ":", "'checkbox'", ",", "'name'", ":", "'Channel {:04d}'", ".", "format", "(", "i", ")", ",", "'value'", ":", "False", "}", ")", "\n", "\n", "", "self", ".", "visdom", ".", "properties", "(", "self", ".", "block_list", ",", "opts", "=", "{", "'title'", ":", "'Featuremap UI'", "}", ",", "win", "=", "'featuremap_ui'", ")", "\n", "self", ".", "visdom", ".", "register_event_handler", "(", "self", ".", "block_list_callback_handler", ",", "'featuremap_ui'", ")", "\n", "\n", "", "self", ".", "raw_data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisFeaturemap.draw_data": [[91, 98], ["enumerate", "visdom.VisFeaturemap.visdom.heatmap", "visdom.VisFeaturemap.visdom.heatmap", "visdom.VisFeaturemap.raw_data[].clone", "visdom.VisFeaturemap.raw_data[].clone"], "methods", ["None"], ["", "def", "draw_data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "block_list", "is", "not", "None", "and", "self", ".", "show_data", ":", "\n", "            ", "for", "i", ",", "d", "in", "enumerate", "(", "self", ".", "block_list", ")", ":", "\n", "                ", "if", "d", "[", "'value'", "]", ":", "\n", "                    ", "fig_title", "=", "'{} ch: {:04d}'", ".", "format", "(", "self", ".", "title", ",", "i", ")", "\n", "self", ".", "visdom", ".", "heatmap", "(", "self", ".", "raw_data", "[", "i", ",", ":", ",", ":", "]", ".", "clone", "(", ")", ",", "\n", "opts", "=", "{", "'title'", ":", "fig_title", "}", ",", "win", "=", "fig_title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.__init__": [[101, 106], ["visdom.VisBase.__init__", "visdom.VisBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "visdom", ",", "show_data", ",", "title", ",", "flip", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "visdom", ",", "show_data", ",", "title", ")", "\n", "self", ".", "show_slice", "=", "False", "\n", "self", ".", "slice_pos", "=", "None", "\n", "self", ".", "flip", "=", "flip", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.show_cost_volume": [[107, 117], ["visdom.VisCostVolume.raw_data.clone", "visdom.VisCostVolume.raw_data.clone", "visdom.VisCostVolume.permute().contiguous", "visdom.VisCostVolume.permute().contiguous", "data_perm.permute().contiguous.permute().contiguous.view", "visdom.VisCostVolume.visdom.heatmap", "visdom.VisCostVolume.visdom.heatmap", "data_perm.permute().contiguous.permute().contiguous.permute().contiguous", "data_perm.permute().contiguous.permute().contiguous.flip", "visdom.VisCostVolume.permute", "visdom.VisCostVolume.permute", "data_perm.permute().contiguous.permute().contiguous.permute"], "methods", ["None"], ["", "def", "show_cost_volume", "(", "self", ")", ":", "\n", "        ", "data", "=", "self", ".", "raw_data", ".", "clone", "(", ")", "\n", "\n", "# data_perm = data.permute(2, 0, 3, 1).contiguous()", "\n", "data_perm", "=", "data", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "if", "self", ".", "flip", ":", "\n", "            ", "data_perm", "=", "data_perm", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "data_perm", "=", "data_perm", ".", "view", "(", "data_perm", ".", "shape", "[", "0", "]", "*", "data_perm", ".", "shape", "[", "1", "]", ",", "-", "1", ")", "\n", "self", ".", "visdom", ".", "heatmap", "(", "data_perm", ".", "flip", "(", "0", ")", ",", "opts", "=", "{", "'title'", ":", "self", ".", "title", "}", ",", "win", "=", "self", ".", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.set_zoom_pos": [[118, 120], ["None"], "methods", ["None"], ["", "def", "set_zoom_pos", "(", "self", ",", "slice_pos", ")", ":", "\n", "        ", "self", ".", "slice_pos", "=", "slice_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.toggle_show_slice": [[121, 126], ["None"], "methods", ["None"], ["", "def", "toggle_show_slice", "(", "self", ",", "new_mode", "=", "None", ")", ":", "\n", "        ", "if", "new_mode", "is", "not", "None", ":", "\n", "            ", "self", ".", "show_slice", "=", "new_mode", "\n", "", "else", ":", "\n", "            ", "self", ".", "show_slice", "=", "not", "self", ".", "show_slice", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.show_cost_volume_slice": [[127, 138], ["visdom.VisCostVolume.raw_data.clone", "visdom.VisCostVolume.raw_data.clone", "visdom.VisCostVolume.visdom.heatmap", "visdom.VisCostVolume.visdom.heatmap", "cost_volume_slice.flip"], "methods", ["None"], ["", "", "def", "show_cost_volume_slice", "(", "self", ")", ":", "\n", "        ", "slice_pos", "=", "self", ".", "slice_pos", "\n", "\n", "# slice_pos: [row, col]", "\n", "cost_volume_data", "=", "self", ".", "raw_data", ".", "clone", "(", ")", "\n", "\n", "if", "self", ".", "flip", ":", "\n", "            ", "cost_volume_slice", "=", "cost_volume_data", "[", ":", ",", ":", ",", "slice_pos", "[", "0", "]", ",", "slice_pos", "[", "1", "]", "]", "\n", "", "else", ":", "\n", "            ", "cost_volume_slice", "=", "cost_volume_data", "[", "slice_pos", "[", "0", "]", ",", "slice_pos", "[", "1", "]", ",", ":", ",", ":", "]", "\n", "", "self", ".", "visdom", ".", "heatmap", "(", "cost_volume_slice", ".", "flip", "(", "0", ")", ",", "opts", "=", "{", "'title'", ":", "self", ".", "title", "}", ",", "win", "=", "self", ".", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.save_data": [[139, 142], ["data.view.view.view"], "methods", ["None"], ["", "def", "save_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "data", "=", "data", ".", "view", "(", "data", ".", "shape", "[", "-", "2", "]", ",", "data", ".", "shape", "[", "-", "1", "]", ",", "data", ".", "shape", "[", "-", "2", "]", ",", "data", ".", "shape", "[", "-", "1", "]", ")", "\n", "self", ".", "raw_data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.draw_data": [[143, 148], ["visdom.VisCostVolume.show_cost_volume_slice", "visdom.VisCostVolume.show_cost_volume_slice", "visdom.VisCostVolume.show_cost_volume", "visdom.VisCostVolume.show_cost_volume"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.show_cost_volume_slice", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.show_cost_volume_slice", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.show_cost_volume", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.show_cost_volume"], ["", "def", "draw_data", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "show_slice", ":", "\n", "            ", "self", ".", "show_cost_volume_slice", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "show_cost_volume", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.cv_ui_handler": [[151, 177], ["visdom.VisCostVolumeUI.show_image", "visdom.VisCostVolumeUI.show_image", "visdom.VisCostVolumeUI.registered_blocks.items", "visdom.VisCostVolumeUI.registered_blocks.items", "isinstance", "min", "block.set_zoom_pos", "block.toggle_show_slice", "max", "block.draw_data", "max", "min"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.show_image", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.show_image", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.set_zoom_pos", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolume.toggle_show_slice", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.draw_data"], ["    ", "def", "cv_ui_handler", "(", "self", ",", "data", ")", ":", "\n", "        ", "zoom_toggled", "=", "False", "\n", "if", "data", "[", "'event_type'", "]", "==", "'KeyPress'", ":", "\n", "            ", "if", "data", "[", "'key'", "]", "==", "'ArrowRight'", ":", "\n", "                ", "self", ".", "zoom_pos", "[", "1", "]", "=", "min", "(", "self", ".", "zoom_pos", "[", "1", "]", "+", "1", ",", "self", ".", "feat_shape", "[", "1", "]", "-", "1", ")", "\n", "", "elif", "data", "[", "'key'", "]", "==", "'ArrowLeft'", ":", "\n", "                ", "self", ".", "zoom_pos", "[", "1", "]", "=", "max", "(", "self", ".", "zoom_pos", "[", "1", "]", "-", "1", ",", "0", ")", "\n", "", "elif", "data", "[", "'key'", "]", "==", "'ArrowUp'", ":", "\n", "                ", "self", ".", "zoom_pos", "[", "0", "]", "=", "max", "(", "self", ".", "zoom_pos", "[", "0", "]", "-", "1", ",", "0", ")", "\n", "", "elif", "data", "[", "'key'", "]", "==", "'ArrowDown'", ":", "\n", "                ", "self", ".", "zoom_pos", "[", "0", "]", "=", "min", "(", "self", ".", "zoom_pos", "[", "0", "]", "+", "1", ",", "self", ".", "feat_shape", "[", "0", "]", "-", "1", ")", "\n", "", "elif", "data", "[", "'key'", "]", "==", "'Enter'", ":", "\n", "                ", "self", ".", "zoom_mode", "=", "not", "self", ".", "zoom_mode", "\n", "zoom_toggled", "=", "True", "\n", "\n", "# Update image", "\n", "", "", "self", ".", "show_image", "(", ")", "\n", "\n", "# Update cost volumes", "\n", "for", "block_title", ",", "block", "in", "self", ".", "registered_blocks", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "block", ",", "VisCostVolume", ")", ":", "\n", "                ", "block", ".", "set_zoom_pos", "(", "self", ".", "zoom_pos", ")", "\n", "block", ".", "toggle_show_slice", "(", "self", ".", "zoom_mode", ")", "\n", "\n", "if", "(", "self", ".", "zoom_mode", "or", "zoom_toggled", ")", "and", "block", ".", "show_data", ":", "\n", "                    ", "block", ".", "draw_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.__init__": [[178, 186], ["visdom.VisBase.__init__", "visdom.VisBase.__init__", "visdom.VisCostVolumeUI.visdom.register_event_handler", "visdom.VisCostVolumeUI.visdom.register_event_handler", "int", "int"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["", "", "", "", "def", "__init__", "(", "self", ",", "visdom", ",", "show_data", ",", "title", ",", "feat_shape", ",", "registered_blocks", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "visdom", ",", "show_data", ",", "title", ")", "\n", "self", ".", "feat_shape", "=", "feat_shape", "\n", "self", ".", "zoom_mode", "=", "False", "\n", "self", ".", "zoom_pos", "=", "[", "int", "(", "(", "feat_shape", "[", "0", "]", "-", "1", ")", "/", "2", ")", ",", "int", "(", "(", "feat_shape", "[", "1", "]", "-", "1", ")", "/", "2", ")", "]", "\n", "self", ".", "registered_blocks", "=", "registered_blocks", "\n", "\n", "self", ".", "visdom", ".", "register_event_handler", "(", "self", ".", "cv_ui_handler", ",", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.draw_grid": [[187, 199], ["int", "int", "list", "list", "list", "list", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "draw_grid", "(", "self", ",", "data", ")", ":", "\n", "        ", "stride_r", "=", "int", "(", "data", ".", "shape", "[", "1", "]", "/", "self", ".", "feat_shape", "[", "0", "]", ")", "\n", "stride_c", "=", "int", "(", "data", ".", "shape", "[", "2", "]", "/", "self", ".", "feat_shape", "[", "1", "]", ")", "\n", "\n", "# Draw grid", "\n", "data", "[", ":", ",", "list", "(", "range", "(", "0", ",", "data", ".", "shape", "[", "1", "]", ",", "stride_r", ")", ")", ",", ":", "]", "=", "0", "\n", "data", "[", ":", ",", ":", ",", "list", "(", "range", "(", "0", ",", "data", ".", "shape", "[", "2", "]", ",", "stride_c", ")", ")", "]", "=", "0", "\n", "\n", "data", "[", "0", ",", "list", "(", "range", "(", "0", ",", "data", ".", "shape", "[", "1", "]", ",", "stride_r", ")", ")", ",", ":", "]", "=", "255", "\n", "data", "[", "0", ",", ":", ",", "list", "(", "range", "(", "0", ",", "data", ".", "shape", "[", "2", "]", ",", "stride_c", ")", ")", "]", "=", "255", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.shade_cell": [[200, 213], ["int", "int", "min", "min", "torch.tensor().view().to", "torch.tensor().view", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "shade_cell", "(", "self", ",", "data", ")", ":", "\n", "        ", "stride_r", "=", "int", "(", "data", ".", "shape", "[", "1", "]", "/", "self", ".", "feat_shape", "[", "0", "]", ")", "\n", "stride_c", "=", "int", "(", "data", ".", "shape", "[", "2", "]", "/", "self", ".", "feat_shape", "[", "1", "]", ")", "\n", "\n", "r1", "=", "self", ".", "zoom_pos", "[", "0", "]", "*", "stride_r", "\n", "r2", "=", "min", "(", "(", "self", ".", "zoom_pos", "[", "0", "]", "+", "1", ")", "*", "stride_r", ",", "data", ".", "shape", "[", "1", "]", ")", "\n", "\n", "c1", "=", "self", ".", "zoom_pos", "[", "1", "]", "*", "stride_c", "\n", "c2", "=", "min", "(", "(", "self", ".", "zoom_pos", "[", "1", "]", "+", "1", ")", "*", "stride_c", ",", "data", ".", "shape", "[", "2", "]", ")", "\n", "\n", "factor", "=", "0.8", "if", "self", ".", "zoom_mode", "else", "0.5", "\n", "data", "[", ":", ",", "r1", ":", "r2", ",", "c1", ":", "c2", "]", "=", "data", "[", ":", ",", "r1", ":", "r2", ",", "c1", ":", "c2", "]", "*", "(", "1", "-", "factor", ")", "+", "torch", ".", "tensor", "(", "[", "255.0", ",", "0.0", ",", "0.0", "]", ")", ".", "view", "(", "3", ",", "1", ",", "1", ")", ".", "to", "(", "data", ".", "device", ")", "*", "factor", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.show_image": [[214, 221], ["visdom.VisCostVolumeUI.draw_grid", "visdom.VisCostVolumeUI.draw_grid", "visdom.VisCostVolumeUI.shade_cell", "visdom.VisCostVolumeUI.shade_cell", "visdom.VisCostVolumeUI.visdom.image", "visdom.VisCostVolumeUI.visdom.image", "visdom.VisCostVolumeUI.raw_data.clone", "visdom.VisCostVolumeUI.raw_data.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.draw_grid", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.draw_grid", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.shade_cell", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.shade_cell"], ["", "def", "show_image", "(", "self", ",", "data", "=", "None", ")", ":", "\n", "        ", "if", "data", "is", "None", ":", "\n", "            ", "data", "=", "self", ".", "raw_data", ".", "clone", "(", ")", "\n", "\n", "", "data", "=", "self", ".", "draw_grid", "(", "data", ")", "\n", "data", "=", "self", ".", "shade_cell", "(", "data", ")", "\n", "self", ".", "visdom", ".", "image", "(", "data", ",", "opts", "=", "{", "'title'", ":", "self", ".", "title", "}", ",", "win", "=", "self", ".", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.save_data": [[222, 227], ["data.float.float.float"], "methods", ["None"], ["", "def", "save_data", "(", "self", ",", "data", ")", ":", "\n", "# Ignore feat shape", "\n", "        ", "data", "=", "data", "[", "0", "]", "\n", "data", "=", "data", ".", "float", "(", ")", "\n", "self", ".", "raw_data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.draw_data": [[228, 230], ["visdom.VisCostVolumeUI.show_image", "visdom.VisCostVolumeUI.show_image", "visdom.VisCostVolumeUI.raw_data.clone", "visdom.VisCostVolumeUI.raw_data.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.show_image", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisCostVolumeUI.show_image"], ["", "def", "draw_data", "(", "self", ")", ":", "\n", "        ", "self", ".", "show_image", "(", "self", ".", "raw_data", ".", "clone", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisInfoDict.__init__": [[233, 236], ["visdom.VisBase.__init__", "visdom.VisBase.__init__", "collections.OrderedDict"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "visdom", ",", "show_data", ",", "title", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "visdom", ",", "show_data", ",", "title", ")", "\n", "self", ".", "raw_data", "=", "OrderedDict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisInfoDict.generate_display_text": [[237, 249], ["data.items", "key.replace.replace.replace", "isinstance"], "methods", ["None"], ["", "def", "generate_display_text", "(", "self", ",", "data", ")", ":", "\n", "        ", "display_text", "=", "''", "\n", "for", "key", ",", "value", "in", "data", ".", "items", "(", ")", ":", "\n", "            ", "key", "=", "key", ".", "replace", "(", "'_'", ",", "' '", ")", "\n", "if", "value", "is", "None", ":", "\n", "                ", "display_text", "+=", "'<b>{}</b>: {}<br>'", ".", "format", "(", "key", ",", "'None'", ")", "\n", "", "elif", "isinstance", "(", "value", ",", "(", "str", ",", "int", ")", ")", ":", "\n", "                ", "display_text", "+=", "'<b>{}</b>: {}<br>'", ".", "format", "(", "key", ",", "value", ")", "\n", "", "else", ":", "\n", "                ", "display_text", "+=", "'<b>{}</b>: {:.2f}<br>'", ".", "format", "(", "key", ",", "value", ")", "\n", "\n", "", "", "return", "display_text", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisInfoDict.save_data": [[250, 253], ["data.items"], "methods", ["None"], ["", "def", "save_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "for", "key", ",", "val", "in", "data", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "raw_data", "[", "key", "]", "=", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisInfoDict.draw_data": [[254, 258], ["copy.deepcopy", "visdom.VisInfoDict.generate_display_text", "visdom.VisInfoDict.generate_display_text", "visdom.VisInfoDict.visdom.text", "visdom.VisInfoDict.visdom.text"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisInfoDict.generate_display_text", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisInfoDict.generate_display_text"], ["", "", "def", "draw_data", "(", "self", ")", ":", "\n", "        ", "data", "=", "copy", ".", "deepcopy", "(", "self", ".", "raw_data", ")", "\n", "display_text", "=", "self", ".", "generate_display_text", "(", "data", ")", "\n", "self", ".", "visdom", ".", "text", "(", "display_text", ",", "opts", "=", "{", "'title'", ":", "self", ".", "title", "}", ",", "win", "=", "self", ".", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisText.__init__": [[261, 263], ["visdom.VisBase.__init__", "visdom.VisBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "visdom", ",", "show_data", ",", "title", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "visdom", ",", "show_data", ",", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisText.save_data": [[264, 266], ["None"], "methods", ["None"], ["", "def", "save_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "raw_data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisText.draw_data": [[267, 270], ["copy.deepcopy", "visdom.VisText.visdom.text", "visdom.VisText.visdom.text"], "methods", ["None"], ["", "def", "draw_data", "(", "self", ")", ":", "\n", "        ", "data", "=", "copy", ".", "deepcopy", "(", "self", ".", "raw_data", ")", "\n", "self", ".", "visdom", ".", "text", "(", "data", ",", "opts", "=", "{", "'title'", ":", "self", ".", "title", "}", ",", "win", "=", "self", ".", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisLinePlot.__init__": [[273, 275], ["visdom.VisBase.__init__", "visdom.VisBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "visdom", ",", "show_data", ",", "title", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "visdom", ",", "show_data", ",", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisLinePlot.save_data": [[276, 278], ["None"], "methods", ["None"], ["", "def", "save_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "raw_data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisLinePlot.draw_data": [[279, 288], ["isinstance", "visdom.VisLinePlot.visdom.line", "visdom.VisLinePlot.visdom.line", "visdom.VisLinePlot.raw_data[].clone", "visdom.VisLinePlot.raw_data[].clone", "visdom.VisLinePlot.raw_data[].clone", "visdom.VisLinePlot.raw_data[].clone", "visdom.VisLinePlot.raw_data.clone", "visdom.VisLinePlot.raw_data.clone", "torch.arange"], "methods", ["None"], ["", "def", "draw_data", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "raw_data", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "data_y", "=", "self", ".", "raw_data", "[", "0", "]", ".", "clone", "(", ")", "\n", "data_x", "=", "self", ".", "raw_data", "[", "1", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "            ", "data_y", "=", "self", ".", "raw_data", ".", "clone", "(", ")", "\n", "data_x", "=", "torch", ".", "arange", "(", "data_y", ".", "shape", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "visdom", ".", "line", "(", "data_y", ",", "data_x", ",", "opts", "=", "{", "'title'", ":", "self", ".", "title", "}", ",", "win", "=", "self", ".", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisTracking.__init__": [[291, 293], ["visdom.VisBase.__init__", "visdom.VisBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "visdom", ",", "show_data", ",", "title", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "visdom", ",", "show_data", ",", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisTracking.save_data": [[294, 312], ["isinstance", "boxes.append", "boxes.append", "len", "masks.append", "bm.float", "torch.Tensor"], "methods", ["None"], ["", "def", "save_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "image", "=", "data", "[", "0", "]", "\n", "boxes_masks", "=", "data", "[", "1", ":", "]", "\n", "\n", "boxes", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "bm", "in", "boxes_masks", ":", "\n", "            ", "if", "bm", "is", "None", ":", "\n", "                ", "continue", "\n", "", "if", "isinstance", "(", "bm", ",", "list", ")", ":", "\n", "                ", "boxes", ".", "append", "(", "torch", ".", "Tensor", "(", "bm", ")", ")", ";", "continue", "\n", "", "if", "len", "(", "bm", ".", "shape", ")", ">", "1", ":", "\n", "# Binarize segmentation if a float tensor is provided", "\n", "                ", "if", "bm", ".", "dtype", "!=", "np", ".", "uint8", ":", "\n", "                    ", "bm", "=", "(", "bm", ">", "0.5", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "", "masks", ".", "append", "(", "bm", ")", ";", "continue", "\n", "", "boxes", ".", "append", "(", "bm", ".", "float", "(", ")", ")", "\n", "\n", "", "self", ".", "raw_data", "=", "[", "image", ",", "boxes", ",", "masks", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisTracking.draw_data": [[313, 335], ["visdom.VisTracking.raw_data[].copy", "visdom.VisTracking.raw_data[].copy", "enumerate", "enumerate", "pytracking.features.preprocessing.numpy_to_torch().squeeze", "pytracking.utils.plotting.overlay_mask.float", "visdom.VisTracking.visdom.image", "visdom.VisTracking.visdom.image", "max", "cv2.resize", "enumerate", "cv2.rectangle", "pytracking.utils.plotting.overlay_mask", "float", "cv2.resize", "b.clone", "pytracking.features.preprocessing.numpy_to_torch", "max", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.overlay_mask", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch"], ["", "def", "draw_data", "(", "self", ")", ":", "\n", "        ", "disp_image", "=", "self", ".", "raw_data", "[", "0", "]", ".", "copy", "(", ")", "\n", "\n", "resize_factor", "=", "1", "\n", "if", "max", "(", "disp_image", ".", "shape", ")", ">", "480", ":", "\n", "            ", "resize_factor", "=", "480.0", "/", "float", "(", "max", "(", "disp_image", ".", "shape", ")", ")", "\n", "disp_image", "=", "cv2", ".", "resize", "(", "disp_image", ",", "None", ",", "fx", "=", "resize_factor", ",", "fy", "=", "resize_factor", ")", "\n", "for", "i", ",", "mask", "in", "enumerate", "(", "self", ".", "raw_data", "[", "2", "]", ")", ":", "\n", "                ", "self", ".", "raw_data", "[", "2", "]", "[", "i", "]", "=", "cv2", ".", "resize", "(", "mask", ",", "None", ",", "fx", "=", "resize_factor", ",", "fy", "=", "resize_factor", ")", "\n", "\n", "", "", "boxes", "=", "[", "resize_factor", "*", "b", ".", "clone", "(", ")", "for", "b", "in", "self", ".", "raw_data", "[", "1", "]", "]", "\n", "\n", "for", "i", ",", "disp_rect", "in", "enumerate", "(", "boxes", ")", ":", "\n", "            ", "color", "=", "(", "(", "255", "*", "(", "(", "i", "%", "3", ")", ">", "0", ")", ")", ",", "255", "*", "(", "(", "i", "+", "1", ")", "%", "2", ")", ",", "(", "255", "*", "(", "i", "%", "5", ")", ")", "//", "4", ")", "\n", "cv2", ".", "rectangle", "(", "disp_image", ",", "\n", "(", "int", "(", "disp_rect", "[", "0", "]", ")", ",", "int", "(", "disp_rect", "[", "1", "]", ")", ")", ",", "\n", "(", "int", "(", "disp_rect", "[", "0", "]", "+", "disp_rect", "[", "2", "]", ")", ",", "int", "(", "disp_rect", "[", "1", "]", "+", "disp_rect", "[", "3", "]", ")", ")", ",", "color", ",", "2", ")", "\n", "", "for", "i", ",", "mask", "in", "enumerate", "(", "self", ".", "raw_data", "[", "2", "]", ",", "1", ")", ":", "\n", "            ", "disp_image", "=", "overlay_mask", "(", "disp_image", ",", "mask", "*", "i", ")", "\n", "", "disp_image", "=", "numpy_to_torch", "(", "disp_image", ")", ".", "squeeze", "(", "0", ")", "\n", "disp_image", "=", "disp_image", ".", "float", "(", ")", "\n", "self", ".", "visdom", ".", "image", "(", "disp_image", ",", "opts", "=", "{", "'title'", ":", "self", ".", "title", "}", ",", "win", "=", "self", ".", "title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.__init__": [[338, 341], ["visdom.VisBase.__init__", "visdom.VisBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "visdom", ",", "show_data", ",", "title", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "visdom", ",", "show_data", ",", "title", ")", "\n", "self", ".", "block_list", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.block_list_callback_handler": [[342, 346], ["visdom.VisBBReg.visdom.properties", "visdom.VisBBReg.visdom.properties", "visdom.VisBBReg.draw_data", "visdom.VisBBReg.draw_data"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.draw_data", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.draw_data"], ["", "def", "block_list_callback_handler", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "block_list", "[", "data", "[", "'propertyId'", "]", "]", "[", "'value'", "]", "=", "data", "[", "'value'", "]", "\n", "self", ".", "visdom", ".", "properties", "(", "self", ".", "block_list", ",", "opts", "=", "{", "'title'", ":", "'BBReg Vis'", "}", ",", "win", "=", "'bbreg_vis'", ")", "\n", "self", ".", "draw_data", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.save_data": [[347, 352], ["data[].float"], "methods", ["None"], ["", "def", "save_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "image", "=", "data", "[", "0", "]", ".", "float", "(", ")", "\n", "self", ".", "init_boxes", "=", "data", "[", "1", "]", "\n", "self", ".", "final_boxes", "=", "data", "[", "2", "]", "\n", "self", ".", "final_ious", "=", "data", "[", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBBReg.draw_data": [[353, 368], ["pytracking.utils.plotting.show_image_with_boxes", "pytracking.utils.plotting.show_image_with_boxes", "visdom.VisBBReg.visdom.image", "visdom.VisBBReg.visdom.image", "visdom.VisBBReg.visdom.image", "visdom.VisBBReg.visdom.image", "len", "visdom.VisBBReg.block_list.append", "visdom.VisBBReg.block_list.append", "visdom.VisBBReg.block_list.append", "visdom.VisBBReg.block_list.append", "visdom.VisBBReg.visdom.properties", "visdom.VisBBReg.visdom.properties", "visdom.VisBBReg.visdom.register_event_handler", "visdom.VisBBReg.visdom.register_event_handler", "disp_image.clone", "visdom.VisBBReg.init_boxes.clone", "visdom.VisBBReg.init_boxes.clone", "disp_image.clone", "visdom.VisBBReg.final_boxes.clone", "visdom.VisBBReg.final_boxes.clone", "visdom.VisBBReg.final_ious.clone", "visdom.VisBBReg.final_ious.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_image_with_boxes", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_image_with_boxes"], ["", "def", "draw_data", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "block_list", ")", "==", "0", ":", "\n", "            ", "self", ".", "block_list", ".", "append", "(", "{", "'type'", ":", "'checkbox'", ",", "'name'", ":", "'ID 0'", ",", "'value'", ":", "True", "}", ")", "\n", "self", ".", "block_list", ".", "append", "(", "{", "'type'", ":", "'checkbox'", ",", "'name'", ":", "'ID 1'", ",", "'value'", ":", "True", "}", ")", "\n", "self", ".", "visdom", ".", "properties", "(", "self", ".", "block_list", ",", "opts", "=", "{", "'title'", ":", "'BBReg Vis'", "}", ",", "win", "=", "'bbreg_vis'", ")", "\n", "self", ".", "visdom", ".", "register_event_handler", "(", "self", ".", "block_list_callback_handler", ",", "'bbreg_vis'", ")", "\n", "\n", "", "disp_image", "=", "self", ".", "image", "\n", "\n", "ids", "=", "[", "x", "[", "'value'", "]", "for", "x", "in", "self", ".", "block_list", "]", "\n", "init_box_image", "=", "show_image_with_boxes", "(", "disp_image", ".", "clone", "(", ")", ",", "self", ".", "init_boxes", ".", "clone", "(", ")", ",", "disp_ids", "=", "ids", ")", "\n", "final_box_image", "=", "show_image_with_boxes", "(", "disp_image", ".", "clone", "(", ")", ",", "self", ".", "final_boxes", ".", "clone", "(", ")", ",", "self", ".", "final_ious", ".", "clone", "(", ")", ",", "disp_ids", "=", "ids", ")", "\n", "\n", "self", ".", "visdom", ".", "image", "(", "init_box_image", ",", "opts", "=", "{", "'title'", ":", "'Init Boxes'", "}", ",", "win", "=", "'Init Boxes'", ")", "\n", "self", ".", "visdom", ".", "image", "(", "final_box_image", ",", "opts", "=", "{", "'title'", ":", "'Final Boxes'", "}", ",", "win", "=", "'Final Boxes'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.Visdom.__init__": [[371, 382], ["visdom.Visdom", "visdom.Visdom", "visdom.Visdom", "visdom.Visdom", "visdom.Visdom.visdom.properties", "visdom.Visdom.visdom.properties", "visdom.Visdom.visdom.register_event_handler", "visdom.Visdom.visdom.register_event_handler", "visdom.Visdom.visdom.register_event_handler", "visdom.Visdom.visdom.register_event_handler", "visdom_info.get", "visdom_info.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["    ", "def", "__init__", "(", "self", ",", "debug", "=", "0", ",", "ui_info", "=", "None", ",", "visdom_info", "=", "None", ")", ":", "\n", "        ", "self", ".", "debug", "=", "debug", "\n", "self", ".", "visdom", "=", "visdom", ".", "Visdom", "(", "server", "=", "visdom_info", ".", "get", "(", "'server'", ",", "'127.0.0.1'", ")", ",", "port", "=", "visdom_info", ".", "get", "(", "'port'", ",", "8097", ")", ")", "\n", "self", ".", "registered_blocks", "=", "{", "}", "\n", "self", ".", "blocks_list", "=", "[", "]", "\n", "\n", "self", ".", "visdom", ".", "properties", "(", "self", ".", "blocks_list", ",", "opts", "=", "{", "'title'", ":", "'Block List'", "}", ",", "win", "=", "'block_list'", ")", "\n", "self", ".", "visdom", ".", "register_event_handler", "(", "self", ".", "block_list_callback_handler", ",", "'block_list'", ")", "\n", "\n", "if", "ui_info", "is", "not", "None", ":", "\n", "            ", "self", ".", "visdom", ".", "register_event_handler", "(", "ui_info", "[", "'handler'", "]", ",", "ui_info", "[", "'win_id'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.Visdom.block_list_callback_handler": [[383, 391], ["visdom.Visdom.registered_blocks[].toggle_display", "visdom.Visdom.registered_blocks[].toggle_display", "visdom.Visdom.visdom.properties", "visdom.Visdom.visdom.properties"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBase.toggle_display", "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.VisBase.toggle_display"], ["", "", "def", "block_list_callback_handler", "(", "self", ",", "data", ")", ":", "\n", "        ", "field_name", "=", "self", ".", "blocks_list", "[", "data", "[", "'propertyId'", "]", "]", "[", "'name'", "]", "\n", "\n", "self", ".", "registered_blocks", "[", "field_name", "]", ".", "toggle_display", "(", "data", "[", "'value'", "]", ")", "\n", "\n", "self", ".", "blocks_list", "[", "data", "[", "'propertyId'", "]", "]", "[", "'value'", "]", "=", "data", "[", "'value'", "]", "\n", "\n", "self", ".", "visdom", ".", "properties", "(", "self", ".", "blocks_list", ",", "opts", "=", "{", "'title'", ":", "'Block List'", "}", ",", "win", "=", "'block_list'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.visdom.Visdom.register": [[392, 428], ["visdom.Visdom.registered_blocks[].update", "visdom.Visdom.registered_blocks[].update", "visdom.Visdom.registered_blocks.keys", "visdom.Visdom.registered_blocks.keys", "visdom.Visdom.visdom.properties", "visdom.Visdom.visdom.properties", "visdom.Visdom.blocks_list.append", "visdom.Visdom.blocks_list.append", "visdom.VisImage", "visdom.VisImage", "visdom.VisHeatmap", "visdom.VisHeatmap", "visdom.VisCostVolume", "visdom.VisCostVolume", "visdom.VisCostVolume", "visdom.VisCostVolume", "visdom.VisCostVolumeUI", "visdom.VisCostVolumeUI", "visdom.VisInfoDict", "visdom.VisInfoDict", "visdom.VisText", "visdom.VisText", "visdom.VisLinePlot", "visdom.VisLinePlot", "visdom.VisTracking", "visdom.VisTracking", "visdom.VisBBReg", "visdom.VisBBReg", "visdom.VisFeaturemap", "visdom.VisFeaturemap", "ValueError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update"], ["", "def", "register", "(", "self", ",", "data", ",", "mode", ",", "debug_level", "=", "0", ",", "title", "=", "'Data'", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "title", "not", "in", "self", ".", "registered_blocks", ".", "keys", "(", ")", ":", "\n", "            ", "show_data", "=", "self", ".", "debug", ">=", "debug_level", "\n", "\n", "if", "title", "!=", "'Tracking'", ":", "\n", "                ", "self", ".", "blocks_list", ".", "append", "(", "{", "'type'", ":", "'checkbox'", ",", "'name'", ":", "title", ",", "'value'", ":", "show_data", "}", ")", "\n", "\n", "", "self", ".", "visdom", ".", "properties", "(", "self", ".", "blocks_list", ",", "opts", "=", "{", "'title'", ":", "'Block List'", "}", ",", "win", "=", "'block_list'", ")", "\n", "\n", "if", "mode", "==", "'image'", ":", "\n", "                ", "self", ".", "registered_blocks", "[", "title", "]", "=", "VisImage", "(", "self", ".", "visdom", ",", "show_data", ",", "title", ")", "\n", "", "elif", "mode", "==", "'heatmap'", ":", "\n", "                ", "self", ".", "registered_blocks", "[", "title", "]", "=", "VisHeatmap", "(", "self", ".", "visdom", ",", "show_data", ",", "title", ")", "\n", "", "elif", "mode", "==", "'cost_volume'", ":", "\n", "                ", "self", ".", "registered_blocks", "[", "title", "]", "=", "VisCostVolume", "(", "self", ".", "visdom", ",", "show_data", ",", "title", ")", "\n", "", "elif", "mode", "==", "'cost_volume_flip'", ":", "\n", "                ", "self", ".", "registered_blocks", "[", "title", "]", "=", "VisCostVolume", "(", "self", ".", "visdom", ",", "show_data", ",", "title", ",", "flip", "=", "True", ")", "\n", "", "elif", "mode", "==", "'cost_volume_ui'", ":", "\n", "                ", "self", ".", "registered_blocks", "[", "title", "]", "=", "VisCostVolumeUI", "(", "self", ".", "visdom", ",", "show_data", ",", "title", ",", "data", "[", "1", "]", ",", "\n", "self", ".", "registered_blocks", ")", "\n", "", "elif", "mode", "==", "'info_dict'", ":", "\n", "                ", "self", ".", "registered_blocks", "[", "title", "]", "=", "VisInfoDict", "(", "self", ".", "visdom", ",", "show_data", ",", "title", ")", "\n", "", "elif", "mode", "==", "'text'", ":", "\n", "                ", "self", ".", "registered_blocks", "[", "title", "]", "=", "VisText", "(", "self", ".", "visdom", ",", "show_data", ",", "title", ")", "\n", "", "elif", "mode", "==", "'lineplot'", ":", "\n", "                ", "self", ".", "registered_blocks", "[", "title", "]", "=", "VisLinePlot", "(", "self", ".", "visdom", ",", "show_data", ",", "title", ")", "\n", "", "elif", "mode", "==", "'Tracking'", ":", "\n", "                ", "self", ".", "registered_blocks", "[", "title", "]", "=", "VisTracking", "(", "self", ".", "visdom", ",", "show_data", ",", "title", ")", "\n", "", "elif", "mode", "==", "'bbreg'", ":", "\n", "                ", "self", ".", "registered_blocks", "[", "title", "]", "=", "VisBBReg", "(", "self", ".", "visdom", ",", "show_data", ",", "title", ")", "\n", "", "elif", "mode", "==", "'featmap'", ":", "\n", "                ", "self", ".", "registered_blocks", "[", "title", "]", "=", "VisFeaturemap", "(", "self", ".", "visdom", ",", "show_data", ",", "title", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Visdom Error: Unknown data mode {}'", ".", "format", "(", "mode", ")", ")", "\n", "# Update", "\n", "", "", "self", ".", "registered_blocks", "[", "title", "]", ".", "update", "(", "data", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.loading.load_network": [[6, 34], ["os.path.isabs", "ltr.load_network", "isinstance", "os.path.join", "ltr.load_network", "pytracking.evaluation.environment.env_settings", "pytracking.evaluation.environment.env_settings", "os.path.join", "ltr.load_network", "pytracking.evaluation.environment.env_settings"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_network", "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_network", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_network", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "load_network", "(", "net_path", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Load network for tracking.\n    args:\n        net_path - Path to network. If it is not an absolute path, it is relative to the network_path in the local.py.\n                   See ltr.admin.loading.load_network for further details.\n        **kwargs - Additional key-word arguments that are sent to ltr.admin.loading.load_network.\n    \"\"\"", "\n", "kwargs", "[", "'backbone_pretrained'", "]", "=", "False", "\n", "if", "os", ".", "path", ".", "isabs", "(", "net_path", ")", ":", "\n", "        ", "path_full", "=", "net_path", "\n", "net", ",", "_", "=", "ltr_loading", ".", "load_network", "(", "path_full", ",", "**", "kwargs", ")", "\n", "", "elif", "isinstance", "(", "env_settings", "(", ")", ".", "network_path", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "net", "=", "None", "\n", "for", "p", "in", "env_settings", "(", ")", ".", "network_path", ":", "\n", "            ", "path_full", "=", "os", ".", "path", ".", "join", "(", "p", ",", "net_path", ")", "\n", "try", ":", "\n", "                ", "net", ",", "_", "=", "ltr_loading", ".", "load_network", "(", "path_full", ",", "**", "kwargs", ")", "\n", "break", "\n", "", "except", "Exception", "as", "e", ":", "\n", "# print(e)", "\n", "                ", "pass", "\n", "\n", "", "", "assert", "net", "is", "not", "None", ",", "'Failed to load network'", "\n", "", "else", ":", "\n", "        ", "path_full", "=", "os", ".", "path", ".", "join", "(", "env_settings", "(", ")", ".", "network_path", ",", "net_path", ")", "\n", "net", ",", "_", "=", "ltr_loading", ".", "load_network", "(", "path_full", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "net", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text_numpy": [[5, 18], ["isinstance", "Exception", "numpy.loadtxt", "numpy.loadtxt"], "function", ["None"], ["def", "load_text_numpy", "(", "path", ",", "delimiter", ",", "dtype", ")", ":", "\n", "    ", "if", "isinstance", "(", "delimiter", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "for", "d", "in", "delimiter", ":", "\n", "            ", "try", ":", "\n", "                ", "ground_truth_rect", "=", "np", ".", "loadtxt", "(", "path", ",", "delimiter", "=", "d", ",", "dtype", "=", "dtype", ")", "\n", "return", "ground_truth_rect", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "\n", "", "", "raise", "Exception", "(", "'Could not read file {}'", ".", "format", "(", "path", ")", ")", "\n", "", "else", ":", "\n", "        ", "ground_truth_rect", "=", "np", ".", "loadtxt", "(", "path", ",", "delimiter", "=", "delimiter", ",", "dtype", "=", "dtype", ")", "\n", "return", "ground_truth_rect", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text_pandas": [[20, 35], ["isinstance", "Exception", "pandas.read_csv", "pandas.read_csv"], "function", ["None"], ["", "", "def", "load_text_pandas", "(", "path", ",", "delimiter", ",", "dtype", ")", ":", "\n", "    ", "if", "isinstance", "(", "delimiter", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "for", "d", "in", "delimiter", ":", "\n", "            ", "try", ":", "\n", "                ", "ground_truth_rect", "=", "pd", ".", "read_csv", "(", "path", ",", "delimiter", "=", "d", ",", "header", "=", "None", ",", "dtype", "=", "dtype", ",", "na_filter", "=", "False", ",", "\n", "low_memory", "=", "False", ")", ".", "values", "\n", "return", "ground_truth_rect", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "pass", "\n", "\n", "", "", "raise", "Exception", "(", "'Could not read file {}'", ".", "format", "(", "path", ")", ")", "\n", "", "else", ":", "\n", "        ", "ground_truth_rect", "=", "pd", ".", "read_csv", "(", "path", ",", "delimiter", "=", "delimiter", ",", "header", "=", "None", ",", "dtype", "=", "dtype", ",", "na_filter", "=", "False", ",", "\n", "low_memory", "=", "False", ")", ".", "values", "\n", "return", "ground_truth_rect", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text": [[37, 42], ["load_text.load_text_numpy", "load_text.load_text_pandas"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text_numpy", "home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text_pandas"], ["", "", "def", "load_text", "(", "path", ",", "delimiter", "=", "' '", ",", "dtype", "=", "np", ".", "float32", ",", "backend", "=", "'numpy'", ")", ":", "\n", "    ", "if", "backend", "==", "'numpy'", ":", "\n", "        ", "return", "load_text_numpy", "(", "path", ",", "delimiter", ",", "dtype", ")", "\n", "", "elif", "backend", "==", "'pandas'", ":", "\n", "        ", "return", "load_text_pandas", "(", "path", ",", "delimiter", ",", "dtype", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.set_default_values": [[7, 11], ["default_vals.items", "hasattr", "setattr"], "methods", ["None"], ["def", "set_default_values", "(", "self", ",", "default_vals", ":", "dict", ")", ":", "\n", "        ", "for", "name", ",", "val", "in", "default_vals", ".", "items", "(", ")", ":", "\n", "            ", "if", "not", "hasattr", "(", "self", ",", "name", ")", ":", "\n", "                ", "setattr", "(", "self", ",", "name", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.get": [[12, 22], ["getattr", "len", "ValueError", "getattr"], "methods", ["None"], ["", "", "", "def", "get", "(", "self", ",", "name", ":", "str", ",", "*", "default", ")", ":", "\n", "        ", "\"\"\"Get a parameter value with the given name. If it does not exists, it return the default value given as a\n        second argument or returns an error if no default value is given.\"\"\"", "\n", "if", "len", "(", "default", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "'Can only give one default value.'", ")", "\n", "\n", "", "if", "not", "default", ":", "\n", "            ", "return", "getattr", "(", "self", ",", "name", ")", "\n", "\n", "", "return", "getattr", "(", "self", ",", "name", ",", "default", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has": [[23, 26], ["hasattr"], "methods", ["None"], ["", "def", "has", "(", "self", ",", "name", ":", "str", ")", ":", "\n", "        ", "\"\"\"Check if there exist a parameter with the given name.\"\"\"", "\n", "return", "hasattr", "(", "self", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.FeatureParams.__init__": [[30, 39], ["kwargs.items", "len", "isinstance", "setattr", "setattr", "pytracking.TensorList"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "len", "(", "args", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "\n", "\n", "", "for", "name", ",", "val", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "val", ",", "list", ")", ":", "\n", "                ", "setattr", "(", "self", ",", "name", ",", "TensorList", "(", "val", ")", ")", "\n", "", "else", ":", "\n", "                ", "setattr", "(", "self", ",", "name", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.Choice": [[41, 44], ["random.choice"], "function", ["None"], ["", "", "", "", "def", "Choice", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\"Can be used to sample random parameter values.\"\"\"", "\n", "return", "random", ".", "choice", "(", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.utils.convert_vot_anno_to_rect.convert_vot_anno_to_rect": [[4, 38], ["len", "min", "max", "min", "max", "numpy.array", "numpy.mean", "numpy.mean", "min", "max", "min", "max", "numpy.sqrt", "len", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["def", "convert_vot_anno_to_rect", "(", "vot_anno", ",", "type", ")", ":", "\n", "    ", "if", "len", "(", "vot_anno", ")", "==", "4", ":", "\n", "        ", "return", "vot_anno", "\n", "\n", "", "if", "type", "==", "'union'", ":", "\n", "        ", "x1", "=", "min", "(", "vot_anno", "[", "0", ":", ":", "2", "]", ")", "\n", "x2", "=", "max", "(", "vot_anno", "[", "0", ":", ":", "2", "]", ")", "\n", "y1", "=", "min", "(", "vot_anno", "[", "1", ":", ":", "2", "]", ")", "\n", "y2", "=", "max", "(", "vot_anno", "[", "1", ":", ":", "2", "]", ")", "\n", "return", "[", "x1", ",", "y1", ",", "x2", "-", "x1", ",", "y2", "-", "y1", "]", "\n", "", "elif", "type", "==", "'preserve_area'", ":", "\n", "        ", "if", "len", "(", "vot_anno", ")", "!=", "8", ":", "\n", "            ", "raise", "ValueError", "\n", "\n", "", "vot_anno", "=", "np", ".", "array", "(", "vot_anno", ")", "\n", "cx", "=", "np", ".", "mean", "(", "vot_anno", "[", "0", ":", ":", "2", "]", ")", "\n", "cy", "=", "np", ".", "mean", "(", "vot_anno", "[", "1", ":", ":", "2", "]", ")", "\n", "\n", "x1", "=", "min", "(", "vot_anno", "[", "0", ":", ":", "2", "]", ")", "\n", "x2", "=", "max", "(", "vot_anno", "[", "0", ":", ":", "2", "]", ")", "\n", "y1", "=", "min", "(", "vot_anno", "[", "1", ":", ":", "2", "]", ")", "\n", "y2", "=", "max", "(", "vot_anno", "[", "1", ":", ":", "2", "]", ")", "\n", "\n", "A1", "=", "np", ".", "linalg", ".", "norm", "(", "vot_anno", "[", "0", ":", "2", "]", "-", "vot_anno", "[", "2", ":", "4", "]", ")", "*", "np", ".", "linalg", ".", "norm", "(", "vot_anno", "[", "2", ":", "4", "]", "-", "vot_anno", "[", "4", ":", "6", "]", ")", "\n", "A2", "=", "(", "x2", "-", "x1", ")", "*", "(", "y2", "-", "y1", ")", "\n", "s", "=", "np", ".", "sqrt", "(", "A1", "/", "A2", ")", "\n", "w", "=", "s", "*", "(", "x2", "-", "x1", ")", "+", "1", "\n", "h", "=", "s", "*", "(", "y2", "-", "y1", ")", "+", "1", "\n", "\n", "x", "=", "cx", "-", "0.5", "*", "w", "\n", "y", "=", "cy", "-", "0.5", "*", "h", "\n", "return", "[", "x", ",", "y", ",", "w", ",", "h", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_boxinit.parameters": [[5, 45], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "seg_to_bb_mode", "=", "'var'", "\n", "params", ".", "max_scale_change", "=", "(", "0.95", ",", "1.1", ")", "\n", "params", ".", "min_mask_area", "=", "100", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "(", "30", "*", "16", ",", "52", "*", "16", ")", "\n", "params", ".", "search_area_scale", "=", "5.0", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "None", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "32", "\n", "params", ".", "learning_rate", "=", "0.2", "\n", "params", ".", "init_samples_minimum_weight", "=", "0", "\n", "params", ".", "train_skipping", "=", "5", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_target_model", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "20", "\n", "params", ".", "net_opt_update_iter", "=", "5", "\n", "\n", "params", ".", "init_with_box", "=", "True", "\n", "params", ".", "lower_init_weight", "=", "True", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'lwl_boxinit.pth'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ",", "\n", "image_format", "=", "'bgr255'", ",", "\n", "mean", "=", "[", "102.9801", ",", "115.9465", ",", "122.7717", "]", ",", "\n", "std", "=", "[", "1.0", ",", "1.0", ",", "1.0", "]", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_ytvos.parameters": [[5, 41], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "seg_to_bb_mode", "=", "'var'", "\n", "params", ".", "max_scale_change", "=", "(", "0.95", ",", "1.1", ")", "\n", "params", ".", "min_mask_area", "=", "100", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "(", "30", "*", "16", ",", "52", "*", "16", ")", "\n", "params", ".", "search_area_scale", "=", "5.0", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "None", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "32", "\n", "params", ".", "learning_rate", "=", "0.1", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "1", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_target_model", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "20", "\n", "params", ".", "net_opt_update_iter", "=", "3", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'lwl_stage2.pth'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ",", "\n", "image_format", "=", "'bgr255'", ",", "\n", "mean", "=", "[", "102.9801", ",", "115.9465", ",", "122.7717", "]", ",", "\n", "std", "=", "[", "1.0", ",", "1.0", ",", "1.0", "]", "\n", ")", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.predicts_segmentation_mask": [[17, 19], ["None"], "methods", ["None"], ["def", "predicts_segmentation_mask", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.initialize_features": [[20, 24], ["getattr", "lwl.LWL.params.net.initialize"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["", "def", "initialize_features", "(", "self", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "self", ",", "'features_initialized'", ",", "False", ")", ":", "\n", "            ", "self", ".", "params", ".", "net", ".", "initialize", "(", ")", "\n", "", "self", ".", "features_initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.initialize": [[25, 101], ["lwl.LWL.initialize_features", "pytracking.features.preprocessing.numpy_to_torch", "time.time", "info.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "lwl.LWL.generate_init_samples", "lwl.LWL.init_target_model", "lwl.LWL.params.has", "torch.tensor().unsqueeze().unsqueeze().float", "torch.tensor().unsqueeze().unsqueeze().float", "torch.tensor().unsqueeze().unsqueeze().float", "torch.tensor().unsqueeze().unsqueeze().float", "hasattr", "info.get", "math.sqrt", "lwl.LWL.img_sample_sz.prod().sqrt", "time.time", "lwl.LWL.params.get", "torch.sigmoid.squeeze().cpu", "torch.sigmoid.squeeze().cpu", "init_mask_raw.squeeze().cpu().numpy", "torch.sigmoid.squeeze().cpu().numpy", "torch.sigmoid.squeeze().cpu().numpy", "Exception", "isinstance", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.tensor().unsqueeze().unsqueeze", "torch.tensor().unsqueeze().unsqueeze", "torch.tensor().unsqueeze().unsqueeze", "torch.tensor().unsqueeze().unsqueeze", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lwl.LWL.net.extract_backbone", "lwl.LWL.net.extract_target_model_features", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to", "lwl.LWL.net.box_label_encoder", "isinstance", "lwl.LWL.net.decoder", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "lwl.LWL.img_sample_sz.prod", "torch.sigmoid.squeeze", "torch.sigmoid.squeeze", "init_mask_raw.squeeze().cpu", "torch.sigmoid.squeeze().cpu", "torch.sigmoid.squeeze().cpu", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "init_mask_raw.squeeze", "torch.sigmoid.squeeze", "torch.sigmoid.squeeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.generate_init_samples", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.init_target_model", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.extract_target_model_features", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "# Learn the initial target model. Initialize memory etc.", "\n", "        ", "self", ".", "frame_num", "=", "1", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'device'", ")", ":", "\n", "            ", "self", ".", "params", ".", "device", "=", "'cuda'", "if", "self", ".", "params", ".", "use_gpu", "else", "'cpu'", "\n", "\n", "# Initialize network", "\n", "", "self", ".", "initialize_features", "(", ")", "\n", "\n", "# The segmentation network", "\n", "self", ".", "net", "=", "self", ".", "params", ".", "net", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# Time initialization", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Output", "\n", "out", "=", "{", "}", "\n", "\n", "# Get target position and size", "\n", "state", "=", "info", "[", "'init_bbox'", "]", "\n", "init_mask", "=", "info", ".", "get", "(", "'init_mask'", ",", "None", ")", "\n", "\n", "if", "init_mask", "is", "not", "None", "and", "not", "self", ".", "params", ".", "get", "(", "'init_with_box'", ",", "False", ")", ":", "\n", "# shape 1 , 1, h, w (frames, seq, h, w)", "\n", "            ", "init_mask", "=", "torch", ".", "tensor", "(", "init_mask", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "float", "(", ")", "\n", "", "elif", "hasattr", "(", "self", ".", "net", ",", "'box_label_encoder'", ")", ":", "\n", "# Generate initial mask from the box", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "init_backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im", ")", "\n", "init_feat_clf", "=", "self", ".", "net", ".", "extract_target_model_features", "(", "init_backbone_feat", ")", "\n", "\n", "init_box", "=", "torch", ".", "tensor", "(", "state", ")", ".", "unsqueeze", "(", "dim", "=", "0", ")", ".", "to", "(", "init_feat_clf", ".", "device", ")", "\n", "init_mask_enc", "=", "self", ".", "net", ".", "box_label_encoder", "(", "init_box", ",", "init_feat_clf", ",", "im", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "\n", "if", "isinstance", "(", "init_mask_enc", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                    ", "init_mask_enc", "=", "init_mask_enc", "[", "0", "]", "\n", "", "init_mask_raw", ",", "_", "=", "self", ".", "net", ".", "decoder", "(", "init_mask_enc", ",", "init_backbone_feat", ",", "im", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "init_mask", "=", "torch", ".", "sigmoid", "(", "init_mask_raw", ")", "\n", "\n", "", "out", "[", "'init_mask'", "]", "=", "init_mask", ".", "squeeze", "(", ")", ".", "cpu", "(", ")", "\n", "out", "[", "'segmentation_raw'", "]", "=", "init_mask_raw", ".", "squeeze", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out", "[", "'segmentation'", "]", "=", "init_mask", ".", "squeeze", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'No mask provided'", ")", "\n", "\n", "# Set target center and target size", "\n", "", "self", ".", "pos", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "1", "]", "+", "(", "state", "[", "3", "]", "-", "1", ")", "/", "2", ",", "state", "[", "0", "]", "+", "(", "state", "[", "2", "]", "-", "1", ")", "/", "2", "]", ")", "\n", "self", ".", "target_sz", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "3", "]", ",", "state", "[", "2", "]", "]", ")", "\n", "\n", "# Get object ids", "\n", "self", ".", "object_id", "=", "info", ".", "get", "(", "'object_ids'", ",", "[", "None", "]", ")", "[", "0", "]", "\n", "self", ".", "id_str", "=", "''", "if", "self", ".", "object_id", "is", "None", "else", "' {}'", ".", "format", "(", "self", ".", "object_id", ")", "\n", "\n", "# Set sizes", "\n", "sz", "=", "self", ".", "params", ".", "image_sample_size", "\n", "self", ".", "img_sample_sz", "=", "torch", ".", "Tensor", "(", "[", "sz", ",", "sz", "]", "if", "isinstance", "(", "sz", ",", "int", ")", "else", "sz", ")", "\n", "self", ".", "img_support_sz", "=", "self", ".", "img_sample_sz", "\n", "\n", "# Set search area.", "\n", "search_area", "=", "torch", ".", "prod", "(", "self", ".", "target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ".", "item", "(", ")", "\n", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", ")", "/", "self", ".", "img_sample_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "\n", "# Target size in base scale", "\n", "self", ".", "base_target_sz", "=", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "\n", "# Extract and transform sample", "\n", "init_backbone_feat", ",", "init_masks", "=", "self", ".", "generate_init_samples", "(", "im", ",", "init_mask", ")", "\n", "\n", "# Initialize target model", "\n", "self", ".", "init_target_model", "(", "init_backbone_feat", ",", "init_masks", ")", "\n", "\n", "out", "[", "'time'", "]", "=", "time", ".", "time", "(", ")", "-", "tic", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.track": [[102, 210], ["torch.from_numpy().unsqueeze().unsqueeze().float", "torch.from_numpy().unsqueeze().unsqueeze().float", "torch.from_numpy().unsqueeze().unsqueeze().float", "torch.from_numpy().unsqueeze().unsqueeze().float", "lwl.LWL.get_target_state", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "pytracking.features.preprocessing.numpy_to_torch", "lwl.LWL.extract_backbone_features", "lwl.LWL.get_centered_sample_pos", "lwl.LWL.get_target_model_features", "lwl.LWL.get_sample_location", "lwl.LWL.segment_target", "lwl.LWL.convert_scores_crop_to_image", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "lwl.LWL.get_target_state", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.tolist", "torch.cat.tolist", "segmentation_mask_im.view().cpu().numpy.view().cpu().numpy.view().cpu().numpy", "segmentation_output.cpu().numpy.cpu().numpy.cpu().numpy", "lwl.LWL.params.get", "torch.from_numpy().unsqueeze().unsqueeze().float.squeeze", "torch.from_numpy().unsqueeze().unsqueeze().float.squeeze", "lwl.LWL.params.get", "lwl.LWL.clip_scale_change", "lwl.LWL.get_centered_sample_pos", "torch.sigmoid.squeeze", "torch.sigmoid.squeeze", "lwl.LWL.visdom.register", "lwl.LWL.visdom.register", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "torch.from_numpy().unsqueeze().unsqueeze", "pytracking.features.preprocessing.sample_patch", "lwl.LWL.update_target_model", "lwl.LWL.target_sz.prod", "lwl.LWL.base_target_sz.prod", "segmentation_mask_im.view().cpu().numpy.view().cpu().numpy.view().cpu", "segmentation_output.cpu().numpy.cpu().numpy.cpu", "prev_segmentation_prob_crop.clone", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "lwl.LWL.params.get", "lwl.LWL.params.get", "segmentation_mask_im.view().cpu().numpy.view().cpu().numpy.view", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.get_target_state", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_centered_sample_pos", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.get_target_model_features", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_sample_location", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.segment_target", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.convert_scores_crop_to_image", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.get_target_state", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.clip_scale_change", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_centered_sample_pos", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.update_target_model", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "track", "(", "self", ",", "image", ",", "info", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "        ", "self", ".", "debug_info", "=", "{", "}", "\n", "\n", "self", ".", "frame_num", "+=", "1", "\n", "self", ".", "debug_info", "[", "'frame_num'", "]", "=", "self", ".", "frame_num", "\n", "\n", "# Obtain the merged segmentation prediction for the previous frames. This is used to update the target model", "\n", "# and determine the search region for the current frame", "\n", "if", "self", ".", "object_id", "is", "None", ":", "\n", "            ", "prev_segmentation_prob_im", "=", "info", "[", "'previous_output'", "]", "[", "'segmentation_raw'", "]", "\n", "", "else", ":", "\n", "            ", "prev_segmentation_prob_im", "=", "info", "[", "'previous_output'", "]", "[", "'segmentation_raw'", "]", "[", "self", ".", "object_id", "]", "\n", "\n", "", "prev_segmentation_prob_im", "=", "torch", ".", "from_numpy", "(", "prev_segmentation_prob_im", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "float", "(", ")", "\n", "\n", "# ********************************************************************************** #", "\n", "# ------- Update the target model using merged masks from the previous frame ------- #", "\n", "# ********************************************************************************** #", "\n", "if", "self", ".", "frame_num", ">", "2", ":", "\n", "# Crop the segmentation mask for the previous search area", "\n", "            ", "if", "self", ".", "params", ".", "get", "(", "'update_target_model'", ",", "True", ")", ":", "\n", "                ", "prev_segmentation_prob_crop", ",", "_", "=", "sample_patch", "(", "prev_segmentation_prob_im", ",", "self", ".", "prev_pos", ",", "\n", "self", ".", "prev_scale", "*", "self", ".", "img_sample_sz", ",", "\n", "self", ".", "img_sample_sz", ",", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", ",", "\n", "max_scale_change", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ")", ",", "\n", "is_mask", "=", "True", ")", "\n", "\n", "# Update the target model", "\n", "self", ".", "update_target_model", "(", "self", ".", "prev_test_x", ",", "prev_segmentation_prob_crop", ".", "clone", "(", ")", ")", "\n", "\n", "# ****************************************************************************************** #", "\n", "# -------- Estimate target box using the merged segmentation mask from prev. frame --------- #", "\n", "# --- The estimated target box is used to obtain the search region for the current frame --- #", "\n", "# ****************************************************************************************** #", "\n", "", "", "self", ".", "pos", ",", "self", ".", "target_sz", "=", "self", ".", "get_target_state", "(", "prev_segmentation_prob_im", ".", "squeeze", "(", ")", ")", "\n", "\n", "new_target_scale", "=", "torch", ".", "sqrt", "(", "self", ".", "target_sz", ".", "prod", "(", ")", "/", "self", ".", "base_target_sz", ".", "prod", "(", ")", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'max_scale_change'", ")", "is", "not", "None", ":", "\n", "# Do not allow drastic scale change, as this might be caused due to occlusions or incorrect mask", "\n", "# prediction", "\n", "            ", "new_target_scale", "=", "self", ".", "clip_scale_change", "(", "new_target_scale", ")", "\n", "\n", "# Update target size and scale using the filtered target size", "\n", "", "self", ".", "target_scale", "=", "new_target_scale", "\n", "self", ".", "target_sz", "=", "self", ".", "base_target_sz", "*", "self", ".", "target_scale", "\n", "\n", "# ********************************************************************** #", "\n", "# ---------- Predict segmentation mask for the current frame ----------- #", "\n", "# ********************************************************************** #", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# Extract backbone features", "\n", "backbone_feat", ",", "sample_coords", ",", "im_patches", "=", "self", ".", "extract_backbone_features", "(", "im", ",", "self", ".", "get_centered_sample_pos", "(", ")", ",", "\n", "self", ".", "target_scale", ",", "\n", "self", ".", "img_sample_sz", ")", "\n", "\n", "# Save the search region information as it is needed to merge the segmentation masks for the next frame update", "\n", "self", ".", "prev_pos", "=", "self", ".", "get_centered_sample_pos", "(", ")", "\n", "self", ".", "prev_scale", "=", "self", ".", "target_scale", "\n", "\n", "# Extract features input to the target model", "\n", "test_x", "=", "self", ".", "get_target_model_features", "(", "backbone_feat", ")", "\n", "\n", "# Location of sample", "\n", "sample_pos", ",", "sample_scale", "=", "self", ".", "get_sample_location", "(", "sample_coords", ")", "\n", "\n", "# Predict the segmentation mask. Note: These are raw scores, before the sigmoid", "\n", "segmentation_scores", "=", "self", ".", "segment_target", "(", "test_x", ",", "backbone_feat", ")", "\n", "\n", "self", ".", "prev_test_x", "=", "test_x", "\n", "\n", "# Get the segmentation scores for the full image.", "\n", "# Regions outside the search region are assigned low scores (-100)", "\n", "segmentation_scores_im", "=", "self", ".", "convert_scores_crop_to_image", "(", "segmentation_scores", ",", "im", ",", "sample_scale", ",", "sample_pos", ")", "\n", "\n", "segmentation_mask_im", "=", "(", "segmentation_scores_im", ">", "0.0", ")", ".", "float", "(", ")", "# Binary segmentation mask", "\n", "segmentation_prob_im", "=", "torch", ".", "sigmoid", "(", "segmentation_scores_im", ")", "# Probability of being target at each pixel", "\n", "\n", "# ************************************************************************ #", "\n", "# ---------- Output estimated segmentation mask and target box ----------- #", "\n", "# ************************************************************************ #", "\n", "\n", "# Get target box from the predicted segmentation", "\n", "pred_pos", ",", "pred_target_sz", "=", "self", ".", "get_target_state", "(", "segmentation_prob_im", ".", "squeeze", "(", ")", ")", "\n", "new_state", "=", "torch", ".", "cat", "(", "(", "pred_pos", "[", "[", "1", ",", "0", "]", "]", "-", "(", "pred_target_sz", "[", "[", "1", ",", "0", "]", "]", "-", "1", ")", "/", "2", ",", "pred_target_sz", "[", "[", "1", ",", "0", "]", "]", ")", ")", "\n", "output_state", "=", "new_state", ".", "tolist", "(", ")", "\n", "\n", "if", "self", ".", "object_id", "is", "None", ":", "\n", "# In single object mode, no merge called. Hence return the probabilities", "\n", "            ", "segmentation_output", "=", "segmentation_prob_im", "\n", "", "else", ":", "\n", "# In multi-object mode, return raw scores", "\n", "            ", "segmentation_output", "=", "segmentation_scores_im", "\n", "\n", "", "segmentation_mask_im", "=", "segmentation_mask_im", ".", "view", "(", "*", "segmentation_mask_im", ".", "shape", "[", "-", "2", ":", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "segmentation_output", "=", "segmentation_output", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "segmentation_scores_im", ",", "'heatmap'", ",", "2", ",", "'Seg Scores'", "+", "self", ".", "id_str", ")", "\n", "self", ".", "visdom", ".", "register", "(", "self", ".", "debug_info", ",", "'info_dict'", ",", "1", ",", "'Status'", ")", "\n", "\n", "", "out", "=", "{", "'segmentation'", ":", "segmentation_mask_im", ",", "'target_bbox'", ":", "output_state", ",", "\n", "'segmentation_raw'", ":", "segmentation_output", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.merge_results": [[211, 275], ["collections.OrderedDict", "list", "numpy.stack", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.prod().clamp", "torch.prod().clamp", "torch.prod().clamp", "torch.prod().clamp", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack.numpy", "torch.stack.numpy", "numpy.array", "collections.OrderedDict", "out_first.keys", "out_all.keys", "out.append", "list", "out_all[].keys", "torch.from_numpy().float.append", "torch.from_numpy().float.append", "torch.from_numpy().float.append", "torch.from_numpy().float.append", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "bg_score.unsqueeze", "torch.stack.numpy.argmax", "out_all.values", "map", "enumerate", "out_all.items", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "lwl.LWL.get_target_state", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.tolist", "torch.cat.tolist", "out_all.items", "s.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.get_target_state"], ["", "def", "merge_results", "(", "self", ",", "out_all", ")", ":", "\n", "        ", "\"\"\" Merges the predictions of individual targets\"\"\"", "\n", "out_merged", "=", "OrderedDict", "(", ")", "\n", "\n", "obj_ids", "=", "list", "(", "out_all", ".", "keys", "(", ")", ")", "\n", "\n", "# Merge segmentation scores using the soft-aggregation approach from RGMP", "\n", "segmentation_scores", "=", "[", "]", "\n", "for", "id", "in", "obj_ids", ":", "\n", "            ", "if", "'segmentation_raw'", "in", "out_all", "[", "id", "]", ".", "keys", "(", ")", ":", "\n", "                ", "segmentation_scores", ".", "append", "(", "out_all", "[", "id", "]", "[", "'segmentation_raw'", "]", ")", "\n", "", "else", ":", "\n", "# If 'segmentation_raw' is not present, then this is the initial frame for the target. Convert the", "\n", "# GT Segmentation mask to raw scores (assign 100 to target region, -100 to background)", "\n", "                ", "segmentation_scores", ".", "append", "(", "(", "out_all", "[", "id", "]", "[", "'segmentation'", "]", "-", "0.5", ")", "*", "200.0", ")", "\n", "\n", "", "", "segmentation_scores", "=", "np", ".", "stack", "(", "segmentation_scores", ")", "\n", "segmentation_scores", "=", "torch", ".", "from_numpy", "(", "segmentation_scores", ")", ".", "float", "(", ")", "\n", "segmentation_prob", "=", "torch", ".", "sigmoid", "(", "segmentation_scores", ")", "\n", "\n", "# Obtain seg. probability and scores for background label", "\n", "eps", "=", "1e-7", "\n", "bg_p", "=", "torch", ".", "prod", "(", "1", "-", "segmentation_prob", ",", "dim", "=", "0", ")", ".", "clamp", "(", "eps", ",", "1.0", "-", "eps", ")", "# bg prob", "\n", "bg_score", "=", "(", "bg_p", "/", "(", "1.0", "-", "bg_p", ")", ")", ".", "log", "(", ")", "\n", "\n", "segmentation_scores_all", "=", "torch", ".", "cat", "(", "(", "bg_score", ".", "unsqueeze", "(", "0", ")", ",", "segmentation_scores", ")", ",", "dim", "=", "0", ")", "\n", "\n", "out", "=", "[", "]", "\n", "for", "s", "in", "segmentation_scores_all", ":", "\n", "            ", "s_out", "=", "1.0", "/", "(", "segmentation_scores_all", "-", "s", ".", "unsqueeze", "(", "0", ")", ")", ".", "exp", "(", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "out", ".", "append", "(", "s_out", ")", "\n", "\n", "", "segmentation_maps_t_agg", "=", "torch", ".", "stack", "(", "out", ",", "dim", "=", "0", ")", "\n", "segmentation_maps_np_agg", "=", "segmentation_maps_t_agg", ".", "numpy", "(", ")", "\n", "\n", "# Obtain segmentation mask", "\n", "obj_ids_all", "=", "np", ".", "array", "(", "[", "0", ",", "*", "map", "(", "int", ",", "obj_ids", ")", "]", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "merged_segmentation", "=", "obj_ids_all", "[", "segmentation_maps_np_agg", ".", "argmax", "(", "axis", "=", "0", ")", "]", "\n", "\n", "out_merged", "[", "'segmentation'", "]", "=", "merged_segmentation", "\n", "out_merged", "[", "'segmentation_raw'", "]", "=", "OrderedDict", "(", "{", "key", ":", "segmentation_maps_np_agg", "[", "i", "+", "1", "]", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "obj_ids", ")", "}", ")", "\n", "\n", "# target_bbox", "\n", "out_first", "=", "list", "(", "out_all", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "out_types", "=", "out_first", ".", "keys", "(", ")", "\n", "\n", "for", "key", "in", "out_types", ":", "\n", "            ", "if", "'segmentation'", "in", "key", ":", "\n", "                ", "pass", "\n", "", "elif", "'target_bbox'", "in", "key", ":", "\n", "# Update the target box using the merged segmentation mask", "\n", "                ", "merged_boxes", "=", "{", "}", "\n", "for", "obj_id", ",", "out", "in", "out_all", ".", "items", "(", ")", ":", "\n", "                    ", "segmentation_prob", "=", "torch", ".", "from_numpy", "(", "out_merged", "[", "'segmentation_raw'", "]", "[", "obj_id", "]", ")", "\n", "pred_pos", ",", "pred_target_sz", "=", "self", ".", "get_target_state", "(", "segmentation_prob", ")", "\n", "new_state", "=", "torch", ".", "cat", "(", "(", "pred_pos", "[", "[", "1", ",", "0", "]", "]", "-", "(", "pred_target_sz", "[", "[", "1", ",", "0", "]", "]", "-", "1", ")", "/", "2", ",", "pred_target_sz", "[", "[", "1", ",", "0", "]", "]", ")", ")", "\n", "merged_boxes", "[", "obj_id", "]", "=", "new_state", ".", "tolist", "(", ")", "\n", "", "out_merged", "[", "'target_bbox'", "]", "=", "merged_boxes", "\n", "", "else", ":", "\n", "# For fields other than segmentation predictions or target box, only convert the data structure", "\n", "                ", "out_merged", "[", "key", "]", "=", "{", "obj_id", ":", "out", "[", "key", "]", "for", "obj_id", ",", "out", "in", "out_all", ".", "items", "(", ")", "}", "\n", "\n", "", "", "return", "out_merged", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.get_target_state": [[276, 301], ["segmentation_prob_im.sum", "lwl.LWL.params.get", "lwl.LWL.params.get", "segmentation_prob_im.sum", "lwl.LWL.params.get", "Exception", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "lwl.LWL.params.get", "segmentation_prob_im.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "segmentation_prob_im.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "segmentation_prob_im.sum", "segmentation_prob_im.sum", "e_h.sqrt", "e_w.sqrt", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "get_target_state", "(", "self", ",", "segmentation_prob_im", ")", ":", "\n", "        ", "\"\"\" Estimate target bounding box using the predicted segmentation probabilities \"\"\"", "\n", "\n", "# If predicted mask area is too small, target might be occluded. In this case, just return prev. box", "\n", "if", "segmentation_prob_im", ".", "sum", "(", ")", "<", "self", ".", "params", ".", "get", "(", "'min_mask_area'", ",", "-", "10", ")", ":", "\n", "            ", "return", "self", ".", "pos", ",", "self", ".", "target_sz", "\n", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'seg_to_bb_mode'", ")", "==", "'var'", ":", "\n", "# Target center is the center of mass of the predicted per-pixel seg. probability scores", "\n", "            ", "prob_sum", "=", "segmentation_prob_im", ".", "sum", "(", ")", "\n", "e_y", "=", "torch", ".", "sum", "(", "segmentation_prob_im", ".", "sum", "(", "dim", "=", "-", "1", ")", "*", "\n", "torch", ".", "arange", "(", "segmentation_prob_im", ".", "shape", "[", "-", "2", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ")", "/", "prob_sum", "\n", "e_x", "=", "torch", ".", "sum", "(", "segmentation_prob_im", ".", "sum", "(", "dim", "=", "-", "2", ")", "*", "\n", "torch", ".", "arange", "(", "segmentation_prob_im", ".", "shape", "[", "-", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ")", "/", "prob_sum", "\n", "\n", "# Target size is obtained using the variance of the seg. probability scores", "\n", "e_h", "=", "torch", ".", "sum", "(", "segmentation_prob_im", ".", "sum", "(", "dim", "=", "-", "1", ")", "*", "\n", "(", "torch", ".", "arange", "(", "segmentation_prob_im", ".", "shape", "[", "-", "2", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "-", "e_y", ")", "**", "2", ")", "/", "prob_sum", "\n", "e_w", "=", "torch", ".", "sum", "(", "segmentation_prob_im", ".", "sum", "(", "dim", "=", "-", "2", ")", "*", "\n", "(", "torch", ".", "arange", "(", "segmentation_prob_im", ".", "shape", "[", "-", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ")", "-", "e_x", ")", "**", "2", ")", "/", "prob_sum", "\n", "\n", "sz_factor", "=", "self", ".", "params", ".", "get", "(", "'seg_to_bb_sz_factor'", ",", "4", ")", "\n", "return", "torch", ".", "Tensor", "(", "[", "e_y", ",", "e_x", "]", ")", ",", "torch", ".", "Tensor", "(", "[", "e_h", ".", "sqrt", "(", ")", "*", "sz_factor", ",", "e_w", ".", "sqrt", "(", ")", "*", "sz_factor", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unknown seg_to_bb_mode mode {}'", ".", "format", "(", "self", ".", "params", ".", "get", "(", "'seg_to_bb_mode'", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.get_sample_location": [[302, 308], ["sample_coord.float.float.float"], "methods", ["None"], ["", "", "def", "get_sample_location", "(", "self", ",", "sample_coord", ")", ":", "\n", "        ", "\"\"\"Get the location of the extracted sample.\"\"\"", "\n", "sample_coord", "=", "sample_coord", ".", "float", "(", ")", "\n", "sample_pos", "=", "0.5", "*", "(", "sample_coord", "[", ":", "2", "]", "+", "sample_coord", "[", "2", ":", "]", "-", "1", ")", "\n", "sample_scales", "=", "(", "(", "sample_coord", "[", "2", ":", "]", "-", "sample_coord", "[", ":", "2", "]", ")", "/", "self", ".", "img_sample_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "return", "sample_pos", ",", "sample_scales", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.get_centered_sample_pos": [[309, 313], ["None"], "methods", ["None"], ["", "def", "get_centered_sample_pos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the center position for the new sample. Make sure the target is correctly centered.\"\"\"", "\n", "return", "self", ".", "pos", "+", "(", "(", "self", ".", "feature_sz", "+", "self", ".", "kernel_size", ")", "%", "2", ")", "*", "self", ".", "target_scale", "*", "self", ".", "img_support_sz", "/", "(", "2", "*", "self", ".", "feature_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.clip_scale_change": [[314, 329], ["isinstance", "lwl.LWL.params.get", "lwl.LWL.params.get", "lwl.LWL.params.get", "lwl.LWL.params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "clip_scale_change", "(", "self", ",", "new_target_scale", ")", ":", "\n", "        ", "\"\"\" Limit scale change \"\"\"", "\n", "if", "not", "isinstance", "(", "self", ".", "params", ".", "get", "(", "'max_scale_change'", ")", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "max_scale_change", "=", "(", "self", ".", "params", ".", "get", "(", "'max_scale_change'", ")", ",", "self", ".", "params", ".", "get", "(", "'max_scale_change'", ")", ")", "\n", "", "else", ":", "\n", "            ", "max_scale_change", "=", "self", ".", "params", ".", "get", "(", "'max_scale_change'", ")", "\n", "\n", "", "scale_change", "=", "new_target_scale", "/", "self", ".", "target_scale", "\n", "\n", "if", "scale_change", "<", "max_scale_change", "[", "0", "]", ":", "\n", "            ", "new_target_scale", "=", "self", ".", "target_scale", "*", "max_scale_change", "[", "0", "]", "\n", "", "elif", "scale_change", ">", "max_scale_change", "[", "1", "]", ":", "\n", "            ", "new_target_scale", "=", "self", ".", "target_scale", "*", "max_scale_change", "[", "1", "]", "\n", "\n", "", "return", "new_target_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.convert_scores_crop_to_image": [[330, 360], ["torch.interpolate", "torch.interpolate", "segmentation_scores_re.view.view.view", "int", "int", "max", "max", "max", "max", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "sample_scale.item", "sample_pos[].item", "sample_pos[].item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate", "home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate"], ["", "def", "convert_scores_crop_to_image", "(", "self", ",", "segmentation_scores", ",", "im", ",", "sample_scale", ",", "sample_pos", ")", ":", "\n", "        ", "\"\"\" Obtain segmentation scores for the full image using the scores for the search region crop. This is done by\n            assigning a low score (-100) for image regions outside the search region \"\"\"", "\n", "\n", "# Resize the segmentation scores to match the image scale", "\n", "segmentation_scores_re", "=", "F", ".", "interpolate", "(", "segmentation_scores", ",", "scale_factor", "=", "sample_scale", ".", "item", "(", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "segmentation_scores_re", "=", "segmentation_scores_re", ".", "view", "(", "*", "segmentation_scores_re", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "\n", "# Regions outside search area get very low score", "\n", "segmentation_scores_im", "=", "torch", ".", "ones", "(", "im", ".", "shape", "[", "-", "2", ":", "]", ",", "dtype", "=", "segmentation_scores_re", ".", "dtype", ")", "*", "(", "-", "100.0", ")", "\n", "\n", "# Find the co-ordinates of the search region in the image scale", "\n", "r1", "=", "int", "(", "sample_pos", "[", "0", "]", ".", "item", "(", ")", "-", "0.5", "*", "segmentation_scores_re", ".", "shape", "[", "-", "2", "]", ")", "\n", "c1", "=", "int", "(", "sample_pos", "[", "1", "]", ".", "item", "(", ")", "-", "0.5", "*", "segmentation_scores_re", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "r2", "=", "r1", "+", "segmentation_scores_re", ".", "shape", "[", "-", "2", "]", "\n", "c2", "=", "c1", "+", "segmentation_scores_re", ".", "shape", "[", "-", "1", "]", "\n", "\n", "r1_pad", "=", "max", "(", "0", ",", "-", "r1", ")", "\n", "c1_pad", "=", "max", "(", "0", ",", "-", "c1", ")", "\n", "\n", "r2_pad", "=", "max", "(", "r2", "-", "im", ".", "shape", "[", "-", "2", "]", ",", "0", ")", "\n", "c2_pad", "=", "max", "(", "c2", "-", "im", ".", "shape", "[", "-", "1", "]", ",", "0", ")", "\n", "\n", "# Copy the scores for the search region", "\n", "shape", "=", "segmentation_scores_re", ".", "shape", "\n", "segmentation_scores_im", "[", "r1", "+", "r1_pad", ":", "r2", "-", "r2_pad", ",", "c1", "+", "c1_pad", ":", "c2", "-", "c2_pad", "]", "=", "segmentation_scores_re", "[", "r1_pad", ":", "shape", "[", "0", "]", "-", "r2_pad", ",", "c1_pad", ":", "shape", "[", "1", "]", "-", "c2_pad", "]", "\n", "\n", "return", "segmentation_scores_im", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.segment_target": [[361, 367], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lwl.LWL.net.segment_target"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.segment_target"], ["", "def", "segment_target", "(", "self", ",", "sample_tm_feat", ",", "sample_x", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "segmentation_scores", ",", "mask_encoding_pred", "=", "self", ".", "net", ".", "segment_target", "(", "self", ".", "target_filter", ",", "sample_tm_feat", ",", "\n", "sample_x", ")", "\n", "\n", "", "return", "segmentation_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.extract_backbone_features": [[368, 375], ["pytracking.features.preprocessing.sample_patch_multiscale", "scale.unsqueeze", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lwl.LWL.net.extract_backbone", "lwl.LWL.params.get", "lwl.LWL.params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_multiscale", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "extract_backbone_features", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ",", "pos", ":", "torch", ".", "Tensor", ",", "scale", ",", "sz", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "im_patches", ",", "patch_coords", "=", "sample_patch_multiscale", "(", "im", ",", "pos", ",", "scale", ".", "unsqueeze", "(", "0", ")", ",", "sz", ",", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", ",", "\n", "max_scale_change", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ",", "None", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im_patches", ")", "\n", "", "return", "backbone_feat", ",", "patch_coords", "[", "0", "]", ",", "im_patches", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.get_target_model_features": [[376, 380], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lwl.LWL.net.extract_target_model_features"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.extract_target_model_features"], ["", "def", "get_target_model_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "\"\"\" Extract features input to the target model\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "extract_target_model_features", "(", "backbone_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.generate_init_samples": [[381, 432], ["lwl.LWL.params.get", "lwl.LWL.pos.round", "lwl.LWL.img_sample_sz.clone", "pytracking.features.preprocessing.sample_patch_transformed", "pytracking.features.preprocessing.sample_patch_transformed", "init_masks.to.to.to", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "shrink_factor.min.min.clamp_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "aug_expansion_sz.float.float.float", "lwl.LWL.img_sample_sz.long().tolist", "pytracking.features.augmentation.Identity", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lwl.LWL.net.extract_backbone", "sample_sz.float", "shrink_factor.min.min.max", "sample_sz.float", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "shrink_factor.min.min.min", "lwl.LWL.params.get", "lwl.LWL.img_sample_sz.long", "lwl.LWL.img_sample_sz.long", "torch.zeros.long", "torch.zeros.long"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_transformed", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_transformed", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "", "def", "generate_init_samples", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ",", "init_mask", ")", ":", "\n", "        ", "\"\"\" Generate initial training sample.\"\"\"", "\n", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", "\n", "if", "'inside'", "in", "mode", ":", "\n", "# Get new sample size if forced inside the image", "\n", "            ", "im_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "sample_sz", "=", "self", ".", "target_scale", "*", "self", ".", "img_sample_sz", "\n", "shrink_factor", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "im_sz", ")", "\n", "if", "mode", "==", "'inside'", ":", "\n", "                ", "shrink_factor", "=", "shrink_factor", ".", "max", "(", ")", "\n", "", "elif", "mode", "==", "'inside_major'", ":", "\n", "                ", "shrink_factor", "=", "shrink_factor", ".", "min", "(", ")", "\n", "", "shrink_factor", ".", "clamp_", "(", "min", "=", "1", ",", "max", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ",", "None", ")", ")", "\n", "sample_sz", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "shrink_factor", ")", "\n", "init_sample_scale", "=", "(", "sample_sz", "/", "self", ".", "img_sample_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "tl", "=", "self", ".", "pos", "-", "(", "sample_sz", "-", "1", ")", "/", "2", "\n", "br", "=", "self", ".", "pos", "+", "sample_sz", "/", "2", "+", "1", "\n", "global_shift", "=", "-", "(", "(", "-", "tl", ")", ".", "clamp", "(", "0", ")", "-", "(", "br", "-", "im_sz", ")", ".", "clamp", "(", "0", ")", ")", "/", "init_sample_scale", "\n", "", "else", ":", "\n", "            ", "init_sample_scale", "=", "self", ".", "target_scale", "\n", "global_shift", "=", "torch", ".", "zeros", "(", "2", ")", "\n", "\n", "", "init_sample_pos", "=", "self", ".", "pos", ".", "round", "(", ")", "\n", "\n", "# Compute augmentation size", "\n", "aug_expansion_factor", "=", "2.0", "\n", "aug_expansion_sz", "=", "self", ".", "img_sample_sz", ".", "clone", "(", ")", "\n", "aug_output_sz", "=", "None", "\n", "if", "aug_expansion_factor", "is", "not", "None", "and", "aug_expansion_factor", "!=", "1", ":", "\n", "            ", "aug_expansion_sz", "=", "(", "self", ".", "img_sample_sz", "*", "aug_expansion_factor", ")", ".", "long", "(", ")", "\n", "aug_expansion_sz", "+=", "(", "aug_expansion_sz", "-", "self", ".", "img_sample_sz", ".", "long", "(", ")", ")", "%", "2", "\n", "aug_expansion_sz", "=", "aug_expansion_sz", ".", "float", "(", ")", "\n", "aug_output_sz", "=", "self", ".", "img_sample_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Can be extended to include data augmentation on the initial frame", "\n", "", "self", ".", "transforms", "=", "[", "augmentation", ".", "Identity", "(", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "]", "\n", "\n", "# Extract image patches", "\n", "im_patches", "=", "sample_patch_transformed", "(", "im", ",", "init_sample_pos", ",", "init_sample_scale", ",", "aug_expansion_sz", ",", "self", ".", "transforms", ")", "\n", "\n", "init_masks", "=", "sample_patch_transformed", "(", "init_mask", ",", "\n", "init_sample_pos", ",", "init_sample_scale", ",", "aug_expansion_sz", ",", "self", ".", "transforms", ",", "\n", "is_mask", "=", "True", ")", "\n", "init_masks", "=", "init_masks", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "# Extract initial backbone features", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "init_backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im_patches", ")", "\n", "\n", "", "return", "init_backbone_feat", ",", "init_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.init_memory": [[433, 458], ["train_x.size", "pytracking.TensorList", "lwl.LWL.num_init_samples.copy", "pytracking.TensorList", "zip", "pytracking.TensorList", "masks.new_zeros", "zip", "masks.dim", "len", "x.new_zeros", "x.new_zeros", "x.new_ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "init_memory", "(", "self", ",", "train_x", ":", "TensorList", ",", "masks", ")", ":", "\n", "        ", "\"\"\" Initialize the sample memory used to update the target model \"\"\"", "\n", "assert", "masks", ".", "dim", "(", ")", "==", "4", "\n", "\n", "# Initialize first-frame spatial training samples", "\n", "self", ".", "num_init_samples", "=", "train_x", ".", "size", "(", "0", ")", "\n", "init_sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_ones", "(", "1", ")", "/", "x", ".", "shape", "[", "0", "]", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "# Sample counters and weights for spatial", "\n", "self", ".", "num_stored_samples", "=", "self", ".", "num_init_samples", ".", "copy", "(", ")", "\n", "self", ".", "previous_replace_ind", "=", "[", "None", "]", "*", "len", "(", "self", ".", "num_stored_samples", ")", "\n", "self", ".", "sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ")", "for", "x", "in", "train_x", "]", ")", "\n", "for", "sw", ",", "init_sw", ",", "num", "in", "zip", "(", "self", ".", "sample_weights", ",", "init_sample_weights", ",", "self", ".", "num_init_samples", ")", ":", "\n", "            ", "sw", "[", ":", "num", "]", "=", "init_sw", "\n", "\n", "# Initialize memory", "\n", "", "self", ".", "training_samples", "=", "TensorList", "(", "\n", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "self", ".", "target_masks", "=", "masks", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "masks", ".", "shape", "[", "-", "3", "]", ",", "masks", ".", "shape", "[", "-", "2", "]", ",", "\n", "masks", ".", "shape", "[", "-", "1", "]", ")", "\n", "self", ".", "target_masks", "[", ":", "masks", ".", "shape", "[", "0", "]", ",", ":", ",", ":", ",", ":", "]", "=", "masks", "\n", "\n", "for", "ts", ",", "x", "in", "zip", "(", "self", ".", "training_samples", ",", "train_x", ")", ":", "\n", "            ", "ts", "[", ":", "x", ".", "shape", "[", "0", "]", ",", "...", "]", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.update_memory": [[459, 472], ["lwl.LWL.update_sample_weights", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_sample_weights"], ["", "", "def", "update_memory", "(", "self", ",", "sample_x", ":", "TensorList", ",", "mask", ",", "learning_rate", "=", "None", ")", ":", "\n", "        ", "\"\"\" Add a new sample to the memory. If the memory is full, an old sample are removed\"\"\"", "\n", "# Update weights and get replace ind", "\n", "replace_ind", "=", "self", ".", "update_sample_weights", "(", "self", ".", "sample_weights", ",", "self", ".", "previous_replace_ind", ",", "self", ".", "num_stored_samples", ",", "self", ".", "num_init_samples", ",", "learning_rate", ")", "\n", "self", ".", "previous_replace_ind", "=", "replace_ind", "\n", "\n", "# Update sample and label memory", "\n", "for", "train_samp", ",", "x", ",", "ind", "in", "zip", "(", "self", ".", "training_samples", ",", "sample_x", ",", "replace_ind", ")", ":", "\n", "            ", "train_samp", "[", "ind", ":", "ind", "+", "1", ",", "...", "]", "=", "x", "\n", "\n", "", "self", ".", "target_masks", "[", "replace_ind", "[", "0", "]", ",", ":", ",", ":", ",", ":", "]", "=", "mask", "[", "0", ",", "...", "]", "\n", "\n", "self", ".", "num_stored_samples", "=", "[", "n", "+", "1", "if", "n", "<", "self", ".", "params", ".", "sample_memory_size", "else", "n", "for", "n", "in", "self", ".", "num_stored_samples", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.update_sample_weights": [[474, 517], ["zip", "lwl.LWL.params.get", "sw.sum", "replace_ind.append", "torch.min", "torch.min", "torch.min", "torch.min", "lwl.LWL.params.get", "sw[].sum", "sw[].sum", "r_ind.item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "update_sample_weights", "(", "self", ",", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ",", "learning_rate", "=", "None", ")", ":", "\n", "        ", "\"\"\" Update weights and get index to replace \"\"\"", "\n", "replace_ind", "=", "[", "]", "\n", "for", "sw", ",", "prev_ind", ",", "num_samp", ",", "num_init", "in", "zip", "(", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ")", ":", "\n", "            ", "lr", "=", "learning_rate", "\n", "if", "lr", "is", "None", ":", "\n", "                ", "lr", "=", "self", ".", "params", ".", "learning_rate", "\n", "\n", "", "init_samp_weight", "=", "self", ".", "params", ".", "get", "(", "'init_samples_minimum_weight'", ",", "None", ")", "\n", "if", "init_samp_weight", "==", "0", ":", "\n", "                ", "init_samp_weight", "=", "None", "\n", "", "s_ind", "=", "0", "if", "init_samp_weight", "is", "None", "else", "num_init", "\n", "\n", "if", "num_samp", "==", "0", "or", "lr", "==", "1", ":", "\n", "                ", "sw", "[", ":", "]", "=", "0", "\n", "sw", "[", "0", "]", "=", "1", "\n", "r_ind", "=", "0", "\n", "", "else", ":", "\n", "# Get index to replace", "\n", "                ", "if", "num_samp", "<", "sw", ".", "shape", "[", "0", "]", ":", "\n", "                    ", "r_ind", "=", "num_samp", "\n", "", "else", ":", "\n", "                    ", "_", ",", "r_ind", "=", "torch", ".", "min", "(", "sw", "[", "s_ind", ":", "]", ",", "0", ")", "\n", "r_ind", "=", "r_ind", ".", "item", "(", ")", "+", "s_ind", "\n", "\n", "# Update weights", "\n", "", "if", "prev_ind", "is", "None", ":", "\n", "                    ", "if", "self", ".", "params", ".", "get", "(", "'lower_init_weight'", ",", "False", ")", ":", "\n", "                        ", "sw", "[", "r_ind", "]", "=", "1", "\n", "", "else", ":", "\n", "                        ", "sw", "/=", "1", "-", "lr", "\n", "sw", "[", "r_ind", "]", "=", "lr", "\n", "", "", "else", ":", "\n", "                    ", "sw", "[", "r_ind", "]", "=", "sw", "[", "prev_ind", "]", "/", "(", "1", "-", "lr", ")", "\n", "\n", "", "", "sw", "/=", "sw", ".", "sum", "(", ")", "\n", "if", "init_samp_weight", "is", "not", "None", "and", "sw", "[", ":", "num_init", "]", ".", "sum", "(", ")", "<", "init_samp_weight", ":", "\n", "                ", "sw", "/=", "init_samp_weight", "+", "sw", "[", "num_init", ":", "]", ".", "sum", "(", ")", "\n", "sw", "[", ":", "num_init", "]", "=", "init_samp_weight", "/", "num_init", "\n", "\n", "", "replace_ind", ".", "append", "(", "r_ind", ")", "\n", "\n", "", "return", "replace_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.init_target_model": [[518, 544], ["lwl.LWL.get_target_model_features", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "lwl.LWL.params.get", "lwl.LWL.params.get", "list", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lwl.LWL.net.label_encoder", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lwl.LWL.net.target_model.get_filter", "lwl.LWL.init_memory", "isinstance", "lwl.LWL.unsqueeze", "lwl.LWL.unsqueeze", "pytracking.TensorList", "init_masks.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.get_target_model_features", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.get_filter", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_memory"], ["", "def", "init_target_model", "(", "self", ",", "init_backbone_feat", ",", "init_masks", ")", ":", "\n", "# Get target model features", "\n", "        ", "x", "=", "self", ".", "get_target_model_features", "(", "init_backbone_feat", ")", "\n", "\n", "# Set feature size and other related sizes", "\n", "self", ".", "feature_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "x", ".", "shape", "[", "-", "2", ":", "]", ")", ")", "\n", "\n", "ksz", "=", "self", ".", "net", ".", "target_model", ".", "filter_size", "\n", "self", ".", "kernel_size", "=", "torch", ".", "Tensor", "(", "[", "ksz", ",", "ksz", "]", "if", "isinstance", "(", "ksz", ",", "(", "int", ",", "float", ")", ")", "else", "ksz", ")", "\n", "self", ".", "output_sz", "=", "self", ".", "feature_sz", "+", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "\n", "# Set number of iterations", "\n", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_iter'", ",", "None", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "few_shot_label", ",", "few_shot_sw", "=", "self", ".", "net", ".", "label_encoder", "(", "init_masks", ",", "x", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "# Get the target module parameters using the few-shot learner", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "target_filter", ",", "_", ",", "losses", "=", "self", ".", "net", ".", "target_model", ".", "get_filter", "(", "x", ".", "unsqueeze", "(", "1", ")", ",", "few_shot_label", ",", "\n", "few_shot_sw", ",", "\n", "num_iter", "=", "num_iter", ")", "\n", "\n", "# Init memory", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'update_target_model'", ",", "True", ")", ":", "\n", "            ", "self", ".", "init_memory", "(", "TensorList", "(", "[", "x", "]", ")", ",", "masks", "=", "init_masks", ".", "view", "(", "-", "1", ",", "1", ",", "*", "init_masks", ".", "shape", "[", "-", "2", ":", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.update_target_model": [[545, 581], ["lwl.LWL.update_memory", "lwl.LWL.params.get", "lwl.LWL.params.get", "pytracking.TensorList", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lwl.LWL.net.label_encoder", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "lwl.LWL.net.target_model.filter_optimizer", "samples.unsqueeze", "sample_weights.view", "pytracking.TensorList", "samples.unsqueeze", "few_shot_label.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_memory", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "", "def", "update_target_model", "(", "self", ",", "train_x", ",", "mask", ",", "learning_rate", "=", "None", ")", ":", "\n", "# Set flags and learning rate", "\n", "        ", "if", "learning_rate", "is", "None", ":", "\n", "            ", "learning_rate", "=", "self", ".", "params", ".", "learning_rate", "\n", "\n", "# Update the tracker memory", "\n", "", "if", "self", ".", "frame_num", "%", "self", ".", "params", ".", "get", "(", "'train_sample_interval'", ",", "1", ")", "==", "0", ":", "\n", "            ", "self", ".", "update_memory", "(", "TensorList", "(", "[", "train_x", "]", ")", ",", "mask", ",", "learning_rate", ")", "\n", "\n", "# Decide the number of iterations to run", "\n", "", "num_iter", "=", "0", "\n", "if", "(", "self", ".", "frame_num", "-", "1", ")", "%", "self", ".", "params", ".", "train_skipping", "==", "0", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_update_iter'", ",", "None", ")", "\n", "\n", "", "if", "num_iter", ">", "0", ":", "\n", "            ", "samples", "=", "self", ".", "training_samples", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", "...", "]", "\n", "masks", "=", "self", ".", "target_masks", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", "...", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "few_shot_label", ",", "few_shot_sw", "=", "self", ".", "net", ".", "label_encoder", "(", "masks", ",", "samples", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "", "sample_weights", "=", "self", ".", "sample_weights", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", "]", "\n", "\n", "if", "few_shot_sw", "is", "not", "None", ":", "\n", "# few_shot_sw provides spatial weights, while sample_weights contains temporal weights.", "\n", "                ", "sample_weights", "=", "few_shot_sw", "*", "sample_weights", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "# Run the filter optimizer module", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "target_filter", ",", "_", ",", "losses", "=", "self", ".", "net", ".", "target_model", ".", "filter_optimizer", "(", "TensorList", "(", "[", "self", ".", "target_filter", "]", ")", ",", "\n", "num_iter", "=", "num_iter", ",", "\n", "feat", "=", "samples", ".", "unsqueeze", "(", "1", ")", ",", "\n", "label", "=", "few_shot_label", ".", "unsqueeze", "(", "1", ")", ",", "\n", "sample_weight", "=", "sample_weights", ")", "\n", "\n", "", "self", ".", "target_filter", "=", "target_filter", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.__init__.get_tracker_class": [[4, 6], ["None"], "function", ["None"], ["import", "pytracking", ".", "libs", ".", "fourier", "as", "fourier", "\n", "import", "pytracking", ".", "libs", ".", "dcf", "as", "dcf", "\n", "import", "pytracking", ".", "libs", ".", "optimization", "as", "optimization", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_stage2.run": [[13, 141], ["ltr.dataset.YouTubeVOS", "ltr.dataset.Davis", "ltr.dataset.YouTubeVOS", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.LWLProcessing", "ltr.data.processing.LWLProcessing", "ltr.data.sampler.LWLSampler", "ltr.data.sampler.LWLSampler", "ltr.data.LTRLoader", "ltr.data.LTRLoader", "ltr.steepest_descent_resnet50", "ltr.load_trained_network", "ltr.MultiGPU.load_state_dict", "ltr.LWLActor", "torch.Adam", "torch.lr_scheduler.MultiStepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToBGR", "ltr.ToGrayscale", "ltr.RandomHorizontalFlip", "ltr.RandomAffine", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.ToTensorAndJitter", "ltr.Normalize", "network_loading.load_trained_network.state_dict", "ltr.MultiGPU", "ltr.models.loss.segmentation.LovaszSegLoss", "segm_actors.LWLActor.net.target_model.filter_initializer.parameters", "segm_actors.LWLActor.net.target_model.filter_optimizer.parameters", "segm_actors.LWLActor.net.target_model.feature_extractor.parameters", "segm_actors.LWLActor.net.decoder.parameters", "segm_actors.LWLActor.net.label_encoder.parameters", "segm_actors.LWLActor.net.feature_extractor.layer2.parameters", "segm_actors.LWLActor.net.feature_extractor.layer3.parameters", "segm_actors.LWLActor.net.feature_extractor.layer4.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.steepest_descent_resnet50", "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_trained_network", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["def", "run", "(", "settings", ")", ":", "\n", "    ", "settings", ".", "description", "=", "'Default train settings for training full network'", "\n", "settings", ".", "batch_size", "=", "20", "\n", "settings", ".", "num_workers", "=", "8", "\n", "settings", ".", "multi_gpu", "=", "True", "\n", "settings", ".", "print_interval", "=", "1", "\n", "settings", ".", "normalize_mean", "=", "[", "102.9801", ",", "115.9465", ",", "122.7717", "]", "\n", "settings", ".", "normalize_std", "=", "[", "1.0", ",", "1.0", ",", "1.0", "]", "\n", "\n", "settings", ".", "feature_sz", "=", "(", "52", ",", "30", ")", "\n", "\n", "# Settings used for generating the image crop input to the network. See documentation of LWTLProcessing class in", "\n", "# ltr/data/processing.py for details.", "\n", "settings", ".", "output_sz", "=", "(", "settings", ".", "feature_sz", "[", "0", "]", "*", "16", ",", "settings", ".", "feature_sz", "[", "1", "]", "*", "16", ")", "# Size of input image crop", "\n", "settings", ".", "search_area_factor", "=", "5.0", "\n", "settings", ".", "crop_type", "=", "'inside_major'", "\n", "settings", ".", "max_scale_change", "=", "None", "\n", "\n", "settings", ".", "center_jitter_factor", "=", "{", "'train'", ":", "3", ",", "'test'", ":", "(", "5.5", ",", "4.5", ")", "}", "\n", "settings", ".", "scale_jitter_factor", "=", "{", "'train'", ":", "0.25", ",", "'test'", ":", "0.5", "}", "\n", "\n", "# Datasets", "\n", "ytvos_train", "=", "YouTubeVOS", "(", "version", "=", "\"2019\"", ",", "multiobj", "=", "False", ",", "split", "=", "'jjtrain'", ")", "\n", "davis_train", "=", "Davis", "(", "version", "=", "'2017'", ",", "multiobj", "=", "False", ",", "split", "=", "'train'", ")", "\n", "\n", "ytvos_val", "=", "YouTubeVOS", "(", "version", "=", "\"2019\"", ",", "multiobj", "=", "False", ",", "split", "=", "'jjvalid'", ")", "\n", "\n", "# Data transform", "\n", "transform_joint", "=", "tfm", ".", "Transform", "(", "tfm", ".", "ToBGR", "(", ")", ",", "\n", "tfm", ".", "ToGrayscale", "(", "probability", "=", "0.05", ")", ",", "\n", "tfm", ".", "RandomHorizontalFlip", "(", "probability", "=", "0.5", ")", ")", "\n", "\n", "transform_train", "=", "tfm", ".", "Transform", "(", "tfm", ".", "RandomAffine", "(", "p_flip", "=", "0.0", ",", "max_rotation", "=", "15.0", ",", "\n", "max_shear", "=", "0.0", ",", "max_ar_factor", "=", "0.0", ",", "\n", "max_scale", "=", "0.2", ",", "pad_amount", "=", "0", ")", ",", "\n", "tfm", ".", "ToTensorAndJitter", "(", "0.2", ",", "normalize", "=", "False", ")", ",", "\n", "tfm", ".", "Normalize", "(", "mean", "=", "settings", ".", "normalize_mean", ",", "std", "=", "settings", ".", "normalize_std", ")", ")", "\n", "\n", "transform_val", "=", "tfm", ".", "Transform", "(", "tfm", ".", "ToTensorAndJitter", "(", "0.0", ",", "normalize", "=", "False", ")", ",", "\n", "tfm", ".", "Normalize", "(", "mean", "=", "settings", ".", "normalize_mean", ",", "std", "=", "settings", ".", "normalize_std", ")", ")", "\n", "\n", "data_processing_train", "=", "processing", ".", "LWLProcessing", "(", "search_area_factor", "=", "settings", ".", "search_area_factor", ",", "\n", "output_sz", "=", "settings", ".", "output_sz", ",", "\n", "center_jitter_factor", "=", "settings", ".", "center_jitter_factor", ",", "\n", "scale_jitter_factor", "=", "settings", ".", "scale_jitter_factor", ",", "\n", "mode", "=", "'sequence'", ",", "\n", "crop_type", "=", "settings", ".", "crop_type", ",", "\n", "max_scale_change", "=", "settings", ".", "max_scale_change", ",", "\n", "transform", "=", "transform_train", ",", "\n", "joint_transform", "=", "transform_joint", ",", "\n", "new_roll", "=", "True", ")", "\n", "\n", "data_processing_val", "=", "processing", ".", "LWLProcessing", "(", "search_area_factor", "=", "settings", ".", "search_area_factor", ",", "\n", "output_sz", "=", "settings", ".", "output_sz", ",", "\n", "center_jitter_factor", "=", "settings", ".", "center_jitter_factor", ",", "\n", "scale_jitter_factor", "=", "settings", ".", "scale_jitter_factor", ",", "\n", "mode", "=", "'sequence'", ",", "\n", "crop_type", "=", "settings", ".", "crop_type", ",", "\n", "max_scale_change", "=", "settings", ".", "max_scale_change", ",", "\n", "transform", "=", "transform_val", ",", "\n", "joint_transform", "=", "transform_joint", ",", "\n", "new_roll", "=", "True", ")", "\n", "\n", "# Train sampler and loader", "\n", "dataset_train", "=", "sampler", ".", "LWLSampler", "(", "[", "ytvos_train", ",", "davis_train", "]", ",", "[", "6", ",", "1", "]", ",", "\n", "samples_per_epoch", "=", "settings", ".", "batch_size", "*", "1000", ",", "max_gap", "=", "100", ",", "num_test_frames", "=", "3", ",", "\n", "num_train_frames", "=", "1", ",", "\n", "processing", "=", "data_processing_train", ")", "\n", "dataset_val", "=", "sampler", ".", "LWLSampler", "(", "[", "ytvos_val", "]", ",", "[", "1", "]", ",", "\n", "samples_per_epoch", "=", "settings", ".", "batch_size", "*", "100", ",", "max_gap", "=", "100", ",", "\n", "num_test_frames", "=", "3", ",", "\n", "num_train_frames", "=", "1", ",", "\n", "processing", "=", "data_processing_val", ")", "\n", "\n", "loader_train", "=", "LTRLoader", "(", "'train'", ",", "dataset_train", ",", "training", "=", "True", ",", "num_workers", "=", "settings", ".", "num_workers", ",", "\n", "stack_dim", "=", "1", ",", "batch_size", "=", "settings", ".", "batch_size", ")", "\n", "\n", "loader_val", "=", "LTRLoader", "(", "'val'", ",", "dataset_val", ",", "training", "=", "False", ",", "num_workers", "=", "settings", ".", "num_workers", ",", "\n", "epoch_interval", "=", "5", ",", "stack_dim", "=", "1", ",", "batch_size", "=", "settings", ".", "batch_size", ")", "\n", "\n", "# Network", "\n", "net", "=", "lwl_networks", ".", "steepest_descent_resnet50", "(", "filter_size", "=", "3", ",", "num_filters", "=", "16", ",", "optim_iter", "=", "5", ",", "\n", "backbone_pretrained", "=", "True", ",", "\n", "out_feature_dim", "=", "512", ",", "\n", "frozen_backbone_layers", "=", "[", "'conv1'", ",", "'bn1'", ",", "'layer1'", "]", ",", "\n", "label_encoder_dims", "=", "(", "16", ",", "32", ",", "64", ")", ",", "\n", "use_bn_in_label_enc", "=", "False", ",", "\n", "clf_feat_blocks", "=", "0", ",", "\n", "final_conv", "=", "True", ",", "\n", "backbone_type", "=", "'mrcnn'", ")", "\n", "\n", "base_net", "=", "network_loading", ".", "load_trained_network", "(", "settings", ".", "env", ".", "workspace_dir", ",", "\n", "'ltr/lwl/lwl_stage1/LWTLNet_ep0070.pth.tar'", ")", "\n", "\n", "net", ".", "load_state_dict", "(", "base_net", ".", "state_dict", "(", ")", ")", "\n", "\n", "# Wrap the network for multi GPU training", "\n", "if", "settings", ".", "multi_gpu", ":", "\n", "        ", "net", "=", "MultiGPU", "(", "net", ",", "dim", "=", "1", ")", "\n", "\n", "# Loss function", "\n", "", "objective", "=", "{", "\n", "'segm'", ":", "LovaszSegLoss", "(", "per_image", "=", "False", ")", ",", "\n", "}", "\n", "\n", "loss_weight", "=", "{", "\n", "'segm'", ":", "100.0", "\n", "}", "\n", "\n", "actor", "=", "segm_actors", ".", "LWLActor", "(", "net", "=", "net", ",", "objective", "=", "objective", ",", "loss_weight", "=", "loss_weight", ",", "\n", "num_refinement_iter", "=", "2", ",", "disable_all_bn", "=", "True", ")", "\n", "\n", "# Optimizer", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "actor", ".", "net", ".", "target_model", ".", "filter_initializer", ".", "parameters", "(", ")", ",", "'lr'", ":", "5e-5", "}", ",", "\n", "{", "'params'", ":", "actor", ".", "net", ".", "target_model", ".", "filter_optimizer", ".", "parameters", "(", ")", ",", "'lr'", ":", "2e-5", "}", ",", "\n", "{", "'params'", ":", "actor", ".", "net", ".", "target_model", ".", "feature_extractor", ".", "parameters", "(", ")", ",", "'lr'", ":", "2e-5", "}", ",", "\n", "{", "'params'", ":", "actor", ".", "net", ".", "decoder", ".", "parameters", "(", ")", ",", "'lr'", ":", "2e-5", "}", ",", "\n", "{", "'params'", ":", "actor", ".", "net", ".", "label_encoder", ".", "parameters", "(", ")", ",", "'lr'", ":", "2e-5", "}", ",", "\n", "{", "'params'", ":", "actor", ".", "net", ".", "feature_extractor", ".", "layer2", ".", "parameters", "(", ")", ",", "'lr'", ":", "2e-5", "}", ",", "\n", "{", "'params'", ":", "actor", ".", "net", ".", "feature_extractor", ".", "layer3", ".", "parameters", "(", ")", ",", "'lr'", ":", "2e-5", "}", ",", "\n", "{", "'params'", ":", "actor", ".", "net", ".", "feature_extractor", ".", "layer4", ".", "parameters", "(", ")", ",", "'lr'", ":", "2e-5", "}", "]", ",", "\n", "lr", "=", "2e-4", ")", "\n", "\n", "lr_scheduler", "=", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "optimizer", ",", "[", "25", ",", "75", "]", ",", "gamma", "=", "0.2", ")", "\n", "\n", "trainer", "=", "LTRTrainer", "(", "actor", ",", "[", "loader_train", ",", "loader_val", "]", ",", "optimizer", ",", "settings", ",", "lr_scheduler", ")", "\n", "\n", "trainer", ".", "train", "(", "80", ",", "load_latest", "=", "True", ",", "fail_safe", "=", "True", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_boxinit.run": [[13, 132], ["ltr.dataset.YouTubeVOS", "ltr.dataset.YouTubeVOS", "ltr.dataset.MSCOCOSeq", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.LWLProcessing", "ltr.data.processing.LWLProcessing", "ltr.data.sampler.LWLSampler", "ltr.data.sampler.LWLSampler", "ltr.data.LTRLoader", "ltr.data.LTRLoader", "ltr.steepest_descent_resnet50", "ltr.load_trained_network", "ltr.MultiGPU.feature_extractor.load_state_dict", "ltr.MultiGPU.target_model.load_state_dict", "ltr.MultiGPU.decoder.load_state_dict", "ltr.MultiGPU.label_encoder.load_state_dict", "ltr.LWLBoxActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToBGR", "ltr.ToGrayscale", "ltr.RandomHorizontalFlip", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.ToTensorAndJitter", "ltr.Normalize", "network_loading.load_trained_network.feature_extractor.state_dict", "network_loading.load_trained_network.target_model.state_dict", "network_loading.load_trained_network.decoder.state_dict", "network_loading.load_trained_network.label_encoder.state_dict", "ltr.MultiGPU", "ltr.models.loss.segmentation.LovaszSegLoss", "lwtl_actors.LWLBoxActor.net.box_label_encoder.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.steepest_descent_resnet50", "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_trained_network", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["params", ".", "min_mask_area", "=", "100", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "(", "30", "*", "16", ",", "52", "*", "16", ")", "\n", "params", ".", "search_area_scale", "=", "5.0", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "None", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "32", "\n", "params", ".", "learning_rate", "=", "0.2", "\n", "params", ".", "init_samples_minimum_weight", "=", "0", "\n", "params", ".", "train_skipping", "=", "5", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_target_model", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "20", "\n", "params", ".", "net_opt_update_iter", "=", "5", "\n", "\n", "params", ".", "init_with_box", "=", "True", "\n", "params", ".", "lower_init_weight", "=", "True", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'lwl_boxinit.pth'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ",", "\n", "image_format", "=", "'bgr255'", ",", "\n", "mean", "=", "[", "102.9801", ",", "115.9465", ",", "122.7717", "]", ",", "\n", "std", "=", "[", "1.0", ",", "1.0", ",", "1.0", "]", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_stage1.run": [[14, 144], ["ltr.dataset.YouTubeVOS", "ltr.dataset.Davis", "ltr.dataset.YouTubeVOS", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.LWLProcessing", "ltr.data.processing.LWLProcessing", "ltr.data.sampler.LWLSampler", "ltr.data.sampler.LWLSampler", "ltr.data.LTRLoader", "ltr.data.LTRLoader", "ltr.steepest_descent_resnet50", "os.path.join", "torch.load", "torch.load", "ltr.MultiGPU.feature_extractor.load_state_dict", "ltr.LWLActor", "torch.Adam", "torch.lr_scheduler.MultiStepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToBGR", "ltr.ToGrayscale", "ltr.RandomHorizontalFlip", "ltr.RandomAffine", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.MultiGPU", "ltr.models.loss.segmentation.LovaszSegLoss", "segm_actors.LWLActor.net.target_model.filter_initializer.parameters", "segm_actors.LWLActor.net.target_model.filter_optimizer.parameters", "segm_actors.LWLActor.net.target_model.feature_extractor.parameters", "segm_actors.LWLActor.net.decoder.parameters", "segm_actors.LWLActor.net.label_encoder.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.steepest_descent_resnet50", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["def", "run", "(", "settings", ")", ":", "\n", "    ", "settings", ".", "description", "=", "'Default train settings with backbone weights fixed. We initialize the backbone ResNet with '", "'pre-trained Mask-RCNN weights. These weights can be obtained from '", "'https://drive.google.com/file/d/12pVHmhqtxaJ151dZrXN1dcgUa7TuAjdA/view?usp=sharing. '", "'Download and save these weights in env_settings.pretrained_networks directory'", "\n", "settings", ".", "batch_size", "=", "20", "\n", "settings", ".", "num_workers", "=", "8", "\n", "settings", ".", "multi_gpu", "=", "True", "\n", "settings", ".", "print_interval", "=", "1", "\n", "settings", ".", "normalize_mean", "=", "[", "102.9801", ",", "115.9465", ",", "122.7717", "]", "\n", "settings", ".", "normalize_std", "=", "[", "1.0", ",", "1.0", ",", "1.0", "]", "\n", "\n", "settings", ".", "feature_sz", "=", "(", "52", ",", "30", ")", "\n", "\n", "# Settings used for generating the image crop input to the network. See documentation of LWTLProcessing class in", "\n", "# ltr/data/processing.py for details.", "\n", "settings", ".", "output_sz", "=", "(", "settings", ".", "feature_sz", "[", "0", "]", "*", "16", ",", "settings", ".", "feature_sz", "[", "1", "]", "*", "16", ")", "# Size of input image crop", "\n", "settings", ".", "search_area_factor", "=", "5.0", "\n", "settings", ".", "crop_type", "=", "'inside_major'", "\n", "settings", ".", "max_scale_change", "=", "None", "\n", "\n", "settings", ".", "center_jitter_factor", "=", "{", "'train'", ":", "3", ",", "'test'", ":", "(", "5.5", ",", "4.5", ")", "}", "\n", "settings", ".", "scale_jitter_factor", "=", "{", "'train'", ":", "0.25", ",", "'test'", ":", "0.5", "}", "\n", "\n", "# Datasets", "\n", "ytvos_train", "=", "YouTubeVOS", "(", "version", "=", "\"2019\"", ",", "multiobj", "=", "False", ",", "split", "=", "'jjtrain'", ")", "\n", "davis_train", "=", "Davis", "(", "version", "=", "'2017'", ",", "multiobj", "=", "False", ",", "split", "=", "'train'", ")", "\n", "\n", "ytvos_val", "=", "YouTubeVOS", "(", "version", "=", "\"2019\"", ",", "multiobj", "=", "False", ",", "split", "=", "'jjvalid'", ")", "\n", "\n", "# Data transform", "\n", "transform_joint", "=", "tfm", ".", "Transform", "(", "tfm", ".", "ToBGR", "(", ")", ",", "\n", "tfm", ".", "ToGrayscale", "(", "probability", "=", "0.05", ")", ",", "\n", "tfm", ".", "RandomHorizontalFlip", "(", "probability", "=", "0.5", ")", ")", "\n", "\n", "transform_train", "=", "tfm", ".", "Transform", "(", "tfm", ".", "RandomAffine", "(", "p_flip", "=", "0.0", ",", "max_rotation", "=", "15.0", ",", "\n", "max_shear", "=", "0.0", ",", "max_ar_factor", "=", "0.0", ",", "\n", "max_scale", "=", "0.2", ",", "pad_amount", "=", "0", ")", ",", "\n", "tfm", ".", "ToTensorAndJitter", "(", "0.2", ",", "normalize", "=", "False", ")", ",", "\n", "tfm", ".", "Normalize", "(", "mean", "=", "settings", ".", "normalize_mean", ",", "std", "=", "settings", ".", "normalize_std", ")", ")", "\n", "\n", "transform_val", "=", "tfm", ".", "Transform", "(", "tfm", ".", "ToTensorAndJitter", "(", "0.0", ",", "normalize", "=", "False", ")", ",", "\n", "tfm", ".", "Normalize", "(", "mean", "=", "settings", ".", "normalize_mean", ",", "std", "=", "settings", ".", "normalize_std", ")", ")", "\n", "\n", "data_processing_train", "=", "processing", ".", "LWLProcessing", "(", "search_area_factor", "=", "settings", ".", "search_area_factor", ",", "\n", "output_sz", "=", "settings", ".", "output_sz", ",", "\n", "center_jitter_factor", "=", "settings", ".", "center_jitter_factor", ",", "\n", "scale_jitter_factor", "=", "settings", ".", "scale_jitter_factor", ",", "\n", "mode", "=", "'sequence'", ",", "\n", "crop_type", "=", "settings", ".", "crop_type", ",", "\n", "max_scale_change", "=", "settings", ".", "max_scale_change", ",", "\n", "transform", "=", "transform_train", ",", "\n", "joint_transform", "=", "transform_joint", ",", "\n", "new_roll", "=", "True", ")", "\n", "\n", "data_processing_val", "=", "processing", ".", "LWLProcessing", "(", "search_area_factor", "=", "settings", ".", "search_area_factor", ",", "\n", "output_sz", "=", "settings", ".", "output_sz", ",", "\n", "center_jitter_factor", "=", "settings", ".", "center_jitter_factor", ",", "\n", "scale_jitter_factor", "=", "settings", ".", "scale_jitter_factor", ",", "\n", "mode", "=", "'sequence'", ",", "\n", "crop_type", "=", "settings", ".", "crop_type", ",", "\n", "max_scale_change", "=", "settings", ".", "max_scale_change", ",", "\n", "transform", "=", "transform_val", ",", "\n", "joint_transform", "=", "transform_joint", ",", "\n", "new_roll", "=", "True", ")", "\n", "\n", "# Train sampler and loader", "\n", "dataset_train", "=", "sampler", ".", "LWLSampler", "(", "[", "ytvos_train", ",", "davis_train", "]", ",", "[", "6", ",", "1", "]", ",", "\n", "samples_per_epoch", "=", "settings", ".", "batch_size", "*", "1000", ",", "max_gap", "=", "100", ",", "num_test_frames", "=", "3", ",", "\n", "num_train_frames", "=", "1", ",", "\n", "processing", "=", "data_processing_train", ")", "\n", "dataset_val", "=", "sampler", ".", "LWLSampler", "(", "[", "ytvos_val", "]", ",", "[", "1", "]", ",", "\n", "samples_per_epoch", "=", "settings", ".", "batch_size", "*", "100", ",", "max_gap", "=", "100", ",", "\n", "num_test_frames", "=", "3", ",", "\n", "num_train_frames", "=", "1", ",", "\n", "processing", "=", "data_processing_val", ")", "\n", "\n", "loader_train", "=", "LTRLoader", "(", "'train'", ",", "dataset_train", ",", "training", "=", "True", ",", "num_workers", "=", "settings", ".", "num_workers", ",", "\n", "stack_dim", "=", "1", ",", "batch_size", "=", "settings", ".", "batch_size", ")", "\n", "\n", "loader_val", "=", "LTRLoader", "(", "'val'", ",", "dataset_val", ",", "training", "=", "False", ",", "num_workers", "=", "settings", ".", "num_workers", ",", "\n", "epoch_interval", "=", "5", ",", "stack_dim", "=", "1", ",", "batch_size", "=", "settings", ".", "batch_size", ")", "\n", "\n", "# Network", "\n", "net", "=", "lwl_networks", ".", "steepest_descent_resnet50", "(", "filter_size", "=", "3", ",", "num_filters", "=", "16", ",", "optim_iter", "=", "5", ",", "\n", "backbone_pretrained", "=", "True", ",", "\n", "out_feature_dim", "=", "512", ",", "\n", "frozen_backbone_layers", "=", "[", "'conv1'", ",", "'bn1'", ",", "'layer1'", ",", "'layer2'", ",", "'layer3'", ",", "\n", "'layer4'", "]", ",", "\n", "label_encoder_dims", "=", "(", "16", ",", "32", ",", "64", ")", ",", "\n", "use_bn_in_label_enc", "=", "False", ",", "\n", "clf_feat_blocks", "=", "0", ",", "\n", "final_conv", "=", "True", ",", "\n", "backbone_type", "=", "'mrcnn'", ")", "\n", "\n", "# Load pre-trained maskrcnn weights", "\n", "weights_path", "=", "os", ".", "path", ".", "join", "(", "settings", ".", "env", ".", "pretrained_networks", ",", "'e2e_mask_rcnn_R_50_FPN_1x_converted.pkl'", ")", "\n", "pretrained_weights", "=", "torch", ".", "load", "(", "weights_path", ")", "\n", "\n", "net", ".", "feature_extractor", ".", "load_state_dict", "(", "pretrained_weights", ")", "\n", "\n", "# Wrap the network for multi GPU training", "\n", "if", "settings", ".", "multi_gpu", ":", "\n", "        ", "net", "=", "MultiGPU", "(", "net", ",", "dim", "=", "1", ")", "\n", "\n", "# Loss function", "\n", "", "objective", "=", "{", "\n", "'segm'", ":", "LovaszSegLoss", "(", "per_image", "=", "False", ")", ",", "\n", "}", "\n", "\n", "loss_weight", "=", "{", "\n", "'segm'", ":", "100.0", "\n", "}", "\n", "\n", "actor", "=", "segm_actors", ".", "LWLActor", "(", "net", "=", "net", ",", "objective", "=", "objective", ",", "loss_weight", "=", "loss_weight", ",", "\n", "num_refinement_iter", "=", "2", ",", "disable_all_bn", "=", "True", ")", "\n", "\n", "# Optimizer", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "actor", ".", "net", ".", "target_model", ".", "filter_initializer", ".", "parameters", "(", ")", ",", "'lr'", ":", "5e-5", "}", ",", "\n", "{", "'params'", ":", "actor", ".", "net", ".", "target_model", ".", "filter_optimizer", ".", "parameters", "(", ")", ",", "'lr'", ":", "1e-4", "}", ",", "\n", "{", "'params'", ":", "actor", ".", "net", ".", "target_model", ".", "feature_extractor", ".", "parameters", "(", ")", ",", "'lr'", ":", "2e-5", "}", ",", "\n", "{", "'params'", ":", "actor", ".", "net", ".", "decoder", ".", "parameters", "(", ")", ",", "'lr'", ":", "1e-4", "}", ",", "\n", "{", "'params'", ":", "actor", ".", "net", ".", "label_encoder", ".", "parameters", "(", ")", ",", "'lr'", ":", "2e-4", "}", "]", ",", "\n", "lr", "=", "2e-4", ")", "\n", "\n", "lr_scheduler", "=", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "optimizer", ",", "milestones", "=", "[", "40", ",", "]", ",", "gamma", "=", "0.2", ")", "\n", "\n", "trainer", "=", "LTRTrainer", "(", "actor", ",", "[", "loader_train", ",", "loader_val", "]", ",", "optimizer", ",", "settings", ",", "lr_scheduler", ")", "\n", "\n", "trainer", ".", "train", "(", "70", ",", "load_latest", "=", "True", ",", "fail_safe", "=", "True", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.loss_residual_modules.LWTLResidual.__init__": [[11, 15], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "init_filter_reg", "=", "1e-2", ",", "filter_dilation_factors", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "filter_reg", "=", "nn", ".", "Parameter", "(", "init_filter_reg", "*", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "filter_dilation_factors", "=", "filter_dilation_factors", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.loss_residual_modules.LWTLResidual.forward": [[16, 42], ["ltr.apply_filter", "label.view.view.view", "pytracking.TensorList", "math.sqrt", "isinstance", "filter.view", "feat.dim", "sample_weight.view.view.numel", "ltr.apply_filter.numel", "sample_weight.view.view.view", "sample_weight.view.view.dim", "sample_weight.view.view.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "forward", "(", "self", ",", "meta_parameter", ":", "TensorList", ",", "feat", ",", "label", ",", "sample_weight", "=", "None", ")", ":", "\n", "# Assumes multiple filters, i.e.  (sequences, filters, feat_dim, fH, fW)", "\n", "        ", "filter", "=", "meta_parameter", "[", "0", "]", "\n", "\n", "num_images", "=", "feat", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "if", "feat", ".", "dim", "(", ")", "==", "5", "else", "1", "\n", "\n", "# Compute scores", "\n", "scores", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "filter", ",", "dilation_factors", "=", "self", ".", "filter_dilation_factors", ")", "\n", "\n", "if", "sample_weight", "is", "None", ":", "\n", "            ", "sample_weight", "=", "math", ".", "sqrt", "(", "1.0", "/", "num_images", ")", "\n", "", "elif", "isinstance", "(", "sample_weight", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "if", "sample_weight", ".", "numel", "(", ")", "==", "scores", ".", "numel", "(", ")", ":", "\n", "                ", "sample_weight", "=", "sample_weight", ".", "view", "(", "scores", ".", "shape", ")", "\n", "", "elif", "sample_weight", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "sample_weight", "=", "sample_weight", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "", "label", "=", "label", ".", "view", "(", "scores", ".", "shape", ")", "\n", "\n", "data_residual", "=", "sample_weight", "*", "(", "scores", "-", "label", ")", "\n", "\n", "# Compute regularization residual. Put batch in second dimension", "\n", "reg_residual", "=", "self", ".", "filter_reg", "*", "filter", ".", "view", "(", "1", ",", "num_sequences", ",", "-", "1", ")", "\n", "\n", "return", "TensorList", "(", "[", "data_residual", ",", "reg_residual", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_box_net.LWTLBoxNet.__init__": [[18, 34], ["torch.Module.__init__", "sorted", "isinstance", "list", "set"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["    ", "def", "__init__", "(", "self", ",", "feature_extractor", ",", "target_model", ",", "decoder", ",", "target_model_input_layer", ",", "decoder_input_layers", ",", "\n", "label_encoder", "=", "None", ",", "box_label_encoder", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "feature_extractor", "=", "feature_extractor", "# Backbone feature extractor F", "\n", "self", ".", "target_model", "=", "target_model", "# Target model and the few-shot learner", "\n", "self", ".", "decoder", "=", "decoder", "# Segmentation Decoder", "\n", "\n", "self", ".", "label_encoder", "=", "label_encoder", "# Few-shot label generator and weight predictor", "\n", "\n", "self", ".", "target_model_input_layer", "=", "(", "target_model_input_layer", ",", ")", "if", "isinstance", "(", "target_model_input_layer", ",", "\n", "str", ")", "else", "target_model_input_layer", "\n", "self", ".", "decoder_input_layers", "=", "decoder_input_layers", "\n", "self", ".", "output_layers", "=", "sorted", "(", "list", "(", "set", "(", "self", ".", "target_model_input_layer", "+", "self", ".", "decoder_input_layers", ")", ")", ")", "\n", "self", ".", "box_label_encoder", "=", "box_label_encoder", "\n", "self", ".", "train_only_box_label_gen", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_box_net.LWTLBoxNet.train": [[35, 83], ["lwl_box_net.LWTLBoxNet.feature_extractor.parameters", "lwl_box_net.LWTLBoxNet.feature_extractor.eval", "x.requires_grad_", "lwl_box_net.LWTLBoxNet.box_label_encoder.parameters", "lwl_box_net.LWTLBoxNet.box_label_encoder.train", "lwl_box_net.LWTLBoxNet.target_model.parameters", "lwl_box_net.LWTLBoxNet.target_model.eval", "lwl_box_net.LWTLBoxNet.label_encoder.parameters", "lwl_box_net.LWTLBoxNet.label_encoder.eval", "lwl_box_net.LWTLBoxNet.decoder.parameters", "lwl_box_net.LWTLBoxNet.decoder.eval", "lwl_box_net.LWTLBoxNet.box_label_encoder.parameters", "lwl_box_net.LWTLBoxNet.box_label_encoder.eval", "x.requires_grad_", "lwl_box_net.LWTLBoxNet.target_model.parameters", "lwl_box_net.LWTLBoxNet.target_model.eval", "lwl_box_net.LWTLBoxNet.label_encoder.parameters", "lwl_box_net.LWTLBoxNet.label_encoder.eval", "lwl_box_net.LWTLBoxNet.decoder.parameters", "lwl_box_net.LWTLBoxNet.decoder.eval", "lwl_box_net.LWTLBoxNet.target_model.parameters", "lwl_box_net.LWTLBoxNet.target_model.train", "lwl_box_net.LWTLBoxNet.label_encoder.parameters", "lwl_box_net.LWTLBoxNet.label_encoder.train", "lwl_box_net.LWTLBoxNet.decoder.parameters", "lwl_box_net.LWTLBoxNet.decoder.train", "x.requires_grad_", "x.requires_grad_", "x.requires_grad_", "x.requires_grad_", "x.requires_grad_", "x.requires_grad_", "x.requires_grad_", "x.requires_grad_", "x.requires_grad_", "x.requires_grad_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "for", "x", "in", "self", ".", "feature_extractor", ".", "parameters", "(", ")", ":", "\n", "            ", "x", ".", "requires_grad_", "(", "False", ")", "\n", "", "self", ".", "feature_extractor", ".", "eval", "(", ")", "\n", "\n", "if", "mode", ":", "\n", "            ", "for", "x", "in", "self", ".", "box_label_encoder", ".", "parameters", "(", ")", ":", "\n", "                ", "x", ".", "requires_grad_", "(", "True", ")", "\n", "", "self", ".", "box_label_encoder", ".", "train", "(", ")", "\n", "\n", "if", "self", ".", "train_only_box_label_gen", ":", "\n", "                ", "for", "x", "in", "self", ".", "target_model", ".", "parameters", "(", ")", ":", "\n", "                    ", "x", ".", "requires_grad_", "(", "False", ")", "\n", "", "self", ".", "target_model", ".", "eval", "(", ")", "\n", "for", "x", "in", "self", ".", "label_encoder", ".", "parameters", "(", ")", ":", "\n", "                    ", "x", ".", "requires_grad_", "(", "False", ")", "\n", "", "self", ".", "label_encoder", ".", "eval", "(", ")", "\n", "for", "x", "in", "self", ".", "decoder", ".", "parameters", "(", ")", ":", "\n", "                    ", "x", ".", "requires_grad_", "(", "False", ")", "\n", "", "self", ".", "decoder", ".", "eval", "(", ")", "\n", "\n", "", "else", ":", "\n", "                ", "for", "x", "in", "self", ".", "target_model", ".", "parameters", "(", ")", ":", "\n", "                    ", "x", ".", "requires_grad_", "(", "True", ")", "\n", "", "self", ".", "target_model", ".", "train", "(", ")", "\n", "for", "x", "in", "self", ".", "label_encoder", ".", "parameters", "(", ")", ":", "\n", "                    ", "x", ".", "requires_grad_", "(", "True", ")", "\n", "", "self", ".", "label_encoder", ".", "train", "(", ")", "\n", "for", "x", "in", "self", ".", "decoder", ".", "parameters", "(", ")", ":", "\n", "                    ", "x", ".", "requires_grad_", "(", "True", ")", "\n", "", "self", ".", "decoder", ".", "train", "(", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "for", "x", "in", "self", ".", "target_model", ".", "parameters", "(", ")", ":", "\n", "                ", "x", ".", "requires_grad_", "(", "False", ")", "\n", "", "self", ".", "target_model", ".", "eval", "(", ")", "\n", "\n", "for", "x", "in", "self", ".", "label_encoder", ".", "parameters", "(", ")", ":", "\n", "                ", "x", ".", "requires_grad_", "(", "False", ")", "\n", "", "self", ".", "label_encoder", ".", "eval", "(", ")", "\n", "\n", "for", "x", "in", "self", ".", "decoder", ".", "parameters", "(", ")", ":", "\n", "                ", "x", ".", "requires_grad_", "(", "False", ")", "\n", "", "self", ".", "decoder", ".", "eval", "(", ")", "\n", "\n", "for", "x", "in", "self", ".", "box_label_encoder", ".", "parameters", "(", ")", ":", "\n", "                ", "x", ".", "requires_grad_", "(", "False", ")", "\n", "", "self", ".", "box_label_encoder", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_box_net.LWTLBoxNet.forward": [[84, 125], ["lwl_box_net.LWTLBoxNet.extract_backbone_features", "lwl_box_net.LWTLBoxNet.extract_backbone_features", "lwl_box_net.LWTLBoxNet.extract_classification_feat", "lwl_box_net.LWTLBoxNet.extract_classification_feat", "lwl_box_net.LWTLBoxNet.box_label_encoder", "lwl_box_net.LWTLBoxNet.decoder", "lwl_box_net.LWTLBoxNet.label_encoder", "lwl_box_net.LWTLBoxNet.label_encoder", "train_feat_clf.view.view.view", "lwl_box_net.LWTLBoxNet.target_model.get_filter", "test_feat_clf.view.view.view", "lwl_box_net.LWTLBoxNet.decoder", "target_scores_last_iter.view", "isinstance", "train_masks.dim", "train_imgs.contiguous().view", "test_imgs.contiguous().view", "test_masks.contiguous", "lwl_box_net.LWTLBoxNet.target_model.classify", "train_imgs.dim", "test_imgs.dim", "train_imgs.contiguous", "test_imgs.contiguous"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat", "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.get_filter", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.classify", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "", "def", "forward", "(", "self", ",", "train_imgs", ",", "test_imgs", ",", "train_masks", ",", "test_masks", ",", "bb_train", ",", "num_refinement_iter", "=", "2", ")", ":", "\n", "        ", "assert", "train_imgs", ".", "dim", "(", ")", "==", "5", "and", "test_imgs", ".", "dim", "(", ")", "==", "5", ",", "'Expect 5 dimensional inputs'", "\n", "assert", "train_masks", ".", "dim", "(", ")", "==", "4", ",", "'Expect 4 dimensional masks'", "\n", "\n", "num_sequences", "=", "train_imgs", ".", "shape", "[", "1", "]", "\n", "num_train_frames", "=", "train_imgs", ".", "shape", "[", "0", "]", "\n", "num_test_frames", "=", "test_imgs", ".", "shape", "[", "0", "]", "\n", "\n", "# Extract backbone features", "\n", "train_feat", "=", "self", ".", "extract_backbone_features", "(", "train_imgs", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "train_imgs", ".", "shape", "[", "-", "3", "]", ",", "train_imgs", ".", "shape", "[", "-", "2", "]", ",", "train_imgs", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "test_feat", "=", "self", ".", "extract_backbone_features", "(", "test_imgs", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "test_imgs", ".", "shape", "[", "-", "3", "]", ",", "test_imgs", ".", "shape", "[", "-", "2", "]", ",", "test_imgs", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "\n", "# Extract classification features", "\n", "train_feat_clf", "=", "self", ".", "extract_classification_feat", "(", "train_feat", ")", "# seq*frames, channels, height, width", "\n", "test_feat_clf", "=", "self", ".", "extract_classification_feat", "(", "test_feat", ")", "# seq*frames, channels, height, width", "\n", "\n", "bb_mask_enc", "=", "self", ".", "box_label_encoder", "(", "bb_train", ",", "train_feat_clf", ")", "\n", "\n", "box_mask_pred", ",", "decoder_feat", "=", "self", ".", "decoder", "(", "bb_mask_enc", ",", "test_feat", ",", "test_imgs", ".", "shape", "[", "-", "2", ":", "]", ",", "\n", "(", "'layer4_dec'", ",", "'layer3_dec'", ",", "'layer2_dec'", ",", "'layer1_dec'", ")", ")", "\n", "\n", "mask_enc", "=", "self", ".", "label_encoder", "(", "box_mask_pred", ",", "train_feat_clf", ")", "\n", "mask_enc_test", "=", "self", ".", "label_encoder", "(", "test_masks", ".", "contiguous", "(", ")", ",", "test_feat_clf", ")", "\n", "\n", "train_feat_clf", "=", "train_feat_clf", ".", "view", "(", "num_train_frames", ",", "num_sequences", ",", "*", "train_feat_clf", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "filter", ",", "filter_iter", ",", "_", "=", "self", ".", "target_model", ".", "get_filter", "(", "train_feat_clf", ",", "*", "mask_enc", ")", "\n", "\n", "test_feat_clf", "=", "test_feat_clf", ".", "view", "(", "num_test_frames", ",", "num_sequences", ",", "*", "test_feat_clf", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "target_scores", "=", "[", "self", ".", "target_model", ".", "classify", "(", "f", ",", "test_feat_clf", ")", "for", "f", "in", "filter_iter", "]", "\n", "# target_scores = [s.unsqueeze(dim=2) for s in target_scores]", "\n", "\n", "target_scores_last_iter", "=", "target_scores", "[", "-", "1", "]", "\n", "\n", "mask_pred", ",", "decoder_feat", "=", "self", ".", "decoder", "(", "target_scores_last_iter", ",", "test_feat", ",", "test_imgs", ".", "shape", "[", "-", "2", ":", "]", ",", "\n", "(", "'layer4_dec'", ",", "'layer3_dec'", ",", "'layer2_dec'", ",", "'layer1_dec'", ")", ")", "\n", "\n", "decoder_feat", "[", "'mask_enc'", "]", "=", "target_scores_last_iter", ".", "view", "(", "-", "1", ",", "*", "target_scores_last_iter", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "if", "isinstance", "(", "mask_enc_test", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "mask_enc_test", "=", "mask_enc_test", "[", "0", "]", "\n", "", "return", "mask_pred", ",", "target_scores", ",", "mask_enc_test", ",", "box_mask_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_box_net.LWTLBoxNet.segment_target": [[126, 137], ["test_feat_tm.view.view.view", "lwl_box_net.LWTLBoxNet.target_model.apply_target_model", "lwl_box_net.LWTLBoxNet.decoder", "target_filter.dim"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.linear_filter.LinearFilter.apply_target_model", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "segment_target", "(", "self", ",", "target_filter", ",", "test_feat_tm", ",", "test_feat", ")", ":", "\n", "# Classification features", "\n", "        ", "assert", "target_filter", ".", "dim", "(", ")", "==", "5", "# seq, filters, ch, h, w", "\n", "test_feat_tm", "=", "test_feat_tm", ".", "view", "(", "1", ",", "1", ",", "*", "test_feat_tm", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "mask_encoding_pred", "=", "self", ".", "target_model", ".", "apply_target_model", "(", "target_filter", ",", "test_feat_tm", ")", "\n", "\n", "mask_pred", ",", "decoder_feat", "=", "self", ".", "decoder", "(", "mask_encoding_pred", ",", "test_feat", ",", "\n", "(", "test_feat_tm", ".", "shape", "[", "-", "2", "]", "*", "16", ",", "test_feat_tm", ".", "shape", "[", "-", "1", "]", "*", "16", ")", ")", "\n", "\n", "return", "mask_pred", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_box_net.LWTLBoxNet.get_backbone_target_model_features": [[138, 144], ["collections.OrderedDict", "len"], "methods", ["None"], ["", "def", "get_backbone_target_model_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "# Get the backbone feature block which is input to the target model", "\n", "        ", "feat", "=", "OrderedDict", "(", "{", "l", ":", "backbone_feat", "[", "l", "]", "for", "l", "in", "self", ".", "target_model_input_layer", "}", ")", "\n", "if", "len", "(", "self", ".", "target_model_input_layer", ")", "==", "1", ":", "\n", "            ", "return", "feat", "[", "self", ".", "target_model_input_layer", "[", "0", "]", "]", "\n", "", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_box_net.LWTLBoxNet.extract_target_model_features": [[145, 147], ["lwl_box_net.LWTLBoxNet.target_model.extract_target_model_features", "lwl_box_net.LWTLBoxNet.get_backbone_target_model_features"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.extract_target_model_features", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.get_backbone_target_model_features"], ["", "def", "extract_target_model_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "return", "self", ".", "target_model", ".", "extract_target_model_features", "(", "self", ".", "get_backbone_target_model_features", "(", "backbone_feat", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_box_net.LWTLBoxNet.extract_backbone_features": [[148, 152], ["lwl_box_net.LWTLBoxNet.feature_extractor"], "methods", ["None"], ["", "def", "extract_backbone_features", "(", "self", ",", "im", ",", "layers", "=", "None", ")", ":", "\n", "        ", "if", "layers", "is", "None", ":", "\n", "            ", "layers", "=", "self", ".", "output_layers", "\n", "", "return", "self", ".", "feature_extractor", "(", "im", ",", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_box_net.steepest_descent_resnet50": [[154, 240], ["float", "math.sqrt", "mrcnn_backbones.resnet50.out_feature_channels", "ltr.residual_basic_block", "ltr.ResidualDS16SW", "ltr.FilterInitializerZero", "ltr.LWTLResidual", "ltr.GNSteepestDescent", "ltr.LinearFilter", "ltr.LWTLDecoder", "lwl_box_net.LWTLBoxNet", "ltr.resnet50", "ltr.ResidualDS16FeatSWBoxCatMultiBlock", "ltr.resnet50"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet.out_feature_channels", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_basic_block", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet50", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet50"], ["", "", "@", "model_constructor", "\n", "def", "steepest_descent_resnet50", "(", "filter_size", "=", "1", ",", "num_filters", "=", "1", ",", "optim_iter", "=", "3", ",", "optim_init_reg", "=", "0.01", ",", "\n", "backbone_pretrained", "=", "False", ",", "clf_feat_blocks", "=", "1", ",", "\n", "clf_feat_norm", "=", "True", ",", "final_conv", "=", "False", ",", "\n", "out_feature_dim", "=", "512", ",", "\n", "target_model_input_layer", "=", "'layer3'", ",", "\n", "decoder_input_layers", "=", "(", "\"layer4\"", ",", "\"layer3\"", ",", "\"layer2\"", ",", "\"layer1\"", ",", ")", ",", "\n", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "\n", "label_encoder_dims", "=", "(", "1", ",", "1", ")", ",", "\n", "frozen_backbone_layers", "=", "(", ")", ",", "\n", "decoder_mdim", "=", "64", ",", "filter_groups", "=", "1", ",", "\n", "use_bn_in_label_enc", "=", "True", ",", "\n", "dilation_factors", "=", "None", ",", "\n", "backbone_type", "=", "'imagenet'", ",", "\n", "box_label_encoder_dims", "=", "(", "1", ",", "1", ")", ",", "\n", "box_label_encoder_type", "=", "'ResidualDS16FeatSWBoxCatMultiBlock'", ",", "\n", "use_gauss", "=", "False", ",", "\n", "use_final_relu", "=", "True", ",", "\n", "init_bn", "=", "1.0", ",", "\n", "final_bn", "=", "False", ",", "\n", "gauss_scale", "=", "0.25", "\n", ")", ":", "\n", "# backbone feature extractor F", "\n", "    ", "if", "backbone_type", "==", "'imagenet'", ":", "\n", "        ", "backbone_net", "=", "backbones", ".", "resnet50", "(", "pretrained", "=", "backbone_pretrained", ",", "frozen_layers", "=", "frozen_backbone_layers", ")", "\n", "", "elif", "backbone_type", "==", "'mrcnn'", ":", "\n", "        ", "backbone_net", "=", "mrcnn_backbones", ".", "resnet50", "(", "pretrained", "=", "False", ",", "frozen_layers", "=", "frozen_backbone_layers", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "\n", "\n", "", "norm_scale", "=", "math", ".", "sqrt", "(", "1.0", "/", "(", "out_feature_dim", "*", "filter_size", "*", "filter_size", ")", ")", "\n", "\n", "layer_channels", "=", "backbone_net", ".", "out_feature_channels", "(", ")", "\n", "\n", "# Extracts features input to the target model", "\n", "target_model_feature_extractor", "=", "clf_features", ".", "residual_basic_block", "(", "\n", "feature_dim", "=", "layer_channels", "[", "target_model_input_layer", "]", ",", "\n", "num_blocks", "=", "clf_feat_blocks", ",", "l2norm", "=", "clf_feat_norm", ",", "\n", "final_conv", "=", "final_conv", ",", "norm_scale", "=", "norm_scale", ",", "\n", "out_dim", "=", "out_feature_dim", ")", "\n", "\n", "# Few-shot label generator and weight predictor", "\n", "label_encoder", "=", "seg_label_encoder", ".", "ResidualDS16SW", "(", "layer_dims", "=", "label_encoder_dims", "+", "(", "num_filters", ",", ")", ",", "\n", "use_bn", "=", "use_bn_in_label_enc", ")", "\n", "\n", "# Predicts initial target model parameters", "\n", "initializer", "=", "seg_initializer", ".", "FilterInitializerZero", "(", "filter_size", "=", "filter_size", ",", "num_filters", "=", "num_filters", ",", "\n", "feature_dim", "=", "out_feature_dim", ",", "filter_groups", "=", "filter_groups", ")", "\n", "\n", "# Computes few-shot learning loss", "\n", "residual_module", "=", "loss_residual_modules", ".", "LWTLResidual", "(", "init_filter_reg", "=", "optim_init_reg", ")", "\n", "\n", "# Iteratively updates the target model parameters by minimizing the few-shot learning loss", "\n", "optimizer", "=", "steepestdescent", ".", "GNSteepestDescent", "(", "residual_module", "=", "residual_module", ",", "num_iter", "=", "optim_iter", ",", "\n", "detach_length", "=", "detach_length", ",", "\n", "residual_batch_dim", "=", "1", ",", "compute_losses", "=", "True", ")", "\n", "\n", "# Target model and Few-shot learner", "\n", "target_model", "=", "target_clf", ".", "LinearFilter", "(", "filter_size", "=", "filter_size", ",", "filter_initializer", "=", "initializer", ",", "\n", "filter_optimizer", "=", "optimizer", ",", "feature_extractor", "=", "target_model_feature_extractor", ",", "\n", "filter_dilation_factors", "=", "dilation_factors", ")", "\n", "\n", "# Decoder", "\n", "decoder_input_layers_channels", "=", "{", "L", ":", "layer_channels", "[", "L", "]", "for", "L", "in", "decoder_input_layers", "}", "\n", "\n", "decoder", "=", "lwtl_decoder", ".", "LWTLDecoder", "(", "num_filters", ",", "decoder_mdim", ",", "decoder_input_layers_channels", ",", "use_bn", "=", "True", ")", "\n", "\n", "if", "box_label_encoder_type", "==", "'ResidualDS16FeatSWBoxCatMultiBlock'", ":", "\n", "        ", "box_label_encoder", "=", "seg_label_encoder", ".", "ResidualDS16FeatSWBoxCatMultiBlock", "(", "feat_dim", "=", "out_feature_dim", ",", "\n", "layer_dims", "=", "box_label_encoder_dims", "+", "(", "\n", "num_filters", ",", ")", ",", "\n", "use_gauss", "=", "use_gauss", ",", "\n", "use_final_relu", "=", "use_final_relu", ",", "\n", "use_bn", "=", "use_bn_in_label_enc", ",", "\n", "non_default_init", "=", "True", ",", "init_bn", "=", "init_bn", ",", "\n", "gauss_scale", "=", "gauss_scale", ",", "\n", "final_bn", "=", "final_bn", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "\n", "\n", "", "net", "=", "LWTLBoxNet", "(", "feature_extractor", "=", "backbone_net", ",", "target_model", "=", "target_model", ",", "decoder", "=", "decoder", ",", "\n", "label_encoder", "=", "label_encoder", ",", "\n", "target_model_input_layer", "=", "target_model_input_layer", ",", "decoder_input_layers", "=", "decoder_input_layers", ",", "\n", "box_label_encoder", "=", "box_label_encoder", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_box_net.steepest_descent_resnet50_from_checkpoint": [[242, 275], ["lwl_box_net.LWTLBoxNet", "ltr.ResidualDS16FeatSWBoxCatMultiBlock"], "function", ["None"], ["", "@", "model_constructor", "\n", "def", "steepest_descent_resnet50_from_checkpoint", "(", "net", "=", "None", ",", "num_filters", "=", "1", ",", "\n", "out_feature_dim", "=", "512", ",", "\n", "target_model_input_layer", "=", "'layer3'", ",", "\n", "box_label_encoder_dims", "=", "(", "1", ",", "1", ")", ",", "\n", "use_bn_in_label_enc", "=", "True", ",", "\n", "box_label_encoder_type", "=", "'ResidualDS16FeatSWBoxCatMultiBlock'", ",", "\n", "use_gauss", "=", "False", ",", "\n", "use_final_relu", "=", "True", ",", "\n", "init_bn", "=", "1", ",", "\n", "gauss_scale", "=", "0.25", ",", "\n", "decoder_input_layers", "=", "(", "\"layer4\"", ",", "\"layer3\"", ",", "\"layer2\"", ",", "\"layer1\"", ",", ")", ",", "\n", "final_bn", "=", "False", ")", ":", "\n", "\n", "    ", "if", "box_label_encoder_type", "==", "'ResidualDS16FeatSWBoxCatMultiBlock'", ":", "\n", "        ", "box_label_encoder", "=", "seg_label_encoder", ".", "ResidualDS16FeatSWBoxCatMultiBlock", "(", "feat_dim", "=", "out_feature_dim", ",", "\n", "layer_dims", "=", "box_label_encoder_dims", "+", "(", "\n", "num_filters", ",", ")", ",", "\n", "use_gauss", "=", "use_gauss", ",", "\n", "use_final_relu", "=", "use_final_relu", ",", "\n", "use_bn", "=", "use_bn_in_label_enc", ",", "\n", "non_default_init", "=", "True", ",", "init_bn", "=", "init_bn", ",", "\n", "gauss_scale", "=", "gauss_scale", ",", "\n", "final_bn", "=", "final_bn", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "\n", "\n", "", "net", "=", "LWTLBoxNet", "(", "feature_extractor", "=", "net", ".", "feature_extractor", ",", "target_model", "=", "net", ".", "target_model", ",", "decoder", "=", "net", ".", "decoder", ",", "\n", "label_encoder", "=", "net", ".", "label_encoder", ",", "target_model_input_layer", "=", "target_model_input_layer", ",", "\n", "decoder_input_layers", "=", "decoder_input_layers", ",", "\n", "box_label_encoder", "=", "box_label_encoder", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.linear_filter.LinearFilter.__init__": [[11, 35], ["torch.Module.__init__", "linear_filter.LinearFilter.feature_extractor.modules", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "filter_size", ",", "filter_initializer", ",", "filter_optimizer", "=", "None", ",", "feature_extractor", "=", "None", ",", "\n", "filter_dilation_factors", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "filter_size", "=", "filter_size", "\n", "\n", "self", ".", "feature_extractor", "=", "feature_extractor", "# Extracts features input to the target model", "\n", "\n", "self", ".", "filter_initializer", "=", "filter_initializer", "# Predicts an initial filter in a feed-forward manner", "\n", "self", ".", "filter_optimizer", "=", "filter_optimizer", "# Iteratively updates the filter by minimizing the few-shot", "\n", "# learning loss", "\n", "\n", "self", ".", "filter_dilation_factors", "=", "filter_dilation_factors", "\n", "\n", "# Init weights", "\n", "for", "m", "in", "self", ".", "feature_extractor", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.linear_filter.LinearFilter.forward": [[36, 59], ["linear_filter.LinearFilter.extract_target_model_features", "linear_filter.LinearFilter.extract_target_model_features", "linear_filter.LinearFilter.get_filter", "train_label.dim", "train_feat.view.view.dim", "train_feat.view.view.view", "test_feat.view.view.dim", "test_feat.view.view.view", "linear_filter.LinearFilter.apply_target_model"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.extract_target_model_features", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.extract_target_model_features", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.get_filter", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.linear_filter.LinearFilter.apply_target_model"], ["", "", "", "def", "forward", "(", "self", ",", "train_feat", ",", "test_feat", ",", "train_label", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" the mask should be 5d\"\"\"", "\n", "assert", "train_label", ".", "dim", "(", ")", "==", "5", "\n", "\n", "num_sequences", "=", "train_label", ".", "shape", "[", "1", "]", "\n", "\n", "if", "train_feat", ".", "dim", "(", ")", "==", "5", ":", "\n", "            ", "train_feat", "=", "train_feat", ".", "view", "(", "-", "1", ",", "*", "train_feat", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "", "if", "test_feat", ".", "dim", "(", ")", "==", "5", ":", "\n", "            ", "test_feat", "=", "test_feat", ".", "view", "(", "-", "1", ",", "*", "test_feat", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "# Extract target model features", "\n", "", "train_feat", "=", "self", ".", "extract_target_model_features", "(", "train_feat", ",", "num_sequences", ")", "\n", "test_feat", "=", "self", ".", "extract_target_model_features", "(", "test_feat", ",", "num_sequences", ")", "\n", "\n", "# Train filter", "\n", "filter", ",", "filter_iter", ",", "_", "=", "self", ".", "get_filter", "(", "train_feat", ",", "train_label", ",", "\n", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Predict mask encodings for the test frames", "\n", "mask_encodings", "=", "[", "self", ".", "apply_target_model", "(", "f", ",", "test_feat", ")", "for", "f", "in", "filter_iter", "]", "\n", "\n", "return", "mask_encodings", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.linear_filter.LinearFilter.extract_target_model_features": [[60, 68], ["linear_filter.LinearFilter.feature_extractor", "linear_filter.LinearFilter.view", "linear_filter.LinearFilter.feature_extractor"], "methods", ["None"], ["", "def", "extract_target_model_features", "(", "self", ",", "feat", ",", "num_sequences", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "feature_extractor", "is", "None", ":", "\n", "            ", "return", "feat", "\n", "", "if", "num_sequences", "is", "None", ":", "\n", "            ", "return", "self", ".", "feature_extractor", "(", "feat", ")", "\n", "\n", "", "output", "=", "self", ".", "feature_extractor", "(", "feat", ")", "\n", "return", "output", ".", "view", "(", "-", "1", ",", "num_sequences", ",", "*", "output", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.linear_filter.LinearFilter.apply_target_model": [[69, 73], ["ltr.apply_filter"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter"], ["", "def", "apply_target_model", "(", "self", ",", "weights", ",", "feat", ")", ":", "\n", "        ", "\"\"\" Apply the target model to obtain the mask encodings\"\"\"", "\n", "mask_encoding", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "weights", ",", "dilation_factors", "=", "self", ".", "filter_dilation_factors", ")", "\n", "return", "mask_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.linear_filter.LinearFilter.get_filter": [[74, 93], ["linear_filter.LinearFilter.filter_initializer", "linear_filter.LinearFilter.filter_initializer", "weights.repeat.repeat.repeat", "linear_filter.LinearFilter.filter_optimizer", "pytracking.TensorList"], "methods", ["None"], ["", "def", "get_filter", "(", "self", ",", "feat", ",", "train_label", ",", "train_sw", ",", "num_objects", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Get the initial target model parameters given the few-shot labels \"\"\"", "\n", "if", "num_objects", "is", "None", ":", "\n", "            ", "weights", "=", "self", ".", "filter_initializer", "(", "feat", ",", "train_label", ")", "\n", "", "else", ":", "\n", "            ", "weights", "=", "self", ".", "filter_initializer", "(", "feat", ",", "train_label", ")", "\n", "weights", "=", "weights", ".", "repeat", "(", "1", ",", "num_objects", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "if", "self", ".", "filter_optimizer", "is", "not", "None", ":", "\n", "            ", "weights", ",", "weights_iter", ",", "losses", "=", "self", ".", "filter_optimizer", "(", "TensorList", "(", "[", "weights", "]", ")", ",", "feat", "=", "feat", ",", "label", "=", "train_label", ",", "\n", "sample_weight", "=", "train_sw", ",", "\n", "*", "args", ",", "**", "kwargs", ")", "\n", "weights", "=", "weights", "[", "0", "]", "\n", "weights_iter", "=", "[", "w", "[", "0", "]", "for", "w", "in", "weights_iter", "]", "\n", "", "else", ":", "\n", "            ", "weights_iter", "=", "[", "weights", "]", "\n", "losses", "=", "None", "\n", "\n", "", "return", "weights", ",", "weights_iter", ",", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.label_encoder.ResidualDS16SW.__init__": [[11, 37], ["torch.Module.__init__", "ltr.models.layers.blocks.conv_block", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "ltr.models.backbone.resnet.BasicBlock", "torch.Conv2d", "torch.Conv2d", "ltr.models.backbone.resnet.BasicBlock", "ltr.models.layers.blocks.conv_block", "torch.Conv2d", "torch.Conv2d", "label_encoder.ResidualDS16SW.modules", "label_encoder.ResidualDS16SW.samp_w_pred.weight.data.fill_", "label_encoder.ResidualDS16SW.samp_w_pred.bias.data.fill_", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block"], ["def", "__init__", "(", "self", ",", "layer_dims", ",", "use_bn", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_block", "=", "conv_block", "(", "1", ",", "layer_dims", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "batch_norm", "=", "use_bn", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "\n", "ds1", "=", "nn", ".", "Conv2d", "(", "layer_dims", "[", "0", "]", ",", "layer_dims", "[", "1", "]", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "2", ")", "\n", "self", ".", "res1", "=", "BasicBlock", "(", "layer_dims", "[", "0", "]", ",", "layer_dims", "[", "1", "]", ",", "stride", "=", "2", ",", "downsample", "=", "ds1", ",", "use_bn", "=", "use_bn", ")", "\n", "\n", "ds2", "=", "nn", ".", "Conv2d", "(", "layer_dims", "[", "1", "]", ",", "layer_dims", "[", "2", "]", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "2", ")", "\n", "self", ".", "res2", "=", "BasicBlock", "(", "layer_dims", "[", "1", "]", ",", "layer_dims", "[", "2", "]", ",", "stride", "=", "2", ",", "downsample", "=", "ds2", ",", "use_bn", "=", "use_bn", ")", "\n", "\n", "self", ".", "label_pred", "=", "conv_block", "(", "layer_dims", "[", "2", "]", ",", "layer_dims", "[", "3", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "relu", "=", "True", ",", "batch_norm", "=", "use_bn", ")", "\n", "\n", "self", ".", "samp_w_pred", "=", "nn", ".", "Conv2d", "(", "layer_dims", "[", "2", "]", ",", "layer_dims", "[", "3", "]", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "1", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "", "", "self", ".", "samp_w_pred", ".", "weight", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "samp_w_pred", ".", "bias", ".", "data", ".", "fill_", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.label_encoder.ResidualDS16SW.forward": [[38, 56], ["label_mask.view.view.view", "label_encoder.ResidualDS16SW.pool", "label_encoder.ResidualDS16SW.res2", "label_encoder.ResidualDS16SW.label_pred", "label_encoder.ResidualDS16SW.samp_w_pred", "label_enc.view.view.view", "sample_w.view.view.view", "label_mask.view.view.dim", "label_encoder.ResidualDS16SW.conv_block", "label_encoder.ResidualDS16SW.res1"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block"], ["", "def", "forward", "(", "self", ",", "label_mask", ",", "feature", "=", "None", ")", ":", "\n", "# label_mask: frames, seq, h, w", "\n", "        ", "assert", "label_mask", ".", "dim", "(", ")", "==", "4", "\n", "\n", "label_shape", "=", "label_mask", ".", "shape", "\n", "label_mask", "=", "label_mask", ".", "view", "(", "-", "1", ",", "1", ",", "*", "label_mask", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "\n", "out", "=", "self", ".", "pool", "(", "self", ".", "conv_block", "(", "label_mask", ")", ")", "\n", "out", "=", "self", ".", "res2", "(", "self", ".", "res1", "(", "out", ")", ")", "\n", "\n", "label_enc", "=", "self", ".", "label_pred", "(", "out", ")", "\n", "sample_w", "=", "self", ".", "samp_w_pred", "(", "out", ")", "\n", "\n", "label_enc", "=", "label_enc", ".", "view", "(", "label_shape", "[", "0", "]", ",", "label_shape", "[", "1", "]", ",", "*", "label_enc", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "sample_w", "=", "sample_w", ".", "view", "(", "label_shape", "[", "0", "]", ",", "label_shape", "[", "1", "]", ",", "*", "sample_w", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "# Out dim is (num_seq, num_frames, layer_dims[-1], h, w)", "\n", "return", "label_enc", ",", "sample_w", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.label_encoder.ResidualDS16FeatSWBoxCatMultiBlock.__init__": [[59, 82], ["torch.Module.__init__", "tuple", "zip", "torch.Sequential", "torch.Sequential", "ltr.models.layers.blocks.conv_block", "tuple", "torch.Conv2d", "torch.Conv2d", "res.append", "label_encoder.ResidualDS16FeatSWBoxCatMultiBlock.modules", "list", "ltr.models.backbone.resnet.BasicBlock", "isinstance", "list", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["    ", "def", "__init__", "(", "self", ",", "layer_dims", ",", "feat_dim", ",", "use_final_relu", "=", "True", ",", "use_gauss", "=", "True", ",", "use_bn", "=", "True", ",", "\n", "non_default_init", "=", "True", ",", "init_bn", "=", "1", ",", "gauss_scale", "=", "0.25", ",", "final_bn", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "in_layer_dim", "=", "(", "feat_dim", "+", "1", ",", ")", "+", "tuple", "(", "list", "(", "layer_dims", ")", "[", ":", "-", "2", "]", ")", "\n", "out_layer_dim", "=", "tuple", "(", "list", "(", "layer_dims", ")", "[", ":", "-", "1", "]", ")", "\n", "self", ".", "use_gauss", "=", "use_gauss", "\n", "res", "=", "[", "]", "\n", "for", "in_d", ",", "out_d", "in", "zip", "(", "in_layer_dim", ",", "out_layer_dim", ")", ":", "\n", "            ", "ds", "=", "nn", ".", "Conv2d", "(", "in_d", ",", "out_d", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "1", ")", "\n", "res", ".", "append", "(", "BasicBlock", "(", "in_d", ",", "out_d", ",", "stride", "=", "1", ",", "downsample", "=", "ds", ",", "use_bn", "=", "use_bn", ")", ")", "\n", "\n", "", "self", ".", "res", "=", "nn", ".", "Sequential", "(", "*", "res", ")", "\n", "self", ".", "label_pred", "=", "conv_block", "(", "layer_dims", "[", "-", "2", "]", ",", "layer_dims", "[", "-", "1", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "relu", "=", "use_final_relu", ",", "batch_norm", "=", "final_bn", ")", "\n", "self", ".", "gauss_scale", "=", "gauss_scale", "\n", "if", "non_default_init", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                    ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "init_bn", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.label_encoder.ResidualDS16FeatSWBoxCatMultiBlock.bbox_to_mask": [[83, 93], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "list", "int", "int", "int", "int", "map"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "", "", "", "def", "bbox_to_mask", "(", "self", ",", "bbox", ",", "sz", ")", ":", "\n", "        ", "mask", "=", "torch", ".", "zeros", "(", "(", "bbox", ".", "shape", "[", "0", "]", ",", "1", ",", "*", "sz", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "bbox", ".", "device", ")", "\n", "for", "i", ",", "bb", "in", "enumerate", "(", "bbox", ")", ":", "\n", "            ", "x1", ",", "y1", ",", "w", ",", "h", "=", "list", "(", "map", "(", "int", ",", "bb", ")", ")", "\n", "x1", "=", "int", "(", "x1", "+", "0.5", ")", "\n", "y1", "=", "int", "(", "y1", "+", "0.5", ")", "\n", "h", "=", "int", "(", "h", "+", "0.5", ")", "\n", "w", "=", "int", "(", "w", "+", "0.5", ")", "\n", "mask", "[", "i", ",", ":", ",", "y1", ":", "(", "y1", "+", "h", ")", ",", "x1", ":", "(", "x1", "+", "w", ")", "]", "=", "1.0", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.label_encoder.ResidualDS16FeatSWBoxCatMultiBlock.bbox_to_gauss": [[94, 107], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "list", "torch.arange().unsqueeze().to().float", "torch.arange().unsqueeze().to().float", "torch.arange().unsqueeze().to().float", "torch.arange().unsqueeze().to().float", "torch.arange().unsqueeze().T.to().float", "torch.arange().unsqueeze().T.to().float", "torch.arange().unsqueeze().T.to().float", "torch.arange().unsqueeze().T.to().float", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "map", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().to", "torch.arange().unsqueeze().T.to", "torch.arange().unsqueeze().T.to", "torch.arange().unsqueeze().T.to", "torch.arange().unsqueeze().T.to", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "bbox_to_gauss", "(", "self", ",", "bbox", ",", "sz", ")", ":", "\n", "        ", "mask", "=", "torch", ".", "zeros", "(", "(", "bbox", ".", "shape", "[", "0", "]", ",", "1", ",", "*", "sz", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "bbox", ".", "device", ")", "\n", "x_max", ",", "y_max", "=", "sz", "[", "-", "1", "]", ",", "sz", "[", "-", "2", "]", "\n", "for", "i", ",", "bb", "in", "enumerate", "(", "bbox", ")", ":", "\n", "            ", "x1", ",", "y1", ",", "w", ",", "h", "=", "list", "(", "map", "(", "int", ",", "bb", ")", ")", "\n", "cx", ",", "cy", "=", "x1", "+", "w", "/", "2", ",", "y1", "+", "h", "/", "2", "\n", "xcoords", "=", "torch", ".", "arange", "(", "0", ",", "x_max", ")", ".", "unsqueeze", "(", "dim", "=", "0", ")", ".", "to", "(", "bbox", ".", "device", ")", ".", "float", "(", ")", "\n", "ycoords", "=", "torch", ".", "arange", "(", "0", ",", "y_max", ")", ".", "unsqueeze", "(", "dim", "=", "0", ")", ".", "T", ".", "to", "(", "bbox", ".", "device", ")", ".", "float", "(", ")", "\n", "d_xcoords", "=", "xcoords", "-", "cx", "\n", "d_ycoords", "=", "ycoords", "-", "cy", "\n", "dtotsqr", "=", "d_xcoords", "**", "2", "/", "(", "self", ".", "gauss_scale", "*", "w", ")", "**", "2", "+", "d_ycoords", "**", "2", "/", "(", "self", ".", "gauss_scale", "*", "h", ")", "**", "2", "\n", "mask", "[", "i", ",", "0", "]", "=", "torch", ".", "exp", "(", "-", "0.5", "*", "dtotsqr", ")", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.label_encoder.ResidualDS16FeatSWBoxCatMultiBlock.forward": [[108, 127], ["label_encoder.ResidualDS16FeatSWBoxCatMultiBlock.view", "feat.view.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "label_encoder.ResidualDS16FeatSWBoxCatMultiBlock.res", "label_encoder.ResidualDS16FeatSWBoxCatMultiBlock.label_pred", "label_enc.view.view.view", "label_encoder.ResidualDS16FeatSWBoxCatMultiBlock.bbox_to_gauss", "label_encoder.ResidualDS16FeatSWBoxCatMultiBlock.bbox_to_mask", "ltr.models.lwl.utils.interpolate"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.label_encoder.ResidualDS16FeatSWBoxCatMultiBlock.bbox_to_gauss", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.label_encoder.ResidualDS16FeatSWBoxCatMultiBlock.bbox_to_mask", "home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate"], ["", "def", "forward", "(", "self", ",", "bb", ",", "feat", ",", "sz", ")", ":", "\n", "\n", "        ", "if", "self", ".", "use_gauss", ":", "\n", "            ", "label_mask", "=", "self", ".", "bbox_to_gauss", "(", "bb", ",", "sz", "[", "-", "2", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "label_mask", "=", "self", ".", "bbox_to_mask", "(", "bb", ",", "sz", "[", "-", "2", ":", "]", ")", "\n", "\n", "", "label_shape", "=", "label_mask", ".", "shape", "\n", "label_mask", "=", "label_mask", ".", "view", "(", "-", "1", ",", "1", ",", "*", "label_mask", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "\n", "feat", "=", "feat", ".", "view", "(", "-", "1", ",", "*", "feat", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "feat_mask_enc", "=", "torch", ".", "cat", "(", "[", "feat", ",", "interpolate", "(", "label_mask", ",", "feat", ".", "shape", "[", "-", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "out", "=", "self", ".", "res", "(", "feat_mask_enc", ")", "\n", "\n", "label_enc", "=", "self", ".", "label_pred", "(", "out", ")", "\n", "\n", "label_enc", "=", "label_enc", ".", "view", "(", "label_shape", "[", "0", "]", ",", "label_shape", "[", "1", "]", ",", "*", "label_enc", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "return", "label_enc", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.__init__": [[19, 33], ["torch.Module.__init__", "sorted", "isinstance", "list", "set"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["    ", "def", "__init__", "(", "self", ",", "feature_extractor", ",", "target_model", ",", "decoder", ",", "target_model_input_layer", ",", "decoder_input_layers", ",", "\n", "label_encoder", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "feature_extractor", "=", "feature_extractor", "# Backbone feature extractor F", "\n", "self", ".", "target_model", "=", "target_model", "# Target model and the few-shot learner", "\n", "self", ".", "decoder", "=", "decoder", "# Segmentation Decoder", "\n", "\n", "self", ".", "label_encoder", "=", "label_encoder", "# Few-shot label generator and weight predictor", "\n", "\n", "self", ".", "target_model_input_layer", "=", "(", "target_model_input_layer", ",", ")", "if", "isinstance", "(", "target_model_input_layer", ",", "\n", "str", ")", "else", "target_model_input_layer", "\n", "self", ".", "decoder_input_layers", "=", "decoder_input_layers", "\n", "self", ".", "output_layers", "=", "sorted", "(", "list", "(", "set", "(", "self", ".", "target_model_input_layer", "+", "self", ".", "decoder_input_layers", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.forward": [[34, 117], ["lwl_net.LWTLNet.extract_backbone_features", "lwl_net.LWTLNet.extract_backbone_features", "lwl_net.LWTLNet.extract_target_model_features", "train_feat_tm.view.view.view", "lwl_net.LWTLNet.label_encoder", "lwl_net.LWTLNet.extract_target_model_features", "lwl_net.LWTLNet.target_model.get_filter", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train_imgs.view", "test_imgs.view", "lwl_net.LWTLNet.decoder", "mask_pred.view.view.view", "torch.cat.append", "torch.cat.append", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "lwl_net.LWTLNet.label_encoder", "few_shot_label_all.append", "train_feat_tm_all.append", "lwl_net.LWTLNet.view", "lwl_net.LWTLNet.target_model.apply_target_model", "mask_pred.view.view.clone().detach", "few_shot_sw_all.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "lwl_net.LWTLNet.target_model.filter_optimizer", "v.view", "lwl_net.LWTLNet.items", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytracking.TensorList", "mask_pred.view.view.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.extract_target_model_features", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.extract_target_model_features", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.get_filter", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.linear_filter.LinearFilter.apply_target_model"], ["", "def", "forward", "(", "self", ",", "train_imgs", ",", "test_imgs", ",", "train_masks", ",", "test_masks", ",", "num_refinement_iter", "=", "2", ")", ":", "\n", "        ", "num_sequences", "=", "train_imgs", ".", "shape", "[", "1", "]", "\n", "num_train_frames", "=", "train_imgs", ".", "shape", "[", "0", "]", "\n", "num_test_frames", "=", "test_imgs", ".", "shape", "[", "0", "]", "\n", "\n", "# Extract backbone features", "\n", "train_feat_backbone", "=", "self", ".", "extract_backbone_features", "(", "\n", "train_imgs", ".", "view", "(", "-", "1", ",", "train_imgs", ".", "shape", "[", "-", "3", "]", ",", "train_imgs", ".", "shape", "[", "-", "2", "]", ",", "train_imgs", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "test_feat_backbone", "=", "self", ".", "extract_backbone_features", "(", "\n", "test_imgs", ".", "view", "(", "-", "1", ",", "test_imgs", ".", "shape", "[", "-", "3", "]", ",", "test_imgs", ".", "shape", "[", "-", "2", "]", ",", "test_imgs", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "\n", "# Extract features input to the target model", "\n", "train_feat_tm", "=", "self", ".", "extract_target_model_features", "(", "train_feat_backbone", ")", "# seq*frames, channels, height, width", "\n", "train_feat_tm", "=", "train_feat_tm", ".", "view", "(", "num_train_frames", ",", "num_sequences", ",", "*", "train_feat_tm", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "train_feat_tm_all", "=", "[", "train_feat_tm", ",", "]", "\n", "\n", "# Get few-shot learner label and spatial importance weights", "\n", "few_shot_label", ",", "few_shot_sw", "=", "self", ".", "label_encoder", "(", "train_masks", ",", "train_feat_tm", ")", "\n", "\n", "few_shot_label_all", "=", "[", "few_shot_label", ",", "]", "\n", "few_shot_sw_all", "=", "None", "if", "few_shot_sw", "is", "None", "else", "[", "few_shot_sw", ",", "]", "\n", "\n", "test_feat_tm", "=", "self", ".", "extract_target_model_features", "(", "test_feat_backbone", ")", "# seq*frames, channels, height, width", "\n", "\n", "# Obtain the target module parameters using the few-shot learner", "\n", "filter", ",", "filter_iter", ",", "_", "=", "self", ".", "target_model", ".", "get_filter", "(", "train_feat_tm", ",", "few_shot_label", ",", "few_shot_sw", ")", "\n", "\n", "mask_predictons_all", "=", "[", "]", "\n", "\n", "# Iterate over the test sequence", "\n", "for", "i", "in", "range", "(", "num_test_frames", ")", ":", "\n", "# Features for the current frame", "\n", "            ", "test_feat_tm_it", "=", "test_feat_tm", ".", "view", "(", "num_test_frames", ",", "num_sequences", ",", "*", "test_feat_tm", ".", "shape", "[", "-", "3", ":", "]", ")", "[", "i", ":", "i", "+", "1", ",", "...", "]", "\n", "\n", "# Apply the target model to obtain mask encodings.", "\n", "mask_encoding_pred", "=", "[", "self", ".", "target_model", ".", "apply_target_model", "(", "f", ",", "test_feat_tm_it", ")", "for", "f", "in", "filter_iter", "]", "\n", "\n", "test_feat_backbone_it", "=", "{", "k", ":", "v", ".", "view", "(", "num_test_frames", ",", "num_sequences", ",", "*", "v", ".", "shape", "[", "-", "3", ":", "]", ")", "[", "i", ",", "...", "]", "for", "k", ",", "v", "in", "\n", "test_feat_backbone", ".", "items", "(", ")", "}", "\n", "mask_encoding_pred_last_iter", "=", "mask_encoding_pred", "[", "-", "1", "]", "\n", "\n", "# Run decoder to obtain the segmentation mask", "\n", "mask_pred", ",", "decoder_feat", "=", "self", ".", "decoder", "(", "mask_encoding_pred_last_iter", ",", "test_feat_backbone_it", ",", "\n", "test_imgs", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "mask_pred", "=", "mask_pred", ".", "view", "(", "1", ",", "num_sequences", ",", "*", "mask_pred", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "\n", "mask_predictons_all", ".", "append", "(", "mask_pred", ")", "\n", "\n", "# Convert the segmentation scores to probability", "\n", "mask_pred_prob", "=", "torch", ".", "sigmoid", "(", "mask_pred", ".", "clone", "(", ")", ".", "detach", "(", ")", ")", "\n", "\n", "# Obtain label encoding for the predicted mask in the previous frame", "\n", "few_shot_label", ",", "few_shot_sw", "=", "self", ".", "label_encoder", "(", "mask_pred_prob", ",", "test_feat_tm_it", ")", "\n", "\n", "# Extend the training data using the predicted mask", "\n", "few_shot_label_all", ".", "append", "(", "few_shot_label", ")", "\n", "if", "few_shot_sw_all", "is", "not", "None", ":", "\n", "                ", "few_shot_sw_all", ".", "append", "(", "few_shot_sw", ")", "\n", "\n", "", "train_feat_tm_all", ".", "append", "(", "test_feat_tm_it", ")", "\n", "\n", "# Update the target model using the extended training set", "\n", "if", "(", "i", "<", "(", "num_test_frames", "-", "1", ")", ")", "and", "(", "num_refinement_iter", ">", "0", ")", ":", "\n", "                ", "train_feat_tm_it", "=", "torch", ".", "cat", "(", "train_feat_tm_all", ",", "dim", "=", "0", ")", "\n", "few_shot_label_it", "=", "torch", ".", "cat", "(", "few_shot_label_all", ",", "dim", "=", "0", ")", "\n", "\n", "if", "few_shot_sw_all", "is", "not", "None", ":", "\n", "                    ", "few_shot_sw_it", "=", "torch", ".", "cat", "(", "few_shot_sw_all", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                    ", "few_shot_sw_it", "=", "None", "\n", "\n", "# Run few-shot learner to update the target model", "\n", "", "filter_updated", ",", "_", ",", "_", "=", "self", ".", "target_model", ".", "filter_optimizer", "(", "TensorList", "(", "[", "filter", "]", ")", ",", "\n", "feat", "=", "train_feat_tm_it", ",", "\n", "label", "=", "few_shot_label_it", ",", "\n", "sample_weight", "=", "few_shot_sw_it", ",", "\n", "num_iter", "=", "num_refinement_iter", ")", "\n", "\n", "filter", "=", "filter_updated", "[", "0", "]", "# filter_updated is a TensorList", "\n", "\n", "", "", "mask_predictons_all", "=", "torch", ".", "cat", "(", "mask_predictons_all", ",", "dim", "=", "0", ")", "\n", "return", "mask_predictons_all", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.segment_target": [[118, 129], ["test_feat_tm.view.view.view", "lwl_net.LWTLNet.target_model.apply_target_model", "lwl_net.LWTLNet.decoder", "target_filter.dim"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.linear_filter.LinearFilter.apply_target_model", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "segment_target", "(", "self", ",", "target_filter", ",", "test_feat_tm", ",", "test_feat", ")", ":", "\n", "# Classification features", "\n", "        ", "assert", "target_filter", ".", "dim", "(", ")", "==", "5", "# seq, filters, ch, h, w", "\n", "test_feat_tm", "=", "test_feat_tm", ".", "view", "(", "1", ",", "1", ",", "*", "test_feat_tm", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "mask_encoding_pred", "=", "self", ".", "target_model", ".", "apply_target_model", "(", "target_filter", ",", "test_feat_tm", ")", "\n", "\n", "mask_pred", ",", "decoder_feat", "=", "self", ".", "decoder", "(", "mask_encoding_pred", ",", "test_feat", ",", "\n", "(", "test_feat_tm", ".", "shape", "[", "-", "2", "]", "*", "16", ",", "test_feat_tm", ".", "shape", "[", "-", "1", "]", "*", "16", ")", ")", "\n", "\n", "return", "mask_pred", ",", "mask_encoding_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.get_backbone_target_model_features": [[130, 136], ["collections.OrderedDict", "len"], "methods", ["None"], ["", "def", "get_backbone_target_model_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "# Get the backbone feature block which is input to the target model", "\n", "        ", "feat", "=", "OrderedDict", "(", "{", "l", ":", "backbone_feat", "[", "l", "]", "for", "l", "in", "self", ".", "target_model_input_layer", "}", ")", "\n", "if", "len", "(", "self", ".", "target_model_input_layer", ")", "==", "1", ":", "\n", "            ", "return", "feat", "[", "self", ".", "target_model_input_layer", "[", "0", "]", "]", "\n", "", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.extract_target_model_features": [[137, 139], ["lwl_net.LWTLNet.target_model.extract_target_model_features", "lwl_net.LWTLNet.get_backbone_target_model_features"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.extract_target_model_features", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.get_backbone_target_model_features"], ["", "def", "extract_target_model_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "return", "self", ".", "target_model", ".", "extract_target_model_features", "(", "self", ".", "get_backbone_target_model_features", "(", "backbone_feat", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.extract_backbone_features": [[140, 144], ["lwl_net.LWTLNet.feature_extractor"], "methods", ["None"], ["", "def", "extract_backbone_features", "(", "self", ",", "im", ",", "layers", "=", "None", ")", ":", "\n", "        ", "if", "layers", "is", "None", ":", "\n", "            ", "layers", "=", "self", ".", "output_layers", "\n", "", "return", "self", ".", "feature_extractor", "(", "im", ",", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.steepest_descent_resnet50": [[146, 210], ["float", "math.sqrt", "mrcnn_backbones.resnet50.out_feature_channels", "ltr.residual_basic_block", "ltr.ResidualDS16SW", "ltr.FilterInitializerZero", "ltr.LWTLResidual", "ltr.GNSteepestDescent", "ltr.LinearFilter", "ltr.LWTLDecoder", "lwl_net.LWTLNet", "ltr.resnet50", "ltr.resnet50"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet.out_feature_channels", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_basic_block", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet50", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet50"], ["", "", "@", "model_constructor", "\n", "def", "steepest_descent_resnet50", "(", "filter_size", "=", "1", ",", "num_filters", "=", "1", ",", "optim_iter", "=", "3", ",", "optim_init_reg", "=", "0.01", ",", "\n", "backbone_pretrained", "=", "False", ",", "clf_feat_blocks", "=", "1", ",", "\n", "clf_feat_norm", "=", "True", ",", "final_conv", "=", "False", ",", "\n", "out_feature_dim", "=", "512", ",", "\n", "target_model_input_layer", "=", "'layer3'", ",", "\n", "decoder_input_layers", "=", "(", "\"layer4\"", ",", "\"layer3\"", ",", "\"layer2\"", ",", "\"layer1\"", ",", ")", ",", "\n", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "\n", "label_encoder_dims", "=", "(", "1", ",", "1", ")", ",", "\n", "frozen_backbone_layers", "=", "(", ")", ",", "\n", "decoder_mdim", "=", "64", ",", "filter_groups", "=", "1", ",", "\n", "use_bn_in_label_enc", "=", "True", ",", "\n", "dilation_factors", "=", "None", ",", "\n", "backbone_type", "=", "'imagenet'", ")", ":", "\n", "# backbone feature extractor F", "\n", "    ", "if", "backbone_type", "==", "'imagenet'", ":", "\n", "        ", "backbone_net", "=", "backbones", ".", "resnet50", "(", "pretrained", "=", "backbone_pretrained", ",", "frozen_layers", "=", "frozen_backbone_layers", ")", "\n", "", "elif", "backbone_type", "==", "'mrcnn'", ":", "\n", "        ", "backbone_net", "=", "mrcnn_backbones", ".", "resnet50", "(", "pretrained", "=", "False", ",", "frozen_layers", "=", "frozen_backbone_layers", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "\n", "\n", "", "norm_scale", "=", "math", ".", "sqrt", "(", "1.0", "/", "(", "out_feature_dim", "*", "filter_size", "*", "filter_size", ")", ")", "\n", "\n", "layer_channels", "=", "backbone_net", ".", "out_feature_channels", "(", ")", "\n", "\n", "# Extracts features input to the target model", "\n", "target_model_feature_extractor", "=", "clf_features", ".", "residual_basic_block", "(", "\n", "feature_dim", "=", "layer_channels", "[", "target_model_input_layer", "]", ",", "\n", "num_blocks", "=", "clf_feat_blocks", ",", "l2norm", "=", "clf_feat_norm", ",", "\n", "final_conv", "=", "final_conv", ",", "norm_scale", "=", "norm_scale", ",", "\n", "out_dim", "=", "out_feature_dim", ")", "\n", "\n", "# Few-shot label generator and weight predictor", "\n", "label_encoder", "=", "seg_label_encoder", ".", "ResidualDS16SW", "(", "layer_dims", "=", "label_encoder_dims", "+", "(", "num_filters", ",", ")", ",", "\n", "use_bn", "=", "use_bn_in_label_enc", ")", "\n", "\n", "# Predicts initial target model parameters", "\n", "initializer", "=", "seg_initializer", ".", "FilterInitializerZero", "(", "filter_size", "=", "filter_size", ",", "num_filters", "=", "num_filters", ",", "\n", "feature_dim", "=", "out_feature_dim", ",", "filter_groups", "=", "filter_groups", ")", "\n", "\n", "# Computes few-shot learning loss", "\n", "residual_module", "=", "loss_residual_modules", ".", "LWTLResidual", "(", "init_filter_reg", "=", "optim_init_reg", ",", "\n", "filter_dilation_factors", "=", "dilation_factors", ")", "\n", "\n", "# Iteratively updates the target model parameters by minimizing the few-shot learning loss", "\n", "optimizer", "=", "steepestdescent", ".", "GNSteepestDescent", "(", "residual_module", "=", "residual_module", ",", "num_iter", "=", "optim_iter", ",", "\n", "detach_length", "=", "detach_length", ",", "\n", "residual_batch_dim", "=", "1", ",", "compute_losses", "=", "True", ")", "\n", "\n", "# Target model and Few-shot learner", "\n", "target_model", "=", "target_clf", ".", "LinearFilter", "(", "filter_size", "=", "filter_size", ",", "filter_initializer", "=", "initializer", ",", "\n", "filter_optimizer", "=", "optimizer", ",", "feature_extractor", "=", "target_model_feature_extractor", ",", "\n", "filter_dilation_factors", "=", "dilation_factors", ")", "\n", "\n", "# Decoder", "\n", "decoder_input_layers_channels", "=", "{", "L", ":", "layer_channels", "[", "L", "]", "for", "L", "in", "decoder_input_layers", "}", "\n", "\n", "decoder", "=", "lwtl_decoder", ".", "LWTLDecoder", "(", "num_filters", ",", "decoder_mdim", ",", "decoder_input_layers_channels", ",", "use_bn", "=", "True", ")", "\n", "\n", "net", "=", "LWTLNet", "(", "feature_extractor", "=", "backbone_net", ",", "target_model", "=", "target_model", ",", "decoder", "=", "decoder", ",", "\n", "label_encoder", "=", "label_encoder", ",", "\n", "target_model_input_layer", "=", "target_model_input_layer", ",", "decoder_input_layers", "=", "decoder_input_layers", ")", "\n", "return", "net", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.initializer.FilterInitializerZero.__init__": [[10, 14], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "filter_size", "=", "1", ",", "num_filters", "=", "1", ",", "feature_dim", "=", "256", ",", "filter_groups", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "filter_size", "=", "(", "num_filters", ",", "feature_dim", "//", "filter_groups", ",", "filter_size", ",", "filter_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.initializer.FilterInitializerZero.forward": [[15, 21], ["feat.new_zeros", "feat.dim"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "forward", "(", "self", ",", "feat", ",", "mask", "=", "None", ")", ":", "\n", "        ", "assert", "feat", ".", "dim", "(", ")", "==", "5", "\n", "# num_sequences = feat.shape[1] if feat.dim() == 5 else 1", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "\n", "\n", "return", "feat", ".", "new_zeros", "(", "num_sequences", ",", "*", "self", ".", "filter_size", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.TSE.__init__": [[18, 26], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "decoder.conv", "decoder.relu", "decoder.conv", "decoder.conv", "decoder.relu", "decoder.conv", "decoder.relu", "decoder.conv", "decoder.relu"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu"], ["    ", "def", "__init__", "(", "self", ",", "fc", ",", "ic", ",", "oc", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "reduce", "=", "nn", ".", "Sequential", "(", "conv", "(", "fc", ",", "oc", ",", "1", ")", ",", "relu", "(", ")", ",", "conv", "(", "oc", ",", "oc", ",", "1", ")", ")", "# Reduce number of feature dimensions", "\n", "nc", "=", "ic", "+", "oc", "\n", "self", ".", "transform", "=", "nn", ".", "Sequential", "(", "conv", "(", "nc", ",", "nc", ",", "3", ")", ",", "relu", "(", ")", ",", "\n", "conv", "(", "nc", ",", "nc", ",", "3", ")", ",", "relu", "(", ")", ",", "\n", "conv", "(", "nc", ",", "oc", ",", "3", ")", ",", "relu", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.TSE.forward": [[27, 33], ["decoder.TSE.reduce", "ltr.models.lwl.utils.adaptive_cat", "decoder.TSE.transform", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.utils.adaptive_cat", "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomBlur.transform"], ["", "def", "forward", "(", "self", ",", "ft", ",", "score", ",", "x", "=", "None", ")", ":", "\n", "        ", "h", "=", "self", ".", "reduce", "(", "ft", ")", "\n", "hpool", "=", "F", ".", "adaptive_avg_pool2d", "(", "h", ",", "(", "1", ",", "1", ")", ")", "if", "x", "is", "None", "else", "x", "\n", "h", "=", "adaptive_cat", "(", "(", "h", ",", "score", ")", ",", "dim", "=", "1", ",", "ref_tensor", "=", "0", ")", "\n", "h", "=", "self", ".", "transform", "(", "h", ")", "\n", "return", "h", ",", "hpool", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.CAB.__init__": [[36, 41], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "decoder.conv", "decoder.relu", "decoder.conv"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv"], ["    ", "def", "__init__", "(", "self", ",", "oc", ",", "deepest", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "convreluconv", "=", "nn", ".", "Sequential", "(", "conv", "(", "2", "*", "oc", ",", "oc", ",", "1", ")", ",", "relu", "(", ")", ",", "conv", "(", "oc", ",", "oc", ",", "1", ")", ")", "\n", "self", ".", "deepest", "=", "deepest", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.CAB.forward": [[42, 55], ["torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "decoder.CAB.convreluconv", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "ltr.models.lwl.utils.interpolate"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate"], ["", "def", "forward", "(", "self", ",", "deeper", ",", "shallower", ",", "att_vec", "=", "None", ")", ":", "\n", "\n", "        ", "shallow_pool", "=", "F", ".", "adaptive_avg_pool2d", "(", "shallower", ",", "(", "1", ",", "1", ")", ")", "\n", "deeper_pool", "=", "deeper", "if", "self", ".", "deepest", "else", "F", ".", "adaptive_avg_pool2d", "(", "deeper", ",", "(", "1", ",", "1", ")", ")", "\n", "if", "att_vec", "is", "not", "None", ":", "\n", "            ", "global_pool", "=", "torch", ".", "cat", "(", "[", "shallow_pool", ",", "deeper_pool", ",", "att_vec", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "global_pool", "=", "torch", ".", "cat", "(", "(", "shallow_pool", ",", "deeper_pool", ")", ",", "dim", "=", "1", ")", "\n", "", "conv_1x1", "=", "self", ".", "convreluconv", "(", "global_pool", ")", "\n", "inputs", "=", "shallower", "*", "torch", ".", "sigmoid", "(", "conv_1x1", ")", "\n", "out", "=", "inputs", "+", "interpolate", "(", "deeper", ",", "inputs", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.RRB.__init__": [[58, 66], ["torch.Module.__init__", "decoder.conv", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "decoder.conv", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "decoder.relu", "decoder.conv", "decoder.conv", "decoder.relu", "decoder.conv"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv"], ["    ", "def", "__init__", "(", "self", ",", "oc", ",", "use_bn", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1x1", "=", "conv", "(", "oc", ",", "oc", ",", "1", ")", "\n", "if", "use_bn", ":", "\n", "            ", "self", ".", "bblock", "=", "nn", ".", "Sequential", "(", "conv", "(", "oc", ",", "oc", ",", "3", ")", ",", "nn", ".", "BatchNorm2d", "(", "oc", ")", ",", "relu", "(", ")", ",", "conv", "(", "oc", ",", "oc", ",", "3", ",", "bias", "=", "False", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bblock", "=", "nn", ".", "Sequential", "(", "conv", "(", "oc", ",", "oc", ",", "3", ")", ",", "relu", "(", ")", ",", "conv", "(", "oc", ",", "oc", ",", "3", ",", "bias", "=", "False", ")", ")", "# Basic block", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.RRB.forward": [[67, 70], ["decoder.RRB.conv1x1", "torch.relu", "torch.relu", "torch.relu", "decoder.RRB.bblock"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv1x1", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "conv1x1", "(", "x", ")", "\n", "return", "F", ".", "relu", "(", "h", "+", "self", ".", "bblock", "(", "h", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.Upsampler.__init__": [[73, 78], ["torch.Module.__init__", "decoder.conv", "decoder.conv"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", "=", "64", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv1", "=", "conv", "(", "in_channels", ",", "in_channels", "//", "2", ",", "3", ")", "\n", "self", ".", "conv2", "=", "conv", "(", "in_channels", "//", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.Upsampler.forward": [[79, 85], ["torch.interpolate", "torch.interpolate", "torch.interpolate", "torch.relu", "torch.relu", "torch.relu", "torch.interpolate", "torch.interpolate", "torch.interpolate", "decoder.Upsampler.conv2", "decoder.Upsampler.conv1"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate", "home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate", "home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate", "home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate", "home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate"], ["", "def", "forward", "(", "self", ",", "x", ",", "image_size", ")", ":", "\n", "        ", "x", "=", "F", ".", "interpolate", "(", "x", ",", "(", "2", "*", "x", ".", "shape", "[", "-", "2", "]", ",", "2", "*", "x", ".", "shape", "[", "-", "1", "]", ")", ",", "mode", "=", "'bicubic'", ",", "align_corners", "=", "False", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "interpolate", "(", "x", ",", "image_size", "[", "-", "2", ":", "]", ",", "mode", "=", "'bicubic'", ",", "align_corners", "=", "False", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.LWTLDecoder.__init__": [[89, 126], ["torch.Module.__init__", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "decoder.LWTLDecoder.ft_channels.items", "decoder.Upsampler", "ft_channels.keys", "decoder.TSE", "decoder.RRB", "decoder.CAB", "decoder.RRB", "torch.Sequential", "torch.Sequential", "torch.Sequential", "decoder.conv", "decoder.relu"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu"], ["def", "__init__", "(", "self", ",", "in_channels", "=", "1", ",", "out_channels", "=", "32", ",", "ft_channels", "=", "None", ",", "use_bn", "=", "False", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "ft_channels", "is", "not", "None", "\n", "self", ".", "ft_channels", "=", "ft_channels", "\n", "\n", "self", ".", "TSE", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "RRB1", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "CAB", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "RRB2", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "proj", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "\n", "ic", "=", "in_channels", "\n", "\n", "oc", "=", "{", "'layer1'", ":", "1", ",", "'layer2'", ":", "2", ",", "'layer3'", ":", "2", ",", "'layer4'", ":", "4", "}", "\n", "out_feature_channels", "=", "{", "}", "\n", "\n", "if", "'layer4'", "in", "ft_channels", ".", "keys", "(", ")", ":", "\n", "            ", "last_layer", "=", "'layer4'", "\n", "", "else", ":", "\n", "            ", "last_layer", "=", "'layer3'", "\n", "\n", "", "prev_layer", "=", "None", "\n", "for", "L", ",", "fc", "in", "self", ".", "ft_channels", ".", "items", "(", ")", ":", "\n", "            ", "if", "not", "L", "==", "last_layer", ":", "\n", "                ", "self", ".", "proj", "[", "L", "]", "=", "nn", ".", "Sequential", "(", "conv", "(", "oc", "[", "prev_layer", "]", "*", "out_channels", ",", "oc", "[", "L", "]", "*", "out_channels", ",", "1", ")", ",", "relu", "(", ")", ")", "\n", "\n", "", "self", ".", "TSE", "[", "L", "]", "=", "TSE", "(", "fc", ",", "ic", ",", "oc", "[", "L", "]", "*", "out_channels", ")", "\n", "self", ".", "RRB1", "[", "L", "]", "=", "RRB", "(", "oc", "[", "L", "]", "*", "out_channels", ",", "use_bn", "=", "use_bn", ")", "\n", "self", ".", "CAB", "[", "L", "]", "=", "CAB", "(", "oc", "[", "L", "]", "*", "out_channels", ",", "L", "==", "last_layer", ")", "\n", "self", ".", "RRB2", "[", "L", "]", "=", "RRB", "(", "oc", "[", "L", "]", "*", "out_channels", ",", "use_bn", "=", "use_bn", ")", "\n", "out_feature_channels", "[", "'{}_dec'", ".", "format", "(", "L", ")", "]", "=", "oc", "[", "L", "]", "*", "out_channels", "\n", "prev_layer", "=", "L", "\n", "\n", "", "self", ".", "project", "=", "Upsampler", "(", "out_channels", ")", "\n", "self", ".", "_out_feature_channels", "=", "out_feature_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.LWTLDecoder.out_feature_channels": [[127, 129], ["None"], "methods", ["None"], ["", "def", "out_feature_channels", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_out_feature_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.LWTLDecoder.forward": [[130, 161], ["collections.OrderedDict", "scores.view.view.view", "enumerate", "decoder.LWTLDecoder.project", "ltr.models.lwl.utils.interpolate", "scores.view.view.dim", "scores.view.view.dim", "ft.view().repeat().view", "ft.view().repeat", "ft.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "forward", "(", "self", ",", "scores", ",", "features", ",", "image_size", ",", "output_layers", "=", "(", ")", ",", "num_objects", "=", "None", ")", ":", "\n", "        ", "if", "num_objects", "is", "None", ":", "\n", "            ", "assert", "scores", ".", "dim", "(", ")", "==", "5", "# frames, seq, ch, h, w", "\n", "", "else", ":", "\n", "            ", "assert", "scores", ".", "dim", "(", ")", "==", "6", "# frames, seq, obj, ch, h, w", "\n", "", "outputs", "=", "OrderedDict", "(", ")", "\n", "\n", "scores", "=", "scores", ".", "view", "(", "-", "1", ",", "*", "scores", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "x", "=", "None", "\n", "for", "i", ",", "L", "in", "enumerate", "(", "self", ".", "ft_channels", ")", ":", "\n", "            ", "ft", "=", "features", "[", "L", "]", "\n", "\n", "s", "=", "interpolate", "(", "scores", ",", "ft", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "if", "not", "x", "is", "None", ":", "\n", "                ", "x", "=", "self", ".", "proj", "[", "L", "]", "(", "x", ")", "\n", "\n", "", "if", "num_objects", "is", "not", "None", ":", "\n", "                ", "h", ",", "hpool", "=", "self", ".", "TSE", "[", "L", "]", "(", "ft", ".", "view", "(", "ft", ".", "shape", "[", "0", "]", ",", "1", ",", "*", "ft", ".", "shape", "[", "-", "3", ":", "]", ")", ".", "repeat", "(", "1", ",", "num_objects", ",", "1", ",", "1", ",", "1", ")", ".", "view", "(", "-", "1", ",", "*", "ft", ".", "shape", "[", "-", "3", ":", "]", ")", ",", "s", ",", "x", ")", "\n", "", "else", ":", "\n", "                ", "h", ",", "hpool", "=", "self", ".", "TSE", "[", "L", "]", "(", "ft", ",", "s", ",", "x", ")", "\n", "\n", "", "h", "=", "self", ".", "RRB1", "[", "L", "]", "(", "h", ")", "\n", "h", "=", "self", ".", "CAB", "[", "L", "]", "(", "hpool", ",", "h", ")", "\n", "x", "=", "self", ".", "RRB2", "[", "L", "]", "(", "h", ")", "\n", "\n", "if", "'{}_dec'", ".", "format", "(", "L", ")", "in", "output_layers", ":", "\n", "                ", "outputs", "[", "'{}_dec'", ".", "format", "(", "L", ")", "]", "=", "x", "\n", "\n", "", "", "x", "=", "self", ".", "project", "(", "x", ",", "image_size", ")", "\n", "return", "x", ",", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.conv": [[9, 11], ["torch.Conv2d"], "function", ["None"], ["def", "conv", "(", "ic", ",", "oc", ",", "ksize", ",", "bias", "=", "True", ",", "dilation", "=", "1", ",", "stride", "=", "1", ")", ":", "\n", "    ", "return", "nn", ".", "Conv2d", "(", "ic", ",", "oc", ",", "ksize", ",", "padding", "=", "ksize", "//", "2", ",", "bias", "=", "bias", ",", "dilation", "=", "dilation", ",", "stride", "=", "stride", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu": [[13, 15], ["torch.LeakyReLU"], "function", ["None"], ["", "def", "relu", "(", "negative_slope", "=", "0.0", ",", "inplace", "=", "False", ")", ":", "\n", "    ", "return", "nn", ".", "LeakyReLU", "(", "negative_slope", ",", "inplace", "=", "inplace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.utils.adaptive_cat": [[5, 9], ["torch.cat", "torch.cat", "utils.interpolate"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate"], ["def", "adaptive_cat", "(", "seq", ",", "dim", "=", "0", ",", "ref_tensor", "=", "0", ",", "mode", "=", "'bilinear'", ")", ":", "\n", "    ", "sz", "=", "seq", "[", "ref_tensor", "]", ".", "shape", "[", "-", "2", ":", "]", "\n", "t", "=", "torch", ".", "cat", "(", "[", "interpolate", "(", "t", ",", "sz", ",", "mode", "=", "mode", ")", "for", "t", "in", "seq", "]", ",", "dim", "=", "dim", ")", "\n", "return", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.lwl.utils.interpolate": [[11, 15], ["torch.is_tensor", "torch.is_tensor", "sz.tolist", "dict", "torch.interpolate"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate"], ["", "def", "interpolate", "(", "t", ",", "sz", ",", "mode", "=", "'bilinear'", ")", ":", "\n", "    ", "sz", "=", "sz", ".", "tolist", "(", ")", "if", "torch", ".", "is_tensor", "(", "sz", ")", "else", "sz", "\n", "align", "=", "{", "}", "if", "mode", "==", "'nearest'", "else", "dict", "(", "align_corners", "=", "False", ")", "\n", "return", "F", ".", "interpolate", "(", "t", ",", "sz", ",", "mode", "=", "mode", ",", "**", "align", ")", "if", "t", ".", "shape", "[", "-", "2", ":", "]", "!=", "sz", "else", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.super_dimp_simple.parameters": [[4, 73], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "22", "*", "16", "\n", "params", ".", "search_area_scale", "=", "6", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "1.5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "2.5e-3", "# 1   # Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'super_dimp_simple.pth.tar'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "params", ".", "use_gt_box", "=", "True", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.initialize_features": [[20, 24], ["getattr", "dimp_simple.DiMPSimple.params.net.initialize"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["def", "initialize_features", "(", "self", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "self", ",", "'features_initialized'", ",", "False", ")", ":", "\n", "            ", "self", ".", "params", ".", "net", ".", "initialize", "(", ")", "\n", "", "self", ".", "features_initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.initialize": [[25, 92], ["dimp_simple.DiMPSimple.initialize_features", "time.time", "pytracking.features.preprocessing.numpy_to_torch", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "dimp_simple.DiMPSimple.params.get", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.max", "torch.max", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min", "dimp_simple.DiMPSimple.generate_init_samples", "dimp_simple.DiMPSimple.init_classifier", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.params.has", "info.get", "dimp_simple.DiMPSimple.params.get", "math.sqrt", "dimp_simple.DiMPSimple.img_sample_sz.prod().sqrt", "dimp_simple.DiMPSimple.params.has", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "isinstance", "dimp_simple.DiMPSimple.init_iou_net", "isinstance", "dimp_simple.DiMPSimple.image_sz.prod().sqrt", "torch.round", "torch.round", "torch.round", "torch.round", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "time.time", "torch.Tensor.prod().sqrt", "torch.Tensor.prod().sqrt", "dimp_simple.DiMPSimple.img_sample_sz.prod", "dimp_simple.DiMPSimple.image_sz.prod", "torch.Tensor.prod", "torch.Tensor.prod"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.generate_init_samples", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_classifier", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_iou_net"], ["", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "# Initialize some stuff", "\n", "        ", "self", ".", "frame_num", "=", "1", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'device'", ")", ":", "\n", "            ", "self", ".", "params", ".", "device", "=", "'cuda'", "if", "self", ".", "params", ".", "use_gpu", "else", "'cpu'", "\n", "\n", "# Initialize network", "\n", "", "self", ".", "initialize_features", "(", ")", "\n", "\n", "# The DiMP network", "\n", "self", ".", "net", "=", "self", ".", "params", ".", "net", "\n", "\n", "# Time initialization", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# Get target position and size", "\n", "state", "=", "info", "[", "'init_bbox'", "]", "\n", "self", ".", "pos", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "1", "]", "+", "(", "state", "[", "3", "]", "-", "1", ")", "/", "2", ",", "state", "[", "0", "]", "+", "(", "state", "[", "2", "]", "-", "1", ")", "/", "2", "]", ")", "\n", "self", ".", "target_sz", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "3", "]", ",", "state", "[", "2", "]", "]", ")", "\n", "\n", "# Get object id", "\n", "self", ".", "object_id", "=", "info", ".", "get", "(", "'object_ids'", ",", "[", "None", "]", ")", "[", "0", "]", "\n", "self", ".", "id_str", "=", "''", "if", "self", ".", "object_id", "is", "None", "else", "' {}'", ".", "format", "(", "self", ".", "object_id", ")", "\n", "\n", "# Set sizes", "\n", "self", ".", "image_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "sz", "=", "self", ".", "params", ".", "image_sample_size", "\n", "sz", "=", "torch", ".", "Tensor", "(", "[", "sz", ",", "sz", "]", "if", "isinstance", "(", "sz", ",", "int", ")", "else", "sz", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_image_aspect_ratio'", ",", "False", ")", ":", "\n", "            ", "sz", "=", "self", ".", "image_sz", "*", "sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "/", "self", ".", "image_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "stride", "=", "self", ".", "params", ".", "get", "(", "'feature_stride'", ",", "32", ")", "\n", "sz", "=", "torch", ".", "round", "(", "sz", "/", "stride", ")", "*", "stride", "\n", "", "self", ".", "img_sample_sz", "=", "sz", "\n", "self", ".", "img_support_sz", "=", "self", ".", "img_sample_sz", "\n", "\n", "# Set search area", "\n", "search_area", "=", "torch", ".", "prod", "(", "self", ".", "target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ".", "item", "(", ")", "\n", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", ")", "/", "self", ".", "img_sample_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "\n", "# Target size in base scale", "\n", "self", ".", "base_target_sz", "=", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "\n", "# Setup scale factors", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'scale_factors'", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "ones", "(", "1", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "params", ".", "scale_factors", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "Tensor", "(", "self", ".", "params", ".", "scale_factors", ")", "\n", "\n", "# Setup scale bounds", "\n", "", "self", ".", "min_scale_factor", "=", "torch", ".", "max", "(", "10", "/", "self", ".", "base_target_sz", ")", "\n", "self", ".", "max_scale_factor", "=", "torch", ".", "min", "(", "self", ".", "image_sz", "/", "self", ".", "base_target_sz", ")", "\n", "\n", "# Extract and transform sample", "\n", "init_backbone_feat", "=", "self", ".", "generate_init_samples", "(", "im", ")", "\n", "\n", "# Initialize classifier", "\n", "self", ".", "init_classifier", "(", "init_backbone_feat", ")", "\n", "\n", "# Initialize IoUNet", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", ":", "\n", "            ", "self", ".", "init_iou_net", "(", "init_backbone_feat", ")", "\n", "\n", "", "out", "=", "{", "'time'", ":", "time", ".", "time", "(", ")", "-", "tic", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.track": [[94, 183], ["pytracking.features.preprocessing.numpy_to_torch", "dimp_simple.DiMPSimple.extract_backbone_features", "dimp_simple.DiMPSimple.get_classification_features", "dimp_simple.DiMPSimple.get_sample_location", "dimp_simple.DiMPSimple.classify_target", "dimp_simple.DiMPSimple.localize_target", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dict", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dimp_simple.DiMPSimple.get_centered_sample_pos", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.get_iounet_box", "dimp_simple.DiMPSimple.get_label_function().to", "dimp_simple.DiMPSimple.update_classifier", "dimp_simple.DiMPSimple.params.get", "hasattr", "dimp_simple.DiMPSimple.pos_iounet.clone", "dimp_simple.DiMPSimple.visdom.register", "dimp_simple.DiMPSimple.visdom.register", "dimp_simple.DiMPSimple.params.get", "torch.cat.tolist", "torch.cat.tolist", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.refine_target_box", "dimp_simple.DiMPSimple.params.get", "torch.max", "torch.max", "torch.max", "torch.max", "pytracking.utils.plotting.show_tensor", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.update_state", "dimp_simple.DiMPSimple.update_state", "dimp_simple.DiMPSimple.get_label_function"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_classification_features", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_sample_location", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.classify_target", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_target", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_centered_sample_pos", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.update_classifier", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.refine_target_box", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_tensor", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_state", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_state", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_label_function"], ["", "def", "track", "(", "self", ",", "image", ",", "info", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "        ", "self", ".", "debug_info", "=", "{", "}", "\n", "\n", "self", ".", "frame_num", "+=", "1", "\n", "self", ".", "debug_info", "[", "'frame_num'", "]", "=", "self", ".", "frame_num", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# ------- LOCALIZATION ------- #", "\n", "\n", "# Extract backbone features", "\n", "backbone_feat", ",", "sample_coords", ",", "im_patches", "=", "self", ".", "extract_backbone_features", "(", "im", ",", "self", ".", "get_centered_sample_pos", "(", ")", ",", "\n", "self", ".", "target_scale", "*", "self", ".", "params", ".", "scale_factors", ",", "\n", "self", ".", "img_sample_sz", ")", "\n", "# Extract classification features", "\n", "test_x", "=", "self", ".", "get_classification_features", "(", "backbone_feat", ")", "\n", "\n", "# Location of sample", "\n", "sample_pos", ",", "sample_scales", "=", "self", ".", "get_sample_location", "(", "sample_coords", ")", "\n", "\n", "# Compute classification scores", "\n", "scores_raw", "=", "self", ".", "classify_target", "(", "test_x", ")", "\n", "\n", "# Localize the target", "\n", "translation_vec", ",", "scale_ind", ",", "s", ",", "flag", "=", "self", ".", "localize_target", "(", "scores_raw", ",", "sample_pos", ",", "sample_scales", ")", "\n", "new_pos", "=", "sample_pos", "[", "scale_ind", ",", ":", "]", "+", "translation_vec", "\n", "\n", "# Update position and scale", "\n", "if", "flag", "!=", "'not_found'", ":", "\n", "            ", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", ":", "\n", "                ", "update_scale_flag", "=", "self", ".", "params", ".", "get", "(", "'update_scale_when_uncertain'", ",", "True", ")", "or", "flag", "!=", "'uncertain'", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_classifier'", ",", "True", ")", ":", "\n", "                    ", "self", ".", "update_state", "(", "new_pos", ")", "\n", "", "self", ".", "refine_target_box", "(", "backbone_feat", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ",", "scale_ind", ",", "update_scale_flag", ")", "\n", "", "elif", "self", ".", "params", ".", "get", "(", "'use_classifier'", ",", "True", ")", ":", "\n", "                ", "self", ".", "update_state", "(", "new_pos", ",", "sample_scales", "[", "scale_ind", "]", ")", "\n", "\n", "\n", "# ------- UPDATE ------- #", "\n", "\n", "", "", "update_flag", "=", "flag", "not", "in", "[", "'not_found'", ",", "'uncertain'", "]", "\n", "hard_negative", "=", "(", "flag", "==", "'hard_negative'", ")", "\n", "learning_rate", "=", "self", ".", "params", ".", "get", "(", "'hard_negative_learning_rate'", ",", "None", ")", "if", "hard_negative", "else", "None", "\n", "\n", "if", "update_flag", "and", "self", ".", "params", ".", "get", "(", "'update_classifier'", ",", "False", ")", ":", "\n", "# Get train sample", "\n", "            ", "train_x", "=", "test_x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "\n", "\n", "# Create target_box and label for spatial sample", "\n", "target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ")", "\n", "train_y", "=", "self", ".", "get_label_function", "(", "self", ".", "pos", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ")", ".", "to", "(", "\n", "self", ".", "params", ".", "device", ")", "\n", "\n", "# Update the classifier model", "\n", "self", ".", "update_classifier", "(", "train_x", ",", "train_y", ",", "target_box", ",", "learning_rate", ",", "s", "[", "scale_ind", ",", "...", "]", ")", "\n", "\n", "# Set the pos of the tracker to iounet pos", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", "and", "flag", "!=", "'not_found'", "and", "hasattr", "(", "self", ",", "'pos_iounet'", ")", ":", "\n", "            ", "self", ".", "pos", "=", "self", ".", "pos_iounet", ".", "clone", "(", ")", "\n", "\n", "", "score_map", "=", "s", "[", "scale_ind", ",", "...", "]", "\n", "max_score", "=", "torch", ".", "max", "(", "score_map", ")", ".", "item", "(", ")", "\n", "\n", "# Visualize and set debug info", "\n", "self", ".", "search_area_box", "=", "torch", ".", "cat", "(", "(", "sample_coords", "[", "scale_ind", ",", "[", "1", ",", "0", "]", "]", ",", "sample_coords", "[", "scale_ind", ",", "[", "3", ",", "2", "]", "]", "-", "sample_coords", "[", "scale_ind", ",", "[", "1", ",", "0", "]", "]", "-", "1", ")", ")", "\n", "self", ".", "debug_info", "[", "'flag'", "+", "self", ".", "id_str", "]", "=", "flag", "\n", "self", ".", "debug_info", "[", "'max_score'", "+", "self", ".", "id_str", "]", "=", "max_score", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "score_map", ",", "'heatmap'", ",", "2", ",", "'Score Map'", "+", "self", ".", "id_str", ")", "\n", "self", ".", "visdom", ".", "register", "(", "self", ".", "debug_info", ",", "'info_dict'", ",", "1", ",", "'Status'", ")", "\n", "", "elif", "self", ".", "params", ".", "debug", ">=", "2", ":", "\n", "            ", "show_tensor", "(", "score_map", ",", "5", ",", "title", "=", "'Max score = {:.2f}'", ".", "format", "(", "max_score", ")", ")", "\n", "\n", "# Stores elements that are used to build the distractor dataset for keep track, see util_scripts/create_distractor_dataset.py", "\n", "", "self", ".", "distractor_dataset_data", "=", "dict", "(", "score_map", "=", "score_map", ",", "sample_pos", "=", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "\n", "sample_scale", "=", "sample_scales", "[", "scale_ind", "]", ",", "\n", "search_area_box", "=", "self", ".", "search_area_box", ")", "\n", "\n", "# Compute output bounding box", "\n", "new_state", "=", "torch", ".", "cat", "(", "(", "self", ".", "pos", "[", "[", "1", ",", "0", "]", "]", "-", "(", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", "-", "1", ")", "/", "2", ",", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", ")", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'output_not_found_box'", ",", "False", ")", "and", "flag", "==", "'not_found'", ":", "\n", "            ", "output_state", "=", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "output_state", "=", "new_state", ".", "tolist", "(", ")", "\n", "\n", "", "out", "=", "{", "'target_bbox'", ":", "output_state", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.get_sample_location": [[184, 190], ["sample_coord.float.float.float"], "methods", ["None"], ["", "def", "get_sample_location", "(", "self", ",", "sample_coord", ")", ":", "\n", "        ", "\"\"\"Get the location of the extracted sample.\"\"\"", "\n", "sample_coord", "=", "sample_coord", ".", "float", "(", ")", "\n", "sample_pos", "=", "0.5", "*", "(", "sample_coord", "[", ":", ",", ":", "2", "]", "+", "sample_coord", "[", ":", ",", "2", ":", "]", "-", "1", ")", "\n", "sample_scales", "=", "(", "(", "sample_coord", "[", ":", ",", "2", ":", "]", "-", "sample_coord", "[", ":", ",", ":", "2", "]", ")", "/", "self", ".", "img_sample_sz", ")", ".", "prod", "(", "dim", "=", "1", ")", ".", "sqrt", "(", ")", "\n", "return", "sample_pos", ",", "sample_scales", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.get_centered_sample_pos": [[191, 195], ["None"], "methods", ["None"], ["", "def", "get_centered_sample_pos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the center position for the new sample. Make sure the target is correctly centered.\"\"\"", "\n", "return", "self", ".", "pos", "+", "(", "(", "self", ".", "feature_sz", "+", "self", ".", "kernel_size", ")", "%", "2", ")", "*", "self", ".", "target_scale", "*", "self", ".", "img_support_sz", "/", "(", "2", "*", "self", ".", "feature_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.classify_target": [[196, 201], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp_simple.DiMPSimple.net.classifier.classify"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.classify"], ["", "def", "classify_target", "(", "self", ",", "sample_x", ":", "TensorList", ")", ":", "\n", "        ", "\"\"\"Classify target by applying the DiMP filter.\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "scores", "=", "self", ".", "net", ".", "classifier", ".", "classify", "(", "self", ".", "target_filter", ",", "sample_x", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.localize_target": [[202, 242], ["activation.softmax_reg.view.squeeze", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.params.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "pytracking.dcf.max2d", "torch.max", "torch.max", "torch.max", "torch.max", "max_disp[].float().cpu().view", "activation.softmax_reg.view.new_ones", "torch.conv2d().view", "torch.conv2d().view", "dimp_simple.DiMPSimple.localize_advanced", "list", "activation.softmax_reg.view.exp", "max_disp[].float().cpu", "getattr", "activation.softmax_reg.view.view", "ltr.models.layers.activation.softmax_reg", "ltr.models.layers.activation.softmax_reg.view", "Exception", "torch.conv2d", "torch.conv2d", "activation.softmax_reg.view.view", "max_disp[].float"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_advanced", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.softmax_reg", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["", "def", "localize_target", "(", "self", ",", "scores", ",", "sample_pos", ",", "sample_scales", ")", ":", "\n", "        ", "\"\"\"Run the target localization.\"\"\"", "\n", "\n", "scores", "=", "scores", ".", "squeeze", "(", "1", ")", "\n", "\n", "preprocess_method", "=", "self", ".", "params", ".", "get", "(", "'score_preprocess'", ",", "'none'", ")", "\n", "if", "preprocess_method", "==", "'none'", ":", "\n", "            ", "pass", "\n", "", "elif", "preprocess_method", "==", "'exp'", ":", "\n", "            ", "scores", "=", "scores", ".", "exp", "(", ")", "\n", "", "elif", "preprocess_method", "==", "'softmax'", ":", "\n", "            ", "reg_val", "=", "getattr", "(", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ",", "'softmax_reg'", ",", "None", ")", "\n", "scores_view", "=", "scores", ".", "view", "(", "scores", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "scores_softmax", "=", "activation", ".", "softmax_reg", "(", "scores_view", ",", "dim", "=", "-", "1", ",", "reg", "=", "reg_val", ")", "\n", "scores", "=", "scores_softmax", ".", "view", "(", "scores", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unknown score_preprocess in params.'", ")", "\n", "\n", "", "score_filter_ksz", "=", "self", ".", "params", ".", "get", "(", "'score_filter_ksz'", ",", "1", ")", "\n", "if", "score_filter_ksz", ">", "1", ":", "\n", "            ", "assert", "score_filter_ksz", "%", "2", "==", "1", "\n", "kernel", "=", "scores", ".", "new_ones", "(", "1", ",", "1", ",", "score_filter_ksz", ",", "score_filter_ksz", ")", "\n", "scores", "=", "F", ".", "conv2d", "(", "scores", ".", "view", "(", "-", "1", ",", "1", ",", "*", "scores", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "kernel", ",", "padding", "=", "score_filter_ksz", "//", "2", ")", ".", "view", "(", "scores", ".", "shape", ")", "\n", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'advanced_localization'", ",", "False", ")", ":", "\n", "            ", "return", "self", ".", "localize_advanced", "(", "scores", ",", "sample_pos", ",", "sample_scales", ")", "\n", "\n", "# Get maximum", "\n", "", "score_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "scores", ".", "shape", "[", "-", "2", ":", "]", ")", ")", "\n", "score_center", "=", "(", "score_sz", "-", "1", ")", "/", "2", "\n", "max_score", ",", "max_disp", "=", "dcf", ".", "max2d", "(", "scores", ")", "\n", "_", ",", "scale_ind", "=", "torch", ".", "max", "(", "max_score", ",", "dim", "=", "0", ")", "\n", "max_disp", "=", "max_disp", "[", "scale_ind", ",", "...", "]", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp", "=", "max_disp", "-", "score_center", "\n", "\n", "# Compute translation vector and scale change factor", "\n", "output_sz", "=", "score_sz", "-", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "translation_vec", "=", "target_disp", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scales", "[", "scale_ind", "]", "\n", "\n", "return", "translation_vec", ",", "scale_ind", ",", "scores", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.localize_advanced": [[244, 310], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "pytracking.dcf.max2d", "torch.max", "torch.max", "torch.max", "torch.max", "max_disp1[].float().cpu().view", "max", "min", "max", "min", "scores_hn[].clone", "pytracking.dcf.max2d", "max_disp2.float().cpu().view.float().cpu().view.float().cpu().view", "list", "dimp_simple.DiMPSimple.params.get", "scores.clone", "max_score1.item", "max_score1.item", "dimp_simple.DiMPSimple.params.get", "max_score1.item", "dimp_simple.DiMPSimple.params.get", "round", "round", "round", "round", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "max_disp1[].float().cpu", "max_disp2.float().cpu().view.float().cpu().view.float().cpu", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "float", "float", "max_disp1[].item", "max_disp1[].item", "math.sqrt", "max_disp1[].float", "target_neigh_sz[].item", "max_disp1[].item", "target_neigh_sz[].item", "max_disp1[].item", "max_disp2.float().cpu().view.float().cpu().view.float", "target_neigh_sz[].item", "target_neigh_sz[].item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "localize_advanced", "(", "self", ",", "scores", ",", "sample_pos", ",", "sample_scales", ")", ":", "\n", "        ", "\"\"\"Run the target advanced localization (as in ATOM).\"\"\"", "\n", "\n", "sz", "=", "scores", ".", "shape", "[", "-", "2", ":", "]", "\n", "score_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "sz", ")", ")", "\n", "output_sz", "=", "score_sz", "-", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "score_center", "=", "(", "score_sz", "-", "1", ")", "/", "2", "\n", "\n", "scores_hn", "=", "scores", "\n", "if", "self", ".", "output_window", "is", "not", "None", "and", "self", ".", "params", ".", "get", "(", "'perform_hn_without_windowing'", ",", "False", ")", ":", "\n", "            ", "scores_hn", "=", "scores", ".", "clone", "(", ")", "\n", "scores", "*=", "self", ".", "output_window", "\n", "\n", "", "max_score1", ",", "max_disp1", "=", "dcf", ".", "max2d", "(", "scores", ")", "\n", "_", ",", "scale_ind", "=", "torch", ".", "max", "(", "max_score1", ",", "dim", "=", "0", ")", "\n", "sample_scale", "=", "sample_scales", "[", "scale_ind", "]", "\n", "max_score1", "=", "max_score1", "[", "scale_ind", "]", "\n", "max_disp1", "=", "max_disp1", "[", "scale_ind", ",", "...", "]", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp1", "=", "max_disp1", "-", "score_center", "\n", "translation_vec1", "=", "target_disp1", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scale", "\n", "\n", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "target_not_found_threshold", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'not_found'", "\n", "", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "get", "(", "'uncertain_threshold'", ",", "-", "float", "(", "'inf'", ")", ")", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'uncertain'", "\n", "", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "get", "(", "'hard_sample_threshold'", ",", "-", "float", "(", "'inf'", ")", ")", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", "\n", "\n", "# Mask out target neighborhood", "\n", "", "target_neigh_sz", "=", "self", ".", "params", ".", "target_neighborhood_scale", "*", "(", "self", ".", "target_sz", "/", "sample_scale", ")", "*", "(", "output_sz", "/", "self", ".", "img_support_sz", ")", "\n", "\n", "tneigh_top", "=", "max", "(", "round", "(", "max_disp1", "[", "0", "]", ".", "item", "(", ")", "-", "target_neigh_sz", "[", "0", "]", ".", "item", "(", ")", "/", "2", ")", ",", "0", ")", "\n", "tneigh_bottom", "=", "min", "(", "round", "(", "max_disp1", "[", "0", "]", ".", "item", "(", ")", "+", "target_neigh_sz", "[", "0", "]", ".", "item", "(", ")", "/", "2", "+", "1", ")", ",", "sz", "[", "0", "]", ")", "\n", "tneigh_left", "=", "max", "(", "round", "(", "max_disp1", "[", "1", "]", ".", "item", "(", ")", "-", "target_neigh_sz", "[", "1", "]", ".", "item", "(", ")", "/", "2", ")", ",", "0", ")", "\n", "tneigh_right", "=", "min", "(", "round", "(", "max_disp1", "[", "1", "]", ".", "item", "(", ")", "+", "target_neigh_sz", "[", "1", "]", ".", "item", "(", ")", "/", "2", "+", "1", ")", ",", "sz", "[", "1", "]", ")", "\n", "scores_masked", "=", "scores_hn", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", ".", "clone", "(", ")", "\n", "scores_masked", "[", "...", ",", "tneigh_top", ":", "tneigh_bottom", ",", "tneigh_left", ":", "tneigh_right", "]", "=", "0", "\n", "\n", "# Find new maximum", "\n", "max_score2", ",", "max_disp2", "=", "dcf", ".", "max2d", "(", "scores_masked", ")", "\n", "max_disp2", "=", "max_disp2", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp2", "=", "max_disp2", "-", "score_center", "\n", "translation_vec2", "=", "target_disp2", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scale", "\n", "\n", "prev_target_vec", "=", "(", "self", ".", "pos", "-", "sample_pos", "[", "scale_ind", ",", ":", "]", ")", "/", "(", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scale", ")", "\n", "\n", "# Handle the different cases", "\n", "if", "max_score2", ">", "self", ".", "params", ".", "distractor_threshold", "*", "max_score1", ":", "\n", "            ", "disp_norm1", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "target_disp1", "-", "prev_target_vec", ")", "**", "2", ")", ")", "\n", "disp_norm2", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "target_disp2", "-", "prev_target_vec", ")", "**", "2", ")", ")", "\n", "disp_threshold", "=", "self", ".", "params", ".", "dispalcement_scale", "*", "math", ".", "sqrt", "(", "sz", "[", "0", "]", "*", "sz", "[", "1", "]", ")", "/", "2", "\n", "\n", "if", "disp_norm2", ">", "disp_threshold", "and", "disp_norm1", "<", "disp_threshold", ":", "\n", "                ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", "\n", "", "if", "disp_norm2", "<", "disp_threshold", "and", "disp_norm1", ">", "disp_threshold", ":", "\n", "                ", "return", "translation_vec2", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", "\n", "", "if", "disp_norm2", ">", "disp_threshold", "and", "disp_norm1", ">", "disp_threshold", ":", "\n", "                ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'uncertain'", "\n", "\n", "# If also the distractor is close, return with highest score", "\n", "", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'uncertain'", "\n", "\n", "", "if", "max_score2", ">", "self", ".", "params", ".", "hard_negative_threshold", "*", "max_score1", "and", "max_score2", ">", "self", ".", "params", ".", "target_not_found_threshold", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", "\n", "\n", "", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'normal'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.extract_backbone_features": [[311, 318], ["pytracking.features.preprocessing.sample_patch_multiscale", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp_simple.DiMPSimple.net.extract_backbone", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_multiscale", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "extract_backbone_features", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ",", "pos", ":", "torch", ".", "Tensor", ",", "scales", ",", "sz", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "im_patches", ",", "patch_coords", "=", "sample_patch_multiscale", "(", "im", ",", "pos", ",", "scales", ",", "sz", ",", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", ",", "\n", "max_scale_change", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ",", "None", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im_patches", ")", "\n", "", "return", "backbone_feat", ",", "patch_coords", ",", "im_patches", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.get_classification_features": [[319, 322], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp_simple.DiMPSimple.net.extract_classification_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat"], ["", "def", "get_classification_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "extract_classification_feat", "(", "backbone_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.get_iou_backbone_features": [[323, 325], ["dimp_simple.DiMPSimple.net.get_backbone_bbreg_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.get_backbone_bbreg_feat"], ["", "", "def", "get_iou_backbone_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "return", "self", ".", "net", ".", "get_backbone_bbreg_feat", "(", "backbone_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.get_iou_features": [[326, 329], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp_simple.DiMPSimple.net.bb_regressor.get_iou_feat", "dimp_simple.DiMPSimple.get_iou_backbone_features"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_iou_feat", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_backbone_features"], ["", "def", "get_iou_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "bb_regressor", ".", "get_iou_feat", "(", "self", ".", "get_iou_backbone_features", "(", "backbone_feat", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.get_iou_modulation": [[330, 333], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp_simple.DiMPSimple.net.bb_regressor.get_modulation"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_modulation"], ["", "", "def", "get_iou_modulation", "(", "self", ",", "iou_backbone_feat", ",", "target_boxes", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "bb_regressor", ".", "get_modulation", "(", "iou_backbone_feat", ",", "target_boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.generate_init_samples": [[335, 404], ["dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.pos.round", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.img_sample_sz.clone", "dimp_simple.DiMPSimple.params.get", "pytracking.features.preprocessing.sample_patch_transformed", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "shrink_factor.min.min.clamp_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "aug_expansion_sz.float.float.float", "dimp_simple.DiMPSimple.img_sample_sz.long().tolist", "pytracking.features.augmentation.Identity", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.transforms.extend", "dimp_simple.DiMPSimple.transforms.extend", "dimp_simple.DiMPSimple.transforms.append", "dimp_simple.DiMPSimple.transforms.extend", "dimp_simple.DiMPSimple.transforms.extend", "dimp_simple.DiMPSimple.transforms.extend", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp_simple.DiMPSimple.net.extract_backbone", "sample_sz.float", "shrink_factor.min.min.max", "sample_sz.float", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "pytracking.features.augmentation.FlipHorizontal", "shrink_factor.min.min.min", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.img_sample_sz.long", "dimp_simple.DiMPSimple.img_sample_sz.long", "pytracking.features.augmentation.Translation", "pytracking.features.augmentation.Translation", "get_rand_shift", "pytracking.features.augmentation.Blur", "pytracking.features.augmentation.Scale", "pytracking.features.augmentation.Rotate", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "get_absolute", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "get_rand_shift", "get_rand_shift", "get_rand_shift", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_transformed", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "", "def", "generate_init_samples", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Perform data augmentation to generate initial training samples.\"\"\"", "\n", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", "\n", "if", "mode", "==", "'inside'", ":", "\n", "# Get new sample size if forced inside the image", "\n", "            ", "im_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "sample_sz", "=", "self", ".", "target_scale", "*", "self", ".", "img_sample_sz", "\n", "shrink_factor", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "im_sz", ")", "\n", "if", "mode", "==", "'inside'", ":", "\n", "                ", "shrink_factor", "=", "shrink_factor", ".", "max", "(", ")", "\n", "", "elif", "mode", "==", "'inside_major'", ":", "\n", "                ", "shrink_factor", "=", "shrink_factor", ".", "min", "(", ")", "\n", "", "shrink_factor", ".", "clamp_", "(", "min", "=", "1", ",", "max", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ",", "None", ")", ")", "\n", "sample_sz", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "shrink_factor", ")", "\n", "self", ".", "init_sample_scale", "=", "(", "sample_sz", "/", "self", ".", "img_sample_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "tl", "=", "self", ".", "pos", "-", "(", "sample_sz", "-", "1", ")", "/", "2", "\n", "br", "=", "self", ".", "pos", "+", "sample_sz", "/", "2", "+", "1", "\n", "global_shift", "=", "-", "(", "(", "-", "tl", ")", ".", "clamp", "(", "0", ")", "-", "(", "br", "-", "im_sz", ")", ".", "clamp", "(", "0", ")", ")", "/", "self", ".", "init_sample_scale", "\n", "", "else", ":", "\n", "            ", "self", ".", "init_sample_scale", "=", "self", ".", "target_scale", "\n", "global_shift", "=", "torch", ".", "zeros", "(", "2", ")", "\n", "\n", "", "self", ".", "init_sample_pos", "=", "self", ".", "pos", ".", "round", "(", ")", "\n", "\n", "# Compute augmentation size", "\n", "aug_expansion_factor", "=", "self", ".", "params", ".", "get", "(", "'augmentation_expansion_factor'", ",", "None", ")", "\n", "aug_expansion_sz", "=", "self", ".", "img_sample_sz", ".", "clone", "(", ")", "\n", "aug_output_sz", "=", "None", "\n", "if", "aug_expansion_factor", "is", "not", "None", "and", "aug_expansion_factor", "!=", "1", ":", "\n", "            ", "aug_expansion_sz", "=", "(", "self", ".", "img_sample_sz", "*", "aug_expansion_factor", ")", ".", "long", "(", ")", "\n", "aug_expansion_sz", "+=", "(", "aug_expansion_sz", "-", "self", ".", "img_sample_sz", ".", "long", "(", ")", ")", "%", "2", "\n", "aug_expansion_sz", "=", "aug_expansion_sz", ".", "float", "(", ")", "\n", "aug_output_sz", "=", "self", ".", "img_sample_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Random shift for each sample", "\n", "", "get_rand_shift", "=", "lambda", ":", "None", "\n", "random_shift_factor", "=", "self", ".", "params", ".", "get", "(", "'random_shift_factor'", ",", "0", ")", "\n", "if", "random_shift_factor", ">", "0", ":", "\n", "            ", "get_rand_shift", "=", "lambda", ":", "(", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "*", "self", ".", "img_sample_sz", "*", "random_shift_factor", "+", "global_shift", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Always put identity transformation first, since it is the unaugmented sample that is always used", "\n", "", "self", ".", "transforms", "=", "[", "augmentation", ".", "Identity", "(", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "]", "\n", "\n", "augs", "=", "self", ".", "params", ".", "augmentation", "if", "self", ".", "params", ".", "get", "(", "'use_augmentation'", ",", "True", ")", "else", "{", "}", "\n", "\n", "# Add all augmentations", "\n", "if", "'shift'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "shift", ",", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "for", "shift", "in", "augs", "[", "'shift'", "]", "]", ")", "\n", "", "if", "'relativeshift'", "in", "augs", ":", "\n", "            ", "get_absolute", "=", "lambda", "shift", ":", "(", "torch", ".", "Tensor", "(", "shift", ")", "*", "self", ".", "img_sample_sz", "/", "2", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "get_absolute", "(", "shift", ")", ",", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "for", "shift", "in", "augs", "[", "'relativeshift'", "]", "]", ")", "\n", "", "if", "'fliplr'", "in", "augs", "and", "augs", "[", "'fliplr'", "]", ":", "\n", "            ", "self", ".", "transforms", ".", "append", "(", "augmentation", ".", "FlipHorizontal", "(", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", ")", "\n", "", "if", "'blur'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Blur", "(", "sigma", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "sigma", "in", "augs", "[", "'blur'", "]", "]", ")", "\n", "", "if", "'scale'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Scale", "(", "scale_factor", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "scale_factor", "in", "augs", "[", "'scale'", "]", "]", ")", "\n", "", "if", "'rotate'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Rotate", "(", "angle", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "angle", "in", "augs", "[", "'rotate'", "]", "]", ")", "\n", "\n", "# Extract augmented image patches", "\n", "", "im_patches", "=", "sample_patch_transformed", "(", "im", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ",", "aug_expansion_sz", ",", "self", ".", "transforms", ")", "\n", "\n", "# Extract initial backbone features", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "init_backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im_patches", ")", "\n", "\n", "", "return", "init_backbone_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.init_target_boxes": [[405, 415], ["dimp_simple.DiMPSimple.get_iounet_box", "pytracking.TensorList", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to.new_zeros", "torch.cat().to.new_zeros", "torch.cat().to.append", "torch.cat().to.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat().to.view", "torch.cat().to.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "init_target_boxes", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the target bounding boxes for the initial augmented samples.\"\"\"", "\n", "self", ".", "classifier_target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ")", "\n", "init_target_boxes", "=", "TensorList", "(", ")", "\n", "for", "T", "in", "self", ".", "transforms", ":", "\n", "            ", "init_target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "T", ".", "shift", "[", "1", "]", ",", "T", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "init_target_boxes", "=", "torch", ".", "cat", "(", "init_target_boxes", ".", "view", "(", "1", ",", "4", ")", ",", "0", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "self", ".", "target_boxes", "=", "init_target_boxes", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "4", ")", "\n", "self", ".", "target_boxes", "[", ":", "init_target_boxes", ".", "shape", "[", "0", "]", ",", ":", "]", "=", "init_target_boxes", "\n", "return", "init_target_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.init_target_labels": [[416, 436], ["pytracking.TensorList", "dimp_simple.DiMPSimple.params.get", "zip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "enumerate", "x.new_zeros", "pytracking.dcf.label_function_spatial", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "int", "int", "dimp_simple.DiMPSimple.kernel_size[].item", "dimp_simple.DiMPSimple.kernel_size[].item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.label_function_spatial"], ["", "def", "init_target_labels", "(", "self", ",", "train_x", ":", "TensorList", ")", ":", "\n", "        ", "self", ".", "target_labels", "=", "TensorList", "(", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "1", ",", "\n", "x", ".", "shape", "[", "2", "]", "+", "(", "int", "(", "self", ".", "kernel_size", "[", "0", "]", ".", "item", "(", ")", ")", "+", "1", ")", "%", "2", ",", "\n", "x", ".", "shape", "[", "3", "]", "+", "(", "int", "(", "self", ".", "kernel_size", "[", "1", "]", ".", "item", "(", ")", ")", "+", "1", ")", "%", "2", ")", "\n", "for", "x", "in", "train_x", "]", ")", "\n", "# Output sigma factor", "\n", "output_sigma_factor", "=", "self", ".", "params", ".", "get", "(", "'output_sigma_factor'", ",", "1", "/", "4", ")", "\n", "self", ".", "sigma", "=", "(", "self", ".", "feature_sz", "/", "self", ".", "img_support_sz", "*", "self", ".", "base_target_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "output_sigma_factor", "*", "torch", ".", "ones", "(", "2", ")", "\n", "\n", "# Center pos in normalized img_coords", "\n", "target_center_norm", "=", "(", "self", ".", "pos", "-", "self", ".", "init_sample_pos", ")", "/", "(", "self", ".", "init_sample_scale", "*", "self", ".", "img_support_sz", ")", "\n", "\n", "for", "target", ",", "x", "in", "zip", "(", "self", ".", "target_labels", ",", "train_x", ")", ":", "\n", "            ", "ksz_even", "=", "torch", ".", "Tensor", "(", "[", "(", "self", ".", "kernel_size", "[", "0", "]", "+", "1", ")", "%", "2", ",", "(", "self", ".", "kernel_size", "[", "1", "]", "+", "1", ")", "%", "2", "]", ")", "\n", "center_pos", "=", "self", ".", "feature_sz", "*", "target_center_norm", "+", "0.5", "*", "ksz_even", "\n", "for", "i", ",", "T", "in", "enumerate", "(", "self", ".", "transforms", "[", ":", "x", ".", "shape", "[", "0", "]", "]", ")", ":", "\n", "                ", "sample_center", "=", "center_pos", "+", "torch", ".", "Tensor", "(", "T", ".", "shift", ")", "/", "self", ".", "img_support_sz", "*", "self", ".", "feature_sz", "\n", "target", "[", "i", ",", "0", ",", "...", "]", "=", "dcf", ".", "label_function_spatial", "(", "self", ".", "feature_sz", ",", "self", ".", "sigma", ",", "sample_center", ",", "end_pad", "=", "ksz_even", ")", "\n", "\n", "", "", "return", "self", ".", "target_labels", "[", "0", "]", "[", ":", "train_x", "[", "0", "]", ".", "shape", "[", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.init_memory": [[437, 455], ["train_x.size", "pytracking.TensorList", "dimp_simple.DiMPSimple.num_init_samples.copy", "pytracking.TensorList", "zip", "pytracking.TensorList", "zip", "len", "x.new_zeros", "x.new_zeros", "x.new_ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "def", "init_memory", "(", "self", ",", "train_x", ":", "TensorList", ")", ":", "\n", "# Initialize first-frame spatial training samples", "\n", "        ", "self", ".", "num_init_samples", "=", "train_x", ".", "size", "(", "0", ")", "\n", "init_sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_ones", "(", "1", ")", "/", "x", ".", "shape", "[", "0", "]", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "# Sample counters and weights for spatial", "\n", "self", ".", "num_stored_samples", "=", "self", ".", "num_init_samples", ".", "copy", "(", ")", "\n", "self", ".", "previous_replace_ind", "=", "[", "None", "]", "*", "len", "(", "self", ".", "num_stored_samples", ")", "\n", "self", ".", "sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ")", "for", "x", "in", "train_x", "]", ")", "\n", "for", "sw", ",", "init_sw", ",", "num", "in", "zip", "(", "self", ".", "sample_weights", ",", "init_sample_weights", ",", "self", ".", "num_init_samples", ")", ":", "\n", "            ", "sw", "[", ":", "num", "]", "=", "init_sw", "\n", "\n", "# Initialize memory", "\n", "", "self", ".", "training_samples", "=", "TensorList", "(", "\n", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "for", "ts", ",", "x", "in", "zip", "(", "self", ".", "training_samples", ",", "train_x", ")", ":", "\n", "            ", "ts", "[", ":", "x", ".", "shape", "[", "0", "]", ",", "...", "]", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.update_memory": [[457, 473], ["dimp_simple.DiMPSimple.update_sample_weights", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_sample_weights"], ["", "", "def", "update_memory", "(", "self", ",", "sample_x", ":", "TensorList", ",", "sample_y", ":", "TensorList", ",", "target_box", ",", "learning_rate", "=", "None", ")", ":", "\n", "# Update weights and get replace ind", "\n", "        ", "replace_ind", "=", "self", ".", "update_sample_weights", "(", "self", ".", "sample_weights", ",", "self", ".", "previous_replace_ind", ",", "self", ".", "num_stored_samples", ",", "self", ".", "num_init_samples", ",", "learning_rate", ")", "\n", "self", ".", "previous_replace_ind", "=", "replace_ind", "\n", "\n", "# Update sample and label memory", "\n", "for", "train_samp", ",", "x", ",", "ind", "in", "zip", "(", "self", ".", "training_samples", ",", "sample_x", ",", "replace_ind", ")", ":", "\n", "            ", "train_samp", "[", "ind", ":", "ind", "+", "1", ",", "...", "]", "=", "x", "\n", "\n", "", "for", "y_memory", ",", "y", ",", "ind", "in", "zip", "(", "self", ".", "target_labels", ",", "sample_y", ",", "replace_ind", ")", ":", "\n", "            ", "y_memory", "[", "ind", ":", "ind", "+", "1", ",", "...", "]", "=", "y", "\n", "\n", "# Update bb memory", "\n", "", "self", ".", "target_boxes", "[", "replace_ind", "[", "0", "]", ",", ":", "]", "=", "target_box", "\n", "\n", "self", ".", "num_stored_samples", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.update_sample_weights": [[475, 515], ["zip", "dimp_simple.DiMPSimple.params.get", "sw.sum", "replace_ind.append", "torch.min", "torch.min", "torch.min", "torch.min", "sw[].sum", "sw[].sum", "r_ind.item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "update_sample_weights", "(", "self", ",", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ",", "learning_rate", "=", "None", ")", ":", "\n", "# Update weights and get index to replace", "\n", "        ", "replace_ind", "=", "[", "]", "\n", "for", "sw", ",", "prev_ind", ",", "num_samp", ",", "num_init", "in", "zip", "(", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ")", ":", "\n", "            ", "lr", "=", "learning_rate", "\n", "if", "lr", "is", "None", ":", "\n", "                ", "lr", "=", "self", ".", "params", ".", "learning_rate", "\n", "\n", "", "init_samp_weight", "=", "self", ".", "params", ".", "get", "(", "'init_samples_minimum_weight'", ",", "None", ")", "\n", "if", "init_samp_weight", "==", "0", ":", "\n", "                ", "init_samp_weight", "=", "None", "\n", "", "s_ind", "=", "0", "if", "init_samp_weight", "is", "None", "else", "num_init", "\n", "\n", "if", "num_samp", "==", "0", "or", "lr", "==", "1", ":", "\n", "                ", "sw", "[", ":", "]", "=", "0", "\n", "sw", "[", "0", "]", "=", "1", "\n", "r_ind", "=", "0", "\n", "", "else", ":", "\n", "# Get index to replace", "\n", "                ", "if", "num_samp", "<", "sw", ".", "shape", "[", "0", "]", ":", "\n", "                    ", "r_ind", "=", "num_samp", "\n", "", "else", ":", "\n", "                    ", "_", ",", "r_ind", "=", "torch", ".", "min", "(", "sw", "[", "s_ind", ":", "]", ",", "0", ")", "\n", "r_ind", "=", "r_ind", ".", "item", "(", ")", "+", "s_ind", "\n", "\n", "# Update weights", "\n", "", "if", "prev_ind", "is", "None", ":", "\n", "                    ", "sw", "/=", "1", "-", "lr", "\n", "sw", "[", "r_ind", "]", "=", "lr", "\n", "", "else", ":", "\n", "                    ", "sw", "[", "r_ind", "]", "=", "sw", "[", "prev_ind", "]", "/", "(", "1", "-", "lr", ")", "\n", "\n", "", "", "sw", "/=", "sw", ".", "sum", "(", ")", "\n", "if", "init_samp_weight", "is", "not", "None", "and", "sw", "[", ":", "num_init", "]", ".", "sum", "(", ")", "<", "init_samp_weight", ":", "\n", "                ", "sw", "/=", "init_samp_weight", "+", "sw", "[", "num_init", ":", "]", ".", "sum", "(", ")", "\n", "sw", "[", ":", "num_init", "]", "=", "init_samp_weight", "/", "num_init", "\n", "\n", "", "replace_ind", ".", "append", "(", "r_ind", ")", "\n", "\n", "", "return", "replace_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.get_label_function": [[516, 526], ["pytracking.TensorList", "zip", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "pytracking.TensorList.append", "pytracking.dcf.label_function_spatial"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.label_function_spatial"], ["", "def", "get_label_function", "(", "self", ",", "pos", ",", "sample_pos", ",", "sample_scale", ")", ":", "\n", "        ", "train_y", "=", "TensorList", "(", ")", "\n", "target_center_norm", "=", "(", "pos", "-", "sample_pos", ")", "/", "(", "sample_scale", "*", "self", ".", "img_support_sz", ")", "\n", "\n", "for", "sig", ",", "sz", ",", "ksz", "in", "zip", "(", "[", "self", ".", "sigma", "]", ",", "[", "self", ".", "feature_sz", "]", ",", "[", "self", ".", "kernel_size", "]", ")", ":", "\n", "            ", "ksz_even", "=", "torch", ".", "Tensor", "(", "[", "(", "self", ".", "kernel_size", "[", "0", "]", "+", "1", ")", "%", "2", ",", "(", "self", ".", "kernel_size", "[", "1", "]", "+", "1", ")", "%", "2", "]", ")", "\n", "center", "=", "sz", "*", "target_center_norm", "+", "0.5", "*", "ksz_even", "\n", "train_y", ".", "append", "(", "dcf", ".", "label_function_spatial", "(", "sz", ",", "sig", ",", "center", ",", "end_pad", "=", "ksz_even", ")", ")", "\n", "\n", "", "return", "train_y", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.update_state": [[527, 537], ["dimp_simple.DiMPSimple.params.get", "torch.max", "torch.max", "torch.max", "torch.max", "new_scale.clamp", "torch.min", "torch.min", "torch.min", "torch.min"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "update_state", "(", "self", ",", "new_pos", ",", "new_scale", "=", "None", ")", ":", "\n", "# Update scale", "\n", "        ", "if", "new_scale", "is", "not", "None", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", ".", "clamp", "(", "self", ".", "min_scale_factor", ",", "self", ".", "max_scale_factor", ")", "\n", "self", ".", "target_sz", "=", "self", ".", "base_target_sz", "*", "self", ".", "target_scale", "\n", "\n", "# Update pos", "\n", "", "inside_ratio", "=", "self", ".", "params", ".", "get", "(", "'target_inside_ratio'", ",", "0.2", ")", "\n", "inside_offset", "=", "(", "inside_ratio", "-", "0.5", ")", "*", "self", ".", "target_sz", "\n", "self", ".", "pos", "=", "torch", ".", "max", "(", "torch", ".", "min", "(", "new_pos", ",", "self", ".", "image_sz", "-", "inside_offset", ")", ",", "inside_offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.get_iounet_box": [[539, 546], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "target_ul.flip", "box_sz.flip"], "methods", ["None"], ["", "def", "get_iounet_box", "(", "self", ",", "pos", ",", "sz", ",", "sample_pos", ",", "sample_scale", ")", ":", "\n", "        ", "\"\"\"All inputs in original image coordinates.\n        Generates a box in the cropped image sample reference frame, in the format used by the IoUNet.\"\"\"", "\n", "box_center", "=", "(", "pos", "-", "sample_pos", ")", "/", "sample_scale", "+", "(", "self", ".", "img_sample_sz", "-", "1", ")", "/", "2", "\n", "box_sz", "=", "sz", "/", "sample_scale", "\n", "target_ul", "=", "box_center", "-", "(", "box_sz", "-", "1", ")", "/", "2", "\n", "return", "torch", ".", "cat", "(", "[", "target_ul", ".", "flip", "(", "(", "0", ",", ")", ")", ",", "box_sz", ".", "flip", "(", "(", "0", ",", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.init_iou_net": [[548, 575], ["dimp_simple.DiMPSimple.net.bb_regressor.parameters", "dimp_simple.DiMPSimple.get_iounet_box", "pytracking.TensorList", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "dimp_simple.DiMPSimple.get_iou_backbone_features", "pytracking.TensorList", "dimp_simple.DiMPSimple.get_iou_modulation", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.cat().to.append", "torch.cat().to.append", "pytracking.TensorList", "torch.cat().to.append", "torch.cat().to.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "isinstance", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat().to.view", "torch.cat().to.view", "x.detach().mean", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "x.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_iou_modulation", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "init_iou_net", "(", "self", ",", "backbone_feat", ")", ":", "\n", "# Setup IoU net and objective", "\n", "        ", "for", "p", "in", "self", ".", "net", ".", "bb_regressor", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "# Get target boxes for the different augmentations", "\n", "", "self", ".", "classifier_target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ")", "\n", "target_boxes", "=", "TensorList", "(", ")", "\n", "if", "self", ".", "params", ".", "iounet_augmentation", ":", "\n", "            ", "for", "T", "in", "self", ".", "transforms", ":", "\n", "                ", "if", "not", "isinstance", "(", "T", ",", "(", "augmentation", ".", "Identity", ",", "augmentation", ".", "Translation", ",", "augmentation", ".", "FlipHorizontal", ",", "augmentation", ".", "FlipVertical", ",", "augmentation", ".", "Blur", ")", ")", ":", "\n", "                    ", "break", "\n", "", "target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "T", ".", "shift", "[", "1", "]", ",", "T", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "self", ".", "transforms", "[", "0", "]", ".", "shift", "[", "1", "]", ",", "self", ".", "transforms", "[", "0", "]", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "target_boxes", "=", "torch", ".", "cat", "(", "target_boxes", ".", "view", "(", "1", ",", "4", ")", ",", "0", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "# Get iou features", "\n", "iou_backbone_feat", "=", "self", ".", "get_iou_backbone_features", "(", "backbone_feat", ")", "\n", "\n", "# Remove other augmentations such as rotation", "\n", "iou_backbone_feat", "=", "TensorList", "(", "[", "x", "[", ":", "target_boxes", ".", "shape", "[", "0", "]", ",", "...", "]", "for", "x", "in", "iou_backbone_feat", "]", ")", "\n", "\n", "# Get modulation vector", "\n", "self", ".", "iou_modulation", "=", "self", ".", "get_iou_modulation", "(", "iou_backbone_feat", ",", "target_boxes", ")", "\n", "if", "torch", ".", "is_tensor", "(", "self", ".", "iou_modulation", "[", "0", "]", ")", ":", "\n", "            ", "self", ".", "iou_modulation", "=", "TensorList", "(", "[", "x", ".", "detach", "(", ")", ".", "mean", "(", "0", ")", "for", "x", "in", "self", ".", "iou_modulation", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.init_classifier": [[577, 635], ["dimp_simple.DiMPSimple.get_classification_features", "dimp_simple.DiMPSimple._overwrite_classifier_params", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.init_target_boxes", "dimp_simple.DiMPSimple.init_target_labels", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.transforms.extend", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "list", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.output_window.squeeze", "pytracking.TensorList", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp_simple.DiMPSimple.net.classifier.get_filter", "dimp_simple.DiMPSimple.init_memory", "isinstance", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "isinstance", "pytracking.dcf.hann2d_clipped().to", "pytracking.dcf.hann2d().to", "pytracking.TensorList", "dimp_simple.DiMPSimple.visdom.register", "torch.dropout2d", "torch.dropout2d", "pytracking.utils.plotting.plot_graph", "x[].expand", "pytracking.dcf.hann2d_clipped", "pytracking.dcf.hann2d", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "dimp_simple.DiMPSimple.output_sz.long", "dimp_simple.DiMPSimple.output_sz.long", "dimp_simple.DiMPSimple.losses.numel"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_classification_features", "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP._overwrite_classifier_params", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_target_boxes", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_target_labels", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.get_filter", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_memory", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d_clipped", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d"], ["", "", "def", "init_classifier", "(", "self", ",", "init_backbone_feat", ")", ":", "\n", "# Get classification features", "\n", "        ", "x", "=", "self", ".", "get_classification_features", "(", "init_backbone_feat", ")", "\n", "\n", "# Overwrite some parameters in the classifier. (These are not generally changed)", "\n", "self", ".", "_overwrite_classifier_params", "(", "feature_dim", "=", "x", ".", "shape", "[", "-", "3", "]", ")", "\n", "\n", "# Add the dropout augmentation here, since it requires extraction of the classification features", "\n", "if", "'dropout'", "in", "self", ".", "params", ".", "augmentation", "and", "self", ".", "params", ".", "get", "(", "'use_augmentation'", ",", "True", ")", ":", "\n", "            ", "num", ",", "prob", "=", "self", ".", "params", ".", "augmentation", "[", "'dropout'", "]", "\n", "self", ".", "transforms", ".", "extend", "(", "self", ".", "transforms", "[", ":", "1", "]", "*", "num", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "F", ".", "dropout2d", "(", "x", "[", "0", ":", "1", ",", "...", "]", ".", "expand", "(", "num", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", ",", "p", "=", "prob", ",", "training", "=", "True", ")", "]", ")", "\n", "\n", "# Set feature size and other related sizes", "\n", "", "self", ".", "feature_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "x", ".", "shape", "[", "-", "2", ":", "]", ")", ")", "\n", "ksz", "=", "self", ".", "net", ".", "classifier", ".", "filter_size", "\n", "self", ".", "kernel_size", "=", "torch", ".", "Tensor", "(", "[", "ksz", ",", "ksz", "]", "if", "isinstance", "(", "ksz", ",", "(", "int", ",", "float", ")", ")", "else", "ksz", ")", "\n", "self", ".", "output_sz", "=", "self", ".", "feature_sz", "+", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "\n", "# Construct output window", "\n", "self", ".", "output_window", "=", "None", "\n", "if", "self", ".", "params", ".", "get", "(", "'window_output'", ",", "False", ")", ":", "\n", "            ", "if", "self", ".", "params", ".", "get", "(", "'use_clipped_window'", ",", "False", ")", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d_clipped", "(", "self", ".", "output_sz", ".", "long", "(", ")", ",", "(", "self", ".", "output_sz", "*", "self", ".", "params", ".", "effective_search_area", "/", "self", ".", "params", ".", "search_area_scale", ")", ".", "long", "(", ")", ",", "centered", "=", "True", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d", "(", "self", ".", "output_sz", ".", "long", "(", ")", ",", "centered", "=", "True", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "", "self", ".", "output_window", "=", "self", ".", "output_window", ".", "squeeze", "(", "0", ")", "\n", "\n", "# Get target boxes for the different augmentations", "\n", "", "target_boxes", "=", "self", ".", "init_target_boxes", "(", ")", "\n", "\n", "# Get target labels for the different augmentations", "\n", "target_labels", "=", "self", ".", "init_target_labels", "(", "TensorList", "(", "[", "x", "]", ")", ")", "\n", "\n", "# Set number of iterations", "\n", "plot_loss", "=", "self", ".", "params", ".", "debug", ">", "0", "\n", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_iter'", ",", "None", ")", "\n", "\n", "self", ".", "net", ".", "classifier", ".", "compute_losses", "=", "plot_loss", "\n", "\n", "# Get target filter by running the discriminative model prediction module", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "target_filter", ",", "_", ",", "losses", "=", "self", ".", "net", ".", "classifier", ".", "get_filter", "(", "x", ",", "target_boxes", ",", "\n", "train_label", "=", "target_labels", ",", "\n", "num_iter", "=", "num_iter", ")", "\n", "\n", "# Init memory", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'update_classifier'", ",", "True", ")", ":", "\n", "            ", "self", ".", "init_memory", "(", "TensorList", "(", "[", "x", "]", ")", ")", "\n", "\n", "", "if", "plot_loss", ":", "\n", "            ", "if", "isinstance", "(", "losses", ",", "dict", ")", ":", "\n", "                ", "losses", "=", "losses", "[", "'train'", "]", "\n", "", "self", ".", "losses", "=", "torch", ".", "stack", "(", "losses", ")", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                ", "self", ".", "visdom", ".", "register", "(", "(", "self", ".", "losses", ",", "torch", ".", "arange", "(", "self", ".", "losses", ".", "numel", "(", ")", ")", ")", ",", "'lineplot'", ",", "3", ",", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "", "elif", "self", ".", "params", ".", "debug", ">=", "3", ":", "\n", "                ", "plot_graph", "(", "self", ".", "losses", ",", "10", ",", "title", "=", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple._overwrite_classifier_params": [[636, 650], ["getattr", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.params.get", "ltr.models.target_classifier.initializer.FilterInitializerZero"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "", "", "def", "_overwrite_classifier_params", "(", "self", ",", "feature_dim", ")", ":", "\n", "# Overwrite some parameters in the classifier. (These are not generally changed)", "\n", "        ", "pred_module", "=", "getattr", "(", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ",", "'score_predictor'", ",", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'label_threshold'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ".", "label_threshold", "=", "self", ".", "params", ".", "label_threshold", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'label_shrink'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ".", "label_shrink", "=", "self", ".", "params", ".", "label_shrink", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'softmax_reg'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ".", "softmax_reg", "=", "self", ".", "params", ".", "softmax_reg", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'filter_reg'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "pred_module", ".", "filter_reg", "[", "0", "]", "=", "self", ".", "params", ".", "filter_reg", "\n", "pred_module", ".", "min_filter_reg", "=", "self", ".", "params", ".", "filter_reg", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'filter_init_zero'", ",", "False", ")", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_initializer", "=", "FilterInitializerZero", "(", "self", ".", "net", ".", "classifier", ".", "filter_size", ",", "feature_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.update_classifier": [[652, 700], ["dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.update_memory", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.target_boxes[].clone", "[].view", "pytracking.TensorList", "dimp_simple.DiMPSimple.params.get", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp_simple.DiMPSimple.net.classifier.filter_optimizer", "isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dimp_simple.DiMPSimple.params.get", "scores.max().item", "dimp_simple.DiMPSimple.params.get", "pytracking.TensorList", "dimp_simple.DiMPSimple.visdom.register", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "pytracking.utils.plotting.plot_graph", "scores.max", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "dimp_simple.DiMPSimple.losses.numel"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_memory", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph"], ["", "", "def", "update_classifier", "(", "self", ",", "train_x", ",", "train_y", ",", "target_box", ",", "learning_rate", "=", "None", ",", "scores", "=", "None", ")", ":", "\n", "# Set flags and learning rate", "\n", "        ", "hard_negative_flag", "=", "learning_rate", "is", "not", "None", "\n", "if", "learning_rate", "is", "None", ":", "\n", "            ", "learning_rate", "=", "self", ".", "params", ".", "learning_rate", "\n", "\n", "# Update the tracker memory", "\n", "", "if", "hard_negative_flag", "or", "self", ".", "frame_num", "%", "self", ".", "params", ".", "get", "(", "'train_sample_interval'", ",", "1", ")", "==", "0", ":", "\n", "            ", "self", ".", "update_memory", "(", "TensorList", "(", "[", "train_x", "]", ")", ",", "train_y", ",", "target_box", ",", "learning_rate", ")", "\n", "\n", "# Decide the number of iterations to run", "\n", "", "num_iter", "=", "0", "\n", "low_score_th", "=", "self", ".", "params", ".", "get", "(", "'low_score_opt_threshold'", ",", "None", ")", "\n", "if", "hard_negative_flag", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_hn_iter'", ",", "None", ")", "\n", "", "elif", "low_score_th", "is", "not", "None", "and", "low_score_th", ">", "scores", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_low_iter'", ",", "None", ")", "\n", "", "elif", "(", "self", ".", "frame_num", "-", "1", ")", "%", "self", ".", "params", ".", "train_skipping", "==", "0", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_update_iter'", ",", "None", ")", "\n", "\n", "", "plot_loss", "=", "self", ".", "params", ".", "debug", ">", "0", "\n", "\n", "if", "num_iter", ">", "0", ":", "\n", "# Get inputs for the DiMP filter optimizer module", "\n", "            ", "samples", "=", "self", ".", "training_samples", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", "...", "]", "\n", "target_labels", "=", "self", ".", "target_labels", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", "...", "]", "\n", "target_boxes", "=", "self", ".", "target_boxes", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", ":", "]", ".", "clone", "(", ")", "\n", "sample_weights", "=", "self", ".", "sample_weights", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", "]", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "self", ".", "net", ".", "classifier", ".", "compute_losses", "=", "plot_loss", "\n", "\n", "# Run the filter optimizer module", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "target_filter", ",", "_", ",", "losses", "=", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", "(", "TensorList", "(", "[", "self", ".", "target_filter", "]", ")", ",", "\n", "num_iter", "=", "num_iter", ",", "feat", "=", "samples", ",", "\n", "bb", "=", "target_boxes", ",", "\n", "train_label", "=", "target_labels", ",", "\n", "sample_weight", "=", "sample_weights", ")", "\n", "self", ".", "target_filter", "=", "target_filter", "[", "0", "]", "\n", "\n", "", "if", "plot_loss", ":", "\n", "                ", "if", "isinstance", "(", "losses", ",", "dict", ")", ":", "\n", "                    ", "losses", "=", "losses", "[", "'train'", "]", "\n", "", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "torch", ".", "stack", "(", "losses", ")", ")", ")", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                    ", "self", ".", "visdom", ".", "register", "(", "(", "self", ".", "losses", ",", "torch", ".", "arange", "(", "self", ".", "losses", ".", "numel", "(", ")", ")", ")", ",", "'lineplot'", ",", "3", ",", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "", "elif", "self", ".", "params", ".", "debug", ">=", "3", ":", "\n", "                    ", "plot_graph", "(", "self", ".", "losses", ",", "10", ",", "title", "=", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.refine_target_box": [[701, 763], ["hasattr", "dimp_simple.DiMPSimple.get_iounet_box", "dimp_simple.DiMPSimple.get_iou_features", "pytracking.TensorList", "dimp_simple.DiMPSimple.view().clone", "dimp_simple.DiMPSimple.optimize_boxes", "output_boxes[].clamp_", "dimp_simple.DiMPSimple.params.get", "min", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "output_boxes[].mean", "[].mean", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "new_pos.clone", "dimp_simple.DiMPSimple.params.get", "dimp_simple.DiMPSimple.direct_box_regression", "init_box[].prod().sqrt", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "predicted_box[].flip", "new_pos.clone", "dimp_simple.DiMPSimple.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "init_box[].min", "new_target_sz.prod", "dimp_simple.DiMPSimple.base_target_sz.prod", "init_box[].prod", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "dimp_simple.DiMPSimple.view", "output_iou.view", "new_pos.flip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_features", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.optimize_boxes", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.direct_box_regression", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "", "", "", "def", "refine_target_box", "(", "self", ",", "backbone_feat", ",", "sample_pos", ",", "sample_scale", ",", "scale_ind", ",", "update_scale", "=", "True", ")", ":", "\n", "        ", "\"\"\"Run the ATOM IoUNet to refine the target bounding box.\"\"\"", "\n", "\n", "if", "hasattr", "(", "self", ".", "net", ".", "bb_regressor", ",", "'predict_bb'", ")", ":", "\n", "            ", "return", "self", ".", "direct_box_regression", "(", "backbone_feat", ",", "sample_pos", ",", "sample_scale", ",", "scale_ind", ",", "update_scale", ")", "\n", "\n", "# Initial box for refinement", "\n", "", "init_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", ",", "sample_scale", ")", "\n", "\n", "# Extract features from the relevant scale", "\n", "iou_features", "=", "self", ".", "get_iou_features", "(", "backbone_feat", ")", "\n", "iou_features", "=", "TensorList", "(", "[", "x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "for", "x", "in", "iou_features", "]", ")", "\n", "\n", "# Generate random initial boxes", "\n", "init_boxes", "=", "init_box", ".", "view", "(", "1", ",", "4", ")", ".", "clone", "(", ")", "\n", "if", "self", ".", "params", ".", "num_init_random_boxes", ">", "0", ":", "\n", "            ", "square_box_sz", "=", "init_box", "[", "2", ":", "]", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "rand_factor", "=", "square_box_sz", "*", "torch", ".", "cat", "(", "[", "self", ".", "params", ".", "box_jitter_pos", "*", "torch", ".", "ones", "(", "2", ")", ",", "self", ".", "params", ".", "box_jitter_sz", "*", "torch", ".", "ones", "(", "2", ")", "]", ")", "\n", "\n", "minimal_edge_size", "=", "init_box", "[", "2", ":", "]", ".", "min", "(", ")", "/", "3", "\n", "rand_bb", "=", "(", "torch", ".", "rand", "(", "self", ".", "params", ".", "num_init_random_boxes", ",", "4", ")", "-", "0.5", ")", "*", "rand_factor", "\n", "new_sz", "=", "(", "init_box", "[", "2", ":", "]", "+", "rand_bb", "[", ":", ",", "2", ":", "]", ")", ".", "clamp", "(", "minimal_edge_size", ")", "\n", "new_center", "=", "(", "init_box", "[", ":", "2", "]", "+", "init_box", "[", "2", ":", "]", "/", "2", ")", "+", "rand_bb", "[", ":", ",", ":", "2", "]", "\n", "init_boxes", "=", "torch", ".", "cat", "(", "[", "new_center", "-", "new_sz", "/", "2", ",", "new_sz", "]", ",", "1", ")", "\n", "init_boxes", "=", "torch", ".", "cat", "(", "[", "init_box", ".", "view", "(", "1", ",", "4", ")", ",", "init_boxes", "]", ")", "\n", "\n", "# Optimize the boxes", "\n", "", "output_boxes", ",", "output_iou", "=", "self", ".", "optimize_boxes", "(", "iou_features", ",", "init_boxes", ")", "\n", "\n", "# Remove weird boxes", "\n", "output_boxes", "[", ":", ",", "2", ":", "]", ".", "clamp_", "(", "1", ")", "\n", "aspect_ratio", "=", "output_boxes", "[", ":", ",", "2", "]", "/", "output_boxes", "[", ":", ",", "3", "]", "\n", "keep_ind", "=", "(", "aspect_ratio", "<", "self", ".", "params", ".", "maximal_aspect_ratio", ")", "*", "(", "aspect_ratio", ">", "1", "/", "self", ".", "params", ".", "maximal_aspect_ratio", ")", "\n", "output_boxes", "=", "output_boxes", "[", "keep_ind", ",", ":", "]", "\n", "output_iou", "=", "output_iou", "[", "keep_ind", "]", "\n", "\n", "# If no box found", "\n", "if", "output_boxes", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "# Predict box", "\n", "", "k", "=", "self", ".", "params", ".", "get", "(", "'iounet_k'", ",", "5", ")", "\n", "topk", "=", "min", "(", "k", ",", "output_boxes", ".", "shape", "[", "0", "]", ")", "\n", "_", ",", "inds", "=", "torch", ".", "topk", "(", "output_iou", ",", "topk", ")", "\n", "predicted_box", "=", "output_boxes", "[", "inds", ",", ":", "]", ".", "mean", "(", "0", ")", "\n", "predicted_iou", "=", "output_iou", ".", "view", "(", "-", "1", ",", "1", ")", "[", "inds", ",", ":", "]", ".", "mean", "(", "0", ")", "\n", "\n", "# Get new position and size", "\n", "new_pos", "=", "predicted_box", "[", ":", "2", "]", "+", "predicted_box", "[", "2", ":", "]", "/", "2", "\n", "new_pos", "=", "(", "new_pos", ".", "flip", "(", "(", "0", ",", ")", ")", "-", "(", "self", ".", "img_sample_sz", "-", "1", ")", "/", "2", ")", "*", "sample_scale", "+", "sample_pos", "\n", "new_target_sz", "=", "predicted_box", "[", "2", ":", "]", ".", "flip", "(", "(", "0", ",", ")", ")", "*", "sample_scale", "\n", "new_scale", "=", "torch", ".", "sqrt", "(", "new_target_sz", ".", "prod", "(", ")", "/", "self", ".", "base_target_sz", ".", "prod", "(", ")", ")", "\n", "\n", "self", ".", "pos_iounet", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iounet_pos_for_learning'", ",", "True", ")", ":", "\n", "            ", "self", ".", "pos", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "", "self", ".", "target_sz", "=", "new_target_sz", "\n", "\n", "if", "update_scale", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.optimize_boxes": [[767, 774], ["dimp_simple.DiMPSimple.params.get", "ValueError", "dimp_simple.DiMPSimple.optimize_boxes_default", "dimp_simple.DiMPSimple.optimize_boxes_relative"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.optimize_boxes_default", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.optimize_boxes_relative"], ["", "", "def", "optimize_boxes", "(", "self", ",", "iou_features", ",", "init_boxes", ")", ":", "\n", "        ", "box_refinement_space", "=", "self", ".", "params", ".", "get", "(", "'box_refinement_space'", ",", "'default'", ")", "\n", "if", "box_refinement_space", "==", "'default'", ":", "\n", "            ", "return", "self", ".", "optimize_boxes_default", "(", "iou_features", ",", "init_boxes", ")", "\n", "", "if", "box_refinement_space", "==", "'relative'", ":", "\n", "            ", "return", "self", ".", "optimize_boxes_relative", "(", "iou_features", ",", "init_boxes", ")", "\n", "", "raise", "ValueError", "(", "'Unknown box_refinement_space {}'", ".", "format", "(", "box_refinement_space", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.optimize_boxes_default": [[776, 802], ["init_boxes.view().to", "isinstance", "range", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "init_boxes.view().to.clone().detach", "dimp_simple.DiMPSimple.net.bb_regressor.predict_iou", "isinstance", "dimp_simple.DiMPSimple.backward", "init_boxes.view().to.detach_", "init_boxes.view().to.view().cpu", "dimp_simple.DiMPSimple.detach().view().cpu", "init_boxes.view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "init_boxes.view().to.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "bb_init[].repeat", "init_boxes.view().to.view", "dimp_simple.DiMPSimple.detach().view", "dimp_simple.DiMPSimple.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou"], ["", "def", "optimize_boxes_default", "(", "self", ",", "iou_features", ",", "init_boxes", ")", ":", "\n", "        ", "\"\"\"Optimize iounet boxes with the default parametrization\"\"\"", "\n", "output_boxes", "=", "init_boxes", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "step_length", "=", "self", ".", "params", ".", "box_refinement_step_length", "\n", "if", "isinstance", "(", "step_length", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "step_length", "=", "torch", ".", "Tensor", "(", "[", "step_length", "[", "0", "]", ",", "step_length", "[", "0", "]", ",", "step_length", "[", "1", "]", ",", "step_length", "[", "1", "]", "]", ",", "device", "=", "self", ".", "params", ".", "device", ")", ".", "view", "(", "1", ",", "1", ",", "4", ")", "\n", "\n", "", "for", "i_", "in", "range", "(", "self", ".", "params", ".", "box_refinement_iter", ")", ":", "\n", "# forward pass", "\n", "            ", "bb_init", "=", "output_boxes", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "bb_init", ".", "requires_grad", "=", "True", "\n", "\n", "outputs", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_iou", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "bb_init", ")", "\n", "\n", "if", "isinstance", "(", "outputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "outputs", "=", "outputs", "[", "0", "]", "\n", "\n", "", "outputs", ".", "backward", "(", "gradient", "=", "torch", ".", "ones_like", "(", "outputs", ")", ")", "\n", "\n", "# Update proposal", "\n", "output_boxes", "=", "bb_init", "+", "step_length", "*", "bb_init", ".", "grad", "*", "bb_init", "[", ":", ",", ":", ",", "2", ":", "]", ".", "repeat", "(", "1", ",", "1", ",", "2", ")", "\n", "output_boxes", ".", "detach_", "(", ")", "\n", "\n", "step_length", "*=", "self", ".", "params", ".", "box_refinement_step_decay", "\n", "\n", "", "return", "output_boxes", ".", "view", "(", "-", "1", ",", "4", ")", ".", "cpu", "(", ")", ",", "outputs", ".", "detach", "(", ")", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.optimize_boxes_relative": [[804, 840], ["init_boxes.view().to", "isinstance", "output_boxes[].clone", "ltr.rect_to_rel", "range", "ltr.rel_to_rect", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "ltr.rect_to_rel.clone().detach", "ltr.rel_to_rect", "dimp_simple.DiMPSimple.net.bb_regressor.predict_iou", "isinstance", "dimp_simple.DiMPSimple.backward", "ltr.rect_to_rel.detach_", "ltr.rel_to_rect.view().cpu", "dimp_simple.DiMPSimple.detach().view().cpu", "init_boxes.view", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "ltr.rect_to_rel.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "ltr.rel_to_rect.view", "dimp_simple.DiMPSimple.detach().view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "dimp_simple.DiMPSimple.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rect_to_rel", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "optimize_boxes_relative", "(", "self", ",", "iou_features", ",", "init_boxes", ")", ":", "\n", "        ", "\"\"\"Optimize iounet boxes with the relative parametrization ised in PrDiMP\"\"\"", "\n", "output_boxes", "=", "init_boxes", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "step_length", "=", "self", ".", "params", ".", "box_refinement_step_length", "\n", "if", "isinstance", "(", "step_length", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "step_length", "=", "torch", ".", "Tensor", "(", "[", "step_length", "[", "0", "]", ",", "step_length", "[", "0", "]", ",", "step_length", "[", "1", "]", ",", "step_length", "[", "1", "]", "]", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", ".", "view", "(", "1", ",", "1", ",", "4", ")", "\n", "\n", "", "sz_norm", "=", "output_boxes", "[", ":", ",", ":", "1", ",", "2", ":", "]", ".", "clone", "(", ")", "\n", "output_boxes_rel", "=", "bbutils", ".", "rect_to_rel", "(", "output_boxes", ",", "sz_norm", ")", "\n", "for", "i_", "in", "range", "(", "self", ".", "params", ".", "box_refinement_iter", ")", ":", "\n", "# forward pass", "\n", "            ", "bb_init_rel", "=", "output_boxes_rel", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "bb_init_rel", ".", "requires_grad", "=", "True", "\n", "\n", "bb_init", "=", "bbutils", ".", "rel_to_rect", "(", "bb_init_rel", ",", "sz_norm", ")", "\n", "outputs", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_iou", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "bb_init", ")", "\n", "\n", "if", "isinstance", "(", "outputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "outputs", "=", "outputs", "[", "0", "]", "\n", "\n", "", "outputs", ".", "backward", "(", "gradient", "=", "torch", ".", "ones_like", "(", "outputs", ")", ")", "\n", "\n", "# Update proposal", "\n", "output_boxes_rel", "=", "bb_init_rel", "+", "step_length", "*", "bb_init_rel", ".", "grad", "\n", "output_boxes_rel", ".", "detach_", "(", ")", "\n", "\n", "step_length", "*=", "self", ".", "params", ".", "box_refinement_step_decay", "\n", "\n", "#     for s in outputs.view(-1):", "\n", "#         print('{:.2f}  '.format(s.item()), end='')", "\n", "#     print('')", "\n", "# print('')", "\n", "\n", "", "output_boxes", "=", "bbutils", ".", "rel_to_rect", "(", "output_boxes_rel", ",", "sz_norm", ")", "\n", "\n", "return", "output_boxes", ".", "view", "(", "-", "1", ",", "4", ")", ".", "cpu", "(", ")", ",", "outputs", ".", "detach", "(", ")", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.direct_box_regression": [[841, 878], ["dimp_simple.DiMPSimple.get_iounet_box", "dimp_simple.DiMPSimple.get_iou_features", "pytracking.TensorList", "dimp_simple.DiMPSimple.view().clone().to", "dimp_simple.DiMPSimple.net.bb_regressor.predict_bb().view().cpu", "output_boxes[].clamp_", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "new_pos.clone", "dimp_simple.DiMPSimple.params.get", "predicted_box[].flip", "new_pos.clone", "dimp_simple.DiMPSimple.view().clone", "dimp_simple.DiMPSimple.net.bb_regressor.predict_bb().view", "new_target_sz.prod", "dimp_simple.DiMPSimple.base_target_sz.prod", "new_pos.flip", "dimp_simple.DiMPSimple.view", "dimp_simple.DiMPSimple.net.bb_regressor.predict_bb"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_features", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "direct_box_regression", "(", "self", ",", "backbone_feat", ",", "sample_pos", ",", "sample_scale", ",", "scale_ind", ",", "update_scale", "=", "True", ")", ":", "\n", "        ", "\"\"\"Implementation of direct bounding box regression.\"\"\"", "\n", "\n", "# Initial box for refinement", "\n", "init_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", ",", "sample_scale", ")", "\n", "\n", "# Extract features from the relevant scale", "\n", "iou_features", "=", "self", ".", "get_iou_features", "(", "backbone_feat", ")", "\n", "iou_features", "=", "TensorList", "(", "[", "x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "for", "x", "in", "iou_features", "]", ")", "\n", "\n", "# Generate random initial boxes", "\n", "init_boxes", "=", "init_box", ".", "view", "(", "1", ",", "1", ",", "4", ")", ".", "clone", "(", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "# Optimize the boxes", "\n", "output_boxes", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_bb", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "init_boxes", ")", ".", "view", "(", "-", "1", ",", "4", ")", ".", "cpu", "(", ")", "\n", "\n", "# Remove weird boxes", "\n", "output_boxes", "[", ":", ",", "2", ":", "]", ".", "clamp_", "(", "1", ")", "\n", "\n", "predicted_box", "=", "output_boxes", "[", "0", ",", ":", "]", "\n", "\n", "# Get new position and size", "\n", "new_pos", "=", "predicted_box", "[", ":", "2", "]", "+", "predicted_box", "[", "2", ":", "]", "/", "2", "\n", "new_pos", "=", "(", "new_pos", ".", "flip", "(", "(", "0", ",", ")", ")", "-", "(", "self", ".", "img_sample_sz", "-", "1", ")", "/", "2", ")", "*", "sample_scale", "+", "sample_pos", "\n", "new_target_sz", "=", "predicted_box", "[", "2", ":", "]", ".", "flip", "(", "(", "0", ",", ")", ")", "*", "sample_scale", "\n", "new_scale_bbr", "=", "torch", ".", "sqrt", "(", "new_target_sz", ".", "prod", "(", ")", "/", "self", ".", "base_target_sz", ".", "prod", "(", ")", ")", "\n", "new_scale", "=", "new_scale_bbr", "\n", "\n", "self", ".", "pos_iounet", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iounet_pos_for_learning'", ",", "True", ")", ":", "\n", "            ", "self", ".", "pos", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "", "self", ".", "target_sz", "=", "new_target_sz", "\n", "\n", "if", "update_scale", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.visualize_iou_pred": [[880, 910], ["center_box.view.view.view", "center_box[].clone", "ltr.rect_to_rel", "math.log", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange.clone", "torch.arange.clone", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange.clone", "torch.arange.clone", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange.clone", "torch.arange.clone", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange.clone", "torch.arange.clone", "ltr.rel_to_rect().view().to", "ltr.rel_to_rect().view().to", "dimp_simple.DiMPSimple.net.bb_regressor.predict_iou().exp", "dimp_simple.DiMPSimple.net.bb_regressor.predict_iou().exp", "pytracking.utils.plotting.show_tensor", "pytracking.utils.plotting.show_tensor", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "dimp_simple.DiMPSimple.view", "dimp_simple.DiMPSimple.view", "ltr.rel_to_rect().view", "ltr.rel_to_rect().view", "dimp_simple.DiMPSimple.net.bb_regressor.predict_iou", "dimp_simple.DiMPSimple.net.bb_regressor.predict_iou", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "ltr.rel_to_rect", "ltr.rel_to_rect"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rect_to_rel", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_tensor", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_tensor", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect"], ["", "", "def", "visualize_iou_pred", "(", "self", ",", "iou_features", ",", "center_box", ")", ":", "\n", "        ", "center_box", "=", "center_box", ".", "view", "(", "1", ",", "1", ",", "4", ")", "\n", "sz_norm", "=", "center_box", "[", "...", ",", "2", ":", "]", ".", "clone", "(", ")", "\n", "center_box_rel", "=", "bbutils", ".", "rect_to_rel", "(", "center_box", ",", "sz_norm", ")", "\n", "\n", "pos_dist", "=", "1.0", "\n", "sz_dist", "=", "math", ".", "log", "(", "3.0", ")", "\n", "pos_step", "=", "0.01", "\n", "sz_step", "=", "0.01", "\n", "\n", "pos_scale", "=", "torch", ".", "arange", "(", "-", "pos_dist", ",", "pos_dist", "+", "pos_step", ",", "step", "=", "pos_step", ")", "\n", "sz_scale", "=", "torch", ".", "arange", "(", "-", "sz_dist", ",", "sz_dist", "+", "sz_step", ",", "step", "=", "sz_step", ")", "\n", "\n", "bbx", "=", "torch", ".", "zeros", "(", "1", ",", "pos_scale", ".", "numel", "(", ")", ",", "4", ")", "\n", "bbx", "[", "0", ",", ":", ",", "0", "]", "=", "pos_scale", ".", "clone", "(", ")", "\n", "bby", "=", "torch", ".", "zeros", "(", "pos_scale", ".", "numel", "(", ")", ",", "1", ",", "4", ")", "\n", "bby", "[", ":", ",", "0", ",", "1", "]", "=", "pos_scale", ".", "clone", "(", ")", "\n", "bbw", "=", "torch", ".", "zeros", "(", "1", ",", "sz_scale", ".", "numel", "(", ")", ",", "4", ")", "\n", "bbw", "[", "0", ",", ":", ",", "2", "]", "=", "sz_scale", ".", "clone", "(", ")", "\n", "bbh", "=", "torch", ".", "zeros", "(", "sz_scale", ".", "numel", "(", ")", ",", "1", ",", "4", ")", "\n", "bbh", "[", ":", ",", "0", ",", "3", "]", "=", "sz_scale", ".", "clone", "(", ")", "\n", "\n", "pos_boxes", "=", "bbutils", ".", "rel_to_rect", "(", "(", "center_box_rel", "+", "bbx", ")", "+", "bby", ",", "sz_norm", ")", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "sz_boxes", "=", "bbutils", ".", "rel_to_rect", "(", "(", "center_box_rel", "+", "bbw", ")", "+", "bbh", ",", "sz_norm", ")", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "pos_scores", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_iou", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "pos_boxes", ")", ".", "exp", "(", ")", "\n", "sz_scores", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_iou", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "sz_boxes", ")", ".", "exp", "(", ")", "\n", "\n", "show_tensor", "(", "pos_scores", ".", "view", "(", "pos_scale", ".", "numel", "(", ")", ",", "-", "1", ")", ",", "title", "=", "'Position scores'", ",", "fig_num", "=", "21", ")", "\n", "show_tensor", "(", "sz_scores", ".", "view", "(", "sz_scale", ".", "numel", "(", ")", ",", "-", "1", ")", ",", "title", "=", "'Size scores'", ",", "fig_num", "=", "22", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.dimp_simple.DiMPSimple.visdom_draw_tracking": [[912, 917], ["hasattr", "dimp_simple.DiMPSimple.visdom.register", "dimp_simple.DiMPSimple.visdom.register"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register"], ["", "def", "visdom_draw_tracking", "(", "self", ",", "image", ",", "box", ",", "segmentation", "=", "None", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "'search_area_box'", ")", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "box", ",", "self", ".", "search_area_box", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "box", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp_simple.__init__.get_tracker_class": [[3, 5], ["None"], "function", ["None"], ["import", "pytracking", ".", "libs", ".", "operation", "as", "operation", "\n", "import", "pytracking", ".", "libs", ".", "fourier", "as", "fourier", "\n", "import", "pytracking", ".", "libs", ".", "dcf", "as", "dcf", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.default.parameters": [[6, 98], ["pytracking.utils.TrackerParams", "pytracking.utils.TrackerParams", "pytracking.utils.TrackerParams", "pytracking.utils.FeatureParams", "pytracking.features.deep.ResNet18m1", "pytracking.features.extractor.MultiResolutionExtractor", "torch.arange().float", "torch.arange"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "# Feature specific parameters", "\n", "shallow_params", "=", "TrackerParams", "(", ")", "\n", "deep_params", "=", "TrackerParams", "(", ")", "\n", "\n", "# Patch sampling parameters", "\n", "params", ".", "max_image_sample_size", "=", "250", "**", "2", "# Maximum image sample size", "\n", "params", ".", "min_image_sample_size", "=", "200", "**", "2", "# Minimum image sample size", "\n", "params", ".", "search_area_scale", "=", "4.5", "# Scale relative to target size", "\n", "\n", "# Conjugate Gradient parameters", "\n", "params", ".", "CG_iter", "=", "5", "# The number of Conjugate Gradient iterations in each update after the first frame", "\n", "params", ".", "init_CG_iter", "=", "100", "# The total number of Conjugate Gradient iterations used in the first frame", "\n", "params", ".", "init_GN_iter", "=", "10", "# The number of Gauss-Newton iterations used in the first frame (only if the projection matrix is updated)", "\n", "params", ".", "post_init_CG_iter", "=", "0", "# CG iterations to run after GN", "\n", "params", ".", "fletcher_reeves", "=", "False", "# Use the Fletcher-Reeves (true) or Polak-Ribiere (false) formula in the Conjugate Gradient", "\n", "params", ".", "standard_alpha", "=", "True", "# Use the standard formula for computing the step length in Conjugate Gradient", "\n", "params", ".", "CG_forgetting_rate", "=", "75", "# Forgetting rate of the last conjugate direction", "\n", "params", ".", "precond_data_param", "=", "0.3", "# Weight of the data term in the preconditioner", "\n", "params", ".", "precond_reg_param", "=", "0.15", "# Weight of the regularization term in the preconditioner", "\n", "params", ".", "precond_proj_param", "=", "35", "# Weight of the projection matrix part in the preconditioner", "\n", "\n", "# Learning parameters", "\n", "shallow_params", ".", "learning_rate", "=", "0.025", "\n", "deep_params", ".", "learning_rate", "=", "0.0075", "\n", "shallow_params", ".", "output_sigma_factor", "=", "1", "/", "16", "\n", "deep_params", ".", "output_sigma_factor", "=", "1", "/", "4", "\n", "\n", "# Training parameters", "\n", "params", ".", "sample_memory_size", "=", "200", "# Memory size", "\n", "params", ".", "train_skipping", "=", "10", "# How often to run training (every n-th frame)", "\n", "\n", "# Detection parameters", "\n", "params", ".", "scale_factors", "=", "1.02", "**", "torch", ".", "arange", "(", "-", "2", ",", "3", ")", ".", "float", "(", ")", "# What scales to use for localization", "\n", "params", ".", "score_upsample_factor", "=", "1", "# How much Fourier upsampling to use", "\n", "params", ".", "score_fusion_strategy", "=", "'weightedsum'", "# Fusion strategy", "\n", "shallow_params", ".", "translation_weight", "=", "0.4", "# Weight of this feature", "\n", "deep_params", ".", "translation_weight", "=", "1", "-", "shallow_params", ".", "translation_weight", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'shift'", ":", "[", "(", "6", ",", "6", ")", ",", "(", "-", "6", ",", "6", ")", ",", "(", "6", ",", "-", "6", ")", ",", "(", "-", "6", ",", "-", "6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "# Whether to use augmentation for this feature", "\n", "deep_params", ".", "use_augmentation", "=", "True", "\n", "shallow_params", ".", "use_augmentation", "=", "True", "\n", "\n", "# Factorized convolution parameters", "\n", "# params.use_projection_matrix = True    # Use projection matrix, i.e. use the factorized convolution formulation", "\n", "params", ".", "update_projection_matrix", "=", "True", "# Whether the projection matrix should be optimized or not", "\n", "# params.proj_init_method = 'pca'        # Method for initializing the projection matrix", "\n", "params", ".", "projection_reg", "=", "5e-8", "# Regularization parameter of the projection matrix", "\n", "shallow_params", ".", "compressed_dim", "=", "16", "# Dimension output of projection matrix for shallow features", "\n", "deep_params", ".", "compressed_dim", "=", "64", "# Dimension output of projection matrix for deep features", "\n", "\n", "# Interpolation parameters", "\n", "params", ".", "interpolation_method", "=", "'bicubic'", "# The kind of interpolation kernel", "\n", "params", ".", "interpolation_bicubic_a", "=", "-", "0.75", "# The parameter for the bicubic interpolation kernel", "\n", "params", ".", "interpolation_centering", "=", "True", "# Center the kernel at the feature sample", "\n", "params", ".", "interpolation_windowing", "=", "False", "# Do additional windowing on the Fourier coefficients of the kernel", "\n", "\n", "# Regularization parameters", "\n", "shallow_params", ".", "use_reg_window", "=", "True", "# Use spatial regularization or not", "\n", "shallow_params", ".", "reg_window_min", "=", "1e-4", "# The minimum value of the regularization window", "\n", "shallow_params", ".", "reg_window_edge", "=", "10e-3", "# The impact of the spatial regularization", "\n", "shallow_params", ".", "reg_window_power", "=", "2", "# The degree of the polynomial to use (e.g. 2 is a quadratic window)", "\n", "shallow_params", ".", "reg_sparsity_threshold", "=", "0.05", "# A relative threshold of which DFT coefficients that should be set to zero", "\n", "\n", "deep_params", ".", "use_reg_window", "=", "True", "# Use spatial regularization or not", "\n", "deep_params", ".", "reg_window_min", "=", "10e-4", "# The minimum value of the regularization window", "\n", "deep_params", ".", "reg_window_edge", "=", "50e-3", "# The impact of the spatial regularization", "\n", "deep_params", ".", "reg_window_power", "=", "2", "# The degree of the polynomial to use (e.g. 2 is a quadratic window)", "\n", "deep_params", ".", "reg_sparsity_threshold", "=", "0.1", "# A relative threshold of which DFT coefficients that should be set to zero", "\n", "\n", "\n", "fparams", "=", "FeatureParams", "(", "feature_params", "=", "[", "shallow_params", ",", "deep_params", "]", ")", "\n", "features", "=", "deep", ".", "ResNet18m1", "(", "output_layers", "=", "[", "'vggconv1'", ",", "'layer3'", "]", ",", "use_gpu", "=", "params", ".", "use_gpu", ",", "fparams", "=", "fparams", ",", "\n", "pool_stride", "=", "[", "2", ",", "1", "]", ",", "normalize_power", "=", "2", ")", "\n", "\n", "params", ".", "features", "=", "MultiResolutionExtractor", "(", "[", "features", "]", ")", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.mobile3.parameters": [[6, 98], ["pytracking.utils.TrackerParams", "pytracking.utils.TrackerParams", "pytracking.utils.TrackerParams", "pytracking.utils.FeatureParams", "pytracking.features.deep.Mobilenet", "pytracking.features.extractor.MultiResolutionExtractor", "torch.arange().float", "torch.arange"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "False", "\n", "\n", "# Feature specific parameters", "\n", "shallow_params", "=", "TrackerParams", "(", ")", "\n", "deep_params", "=", "TrackerParams", "(", ")", "\n", "\n", "# Patch sampling parameters", "\n", "params", ".", "max_image_sample_size", "=", "250", "**", "2", "# Maximum image sample size", "\n", "params", ".", "min_image_sample_size", "=", "200", "**", "2", "# Minimum image sample size", "\n", "params", ".", "search_area_scale", "=", "4.5", "# Scale relative to target size", "\n", "\n", "# Conjugate Gradient parameters", "\n", "params", ".", "CG_iter", "=", "5", "# The number of Conjugate Gradient iterations in each update after the first frame", "\n", "params", ".", "init_CG_iter", "=", "100", "# The total number of Conjugate Gradient iterations used in the first frame", "\n", "params", ".", "init_GN_iter", "=", "10", "# The number of Gauss-Newton iterations used in the first frame (only if the projection matrix is updated)", "\n", "params", ".", "post_init_CG_iter", "=", "0", "# CG iterations to run after GN", "\n", "params", ".", "fletcher_reeves", "=", "False", "# Use the Fletcher-Reeves (true) or Polak-Ribiere (false) formula in the Conjugate Gradient", "\n", "params", ".", "standard_alpha", "=", "True", "# Use the standard formula for computing the step length in Conjugate Gradient", "\n", "params", ".", "CG_forgetting_rate", "=", "75", "# Forgetting rate of the last conjugate direction", "\n", "params", ".", "precond_data_param", "=", "0.3", "# Weight of the data term in the preconditioner", "\n", "params", ".", "precond_reg_param", "=", "0.15", "# Weight of the regularization term in the preconditioner", "\n", "params", ".", "precond_proj_param", "=", "35", "# Weight of the projection matrix part in the preconditioner", "\n", "\n", "# Learning parameters", "\n", "shallow_params", ".", "learning_rate", "=", "0.025", "\n", "deep_params", ".", "learning_rate", "=", "0.0075", "\n", "shallow_params", ".", "output_sigma_factor", "=", "1", "/", "16", "\n", "deep_params", ".", "output_sigma_factor", "=", "1", "/", "4", "\n", "\n", "# Training parameters", "\n", "params", ".", "sample_memory_size", "=", "200", "# Memory size", "\n", "params", ".", "train_skipping", "=", "10", "# How often to run training (every n-th frame)", "\n", "\n", "# Detection parameters", "\n", "params", ".", "scale_factors", "=", "1.02", "**", "torch", ".", "arange", "(", "-", "2", ",", "3", ")", ".", "float", "(", ")", "# What scales to use for localization", "\n", "params", ".", "score_upsample_factor", "=", "1", "# How much Fourier upsampling to use", "\n", "params", ".", "score_fusion_strategy", "=", "'weightedsum'", "# Fusion strategy", "\n", "shallow_params", ".", "translation_weight", "=", "0.4", "# Weight of this feature", "\n", "deep_params", ".", "translation_weight", "=", "1", "-", "shallow_params", ".", "translation_weight", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'shift'", ":", "[", "(", "6", ",", "6", ")", ",", "(", "-", "6", ",", "6", ")", ",", "(", "6", ",", "-", "6", ")", ",", "(", "-", "6", ",", "-", "6", ")", "]", "}", "\n", "#                       'dropout': (7, 0.2)}", "\n", "\n", "# Whether to use augmentation for this feature", "\n", "deep_params", ".", "use_augmentation", "=", "True", "\n", "shallow_params", ".", "use_augmentation", "=", "True", "\n", "\n", "# Factorized convolution parameters", "\n", "# params.use_projection_matrix = True    # Use projection matrix, i.e. use the factorized convolution formulation", "\n", "params", ".", "update_projection_matrix", "=", "True", "# Whether the projection matrix should be optimized or not", "\n", "# params.proj_init_method = 'pca'        # Method for initializing the projection matrix", "\n", "params", ".", "projection_reg", "=", "5e-8", "# Regularization parameter of the projection matrix", "\n", "shallow_params", ".", "compressed_dim", "=", "16", "# Dimension output of projection matrix for shallow features", "\n", "deep_params", ".", "compressed_dim", "=", "64", "# Dimension output of projection matrix for deep features", "\n", "\n", "# Interpolation parameters", "\n", "params", ".", "interpolation_method", "=", "'bicubic'", "# The kind of interpolation kernel", "\n", "params", ".", "interpolation_bicubic_a", "=", "-", "0.75", "# The parameter for the bicubic interpolation kernel", "\n", "params", ".", "interpolation_centering", "=", "True", "# Center the kernel at the feature sample", "\n", "params", ".", "interpolation_windowing", "=", "False", "# Do additional windowing on the Fourier coefficients of the kernel", "\n", "\n", "# Regularization parameters", "\n", "shallow_params", ".", "use_reg_window", "=", "True", "# Use spatial regularization or not", "\n", "shallow_params", ".", "reg_window_min", "=", "1e-4", "# The minimum value of the regularization window", "\n", "shallow_params", ".", "reg_window_edge", "=", "10e-3", "# The impact of the spatial regularization", "\n", "shallow_params", ".", "reg_window_power", "=", "2", "# The degree of the polynomial to use (e.g. 2 is a quadratic window)", "\n", "shallow_params", ".", "reg_sparsity_threshold", "=", "0.05", "# A relative threshold of which DFT coefficients that should be set to zero", "\n", "\n", "deep_params", ".", "use_reg_window", "=", "True", "# Use spatial regularization or not", "\n", "deep_params", ".", "reg_window_min", "=", "10e-4", "# The minimum value of the regularization window", "\n", "deep_params", ".", "reg_window_edge", "=", "50e-3", "# The impact of the spatial regularization", "\n", "deep_params", ".", "reg_window_power", "=", "2", "# The degree of the polynomial to use (e.g. 2 is a quadratic window)", "\n", "deep_params", ".", "reg_sparsity_threshold", "=", "0.1", "# A relative threshold of which DFT coefficients that should be set to zero", "\n", "\n", "\n", "fparams", "=", "FeatureParams", "(", "feature_params", "=", "[", "shallow_params", ",", "deep_params", "]", ")", "\n", "features", "=", "deep", ".", "Mobilenet", "(", "output_layers", "=", "[", "'init_conv'", ",", "'layer5'", "]", ",", "use_gpu", "=", "params", ".", "use_gpu", ",", "fparams", "=", "fparams", ",", "\n", "pool_stride", "=", "[", "1", ",", "1", "]", ",", "normalize_power", "=", "2", ")", "\n", "\n", "params", ".", "features", "=", "MultiResolutionExtractor", "(", "[", "features", "]", ")", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.__init__.get_tracker_class": [[3, 5], ["None"], "function", ["None"], ["import", "pytracking", ".", "libs", ".", "operation", "as", "operation", "\n", "import", "pytracking", ".", "libs", ".", "fourier", "as", "fourier", "\n", "import", "pytracking", ".", "libs", ".", "dcf", "as", "dcf", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FactorizedConvProblem.__init__": [[9, 32], ["pytracking.complex.complex().permute", "pytracking.complex.mtimes", "pytracking.complex.abs_sqr().mean().permute", "optim.FactorizedConvProblem.diag_M.unsqueeze_", "optim.FactorizedConvProblem.diag_M.extend", "sample_weights.sqrt", "optim.FactorizedConvProblem.reg_filter.view", "optim.FactorizedConvProblem.reg_filter.view", "optim.FactorizedConvProblem.training_samples.size", "pytracking.complex.complex", "pytracking.complex.abs_sqr().mean", "pytracking.fourier.inner_prod_fs", "pytracking.complex.abs_sqr", "optim.FactorizedConvProblem.sample_energy.mean"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mtimes", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.complex", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.inner_prod_fs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs_sqr", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["    ", "def", "__init__", "(", "self", ",", "training_samples", ":", "TensorList", ",", "yf", ":", "TensorList", ",", "reg_filter", ":", "torch", ".", "Tensor", ",", "init_proj_mat", ":", "TensorList", ",", "params", ",", "sample_weights", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "        ", "self", ".", "training_samples", "=", "training_samples", "\n", "self", ".", "yf", "=", "complex", ".", "complex", "(", "yf", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ",", "4", ")", "\n", "self", ".", "reg_filter", "=", "reg_filter", "\n", "self", ".", "sample_weights_sqrt", "=", "None", "if", "sample_weights", "is", "None", "else", "sample_weights", ".", "sqrt", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "\n", "# Sample energy for preconditioner", "\n", "compressed_samples", "=", "complex", ".", "mtimes", "(", "self", ".", "training_samples", ",", "init_proj_mat", ")", "\n", "self", ".", "sample_energy", "=", "complex", ".", "abs_sqr", "(", "compressed_samples", ")", ".", "mean", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", "\n", "self", ".", "reg_energy", "=", "self", ".", "reg_filter", ".", "view", "(", "-", "1", ")", "@", "self", ".", "reg_filter", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Projection energy for preconditioner", "\n", "self", ".", "proj_energy", "=", "2", "*", "fourier", ".", "inner_prod_fs", "(", "yf", ",", "yf", ")", "/", "self", ".", "training_samples", ".", "size", "(", "3", ")", "\n", "\n", "# Filter part of preconditioner", "\n", "self", ".", "diag_M", "=", "(", "1", "-", "self", ".", "params", ".", "precond_reg_param", ")", "*", "(", "self", ".", "params", ".", "precond_data_param", "*", "self", ".", "sample_energy", "+", "\n", "(", "1", "-", "self", ".", "params", ".", "precond_data_param", ")", "*", "self", ".", "sample_energy", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", ")", "+", "self", ".", "params", ".", "precond_reg_param", "*", "self", ".", "reg_energy", "\n", "self", ".", "diag_M", ".", "unsqueeze_", "(", "-", "1", ")", "\n", "\n", "# Projection matrix part of preconditioner", "\n", "self", ".", "diag_M", ".", "extend", "(", "self", ".", "params", ".", "precond_proj_param", "*", "(", "self", ".", "proj_energy", "+", "self", ".", "params", ".", "projection_reg", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FactorizedConvProblem.__call__": [[34, 75], ["pytracking.complex.mtimes", "pytracking.complex.mtimes", "zip", "pytracking.complex.mult.extend", "hf.permute", "pytracking.complex.mult", "min", "min", "hfe.clone.permute().reshape", "torch.conv2d", "torch.conv2d", "pytracking.complex.mult.append", "optim.FactorizedConvProblem.sample_weights_sqrt.view", "pytracking.complex.conj", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hfe.clone", "math.sqrt", "len", "len", "hfe[].clone().detach().flip", "hfe.clone.permute", "hfe[].clone().detach", "hfe[].clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mtimes", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mtimes", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.conj"], ["", "def", "__call__", "(", "self", ",", "x", ":", "TensorList", ")", ":", "\n", "        ", "\"\"\"\n        Compute residuals\n        :param x: [filters, projection_matrices]\n        :return: [data_terms, filter_regularizations, proj_mat_regularizations]\n        \"\"\"", "\n", "hf", "=", "x", "[", ":", "len", "(", "x", ")", "//", "2", "]", "\n", "P", "=", "x", "[", "len", "(", "x", ")", "//", "2", ":", "]", "\n", "\n", "compressed_samples", "=", "complex", ".", "mtimes", "(", "self", ".", "training_samples", ",", "P", ")", "\n", "residuals", "=", "complex", ".", "mtimes", "(", "compressed_samples", ",", "hf", ".", "permute", "(", "2", ",", "3", ",", "1", ",", "0", ",", "4", ")", ")", "# (h, w, num_samp, num_filt, 2)", "\n", "residuals", "=", "residuals", "-", "self", ".", "yf", "\n", "\n", "if", "self", ".", "sample_weights_sqrt", "is", "not", "None", ":", "\n", "            ", "residuals", "=", "complex", ".", "mult", "(", "self", ".", "sample_weights_sqrt", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", ",", "residuals", ")", "\n", "\n", "\n", "# Add spatial regularization", "\n", "", "for", "hfe", ",", "reg_filter", "in", "zip", "(", "hf", ",", "self", ".", "reg_filter", ")", ":", "\n", "            ", "reg_pad1", "=", "min", "(", "reg_filter", ".", "shape", "[", "-", "2", "]", "-", "1", ",", "hfe", ".", "shape", "[", "-", "3", "]", "-", "1", ")", "\n", "reg_pad2", "=", "min", "(", "reg_filter", ".", "shape", "[", "-", "1", "]", "-", "1", ",", "hfe", ".", "shape", "[", "-", "2", "]", "-", "1", ")", "\n", "\n", "# Add part needed for convolution", "\n", "if", "reg_pad2", ">", "0", ":", "\n", "                ", "hfe_left_padd", "=", "complex", ".", "conj", "(", "hfe", "[", "...", ",", "1", ":", "reg_pad2", "+", "1", ",", ":", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "flip", "(", "(", "2", ",", "3", ")", ")", ")", "\n", "hfe_conv", "=", "torch", ".", "cat", "(", "[", "hfe_left_padd", ",", "hfe", "]", ",", "-", "2", ")", "\n", "", "else", ":", "\n", "                ", "hfe_conv", "=", "hfe", ".", "clone", "(", ")", "\n", "\n", "# Shift data to batch dimension", "\n", "", "hfe_conv", "=", "hfe_conv", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", ".", "reshape", "(", "-", "1", ",", "1", ",", "hfe_conv", ".", "shape", "[", "-", "3", "]", ",", "hfe_conv", ".", "shape", "[", "-", "2", "]", ")", "\n", "\n", "# Do first convolution", "\n", "hfe_conv", "=", "F", ".", "conv2d", "(", "hfe_conv", ",", "reg_filter", ",", "padding", "=", "(", "reg_pad1", ",", "reg_pad2", ")", ")", "\n", "\n", "residuals", ".", "append", "(", "hfe_conv", ")", "\n", "\n", "# Add regularization for projection matrix", "\n", "", "residuals", ".", "extend", "(", "math", ".", "sqrt", "(", "self", ".", "params", ".", "projection_reg", ")", "*", "P", ")", "\n", "\n", "return", "residuals", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FactorizedConvProblem.ip_input": [[77, 92], ["pytracking.fourier.inner_prod_fs", "pytracking.fourier.inner_prod_fs.concat", "len", "a_P.reshape", "b_P.reshape", "pytracking.fourier.inner_prod_fs.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.inner_prod_fs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.concat"], ["", "def", "ip_input", "(", "self", ",", "a", ":", "TensorList", ",", "b", ":", "TensorList", ")", ":", "\n", "        ", "num", "=", "len", "(", "a", ")", "//", "2", "# Number of filters", "\n", "a_filter", "=", "a", "[", ":", "num", "]", "\n", "b_filter", "=", "b", "[", ":", "num", "]", "\n", "a_P", "=", "a", "[", "num", ":", "]", "\n", "b_P", "=", "b", "[", "num", ":", "]", "\n", "\n", "# Filter inner product", "\n", "ip_out", "=", "fourier", ".", "inner_prod_fs", "(", "a_filter", ",", "b_filter", ")", "\n", "\n", "# Add projection matrix part", "\n", "ip_out", "+=", "a_P", ".", "reshape", "(", "-", "1", ")", "@", "b_P", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "# Have independent inner products for each filter", "\n", "return", "ip_out", ".", "concat", "(", "ip_out", ".", "clone", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FactorizedConvProblem.ip_output": [[94, 115], ["a[].permute", "b[].permute", "sum", "sum.new_zeros", "zip", "sum", "len", "pytracking.fourier.inner_prod_fs", "min", "ar.reshape().permute", "br.reshape().permute", "pytracking.fourier.inner_prod_fs", "a_P_reg.view", "b_P_reg.view", "ar.reshape", "br.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.inner_prod_fs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.inner_prod_fs"], ["", "def", "ip_output", "(", "self", ",", "a", ":", "TensorList", ",", "b", ":", "TensorList", ")", ":", "\n", "        ", "num", "=", "len", "(", "a", ")", "//", "3", "# Number of filters", "\n", "a_data", "=", "a", "[", ":", "num", "]", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ",", "4", ")", "\n", "b_data", "=", "b", "[", ":", "num", "]", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ",", "4", ")", "\n", "a_filt_reg", "=", "a", "[", "num", ":", "2", "*", "num", "]", "\n", "b_filt_reg", "=", "b", "[", "num", ":", "2", "*", "num", "]", "\n", "a_P_reg", "=", "a", "[", "2", "*", "num", ":", "]", "\n", "b_P_reg", "=", "b", "[", "2", "*", "num", ":", "]", "\n", "\n", "ip_data", "=", "sum", "(", "fourier", ".", "inner_prod_fs", "(", "a_data", ",", "b_data", ")", ")", "\n", "ip_filt_reg", "=", "ip_data", ".", "new_zeros", "(", "1", ")", "\n", "\n", "for", "ar", ",", "br", ",", "res_data", ",", "reg_filter", "in", "zip", "(", "a_filt_reg", ",", "b_filt_reg", ",", "a_data", ",", "self", ".", "reg_filter", ")", ":", "\n", "            ", "reg_pad2", "=", "min", "(", "reg_filter", ".", "shape", "[", "-", "1", "]", "-", "1", ",", "res_data", ".", "shape", "[", "-", "2", "]", "-", "1", ")", "\n", "arp", "=", "ar", ".", "reshape", "(", "1", ",", "-", "1", ",", "2", ",", "ar", ".", "shape", "[", "2", "]", ",", "ar", ".", "shape", "[", "3", "]", ")", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", "\n", "brp", "=", "br", ".", "reshape", "(", "1", ",", "-", "1", ",", "2", ",", "br", ".", "shape", "[", "2", "]", ",", "br", ".", "shape", "[", "3", "]", ")", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", "\n", "ip_filt_reg", "+=", "fourier", ".", "inner_prod_fs", "(", "arp", "[", ":", ",", ":", ",", ":", ",", "2", "*", "reg_pad2", ":", ",", ":", "]", ",", "brp", "[", ":", ",", ":", ",", ":", ",", "2", "*", "reg_pad2", ":", ",", ":", "]", ")", "\n", "\n", "", "ip_P_reg", "=", "sum", "(", "a_P_reg", ".", "view", "(", "-", "1", ")", "@", "b_P_reg", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "return", "ip_data", "+", "ip_filt_reg", "+", "ip_P_reg", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FactorizedConvProblem.M1": [[117, 119], ["None"], "methods", ["None"], ["", "def", "M1", "(", "self", ",", "x", ":", "TensorList", ")", ":", "\n", "        ", "return", "x", "/", "self", ".", "diag_M", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.__init__": [[122, 132], ["pytracking.optimization.ConjugateGradientBase.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "reg_energy", ")", ":", "\n", "        ", "super", "(", "FilterOptim", ",", "self", ")", ".", "__init__", "(", "params", ".", "fletcher_reeves", ",", "params", ".", "standard_alpha", ",", "params", ".", "direction_forget_factor", ",", "(", "params", ".", "debug", ">=", "3", ")", ")", "\n", "\n", "# Parameters", "\n", "self", ".", "params", "=", "params", "\n", "\n", "self", ".", "reg_energy", "=", "reg_energy", "\n", "self", ".", "sample_energy", "=", "None", "\n", "\n", "self", ".", "residuals", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register": [[134, 140], ["None"], "methods", ["None"], ["", "def", "register", "(", "self", ",", "filter", ",", "training_samples", ",", "yf", ",", "sample_weights", ",", "reg_filter", ")", ":", "\n", "        ", "self", ".", "filter", "=", "filter", "\n", "self", ".", "training_samples", "=", "training_samples", "# (h, w, num_samples, num_channels, 2)", "\n", "self", ".", "yf", "=", "yf", "\n", "self", ".", "sample_weights", "=", "sample_weights", "\n", "self", ".", "reg_filter", "=", "reg_filter", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.run": [[142, 165], ["pytracking.complex.mtimes().permute", "pytracking.complex.mult_conj", "optim.FilterOptim.run_CG", "pytracking.complex.abs_sqr", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytracking.utils.plotting.plot_graph", "pytracking.complex.mtimes", "optim.FilterOptim.sample_weights.view", "optim.FilterOptim.sample_energy.mean"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult_conj", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.run_CG", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs_sqr", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mtimes", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "run", "(", "self", ",", "num_iter", ",", "new_xf", ":", "TensorList", "=", "None", ")", ":", "\n", "        ", "if", "num_iter", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "if", "new_xf", "is", "not", "None", ":", "\n", "            ", "new_sample_energy", "=", "complex", ".", "abs_sqr", "(", "new_xf", ")", "\n", "if", "self", ".", "sample_energy", "is", "None", ":", "\n", "                ", "self", ".", "sample_energy", "=", "new_sample_energy", "\n", "", "else", ":", "\n", "                ", "self", ".", "sample_energy", "=", "(", "1", "-", "self", ".", "params", ".", "precond_learning_rate", ")", "*", "self", ".", "sample_energy", "+", "self", ".", "params", ".", "precond_learning_rate", "*", "new_sample_energy", "\n", "\n", "# Compute right hand side", "\n", "", "", "self", ".", "b", "=", "complex", ".", "mtimes", "(", "self", ".", "sample_weights", ".", "view", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", ",", "self", ".", "training_samples", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ",", "4", ")", "\n", "self", ".", "b", "=", "complex", ".", "mult_conj", "(", "self", ".", "yf", ",", "self", ".", "b", ")", "\n", "\n", "self", ".", "diag_M", "=", "(", "1", "-", "self", ".", "params", ".", "precond_reg_param", ")", "*", "(", "self", ".", "params", ".", "precond_data_param", "*", "self", ".", "sample_energy", "+", "\n", "(", "1", "-", "self", ".", "params", ".", "precond_data_param", ")", "*", "self", ".", "sample_energy", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", ")", "+", "self", ".", "params", ".", "precond_reg_param", "*", "self", ".", "reg_energy", "\n", "\n", "_", ",", "res", "=", "self", ".", "run_CG", "(", "num_iter", ",", "self", ".", "filter", ")", "\n", "\n", "if", "self", ".", "debug", ":", "\n", "            ", "self", ".", "residuals", "=", "torch", ".", "cat", "(", "(", "self", ".", "residuals", ",", "res", ")", ")", "\n", "plot_graph", "(", "self", ".", "residuals", ",", "9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.A": [[168, 201], ["pytracking.complex.mtimes", "pytracking.complex.mult", "pytracking.complex.mtimes().permute", "zip", "hf.permute", "optim.FilterOptim.sample_weights.view", "min", "min", "hfe.clone.permute().reshape", "torch.conv2d", "torch.conv2d", "min", "torch.conv2d", "torch.conv2d", "hfe.clone.reshape().permute", "pytracking.complex.mtimes", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "hfe.clone", "pytracking.complex.mult.permute", "hfe.clone.permute", "hfe.clone.reshape", "pytracking.complex.conj", "hfe[].flip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mtimes", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mtimes", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.conj"], ["", "", "def", "A", "(", "self", ",", "hf", ":", "TensorList", ")", ":", "\n", "# Classify", "\n", "        ", "sh", "=", "complex", ".", "mtimes", "(", "self", ".", "training_samples", ",", "hf", ".", "permute", "(", "2", ",", "3", ",", "1", ",", "0", ",", "4", ")", ")", "# (h, w, num_samp, num_filt, 2)", "\n", "sh", "=", "complex", ".", "mult", "(", "self", ".", "sample_weights", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", ",", "sh", ")", "\n", "\n", "# Multiply with transpose", "\n", "hf_out", "=", "complex", ".", "mtimes", "(", "sh", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ")", ",", "self", ".", "training_samples", ",", "conj_b", "=", "True", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ",", "4", ")", "\n", "\n", "# Add regularization", "\n", "for", "hfe", ",", "hfe_out", ",", "reg_filter", "in", "zip", "(", "hf", ",", "hf_out", ",", "self", ".", "reg_filter", ")", ":", "\n", "            ", "reg_pad1", "=", "min", "(", "reg_filter", ".", "shape", "[", "-", "2", "]", "-", "1", ",", "hfe", ".", "shape", "[", "-", "3", "]", "-", "1", ")", "\n", "reg_pad2", "=", "min", "(", "reg_filter", ".", "shape", "[", "-", "1", "]", "-", "1", ",", "2", "*", "hfe", ".", "shape", "[", "-", "2", "]", "-", "2", ")", "\n", "\n", "# Add part needed for convolution", "\n", "if", "reg_pad2", ">", "0", ":", "\n", "                ", "hfe_conv", "=", "torch", ".", "cat", "(", "[", "complex", ".", "conj", "(", "hfe", "[", "...", ",", "1", ":", "reg_pad2", "+", "1", ",", ":", "]", ".", "flip", "(", "(", "2", ",", "3", ")", ")", ")", ",", "hfe", "]", ",", "-", "2", ")", "\n", "", "else", ":", "\n", "                ", "hfe_conv", "=", "hfe", ".", "clone", "(", ")", "\n", "\n", "# Shift data to batch dimension", "\n", "", "hfe_conv", "=", "hfe_conv", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", ".", "reshape", "(", "-", "1", ",", "1", ",", "hfe_conv", ".", "shape", "[", "-", "3", "]", ",", "hfe_conv", ".", "shape", "[", "-", "2", "]", ")", "\n", "\n", "# Do first convolution", "\n", "hfe_conv", "=", "F", ".", "conv2d", "(", "hfe_conv", ",", "reg_filter", ",", "padding", "=", "(", "reg_pad1", ",", "reg_pad2", ")", ")", "\n", "\n", "# Do second convolution", "\n", "remove_size", "=", "min", "(", "reg_pad2", ",", "hfe", ".", "shape", "[", "-", "2", "]", "-", "1", ")", "\n", "hfe_conv", "=", "F", ".", "conv2d", "(", "hfe_conv", "[", "...", ",", "remove_size", ":", "]", ",", "reg_filter", ")", "\n", "\n", "# Reshape back and add", "\n", "hfe_out", "+=", "hfe_conv", ".", "reshape", "(", "hfe", ".", "shape", "[", "0", "]", ",", "hfe", ".", "shape", "[", "1", "]", ",", "2", ",", "hfe", ".", "shape", "[", "2", "]", ",", "hfe", ".", "shape", "[", "3", "]", ")", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", "\n", "\n", "", "return", "hf_out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.ip": [[203, 205], ["pytracking.fourier.inner_prod_fs"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.inner_prod_fs"], ["", "def", "ip", "(", "self", ",", "a", ":", "torch", ".", "Tensor", ",", "b", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "fourier", ".", "inner_prod_fs", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.M1": [[207, 209], ["pytracking.complex.div"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.div"], ["", "def", "M1", "(", "self", ",", "hf", ")", ":", "\n", "        ", "return", "complex", ".", "div", "(", "hf", ",", "self", ".", "diag_M", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.initialize_features": [[19, 23], ["getattr", "eco.ECO.params.features.initialize"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["def", "initialize_features", "(", "self", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "self", ",", "'features_initialized'", ",", "False", ")", ":", "\n", "            ", "self", ".", "params", ".", "features", ".", "initialize", "(", ")", "\n", "", "self", ".", "features_initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.initialize": [[25, 178], ["eco.ECO.initialize_features", "eco.ECO.params.features.set_is_color", "eco.ECO.params.features.get_fparams", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "max", "eco.ECO.params.features.size", "eco.ECO.fparams.attribute", "len", "pytracking.TensorList", "pytracking.TensorList", "pytracking.TensorList", "eco.ECO.fparams.attribute", "pytracking.TensorList", "eco.ECO.fparams.attribute", "pytracking.features.preprocessing.numpy_to_torch", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.max", "torch.max", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min", "eco.ECO.generate_init_samples", "pytracking.TensorList", "pytracking.TensorList.mean", "pytracking.TensorList", "eco.ECO.preprocess_sample", "pytracking.fourier.shift_fs", "pytracking.fourier.shift_fs.size", "pytracking.TensorList", "pytracking.fourier.shift_fs.permute", "pytracking.TensorList", "zip", "pytracking.TensorList", "pytracking.TensorList", "optim.FactorizedConvProblem", "eco.ECO.filter.concat", "pytracking.libs.optimization.GaussNewtonCG", "pytracking.complex.mtimes", "zip", "optim.FilterOptim", "eco.ECO.filter_optimizer.register", "eco.ECO.joint_optimizer.residuals.clone", "eco.ECO.filter_optimizer.run", "eco.ECO.symmetrize_filter", "eco.ECO.params.has", "math.sqrt", "eco.ECO.params.features.stride", "torch.round", "torch.round", "torch.round", "torch.round", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "eco.ECO.reg_filter.view", "eco.ECO.reg_filter.view", "pytracking.TensorList.t", "len", "eco.ECO.joint_optimizer.run", "eco.ECO.filter_optimizer.run", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "math.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "pytracking.dcf.hann2d().to", "pytracking.dcf.get_interp_fourier", "pytracking.dcf.get_reg_filter().to", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "pytracking.dcf.label_function().to", "max", "e.permute().reshape().clone", "[].clone", "enumerate", "xf.new_zeros", "xf.new_zeros", "xf.new_zeros", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "eco.ECO.base_target_sz.prod", "zip", "max", "zip", "pytracking.fourier.shift_fs", "eco.ECO.pos.round", "xf.new_ones", "zip", "zip", "pytracking.dcf.hann2d", "pytracking.dcf.get_reg_filter", "pytracking.dcf.label_function", "e.permute().reshape", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "e.permute", "torch.svd", "torch.svd", "torch.svd", "torch.svd"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.set_is_color", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.get_fparams", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.generate_init_samples", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.preprocess_sample", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.shift_fs", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.concat", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mtimes", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.run", "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.symmetrize_filter", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.stride", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.run", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.run", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.get_interp_fourier", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.shift_fs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.get_reg_filter", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.label_function"], ["", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "        ", "state", "=", "info", "[", "'init_bbox'", "]", "\n", "\n", "# Initialize some stuff", "\n", "self", ".", "frame_num", "=", "1", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'device'", ")", ":", "\n", "            ", "self", ".", "params", ".", "device", "=", "'cuda'", "if", "self", ".", "params", ".", "use_gpu", "else", "'cpu'", "\n", "\n", "# Initialize features", "\n", "", "self", ".", "initialize_features", "(", ")", "\n", "\n", "# Chack if image is color", "\n", "self", ".", "params", ".", "features", ".", "set_is_color", "(", "image", ".", "shape", "[", "2", "]", "==", "3", ")", "\n", "\n", "# Get feature specific params", "\n", "self", ".", "fparams", "=", "self", ".", "params", ".", "features", ".", "get_fparams", "(", "'feature_params'", ")", "\n", "\n", "# Get position and size", "\n", "self", ".", "pos", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "1", "]", "+", "(", "state", "[", "3", "]", "-", "1", ")", "/", "2", ",", "state", "[", "0", "]", "+", "(", "state", "[", "2", "]", "-", "1", ")", "/", "2", "]", ")", "\n", "self", ".", "target_sz", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "3", "]", ",", "state", "[", "2", "]", "]", ")", "\n", "\n", "# Set search area", "\n", "self", ".", "target_scale", "=", "1.0", "\n", "search_area", "=", "torch", ".", "prod", "(", "self", ".", "target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ".", "item", "(", ")", "\n", "if", "search_area", ">", "self", ".", "params", ".", "max_image_sample_size", ":", "\n", "            ", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", "/", "self", ".", "params", ".", "max_image_sample_size", ")", "\n", "", "elif", "search_area", "<", "self", ".", "params", ".", "min_image_sample_size", ":", "\n", "            ", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", "/", "self", ".", "params", ".", "min_image_sample_size", ")", "\n", "\n", "# Target size in base scale", "\n", "", "self", ".", "base_target_sz", "=", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "\n", "# Use odd square search area and set sizes", "\n", "feat_max_stride", "=", "max", "(", "self", ".", "params", ".", "features", ".", "stride", "(", ")", ")", "\n", "self", ".", "img_sample_sz", "=", "torch", ".", "round", "(", "torch", ".", "sqrt", "(", "torch", ".", "prod", "(", "self", ".", "base_target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ")", ")", "*", "torch", ".", "ones", "(", "2", ")", "\n", "self", ".", "img_sample_sz", "+=", "feat_max_stride", "-", "self", ".", "img_sample_sz", "%", "(", "2", "*", "feat_max_stride", ")", "\n", "\n", "# Set other sizes (corresponds to ECO code)", "\n", "self", ".", "img_support_sz", "=", "self", ".", "img_sample_sz", "\n", "self", ".", "feature_sz", "=", "self", ".", "params", ".", "features", ".", "size", "(", "self", ".", "img_sample_sz", ")", "\n", "self", ".", "filter_sz", "=", "self", ".", "feature_sz", "+", "(", "self", ".", "feature_sz", "+", "1", ")", "%", "2", "\n", "self", ".", "output_sz", "=", "self", ".", "params", ".", "score_upsample_factor", "*", "self", ".", "img_support_sz", "# Interpolated size of the output", "\n", "self", ".", "compressed_dim", "=", "self", ".", "fparams", ".", "attribute", "(", "'compressed_dim'", ")", "\n", "\n", "# Number of filters", "\n", "self", ".", "num_filters", "=", "len", "(", "self", ".", "filter_sz", ")", "\n", "\n", "# Get window function", "\n", "self", ".", "window", "=", "TensorList", "(", "[", "dcf", ".", "hann2d", "(", "sz", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "for", "sz", "in", "self", ".", "feature_sz", "]", ")", "\n", "\n", "# Get interpolation function", "\n", "self", ".", "interp_fs", "=", "TensorList", "(", "[", "dcf", ".", "get_interp_fourier", "(", "sz", ",", "self", ".", "params", ".", "interpolation_method", ",", "\n", "self", ".", "params", ".", "interpolation_bicubic_a", ",", "self", ".", "params", ".", "interpolation_centering", ",", "\n", "self", ".", "params", ".", "interpolation_windowing", ",", "self", ".", "params", ".", "device", ")", "for", "sz", "in", "self", ".", "filter_sz", "]", ")", "\n", "\n", "# Get regularization filter", "\n", "self", ".", "reg_filter", "=", "TensorList", "(", "[", "dcf", ".", "get_reg_filter", "(", "self", ".", "img_support_sz", ",", "self", ".", "base_target_sz", ",", "fparams", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "for", "fparams", "in", "self", ".", "fparams", "]", ")", "\n", "self", ".", "reg_energy", "=", "self", ".", "reg_filter", ".", "view", "(", "-", "1", ")", "@", "self", ".", "reg_filter", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Get label function", "\n", "output_sigma_factor", "=", "self", ".", "fparams", ".", "attribute", "(", "'output_sigma_factor'", ")", "\n", "sigma", "=", "(", "self", ".", "filter_sz", "/", "self", ".", "img_support_sz", ")", "*", "torch", ".", "sqrt", "(", "self", ".", "base_target_sz", ".", "prod", "(", ")", ")", "*", "output_sigma_factor", "\n", "self", ".", "yf", "=", "TensorList", "(", "[", "dcf", ".", "label_function", "(", "sz", ",", "sig", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "for", "sz", ",", "sig", "in", "zip", "(", "self", ".", "filter_sz", ",", "sigma", ")", "]", ")", "\n", "\n", "# Optimization options", "\n", "self", ".", "params", ".", "precond_learning_rate", "=", "self", ".", "fparams", ".", "attribute", "(", "'learning_rate'", ")", "\n", "if", "self", ".", "params", ".", "CG_forgetting_rate", "is", "None", "or", "max", "(", "self", ".", "params", ".", "precond_learning_rate", ")", ">=", "1", ":", "\n", "            ", "self", ".", "params", ".", "direction_forget_factor", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "params", ".", "direction_forget_factor", "=", "(", "1", "-", "max", "(", "self", ".", "params", ".", "precond_learning_rate", ")", ")", "**", "self", ".", "params", ".", "CG_forgetting_rate", "\n", "\n", "\n", "# Convert image", "\n", "", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# Setup bounds", "\n", "self", ".", "image_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "self", ".", "min_scale_factor", "=", "torch", ".", "max", "(", "10", "/", "self", ".", "base_target_sz", ")", "\n", "self", ".", "max_scale_factor", "=", "torch", ".", "min", "(", "self", ".", "image_sz", "/", "self", ".", "base_target_sz", ")", "\n", "\n", "# Extract and transform sample", "\n", "x", "=", "self", ".", "generate_init_samples", "(", "im", ")", "\n", "\n", "# Initialize projection matrix", "\n", "x_mat", "=", "TensorList", "(", "[", "e", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "reshape", "(", "e", ".", "shape", "[", "1", "]", ",", "-", "1", ")", ".", "clone", "(", ")", "for", "e", "in", "x", "]", ")", "\n", "x_mat", "-=", "x_mat", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "cov_x", "=", "x_mat", "@", "x_mat", ".", "t", "(", ")", "\n", "self", ".", "projection_matrix", "=", "TensorList", "(", "[", "torch", ".", "svd", "(", "C", ")", "[", "0", "]", "[", ":", ",", ":", "cdim", "]", ".", "clone", "(", ")", "for", "C", ",", "cdim", "in", "zip", "(", "cov_x", ",", "self", ".", "compressed_dim", ")", "]", ")", "\n", "\n", "# Transform to get the training sample", "\n", "train_xf", "=", "self", ".", "preprocess_sample", "(", "x", ")", "\n", "\n", "# Shift the samples back", "\n", "if", "'shift'", "in", "self", ".", "params", ".", "augmentation", ":", "\n", "            ", "for", "xf", "in", "train_xf", ":", "\n", "                ", "if", "xf", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "                    ", "continue", "\n", "", "for", "i", ",", "shift", "in", "enumerate", "(", "self", ".", "params", ".", "augmentation", "[", "'shift'", "]", ")", ":", "\n", "                    ", "shift_samp", "=", "2", "*", "math", ".", "pi", "*", "torch", ".", "Tensor", "(", "shift", ")", "/", "self", ".", "img_support_sz", "\n", "xf", "[", "1", "+", "i", ":", "2", "+", "i", ",", "...", "]", "=", "fourier", ".", "shift_fs", "(", "xf", "[", "1", "+", "i", ":", "2", "+", "i", ",", "...", "]", ",", "shift", "=", "shift_samp", ")", "\n", "\n", "# Shift sample", "\n", "", "", "", "shift_samp", "=", "2", "*", "math", ".", "pi", "*", "(", "self", ".", "pos", "-", "self", ".", "pos", ".", "round", "(", ")", ")", "/", "(", "self", ".", "target_scale", "*", "self", ".", "img_support_sz", ")", "\n", "train_xf", "=", "fourier", ".", "shift_fs", "(", "train_xf", ",", "shift", "=", "shift_samp", ")", "\n", "\n", "# Initialize first-frame training samples", "\n", "num_init_samples", "=", "train_xf", ".", "size", "(", "0", ")", "\n", "self", ".", "init_sample_weights", "=", "TensorList", "(", "[", "xf", ".", "new_ones", "(", "1", ")", "/", "xf", ".", "shape", "[", "0", "]", "for", "xf", "in", "train_xf", "]", ")", "\n", "self", ".", "init_training_samples", "=", "train_xf", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ",", "4", ")", "\n", "\n", "\n", "# Sample counters and weights", "\n", "self", ".", "num_stored_samples", "=", "num_init_samples", "\n", "self", ".", "previous_replace_ind", "=", "[", "None", "]", "*", "len", "(", "self", ".", "num_stored_samples", ")", "\n", "self", ".", "sample_weights", "=", "TensorList", "(", "[", "xf", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ")", "for", "xf", "in", "train_xf", "]", ")", "\n", "for", "sw", ",", "init_sw", ",", "num", "in", "zip", "(", "self", ".", "sample_weights", ",", "self", ".", "init_sample_weights", ",", "num_init_samples", ")", ":", "\n", "            ", "sw", "[", ":", "num", "]", "=", "init_sw", "\n", "\n", "# Initialize memory", "\n", "", "self", ".", "training_samples", "=", "TensorList", "(", "\n", "[", "xf", ".", "new_zeros", "(", "xf", ".", "shape", "[", "2", "]", ",", "xf", ".", "shape", "[", "3", "]", ",", "self", ".", "params", ".", "sample_memory_size", ",", "cdim", ",", "2", ")", "for", "xf", ",", "cdim", "in", "zip", "(", "train_xf", ",", "self", ".", "compressed_dim", ")", "]", ")", "\n", "\n", "# Initialize filter", "\n", "self", ".", "filter", "=", "TensorList", "(", "\n", "[", "xf", ".", "new_zeros", "(", "1", ",", "cdim", ",", "xf", ".", "shape", "[", "2", "]", ",", "xf", ".", "shape", "[", "3", "]", ",", "2", ")", "for", "xf", ",", "cdim", "in", "zip", "(", "train_xf", ",", "self", ".", "compressed_dim", ")", "]", ")", "\n", "\n", "# Do joint optimization", "\n", "self", ".", "joint_problem", "=", "FactorizedConvProblem", "(", "self", ".", "init_training_samples", ",", "self", ".", "yf", ",", "self", ".", "reg_filter", ",", "self", ".", "projection_matrix", ",", "self", ".", "params", ",", "self", ".", "init_sample_weights", ")", "\n", "joint_var", "=", "self", ".", "filter", ".", "concat", "(", "self", ".", "projection_matrix", ")", "\n", "self", ".", "joint_optimizer", "=", "GaussNewtonCG", "(", "self", ".", "joint_problem", ",", "joint_var", ",", "debug", "=", "(", "self", ".", "params", ".", "debug", ">=", "1", ")", ",", "visdom", "=", "self", ".", "visdom", ")", "\n", "\n", "if", "self", ".", "params", ".", "update_projection_matrix", ":", "\n", "            ", "self", ".", "joint_optimizer", ".", "run", "(", "self", ".", "params", ".", "init_CG_iter", "//", "self", ".", "params", ".", "init_GN_iter", ",", "self", ".", "params", ".", "init_GN_iter", ")", "\n", "\n", "# Re-project samples with the new projection matrix", "\n", "", "compressed_samples", "=", "complex", ".", "mtimes", "(", "self", ".", "init_training_samples", ",", "self", ".", "projection_matrix", ")", "\n", "for", "train_samp", ",", "init_samp", "in", "zip", "(", "self", ".", "training_samples", ",", "compressed_samples", ")", ":", "\n", "            ", "train_samp", "[", ":", ",", ":", ",", ":", "init_samp", ".", "shape", "[", "2", "]", ",", ":", ",", ":", "]", "=", "init_samp", "\n", "\n", "# Initialize optimizer", "\n", "", "self", ".", "filter_optimizer", "=", "FilterOptim", "(", "self", ".", "params", ",", "self", ".", "reg_energy", ")", "\n", "self", ".", "filter_optimizer", ".", "register", "(", "self", ".", "filter", ",", "self", ".", "training_samples", ",", "self", ".", "yf", ",", "self", ".", "sample_weights", ",", "self", ".", "reg_filter", ")", "\n", "self", ".", "filter_optimizer", ".", "sample_energy", "=", "self", ".", "joint_problem", ".", "sample_energy", "\n", "self", ".", "filter_optimizer", ".", "residuals", "=", "self", ".", "joint_optimizer", ".", "residuals", ".", "clone", "(", ")", "\n", "\n", "if", "not", "self", ".", "params", ".", "update_projection_matrix", ":", "\n", "            ", "self", ".", "filter_optimizer", ".", "run", "(", "self", ".", "params", ".", "init_CG_iter", ")", "\n", "\n", "# Post optimization", "\n", "", "self", ".", "filter_optimizer", ".", "run", "(", "self", ".", "params", ".", "post_init_CG_iter", ")", "\n", "\n", "self", ".", "symmetrize_filter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.track": [[181, 242], ["pytracking.features.preprocessing.numpy_to_torch", "eco.ECO.pos.round", "eco.ECO.extract_fourier_sample", "eco.ECO.apply_filter", "eco.ECO.localize_target", "eco.ECO.update_state", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "pytracking.TensorList", "pytracking.fourier.shift_fs", "eco.ECO.update_memory", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "eco.ECO.visdom.register", "eco.ECO.visdom.register", "eco.ECO.filter_optimizer.run", "eco.ECO.symmetrize_filter", "torch.cat.tolist", "torch.cat.tolist", "torch.max", "torch.max", "torch.max", "torch.max", "pytracking.utils.plotting.show_tensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.extract_fourier_sample", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_target", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_state", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.shift_fs", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_memory", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.run", "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.symmetrize_filter", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_tensor"], ["", "def", "track", "(", "self", ",", "image", ",", "info", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "        ", "self", ".", "debug_info", "=", "{", "}", "\n", "\n", "self", ".", "frame_num", "+=", "1", "\n", "self", ".", "debug_info", "[", "'frame_num'", "]", "=", "self", ".", "frame_num", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# ------- LOCALIZATION ------- #", "\n", "\n", "# Get sample", "\n", "sample_pos", "=", "self", ".", "pos", ".", "round", "(", ")", "\n", "sample_scales", "=", "self", ".", "target_scale", "*", "self", ".", "params", ".", "scale_factors", "\n", "test_xf", "=", "self", ".", "extract_fourier_sample", "(", "im", ",", "self", ".", "pos", ",", "sample_scales", ",", "self", ".", "img_sample_sz", ")", "\n", "\n", "# Compute scores", "\n", "sf", "=", "self", ".", "apply_filter", "(", "test_xf", ")", "\n", "translation_vec", ",", "scale_ind", ",", "s", "=", "self", ".", "localize_target", "(", "sf", ")", "\n", "scale_change_factor", "=", "self", ".", "params", ".", "scale_factors", "[", "scale_ind", "]", "\n", "\n", "# Update position and scale", "\n", "self", ".", "update_state", "(", "sample_pos", "+", "translation_vec", ",", "self", ".", "target_scale", "*", "scale_change_factor", ")", "\n", "\n", "score_map", "=", "s", "[", "scale_ind", ",", "...", "]", "\n", "max_score", "=", "torch", ".", "max", "(", "score_map", ")", ".", "item", "(", ")", "\n", "self", ".", "debug_info", "[", "'max_score'", "]", "=", "max_score", "\n", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "score_map", ",", "'heatmap'", ",", "2", ",", "'Score Map'", ")", "\n", "self", ".", "visdom", ".", "register", "(", "self", ".", "debug_info", ",", "'info_dict'", ",", "1", ",", "'Status'", ")", "\n", "", "elif", "self", ".", "params", ".", "debug", ">=", "2", ":", "\n", "            ", "show_tensor", "(", "score_map", ",", "5", ",", "title", "=", "'Max score = {:.2f}'", ".", "format", "(", "max_score", ")", ")", "\n", "\n", "# if self.params.debug >= 3:", "\n", "#     for i, hf in enumerate(self.filter):", "\n", "#         show_tensor(fourier.sample_fs(hf).abs().mean(1), 6+i)", "\n", "\n", "\n", "# ------- UPDATE ------- #", "\n", "\n", "# Get train sample", "\n", "", "train_xf", "=", "TensorList", "(", "[", "xf", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "for", "xf", "in", "test_xf", "]", ")", "\n", "\n", "# Shift the sample", "\n", "shift_samp", "=", "2", "*", "math", ".", "pi", "*", "(", "self", ".", "pos", "-", "sample_pos", ")", "/", "(", "sample_scales", "[", "scale_ind", "]", "*", "self", ".", "img_support_sz", ")", "\n", "train_xf", "=", "fourier", ".", "shift_fs", "(", "train_xf", ",", "shift", "=", "shift_samp", ")", "\n", "\n", "# Update memory", "\n", "self", ".", "update_memory", "(", "train_xf", ")", "\n", "\n", "# Train filter", "\n", "if", "self", ".", "frame_num", "%", "self", ".", "params", ".", "train_skipping", "==", "1", ":", "\n", "            ", "self", ".", "filter_optimizer", ".", "run", "(", "self", ".", "params", ".", "CG_iter", ",", "train_xf", ")", "\n", "self", ".", "symmetrize_filter", "(", ")", "\n", "\n", "# Return new state", "\n", "", "new_state", "=", "torch", ".", "cat", "(", "(", "self", ".", "pos", "[", "[", "1", ",", "0", "]", "]", "-", "(", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", "-", "1", ")", "/", "2", ",", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", ")", ")", "\n", "\n", "out", "=", "{", "'target_bbox'", ":", "new_state", ".", "tolist", "(", ")", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.apply_filter": [[244, 246], ["pytracking.complex.mult().sum", "pytracking.complex.mult"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult"], ["", "def", "apply_filter", "(", "self", ",", "sample_xf", ":", "TensorList", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "complex", ".", "mult", "(", "self", ".", "filter", ",", "sample_xf", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.localize_target": [[247, 288], ["pytracking.dcf.max2d", "torch.max", "torch.max", "torch.max", "torch.max", "max_disp.float().cpu.float().cpu.float().cpu", "pytracking.fourier.sample_fs", "pytracking.fourier.sum_fs", "eco.ECO.fparams.attribute", "pytracking.fourier.sample_fs", "max_disp.float().cpu.float().cpu.float", "disp[].view", "pytracking.fourier.sum_fs", "eco.ECO.fparams.attribute", "eco.ECO.fparams.attribute", "torch.round", "torch.round", "torch.round", "torch.round", "zip", "ValueError", "pytracking.fourier.shift_fs", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "eco.ECO.output_sz.view", "eco.ECO.params.scale_factors.view", "scores_scales.append", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.pad", "torch.pad", "pytracking.fourier.sample_fs", "torch.cat.mean", "torch.cat.mean", "math.floor", "math.ceil", "math.floor", "math.ceil", "pd[].item", "pd[].item", "pd[].item", "pd[].item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.sample_fs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.sum_fs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.sample_fs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.sum_fs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.shift_fs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.sample_fs", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "localize_target", "(", "self", ",", "sf", ":", "TensorList", ")", ":", "\n", "        ", "if", "self", ".", "params", ".", "score_fusion_strategy", "==", "'sum'", ":", "\n", "            ", "scores", "=", "fourier", ".", "sample_fs", "(", "fourier", ".", "sum_fs", "(", "sf", ")", ",", "self", ".", "output_sz", ")", "\n", "", "elif", "self", ".", "params", ".", "score_fusion_strategy", "==", "'weightedsum'", ":", "\n", "            ", "weight", "=", "self", ".", "fparams", ".", "attribute", "(", "'translation_weight'", ")", "\n", "scores", "=", "fourier", ".", "sample_fs", "(", "fourier", ".", "sum_fs", "(", "weight", "*", "sf", ")", ",", "self", ".", "output_sz", ")", "\n", "", "elif", "self", ".", "params", ".", "score_fusion_strategy", "==", "'transcale'", ":", "\n", "            ", "alpha", "=", "self", ".", "fparams", ".", "attribute", "(", "'scale_weight'", ")", "\n", "beta", "=", "self", ".", "fparams", ".", "attribute", "(", "'translation_weight'", ")", "\n", "sample_sz", "=", "torch", ".", "round", "(", "self", ".", "output_sz", ".", "view", "(", "1", ",", "-", "1", ")", "*", "self", ".", "params", ".", "scale_factors", ".", "view", "(", "-", "1", ",", "1", ")", ")", "\n", "scores", "=", "0", "\n", "for", "sfe", ",", "a", ",", "b", "in", "zip", "(", "sf", ",", "alpha", ",", "beta", ")", ":", "\n", "                ", "sfe", "=", "fourier", ".", "shift_fs", "(", "sfe", ",", "math", ".", "pi", "*", "torch", ".", "ones", "(", "2", ")", ")", "\n", "scores_scales", "=", "[", "]", "\n", "for", "sind", ",", "sz", "in", "enumerate", "(", "sample_sz", ")", ":", "\n", "                    ", "pd", "=", "(", "self", ".", "output_sz", "-", "sz", ")", "/", "2", "\n", "scores_scales", ".", "append", "(", "F", ".", "pad", "(", "fourier", ".", "sample_fs", "(", "sfe", "[", "sind", ":", "sind", "+", "1", ",", "...", "]", ",", "sz", ")", ",", "\n", "(", "math", ".", "floor", "(", "pd", "[", "1", "]", ".", "item", "(", ")", ")", ",", "math", ".", "ceil", "(", "pd", "[", "1", "]", ".", "item", "(", ")", ")", ",", "\n", "math", ".", "floor", "(", "pd", "[", "0", "]", ".", "item", "(", ")", ")", ",", "math", ".", "ceil", "(", "pd", "[", "0", "]", ".", "item", "(", ")", ")", ")", ")", ")", "\n", "", "scores_cat", "=", "torch", ".", "cat", "(", "scores_scales", ")", "\n", "scores", "=", "scores", "+", "(", "b", "-", "a", ")", "*", "scores_cat", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "+", "a", "*", "scores_cat", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown score fusion strategy.'", ")", "\n", "\n", "# Get maximum", "\n", "", "max_score", ",", "max_disp", "=", "dcf", ".", "max2d", "(", "scores", ")", "\n", "_", ",", "scale_ind", "=", "torch", ".", "max", "(", "max_score", ",", "dim", "=", "0", ")", "\n", "max_disp", "=", "max_disp", ".", "float", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "# Convert to displacements in the base scale", "\n", "if", "self", ".", "params", ".", "score_fusion_strategy", "in", "[", "'sum'", ",", "'weightedsum'", "]", ":", "\n", "            ", "disp", "=", "(", "max_disp", "+", "self", ".", "output_sz", "/", "2", ")", "%", "self", ".", "output_sz", "-", "self", ".", "output_sz", "/", "2", "\n", "", "elif", "self", ".", "params", ".", "score_fusion_strategy", "==", "'transcale'", ":", "\n", "            ", "disp", "=", "max_disp", "-", "self", ".", "output_sz", "/", "2", "\n", "\n", "# Compute translation vector and scale change factor", "\n", "", "translation_vec", "=", "disp", "[", "scale_ind", ",", "...", "]", ".", "view", "(", "-", "1", ")", "*", "(", "self", ".", "img_support_sz", "/", "self", ".", "output_sz", ")", "*", "self", ".", "target_scale", "\n", "if", "self", ".", "params", ".", "score_fusion_strategy", "in", "[", "'sum'", ",", "'weightedsum'", "]", ":", "\n", "            ", "translation_vec", "*=", "self", ".", "params", ".", "scale_factors", "[", "scale_ind", "]", "\n", "\n", "", "return", "translation_vec", ",", "scale_ind", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.extract_sample": [[290, 292], ["eco.ECO.params.features.extract"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.extract"], ["", "def", "extract_sample", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ",", "pos", ":", "torch", ".", "Tensor", ",", "scales", ",", "sz", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "self", ".", "params", ".", "features", ".", "extract", "(", "im", ",", "pos", ",", "scales", ",", "sz", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.extract_fourier_sample": [[293, 296], ["eco.ECO.extract_sample", "eco.ECO.preprocess_sample", "eco.ECO.project_sample"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.extract_sample", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.preprocess_sample", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.project_sample"], ["", "def", "extract_fourier_sample", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ",", "pos", ":", "torch", ".", "Tensor", ",", "scales", ",", "sz", ":", "torch", ".", "Tensor", ")", "->", "TensorList", ":", "\n", "        ", "x", "=", "self", ".", "extract_sample", "(", "im", ",", "pos", ",", "scales", ",", "sz", ")", "\n", "return", "self", ".", "preprocess_sample", "(", "self", ".", "project_sample", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.preprocess_sample": [[297, 301], ["pytracking.fourier.cfft2", "pytracking.TensorList", "pytracking.dcf.interpolate_dft", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.cfft2", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.interpolate_dft"], ["", "def", "preprocess_sample", "(", "self", ",", "x", ":", "TensorList", ")", "->", "TensorList", ":", "\n", "        ", "x", "*=", "self", ".", "window", "\n", "sample_xf", "=", "fourier", ".", "cfft2", "(", "x", ")", "\n", "return", "TensorList", "(", "[", "dcf", ".", "interpolate_dft", "(", "xf", ",", "bf", ")", "for", "xf", ",", "bf", "in", "zip", "(", "sample_xf", ",", "self", ".", "interp_fs", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.project_sample": [[302, 310], ["eco.ECO.project_sample._project_sample"], "methods", ["None"], ["", "def", "project_sample", "(", "self", ",", "x", ":", "TensorList", ")", ":", "\n", "        ", "@", "tensor_operation", "\n", "def", "_project_sample", "(", "x", ":", "torch", ".", "Tensor", ",", "P", ":", "torch", ".", "Tensor", ")", ":", "\n", "            ", "if", "P", "is", "None", ":", "\n", "                ", "return", "x", "\n", "", "return", "torch", ".", "matmul", "(", "x", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ",", "P", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", "\n", "\n", "", "return", "_project_sample", "(", "x", ",", "self", ".", "projection_matrix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.generate_init_samples": [[311, 337], ["eco.ECO.params.features.extract_transformed", "enumerate", "pytracking.features.augmentation.Identity", "transforms.extend", "transforms.append", "transforms.extend", "transforms.extend", "eco.ECO.fparams.attribute", "enumerate", "pytracking.features.augmentation.FlipHorizontal", "eco.ECO.fparams.attribute", "pytracking.features.augmentation.Translation", "pytracking.features.augmentation.Rotate", "pytracking.features.augmentation.Blur", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.dropout2d", "torch.dropout2d", "[].expand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.extract_transformed", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute"], ["", "def", "generate_init_samples", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", "->", "TensorList", ":", "\n", "# Do data augmentation", "\n", "        ", "transforms", "=", "[", "augmentation", ".", "Identity", "(", ")", "]", "\n", "if", "'shift'", "in", "self", ".", "params", ".", "augmentation", ":", "\n", "            ", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "shift", ")", "for", "shift", "in", "self", ".", "params", ".", "augmentation", "[", "'shift'", "]", "]", ")", "\n", "", "if", "'fliplr'", "in", "self", ".", "params", ".", "augmentation", "and", "self", ".", "params", ".", "augmentation", "[", "'fliplr'", "]", ":", "\n", "            ", "transforms", ".", "append", "(", "augmentation", ".", "FlipHorizontal", "(", ")", ")", "\n", "", "if", "'rotate'", "in", "self", ".", "params", ".", "augmentation", ":", "\n", "            ", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Rotate", "(", "angle", ")", "for", "angle", "in", "self", ".", "params", ".", "augmentation", "[", "'rotate'", "]", "]", ")", "\n", "", "if", "'blur'", "in", "self", ".", "params", ".", "augmentation", ":", "\n", "            ", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Blur", "(", "sigma", ")", "for", "sigma", "in", "self", ".", "params", ".", "augmentation", "[", "'blur'", "]", "]", ")", "\n", "\n", "", "init_samples", "=", "self", ".", "params", ".", "features", ".", "extract_transformed", "(", "im", ",", "self", ".", "pos", ",", "self", ".", "target_scale", ",", "self", ".", "img_sample_sz", ",", "transforms", ")", "\n", "\n", "# Remove augmented samples for those that shall not have", "\n", "for", "i", ",", "use_aug", "in", "enumerate", "(", "self", ".", "fparams", ".", "attribute", "(", "'use_augmentation'", ")", ")", ":", "\n", "            ", "if", "not", "use_aug", ":", "\n", "                ", "init_samples", "[", "i", "]", "=", "init_samples", "[", "i", "]", "[", "0", ":", "1", ",", "...", "]", "\n", "\n", "", "", "if", "'dropout'", "in", "self", ".", "params", ".", "augmentation", ":", "\n", "            ", "num", ",", "prob", "=", "self", ".", "params", ".", "augmentation", "[", "'dropout'", "]", "\n", "for", "i", ",", "use_aug", "in", "enumerate", "(", "self", ".", "fparams", ".", "attribute", "(", "'use_augmentation'", ")", ")", ":", "\n", "                ", "if", "use_aug", ":", "\n", "                    ", "init_samples", "[", "i", "]", "=", "torch", ".", "cat", "(", "[", "init_samples", "[", "i", "]", ",", "F", ".", "dropout2d", "(", "init_samples", "[", "i", "]", "[", "0", ":", "1", ",", "...", "]", ".", "expand", "(", "num", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", ",", "p", "=", "prob", ",", "training", "=", "True", ")", "]", ")", "\n", "\n", "", "", "", "return", "init_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.update_memory": [[339, 344], ["eco.ECO.update_sample_weights", "zip", "xf.permute"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_sample_weights"], ["", "def", "update_memory", "(", "self", ",", "sample_xf", ":", "TensorList", ")", ":", "\n", "# Update weights and get index to replace", "\n", "        ", "replace_ind", "=", "self", ".", "update_sample_weights", "(", ")", "\n", "for", "train_samp", ",", "xf", ",", "ind", "in", "zip", "(", "self", ".", "training_samples", ",", "sample_xf", ",", "replace_ind", ")", ":", "\n", "            ", "train_samp", "[", ":", ",", ":", ",", "ind", ":", "ind", "+", "1", ",", ":", ",", ":", "]", "=", "xf", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.update_sample_weights": [[346, 371], ["zip", "replace_ind.copy", "sw.sum", "replace_ind.append", "torch.min", "torch.min", "torch.min", "torch.min", "r_ind.item.item.item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "", "def", "update_sample_weights", "(", "self", ")", ":", "\n", "        ", "replace_ind", "=", "[", "]", "\n", "for", "sw", ",", "prev_ind", ",", "num_samp", ",", "fparams", "in", "zip", "(", "self", ".", "sample_weights", ",", "self", ".", "previous_replace_ind", ",", "self", ".", "num_stored_samples", ",", "self", ".", "fparams", ")", ":", "\n", "            ", "if", "num_samp", "==", "0", "or", "fparams", ".", "learning_rate", "==", "1", ":", "\n", "                ", "sw", "[", ":", "]", "=", "0", "\n", "sw", "[", "0", "]", "=", "1", "\n", "r_ind", "=", "0", "\n", "", "else", ":", "\n", "# Get index to replace", "\n", "                ", "_", ",", "r_ind", "=", "torch", ".", "min", "(", "sw", ",", "0", ")", "\n", "r_ind", "=", "r_ind", ".", "item", "(", ")", "\n", "\n", "# Update weights", "\n", "if", "prev_ind", "is", "None", ":", "\n", "                    ", "sw", "/=", "1", "-", "fparams", ".", "learning_rate", "\n", "sw", "[", "r_ind", "]", "=", "fparams", ".", "learning_rate", "\n", "", "else", ":", "\n", "                    ", "sw", "[", "r_ind", "]", "=", "sw", "[", "prev_ind", "]", "/", "(", "1", "-", "fparams", ".", "learning_rate", ")", "\n", "\n", "", "", "sw", "/=", "sw", ".", "sum", "(", ")", "\n", "replace_ind", ".", "append", "(", "r_ind", ")", "\n", "\n", "", "self", ".", "previous_replace_ind", "=", "replace_ind", ".", "copy", "(", ")", "\n", "self", ".", "num_stored_samples", "+=", "1", "\n", "return", "replace_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.update_state": [[372, 381], ["new_scale.clamp", "torch.max", "torch.max", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "new_pos", ",", "new_scale", ")", ":", "\n", "# Update scale", "\n", "        ", "self", ".", "target_scale", "=", "new_scale", ".", "clamp", "(", "self", ".", "min_scale_factor", ",", "self", ".", "max_scale_factor", ")", "\n", "self", ".", "target_sz", "=", "self", ".", "base_target_sz", "*", "self", ".", "target_scale", "\n", "\n", "# Update pos", "\n", "inside_ratio", "=", "0.2", "\n", "inside_offset", "=", "(", "inside_ratio", "-", "0.5", ")", "*", "self", ".", "target_sz", "\n", "self", ".", "pos", "=", "torch", ".", "max", "(", "torch", ".", "min", "(", "new_pos", ",", "self", ".", "image_sz", "-", "inside_offset", ")", ",", "inside_offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.eco.eco.ECO.symmetrize_filter": [[382, 386], ["pytracking.complex.conj", "hf[].flip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.conj"], ["", "def", "symmetrize_filter", "(", "self", ")", ":", "\n", "        ", "for", "hf", "in", "self", ".", "filter", ":", "\n", "            ", "hf", "[", ":", ",", ":", ",", ":", ",", "0", ",", ":", "]", "/=", "2", "\n", "hf", "[", ":", ",", ":", ",", ":", ",", "0", ",", ":", "]", "+=", "complex", ".", "conj", "(", "hf", "[", ":", ",", ":", ",", ":", ",", "0", ",", ":", "]", ".", "flip", "(", "(", "2", ",", ")", ")", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.super_dimp.parameters": [[4, 71], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "22", "*", "16", "\n", "params", ".", "search_area_scale", "=", "6", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "1.5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "2.5e-3", "# 1   # Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'super_dimp.pth.tar'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp50_vot19.parameters": [[4, 72], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "16", "*", "16", "\n", "params", ".", "search_area_scale", "=", "4.5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "100", "\n", "params", ".", "learning_rate", "=", "0.0075", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.0", "\n", "params", ".", "train_skipping", "=", "10", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "15", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "2", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "True", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "-", "5", ",", "10", ",", "-", "30", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "1", ",", "3", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "3", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "1.4", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.0", "\n", "params", ".", "distractor_threshold", "=", "100", "\n", "params", ".", "hard_negative_threshold", "=", "0.45", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.7", "\n", "\n", "params", ".", "perform_hn_without_windowing", "=", "True", "\n", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "iounet_augmentation", "=", "False", "\n", "params", ".", "iounet_use_log_scale", "=", "True", "\n", "params", ".", "iounet_k", "=", "3", "\n", "params", ".", "num_init_random_boxes", "=", "9", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "\n", "params", ".", "box_refinement_iter", "=", "3", "\n", "params", ".", "box_refinement_step_length", "=", "1", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'dimp50.pth'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.prdimp50_vot18.parameters": [[4, 72], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "14", "*", "16", "\n", "params", ".", "search_area_scale", "=", "4", "\n", "params", ".", "feature_size_odd", "=", "False", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "250", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.0", "\n", "params", ".", "train_skipping", "=", "1", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "25", "\n", "params", ".", "net_opt_update_iter", "=", "1", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "True", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "# params.score_preprocess = 'softmax'", "\n", "params", ".", "target_not_found_threshold", "=", "0.00", "\n", "params", ".", "distractor_threshold", "=", "99999", "\n", "params", ".", "hard_negative_threshold", "=", "999999", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.7", "\n", "params", ".", "perform_hn_without_windowing", "=", "True", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "2.5e-3", "# 1   # Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'prdimp50.pth.tar'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.prdimp50.parameters": [[4, 72], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "22", "*", "16", "\n", "params", ".", "search_area_scale", "=", "6", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "1.5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "score_preprocess", "=", "'softmax'", "\n", "params", ".", "target_not_found_threshold", "=", "0.04", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "2.5e-3", "# 1   # Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'prdimp50.pth.tar'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp50_vot18.parameters": [[4, 72], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "14", "*", "16", "\n", "params", ".", "search_area_scale", "=", "4", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "250", "\n", "params", ".", "learning_rate", "=", "0.0075", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.0", "\n", "params", ".", "train_skipping", "=", "10", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "25", "\n", "params", ".", "net_opt_update_iter", "=", "3", "\n", "params", ".", "net_opt_hn_iter", "=", "3", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "True", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.0", "\n", "params", ".", "distractor_threshold", "=", "100", "\n", "params", ".", "hard_negative_threshold", "=", "0.45", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.7", "\n", "\n", "params", ".", "perform_hn_without_windowing", "=", "True", "\n", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "iounet_augmentation", "=", "False", "\n", "params", ".", "iounet_use_log_scale", "=", "True", "\n", "params", ".", "iounet_k", "=", "3", "\n", "params", ".", "num_init_random_boxes", "=", "9", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "\n", "params", ".", "box_refinement_iter", "=", "5", "\n", "params", ".", "box_refinement_step_length", "=", "1", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'dimp50.pth'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp18_vot18.parameters": [[4, 73], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "14", "*", "16", "\n", "params", ".", "search_area_scale", "=", "4", "\n", "params", ".", "feature_size_odd", "=", "False", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "250", "\n", "params", ".", "learning_rate", "=", "0.0075", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.0", "\n", "params", ".", "train_skipping", "=", "10", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "25", "\n", "params", ".", "net_opt_update_iter", "=", "3", "\n", "params", ".", "net_opt_hn_iter", "=", "3", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "True", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.0", "\n", "params", ".", "distractor_threshold", "=", "100", "\n", "params", ".", "hard_negative_threshold", "=", "0.45", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.7", "\n", "\n", "params", ".", "perform_hn_without_windowing", "=", "True", "\n", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "iounet_augmentation", "=", "False", "\n", "params", ".", "iounet_use_log_scale", "=", "True", "\n", "params", ".", "iounet_k", "=", "3", "\n", "params", ".", "num_init_random_boxes", "=", "9", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "\n", "params", ".", "box_refinement_iter", "=", "5", "\n", "params", ".", "box_refinement_step_length", "=", "1", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'dimp18.pth'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp50.parameters": [[4, 69], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "18", "*", "16", "\n", "params", ".", "search_area_scale", "=", "5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "iounet_augmentation", "=", "False", "\n", "params", ".", "iounet_use_log_scale", "=", "True", "\n", "params", ".", "iounet_k", "=", "3", "\n", "params", ".", "num_init_random_boxes", "=", "9", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "\n", "params", ".", "box_refinement_iter", "=", "5", "\n", "params", ".", "box_refinement_step_length", "=", "1", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'dimp50.pth'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.prdimp18.parameters": [[4, 70], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "18", "*", "16", "\n", "params", ".", "search_area_scale", "=", "5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "score_preprocess", "=", "'softmax'", "\n", "params", ".", "target_not_found_threshold", "=", "0.04", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "2.5e-3", "# 1   # Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'prdimp18.pth.tar'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp18.parameters": [[4, 69], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "18", "*", "16", "\n", "params", ".", "search_area_scale", "=", "5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "iounet_augmentation", "=", "False", "\n", "params", ".", "iounet_use_log_scale", "=", "True", "\n", "params", ".", "iounet_k", "=", "3", "\n", "params", ".", "num_init_random_boxes", "=", "9", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "\n", "params", ".", "box_refinement_iter", "=", "5", "\n", "params", ".", "box_refinement_step_length", "=", "1", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'dimp18.pth'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.initialize_features": [[20, 24], ["getattr", "dimp.DiMP.params.net.initialize"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["def", "initialize_features", "(", "self", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "self", ",", "'features_initialized'", ",", "False", ")", ":", "\n", "            ", "self", ".", "params", ".", "net", ".", "initialize", "(", ")", "\n", "", "self", ".", "features_initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.initialize": [[25, 92], ["dimp.DiMP.initialize_features", "time.time", "pytracking.features.preprocessing.numpy_to_torch", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "dimp.DiMP.params.get", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.max", "torch.max", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min", "dimp.DiMP.generate_init_samples", "dimp.DiMP.init_classifier", "dimp.DiMP.params.get", "dimp.DiMP.params.has", "info.get", "dimp.DiMP.params.get", "math.sqrt", "dimp.DiMP.img_sample_sz.prod().sqrt", "dimp.DiMP.params.has", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "isinstance", "dimp.DiMP.init_iou_net", "isinstance", "dimp.DiMP.image_sz.prod().sqrt", "torch.round", "torch.round", "torch.round", "torch.round", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "time.time", "torch.Tensor.prod().sqrt", "torch.Tensor.prod().sqrt", "dimp.DiMP.img_sample_sz.prod", "dimp.DiMP.image_sz.prod", "torch.Tensor.prod", "torch.Tensor.prod"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.generate_init_samples", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_classifier", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_iou_net"], ["", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "# Initialize some stuff", "\n", "        ", "self", ".", "frame_num", "=", "1", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'device'", ")", ":", "\n", "            ", "self", ".", "params", ".", "device", "=", "'cuda'", "if", "self", ".", "params", ".", "use_gpu", "else", "'cpu'", "\n", "\n", "# Initialize network", "\n", "", "self", ".", "initialize_features", "(", ")", "\n", "\n", "# The DiMP network", "\n", "self", ".", "net", "=", "self", ".", "params", ".", "net", "\n", "\n", "# Time initialization", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# Get target position and size", "\n", "state", "=", "info", "[", "'init_bbox'", "]", "\n", "self", ".", "pos", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "1", "]", "+", "(", "state", "[", "3", "]", "-", "1", ")", "/", "2", ",", "state", "[", "0", "]", "+", "(", "state", "[", "2", "]", "-", "1", ")", "/", "2", "]", ")", "\n", "self", ".", "target_sz", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "3", "]", ",", "state", "[", "2", "]", "]", ")", "\n", "\n", "# Get object id", "\n", "self", ".", "object_id", "=", "info", ".", "get", "(", "'object_ids'", ",", "[", "None", "]", ")", "[", "0", "]", "\n", "self", ".", "id_str", "=", "''", "if", "self", ".", "object_id", "is", "None", "else", "' {}'", ".", "format", "(", "self", ".", "object_id", ")", "\n", "\n", "# Set sizes", "\n", "self", ".", "image_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "sz", "=", "self", ".", "params", ".", "image_sample_size", "\n", "sz", "=", "torch", ".", "Tensor", "(", "[", "sz", ",", "sz", "]", "if", "isinstance", "(", "sz", ",", "int", ")", "else", "sz", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_image_aspect_ratio'", ",", "False", ")", ":", "\n", "            ", "sz", "=", "self", ".", "image_sz", "*", "sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "/", "self", ".", "image_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "stride", "=", "self", ".", "params", ".", "get", "(", "'feature_stride'", ",", "32", ")", "\n", "sz", "=", "torch", ".", "round", "(", "sz", "/", "stride", ")", "*", "stride", "\n", "", "self", ".", "img_sample_sz", "=", "sz", "\n", "self", ".", "img_support_sz", "=", "self", ".", "img_sample_sz", "\n", "\n", "# Set search area", "\n", "search_area", "=", "torch", ".", "prod", "(", "self", ".", "target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ".", "item", "(", ")", "\n", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", ")", "/", "self", ".", "img_sample_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "\n", "# Target size in base scale", "\n", "self", ".", "base_target_sz", "=", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "\n", "# Setup scale factors", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'scale_factors'", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "ones", "(", "1", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "params", ".", "scale_factors", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "Tensor", "(", "self", ".", "params", ".", "scale_factors", ")", "\n", "\n", "# Setup scale bounds", "\n", "", "self", ".", "min_scale_factor", "=", "torch", ".", "max", "(", "10", "/", "self", ".", "base_target_sz", ")", "\n", "self", ".", "max_scale_factor", "=", "torch", ".", "min", "(", "self", ".", "image_sz", "/", "self", ".", "base_target_sz", ")", "\n", "\n", "# Extract and transform sample", "\n", "init_backbone_feat", "=", "self", ".", "generate_init_samples", "(", "im", ")", "\n", "\n", "# Initialize classifier", "\n", "self", ".", "init_classifier", "(", "init_backbone_feat", ")", "\n", "\n", "# Initialize IoUNet", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", ":", "\n", "            ", "self", ".", "init_iou_net", "(", "init_backbone_feat", ")", "\n", "\n", "", "out", "=", "{", "'time'", ":", "time", ".", "time", "(", ")", "-", "tic", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.track": [[94, 176], ["pytracking.features.preprocessing.numpy_to_torch", "dimp.DiMP.extract_backbone_features", "dimp.DiMP.get_classification_features", "dimp.DiMP.get_sample_location", "dimp.DiMP.classify_target", "dimp.DiMP.localize_target", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dimp.DiMP.get_centered_sample_pos", "dimp.DiMP.params.get", "dimp.DiMP.params.get", "dimp.DiMP.params.get", "dimp.DiMP.get_iounet_box", "dimp.DiMP.update_classifier", "dimp.DiMP.params.get", "hasattr", "dimp.DiMP.pos_iounet.clone", "dimp.DiMP.visdom.register", "dimp.DiMP.visdom.register", "dimp.DiMP.params.get", "torch.cat.tolist", "torch.cat.tolist", "dimp.DiMP.params.get", "dimp.DiMP.refine_target_box", "dimp.DiMP.params.get", "torch.max", "torch.max", "torch.max", "torch.max", "pytracking.utils.plotting.show_tensor", "dimp.DiMP.params.get", "dimp.DiMP.update_state", "dimp.DiMP.update_state"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_classification_features", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_sample_location", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.classify_target", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_target", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_centered_sample_pos", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.update_classifier", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.refine_target_box", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_tensor", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_state", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_state"], ["", "def", "track", "(", "self", ",", "image", ",", "info", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "        ", "self", ".", "debug_info", "=", "{", "}", "\n", "\n", "self", ".", "frame_num", "+=", "1", "\n", "self", ".", "debug_info", "[", "'frame_num'", "]", "=", "self", ".", "frame_num", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# ------- LOCALIZATION ------- #", "\n", "\n", "# Extract backbone features", "\n", "backbone_feat", ",", "sample_coords", ",", "im_patches", "=", "self", ".", "extract_backbone_features", "(", "im", ",", "self", ".", "get_centered_sample_pos", "(", ")", ",", "\n", "self", ".", "target_scale", "*", "self", ".", "params", ".", "scale_factors", ",", "\n", "self", ".", "img_sample_sz", ")", "\n", "# Extract classification features", "\n", "test_x", "=", "self", ".", "get_classification_features", "(", "backbone_feat", ")", "\n", "\n", "# Location of sample", "\n", "sample_pos", ",", "sample_scales", "=", "self", ".", "get_sample_location", "(", "sample_coords", ")", "\n", "\n", "# Compute classification scores", "\n", "scores_raw", "=", "self", ".", "classify_target", "(", "test_x", ")", "\n", "\n", "# Localize the target", "\n", "translation_vec", ",", "scale_ind", ",", "s", ",", "flag", "=", "self", ".", "localize_target", "(", "scores_raw", ",", "sample_pos", ",", "sample_scales", ")", "\n", "new_pos", "=", "sample_pos", "[", "scale_ind", ",", ":", "]", "+", "translation_vec", "\n", "\n", "# Update position and scale", "\n", "if", "flag", "!=", "'not_found'", ":", "\n", "            ", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", ":", "\n", "                ", "update_scale_flag", "=", "self", ".", "params", ".", "get", "(", "'update_scale_when_uncertain'", ",", "True", ")", "or", "flag", "!=", "'uncertain'", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_classifier'", ",", "True", ")", ":", "\n", "                    ", "self", ".", "update_state", "(", "new_pos", ")", "\n", "", "self", ".", "refine_target_box", "(", "backbone_feat", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ",", "scale_ind", ",", "update_scale_flag", ")", "\n", "", "elif", "self", ".", "params", ".", "get", "(", "'use_classifier'", ",", "True", ")", ":", "\n", "                ", "self", ".", "update_state", "(", "new_pos", ",", "sample_scales", "[", "scale_ind", "]", ")", "\n", "\n", "\n", "# ------- UPDATE ------- #", "\n", "\n", "", "", "update_flag", "=", "flag", "not", "in", "[", "'not_found'", ",", "'uncertain'", "]", "\n", "hard_negative", "=", "(", "flag", "==", "'hard_negative'", ")", "\n", "learning_rate", "=", "self", ".", "params", ".", "get", "(", "'hard_negative_learning_rate'", ",", "None", ")", "if", "hard_negative", "else", "None", "\n", "\n", "if", "update_flag", "and", "self", ".", "params", ".", "get", "(", "'update_classifier'", ",", "False", ")", ":", "\n", "# Get train sample", "\n", "            ", "train_x", "=", "test_x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "\n", "\n", "# Create target_box and label for spatial sample", "\n", "target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ")", "\n", "\n", "# Update the classifier model", "\n", "self", ".", "update_classifier", "(", "train_x", ",", "target_box", ",", "learning_rate", ",", "s", "[", "scale_ind", ",", "...", "]", ")", "\n", "\n", "# Set the pos of the tracker to iounet pos", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", "and", "flag", "!=", "'not_found'", "and", "hasattr", "(", "self", ",", "'pos_iounet'", ")", ":", "\n", "            ", "self", ".", "pos", "=", "self", ".", "pos_iounet", ".", "clone", "(", ")", "\n", "\n", "", "score_map", "=", "s", "[", "scale_ind", ",", "...", "]", "\n", "max_score", "=", "torch", ".", "max", "(", "score_map", ")", ".", "item", "(", ")", "\n", "\n", "# Visualize and set debug info", "\n", "self", ".", "search_area_box", "=", "torch", ".", "cat", "(", "(", "sample_coords", "[", "scale_ind", ",", "[", "1", ",", "0", "]", "]", ",", "sample_coords", "[", "scale_ind", ",", "[", "3", ",", "2", "]", "]", "-", "sample_coords", "[", "scale_ind", ",", "[", "1", ",", "0", "]", "]", "-", "1", ")", ")", "\n", "self", ".", "debug_info", "[", "'flag'", "+", "self", ".", "id_str", "]", "=", "flag", "\n", "self", ".", "debug_info", "[", "'max_score'", "+", "self", ".", "id_str", "]", "=", "max_score", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "score_map", ",", "'heatmap'", ",", "2", ",", "'Score Map'", "+", "self", ".", "id_str", ")", "\n", "self", ".", "visdom", ".", "register", "(", "self", ".", "debug_info", ",", "'info_dict'", ",", "1", ",", "'Status'", ")", "\n", "", "elif", "self", ".", "params", ".", "debug", ">=", "2", ":", "\n", "            ", "show_tensor", "(", "score_map", ",", "5", ",", "title", "=", "'Max score = {:.2f}'", ".", "format", "(", "max_score", ")", ")", "\n", "\n", "# Compute output bounding box", "\n", "", "new_state", "=", "torch", ".", "cat", "(", "(", "self", ".", "pos", "[", "[", "1", ",", "0", "]", "]", "-", "(", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", "-", "1", ")", "/", "2", ",", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", ")", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'output_not_found_box'", ",", "False", ")", "and", "flag", "==", "'not_found'", ":", "\n", "            ", "output_state", "=", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "output_state", "=", "new_state", ".", "tolist", "(", ")", "\n", "\n", "", "out", "=", "{", "'target_bbox'", ":", "output_state", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.get_sample_location": [[178, 184], ["sample_coord.float.float.float"], "methods", ["None"], ["", "def", "get_sample_location", "(", "self", ",", "sample_coord", ")", ":", "\n", "        ", "\"\"\"Get the location of the extracted sample.\"\"\"", "\n", "sample_coord", "=", "sample_coord", ".", "float", "(", ")", "\n", "sample_pos", "=", "0.5", "*", "(", "sample_coord", "[", ":", ",", ":", "2", "]", "+", "sample_coord", "[", ":", ",", "2", ":", "]", "-", "1", ")", "\n", "sample_scales", "=", "(", "(", "sample_coord", "[", ":", ",", "2", ":", "]", "-", "sample_coord", "[", ":", ",", ":", "2", "]", ")", "/", "self", ".", "img_sample_sz", ")", ".", "prod", "(", "dim", "=", "1", ")", ".", "sqrt", "(", ")", "\n", "return", "sample_pos", ",", "sample_scales", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.get_centered_sample_pos": [[185, 189], ["None"], "methods", ["None"], ["", "def", "get_centered_sample_pos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the center position for the new sample. Make sure the target is correctly centered.\"\"\"", "\n", "return", "self", ".", "pos", "+", "(", "(", "self", ".", "feature_sz", "+", "self", ".", "kernel_size", ")", "%", "2", ")", "*", "self", ".", "target_scale", "*", "self", ".", "img_support_sz", "/", "(", "2", "*", "self", ".", "feature_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.classify_target": [[190, 195], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp.DiMP.net.classifier.classify"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.classify"], ["", "def", "classify_target", "(", "self", ",", "sample_x", ":", "TensorList", ")", ":", "\n", "        ", "\"\"\"Classify target by applying the DiMP filter.\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "scores", "=", "self", ".", "net", ".", "classifier", ".", "classify", "(", "self", ".", "target_filter", ",", "sample_x", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.localize_target": [[196, 236], ["activation.softmax_reg.view.squeeze", "dimp.DiMP.params.get", "dimp.DiMP.params.get", "dimp.DiMP.params.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "pytracking.dcf.max2d", "torch.max", "torch.max", "torch.max", "torch.max", "max_disp[].float().cpu().view", "activation.softmax_reg.view.new_ones", "torch.conv2d().view", "torch.conv2d().view", "dimp.DiMP.localize_advanced", "list", "activation.softmax_reg.view.exp", "max_disp[].float().cpu", "getattr", "activation.softmax_reg.view.view", "ltr.models.layers.activation.softmax_reg", "ltr.models.layers.activation.softmax_reg.view", "Exception", "torch.conv2d", "torch.conv2d", "activation.softmax_reg.view.view", "max_disp[].float"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_advanced", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.softmax_reg", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["", "def", "localize_target", "(", "self", ",", "scores", ",", "sample_pos", ",", "sample_scales", ")", ":", "\n", "        ", "\"\"\"Run the target localization.\"\"\"", "\n", "\n", "scores", "=", "scores", ".", "squeeze", "(", "1", ")", "\n", "\n", "preprocess_method", "=", "self", ".", "params", ".", "get", "(", "'score_preprocess'", ",", "'none'", ")", "\n", "if", "preprocess_method", "==", "'none'", ":", "\n", "            ", "pass", "\n", "", "elif", "preprocess_method", "==", "'exp'", ":", "\n", "            ", "scores", "=", "scores", ".", "exp", "(", ")", "\n", "", "elif", "preprocess_method", "==", "'softmax'", ":", "\n", "            ", "reg_val", "=", "getattr", "(", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ",", "'softmax_reg'", ",", "None", ")", "\n", "scores_view", "=", "scores", ".", "view", "(", "scores", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "scores_softmax", "=", "activation", ".", "softmax_reg", "(", "scores_view", ",", "dim", "=", "-", "1", ",", "reg", "=", "reg_val", ")", "\n", "scores", "=", "scores_softmax", ".", "view", "(", "scores", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unknown score_preprocess in params.'", ")", "\n", "\n", "", "score_filter_ksz", "=", "self", ".", "params", ".", "get", "(", "'score_filter_ksz'", ",", "1", ")", "\n", "if", "score_filter_ksz", ">", "1", ":", "\n", "            ", "assert", "score_filter_ksz", "%", "2", "==", "1", "\n", "kernel", "=", "scores", ".", "new_ones", "(", "1", ",", "1", ",", "score_filter_ksz", ",", "score_filter_ksz", ")", "\n", "scores", "=", "F", ".", "conv2d", "(", "scores", ".", "view", "(", "-", "1", ",", "1", ",", "*", "scores", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "kernel", ",", "padding", "=", "score_filter_ksz", "//", "2", ")", ".", "view", "(", "scores", ".", "shape", ")", "\n", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'advanced_localization'", ",", "False", ")", ":", "\n", "            ", "return", "self", ".", "localize_advanced", "(", "scores", ",", "sample_pos", ",", "sample_scales", ")", "\n", "\n", "# Get maximum", "\n", "", "score_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "scores", ".", "shape", "[", "-", "2", ":", "]", ")", ")", "\n", "score_center", "=", "(", "score_sz", "-", "1", ")", "/", "2", "\n", "max_score", ",", "max_disp", "=", "dcf", ".", "max2d", "(", "scores", ")", "\n", "_", ",", "scale_ind", "=", "torch", ".", "max", "(", "max_score", ",", "dim", "=", "0", ")", "\n", "max_disp", "=", "max_disp", "[", "scale_ind", ",", "...", "]", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp", "=", "max_disp", "-", "score_center", "\n", "\n", "# Compute translation vector and scale change factor", "\n", "output_sz", "=", "score_sz", "-", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "translation_vec", "=", "target_disp", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scales", "[", "scale_ind", "]", "\n", "\n", "return", "translation_vec", ",", "scale_ind", ",", "scores", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.localize_advanced": [[238, 304], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "pytracking.dcf.max2d", "torch.max", "torch.max", "torch.max", "torch.max", "max_disp1[].float().cpu().view", "max", "min", "max", "min", "scores_hn[].clone", "pytracking.dcf.max2d", "max_disp2.float().cpu().view.float().cpu().view.float().cpu().view", "list", "dimp.DiMP.params.get", "scores.clone", "max_score1.item", "max_score1.item", "dimp.DiMP.params.get", "max_score1.item", "dimp.DiMP.params.get", "round", "round", "round", "round", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "max_disp1[].float().cpu", "max_disp2.float().cpu().view.float().cpu().view.float().cpu", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "float", "float", "max_disp1[].item", "max_disp1[].item", "math.sqrt", "max_disp1[].float", "target_neigh_sz[].item", "max_disp1[].item", "target_neigh_sz[].item", "max_disp1[].item", "max_disp2.float().cpu().view.float().cpu().view.float", "target_neigh_sz[].item", "target_neigh_sz[].item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "localize_advanced", "(", "self", ",", "scores", ",", "sample_pos", ",", "sample_scales", ")", ":", "\n", "        ", "\"\"\"Run the target advanced localization (as in ATOM).\"\"\"", "\n", "\n", "sz", "=", "scores", ".", "shape", "[", "-", "2", ":", "]", "\n", "score_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "sz", ")", ")", "\n", "output_sz", "=", "score_sz", "-", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "score_center", "=", "(", "score_sz", "-", "1", ")", "/", "2", "\n", "\n", "scores_hn", "=", "scores", "\n", "if", "self", ".", "output_window", "is", "not", "None", "and", "self", ".", "params", ".", "get", "(", "'perform_hn_without_windowing'", ",", "False", ")", ":", "\n", "            ", "scores_hn", "=", "scores", ".", "clone", "(", ")", "\n", "scores", "*=", "self", ".", "output_window", "\n", "\n", "", "max_score1", ",", "max_disp1", "=", "dcf", ".", "max2d", "(", "scores", ")", "\n", "_", ",", "scale_ind", "=", "torch", ".", "max", "(", "max_score1", ",", "dim", "=", "0", ")", "\n", "sample_scale", "=", "sample_scales", "[", "scale_ind", "]", "\n", "max_score1", "=", "max_score1", "[", "scale_ind", "]", "\n", "max_disp1", "=", "max_disp1", "[", "scale_ind", ",", "...", "]", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp1", "=", "max_disp1", "-", "score_center", "\n", "translation_vec1", "=", "target_disp1", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scale", "\n", "\n", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "target_not_found_threshold", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'not_found'", "\n", "", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "get", "(", "'uncertain_threshold'", ",", "-", "float", "(", "'inf'", ")", ")", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'uncertain'", "\n", "", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "get", "(", "'hard_sample_threshold'", ",", "-", "float", "(", "'inf'", ")", ")", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", "\n", "\n", "# Mask out target neighborhood", "\n", "", "target_neigh_sz", "=", "self", ".", "params", ".", "target_neighborhood_scale", "*", "(", "self", ".", "target_sz", "/", "sample_scale", ")", "*", "(", "output_sz", "/", "self", ".", "img_support_sz", ")", "\n", "\n", "tneigh_top", "=", "max", "(", "round", "(", "max_disp1", "[", "0", "]", ".", "item", "(", ")", "-", "target_neigh_sz", "[", "0", "]", ".", "item", "(", ")", "/", "2", ")", ",", "0", ")", "\n", "tneigh_bottom", "=", "min", "(", "round", "(", "max_disp1", "[", "0", "]", ".", "item", "(", ")", "+", "target_neigh_sz", "[", "0", "]", ".", "item", "(", ")", "/", "2", "+", "1", ")", ",", "sz", "[", "0", "]", ")", "\n", "tneigh_left", "=", "max", "(", "round", "(", "max_disp1", "[", "1", "]", ".", "item", "(", ")", "-", "target_neigh_sz", "[", "1", "]", ".", "item", "(", ")", "/", "2", ")", ",", "0", ")", "\n", "tneigh_right", "=", "min", "(", "round", "(", "max_disp1", "[", "1", "]", ".", "item", "(", ")", "+", "target_neigh_sz", "[", "1", "]", ".", "item", "(", ")", "/", "2", "+", "1", ")", ",", "sz", "[", "1", "]", ")", "\n", "scores_masked", "=", "scores_hn", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", ".", "clone", "(", ")", "\n", "scores_masked", "[", "...", ",", "tneigh_top", ":", "tneigh_bottom", ",", "tneigh_left", ":", "tneigh_right", "]", "=", "0", "\n", "\n", "# Find new maximum", "\n", "max_score2", ",", "max_disp2", "=", "dcf", ".", "max2d", "(", "scores_masked", ")", "\n", "max_disp2", "=", "max_disp2", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp2", "=", "max_disp2", "-", "score_center", "\n", "translation_vec2", "=", "target_disp2", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scale", "\n", "\n", "prev_target_vec", "=", "(", "self", ".", "pos", "-", "sample_pos", "[", "scale_ind", ",", ":", "]", ")", "/", "(", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scale", ")", "\n", "\n", "# Handle the different cases", "\n", "if", "max_score2", ">", "self", ".", "params", ".", "distractor_threshold", "*", "max_score1", ":", "\n", "            ", "disp_norm1", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "target_disp1", "-", "prev_target_vec", ")", "**", "2", ")", ")", "\n", "disp_norm2", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "target_disp2", "-", "prev_target_vec", ")", "**", "2", ")", ")", "\n", "disp_threshold", "=", "self", ".", "params", ".", "dispalcement_scale", "*", "math", ".", "sqrt", "(", "sz", "[", "0", "]", "*", "sz", "[", "1", "]", ")", "/", "2", "\n", "\n", "if", "disp_norm2", ">", "disp_threshold", "and", "disp_norm1", "<", "disp_threshold", ":", "\n", "                ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", "\n", "", "if", "disp_norm2", "<", "disp_threshold", "and", "disp_norm1", ">", "disp_threshold", ":", "\n", "                ", "return", "translation_vec2", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", "\n", "", "if", "disp_norm2", ">", "disp_threshold", "and", "disp_norm1", ">", "disp_threshold", ":", "\n", "                ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'uncertain'", "\n", "\n", "# If also the distractor is close, return with highest score", "\n", "", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'uncertain'", "\n", "\n", "", "if", "max_score2", ">", "self", ".", "params", ".", "hard_negative_threshold", "*", "max_score1", "and", "max_score2", ">", "self", ".", "params", ".", "target_not_found_threshold", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", "\n", "\n", "", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'normal'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.extract_backbone_features": [[305, 312], ["pytracking.features.preprocessing.sample_patch_multiscale", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp.DiMP.net.extract_backbone", "dimp.DiMP.params.get", "dimp.DiMP.params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_multiscale", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "extract_backbone_features", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ",", "pos", ":", "torch", ".", "Tensor", ",", "scales", ",", "sz", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "im_patches", ",", "patch_coords", "=", "sample_patch_multiscale", "(", "im", ",", "pos", ",", "scales", ",", "sz", ",", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", ",", "\n", "max_scale_change", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ",", "None", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im_patches", ")", "\n", "", "return", "backbone_feat", ",", "patch_coords", ",", "im_patches", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.get_classification_features": [[313, 316], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp.DiMP.net.extract_classification_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat"], ["", "def", "get_classification_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "extract_classification_feat", "(", "backbone_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.get_iou_backbone_features": [[317, 319], ["dimp.DiMP.net.get_backbone_bbreg_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.get_backbone_bbreg_feat"], ["", "", "def", "get_iou_backbone_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "return", "self", ".", "net", ".", "get_backbone_bbreg_feat", "(", "backbone_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.get_iou_features": [[320, 323], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp.DiMP.net.bb_regressor.get_iou_feat", "dimp.DiMP.get_iou_backbone_features"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_iou_feat", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_backbone_features"], ["", "def", "get_iou_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "bb_regressor", ".", "get_iou_feat", "(", "self", ".", "get_iou_backbone_features", "(", "backbone_feat", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.get_iou_modulation": [[324, 327], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp.DiMP.net.bb_regressor.get_modulation"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_modulation"], ["", "", "def", "get_iou_modulation", "(", "self", ",", "iou_backbone_feat", ",", "target_boxes", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "bb_regressor", ".", "get_modulation", "(", "iou_backbone_feat", ",", "target_boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.generate_init_samples": [[329, 398], ["dimp.DiMP.params.get", "dimp.DiMP.pos.round", "dimp.DiMP.params.get", "dimp.DiMP.img_sample_sz.clone", "dimp.DiMP.params.get", "pytracking.features.preprocessing.sample_patch_transformed", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "shrink_factor.min.min.clamp_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "aug_expansion_sz.float.float.float", "dimp.DiMP.img_sample_sz.long().tolist", "pytracking.features.augmentation.Identity", "dimp.DiMP.params.get", "dimp.DiMP.transforms.extend", "dimp.DiMP.transforms.extend", "dimp.DiMP.transforms.append", "dimp.DiMP.transforms.extend", "dimp.DiMP.transforms.extend", "dimp.DiMP.transforms.extend", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp.DiMP.net.extract_backbone", "sample_sz.float", "shrink_factor.min.min.max", "sample_sz.float", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "pytracking.features.augmentation.FlipHorizontal", "shrink_factor.min.min.min", "dimp.DiMP.params.get", "dimp.DiMP.img_sample_sz.long", "dimp.DiMP.img_sample_sz.long", "pytracking.features.augmentation.Translation", "pytracking.features.augmentation.Translation", "get_rand_shift", "pytracking.features.augmentation.Blur", "pytracking.features.augmentation.Scale", "pytracking.features.augmentation.Rotate", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "get_absolute", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "get_rand_shift", "get_rand_shift", "get_rand_shift", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_transformed", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "", "def", "generate_init_samples", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Perform data augmentation to generate initial training samples.\"\"\"", "\n", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", "\n", "if", "mode", "==", "'inside'", ":", "\n", "# Get new sample size if forced inside the image", "\n", "            ", "im_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "sample_sz", "=", "self", ".", "target_scale", "*", "self", ".", "img_sample_sz", "\n", "shrink_factor", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "im_sz", ")", "\n", "if", "mode", "==", "'inside'", ":", "\n", "                ", "shrink_factor", "=", "shrink_factor", ".", "max", "(", ")", "\n", "", "elif", "mode", "==", "'inside_major'", ":", "\n", "                ", "shrink_factor", "=", "shrink_factor", ".", "min", "(", ")", "\n", "", "shrink_factor", ".", "clamp_", "(", "min", "=", "1", ",", "max", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ",", "None", ")", ")", "\n", "sample_sz", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "shrink_factor", ")", "\n", "self", ".", "init_sample_scale", "=", "(", "sample_sz", "/", "self", ".", "img_sample_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "tl", "=", "self", ".", "pos", "-", "(", "sample_sz", "-", "1", ")", "/", "2", "\n", "br", "=", "self", ".", "pos", "+", "sample_sz", "/", "2", "+", "1", "\n", "global_shift", "=", "-", "(", "(", "-", "tl", ")", ".", "clamp", "(", "0", ")", "-", "(", "br", "-", "im_sz", ")", ".", "clamp", "(", "0", ")", ")", "/", "self", ".", "init_sample_scale", "\n", "", "else", ":", "\n", "            ", "self", ".", "init_sample_scale", "=", "self", ".", "target_scale", "\n", "global_shift", "=", "torch", ".", "zeros", "(", "2", ")", "\n", "\n", "", "self", ".", "init_sample_pos", "=", "self", ".", "pos", ".", "round", "(", ")", "\n", "\n", "# Compute augmentation size", "\n", "aug_expansion_factor", "=", "self", ".", "params", ".", "get", "(", "'augmentation_expansion_factor'", ",", "None", ")", "\n", "aug_expansion_sz", "=", "self", ".", "img_sample_sz", ".", "clone", "(", ")", "\n", "aug_output_sz", "=", "None", "\n", "if", "aug_expansion_factor", "is", "not", "None", "and", "aug_expansion_factor", "!=", "1", ":", "\n", "            ", "aug_expansion_sz", "=", "(", "self", ".", "img_sample_sz", "*", "aug_expansion_factor", ")", ".", "long", "(", ")", "\n", "aug_expansion_sz", "+=", "(", "aug_expansion_sz", "-", "self", ".", "img_sample_sz", ".", "long", "(", ")", ")", "%", "2", "\n", "aug_expansion_sz", "=", "aug_expansion_sz", ".", "float", "(", ")", "\n", "aug_output_sz", "=", "self", ".", "img_sample_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Random shift for each sample", "\n", "", "get_rand_shift", "=", "lambda", ":", "None", "\n", "random_shift_factor", "=", "self", ".", "params", ".", "get", "(", "'random_shift_factor'", ",", "0", ")", "\n", "if", "random_shift_factor", ">", "0", ":", "\n", "            ", "get_rand_shift", "=", "lambda", ":", "(", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "*", "self", ".", "img_sample_sz", "*", "random_shift_factor", "+", "global_shift", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Always put identity transformation first, since it is the unaugmented sample that is always used", "\n", "", "self", ".", "transforms", "=", "[", "augmentation", ".", "Identity", "(", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "]", "\n", "\n", "augs", "=", "self", ".", "params", ".", "augmentation", "if", "self", ".", "params", ".", "get", "(", "'use_augmentation'", ",", "True", ")", "else", "{", "}", "\n", "\n", "# Add all augmentations", "\n", "if", "'shift'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "shift", ",", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "for", "shift", "in", "augs", "[", "'shift'", "]", "]", ")", "\n", "", "if", "'relativeshift'", "in", "augs", ":", "\n", "            ", "get_absolute", "=", "lambda", "shift", ":", "(", "torch", ".", "Tensor", "(", "shift", ")", "*", "self", ".", "img_sample_sz", "/", "2", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "get_absolute", "(", "shift", ")", ",", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "for", "shift", "in", "augs", "[", "'relativeshift'", "]", "]", ")", "\n", "", "if", "'fliplr'", "in", "augs", "and", "augs", "[", "'fliplr'", "]", ":", "\n", "            ", "self", ".", "transforms", ".", "append", "(", "augmentation", ".", "FlipHorizontal", "(", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", ")", "\n", "", "if", "'blur'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Blur", "(", "sigma", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "sigma", "in", "augs", "[", "'blur'", "]", "]", ")", "\n", "", "if", "'scale'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Scale", "(", "scale_factor", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "scale_factor", "in", "augs", "[", "'scale'", "]", "]", ")", "\n", "", "if", "'rotate'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Rotate", "(", "angle", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "angle", "in", "augs", "[", "'rotate'", "]", "]", ")", "\n", "\n", "# Extract augmented image patches", "\n", "", "im_patches", "=", "sample_patch_transformed", "(", "im", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ",", "aug_expansion_sz", ",", "self", ".", "transforms", ")", "\n", "\n", "# Extract initial backbone features", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "init_backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im_patches", ")", "\n", "\n", "", "return", "init_backbone_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.init_target_boxes": [[399, 409], ["dimp.DiMP.get_iounet_box", "pytracking.TensorList", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to.new_zeros", "torch.cat().to.new_zeros", "torch.cat().to.append", "torch.cat().to.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat().to.view", "torch.cat().to.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "init_target_boxes", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the target bounding boxes for the initial augmented samples.\"\"\"", "\n", "self", ".", "classifier_target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ")", "\n", "init_target_boxes", "=", "TensorList", "(", ")", "\n", "for", "T", "in", "self", ".", "transforms", ":", "\n", "            ", "init_target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "T", ".", "shift", "[", "1", "]", ",", "T", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "init_target_boxes", "=", "torch", ".", "cat", "(", "init_target_boxes", ".", "view", "(", "1", ",", "4", ")", ",", "0", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "self", ".", "target_boxes", "=", "init_target_boxes", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "4", ")", "\n", "self", ".", "target_boxes", "[", ":", "init_target_boxes", ".", "shape", "[", "0", "]", ",", ":", "]", "=", "init_target_boxes", "\n", "return", "init_target_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.init_memory": [[410, 428], ["train_x.size", "pytracking.TensorList", "dimp.DiMP.num_init_samples.copy", "pytracking.TensorList", "zip", "pytracking.TensorList", "zip", "len", "x.new_zeros", "x.new_zeros", "x.new_ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "def", "init_memory", "(", "self", ",", "train_x", ":", "TensorList", ")", ":", "\n", "# Initialize first-frame spatial training samples", "\n", "        ", "self", ".", "num_init_samples", "=", "train_x", ".", "size", "(", "0", ")", "\n", "init_sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_ones", "(", "1", ")", "/", "x", ".", "shape", "[", "0", "]", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "# Sample counters and weights for spatial", "\n", "self", ".", "num_stored_samples", "=", "self", ".", "num_init_samples", ".", "copy", "(", ")", "\n", "self", ".", "previous_replace_ind", "=", "[", "None", "]", "*", "len", "(", "self", ".", "num_stored_samples", ")", "\n", "self", ".", "sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ")", "for", "x", "in", "train_x", "]", ")", "\n", "for", "sw", ",", "init_sw", ",", "num", "in", "zip", "(", "self", ".", "sample_weights", ",", "init_sample_weights", ",", "self", ".", "num_init_samples", ")", ":", "\n", "            ", "sw", "[", ":", "num", "]", "=", "init_sw", "\n", "\n", "# Initialize memory", "\n", "", "self", ".", "training_samples", "=", "TensorList", "(", "\n", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "for", "ts", ",", "x", "in", "zip", "(", "self", ".", "training_samples", ",", "train_x", ")", ":", "\n", "            ", "ts", "[", ":", "x", ".", "shape", "[", "0", "]", ",", "...", "]", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.update_memory": [[430, 443], ["dimp.DiMP.update_sample_weights", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_sample_weights"], ["", "", "def", "update_memory", "(", "self", ",", "sample_x", ":", "TensorList", ",", "target_box", ",", "learning_rate", "=", "None", ")", ":", "\n", "# Update weights and get replace ind", "\n", "        ", "replace_ind", "=", "self", ".", "update_sample_weights", "(", "self", ".", "sample_weights", ",", "self", ".", "previous_replace_ind", ",", "self", ".", "num_stored_samples", ",", "self", ".", "num_init_samples", ",", "learning_rate", ")", "\n", "self", ".", "previous_replace_ind", "=", "replace_ind", "\n", "\n", "# Update sample and label memory", "\n", "for", "train_samp", ",", "x", ",", "ind", "in", "zip", "(", "self", ".", "training_samples", ",", "sample_x", ",", "replace_ind", ")", ":", "\n", "            ", "train_samp", "[", "ind", ":", "ind", "+", "1", ",", "...", "]", "=", "x", "\n", "\n", "# Update bb memory", "\n", "", "self", ".", "target_boxes", "[", "replace_ind", "[", "0", "]", ",", ":", "]", "=", "target_box", "\n", "\n", "self", ".", "num_stored_samples", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.update_sample_weights": [[445, 485], ["zip", "dimp.DiMP.params.get", "sw.sum", "replace_ind.append", "torch.min", "torch.min", "torch.min", "torch.min", "sw[].sum", "sw[].sum", "r_ind.item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "update_sample_weights", "(", "self", ",", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ",", "learning_rate", "=", "None", ")", ":", "\n", "# Update weights and get index to replace", "\n", "        ", "replace_ind", "=", "[", "]", "\n", "for", "sw", ",", "prev_ind", ",", "num_samp", ",", "num_init", "in", "zip", "(", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ")", ":", "\n", "            ", "lr", "=", "learning_rate", "\n", "if", "lr", "is", "None", ":", "\n", "                ", "lr", "=", "self", ".", "params", ".", "learning_rate", "\n", "\n", "", "init_samp_weight", "=", "self", ".", "params", ".", "get", "(", "'init_samples_minimum_weight'", ",", "None", ")", "\n", "if", "init_samp_weight", "==", "0", ":", "\n", "                ", "init_samp_weight", "=", "None", "\n", "", "s_ind", "=", "0", "if", "init_samp_weight", "is", "None", "else", "num_init", "\n", "\n", "if", "num_samp", "==", "0", "or", "lr", "==", "1", ":", "\n", "                ", "sw", "[", ":", "]", "=", "0", "\n", "sw", "[", "0", "]", "=", "1", "\n", "r_ind", "=", "0", "\n", "", "else", ":", "\n", "# Get index to replace", "\n", "                ", "if", "num_samp", "<", "sw", ".", "shape", "[", "0", "]", ":", "\n", "                    ", "r_ind", "=", "num_samp", "\n", "", "else", ":", "\n", "                    ", "_", ",", "r_ind", "=", "torch", ".", "min", "(", "sw", "[", "s_ind", ":", "]", ",", "0", ")", "\n", "r_ind", "=", "r_ind", ".", "item", "(", ")", "+", "s_ind", "\n", "\n", "# Update weights", "\n", "", "if", "prev_ind", "is", "None", ":", "\n", "                    ", "sw", "/=", "1", "-", "lr", "\n", "sw", "[", "r_ind", "]", "=", "lr", "\n", "", "else", ":", "\n", "                    ", "sw", "[", "r_ind", "]", "=", "sw", "[", "prev_ind", "]", "/", "(", "1", "-", "lr", ")", "\n", "\n", "", "", "sw", "/=", "sw", ".", "sum", "(", ")", "\n", "if", "init_samp_weight", "is", "not", "None", "and", "sw", "[", ":", "num_init", "]", ".", "sum", "(", ")", "<", "init_samp_weight", ":", "\n", "                ", "sw", "/=", "init_samp_weight", "+", "sw", "[", "num_init", ":", "]", ".", "sum", "(", ")", "\n", "sw", "[", ":", "num_init", "]", "=", "init_samp_weight", "/", "num_init", "\n", "\n", "", "replace_ind", ".", "append", "(", "r_ind", ")", "\n", "\n", "", "return", "replace_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.update_state": [[486, 496], ["dimp.DiMP.params.get", "torch.max", "torch.max", "torch.max", "torch.max", "new_scale.clamp", "torch.min", "torch.min", "torch.min", "torch.min"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "update_state", "(", "self", ",", "new_pos", ",", "new_scale", "=", "None", ")", ":", "\n", "# Update scale", "\n", "        ", "if", "new_scale", "is", "not", "None", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", ".", "clamp", "(", "self", ".", "min_scale_factor", ",", "self", ".", "max_scale_factor", ")", "\n", "self", ".", "target_sz", "=", "self", ".", "base_target_sz", "*", "self", ".", "target_scale", "\n", "\n", "# Update pos", "\n", "", "inside_ratio", "=", "self", ".", "params", ".", "get", "(", "'target_inside_ratio'", ",", "0.2", ")", "\n", "inside_offset", "=", "(", "inside_ratio", "-", "0.5", ")", "*", "self", ".", "target_sz", "\n", "self", ".", "pos", "=", "torch", ".", "max", "(", "torch", ".", "min", "(", "new_pos", ",", "self", ".", "image_sz", "-", "inside_offset", ")", ",", "inside_offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.get_iounet_box": [[498, 505], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "target_ul.flip", "box_sz.flip"], "methods", ["None"], ["", "def", "get_iounet_box", "(", "self", ",", "pos", ",", "sz", ",", "sample_pos", ",", "sample_scale", ")", ":", "\n", "        ", "\"\"\"All inputs in original image coordinates.\n        Generates a box in the cropped image sample reference frame, in the format used by the IoUNet.\"\"\"", "\n", "box_center", "=", "(", "pos", "-", "sample_pos", ")", "/", "sample_scale", "+", "(", "self", ".", "img_sample_sz", "-", "1", ")", "/", "2", "\n", "box_sz", "=", "sz", "/", "sample_scale", "\n", "target_ul", "=", "box_center", "-", "(", "box_sz", "-", "1", ")", "/", "2", "\n", "return", "torch", ".", "cat", "(", "[", "target_ul", ".", "flip", "(", "(", "0", ",", ")", ")", ",", "box_sz", ".", "flip", "(", "(", "0", ",", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.init_iou_net": [[507, 534], ["dimp.DiMP.net.bb_regressor.parameters", "dimp.DiMP.get_iounet_box", "pytracking.TensorList", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "dimp.DiMP.get_iou_backbone_features", "pytracking.TensorList", "dimp.DiMP.get_iou_modulation", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.cat().to.append", "torch.cat().to.append", "pytracking.TensorList", "torch.cat().to.append", "torch.cat().to.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "isinstance", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat().to.view", "torch.cat().to.view", "x.detach().mean", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "x.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_iou_modulation", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "init_iou_net", "(", "self", ",", "backbone_feat", ")", ":", "\n", "# Setup IoU net and objective", "\n", "        ", "for", "p", "in", "self", ".", "net", ".", "bb_regressor", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "# Get target boxes for the different augmentations", "\n", "", "self", ".", "classifier_target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ")", "\n", "target_boxes", "=", "TensorList", "(", ")", "\n", "if", "self", ".", "params", ".", "iounet_augmentation", ":", "\n", "            ", "for", "T", "in", "self", ".", "transforms", ":", "\n", "                ", "if", "not", "isinstance", "(", "T", ",", "(", "augmentation", ".", "Identity", ",", "augmentation", ".", "Translation", ",", "augmentation", ".", "FlipHorizontal", ",", "augmentation", ".", "FlipVertical", ",", "augmentation", ".", "Blur", ")", ")", ":", "\n", "                    ", "break", "\n", "", "target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "T", ".", "shift", "[", "1", "]", ",", "T", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "self", ".", "transforms", "[", "0", "]", ".", "shift", "[", "1", "]", ",", "self", ".", "transforms", "[", "0", "]", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "target_boxes", "=", "torch", ".", "cat", "(", "target_boxes", ".", "view", "(", "1", ",", "4", ")", ",", "0", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "# Get iou features", "\n", "iou_backbone_feat", "=", "self", ".", "get_iou_backbone_features", "(", "backbone_feat", ")", "\n", "\n", "# Remove other augmentations such as rotation", "\n", "iou_backbone_feat", "=", "TensorList", "(", "[", "x", "[", ":", "target_boxes", ".", "shape", "[", "0", "]", ",", "...", "]", "for", "x", "in", "iou_backbone_feat", "]", ")", "\n", "\n", "# Get modulation vector", "\n", "self", ".", "iou_modulation", "=", "self", ".", "get_iou_modulation", "(", "iou_backbone_feat", ",", "target_boxes", ")", "\n", "if", "torch", ".", "is_tensor", "(", "self", ".", "iou_modulation", "[", "0", "]", ")", ":", "\n", "            ", "self", ".", "iou_modulation", "=", "TensorList", "(", "[", "x", ".", "detach", "(", ")", ".", "mean", "(", "0", ")", "for", "x", "in", "self", ".", "iou_modulation", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.init_classifier": [[536, 588], ["dimp.DiMP.get_classification_features", "dimp.DiMP._overwrite_classifier_params", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "dimp.DiMP.params.get", "dimp.DiMP.init_target_boxes", "dimp.DiMP.params.get", "dimp.DiMP.params.get", "dimp.DiMP.params.get", "dimp.DiMP.transforms.extend", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "list", "dimp.DiMP.params.get", "dimp.DiMP.output_window.squeeze", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp.DiMP.net.classifier.get_filter", "dimp.DiMP.init_memory", "isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "isinstance", "pytracking.dcf.hann2d_clipped().to", "pytracking.dcf.hann2d().to", "pytracking.TensorList", "dimp.DiMP.visdom.register", "torch.dropout2d", "torch.dropout2d", "pytracking.utils.plotting.plot_graph", "x[].expand", "pytracking.dcf.hann2d_clipped", "pytracking.dcf.hann2d", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "dimp.DiMP.output_sz.long", "dimp.DiMP.output_sz.long", "dimp.DiMP.losses.numel"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_classification_features", "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP._overwrite_classifier_params", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_target_boxes", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.get_filter", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_memory", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d_clipped", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d"], ["", "", "def", "init_classifier", "(", "self", ",", "init_backbone_feat", ")", ":", "\n", "# Get classification features", "\n", "        ", "x", "=", "self", ".", "get_classification_features", "(", "init_backbone_feat", ")", "\n", "\n", "# Overwrite some parameters in the classifier. (These are not generally changed)", "\n", "self", ".", "_overwrite_classifier_params", "(", "feature_dim", "=", "x", ".", "shape", "[", "-", "3", "]", ")", "\n", "\n", "# Add the dropout augmentation here, since it requires extraction of the classification features", "\n", "if", "'dropout'", "in", "self", ".", "params", ".", "augmentation", "and", "self", ".", "params", ".", "get", "(", "'use_augmentation'", ",", "True", ")", ":", "\n", "            ", "num", ",", "prob", "=", "self", ".", "params", ".", "augmentation", "[", "'dropout'", "]", "\n", "self", ".", "transforms", ".", "extend", "(", "self", ".", "transforms", "[", ":", "1", "]", "*", "num", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "F", ".", "dropout2d", "(", "x", "[", "0", ":", "1", ",", "...", "]", ".", "expand", "(", "num", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", ",", "p", "=", "prob", ",", "training", "=", "True", ")", "]", ")", "\n", "\n", "# Set feature size and other related sizes", "\n", "", "self", ".", "feature_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "x", ".", "shape", "[", "-", "2", ":", "]", ")", ")", "\n", "ksz", "=", "self", ".", "net", ".", "classifier", ".", "filter_size", "\n", "self", ".", "kernel_size", "=", "torch", ".", "Tensor", "(", "[", "ksz", ",", "ksz", "]", "if", "isinstance", "(", "ksz", ",", "(", "int", ",", "float", ")", ")", "else", "ksz", ")", "\n", "self", ".", "output_sz", "=", "self", ".", "feature_sz", "+", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "\n", "# Construct output window", "\n", "self", ".", "output_window", "=", "None", "\n", "if", "self", ".", "params", ".", "get", "(", "'window_output'", ",", "False", ")", ":", "\n", "            ", "if", "self", ".", "params", ".", "get", "(", "'use_clipped_window'", ",", "False", ")", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d_clipped", "(", "self", ".", "output_sz", ".", "long", "(", ")", ",", "(", "self", ".", "output_sz", "*", "self", ".", "params", ".", "effective_search_area", "/", "self", ".", "params", ".", "search_area_scale", ")", ".", "long", "(", ")", ",", "centered", "=", "True", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d", "(", "self", ".", "output_sz", ".", "long", "(", ")", ",", "centered", "=", "True", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "", "self", ".", "output_window", "=", "self", ".", "output_window", ".", "squeeze", "(", "0", ")", "\n", "\n", "# Get target boxes for the different augmentations", "\n", "", "target_boxes", "=", "self", ".", "init_target_boxes", "(", ")", "\n", "\n", "# Set number of iterations", "\n", "plot_loss", "=", "self", ".", "params", ".", "debug", ">", "0", "\n", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_iter'", ",", "None", ")", "\n", "\n", "# Get target filter by running the discriminative model prediction module", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "target_filter", ",", "_", ",", "losses", "=", "self", ".", "net", ".", "classifier", ".", "get_filter", "(", "x", ",", "target_boxes", ",", "num_iter", "=", "num_iter", ",", "\n", "compute_losses", "=", "plot_loss", ")", "\n", "\n", "# Init memory", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'update_classifier'", ",", "True", ")", ":", "\n", "            ", "self", ".", "init_memory", "(", "TensorList", "(", "[", "x", "]", ")", ")", "\n", "\n", "", "if", "plot_loss", ":", "\n", "            ", "if", "isinstance", "(", "losses", ",", "dict", ")", ":", "\n", "                ", "losses", "=", "losses", "[", "'train'", "]", "\n", "", "self", ".", "losses", "=", "torch", ".", "cat", "(", "losses", ")", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                ", "self", ".", "visdom", ".", "register", "(", "(", "self", ".", "losses", ",", "torch", ".", "arange", "(", "self", ".", "losses", ".", "numel", "(", ")", ")", ")", ",", "'lineplot'", ",", "3", ",", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "", "elif", "self", ".", "params", ".", "debug", ">=", "3", ":", "\n", "                ", "plot_graph", "(", "self", ".", "losses", ",", "10", ",", "title", "=", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP._overwrite_classifier_params": [[589, 603], ["getattr", "dimp.DiMP.params.get", "dimp.DiMP.params.get", "dimp.DiMP.params.get", "dimp.DiMP.params.get", "dimp.DiMP.params.get", "ltr.models.target_classifier.initializer.FilterInitializerZero"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "", "", "def", "_overwrite_classifier_params", "(", "self", ",", "feature_dim", ")", ":", "\n", "# Overwrite some parameters in the classifier. (These are not generally changed)", "\n", "        ", "pred_module", "=", "getattr", "(", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ",", "'score_predictor'", ",", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'label_threshold'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ".", "label_threshold", "=", "self", ".", "params", ".", "label_threshold", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'label_shrink'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ".", "label_shrink", "=", "self", ".", "params", ".", "label_shrink", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'softmax_reg'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ".", "softmax_reg", "=", "self", ".", "params", ".", "softmax_reg", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'filter_reg'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "pred_module", ".", "filter_reg", "[", "0", "]", "=", "self", ".", "params", ".", "filter_reg", "\n", "pred_module", ".", "min_filter_reg", "=", "self", ".", "params", ".", "filter_reg", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'filter_init_zero'", ",", "False", ")", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_initializer", "=", "FilterInitializerZero", "(", "self", ".", "net", ".", "classifier", ".", "filter_size", ",", "feature_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.update_classifier": [[605, 649], ["dimp.DiMP.params.get", "dimp.DiMP.update_memory", "dimp.DiMP.params.get", "dimp.DiMP.target_boxes[].clone", "pytracking.TensorList", "dimp.DiMP.params.get", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dimp.DiMP.net.classifier.filter_optimizer", "isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dimp.DiMP.params.get", "scores.max().item", "dimp.DiMP.params.get", "dimp.DiMP.visdom.register", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytracking.utils.plotting.plot_graph", "scores.max", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "dimp.DiMP.losses.numel"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_memory", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph"], ["", "", "def", "update_classifier", "(", "self", ",", "train_x", ",", "target_box", ",", "learning_rate", "=", "None", ",", "scores", "=", "None", ")", ":", "\n", "# Set flags and learning rate", "\n", "        ", "hard_negative_flag", "=", "learning_rate", "is", "not", "None", "\n", "if", "learning_rate", "is", "None", ":", "\n", "            ", "learning_rate", "=", "self", ".", "params", ".", "learning_rate", "\n", "\n", "# Update the tracker memory", "\n", "", "if", "hard_negative_flag", "or", "self", ".", "frame_num", "%", "self", ".", "params", ".", "get", "(", "'train_sample_interval'", ",", "1", ")", "==", "0", ":", "\n", "            ", "self", ".", "update_memory", "(", "TensorList", "(", "[", "train_x", "]", ")", ",", "target_box", ",", "learning_rate", ")", "\n", "\n", "# Decide the number of iterations to run", "\n", "", "num_iter", "=", "0", "\n", "low_score_th", "=", "self", ".", "params", ".", "get", "(", "'low_score_opt_threshold'", ",", "None", ")", "\n", "if", "hard_negative_flag", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_hn_iter'", ",", "None", ")", "\n", "", "elif", "low_score_th", "is", "not", "None", "and", "low_score_th", ">", "scores", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_low_iter'", ",", "None", ")", "\n", "", "elif", "(", "self", ".", "frame_num", "-", "1", ")", "%", "self", ".", "params", ".", "train_skipping", "==", "0", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_update_iter'", ",", "None", ")", "\n", "\n", "", "plot_loss", "=", "self", ".", "params", ".", "debug", ">", "0", "\n", "\n", "if", "num_iter", ">", "0", ":", "\n", "# Get inputs for the DiMP filter optimizer module", "\n", "            ", "samples", "=", "self", ".", "training_samples", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", "...", "]", "\n", "target_boxes", "=", "self", ".", "target_boxes", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", ":", "]", ".", "clone", "(", ")", "\n", "sample_weights", "=", "self", ".", "sample_weights", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", "]", "\n", "\n", "# Run the filter optimizer module", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "target_filter", ",", "_", ",", "losses", "=", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", "(", "self", ".", "target_filter", ",", "\n", "num_iter", "=", "num_iter", ",", "feat", "=", "samples", ",", "\n", "bb", "=", "target_boxes", ",", "\n", "sample_weight", "=", "sample_weights", ",", "\n", "compute_losses", "=", "plot_loss", ")", "\n", "\n", "", "if", "plot_loss", ":", "\n", "                ", "if", "isinstance", "(", "losses", ",", "dict", ")", ":", "\n", "                    ", "losses", "=", "losses", "[", "'train'", "]", "\n", "", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "torch", ".", "cat", "(", "losses", ")", ")", ")", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                    ", "self", ".", "visdom", ".", "register", "(", "(", "self", ".", "losses", ",", "torch", ".", "arange", "(", "self", ".", "losses", ".", "numel", "(", ")", ")", ")", ",", "'lineplot'", ",", "3", ",", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "", "elif", "self", ".", "params", ".", "debug", ">=", "3", ":", "\n", "                    ", "plot_graph", "(", "self", ".", "losses", ",", "10", ",", "title", "=", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.refine_target_box": [[650, 712], ["hasattr", "dimp.DiMP.get_iounet_box", "dimp.DiMP.get_iou_features", "pytracking.TensorList", "dimp.DiMP.view().clone", "dimp.DiMP.optimize_boxes", "output_boxes[].clamp_", "dimp.DiMP.params.get", "min", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "output_boxes[].mean", "[].mean", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "new_pos.clone", "dimp.DiMP.params.get", "dimp.DiMP.direct_box_regression", "init_box[].prod().sqrt", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "predicted_box[].flip", "new_pos.clone", "dimp.DiMP.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "init_box[].min", "new_target_sz.prod", "dimp.DiMP.base_target_sz.prod", "init_box[].prod", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "dimp.DiMP.view", "output_iou.view", "new_pos.flip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_features", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.optimize_boxes", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.direct_box_regression", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "", "", "", "def", "refine_target_box", "(", "self", ",", "backbone_feat", ",", "sample_pos", ",", "sample_scale", ",", "scale_ind", ",", "update_scale", "=", "True", ")", ":", "\n", "        ", "\"\"\"Run the ATOM IoUNet to refine the target bounding box.\"\"\"", "\n", "\n", "if", "hasattr", "(", "self", ".", "net", ".", "bb_regressor", ",", "'predict_bb'", ")", ":", "\n", "            ", "return", "self", ".", "direct_box_regression", "(", "backbone_feat", ",", "sample_pos", ",", "sample_scale", ",", "scale_ind", ",", "update_scale", ")", "\n", "\n", "# Initial box for refinement", "\n", "", "init_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", ",", "sample_scale", ")", "\n", "\n", "# Extract features from the relevant scale", "\n", "iou_features", "=", "self", ".", "get_iou_features", "(", "backbone_feat", ")", "\n", "iou_features", "=", "TensorList", "(", "[", "x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "for", "x", "in", "iou_features", "]", ")", "\n", "\n", "# Generate random initial boxes", "\n", "init_boxes", "=", "init_box", ".", "view", "(", "1", ",", "4", ")", ".", "clone", "(", ")", "\n", "if", "self", ".", "params", ".", "num_init_random_boxes", ">", "0", ":", "\n", "            ", "square_box_sz", "=", "init_box", "[", "2", ":", "]", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "rand_factor", "=", "square_box_sz", "*", "torch", ".", "cat", "(", "[", "self", ".", "params", ".", "box_jitter_pos", "*", "torch", ".", "ones", "(", "2", ")", ",", "self", ".", "params", ".", "box_jitter_sz", "*", "torch", ".", "ones", "(", "2", ")", "]", ")", "\n", "\n", "minimal_edge_size", "=", "init_box", "[", "2", ":", "]", ".", "min", "(", ")", "/", "3", "\n", "rand_bb", "=", "(", "torch", ".", "rand", "(", "self", ".", "params", ".", "num_init_random_boxes", ",", "4", ")", "-", "0.5", ")", "*", "rand_factor", "\n", "new_sz", "=", "(", "init_box", "[", "2", ":", "]", "+", "rand_bb", "[", ":", ",", "2", ":", "]", ")", ".", "clamp", "(", "minimal_edge_size", ")", "\n", "new_center", "=", "(", "init_box", "[", ":", "2", "]", "+", "init_box", "[", "2", ":", "]", "/", "2", ")", "+", "rand_bb", "[", ":", ",", ":", "2", "]", "\n", "init_boxes", "=", "torch", ".", "cat", "(", "[", "new_center", "-", "new_sz", "/", "2", ",", "new_sz", "]", ",", "1", ")", "\n", "init_boxes", "=", "torch", ".", "cat", "(", "[", "init_box", ".", "view", "(", "1", ",", "4", ")", ",", "init_boxes", "]", ")", "\n", "\n", "# Optimize the boxes", "\n", "", "output_boxes", ",", "output_iou", "=", "self", ".", "optimize_boxes", "(", "iou_features", ",", "init_boxes", ")", "\n", "\n", "# Remove weird boxes", "\n", "output_boxes", "[", ":", ",", "2", ":", "]", ".", "clamp_", "(", "1", ")", "\n", "aspect_ratio", "=", "output_boxes", "[", ":", ",", "2", "]", "/", "output_boxes", "[", ":", ",", "3", "]", "\n", "keep_ind", "=", "(", "aspect_ratio", "<", "self", ".", "params", ".", "maximal_aspect_ratio", ")", "*", "(", "aspect_ratio", ">", "1", "/", "self", ".", "params", ".", "maximal_aspect_ratio", ")", "\n", "output_boxes", "=", "output_boxes", "[", "keep_ind", ",", ":", "]", "\n", "output_iou", "=", "output_iou", "[", "keep_ind", "]", "\n", "\n", "# If no box found", "\n", "if", "output_boxes", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "# Predict box", "\n", "", "k", "=", "self", ".", "params", ".", "get", "(", "'iounet_k'", ",", "5", ")", "\n", "topk", "=", "min", "(", "k", ",", "output_boxes", ".", "shape", "[", "0", "]", ")", "\n", "_", ",", "inds", "=", "torch", ".", "topk", "(", "output_iou", ",", "topk", ")", "\n", "predicted_box", "=", "output_boxes", "[", "inds", ",", ":", "]", ".", "mean", "(", "0", ")", "\n", "predicted_iou", "=", "output_iou", ".", "view", "(", "-", "1", ",", "1", ")", "[", "inds", ",", ":", "]", ".", "mean", "(", "0", ")", "\n", "\n", "# Get new position and size", "\n", "new_pos", "=", "predicted_box", "[", ":", "2", "]", "+", "predicted_box", "[", "2", ":", "]", "/", "2", "\n", "new_pos", "=", "(", "new_pos", ".", "flip", "(", "(", "0", ",", ")", ")", "-", "(", "self", ".", "img_sample_sz", "-", "1", ")", "/", "2", ")", "*", "sample_scale", "+", "sample_pos", "\n", "new_target_sz", "=", "predicted_box", "[", "2", ":", "]", ".", "flip", "(", "(", "0", ",", ")", ")", "*", "sample_scale", "\n", "new_scale", "=", "torch", ".", "sqrt", "(", "new_target_sz", ".", "prod", "(", ")", "/", "self", ".", "base_target_sz", ".", "prod", "(", ")", ")", "\n", "\n", "self", ".", "pos_iounet", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iounet_pos_for_learning'", ",", "True", ")", ":", "\n", "            ", "self", ".", "pos", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "", "self", ".", "target_sz", "=", "new_target_sz", "\n", "\n", "if", "update_scale", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.optimize_boxes": [[716, 723], ["dimp.DiMP.params.get", "ValueError", "dimp.DiMP.optimize_boxes_default", "dimp.DiMP.optimize_boxes_relative"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.optimize_boxes_default", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.optimize_boxes_relative"], ["", "", "def", "optimize_boxes", "(", "self", ",", "iou_features", ",", "init_boxes", ")", ":", "\n", "        ", "box_refinement_space", "=", "self", ".", "params", ".", "get", "(", "'box_refinement_space'", ",", "'default'", ")", "\n", "if", "box_refinement_space", "==", "'default'", ":", "\n", "            ", "return", "self", ".", "optimize_boxes_default", "(", "iou_features", ",", "init_boxes", ")", "\n", "", "if", "box_refinement_space", "==", "'relative'", ":", "\n", "            ", "return", "self", ".", "optimize_boxes_relative", "(", "iou_features", ",", "init_boxes", ")", "\n", "", "raise", "ValueError", "(", "'Unknown box_refinement_space {}'", ".", "format", "(", "box_refinement_space", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.optimize_boxes_default": [[725, 751], ["init_boxes.view().to", "isinstance", "range", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "init_boxes.view().to.clone().detach", "dimp.DiMP.net.bb_regressor.predict_iou", "isinstance", "dimp.DiMP.backward", "init_boxes.view().to.detach_", "init_boxes.view().to.view().cpu", "dimp.DiMP.detach().view().cpu", "init_boxes.view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "init_boxes.view().to.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "bb_init[].repeat", "init_boxes.view().to.view", "dimp.DiMP.detach().view", "dimp.DiMP.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou"], ["", "def", "optimize_boxes_default", "(", "self", ",", "iou_features", ",", "init_boxes", ")", ":", "\n", "        ", "\"\"\"Optimize iounet boxes with the default parametrization\"\"\"", "\n", "output_boxes", "=", "init_boxes", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "step_length", "=", "self", ".", "params", ".", "box_refinement_step_length", "\n", "if", "isinstance", "(", "step_length", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "step_length", "=", "torch", ".", "Tensor", "(", "[", "step_length", "[", "0", "]", ",", "step_length", "[", "0", "]", ",", "step_length", "[", "1", "]", ",", "step_length", "[", "1", "]", "]", ",", "device", "=", "self", ".", "params", ".", "device", ")", ".", "view", "(", "1", ",", "1", ",", "4", ")", "\n", "\n", "", "for", "i_", "in", "range", "(", "self", ".", "params", ".", "box_refinement_iter", ")", ":", "\n", "# forward pass", "\n", "            ", "bb_init", "=", "output_boxes", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "bb_init", ".", "requires_grad", "=", "True", "\n", "\n", "outputs", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_iou", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "bb_init", ")", "\n", "\n", "if", "isinstance", "(", "outputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "outputs", "=", "outputs", "[", "0", "]", "\n", "\n", "", "outputs", ".", "backward", "(", "gradient", "=", "torch", ".", "ones_like", "(", "outputs", ")", ")", "\n", "\n", "# Update proposal", "\n", "output_boxes", "=", "bb_init", "+", "step_length", "*", "bb_init", ".", "grad", "*", "bb_init", "[", ":", ",", ":", ",", "2", ":", "]", ".", "repeat", "(", "1", ",", "1", ",", "2", ")", "\n", "output_boxes", ".", "detach_", "(", ")", "\n", "\n", "step_length", "*=", "self", ".", "params", ".", "box_refinement_step_decay", "\n", "\n", "", "return", "output_boxes", ".", "view", "(", "-", "1", ",", "4", ")", ".", "cpu", "(", ")", ",", "outputs", ".", "detach", "(", ")", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.optimize_boxes_relative": [[753, 789], ["init_boxes.view().to", "isinstance", "output_boxes[].clone", "ltr.rect_to_rel", "range", "ltr.rel_to_rect", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "ltr.rect_to_rel.clone().detach", "ltr.rel_to_rect", "dimp.DiMP.net.bb_regressor.predict_iou", "isinstance", "dimp.DiMP.backward", "ltr.rect_to_rel.detach_", "ltr.rel_to_rect.view().cpu", "dimp.DiMP.detach().view().cpu", "init_boxes.view", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "ltr.rect_to_rel.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "ltr.rel_to_rect.view", "dimp.DiMP.detach().view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "dimp.DiMP.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rect_to_rel", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "optimize_boxes_relative", "(", "self", ",", "iou_features", ",", "init_boxes", ")", ":", "\n", "        ", "\"\"\"Optimize iounet boxes with the relative parametrization ised in PrDiMP\"\"\"", "\n", "output_boxes", "=", "init_boxes", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "step_length", "=", "self", ".", "params", ".", "box_refinement_step_length", "\n", "if", "isinstance", "(", "step_length", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "step_length", "=", "torch", ".", "Tensor", "(", "[", "step_length", "[", "0", "]", ",", "step_length", "[", "0", "]", ",", "step_length", "[", "1", "]", ",", "step_length", "[", "1", "]", "]", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", ".", "view", "(", "1", ",", "1", ",", "4", ")", "\n", "\n", "", "sz_norm", "=", "output_boxes", "[", ":", ",", ":", "1", ",", "2", ":", "]", ".", "clone", "(", ")", "\n", "output_boxes_rel", "=", "bbutils", ".", "rect_to_rel", "(", "output_boxes", ",", "sz_norm", ")", "\n", "for", "i_", "in", "range", "(", "self", ".", "params", ".", "box_refinement_iter", ")", ":", "\n", "# forward pass", "\n", "            ", "bb_init_rel", "=", "output_boxes_rel", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "bb_init_rel", ".", "requires_grad", "=", "True", "\n", "\n", "bb_init", "=", "bbutils", ".", "rel_to_rect", "(", "bb_init_rel", ",", "sz_norm", ")", "\n", "outputs", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_iou", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "bb_init", ")", "\n", "\n", "if", "isinstance", "(", "outputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "outputs", "=", "outputs", "[", "0", "]", "\n", "\n", "", "outputs", ".", "backward", "(", "gradient", "=", "torch", ".", "ones_like", "(", "outputs", ")", ")", "\n", "\n", "# Update proposal", "\n", "output_boxes_rel", "=", "bb_init_rel", "+", "step_length", "*", "bb_init_rel", ".", "grad", "\n", "output_boxes_rel", ".", "detach_", "(", ")", "\n", "\n", "step_length", "*=", "self", ".", "params", ".", "box_refinement_step_decay", "\n", "\n", "#     for s in outputs.view(-1):", "\n", "#         print('{:.2f}  '.format(s.item()), end='')", "\n", "#     print('')", "\n", "# print('')", "\n", "\n", "", "output_boxes", "=", "bbutils", ".", "rel_to_rect", "(", "output_boxes_rel", ",", "sz_norm", ")", "\n", "\n", "return", "output_boxes", ".", "view", "(", "-", "1", ",", "4", ")", ".", "cpu", "(", ")", ",", "outputs", ".", "detach", "(", ")", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.direct_box_regression": [[790, 827], ["dimp.DiMP.get_iounet_box", "dimp.DiMP.get_iou_features", "pytracking.TensorList", "dimp.DiMP.view().clone().to", "dimp.DiMP.net.bb_regressor.predict_bb().view().cpu", "output_boxes[].clamp_", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "new_pos.clone", "dimp.DiMP.params.get", "predicted_box[].flip", "new_pos.clone", "dimp.DiMP.view().clone", "dimp.DiMP.net.bb_regressor.predict_bb().view", "new_target_sz.prod", "dimp.DiMP.base_target_sz.prod", "new_pos.flip", "dimp.DiMP.view", "dimp.DiMP.net.bb_regressor.predict_bb"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_features", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "direct_box_regression", "(", "self", ",", "backbone_feat", ",", "sample_pos", ",", "sample_scale", ",", "scale_ind", ",", "update_scale", "=", "True", ")", ":", "\n", "        ", "\"\"\"Implementation of direct bounding box regression.\"\"\"", "\n", "\n", "# Initial box for refinement", "\n", "init_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", ",", "sample_scale", ")", "\n", "\n", "# Extract features from the relevant scale", "\n", "iou_features", "=", "self", ".", "get_iou_features", "(", "backbone_feat", ")", "\n", "iou_features", "=", "TensorList", "(", "[", "x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "for", "x", "in", "iou_features", "]", ")", "\n", "\n", "# Generate random initial boxes", "\n", "init_boxes", "=", "init_box", ".", "view", "(", "1", ",", "1", ",", "4", ")", ".", "clone", "(", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "# Optimize the boxes", "\n", "output_boxes", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_bb", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "init_boxes", ")", ".", "view", "(", "-", "1", ",", "4", ")", ".", "cpu", "(", ")", "\n", "\n", "# Remove weird boxes", "\n", "output_boxes", "[", ":", ",", "2", ":", "]", ".", "clamp_", "(", "1", ")", "\n", "\n", "predicted_box", "=", "output_boxes", "[", "0", ",", ":", "]", "\n", "\n", "# Get new position and size", "\n", "new_pos", "=", "predicted_box", "[", ":", "2", "]", "+", "predicted_box", "[", "2", ":", "]", "/", "2", "\n", "new_pos", "=", "(", "new_pos", ".", "flip", "(", "(", "0", ",", ")", ")", "-", "(", "self", ".", "img_sample_sz", "-", "1", ")", "/", "2", ")", "*", "sample_scale", "+", "sample_pos", "\n", "new_target_sz", "=", "predicted_box", "[", "2", ":", "]", ".", "flip", "(", "(", "0", ",", ")", ")", "*", "sample_scale", "\n", "new_scale_bbr", "=", "torch", ".", "sqrt", "(", "new_target_sz", ".", "prod", "(", ")", "/", "self", ".", "base_target_sz", ".", "prod", "(", ")", ")", "\n", "new_scale", "=", "new_scale_bbr", "\n", "\n", "self", ".", "pos_iounet", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iounet_pos_for_learning'", ",", "True", ")", ":", "\n", "            ", "self", ".", "pos", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "", "self", ".", "target_sz", "=", "new_target_sz", "\n", "\n", "if", "update_scale", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.visualize_iou_pred": [[829, 859], ["center_box.view.view.view", "center_box[].clone", "ltr.rect_to_rel", "math.log", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange.clone", "torch.arange.clone", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange.clone", "torch.arange.clone", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange.clone", "torch.arange.clone", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange.clone", "torch.arange.clone", "ltr.rel_to_rect().view().to", "ltr.rel_to_rect().view().to", "dimp.DiMP.net.bb_regressor.predict_iou().exp", "dimp.DiMP.net.bb_regressor.predict_iou().exp", "pytracking.utils.plotting.show_tensor", "pytracking.utils.plotting.show_tensor", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "dimp.DiMP.view", "dimp.DiMP.view", "ltr.rel_to_rect().view", "ltr.rel_to_rect().view", "dimp.DiMP.net.bb_regressor.predict_iou", "dimp.DiMP.net.bb_regressor.predict_iou", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "torch.arange.numel", "ltr.rel_to_rect", "ltr.rel_to_rect"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rect_to_rel", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_tensor", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_tensor", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect"], ["", "", "def", "visualize_iou_pred", "(", "self", ",", "iou_features", ",", "center_box", ")", ":", "\n", "        ", "center_box", "=", "center_box", ".", "view", "(", "1", ",", "1", ",", "4", ")", "\n", "sz_norm", "=", "center_box", "[", "...", ",", "2", ":", "]", ".", "clone", "(", ")", "\n", "center_box_rel", "=", "bbutils", ".", "rect_to_rel", "(", "center_box", ",", "sz_norm", ")", "\n", "\n", "pos_dist", "=", "1.0", "\n", "sz_dist", "=", "math", ".", "log", "(", "3.0", ")", "\n", "pos_step", "=", "0.01", "\n", "sz_step", "=", "0.01", "\n", "\n", "pos_scale", "=", "torch", ".", "arange", "(", "-", "pos_dist", ",", "pos_dist", "+", "pos_step", ",", "step", "=", "pos_step", ")", "\n", "sz_scale", "=", "torch", ".", "arange", "(", "-", "sz_dist", ",", "sz_dist", "+", "sz_step", ",", "step", "=", "sz_step", ")", "\n", "\n", "bbx", "=", "torch", ".", "zeros", "(", "1", ",", "pos_scale", ".", "numel", "(", ")", ",", "4", ")", "\n", "bbx", "[", "0", ",", ":", ",", "0", "]", "=", "pos_scale", ".", "clone", "(", ")", "\n", "bby", "=", "torch", ".", "zeros", "(", "pos_scale", ".", "numel", "(", ")", ",", "1", ",", "4", ")", "\n", "bby", "[", ":", ",", "0", ",", "1", "]", "=", "pos_scale", ".", "clone", "(", ")", "\n", "bbw", "=", "torch", ".", "zeros", "(", "1", ",", "sz_scale", ".", "numel", "(", ")", ",", "4", ")", "\n", "bbw", "[", "0", ",", ":", ",", "2", "]", "=", "sz_scale", ".", "clone", "(", ")", "\n", "bbh", "=", "torch", ".", "zeros", "(", "sz_scale", ".", "numel", "(", ")", ",", "1", ",", "4", ")", "\n", "bbh", "[", ":", ",", "0", ",", "3", "]", "=", "sz_scale", ".", "clone", "(", ")", "\n", "\n", "pos_boxes", "=", "bbutils", ".", "rel_to_rect", "(", "(", "center_box_rel", "+", "bbx", ")", "+", "bby", ",", "sz_norm", ")", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "sz_boxes", "=", "bbutils", ".", "rel_to_rect", "(", "(", "center_box_rel", "+", "bbw", ")", "+", "bbh", ",", "sz_norm", ")", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "pos_scores", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_iou", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "pos_boxes", ")", ".", "exp", "(", ")", "\n", "sz_scores", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_iou", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "sz_boxes", ")", ".", "exp", "(", ")", "\n", "\n", "show_tensor", "(", "pos_scores", ".", "view", "(", "pos_scale", ".", "numel", "(", ")", ",", "-", "1", ")", ",", "title", "=", "'Position scores'", ",", "fig_num", "=", "21", ")", "\n", "show_tensor", "(", "sz_scores", ".", "view", "(", "sz_scale", ".", "numel", "(", ")", ",", "-", "1", ")", ",", "title", "=", "'Size scores'", ",", "fig_num", "=", "22", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp.DiMP.visdom_draw_tracking": [[861, 866], ["hasattr", "dimp.DiMP.visdom.register", "dimp.DiMP.visdom.register"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register"], ["", "def", "visdom_draw_tracking", "(", "self", ",", "image", ",", "box", ",", "segmentation", "=", "None", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "'search_area_box'", ")", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "box", ",", "self", ".", "search_area_box", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "box", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.__init__.get_tracker_class": [[3, 5], ["None"], "function", ["None"], ["import", "pytracking", ".", "libs", ".", "operation", "as", "operation", "\n", "import", "pytracking", ".", "libs", ".", "fourier", "as", "fourier", "\n", "import", "pytracking", ".", "libs", ".", "dcf", "as", "dcf", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.super_dimp.run": [[13, 133], ["ltr.dataset.Lasot", "ltr.dataset.Got10k", "ltr.dataset.TrackingNet", "ltr.dataset.MSCOCOSeq", "ltr.dataset.Got10k", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.KLDiMPProcessing", "ltr.data.processing.KLDiMPProcessing", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.models.tracking.dimpnet.dimpnet50", "ltr.KLDiMPActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.RandomHorizontalFlip", "ltr.ToTensorAndJitter", "ltr.RandomHorizontalFlip", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "ltr.MultiGPU", "ltr.KLRegression", "ltr.LBHinge", "list", "range", "tracking_actors.KLDiMPActor.net.classifier.filter_initializer.parameters", "tracking_actors.KLDiMPActor.net.classifier.filter_optimizer.parameters", "tracking_actors.KLDiMPActor.net.classifier.feature_extractor.parameters", "tracking_actors.KLDiMPActor.net.bb_regressor.parameters", "tracking_actors.KLDiMPActor.net.feature_extractor.layer3.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.dimpnet50", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["params", ".", "search_area_scale", "=", "6", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "1.5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "2.5e-3", "# 1   # Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'super_dimp.pth.tar'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.super_dimp_simple.run": [[13, 133], ["ltr.dataset.Lasot", "ltr.dataset.Got10k", "ltr.dataset.TrackingNet", "ltr.dataset.MSCOCOSeq", "ltr.dataset.Got10k", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.KLDiMPProcessing", "ltr.data.processing.KLDiMPProcessing", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.models.tracking.dimpnet.dimpnet50_simple", "ltr.DiMPSimpleActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.RandomHorizontalFlip", "ltr.ToTensorAndJitter", "ltr.RandomHorizontalFlip", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "ltr.MultiGPU", "ltr.KLRegression", "ltr.LBHinge", "list", "range", "tracking_actors.DiMPSimpleActor.net.classifier.filter_initializer.parameters", "tracking_actors.DiMPSimpleActor.net.classifier.filter_optimizer.parameters", "tracking_actors.DiMPSimpleActor.net.classifier.feature_extractor.parameters", "tracking_actors.DiMPSimpleActor.net.bb_regressor.parameters", "tracking_actors.DiMPSimpleActor.net.feature_extractor.layer3.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.dimpnet50_simple", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["params", ".", "search_area_scale", "=", "6", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "1.5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "2.5e-3", "# 1   # Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'super_dimp_simple.pth.tar'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "params", ".", "use_gt_box", "=", "True", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.prdimp50.run": [[13, 121], ["ltr.dataset.Lasot", "ltr.dataset.Got10k", "ltr.dataset.TrackingNet", "ltr.dataset.MSCOCOSeq", "ltr.dataset.Got10k", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.KLDiMPProcessing", "ltr.data.processing.KLDiMPProcessing", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.models.tracking.dimpnet.klcedimpnet50", "ltr.KLDiMPActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "ltr.MultiGPU", "ltr.KLRegression", "ltr.KLRegressionGrid", "list", "range", "tracking_actors.KLDiMPActor.net.classifier.parameters", "tracking_actors.KLDiMPActor.net.bb_regressor.parameters", "tracking_actors.KLDiMPActor.net.feature_extractor.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.klcedimpnet50", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["params", ".", "search_area_scale", "=", "6", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "1.5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "score_preprocess", "=", "'softmax'", "\n", "params", ".", "target_not_found_threshold", "=", "0.04", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "2.5e-3", "# 1   # Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'prdimp50.pth.tar'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp50.run": [[13, 120], ["ltr.dataset.Lasot", "ltr.dataset.Got10k", "ltr.dataset.TrackingNet", "ltr.dataset.MSCOCOSeq", "ltr.dataset.Got10k", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.DiMPProcessing", "ltr.data.processing.DiMPProcessing", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.models.tracking.dimpnet.dimpnet50", "ltr.actors.DiMPActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "ltr.MultiGPU", "torch.MSELoss", "ltr.LBHinge", "list", "range", "actors.DiMPActor.net.classifier.filter_initializer.parameters", "actors.DiMPActor.net.classifier.filter_optimizer.parameters", "actors.DiMPActor.net.classifier.feature_extractor.parameters", "actors.DiMPActor.net.bb_regressor.parameters", "actors.DiMPActor.net.feature_extractor.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.dimpnet50", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["params", ".", "search_area_scale", "=", "5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "iounet_augmentation", "=", "False", "\n", "params", ".", "iounet_use_log_scale", "=", "True", "\n", "params", ".", "iounet_k", "=", "3", "\n", "params", ".", "num_init_random_boxes", "=", "9", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "\n", "params", ".", "box_refinement_iter", "=", "5", "\n", "params", ".", "box_refinement_step_length", "=", "1", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'dimp50.pth'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.prdimp18.run": [[13, 120], ["ltr.dataset.Lasot", "ltr.dataset.Got10k", "ltr.dataset.TrackingNet", "ltr.dataset.MSCOCOSeq", "ltr.dataset.Got10k", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.KLDiMPProcessing", "ltr.data.processing.KLDiMPProcessing", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.models.tracking.dimpnet.klcedimpnet18", "ltr.KLDiMPActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "ltr.MultiGPU", "ltr.KLRegression", "ltr.KLRegressionGrid", "list", "range", "tracking_actors.KLDiMPActor.net.classifier.parameters", "tracking_actors.KLDiMPActor.net.bb_regressor.parameters", "tracking_actors.KLDiMPActor.net.feature_extractor.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.klcedimpnet18", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["params", ".", "search_area_scale", "=", "5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "score_preprocess", "=", "'softmax'", "\n", "params", ".", "target_not_found_threshold", "=", "0.04", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "2.5e-3", "# 1   # Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'prdimp18.pth.tar'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dimp.dimp18.run": [[13, 119], ["ltr.dataset.Lasot", "ltr.dataset.Got10k", "ltr.dataset.TrackingNet", "ltr.dataset.MSCOCOSeq", "ltr.dataset.Got10k", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.DiMPProcessing", "ltr.data.processing.DiMPProcessing", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.models.tracking.dimpnet.dimpnet18", "ltr.actors.DiMPActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "ltr.MultiGPU", "torch.MSELoss", "ltr.LBHinge", "list", "range", "actors.DiMPActor.net.classifier.filter_initializer.parameters", "actors.DiMPActor.net.classifier.filter_optimizer.parameters", "actors.DiMPActor.net.classifier.feature_extractor.parameters", "actors.DiMPActor.net.bb_regressor.parameters", "actors.DiMPActor.net.feature_extractor.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.dimpnet18", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["params", ".", "search_area_scale", "=", "5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "iounet_augmentation", "=", "False", "\n", "params", ".", "iounet_use_log_scale", "=", "True", "\n", "params", ".", "iounet_k", "=", "3", "\n", "params", ".", "num_init_random_boxes", "=", "9", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "\n", "params", ".", "box_refinement_iter", "=", "5", "\n", "params", ".", "box_refinement_step_length", "=", "1", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'dimp18.pth'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.default.parameters": [[4, 77], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWrapper", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["import", "torch", "\n", "\n", "def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "# Feature specific parameters", "\n", "shallow_params", "=", "TrackerParams", "(", ")", "\n", "deep_params", "=", "TrackerParams", "(", ")", "\n", "\n", "# Patch sampling parameters", "\n", "params", ".", "max_image_sample_size", "=", "250", "**", "2", "# Maximum image sample size", "\n", "params", ".", "min_image_sample_size", "=", "200", "**", "2", "# Minimum image sample size", "\n", "params", ".", "search_area_scale", "=", "4.5", "# Scale relative to target size", "\n", "\n", "# Conjugate Gradient parameters", "\n", "params", ".", "CG_iter", "=", "5", "# The number of Conjugate Gradient iterations in each update after the first frame", "\n", "params", ".", "init_CG_iter", "=", "100", "# The total number of Conjugate Gradient iterations used in the first frame", "\n", "params", ".", "init_GN_iter", "=", "10", "# The number of Gauss-Newton iterations used in the first frame (only if the projection matrix is updated)", "\n", "params", ".", "post_init_CG_iter", "=", "0", "# CG iterations to run after GN", "\n", "params", ".", "fletcher_reeves", "=", "False", "# Use the Fletcher-Reeves (true) or Polak-Ribiere (false) formula in the Conjugate Gradient", "\n", "params", ".", "standard_alpha", "=", "True", "# Use the standard formula for computing the step length in Conjugate Gradient", "\n", "params", ".", "CG_forgetting_rate", "=", "75", "# Forgetting rate of the last conjugate direction", "\n", "params", ".", "precond_data_param", "=", "0.3", "# Weight of the data term in the preconditioner", "\n", "params", ".", "precond_reg_param", "=", "0.15", "# Weight of the regularization term in the preconditioner", "\n", "params", ".", "precond_proj_param", "=", "35", "# Weight of the projection matrix part in the preconditioner", "\n", "\n", "# Learning parameters", "\n", "shallow_params", ".", "learning_rate", "=", "0.025", "\n", "deep_params", ".", "learning_rate", "=", "0.0075", "\n", "shallow_params", ".", "output_sigma_factor", "=", "1", "/", "16", "\n", "deep_params", ".", "output_sigma_factor", "=", "1", "/", "4", "\n", "\n", "# Training parameters", "\n", "params", ".", "sample_memory_size", "=", "200", "# Memory size", "\n", "params", ".", "train_skipping", "=", "10", "# How often to run training (every n-th frame)", "\n", "\n", "# Detection parameters", "\n", "params", ".", "scale_factors", "=", "1.02", "**", "torch", ".", "arange", "(", "-", "2", ",", "3", ")", ".", "float", "(", ")", "# What scales to use for localization", "\n", "params", ".", "score_upsample_factor", "=", "1", "# How much Fourier upsampling to use", "\n", "params", ".", "score_fusion_strategy", "=", "'weightedsum'", "# Fusion strategy", "\n", "shallow_params", ".", "translation_weight", "=", "0.4", "# Weight of this feature", "\n", "deep_params", ".", "translation_weight", "=", "1", "-", "shallow_params", ".", "translation_weight", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'shift'", ":", "[", "(", "6", ",", "6", ")", ",", "(", "-", "6", ",", "6", ")", ",", "(", "6", ",", "-", "6", ")", ",", "(", "-", "6", ",", "-", "6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "# Whether to use augmentation for this feature", "\n", "deep_params", ".", "use_augmentation", "=", "True", "\n", "shallow_params", ".", "use_augmentation", "=", "True", "\n", "\n", "# Factorized convolution parameters", "\n", "# params.use_projection_matrix = True    # Use projection matrix, i.e. use the factorized convolution formulation", "\n", "params", ".", "update_projection_matrix", "=", "True", "# Whether the projection matrix should be optimized or not", "\n", "# params.proj_init_method = 'pca'        # Method for initializing the projection matrix", "\n", "params", ".", "projection_reg", "=", "5e-8", "# Regularization parameter of the projection matrix", "\n", "shallow_params", ".", "compressed_dim", "=", "16", "# Dimension output of projection matrix for shallow features", "\n", "deep_params", ".", "compressed_dim", "=", "64", "# Dimension output of projection matrix for deep features", "\n", "\n", "# Interpolation parameters", "\n", "params", ".", "interpolation_method", "=", "'bicubic'", "# The kind of interpolation kernel", "\n", "params", ".", "interpolation_bicubic_a", "=", "-", "0.75", "# The parameter for the bicubic interpolation kernel", "\n", "params", ".", "interpolation_centering", "=", "True", "# Center the kernel at the feature sample", "\n", "params", ".", "interpolation_windowing", "=", "False", "# Do additional windowing on the Fourier coefficients of the kernel", "\n", "\n", "# Regularization parameters", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.default_fast.parameters": [[4, 78], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWrapper", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "22", "*", "16", "\n", "params", ".", "search_area_scale", "=", "6", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "1.5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "50", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "10", ",", "-", "10", ",", "45", ",", "-", "45", "]", ",", "\n", "'blur'", ":", "[", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "2", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "3", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "2.5e-3", "# 1   # Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "# KeepTrack parameters", "\n", "params", ".", "use_certainty_for_weight_computation", "=", "True", "\n", "params", ".", "certainty_for_weight_computation_ths", "=", "0.5", "\n", "params", ".", "local_max_candidate_score_th", "=", "0.1", "\n", "params", ".", "target_candidate_matching_net", "=", "NetWrapper", "(", "net_path", "=", "'keep_track.pth.tar'", ",", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'super_dimp_simple.pth.tar'", ",", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "visualize_candidate_matching", "=", "False", "\n", "params", ".", "visualize_candidate_assignment_matrix", "=", "False", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.initialize_features": [[27, 31], ["getattr", "keep_track.KeepTrack.params.net.initialize"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["def", "initialize_features", "(", "self", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "self", ",", "'features_initialized'", ",", "False", ")", ":", "\n", "            ", "self", ".", "params", ".", "net", ".", "initialize", "(", ")", "\n", "", "self", ".", "features_initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.initialize": [[32, 115], ["keep_track.KeepTrack.initialize_features", "time.time", "pytracking.features.preprocessing.numpy_to_torch", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "keep_track.KeepTrack.params.get", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.max", "torch.max", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min", "keep_track.KeepTrack.generate_init_samples", "keep_track.KeepTrack.init_classifier", "keep_track.KeepTrack.params.get", "collections.defaultdict", "keep_track.KeepTrack.params.target_candidate_matching_net.initialize", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "keep_track.KeepTrack.params.has", "info.get", "keep_track.KeepTrack.params.get", "math.sqrt", "keep_track.KeepTrack.img_sample_sz.prod().sqrt", "keep_track.KeepTrack.params.has", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "isinstance", "keep_track.KeepTrack.init_iou_net", "isinstance", "keep_track.KeepTrack.image_sz.prod().sqrt", "torch.round", "torch.round", "torch.round", "torch.round", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "time.time", "torch.Tensor.prod().sqrt", "torch.Tensor.prod().sqrt", "keep_track.KeepTrack.img_sample_sz.prod", "keep_track.KeepTrack.image_sz.prod", "torch.Tensor.prod", "torch.Tensor.prod"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.generate_init_samples", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_classifier", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_iou_net"], ["", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "# Initialize some stuff", "\n", "        ", "self", ".", "frame_num", "=", "1", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'device'", ")", ":", "\n", "            ", "self", ".", "params", ".", "device", "=", "'cuda'", "if", "self", ".", "params", ".", "use_gpu", "else", "'cpu'", "\n", "\n", "# Initialize network", "\n", "", "self", ".", "initialize_features", "(", ")", "\n", "\n", "# The DiMP network", "\n", "self", ".", "net", "=", "self", ".", "params", ".", "net", "\n", "\n", "# Time initialization", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# Get target position and size", "\n", "state", "=", "info", "[", "'init_bbox'", "]", "\n", "self", ".", "pos", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "1", "]", "+", "(", "state", "[", "3", "]", "-", "1", ")", "/", "2", ",", "state", "[", "0", "]", "+", "(", "state", "[", "2", "]", "-", "1", ")", "/", "2", "]", ")", "\n", "self", ".", "target_sz", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "3", "]", ",", "state", "[", "2", "]", "]", ")", "\n", "\n", "# Get object id", "\n", "self", ".", "object_id", "=", "info", ".", "get", "(", "'object_ids'", ",", "[", "None", "]", ")", "[", "0", "]", "\n", "self", ".", "id_str", "=", "''", "if", "self", ".", "object_id", "is", "None", "else", "' {}'", ".", "format", "(", "self", ".", "object_id", ")", "\n", "\n", "# Set sizes", "\n", "self", ".", "image_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "sz", "=", "self", ".", "params", ".", "image_sample_size", "\n", "sz", "=", "torch", ".", "Tensor", "(", "[", "sz", ",", "sz", "]", "if", "isinstance", "(", "sz", ",", "int", ")", "else", "sz", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_image_aspect_ratio'", ",", "False", ")", ":", "\n", "            ", "sz", "=", "self", ".", "image_sz", "*", "sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "/", "self", ".", "image_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "stride", "=", "self", ".", "params", ".", "get", "(", "'feature_stride'", ",", "32", ")", "\n", "sz", "=", "torch", ".", "round", "(", "sz", "/", "stride", ")", "*", "stride", "\n", "", "self", ".", "img_sample_sz", "=", "sz", "\n", "self", ".", "img_support_sz", "=", "self", ".", "img_sample_sz", "\n", "\n", "# Set search area", "\n", "search_area", "=", "torch", ".", "prod", "(", "self", ".", "target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ".", "item", "(", ")", "\n", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", ")", "/", "self", ".", "img_sample_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "\n", "# Target size in base scale", "\n", "self", ".", "base_target_sz", "=", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "\n", "# Setup scale factors", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'scale_factors'", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "ones", "(", "1", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "params", ".", "scale_factors", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "Tensor", "(", "self", ".", "params", ".", "scale_factors", ")", "\n", "\n", "# Setup scale bounds", "\n", "", "self", ".", "min_scale_factor", "=", "torch", ".", "max", "(", "10", "/", "self", ".", "base_target_sz", ")", "\n", "self", ".", "max_scale_factor", "=", "torch", ".", "min", "(", "self", ".", "image_sz", "/", "self", ".", "base_target_sz", ")", "\n", "\n", "# Extract and transform sample", "\n", "init_backbone_feat", "=", "self", ".", "generate_init_samples", "(", "im", ")", "\n", "\n", "# Initialize classifier", "\n", "self", ".", "init_classifier", "(", "init_backbone_feat", ")", "\n", "\n", "# Initialize IoUNet", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", ":", "\n", "            ", "self", ".", "init_iou_net", "(", "init_backbone_feat", ")", "\n", "\n", "", "self", ".", "logging_dict", "=", "defaultdict", "(", "list", ")", "\n", "\n", "self", ".", "params", ".", "target_candidate_matching_net", ".", "initialize", "(", ")", "\n", "self", ".", "target_candidate_matching_net", "=", "self", ".", "params", ".", "target_candidate_matching_net", "\n", "self", ".", "previous_candidates", "=", "None", "\n", "self", ".", "candidate_collection", "=", "None", "\n", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "            ", "self", ".", "previous_im_patches", "=", "None", "\n", "self", ".", "previous_score_map", "=", "None", "\n", "\n", "", "self", ".", "target_scales", "=", "[", "]", "\n", "self", ".", "target_not_found_counter", "=", "0", "\n", "\n", "self", ".", "mem_sort_indices", "=", "torch", ".", "arange", "(", "0", ",", "self", ".", "num_init_samples", "[", "0", "]", ")", "\n", "\n", "out", "=", "{", "'time'", ":", "time", ".", "time", "(", ")", "-", "tic", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.track": [[116, 226], ["pytracking.features.preprocessing.numpy_to_torch", "keep_track.KeepTrack.extract_backbone_features", "keep_track.KeepTrack.get_classification_features", "keep_track.KeepTrack.get_sample_location", "keep_track.KeepTrack.classify_target", "keep_track.KeepTrack.params.get", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "keep_track.KeepTrack.localize_target_by_candidate_matching", "keep_track.KeepTrack.max", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "score_map.max", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "keep_track.KeepTrack.get_centered_sample_pos", "torch.max", "torch.max", "torch.max", "torch.max", "keep_track.KeepTrack.search_area_rescaling", "keep_track.KeepTrack.target_scales.append", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "hasattr", "keep_track.KeepTrack.pos_iounet.clone", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.get_iounet_box", "keep_track.KeepTrack.get_label_function().to", "keep_track.KeepTrack.update_classifier", "keep_track.KeepTrack.params.get", "torch.cat.tolist", "torch.cat.tolist", "torch.max.cpu().item", "torch.max.cpu().item", "keep_track.KeepTrack.visdom.register", "keep_track.KeepTrack.visdom.register", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.refine_target_box", "keep_track.KeepTrack.params.get", "torch.max", "torch.max", "torch.max", "torch.max", "keep_track.KeepTrack.visualize_candidate_matching", "keep_track.KeepTrack.visualize_candidate_assignment_matrix", "pytracking.utils.plotting.show_tensor", "torch.max.clone().detach", "torch.max.clone().detach", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.update_state", "keep_track.KeepTrack.update_state", "keep_track.KeepTrack.get_label_function", "torch.max.cpu", "torch.max.cpu", "torch.max.clone", "torch.max.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_classification_features", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_sample_location", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.classify_target", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.localize_target_by_candidate_matching", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_centered_sample_pos", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.search_area_rescaling", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.update_classifier", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.refine_target_box", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.visualize_candidate_matching", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.visualize_candidate_assignment_matrix", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_tensor", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_state", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_state", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_label_function"], ["", "def", "track", "(", "self", ",", "image", ",", "info", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "        ", "self", ".", "debug_info", "=", "{", "}", "\n", "\n", "self", ".", "frame_num", "+=", "1", "\n", "self", ".", "debug_info", "[", "'frame_num'", "]", "=", "self", ".", "frame_num", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# ------- LOCALIZATION ------- #", "\n", "\n", "# Extract backbone features", "\n", "backbone_feat", ",", "sample_coords", ",", "im_patches", "=", "self", ".", "extract_backbone_features", "(", "im", ",", "self", ".", "get_centered_sample_pos", "(", ")", ",", "\n", "self", ".", "target_scale", "*", "self", ".", "params", ".", "scale_factors", ",", "\n", "self", ".", "img_sample_sz", ")", "\n", "# Extract classification features", "\n", "test_x", "=", "self", ".", "get_classification_features", "(", "backbone_feat", ")", "\n", "\n", "# Location of sample", "\n", "sample_pos", ",", "sample_scales", "=", "self", ".", "get_sample_location", "(", "sample_coords", ")", "\n", "\n", "# Compute classification scores", "\n", "scores", "=", "self", ".", "classify_target", "(", "test_x", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'window_output'", ",", "False", ")", ":", "\n", "            ", "scores", "=", "self", ".", "output_window", "*", "scores", "\n", "\n", "# Localize the target", "\n", "", "search_area_box", "=", "torch", ".", "cat", "(", "(", "sample_coords", "[", "0", ",", "[", "1", ",", "0", "]", "]", ",", "sample_coords", "[", "0", ",", "[", "3", ",", "2", "]", "]", "-", "sample_coords", "[", "0", ",", "[", "1", ",", "0", "]", "]", "-", "1", ")", ")", "\n", "\n", "out", "=", "self", ".", "localize_target_by_candidate_matching", "(", "im_patches", ",", "backbone_feat", ",", "scores", ",", "search_area_box", ",", "\n", "sample_pos", ",", "sample_scales", ",", "im", ".", "shape", "[", "2", ":", "]", ")", "\n", "translation_vec", ",", "scale_ind", ",", "s", ",", "flag", ",", "candidate_score", ",", "matching_visualization_data", "=", "out", "\n", "\n", "object_presence_score", "=", "scores", ".", "max", "(", ")", "\n", "if", "(", "self", ".", "candidate_collection", "is", "None", "or", "self", ".", "candidate_collection", ".", "object_id_of_selected_candidate", "==", "0", ")", ":", "\n", "            ", "object_presence_score", "=", "torch", ".", "max", "(", "object_presence_score", ",", "torch", ".", "sqrt", "(", "object_presence_score", ".", "clone", "(", ")", ".", "detach", "(", ")", ")", ")", "\n", "\n", "", "new_pos", "=", "sample_pos", "[", "scale_ind", ",", ":", "]", "+", "translation_vec", "\n", "\n", "self", ".", "debug_info", "[", "'flag'", "+", "self", ".", "id_str", "]", "=", "flag", "\n", "\n", "self", ".", "search_area_box", "=", "torch", ".", "cat", "(", "(", "sample_coords", "[", "scale_ind", ",", "[", "1", ",", "0", "]", "]", ",", "sample_coords", "[", "scale_ind", ",", "[", "3", ",", "2", "]", "]", "-", "sample_coords", "[", "scale_ind", ",", "[", "1", ",", "0", "]", "]", "-", "1", ")", ")", "\n", "\n", "# Update position and scale", "\n", "if", "flag", "==", "'not_found'", ":", "\n", "            ", "self", ".", "search_area_rescaling", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "target_not_found_counter", "=", "0", "\n", "self", ".", "target_scales", ".", "append", "(", "self", ".", "target_scale", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", ":", "\n", "                ", "update_scale_flag", "=", "self", ".", "params", ".", "get", "(", "'update_scale_when_uncertain'", ",", "True", ")", "or", "flag", "!=", "'uncertain'", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_classifier'", ",", "True", ")", ":", "\n", "                    ", "self", ".", "update_state", "(", "new_pos", ")", "\n", "", "self", ".", "refine_target_box", "(", "backbone_feat", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ",", "scale_ind", ",", "update_scale_flag", ")", "\n", "", "elif", "self", ".", "params", ".", "get", "(", "'use_classifier'", ",", "True", ")", ":", "\n", "                ", "self", ".", "update_state", "(", "new_pos", ",", "sample_scales", "[", "scale_ind", "]", ")", "\n", "\n", "\n", "# Set the pos of the tracker to iounet pos", "\n", "", "", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", "and", "flag", "!=", "'not_found'", "and", "hasattr", "(", "self", ",", "'pos_iounet'", ")", ":", "\n", "            ", "self", ".", "pos", "=", "self", ".", "pos_iounet", ".", "clone", "(", ")", "\n", "\n", "", "score_map", "=", "s", "[", "scale_ind", ",", "...", "]", "\n", "max_score", "=", "torch", ".", "max", "(", "score_map", ")", ".", "item", "(", ")", "\n", "self", ".", "debug_info", "[", "'max_score'", "+", "self", ".", "id_str", "]", "=", "max_score", "\n", "\n", "# ------- Compute target certainty ------ #", "\n", "target_label_certainty", "=", "score_map", ".", "max", "(", ")", "\n", "\n", "# ------- UPDATE ------- #", "\n", "update_flag", "=", "flag", "not", "in", "[", "'not_found'", ",", "'uncertain'", "]", "\n", "hard_negative", "=", "(", "flag", "==", "'hard_negative'", ")", "\n", "learning_rate", "=", "self", ".", "params", ".", "get", "(", "'hard_negative_learning_rate'", ",", "None", ")", "if", "hard_negative", "else", "None", "\n", "\n", "if", "update_flag", "and", "self", ".", "params", ".", "get", "(", "'update_classifier'", ",", "False", ")", ":", "\n", "# Get train sample", "\n", "            ", "train_x", "=", "test_x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "\n", "\n", "# Create target_box and label for spatial sample", "\n", "target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ")", "\n", "train_y", "=", "self", ".", "get_label_function", "(", "self", ".", "pos", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "self", ".", "update_classifier", "(", "train_x", ",", "train_y", ",", "target_box", ",", "learning_rate", ",", "s", "[", "scale_ind", ",", "...", "]", ",", "target_label_certainty", ")", "\n", "\n", "# Compute output bounding box", "\n", "", "new_state", "=", "torch", ".", "cat", "(", "(", "self", ".", "pos", "[", "[", "1", ",", "0", "]", "]", "-", "(", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", "-", "1", ")", "/", "2", ",", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", ")", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'output_not_found_box'", ",", "False", ")", "and", "flag", "==", "'not_found'", ":", "\n", "            ", "output_state", "=", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "output_state", "=", "new_state", ".", "tolist", "(", ")", "\n", "\n", "", "out", "=", "{", "\n", "'target_bbox'", ":", "output_state", ",", "\n", "'object_presence_score'", ":", "object_presence_score", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "}", "\n", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "self", ".", "debug_info", ",", "'info_dict'", ",", "1", ",", "'Status'", ")", "\n", "self", ".", "visdom", ".", "register", "(", "score_map", ",", "'heatmap'", ",", "2", ",", "'Score Map'", "+", "self", ".", "id_str", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'visualize_candidate_matching'", ",", "False", ")", ":", "\n", "                ", "self", ".", "visualize_candidate_matching", "(", "matching_visualization_data", ")", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'visualize_candidate_assignment_matrix'", ",", "False", ")", ":", "\n", "                ", "self", ".", "visualize_candidate_assignment_matrix", "(", "matching_visualization_data", ")", "\n", "\n", "", "", "elif", "self", ".", "params", ".", "debug", ">=", "2", ":", "\n", "            ", "show_tensor", "(", "score_map", ",", "5", ",", "title", "=", "'Max score = {:.2f}'", ".", "format", "(", "max_score", ")", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.search_area_rescaling": [[227, 236], ["len", "max", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "min", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "search_area_rescaling", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "target_scales", ")", ">", "0", ":", "\n", "            ", "min_scales", ",", "max_scales", ",", "max_history", "=", "2", ",", "30", ",", "60", "\n", "self", ".", "target_not_found_counter", "+=", "1", "\n", "num_scales", "=", "max", "(", "min_scales", ",", "min", "(", "max_scales", ",", "self", ".", "target_not_found_counter", ")", ")", "\n", "target_scales", "=", "torch", ".", "tensor", "(", "self", ".", "target_scales", ")", "[", "-", "max_history", ":", "]", "\n", "target_scales", "=", "target_scales", "[", "target_scales", ">=", "target_scales", "[", "-", "1", "]", "]", "# only boxes that are bigger than the `not found`", "\n", "target_scales", "=", "target_scales", "[", "-", "num_scales", ":", "]", "# look as many samples into past as not found endures.", "\n", "self", ".", "target_scale", "=", "torch", ".", "mean", "(", "target_scales", ")", "# average bigger boxes from the past", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.get_sample_location": [[237, 243], ["sample_coord.float.float.float"], "methods", ["None"], ["", "", "def", "get_sample_location", "(", "self", ",", "sample_coord", ")", ":", "\n", "        ", "\"\"\"Get the location of the extracted sample.\"\"\"", "\n", "sample_coord", "=", "sample_coord", ".", "float", "(", ")", "\n", "sample_pos", "=", "0.5", "*", "(", "sample_coord", "[", ":", ",", ":", "2", "]", "+", "sample_coord", "[", ":", ",", "2", ":", "]", "-", "1", ")", "\n", "sample_scales", "=", "(", "(", "sample_coord", "[", ":", ",", "2", ":", "]", "-", "sample_coord", "[", ":", ",", ":", "2", "]", ")", "/", "self", ".", "img_sample_sz", ")", ".", "prod", "(", "dim", "=", "1", ")", ".", "sqrt", "(", ")", "\n", "return", "sample_pos", ",", "sample_scales", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.get_centered_sample_pos": [[244, 248], ["None"], "methods", ["None"], ["", "def", "get_centered_sample_pos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the center position for the new sample. Make sure the target is correctly centered.\"\"\"", "\n", "return", "self", ".", "pos", "+", "(", "(", "self", ".", "feature_sz", "+", "self", ".", "kernel_size", ")", "%", "2", ")", "*", "self", ".", "target_scale", "*", "self", ".", "img_support_sz", "/", "(", "2", "*", "self", ".", "feature_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.classify_target": [[249, 254], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "keep_track.KeepTrack.net.classifier.classify"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.classify"], ["", "def", "classify_target", "(", "self", ",", "sample_x", ":", "TensorList", ")", ":", "\n", "        ", "\"\"\"Classify target by applying the DiMP filter.\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "scores", "=", "self", ".", "net", ".", "classifier", ".", "classify", "(", "self", ".", "target_filter", ",", "sample_x", ")", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.localize_target_by_candidate_matching": [[256, 328], ["score_map1.max", "keep_track.KeepTrack.extract_descriptors_and_keypoints", "dict", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.localize_target", "keep_track.KeepTrack.localize_target", "keep_track.KeepTrack.candidate_collection.update", "score_map1.squeeze", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "candidates.CandidateCollection", "keep_track.KeepTrack.extract_matches", "list", "candidate_coord.cpu", "keep_track.KeepTrack.previous_candidates[].max", "current_candidates[].max", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "dict", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.extract_descriptors_and_keypoints", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_target", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_target", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.extract_matches", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "localize_target_by_candidate_matching", "(", "self", ",", "im_patches1", ",", "backbone_feat1", ",", "score_map1", ",", "search_area_box1", ",", "sample_pos", ",", "sample_scales", ",", "img_shape", ")", ":", "\n", "        ", "matching_visualization_data", "=", "None", "\n", "\n", "max_score1", "=", "score_map1", ".", "max", "(", ")", "\n", "candidate_score", "=", "max_score1", "\n", "\n", "if", "max_score1", "<", "self", ".", "params", ".", "get", "(", "'local_max_candidate_score_th'", ",", "0.05", ")", ":", "\n", "            ", "translation_vec", ",", "scale_ind", ",", "scores", ",", "flag", "=", "self", ".", "localize_target", "(", "score_map1", ",", "sample_pos", ",", "sample_scales", ")", "\n", "return", "translation_vec", ",", "scale_ind", ",", "scores", ",", "flag", ",", "max_score1", ",", "matching_visualization_data", "\n", "\n", "", "current_candidates", "=", "self", ".", "extract_descriptors_and_keypoints", "(", "backbone_feat1", ",", "score_map1", ",", "search_area_box1", ")", "\n", "\n", "if", "self", ".", "previous_candidates", "is", "None", "or", "(", "self", ".", "frame_num", "-", "self", ".", "previous_candidates", "[", "'frame_num'", "]", ")", ">", "1", ":", "\n", "            ", "translation_vec", ",", "scale_ind", ",", "s", ",", "flag", "=", "self", ".", "localize_target", "(", "score_map1", ",", "sample_pos", ",", "sample_scales", ")", "\n", "self", ".", "candidate_collection", "=", "None", "\n", "\n", "", "else", ":", "\n", "# Check if candidate matching can be skipped.", "\n", "            ", "if", "(", "self", ".", "previous_candidates", "[", "'scores'", "]", ".", "shape", "[", "0", "]", "==", "1", "and", "current_candidates", "[", "'scores'", "]", ".", "shape", "[", "0", "]", "==", "1", "and", "\n", "self", ".", "previous_candidates", "[", "'scores'", "]", ".", "max", "(", ")", ">", "0.5", "and", "current_candidates", "[", "'scores'", "]", ".", "max", "(", ")", ">", "0.5", ")", ":", "\n", "                ", "match_preds", "=", "{", "'matches1'", ":", "torch", ".", "zeros", "(", "1", ")", ".", "long", "(", ")", ",", "'match_scores1'", ":", "torch", ".", "ones", "(", "1", ")", "}", "\n", "\n", "", "else", ":", "\n", "                ", "match_preds", "=", "self", ".", "extract_matches", "(", "descriptors0", "=", "self", ".", "previous_candidates", "[", "'descriptors'", "]", ",", "\n", "img_coords0", "=", "self", ".", "previous_candidates", "[", "'img_coords'", "]", ",", "\n", "scores0", "=", "self", ".", "previous_candidates", "[", "'scores'", "]", ",", "\n", "descriptors1", "=", "current_candidates", "[", "'descriptors'", "]", ",", "\n", "img_coords1", "=", "current_candidates", "[", "'img_coords'", "]", ",", "\n", "scores1", "=", "current_candidates", "[", "'scores'", "]", ",", "\n", "image_shape", "=", "img_shape", ")", "\n", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                    ", "matching_visualization_data", "=", "dict", "(", "match_preds", "=", "match_preds", ",", "im_patches0", "=", "self", ".", "previous_im_patches", ",", "\n", "im_patches1", "=", "im_patches1", ",", "score_map0", "=", "self", ".", "previous_score_map", ",", "\n", "score_map1", "=", "score_map1", ",", "frameid0", "=", "self", ".", "previous_candidates", "[", "'frame_num'", "]", ",", "\n", "frameid1", "=", "self", ".", "frame_num", ")", "\n", "\n", "", "", "self", ".", "candidate_collection", ".", "update", "(", "scores", "=", "current_candidates", "[", "'scores'", "]", ",", "\n", "tsm_coords", "=", "current_candidates", "[", "'tsm_coords'", "]", ",", "\n", "matches", "=", "match_preds", "[", "'matches1'", "]", ",", "\n", "match_scores", "=", "match_preds", "[", "'match_scores1'", "]", ")", "\n", "\n", "candidate_coord", "=", "current_candidates", "[", "'tsm_coords'", "]", "[", "self", ".", "candidate_collection", ".", "candidate_id_of_selected_candidate", "]", "\n", "candidate_score", "=", "current_candidates", "[", "'scores'", "]", "[", "self", ".", "candidate_collection", ".", "candidate_id_of_selected_candidate", "]", "\n", "flag", "=", "self", ".", "candidate_collection", ".", "flag", "\n", "\n", "scale_ind", "=", "0", "\n", "s", "=", "score_map1", ".", "squeeze", "(", "1", ")", "\n", "sz", "=", "score_map1", ".", "shape", "[", "-", "2", ":", "]", "\n", "score_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "sz", ")", ")", "\n", "output_sz", "=", "score_sz", "-", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "score_center", "=", "(", "score_sz", "-", "1", ")", "/", "2", "\n", "\n", "target_disp", "=", "candidate_coord", ".", "cpu", "(", ")", "-", "score_center", "\n", "translation_vec", "=", "target_disp", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scales", "[", "scale_ind", "]", "\n", "\n", "# Setup peak collection", "\n", "", "if", "self", ".", "candidate_collection", "is", "None", ":", "\n", "            ", "self", ".", "candidate_collection", "=", "CandidateCollection", "(", "scores", "=", "current_candidates", "[", "'scores'", "]", ",", "\n", "tsm_coords", "=", "current_candidates", "[", "'tsm_coords'", "]", ",", "\n", "candidate_selection_is_certain", "=", "(", "self", ".", "frame_num", "<", "10", ")", ")", "\n", "\n", "", "self", ".", "previous_candidates", "=", "dict", "(", "frame_num", "=", "self", ".", "frame_num", ",", "\n", "descriptors", "=", "current_candidates", "[", "'descriptors'", "]", ",", "\n", "img_coords", "=", "current_candidates", "[", "'img_coords'", "]", ",", "\n", "scores", "=", "current_candidates", "[", "'scores'", "]", ")", "\n", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "            ", "self", ".", "previous_im_patches", "=", "im_patches1", "\n", "self", ".", "previous_score_map", "=", "score_map1", "\n", "\n", "", "return", "translation_vec", ",", "scale_ind", ",", "s", ",", "flag", ",", "candidate_score", ",", "matching_visualization_data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.localize_target": [[329, 369], ["activation.softmax_reg.view.squeeze", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "pytracking.dcf.max2d", "torch.max", "torch.max", "torch.max", "torch.max", "max_disp[].float().cpu().view", "activation.softmax_reg.view.new_ones", "torch.conv2d().view", "torch.conv2d().view", "keep_track.KeepTrack.localize_advanced", "list", "activation.softmax_reg.view.exp", "max_disp[].float().cpu", "getattr", "activation.softmax_reg.view.view", "ltr.models.layers.activation.softmax_reg", "ltr.models.layers.activation.softmax_reg", "ltr.models.layers.activation.softmax_reg.view", "Exception", "torch.conv2d", "torch.conv2d", "activation.softmax_reg.view.view", "max_disp[].float"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_advanced", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.softmax_reg", "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.softmax_reg", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["", "def", "localize_target", "(", "self", ",", "scores", ",", "sample_pos", ",", "sample_scales", ")", ":", "\n", "        ", "\"\"\"Run the target localization.\"\"\"", "\n", "\n", "scores", "=", "scores", ".", "squeeze", "(", "1", ")", "\n", "\n", "preprocess_method", "=", "self", ".", "params", ".", "get", "(", "'score_preprocess'", ",", "'none'", ")", "\n", "if", "preprocess_method", "==", "'none'", ":", "\n", "            ", "pass", "\n", "", "elif", "preprocess_method", "==", "'exp'", ":", "\n", "            ", "scores", "=", "scores", ".", "exp", "(", ")", "\n", "", "elif", "preprocess_method", "==", "'softmax'", ":", "\n", "            ", "reg_val", "=", "getattr", "(", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ",", "'softmax_reg'", ",", "None", ")", "\n", "scores_view", "=", "scores", ".", "view", "(", "scores", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "scores_softmax", "=", "activation", ".", "softmax_reg", "(", "scores_view", ",", "dim", "=", "-", "1", ",", "reg", "=", "reg_val", ")", "\n", "scores", "=", "scores_softmax", ".", "view", "(", "scores", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unknown score_preprocess in params.'", ")", "\n", "\n", "", "score_filter_ksz", "=", "self", ".", "params", ".", "get", "(", "'score_filter_ksz'", ",", "1", ")", "\n", "if", "score_filter_ksz", ">", "1", ":", "\n", "            ", "assert", "score_filter_ksz", "%", "2", "==", "1", "\n", "kernel", "=", "scores", ".", "new_ones", "(", "1", ",", "1", ",", "score_filter_ksz", ",", "score_filter_ksz", ")", "\n", "scores", "=", "F", ".", "conv2d", "(", "scores", ".", "view", "(", "-", "1", ",", "1", ",", "*", "scores", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "kernel", ",", "padding", "=", "score_filter_ksz", "//", "2", ")", ".", "view", "(", "scores", ".", "shape", ")", "\n", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'advanced_localization'", ",", "False", ")", ":", "\n", "            ", "return", "self", ".", "localize_advanced", "(", "scores", ",", "sample_pos", ",", "sample_scales", ")", "\n", "\n", "# Get maximum", "\n", "", "score_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "scores", ".", "shape", "[", "-", "2", ":", "]", ")", ")", "\n", "score_center", "=", "(", "score_sz", "-", "1", ")", "/", "2", "\n", "max_score", ",", "max_disp", "=", "dcf", ".", "max2d", "(", "scores", ")", "\n", "_", ",", "scale_ind", "=", "torch", ".", "max", "(", "max_score", ",", "dim", "=", "0", ")", "\n", "max_disp", "=", "max_disp", "[", "scale_ind", ",", "...", "]", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp", "=", "max_disp", "-", "score_center", "\n", "\n", "# Compute translation vector and scale change factor", "\n", "output_sz", "=", "score_sz", "-", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "translation_vec", "=", "target_disp", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scales", "[", "scale_ind", "]", "\n", "\n", "return", "translation_vec", ",", "scale_ind", ",", "scores", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.localize_advanced": [[370, 436], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "pytracking.dcf.max2d", "torch.max", "torch.max", "torch.max", "torch.max", "max_disp1[].float().cpu().view", "max", "min", "max", "min", "scores_hn[].clone", "pytracking.dcf.max2d", "max_disp2.float().cpu().view.float().cpu().view.float().cpu().view", "list", "keep_track.KeepTrack.params.get", "scores.clone", "max_score1.item", "max_score1.item", "keep_track.KeepTrack.params.get", "max_score1.item", "keep_track.KeepTrack.params.get", "round", "round", "round", "round", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "max_disp1[].float().cpu", "max_disp2.float().cpu().view.float().cpu().view.float().cpu", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "float", "float", "max_disp1[].item", "max_disp1[].item", "math.sqrt", "max_disp1[].float", "target_neigh_sz[].item", "max_disp1[].item", "target_neigh_sz[].item", "max_disp1[].item", "max_disp2.float().cpu().view.float().cpu().view.float", "target_neigh_sz[].item", "target_neigh_sz[].item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "localize_advanced", "(", "self", ",", "scores", ",", "sample_pos", ",", "sample_scales", ")", ":", "\n", "        ", "\"\"\"Run the target advanced localization (as in ATOM).\"\"\"", "\n", "\n", "sz", "=", "scores", ".", "shape", "[", "-", "2", ":", "]", "\n", "score_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "sz", ")", ")", "\n", "output_sz", "=", "score_sz", "-", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "score_center", "=", "(", "score_sz", "-", "1", ")", "/", "2", "\n", "\n", "scores_hn", "=", "scores", "\n", "if", "self", ".", "output_window", "is", "not", "None", "and", "self", ".", "params", ".", "get", "(", "'perform_hn_without_windowing'", ",", "False", ")", ":", "\n", "            ", "scores_hn", "=", "scores", ".", "clone", "(", ")", "\n", "scores", "*=", "self", ".", "output_window", "\n", "\n", "", "max_score1", ",", "max_disp1", "=", "dcf", ".", "max2d", "(", "scores", ")", "\n", "_", ",", "scale_ind", "=", "torch", ".", "max", "(", "max_score1", ",", "dim", "=", "0", ")", "\n", "sample_scale", "=", "sample_scales", "[", "scale_ind", "]", "\n", "max_score1", "=", "max_score1", "[", "scale_ind", "]", "\n", "max_disp1", "=", "max_disp1", "[", "scale_ind", ",", "...", "]", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp1", "=", "max_disp1", "-", "score_center", "\n", "translation_vec1", "=", "target_disp1", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scale", "\n", "\n", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "target_not_found_threshold", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'not_found'", "\n", "", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "get", "(", "'uncertain_threshold'", ",", "-", "float", "(", "'inf'", ")", ")", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'uncertain'", "\n", "", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "get", "(", "'hard_sample_threshold'", ",", "-", "float", "(", "'inf'", ")", ")", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", "\n", "\n", "# Mask out target neighborhood", "\n", "", "target_neigh_sz", "=", "self", ".", "params", ".", "target_neighborhood_scale", "*", "(", "self", ".", "target_sz", "/", "sample_scale", ")", "*", "(", "output_sz", "/", "self", ".", "img_support_sz", ")", "\n", "\n", "tneigh_top", "=", "max", "(", "round", "(", "max_disp1", "[", "0", "]", ".", "item", "(", ")", "-", "target_neigh_sz", "[", "0", "]", ".", "item", "(", ")", "/", "2", ")", ",", "0", ")", "\n", "tneigh_bottom", "=", "min", "(", "round", "(", "max_disp1", "[", "0", "]", ".", "item", "(", ")", "+", "target_neigh_sz", "[", "0", "]", ".", "item", "(", ")", "/", "2", "+", "1", ")", ",", "sz", "[", "0", "]", ")", "\n", "tneigh_left", "=", "max", "(", "round", "(", "max_disp1", "[", "1", "]", ".", "item", "(", ")", "-", "target_neigh_sz", "[", "1", "]", ".", "item", "(", ")", "/", "2", ")", ",", "0", ")", "\n", "tneigh_right", "=", "min", "(", "round", "(", "max_disp1", "[", "1", "]", ".", "item", "(", ")", "+", "target_neigh_sz", "[", "1", "]", ".", "item", "(", ")", "/", "2", "+", "1", ")", ",", "sz", "[", "1", "]", ")", "\n", "scores_masked", "=", "scores_hn", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", ".", "clone", "(", ")", "\n", "scores_masked", "[", "...", ",", "tneigh_top", ":", "tneigh_bottom", ",", "tneigh_left", ":", "tneigh_right", "]", "=", "0", "\n", "\n", "# Find new maximum", "\n", "max_score2", ",", "max_disp2", "=", "dcf", ".", "max2d", "(", "scores_masked", ")", "\n", "max_disp2", "=", "max_disp2", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp2", "=", "max_disp2", "-", "score_center", "\n", "translation_vec2", "=", "target_disp2", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scale", "\n", "\n", "prev_target_vec", "=", "(", "self", ".", "pos", "-", "sample_pos", "[", "scale_ind", ",", ":", "]", ")", "/", "(", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scale", ")", "\n", "\n", "# Handle the different cases", "\n", "if", "max_score2", ">", "self", ".", "params", ".", "distractor_threshold", "*", "max_score1", ":", "\n", "            ", "disp_norm1", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "target_disp1", "-", "prev_target_vec", ")", "**", "2", ")", ")", "\n", "disp_norm2", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "target_disp2", "-", "prev_target_vec", ")", "**", "2", ")", ")", "\n", "disp_threshold", "=", "self", ".", "params", ".", "dispalcement_scale", "*", "math", ".", "sqrt", "(", "sz", "[", "0", "]", "*", "sz", "[", "1", "]", ")", "/", "2", "\n", "\n", "if", "disp_norm2", ">", "disp_threshold", "and", "disp_norm1", "<", "disp_threshold", ":", "\n", "                ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", "\n", "", "if", "disp_norm2", "<", "disp_threshold", "and", "disp_norm1", ">", "disp_threshold", ":", "\n", "                ", "return", "translation_vec2", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", "\n", "", "if", "disp_norm2", ">", "disp_threshold", "and", "disp_norm1", ">", "disp_threshold", ":", "\n", "                ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'uncertain'", "\n", "\n", "# If also the distractor is close, return with highest score", "\n", "", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'uncertain'", "\n", "\n", "", "if", "max_score2", ">", "self", ".", "params", ".", "hard_negative_threshold", "*", "max_score1", "and", "max_score2", ">", "self", ".", "params", ".", "target_not_found_threshold", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", "\n", "\n", "", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'normal'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.extract_descriptors_and_keypoints": [[437, 460], ["keep_track.KeepTrack.params.get", "score_map.squeeze.squeeze.squeeze", "keep_track.KeepTrack.target_candidate_matching_net.get_backbone_clf_feat", "ltr.find_local_maxima", "ltr.find_local_maxima", "dict", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "keep_track.KeepTrack.target_candidate_matching_net.descriptor_extractor.get_descriptors", "keep_track.KeepTrack.params.get", "search_area_box.tolist", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack().permute", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "tsm_coords[].float", "tsm_coords[].float", "tsm_coords[].float", "tsm_coords[].float"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.get_backbone_clf_feat", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.find_local_maxima", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.find_local_maxima", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.DescriptorExtractor.get_descriptors", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "extract_descriptors_and_keypoints", "(", "self", ",", "backbone_feat", ",", "score_map", ",", "search_area_box", ")", ":", "\n", "        ", "th", "=", "self", ".", "params", ".", "get", "(", "'local_max_candidate_score_th'", ",", "0.05", ")", "\n", "score_map", "=", "score_map", ".", "squeeze", "(", ")", "\n", "frame_feat_clf", "=", "self", ".", "target_candidate_matching_net", ".", "get_backbone_clf_feat", "(", "backbone_feat", ")", "\n", "tsm_coords", ",", "scores", "=", "prutils", ".", "find_local_maxima", "(", "score_map", ",", "ks", "=", "5", ",", "th", "=", "th", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "descriptors", "=", "self", ".", "target_candidate_matching_net", ".", "descriptor_extractor", ".", "get_descriptors", "(", "frame_feat_clf", ",", "tsm_coords", ")", "\n", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'matching_coordinate_system_reference'", ",", "'full'", ")", "==", "'full'", ":", "\n", "            ", "x", ",", "y", ",", "w", ",", "h", "=", "search_area_box", ".", "tolist", "(", ")", "\n", "img_coords", "=", "torch", ".", "stack", "(", "[", "\n", "h", "*", "(", "tsm_coords", "[", ":", ",", "0", "]", ".", "float", "(", ")", "/", "(", "score_map", ".", "shape", "[", "0", "]", "-", "1", ")", ")", "+", "y", ",", "\n", "w", "*", "(", "tsm_coords", "[", ":", ",", "1", "]", ".", "float", "(", ")", "/", "(", "score_map", ".", "shape", "[", "1", "]", "-", "1", ")", ")", "+", "x", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "img_coords", "=", "torch", ".", "stack", "(", "[", "\n", "self", ".", "params", ".", "image_sample_size", "*", "(", "tsm_coords", "[", ":", ",", "0", "]", ".", "float", "(", ")", "/", "(", "score_map", ".", "shape", "[", "0", "]", "-", "1", ")", ")", ",", "\n", "self", ".", "params", ".", "image_sample_size", "*", "(", "tsm_coords", "[", ":", ",", "1", "]", ".", "float", "(", ")", "/", "(", "score_map", ".", "shape", "[", "1", "]", "-", "1", ")", ")", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "", "candidates", "=", "dict", "(", "descriptors", "=", "descriptors", ",", "img_coords", "=", "img_coords", ",", "scores", "=", "scores", ",", "tsm_coords", "=", "tsm_coords", ")", "\n", "return", "candidates", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.extract_matches": [[461, 477], ["scores0.unsqueeze", "scores1.unsqueeze", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "keep_track.KeepTrack.target_candidate_matching_net.matcher"], "methods", ["None"], ["", "def", "extract_matches", "(", "self", ",", "descriptors0", ",", "descriptors1", ",", "img_coords0", ",", "img_coords1", ",", "scores0", ",", "scores1", ",", "\n", "image_shape", ")", ":", "\n", "        ", "data", "=", "{", "\n", "'descriptors0'", ":", "descriptors0", ",", "\n", "'descriptors1'", ":", "descriptors1", ",", "\n", "'img_coords0'", ":", "img_coords0", ",", "\n", "'img_coords1'", ":", "img_coords1", ",", "\n", "'scores0'", ":", "scores0", ".", "unsqueeze", "(", "0", ")", ",", "\n", "'scores1'", ":", "scores1", ".", "unsqueeze", "(", "0", ")", ",", "\n", "'image_size0'", ":", "image_shape", "[", "-", "2", ":", "]", ",", "\n", "'image_size1'", ":", "image_shape", "[", "-", "2", ":", "]", ",", "\n", "}", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pred", "=", "self", ".", "target_candidate_matching_net", ".", "matcher", "(", "data", ")", "\n", "\n", "", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.extract_backbone_features": [[478, 485], ["pytracking.features.preprocessing.sample_patch_multiscale", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "keep_track.KeepTrack.net.extract_backbone", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_multiscale", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "extract_backbone_features", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ",", "pos", ":", "torch", ".", "Tensor", ",", "scales", ",", "sz", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "im_patches", ",", "patch_coords", "=", "sample_patch_multiscale", "(", "im", ",", "pos", ",", "scales", ",", "sz", ",", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", ",", "\n", "max_scale_change", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ",", "None", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im_patches", ")", "\n", "", "return", "backbone_feat", ",", "patch_coords", ",", "im_patches", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.get_classification_features": [[486, 489], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "keep_track.KeepTrack.net.extract_classification_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat"], ["", "def", "get_classification_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "extract_classification_feat", "(", "backbone_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.get_iou_backbone_features": [[490, 492], ["keep_track.KeepTrack.net.get_backbone_bbreg_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.get_backbone_bbreg_feat"], ["", "", "def", "get_iou_backbone_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "return", "self", ".", "net", ".", "get_backbone_bbreg_feat", "(", "backbone_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.get_iou_features": [[493, 496], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "keep_track.KeepTrack.net.bb_regressor.get_iou_feat", "keep_track.KeepTrack.get_iou_backbone_features"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_iou_feat", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_backbone_features"], ["", "def", "get_iou_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "bb_regressor", ".", "get_iou_feat", "(", "self", ".", "get_iou_backbone_features", "(", "backbone_feat", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.get_iou_modulation": [[497, 500], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "keep_track.KeepTrack.net.bb_regressor.get_modulation"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_modulation"], ["", "", "def", "get_iou_modulation", "(", "self", ",", "iou_backbone_feat", ",", "target_boxes", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "bb_regressor", ".", "get_modulation", "(", "iou_backbone_feat", ",", "target_boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.generate_init_samples": [[501, 570], ["keep_track.KeepTrack.params.get", "keep_track.KeepTrack.pos.round", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.img_sample_sz.clone", "keep_track.KeepTrack.params.get", "pytracking.features.preprocessing.sample_patch_transformed", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "shrink_factor.min.min.clamp_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "aug_expansion_sz.float.float.float", "keep_track.KeepTrack.img_sample_sz.long().tolist", "pytracking.features.augmentation.Identity", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.transforms.extend", "keep_track.KeepTrack.transforms.extend", "keep_track.KeepTrack.transforms.append", "keep_track.KeepTrack.transforms.extend", "keep_track.KeepTrack.transforms.extend", "keep_track.KeepTrack.transforms.extend", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "keep_track.KeepTrack.net.extract_backbone", "sample_sz.float", "shrink_factor.min.min.max", "sample_sz.float", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "pytracking.features.augmentation.FlipHorizontal", "shrink_factor.min.min.min", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.img_sample_sz.long", "keep_track.KeepTrack.img_sample_sz.long", "pytracking.features.augmentation.Translation", "pytracking.features.augmentation.Translation", "get_rand_shift", "pytracking.features.augmentation.Blur", "pytracking.features.augmentation.Scale", "pytracking.features.augmentation.Rotate", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "get_absolute", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "get_rand_shift", "get_rand_shift", "get_rand_shift", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_transformed", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "", "def", "generate_init_samples", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Perform data augmentation to generate initial training samples.\"\"\"", "\n", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", "\n", "if", "mode", "==", "'inside'", ":", "\n", "# Get new sample size if forced inside the image", "\n", "            ", "im_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "sample_sz", "=", "self", ".", "target_scale", "*", "self", ".", "img_sample_sz", "\n", "shrink_factor", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "im_sz", ")", "\n", "if", "mode", "==", "'inside'", ":", "\n", "                ", "shrink_factor", "=", "shrink_factor", ".", "max", "(", ")", "\n", "", "elif", "mode", "==", "'inside_major'", ":", "\n", "                ", "shrink_factor", "=", "shrink_factor", ".", "min", "(", ")", "\n", "", "shrink_factor", ".", "clamp_", "(", "min", "=", "1", ",", "max", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ",", "None", ")", ")", "\n", "sample_sz", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "shrink_factor", ")", "\n", "self", ".", "init_sample_scale", "=", "(", "sample_sz", "/", "self", ".", "img_sample_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "tl", "=", "self", ".", "pos", "-", "(", "sample_sz", "-", "1", ")", "/", "2", "\n", "br", "=", "self", ".", "pos", "+", "sample_sz", "/", "2", "+", "1", "\n", "global_shift", "=", "-", "(", "(", "-", "tl", ")", ".", "clamp", "(", "0", ")", "-", "(", "br", "-", "im_sz", ")", ".", "clamp", "(", "0", ")", ")", "/", "self", ".", "init_sample_scale", "\n", "", "else", ":", "\n", "            ", "self", ".", "init_sample_scale", "=", "self", ".", "target_scale", "\n", "global_shift", "=", "torch", ".", "zeros", "(", "2", ")", "\n", "\n", "", "self", ".", "init_sample_pos", "=", "self", ".", "pos", ".", "round", "(", ")", "\n", "\n", "# Compute augmentation size", "\n", "aug_expansion_factor", "=", "self", ".", "params", ".", "get", "(", "'augmentation_expansion_factor'", ",", "None", ")", "\n", "aug_expansion_sz", "=", "self", ".", "img_sample_sz", ".", "clone", "(", ")", "\n", "aug_output_sz", "=", "None", "\n", "if", "aug_expansion_factor", "is", "not", "None", "and", "aug_expansion_factor", "!=", "1", ":", "\n", "            ", "aug_expansion_sz", "=", "(", "self", ".", "img_sample_sz", "*", "aug_expansion_factor", ")", ".", "long", "(", ")", "\n", "aug_expansion_sz", "+=", "(", "aug_expansion_sz", "-", "self", ".", "img_sample_sz", ".", "long", "(", ")", ")", "%", "2", "\n", "aug_expansion_sz", "=", "aug_expansion_sz", ".", "float", "(", ")", "\n", "aug_output_sz", "=", "self", ".", "img_sample_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Random shift for each sample", "\n", "", "get_rand_shift", "=", "lambda", ":", "None", "\n", "random_shift_factor", "=", "self", ".", "params", ".", "get", "(", "'random_shift_factor'", ",", "0", ")", "\n", "if", "random_shift_factor", ">", "0", ":", "\n", "            ", "get_rand_shift", "=", "lambda", ":", "(", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "*", "self", ".", "img_sample_sz", "*", "random_shift_factor", "+", "global_shift", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Always put identity transformation first, since it is the unaugmented sample that is always used", "\n", "", "self", ".", "transforms", "=", "[", "augmentation", ".", "Identity", "(", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "]", "\n", "\n", "augs", "=", "self", ".", "params", ".", "augmentation", "if", "self", ".", "params", ".", "get", "(", "'use_augmentation'", ",", "True", ")", "else", "{", "}", "\n", "\n", "# Add all augmentations", "\n", "if", "'shift'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "shift", ",", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "for", "shift", "in", "augs", "[", "'shift'", "]", "]", ")", "\n", "", "if", "'relativeshift'", "in", "augs", ":", "\n", "            ", "get_absolute", "=", "lambda", "shift", ":", "(", "torch", ".", "Tensor", "(", "shift", ")", "*", "self", ".", "img_sample_sz", "/", "2", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "get_absolute", "(", "shift", ")", ",", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "for", "shift", "in", "augs", "[", "'relativeshift'", "]", "]", ")", "\n", "", "if", "'fliplr'", "in", "augs", "and", "augs", "[", "'fliplr'", "]", ":", "\n", "            ", "self", ".", "transforms", ".", "append", "(", "augmentation", ".", "FlipHorizontal", "(", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", ")", "\n", "", "if", "'blur'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Blur", "(", "sigma", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "sigma", "in", "augs", "[", "'blur'", "]", "]", ")", "\n", "", "if", "'scale'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Scale", "(", "scale_factor", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "scale_factor", "in", "augs", "[", "'scale'", "]", "]", ")", "\n", "", "if", "'rotate'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Rotate", "(", "angle", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "angle", "in", "augs", "[", "'rotate'", "]", "]", ")", "\n", "\n", "# Extract augmented image patches", "\n", "", "im_patches", "=", "sample_patch_transformed", "(", "im", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ",", "aug_expansion_sz", ",", "self", ".", "transforms", ")", "\n", "\n", "# Extract initial backbone features", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "init_backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im_patches", ")", "\n", "\n", "", "return", "init_backbone_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.init_target_label_certainties": [[571, 575], ["train_x[].new_zeros"], "methods", ["None"], ["", "def", "init_target_label_certainties", "(", "self", ",", "train_x", ":", "TensorList", ")", ":", "\n", "        ", "num_train_samples", "=", "train_x", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "self", ".", "target_label_certainties", "=", "train_x", "[", "0", "]", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "target_label_certainties", "[", ":", "num_train_samples", "]", "=", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.init_target_boxes": [[576, 587], ["keep_track.KeepTrack.get_iounet_box", "pytracking.TensorList", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to.new_zeros", "torch.cat().to.new_zeros", "torch.cat().to.append", "torch.cat().to.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat().to.view", "torch.cat().to.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "init_target_boxes", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the target bounding boxes for the initial augmented samples.\"\"\"", "\n", "self", ".", "classifier_target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ")", "\n", "init_target_boxes", "=", "TensorList", "(", ")", "\n", "for", "T", "in", "self", ".", "transforms", ":", "\n", "            ", "init_target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "T", ".", "shift", "[", "1", "]", ",", "T", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "init_target_boxes", "=", "torch", ".", "cat", "(", "init_target_boxes", ".", "view", "(", "1", ",", "4", ")", ",", "0", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "self", ".", "target_boxes", "=", "init_target_boxes", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "4", ")", "\n", "self", ".", "target_boxes", "[", ":", "init_target_boxes", ".", "shape", "[", "0", "]", ",", ":", "]", "=", "init_target_boxes", "\n", "return", "init_target_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.init_target_labels": [[588, 608], ["pytracking.TensorList", "keep_track.KeepTrack.params.get", "zip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "enumerate", "x.new_zeros", "pytracking.dcf.label_function_spatial", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "int", "int", "keep_track.KeepTrack.kernel_size[].item", "keep_track.KeepTrack.kernel_size[].item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.label_function_spatial"], ["", "def", "init_target_labels", "(", "self", ",", "train_x", ":", "TensorList", ")", ":", "\n", "        ", "self", ".", "target_labels", "=", "TensorList", "(", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "1", ",", "\n", "x", ".", "shape", "[", "2", "]", "+", "(", "int", "(", "self", ".", "kernel_size", "[", "0", "]", ".", "item", "(", ")", ")", "+", "1", ")", "%", "2", ",", "\n", "x", ".", "shape", "[", "3", "]", "+", "(", "int", "(", "self", ".", "kernel_size", "[", "1", "]", ".", "item", "(", ")", ")", "+", "1", ")", "%", "2", ")", "\n", "for", "x", "in", "train_x", "]", ")", "\n", "# Output sigma factor", "\n", "output_sigma_factor", "=", "self", ".", "params", ".", "get", "(", "'output_sigma_factor'", ",", "1", "/", "4", ")", "\n", "self", ".", "sigma", "=", "(", "self", ".", "feature_sz", "/", "self", ".", "img_support_sz", "*", "self", ".", "base_target_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "output_sigma_factor", "*", "torch", ".", "ones", "(", "2", ")", "\n", "\n", "# Center pos in normalized img_coords", "\n", "target_center_norm", "=", "(", "self", ".", "pos", "-", "self", ".", "init_sample_pos", ")", "/", "(", "self", ".", "init_sample_scale", "*", "self", ".", "img_support_sz", ")", "\n", "\n", "for", "target", ",", "x", "in", "zip", "(", "self", ".", "target_labels", ",", "train_x", ")", ":", "\n", "            ", "ksz_even", "=", "torch", ".", "Tensor", "(", "[", "(", "self", ".", "kernel_size", "[", "0", "]", "+", "1", ")", "%", "2", ",", "(", "self", ".", "kernel_size", "[", "1", "]", "+", "1", ")", "%", "2", "]", ")", "\n", "center_pos", "=", "self", ".", "feature_sz", "*", "target_center_norm", "+", "0.5", "*", "ksz_even", "\n", "for", "i", ",", "T", "in", "enumerate", "(", "self", ".", "transforms", "[", ":", "x", ".", "shape", "[", "0", "]", "]", ")", ":", "\n", "                ", "sample_center", "=", "center_pos", "+", "torch", ".", "Tensor", "(", "T", ".", "shift", ")", "/", "self", ".", "img_support_sz", "*", "self", ".", "feature_sz", "\n", "target", "[", "i", ",", "0", ",", "...", "]", "=", "dcf", ".", "label_function_spatial", "(", "self", ".", "feature_sz", ",", "self", ".", "sigma", ",", "sample_center", ",", "end_pad", "=", "ksz_even", ")", "\n", "\n", "", "", "return", "self", ".", "target_labels", "[", "0", "]", "[", ":", "train_x", "[", "0", "]", ".", "shape", "[", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.init_memory": [[609, 627], ["train_x.size", "pytracking.TensorList", "keep_track.KeepTrack.num_init_samples.copy", "pytracking.TensorList", "zip", "pytracking.TensorList", "zip", "len", "x.new_zeros", "x.new_zeros", "x.new_ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "def", "init_memory", "(", "self", ",", "train_x", ":", "TensorList", ")", ":", "\n", "# Initialize first-frame spatial training samples", "\n", "        ", "self", ".", "num_init_samples", "=", "train_x", ".", "size", "(", "0", ")", "\n", "init_sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_ones", "(", "1", ")", "/", "x", ".", "shape", "[", "0", "]", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "# Sample counters and weights for spatial", "\n", "self", ".", "num_stored_samples", "=", "self", ".", "num_init_samples", ".", "copy", "(", ")", "\n", "self", ".", "previous_replace_ind", "=", "[", "None", "]", "*", "len", "(", "self", ".", "num_stored_samples", ")", "\n", "self", ".", "sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ")", "for", "x", "in", "train_x", "]", ")", "\n", "for", "sw", ",", "init_sw", ",", "num", "in", "zip", "(", "self", ".", "sample_weights", ",", "init_sample_weights", ",", "self", ".", "num_init_samples", ")", ":", "\n", "            ", "sw", "[", ":", "num", "]", "=", "init_sw", "\n", "\n", "# Initialize memory", "\n", "", "self", ".", "training_samples", "=", "TensorList", "(", "\n", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "for", "ts", ",", "x", "in", "zip", "(", "self", ".", "training_samples", ",", "train_x", ")", ":", "\n", "            ", "ts", "[", ":", "x", ".", "shape", "[", "0", "]", ",", "...", "]", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.update_memory": [[628, 666], ["keep_track.KeepTrack.update_sample_weights_based_on_certainty", "zip", "zip", "torch.max", "torch.max", "torch.max", "torch.max", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "keep_track.KeepTrack.mem_sort_indices.clone", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "keep_track.KeepTrack.target_label_certainties.view", "keep_track.KeepTrack.sample_weights[].view", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max.clone().detach", "torch.max.clone().detach", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.max.clone", "torch.max.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.update_sample_weights_based_on_certainty"], ["", "", "def", "update_memory", "(", "self", ",", "sample_x", ":", "TensorList", ",", "sample_y", ":", "TensorList", ",", "target_box", ",", "learning_rate", "=", "None", ",", "target_label_certainty", "=", "None", ")", ":", "\n", "# Update weights and get replace ind", "\n", "        ", "if", "(", "self", ".", "candidate_collection", "is", "None", "or", "self", ".", "candidate_collection", ".", "object_id_of_selected_candidate", "==", "0", ")", ":", "\n", "            ", "target_label_certainty", "=", "torch", ".", "max", "(", "target_label_certainty", ",", "torch", ".", "sqrt", "(", "target_label_certainty", ".", "clone", "(", ")", ".", "detach", "(", ")", ")", ")", "\n", "\n", "", "certainties", "=", "[", "self", ".", "target_label_certainties", ".", "view", "(", "-", "1", ")", "*", "self", ".", "sample_weights", "[", "0", "]", ".", "view", "(", "-", "1", ")", "]", "\n", "\n", "replace_ind", "=", "self", ".", "update_sample_weights_based_on_certainty", "(", "certainties", ",", "self", ".", "sample_weights", ",", "\n", "self", ".", "previous_replace_ind", ",", "self", ".", "num_stored_samples", ",", "\n", "self", ".", "num_init_samples", ",", "learning_rate", ")", "\n", "\n", "self", ".", "previous_replace_ind", "=", "replace_ind", "\n", "\n", "# Update sample and label memory", "\n", "for", "train_samp", ",", "x", ",", "ind", "in", "zip", "(", "self", ".", "training_samples", ",", "sample_x", ",", "replace_ind", ")", ":", "\n", "            ", "train_samp", "[", "ind", ":", "ind", "+", "1", ",", "...", "]", "=", "x", "\n", "\n", "", "for", "y_memory", ",", "y", ",", "ind", "in", "zip", "(", "self", ".", "target_labels", ",", "sample_y", ",", "replace_ind", ")", ":", "\n", "            ", "y_memory", "[", "ind", ":", "ind", "+", "1", ",", "...", "]", "=", "y", "\n", "\n", "# Update target label certainties memory", "\n", "\n", "", "self", ".", "target_label_certainties", "[", "replace_ind", "[", "0", "]", "]", "=", "target_label_certainty", "\n", "\n", "# Update bb memory", "\n", "self", ".", "target_boxes", "[", "replace_ind", "[", "0", "]", ",", ":", "]", "=", "target_box", "\n", "\n", "if", "replace_ind", "[", "0", "]", ">=", "len", "(", "self", ".", "mem_sort_indices", ")", ":", "\n", "            ", "self", ".", "mem_sort_indices", "=", "torch", ".", "cat", "(", "[", "self", ".", "mem_sort_indices", ",", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "long", ")", "]", ")", "\n", "self", ".", "mem_sort_indices", "[", "replace_ind", "[", "0", "]", "]", "=", "torch", ".", "max", "(", "self", ".", "mem_sort_indices", ")", "+", "1", "\n", "", "else", ":", "\n", "            ", "idx", "=", "torch", ".", "nonzero", "(", "self", ".", "mem_sort_indices", "==", "replace_ind", "[", "0", "]", ")", "\n", "mem_temp", "=", "self", ".", "mem_sort_indices", ".", "clone", "(", ")", "\n", "mem_temp", "[", "idx", ":", "-", "1", "]", "=", "self", ".", "mem_sort_indices", "[", "idx", "+", "1", ":", "]", "\n", "mem_temp", "[", "-", "1", "]", "=", "replace_ind", "[", "0", "]", "\n", "self", ".", "mem_sort_indices", "=", "mem_temp", "\n", "\n", "", "self", ".", "num_stored_samples", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.update_sample_weights_based_on_certainty": [[667, 709], ["zip", "keep_track.KeepTrack.params.get", "sw.sum", "replace_ind.append", "torch.min", "torch.min", "torch.min", "torch.min", "sw[].sum", "sw[].sum", "r_ind.item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "update_sample_weights_based_on_certainty", "(", "self", ",", "certainties", ",", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ",", "learning_rate", "=", "None", ")", ":", "\n", "# Update weights and get index to replace", "\n", "        ", "replace_ind", "=", "[", "]", "\n", "for", "cert", ",", "sw", ",", "prev_ind", ",", "num_samp", ",", "num_init", "in", "zip", "(", "certainties", ",", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ")", ":", "\n", "            ", "lr", "=", "learning_rate", "\n", "if", "lr", "is", "None", ":", "\n", "                ", "lr", "=", "self", ".", "params", ".", "learning_rate", "\n", "\n", "", "init_samp_weight", "=", "self", ".", "params", ".", "get", "(", "'init_samples_minimum_weight'", ",", "None", ")", "\n", "if", "init_samp_weight", "==", "0", ":", "\n", "                ", "init_samp_weight", "=", "None", "\n", "", "s_ind", "=", "0", "if", "init_samp_weight", "is", "None", "else", "num_init", "\n", "\n", "if", "num_samp", "==", "0", "or", "lr", "==", "1", ":", "\n", "                ", "sw", "[", ":", "]", "=", "0", "\n", "sw", "[", "0", "]", "=", "1", "\n", "r_ind", "=", "0", "\n", "", "else", ":", "\n", "# Get index to replace", "\n", "                ", "if", "num_samp", "<", "sw", ".", "shape", "[", "0", "]", ":", "\n", "                    ", "r_ind", "=", "num_samp", "\n", "", "else", ":", "\n", "                    ", "_", ",", "r_ind", "=", "torch", ".", "min", "(", "cert", "[", "s_ind", ":", "]", ",", "0", ")", "\n", "r_ind", "=", "r_ind", ".", "item", "(", ")", "+", "s_ind", "\n", "\n", "# Update weights", "\n", "", "if", "prev_ind", "is", "None", ":", "\n", "                    ", "sw", "/=", "1", "-", "lr", "\n", "sw", "[", "r_ind", "]", "=", "lr", "\n", "", "elif", "r_ind", "==", "prev_ind", ":", "\n", "                    ", "pass", "\n", "", "else", ":", "\n", "                    ", "sw", "[", "r_ind", "]", "=", "sw", "[", "prev_ind", "]", "/", "(", "1", "-", "lr", ")", "\n", "\n", "", "", "sw", "/=", "sw", ".", "sum", "(", ")", "\n", "if", "init_samp_weight", "is", "not", "None", "and", "sw", "[", ":", "num_init", "]", ".", "sum", "(", ")", "<", "init_samp_weight", ":", "\n", "                ", "sw", "/=", "init_samp_weight", "+", "sw", "[", "num_init", ":", "]", ".", "sum", "(", ")", "\n", "sw", "[", ":", "num_init", "]", "=", "init_samp_weight", "/", "num_init", "\n", "\n", "", "replace_ind", ".", "append", "(", "r_ind", ")", "\n", "\n", "", "return", "replace_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.get_label_function": [[710, 720], ["pytracking.TensorList", "zip", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "pytracking.TensorList.append", "pytracking.dcf.label_function_spatial"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.label_function_spatial"], ["", "def", "get_label_function", "(", "self", ",", "pos", ",", "sample_pos", ",", "sample_scale", ")", ":", "\n", "        ", "train_y", "=", "TensorList", "(", ")", "\n", "target_center_norm", "=", "(", "pos", "-", "sample_pos", ")", "/", "(", "sample_scale", "*", "self", ".", "img_support_sz", ")", "\n", "\n", "for", "sig", ",", "sz", ",", "ksz", "in", "zip", "(", "[", "self", ".", "sigma", "]", ",", "[", "self", ".", "feature_sz", "]", ",", "[", "self", ".", "kernel_size", "]", ")", ":", "\n", "            ", "ksz_even", "=", "torch", ".", "Tensor", "(", "[", "(", "self", ".", "kernel_size", "[", "0", "]", "+", "1", ")", "%", "2", ",", "(", "self", ".", "kernel_size", "[", "1", "]", "+", "1", ")", "%", "2", "]", ")", "\n", "center", "=", "sz", "*", "target_center_norm", "+", "0.5", "*", "ksz_even", "\n", "train_y", ".", "append", "(", "dcf", ".", "label_function_spatial", "(", "sz", ",", "sig", ",", "center", ",", "end_pad", "=", "ksz_even", ")", ")", "\n", "\n", "", "return", "train_y", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.update_state": [[721, 731], ["keep_track.KeepTrack.params.get", "torch.max", "torch.max", "torch.max", "torch.max", "new_scale.clamp", "torch.min", "torch.min", "torch.min", "torch.min"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "update_state", "(", "self", ",", "new_pos", ",", "new_scale", "=", "None", ")", ":", "\n", "# Update scale", "\n", "        ", "if", "new_scale", "is", "not", "None", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", ".", "clamp", "(", "self", ".", "min_scale_factor", ",", "self", ".", "max_scale_factor", ")", "\n", "self", ".", "target_sz", "=", "self", ".", "base_target_sz", "*", "self", ".", "target_scale", "\n", "\n", "# Update pos", "\n", "", "inside_ratio", "=", "self", ".", "params", ".", "get", "(", "'target_inside_ratio'", ",", "0.2", ")", "\n", "inside_offset", "=", "(", "inside_ratio", "-", "0.5", ")", "*", "self", ".", "target_sz", "\n", "self", ".", "pos", "=", "torch", ".", "max", "(", "torch", ".", "min", "(", "new_pos", ",", "self", ".", "image_sz", "-", "inside_offset", ")", ",", "inside_offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.get_iounet_box": [[733, 740], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "target_ul.flip", "box_sz.flip"], "methods", ["None"], ["", "def", "get_iounet_box", "(", "self", ",", "pos", ",", "sz", ",", "sample_pos", ",", "sample_scale", ")", ":", "\n", "        ", "\"\"\"All inputs in original image coordinates.\n        Generates a box in the cropped image sample reference frame, in the format used by the IoUNet.\"\"\"", "\n", "box_center", "=", "(", "pos", "-", "sample_pos", ")", "/", "sample_scale", "+", "(", "self", ".", "img_sample_sz", "-", "1", ")", "/", "2", "\n", "box_sz", "=", "sz", "/", "sample_scale", "\n", "target_ul", "=", "box_center", "-", "(", "box_sz", "-", "1", ")", "/", "2", "\n", "return", "torch", ".", "cat", "(", "[", "target_ul", ".", "flip", "(", "(", "0", ",", ")", ")", ",", "box_sz", ".", "flip", "(", "(", "0", ",", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.init_iou_net": [[741, 768], ["keep_track.KeepTrack.net.bb_regressor.parameters", "keep_track.KeepTrack.get_iounet_box", "pytracking.TensorList", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "keep_track.KeepTrack.get_iou_backbone_features", "pytracking.TensorList", "keep_track.KeepTrack.get_iou_modulation", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.cat().to.append", "torch.cat().to.append", "pytracking.TensorList", "torch.cat().to.append", "torch.cat().to.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "isinstance", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat().to.view", "torch.cat().to.view", "x.detach().mean", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "x.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_iou_modulation", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "init_iou_net", "(", "self", ",", "backbone_feat", ")", ":", "\n", "# Setup IoU net and objective", "\n", "        ", "for", "p", "in", "self", ".", "net", ".", "bb_regressor", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "# Get target boxes for the different augmentations", "\n", "", "self", ".", "classifier_target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ")", "\n", "target_boxes", "=", "TensorList", "(", ")", "\n", "if", "self", ".", "params", ".", "iounet_augmentation", ":", "\n", "            ", "for", "T", "in", "self", ".", "transforms", ":", "\n", "                ", "if", "not", "isinstance", "(", "T", ",", "(", "augmentation", ".", "Identity", ",", "augmentation", ".", "Translation", ",", "augmentation", ".", "FlipHorizontal", ",", "augmentation", ".", "FlipVertical", ",", "augmentation", ".", "Blur", ")", ")", ":", "\n", "                    ", "break", "\n", "", "target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "T", ".", "shift", "[", "1", "]", ",", "T", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "self", ".", "transforms", "[", "0", "]", ".", "shift", "[", "1", "]", ",", "self", ".", "transforms", "[", "0", "]", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "target_boxes", "=", "torch", ".", "cat", "(", "target_boxes", ".", "view", "(", "1", ",", "4", ")", ",", "0", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "# Get iou features", "\n", "iou_backbone_feat", "=", "self", ".", "get_iou_backbone_features", "(", "backbone_feat", ")", "\n", "\n", "# Remove other augmentations such as rotation", "\n", "iou_backbone_feat", "=", "TensorList", "(", "[", "x", "[", ":", "target_boxes", ".", "shape", "[", "0", "]", ",", "...", "]", "for", "x", "in", "iou_backbone_feat", "]", ")", "\n", "\n", "# Get modulation vector", "\n", "self", ".", "iou_modulation", "=", "self", ".", "get_iou_modulation", "(", "iou_backbone_feat", ",", "target_boxes", ")", "\n", "if", "torch", ".", "is_tensor", "(", "self", ".", "iou_modulation", "[", "0", "]", ")", ":", "\n", "            ", "self", ".", "iou_modulation", "=", "TensorList", "(", "[", "x", ".", "detach", "(", ")", ".", "mean", "(", "0", ")", "for", "x", "in", "self", ".", "iou_modulation", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.init_classifier": [[769, 849], ["keep_track.KeepTrack.get_classification_features", "hasattr", "keep_track.KeepTrack.params.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.init_target_boxes", "keep_track.KeepTrack.init_target_labels", "keep_track.KeepTrack.init_target_label_certainties", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "getattr", "hasattr", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "ltr.models.target_classifier.initializer.FilterInitializerZero", "ltr.models.target_classifier.initializer.FilterInitializerZero", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.transforms.extend", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "list", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.output_window.squeeze", "pytracking.TensorList", "pytracking.TensorList", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "keep_track.KeepTrack.net.classifier.get_filter", "keep_track.KeepTrack.init_memory", "isinstance", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "getattr", "isinstance", "pytracking.dcf.hann2d_clipped().to", "pytracking.dcf.hann2d().to", "pytracking.TensorList", "keep_track.KeepTrack.visdom.register", "torch.dropout2d", "torch.dropout2d", "pytracking.utils.plotting.plot_graph", "x[].expand", "pytracking.dcf.hann2d_clipped", "pytracking.dcf.hann2d", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "keep_track.KeepTrack.output_sz.long", "keep_track.KeepTrack.output_sz.long", "keep_track.KeepTrack.losses.numel"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_classification_features", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_target_boxes", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_target_labels", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.init_target_label_certainties", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.get_filter", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_memory", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d_clipped", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d"], ["", "", "def", "init_classifier", "(", "self", ",", "init_backbone_feat", ")", ":", "\n", "# Get classification features", "\n", "        ", "x", "=", "self", ".", "get_classification_features", "(", "init_backbone_feat", ")", "\n", "\n", "# Set regularization weight and initializer", "\n", "if", "hasattr", "(", "self", ".", "net", ",", "'classifier'", ")", ":", "\n", "            ", "pred_module", "=", "getattr", "(", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ",", "'score_predictor'", ",", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ")", "\n", "", "elif", "hasattr", "(", "self", ".", "net", ",", "'dimp_classifier'", ")", ":", "\n", "            ", "self", ".", "net", ".", "classifier", "=", "self", ".", "net", ".", "dimp_classifier", "\n", "pred_module", "=", "getattr", "(", "self", ".", "net", ".", "dimp_classifier", ".", "filter_optimizer", ",", "'score_predictor'", ",", "\n", "self", ".", "net", ".", "dimp_classifier", ".", "filter_optimizer", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'label_threshold'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ".", "label_threshold", "=", "self", ".", "params", ".", "label_threshold", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'label_shrink'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ".", "label_shrink", "=", "self", ".", "params", ".", "label_shrink", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'softmax_reg'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ".", "softmax_reg", "=", "self", ".", "params", ".", "softmax_reg", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'filter_reg'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "pred_module", ".", "filter_reg", "[", "0", "]", "=", "self", ".", "params", ".", "filter_reg", "\n", "pred_module", ".", "min_filter_reg", "=", "self", ".", "params", ".", "filter_reg", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'filter_init_zero'", ",", "False", ")", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_initializer", "=", "FilterInitializerZero", "(", "self", ".", "net", ".", "classifier", ".", "filter_size", ",", "x", ".", "shape", "[", "-", "3", "]", ")", "\n", "\n", "# Add the dropout augmentation here, since it requires extraction of the classification features", "\n", "", "if", "'dropout'", "in", "self", ".", "params", ".", "augmentation", "and", "self", ".", "params", ".", "get", "(", "'use_augmentation'", ",", "True", ")", ":", "\n", "            ", "num", ",", "prob", "=", "self", ".", "params", ".", "augmentation", "[", "'dropout'", "]", "\n", "self", ".", "transforms", ".", "extend", "(", "self", ".", "transforms", "[", ":", "1", "]", "*", "num", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "F", ".", "dropout2d", "(", "x", "[", "0", ":", "1", ",", "...", "]", ".", "expand", "(", "num", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", ",", "p", "=", "prob", ",", "training", "=", "True", ")", "]", ")", "\n", "\n", "# Set feature size and other related sizes", "\n", "", "self", ".", "feature_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "x", ".", "shape", "[", "-", "2", ":", "]", ")", ")", "\n", "ksz", "=", "self", ".", "net", ".", "classifier", ".", "filter_size", "\n", "self", ".", "kernel_size", "=", "torch", ".", "Tensor", "(", "[", "ksz", ",", "ksz", "]", "if", "isinstance", "(", "ksz", ",", "(", "int", ",", "float", ")", ")", "else", "ksz", ")", "\n", "self", ".", "output_sz", "=", "self", ".", "feature_sz", "+", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "\n", "# Construct output window", "\n", "self", ".", "output_window", "=", "None", "\n", "if", "self", ".", "params", ".", "get", "(", "'window_output'", ",", "False", ")", ":", "\n", "            ", "if", "self", ".", "params", ".", "get", "(", "'use_clipped_window'", ",", "False", ")", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d_clipped", "(", "self", ".", "output_sz", ".", "long", "(", ")", ",", "(", "self", ".", "output_sz", "*", "self", ".", "params", ".", "effective_search_area", "/", "self", ".", "params", ".", "search_area_scale", ")", ".", "long", "(", ")", ",", "centered", "=", "True", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d", "(", "self", ".", "output_sz", ".", "long", "(", ")", ",", "centered", "=", "True", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "", "self", ".", "output_window", "=", "self", ".", "output_window", ".", "squeeze", "(", "0", ")", "\n", "\n", "# Get target boxes for the different augmentations", "\n", "", "target_boxes", "=", "self", ".", "init_target_boxes", "(", ")", "\n", "\n", "# Get target boxes for the different augmentations", "\n", "target_labels", "=", "self", ".", "init_target_labels", "(", "TensorList", "(", "[", "x", "]", ")", ")", "\n", "\n", "# Init target label certainties, init gth samples as 1.0", "\n", "self", ".", "init_target_label_certainties", "(", "TensorList", "(", "[", "x", "]", ")", ")", "\n", "\n", "# Set number of iterations", "\n", "plot_loss", "=", "self", ".", "params", ".", "debug", ">", "0", "\n", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_iter'", ",", "None", ")", "\n", "\n", "self", ".", "net", ".", "classifier", ".", "compute_losses", "=", "plot_loss", "\n", "\n", "# Get target filter by running the discriminative model prediction module", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "target_filter", ",", "_", ",", "losses", "=", "self", ".", "net", ".", "classifier", ".", "get_filter", "(", "x", ",", "target_boxes", ",", "\n", "train_label", "=", "target_labels", ",", "\n", "num_iter", "=", "num_iter", ")", "\n", "\n", "# Init memory", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'update_classifier'", ",", "True", ")", ":", "\n", "            ", "self", ".", "init_memory", "(", "TensorList", "(", "[", "x", "]", ")", ")", "\n", "\n", "", "if", "plot_loss", ":", "\n", "            ", "if", "isinstance", "(", "losses", ",", "dict", ")", ":", "\n", "                ", "losses", "=", "losses", "[", "'train'", "]", "\n", "", "self", ".", "losses", "=", "torch", ".", "stack", "(", "losses", ")", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                ", "self", ".", "visdom", ".", "register", "(", "(", "self", ".", "losses", ",", "torch", ".", "arange", "(", "self", ".", "losses", ".", "numel", "(", ")", ")", ")", ",", "'lineplot'", ",", "3", ",", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "", "elif", "self", ".", "params", ".", "debug", ">=", "3", ":", "\n", "                ", "plot_graph", "(", "self", ".", "losses", ",", "10", ",", "title", "=", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.update_classifier": [[850, 928], ["keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.logging_dict[].append", "[].view", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.update_memory", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.target_label_certainties[].view", "keep_track.KeepTrack.params.get", "[].view.clone", "keep_track.KeepTrack.target_boxes[].clone", "pytracking.TensorList", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.params.get", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "keep_track.KeepTrack.net.classifier.filter_optimizer", "isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "keep_track.KeepTrack.params.get", "scores.max().item", "keep_track.KeepTrack.params.get", "pytracking.TensorList", "keep_track.KeepTrack.visdom.register", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "pytracking.utils.plotting.plot_graph", "scores.max", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "keep_track.KeepTrack.losses.numel"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_memory", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph"], ["", "", "", "def", "update_classifier", "(", "self", ",", "train_x", ",", "train_y", ",", "target_box", ",", "learning_rate", "=", "None", ",", "scores", "=", "None", ",", "target_label_certainty", "=", "None", ")", ":", "\n", "        ", "if", "target_label_certainty", "is", "None", ":", "\n", "            ", "target_label_certainty", "=", "1.", "\n", "\n", "# Set flags and learning rate", "\n", "", "hard_negative_flag", "=", "learning_rate", "is", "not", "None", "\n", "if", "learning_rate", "is", "None", ":", "\n", "            ", "learning_rate", "=", "self", ".", "params", ".", "learning_rate", "\n", "\n", "# Update the tracker memory", "\n", "", "if", "hard_negative_flag", "or", "self", ".", "frame_num", "%", "self", ".", "params", ".", "get", "(", "'train_sample_interval'", ",", "1", ")", "==", "0", ":", "\n", "            ", "self", ".", "update_memory", "(", "TensorList", "(", "[", "train_x", "]", ")", ",", "train_y", ",", "target_box", ",", "learning_rate", ",", "target_label_certainty", ")", "\n", "\n", "# Decide the number of iterations to run", "\n", "", "num_iter", "=", "0", "\n", "low_score_th", "=", "self", ".", "params", ".", "get", "(", "'low_score_opt_threshold'", ",", "None", ")", "\n", "if", "hard_negative_flag", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_hn_iter'", ",", "None", ")", "\n", "\n", "# do not update if certainty of hn_sample is lower than ths it won't be considered during update anyway.", "\n", "ths_cert", "=", "self", ".", "params", ".", "get", "(", "'certainty_for_weight_computation_ths'", ",", "0.5", ")", "\n", "if", "(", "self", ".", "params", ".", "get", "(", "'use_certainty_for_weight_computation'", ",", "False", ")", "and", "ths_cert", ">", "target_label_certainty", ")", ":", "\n", "                ", "num_iter", "=", "0", "\n", "\n", "", "", "elif", "low_score_th", "is", "not", "None", "and", "low_score_th", ">", "scores", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_low_iter'", ",", "None", ")", "\n", "", "elif", "(", "self", ".", "frame_num", "-", "1", ")", "%", "self", ".", "params", ".", "train_skipping", "==", "0", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_update_iter'", ",", "None", ")", "\n", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'net_opt_every_frame'", ",", "False", ")", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_every_frame_iter'", ",", "1", ")", "\n", "\n", "", "plot_loss", "=", "self", ".", "params", ".", "debug", ">", "0", "\n", "\n", "self", ".", "logging_dict", "[", "'num_iters'", "]", ".", "append", "(", "num_iter", ")", "\n", "\n", "# Compute sample weights either fully on age or mix with correctness certainty of target lables.", "\n", "# Supress memory sample if certainty is below certain threshold.", "\n", "sample_weights", "=", "self", ".", "sample_weights", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", "]", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_certainty_for_weight_computation'", ",", "False", ")", ":", "\n", "            ", "target_label_certainties", "=", "self", ".", "target_label_certainties", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", "]", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "ths_cert", "=", "self", ".", "params", ".", "get", "(", "'certainty_for_weight_computation_ths'", ",", "0.5", ")", "\n", "weights", "=", "target_label_certainties", "\n", "weights", "[", "weights", "<", "ths_cert", "]", "=", "0.0", "\n", "weights", "=", "weights", "*", "sample_weights", "\n", "", "else", ":", "\n", "            ", "weights", "=", "sample_weights", ".", "clone", "(", ")", "\n", "\n", "\n", "", "if", "num_iter", ">", "0", ":", "\n", "# Get inputs for the DiMP filter optimizer module", "\n", "            ", "samples", "=", "self", ".", "training_samples", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", "...", "]", "\n", "target_labels", "=", "self", ".", "target_labels", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", "...", "]", "\n", "target_boxes", "=", "self", ".", "target_boxes", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", ":", "]", ".", "clone", "(", ")", "\n", "\n", "self", ".", "net", ".", "classifier", ".", "compute_losses", "=", "plot_loss", "\n", "\n", "\n", "# Run the filter optimizer module", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "target_filter", ",", "_", ",", "losses", "=", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", "(", "TensorList", "(", "[", "self", ".", "target_filter", "]", ")", ",", "\n", "num_iter", "=", "num_iter", ",", "feat", "=", "samples", ",", "\n", "bb", "=", "target_boxes", ",", "train_label", "=", "target_labels", ",", "\n", "sample_weight", "=", "weights", ")", "\n", "self", ".", "target_filter", "=", "target_filter", "[", "0", "]", "\n", "\n", "\n", "", "if", "plot_loss", ":", "\n", "                ", "if", "isinstance", "(", "losses", ",", "dict", ")", ":", "\n", "                    ", "losses", "=", "losses", "[", "'train'", "]", "\n", "\n", "", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "torch", ".", "stack", "(", "losses", ")", ")", ")", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                    ", "self", ".", "visdom", ".", "register", "(", "(", "self", ".", "losses", ",", "torch", ".", "arange", "(", "self", ".", "losses", ".", "numel", "(", ")", ")", ")", ",", "'lineplot'", ",", "3", ",", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "", "elif", "self", ".", "params", ".", "debug", ">=", "3", ":", "\n", "                    ", "plot_graph", "(", "self", ".", "losses", ",", "10", ",", "title", "=", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.refine_target_box": [[930, 992], ["hasattr", "keep_track.KeepTrack.get_iounet_box", "keep_track.KeepTrack.get_iou_features", "pytracking.TensorList", "keep_track.KeepTrack.view().clone", "keep_track.KeepTrack.optimize_boxes", "output_boxes[].clamp_", "keep_track.KeepTrack.params.get", "min", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "output_boxes[].mean", "[].mean", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "new_pos.clone", "keep_track.KeepTrack.params.get", "keep_track.KeepTrack.direct_box_regression", "init_box[].prod().sqrt", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "predicted_box[].flip", "new_pos.clone", "keep_track.KeepTrack.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "init_box[].min", "new_target_sz.prod", "keep_track.KeepTrack.base_target_sz.prod", "init_box[].prod", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "keep_track.KeepTrack.view", "output_iou.view", "new_pos.flip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_features", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.optimize_boxes", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.direct_box_regression", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "", "", "", "def", "refine_target_box", "(", "self", ",", "backbone_feat", ",", "sample_pos", ",", "sample_scale", ",", "scale_ind", ",", "update_scale", "=", "True", ")", ":", "\n", "        ", "\"\"\"Run the ATOM IoUNet to refine the target bounding box.\"\"\"", "\n", "\n", "if", "hasattr", "(", "self", ".", "net", ".", "bb_regressor", ",", "'predict_bb'", ")", ":", "\n", "            ", "return", "self", ".", "direct_box_regression", "(", "backbone_feat", ",", "sample_pos", ",", "sample_scale", ",", "scale_ind", ",", "update_scale", ")", "\n", "\n", "# Initial box for refinement", "\n", "", "init_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", ",", "sample_scale", ")", "\n", "\n", "# Extract features from the relevant scale", "\n", "iou_features", "=", "self", ".", "get_iou_features", "(", "backbone_feat", ")", "\n", "iou_features", "=", "TensorList", "(", "[", "x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "for", "x", "in", "iou_features", "]", ")", "\n", "\n", "# Generate random initial boxes", "\n", "init_boxes", "=", "init_box", ".", "view", "(", "1", ",", "4", ")", ".", "clone", "(", ")", "\n", "if", "self", ".", "params", ".", "num_init_random_boxes", ">", "0", ":", "\n", "            ", "square_box_sz", "=", "init_box", "[", "2", ":", "]", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "rand_factor", "=", "square_box_sz", "*", "torch", ".", "cat", "(", "[", "self", ".", "params", ".", "box_jitter_pos", "*", "torch", ".", "ones", "(", "2", ")", ",", "self", ".", "params", ".", "box_jitter_sz", "*", "torch", ".", "ones", "(", "2", ")", "]", ")", "\n", "\n", "minimal_edge_size", "=", "init_box", "[", "2", ":", "]", ".", "min", "(", ")", "/", "3", "\n", "rand_bb", "=", "(", "torch", ".", "rand", "(", "self", ".", "params", ".", "num_init_random_boxes", ",", "4", ")", "-", "0.5", ")", "*", "rand_factor", "\n", "new_sz", "=", "(", "init_box", "[", "2", ":", "]", "+", "rand_bb", "[", ":", ",", "2", ":", "]", ")", ".", "clamp", "(", "minimal_edge_size", ")", "\n", "new_center", "=", "(", "init_box", "[", ":", "2", "]", "+", "init_box", "[", "2", ":", "]", "/", "2", ")", "+", "rand_bb", "[", ":", ",", ":", "2", "]", "\n", "init_boxes", "=", "torch", ".", "cat", "(", "[", "new_center", "-", "new_sz", "/", "2", ",", "new_sz", "]", ",", "1", ")", "\n", "init_boxes", "=", "torch", ".", "cat", "(", "[", "init_box", ".", "view", "(", "1", ",", "4", ")", ",", "init_boxes", "]", ")", "\n", "\n", "# Optimize the boxes", "\n", "", "output_boxes", ",", "output_iou", "=", "self", ".", "optimize_boxes", "(", "iou_features", ",", "init_boxes", ")", "\n", "\n", "# Remove weird boxes", "\n", "output_boxes", "[", ":", ",", "2", ":", "]", ".", "clamp_", "(", "1", ")", "\n", "aspect_ratio", "=", "output_boxes", "[", ":", ",", "2", "]", "/", "output_boxes", "[", ":", ",", "3", "]", "\n", "keep_ind", "=", "(", "aspect_ratio", "<", "self", ".", "params", ".", "maximal_aspect_ratio", ")", "*", "(", "aspect_ratio", ">", "1", "/", "self", ".", "params", ".", "maximal_aspect_ratio", ")", "\n", "output_boxes", "=", "output_boxes", "[", "keep_ind", ",", ":", "]", "\n", "output_iou", "=", "output_iou", "[", "keep_ind", "]", "\n", "\n", "# If no box found", "\n", "if", "output_boxes", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "# Predict box", "\n", "", "k", "=", "self", ".", "params", ".", "get", "(", "'iounet_k'", ",", "5", ")", "\n", "topk", "=", "min", "(", "k", ",", "output_boxes", ".", "shape", "[", "0", "]", ")", "\n", "_", ",", "inds", "=", "torch", ".", "topk", "(", "output_iou", ",", "topk", ")", "\n", "predicted_box", "=", "output_boxes", "[", "inds", ",", ":", "]", ".", "mean", "(", "0", ")", "\n", "self", ".", "predicted_iou", "=", "output_iou", ".", "view", "(", "-", "1", ",", "1", ")", "[", "inds", ",", ":", "]", ".", "mean", "(", "0", ")", "\n", "\n", "# Get new position and size", "\n", "new_pos", "=", "predicted_box", "[", ":", "2", "]", "+", "predicted_box", "[", "2", ":", "]", "/", "2", "\n", "new_pos", "=", "(", "new_pos", ".", "flip", "(", "(", "0", ",", ")", ")", "-", "(", "self", ".", "img_sample_sz", "-", "1", ")", "/", "2", ")", "*", "sample_scale", "+", "sample_pos", "\n", "new_target_sz", "=", "predicted_box", "[", "2", ":", "]", ".", "flip", "(", "(", "0", ",", ")", ")", "*", "sample_scale", "\n", "new_scale", "=", "torch", ".", "sqrt", "(", "new_target_sz", ".", "prod", "(", ")", "/", "self", ".", "base_target_sz", ".", "prod", "(", ")", ")", "\n", "\n", "self", ".", "pos_iounet", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iounet_pos_for_learning'", ",", "True", ")", ":", "\n", "            ", "self", ".", "pos", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "", "self", ".", "target_sz", "=", "new_target_sz", "\n", "\n", "if", "update_scale", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.optimize_boxes": [[993, 1000], ["keep_track.KeepTrack.params.get", "ValueError", "keep_track.KeepTrack.optimize_boxes_default", "keep_track.KeepTrack.optimize_boxes_relative"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.optimize_boxes_default", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.optimize_boxes_relative"], ["", "", "def", "optimize_boxes", "(", "self", ",", "iou_features", ",", "init_boxes", ")", ":", "\n", "        ", "box_refinement_space", "=", "self", ".", "params", ".", "get", "(", "'box_refinement_space'", ",", "'default'", ")", "\n", "if", "box_refinement_space", "==", "'default'", ":", "\n", "            ", "return", "self", ".", "optimize_boxes_default", "(", "iou_features", ",", "init_boxes", ")", "\n", "", "if", "box_refinement_space", "==", "'relative'", ":", "\n", "            ", "return", "self", ".", "optimize_boxes_relative", "(", "iou_features", ",", "init_boxes", ")", "\n", "", "raise", "ValueError", "(", "'Unknown box_refinement_space {}'", ".", "format", "(", "box_refinement_space", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.optimize_boxes_default": [[1001, 1027], ["init_boxes.view().to", "isinstance", "range", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "init_boxes.view().to.clone().detach", "keep_track.KeepTrack.net.bb_regressor.predict_iou", "isinstance", "keep_track.KeepTrack.backward", "init_boxes.view().to.detach_", "init_boxes.view().to.view().cpu", "keep_track.KeepTrack.detach().view().cpu", "init_boxes.view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "init_boxes.view().to.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "bb_init[].repeat", "init_boxes.view().to.view", "keep_track.KeepTrack.detach().view", "keep_track.KeepTrack.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou"], ["", "def", "optimize_boxes_default", "(", "self", ",", "iou_features", ",", "init_boxes", ")", ":", "\n", "# Optimize iounet boxes", "\n", "        ", "output_boxes", "=", "init_boxes", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "step_length", "=", "self", ".", "params", ".", "box_refinement_step_length", "\n", "if", "isinstance", "(", "step_length", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "step_length", "=", "torch", ".", "Tensor", "(", "[", "step_length", "[", "0", "]", ",", "step_length", "[", "0", "]", ",", "step_length", "[", "1", "]", ",", "step_length", "[", "1", "]", "]", ",", "device", "=", "self", ".", "params", ".", "device", ")", ".", "view", "(", "1", ",", "1", ",", "4", ")", "\n", "\n", "", "for", "i_", "in", "range", "(", "self", ".", "params", ".", "box_refinement_iter", ")", ":", "\n", "# forward pass", "\n", "            ", "bb_init", "=", "output_boxes", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "bb_init", ".", "requires_grad", "=", "True", "\n", "\n", "outputs", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_iou", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "bb_init", ")", "\n", "\n", "if", "isinstance", "(", "outputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "outputs", "=", "outputs", "[", "0", "]", "\n", "\n", "", "outputs", ".", "backward", "(", "gradient", "=", "torch", ".", "ones_like", "(", "outputs", ")", ")", "\n", "\n", "# Update proposal", "\n", "output_boxes", "=", "bb_init", "+", "step_length", "*", "bb_init", ".", "grad", "*", "bb_init", "[", ":", ",", ":", ",", "2", ":", "]", ".", "repeat", "(", "1", ",", "1", ",", "2", ")", "\n", "output_boxes", ".", "detach_", "(", ")", "\n", "\n", "step_length", "*=", "self", ".", "params", ".", "box_refinement_step_decay", "\n", "\n", "", "return", "output_boxes", ".", "view", "(", "-", "1", ",", "4", ")", ".", "cpu", "(", ")", ",", "outputs", ".", "detach", "(", ")", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.optimize_boxes_relative": [[1028, 1059], ["init_boxes.view().to", "isinstance", "output_boxes[].clone", "ltr.rect_to_rel", "ltr.rect_to_rel", "range", "ltr.rel_to_rect", "ltr.rel_to_rect", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "ltr.rect_to_rel.clone().detach", "ltr.rel_to_rect", "ltr.rel_to_rect", "keep_track.KeepTrack.net.bb_regressor.predict_iou", "isinstance", "keep_track.KeepTrack.backward", "ltr.rect_to_rel.detach_", "ltr.rel_to_rect.view().cpu", "keep_track.KeepTrack.detach().view().cpu", "init_boxes.view", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "ltr.rect_to_rel.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "ltr.rel_to_rect.view", "keep_track.KeepTrack.detach().view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "keep_track.KeepTrack.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rect_to_rel", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rect_to_rel", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "optimize_boxes_relative", "(", "self", ",", "iou_features", ",", "init_boxes", ")", ":", "\n", "# Optimize iounet boxes", "\n", "        ", "output_boxes", "=", "init_boxes", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "step_length", "=", "self", ".", "params", ".", "box_refinement_step_length", "\n", "if", "isinstance", "(", "step_length", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "step_length", "=", "torch", ".", "Tensor", "(", "[", "step_length", "[", "0", "]", ",", "step_length", "[", "0", "]", ",", "step_length", "[", "1", "]", ",", "step_length", "[", "1", "]", "]", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", ".", "view", "(", "1", ",", "1", ",", "4", ")", "\n", "\n", "", "sz_norm", "=", "output_boxes", "[", ":", ",", ":", "1", ",", "2", ":", "]", ".", "clone", "(", ")", "\n", "output_boxes_rel", "=", "bbutils", ".", "rect_to_rel", "(", "output_boxes", ",", "sz_norm", ")", "\n", "for", "i_", "in", "range", "(", "self", ".", "params", ".", "box_refinement_iter", ")", ":", "\n", "# forward pass", "\n", "            ", "bb_init_rel", "=", "output_boxes_rel", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "bb_init_rel", ".", "requires_grad", "=", "True", "\n", "\n", "bb_init", "=", "bbutils", ".", "rel_to_rect", "(", "bb_init_rel", ",", "sz_norm", ")", "\n", "outputs", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_iou", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "bb_init", ")", "\n", "\n", "if", "isinstance", "(", "outputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "outputs", "=", "outputs", "[", "0", "]", "\n", "\n", "", "outputs", ".", "backward", "(", "gradient", "=", "torch", ".", "ones_like", "(", "outputs", ")", ")", "\n", "\n", "# Update proposal", "\n", "output_boxes_rel", "=", "bb_init_rel", "+", "step_length", "*", "bb_init_rel", ".", "grad", "\n", "output_boxes_rel", ".", "detach_", "(", ")", "\n", "\n", "step_length", "*=", "self", ".", "params", ".", "box_refinement_step_decay", "\n", "\n", "", "output_boxes", "=", "bbutils", ".", "rel_to_rect", "(", "output_boxes_rel", ",", "sz_norm", ")", "\n", "\n", "return", "output_boxes", ".", "view", "(", "-", "1", ",", "4", ")", ".", "cpu", "(", ")", ",", "outputs", ".", "detach", "(", ")", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.direct_box_regression": [[1060, 1097], ["keep_track.KeepTrack.get_iounet_box", "keep_track.KeepTrack.get_iou_features", "pytracking.TensorList", "keep_track.KeepTrack.view().clone().to", "keep_track.KeepTrack.net.bb_regressor.predict_bb().view().cpu", "output_boxes[].clamp_", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "new_pos.clone", "keep_track.KeepTrack.params.get", "predicted_box[].flip", "new_pos.clone", "keep_track.KeepTrack.view().clone", "keep_track.KeepTrack.net.bb_regressor.predict_bb().view", "new_target_sz.prod", "keep_track.KeepTrack.base_target_sz.prod", "new_pos.flip", "keep_track.KeepTrack.view", "keep_track.KeepTrack.net.bb_regressor.predict_bb"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_features", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "direct_box_regression", "(", "self", ",", "backbone_feat", ",", "sample_pos", ",", "sample_scale", ",", "scale_ind", ",", "update_scale", "=", "True", ")", ":", "\n", "        ", "\"\"\"Run the ATOM IoUNet to refine the target bounding box.\"\"\"", "\n", "\n", "# Initial box for refinement", "\n", "init_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", ",", "sample_scale", ")", "\n", "\n", "# Extract features from the relevant scale", "\n", "iou_features", "=", "self", ".", "get_iou_features", "(", "backbone_feat", ")", "\n", "iou_features", "=", "TensorList", "(", "[", "x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "for", "x", "in", "iou_features", "]", ")", "\n", "\n", "# Generate random initial boxes", "\n", "init_boxes", "=", "init_box", ".", "view", "(", "1", ",", "1", ",", "4", ")", ".", "clone", "(", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "# Optimize the boxes", "\n", "output_boxes", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_bb", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "init_boxes", ")", ".", "view", "(", "-", "1", ",", "4", ")", ".", "cpu", "(", ")", "\n", "\n", "# Remove weird boxes", "\n", "output_boxes", "[", ":", ",", "2", ":", "]", ".", "clamp_", "(", "1", ")", "\n", "\n", "predicted_box", "=", "output_boxes", "[", "0", ",", ":", "]", "\n", "\n", "# Get new position and size", "\n", "new_pos", "=", "predicted_box", "[", ":", "2", "]", "+", "predicted_box", "[", "2", ":", "]", "/", "2", "\n", "new_pos", "=", "(", "new_pos", ".", "flip", "(", "(", "0", ",", ")", ")", "-", "(", "self", ".", "img_sample_sz", "-", "1", ")", "/", "2", ")", "*", "sample_scale", "+", "sample_pos", "\n", "new_target_sz", "=", "predicted_box", "[", "2", ":", "]", ".", "flip", "(", "(", "0", ",", ")", ")", "*", "sample_scale", "\n", "new_scale_bbr", "=", "torch", ".", "sqrt", "(", "new_target_sz", ".", "prod", "(", ")", "/", "self", ".", "base_target_sz", ".", "prod", "(", ")", ")", "\n", "new_scale", "=", "new_scale_bbr", "\n", "\n", "self", ".", "pos_iounet", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iounet_pos_for_learning'", ",", "True", ")", ":", "\n", "            ", "self", ".", "pos", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "", "self", ".", "target_sz", "=", "new_target_sz", "\n", "\n", "if", "update_scale", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.visdom_draw_tracking": [[1098, 1103], ["hasattr", "keep_track.KeepTrack.visdom.register", "keep_track.KeepTrack.visdom.register"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register"], ["", "", "def", "visdom_draw_tracking", "(", "self", ",", "image", ",", "box", ",", "segmentation", "=", "None", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "'search_area_box'", ")", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "box", ",", "self", ".", "search_area_box", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "box", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.visualize_candidate_assignment_matrix": [[1104, 1125], ["[].exp().cpu().numpy", "matplotlib.subplots", "matplotlib.subplots", "ax.imshow", "ax.set_xticks", "ax.set_yticks", "ax.set_xticklabels", "ax.set_yticklabels", "range", "ax.set_title", "keep_track.KeepTrack.visdom.visdom.matplot", "matplotlib.close", "matplotlib.close", "numpy.arange", "numpy.arange", "range", "[].exp().cpu", "ax.text", "ax.text", "[].exp", "range", "range"], "methods", ["None"], ["", "", "def", "visualize_candidate_assignment_matrix", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "data", "is", "not", "None", ":", "\n", "            ", "assignment_probs", "=", "data", "[", "'match_preds'", "]", "[", "'log_assignment'", "]", "[", "0", "]", ".", "exp", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "(", "4", ",", "4", ")", ")", "\n", "ax", ".", "imshow", "(", "assignment_probs", ",", "vmin", "=", "0", ",", "vmax", "=", "1", ")", "\n", "\n", "ax", ".", "set_xticks", "(", "np", ".", "arange", "(", "assignment_probs", ".", "shape", "[", "1", "]", ")", ")", "\n", "ax", ".", "set_yticks", "(", "np", ".", "arange", "(", "assignment_probs", ".", "shape", "[", "0", "]", ")", ")", "\n", "ax", ".", "set_xticklabels", "(", "[", "'{}'", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "assignment_probs", ".", "shape", "[", "1", "]", "-", "1", ")", "]", "+", "[", "'NM'", "]", ")", "\n", "ax", ".", "set_yticklabels", "(", "[", "'{}'", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "assignment_probs", ".", "shape", "[", "0", "]", "-", "1", ")", "]", "+", "[", "'NM'", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "assignment_probs", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "assignment_probs", ".", "shape", "[", "1", "]", ")", ":", "\n", "                    ", "if", "assignment_probs", "[", "i", ",", "j", "]", "<", "0.5", ":", "\n", "                        ", "ax", ".", "text", "(", "j", ",", "i", ",", "'{:0.2f}'", ".", "format", "(", "assignment_probs", "[", "i", ",", "j", "]", ")", ",", "ha", "=", "\"center\"", ",", "va", "=", "\"center\"", ",", "color", "=", "\"w\"", ")", "\n", "", "else", ":", "\n", "                        ", "ax", ".", "text", "(", "j", ",", "i", ",", "'{:0.2f}'", ".", "format", "(", "assignment_probs", "[", "i", ",", "j", "]", ")", ",", "ha", "=", "\"center\"", ",", "va", "=", "\"center\"", ",", "color", "=", "\"k\"", ")", "\n", "", "", "", "ax", ".", "set_title", "(", "'Assignment Matrix Probs {},{}'", ".", "format", "(", "data", "[", "'frameid0'", "]", ",", "data", "[", "'frameid1'", "]", ")", ")", "\n", "self", ".", "visdom", ".", "visdom", ".", "matplot", "(", "plt", ",", "opts", "=", "{", "'title'", ":", "'assignment matrix'", "}", ",", "win", "=", "'assignment matrix'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.KeepTrack.visualize_candidate_matching": [[1126, 1200], ["axis.add_patch", "axis.text", "axis.plot", "axis.text", "axis.text", "[].exp().cpu().numpy", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "keep_track.KeepTrack.params.get", "ltr.find_local_maxima", "ltr.find_local_maxima", "ltr.find_local_maxima", "ltr.find_local_maxima", "torch.stack().permute().cpu().numpy", "torch.stack().permute().cpu().numpy", "torch.stack().permute().cpu().numpy", "torch.stack().permute().cpu().numpy", "torch.stack().permute().cpu().numpy", "torch.stack().permute().cpu().numpy", "torch.stack().permute().cpu().numpy", "torch.stack().permute().cpu().numpy", "[].cpu().tolist", "matplotlib.subplots", "matplotlib.subplots", "ax.imshow", "enumerate", "ax.set_title", "ax.axis", "keep_track.KeepTrack.visdom.visdom.matplot", "matplotlib.close", "matplotlib.close", "matplotlib.Circle", "matplotlib.Circle", "data[].squeeze", "data[].squeeze", "data[].squeeze", "data[].squeeze", "im_patches[].numpy().astype", "keep_track.KeepTrack.visualize_candidate_matching.add_circle"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.find_local_maxima", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.find_local_maxima", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.find_local_maxima", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.find_local_maxima"], ["", "", "def", "visualize_candidate_matching", "(", "self", ",", "data", ")", ":", "\n", "\n", "        ", "def", "add_circle", "(", "axis", ",", "x", ",", "y", ",", "id", ",", "color", ")", ":", "\n", "            ", "axis", ".", "add_patch", "(", "patches", ".", "Circle", "(", "(", "x", ",", "y", ")", ",", "20", ",", "linewidth", "=", "3", ",", "edgecolor", "=", "color", ",", "facecolor", "=", "'none'", ")", ")", "\n", "axis", ".", "text", "(", "x", ",", "y", ",", "'{}'", ".", "format", "(", "id", ")", ",", "ha", "=", "\"center\"", ",", "va", "=", "\"center\"", ",", "color", "=", "color", ",", "fontsize", "=", "15", ",", "weight", "=", "'bold'", ")", "\n", "\n", "", "def", "add_connection", "(", "axis", ",", "x0", ",", "y0", ",", "x1", ",", "y1", ",", "color", ")", ":", "\n", "            ", "axis", ".", "plot", "(", "[", "x0", ",", "x1", "]", ",", "[", "y0", ",", "y1", "]", ",", "color", "=", "color", ",", "linewidth", "=", "2", ")", "\n", "\n", "", "def", "add_score_value", "(", "axis", ",", "score", ",", "id", ",", "offset", ",", "color", ")", ":", "\n", "            ", "x", "=", "10", "+", "100", "*", "(", "id", "//", "3", ")", "+", "offset", "\n", "y", "=", "(", "int", "(", "id", ")", "%", "3", ")", "*", "20", "+", "10", "+", "img_sz", "\n", "axis", ".", "text", "(", "x", ",", "y", ",", "'{}: {:0.3f}'", ".", "format", "(", "id", ",", "score", ")", ",", "ha", "=", "\"left\"", ",", "va", "=", "\"center\"", ",", "color", "=", "color", ",", "fontsize", "=", "10", ")", "\n", "\n", "", "def", "add_matching_probability", "(", "axis", ",", "prob", ",", "id0", ",", "id1", ",", "num_entry", ",", "offset", ",", "color", ")", ":", "\n", "            ", "x", "=", "offset", "+", "10", "\n", "y", "=", "num_entry", "*", "20", "\n", "axis", ".", "text", "(", "x", ",", "y", ",", "'{}--[{:0.1f}]--{}'", ".", "format", "(", "id0", ",", "100", "*", "prob", ",", "id1", ")", ",", "ha", "=", "\"left\"", ",", "va", "=", "\"center\"", ",", "color", "=", "color", ",", "fontsize", "=", "10", ")", "\n", "\n", "", "if", "data", "is", "not", "None", ":", "\n", "            ", "gap", "=", "50", "\n", "\n", "assignment_probs", "=", "data", "[", "'match_preds'", "]", "[", "'log_assignment'", "]", "[", "0", "]", ".", "exp", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "im_patches", "=", "torch", ".", "cat", "(", "[", "\n", "data", "[", "'im_patches0'", "]", ",", "\n", "255", "*", "torch", ".", "ones", "(", "(", "1", ",", "3", ",", "data", "[", "'im_patches0'", "]", ".", "shape", "[", "3", "]", ",", "gap", ")", ")", ",", "\n", "data", "[", "'im_patches1'", "]", "\n", "]", ",", "dim", "=", "3", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "th", "=", "self", ".", "params", ".", "get", "(", "'local_max_candidate_score_th'", ",", "0.05", ")", "\n", "coords0", ",", "scores0", "=", "prutils", ".", "find_local_maxima", "(", "data", "[", "'score_map0'", "]", ".", "squeeze", "(", ")", ",", "ks", "=", "5", ",", "th", "=", "th", ")", "\n", "coords1", ",", "scores1", "=", "prutils", ".", "find_local_maxima", "(", "data", "[", "'score_map1'", "]", ".", "squeeze", "(", ")", ",", "ks", "=", "5", ",", "th", "=", "th", ")", "\n", "\n", "img_sz", "=", "self", ".", "params", ".", "image_sample_size", "\n", "sm0_sz", "=", "data", "[", "'score_map0'", "]", ".", "squeeze", "(", ")", ".", "shape", "\n", "sm1_sz", "=", "data", "[", "'score_map1'", "]", ".", "squeeze", "(", ")", ".", "shape", "\n", "\n", "img_coords0", "=", "torch", ".", "stack", "(", "[", "\n", "img_sz", "*", "(", "coords0", "[", ":", ",", "0", "]", ".", "float", "(", ")", "/", "(", "sm0_sz", "[", "0", "]", "-", "1", ")", ")", ",", "\n", "img_sz", "*", "(", "coords0", "[", ":", ",", "1", "]", ".", "float", "(", ")", "/", "(", "sm0_sz", "[", "1", "]", "-", "1", ")", ")", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "img_coords1", "=", "torch", ".", "stack", "(", "[", "\n", "img_sz", "*", "(", "coords1", "[", ":", ",", "0", "]", ".", "float", "(", ")", "/", "(", "sm1_sz", "[", "0", "]", "-", "1", ")", ")", ",", "\n", "img_sz", "*", "(", "coords1", "[", ":", ",", "1", "]", ".", "float", "(", ")", "/", "(", "sm1_sz", "[", "1", "]", "-", "1", ")", ")", "+", "(", "gap", "+", "img_sz", ")", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "matches1", "=", "data", "[", "'match_preds'", "]", "[", "'matches1'", "]", "[", "0", "]", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "colors", "=", "[", "'red'", ",", "'limegreen'", ",", "'deepskyblue'", ",", "'darkorange'", ",", "'darkviolet'", ",", "'grey'", ",", "'black'", ",", "'blue'", ",", "'gold'", ",", "'pink'", "]", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "12", ",", "5", ")", ")", "\n", "\n", "ax", ".", "imshow", "(", "im_patches", "[", "0", "]", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "uint8", ")", ")", "\n", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "matches1", ")", ":", "\n", "                ", "color", "=", "colors", "[", "i", "%", "len", "(", "colors", ")", "]", "\n", "\n", "add_circle", "(", "ax", ",", "x", "=", "img_coords1", "[", "i", ",", "1", "]", ",", "y", "=", "img_coords1", "[", "i", ",", "0", "]", ",", "id", "=", "i", ",", "color", "=", "color", ")", "\n", "add_score_value", "(", "ax", ",", "score", "=", "scores1", "[", "i", "]", ",", "id", "=", "i", ",", "offset", "=", "img_sz", "+", "gap", ",", "color", "=", "color", ")", "\n", "\n", "if", "m", ">=", "0", ":", "\n", "                    ", "add_circle", "(", "ax", ",", "x", "=", "img_coords0", "[", "m", ",", "1", "]", ",", "y", "=", "img_coords0", "[", "m", ",", "0", "]", ",", "id", "=", "m", ",", "color", "=", "color", ")", "\n", "add_connection", "(", "ax", ",", "x0", "=", "img_coords0", "[", "m", ",", "1", "]", ",", "y0", "=", "img_coords0", "[", "m", ",", "0", "]", ",", "x1", "=", "img_coords1", "[", "i", ",", "1", "]", ",", "\n", "y1", "=", "img_coords1", "[", "i", ",", "0", "]", ",", "color", "=", "color", ")", "\n", "add_score_value", "(", "ax", ",", "score", "=", "scores0", "[", "m", "]", ",", "id", "=", "m", ",", "offset", "=", "0", ",", "color", "=", "color", ")", "\n", "add_matching_probability", "(", "ax", ",", "prob", "=", "assignment_probs", "[", "m", ",", "i", "]", ",", "id0", "=", "m", ",", "id1", "=", "i", ",", "offset", "=", "2", "*", "img_sz", "+", "gap", ",", "\n", "num_entry", "=", "sum", "(", "torch", ".", "tensor", "(", "matches1", "[", ":", "i", "]", ")", ">=", "0", ")", ",", "color", "=", "color", ")", "\n", "\n", "\n", "", "", "ax", ".", "set_title", "(", "'Matching between Frames {} {}'", ".", "format", "(", "data", "[", "'frameid0'", "]", ",", "data", "[", "'frameid1'", "]", ")", ")", "\n", "ax", ".", "axis", "(", "'off'", ")", "\n", "self", ".", "visdom", ".", "visdom", ".", "matplot", "(", "plt", ",", "opts", "=", "{", "'title'", ":", "'matching between frames'", "}", ",", "win", "=", "'matching between frames'", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.__init__.get_tracker_class": [[3, 5], ["None"], "function", ["None"], ["import", "pytracking", ".", "libs", ".", "operation", "as", "operation", "\n", "import", "pytracking", ".", "libs", ".", "fourier", "as", "fourier", "\n", "import", "pytracking", ".", "libs", ".", "dcf", "as", "dcf", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.Candidate.__init__": [[5, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "id", ",", "score", ",", "tsm_coord", ",", "object_id", ")", ":", "\n", "        ", "self", ".", "ids", "=", "[", "id", "]", "\n", "self", ".", "scores", "=", "[", "score", "]", "\n", "self", ".", "tsm_coords", "=", "[", "tsm_coord", "]", "\n", "self", ".", "object_id", "=", "object_id", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.CandidateCollection.__init__": [[13, 28], ["enumerate", "zip", "candidates.Candidate", "scores.cpu().numpy", "tsm_coords.cpu().numpy", "scores.cpu", "tsm_coords.cpu"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "scores", ",", "tsm_coords", ",", "candidate_selection_is_certain", "=", "True", ")", ":", "\n", "        ", "self", ".", "candidates", "=", "{", "}", "\n", "self", ".", "object_id_cntr", "=", "0", "\n", "self", ".", "flag", "=", "'normal'", "\n", "self", ".", "candidate_id_of_selected_candidate", "=", "0", "\n", "self", ".", "object_id_of_selected_candidate", "=", "0", "\n", "self", ".", "candidate_selection_is_certain", "=", "candidate_selection_is_certain", "\n", "\n", "if", "candidate_selection_is_certain", "==", "False", ":", "\n", "            ", "self", ".", "object_id_of_selected_candidate", "=", "1", "\n", "self", ".", "object_id_cntr", "=", "1", "\n", "\n", "", "for", "id", ",", "(", "score", ",", "tsm_coord", ")", "in", "enumerate", "(", "zip", "(", "scores", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "tsm_coords", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ":", "\n", "            ", "self", ".", "candidates", "[", "id", "]", "=", "Candidate", "(", "id", ",", "score", ",", "tsm_coord", ",", "self", ".", "object_id_cntr", ")", "\n", "self", ".", "object_id_cntr", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.CandidateCollection.update": [[29, 41], ["matches.view.view.view", "match_scores.view.view.view", "candidates.CandidateCollection._reassign_candidates_according_to_matching", "candidates.CandidateCollection._check_if_object0_is_detected", "candidates.CandidateCollection._check_if_more_suitable_candidate_is_available", "candidates.CandidateCollection._clean_up_if_object0_not_found", "candidates.CandidateCollection._try_to_reselect_candidate"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.CandidateCollection._reassign_candidates_according_to_matching", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.CandidateCollection._check_if_object0_is_detected", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.CandidateCollection._check_if_more_suitable_candidate_is_available", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.CandidateCollection._clean_up_if_object0_not_found", "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.CandidateCollection._try_to_reselect_candidate"], ["", "", "def", "update", "(", "self", ",", "scores", ",", "tsm_coords", ",", "matches", ",", "match_scores", ")", ":", "\n", "        ", "matches", "=", "matches", ".", "view", "(", "-", "1", ")", "\n", "match_scores", "=", "match_scores", ".", "view", "(", "-", "1", ")", "\n", "\n", "self", ".", "_reassign_candidates_according_to_matching", "(", "match_scores", ",", "matches", ",", "scores", ",", "tsm_coords", ")", "\n", "\n", "object0_detected", "=", "self", ".", "_check_if_object0_is_detected", "(", ")", "\n", "object0_detected", "=", "self", ".", "_check_if_more_suitable_candidate_is_available", "(", "object0_detected", ")", "\n", "\n", "if", "not", "object0_detected", ":", "\n", "            ", "self", ".", "_clean_up_if_object0_not_found", "(", ")", "\n", "self", ".", "_try_to_reselect_candidate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.CandidateCollection._reassign_candidates_according_to_matching": [[42, 69], ["torch.ones", "enumerate", "len", "zip", "candidates.Candidate", "candidates.Candidate", "Candidate.scores.append", "Candidate.ids.append", "Candidate.tsm_coords.append", "match.item", "match.item"], "methods", ["None"], ["", "", "def", "_reassign_candidates_according_to_matching", "(", "self", ",", "match_scores", ",", "matches", ",", "scores", ",", "tsm_coords", ")", ":", "\n", "        ", "candidates", "=", "{", "}", "\n", "non_matched_candidates", "=", "torch", ".", "ones", "(", "len", "(", "self", ".", "candidates", ")", ")", "\n", "# reassign peaks according to matches.", "\n", "for", "id", ",", "(", "score", ",", "tsm_coord", ",", "match", ",", "match_score", ")", "in", "enumerate", "(", "zip", "(", "scores", ",", "tsm_coords", ",", "matches", ",", "match_scores", ")", ")", ":", "\n", "            ", "if", "match", ">=", "0", ":", "\n", "                ", "candidate", "=", "self", ".", "candidates", "[", "match", ".", "item", "(", ")", "]", "\n", "non_matched_candidates", "[", "match", ".", "item", "(", ")", "]", "=", "0", "\n", "\n", "is_prob_too_low", "=", "(", "match_score", "<", "0.6", "or", "(", "match_score", "<", "0.85", "and", "score", "<", "0.2", ")", ")", "\n", "\n", "if", "candidate", ".", "object_id", "==", "self", ".", "object_id_of_selected_candidate", "and", "is_prob_too_low", ":", "\n", "# matching assignment probability is too low skip assignment and start with a new peak.", "\n", "                    ", "candidate", "=", "Candidate", "(", "id", ",", "score", ",", "tsm_coord", ",", "self", ".", "object_id_cntr", ")", "\n", "self", ".", "object_id_cntr", "+=", "1", "\n", "", "else", ":", "\n", "# add candidate meta data to assigned candidate", "\n", "                    ", "candidate", ".", "scores", ".", "append", "(", "score", ")", "\n", "candidate", ".", "ids", ".", "append", "(", "id", ")", "\n", "candidate", ".", "tsm_coords", ".", "append", "(", "tsm_coord", ")", "\n", "\n", "", "candidates", "[", "id", "]", "=", "candidate", "\n", "\n", "", "else", ":", "\n", "                ", "candidates", "[", "id", "]", "=", "Candidate", "(", "id", ",", "score", ",", "tsm_coord", ",", "self", ".", "object_id_cntr", ")", "\n", "self", ".", "object_id_cntr", "+=", "1", "\n", "", "", "self", ".", "candidates", "=", "candidates", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.CandidateCollection._check_if_object0_is_detected": [[70, 82], ["candidates.CandidateCollection.candidates.items", "max"], "methods", ["None"], ["", "def", "_check_if_object0_is_detected", "(", "self", ")", ":", "\n", "        ", "object0_detected", "=", "False", "\n", "for", "id", ",", "candidate", "in", "self", ".", "candidates", ".", "items", "(", ")", ":", "\n", "            ", "if", "candidate", ".", "object_id", "==", "self", ".", "object_id_of_selected_candidate", ":", "\n", "                ", "self", ".", "candidate_id_of_selected_candidate", "=", "id", "\n", "self", ".", "flag", "=", "'normal'", "\n", "object0_detected", "=", "True", "\n", "\n", "if", "max", "(", "candidate", ".", "scores", ")", ">", "0.75", ":", "\n", "                    ", "self", ".", "candidate_selection_is_certain", "=", "True", "\n", "\n", "", "", "", "return", "object0_detected", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.CandidateCollection._check_if_more_suitable_candidate_is_available": [[83, 96], ["max", "max"], "methods", ["None"], ["", "def", "_check_if_more_suitable_candidate_is_available", "(", "self", ",", "object0_detected", ")", ":", "\n", "        ", "if", "object0_detected", "and", "self", ".", "candidate_id_of_selected_candidate", "!=", "0", ":", "\n", "# there is a candidate that has a higher score than the currently selected one.", "\n", "            ", "max_score_candidate", "=", "self", ".", "candidates", "[", "0", "]", "\n", "candidate_selected_as_target", "=", "self", ".", "candidates", "[", "self", ".", "candidate_id_of_selected_candidate", "]", "\n", "\n", "if", "max", "(", "max_score_candidate", ".", "scores", ")", ">", "max", "(", "candidate_selected_as_target", ".", "scores", ")", ":", "\n", "                ", "self", ".", "flag", "=", "'normal'", "\n", "self", ".", "candidate_id_of_selected_candidate", "=", "0", "\n", "self", ".", "object_id_of_selected_candidate", "=", "max_score_candidate", ".", "object_id", "\n", "object0_detected", "=", "True", "\n", "\n", "", "", "return", "object0_detected", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.CandidateCollection._clean_up_if_object0_not_found": [[97, 103], ["None"], "methods", ["None"], ["", "def", "_clean_up_if_object0_not_found", "(", "self", ")", ":", "\n", "        ", "self", ".", "candidate_id_of_selected_candidate", "=", "None", "\n", "# object has just disappeared now.", "\n", "if", "self", ".", "flag", "==", "'normal'", ":", "\n", "            ", "self", ".", "flag", "=", "'not_found'", "\n", "self", ".", "candidate_selection_is_certain", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.candidates.CandidateCollection._try_to_reselect_candidate": [[104, 115], ["candidates.CandidateCollection.candidates.keys"], "methods", ["None"], ["", "", "def", "_try_to_reselect_candidate", "(", "self", ")", ":", "\n", "        ", "max_score", "=", "0", "\n", "for", "id", "in", "self", ".", "candidates", ".", "keys", "(", ")", ":", "\n", "            ", "candidate", "=", "self", ".", "candidates", "[", "id", "]", "\n", "recent_score", "=", "candidate", ".", "scores", "[", "-", "1", "]", "\n", "\n", "if", "(", "recent_score", ">", "0.25", "and", "recent_score", ">", "max_score", ")", ":", "\n", "                ", "self", ".", "flag", "=", "'normal'", "\n", "self", ".", "candidate_id_of_selected_candidate", "=", "id", "\n", "self", ".", "object_id_of_selected_candidate", "=", "self", ".", "candidates", "[", "id", "]", ".", "object_id", "\n", "max_score", "=", "recent_score", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.keep_track.keep_track.run": [[14, 126], ["ltr.dataset.LasotCandidateMatching", "ltr.dataset.LasotCandidateMatching", "ltr.Transform", "ltr.Transform", "ltr.data.processing.TargetCandiateMatchingProcessing", "ltr.data.processing.TargetCandiateMatchingProcessing", "ltr.data.processing.TargetCandiateMatchingProcessing", "ltr.data.sampler.SequentialTargetCandidateMatchingSampler", "ltr.data.sampler.SequentialTargetCandidateMatchingSampler", "ltr.data.sampler.SequentialTargetCandidateMatchingSampler", "ltr.data.sampler.SequentialTargetCandidateMatchingSampler", "ltr.data.LTRLoader", "ltr.data.LTRLoader", "ltr.data.LTRLoader", "ltr.data.LTRLoader", "ltr.models.target_candidate_matching.target_candidate_matching.target_candidate_matching_net_resnet50", "os.path.join", "ltr.load_network", "ltr.MultiGPU.load_state_dict", "ltr.MultiGPU.parameters", "ltr.MultiGPU.feature_extractor.parameters", "ltr.TargetCandiateMatchingActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToTensor", "ltr.Normalize", "ltr.ToTensorAndJitter", "ltr.RandomBlur", "ltr.Normalize", "base_net.state_dict", "p.requires_grad_", "p.requires_grad_", "ltr.MultiGPU", "ltr.TargetCandidateMatchingLoss", "int", "int", "int", "int", "tcm_actors.TargetCandiateMatchingActor.net.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.target_candidate_matching_net_resnet50", "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_network", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["import", "matplotlib", ".", "patches", "as", "patches", "\n", "from", "ltr", ".", "models", ".", "layers", "import", "activation", "\n", "import", "ltr", ".", "data", ".", "processing_utils", "as", "prutils", "\n", "from", ".", "candidates", "import", "CandidateCollection", "\n", "\n", "from", "collections", "import", "defaultdict", "\n", "import", "numpy", "as", "np", "\n", "\n", "\n", "class", "KeepTrack", "(", "BaseTracker", ")", ":", "\n", "\n", "    ", "multiobj_mode", "=", "'parallel'", "\n", "\n", "def", "initialize_features", "(", "self", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "self", ",", "'features_initialized'", ",", "False", ")", ":", "\n", "            ", "self", ".", "params", ".", "net", ".", "initialize", "(", ")", "\n", "", "self", ".", "features_initialized", "=", "True", "\n", "\n", "", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "# Initialize some stuff", "\n", "        ", "self", ".", "frame_num", "=", "1", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'device'", ")", ":", "\n", "            ", "self", ".", "params", ".", "device", "=", "'cuda'", "if", "self", ".", "params", ".", "use_gpu", "else", "'cpu'", "\n", "\n", "# Initialize network", "\n", "", "self", ".", "initialize_features", "(", ")", "\n", "\n", "# The DiMP network", "\n", "self", ".", "net", "=", "self", ".", "params", ".", "net", "\n", "\n", "# Time initialization", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# Get target position and size", "\n", "state", "=", "info", "[", "'init_bbox'", "]", "\n", "self", ".", "pos", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "1", "]", "+", "(", "state", "[", "3", "]", "-", "1", ")", "/", "2", ",", "state", "[", "0", "]", "+", "(", "state", "[", "2", "]", "-", "1", ")", "/", "2", "]", ")", "\n", "self", ".", "target_sz", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "3", "]", ",", "state", "[", "2", "]", "]", ")", "\n", "\n", "# Get object id", "\n", "self", ".", "object_id", "=", "info", ".", "get", "(", "'object_ids'", ",", "[", "None", "]", ")", "[", "0", "]", "\n", "self", ".", "id_str", "=", "''", "if", "self", ".", "object_id", "is", "None", "else", "' {}'", ".", "format", "(", "self", ".", "object_id", ")", "\n", "\n", "# Set sizes", "\n", "self", ".", "image_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "sz", "=", "self", ".", "params", ".", "image_sample_size", "\n", "sz", "=", "torch", ".", "Tensor", "(", "[", "sz", ",", "sz", "]", "if", "isinstance", "(", "sz", ",", "int", ")", "else", "sz", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_image_aspect_ratio'", ",", "False", ")", ":", "\n", "            ", "sz", "=", "self", ".", "image_sz", "*", "sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "/", "self", ".", "image_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "stride", "=", "self", ".", "params", ".", "get", "(", "'feature_stride'", ",", "32", ")", "\n", "sz", "=", "torch", ".", "round", "(", "sz", "/", "stride", ")", "*", "stride", "\n", "", "self", ".", "img_sample_sz", "=", "sz", "\n", "self", ".", "img_support_sz", "=", "self", ".", "img_sample_sz", "\n", "\n", "# Set search area", "\n", "search_area", "=", "torch", ".", "prod", "(", "self", ".", "target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ".", "item", "(", ")", "\n", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", ")", "/", "self", ".", "img_sample_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "\n", "# Target size in base scale", "\n", "self", ".", "base_target_sz", "=", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "\n", "# Setup scale factors", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'scale_factors'", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "ones", "(", "1", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "params", ".", "scale_factors", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "Tensor", "(", "self", ".", "params", ".", "scale_factors", ")", "\n", "\n", "# Setup scale bounds", "\n", "", "self", ".", "min_scale_factor", "=", "torch", ".", "max", "(", "10", "/", "self", ".", "base_target_sz", ")", "\n", "self", ".", "max_scale_factor", "=", "torch", ".", "min", "(", "self", ".", "image_sz", "/", "self", ".", "base_target_sz", ")", "\n", "\n", "# Extract and transform sample", "\n", "init_backbone_feat", "=", "self", ".", "generate_init_samples", "(", "im", ")", "\n", "\n", "# Initialize classifier", "\n", "self", ".", "init_classifier", "(", "init_backbone_feat", ")", "\n", "\n", "# Initialize IoUNet", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", ":", "\n", "            ", "self", ".", "init_iou_net", "(", "init_backbone_feat", ")", "\n", "\n", "", "self", ".", "logging_dict", "=", "defaultdict", "(", "list", ")", "\n", "\n", "self", ".", "params", ".", "target_candidate_matching_net", ".", "initialize", "(", ")", "\n", "self", ".", "target_candidate_matching_net", "=", "self", ".", "params", ".", "target_candidate_matching_net", "\n", "self", ".", "previous_candidates", "=", "None", "\n", "self", ".", "candidate_collection", "=", "None", "\n", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "            ", "self", ".", "previous_im_patches", "=", "None", "\n", "self", ".", "previous_score_map", "=", "None", "\n", "\n", "", "self", ".", "target_scales", "=", "[", "]", "\n", "self", ".", "target_not_found_counter", "=", "0", "\n", "\n", "self", ".", "mem_sort_indices", "=", "torch", ".", "arange", "(", "0", ",", "self", ".", "num_init_samples", "[", "0", "]", ")", "\n", "\n", "out", "=", "{", "'time'", ":", "time", ".", "time", "(", ")", "-", "tic", "}", "\n", "return", "out", "\n", "\n", "", "def", "track", "(", "self", ",", "image", ",", "info", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "        ", "self", ".", "debug_info", "=", "{", "}", "\n", "\n", "self", ".", "frame_num", "+=", "1", "\n", "self", ".", "debug_info", "[", "'frame_num'", "]", "=", "self", ".", "frame_num", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# ------- LOCALIZATION ------- #", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.default.parameters": [[5, 75], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["\n", "def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "# Feature specific parameters", "\n", "shallow_params", "=", "TrackerParams", "(", ")", "\n", "deep_params", "=", "TrackerParams", "(", ")", "\n", "\n", "# Patch sampling parameters", "\n", "params", ".", "max_image_sample_size", "=", "250", "**", "2", "# Maximum image sample size", "\n", "params", ".", "min_image_sample_size", "=", "200", "**", "2", "# Minimum image sample size", "\n", "params", ".", "search_area_scale", "=", "4.5", "# Scale relative to target size", "\n", "\n", "# Conjugate Gradient parameters", "\n", "params", ".", "CG_iter", "=", "5", "# The number of Conjugate Gradient iterations in each update after the first frame", "\n", "params", ".", "init_CG_iter", "=", "100", "# The total number of Conjugate Gradient iterations used in the first frame", "\n", "params", ".", "init_GN_iter", "=", "10", "# The number of Gauss-Newton iterations used in the first frame (only if the projection matrix is updated)", "\n", "params", ".", "post_init_CG_iter", "=", "0", "# CG iterations to run after GN", "\n", "params", ".", "fletcher_reeves", "=", "False", "# Use the Fletcher-Reeves (true) or Polak-Ribiere (false) formula in the Conjugate Gradient", "\n", "params", ".", "standard_alpha", "=", "True", "# Use the standard formula for computing the step length in Conjugate Gradient", "\n", "params", ".", "CG_forgetting_rate", "=", "75", "# Forgetting rate of the last conjugate direction", "\n", "params", ".", "precond_data_param", "=", "0.3", "# Weight of the data term in the preconditioner", "\n", "params", ".", "precond_reg_param", "=", "0.15", "# Weight of the regularization term in the preconditioner", "\n", "params", ".", "precond_proj_param", "=", "35", "# Weight of the projection matrix part in the preconditioner", "\n", "\n", "# Learning parameters", "\n", "shallow_params", ".", "learning_rate", "=", "0.025", "\n", "deep_params", ".", "learning_rate", "=", "0.0075", "\n", "shallow_params", ".", "output_sigma_factor", "=", "1", "/", "16", "\n", "deep_params", ".", "output_sigma_factor", "=", "1", "/", "4", "\n", "\n", "# Training parameters", "\n", "params", ".", "sample_memory_size", "=", "200", "# Memory size", "\n", "params", ".", "train_skipping", "=", "10", "# How often to run training (every n-th frame)", "\n", "\n", "# Detection parameters", "\n", "params", ".", "scale_factors", "=", "1.02", "**", "torch", ".", "arange", "(", "-", "2", ",", "3", ")", ".", "float", "(", ")", "# What scales to use for localization", "\n", "params", ".", "score_upsample_factor", "=", "1", "# How much Fourier upsampling to use", "\n", "params", ".", "score_fusion_strategy", "=", "'weightedsum'", "# Fusion strategy", "\n", "shallow_params", ".", "translation_weight", "=", "0.4", "# Weight of this feature", "\n", "deep_params", ".", "translation_weight", "=", "1", "-", "shallow_params", ".", "translation_weight", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'shift'", ":", "[", "(", "6", ",", "6", ")", ",", "(", "-", "6", ",", "6", ")", ",", "(", "6", ",", "-", "6", ")", ",", "(", "-", "6", ",", "-", "6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "# Whether to use augmentation for this feature", "\n", "deep_params", ".", "use_augmentation", "=", "True", "\n", "shallow_params", ".", "use_augmentation", "=", "True", "\n", "\n", "# Factorized convolution parameters", "\n", "# params.use_projection_matrix = True    # Use projection matrix, i.e. use the factorized convolution formulation", "\n", "params", ".", "update_projection_matrix", "=", "True", "# Whether the projection matrix should be optimized or not", "\n", "# params.proj_init_method = 'pca'        # Method for initializing the projection matrix", "\n", "params", ".", "projection_reg", "=", "5e-8", "# Regularization parameter of the projection matrix", "\n", "shallow_params", ".", "compressed_dim", "=", "16", "# Dimension output of projection matrix for shallow features", "\n", "deep_params", ".", "compressed_dim", "=", "64", "# Dimension output of projection matrix for deep features", "\n", "\n", "# Interpolation parameters", "\n", "params", ".", "interpolation_method", "=", "'bicubic'", "# The kind of interpolation kernel", "\n", "params", ".", "interpolation_bicubic_a", "=", "-", "0.75", "# The parameter for the bicubic interpolation kernel", "\n", "params", ".", "interpolation_centering", "=", "True", "# Center the kernel at the feature sample", "\n", "params", ".", "interpolation_windowing", "=", "False", "# Do additional windowing on the Fourier coefficients of the kernel", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.default_vot.parameters": [[5, 82], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "14", "*", "16", "\n", "params", ".", "search_area_scale", "=", "4", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "250", "\n", "params", ".", "learning_rate", "=", "0.0075", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.0", "\n", "params", ".", "train_skipping", "=", "10", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "25", "\n", "params", ".", "net_opt_update_iter", "=", "3", "\n", "params", ".", "net_opt_hn_iter", "=", "3", "\n", "\n", "params", ".", "output_sigma_factor", "=", "1", "/", "4", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# localization parameters", "\n", "params", ".", "window_output", "=", "True", "\n", "params", ".", "use_clipped_window", "=", "True", "\n", "params", ".", "effective_search_area", "=", "4.0", "\n", "params", ".", "apply_window_to_dimp_score", "=", "True", "\n", "\n", "params", ".", "target_not_found_threshold_fused", "=", "0.05", "\n", "params", ".", "dimp_threshold", "=", "0.05", "\n", "\n", "params", ".", "reset_state_during_occlusion", "=", "True", "\n", "\n", "params", ".", "prev_feat_remove_subpixel_shift", "=", "True", "\n", "params", ".", "move_feat_to_center", "=", "True", "\n", "\n", "params", ".", "perform_hn_mining_dimp", "=", "True", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale_safe", "=", "2.2", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "use_iou_net", "=", "True", "\n", "params", ".", "iounet_augmentation", "=", "False", "\n", "params", ".", "iounet_use_log_scale", "=", "True", "\n", "params", ".", "iounet_k", "=", "3", "\n", "params", ".", "num_init_random_boxes", "=", "9", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "\n", "params", ".", "box_refinement_iter", "=", "5", "\n", "params", ".", "box_refinement_step_length", "=", "1", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "\n", "\n", "params", ".", "remove_offset_in_fused_score", "=", "True", "\n", "params", ".", "score_downsample_factor", "=", "1", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'kys.pth'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.__init__.get_tracker_class": [[4, 6], ["None"], "function", ["None"], ["import", "pytracking", ".", "libs", ".", "fourier", "as", "fourier", "\n", "import", "pytracking", ".", "libs", ".", "dcf", "as", "dcf", "\n", "import", "pytracking", ".", "libs", ".", "optimization", "as", "optimization", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.PrevStateHandler.__init__": [[17, 19], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "info_dict", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.PrevStateHandler.set_data": [[20, 23], ["None"], "methods", ["None"], ["", "def", "set_data", "(", "self", ",", "frame_number", ",", "feat", ",", "state", ",", "im", ",", "bb", ",", "label", ",", "bb_patch", ")", ":", "\n", "        ", "self", ".", "info_dict", "=", "{", "'frame_number'", ":", "frame_number", ",", "'feat'", ":", "feat", ",", "'state'", ":", "state", ",", "'im'", ":", "im", ",", "'bb'", ":", "bb", ",", "\n", "'label'", ":", "label", ",", "'bb_patch'", ":", "bb_patch", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.PrevStateHandler.get_data": [[24, 27], ["None"], "methods", ["None"], ["", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "info_dict", "[", "'feat'", "]", ",", "self", ".", "info_dict", "[", "'state'", "]", ",", "self", ".", "info_dict", "[", "'im'", "]", ",", "self", ".", "info_dict", "[", "'label'", "]", ",", "self", ".", "info_dict", "[", "'bb_patch'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.PrevStateHandler.reset_state": [[28, 32], ["None"], "methods", ["None"], ["", "def", "reset_state", "(", "self", ")", ":", "\n", "# Reset state in case of long occlusions", "\n", "        ", "if", "self", ".", "info_dict", "[", "'state'", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "info_dict", "[", "'state'", "]", "=", "self", ".", "info_dict", "[", "'state'", "]", "*", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.initialize_features": [[37, 41], ["getattr", "kys.KYS.params.net.initialize"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["def", "initialize_features", "(", "self", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "self", ",", "'features_initialized'", ",", "False", ")", ":", "\n", "            ", "self", ".", "params", ".", "net", ".", "initialize", "(", ")", "\n", "", "self", ".", "features_initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.initialize": [[42, 113], ["kys.KYS.initialize_features", "time.time", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "pytracking.features.preprocessing.numpy_to_torch", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "kys.KYS.generate_init_samples", "kys.KYS.init_classifier", "kys.KYS.params.get", "kys.PrevStateHandler", "kys.KYS.init_motion_module", "kys.KYS.params.has", "info.get", "math.sqrt", "kys.KYS.img_sample_sz.prod().sqrt", "kys.KYS.params.has", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "isinstance", "kys.KYS.init_iou_net", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "isinstance", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "time.time", "kys.KYS.img_sample_sz.prod"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.generate_init_samples", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_classifier", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.init_motion_module", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_iou_net"], ["", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "        ", "self", ".", "frame_num", "=", "1", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'device'", ")", ":", "\n", "            ", "self", ".", "params", ".", "device", "=", "'cuda'", "if", "self", ".", "params", ".", "use_gpu", "else", "'cpu'", "\n", "\n", "# Initialize network", "\n", "", "self", ".", "initialize_features", "(", ")", "\n", "\n", "# The DiMP network", "\n", "self", ".", "net", "=", "self", ".", "params", ".", "net", "\n", "\n", "# Time initialization", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Get target position and size", "\n", "state", "=", "info", "[", "'init_bbox'", "]", "\n", "self", ".", "pos", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "1", "]", "+", "(", "state", "[", "3", "]", "-", "1", ")", "/", "2", ",", "state", "[", "0", "]", "+", "(", "state", "[", "2", "]", "-", "1", ")", "/", "2", "]", ")", "\n", "self", ".", "target_sz", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "3", "]", ",", "state", "[", "2", "]", "]", ")", "\n", "\n", "# Get object id", "\n", "self", ".", "object_id", "=", "info", ".", "get", "(", "'object_ids'", ",", "[", "None", "]", ")", "[", "0", "]", "\n", "self", ".", "id_str", "=", "''", "if", "self", ".", "object_id", "is", "None", "else", "' {}'", ".", "format", "(", "self", ".", "object_id", ")", "\n", "\n", "# Set sizes", "\n", "sz", "=", "self", ".", "params", ".", "image_sample_size", "\n", "self", ".", "img_sample_sz", "=", "torch", ".", "Tensor", "(", "[", "sz", ",", "sz", "]", "if", "isinstance", "(", "sz", ",", "int", ")", "else", "sz", ")", "\n", "self", ".", "img_support_sz", "=", "self", ".", "img_sample_sz", "\n", "\n", "# Set search area", "\n", "search_area", "=", "torch", ".", "prod", "(", "self", ".", "target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ".", "item", "(", ")", "\n", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", ")", "/", "self", ".", "img_sample_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "\n", "# Target size in base scale", "\n", "self", ".", "base_target_sz", "=", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# Setup scale factors", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'scale_factors'", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "ones", "(", "1", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "params", ".", "scale_factors", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "Tensor", "(", "self", ".", "params", ".", "scale_factors", ")", "\n", "\n", "# Setup scale bounds", "\n", "", "self", ".", "image_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "self", ".", "min_scale_factor", "=", "torch", ".", "max", "(", "10", "/", "self", ".", "base_target_sz", ")", "\n", "self", ".", "max_scale_factor", "=", "torch", ".", "min", "(", "self", ".", "image_sz", "/", "self", ".", "base_target_sz", ")", "\n", "\n", "# Extract and transform sample", "\n", "init_backbone_feat", "=", "self", ".", "generate_init_samples", "(", "im", ")", "\n", "\n", "# Initialize dimp classifier", "\n", "self", ".", "init_classifier", "(", "init_backbone_feat", ")", "\n", "\n", "# Initialize IoUNet", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", ":", "\n", "            ", "self", ".", "init_iou_net", "(", "init_backbone_feat", ")", "\n", "\n", "", "self", ".", "label_sz", "=", "self", ".", "feature_sz", "/", "self", ".", "params", ".", "score_downsample_factor", "\n", "\n", "output_sigma_factor", "=", "self", ".", "params", ".", "output_sigma_factor", "\n", "self", ".", "sigma", "=", "(", "self", ".", "label_sz", "/", "self", ".", "img_support_sz", "*", "\n", "self", ".", "base_target_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "output_sigma_factor", "*", "torch", ".", "ones", "(", "2", ")", "\n", "\n", "self", ".", "prev_state_handler", "=", "PrevStateHandler", "(", ")", "\n", "\n", "self", ".", "init_motion_module", "(", "im", ")", "\n", "\n", "out", "=", "{", "'time'", ":", "time", ".", "time", "(", ")", "-", "tic", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.track": [[114, 214], ["pytracking.features.preprocessing.numpy_to_torch", "kys.KYS.extract_backbone_features", "im_patches[].int", "kys.KYS.get_classification_features", "kys.KYS.get_sample_location", "kys.KYS.classify_target", "kys.KYS.get_response_prediction", "kys.KYS.localize_target", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "kys.KYS.get_centered_sample_pos", "kys.KYS.params.get", "kys.KYS.params.get", "kys.KYS.params.get", "kys.KYS.params.get", "kys.KYS.get_iounet_box", "kys.KYS.update_classifier", "kys.KYS.params.get", "hasattr", "kys.KYS.pos_iounet.clone", "kys.KYS.get_iounet_box", "kys.KYS.prev_state_handler.set_data", "kys.KYS.get_iounet_box", "kys.KYS.params.get", "kys.KYS.visdom.register", "kys.KYS.visdom.register", "kys.KYS.visdom.register", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "kys.KYS.params.get", "kys.KYS.refine_target_box", "kys.KYS.params.get", "kys.KYS.get_label_function().to", "kys.KYS.prev_state_handler.reset_state", "kys.KYS.params.get", "kys.KYS.update_state", "kys.KYS.update_state", "kys.KYS.params.get", "kys.KYS.get_label_function"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_classification_features", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_sample_location", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.classify_target", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_response_prediction", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_target", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_centered_sample_pos", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.update_classifier", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.PrevStateHandler.set_data", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.refine_target_box", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.reset_state", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_state", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_state", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_label_function"], ["", "def", "track", "(", "self", ",", "image", ",", "info", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "        ", "self", ".", "debug_info", "=", "{", "}", "\n", "\n", "self", ".", "frame_num", "+=", "1", "\n", "self", ".", "debug_info", "[", "'frame_num'", "]", "=", "self", ".", "frame_num", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "self", ".", "im", "=", "im", "\n", "\n", "# ------- LOCALIZATION ------- #", "\n", "# Extract backbone features", "\n", "backbone_feat", ",", "sample_coords", ",", "im_patches", "=", "self", ".", "extract_backbone_features", "(", "im", ",", "self", ".", "get_centered_sample_pos", "(", ")", ",", "\n", "self", ".", "target_scale", "*", "self", ".", "params", ".", "scale_factors", ",", "\n", "self", ".", "img_sample_sz", ")", "\n", "# Extract classification features", "\n", "test_patch", "=", "im_patches", "[", "0", "]", ".", "int", "(", ")", "\n", "self", ".", "test_patch", "=", "test_patch", "\n", "\n", "test_x", "=", "self", ".", "get_classification_features", "(", "backbone_feat", ")", "\n", "\n", "# Location of sample", "\n", "sample_pos", ",", "sample_scales", "=", "self", ".", "get_sample_location", "(", "sample_coords", ")", "\n", "\n", "# Compute classification scores", "\n", "scores_dimp", "=", "self", ".", "classify_target", "(", "test_x", ")", "\n", "\n", "# Compute fused score using the motion module", "\n", "scores_fused", ",", "motion_feat", ",", "new_state_vector", "=", "self", ".", "get_response_prediction", "(", "backbone_feat", ",", "scores_dimp", ")", "\n", "\n", "# Localize the target", "\n", "translation_vec", ",", "scale_ind", ",", "s", ",", "flag", "=", "self", ".", "localize_target", "(", "scores_fused", ",", "scores_dimp", ",", "sample_scales", ")", "\n", "new_pos", "=", "sample_pos", "[", "scale_ind", ",", ":", "]", "+", "translation_vec", "\n", "\n", "self", ".", "debug_info", "[", "'flag'", "+", "self", ".", "id_str", "]", "=", "flag", "\n", "self", ".", "search_area_box", "=", "torch", ".", "cat", "(", "(", "sample_coords", "[", "scale_ind", ",", "[", "1", ",", "0", "]", "]", ",", "\n", "sample_coords", "[", "scale_ind", ",", "[", "3", ",", "2", "]", "]", "-", "sample_coords", "[", "scale_ind", ",", "[", "1", ",", "0", "]", "]", "-", "1", ")", ")", "\n", "\n", "# Debug information", "\n", "dimp_score_at_loc", "=", "self", ".", "debug_info", "[", "'dimp_score_at_loc'", "]", "\n", "\n", "# Update position and scale", "\n", "if", "flag", "!=", "'not_found'", ":", "\n", "            ", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", ":", "\n", "                ", "update_scale_flag", "=", "self", ".", "params", ".", "get", "(", "'update_scale_when_uncertain'", ",", "True", ")", "or", "flag", "!=", "'uncertain'", "\n", "update_scale_flag", "=", "update_scale_flag", "and", "(", "dimp_score_at_loc", ">", "self", ".", "params", ".", "get", "(", "'min_dimp_score_for_scale_update'", ",", "-", "1.0", ")", ")", "\n", "\n", "self", ".", "debug_info", "[", "'update_scale_flag'", "]", "=", "update_scale_flag", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_classifier'", ",", "True", ")", ":", "\n", "                    ", "self", ".", "update_state", "(", "new_pos", ")", "\n", "", "self", ".", "refine_target_box", "(", "backbone_feat", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ",", "scale_ind", ",", "\n", "update_scale_flag", ")", "\n", "", "elif", "self", ".", "params", ".", "get", "(", "'use_classifier'", ",", "True", ")", ":", "\n", "                ", "self", ".", "update_state", "(", "new_pos", ",", "sample_scales", "[", "scale_ind", "]", ")", "\n", "\n", "# ------- UPDATE ------- #", "\n", "", "", "update_flag", "=", "flag", "not", "in", "[", "'not_found'", ",", "'uncertain'", "]", "\n", "hard_negative", "=", "(", "flag", "==", "'hard_negative'", ")", "\n", "learning_rate", "=", "self", ".", "params", ".", "get", "(", "'hard_negative_learning_rate'", ",", "None", ")", "if", "hard_negative", "else", "None", "\n", "\n", "if", "dimp_score_at_loc", "<", "self", ".", "params", ".", "get", "(", "'min_dimp_score_update'", ",", "-", "1.0", ")", ":", "\n", "            ", "update_flag", "=", "False", "\n", "\n", "", "if", "update_flag", "and", "self", ".", "params", ".", "get", "(", "'update_classifier'", ",", "False", ")", ":", "\n", "# Get train sample", "\n", "            ", "train_x", "=", "test_x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "\n", "\n", "# Create target_box and label for spatial sample", "\n", "target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "\n", "sample_scales", "[", "scale_ind", "]", ")", "\n", "\n", "# Update the classifier model", "\n", "self", ".", "update_classifier", "(", "train_x", ",", "target_box", ",", "learning_rate", ",", "s", "[", "scale_ind", ",", "...", "]", ")", "\n", "\n", "# Set the pos of the tracker to iounet pos", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", "and", "flag", "!=", "'not_found'", "and", "hasattr", "(", "self", ",", "'pos_iounet'", ")", ":", "\n", "            ", "self", ".", "pos", "=", "self", ".", "pos_iounet", ".", "clone", "(", ")", "\n", "\n", "# Compute output bounding box", "\n", "", "new_state", "=", "torch", ".", "cat", "(", "(", "self", ".", "pos", "[", "[", "1", ",", "0", "]", "]", "-", "(", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", "-", "1", ")", "/", "2", ",", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", ")", ")", "\n", "\n", "# Update motion state", "\n", "if", "flag", "!=", "'not_found'", ":", "\n", "            ", "box_patch", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", "[", "0", ",", ":", "]", ",", "sample_scales", "[", "0", "]", ")", "\n", "\n", "prev_label", "=", "self", ".", "get_label_function", "(", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "[", "0", "]", "\n", "self", ".", "prev_state_handler", ".", "set_data", "(", "self", ".", "frame_num", ",", "motion_feat", ",", "new_state_vector", ",", "test_patch", ",", "\n", "new_state", ",", "prev_label", ",", "box_patch", ")", "\n", "self", ".", "prev_anno", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ")", "\n", "", "elif", "self", ".", "params", ".", "get", "(", "'reset_state_during_occlusion'", ",", "False", ")", ":", "\n", "            ", "self", ".", "prev_state_handler", ".", "reset_state", "(", ")", "\n", "\n", "", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "scores_dimp", "[", "0", "]", ",", "'heatmap'", ",", "2", ",", "'Dimp'", ")", "\n", "self", ".", "visdom", ".", "register", "(", "self", ".", "debug_info", ",", "'info_dict'", ",", "1", ",", "'Status'", ")", "\n", "self", ".", "visdom", ".", "register", "(", "test_patch", ",", "'image'", ",", "2", ",", "'im current'", ")", "\n", "", "out", "=", "{", "'target_bbox'", ":", "new_state", ".", "tolist", "(", ")", "}", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_sample_location": [[215, 221], ["sample_coord.float.float.float"], "methods", ["None"], ["", "def", "get_sample_location", "(", "self", ",", "sample_coord", ")", ":", "\n", "        ", "\"\"\"Get the location of the extracted sample.\"\"\"", "\n", "sample_coord", "=", "sample_coord", ".", "float", "(", ")", "\n", "sample_pos", "=", "0.5", "*", "(", "sample_coord", "[", ":", ",", ":", "2", "]", "+", "sample_coord", "[", ":", ",", "2", ":", "]", "-", "1", ")", "\n", "sample_scales", "=", "(", "(", "sample_coord", "[", ":", ",", "2", ":", "]", "-", "sample_coord", "[", ":", ",", ":", "2", "]", ")", "/", "self", ".", "img_sample_sz", ")", ".", "prod", "(", "dim", "=", "1", ")", ".", "sqrt", "(", ")", "\n", "return", "sample_pos", ",", "sample_scales", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_centered_sample_pos": [[222, 226], ["None"], "methods", ["None"], ["", "def", "get_centered_sample_pos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the center position for the new sample. Make sure the target is correctly centered.\"\"\"", "\n", "return", "self", ".", "pos", "+", "(", "(", "self", ".", "feature_sz", "+", "self", ".", "kernel_size", ")", "%", "2", ")", "*", "self", ".", "target_scale", "*", "self", ".", "img_support_sz", "/", "(", "2", "*", "self", ".", "feature_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.extract_backbone_features": [[227, 234], ["pytracking.features.preprocessing.sample_patch_multiscale", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "kys.KYS.net.extract_backbone", "kys.KYS.params.get", "kys.KYS.params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_multiscale", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "extract_backbone_features", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ",", "pos", ":", "torch", ".", "Tensor", ",", "scales", ",", "sz", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "im_patches", ",", "patch_coords", "=", "sample_patch_multiscale", "(", "im", ",", "pos", ",", "scales", ",", "sz", ",", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", ",", "\n", "max_scale_change", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ",", "None", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im_patches", ")", "\n", "", "return", "backbone_feat", ",", "patch_coords", ",", "im_patches", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_classification_features": [[235, 238], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "kys.KYS.net.extract_classification_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat"], ["", "def", "get_classification_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "extract_classification_feat", "(", "backbone_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.classify_target": [[239, 245], ["scores[].contiguous", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "kys.KYS.net.classifier.classify"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.classify"], ["", "", "def", "classify_target", "(", "self", ",", "sample_x", ":", "TensorList", ")", ":", "\n", "        ", "\"\"\"Classify target by applying the DiMP filter.\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "scores", "=", "self", ".", "net", ".", "classifier", ".", "classify", "(", "self", ".", "target_filter", ",", "sample_x", ")", "\n", "", "scores", "=", "scores", "[", "...", ",", ":", "-", "1", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_motion_features": [[246, 249], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "kys.KYS.net.get_motion_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.get_motion_feat"], ["", "def", "get_motion_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "get_motion_feat", "(", "backbone_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.init_motion_module": [[250, 270], ["kys.KYS.extract_backbone_features", "kys.KYS.get_sample_location", "im_patches[].int", "kys.KYS.get_motion_features", "sample_pos.view.view.view", "kys.KYS.get_iounet_box", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "kys.KYS.prev_state_handler.set_data", "kys.KYS.get_iounet_box", "kys.KYS.get_centered_sample_pos", "kys.KYS.get_label_function().to", "kys.KYS.get_label_function"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_sample_location", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_motion_features", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.PrevStateHandler.set_data", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_centered_sample_pos", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_label_function"], ["", "", "def", "init_motion_module", "(", "self", ",", "im", ")", ":", "\n", "        ", "backbone_feat", ",", "sample_coords", ",", "im_patches", "=", "self", ".", "extract_backbone_features", "(", "im", ",", "self", ".", "get_centered_sample_pos", "(", ")", ",", "\n", "self", ".", "target_scale", "*", "self", ".", "params", ".", "scale_factors", ",", "\n", "self", ".", "img_sample_sz", ")", "\n", "\n", "# Location of sample", "\n", "sample_pos", ",", "sample_scales", "=", "self", ".", "get_sample_location", "(", "sample_coords", ")", "\n", "test_patch", "=", "im_patches", "[", "0", "]", ".", "int", "(", ")", "\n", "\n", "motion_feat", "=", "self", ".", "get_motion_features", "(", "backbone_feat", ")", "\n", "\n", "sample_pos", "=", "sample_pos", ".", "view", "(", "-", "1", ")", "\n", "prev_label", "=", "self", ".", "get_label_function", "(", "sample_pos", ",", "sample_scales", "[", "0", "]", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "[", "0", "]", "\n", "\n", "box_patch", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", ",", "sample_scales", "[", "0", "]", ")", "\n", "current_bb", "=", "torch", ".", "cat", "(", "(", "self", ".", "pos", "[", "[", "1", ",", "0", "]", "]", "-", "(", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", "-", "1", ")", "/", "2", ",", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", ")", ")", "\n", "\n", "self", ".", "prev_state_handler", ".", "set_data", "(", "0", ",", "motion_feat", ",", "None", ",", "test_patch", ",", "current_bb", ",", "prev_label", ",", "\n", "box_patch", ")", "\n", "self", ".", "prev_anno", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", ",", "sample_scales", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_response_prediction": [[271, 321], ["kys.KYS.get_motion_features", "kys.KYS.prev_state_handler.get_data", "box_patch.to.to.to", "torch.relu", "torch.relu", "torch.relu", "kys.KYS.params.get", "kys.KYS.params.get", "kys.KYS.prev_anno.to", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "kys.KYS.net.predictor.predict_response", "ltr.models.kys.utils.CenterShiftFeatures", "ltr.models.kys.utils.shift_features.clone", "ltr.models.kys.utils.CenterShiftFeatures", "ltr.models.kys.utils.shift_features.clone", "kys.KYS.params.get", "ltr.models.kys.utils.shift_features", "box_c_feat.round", "kys.KYS.output_sz.view().to", "ltr.models.kys.utils.shift_features.clone", "ltr.models.kys.utils.shift_features", "ltr.models.kys.utils.shift_features", "kys.KYS.params.get", "ltr.models.kys.utils.shift_features.clone", "kys.KYS.output_sz.view", "box_c_max.to", "box_c_min.to"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_motion_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.PrevStateHandler.get_data", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.predict_response", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "get_response_prediction", "(", "self", ",", "backbone_feat", ",", "scores_dimp", ")", ":", "\n", "        ", "motion_feat", "=", "self", ".", "get_motion_features", "(", "backbone_feat", ")", "\n", "\n", "prev_motion_feat", ",", "prev_motion_state_vector", ",", "prev_test_patch", ",", "prev_label", ",", "box_patch", "=", "self", ".", "prev_state_handler", ".", "get_data", "(", ")", "\n", "\n", "box_patch", "=", "box_patch", ".", "to", "(", "prev_motion_feat", ".", "device", ")", "\n", "box_c", "=", "box_patch", "[", "0", ":", "2", "]", "+", "0.5", "*", "box_patch", "[", "2", ":", "]", "\n", "\n", "box_c_max", "=", "self", ".", "img_sample_sz", "[", "0", "]", "*", "(", "0.5", "+", "1.0", "/", "self", ".", "params", ".", "search_area_scale", ")", "\n", "box_c_min", "=", "self", ".", "img_sample_sz", "[", "0", "]", "*", "(", "0.5", "-", "1.0", "/", "self", ".", "params", ".", "search_area_scale", ")", "\n", "\n", "if", "prev_motion_state_vector", "is", "not", "None", "and", "self", ".", "params", ".", "get", "(", "'move_feat_to_center'", ",", "False", ")", "and", "not", "(", "(", "box_c", "<", "box_c_max", ".", "to", "(", "box_c", ".", "device", ")", ")", "*", "(", "box_c", ">", "box_c_min", ".", "to", "(", "box_c", ".", "device", ")", ")", ")", ".", "all", "(", ")", ":", "\n", "# In case the target was not near the center in the prev. frame, shift the feature map so that the target", "\n", "# is in the center.", "\n", "            ", "prev_motion_feat", "=", "CenterShiftFeatures", "(", "feature_stride", "=", "16", ")", "(", "prev_motion_feat", ".", "clone", "(", ")", ",", "box_patch", ")", "\n", "prev_motion_state_vector", "=", "CenterShiftFeatures", "(", "feature_stride", "=", "16", ")", "(", "prev_motion_state_vector", ".", "clone", "(", ")", ",", "box_patch", ")", "\n", "", "elif", "self", ".", "params", ".", "get", "(", "'prev_feat_remove_subpixel_shift'", ",", "False", ")", "and", "prev_motion_state_vector", "is", "not", "None", ":", "\n", "            ", "box_c_feat", "=", "box_c", "/", "16.0", "\n", "box_c_feat_round", "=", "box_c_feat", ".", "round", "(", ")", "+", "0.5", "*", "self", ".", "net", ".", "predictor", ".", "fix_coordinate_shift", "\n", "feat_trans", "=", "(", "box_c_feat_round", "-", "box_c_feat", ")", ".", "view", "(", "-", "1", ",", "2", ")", "/", "self", ".", "output_sz", ".", "view", "(", "-", "1", ",", "2", ")", ".", "to", "(", "box_c_feat", ".", "device", ")", "\n", "\n", "prev_motion_feat", "=", "shift_features", "(", "prev_motion_feat", ".", "clone", "(", ")", ",", "feat_trans", ")", "\n", "\n", "if", "prev_motion_state_vector", "is", "not", "None", ":", "\n", "                ", "prev_motion_state_vector", "=", "shift_features", "(", "prev_motion_state_vector", ".", "clone", "(", ")", ",", "feat_trans", ")", "\n", "", "else", ":", "\n", "                ", "prev_label", "=", "shift_features", "(", "prev_label", ",", "feat_trans", ")", "\n", "\n", "", "", "if", "self", ".", "output_window", "is", "not", "None", "and", "self", ".", "params", ".", "get", "(", "'apply_window_to_dimp_score'", ",", "True", ")", ":", "\n", "            ", "scores_dimp_win", "=", "scores_dimp", "*", "self", ".", "output_window", "\n", "", "else", ":", "\n", "            ", "scores_dimp_win", "=", "scores_dimp", "\n", "\n", "", "predictor_input", "=", "{", "'dimp_score_cur'", ":", "scores_dimp_win", ",", "\n", "'label_prev'", ":", "prev_label", ",", "\n", "'feat1'", ":", "prev_motion_feat", ",", "'feat2'", ":", "motion_feat", ",", "\n", "'anno_prev'", ":", "self", ".", "prev_anno", ".", "to", "(", "self", ".", "params", ".", "device", ")", ",", "\n", "'state_prev'", ":", "prev_motion_state_vector", "}", "\n", "\n", "window_fn", "=", "self", ".", "output_window", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "resp_output", "=", "self", ".", "net", ".", "predictor", ".", "predict_response", "(", "predictor_input", ",", "dimp_thresh", "=", "self", ".", "params", ".", "get", "(", "'dimp_threshold'", ",", "None", ")", ",", "\n", "output_window", "=", "window_fn", ")", "\n", "\n", "", "scores_am", "=", "F", ".", "relu", "(", "resp_output", "[", "'response'", "]", ")", "\n", "new_state_vector", "=", "resp_output", "[", "'state_cur'", "]", "\n", "\n", "return", "scores_am", ",", "motion_feat", ",", "new_state_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.localize_target": [[322, 356], ["score_dimp.max().item", "score_fused.view().argmax", "[].item", "kys.KYS.compute_target_location", "kys.KYS.params.get", "kys.KYS.perform_hn_mining_dimp", "score_dimp.max", "score_fused.view", "score_dimp_win.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.compute_target_location", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.perform_hn_mining_dimp"], ["", "def", "localize_target", "(", "self", ",", "score_fused", ",", "score_dimp", ",", "sample_scales", ")", ":", "\n", "        ", "\"\"\"Run the target localization.\"\"\"", "\n", "if", "score_fused", "is", "not", "None", ":", "\n", "            ", "score_fused", "=", "score_fused", "[", "0", "]", "\n", "", "score_dimp", "=", "score_dimp", "[", "0", "]", "\n", "\n", "# Apply window function", "\n", "if", "self", ".", "output_window", "is", "not", "None", "and", "score_fused", "is", "not", "None", ":", "\n", "            ", "score_dimp_win", "=", "score_dimp", "*", "self", ".", "output_window", "\n", "", "else", ":", "\n", "            ", "score_dimp_win", "=", "score_dimp", "\n", "\n", "", "max_dimp_score", "=", "score_dimp", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "max_id", "=", "score_fused", ".", "view", "(", "-", "1", ")", ".", "argmax", "(", ")", "\n", "\n", "dimp_score_at_loc", "=", "score_dimp_win", ".", "view", "(", "-", "1", ")", "[", "max_id", "]", ".", "item", "(", ")", "\n", "self", ".", "debug_info", "[", "'dimp_score_at_loc'", "]", "=", "dimp_score_at_loc", "\n", "self", ".", "debug_info", "[", "'max_dimp_score'", "]", "=", "max_dimp_score", "\n", "\n", "loc_params", "=", "{", "'target_not_found_threshold'", ":", "self", ".", "params", ".", "target_not_found_threshold_fused", "}", "\n", "\n", "translation_vec", ",", "scale_ind", ",", "scores", ",", "max_dimp_score", ",", "flag", ",", "max_disp1", "=", "self", ".", "compute_target_location", "(", "\n", "score_fused", ",", "loc_params", ",", "sample_scales", ",", "score_dimp_win", ")", "\n", "\n", "self", ".", "debug_info", "[", "'fused_score'", "]", "=", "max_dimp_score", "\n", "self", ".", "debug_info", "[", "'fused_flag'", "]", "=", "flag", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'perform_hn_mining_dimp'", ",", "False", ")", "and", "flag", "!=", "'not_found'", ":", "\n", "            ", "hn_flag", "=", "self", ".", "perform_hn_mining_dimp", "(", "score_dimp", ",", "max_disp1", ",", "sample_scales", ")", "\n", "\n", "if", "hn_flag", ":", "\n", "                ", "flag", "=", "'hard_negative'", "\n", "\n", "", "", "return", "translation_vec", ",", "scale_ind", ",", "scores", ",", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.compute_target_location": [[357, 382], ["pytracking.dcf.max2d", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "max_disp1[].float().cpu().view", "pytracking.dcf.max2d", "max_disp1_dimp[].float().cpu().view", "kys.KYS.params.get", "max_score1.item", "max_disp1[].float().cpu", "max_score1.item", "max_score1.item", "max_disp1_dimp[].float().cpu", "max_disp1[].float", "max_disp1_dimp[].float"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "compute_target_location", "(", "self", ",", "scores", ",", "loc_params", ",", "sample_scales", ",", "scores_dimp", "=", "None", ")", ":", "\n", "        ", "sample_scale", "=", "sample_scales", "[", "0", "]", "\n", "\n", "max_score1", ",", "max_disp1", "=", "dcf", ".", "max2d", "(", "scores", ")", "\n", "_", ",", "scale_ind", "=", "torch", ".", "max", "(", "max_score1", ",", "dim", "=", "0", ")", "\n", "max_score1", "=", "max_score1", "[", "scale_ind", "]", "\n", "max_disp1", "=", "max_disp1", "[", "scale_ind", ",", "...", "]", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "if", "scores_dimp", "is", "not", "None", ":", "\n", "            ", "max_score1_dimp", ",", "max_disp1_dimp", "=", "dcf", ".", "max2d", "(", "scores_dimp", ")", "\n", "max_disp1_dimp", "=", "max_disp1_dimp", "[", "scale_ind", ",", "...", "]", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "# In case dimp score peak and fused score peak only have a small offset between them, go with dimp peak to", "\n", "# avoid drift due to state propagation", "\n", "if", "self", ".", "params", ".", "get", "(", "'remove_offset_in_fused_score'", ",", "False", ")", ":", "\n", "                ", "if", "(", "max_disp1", "-", "max_disp1_dimp", ")", ".", "abs", "(", ")", ".", "max", "(", ")", "==", "1", ":", "\n", "                    ", "max_disp1", "=", "max_disp1_dimp", "\n", "\n", "", "", "", "target_disp1", "=", "max_disp1", "-", "self", ".", "output_sz", "//", "2", "\n", "translation_vec1", "=", "target_disp1", "*", "(", "self", ".", "img_support_sz", "/", "self", ".", "output_sz", ")", "*", "sample_scale", "\n", "\n", "if", "max_score1", ".", "item", "(", ")", "<", "loc_params", "[", "'target_not_found_threshold'", "]", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores", ",", "max_score1", ".", "item", "(", ")", ",", "'not_found'", ",", "max_disp1", "\n", "", "else", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores", ",", "max_score1", ".", "item", "(", ")", ",", "'normal'", ",", "max_disp1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.perform_hn_mining_dimp": [[383, 409], ["max", "min", "max", "min", "score_dimp[].clone", "pytracking.dcf.max2d", "round", "round", "round", "round", "max_disp1[].long", "max_disp1[].long", "kys.KYS.target_sz.prod().sqrt().repeat", "max_disp1[].item", "max_disp1[].item", "target_neigh_sz[].item", "max_disp1[].item", "target_neigh_sz[].item", "max_disp1[].item", "kys.KYS.target_sz.prod().sqrt", "target_neigh_sz[].item", "target_neigh_sz[].item", "kys.KYS.target_sz.prod"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d"], ["", "", "def", "perform_hn_mining_dimp", "(", "self", ",", "score_dimp", ",", "max_disp1", ",", "sample_scales", ")", ":", "\n", "# Compute hard negatives using the dimp score", "\n", "        ", "sample_scale", "=", "sample_scales", "[", "0", "]", "\n", "sz", "=", "score_dimp", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "max_score1", "=", "score_dimp", "[", "0", ",", "max_disp1", "[", "0", "]", ".", "long", "(", ")", ",", "max_disp1", "[", "1", "]", ".", "long", "(", ")", "]", "\n", "\n", "target_neigh_sz", "=", "self", ".", "params", ".", "target_neighborhood_scale_safe", "*", "(", "\n", "self", ".", "target_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", ".", "repeat", "(", "2", ")", "/", "sample_scale", ")", "*", "(", "\n", "self", ".", "output_sz", "/", "self", ".", "img_support_sz", ")", "\n", "\n", "tneigh_top", "=", "max", "(", "round", "(", "max_disp1", "[", "0", "]", ".", "item", "(", ")", "-", "target_neigh_sz", "[", "0", "]", ".", "item", "(", ")", "/", "2", ")", ",", "0", ")", "\n", "tneigh_bottom", "=", "min", "(", "round", "(", "max_disp1", "[", "0", "]", ".", "item", "(", ")", "+", "target_neigh_sz", "[", "0", "]", ".", "item", "(", ")", "/", "2", "+", "1", ")", ",", "sz", "[", "0", "]", ")", "\n", "tneigh_left", "=", "max", "(", "round", "(", "max_disp1", "[", "1", "]", ".", "item", "(", ")", "-", "target_neigh_sz", "[", "1", "]", ".", "item", "(", ")", "/", "2", ")", ",", "0", ")", "\n", "tneigh_right", "=", "min", "(", "round", "(", "max_disp1", "[", "1", "]", ".", "item", "(", ")", "+", "target_neigh_sz", "[", "1", "]", ".", "item", "(", ")", "/", "2", "+", "1", ")", ",", "sz", "[", "1", "]", ")", "\n", "\n", "scale_ind", "=", "0", "\n", "scores_masked", "=", "score_dimp", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", ".", "clone", "(", ")", "\n", "scores_masked", "[", "...", ",", "tneigh_top", ":", "tneigh_bottom", ",", "tneigh_left", ":", "tneigh_right", "]", "=", "0", "\n", "\n", "# Find new maximum", "\n", "max_score2", ",", "max_disp2", "=", "dcf", ".", "max2d", "(", "scores_masked", ")", "\n", "\n", "if", "max_score2", ">", "self", ".", "params", ".", "hard_negative_threshold", "*", "max_score1", "and", "max_score2", ">", "0.1", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_label_function": [[410, 422], ["pytracking.TensorList", "pytracking.TensorList.append", "pytracking.dcf.label_function_spatial"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.label_function_spatial"], ["", "def", "get_label_function", "(", "self", ",", "sample_pos", ",", "sample_scale", ",", "output_sz", "=", "None", ")", ":", "\n", "        ", "train_y", "=", "TensorList", "(", ")", "\n", "target_center_norm", "=", "(", "self", ".", "pos", "-", "sample_pos", ")", "/", "(", "sample_scale", "*", "self", ".", "img_support_sz", ")", "\n", "\n", "if", "output_sz", "is", "None", ":", "\n", "            ", "output_sz", "=", "self", ".", "label_sz", "\n", "\n", "", "ksz_even", "=", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "center", "=", "output_sz", "*", "target_center_norm", "+", "0.5", "*", "ksz_even", "\n", "\n", "train_y", ".", "append", "(", "dcf", ".", "label_function_spatial", "(", "output_sz", ",", "self", ".", "sigma", ",", "center", ")", ")", "\n", "return", "train_y", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_iou_backbone_features": [[423, 425], ["kys.KYS.net.get_backbone_bbreg_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.get_backbone_bbreg_feat"], ["", "def", "get_iou_backbone_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "return", "self", ".", "net", ".", "get_backbone_bbreg_feat", "(", "backbone_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_iou_features": [[426, 429], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "kys.KYS.net.bb_regressor.get_iou_feat", "kys.KYS.get_iou_backbone_features"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_iou_feat", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_backbone_features"], ["", "def", "get_iou_features", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "bb_regressor", ".", "get_iou_feat", "(", "self", ".", "get_iou_backbone_features", "(", "backbone_feat", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_iou_modulation": [[430, 433], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "kys.KYS.net.bb_regressor.get_modulation"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_modulation"], ["", "", "def", "get_iou_modulation", "(", "self", ",", "iou_backbone_feat", ",", "target_boxes", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "bb_regressor", ".", "get_modulation", "(", "iou_backbone_feat", ",", "target_boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.generate_init_samples": [[434, 503], ["kys.KYS.params.get", "kys.KYS.pos.round", "kys.KYS.params.get", "kys.KYS.img_sample_sz.clone", "kys.KYS.params.get", "pytracking.features.preprocessing.sample_patch_transformed", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "shrink_factor.min.min.clamp_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "aug_expansion_sz.float.float.float", "kys.KYS.img_sample_sz.long().tolist", "pytracking.features.augmentation.Identity", "kys.KYS.params.get", "kys.KYS.transforms.extend", "kys.KYS.transforms.extend", "kys.KYS.transforms.append", "kys.KYS.transforms.extend", "kys.KYS.transforms.extend", "kys.KYS.transforms.extend", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "kys.KYS.net.extract_backbone", "sample_sz.float", "shrink_factor.min.min.max", "sample_sz.float", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "pytracking.features.augmentation.FlipHorizontal", "shrink_factor.min.min.min", "kys.KYS.params.get", "kys.KYS.img_sample_sz.long", "kys.KYS.img_sample_sz.long", "pytracking.features.augmentation.Translation", "pytracking.features.augmentation.Translation", "get_rand_shift", "pytracking.features.augmentation.Blur", "pytracking.features.augmentation.Scale", "pytracking.features.augmentation.Rotate", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "get_absolute", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "get_rand_shift", "get_rand_shift", "get_rand_shift", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_transformed", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "", "def", "generate_init_samples", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Perform data augmentation to generate initial training samples.\"\"\"", "\n", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", "\n", "if", "mode", "==", "'inside'", ":", "\n", "# Get new sample size if forced inside the image", "\n", "            ", "im_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "sample_sz", "=", "self", ".", "target_scale", "*", "self", ".", "img_sample_sz", "\n", "shrink_factor", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "im_sz", ")", "\n", "if", "mode", "==", "'inside'", ":", "\n", "                ", "shrink_factor", "=", "shrink_factor", ".", "max", "(", ")", "\n", "", "elif", "mode", "==", "'inside_major'", ":", "\n", "                ", "shrink_factor", "=", "shrink_factor", ".", "min", "(", ")", "\n", "", "shrink_factor", ".", "clamp_", "(", "min", "=", "1", ",", "max", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ",", "None", ")", ")", "\n", "sample_sz", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "shrink_factor", ")", "\n", "self", ".", "init_sample_scale", "=", "(", "sample_sz", "/", "self", ".", "img_sample_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "tl", "=", "self", ".", "pos", "-", "(", "sample_sz", "-", "1", ")", "/", "2", "\n", "br", "=", "self", ".", "pos", "+", "sample_sz", "/", "2", "+", "1", "\n", "global_shift", "=", "-", "(", "(", "-", "tl", ")", ".", "clamp", "(", "0", ")", "-", "(", "br", "-", "im_sz", ")", ".", "clamp", "(", "0", ")", ")", "/", "self", ".", "init_sample_scale", "\n", "", "else", ":", "\n", "            ", "self", ".", "init_sample_scale", "=", "self", ".", "target_scale", "\n", "global_shift", "=", "torch", ".", "zeros", "(", "2", ")", "\n", "\n", "", "self", ".", "init_sample_pos", "=", "self", ".", "pos", ".", "round", "(", ")", "\n", "\n", "# Compute augmentation size", "\n", "aug_expansion_factor", "=", "self", ".", "params", ".", "get", "(", "'augmentation_expansion_factor'", ",", "None", ")", "\n", "aug_expansion_sz", "=", "self", ".", "img_sample_sz", ".", "clone", "(", ")", "\n", "aug_output_sz", "=", "None", "\n", "if", "aug_expansion_factor", "is", "not", "None", "and", "aug_expansion_factor", "!=", "1", ":", "\n", "            ", "aug_expansion_sz", "=", "(", "self", ".", "img_sample_sz", "*", "aug_expansion_factor", ")", ".", "long", "(", ")", "\n", "aug_expansion_sz", "+=", "(", "aug_expansion_sz", "-", "self", ".", "img_sample_sz", ".", "long", "(", ")", ")", "%", "2", "\n", "aug_expansion_sz", "=", "aug_expansion_sz", ".", "float", "(", ")", "\n", "aug_output_sz", "=", "self", ".", "img_sample_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Random shift for each sample", "\n", "", "get_rand_shift", "=", "lambda", ":", "None", "\n", "random_shift_factor", "=", "self", ".", "params", ".", "get", "(", "'random_shift_factor'", ",", "0", ")", "\n", "if", "random_shift_factor", ">", "0", ":", "\n", "            ", "get_rand_shift", "=", "lambda", ":", "(", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "*", "self", ".", "img_sample_sz", "*", "random_shift_factor", "+", "global_shift", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Always put identity transformation first, since it is the unaugmented sample that is always used", "\n", "", "self", ".", "transforms", "=", "[", "augmentation", ".", "Identity", "(", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "]", "\n", "\n", "augs", "=", "self", ".", "params", ".", "augmentation", "if", "self", ".", "params", ".", "get", "(", "'use_augmentation'", ",", "True", ")", "else", "{", "}", "\n", "\n", "# Add all augmentations", "\n", "if", "'shift'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "shift", ",", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "for", "shift", "in", "augs", "[", "'shift'", "]", "]", ")", "\n", "", "if", "'relativeshift'", "in", "augs", ":", "\n", "            ", "get_absolute", "=", "lambda", "shift", ":", "(", "torch", ".", "Tensor", "(", "shift", ")", "*", "self", ".", "img_sample_sz", "/", "2", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "get_absolute", "(", "shift", ")", ",", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "for", "shift", "in", "augs", "[", "'relativeshift'", "]", "]", ")", "\n", "", "if", "'fliplr'", "in", "augs", "and", "augs", "[", "'fliplr'", "]", ":", "\n", "            ", "self", ".", "transforms", ".", "append", "(", "augmentation", ".", "FlipHorizontal", "(", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", ")", "\n", "", "if", "'blur'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Blur", "(", "sigma", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "sigma", "in", "augs", "[", "'blur'", "]", "]", ")", "\n", "", "if", "'scale'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Scale", "(", "scale_factor", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "scale_factor", "in", "augs", "[", "'scale'", "]", "]", ")", "\n", "", "if", "'rotate'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Rotate", "(", "angle", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "angle", "in", "augs", "[", "'rotate'", "]", "]", ")", "\n", "\n", "# Extract augmented image patches", "\n", "", "im_patches", "=", "sample_patch_transformed", "(", "im", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ",", "aug_expansion_sz", ",", "self", ".", "transforms", ")", "\n", "\n", "# Extract initial backbone features", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "init_backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im_patches", ")", "\n", "\n", "", "return", "init_backbone_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.init_target_boxes": [[504, 514], ["kys.KYS.get_iounet_box", "pytracking.TensorList", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to.new_zeros", "torch.cat().to.new_zeros", "torch.cat().to.new_zeros", "torch.cat().to.append", "torch.cat().to.append", "torch.cat().to.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat().to.view", "torch.cat().to.view", "torch.cat().to.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "init_target_boxes", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the target bounding boxes for the initial augmented samples.\"\"\"", "\n", "self", ".", "classifier_target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ")", "\n", "init_target_boxes", "=", "TensorList", "(", ")", "\n", "for", "T", "in", "self", ".", "transforms", ":", "\n", "            ", "init_target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "T", ".", "shift", "[", "1", "]", ",", "T", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "init_target_boxes", "=", "torch", ".", "cat", "(", "init_target_boxes", ".", "view", "(", "1", ",", "4", ")", ",", "0", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "self", ".", "target_boxes", "=", "init_target_boxes", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "4", ")", "\n", "self", ".", "target_boxes", "[", ":", "init_target_boxes", ".", "shape", "[", "0", "]", ",", ":", "]", "=", "init_target_boxes", "\n", "return", "init_target_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.init_memory": [[515, 533], ["train_x.size", "pytracking.TensorList", "kys.KYS.num_init_samples.copy", "pytracking.TensorList", "zip", "pytracking.TensorList", "zip", "len", "x.new_zeros", "x.new_zeros", "x.new_ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "def", "init_memory", "(", "self", ",", "train_x", ":", "TensorList", ")", ":", "\n", "# Initialize first-frame spatial training samples", "\n", "        ", "self", ".", "num_init_samples", "=", "train_x", ".", "size", "(", "0", ")", "\n", "init_sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_ones", "(", "1", ")", "/", "x", ".", "shape", "[", "0", "]", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "# Sample counters and weights for spatial", "\n", "self", ".", "num_stored_samples", "=", "self", ".", "num_init_samples", ".", "copy", "(", ")", "\n", "self", ".", "previous_replace_ind", "=", "[", "None", "]", "*", "len", "(", "self", ".", "num_stored_samples", ")", "\n", "self", ".", "sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ")", "for", "x", "in", "train_x", "]", ")", "\n", "for", "sw", ",", "init_sw", ",", "num", "in", "zip", "(", "self", ".", "sample_weights", ",", "init_sample_weights", ",", "self", ".", "num_init_samples", ")", ":", "\n", "            ", "sw", "[", ":", "num", "]", "=", "init_sw", "\n", "\n", "# Initialize memory", "\n", "", "self", ".", "training_samples", "=", "TensorList", "(", "\n", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "for", "ts", ",", "x", "in", "zip", "(", "self", ".", "training_samples", ",", "train_x", ")", ":", "\n", "            ", "ts", "[", ":", "x", ".", "shape", "[", "0", "]", ",", "...", "]", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.update_memory": [[534, 547], ["kys.KYS.update_sample_weights", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_sample_weights"], ["", "", "def", "update_memory", "(", "self", ",", "sample_x", ":", "TensorList", ",", "target_box", ",", "learning_rate", "=", "None", ")", ":", "\n", "# Update weights and get replace ind", "\n", "        ", "replace_ind", "=", "self", ".", "update_sample_weights", "(", "self", ".", "sample_weights", ",", "self", ".", "previous_replace_ind", ",", "self", ".", "num_stored_samples", ",", "self", ".", "num_init_samples", ",", "learning_rate", ")", "\n", "self", ".", "previous_replace_ind", "=", "replace_ind", "\n", "\n", "# Update sample and label memory", "\n", "for", "train_samp", ",", "x", ",", "ind", "in", "zip", "(", "self", ".", "training_samples", ",", "sample_x", ",", "replace_ind", ")", ":", "\n", "            ", "train_samp", "[", "ind", ":", "ind", "+", "1", ",", "...", "]", "=", "x", "\n", "\n", "# Update bb memory", "\n", "", "self", ".", "target_boxes", "[", "replace_ind", "[", "0", "]", ",", ":", "]", "=", "target_box", "\n", "\n", "self", ".", "num_stored_samples", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.update_sample_weights": [[548, 588], ["zip", "kys.KYS.params.get", "sw.sum", "replace_ind.append", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "sw[].sum", "sw[].sum", "r_ind.item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "update_sample_weights", "(", "self", ",", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ",", "learning_rate", "=", "None", ")", ":", "\n", "# Update weights and get index to replace", "\n", "        ", "replace_ind", "=", "[", "]", "\n", "for", "sw", ",", "prev_ind", ",", "num_samp", ",", "num_init", "in", "zip", "(", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ")", ":", "\n", "            ", "lr", "=", "learning_rate", "\n", "if", "lr", "is", "None", ":", "\n", "                ", "lr", "=", "self", ".", "params", ".", "learning_rate", "\n", "\n", "", "init_samp_weight", "=", "self", ".", "params", ".", "get", "(", "'init_samples_minimum_weight'", ",", "None", ")", "\n", "if", "init_samp_weight", "==", "0", ":", "\n", "                ", "init_samp_weight", "=", "None", "\n", "", "s_ind", "=", "0", "if", "init_samp_weight", "is", "None", "else", "num_init", "\n", "\n", "if", "num_samp", "==", "0", "or", "lr", "==", "1", ":", "\n", "                ", "sw", "[", ":", "]", "=", "0", "\n", "sw", "[", "0", "]", "=", "1", "\n", "r_ind", "=", "0", "\n", "", "else", ":", "\n", "# Get index to replace", "\n", "                ", "if", "num_samp", "<", "sw", ".", "shape", "[", "0", "]", ":", "\n", "                    ", "r_ind", "=", "num_samp", "\n", "", "else", ":", "\n", "                    ", "_", ",", "r_ind", "=", "torch", ".", "min", "(", "sw", "[", "s_ind", ":", "]", ",", "0", ")", "\n", "r_ind", "=", "r_ind", ".", "item", "(", ")", "+", "s_ind", "\n", "\n", "# Update weights", "\n", "", "if", "prev_ind", "is", "None", ":", "\n", "                    ", "sw", "/=", "1", "-", "lr", "\n", "sw", "[", "r_ind", "]", "=", "lr", "\n", "", "else", ":", "\n", "                    ", "sw", "[", "r_ind", "]", "=", "sw", "[", "prev_ind", "]", "/", "(", "1", "-", "lr", ")", "\n", "\n", "", "", "sw", "/=", "sw", ".", "sum", "(", ")", "\n", "if", "init_samp_weight", "is", "not", "None", "and", "sw", "[", ":", "num_init", "]", ".", "sum", "(", ")", "<", "init_samp_weight", ":", "\n", "                ", "sw", "/=", "init_samp_weight", "+", "sw", "[", "num_init", ":", "]", ".", "sum", "(", ")", "\n", "sw", "[", ":", "num_init", "]", "=", "init_samp_weight", "/", "num_init", "\n", "\n", "", "replace_ind", ".", "append", "(", "r_ind", ")", "\n", "\n", "", "return", "replace_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.update_state": [[589, 599], ["kys.KYS.params.get", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "new_scale.clamp", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "update_state", "(", "self", ",", "new_pos", ",", "new_scale", "=", "None", ")", ":", "\n", "# Update scale", "\n", "        ", "if", "new_scale", "is", "not", "None", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", ".", "clamp", "(", "self", ".", "min_scale_factor", ",", "self", ".", "max_scale_factor", ")", "\n", "self", ".", "target_sz", "=", "self", ".", "base_target_sz", "*", "self", ".", "target_scale", "\n", "\n", "# Update pos", "\n", "", "inside_ratio", "=", "self", ".", "params", ".", "get", "(", "'target_inside_ratio'", ",", "0.2", ")", "\n", "inside_offset", "=", "(", "inside_ratio", "-", "0.5", ")", "*", "self", ".", "target_sz", "\n", "self", ".", "pos", "=", "torch", ".", "max", "(", "torch", ".", "min", "(", "new_pos", ",", "self", ".", "image_sz", "-", "inside_offset", ")", ",", "inside_offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_iounet_box": [[600, 607], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "target_ul.flip", "box_sz.flip"], "methods", ["None"], ["", "def", "get_iounet_box", "(", "self", ",", "pos", ",", "sz", ",", "sample_pos", ",", "sample_scale", ")", ":", "\n", "        ", "\"\"\"All inputs in original image coordinates.\n        Generates a box in the cropped image sample reference frame, in the format used by the IoUNet.\"\"\"", "\n", "box_center", "=", "(", "pos", "-", "sample_pos", ")", "/", "sample_scale", "+", "(", "self", ".", "img_sample_sz", "-", "1", ")", "/", "2", "\n", "box_sz", "=", "sz", "/", "sample_scale", "\n", "target_ul", "=", "box_center", "-", "(", "box_sz", "-", "1", ")", "/", "2", "\n", "return", "torch", ".", "cat", "(", "[", "target_ul", ".", "flip", "(", "(", "0", ",", ")", ")", ",", "box_sz", ".", "flip", "(", "(", "0", ",", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.init_iou_net": [[608, 634], ["kys.KYS.net.bb_regressor.parameters", "kys.KYS.get_iounet_box", "pytracking.TensorList", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "kys.KYS.get_iou_backbone_features", "pytracking.TensorList", "kys.KYS.get_iou_modulation", "pytracking.TensorList", "torch.cat().to.append", "torch.cat().to.append", "torch.cat().to.append", "torch.cat().to.append", "torch.cat().to.append", "torch.cat().to.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.detach().mean", "isinstance", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat().to.view", "torch.cat().to.view", "torch.cat().to.view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "x.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_iou_modulation", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "init_iou_net", "(", "self", ",", "backbone_feat", ")", ":", "\n", "# Setup IoU net and objective", "\n", "        ", "for", "p", "in", "self", ".", "net", ".", "bb_regressor", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "# Get target boxes for the different augmentations", "\n", "", "self", ".", "classifier_target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ")", "\n", "target_boxes", "=", "TensorList", "(", ")", "\n", "if", "self", ".", "params", ".", "iounet_augmentation", ":", "\n", "            ", "for", "T", "in", "self", ".", "transforms", ":", "\n", "                ", "if", "not", "isinstance", "(", "T", ",", "(", "augmentation", ".", "Identity", ",", "augmentation", ".", "Translation", ",", "augmentation", ".", "FlipHorizontal", ",", "augmentation", ".", "FlipVertical", ",", "augmentation", ".", "Blur", ")", ")", ":", "\n", "                    ", "break", "\n", "", "target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "T", ".", "shift", "[", "1", "]", ",", "T", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "self", ".", "transforms", "[", "0", "]", ".", "shift", "[", "1", "]", ",", "self", ".", "transforms", "[", "0", "]", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "target_boxes", "=", "torch", ".", "cat", "(", "target_boxes", ".", "view", "(", "1", ",", "4", ")", ",", "0", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "# Get iou features", "\n", "iou_backbone_feat", "=", "self", ".", "get_iou_backbone_features", "(", "backbone_feat", ")", "\n", "\n", "# Remove other augmentations such as rotation", "\n", "iou_backbone_feat", "=", "TensorList", "(", "[", "x", "[", ":", "target_boxes", ".", "shape", "[", "0", "]", ",", "...", "]", "for", "x", "in", "iou_backbone_feat", "]", ")", "\n", "\n", "# Get modulation vector", "\n", "self", ".", "iou_modulation", "=", "self", ".", "get_iou_modulation", "(", "iou_backbone_feat", ",", "target_boxes", ")", "\n", "self", ".", "iou_modulation", "=", "TensorList", "(", "[", "x", ".", "detach", "(", ")", ".", "mean", "(", "0", ")", "for", "x", "in", "self", ".", "iou_modulation", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.init_classifier": [[635, 710], ["kys.KYS.get_classification_features", "hasattr", "kys.KYS.params.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "kys.KYS.params.get", "kys.KYS.init_target_boxes", "kys.KYS.params.get", "kys.KYS.params.get", "getattr", "hasattr", "kys.KYS.params.get", "kys.KYS.params.get", "kys.KYS.params.get", "kys.KYS.params.get", "ltr.models.target_classifier.initializer.FilterInitializerZero", "kys.KYS.params.get", "kys.KYS.transforms.extend", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "list", "kys.KYS.params.get", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "kys.KYS.net.classifier.get_filter", "kys.KYS.init_memory", "isinstance", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "getattr", "isinstance", "pytracking.dcf.hann2d_clipped().to", "pytracking.dcf.hann2d().to", "kys.KYS.output_window.squeeze", "kys.KYS.params.get", "pytracking.TensorList", "kys.KYS.visdom.register", "torch.dropout2d", "torch.dropout2d", "torch.dropout2d", "pytracking.utils.plotting.plot_graph", "x[].expand", "pytracking.dcf.hann2d_clipped", "pytracking.dcf.hann2d", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "score_map_sz.long", "score_map_sz.long", "kys.KYS.losses.numel", "kys.KYS.params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.get_classification_features", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_target_boxes", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.get_filter", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_memory", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d_clipped", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "init_classifier", "(", "self", ",", "init_backbone_feat", ")", ":", "\n", "# Get classification features", "\n", "        ", "x", "=", "self", ".", "get_classification_features", "(", "init_backbone_feat", ")", "\n", "\n", "# Set regularization weight and initializer", "\n", "if", "hasattr", "(", "self", ".", "net", ",", "'classifier'", ")", ":", "\n", "            ", "pred_module", "=", "getattr", "(", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ",", "'score_predictor'", ",", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ")", "\n", "", "elif", "hasattr", "(", "self", ".", "net", ",", "'dimp_classifier'", ")", ":", "\n", "            ", "self", ".", "net", ".", "classifier", "=", "self", ".", "net", ".", "dimp_classifier", "\n", "pred_module", "=", "getattr", "(", "self", ".", "net", ".", "dimp_classifier", ".", "filter_optimizer", ",", "'score_predictor'", ",", "\n", "self", ".", "net", ".", "dimp_classifier", ".", "filter_optimizer", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'label_threshold'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ".", "label_threshold", "=", "self", ".", "params", ".", "label_threshold", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'label_shrink'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ".", "label_shrink", "=", "self", ".", "params", ".", "label_shrink", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'softmax_reg'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ".", "softmax_reg", "=", "self", ".", "params", ".", "softmax_reg", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'filter_reg'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "pred_module", ".", "filter_reg", "[", "0", "]", "=", "self", ".", "params", ".", "filter_reg", "\n", "pred_module", ".", "min_filter_reg", "=", "self", ".", "params", ".", "filter_reg", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'filter_init_zero'", ",", "False", ")", ":", "\n", "            ", "self", ".", "net", ".", "classifier", ".", "filter_initializer", "=", "FilterInitializerZero", "(", "self", ".", "net", ".", "classifier", ".", "filter_size", ",", "x", ".", "shape", "[", "-", "3", "]", ")", "\n", "\n", "# Add the dropout augmentation here, since it requires extraction of the classification features", "\n", "", "if", "'dropout'", "in", "self", ".", "params", ".", "augmentation", "and", "self", ".", "params", ".", "get", "(", "'use_augmentation'", ",", "True", ")", ":", "\n", "            ", "num", ",", "prob", "=", "self", ".", "params", ".", "augmentation", "[", "'dropout'", "]", "\n", "self", ".", "transforms", ".", "extend", "(", "self", ".", "transforms", "[", ":", "1", "]", "*", "num", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "F", ".", "dropout2d", "(", "x", "[", "0", ":", "1", ",", "...", "]", ".", "expand", "(", "num", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", ",", "p", "=", "prob", ",", "training", "=", "True", ")", "]", ")", "\n", "\n", "# Set feature size and other related sizes", "\n", "", "self", ".", "feature_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "x", ".", "shape", "[", "-", "2", ":", "]", ")", ")", "\n", "ksz", "=", "self", ".", "net", ".", "classifier", ".", "filter_size", "\n", "self", ".", "kernel_size", "=", "torch", ".", "Tensor", "(", "[", "ksz", ",", "ksz", "]", "if", "isinstance", "(", "ksz", ",", "(", "int", ",", "float", ")", ")", "else", "ksz", ")", "\n", "self", ".", "output_sz", "=", "self", ".", "feature_sz", "#+ (self.kernel_size + 1)%2", "\n", "\n", "# Construct output window", "\n", "self", ".", "output_window", "=", "None", "\n", "if", "self", ".", "params", ".", "get", "(", "'window_output'", ",", "False", ")", ":", "\n", "            ", "score_map_sz", "=", "self", ".", "feature_sz", "+", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_clipped_window'", ",", "False", ")", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d_clipped", "(", "score_map_sz", ".", "long", "(", ")", ",", "(", "score_map_sz", "*", "self", ".", "params", ".", "effective_search_area", "/", "self", ".", "params", ".", "search_area_scale", ")", ".", "long", "(", ")", ",", "centered", "=", "True", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d", "(", "score_map_sz", ".", "long", "(", ")", ",", "centered", "=", "True", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "", "self", ".", "output_window", "=", "self", ".", "output_window", ".", "squeeze", "(", "0", ")", "[", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", "\n", "if", "self", ".", "params", ".", "get", "(", "'windom_clamp_factor'", ",", "None", ")", "is", "not", "None", ":", "\n", "                ", "self", ".", "output_window", "=", "(", "self", ".", "output_window", "*", "(", "1.0", "/", "self", ".", "params", ".", "get", "(", "'windom_clamp_factor'", ")", ")", ")", ".", "clamp", "(", "0.0", ",", "1.0", ")", "\n", "\n", "# Get target boxes for the different augmentations", "\n", "", "", "target_boxes", "=", "self", ".", "init_target_boxes", "(", ")", "\n", "\n", "# Set number of iterations", "\n", "plot_loss", "=", "self", ".", "params", ".", "debug", ">", "0", "\n", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_iter'", ",", "None", ")", "\n", "\n", "# Get target filter by running the discriminative model prediction module", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "target_filter", ",", "_", ",", "losses", "=", "self", ".", "net", ".", "classifier", ".", "get_filter", "(", "x", ",", "target_boxes", ",", "num_iter", "=", "num_iter", ",", "\n", "compute_losses", "=", "plot_loss", ")", "\n", "\n", "# Init memory", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'update_classifier'", ",", "True", ")", ":", "\n", "            ", "self", ".", "init_memory", "(", "TensorList", "(", "[", "x", "]", ")", ")", "\n", "\n", "", "if", "plot_loss", ":", "\n", "            ", "if", "isinstance", "(", "losses", ",", "dict", ")", ":", "\n", "                ", "losses", "=", "losses", "[", "'train'", "]", "\n", "", "self", ".", "losses", "=", "torch", ".", "stack", "(", "losses", ")", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                ", "self", ".", "visdom", ".", "register", "(", "(", "self", ".", "losses", ",", "torch", ".", "arange", "(", "self", ".", "losses", ".", "numel", "(", ")", ")", ")", ",", "'lineplot'", ",", "3", ",", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "", "elif", "self", ".", "params", ".", "debug", ">=", "3", ":", "\n", "                ", "plot_graph", "(", "self", ".", "losses", ",", "10", ",", "title", "=", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.update_classifier": [[711, 752], ["kys.KYS.update_memory", "kys.KYS.params.get", "kys.KYS.target_boxes[].clone", "pytracking.TensorList", "kys.KYS.params.get", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "kys.KYS.net.classifier.filter_optimizer", "isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "kys.KYS.params.get", "kys.KYS.visdom.register", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "pytracking.utils.plotting.plot_graph", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "kys.KYS.losses.numel"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_memory", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph"], ["", "", "", "def", "update_classifier", "(", "self", ",", "train_x", ",", "target_box", ",", "learning_rate", "=", "None", ",", "scores", "=", "None", ")", ":", "\n", "# Set flags and learning rate", "\n", "        ", "hard_negative_flag", "=", "learning_rate", "is", "not", "None", "\n", "if", "learning_rate", "is", "None", ":", "\n", "            ", "learning_rate", "=", "self", ".", "params", ".", "learning_rate", "\n", "\n", "# Update the tracker memory", "\n", "", "if", "hard_negative_flag", "or", "self", ".", "frame_num", "%", "self", ".", "params", ".", "get", "(", "'train_sample_interval'", ",", "1", ")", "==", "0", ":", "\n", "            ", "self", ".", "update_memory", "(", "TensorList", "(", "[", "train_x", "]", ")", ",", "target_box", ",", "learning_rate", ")", "\n", "\n", "# Decide the number of iterations to run", "\n", "", "num_iter", "=", "0", "\n", "if", "hard_negative_flag", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_hn_iter'", ",", "None", ")", "\n", "", "elif", "(", "self", ".", "frame_num", "-", "1", ")", "%", "self", ".", "params", ".", "train_skipping", "==", "0", ":", "\n", "            ", "num_iter", "=", "self", ".", "params", ".", "get", "(", "'net_opt_update_iter'", ",", "None", ")", "\n", "\n", "", "plot_loss", "=", "self", ".", "params", ".", "debug", ">", "0", "\n", "\n", "if", "num_iter", ">", "0", ":", "\n", "# Get inputs for the DiMP filter optimizer module", "\n", "            ", "samples", "=", "self", ".", "training_samples", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", "...", "]", "\n", "target_boxes", "=", "self", ".", "target_boxes", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", ":", "]", ".", "clone", "(", ")", "\n", "sample_weights", "=", "self", ".", "sample_weights", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", "]", "\n", "\n", "# Run the filter optimizer module", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "target_filter", ",", "_", ",", "losses", "=", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", "(", "self", ".", "target_filter", ",", "\n", "num_iter", "=", "num_iter", ",", "feat", "=", "samples", ",", "\n", "bb", "=", "target_boxes", ",", "\n", "sample_weight", "=", "sample_weights", ",", "\n", "compute_losses", "=", "plot_loss", ")", "\n", "\n", "", "if", "plot_loss", ":", "\n", "                ", "if", "isinstance", "(", "losses", ",", "dict", ")", ":", "\n", "                    ", "losses", "=", "losses", "[", "'train'", "]", "\n", "", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "torch", ".", "stack", "(", "losses", ")", ")", ")", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                    ", "self", ".", "visdom", ".", "register", "(", "(", "self", ".", "losses", ",", "torch", ".", "arange", "(", "self", ".", "losses", ".", "numel", "(", ")", ")", ")", ",", "'lineplot'", ",", "3", ",", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "", "elif", "self", ".", "params", ".", "debug", ">=", "3", ":", "\n", "                    ", "plot_graph", "(", "self", ".", "losses", ",", "10", ",", "title", "=", "'Training Loss'", "+", "self", ".", "id_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.refine_target_box": [[753, 816], ["kys.KYS.get_iounet_box", "kys.KYS.get_iou_features", "pytracking.TensorList", "kys.KYS.view().clone", "kys.KYS.optimize_boxes", "output_boxes[].clamp_", "kys.KYS.params.get", "min", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "output_boxes[].mean", "[].mean", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "new_pos.clone", "kys.KYS.params.get", "init_box[].prod().sqrt", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "predicted_box[].flip", "new_pos.clone", "kys.KYS.params.has", "kys.KYS.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "init_box[].min", "new_target_sz.prod", "kys.KYS.base_target_sz.prod", "init_box[].prod", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "kys.KYS.view", "output_iou.view", "new_pos.flip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_features", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.optimize_boxes", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "", "", "", "def", "refine_target_box", "(", "self", ",", "backbone_feat", ",", "sample_pos", ",", "sample_scale", ",", "scale_ind", ",", "update_scale", "=", "True", ")", ":", "\n", "        ", "\"\"\"Run the ATOM IoUNet to refine the target bounding box.\"\"\"", "\n", "\n", "# Initial box for refinement", "\n", "init_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", ",", "sample_scale", ")", "\n", "\n", "# Extract features from the relevant scale", "\n", "iou_features", "=", "self", ".", "get_iou_features", "(", "backbone_feat", ")", "\n", "iou_features", "=", "TensorList", "(", "[", "x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "for", "x", "in", "iou_features", "]", ")", "\n", "\n", "# Generate random initial boxes", "\n", "init_boxes", "=", "init_box", ".", "view", "(", "1", ",", "4", ")", ".", "clone", "(", ")", "\n", "if", "self", ".", "params", ".", "num_init_random_boxes", ">", "0", ":", "\n", "            ", "square_box_sz", "=", "init_box", "[", "2", ":", "]", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "rand_factor", "=", "square_box_sz", "*", "torch", ".", "cat", "(", "[", "self", ".", "params", ".", "box_jitter_pos", "*", "torch", ".", "ones", "(", "2", ")", ",", "self", ".", "params", ".", "box_jitter_sz", "*", "torch", ".", "ones", "(", "2", ")", "]", ")", "\n", "\n", "minimal_edge_size", "=", "init_box", "[", "2", ":", "]", ".", "min", "(", ")", "/", "3", "\n", "rand_bb", "=", "(", "torch", ".", "rand", "(", "self", ".", "params", ".", "num_init_random_boxes", ",", "4", ")", "-", "0.5", ")", "*", "rand_factor", "\n", "new_sz", "=", "(", "init_box", "[", "2", ":", "]", "+", "rand_bb", "[", ":", ",", "2", ":", "]", ")", ".", "clamp", "(", "minimal_edge_size", ")", "\n", "new_center", "=", "(", "init_box", "[", ":", "2", "]", "+", "init_box", "[", "2", ":", "]", "/", "2", ")", "+", "rand_bb", "[", ":", ",", ":", "2", "]", "\n", "init_boxes", "=", "torch", ".", "cat", "(", "[", "new_center", "-", "new_sz", "/", "2", ",", "new_sz", "]", ",", "1", ")", "\n", "init_boxes", "=", "torch", ".", "cat", "(", "[", "init_box", ".", "view", "(", "1", ",", "4", ")", ",", "init_boxes", "]", ")", "\n", "\n", "# Optimize the boxes", "\n", "", "output_boxes", ",", "output_iou", "=", "self", ".", "optimize_boxes", "(", "iou_features", ",", "init_boxes", ")", "\n", "\n", "# Remove weird boxes", "\n", "output_boxes", "[", ":", ",", "2", ":", "]", ".", "clamp_", "(", "1", ")", "\n", "aspect_ratio", "=", "output_boxes", "[", ":", ",", "2", "]", "/", "output_boxes", "[", ":", ",", "3", "]", "\n", "keep_ind", "=", "(", "aspect_ratio", "<", "self", ".", "params", ".", "maximal_aspect_ratio", ")", "*", "(", "aspect_ratio", ">", "1", "/", "self", ".", "params", ".", "maximal_aspect_ratio", ")", "\n", "output_boxes", "=", "output_boxes", "[", "keep_ind", ",", ":", "]", "\n", "output_iou", "=", "output_iou", "[", "keep_ind", "]", "\n", "\n", "# If no box found", "\n", "if", "output_boxes", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "# Predict box", "\n", "", "k", "=", "self", ".", "params", ".", "get", "(", "'iounet_k'", ",", "5", ")", "\n", "topk", "=", "min", "(", "k", ",", "output_boxes", ".", "shape", "[", "0", "]", ")", "\n", "_", ",", "inds", "=", "torch", ".", "topk", "(", "output_iou", ",", "topk", ")", "\n", "predicted_box", "=", "output_boxes", "[", "inds", ",", ":", "]", ".", "mean", "(", "0", ")", "\n", "predicted_iou", "=", "output_iou", ".", "view", "(", "-", "1", ",", "1", ")", "[", "inds", ",", ":", "]", ".", "mean", "(", "0", ")", "\n", "\n", "# Get new position and size", "\n", "new_pos", "=", "predicted_box", "[", ":", "2", "]", "+", "predicted_box", "[", "2", ":", "]", "/", "2", "\n", "new_pos", "=", "(", "new_pos", ".", "flip", "(", "(", "0", ",", ")", ")", "-", "(", "self", ".", "img_sample_sz", "-", "1", ")", "/", "2", ")", "*", "sample_scale", "+", "sample_pos", "\n", "new_target_sz", "=", "predicted_box", "[", "2", ":", "]", ".", "flip", "(", "(", "0", ",", ")", ")", "*", "sample_scale", "\n", "new_scale", "=", "torch", ".", "sqrt", "(", "new_target_sz", ".", "prod", "(", ")", "/", "self", ".", "base_target_sz", ".", "prod", "(", ")", ")", "\n", "\n", "self", ".", "pos_iounet", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iounet_pos_for_learning'", ",", "True", ")", ":", "\n", "            ", "self", ".", "pos", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "", "self", ".", "target_sz", "=", "new_target_sz", "\n", "\n", "if", "update_scale", ":", "\n", "            ", "if", "self", ".", "params", ".", "has", "(", "'target_scale_update_rate'", ")", ":", "\n", "                ", "self", ".", "target_scale", "=", "new_scale", "*", "self", ".", "params", ".", "target_scale_update_rate", "+", "self", ".", "target_scale", "*", "(", "1", "-", "self", ".", "params", ".", "target_scale_update_rate", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "target_scale", "=", "new_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.optimize_boxes": [[817, 819], ["kys.KYS.optimize_boxes_default"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.optimize_boxes_default"], ["", "", "", "def", "optimize_boxes", "(", "self", ",", "iou_features", ",", "init_boxes", ")", ":", "\n", "        ", "return", "self", ".", "optimize_boxes_default", "(", "iou_features", ",", "init_boxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.optimize_boxes_default": [[820, 847], ["init_boxes.view().to", "isinstance", "range", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor().view", "init_boxes.view().to.clone().detach", "kys.KYS.net.bb_regressor.predict_iou", "isinstance", "kys.KYS.backward", "init_boxes.view().to.detach_", "init_boxes.view().to.view().cpu", "kys.KYS.detach().view().cpu", "init_boxes.view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "init_boxes.view().to.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "bb_init[].repeat", "init_boxes.view().to.view", "kys.KYS.detach().view", "kys.KYS.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou"], ["", "def", "optimize_boxes_default", "(", "self", ",", "iou_features", ",", "init_boxes", ")", ":", "\n", "# Optimize iounet boxes", "\n", "        ", "output_boxes", "=", "init_boxes", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "step_length", "=", "self", ".", "params", ".", "box_refinement_step_length", "\n", "if", "isinstance", "(", "step_length", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "step_length", "=", "torch", ".", "Tensor", "(", "[", "step_length", "[", "0", "]", ",", "step_length", "[", "0", "]", ",", "step_length", "[", "1", "]", ",", "step_length", "[", "1", "]", "]", ",", "\n", "device", "=", "self", ".", "params", ".", "device", ")", ".", "view", "(", "1", ",", "1", ",", "4", ")", "\n", "\n", "", "for", "i_", "in", "range", "(", "self", ".", "params", ".", "box_refinement_iter", ")", ":", "\n", "# forward pass", "\n", "            ", "bb_init", "=", "output_boxes", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "bb_init", ".", "requires_grad", "=", "True", "\n", "\n", "outputs", "=", "self", ".", "net", ".", "bb_regressor", ".", "predict_iou", "(", "self", ".", "iou_modulation", ",", "iou_features", ",", "bb_init", ")", "\n", "\n", "if", "isinstance", "(", "outputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "outputs", "=", "outputs", "[", "0", "]", "\n", "\n", "", "outputs", ".", "backward", "(", "gradient", "=", "torch", ".", "ones_like", "(", "outputs", ")", ")", "\n", "\n", "# Update proposal", "\n", "output_boxes", "=", "bb_init", "+", "step_length", "*", "bb_init", ".", "grad", "*", "bb_init", "[", ":", ",", ":", ",", "2", ":", "]", ".", "repeat", "(", "1", ",", "1", ",", "2", ")", "\n", "output_boxes", ".", "detach_", "(", ")", "\n", "\n", "step_length", "*=", "self", ".", "params", ".", "box_refinement_step_decay", "\n", "\n", "", "return", "output_boxes", ".", "view", "(", "-", "1", ",", "4", ")", ".", "cpu", "(", ")", ",", "outputs", ".", "detach", "(", ")", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.KYS.visdom_draw_tracking": [[848, 853], ["hasattr", "kys.KYS.visdom.register", "kys.KYS.visdom.register"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register"], ["", "def", "visdom_draw_tracking", "(", "self", ",", "image", ",", "box", ",", "segmentation", "=", "None", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "'search_area_box'", ")", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "box", ",", "self", ".", "search_area_box", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "box", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.kys.run": [[14, 149], ["ltr.dataset.Lasot", "ltr.dataset.Got10k", "ltr.dataset.TrackingNet", "ltr.dataset.Got10k", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.KYSProcessing", "ltr.data.processing.KYSProcessing", "ltr.data.sampler.KYSSampler", "ltr.data.LTRLoader", "ltr.data.sampler.KYSSampler", "ltr.data.LTRLoader", "os.path.join", "ltr.load_network", "ltr.kysnet_res50", "kysnet_models.kysnet_res50.backbone_feature_extractor.load_state_dict", "kysnet_models.kysnet_res50.dimp_classifier.load_state_dict", "kysnet_models.kysnet_res50.bb_regressor.load_state_dict", "kysnet_models.kysnet_res50.backbone_feature_extractor.parameters", "kysnet_models.kysnet_res50.dimp_classifier.parameters", "kysnet_models.kysnet_res50.bb_regressor.parameters", "ltr.models.kys.utils.DiMPScoreJittering", "ltr.actors.KYSActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "base_net.feature_extractor.state_dict", "base_net.classifier.state_dict", "base_net.bb_regressor.state_dict", "p.requires_grad_", "p.requires_grad_", "p.requires_grad_", "ltr.LBHingev2", "ltr.LBHingev2", "ltr.IsTargetCellLoss", "ltr.TrackingClassificationAccuracy", "actors.KYSActor.net.predictor.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_network", "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.kysnet_res50", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["\n", "\n", "class", "PrevStateHandler", ":", "\n", "    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "info_dict", "=", "{", "}", "\n", "\n", "", "def", "set_data", "(", "self", ",", "frame_number", ",", "feat", ",", "state", ",", "im", ",", "bb", ",", "label", ",", "bb_patch", ")", ":", "\n", "        ", "self", ".", "info_dict", "=", "{", "'frame_number'", ":", "frame_number", ",", "'feat'", ":", "feat", ",", "'state'", ":", "state", ",", "'im'", ":", "im", ",", "'bb'", ":", "bb", ",", "\n", "'label'", ":", "label", ",", "'bb_patch'", ":", "bb_patch", "}", "\n", "\n", "", "def", "get_data", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "info_dict", "[", "'feat'", "]", ",", "self", ".", "info_dict", "[", "'state'", "]", ",", "self", ".", "info_dict", "[", "'im'", "]", ",", "self", ".", "info_dict", "[", "'label'", "]", ",", "self", ".", "info_dict", "[", "'bb_patch'", "]", "\n", "\n", "", "def", "reset_state", "(", "self", ")", ":", "\n", "# Reset state in case of long occlusions", "\n", "        ", "if", "self", ".", "info_dict", "[", "'state'", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "info_dict", "[", "'state'", "]", "=", "self", ".", "info_dict", "[", "'state'", "]", "*", "0.0", "\n", "\n", "\n", "", "", "", "class", "KYS", "(", "BaseTracker", ")", ":", "\n", "    ", "multiobj_mode", "=", "'parallel'", "\n", "\n", "def", "initialize_features", "(", "self", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "self", ",", "'features_initialized'", ",", "False", ")", ":", "\n", "            ", "self", ".", "params", ".", "net", ".", "initialize", "(", ")", "\n", "", "self", ".", "features_initialized", "=", "True", "\n", "\n", "", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "        ", "self", ".", "frame_num", "=", "1", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'device'", ")", ":", "\n", "            ", "self", ".", "params", ".", "device", "=", "'cuda'", "if", "self", ".", "params", ".", "use_gpu", "else", "'cpu'", "\n", "\n", "# Initialize network", "\n", "", "self", ".", "initialize_features", "(", ")", "\n", "\n", "# The DiMP network", "\n", "self", ".", "net", "=", "self", ".", "params", ".", "net", "\n", "\n", "# Time initialization", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Get target position and size", "\n", "state", "=", "info", "[", "'init_bbox'", "]", "\n", "self", ".", "pos", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "1", "]", "+", "(", "state", "[", "3", "]", "-", "1", ")", "/", "2", ",", "state", "[", "0", "]", "+", "(", "state", "[", "2", "]", "-", "1", ")", "/", "2", "]", ")", "\n", "self", ".", "target_sz", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "3", "]", ",", "state", "[", "2", "]", "]", ")", "\n", "\n", "# Get object id", "\n", "self", ".", "object_id", "=", "info", ".", "get", "(", "'object_ids'", ",", "[", "None", "]", ")", "[", "0", "]", "\n", "self", ".", "id_str", "=", "''", "if", "self", ".", "object_id", "is", "None", "else", "' {}'", ".", "format", "(", "self", ".", "object_id", ")", "\n", "\n", "# Set sizes", "\n", "sz", "=", "self", ".", "params", ".", "image_sample_size", "\n", "self", ".", "img_sample_sz", "=", "torch", ".", "Tensor", "(", "[", "sz", ",", "sz", "]", "if", "isinstance", "(", "sz", ",", "int", ")", "else", "sz", ")", "\n", "self", ".", "img_support_sz", "=", "self", ".", "img_sample_sz", "\n", "\n", "# Set search area", "\n", "search_area", "=", "torch", ".", "prod", "(", "self", ".", "target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ".", "item", "(", ")", "\n", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", ")", "/", "self", ".", "img_sample_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "\n", "# Target size in base scale", "\n", "self", ".", "base_target_sz", "=", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# Setup scale factors", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'scale_factors'", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "ones", "(", "1", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "params", ".", "scale_factors", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "Tensor", "(", "self", ".", "params", ".", "scale_factors", ")", "\n", "\n", "# Setup scale bounds", "\n", "", "self", ".", "image_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "self", ".", "min_scale_factor", "=", "torch", ".", "max", "(", "10", "/", "self", ".", "base_target_sz", ")", "\n", "self", ".", "max_scale_factor", "=", "torch", ".", "min", "(", "self", ".", "image_sz", "/", "self", ".", "base_target_sz", ")", "\n", "\n", "# Extract and transform sample", "\n", "init_backbone_feat", "=", "self", ".", "generate_init_samples", "(", "im", ")", "\n", "\n", "# Initialize dimp classifier", "\n", "self", ".", "init_classifier", "(", "init_backbone_feat", ")", "\n", "\n", "# Initialize IoUNet", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", ":", "\n", "            ", "self", ".", "init_iou_net", "(", "init_backbone_feat", ")", "\n", "\n", "", "self", ".", "label_sz", "=", "self", ".", "feature_sz", "/", "self", ".", "params", ".", "score_downsample_factor", "\n", "\n", "output_sigma_factor", "=", "self", ".", "params", ".", "output_sigma_factor", "\n", "self", ".", "sigma", "=", "(", "self", ".", "label_sz", "/", "self", ".", "img_support_sz", "*", "\n", "self", ".", "base_target_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "output_sigma_factor", "*", "torch", ".", "ones", "(", "2", ")", "\n", "\n", "self", ".", "prev_state_handler", "=", "PrevStateHandler", "(", ")", "\n", "\n", "self", ".", "init_motion_module", "(", "im", ")", "\n", "\n", "out", "=", "{", "'time'", ":", "time", ".", "time", "(", ")", "-", "tic", "}", "\n", "return", "out", "\n", "\n", "", "def", "track", "(", "self", ",", "image", ",", "info", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "        ", "self", ".", "debug_info", "=", "{", "}", "\n", "\n", "self", ".", "frame_num", "+=", "1", "\n", "self", ".", "debug_info", "[", "'frame_num'", "]", "=", "self", ".", "frame_num", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "self", ".", "im", "=", "im", "\n", "\n", "# ------- LOCALIZATION ------- #", "\n", "# Extract backbone features", "\n", "backbone_feat", ",", "sample_coords", ",", "im_patches", "=", "self", ".", "extract_backbone_features", "(", "im", ",", "self", ".", "get_centered_sample_pos", "(", ")", ",", "\n", "self", ".", "target_scale", "*", "self", ".", "params", ".", "scale_factors", ",", "\n", "self", ".", "img_sample_sz", ")", "\n", "# Extract classification features", "\n", "test_patch", "=", "im_patches", "[", "0", "]", ".", "int", "(", ")", "\n", "self", ".", "test_patch", "=", "test_patch", "\n", "\n", "test_x", "=", "self", ".", "get_classification_features", "(", "backbone_feat", ")", "\n", "\n", "# Location of sample", "\n", "sample_pos", ",", "sample_scales", "=", "self", ".", "get_sample_location", "(", "sample_coords", ")", "\n", "\n", "# Compute classification scores", "\n", "scores_dimp", "=", "self", ".", "classify_target", "(", "test_x", ")", "\n", "\n", "# Compute fused score using the motion module", "\n", "scores_fused", ",", "motion_feat", ",", "new_state_vector", "=", "self", ".", "get_response_prediction", "(", "backbone_feat", ",", "scores_dimp", ")", "\n", "\n", "# Localize the target", "\n", "translation_vec", ",", "scale_ind", ",", "s", ",", "flag", "=", "self", ".", "localize_target", "(", "scores_fused", ",", "scores_dimp", ",", "sample_scales", ")", "\n", "new_pos", "=", "sample_pos", "[", "scale_ind", ",", ":", "]", "+", "translation_vec", "\n", "\n", "self", ".", "debug_info", "[", "'flag'", "+", "self", ".", "id_str", "]", "=", "flag", "\n", "self", ".", "search_area_box", "=", "torch", ".", "cat", "(", "(", "sample_coords", "[", "scale_ind", ",", "[", "1", ",", "0", "]", "]", ",", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.cost_volume.CostVolume.__init__": [[9, 14], ["torch.Module.__init__", "spatial_correlation_sampler.SpatialCorrelationSampler", "int"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "kernel_size", ",", "max_displacement", ",", "stride", "=", "1", ",", "abs_coordinate_output", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "correlation_layer", "=", "SpatialCorrelationSampler", "(", "kernel_size", ",", "2", "*", "max_displacement", "+", "1", ",", "stride", ",", "\n", "int", "(", "(", "kernel_size", "-", "1", ")", "/", "2", ")", ")", "\n", "self", ".", "abs_coordinate_output", "=", "abs_coordinate_output", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.cost_volume.CostVolume.forward": [[15, 27], ["remap_cost_volume.CostVolume.correlation_layer", "remap_cost_volume.view", "remap_cost_volume.view", "cost_volume.remap_cost_volume", "feat1.dim", "feat2.dim"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.cost_volume.remap_cost_volume", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "forward", "(", "self", ",", "feat1", ",", "feat2", ")", ":", "\n", "        ", "assert", "feat1", ".", "dim", "(", ")", "==", "4", "and", "feat2", ".", "dim", "(", ")", "==", "4", ",", "'Expect 4 dimensional inputs'", "\n", "\n", "batch_size", "=", "feat1", ".", "shape", "[", "0", "]", "\n", "\n", "cost_volume", "=", "self", ".", "correlation_layer", "(", "feat1", ",", "feat2", ")", "\n", "\n", "if", "self", ".", "abs_coordinate_output", ":", "\n", "            ", "cost_volume", "=", "cost_volume", ".", "view", "(", "batch_size", ",", "-", "1", ",", "cost_volume", ".", "shape", "[", "-", "2", "]", ",", "cost_volume", ".", "shape", "[", "-", "1", "]", ")", "\n", "cost_volume", "=", "remap_cost_volume", "(", "cost_volume", ")", "\n", "\n", "", "return", "cost_volume", ".", "view", "(", "batch_size", ",", "-", "1", ",", "cost_volume", ".", "shape", "[", "-", "2", "]", ",", "cost_volume", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.cost_volume.remap_cost_volume": [[29, 76], ["cost_volume.view.size", "numpy.sqrt", "cost_volume.view.view", "torch.zeros", "torch.zeros", "int", "range", "cost_volume.view.dim", "ValueError", "np.sqrt.is_integer", "ValueError", "int", "int", "range", "max", "max", "max", "max", "cost_volume.view.size", "cost_volume.view.size", "cost_volume.view.size"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size"], ["", "", "def", "remap_cost_volume", "(", "cost_volume", ")", ":", "\n", "    ", "\"\"\"\n\n    :param cost_volume: cost volume of shape (batch, (2*md-1)*(2*md-1), rows, cols), where md is the maximum displacement\n                        allowed when computing the cost volume.\n    :return: cost_volume_remapped: The input cost volume is remapped to shape (batch, rows, cols, rows, cols)\n    \"\"\"", "\n", "\n", "if", "cost_volume", ".", "dim", "(", ")", "!=", "4", ":", "\n", "        ", "raise", "ValueError", "(", "'input cost_volume should have 4 dimensions'", ")", "\n", "\n", "", "[", "batch_size", ",", "d_", ",", "num_rows", ",", "num_cols", "]", "=", "cost_volume", ".", "size", "(", ")", "\n", "d_sqrt_", "=", "np", ".", "sqrt", "(", "d_", ")", "\n", "\n", "if", "not", "d_sqrt_", ".", "is_integer", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Invalid cost volume\"", ")", "\n", "\n", "", "cost_volume", "=", "cost_volume", ".", "view", "(", "batch_size", ",", "int", "(", "d_sqrt_", ")", ",", "int", "(", "d_sqrt_", ")", ",", "num_rows", ",", "num_cols", ")", "\n", "\n", "cost_volume_remapped", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "num_rows", ",", "num_cols", ",", "\n", "num_rows", ",", "num_cols", ")", ",", "\n", "dtype", "=", "cost_volume", ".", "dtype", ",", "\n", "device", "=", "cost_volume", ".", "device", ")", "\n", "\n", "if", "cost_volume", ".", "size", "(", ")", "[", "1", "]", "%", "2", "!=", "1", ":", "\n", "        ", "raise", "ValueError", "\n", "\n", "", "md", "=", "int", "(", "(", "cost_volume", ".", "size", "(", ")", "[", "1", "]", "-", "1", ")", "/", "2", ")", "\n", "\n", "for", "r", "in", "range", "(", "num_rows", ")", ":", "\n", "        ", "for", "c", "in", "range", "(", "num_cols", ")", ":", "\n", "            ", "r1_", "=", "r", "-", "md", "\n", "r2_", "=", "r1_", "+", "2", "*", "md", "+", "1", "\n", "c1_", "=", "c", "-", "md", "\n", "c2_", "=", "c1_", "+", "2", "*", "md", "+", "1", "\n", "\n", "r1_pad_", "=", "max", "(", "-", "r1_", ",", "0", ")", "\n", "r2_pad_", "=", "max", "(", "r2_", "-", "cost_volume_remapped", ".", "shape", "[", "1", "]", ",", "0", ")", "\n", "\n", "c1_pad_", "=", "max", "(", "-", "c1_", ",", "0", ")", "\n", "c2_pad_", "=", "max", "(", "c2_", "-", "cost_volume_remapped", ".", "shape", "[", "2", "]", ",", "0", ")", "\n", "\n", "d_", "=", "cost_volume", ".", "size", "(", ")", "[", "1", "]", "\n", "cost_volume_remapped", "[", ":", ",", "r1_", "+", "r1_pad_", ":", "r2_", "-", "r2_pad_", ",", "c1_", "+", "c1_pad_", ":", "c2_", "-", "c2_pad_", ",", "r", ",", "c", "]", "=", "cost_volume", "[", ":", ",", "r1_pad_", ":", "d_", "-", "r2_pad_", ",", "c1_pad_", ":", "d_", "-", "c2_pad_", ",", "r", ",", "c", "]", "\n", "\n", "", "", "return", "cost_volume_remapped", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.conv_gru.ConvGRUCell.__init__": [[7, 33], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "ltr.models.layers.blocks.conv_block", "ltr.models.layers.blocks.conv_block", "ltr.models.layers.blocks.conv_block", "isinstance", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "hidden_dim", ",", "kernel_size", ",", "padding_mode", "=", "'zeros'", ")", ":", "\n", "        ", "\" Referenced from https://github.com/happyjin/ConvGRU-pytorch\"", "\n", "super", "(", "ConvGRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "\n", "if", "padding_mode", "==", "'zeros'", ":", "\n", "            ", "if", "not", "isinstance", "(", "kernel_size", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "kernel_size", "=", "(", "kernel_size", ",", "kernel_size", ")", "\n", "\n", "", "padding", "=", "kernel_size", "[", "0", "]", "//", "2", ",", "kernel_size", "[", "1", "]", "//", "2", "\n", "self", ".", "conv_reset", "=", "nn", ".", "Conv2d", "(", "input_dim", "+", "hidden_dim", ",", "self", ".", "hidden_dim", ",", "kernel_size", ",", "padding", "=", "padding", ")", "\n", "self", ".", "conv_update", "=", "nn", ".", "Conv2d", "(", "input_dim", "+", "hidden_dim", ",", "self", ".", "hidden_dim", ",", "kernel_size", ",", "padding", "=", "padding", ")", "\n", "\n", "self", ".", "conv_state_new", "=", "nn", ".", "Conv2d", "(", "input_dim", "+", "hidden_dim", ",", "self", ".", "hidden_dim", ",", "kernel_size", ",", "padding", "=", "padding", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv_reset", "=", "conv_block", "(", "input_dim", "+", "hidden_dim", ",", "hidden_dim", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "int", "(", "kernel_size", "//", "2", ")", ",", "batch_norm", "=", "False", ",", "relu", "=", "False", ",", "\n", "padding_mode", "=", "padding_mode", ")", "\n", "\n", "self", ".", "conv_update", "=", "conv_block", "(", "input_dim", "+", "hidden_dim", ",", "hidden_dim", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "int", "(", "kernel_size", "//", "2", ")", ",", "batch_norm", "=", "False", ",", "relu", "=", "False", ",", "\n", "padding_mode", "=", "padding_mode", ")", "\n", "\n", "self", ".", "conv_state_new", "=", "conv_block", "(", "input_dim", "+", "hidden_dim", ",", "hidden_dim", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "int", "(", "kernel_size", "//", "2", ")", ",", "batch_norm", "=", "False", ",", "relu", "=", "False", ",", "\n", "padding_mode", "=", "padding_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.conv_gru.ConvGRUCell.forward": [[34, 45], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "conv_gru.ConvGRUCell.conv_reset", "conv_gru.ConvGRUCell.conv_update", "conv_gru.ConvGRUCell.conv_state_new"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "state_cur", ")", ":", "\n", "        ", "input_state_cur", "=", "torch", ".", "cat", "(", "[", "input", ",", "state_cur", "]", ",", "dim", "=", "1", ")", "\n", "\n", "reset_gate", "=", "torch", ".", "sigmoid", "(", "self", ".", "conv_reset", "(", "input_state_cur", ")", ")", "\n", "update_gate", "=", "torch", ".", "sigmoid", "(", "self", ".", "conv_update", "(", "input_state_cur", ")", ")", "\n", "\n", "input_state_cur_reset", "=", "torch", ".", "cat", "(", "[", "input", ",", "reset_gate", "*", "state_cur", "]", ",", "dim", "=", "1", ")", "\n", "state_new", "=", "torch", ".", "tanh", "(", "self", ".", "conv_state_new", "(", "input_state_cur_reset", ")", ")", "\n", "\n", "state_next", "=", "(", "1.0", "-", "update_gate", ")", "*", "state_cur", "+", "update_gate", "*", "state_new", "\n", "return", "state_next", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.response_predictor.ResponsePredictor.__init__": [[9, 64], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "conv_gru.ConvGRUCell", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "response_predictor.ResponsePredictor.modules", "int", "ltr.models.layers.blocks.conv_block", "ltr.models.layers.blocks.conv_block", "ltr.models.layers.blocks.conv_block", "ltr.models.layers.blocks.conv_block", "representation_predictor_list.append", "ltr.models.layers.blocks.conv_block", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "ltr.models.layers.blocks.conv_block", "torch.Tanh", "torch.Tanh", "torch.Tanh", "ltr.models.layers.blocks.conv_block", "ltr.models.layers.blocks.conv_block", "ltr.models.layers.blocks.conv_block", "isinstance", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "int", "int", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block"], ["    ", "def", "__init__", "(", "self", ",", "state_dim", "=", "8", ",", "representation_predictor_dims", "=", "(", "64", ",", "32", ")", ",", "gru_ksz", "=", "3", ",", "\n", "prev_max_pool_ksz", "=", "1", ",", "conf_measure", "=", "'max'", ",", "dimp_thresh", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "prev_max_pool_ksz", "=", "prev_max_pool_ksz", "\n", "self", ".", "conf_measure", "=", "conf_measure", "\n", "self", ".", "dimp_thresh", "=", "dimp_thresh", "\n", "\n", "cvproc_ksz", "=", "[", "3", ",", "3", "]", "\n", "use_bn", "=", "True", "\n", "\n", "padding_val", "=", "[", "int", "(", "(", "s", "-", "1", ")", "/", "2", ")", "for", "s", "in", "cvproc_ksz", "]", "\n", "\n", "self", ".", "cost_volume_proc1", "=", "nn", ".", "Sequential", "(", "\n", "conv_block", "(", "1", ",", "8", ",", "kernel_size", "=", "cvproc_ksz", "[", "0", "]", ",", "stride", "=", "1", ",", "padding", "=", "padding_val", "[", "0", "]", ",", "batch_norm", "=", "use_bn", ",", "relu", "=", "True", ")", ",", "\n", "conv_block", "(", "8", ",", "1", ",", "kernel_size", "=", "cvproc_ksz", "[", "1", "]", ",", "stride", "=", "1", ",", "padding", "=", "padding_val", "[", "1", "]", ",", "batch_norm", "=", "use_bn", ",", "relu", "=", "False", ")", ")", "\n", "\n", "self", ".", "cost_volume_proc2", "=", "nn", ".", "Sequential", "(", "\n", "conv_block", "(", "1", ",", "8", ",", "kernel_size", "=", "cvproc_ksz", "[", "0", "]", ",", "stride", "=", "1", ",", "padding", "=", "padding_val", "[", "0", "]", ",", "batch_norm", "=", "use_bn", ",", "relu", "=", "True", ")", ",", "\n", "conv_block", "(", "8", ",", "1", ",", "kernel_size", "=", "cvproc_ksz", "[", "1", "]", ",", "stride", "=", "1", ",", "padding", "=", "padding_val", "[", "1", "]", ",", "batch_norm", "=", "use_bn", ",", "relu", "=", "False", ")", ")", "\n", "\n", "in_dim", "=", "state_dim", "+", "1", "+", "(", "conf_measure", "!=", "'none'", ")", "\n", "representation_predictor_list", "=", "[", "]", "\n", "for", "out_dim", "in", "representation_predictor_dims", ":", "\n", "            ", "representation_predictor_list", ".", "append", "(", "conv_block", "(", "in_dim", ",", "out_dim", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "\n", "batch_norm", "=", "False", ",", "relu", "=", "True", ")", ")", "\n", "in_dim", "=", "out_dim", "\n", "\n", "", "self", ".", "representation_predictor", "=", "nn", ".", "Sequential", "(", "*", "representation_predictor_list", ")", "\n", "self", ".", "representation_dim", "=", "in_dim", "\n", "\n", "self", ".", "response_predictor", "=", "nn", ".", "Sequential", "(", "\n", "conv_block", "(", "in_dim", ",", "1", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "batch_norm", "=", "False", ",", "relu", "=", "False", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "\n", "self", ".", "state_predictor", "=", "ConvGRUCell", "(", "4", ",", "state_dim", ",", "gru_ksz", ")", "\n", "\n", "self", ".", "init_hidden_state_predictor", "=", "nn", ".", "Sequential", "(", "\n", "conv_block", "(", "1", ",", "state_dim", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "batch_norm", "=", "False", ",", "relu", "=", "False", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ")", "\n", "\n", "self", ".", "is_target_predictor", "=", "nn", ".", "Sequential", "(", "\n", "conv_block", "(", "state_dim", ",", "4", ",", "kernel_size", "=", "gru_ksz", ",", "stride", "=", "1", ",", "padding", "=", "int", "(", "gru_ksz", "//", "2", ")", ",", "batch_norm", "=", "False", ",", "\n", "relu", "=", "True", ")", ",", "\n", "conv_block", "(", "4", ",", "1", ",", "kernel_size", "=", "gru_ksz", ",", "stride", "=", "1", ",", "padding", "=", "int", "(", "gru_ksz", "//", "2", ")", ",", "batch_norm", "=", "False", ",", "relu", "=", "False", ")", ")", "\n", "\n", "# Init weights", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "mode", "=", "'fan_in'", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.response_predictor.ResponsePredictor.forward": [[65, 160], ["cost_volume.view.view.view", "response_predictor.ResponsePredictor.cost_volume_proc1().view", "torch.softmax", "torch.softmax", "torch.softmax", "response_predictor.ResponsePredictor.cost_volume_proc2", "cost_volume_p2.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "cost_volume_p2.view.view.view", "response_predictor.ResponsePredictor.is_target_predictor", "state_prev_ndhw.view.view.view", "state_prev_ndhw.view.view.permute().contiguous().view().expand", "cost_volume_p2.view.view.view", "propagated_h.view.view.view", "propagated_h.view.view.clone", "response_predictor.ResponsePredictor.is_target_predictor", "response_predictor.ResponsePredictor.representation_predictor", "response_predictor.ResponsePredictor.response_predictor", "response_predictor.ResponsePredictor.clone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.adaptive_max_pool2d().view().expand", "torch.adaptive_max_pool2d().view().expand", "torch.adaptive_max_pool2d().view().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "response_predictor.ResponsePredictor.state_predictor", "response_predictor.ResponsePredictor.is_target_predictor", "torch.softmax.view", "response_predictor.ResponsePredictor.init_hidden_state_predictor", "cost_volume_p2.view.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "response_predictor.ResponsePredictor.cost_volume_proc1", "init_label.view", "state_prev_ndhw.view.view.permute().contiguous().view", "cost_volume_p2.view.view.view().max", "cost_volume_p2.view.view.view", "torch.adaptive_max_pool2d().view", "torch.adaptive_max_pool2d().view", "torch.adaptive_max_pool2d().view", "dimp_score_cur.view", "dimp_score_cur.view", "state_prev_ndhw.view.view.permute().contiguous", "cost_volume_p2.view.view.view", "torch.adaptive_max_pool2d", "torch.adaptive_max_pool2d", "torch.adaptive_max_pool2d", "state_prev_ndhw.view.view.permute"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "cost_volume", ",", "state_prev", ",", "dimp_score_cur", ",", "init_label", "=", "None", ",", "dimp_thresh", "=", "None", ",", "\n", "output_window", "=", "None", ")", ":", "\n", "# Cost vol shape: n x h*w x h x w", "\n", "# state_prev shape: n x d x h x w", "\n", "# dimp_cur_shape: n x 1 x h x w", "\n", "# init_label shape: n x 1 x h x w", "\n", "        ", "if", "dimp_thresh", "is", "None", ":", "\n", "            ", "dimp_thresh", "=", "self", ".", "dimp_thresh", "\n", "", "auxiliary_outputs", "=", "{", "}", "\n", "\n", "num_sequences", "=", "cost_volume", ".", "shape", "[", "0", "]", "\n", "feat_sz", "=", "cost_volume", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "cost_volume", "=", "cost_volume", ".", "view", "(", "-", "1", ",", "1", ",", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", "\n", "cost_volume_p1", "=", "self", ".", "cost_volume_proc1", "(", "cost_volume", ")", ".", "view", "(", "-", "1", ",", "feat_sz", "[", "0", "]", "*", "feat_sz", "[", "1", "]", ")", "\n", "cost_volume_p1", "=", "F", ".", "softmax", "(", "cost_volume_p1", ",", "dim", "=", "1", ")", "\n", "\n", "cost_volume_p2", "=", "self", ".", "cost_volume_proc2", "(", "cost_volume_p1", ".", "view", "(", "-", "1", ",", "1", ",", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", ")", "\n", "cost_volume_p2", "=", "cost_volume_p2", ".", "view", "(", "num_sequences", ",", "-", "1", ",", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", "\n", "cost_volume_p2", "=", "F", ".", "softmax", "(", "cost_volume_p2", ",", "dim", "=", "1", ")", "\n", "cost_volume_p2", "=", "cost_volume_p2", ".", "view", "(", "num_sequences", ",", "-", "1", ",", "1", ",", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", "\n", "\n", "auxiliary_outputs", "[", "'cost_volume_processed'", "]", "=", "cost_volume_p2", "\n", "\n", "if", "state_prev", "is", "None", ":", "\n", "            ", "init_hidden_state", "=", "self", ".", "init_hidden_state_predictor", "(", "init_label", ".", "view", "(", "num_sequences", ",", "1", ",", "\n", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", ")", "\n", "state_prev_ndhw", "=", "init_hidden_state", "\n", "", "else", ":", "\n", "            ", "state_prev_ndhw", "=", "state_prev", "\n", "\n", "", "is_target", "=", "self", ".", "is_target_predictor", "(", "state_prev_ndhw", ")", "\n", "auxiliary_outputs", "[", "'is_target'", "]", "=", "is_target", "\n", "\n", "state_prev_ndhw", "=", "state_prev_ndhw", ".", "view", "(", "num_sequences", ",", "-", "1", ",", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", "\n", "\n", "state_prev_nhwd", "=", "state_prev_ndhw", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "num_sequences", ",", "feat_sz", "[", "0", "]", "*", "feat_sz", "[", "1", "]", ",", "-", "1", ",", "1", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "-", "1", ",", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", "\n", "\n", "#  Compute propagation weights", "\n", "propagation_weight_norm", "=", "cost_volume_p2", ".", "view", "(", "num_sequences", ",", "feat_sz", "[", "0", "]", "*", "feat_sz", "[", "1", "]", ",", "1", ",", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", "\n", "\n", "# Pool", "\n", "if", "self", ".", "prev_max_pool_ksz", ">", "1", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "# Max pool along prev frame ref", "\n", "", "if", "self", ".", "conf_measure", "==", "'max'", ":", "\n", "            ", "propagation_conf", "=", "propagation_weight_norm", ".", "view", "(", "num_sequences", ",", "-", "1", ",", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "", "elif", "self", ".", "conf_measure", "==", "'entropy'", ":", "\n", "            ", "propagation_conf", "=", "propagation_weight_norm", ".", "view", "(", "num_sequences", ",", "-", "1", ",", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", "\n", "propagation_conf", "=", "-", "(", "propagation_conf", "*", "(", "propagation_conf", "+", "1e-4", ")", ".", "log", "(", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "", "auxiliary_outputs", "[", "'propagation_weights'", "]", "=", "propagation_weight_norm", "\n", "\n", "propagated_h", "=", "(", "propagation_weight_norm", "*", "state_prev_nhwd", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "propagated_h", "=", "propagated_h", ".", "view", "(", "num_sequences", ",", "-", "1", ",", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", "\n", "\n", "auxiliary_outputs", "[", "'propagated_h'", "]", "=", "propagated_h", ".", "clone", "(", ")", "\n", "is_target_after_prop", "=", "self", ".", "is_target_predictor", "(", "propagated_h", ")", "\n", "auxiliary_outputs", "[", "'is_target_after_prop'", "]", "=", "is_target_after_prop", "\n", "\n", "if", "self", ".", "conf_measure", "!=", "'none'", ":", "\n", "            ", "propagation_conf", "=", "propagation_conf", ".", "view", "(", "num_sequences", ",", "1", ",", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", "\n", "auxiliary_outputs", "[", "'propagation_conf'", "]", "=", "propagation_conf", "\n", "\n", "predictor_input", "=", "torch", ".", "cat", "(", "\n", "(", "propagated_h", ",", "dimp_score_cur", ".", "view", "(", "num_sequences", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "\n", "propagation_conf", ")", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "predictor_input", "=", "torch", ".", "cat", "(", "\n", "(", "propagated_h", ",", "dimp_score_cur", ".", "view", "(", "num_sequences", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", ")", ",", "dim", "=", "1", ")", "\n", "", "resp_representation", "=", "self", ".", "representation_predictor", "(", "predictor_input", ")", "\n", "fused_prediction", "=", "self", ".", "response_predictor", "(", "resp_representation", ")", "\n", "\n", "auxiliary_outputs", "[", "'fused_score_orig'", "]", "=", "fused_prediction", ".", "clone", "(", ")", "\n", "if", "dimp_thresh", "is", "not", "None", ":", "\n", "            ", "fused_prediction", "=", "fused_prediction", "*", "(", "dimp_score_cur", ">", "dimp_thresh", ")", ".", "float", "(", ")", "\n", "\n", "", "if", "output_window", "is", "not", "None", ":", "\n", "            ", "fused_prediction", "=", "fused_prediction", "*", "output_window", "\n", "\n", "", "scores_cat", "=", "torch", ".", "cat", "(", "(", "dimp_score_cur", ",", "fused_prediction", ")", ",", "dim", "=", "1", ")", "\n", "\n", "scores_cat_pool", "=", "F", ".", "adaptive_max_pool2d", "(", "scores_cat", ",", "1", ")", ".", "view", "(", "scores_cat", ".", "shape", "[", "0", "]", ",", "scores_cat", ".", "shape", "[", "1", "]", ",", "1", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "feat_sz", "[", "0", "]", ",", "feat_sz", "[", "1", "]", ")", "\n", "\n", "state_gru_input", "=", "torch", ".", "cat", "(", "(", "scores_cat", ",", "scores_cat_pool", ")", ",", "dim", "=", "1", ")", "\n", "\n", "state_new", "=", "self", ".", "state_predictor", "(", "state_gru_input", ",", "propagated_h", ")", "\n", "\n", "is_target_new", "=", "self", ".", "is_target_predictor", "(", "state_new", ")", "\n", "auxiliary_outputs", "[", "'is_target_new'", "]", "=", "is_target_new", "\n", "\n", "return", "fused_prediction", ",", "state_new", ",", "auxiliary_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.CenterShiftFeatures.__init__": [[17, 20], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], []], "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.CenterShiftFeatures.forward": [[21, 33], ["anno.view.view.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "utils.shift_features", "t_x.view", "t_y.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features"], []], "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.__init__": [[36, 44], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand": [[45, 47], ["torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], []], "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.__call__": [[48, 80], ["score.view.view.view", "label.view.view.view", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "score.view.view.clone().detach", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "range", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "score_jittered.view", "utils.DiMPScoreJittering.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "score.view.view.clone", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], []], "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features": [[6, 14], ["torch.eye().repeat().to", "torch.eye().repeat().to", "torch.eye().repeat().to", "torch.cat", "torch.cat", "torch.cat", "torch.affine_grid", "torch.grid_sample", "torch.eye().repeat", "torch.eye().repeat", "torch.eye().repeat", "relative_translation_vector.view", "torch.eye", "torch.eye", "torch.eye"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["    ", "sz", "=", "seq", "[", "ref_tensor", "]", ".", "shape", "[", "-", "2", ":", "]", "\n", "t", "=", "torch", ".", "cat", "(", "[", "interpolate", "(", "t", ",", "sz", ",", "mode", "=", "mode", ")", "for", "t", "in", "seq", "]", ",", "dim", "=", "dim", ")", "\n", "return", "t", "\n", "\n", "\n", "", "def", "interpolate", "(", "t", ",", "sz", ",", "mode", "=", "'bilinear'", ")", ":", "\n", "    ", "sz", "=", "sz", ".", "tolist", "(", ")", "if", "torch", ".", "is_tensor", "(", "sz", ")", "else", "sz", "\n", "align", "=", "{", "}", "if", "mode", "==", "'nearest'", "else", "dict", "(", "align_corners", "=", "False", ")", "\n", "return", "F", ".", "interpolate", "(", "t", ",", "sz", ",", "mode", "=", "mode", ",", "**", "align", ")", "if", "t", ".", "shape", "[", "-", "2", ":", "]", "!=", "sz", "else", "t", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.__init__": [[7, 13], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "cost_volume", ",", "predictor", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "cost_volume", "=", "cost_volume", "\n", "self", ".", "predictor", "=", "predictor", "\n", "self", ".", "fix_coordinate_shift", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.forward": [[14, 74], ["data.get", "isinstance", "predictor_wrapper.PredictorWrapper.extract_motion_feat", "feat2.view.view.view", "ltr.models.kys.utils.shift_features.view", "isinstance", "torch.tensor().view().float().to", "torch.tensor().view().float().to", "torch.tensor().view().float().to", "torch.tensor().view().float().to", "predictor_wrapper.PredictorWrapper.predictor", "ltr.models.kys.utils.shift_features().view.view", "predictor_wrapper.PredictorWrapper.extract_motion_feat", "feat1.view.view.view", "predictor_wrapper.PredictorWrapper.compute_cost_volume", "ltr.models.kys.utils.shift_features", "ltr.models.kys.utils.shift_features().view", "predictor_wrapper.PredictorWrapper.extract_motion_feat", "f1.view", "predictor_wrapper.PredictorWrapper.compute_cost_volume", "torch.tensor().view().float", "torch.tensor().view().float", "torch.tensor().view().float", "torch.tensor().view().float", "ltr.models.kys.utils.shift_features().view", "ltr.models.kys.utils.shift_features.clone", "ltr.models.kys.utils.shift_features().view", "ltr.models.kys.utils.shift_features().view", "ltr.models.kys.utils.shift_features().view", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "ltr.models.kys.utils.shift_features", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "ltr.models.kys.utils.shift_features", "ltr.models.kys.utils.shift_features", "ltr.models.kys.utils.shift_features", "ltr.models.kys.utils.shift_features", "ltr.models.kys.utils.shift_features().view.view", "ltr.models.kys.utils.shift_features().view.clone().view", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "auxiliary_outputs[].view", "auxiliary_outputs[].view", "auxiliary_outputs[].view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "ltr.models.kys.utils.shift_features().view.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.extract_motion_feat", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.extract_motion_feat", "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.compute_cost_volume", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.extract_motion_feat", "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.compute_cost_volume", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features"], ["", "def", "forward", "(", "self", ",", "data", ")", ":", "\n", "        ", "input1", "=", "data", "[", "'input1'", "]", "\n", "input2", "=", "data", "[", "'input2'", "]", "\n", "label_prev", "=", "data", ".", "get", "(", "'label_prev'", ",", "None", ")", "\n", "\n", "dimp_score_cur", "=", "data", "[", "'dimp_score_cur'", "]", "\n", "state_prev", "=", "data", "[", "'state_prev'", "]", "\n", "\n", "score_shape", "=", "dimp_score_cur", ".", "shape", "\n", "\n", "if", "isinstance", "(", "input1", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "feat1", "=", "[", "self", ".", "extract_motion_feat", "(", "in1", ")", "for", "in1", "in", "input1", "]", "\n", "feat1", "=", "[", "f1", ".", "view", "(", "-", "1", ",", "*", "f1", ".", "shape", "[", "-", "3", ":", "]", ")", "for", "f1", "in", "feat1", "]", "\n", "", "else", ":", "\n", "            ", "feat1", "=", "self", ".", "extract_motion_feat", "(", "input1", ")", "\n", "feat1", "=", "feat1", ".", "view", "(", "-", "1", ",", "*", "feat1", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "", "feat2", "=", "self", ".", "extract_motion_feat", "(", "input2", ")", "\n", "feat2", "=", "feat2", ".", "view", "(", "-", "1", ",", "*", "feat2", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "dimp_score_cur", "=", "dimp_score_cur", ".", "view", "(", "-", "1", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "\n", "if", "isinstance", "(", "input1", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "cost_volume", "=", "[", "self", ".", "compute_cost_volume", "(", "f1", ",", "feat2", ",", "True", ")", "for", "f1", "in", "feat1", "]", "\n", "", "else", ":", "\n", "            ", "cost_volume", "=", "self", ".", "compute_cost_volume", "(", "feat1", ",", "feat2", ",", "True", ")", "\n", "\n", "", "feat_map_size", "=", "torch", ".", "tensor", "(", "[", "dimp_score_cur", ".", "shape", "[", "-", "1", "]", ",", "dimp_score_cur", ".", "shape", "[", "-", "2", "]", "]", ")", ".", "view", "(", "1", ",", "2", ")", ".", "float", "(", ")", ".", "to", "(", "dimp_score_cur", ".", "device", ")", "\n", "if", "self", ".", "fix_coordinate_shift", ":", "\n", "            ", "shift_value", "=", "-", "torch", ".", "ones", "(", "dimp_score_cur", ".", "shape", "[", "0", "]", ",", "2", ")", ".", "to", "(", "dimp_score_cur", ".", "device", ")", "*", "0.5", "/", "feat_map_size", "\n", "\n", "if", "label_prev", "is", "not", "None", ":", "\n", "                ", "label_prev_shape", "=", "label_prev", ".", "shape", "\n", "label_prev", "=", "shift_features", "(", "label_prev", ".", "clone", "(", ")", ".", "view", "(", "-", "1", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "shift_value", ")", ".", "view", "(", "label_prev_shape", ")", "\n", "\n", "", "dimp_score_cur", "=", "shift_features", "(", "dimp_score_cur", ".", "clone", "(", ")", ",", "shift_value", ")", "\n", "\n", "", "pred_response", ",", "state_new", ",", "auxiliary_outputs", "=", "self", ".", "predictor", "(", "cost_volume", ",", "state_prev", ",", "dimp_score_cur", ",", "label_prev", ")", "\n", "pred_response", "=", "pred_response", ".", "view", "(", "score_shape", ")", "\n", "\n", "# Shift back", "\n", "if", "self", ".", "fix_coordinate_shift", ":", "\n", "            ", "shift_value", "=", "torch", ".", "ones", "(", "dimp_score_cur", ".", "shape", "[", "0", "]", ",", "2", ")", ".", "to", "(", "dimp_score_cur", ".", "device", ")", "*", "0.5", "/", "feat_map_size", "\n", "\n", "if", "'is_target'", "in", "auxiliary_outputs", ":", "\n", "                ", "auxiliary_outputs", "[", "'is_target'", "]", "=", "shift_features", "(", "\n", "auxiliary_outputs", "[", "'is_target'", "]", ".", "view", "(", "-", "1", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "shift_value", ")", ".", "view", "(", "score_shape", ")", "\n", "\n", "", "if", "'is_target_after_prop'", "in", "auxiliary_outputs", ":", "\n", "                ", "auxiliary_outputs", "[", "'is_target_after_prop'", "]", "=", "shift_features", "(", "\n", "auxiliary_outputs", "[", "'is_target_after_prop'", "]", ".", "view", "(", "-", "1", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "shift_value", ")", ".", "view", "(", "score_shape", ")", "\n", "\n", "", "if", "'is_target_new'", "in", "auxiliary_outputs", ":", "\n", "                ", "auxiliary_outputs", "[", "'is_target_new'", "]", "=", "shift_features", "(", "\n", "auxiliary_outputs", "[", "'is_target_new'", "]", ".", "view", "(", "-", "1", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "shift_value", ")", ".", "view", "(", "score_shape", ")", "\n", "\n", "", "pred_response", "=", "shift_features", "(", "pred_response", ".", "view", "(", "-", "1", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "shift_value", ")", ".", "view", "(", "score_shape", ")", "\n", "\n", "", "output", "=", "{", "'response'", ":", "pred_response", ",", "'state_cur'", ":", "state_new", ",", "'auxiliary_outputs'", ":", "auxiliary_outputs", "}", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.compute_cost_volume": [[75, 81], ["predictor_wrapper.PredictorWrapper.cost_volume", "predictor_wrapper.PredictorWrapper.cost_volume"], "methods", ["None"], ["", "def", "compute_cost_volume", "(", "self", ",", "feat_prev", ",", "feat_cur", ",", "use_current_frame_as_ref", ")", ":", "\n", "        ", "if", "use_current_frame_as_ref", ":", "\n", "            ", "cost_volume", "=", "self", ".", "cost_volume", "(", "feat_cur", ",", "feat_prev", ")", "\n", "", "else", ":", "\n", "            ", "cost_volume", "=", "self", ".", "cost_volume", "(", "feat_prev", ",", "feat_cur", ")", "\n", "", "return", "cost_volume", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.extract_motion_feat": [[82, 87], ["backbone_feat.view.view.view"], "methods", ["None"], ["", "def", "extract_motion_feat", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "backbone_feat", "=", "backbone_feat", ".", "view", "(", "-", "1", ",", "backbone_feat", ".", "shape", "[", "-", "3", "]", ",", "backbone_feat", ".", "shape", "[", "-", "2", "]", ",", "\n", "backbone_feat", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "return", "backbone_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.predict_response": [[88, 154], ["data.get", "isinstance", "feat2.view.view.view", "ltr.models.kys.utils.shift_features.view", "isinstance", "torch.tensor().view().float().to", "torch.tensor().view().float().to", "torch.tensor().view().float().to", "torch.tensor().view().float().to", "predictor_wrapper.PredictorWrapper.predictor", "ltr.models.kys.utils.shift_features().view.view", "feat1.view.view.view", "predictor_wrapper.PredictorWrapper.compute_cost_volume", "ltr.models.kys.utils.shift_features", "ltr.models.kys.utils.shift_features().view", "f1.view", "predictor_wrapper.PredictorWrapper.compute_cost_volume", "torch.tensor().view().float", "torch.tensor().view().float", "torch.tensor().view().float", "torch.tensor().view().float", "ltr.models.kys.utils.shift_features().view", "ltr.models.kys.utils.shift_features.clone", "ltr.models.kys.utils.shift_features().view", "ltr.models.kys.utils.shift_features().view", "ltr.models.kys.utils.shift_features().view", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "ltr.models.kys.utils.shift_features", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "ltr.models.kys.utils.shift_features", "ltr.models.kys.utils.shift_features", "ltr.models.kys.utils.shift_features", "ltr.models.kys.utils.shift_features", "ltr.models.kys.utils.shift_features().view.view", "ltr.models.kys.utils.shift_features().view.clone().view", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "auxiliary_outputs[].view", "auxiliary_outputs[].view", "auxiliary_outputs[].view", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "ltr.models.kys.utils.shift_features().view.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.compute_cost_volume", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.compute_cost_volume", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.shift_features"], ["", "def", "predict_response", "(", "self", ",", "data", ",", "dimp_thresh", "=", "None", ",", "output_window", "=", "None", ")", ":", "\n", "        ", "feat1", "=", "data", "[", "'feat1'", "]", "\n", "feat2", "=", "data", "[", "'feat2'", "]", "\n", "label_prev", "=", "data", ".", "get", "(", "'label_prev'", ",", "None", ")", "\n", "\n", "dimp_score_cur", "=", "data", "[", "'dimp_score_cur'", "]", "\n", "state_prev", "=", "data", "[", "'state_prev'", "]", "\n", "\n", "score_shape", "=", "dimp_score_cur", ".", "shape", "\n", "\n", "if", "isinstance", "(", "feat1", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "feat1", "=", "[", "f1", ".", "view", "(", "-", "1", ",", "*", "f1", ".", "shape", "[", "-", "3", ":", "]", ")", "for", "f1", "in", "feat1", "]", "\n", "", "else", ":", "\n", "            ", "feat1", "=", "feat1", ".", "view", "(", "-", "1", ",", "*", "feat1", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "", "feat2", "=", "feat2", ".", "view", "(", "-", "1", ",", "*", "feat2", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "dimp_score_cur", "=", "dimp_score_cur", ".", "view", "(", "-", "1", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "\n", "if", "isinstance", "(", "feat1", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "cost_volume", "=", "[", "self", ".", "compute_cost_volume", "(", "f1", ",", "feat2", ",", "True", ")", "for", "f1", "in", "feat1", "]", "\n", "", "else", ":", "\n", "            ", "cost_volume", "=", "self", ".", "compute_cost_volume", "(", "feat1", ",", "feat2", ",", "True", ")", "\n", "\n", "", "feat_map_size", "=", "torch", ".", "tensor", "(", "[", "dimp_score_cur", ".", "shape", "[", "-", "1", "]", ",", "dimp_score_cur", ".", "shape", "[", "-", "2", "]", "]", ")", ".", "view", "(", "1", ",", "2", ")", ".", "float", "(", ")", ".", "to", "(", "\n", "dimp_score_cur", ".", "device", ")", "\n", "if", "self", ".", "fix_coordinate_shift", ":", "\n", "            ", "shift_value", "=", "-", "torch", ".", "ones", "(", "dimp_score_cur", ".", "shape", "[", "0", "]", ",", "2", ")", ".", "to", "(", "dimp_score_cur", ".", "device", ")", "*", "0.5", "/", "feat_map_size", "\n", "\n", "if", "label_prev", "is", "not", "None", ":", "\n", "                ", "label_prev_shape", "=", "label_prev", ".", "shape", "\n", "label_prev", "=", "shift_features", "(", "label_prev", ".", "clone", "(", ")", ".", "view", "(", "-", "1", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "\n", "shift_value", ")", ".", "view", "(", "label_prev_shape", ")", "\n", "\n", "", "dimp_score_cur", "=", "shift_features", "(", "dimp_score_cur", ".", "clone", "(", ")", ",", "shift_value", ")", "\n", "\n", "", "pred_response", ",", "state_new", ",", "auxiliary_outputs", "=", "self", ".", "predictor", "(", "cost_volume", ",", "state_prev", ",", "dimp_score_cur", ",", "\n", "label_prev", ",", "dimp_thresh", ",", "output_window", ")", "\n", "\n", "pred_response", "=", "pred_response", ".", "view", "(", "score_shape", ")", "\n", "\n", "# Shift back", "\n", "if", "self", ".", "fix_coordinate_shift", ":", "\n", "            ", "shift_value", "=", "torch", ".", "ones", "(", "dimp_score_cur", ".", "shape", "[", "0", "]", ",", "2", ")", ".", "to", "(", "dimp_score_cur", ".", "device", ")", "*", "0.5", "/", "feat_map_size", "\n", "\n", "if", "'is_target'", "in", "auxiliary_outputs", ":", "\n", "                ", "auxiliary_outputs", "[", "'is_target'", "]", "=", "shift_features", "(", "\n", "auxiliary_outputs", "[", "'is_target'", "]", ".", "view", "(", "-", "1", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "shift_value", ")", ".", "view", "(", "\n", "score_shape", ")", "\n", "\n", "", "if", "'is_target_after_prop'", "in", "auxiliary_outputs", ":", "\n", "                ", "auxiliary_outputs", "[", "'is_target_after_prop'", "]", "=", "shift_features", "(", "\n", "auxiliary_outputs", "[", "'is_target_after_prop'", "]", ".", "view", "(", "-", "1", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "\n", "shift_value", ")", ".", "view", "(", "score_shape", ")", "\n", "\n", "", "if", "'is_target_new'", "in", "auxiliary_outputs", ":", "\n", "                ", "auxiliary_outputs", "[", "'is_target_new'", "]", "=", "shift_features", "(", "\n", "auxiliary_outputs", "[", "'is_target_new'", "]", ".", "view", "(", "-", "1", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "shift_value", ")", ".", "view", "(", "\n", "score_shape", ")", "\n", "\n", "", "pred_response", "=", "shift_features", "(", "pred_response", ".", "view", "(", "-", "1", ",", "1", ",", "*", "dimp_score_cur", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "shift_value", ")", ".", "view", "(", "\n", "score_shape", ")", "\n", "\n", "", "output", "=", "{", "'response'", ":", "pred_response", ",", "'state_cur'", ":", "state_new", ",", "'auxiliary_outputs'", ":", "auxiliary_outputs", ",", "\n", "'cost_volume'", ":", "cost_volume", "}", "\n", "\n", "return", "output", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom_gmm_sampl.parameters": [[6, 106], ["pytracking.utils.TrackerParams", "pytracking.utils.TrackerParams", "torch.ones", "pytracking.utils.FeatureParams", "pytracking.features.deep.ATOMResNet18", "pytracking.features.extractor.MultiResolutionExtractor"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "# These are usually set from outside", "\n", "params", ".", "debug", "=", "0", "# Debug level", "\n", "params", ".", "visualization", "=", "False", "# Do visualization", "\n", "\n", "# Use GPU or not (IoUNet requires this to be True)", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "# Feature specific parameters", "\n", "deep_params", "=", "TrackerParams", "(", ")", "\n", "\n", "# Patch sampling parameters", "\n", "params", ".", "max_image_sample_size", "=", "(", "18", "*", "16", ")", "**", "2", "# Maximum image sample size", "\n", "params", ".", "min_image_sample_size", "=", "(", "18", "*", "16", ")", "**", "2", "# Minimum image sample size", "\n", "params", ".", "search_area_scale", "=", "5", "# Scale relative to target size", "\n", "params", ".", "feature_size_odd", "=", "False", "# Good to use False for even-sized kernels and vice versa", "\n", "\n", "# Optimization parameters", "\n", "params", ".", "CG_iter", "=", "5", "# The number of Conjugate Gradient iterations in each update after the first frame", "\n", "params", ".", "init_CG_iter", "=", "60", "# The total number of Conjugate Gradient iterations used in the first frame", "\n", "params", ".", "init_GN_iter", "=", "6", "# The number of Gauss-Newton iterations used in the first frame (only if the projection matrix is updated)", "\n", "params", ".", "post_init_CG_iter", "=", "0", "# CG iterations to run after GN", "\n", "params", ".", "fletcher_reeves", "=", "False", "# Use the Fletcher-Reeves (true) or Polak-Ribiere (false) formula in the Conjugate Gradient", "\n", "params", ".", "standard_alpha", "=", "True", "# Use the standard formula for computing the step length in Conjugate Gradient", "\n", "params", ".", "CG_forgetting_rate", "=", "None", "# Forgetting rate of the last conjugate direction", "\n", "\n", "# Learning parameters for each feature type", "\n", "deep_params", ".", "learning_rate", "=", "0.01", "# Learning rate", "\n", "deep_params", ".", "init_samples_minimum_weight", "=", "0.25", "# Minimum weight of initial samples in memory", "\n", "deep_params", ".", "output_sigma_factor", "=", "1", "/", "4", "# Standard deviation of Gaussian label relative to target size", "\n", "\n", "# Training parameters", "\n", "params", ".", "sample_memory_size", "=", "250", "# Memory size", "\n", "params", ".", "train_skipping", "=", "10", "# How often to run training (every n-th frame)", "\n", "\n", "# Online model parameters", "\n", "deep_params", ".", "kernel_size", "=", "(", "4", ",", "4", ")", "# Kernel size of filter", "\n", "deep_params", ".", "compressed_dim", "=", "64", "# Dimension output of projection matrix", "\n", "deep_params", ".", "filter_reg", "=", "1e-1", "# Filter regularization factor", "\n", "deep_params", ".", "projection_reg", "=", "1e-4", "# Projection regularization factor", "\n", "\n", "# Windowing", "\n", "params", ".", "feature_window", "=", "False", "# Perform windowing of features", "\n", "params", ".", "window_output", "=", "False", "# Perform windowing of output scores", "\n", "\n", "# Detection parameters", "\n", "params", ".", "scale_factors", "=", "torch", ".", "ones", "(", "1", ")", "# What scales to use for localization (only one scale if IoUNet is used)", "\n", "params", ".", "score_upsample_factor", "=", "1", "# How much Fourier upsampling to use", "\n", "\n", "# Init data augmentation parameters", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "# How much to expand sample when doing augmentation", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "# How much random shift to do on each augmented sample", "\n", "deep_params", ".", "use_augmentation", "=", "True", "# Whether to use augmentation for this feature", "\n", "\n", "# Factorized convolution parameters", "\n", "# params.use_projection_matrix = True       # Use projection matrix, i.e. use the factorized convolution formulation", "\n", "params", ".", "update_projection_matrix", "=", "True", "# Whether the projection matrix should be optimized or not", "\n", "params", ".", "proj_init_method", "=", "'randn'", "# Method for initializing the projection matrix", "\n", "params", ".", "filter_init_method", "=", "'randn'", "# Method for initializing the spatial filter", "\n", "params", ".", "projection_activation", "=", "'none'", "# Activation function after projection ('none', 'relu', 'elu' or 'mlu')", "\n", "params", ".", "response_activation", "=", "(", "'mlu'", ",", "0.05", ")", "# Activation function on the output scores ('none', 'relu', 'elu' or 'mlu')", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "# Use this or not", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "# Absolute score threshold to detect target missing", "\n", "params", ".", "distractor_threshold", "=", "0.8", "# Relative threshold to find distractors", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "# Relative threshold to find hard negative samples", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "# Target neighborhood to remove", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "# Dispacement to consider for distractors", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "# Learning rate if hard negative detected", "\n", "params", ".", "hard_negative_CG_iter", "=", "5", "# Number of optimization iterations to use if hard negative detected", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "# Update scale or not if distractor is close", "\n", "\n", "# IoUNet parameters", "\n", "params", ".", "use_iou_net", "=", "True", "# Use IoU net or not", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "(", "1e-2", ",", "5e-2", ")", "# 1   # Gradient step length in the bounding box refinement 5e-3 2e-2", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "# Setup the feature extractor (which includes the IoUNet)", "\n", "deep_fparams", "=", "FeatureParams", "(", "feature_params", "=", "[", "deep_params", "]", ")", "\n", "deep_feat", "=", "deep", ".", "ATOMResNet18", "(", "net_path", "=", "'atom_gmm_sampl'", ",", "output_layers", "=", "[", "'layer3'", "]", ",", "fparams", "=", "deep_fparams", ",", "normalize_power", "=", "2", ")", "\n", "params", ".", "features", "=", "MultiResolutionExtractor", "(", "[", "deep_feat", "]", ")", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.multiscale_no_iounet.parameters": [[6, 105], ["pytracking.utils.TrackerParams", "pytracking.utils.TrackerParams", "pytracking.utils.FeatureParams", "pytracking.features.deep.ATOMResNet18", "pytracking.features.extractor.MultiResolutionExtractor", "torch.arange().float", "torch.arange"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "# These are usually set from outside", "\n", "params", ".", "debug", "=", "0", "# Debug level", "\n", "params", ".", "visualization", "=", "False", "# Do visualization", "\n", "\n", "# Use GPU or not (IoUNet requires this to be True)", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "# Feature specific parameters", "\n", "deep_params", "=", "TrackerParams", "(", ")", "\n", "\n", "# Patch sampling parameters", "\n", "params", ".", "max_image_sample_size", "=", "(", "18", "*", "16", ")", "**", "2", "# Maximum image sample size", "\n", "params", ".", "min_image_sample_size", "=", "(", "18", "*", "16", ")", "**", "2", "# Minimum image sample size", "\n", "params", ".", "search_area_scale", "=", "5", "# Scale relative to target size", "\n", "params", ".", "feature_size_odd", "=", "False", "# Good to use False for even-sized kernels and vice versa", "\n", "\n", "# Optimization parameters", "\n", "params", ".", "CG_iter", "=", "5", "# The number of Conjugate Gradient iterations in each update after the first frame", "\n", "params", ".", "init_CG_iter", "=", "60", "# The total number of Conjugate Gradient iterations used in the first frame", "\n", "params", ".", "init_GN_iter", "=", "6", "# The number of Gauss-Newton iterations used in the first frame (only if the projection matrix is updated)", "\n", "params", ".", "post_init_CG_iter", "=", "0", "# CG iterations to run after GN", "\n", "params", ".", "fletcher_reeves", "=", "False", "# Use the Fletcher-Reeves (true) or Polak-Ribiere (false) formula in the Conjugate Gradient", "\n", "params", ".", "standard_alpha", "=", "True", "# Use the standard formula for computing the step length in Conjugate Gradient", "\n", "params", ".", "CG_forgetting_rate", "=", "None", "# Forgetting rate of the last conjugate direction", "\n", "\n", "# Learning parameters for each feature type", "\n", "deep_params", ".", "learning_rate", "=", "0.01", "# Learning rate", "\n", "deep_params", ".", "init_samples_minimum_weight", "=", "0.25", "# Minimum weight of initial samples in memory", "\n", "deep_params", ".", "output_sigma_factor", "=", "1", "/", "4", "# Standard deviation of Gaussian label relative to target size", "\n", "\n", "# Training parameters", "\n", "params", ".", "sample_memory_size", "=", "250", "# Memory size", "\n", "params", ".", "train_skipping", "=", "10", "# How often to run training (every n-th frame)", "\n", "\n", "# Online model parameters", "\n", "deep_params", ".", "kernel_size", "=", "(", "4", ",", "4", ")", "# Kernel size of filter", "\n", "deep_params", ".", "compressed_dim", "=", "64", "# Dimension output of projection matrix", "\n", "deep_params", ".", "filter_reg", "=", "1e-1", "# Filter regularization factor", "\n", "deep_params", ".", "projection_reg", "=", "1e-4", "# Projection regularization factor", "\n", "\n", "# Windowing", "\n", "params", ".", "feature_window", "=", "False", "# Perform windowing of features", "\n", "params", ".", "window_output", "=", "False", "# Perform windowing of output scores", "\n", "\n", "# Detection parameters", "\n", "params", ".", "scale_factors", "=", "1.02", "**", "torch", ".", "arange", "(", "-", "2", ",", "3", ")", ".", "float", "(", ")", "# What scales to use for localization (only one scale if IoUNet is used)", "\n", "params", ".", "score_upsample_factor", "=", "1", "# How much Fourier upsampling to use", "\n", "\n", "# Init data augmentation parameters", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "# How much to expand sample when doing augmentation", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "# How much random shift to do on each augmented sample", "\n", "deep_params", ".", "use_augmentation", "=", "True", "# Whether to use augmentation for this feature", "\n", "\n", "# Factorized convolution parameters", "\n", "# params.use_projection_matrix = True       # Use projection matrix, i.e. use the factorized convolution formulation", "\n", "params", ".", "update_projection_matrix", "=", "True", "# Whether the projection matrix should be optimized or not", "\n", "params", ".", "proj_init_method", "=", "'randn'", "# Method for initializing the projection matrix", "\n", "params", ".", "filter_init_method", "=", "'randn'", "# Method for initializing the spatial filter", "\n", "params", ".", "projection_activation", "=", "'none'", "# Activation function after projection ('none', 'relu', 'elu' or 'mlu')", "\n", "params", ".", "response_activation", "=", "(", "'mlu'", ",", "0.05", ")", "# Activation function on the output scores ('none', 'relu', 'elu' or 'mlu')", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "# Use this or not", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "# Absolute score threshold to detect target missing", "\n", "params", ".", "distractor_threshold", "=", "0.8", "# Relative threshold to find distractors", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "# Relative threshold to find hard negative samples", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "# Target neighborhood to remove", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "# Dispacement to consider for distractors", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "# Learning rate if hard negative detected", "\n", "params", ".", "hard_negative_CG_iter", "=", "5", "# Number of optimization iterations to use if hard negative detected", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "# Update scale or not if distractor is close", "\n", "\n", "# IoUNet parameters", "\n", "params", ".", "use_iou_net", "=", "False", "# Use IoU net or not", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "5", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "1", "# Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "# Setup the feature extractor (which includes the IoUNet)", "\n", "deep_fparams", "=", "FeatureParams", "(", "feature_params", "=", "[", "deep_params", "]", ")", "\n", "deep_feat", "=", "deep", ".", "ATOMResNet18", "(", "net_path", "=", "'atom_default.pth'", ",", "output_layers", "=", "[", "'layer3'", "]", ",", "fparams", "=", "deep_fparams", ",", "normalize_power", "=", "2", ")", "\n", "params", ".", "features", "=", "MultiResolutionExtractor", "(", "[", "deep_feat", "]", ")", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.default.parameters": [[6, 105], ["pytracking.utils.TrackerParams", "pytracking.utils.TrackerParams", "torch.ones", "pytracking.utils.FeatureParams", "pytracking.features.deep.ATOMResNet18", "pytracking.features.extractor.MultiResolutionExtractor"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "# Feature specific parameters", "\n", "shallow_params", "=", "TrackerParams", "(", ")", "\n", "deep_params", "=", "TrackerParams", "(", ")", "\n", "\n", "# Patch sampling parameters", "\n", "params", ".", "max_image_sample_size", "=", "250", "**", "2", "# Maximum image sample size", "\n", "params", ".", "min_image_sample_size", "=", "200", "**", "2", "# Minimum image sample size", "\n", "params", ".", "search_area_scale", "=", "4.5", "# Scale relative to target size", "\n", "\n", "# Conjugate Gradient parameters", "\n", "params", ".", "CG_iter", "=", "5", "# The number of Conjugate Gradient iterations in each update after the first frame", "\n", "params", ".", "init_CG_iter", "=", "100", "# The total number of Conjugate Gradient iterations used in the first frame", "\n", "params", ".", "init_GN_iter", "=", "10", "# The number of Gauss-Newton iterations used in the first frame (only if the projection matrix is updated)", "\n", "params", ".", "post_init_CG_iter", "=", "0", "# CG iterations to run after GN", "\n", "params", ".", "fletcher_reeves", "=", "False", "# Use the Fletcher-Reeves (true) or Polak-Ribiere (false) formula in the Conjugate Gradient", "\n", "params", ".", "standard_alpha", "=", "True", "# Use the standard formula for computing the step length in Conjugate Gradient", "\n", "params", ".", "CG_forgetting_rate", "=", "75", "# Forgetting rate of the last conjugate direction", "\n", "params", ".", "precond_data_param", "=", "0.3", "# Weight of the data term in the preconditioner", "\n", "params", ".", "precond_reg_param", "=", "0.15", "# Weight of the regularization term in the preconditioner", "\n", "params", ".", "precond_proj_param", "=", "35", "# Weight of the projection matrix part in the preconditioner", "\n", "\n", "# Learning parameters", "\n", "shallow_params", ".", "learning_rate", "=", "0.025", "\n", "deep_params", ".", "learning_rate", "=", "0.0075", "\n", "shallow_params", ".", "output_sigma_factor", "=", "1", "/", "16", "\n", "deep_params", ".", "output_sigma_factor", "=", "1", "/", "4", "\n", "\n", "# Training parameters", "\n", "params", ".", "sample_memory_size", "=", "200", "# Memory size", "\n", "params", ".", "train_skipping", "=", "10", "# How often to run training (every n-th frame)", "\n", "\n", "# Detection parameters", "\n", "params", ".", "scale_factors", "=", "1.02", "**", "torch", ".", "arange", "(", "-", "2", ",", "3", ")", ".", "float", "(", ")", "# What scales to use for localization", "\n", "params", ".", "score_upsample_factor", "=", "1", "# How much Fourier upsampling to use", "\n", "params", ".", "score_fusion_strategy", "=", "'weightedsum'", "# Fusion strategy", "\n", "shallow_params", ".", "translation_weight", "=", "0.4", "# Weight of this feature", "\n", "deep_params", ".", "translation_weight", "=", "1", "-", "shallow_params", ".", "translation_weight", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'shift'", ":", "[", "(", "6", ",", "6", ")", ",", "(", "-", "6", ",", "6", ")", ",", "(", "6", ",", "-", "6", ")", ",", "(", "-", "6", ",", "-", "6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "# Whether to use augmentation for this feature", "\n", "deep_params", ".", "use_augmentation", "=", "True", "\n", "shallow_params", ".", "use_augmentation", "=", "True", "\n", "\n", "# Factorized convolution parameters", "\n", "# params.use_projection_matrix = True    # Use projection matrix, i.e. use the factorized convolution formulation", "\n", "params", ".", "update_projection_matrix", "=", "True", "# Whether the projection matrix should be optimized or not", "\n", "# params.proj_init_method = 'pca'        # Method for initializing the projection matrix", "\n", "params", ".", "projection_reg", "=", "5e-8", "# Regularization parameter of the projection matrix", "\n", "shallow_params", ".", "compressed_dim", "=", "16", "# Dimension output of projection matrix for shallow features", "\n", "deep_params", ".", "compressed_dim", "=", "64", "# Dimension output of projection matrix for deep features", "\n", "\n", "# Interpolation parameters", "\n", "params", ".", "interpolation_method", "=", "'bicubic'", "# The kind of interpolation kernel", "\n", "params", ".", "interpolation_bicubic_a", "=", "-", "0.75", "# The parameter for the bicubic interpolation kernel", "\n", "params", ".", "interpolation_centering", "=", "True", "# Center the kernel at the feature sample", "\n", "params", ".", "interpolation_windowing", "=", "False", "# Do additional windowing on the Fourier coefficients of the kernel", "\n", "\n", "# Regularization parameters", "\n", "shallow_params", ".", "use_reg_window", "=", "True", "# Use spatial regularization or not", "\n", "shallow_params", ".", "reg_window_min", "=", "1e-4", "# The minimum value of the regularization window", "\n", "shallow_params", ".", "reg_window_edge", "=", "10e-3", "# The impact of the spatial regularization", "\n", "shallow_params", ".", "reg_window_power", "=", "2", "# The degree of the polynomial to use (e.g. 2 is a quadratic window)", "\n", "shallow_params", ".", "reg_sparsity_threshold", "=", "0.05", "# A relative threshold of which DFT coefficients that should be set to zero", "\n", "\n", "deep_params", ".", "use_reg_window", "=", "True", "# Use spatial regularization or not", "\n", "deep_params", ".", "reg_window_min", "=", "10e-4", "# The minimum value of the regularization window", "\n", "deep_params", ".", "reg_window_edge", "=", "50e-3", "# The impact of the spatial regularization", "\n", "deep_params", ".", "reg_window_power", "=", "2", "# The degree of the polynomial to use (e.g. 2 is a quadratic window)", "\n", "deep_params", ".", "reg_sparsity_threshold", "=", "0.1", "# A relative threshold of which DFT coefficients that should be set to zero", "\n", "\n", "\n", "fparams", "=", "FeatureParams", "(", "feature_params", "=", "[", "shallow_params", ",", "deep_params", "]", ")", "\n", "features", "=", "deep", ".", "ResNet18m1", "(", "output_layers", "=", "[", "'vggconv1'", ",", "'layer3'", "]", ",", "use_gpu", "=", "params", ".", "use_gpu", ",", "fparams", "=", "fparams", ",", "\n", "pool_stride", "=", "[", "2", ",", "1", "]", ",", "normalize_power", "=", "2", ")", "\n", "\n", "params", ".", "features", "=", "MultiResolutionExtractor", "(", "[", "features", "]", ")", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom_prob_ml.parameters": [[6, 106], ["pytracking.utils.TrackerParams", "pytracking.utils.TrackerParams", "torch.ones", "pytracking.utils.FeatureParams", "pytracking.features.deep.ATOMResNet18", "pytracking.features.extractor.MultiResolutionExtractor"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "# These are usually set from outside", "\n", "params", ".", "debug", "=", "0", "# Debug level", "\n", "params", ".", "visualization", "=", "False", "# Do visualization", "\n", "\n", "# Use GPU or not (IoUNet requires this to be True)", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "# Feature specific parameters", "\n", "deep_params", "=", "TrackerParams", "(", ")", "\n", "\n", "# Patch sampling parameters", "\n", "params", ".", "max_image_sample_size", "=", "(", "18", "*", "16", ")", "**", "2", "# Maximum image sample size", "\n", "params", ".", "min_image_sample_size", "=", "(", "18", "*", "16", ")", "**", "2", "# Minimum image sample size", "\n", "params", ".", "search_area_scale", "=", "5", "# Scale relative to target size", "\n", "params", ".", "feature_size_odd", "=", "False", "# Good to use False for even-sized kernels and vice versa", "\n", "\n", "# Optimization parameters", "\n", "params", ".", "CG_iter", "=", "5", "# The number of Conjugate Gradient iterations in each update after the first frame", "\n", "params", ".", "init_CG_iter", "=", "60", "# The total number of Conjugate Gradient iterations used in the first frame", "\n", "params", ".", "init_GN_iter", "=", "6", "# The number of Gauss-Newton iterations used in the first frame (only if the projection matrix is updated)", "\n", "params", ".", "post_init_CG_iter", "=", "0", "# CG iterations to run after GN", "\n", "params", ".", "fletcher_reeves", "=", "False", "# Use the Fletcher-Reeves (true) or Polak-Ribiere (false) formula in the Conjugate Gradient", "\n", "params", ".", "standard_alpha", "=", "True", "# Use the standard formula for computing the step length in Conjugate Gradient", "\n", "params", ".", "CG_forgetting_rate", "=", "None", "# Forgetting rate of the last conjugate direction", "\n", "\n", "# Learning parameters for each feature type", "\n", "deep_params", ".", "learning_rate", "=", "0.01", "# Learning rate", "\n", "deep_params", ".", "init_samples_minimum_weight", "=", "0.25", "# Minimum weight of initial samples in memory", "\n", "deep_params", ".", "output_sigma_factor", "=", "1", "/", "4", "# Standard deviation of Gaussian label relative to target size", "\n", "\n", "# Training parameters", "\n", "params", ".", "sample_memory_size", "=", "250", "# Memory size", "\n", "params", ".", "train_skipping", "=", "10", "# How often to run training (every n-th frame)", "\n", "\n", "# Online model parameters", "\n", "deep_params", ".", "kernel_size", "=", "(", "4", ",", "4", ")", "# Kernel size of filter", "\n", "deep_params", ".", "compressed_dim", "=", "64", "# Dimension output of projection matrix", "\n", "deep_params", ".", "filter_reg", "=", "1e-1", "# Filter regularization factor", "\n", "deep_params", ".", "projection_reg", "=", "1e-4", "# Projection regularization factor", "\n", "\n", "# Windowing", "\n", "params", ".", "feature_window", "=", "False", "# Perform windowing of features", "\n", "params", ".", "window_output", "=", "False", "# Perform windowing of output scores", "\n", "\n", "# Detection parameters", "\n", "params", ".", "scale_factors", "=", "torch", ".", "ones", "(", "1", ")", "# What scales to use for localization (only one scale if IoUNet is used)", "\n", "params", ".", "score_upsample_factor", "=", "1", "# How much Fourier upsampling to use", "\n", "\n", "# Init data augmentation parameters", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "# How much to expand sample when doing augmentation", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "# How much random shift to do on each augmented sample", "\n", "deep_params", ".", "use_augmentation", "=", "True", "# Whether to use augmentation for this feature", "\n", "\n", "# Factorized convolution parameters", "\n", "# params.use_projection_matrix = True       # Use projection matrix, i.e. use the factorized convolution formulation", "\n", "params", ".", "update_projection_matrix", "=", "True", "# Whether the projection matrix should be optimized or not", "\n", "params", ".", "proj_init_method", "=", "'randn'", "# Method for initializing the projection matrix", "\n", "params", ".", "filter_init_method", "=", "'randn'", "# Method for initializing the spatial filter", "\n", "params", ".", "projection_activation", "=", "'none'", "# Activation function after projection ('none', 'relu', 'elu' or 'mlu')", "\n", "params", ".", "response_activation", "=", "(", "'mlu'", ",", "0.05", ")", "# Activation function on the output scores ('none', 'relu', 'elu' or 'mlu')", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "# Use this or not", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "# Absolute score threshold to detect target missing", "\n", "params", ".", "distractor_threshold", "=", "0.8", "# Relative threshold to find distractors", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "# Relative threshold to find hard negative samples", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "# Target neighborhood to remove", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "# Dispacement to consider for distractors", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "# Learning rate if hard negative detected", "\n", "params", ".", "hard_negative_CG_iter", "=", "5", "# Number of optimization iterations to use if hard negative detected", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "# Update scale or not if distractor is close", "\n", "\n", "# IoUNet parameters", "\n", "params", ".", "use_iou_net", "=", "True", "# Use IoU net or not", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "(", "2e-4", ",", "10e-4", ")", "# 1   # Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n", "\n", "# Setup the feature extractor (which includes the IoUNet)", "\n", "deep_fparams", "=", "FeatureParams", "(", "feature_params", "=", "[", "deep_params", "]", ")", "\n", "deep_feat", "=", "deep", ".", "ATOMResNet18", "(", "net_path", "=", "'atom_prob_ml'", ",", "output_layers", "=", "[", "'layer3'", "]", ",", "fparams", "=", "deep_fparams", ",", "normalize_power", "=", "2", ")", "\n", "params", ".", "features", "=", "MultiResolutionExtractor", "(", "[", "deep_feat", "]", ")", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.default_vot.parameters": [[6, 105], ["pytracking.utils.TrackerParams", "pytracking.utils.TrackerParams", "torch.ones", "pytracking.utils.FeatureParams", "pytracking.features.deep.ATOMResNet18", "pytracking.features.extractor.MultiResolutionExtractor"], "function", ["None"], ["    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "image_sample_size", "=", "14", "*", "16", "\n", "params", ".", "search_area_scale", "=", "4", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "250", "\n", "params", ".", "learning_rate", "=", "0.0075", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.0", "\n", "params", ".", "train_skipping", "=", "10", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "25", "\n", "params", ".", "net_opt_update_iter", "=", "3", "\n", "params", ".", "net_opt_hn_iter", "=", "3", "\n", "\n", "params", ".", "output_sigma_factor", "=", "1", "/", "4", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "True", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# localization parameters", "\n", "params", ".", "window_output", "=", "True", "\n", "params", ".", "use_clipped_window", "=", "True", "\n", "params", ".", "effective_search_area", "=", "4.0", "\n", "params", ".", "apply_window_to_dimp_score", "=", "True", "\n", "\n", "params", ".", "target_not_found_threshold_fused", "=", "0.05", "\n", "params", ".", "dimp_threshold", "=", "0.05", "\n", "\n", "params", ".", "reset_state_during_occlusion", "=", "True", "\n", "\n", "params", ".", "prev_feat_remove_subpixel_shift", "=", "True", "\n", "params", ".", "move_feat_to_center", "=", "True", "\n", "\n", "params", ".", "perform_hn_mining_dimp", "=", "True", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale_safe", "=", "2.2", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "\n", "# IoUnet parameters", "\n", "params", ".", "use_iou_net", "=", "True", "\n", "params", ".", "iounet_augmentation", "=", "False", "\n", "params", ".", "iounet_use_log_scale", "=", "True", "\n", "params", ".", "iounet_k", "=", "3", "\n", "params", ".", "num_init_random_boxes", "=", "9", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "\n", "params", ".", "box_refinement_iter", "=", "5", "\n", "params", ".", "box_refinement_step_length", "=", "1", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "\n", "\n", "params", ".", "remove_offset_in_fused_score", "=", "True", "\n", "params", ".", "score_downsample_factor", "=", "1", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'kys.pth'", ",", "\n", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.__init__.get_tracker_class": [[3, 5], ["None"], "function", ["None"], ["import", "pytracking", ".", "libs", ".", "operation", "as", "operation", "\n", "import", "pytracking", ".", "libs", ".", "fourier", "as", "fourier", "\n", "import", "pytracking", ".", "libs", ".", "dcf", "as", "dcf", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.optim.FactorizedConvProblem.__init__": [[7, 19], ["optim.FactorizedConvProblem.filter_reg.concat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.concat"], ["\n", "class", "FactorizedConvProblem", "(", "optimization", ".", "L2Problem", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "training_samples", ":", "TensorList", ",", "yf", ":", "TensorList", ",", "reg_filter", ":", "torch", ".", "Tensor", ",", "init_proj_mat", ":", "TensorList", ",", "params", ",", "sample_weights", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "        ", "self", ".", "training_samples", "=", "training_samples", "\n", "self", ".", "yf", "=", "complex", ".", "complex", "(", "yf", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ",", "4", ")", "\n", "self", ".", "reg_filter", "=", "reg_filter", "\n", "self", ".", "sample_weights_sqrt", "=", "None", "if", "sample_weights", "is", "None", "else", "sample_weights", ".", "sqrt", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "\n", "# Sample energy for preconditioner", "\n", "compressed_samples", "=", "complex", ".", "mtimes", "(", "self", ".", "training_samples", ",", "init_proj_mat", ")", "\n", "self", ".", "sample_energy", "=", "complex", ".", "abs_sqr", "(", "compressed_samples", ")", ".", "mean", "(", "dim", "=", "2", ",", "keepdim", "=", "True", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", "\n", "self", ".", "reg_energy", "=", "self", ".", "reg_filter", ".", "view", "(", "-", "1", ")", "@", "self", ".", "reg_filter", ".", "view", "(", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.optim.FactorizedConvProblem.__call__": [[20, 47], ["pytracking.operation.conv1x1().apply", "pytracking.operation.conv2d().apply", "pytracking.operation.conv2d().apply.extend", "pytracking.operation.conv2d().apply.extend", "optim.FactorizedConvProblem.sample_weights.sqrt().view", "pytracking.operation.conv1x1", "pytracking.operation.conv2d", "optim.FactorizedConvProblem.filter_reg.apply", "optim.FactorizedConvProblem.projection_reg.apply", "len", "len", "optim.FactorizedConvProblem.sample_weights.sqrt"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv1x1", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply"], ["\n", "# Projection energy for preconditioner", "\n", "self", ".", "proj_energy", "=", "2", "*", "fourier", ".", "inner_prod_fs", "(", "yf", ",", "yf", ")", "/", "self", ".", "training_samples", ".", "size", "(", "3", ")", "\n", "\n", "# Filter part of preconditioner", "\n", "self", ".", "diag_M", "=", "(", "1", "-", "self", ".", "params", ".", "precond_reg_param", ")", "*", "(", "self", ".", "params", ".", "precond_data_param", "*", "self", ".", "sample_energy", "+", "\n", "(", "1", "-", "self", ".", "params", ".", "precond_data_param", ")", "*", "self", ".", "sample_energy", ".", "mean", "(", "1", ",", "keepdim", "=", "True", ")", ")", "+", "self", ".", "params", ".", "precond_reg_param", "*", "self", ".", "reg_energy", "\n", "self", ".", "diag_M", ".", "unsqueeze_", "(", "-", "1", ")", "\n", "\n", "# Projection matrix part of preconditioner", "\n", "self", ".", "diag_M", ".", "extend", "(", "self", ".", "params", ".", "precond_proj_param", "*", "(", "self", ".", "proj_energy", "+", "self", ".", "params", ".", "projection_reg", ")", ")", "\n", "\n", "\n", "", "def", "__call__", "(", "self", ",", "x", ":", "TensorList", ")", ":", "\n", "        ", "\"\"\"\n        Compute residuals\n        :param x: [filters, projection_matrices]\n        :return: [data_terms, filter_regularizations, proj_mat_regularizations]\n        \"\"\"", "\n", "hf", "=", "x", "[", ":", "len", "(", "x", ")", "//", "2", "]", "\n", "P", "=", "x", "[", "len", "(", "x", ")", "//", "2", ":", "]", "\n", "\n", "compressed_samples", "=", "complex", ".", "mtimes", "(", "self", ".", "training_samples", ",", "P", ")", "\n", "residuals", "=", "complex", ".", "mtimes", "(", "compressed_samples", ",", "hf", ".", "permute", "(", "2", ",", "3", ",", "1", ",", "0", ",", "4", ")", ")", "# (h, w, num_samp, num_filt, 2)", "\n", "residuals", "=", "residuals", "-", "self", ".", "yf", "\n", "\n", "if", "self", ".", "sample_weights_sqrt", "is", "not", "None", ":", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.optim.FactorizedConvProblem.ip_input": [[49, 66], ["pytracking.operation.conv2d().view", "pytracking.operation.conv2d().view", "pytracking.operation.conv2d().view.concat", "len", "pytracking.operation.conv2d().view.clone", "pytracking.operation.conv2d", "pytracking.operation.conv2d", "a_P.view", "b_P.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.concat", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["\n", "\n", "# Add spatial regularization", "\n", "", "for", "hfe", ",", "reg_filter", "in", "zip", "(", "hf", ",", "self", ".", "reg_filter", ")", ":", "\n", "            ", "reg_pad1", "=", "min", "(", "reg_filter", ".", "shape", "[", "-", "2", "]", "-", "1", ",", "hfe", ".", "shape", "[", "-", "3", "]", "-", "1", ")", "\n", "reg_pad2", "=", "min", "(", "reg_filter", ".", "shape", "[", "-", "1", "]", "-", "1", ",", "hfe", ".", "shape", "[", "-", "2", "]", "-", "1", ")", "\n", "\n", "# Add part needed for convolution", "\n", "if", "reg_pad2", ">", "0", ":", "\n", "                ", "hfe_left_padd", "=", "complex", ".", "conj", "(", "hfe", "[", "...", ",", "1", ":", "reg_pad2", "+", "1", ",", ":", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "flip", "(", "(", "2", ",", "3", ")", ")", ")", "\n", "hfe_conv", "=", "torch", ".", "cat", "(", "[", "hfe_left_padd", ",", "hfe", "]", ",", "-", "2", ")", "\n", "", "else", ":", "\n", "                ", "hfe_conv", "=", "hfe", ".", "clone", "(", ")", "\n", "\n", "# Shift data to batch dimension", "\n", "", "hfe_conv", "=", "hfe_conv", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", ".", "reshape", "(", "-", "1", ",", "1", ",", "hfe_conv", ".", "shape", "[", "-", "3", "]", ",", "hfe_conv", ".", "shape", "[", "-", "2", "]", ")", "\n", "\n", "# Do first convolution", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.optim.FactorizedConvProblem.M1": [[67, 69], ["None"], "methods", ["None"], ["hfe_conv", "=", "F", ".", "conv2d", "(", "hfe_conv", ",", "reg_filter", ",", "padding", "=", "(", "reg_pad1", ",", "reg_pad2", ")", ")", "\n", "\n", "residuals", ".", "append", "(", "hfe_conv", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.optim.ConvProblem.__init__": [[72, 78], ["None"], "methods", ["None"], ["", "residuals", ".", "extend", "(", "math", ".", "sqrt", "(", "self", ".", "params", ".", "projection_reg", ")", "*", "P", ")", "\n", "\n", "return", "residuals", "\n", "\n", "\n", "", "def", "ip_input", "(", "self", ",", "a", ":", "TensorList", ",", "b", ":", "TensorList", ")", ":", "\n", "        ", "num", "=", "len", "(", "a", ")", "//", "2", "# Number of filters", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.optim.ConvProblem.__call__": [[79, 95], ["pytracking.operation.conv2d().apply", "pytracking.operation.conv2d().apply.extend", "optim.ConvProblem.sample_weights.sqrt().view", "pytracking.operation.conv2d", "optim.ConvProblem.filter_reg.apply", "optim.ConvProblem.sample_weights.sqrt"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply"], ["a_filter", "=", "a", "[", ":", "num", "]", "\n", "b_filter", "=", "b", "[", ":", "num", "]", "\n", "a_P", "=", "a", "[", "num", ":", "]", "\n", "b_P", "=", "b", "[", "num", ":", "]", "\n", "\n", "# Filter inner product", "\n", "ip_out", "=", "fourier", ".", "inner_prod_fs", "(", "a_filter", ",", "b_filter", ")", "\n", "\n", "# Add projection matrix part", "\n", "ip_out", "+=", "a_P", ".", "reshape", "(", "-", "1", ")", "@", "b_P", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "# Have independent inner products for each filter", "\n", "return", "ip_out", ".", "concat", "(", "ip_out", ".", "clone", "(", ")", ")", "\n", "\n", "\n", "", "def", "ip_output", "(", "self", ",", "a", ":", "TensorList", ",", "b", ":", "TensorList", ")", ":", "\n", "        ", "num", "=", "len", "(", "a", ")", "//", "3", "# Number of filters", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.optim.ConvProblem.ip_input": [[96, 100], ["pytracking.operation.conv2d().view", "pytracking.operation.conv2d"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["a_data", "=", "a", "[", ":", "num", "]", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ",", "4", ")", "\n", "b_data", "=", "b", "[", ":", "num", "]", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ",", "4", ")", "\n", "a_filt_reg", "=", "a", "[", "num", ":", "2", "*", "num", "]", "\n", "b_filt_reg", "=", "b", "[", "num", ":", "2", "*", "num", "]", "\n", "a_P_reg", "=", "a", "[", "2", "*", "num", ":", "]", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.initialize_features": [[20, 24], ["getattr", "atom.ATOM.params.features.initialize"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["def", "initialize_features", "(", "self", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "self", ",", "'features_initialized'", ",", "False", ")", ":", "\n", "            ", "self", ".", "params", ".", "features", ".", "initialize", "(", ")", "\n", "", "self", ".", "features_initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.initialize": [[26, 136], ["atom.ATOM.initialize_features", "atom.ATOM.params.features.set_is_color", "atom.ATOM.params.features.get_fparams", "time.time", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "atom.ATOM.params.get", "max", "atom.ATOM.params.features.size", "atom.ATOM.fparams.attribute", "atom.ATOM.fparams.attribute", "atom.ATOM.params.get", "atom.ATOM.init_learning", "pytracking.features.preprocessing.numpy_to_torch", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "atom.ATOM.generate_init_samples", "atom.ATOM.init_projection_matrix", "atom.ATOM.preprocess_sample", "atom.ATOM.init_label_function", "atom.ATOM.init_memory", "atom.ATOM.init_optimization", "atom.ATOM.pos.clone", "atom.ATOM.params.has", "math.sqrt", "atom.ATOM.params.features.stride", "atom.ATOM.params.get", "atom.ATOM.params.get", "atom.ATOM.init_iou_net", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "math.sqrt", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "torch.round", "ValueError", "max", "pytracking.dcf.hann2d_clipped().to", "pytracking.dcf.hann2d().to", "time.time", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "max", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "pytracking.dcf.hann2d_clipped", "pytracking.dcf.hann2d", "atom.ATOM.output_sz.long", "atom.ATOM.output_sz.long", "atom.ATOM.output_sz.long"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.set_is_color", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.get_fparams", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_learning", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.generate_init_samples", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_projection_matrix", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.preprocess_sample", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_memory", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_optimization", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.stride", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_iou_net", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d_clipped", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d"], ["", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "        ", "state", "=", "info", "[", "'init_bbox'", "]", "\n", "\n", "# Initialize some stuff", "\n", "self", ".", "frame_num", "=", "1", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'device'", ")", ":", "\n", "            ", "self", ".", "params", ".", "device", "=", "'cuda'", "if", "self", ".", "params", ".", "use_gpu", "else", "'cpu'", "\n", "\n", "# Initialize features", "\n", "", "self", ".", "initialize_features", "(", ")", "\n", "\n", "# Check if image is color", "\n", "self", ".", "params", ".", "features", ".", "set_is_color", "(", "image", ".", "shape", "[", "2", "]", "==", "3", ")", "\n", "\n", "# Get feature specific params", "\n", "self", ".", "fparams", "=", "self", ".", "params", ".", "features", ".", "get_fparams", "(", "'feature_params'", ")", "\n", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Get position and size", "\n", "self", ".", "pos", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "1", "]", "+", "(", "state", "[", "3", "]", "-", "1", ")", "/", "2", ",", "state", "[", "0", "]", "+", "(", "state", "[", "2", "]", "-", "1", ")", "/", "2", "]", ")", "\n", "self", ".", "target_sz", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "3", "]", ",", "state", "[", "2", "]", "]", ")", "\n", "\n", "# Set search area", "\n", "self", ".", "target_scale", "=", "1.0", "\n", "search_area", "=", "torch", ".", "prod", "(", "self", ".", "target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ".", "item", "(", ")", "\n", "if", "search_area", ">", "self", ".", "params", ".", "max_image_sample_size", ":", "\n", "            ", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", "/", "self", ".", "params", ".", "max_image_sample_size", ")", "\n", "", "elif", "search_area", "<", "self", ".", "params", ".", "min_image_sample_size", ":", "\n", "            ", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", "/", "self", ".", "params", ".", "min_image_sample_size", ")", "\n", "\n", "# Check if IoUNet is used", "\n", "", "self", ".", "use_iou_net", "=", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", "\n", "\n", "# Target size in base scale", "\n", "self", ".", "base_target_sz", "=", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "\n", "# Use odd square search area and set sizes", "\n", "feat_max_stride", "=", "max", "(", "self", ".", "params", ".", "features", ".", "stride", "(", ")", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'search_area_shape'", ",", "'square'", ")", "==", "'square'", ":", "\n", "            ", "self", ".", "img_sample_sz", "=", "torch", ".", "round", "(", "torch", ".", "sqrt", "(", "torch", ".", "prod", "(", "self", ".", "base_target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ")", ")", "*", "torch", ".", "ones", "(", "2", ")", "\n", "", "elif", "self", ".", "params", ".", "search_area_shape", "==", "'initrect'", ":", "\n", "            ", "self", ".", "img_sample_sz", "=", "torch", ".", "round", "(", "self", ".", "base_target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown search area shape'", ")", "\n", "", "if", "self", ".", "params", ".", "feature_size_odd", ":", "\n", "            ", "self", ".", "img_sample_sz", "+=", "feat_max_stride", "-", "self", ".", "img_sample_sz", "%", "(", "2", "*", "feat_max_stride", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "img_sample_sz", "+=", "feat_max_stride", "-", "(", "self", ".", "img_sample_sz", "+", "feat_max_stride", ")", "%", "(", "2", "*", "feat_max_stride", ")", "\n", "\n", "# Set sizes", "\n", "", "self", ".", "img_support_sz", "=", "self", ".", "img_sample_sz", "\n", "self", ".", "feature_sz", "=", "self", ".", "params", ".", "features", ".", "size", "(", "self", ".", "img_sample_sz", ")", "\n", "self", ".", "output_sz", "=", "self", ".", "params", ".", "score_upsample_factor", "*", "self", ".", "img_support_sz", "# Interpolated size of the output", "\n", "self", ".", "kernel_size", "=", "self", ".", "fparams", ".", "attribute", "(", "'kernel_size'", ")", "\n", "\n", "self", ".", "iou_img_sample_sz", "=", "self", ".", "img_sample_sz", "\n", "\n", "# Optimization options", "\n", "self", ".", "params", ".", "precond_learning_rate", "=", "self", ".", "fparams", ".", "attribute", "(", "'learning_rate'", ")", "\n", "if", "self", ".", "params", ".", "CG_forgetting_rate", "is", "None", "or", "max", "(", "self", ".", "params", ".", "precond_learning_rate", ")", ">=", "1", ":", "\n", "            ", "self", ".", "params", ".", "direction_forget_factor", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "params", ".", "direction_forget_factor", "=", "(", "1", "-", "max", "(", "self", ".", "params", ".", "precond_learning_rate", ")", ")", "**", "self", ".", "params", ".", "CG_forgetting_rate", "\n", "\n", "", "self", ".", "output_window", "=", "None", "\n", "if", "self", ".", "params", ".", "get", "(", "'window_output'", ",", "False", ")", ":", "\n", "            ", "if", "self", ".", "params", ".", "get", "(", "'use_clipped_window'", ",", "False", ")", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d_clipped", "(", "self", ".", "output_sz", ".", "long", "(", ")", ",", "self", ".", "output_sz", ".", "long", "(", ")", "*", "self", ".", "params", ".", "effective_search_area", "/", "self", ".", "params", ".", "search_area_scale", ",", "centered", "=", "False", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d", "(", "self", ".", "output_sz", ".", "long", "(", ")", ",", "centered", "=", "False", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "# Initialize some learning things", "\n", "", "", "self", ".", "init_learning", "(", ")", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "self", ".", "im", "=", "im", "# For debugging only", "\n", "\n", "# Setup scale bounds", "\n", "self", ".", "image_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "self", ".", "min_scale_factor", "=", "torch", ".", "max", "(", "10", "/", "self", ".", "base_target_sz", ")", "\n", "self", ".", "max_scale_factor", "=", "torch", ".", "min", "(", "self", ".", "image_sz", "/", "self", ".", "base_target_sz", ")", "\n", "\n", "# Extract and transform sample", "\n", "x", "=", "self", ".", "generate_init_samples", "(", "im", ")", "\n", "\n", "# Initialize iounet", "\n", "if", "self", ".", "use_iou_net", ":", "\n", "            ", "self", ".", "init_iou_net", "(", ")", "\n", "\n", "# Initialize projection matrix", "\n", "", "self", ".", "init_projection_matrix", "(", "x", ")", "\n", "\n", "# Transform to get the training sample", "\n", "train_x", "=", "self", ".", "preprocess_sample", "(", "x", ")", "\n", "\n", "# Generate label function", "\n", "init_y", "=", "self", ".", "init_label_function", "(", "train_x", ")", "\n", "\n", "# Init memory", "\n", "self", ".", "init_memory", "(", "train_x", ")", "\n", "\n", "# Init optimizer and do initial optimization", "\n", "self", ".", "init_optimization", "(", "train_x", ",", "init_y", ")", "\n", "\n", "self", ".", "pos_iounet", "=", "self", ".", "pos", ".", "clone", "(", ")", "\n", "\n", "out", "=", "{", "'time'", ":", "time", ".", "time", "(", ")", "-", "tic", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_optimization": [[138, 223], ["atom.ATOM.params.get", "pytracking.TensorList", "atom.ATOM.params.get", "atom.ATOM.project_sample", "zip", "optim.ConvProblem", "atom.ATOM.filter_optimizer.run", "atom.ATOM.params.get", "optim.FactorizedConvProblem", "atom.ATOM.filter.concat", "atom.ATOM.params.get", "isinstance", "pytracking.libs.optimization.ConjugateGradient", "atom.ATOM.filter_optimizer.run", "x.new_zeros", "ValueError", "atom.ATOM.fparams.attribute", "pytracking.libs.optimization.GaussNewtonCG", "atom.ATOM.joint_optimizer.run", "atom.ATOM.joint_optimizer.run", "zip", "RuntimeError", "pytracking.libs.optimization.GradientDescentL2", "zip", "f.normal_", "pytracking.libs.optimization.GradientDescentL2", "atom.ATOM.params.get", "open", "f.write", "f.numel", "v.item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.project_sample", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.run", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.concat", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.run", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.run", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.run", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "init_optimization", "(", "self", ",", "train_x", ",", "init_y", ")", ":", "\n", "# Initialize filter", "\n", "        ", "filter_init_method", "=", "self", ".", "params", ".", "get", "(", "'filter_init_method'", ",", "'zeros'", ")", "\n", "self", ".", "filter", "=", "TensorList", "(", "\n", "[", "x", ".", "new_zeros", "(", "1", ",", "cdim", ",", "sz", "[", "0", "]", ",", "sz", "[", "1", "]", ")", "for", "x", ",", "cdim", ",", "sz", "in", "zip", "(", "train_x", ",", "self", ".", "compressed_dim", ",", "self", ".", "kernel_size", ")", "]", ")", "\n", "if", "filter_init_method", "==", "'zeros'", ":", "\n", "            ", "pass", "\n", "", "elif", "filter_init_method", "==", "'randn'", ":", "\n", "            ", "for", "f", "in", "self", ".", "filter", ":", "\n", "                ", "f", ".", "normal_", "(", "0", ",", "1", "/", "f", ".", "numel", "(", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown \"filter_init_method\"'", ")", "\n", "\n", "# Get parameters", "\n", "", "self", ".", "params", ".", "update_projection_matrix", "=", "self", ".", "params", ".", "get", "(", "'update_projection_matrix'", ",", "True", ")", "and", "self", ".", "params", ".", "use_projection_matrix", "\n", "optimizer", "=", "self", ".", "params", ".", "get", "(", "'optimizer'", ",", "'GaussNewtonCG'", ")", "\n", "\n", "# Setup factorized joint optimization", "\n", "if", "self", ".", "params", ".", "update_projection_matrix", ":", "\n", "            ", "self", ".", "joint_problem", "=", "FactorizedConvProblem", "(", "self", ".", "init_training_samples", ",", "init_y", ",", "self", ".", "filter_reg", ",", "\n", "self", ".", "fparams", ".", "attribute", "(", "'projection_reg'", ")", ",", "self", ".", "params", ",", "self", ".", "init_sample_weights", ",", "\n", "self", ".", "projection_activation", ",", "self", ".", "response_activation", ")", "\n", "\n", "# Variable containing both filter and projection matrix", "\n", "joint_var", "=", "self", ".", "filter", ".", "concat", "(", "self", ".", "projection_matrix", ")", "\n", "\n", "# Initialize optimizer", "\n", "analyze_convergence", "=", "self", ".", "params", ".", "get", "(", "'analyze_convergence'", ",", "False", ")", "\n", "if", "optimizer", "==", "'GaussNewtonCG'", ":", "\n", "                ", "self", ".", "joint_optimizer", "=", "GaussNewtonCG", "(", "self", ".", "joint_problem", ",", "joint_var", ",", "debug", "=", "(", "self", ".", "params", ".", "debug", ">=", "1", ")", ",", "\n", "plotting", "=", "(", "self", ".", "params", ".", "debug", ">=", "3", ")", ",", "analyze", "=", "analyze_convergence", ",", "\n", "visdom", "=", "self", ".", "visdom", ")", "\n", "", "elif", "optimizer", "==", "'GradientDescentL2'", ":", "\n", "                ", "self", ".", "joint_optimizer", "=", "GradientDescentL2", "(", "self", ".", "joint_problem", ",", "joint_var", ",", "self", ".", "params", ".", "optimizer_step_length", ",", "self", ".", "params", ".", "optimizer_momentum", ",", "plotting", "=", "(", "self", ".", "params", ".", "debug", ">=", "3", ")", ",", "debug", "=", "(", "self", ".", "params", ".", "debug", ">=", "1", ")", ",", "\n", "visdom", "=", "self", ".", "visdom", ")", "\n", "\n", "# Do joint optimization", "\n", "", "if", "isinstance", "(", "self", ".", "params", ".", "init_CG_iter", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "self", ".", "joint_optimizer", ".", "run", "(", "self", ".", "params", ".", "init_CG_iter", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "joint_optimizer", ".", "run", "(", "self", ".", "params", ".", "init_CG_iter", "//", "self", ".", "params", ".", "init_GN_iter", ",", "self", ".", "params", ".", "init_GN_iter", ")", "\n", "\n", "", "if", "analyze_convergence", ":", "\n", "                ", "opt_name", "=", "'CG'", "if", "self", ".", "params", ".", "get", "(", "'CG_optimizer'", ",", "True", ")", "else", "'GD'", "\n", "for", "val_name", ",", "values", "in", "zip", "(", "[", "'loss'", ",", "'gradient'", "]", ",", "[", "self", ".", "joint_optimizer", ".", "losses", ",", "self", ".", "joint_optimizer", ".", "gradient_mags", "]", ")", ":", "\n", "                    ", "val_str", "=", "' '", ".", "join", "(", "[", "'{:.8e}'", ".", "format", "(", "v", ".", "item", "(", ")", ")", "for", "v", "in", "values", "]", ")", "\n", "file_name", "=", "'{}_{}.txt'", ".", "format", "(", "opt_name", ",", "val_name", ")", "\n", "with", "open", "(", "file_name", ",", "'a'", ")", "as", "f", ":", "\n", "                        ", "f", ".", "write", "(", "val_str", "+", "'\\n'", ")", "\n", "", "", "raise", "RuntimeError", "(", "'Exiting'", ")", "\n", "\n", "# Re-project samples with the new projection matrix", "\n", "", "", "compressed_samples", "=", "self", ".", "project_sample", "(", "self", ".", "init_training_samples", ",", "self", ".", "projection_matrix", ")", "\n", "for", "train_samp", ",", "init_samp", "in", "zip", "(", "self", ".", "training_samples", ",", "compressed_samples", ")", ":", "\n", "            ", "train_samp", "[", ":", "init_samp", ".", "shape", "[", "0", "]", ",", "...", "]", "=", "init_samp", "\n", "\n", "", "self", ".", "hinge_mask", "=", "None", "\n", "\n", "# Initialize optimizer", "\n", "self", ".", "conv_problem", "=", "ConvProblem", "(", "self", ".", "training_samples", ",", "self", ".", "y", ",", "self", ".", "filter_reg", ",", "self", ".", "sample_weights", ",", "self", ".", "response_activation", ")", "\n", "\n", "if", "optimizer", "==", "'GaussNewtonCG'", ":", "\n", "            ", "self", ".", "filter_optimizer", "=", "ConjugateGradient", "(", "self", ".", "conv_problem", ",", "self", ".", "filter", ",", "fletcher_reeves", "=", "self", ".", "params", ".", "fletcher_reeves", ",", "\n", "direction_forget_factor", "=", "self", ".", "params", ".", "direction_forget_factor", ",", "debug", "=", "(", "self", ".", "params", ".", "debug", ">=", "1", ")", ",", "\n", "plotting", "=", "(", "self", ".", "params", ".", "debug", ">=", "3", ")", ",", "visdom", "=", "self", ".", "visdom", ")", "\n", "", "elif", "optimizer", "==", "'GradientDescentL2'", ":", "\n", "            ", "self", ".", "filter_optimizer", "=", "GradientDescentL2", "(", "self", ".", "conv_problem", ",", "self", ".", "filter", ",", "self", ".", "params", ".", "optimizer_step_length", ",", "\n", "self", ".", "params", ".", "optimizer_momentum", ",", "debug", "=", "(", "self", ".", "params", ".", "debug", ">=", "1", ")", ",", "\n", "plotting", "=", "(", "self", ".", "params", ".", "debug", ">=", "3", ")", ",", "visdom", "=", "self", ".", "visdom", ")", "\n", "\n", "# Transfer losses from previous optimization", "\n", "", "if", "self", ".", "params", ".", "update_projection_matrix", ":", "\n", "            ", "self", ".", "filter_optimizer", ".", "residuals", "=", "self", ".", "joint_optimizer", ".", "residuals", "\n", "self", ".", "filter_optimizer", ".", "losses", "=", "self", ".", "joint_optimizer", ".", "losses", "\n", "\n", "", "if", "not", "self", ".", "params", ".", "update_projection_matrix", ":", "\n", "            ", "self", ".", "filter_optimizer", ".", "run", "(", "self", ".", "params", ".", "init_CG_iter", ")", "\n", "\n", "# Post optimization", "\n", "", "self", ".", "filter_optimizer", ".", "run", "(", "self", ".", "params", ".", "post_init_CG_iter", ")", "\n", "\n", "# Free memory", "\n", "del", "self", ".", "init_training_samples", "\n", "if", "self", ".", "params", ".", "use_projection_matrix", ":", "\n", "            ", "del", "self", ".", "joint_problem", ",", "self", ".", "joint_optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.track": [[225, 299], ["pytracking.features.preprocessing.numpy_to_torch", "atom.ATOM.pos.round", "atom.ATOM.extract_processed_sample", "atom.ATOM.apply_filter", "atom.ATOM.localize_target", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.max().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "atom.ATOM.visdom.register", "atom.ATOM.visdom.register", "pytracking.TensorList", "atom.ATOM.get_label_function", "atom.ATOM.update_memory", "atom.ATOM.filter_optimizer.run", "atom.ATOM.pos_iounet.clone", "torch.cat.tolist", "torch.cat.tolist", "torch.cat.tolist", "atom.ATOM.params.get", "atom.ATOM.refine_target_box", "atom.ATOM.params.get", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "pytracking.utils.plotting.show_tensor", "atom.ATOM.filter_optimizer.run", "atom.ATOM.params.get", "atom.ATOM.update_state", "atom.ATOM.update_state"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.extract_processed_sample", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_target", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_memory", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.run", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.refine_target_box", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.show_tensor", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.run", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_state", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_state"], ["", "", "def", "track", "(", "self", ",", "image", ",", "info", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "        ", "self", ".", "debug_info", "=", "{", "}", "\n", "\n", "self", ".", "frame_num", "+=", "1", "\n", "self", ".", "debug_info", "[", "'frame_num'", "]", "=", "self", ".", "frame_num", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "self", ".", "im", "=", "im", "# For debugging only", "\n", "\n", "# ------- LOCALIZATION ------- #", "\n", "\n", "# Get sample", "\n", "sample_pos", "=", "self", ".", "pos", ".", "round", "(", ")", "\n", "sample_scales", "=", "self", ".", "target_scale", "*", "self", ".", "params", ".", "scale_factors", "\n", "test_x", "=", "self", ".", "extract_processed_sample", "(", "im", ",", "self", ".", "pos", ",", "sample_scales", ",", "self", ".", "img_sample_sz", ")", "\n", "\n", "# Compute scores", "\n", "scores_raw", "=", "self", ".", "apply_filter", "(", "test_x", ")", "\n", "translation_vec", ",", "scale_ind", ",", "s", ",", "flag", "=", "self", ".", "localize_target", "(", "scores_raw", ")", "\n", "\n", "# Update position and scale", "\n", "if", "flag", "!=", "'not_found'", ":", "\n", "            ", "if", "self", ".", "use_iou_net", ":", "\n", "                ", "update_scale_flag", "=", "self", ".", "params", ".", "get", "(", "'update_scale_when_uncertain'", ",", "True", ")", "or", "flag", "!=", "'uncertain'", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_classifier'", ",", "True", ")", ":", "\n", "                    ", "self", ".", "update_state", "(", "sample_pos", "+", "translation_vec", ")", "\n", "", "self", ".", "refine_target_box", "(", "sample_pos", ",", "sample_scales", "[", "scale_ind", "]", ",", "scale_ind", ",", "update_scale_flag", ")", "\n", "", "elif", "self", ".", "params", ".", "get", "(", "'use_classifier'", ",", "True", ")", ":", "\n", "                ", "self", ".", "update_state", "(", "sample_pos", "+", "translation_vec", ",", "sample_scales", "[", "scale_ind", "]", ")", "\n", "\n", "", "", "score_map", "=", "s", "[", "scale_ind", ",", "...", "]", "\n", "max_score", "=", "torch", ".", "max", "(", "score_map", ")", ".", "item", "(", ")", "\n", "self", ".", "debug_info", "[", "'max_score'", "]", "=", "max_score", "\n", "self", ".", "debug_info", "[", "'flag'", "]", "=", "flag", "\n", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "score_map", ",", "'heatmap'", ",", "2", ",", "'Score Map'", ")", "\n", "self", ".", "visdom", ".", "register", "(", "self", ".", "debug_info", ",", "'info_dict'", ",", "1", ",", "'Status'", ")", "\n", "", "elif", "self", ".", "params", ".", "debug", ">=", "2", ":", "\n", "            ", "show_tensor", "(", "score_map", ",", "5", ",", "title", "=", "'Max score = {:.2f}'", ".", "format", "(", "max_score", ")", ")", "\n", "\n", "# ------- UPDATE ------- #", "\n", "\n", "# Check flags and set learning rate if hard negative", "\n", "", "update_flag", "=", "flag", "not", "in", "[", "'not_found'", ",", "'uncertain'", "]", "\n", "hard_negative", "=", "(", "flag", "==", "'hard_negative'", ")", "\n", "learning_rate", "=", "self", ".", "params", ".", "hard_negative_learning_rate", "if", "hard_negative", "else", "None", "\n", "\n", "if", "update_flag", ":", "\n", "# Get train sample", "\n", "            ", "train_x", "=", "TensorList", "(", "[", "x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "for", "x", "in", "test_x", "]", ")", "\n", "\n", "# Create label for sample", "\n", "train_y", "=", "self", ".", "get_label_function", "(", "sample_pos", ",", "sample_scales", "[", "scale_ind", "]", ")", "\n", "\n", "# Update memory", "\n", "self", ".", "update_memory", "(", "train_x", ",", "train_y", ",", "learning_rate", ")", "\n", "\n", "# Train filter", "\n", "", "if", "hard_negative", ":", "\n", "            ", "self", ".", "filter_optimizer", ".", "run", "(", "self", ".", "params", ".", "hard_negative_CG_iter", ")", "\n", "", "elif", "(", "self", ".", "frame_num", "-", "1", ")", "%", "self", ".", "params", ".", "train_skipping", "==", "0", ":", "\n", "            ", "self", ".", "filter_optimizer", ".", "run", "(", "self", ".", "params", ".", "CG_iter", ")", "\n", "\n", "# Set the pos of the tracker to iounet pos", "\n", "", "if", "self", ".", "use_iou_net", "and", "flag", "!=", "'not_found'", ":", "\n", "            ", "self", ".", "pos", "=", "self", ".", "pos_iounet", ".", "clone", "(", ")", "\n", "\n", "# Return new state", "\n", "", "new_state", "=", "torch", ".", "cat", "(", "(", "self", ".", "pos", "[", "[", "1", ",", "0", "]", "]", "-", "(", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", "-", "1", ")", "/", "2", ",", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", ")", ")", "\n", "\n", "out", "=", "{", "'target_bbox'", ":", "new_state", ".", "tolist", "(", ")", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.apply_filter": [[301, 303], ["pytracking.operation.conv2d"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["", "def", "apply_filter", "(", "self", ",", "sample_x", ":", "TensorList", ")", ":", "\n", "        ", "return", "operation", ".", "conv2d", "(", "sample_x", ",", "self", ".", "filter", ",", "mode", "=", "'same'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.localize_target": [[304, 340], ["atom.ATOM.fparams.attribute", "enumerate", "pytracking.fourier.sum_fs", "pytracking.fourier.sample_fs", "atom.ATOM.params.get", "pytracking.dcf.max2d", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "max_disp.float().cpu.float().cpu.float().cpu", "pytracking.fourier.cfft2", "zip", "pytracking.fourier.shift_fs", "atom.ATOM.localize_advanced", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "scores_raw.size", "scores_raw.size", "atom.ATOM.params.get", "max_disp.float().cpu.float().cpu.float", "disp[].view", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.sum_fs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.sample_fs", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.cfft2", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.shift_fs", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_advanced", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "localize_target", "(", "self", ",", "scores_raw", ")", ":", "\n", "# Weighted sum (if multiple features) with interpolation in fourier domain", "\n", "        ", "weight", "=", "self", ".", "fparams", ".", "attribute", "(", "'translation_weight'", ",", "1.0", ")", "\n", "scores_raw", "=", "weight", "*", "scores_raw", "\n", "sf_weighted", "=", "fourier", ".", "cfft2", "(", "scores_raw", ")", "/", "(", "scores_raw", ".", "size", "(", "2", ")", "*", "scores_raw", ".", "size", "(", "3", ")", ")", "\n", "for", "i", ",", "(", "sz", ",", "ksz", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "feature_sz", ",", "self", ".", "kernel_size", ")", ")", ":", "\n", "            ", "sf_weighted", "[", "i", "]", "=", "fourier", ".", "shift_fs", "(", "sf_weighted", "[", "i", "]", ",", "math", ".", "pi", "*", "(", "1", "-", "torch", ".", "Tensor", "(", "[", "ksz", "[", "0", "]", "%", "2", ",", "ksz", "[", "1", "]", "%", "2", "]", ")", "/", "sz", ")", ")", "\n", "\n", "", "scores_fs", "=", "fourier", ".", "sum_fs", "(", "sf_weighted", ")", "\n", "scores", "=", "fourier", ".", "sample_fs", "(", "scores_fs", ",", "self", ".", "output_sz", ")", "\n", "\n", "if", "self", ".", "output_window", "is", "not", "None", "and", "not", "self", ".", "params", ".", "get", "(", "'perform_hn_without_windowing'", ",", "False", ")", ":", "\n", "            ", "scores", "*=", "self", ".", "output_window", "\n", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'advanced_localization'", ",", "False", ")", ":", "\n", "            ", "return", "self", ".", "localize_advanced", "(", "scores", ")", "\n", "\n", "# Get maximum", "\n", "", "max_score", ",", "max_disp", "=", "dcf", ".", "max2d", "(", "scores", ")", "\n", "_", ",", "scale_ind", "=", "torch", ".", "max", "(", "max_score", ",", "dim", "=", "0", ")", "\n", "max_disp", "=", "max_disp", ".", "float", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "# Convert to displacements in the base scale", "\n", "disp", "=", "(", "max_disp", "+", "self", ".", "output_sz", "/", "2", ")", "%", "self", ".", "output_sz", "-", "self", ".", "output_sz", "/", "2", "\n", "\n", "# Compute translation vector and scale change factor", "\n", "translation_vec", "=", "disp", "[", "scale_ind", ",", "...", "]", ".", "view", "(", "-", "1", ")", "*", "(", "self", ".", "img_support_sz", "/", "self", ".", "output_sz", ")", "*", "self", ".", "target_scale", "\n", "translation_vec", "*=", "self", ".", "params", ".", "scale_factors", "[", "scale_ind", "]", "\n", "\n", "# Shift the score output for visualization purposes", "\n", "if", "self", ".", "params", ".", "debug", ">=", "2", ":", "\n", "            ", "sz", "=", "scores", ".", "shape", "[", "-", "2", ":", "]", "\n", "scores", "=", "torch", ".", "cat", "(", "[", "scores", "[", "...", ",", "sz", "[", "0", "]", "//", "2", ":", ",", ":", "]", ",", "scores", "[", "...", ",", ":", "sz", "[", "0", "]", "//", "2", ",", ":", "]", "]", ",", "-", "2", ")", "\n", "scores", "=", "torch", ".", "cat", "(", "[", "scores", "[", "...", ",", ":", ",", "sz", "[", "1", "]", "//", "2", ":", "]", ",", "scores", "[", "...", ",", ":", ",", ":", "sz", "[", "1", "]", "//", "2", "]", "]", ",", "-", "1", ")", "\n", "\n", "", "return", "translation_vec", ",", "scale_ind", ",", "scores", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.localize_advanced": [[341, 407], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytracking.dcf.max2d", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "max_disp1[].float().cpu().view", "max", "min", "max", "min", "scores[].clone", "pytracking.dcf.max2d", "max_disp2.float().cpu().view.float().cpu().view.float().cpu().view", "atom.ATOM.params.get", "torch.cat.clone", "torch.cat.clone", "torch.cat.clone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "max_score1.item", "atom.ATOM.params.get", "round", "round", "round", "round", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "max_disp1[].float().cpu", "max_disp2.float().cpu().view.float().cpu().view.float().cpu", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "max_disp1[].item", "max_disp1[].item", "math.sqrt", "max_disp1[].float", "target_neigh_sz[].item", "max_disp1[].item", "target_neigh_sz[].item", "max_disp1[].item", "max_disp2.float().cpu().view.float().cpu().view.float", "target_neigh_sz[].item", "target_neigh_sz[].item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "localize_advanced", "(", "self", ",", "scores", ")", ":", "\n", "        ", "\"\"\"Dows the advanced localization with hard negative detection and target not found.\"\"\"", "\n", "\n", "sz", "=", "scores", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "if", "self", ".", "output_window", "is", "not", "None", "and", "self", ".", "params", ".", "get", "(", "'perform_hn_without_windowing'", ",", "False", ")", ":", "\n", "            ", "scores_orig", "=", "scores", ".", "clone", "(", ")", "\n", "\n", "scores_orig", "=", "torch", ".", "cat", "(", "[", "scores_orig", "[", "...", ",", "(", "sz", "[", "0", "]", "+", "1", ")", "//", "2", ":", ",", ":", "]", ",", "scores_orig", "[", "...", ",", ":", "(", "sz", "[", "0", "]", "+", "1", ")", "//", "2", ",", ":", "]", "]", ",", "-", "2", ")", "\n", "scores_orig", "=", "torch", ".", "cat", "(", "[", "scores_orig", "[", "...", ",", ":", ",", "(", "sz", "[", "1", "]", "+", "1", ")", "//", "2", ":", "]", ",", "scores_orig", "[", "...", ",", ":", ",", ":", "(", "sz", "[", "1", "]", "+", "1", ")", "//", "2", "]", "]", ",", "-", "1", ")", "\n", "\n", "scores", "*=", "self", ".", "output_window", "\n", "\n", "# Shift scores back", "\n", "", "scores", "=", "torch", ".", "cat", "(", "[", "scores", "[", "...", ",", "(", "sz", "[", "0", "]", "+", "1", ")", "//", "2", ":", ",", ":", "]", ",", "scores", "[", "...", ",", ":", "(", "sz", "[", "0", "]", "+", "1", ")", "//", "2", ",", ":", "]", "]", ",", "-", "2", ")", "\n", "scores", "=", "torch", ".", "cat", "(", "[", "scores", "[", "...", ",", ":", ",", "(", "sz", "[", "1", "]", "+", "1", ")", "//", "2", ":", "]", ",", "scores", "[", "...", ",", ":", ",", ":", "(", "sz", "[", "1", "]", "+", "1", ")", "//", "2", "]", "]", ",", "-", "1", ")", "\n", "\n", "# Find maximum", "\n", "max_score1", ",", "max_disp1", "=", "dcf", ".", "max2d", "(", "scores", ")", "\n", "_", ",", "scale_ind", "=", "torch", ".", "max", "(", "max_score1", ",", "dim", "=", "0", ")", "\n", "max_score1", "=", "max_score1", "[", "scale_ind", "]", "\n", "max_disp1", "=", "max_disp1", "[", "scale_ind", ",", "...", "]", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp1", "=", "max_disp1", "-", "self", ".", "output_sz", "//", "2", "\n", "translation_vec1", "=", "target_disp1", "*", "(", "self", ".", "img_support_sz", "/", "self", ".", "output_sz", ")", "*", "self", ".", "target_scale", "\n", "\n", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "target_not_found_threshold", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores", ",", "'not_found'", "\n", "\n", "", "if", "self", ".", "output_window", "is", "not", "None", "and", "self", ".", "params", ".", "get", "(", "'perform_hn_without_windowing'", ",", "False", ")", ":", "\n", "            ", "scores", "=", "scores_orig", "\n", "\n", "# Mask out target neighborhood", "\n", "", "target_neigh_sz", "=", "self", ".", "params", ".", "target_neighborhood_scale", "*", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "tneigh_top", "=", "max", "(", "round", "(", "max_disp1", "[", "0", "]", ".", "item", "(", ")", "-", "target_neigh_sz", "[", "0", "]", ".", "item", "(", ")", "/", "2", ")", ",", "0", ")", "\n", "tneigh_bottom", "=", "min", "(", "round", "(", "max_disp1", "[", "0", "]", ".", "item", "(", ")", "+", "target_neigh_sz", "[", "0", "]", ".", "item", "(", ")", "/", "2", "+", "1", ")", ",", "sz", "[", "0", "]", ")", "\n", "tneigh_left", "=", "max", "(", "round", "(", "max_disp1", "[", "1", "]", ".", "item", "(", ")", "-", "target_neigh_sz", "[", "1", "]", ".", "item", "(", ")", "/", "2", ")", ",", "0", ")", "\n", "tneigh_right", "=", "min", "(", "round", "(", "max_disp1", "[", "1", "]", ".", "item", "(", ")", "+", "target_neigh_sz", "[", "1", "]", ".", "item", "(", ")", "/", "2", "+", "1", ")", ",", "sz", "[", "1", "]", ")", "\n", "scores_masked", "=", "scores", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", ".", "clone", "(", ")", "\n", "scores_masked", "[", "...", ",", "tneigh_top", ":", "tneigh_bottom", ",", "tneigh_left", ":", "tneigh_right", "]", "=", "0", "\n", "\n", "# Find new maximum", "\n", "max_score2", ",", "max_disp2", "=", "dcf", ".", "max2d", "(", "scores_masked", ")", "\n", "max_disp2", "=", "max_disp2", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp2", "=", "max_disp2", "-", "self", ".", "output_sz", "//", "2", "\n", "translation_vec2", "=", "target_disp2", "*", "(", "self", ".", "img_support_sz", "/", "self", ".", "output_sz", ")", "*", "self", ".", "target_scale", "\n", "\n", "# Handle the different cases", "\n", "if", "max_score2", ">", "self", ".", "params", ".", "distractor_threshold", "*", "max_score1", ":", "\n", "            ", "disp_norm1", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "target_disp1", "**", "2", ")", ")", "\n", "disp_norm2", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "target_disp2", "**", "2", ")", ")", "\n", "disp_threshold", "=", "self", ".", "params", ".", "dispalcement_scale", "*", "math", ".", "sqrt", "(", "sz", "[", "0", "]", "*", "sz", "[", "1", "]", ")", "/", "2", "\n", "\n", "if", "disp_norm2", ">", "disp_threshold", "and", "disp_norm1", "<", "disp_threshold", ":", "\n", "                ", "return", "translation_vec1", ",", "scale_ind", ",", "scores", ",", "'hard_negative'", "\n", "", "if", "disp_norm2", "<", "disp_threshold", "and", "disp_norm1", ">", "disp_threshold", ":", "\n", "                ", "return", "translation_vec2", ",", "scale_ind", ",", "scores", ",", "'hard_negative'", "\n", "", "if", "disp_norm2", ">", "disp_threshold", "and", "disp_norm1", ">", "disp_threshold", ":", "\n", "                ", "return", "translation_vec1", ",", "scale_ind", ",", "scores", ",", "'uncertain'", "\n", "\n", "# If also the distractor is close, return with highest score", "\n", "", "return", "translation_vec1", ",", "scale_ind", ",", "scores", ",", "'uncertain'", "\n", "\n", "", "if", "max_score2", ">", "self", ".", "params", ".", "hard_negative_threshold", "*", "max_score1", "and", "max_score2", ">", "self", ".", "params", ".", "target_not_found_threshold", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores", ",", "'hard_negative'", "\n", "\n", "", "return", "translation_vec1", ",", "scale_ind", ",", "scores", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.extract_sample": [[409, 411], ["atom.ATOM.params.features.extract"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.extract"], ["", "def", "extract_sample", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ",", "pos", ":", "torch", ".", "Tensor", ",", "scales", ",", "sz", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "self", ".", "params", ".", "features", ".", "extract", "(", "im", ",", "pos", ",", "scales", ",", "sz", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_features": [[412, 414], ["atom.ATOM.params.features.get_unique_attribute"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.get_unique_attribute"], ["", "def", "get_iou_features", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "params", ".", "features", ".", "get_unique_attribute", "(", "'iounet_features'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_backbone_features": [[415, 417], ["atom.ATOM.params.features.get_unique_attribute"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.get_unique_attribute"], ["", "def", "get_iou_backbone_features", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "params", ".", "features", ".", "get_unique_attribute", "(", "'iounet_backbone_features'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.extract_processed_sample": [[418, 421], ["atom.ATOM.extract_sample", "atom.ATOM.preprocess_sample", "atom.ATOM.project_sample"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.extract_sample", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.preprocess_sample", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.project_sample"], ["", "def", "extract_processed_sample", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ",", "pos", ":", "torch", ".", "Tensor", ",", "scales", ",", "sz", ":", "torch", ".", "Tensor", ")", "->", "(", "TensorList", ",", "TensorList", ")", ":", "\n", "        ", "x", "=", "self", ".", "extract_sample", "(", "im", ",", "pos", ",", "scales", ",", "sz", ")", "\n", "return", "self", ".", "preprocess_sample", "(", "self", ".", "project_sample", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.preprocess_sample": [[422, 426], ["atom.ATOM.params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "preprocess_sample", "(", "self", ",", "x", ":", "TensorList", ")", "->", "(", "TensorList", ",", "TensorList", ")", ":", "\n", "        ", "if", "self", ".", "params", ".", "get", "(", "'_feature_window'", ",", "False", ")", ":", "\n", "            ", "x", "=", "x", "*", "self", ".", "feature_window", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.project_sample": [[427, 432], ["pytracking.operation.conv2d().apply", "pytracking.operation.conv2d"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["", "def", "project_sample", "(", "self", ",", "x", ":", "TensorList", ",", "proj_matrix", "=", "None", ")", ":", "\n", "# Apply projection matrix", "\n", "        ", "if", "proj_matrix", "is", "None", ":", "\n", "            ", "proj_matrix", "=", "self", ".", "projection_matrix", "\n", "", "return", "operation", ".", "conv2d", "(", "x", ",", "proj_matrix", ")", ".", "apply", "(", "self", ".", "projection_activation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_learning": [[433, 471], ["pytracking.TensorList", "atom.ATOM.fparams.attribute", "atom.ATOM.params.get", "isinstance", "atom.ATOM.params.get", "isinstance", "pytracking.dcf.hann2d().to", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "torch.nn.ELU", "pytracking.dcf.hann2d", "ValueError", "ValueError", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d"], ["", "def", "init_learning", "(", "self", ")", ":", "\n", "# Get window function", "\n", "        ", "self", ".", "feature_window", "=", "TensorList", "(", "[", "dcf", ".", "hann2d", "(", "sz", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "for", "sz", "in", "self", ".", "feature_sz", "]", ")", "\n", "\n", "# Filter regularization", "\n", "self", ".", "filter_reg", "=", "self", ".", "fparams", ".", "attribute", "(", "'filter_reg'", ")", "\n", "\n", "# Activation function after the projection matrix (phi_1 in the paper)", "\n", "projection_activation", "=", "self", ".", "params", ".", "get", "(", "'projection_activation'", ",", "'none'", ")", "\n", "if", "isinstance", "(", "projection_activation", ",", "tuple", ")", ":", "\n", "            ", "projection_activation", ",", "act_param", "=", "projection_activation", "\n", "\n", "", "if", "projection_activation", "==", "'none'", ":", "\n", "            ", "self", ".", "projection_activation", "=", "lambda", "x", ":", "x", "\n", "", "elif", "projection_activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "projection_activation", "=", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "projection_activation", "==", "'elu'", ":", "\n", "            ", "self", ".", "projection_activation", "=", "torch", ".", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "projection_activation", "==", "'mlu'", ":", "\n", "            ", "self", ".", "projection_activation", "=", "lambda", "x", ":", "F", ".", "elu", "(", "F", ".", "leaky_relu", "(", "x", ",", "1", "/", "act_param", ")", ",", "act_param", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown activation'", ")", "\n", "\n", "# Activation function after the output scores (phi_2 in the paper)", "\n", "", "response_activation", "=", "self", ".", "params", ".", "get", "(", "'response_activation'", ",", "'none'", ")", "\n", "if", "isinstance", "(", "response_activation", ",", "tuple", ")", ":", "\n", "            ", "response_activation", ",", "act_param", "=", "response_activation", "\n", "\n", "", "if", "response_activation", "==", "'none'", ":", "\n", "            ", "self", ".", "response_activation", "=", "lambda", "x", ":", "x", "\n", "", "elif", "response_activation", "==", "'relu'", ":", "\n", "            ", "self", ".", "response_activation", "=", "torch", ".", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "response_activation", "==", "'elu'", ":", "\n", "            ", "self", ".", "response_activation", "=", "torch", ".", "nn", ".", "ELU", "(", "inplace", "=", "True", ")", "\n", "", "elif", "response_activation", "==", "'mlu'", ":", "\n", "            ", "self", ".", "response_activation", "=", "lambda", "x", ":", "F", ".", "elu", "(", "F", ".", "leaky_relu", "(", "x", ",", "1", "/", "act_param", ")", ",", "act_param", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown activation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.generate_init_samples": [[473, 525], ["atom.ATOM.params.get", "atom.ATOM.img_sample_sz.clone", "atom.ATOM.params.get", "atom.ATOM.params.features.extract_transformed", "enumerate", "aug_expansion_sz.float.float.float", "atom.ATOM.img_sample_sz.long().tolist", "pytracking.features.augmentation.Identity", "atom.ATOM.transforms.extend", "atom.ATOM.transforms.extend", "atom.ATOM.transforms.append", "atom.ATOM.transforms.extend", "atom.ATOM.transforms.extend", "atom.ATOM.transforms.extend", "atom.ATOM.fparams.attribute", "atom.ATOM.transforms.extend", "enumerate", "pytracking.features.augmentation.FlipHorizontal", "atom.ATOM.fparams.attribute", "atom.ATOM.img_sample_sz.long", "atom.ATOM.img_sample_sz.long", "pytracking.features.augmentation.Translation", "pytracking.features.augmentation.Translation", "get_rand_shift", "pytracking.features.augmentation.Blur", "pytracking.features.augmentation.Scale", "pytracking.features.augmentation.Rotate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "get_absolute", "get_rand_shift", "get_rand_shift", "get_rand_shift", "torch.dropout2d", "torch.dropout2d", "torch.dropout2d", "[].expand", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.extract_transformed", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "", "def", "generate_init_samples", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Generate augmented initial samples.\"\"\"", "\n", "\n", "# Compute augmentation size", "\n", "aug_expansion_factor", "=", "self", ".", "params", ".", "get", "(", "'augmentation_expansion_factor'", ",", "None", ")", "\n", "aug_expansion_sz", "=", "self", ".", "img_sample_sz", ".", "clone", "(", ")", "\n", "aug_output_sz", "=", "None", "\n", "if", "aug_expansion_factor", "is", "not", "None", "and", "aug_expansion_factor", "!=", "1", ":", "\n", "            ", "aug_expansion_sz", "=", "(", "self", ".", "img_sample_sz", "*", "aug_expansion_factor", ")", ".", "long", "(", ")", "\n", "aug_expansion_sz", "+=", "(", "aug_expansion_sz", "-", "self", ".", "img_sample_sz", ".", "long", "(", ")", ")", "%", "2", "\n", "aug_expansion_sz", "=", "aug_expansion_sz", ".", "float", "(", ")", "\n", "aug_output_sz", "=", "self", ".", "img_sample_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Random shift operator", "\n", "", "get_rand_shift", "=", "lambda", ":", "None", "\n", "random_shift_factor", "=", "self", ".", "params", ".", "get", "(", "'random_shift_factor'", ",", "0", ")", "\n", "if", "random_shift_factor", ">", "0", ":", "\n", "            ", "get_rand_shift", "=", "lambda", ":", "(", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "*", "self", ".", "img_sample_sz", "*", "random_shift_factor", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Create transformations", "\n", "", "self", ".", "transforms", "=", "[", "augmentation", ".", "Identity", "(", "aug_output_sz", ")", "]", "\n", "if", "'shift'", "in", "self", ".", "params", ".", "augmentation", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "shift", ",", "aug_output_sz", ")", "for", "shift", "in", "self", ".", "params", ".", "augmentation", "[", "'shift'", "]", "]", ")", "\n", "", "if", "'relativeshift'", "in", "self", ".", "params", ".", "augmentation", ":", "\n", "            ", "get_absolute", "=", "lambda", "shift", ":", "(", "torch", ".", "Tensor", "(", "shift", ")", "*", "self", ".", "img_sample_sz", "/", "2", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "get_absolute", "(", "shift", ")", ",", "aug_output_sz", ")", "for", "shift", "in", "self", ".", "params", ".", "augmentation", "[", "'relativeshift'", "]", "]", ")", "\n", "", "if", "'fliplr'", "in", "self", ".", "params", ".", "augmentation", "and", "self", ".", "params", ".", "augmentation", "[", "'fliplr'", "]", ":", "\n", "            ", "self", ".", "transforms", ".", "append", "(", "augmentation", ".", "FlipHorizontal", "(", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", ")", "\n", "", "if", "'blur'", "in", "self", ".", "params", ".", "augmentation", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Blur", "(", "sigma", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "sigma", "in", "self", ".", "params", ".", "augmentation", "[", "'blur'", "]", "]", ")", "\n", "", "if", "'scale'", "in", "self", ".", "params", ".", "augmentation", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Scale", "(", "scale_factor", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "scale_factor", "in", "self", ".", "params", ".", "augmentation", "[", "'scale'", "]", "]", ")", "\n", "", "if", "'rotate'", "in", "self", ".", "params", ".", "augmentation", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Rotate", "(", "angle", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "angle", "in", "self", ".", "params", ".", "augmentation", "[", "'rotate'", "]", "]", ")", "\n", "\n", "# Generate initial samples", "\n", "", "init_samples", "=", "self", ".", "params", ".", "features", ".", "extract_transformed", "(", "im", ",", "self", ".", "pos", ",", "self", ".", "target_scale", ",", "aug_expansion_sz", ",", "self", ".", "transforms", ")", "\n", "\n", "# Remove augmented samples for those that shall not have", "\n", "for", "i", ",", "use_aug", "in", "enumerate", "(", "self", ".", "fparams", ".", "attribute", "(", "'use_augmentation'", ")", ")", ":", "\n", "            ", "if", "not", "use_aug", ":", "\n", "                ", "init_samples", "[", "i", "]", "=", "init_samples", "[", "i", "]", "[", "0", ":", "1", ",", "...", "]", "\n", "\n", "# Add dropout samples", "\n", "", "", "if", "'dropout'", "in", "self", ".", "params", ".", "augmentation", ":", "\n", "            ", "num", ",", "prob", "=", "self", ".", "params", ".", "augmentation", "[", "'dropout'", "]", "\n", "self", ".", "transforms", ".", "extend", "(", "self", ".", "transforms", "[", ":", "1", "]", "*", "num", ")", "\n", "for", "i", ",", "use_aug", "in", "enumerate", "(", "self", ".", "fparams", ".", "attribute", "(", "'use_augmentation'", ")", ")", ":", "\n", "                ", "if", "use_aug", ":", "\n", "                    ", "init_samples", "[", "i", "]", "=", "torch", ".", "cat", "(", "[", "init_samples", "[", "i", "]", ",", "F", ".", "dropout2d", "(", "init_samples", "[", "i", "]", "[", "0", ":", "1", ",", "...", "]", ".", "expand", "(", "num", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", ",", "p", "=", "prob", ",", "training", "=", "True", ")", "]", ")", "\n", "\n", "", "", "", "return", "init_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_projection_matrix": [[527, 549], ["atom.ATOM.params.get", "atom.ATOM.fparams.attribute", "atom.ATOM.params.get", "x.size", "pytracking.TensorList", "pytracking.TensorList", "pytracking.TensorList.mean", "pytracking.TensorList", "pytracking.TensorList.t", "pytracking.TensorList", "len", "e.permute().reshape().clone", "[].t().unsqueeze().unsqueeze().clone", "zip", "e.permute().reshape", "ex.new_zeros().normal_", "zip", "[].t().unsqueeze().unsqueeze", "e.permute", "ex.new_zeros", "math.sqrt", "[].t().unsqueeze", "[].t", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "init_projection_matrix", "(", "self", ",", "x", ")", ":", "\n", "# Set if using projection matrix", "\n", "        ", "self", ".", "params", ".", "use_projection_matrix", "=", "self", ".", "params", ".", "get", "(", "'use_projection_matrix'", ",", "True", ")", "\n", "\n", "if", "self", ".", "params", ".", "use_projection_matrix", ":", "\n", "            ", "self", ".", "compressed_dim", "=", "self", ".", "fparams", ".", "attribute", "(", "'compressed_dim'", ",", "None", ")", "\n", "\n", "proj_init_method", "=", "self", ".", "params", ".", "get", "(", "'proj_init_method'", ",", "'pca'", ")", "\n", "if", "proj_init_method", "==", "'pca'", ":", "\n", "                ", "x_mat", "=", "TensorList", "(", "[", "e", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "reshape", "(", "e", ".", "shape", "[", "1", "]", ",", "-", "1", ")", ".", "clone", "(", ")", "for", "e", "in", "x", "]", ")", "\n", "x_mat", "-=", "x_mat", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "cov_x", "=", "x_mat", "@", "x_mat", ".", "t", "(", ")", "\n", "self", ".", "projection_matrix", "=", "TensorList", "(", "\n", "[", "None", "if", "cdim", "is", "None", "else", "torch", ".", "svd", "(", "C", ")", "[", "0", "]", "[", ":", ",", ":", "cdim", "]", ".", "t", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "clone", "(", ")", "for", "C", ",", "cdim", "in", "\n", "zip", "(", "cov_x", ",", "self", ".", "compressed_dim", ")", "]", ")", "\n", "", "elif", "proj_init_method", "==", "'randn'", ":", "\n", "                ", "self", ".", "projection_matrix", "=", "TensorList", "(", "\n", "[", "None", "if", "cdim", "is", "None", "else", "ex", ".", "new_zeros", "(", "cdim", ",", "ex", ".", "shape", "[", "1", "]", ",", "1", ",", "1", ")", ".", "normal_", "(", "0", ",", "1", "/", "math", ".", "sqrt", "(", "ex", ".", "shape", "[", "1", "]", ")", ")", "for", "ex", ",", "cdim", "in", "\n", "zip", "(", "x", ",", "self", ".", "compressed_dim", ")", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "compressed_dim", "=", "x", ".", "size", "(", "1", ")", "\n", "self", ".", "projection_matrix", "=", "TensorList", "(", "[", "None", "]", "*", "len", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_label_function": [[550, 570], ["pytracking.TensorList", "atom.ATOM.fparams.attribute", "zip", "pytracking.TensorList", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "enumerate", "x.new_zeros", "atom.ATOM.pos.round", "pytracking.dcf.label_function_spatial", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "zip", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.label_function_spatial"], ["", "", "def", "init_label_function", "(", "self", ",", "train_x", ")", ":", "\n", "# Allocate label function", "\n", "        ", "self", ".", "y", "=", "TensorList", "(", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "1", ",", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "# Output sigma factor", "\n", "output_sigma_factor", "=", "self", ".", "fparams", ".", "attribute", "(", "'output_sigma_factor'", ")", "\n", "self", ".", "sigma", "=", "(", "self", ".", "feature_sz", "/", "self", ".", "img_support_sz", "*", "self", ".", "base_target_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "output_sigma_factor", "*", "torch", ".", "ones", "(", "2", ")", "\n", "\n", "# Center pos in normalized coords", "\n", "target_center_norm", "=", "(", "self", ".", "pos", "-", "self", ".", "pos", ".", "round", "(", ")", ")", "/", "(", "self", ".", "target_scale", "*", "self", ".", "img_support_sz", ")", "\n", "\n", "# Generate label functions", "\n", "for", "y", ",", "sig", ",", "sz", ",", "ksz", ",", "x", "in", "zip", "(", "self", ".", "y", ",", "self", ".", "sigma", ",", "self", ".", "feature_sz", ",", "self", ".", "kernel_size", ",", "train_x", ")", ":", "\n", "            ", "center_pos", "=", "sz", "*", "target_center_norm", "+", "0.5", "*", "torch", ".", "Tensor", "(", "[", "(", "ksz", "[", "0", "]", "+", "1", ")", "%", "2", ",", "(", "ksz", "[", "1", "]", "+", "1", ")", "%", "2", "]", ")", "\n", "for", "i", ",", "T", "in", "enumerate", "(", "self", ".", "transforms", "[", ":", "x", ".", "shape", "[", "0", "]", "]", ")", ":", "\n", "                ", "sample_center", "=", "center_pos", "+", "torch", ".", "Tensor", "(", "T", ".", "shift", ")", "/", "self", ".", "img_support_sz", "*", "sz", "\n", "y", "[", "i", ",", "0", ",", "...", "]", "=", "dcf", ".", "label_function_spatial", "(", "sz", ",", "sig", ",", "sample_center", ")", "\n", "\n", "# Return only the ones to use for initial training", "\n", "", "", "return", "TensorList", "(", "[", "y", "[", ":", "x", ".", "shape", "[", "0", "]", ",", "...", "]", "for", "y", ",", "x", "in", "zip", "(", "self", ".", "y", ",", "train_x", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_memory": [[572, 589], ["train_x.size", "pytracking.TensorList", "atom.ATOM.num_init_samples.copy", "pytracking.TensorList", "zip", "pytracking.TensorList", "len", "x.new_zeros", "x.new_zeros", "x.new_ones", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "def", "init_memory", "(", "self", ",", "train_x", ")", ":", "\n", "# Initialize first-frame training samples", "\n", "        ", "self", ".", "num_init_samples", "=", "train_x", ".", "size", "(", "0", ")", "\n", "self", ".", "init_sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_ones", "(", "1", ")", "/", "x", ".", "shape", "[", "0", "]", "for", "x", "in", "train_x", "]", ")", "\n", "self", ".", "init_training_samples", "=", "train_x", "\n", "\n", "# Sample counters and weights", "\n", "self", ".", "num_stored_samples", "=", "self", ".", "num_init_samples", ".", "copy", "(", ")", "\n", "self", ".", "previous_replace_ind", "=", "[", "None", "]", "*", "len", "(", "self", ".", "num_stored_samples", ")", "\n", "self", ".", "sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ")", "for", "x", "in", "train_x", "]", ")", "\n", "for", "sw", ",", "init_sw", ",", "num", "in", "zip", "(", "self", ".", "sample_weights", ",", "self", ".", "init_sample_weights", ",", "self", ".", "num_init_samples", ")", ":", "\n", "            ", "sw", "[", ":", "num", "]", "=", "init_sw", "\n", "\n", "# Initialize memory", "\n", "", "self", ".", "training_samples", "=", "TensorList", "(", "\n", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "cdim", ",", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", "for", "x", ",", "cdim", "in", "\n", "zip", "(", "train_x", ",", "self", ".", "compressed_dim", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.update_memory": [[590, 601], ["atom.ATOM.update_sample_weights", "zip", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_sample_weights"], ["", "def", "update_memory", "(", "self", ",", "sample_x", ":", "TensorList", ",", "sample_y", ":", "TensorList", ",", "learning_rate", "=", "None", ")", ":", "\n", "        ", "replace_ind", "=", "self", ".", "update_sample_weights", "(", "self", ".", "sample_weights", ",", "self", ".", "previous_replace_ind", ",", "self", ".", "num_stored_samples", ",", "self", ".", "num_init_samples", ",", "self", ".", "fparams", ",", "learning_rate", ")", "\n", "self", ".", "previous_replace_ind", "=", "replace_ind", "\n", "for", "train_samp", ",", "x", ",", "ind", "in", "zip", "(", "self", ".", "training_samples", ",", "sample_x", ",", "replace_ind", ")", ":", "\n", "            ", "train_samp", "[", "ind", ":", "ind", "+", "1", ",", "...", "]", "=", "x", "\n", "", "for", "y_memory", ",", "y", ",", "ind", "in", "zip", "(", "self", ".", "y", ",", "sample_y", ",", "replace_ind", ")", ":", "\n", "            ", "y_memory", "[", "ind", ":", "ind", "+", "1", ",", "...", "]", "=", "y", "\n", "", "if", "self", ".", "hinge_mask", "is", "not", "None", ":", "\n", "            ", "for", "m", ",", "y", ",", "ind", "in", "zip", "(", "self", ".", "hinge_mask", ",", "sample_y", ",", "replace_ind", ")", ":", "\n", "                ", "m", "[", "ind", ":", "ind", "+", "1", ",", "...", "]", "=", "(", "y", ">=", "self", ".", "params", ".", "hinge_threshold", ")", ".", "float", "(", ")", "\n", "", "", "self", ".", "num_stored_samples", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.update_sample_weights": [[603, 640], ["zip", "getattr", "sw.sum", "replace_ind.append", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "r_ind.item", "sw[].sum", "sw[].sum"], "methods", ["None"], ["", "def", "update_sample_weights", "(", "self", ",", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ",", "fparams", ",", "learning_rate", "=", "None", ")", ":", "\n", "# Update weights and get index to replace in memory", "\n", "        ", "replace_ind", "=", "[", "]", "\n", "for", "sw", ",", "prev_ind", ",", "num_samp", ",", "num_init", ",", "fpar", "in", "zip", "(", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ",", "fparams", ")", ":", "\n", "            ", "lr", "=", "learning_rate", "\n", "if", "lr", "is", "None", ":", "\n", "                ", "lr", "=", "fpar", ".", "learning_rate", "\n", "\n", "", "init_samp_weight", "=", "getattr", "(", "fpar", ",", "'init_samples_minimum_weight'", ",", "None", ")", "\n", "if", "init_samp_weight", "==", "0", ":", "\n", "                ", "init_samp_weight", "=", "None", "\n", "", "s_ind", "=", "0", "if", "init_samp_weight", "is", "None", "else", "num_init", "\n", "\n", "if", "num_samp", "==", "0", "or", "lr", "==", "1", ":", "\n", "                ", "sw", "[", ":", "]", "=", "0", "\n", "sw", "[", "0", "]", "=", "1", "\n", "r_ind", "=", "0", "\n", "", "else", ":", "\n", "# Get index to replace", "\n", "                ", "_", ",", "r_ind", "=", "torch", ".", "min", "(", "sw", "[", "s_ind", ":", "]", ",", "0", ")", "\n", "r_ind", "=", "r_ind", ".", "item", "(", ")", "+", "s_ind", "\n", "\n", "# Update weights", "\n", "if", "prev_ind", "is", "None", ":", "\n", "                    ", "sw", "/=", "1", "-", "lr", "\n", "sw", "[", "r_ind", "]", "=", "lr", "\n", "", "else", ":", "\n", "                    ", "sw", "[", "r_ind", "]", "=", "sw", "[", "prev_ind", "]", "/", "(", "1", "-", "lr", ")", "\n", "\n", "", "", "sw", "/=", "sw", ".", "sum", "(", ")", "\n", "if", "init_samp_weight", "is", "not", "None", "and", "sw", "[", ":", "num_init", "]", ".", "sum", "(", ")", "<", "init_samp_weight", ":", "\n", "                ", "sw", "/=", "init_samp_weight", "+", "sw", "[", "num_init", ":", "]", ".", "sum", "(", ")", "\n", "sw", "[", ":", "num_init", "]", "=", "init_samp_weight", "/", "num_init", "\n", "\n", "", "replace_ind", ".", "append", "(", "r_ind", ")", "\n", "\n", "", "return", "replace_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_label_function": [[641, 649], ["pytracking.TensorList", "zip", "pytracking.TensorList.append", "pytracking.dcf.label_function_spatial", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.label_function_spatial"], ["", "def", "get_label_function", "(", "self", ",", "sample_pos", ",", "sample_scale", ")", ":", "\n", "# Generate label function", "\n", "        ", "train_y", "=", "TensorList", "(", ")", "\n", "target_center_norm", "=", "(", "self", ".", "pos", "-", "sample_pos", ")", "/", "(", "sample_scale", "*", "self", ".", "img_support_sz", ")", "\n", "for", "sig", ",", "sz", ",", "ksz", "in", "zip", "(", "self", ".", "sigma", ",", "self", ".", "feature_sz", ",", "self", ".", "kernel_size", ")", ":", "\n", "            ", "center", "=", "sz", "*", "target_center_norm", "+", "0.5", "*", "torch", ".", "Tensor", "(", "[", "(", "ksz", "[", "0", "]", "+", "1", ")", "%", "2", ",", "(", "ksz", "[", "1", "]", "+", "1", ")", "%", "2", "]", ")", "\n", "train_y", ".", "append", "(", "dcf", ".", "label_function_spatial", "(", "sz", ",", "sig", ",", "center", ")", ")", "\n", "", "return", "train_y", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.update_state": [[650, 660], ["torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "new_scale.clamp", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "new_pos", ",", "new_scale", "=", "None", ")", ":", "\n", "# Update scale", "\n", "        ", "if", "new_scale", "is", "not", "None", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", ".", "clamp", "(", "self", ".", "min_scale_factor", ",", "self", ".", "max_scale_factor", ")", "\n", "self", ".", "target_sz", "=", "self", ".", "base_target_sz", "*", "self", ".", "target_scale", "\n", "\n", "# Update pos", "\n", "", "inside_ratio", "=", "0.2", "\n", "inside_offset", "=", "(", "inside_ratio", "-", "0.5", ")", "*", "self", ".", "target_sz", "\n", "self", ".", "pos", "=", "torch", ".", "max", "(", "torch", ".", "min", "(", "new_pos", ",", "self", ".", "image_sz", "-", "inside_offset", ")", ",", "inside_offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iounet_box": [[661, 667], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "target_ul.flip", "box_sz.flip"], "methods", ["None"], ["", "def", "get_iounet_box", "(", "self", ",", "pos", ",", "sz", ",", "sample_pos", ",", "sample_scale", ")", ":", "\n", "        ", "\"\"\"All inputs in original image coordinates\"\"\"", "\n", "box_center", "=", "(", "pos", "-", "sample_pos", ")", "/", "sample_scale", "+", "(", "self", ".", "iou_img_sample_sz", "-", "1", ")", "/", "2", "\n", "box_sz", "=", "sz", "/", "sample_scale", "\n", "target_ul", "=", "box_center", "-", "(", "box_sz", "-", "1", ")", "/", "2", "\n", "return", "torch", ".", "cat", "(", "[", "target_ul", ".", "flip", "(", "(", "0", ",", ")", ")", ",", "box_sz", ".", "flip", "(", "(", "0", ",", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.init_iou_net": [[668, 699], ["atom.ATOM.params.features.get_unique_attribute", "atom.ATOM.iou_predictor.parameters", "atom.ATOM.get_iounet_box", "pytracking.TensorList", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "atom.ATOM.get_iou_backbone_features", "pytracking.TensorList", "pytracking.TensorList", "atom.ATOM.params.get", "atom.ATOM.pos.round", "torch.cat().to.append", "torch.cat().to.append", "torch.cat().to.append", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "atom.ATOM.iou_predictor.get_modulation", "pytracking.TensorList", "torch.cat().to.append", "torch.cat().to.append", "torch.cat().to.append", "atom.ATOM.iou_target_box.clone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x.detach().mean", "isinstance", "torch.cat().to.view", "torch.cat().to.view", "torch.cat().to.view", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "x.detach", "tf.norm", "tf.numel"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.get_unique_attribute", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_modulation", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "init_iou_net", "(", "self", ")", ":", "\n", "# Setup IoU net", "\n", "        ", "self", ".", "iou_predictor", "=", "self", ".", "params", ".", "features", ".", "get_unique_attribute", "(", "'iou_predictor'", ")", "\n", "for", "p", "in", "self", ".", "iou_predictor", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "# Get target boxes for the different augmentations", "\n", "", "self", ".", "iou_target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "self", ".", "pos", ".", "round", "(", ")", ",", "self", ".", "target_scale", ")", "\n", "target_boxes", "=", "TensorList", "(", ")", "\n", "if", "self", ".", "params", ".", "iounet_augmentation", ":", "\n", "            ", "for", "T", "in", "self", ".", "transforms", ":", "\n", "                ", "if", "not", "isinstance", "(", "T", ",", "(", "augmentation", ".", "Identity", ",", "augmentation", ".", "Translation", ",", "augmentation", ".", "FlipHorizontal", ",", "augmentation", ".", "FlipVertical", ",", "augmentation", ".", "Blur", ")", ")", ":", "\n", "                    ", "break", "\n", "", "target_boxes", ".", "append", "(", "self", ".", "iou_target_box", "+", "torch", ".", "Tensor", "(", "[", "T", ".", "shift", "[", "1", "]", ",", "T", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "target_boxes", ".", "append", "(", "self", ".", "iou_target_box", ".", "clone", "(", ")", ")", "\n", "", "target_boxes", "=", "torch", ".", "cat", "(", "target_boxes", ".", "view", "(", "1", ",", "4", ")", ",", "0", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "\n", "# Get iou features", "\n", "iou_backbone_features", "=", "self", ".", "get_iou_backbone_features", "(", ")", "\n", "\n", "# Remove other augmentations such as rotation", "\n", "iou_backbone_features", "=", "TensorList", "(", "[", "x", "[", ":", "target_boxes", ".", "shape", "[", "0", "]", ",", "...", "]", "for", "x", "in", "iou_backbone_features", "]", ")", "\n", "\n", "# Extract target feat", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "target_feat", "=", "self", ".", "iou_predictor", ".", "get_modulation", "(", "iou_backbone_features", ",", "target_boxes", ")", "\n", "", "self", ".", "target_feat", "=", "TensorList", "(", "[", "x", ".", "detach", "(", ")", ".", "mean", "(", "0", ")", "for", "x", "in", "target_feat", "]", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'iounet_not_use_reference'", ",", "False", ")", ":", "\n", "            ", "self", ".", "target_feat", "=", "TensorList", "(", "[", "torch", ".", "full_like", "(", "tf", ",", "tf", ".", "norm", "(", ")", "/", "tf", ".", "numel", "(", ")", ")", "for", "tf", "in", "self", ".", "target_feat", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.refine_target_box": [[701, 757], ["atom.ATOM.get_iounet_box", "atom.ATOM.get_iou_features", "pytracking.TensorList", "atom.ATOM.view().clone", "atom.ATOM.optimize_boxes", "output_boxes[].clamp_", "atom.ATOM.params.get", "min", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "output_boxes[].mean", "[].mean", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "new_pos.clone", "atom.ATOM.params.get", "init_box[].prod().sqrt", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "predicted_box[].flip", "new_pos.clone", "atom.ATOM.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "init_box[].min", "new_pos.flip", "new_target_sz.prod", "atom.ATOM.base_target_sz.prod", "init_box[].prod", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "atom.ATOM.view", "output_iou.view", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.get_iou_features", "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.optimize_boxes", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "", "def", "refine_target_box", "(", "self", ",", "sample_pos", ",", "sample_scale", ",", "scale_ind", ",", "update_scale", "=", "True", ")", ":", "\n", "# Initial box for refinement", "\n", "        ", "init_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", ",", "sample_scale", ")", "\n", "\n", "# Extract features from the relevant scale", "\n", "iou_features", "=", "self", ".", "get_iou_features", "(", ")", "\n", "iou_features", "=", "TensorList", "(", "[", "x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "for", "x", "in", "iou_features", "]", ")", "\n", "\n", "init_boxes", "=", "init_box", ".", "view", "(", "1", ",", "4", ")", ".", "clone", "(", ")", "\n", "if", "self", ".", "params", ".", "num_init_random_boxes", ">", "0", ":", "\n", "# Get random initial boxes", "\n", "            ", "square_box_sz", "=", "init_box", "[", "2", ":", "]", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "rand_factor", "=", "square_box_sz", "*", "torch", ".", "cat", "(", "[", "self", ".", "params", ".", "box_jitter_pos", "*", "torch", ".", "ones", "(", "2", ")", ",", "self", ".", "params", ".", "box_jitter_sz", "*", "torch", ".", "ones", "(", "2", ")", "]", ")", "\n", "minimal_edge_size", "=", "init_box", "[", "2", ":", "]", ".", "min", "(", ")", "/", "3", "\n", "rand_bb", "=", "(", "torch", ".", "rand", "(", "self", ".", "params", ".", "num_init_random_boxes", ",", "4", ")", "-", "0.5", ")", "*", "rand_factor", "\n", "new_sz", "=", "(", "init_box", "[", "2", ":", "]", "+", "rand_bb", "[", ":", ",", "2", ":", "]", ")", ".", "clamp", "(", "minimal_edge_size", ")", "\n", "new_center", "=", "(", "init_box", "[", ":", "2", "]", "+", "init_box", "[", "2", ":", "]", "/", "2", ")", "+", "rand_bb", "[", ":", ",", ":", "2", "]", "\n", "init_boxes", "=", "torch", ".", "cat", "(", "[", "new_center", "-", "new_sz", "/", "2", ",", "new_sz", "]", ",", "1", ")", "\n", "init_boxes", "=", "torch", ".", "cat", "(", "[", "init_box", ".", "view", "(", "1", ",", "4", ")", ",", "init_boxes", "]", ")", "\n", "\n", "# Refine boxes by maximizing iou", "\n", "", "output_boxes", ",", "output_iou", "=", "self", ".", "optimize_boxes", "(", "iou_features", ",", "init_boxes", ")", "\n", "\n", "# Remove weird boxes with extreme aspect ratios", "\n", "output_boxes", "[", ":", ",", "2", ":", "]", ".", "clamp_", "(", "1", ")", "\n", "aspect_ratio", "=", "output_boxes", "[", ":", ",", "2", "]", "/", "output_boxes", "[", ":", ",", "3", "]", "\n", "keep_ind", "=", "(", "aspect_ratio", "<", "self", ".", "params", ".", "maximal_aspect_ratio", ")", "*", "(", "aspect_ratio", ">", "1", "/", "self", ".", "params", ".", "maximal_aspect_ratio", ")", "\n", "output_boxes", "=", "output_boxes", "[", "keep_ind", ",", ":", "]", "\n", "output_iou", "=", "output_iou", "[", "keep_ind", "]", "\n", "\n", "# If no box found", "\n", "if", "output_boxes", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "# Take average of top k boxes", "\n", "", "k", "=", "self", ".", "params", ".", "get", "(", "'iounet_k'", ",", "5", ")", "\n", "topk", "=", "min", "(", "k", ",", "output_boxes", ".", "shape", "[", "0", "]", ")", "\n", "_", ",", "inds", "=", "torch", ".", "topk", "(", "output_iou", ",", "topk", ")", "\n", "predicted_box", "=", "output_boxes", "[", "inds", ",", ":", "]", ".", "mean", "(", "0", ")", "\n", "predicted_iou", "=", "output_iou", ".", "view", "(", "-", "1", ",", "1", ")", "[", "inds", ",", ":", "]", ".", "mean", "(", "0", ")", "\n", "\n", "# Update position", "\n", "new_pos", "=", "predicted_box", "[", ":", "2", "]", "+", "predicted_box", "[", "2", ":", "]", "/", "2", "-", "(", "self", ".", "iou_img_sample_sz", "-", "1", ")", "/", "2", "\n", "new_pos", "=", "new_pos", ".", "flip", "(", "(", "0", ",", ")", ")", "*", "sample_scale", "+", "sample_pos", "\n", "new_target_sz", "=", "predicted_box", "[", "2", ":", "]", ".", "flip", "(", "(", "0", ",", ")", ")", "*", "sample_scale", "\n", "new_scale", "=", "torch", ".", "sqrt", "(", "new_target_sz", ".", "prod", "(", ")", "/", "self", ".", "base_target_sz", ".", "prod", "(", ")", ")", "\n", "\n", "self", ".", "pos_iounet", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_iounet_pos_for_learning'", ",", "True", ")", ":", "\n", "            ", "self", ".", "pos", "=", "new_pos", ".", "clone", "(", ")", "\n", "\n", "", "self", ".", "target_sz", "=", "new_target_sz", "\n", "\n", "if", "update_scale", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.atom.atom.ATOM.optimize_boxes": [[758, 837], ["init_boxes.view().to", "isinstance", "atom.ATOM.params.get", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "torch.Tensor().to().view", "ltr.rel_to_rect.new_ones", "ltr.rel_to_rect.new_ones", "range", "ltr.rel_to_rect.view().cpu", "atom.ATOM.detach().view().cpu", "init_boxes.view", "ltr.rel_to_rect.clone().detach", "atom.ATOM.iou_predictor.predict_iou", "isinstance", "atom.ATOM.backward", "update_mask.view().float", "atom.ATOM.detach().clone", "ltr.rel_to_rect.detach_", "output_boxes[].clone", "ltr.rect_to_rel", "range", "ltr.rel_to_rect", "ValueError", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "ltr.rect_to_rel.clone().detach", "ltr.rel_to_rect", "atom.ATOM.iou_predictor.predict_iou", "isinstance", "atom.ATOM.backward", "update_mask.view().float", "atom.ATOM.detach().clone", "ltr.rect_to_rel.detach_", "ltr.rel_to_rect.view", "atom.ATOM.detach().view", "ltr.rel_to_rect.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "atom.ATOM.detach", "update_mask.view", "atom.ATOM.detach", "bb_init[].repeat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "ltr.rect_to_rel.clone", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "atom.ATOM.detach", "update_mask.view", "atom.ATOM.detach", "atom.ATOM.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rect_to_rel", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou"], ["", "", "def", "optimize_boxes", "(", "self", ",", "iou_features", ",", "init_boxes", ")", ":", "\n", "# Optimize iounet boxes", "\n", "        ", "output_boxes", "=", "init_boxes", ".", "view", "(", "1", ",", "-", "1", ",", "4", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "step_length", "=", "self", ".", "params", ".", "box_refinement_step_length", "\n", "init_step_length", "=", "self", ".", "params", ".", "box_refinement_step_length", "\n", "if", "isinstance", "(", "step_length", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "init_step_length", "=", "torch", ".", "Tensor", "(", "[", "step_length", "[", "0", "]", ",", "step_length", "[", "0", "]", ",", "step_length", "[", "1", "]", ",", "step_length", "[", "1", "]", "]", ")", ".", "to", "(", "\n", "self", ".", "params", ".", "device", ")", ".", "view", "(", "1", ",", "1", ",", "4", ")", "\n", "", "box_refinement_space", "=", "self", ".", "params", ".", "get", "(", "'box_refinement_space'", ",", "'default'", ")", "\n", "\n", "step_length", "=", "init_step_length", "*", "output_boxes", ".", "new_ones", "(", "1", ",", "output_boxes", ".", "shape", "[", "1", "]", ",", "1", ")", "\n", "outputs_prev", "=", "-", "99999999", "*", "output_boxes", ".", "new_ones", "(", "1", ",", "output_boxes", ".", "shape", "[", "1", "]", ")", "\n", "step", "=", "torch", ".", "zeros_like", "(", "output_boxes", ")", "\n", "\n", "if", "box_refinement_space", "==", "'default'", ":", "\n", "# Optimization using bounding box space used in original IoUNet", "\n", "            ", "for", "i_", "in", "range", "(", "self", ".", "params", ".", "box_refinement_iter", ")", ":", "\n", "# forward pass", "\n", "                ", "bb_init", "=", "output_boxes", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "bb_init", ".", "requires_grad", "=", "True", "\n", "\n", "outputs", "=", "self", ".", "iou_predictor", ".", "predict_iou", "(", "self", ".", "target_feat", ",", "iou_features", ",", "bb_init", ")", "\n", "\n", "if", "isinstance", "(", "outputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                    ", "outputs", "=", "outputs", "[", "0", "]", "\n", "\n", "", "outputs", ".", "backward", "(", "gradient", "=", "torch", ".", "ones_like", "(", "outputs", ")", ")", "\n", "\n", "# Update mask and step length", "\n", "update_mask", "=", "(", "outputs", ".", "detach", "(", ")", ">", "outputs_prev", ")", "|", "(", "self", ".", "params", ".", "box_refinement_step_decay", ">=", "1", ")", "\n", "update_mask_float", "=", "update_mask", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", ".", "float", "(", ")", "\n", "step_length", "[", "~", "update_mask", ",", ":", "]", "*=", "self", ".", "params", ".", "box_refinement_step_decay", "\n", "outputs_prev", "=", "outputs", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "\n", "# Update proposal", "\n", "step", "=", "update_mask_float", "*", "step_length", "*", "bb_init", ".", "grad", "*", "bb_init", "[", ":", ",", ":", ",", "2", ":", "]", ".", "repeat", "(", "1", ",", "1", ",", "2", ")", "-", "(", "\n", "1.0", "-", "update_mask_float", ")", "*", "step", "\n", "output_boxes", "=", "bb_init", "+", "step", "\n", "output_boxes", ".", "detach_", "(", ")", "\n", "\n", "", "", "elif", "box_refinement_space", "==", "'relative'", ":", "\n", "# Optimization using relative bounding box space", "\n", "            ", "sz_norm", "=", "output_boxes", "[", ":", ",", ":", "1", ",", "2", ":", "]", ".", "clone", "(", ")", "\n", "output_boxes_rel", "=", "bbutils", ".", "rect_to_rel", "(", "output_boxes", ",", "sz_norm", ")", "\n", "for", "i_", "in", "range", "(", "self", ".", "params", ".", "box_refinement_iter", ")", ":", "\n", "# forward pass", "\n", "                ", "bb_init_rel", "=", "output_boxes_rel", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "bb_init_rel", ".", "requires_grad", "=", "True", "\n", "\n", "bb_init", "=", "bbutils", ".", "rel_to_rect", "(", "bb_init_rel", ",", "sz_norm", ")", "\n", "outputs", "=", "self", ".", "iou_predictor", ".", "predict_iou", "(", "self", ".", "target_feat", ",", "iou_features", ",", "bb_init", ")", "\n", "\n", "if", "isinstance", "(", "outputs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                    ", "outputs", "=", "outputs", "[", "0", "]", "\n", "\n", "", "outputs", ".", "backward", "(", "gradient", "=", "torch", ".", "ones_like", "(", "outputs", ")", ")", "\n", "\n", "# Update mask and step length", "\n", "update_mask", "=", "(", "outputs", ".", "detach", "(", ")", ">", "outputs_prev", ")", "|", "(", "self", ".", "params", ".", "box_refinement_step_decay", ">=", "1", ")", "\n", "update_mask_float", "=", "update_mask", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", ".", "float", "(", ")", "\n", "step_length", "[", "~", "update_mask", ",", ":", "]", "*=", "self", ".", "params", ".", "box_refinement_step_decay", "\n", "outputs_prev", "=", "outputs", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "\n", "# Update proposal", "\n", "step", "=", "update_mask_float", "*", "step_length", "*", "bb_init_rel", ".", "grad", "-", "(", "1.0", "-", "update_mask_float", ")", "*", "step", "\n", "output_boxes_rel", "=", "bb_init_rel", "+", "step", "\n", "output_boxes_rel", ".", "detach_", "(", ")", "\n", "\n", "# for s in outputs.view(-1):", "\n", "#     print('{:.2f}  '.format(s.item()), end='')", "\n", "# print('')", "\n", "# print('')", "\n", "\n", "", "output_boxes", "=", "bbutils", ".", "rel_to_rect", "(", "output_boxes_rel", ",", "sz_norm", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown box_refinement_space {}'", ".", "format", "(", "box_refinement_space", ")", ")", "\n", "\n", "", "return", "output_boxes", ".", "view", "(", "-", "1", ",", "4", ")", ".", "cpu", "(", ")", ",", "outputs", ".", "detach", "(", ")", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp101.parameters": [[4, 61], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "train_feature_size", "=", "18", "\n", "params", ".", "feature_stride", "=", "16", "\n", "params", ".", "image_sample_size", "=", "params", ".", "train_feature_size", "*", "params", ".", "feature_stride", "\n", "params", ".", "search_area_scale", "=", "5", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "1.5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "2", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "False", "\n", "params", ".", "augmentation", "=", "{", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "params", ".", "conf_ths", "=", "0.9", "\n", "params", ".", "search_area_rescaling_at_occlusion", "=", "True", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'tomp101.pth.tar'", ",", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "params", ".", "use_gt_box", "=", "True", "\n", "params", ".", "plot_iou", "=", "True", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters": [[4, 61], ["pytracking.utils.TrackerParams", "pytracking.features.net_wrappers.NetWithBackbone"], "function", ["None"], ["def", "parameters", "(", ")", ":", "\n", "    ", "params", "=", "TrackerParams", "(", ")", "\n", "\n", "params", ".", "debug", "=", "0", "\n", "params", ".", "visualization", "=", "False", "\n", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "params", ".", "train_feature_size", "=", "18", "\n", "params", ".", "feature_stride", "=", "16", "\n", "params", ".", "image_sample_size", "=", "params", ".", "train_feature_size", "*", "params", ".", "feature_stride", "\n", "params", ".", "search_area_scale", "=", "5", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "1.5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "2", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "False", "\n", "params", ".", "augmentation", "=", "{", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "params", ".", "conf_ths", "=", "0.9", "\n", "params", ".", "search_area_rescaling_at_occlusion", "=", "True", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'tomp50.pth.tar'", ",", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "params", ".", "use_gt_box", "=", "True", "\n", "params", ".", "plot_iou", "=", "True", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features": [[20, 24], ["getattr", "tomp.ToMP.params.net.initialize"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["def", "initialize_features", "(", "self", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "self", ",", "'features_initialized'", ",", "False", ")", ":", "\n", "            ", "self", ".", "params", ".", "net", ".", "initialize", "(", ")", "\n", "", "self", ".", "features_initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize": [[25, 98], ["tomp.ToMP.initialize_features", "time.time", "pytracking.features.preprocessing.numpy_to_torch", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "tomp.ToMP.params.get", "tomp.ToMP.params.get", "tomp.ToMP.params.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.prod().item", "torch.max", "torch.max", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min", "tomp.ToMP.generate_init_samples", "tomp.ToMP.init_classifier", "collections.defaultdict", "tomp.ToMP.params.has", "info.get", "tomp.ToMP.params.get", "math.sqrt", "tomp.ToMP.img_sample_sz.prod().sqrt", "tomp.ToMP.params.has", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "isinstance", "isinstance", "tomp.ToMP.image_sz.prod().sqrt", "torch.round", "torch.round", "torch.round", "torch.round", "torch.prod", "torch.prod", "torch.prod", "torch.prod", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "time.time", "torch.Tensor.prod().sqrt", "torch.Tensor.prod().sqrt", "tomp.ToMP.img_sample_sz.prod", "tomp.ToMP.image_sz.prod", "torch.Tensor.prod", "torch.Tensor.prod"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.generate_init_samples", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_classifier", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.utils.params.TrackerParams.has"], ["", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "# Initialize some stuff", "\n", "        ", "self", ".", "frame_num", "=", "1", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'device'", ")", ":", "\n", "            ", "self", ".", "params", ".", "device", "=", "'cuda'", "if", "self", ".", "params", ".", "use_gpu", "else", "'cpu'", "\n", "\n", "# Initialize network", "\n", "", "self", ".", "initialize_features", "(", ")", "\n", "\n", "# The DiMP network", "\n", "self", ".", "net", "=", "self", ".", "params", ".", "net", "\n", "\n", "# Time initialization", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# Get target position and size", "\n", "state", "=", "info", "[", "'init_bbox'", "]", "\n", "self", ".", "pos", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "1", "]", "+", "(", "state", "[", "3", "]", "-", "1", ")", "/", "2", ",", "state", "[", "0", "]", "+", "(", "state", "[", "2", "]", "-", "1", ")", "/", "2", "]", ")", "\n", "self", ".", "target_sz", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "3", "]", ",", "state", "[", "2", "]", "]", ")", "\n", "\n", "# Get object id", "\n", "self", ".", "object_id", "=", "info", ".", "get", "(", "'object_ids'", ",", "[", "None", "]", ")", "[", "0", "]", "\n", "self", ".", "id_str", "=", "''", "if", "self", ".", "object_id", "is", "None", "else", "' {}'", ".", "format", "(", "self", ".", "object_id", ")", "\n", "\n", "# Set sizes", "\n", "self", ".", "image_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "sz", "=", "self", ".", "params", ".", "image_sample_size", "\n", "sz", "=", "torch", ".", "Tensor", "(", "[", "sz", ",", "sz", "]", "if", "isinstance", "(", "sz", ",", "int", ")", "else", "sz", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'use_image_aspect_ratio'", ",", "False", ")", ":", "\n", "            ", "sz", "=", "self", ".", "image_sz", "*", "sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "/", "self", ".", "image_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "stride", "=", "self", ".", "params", ".", "get", "(", "'feature_stride'", ",", "32", ")", "\n", "sz", "=", "torch", ".", "round", "(", "sz", "/", "stride", ")", "*", "stride", "\n", "", "self", ".", "img_sample_sz", "=", "sz", "\n", "self", ".", "img_support_sz", "=", "self", ".", "img_sample_sz", "\n", "tfs", "=", "self", ".", "params", ".", "get", "(", "'train_feature_size'", ",", "18", ")", "\n", "stride", "=", "self", ".", "params", ".", "get", "(", "'feature_stride'", ",", "16", ")", "\n", "self", ".", "train_img_sample_sz", "=", "torch", ".", "Tensor", "(", "[", "tfs", "*", "stride", ",", "tfs", "*", "stride", "]", ")", "\n", "\n", "# Set search area", "\n", "search_area", "=", "torch", ".", "prod", "(", "self", ".", "target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ".", "item", "(", ")", "\n", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", ")", "/", "self", ".", "img_sample_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "\n", "# Target size in base scale", "\n", "self", ".", "base_target_sz", "=", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "\n", "# Setup scale factors", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'scale_factors'", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "ones", "(", "1", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "params", ".", "scale_factors", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "self", ".", "params", ".", "scale_factors", "=", "torch", ".", "Tensor", "(", "self", ".", "params", ".", "scale_factors", ")", "\n", "\n", "# Setup scale bounds", "\n", "", "self", ".", "min_scale_factor", "=", "torch", ".", "max", "(", "10", "/", "self", ".", "base_target_sz", ")", "\n", "self", ".", "max_scale_factor", "=", "torch", ".", "min", "(", "self", ".", "image_sz", "/", "self", ".", "base_target_sz", ")", "\n", "\n", "# Extract and transform sample", "\n", "init_backbone_feat", "=", "self", ".", "generate_init_samples", "(", "im", ")", "\n", "\n", "# Initialize classifier", "\n", "self", ".", "init_classifier", "(", "init_backbone_feat", ")", "\n", "\n", "self", ".", "logging_dict", "=", "defaultdict", "(", "list", ")", "\n", "\n", "self", ".", "target_scales", "=", "[", "]", "\n", "self", ".", "target_not_found_counter", "=", "0", "\n", "\n", "self", ".", "cls_weights_avg", "=", "None", "\n", "\n", "out", "=", "{", "'time'", ":", "time", ".", "time", "(", ")", "-", "tic", "}", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.clip_bbox_to_image_area": [[99, 106], ["max", "max", "max", "max", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "min", "min", "min", "min"], "methods", ["None"], ["", "def", "clip_bbox_to_image_area", "(", "self", ",", "bbox", ",", "image", ",", "minwidth", "=", "10", ",", "minheight", "=", "10", ")", ":", "\n", "        ", "H", ",", "W", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "x1", "=", "max", "(", "0", ",", "min", "(", "bbox", "[", "0", "]", ",", "W", "-", "minwidth", ")", ")", "\n", "y1", "=", "max", "(", "0", ",", "min", "(", "bbox", "[", "1", "]", ",", "H", "-", "minheight", ")", ")", "\n", "x2", "=", "max", "(", "x1", "+", "minwidth", ",", "min", "(", "bbox", "[", "0", "]", "+", "bbox", "[", "2", "]", ",", "W", ")", ")", "\n", "y2", "=", "max", "(", "y1", "+", "minheight", ",", "min", "(", "bbox", "[", "1", "]", "+", "bbox", "[", "3", "]", ",", "H", ")", ")", "\n", "return", "torch", ".", "Tensor", "(", "[", "x1", ",", "y1", ",", "x2", "-", "x1", ",", "y2", "-", "y1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.encode_bbox": [[107, 141], ["tomp.ToMP.params.get", "tomp.ToMP.params.get", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "shift_x.reshape.reshape.reshape", "shift_y.reshape.reshape.reshape", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack().reshape", "torch.stack().reshape", "torch.stack().reshape", "torch.stack().reshape", "reg_targets_per_im.reshape().permute.reshape().permute.reshape().permute", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "reg_targets_per_im.reshape().permute.reshape().permute.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "encode_bbox", "(", "self", ",", "bbox", ")", ":", "\n", "        ", "stride", "=", "self", ".", "params", ".", "get", "(", "'feature_stride'", ")", "\n", "output_sz", "=", "self", ".", "params", ".", "get", "(", "'image_sample_size'", ")", "\n", "\n", "shifts_x", "=", "torch", ".", "arange", "(", "\n", "0", ",", "output_sz", ",", "step", "=", "stride", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "bbox", ".", "device", "\n", ")", "\n", "shifts_y", "=", "torch", ".", "arange", "(", "\n", "0", ",", "output_sz", ",", "step", "=", "stride", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "bbox", ".", "device", "\n", ")", "\n", "shift_y", ",", "shift_x", "=", "torch", ".", "meshgrid", "(", "shifts_y", ",", "shifts_x", ")", "\n", "shift_x", "=", "shift_x", ".", "reshape", "(", "-", "1", ")", "\n", "shift_y", "=", "shift_y", ".", "reshape", "(", "-", "1", ")", "\n", "locations", "=", "torch", ".", "stack", "(", "(", "shift_x", ",", "shift_y", ")", ",", "dim", "=", "1", ")", "+", "stride", "//", "2", "\n", "xs", ",", "ys", "=", "locations", "[", ":", ",", "0", "]", ",", "locations", "[", ":", ",", "1", "]", "\n", "\n", "xyxy", "=", "torch", ".", "stack", "(", "[", "bbox", "[", ":", ",", "0", "]", ",", "bbox", "[", ":", ",", "1", "]", ",", "bbox", "[", ":", ",", "0", "]", "+", "bbox", "[", ":", ",", "2", "]", ",", "\n", "bbox", "[", ":", ",", "1", "]", "+", "bbox", "[", ":", ",", "3", "]", "]", ",", "dim", "=", "1", ")", "\n", "\n", "l", "=", "xs", "[", ":", ",", "None", "]", "-", "xyxy", "[", ":", ",", "0", "]", "[", "None", "]", "\n", "t", "=", "ys", "[", ":", ",", "None", "]", "-", "xyxy", "[", ":", ",", "1", "]", "[", "None", "]", "\n", "r", "=", "xyxy", "[", ":", ",", "2", "]", "[", "None", "]", "-", "xs", "[", ":", ",", "None", "]", "\n", "b", "=", "xyxy", "[", ":", ",", "3", "]", "[", "None", "]", "-", "ys", "[", ":", ",", "None", "]", "\n", "reg_targets_per_im", "=", "torch", ".", "stack", "(", "[", "l", ",", "t", ",", "r", ",", "b", "]", ",", "dim", "=", "2", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "\n", "\n", "reg_targets_per_im", "=", "reg_targets_per_im", "/", "output_sz", "\n", "\n", "sz", "=", "output_sz", "//", "stride", "\n", "nb", "=", "bbox", ".", "shape", "[", "0", "]", "\n", "reg_targets_per_im", "=", "reg_targets_per_im", ".", "reshape", "(", "sz", ",", "sz", ",", "nb", ",", "4", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", "\n", "\n", "return", "reg_targets_per_im", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.track": [[142, 218], ["pytracking.features.preprocessing.numpy_to_torch", "tomp.ToMP.extract_backbone_features", "tomp.ToMP.get_backbone_head_feat", "tomp.ToMP.get_sample_location", "tomp.ToMP.classify_target", "tomp.ToMP.localize_target", "tomp.ToMP.direct_bbox_regression", "tomp.ToMP.clip_bbox_to_image_area", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tomp.ToMP.params.get", "tomp.ToMP.get_centered_sample_pos", "bbox[].flip", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "tomp.ToMP.target_scales.append", "tomp.ToMP.params.get", "tomp.ToMP.params.get", "tomp.ToMP.params.get", "tomp.ToMP.get_iounet_box", "tomp.ToMP.get_label_function().to", "tomp.ToMP.update_memory", "torch.cat.tolist", "torch.cat.tolist", "score_map.max().cpu().item", "tomp.ToMP.visualize_raw_results", "bbox[].flip", "tomp.ToMP.search_area_rescaling", "scores_raw.max", "tomp.ToMP.params.get", "pytracking.TensorList", "bbox[].flip", "tomp.ToMP.target_sz.prod", "tomp.ToMP.base_target_sz.prod", "tomp.ToMP.get_label_function", "score_map.max().cpu", "score_map.max"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.ToMPnet.get_backbone_head_feat", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_sample_location", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.classify_target", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_target", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.direct_bbox_regression", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.clip_bbox_to_image_area", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_centered_sample_pos", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_memory", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.visualize_raw_results", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.search_area_rescaling", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_label_function"], ["", "def", "track", "(", "self", ",", "image", ",", "info", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "        ", "self", ".", "debug_info", "=", "{", "}", "\n", "\n", "self", ".", "frame_num", "+=", "1", "\n", "self", ".", "debug_info", "[", "'frame_num'", "]", "=", "self", ".", "frame_num", "\n", "\n", "# Convert image", "\n", "im", "=", "numpy_to_torch", "(", "image", ")", "\n", "\n", "# ------- LOCALIZATION ------- #", "\n", "\n", "# Extract backbone features", "\n", "backbone_feat", ",", "sample_coords", ",", "im_patches", "=", "self", ".", "extract_backbone_features", "(", "im", ",", "self", ".", "get_centered_sample_pos", "(", ")", ",", "\n", "self", ".", "target_scale", "*", "self", ".", "params", ".", "scale_factors", ",", "\n", "self", ".", "img_sample_sz", ")", "\n", "# Extract classification features", "\n", "test_x", "=", "self", ".", "get_backbone_head_feat", "(", "backbone_feat", ")", "\n", "\n", "# Location of sample", "\n", "sample_pos", ",", "sample_scales", "=", "self", ".", "get_sample_location", "(", "sample_coords", ")", "\n", "\n", "# Compute classification scores", "\n", "scores_raw", ",", "bbox_preds", "=", "self", ".", "classify_target", "(", "test_x", ")", "\n", "\n", "translation_vec", ",", "scale_ind", ",", "s", ",", "flag", ",", "score_loc", "=", "self", ".", "localize_target", "(", "scores_raw", ",", "sample_pos", ",", "sample_scales", ")", "\n", "\n", "bbox_raw", "=", "self", ".", "direct_bbox_regression", "(", "bbox_preds", ",", "sample_coords", ",", "score_loc", ",", "scores_raw", ")", "\n", "bbox", "=", "self", ".", "clip_bbox_to_image_area", "(", "bbox_raw", ",", "image", ")", "\n", "\n", "if", "flag", "!=", "'not_found'", ":", "\n", "            ", "self", ".", "pos", "=", "bbox", "[", ":", "2", "]", ".", "flip", "(", "0", ")", "+", "bbox", "[", "2", ":", "]", ".", "flip", "(", "0", ")", "/", "2", "# [y + h/2, x + w/2]", "\n", "self", ".", "target_sz", "=", "bbox", "[", "2", ":", "]", ".", "flip", "(", "0", ")", "\n", "self", ".", "target_scale", "=", "torch", ".", "sqrt", "(", "self", ".", "target_sz", ".", "prod", "(", ")", "/", "self", ".", "base_target_sz", ".", "prod", "(", ")", ")", "\n", "self", ".", "target_scales", ".", "append", "(", "self", ".", "target_scale", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "params", ".", "get", "(", "'search_area_rescaling_at_occlusion'", ",", "False", ")", ":", "\n", "                ", "self", ".", "search_area_rescaling", "(", ")", "\n", "\n", "# ------- UPDATE ------- #", "\n", "\n", "", "", "update_flag", "=", "flag", "not", "in", "[", "'not_found'", ",", "'uncertain'", "]", "\n", "hard_negative", "=", "(", "flag", "==", "'hard_negative'", ")", "\n", "learning_rate", "=", "self", ".", "params", ".", "get", "(", "'hard_negative_learning_rate'", ",", "None", ")", "if", "hard_negative", "else", "None", "\n", "\n", "if", "update_flag", "and", "self", ".", "params", ".", "get", "(", "'update_classifier'", ",", "False", ")", "and", "scores_raw", ".", "max", "(", ")", ">", "self", ".", "params", ".", "get", "(", "'conf_ths'", ",", "0.0", ")", ":", "\n", "# Get train sample", "\n", "            ", "train_x", "=", "test_x", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", "\n", "\n", "# Create target_box and label for spatial sample", "\n", "target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ")", "\n", "train_y", "=", "self", ".", "get_label_function", "(", "self", ".", "pos", ",", "sample_pos", "[", "scale_ind", ",", ":", "]", ",", "sample_scales", "[", "scale_ind", "]", ")", ".", "to", "(", "\n", "self", ".", "params", ".", "device", ")", "\n", "\n", "# Update the classifier model", "\n", "self", ".", "update_memory", "(", "TensorList", "(", "[", "train_x", "]", ")", ",", "train_y", ",", "target_box", ",", "learning_rate", ")", "\n", "\n", "", "score_map", "=", "s", "[", "scale_ind", ",", "...", "]", "\n", "\n", "# Compute output bounding box", "\n", "new_state", "=", "torch", ".", "cat", "(", "(", "self", ".", "pos", "[", "[", "1", ",", "0", "]", "]", "-", "(", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", "-", "1", ")", "/", "2", ",", "self", ".", "target_sz", "[", "[", "1", ",", "0", "]", "]", ")", ")", "\n", "\n", "# Visualize and set debug info", "\n", "self", ".", "search_area_box", "=", "torch", ".", "cat", "(", "(", "sample_coords", "[", "0", ",", "[", "1", ",", "0", "]", "]", ",", "sample_coords", "[", "0", ",", "[", "3", ",", "2", "]", "]", "-", "sample_coords", "[", "0", ",", "[", "1", ",", "0", "]", "]", "-", "1", ")", ")", "\n", "\n", "if", "self", ".", "params", ".", "get", "(", "'output_not_found_box'", ",", "False", ")", ":", "\n", "            ", "output_state", "=", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "output_state", "=", "new_state", ".", "tolist", "(", ")", "\n", "\n", "", "out", "=", "{", "'target_bbox'", ":", "output_state", ",", "\n", "'object_presence_score'", ":", "score_map", ".", "max", "(", ")", ".", "cpu", "(", ")", ".", "item", "(", ")", "}", "\n", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "            ", "self", ".", "visualize_raw_results", "(", "score_map", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.visualize_raw_results": [[219, 225], ["tomp.ToMP.visdom.register", "tomp.ToMP.logging_dict[].append", "tomp.ToMP.visdom.register", "score_map.max().item", "tomp.ToMP.visdom.register", "score_map.max", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "score_map.max"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register"], ["", "def", "visualize_raw_results", "(", "self", ",", "score_map", ")", ":", "\n", "        ", "self", ".", "visdom", ".", "register", "(", "score_map", ",", "'heatmap'", ",", "2", ",", "'Score Map'", "+", "self", ".", "id_str", ")", "\n", "self", ".", "logging_dict", "[", "'max_score'", "]", ".", "append", "(", "score_map", ".", "max", "(", ")", ")", "\n", "self", ".", "visdom", ".", "register", "(", "torch", ".", "tensor", "(", "self", ".", "logging_dict", "[", "'max_score'", "]", ")", ",", "'lineplot'", ",", "3", ",", "'Max Score'", ")", "\n", "self", ".", "debug_info", "[", "'max_score'", "]", "=", "score_map", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "visdom", ".", "register", "(", "self", ".", "debug_info", ",", "'info_dict'", ",", "1", ",", "'Status'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.direct_bbox_regression": [[226, 259], ["torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "shift_x.reshape.reshape.reshape", "shift_y.reshape.reshape.reshape", "xs.reshape.reshape.reshape", "ys.reshape.reshape.reshape", "score_loc.int", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "[].cpu", "bbox_preds.permute"], "methods", ["None"], ["", "def", "direct_bbox_regression", "(", "self", ",", "bbox_preds", ",", "sample_coords", ",", "score_loc", ",", "scores_raw", ")", ":", "\n", "        ", "shifts_x", "=", "torch", ".", "arange", "(", "\n", "0", ",", "self", ".", "img_sample_sz", "[", "0", "]", ",", "step", "=", "16", ",", "\n", "dtype", "=", "torch", ".", "float32", "\n", ")", "\n", "shifts_y", "=", "torch", ".", "arange", "(", "\n", "0", ",", "self", ".", "img_sample_sz", "[", "1", "]", ",", "step", "=", "16", ",", "\n", "dtype", "=", "torch", ".", "float32", "\n", ")", "\n", "shift_y", ",", "shift_x", "=", "torch", ".", "meshgrid", "(", "shifts_y", ",", "shifts_x", ")", "\n", "shift_x", "=", "shift_x", ".", "reshape", "(", "-", "1", ")", "\n", "shift_y", "=", "shift_y", ".", "reshape", "(", "-", "1", ")", "\n", "locations", "=", "torch", ".", "stack", "(", "(", "shift_x", ",", "shift_y", ")", ",", "dim", "=", "1", ")", "+", "16", "//", "2", "\n", "xs", ",", "ys", "=", "locations", "[", ":", ",", "0", "]", ",", "locations", "[", ":", ",", "1", "]", "\n", "s1", ",", "s2", "=", "scores_raw", ".", "shape", "[", "2", ":", "]", "\n", "xs", "=", "xs", ".", "reshape", "(", "s1", ",", "s2", ")", "\n", "ys", "=", "ys", ".", "reshape", "(", "s1", ",", "s2", ")", "\n", "\n", "ltrb", "=", "bbox_preds", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", "[", "0", ",", "0", "]", ".", "cpu", "(", ")", "*", "self", ".", "train_img_sample_sz", "[", "[", "0", ",", "1", ",", "0", ",", "1", "]", "]", "\n", "xs1", "=", "xs", "-", "ltrb", "[", ":", ",", ":", ",", "0", "]", "\n", "xs2", "=", "xs", "+", "ltrb", "[", ":", ",", ":", ",", "2", "]", "\n", "ys1", "=", "ys", "-", "ltrb", "[", ":", ",", ":", ",", "1", "]", "\n", "ys2", "=", "ys", "+", "ltrb", "[", ":", ",", ":", ",", "3", "]", "\n", "sl", "=", "score_loc", ".", "int", "(", ")", "\n", "\n", "x1", "=", "xs1", "[", "sl", "[", "0", "]", ",", "sl", "[", "1", "]", "]", "/", "self", ".", "img_sample_sz", "[", "1", "]", "*", "(", "sample_coords", "[", "0", ",", "3", "]", "-", "sample_coords", "[", "0", ",", "1", "]", ")", "+", "sample_coords", "[", "0", ",", "1", "]", "\n", "y1", "=", "ys1", "[", "sl", "[", "0", "]", ",", "sl", "[", "1", "]", "]", "/", "self", ".", "img_sample_sz", "[", "0", "]", "*", "(", "sample_coords", "[", "0", ",", "2", "]", "-", "sample_coords", "[", "0", ",", "0", "]", ")", "+", "sample_coords", "[", "0", ",", "0", "]", "\n", "x2", "=", "xs2", "[", "sl", "[", "0", "]", ",", "sl", "[", "1", "]", "]", "/", "self", ".", "img_sample_sz", "[", "1", "]", "*", "(", "sample_coords", "[", "0", ",", "3", "]", "-", "sample_coords", "[", "0", ",", "1", "]", ")", "+", "sample_coords", "[", "0", ",", "1", "]", "\n", "y2", "=", "ys2", "[", "sl", "[", "0", "]", ",", "sl", "[", "1", "]", "]", "/", "self", ".", "img_sample_sz", "[", "0", "]", "*", "(", "sample_coords", "[", "0", ",", "2", "]", "-", "sample_coords", "[", "0", ",", "0", "]", ")", "+", "sample_coords", "[", "0", ",", "0", "]", "\n", "w", "=", "x2", "-", "x1", "\n", "h", "=", "y2", "-", "y1", "\n", "\n", "return", "torch", ".", "Tensor", "(", "[", "x1", ",", "y1", ",", "w", ",", "h", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.search_area_rescaling": [[260, 269], ["len", "max", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "min", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "search_area_rescaling", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "target_scales", ")", ">", "0", ":", "\n", "            ", "min_scales", ",", "max_scales", ",", "max_history", "=", "2", ",", "30", ",", "60", "\n", "self", ".", "target_not_found_counter", "+=", "1", "\n", "num_scales", "=", "max", "(", "min_scales", ",", "min", "(", "max_scales", ",", "self", ".", "target_not_found_counter", ")", ")", "\n", "target_scales", "=", "torch", ".", "tensor", "(", "self", ".", "target_scales", ")", "[", "-", "max_history", ":", "]", "\n", "target_scales", "=", "target_scales", "[", "target_scales", ">=", "target_scales", "[", "-", "1", "]", "]", "# only boxes that are bigger than the `not found`", "\n", "target_scales", "=", "target_scales", "[", "-", "num_scales", ":", "]", "# look as many samples into past as not found endures.", "\n", "self", ".", "target_scale", "=", "torch", ".", "mean", "(", "target_scales", ")", "# average bigger boxes from the past", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_sample_location": [[270, 276], ["sample_coord.float.float.float"], "methods", ["None"], ["", "", "def", "get_sample_location", "(", "self", ",", "sample_coord", ")", ":", "\n", "        ", "\"\"\"Get the location of the extracted sample.\"\"\"", "\n", "sample_coord", "=", "sample_coord", ".", "float", "(", ")", "\n", "sample_pos", "=", "0.5", "*", "(", "sample_coord", "[", ":", ",", ":", "2", "]", "+", "sample_coord", "[", ":", ",", "2", ":", "]", "-", "1", ")", "\n", "sample_scales", "=", "(", "(", "sample_coord", "[", ":", ",", "2", ":", "]", "-", "sample_coord", "[", ":", ",", ":", "2", "]", ")", "/", "self", ".", "img_sample_sz", ")", ".", "prod", "(", "dim", "=", "1", ")", ".", "sqrt", "(", ")", "\n", "return", "sample_pos", ",", "sample_scales", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_centered_sample_pos": [[277, 281], ["None"], "methods", ["None"], ["", "def", "get_centered_sample_pos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the center position for the new sample. Make sure the target is correctly centered.\"\"\"", "\n", "return", "self", ".", "pos", "+", "(", "(", "self", ".", "feature_sz", "+", "self", ".", "kernel_size", ")", "%", "2", ")", "*", "self", ".", "target_scale", "*", "self", ".", "img_support_sz", "/", "(", "2", "*", "self", ".", "feature_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.classify_target": [[282, 304], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tomp.ToMP.net.head.extract_head_feat", "tomp.ToMP.net.head.extract_head_feat", "tomp.ToMP.encode_bbox", "tomp.ToMP.net.head.get_filter_and_features_in_parallel", "tomp.ToMP.net.head.classifier", "tomp.ToMP.net.head.bb_regressor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.extract_head_feat", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.extract_head_feat", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.encode_bbox", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.get_filter_and_features_in_parallel"], ["", "def", "classify_target", "(", "self", ",", "sample_x", ":", "TensorList", ")", ":", "\n", "        ", "\"\"\"Classify target by applying the DiMP filter.\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "train_samples", "=", "self", ".", "training_samples", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", "...", "]", "\n", "target_labels", "=", "self", ".", "target_labels", "[", "0", "]", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", "...", "]", "\n", "target_boxes", "=", "self", ".", "target_boxes", "[", ":", "self", ".", "num_stored_samples", "[", "0", "]", ",", ":", "]", "\n", "\n", "test_feat", "=", "self", ".", "net", ".", "head", ".", "extract_head_feat", "(", "sample_x", ")", "\n", "train_feat", "=", "self", ".", "net", ".", "head", ".", "extract_head_feat", "(", "train_samples", ")", "\n", "\n", "train_ltrb", "=", "self", ".", "encode_bbox", "(", "target_boxes", ")", "\n", "cls_weights", ",", "bbreg_weights", ",", "cls_test_feat_enc", ",", "bbreg_test_feat_enc", "=", "self", ".", "net", ".", "head", ".", "get_filter_and_features_in_parallel", "(", "train_feat", ",", "test_feat", ",", "num_gth_frames", "=", "self", ".", "num_gth_frames", ",", "\n", "train_label", "=", "target_labels", ",", "train_ltrb_target", "=", "train_ltrb", ")", "\n", "\n", "# fuse encoder and decoder features to one feature map", "\n", "target_scores", "=", "self", ".", "net", ".", "head", ".", "classifier", "(", "cls_test_feat_enc", ",", "cls_weights", ")", "\n", "\n", "# compute the final prediction using the output module", "\n", "bbox_preds", "=", "self", ".", "net", ".", "head", ".", "bb_regressor", "(", "bbreg_test_feat_enc", ",", "bbreg_weights", ")", "\n", "\n", "", "return", "target_scores", ",", "bbox_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_target": [[305, 345], ["activation.softmax_reg.view.squeeze", "tomp.ToMP.params.get", "tomp.ToMP.params.get", "tomp.ToMP.params.get", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "pytracking.dcf.max2d", "torch.max", "torch.max", "torch.max", "torch.max", "max_disp[].float().cpu().view", "activation.softmax_reg.view.new_ones", "torch.conv2d().view", "torch.conv2d().view", "tomp.ToMP.localize_advanced", "list", "activation.softmax_reg.view.exp", "max_disp[].float().cpu", "getattr", "activation.softmax_reg.view.view", "ltr.models.layers.activation.softmax_reg", "ltr.models.layers.activation.softmax_reg.view", "Exception", "torch.conv2d", "torch.conv2d", "activation.softmax_reg.view.view", "max_disp[].float"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_advanced", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.softmax_reg", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["", "def", "localize_target", "(", "self", ",", "scores", ",", "sample_pos", ",", "sample_scales", ")", ":", "\n", "        ", "\"\"\"Run the target localization.\"\"\"", "\n", "\n", "scores", "=", "scores", ".", "squeeze", "(", "1", ")", "\n", "\n", "preprocess_method", "=", "self", ".", "params", ".", "get", "(", "'score_preprocess'", ",", "'none'", ")", "\n", "if", "preprocess_method", "==", "'none'", ":", "\n", "            ", "pass", "\n", "", "elif", "preprocess_method", "==", "'exp'", ":", "\n", "            ", "scores", "=", "scores", ".", "exp", "(", ")", "\n", "", "elif", "preprocess_method", "==", "'softmax'", ":", "\n", "            ", "reg_val", "=", "getattr", "(", "self", ".", "net", ".", "classifier", ".", "filter_optimizer", ",", "'softmax_reg'", ",", "None", ")", "\n", "scores_view", "=", "scores", ".", "view", "(", "scores", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "scores_softmax", "=", "activation", ".", "softmax_reg", "(", "scores_view", ",", "dim", "=", "-", "1", ",", "reg", "=", "reg_val", ")", "\n", "scores", "=", "scores_softmax", ".", "view", "(", "scores", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Unknown score_preprocess in params.'", ")", "\n", "\n", "", "score_filter_ksz", "=", "self", ".", "params", ".", "get", "(", "'score_filter_ksz'", ",", "1", ")", "\n", "if", "score_filter_ksz", ">", "1", ":", "\n", "            ", "assert", "score_filter_ksz", "%", "2", "==", "1", "\n", "kernel", "=", "scores", ".", "new_ones", "(", "1", ",", "1", ",", "score_filter_ksz", ",", "score_filter_ksz", ")", "\n", "scores", "=", "F", ".", "conv2d", "(", "scores", ".", "view", "(", "-", "1", ",", "1", ",", "*", "scores", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "kernel", ",", "padding", "=", "score_filter_ksz", "//", "2", ")", ".", "view", "(", "scores", ".", "shape", ")", "\n", "\n", "", "if", "self", ".", "params", ".", "get", "(", "'advanced_localization'", ",", "False", ")", ":", "\n", "            ", "return", "self", ".", "localize_advanced", "(", "scores", ",", "sample_pos", ",", "sample_scales", ")", "\n", "\n", "# Get maximum", "\n", "", "score_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "scores", ".", "shape", "[", "-", "2", ":", "]", ")", ")", "\n", "score_center", "=", "(", "score_sz", "-", "1", ")", "/", "2", "\n", "max_score", ",", "max_disp", "=", "dcf", ".", "max2d", "(", "scores", ")", "\n", "_", ",", "scale_ind", "=", "torch", ".", "max", "(", "max_score", ",", "dim", "=", "0", ")", "\n", "max_disp", "=", "max_disp", "[", "scale_ind", ",", "...", "]", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp", "=", "max_disp", "-", "score_center", "\n", "\n", "# Compute translation vector and scale change factor", "\n", "output_sz", "=", "score_sz", "-", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "translation_vec", "=", "target_disp", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scales", "[", "scale_ind", "]", "\n", "\n", "return", "translation_vec", ",", "scale_ind", ",", "scores", ",", "None", ",", "max_disp", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.localize_advanced": [[346, 412], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "pytracking.dcf.max2d", "torch.max", "torch.max", "torch.max", "torch.max", "max_disp1[].float().cpu().view", "max", "min", "max", "min", "scores_hn[].clone", "pytracking.dcf.max2d", "max_disp2.float().cpu().view.float().cpu().view.float().cpu().view", "list", "tomp.ToMP.params.get", "scores.clone", "max_score1.item", "max_score1.item", "tomp.ToMP.params.get", "max_score1.item", "tomp.ToMP.params.get", "round", "round", "round", "round", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "max_disp1[].float().cpu", "max_disp2.float().cpu().view.float().cpu().view.float().cpu", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "float", "float", "max_disp1[].item", "max_disp1[].item", "math.sqrt", "max_disp1[].float", "target_neigh_sz[].item", "max_disp1[].item", "target_neigh_sz[].item", "max_disp1[].item", "max_disp2.float().cpu().view.float().cpu().view.float", "target_neigh_sz[].item", "target_neigh_sz[].item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "localize_advanced", "(", "self", ",", "scores", ",", "sample_pos", ",", "sample_scales", ")", ":", "\n", "        ", "\"\"\"Run the target advanced localization (as in ATOM).\"\"\"", "\n", "\n", "sz", "=", "scores", ".", "shape", "[", "-", "2", ":", "]", "\n", "score_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "sz", ")", ")", "\n", "output_sz", "=", "score_sz", "-", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "score_center", "=", "(", "score_sz", "-", "1", ")", "/", "2", "\n", "\n", "scores_hn", "=", "scores", "\n", "if", "self", ".", "output_window", "is", "not", "None", "and", "self", ".", "params", ".", "get", "(", "'perform_hn_without_windowing'", ",", "False", ")", ":", "\n", "            ", "scores_hn", "=", "scores", ".", "clone", "(", ")", "\n", "scores", "*=", "self", ".", "output_window", "\n", "\n", "", "max_score1", ",", "max_disp1", "=", "dcf", ".", "max2d", "(", "scores", ")", "\n", "_", ",", "scale_ind", "=", "torch", ".", "max", "(", "max_score1", ",", "dim", "=", "0", ")", "\n", "sample_scale", "=", "sample_scales", "[", "scale_ind", "]", "\n", "max_score1", "=", "max_score1", "[", "scale_ind", "]", "\n", "max_disp1", "=", "max_disp1", "[", "scale_ind", ",", "...", "]", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp1", "=", "max_disp1", "-", "score_center", "\n", "translation_vec1", "=", "target_disp1", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scale", "\n", "\n", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "target_not_found_threshold", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'not_found'", ",", "max_disp1", "\n", "", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "get", "(", "'uncertain_threshold'", ",", "-", "float", "(", "'inf'", ")", ")", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'uncertain'", ",", "max_disp1", "\n", "", "if", "max_score1", ".", "item", "(", ")", "<", "self", ".", "params", ".", "get", "(", "'hard_sample_threshold'", ",", "-", "float", "(", "'inf'", ")", ")", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", ",", "max_disp1", "\n", "\n", "# Mask out target neighborhood", "\n", "", "target_neigh_sz", "=", "self", ".", "params", ".", "target_neighborhood_scale", "*", "(", "self", ".", "target_sz", "/", "sample_scale", ")", "*", "(", "output_sz", "/", "self", ".", "img_support_sz", ")", "\n", "\n", "tneigh_top", "=", "max", "(", "round", "(", "max_disp1", "[", "0", "]", ".", "item", "(", ")", "-", "target_neigh_sz", "[", "0", "]", ".", "item", "(", ")", "/", "2", ")", ",", "0", ")", "\n", "tneigh_bottom", "=", "min", "(", "round", "(", "max_disp1", "[", "0", "]", ".", "item", "(", ")", "+", "target_neigh_sz", "[", "0", "]", ".", "item", "(", ")", "/", "2", "+", "1", ")", ",", "sz", "[", "0", "]", ")", "\n", "tneigh_left", "=", "max", "(", "round", "(", "max_disp1", "[", "1", "]", ".", "item", "(", ")", "-", "target_neigh_sz", "[", "1", "]", ".", "item", "(", ")", "/", "2", ")", ",", "0", ")", "\n", "tneigh_right", "=", "min", "(", "round", "(", "max_disp1", "[", "1", "]", ".", "item", "(", ")", "+", "target_neigh_sz", "[", "1", "]", ".", "item", "(", ")", "/", "2", "+", "1", ")", ",", "sz", "[", "1", "]", ")", "\n", "scores_masked", "=", "scores_hn", "[", "scale_ind", ":", "scale_ind", "+", "1", ",", "...", "]", ".", "clone", "(", ")", "\n", "scores_masked", "[", "...", ",", "tneigh_top", ":", "tneigh_bottom", ",", "tneigh_left", ":", "tneigh_right", "]", "=", "0", "\n", "\n", "# Find new maximum", "\n", "max_score2", ",", "max_disp2", "=", "dcf", ".", "max2d", "(", "scores_masked", ")", "\n", "max_disp2", "=", "max_disp2", ".", "float", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "target_disp2", "=", "max_disp2", "-", "score_center", "\n", "translation_vec2", "=", "target_disp2", "*", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scale", "\n", "\n", "prev_target_vec", "=", "(", "self", ".", "pos", "-", "sample_pos", "[", "scale_ind", ",", ":", "]", ")", "/", "(", "(", "self", ".", "img_support_sz", "/", "output_sz", ")", "*", "sample_scale", ")", "\n", "\n", "# Handle the different cases", "\n", "if", "max_score2", ">", "self", ".", "params", ".", "distractor_threshold", "*", "max_score1", ":", "\n", "            ", "disp_norm1", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "target_disp1", "-", "prev_target_vec", ")", "**", "2", ")", ")", "\n", "disp_norm2", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "target_disp2", "-", "prev_target_vec", ")", "**", "2", ")", ")", "\n", "disp_threshold", "=", "self", ".", "params", ".", "dispalcement_scale", "*", "math", ".", "sqrt", "(", "sz", "[", "0", "]", "*", "sz", "[", "1", "]", ")", "/", "2", "\n", "\n", "if", "disp_norm2", ">", "disp_threshold", "and", "disp_norm1", "<", "disp_threshold", ":", "\n", "                ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", ",", "max_disp1", "\n", "", "if", "disp_norm2", "<", "disp_threshold", "and", "disp_norm1", ">", "disp_threshold", ":", "\n", "                ", "return", "translation_vec2", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", ",", "max_disp2", "\n", "", "if", "disp_norm2", ">", "disp_threshold", "and", "disp_norm1", ">", "disp_threshold", ":", "\n", "                ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'uncertain'", ",", "max_disp1", "\n", "\n", "# If also the distractor is close, return with highest score", "\n", "", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'uncertain'", ",", "max_disp1", "\n", "\n", "", "if", "max_score2", ">", "self", ".", "params", ".", "hard_negative_threshold", "*", "max_score1", "and", "max_score2", ">", "self", ".", "params", ".", "target_not_found_threshold", ":", "\n", "            ", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'hard_negative'", ",", "max_disp1", "\n", "\n", "", "return", "translation_vec1", ",", "scale_ind", ",", "scores_hn", ",", "'normal'", ",", "max_disp1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.extract_backbone_features": [[413, 420], ["pytracking.features.preprocessing.sample_patch_multiscale", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tomp.ToMP.net.extract_backbone", "tomp.ToMP.params.get", "tomp.ToMP.params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_multiscale", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "extract_backbone_features", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ",", "pos", ":", "torch", ".", "Tensor", ",", "scales", ",", "sz", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "im_patches", ",", "patch_coords", "=", "sample_patch_multiscale", "(", "im", ",", "pos", ",", "scales", ",", "sz", ",", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", ",", "\n", "max_scale_change", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ",", "None", ")", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im_patches", ")", "\n", "", "return", "backbone_feat", ",", "patch_coords", ",", "im_patches", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_backbone_head_feat": [[421, 424], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tomp.ToMP.net.get_backbone_head_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.ToMPnet.get_backbone_head_feat"], ["", "def", "get_backbone_head_feat", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "self", ".", "net", ".", "get_backbone_head_feat", "(", "backbone_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.generate_init_samples": [[425, 494], ["tomp.ToMP.params.get", "tomp.ToMP.pos.round", "tomp.ToMP.params.get", "tomp.ToMP.img_sample_sz.clone", "tomp.ToMP.params.get", "pytracking.features.preprocessing.sample_patch_transformed", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "shrink_factor.min.min.clamp_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "aug_expansion_sz.float.float.float", "tomp.ToMP.img_sample_sz.long().tolist", "pytracking.features.augmentation.Identity", "tomp.ToMP.params.get", "tomp.ToMP.transforms.extend", "tomp.ToMP.transforms.extend", "tomp.ToMP.transforms.append", "tomp.ToMP.transforms.extend", "tomp.ToMP.transforms.extend", "tomp.ToMP.transforms.extend", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tomp.ToMP.net.extract_backbone", "sample_sz.float", "shrink_factor.min.min.max", "sample_sz.float", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "pytracking.features.augmentation.FlipHorizontal", "shrink_factor.min.min.min", "tomp.ToMP.params.get", "tomp.ToMP.img_sample_sz.long", "tomp.ToMP.img_sample_sz.long", "pytracking.features.augmentation.Translation", "pytracking.features.augmentation.Translation", "get_rand_shift", "pytracking.features.augmentation.Blur", "pytracking.features.augmentation.Scale", "pytracking.features.augmentation.Rotate", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "get_absolute", "torch.zeros.long().tolist", "torch.zeros.long().tolist", "get_rand_shift", "get_rand_shift", "get_rand_shift", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.zeros.long", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_transformed", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "", "def", "generate_init_samples", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Perform data augmentation to generate initial training samples.\"\"\"", "\n", "\n", "mode", "=", "self", ".", "params", ".", "get", "(", "'border_mode'", ",", "'replicate'", ")", "\n", "if", "mode", "==", "'inside'", ":", "\n", "# Get new sample size if forced inside the image", "\n", "            ", "im_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "sample_sz", "=", "self", ".", "target_scale", "*", "self", ".", "img_sample_sz", "\n", "shrink_factor", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "im_sz", ")", "\n", "if", "mode", "==", "'inside'", ":", "\n", "                ", "shrink_factor", "=", "shrink_factor", ".", "max", "(", ")", "\n", "", "elif", "mode", "==", "'inside_major'", ":", "\n", "                ", "shrink_factor", "=", "shrink_factor", ".", "min", "(", ")", "\n", "", "shrink_factor", ".", "clamp_", "(", "min", "=", "1", ",", "max", "=", "self", ".", "params", ".", "get", "(", "'patch_max_scale_change'", ",", "None", ")", ")", "\n", "sample_sz", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "shrink_factor", ")", "\n", "self", ".", "init_sample_scale", "=", "(", "sample_sz", "/", "self", ".", "img_sample_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "\n", "tl", "=", "self", ".", "pos", "-", "(", "sample_sz", "-", "1", ")", "/", "2", "\n", "br", "=", "self", ".", "pos", "+", "sample_sz", "/", "2", "+", "1", "\n", "global_shift", "=", "-", "(", "(", "-", "tl", ")", ".", "clamp", "(", "0", ")", "-", "(", "br", "-", "im_sz", ")", ".", "clamp", "(", "0", ")", ")", "/", "self", ".", "init_sample_scale", "\n", "", "else", ":", "\n", "            ", "self", ".", "init_sample_scale", "=", "self", ".", "target_scale", "\n", "global_shift", "=", "torch", ".", "zeros", "(", "2", ")", "\n", "\n", "", "self", ".", "init_sample_pos", "=", "self", ".", "pos", ".", "round", "(", ")", "\n", "\n", "# Compute augmentation size", "\n", "aug_expansion_factor", "=", "self", ".", "params", ".", "get", "(", "'augmentation_expansion_factor'", ",", "None", ")", "\n", "aug_expansion_sz", "=", "self", ".", "img_sample_sz", ".", "clone", "(", ")", "\n", "aug_output_sz", "=", "None", "\n", "if", "aug_expansion_factor", "is", "not", "None", "and", "aug_expansion_factor", "!=", "1", ":", "\n", "            ", "aug_expansion_sz", "=", "(", "self", ".", "img_sample_sz", "*", "aug_expansion_factor", ")", ".", "long", "(", ")", "\n", "aug_expansion_sz", "+=", "(", "aug_expansion_sz", "-", "self", ".", "img_sample_sz", ".", "long", "(", ")", ")", "%", "2", "\n", "aug_expansion_sz", "=", "aug_expansion_sz", ".", "float", "(", ")", "\n", "aug_output_sz", "=", "self", ".", "img_sample_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Random shift for each sample", "\n", "", "get_rand_shift", "=", "lambda", ":", "None", "\n", "random_shift_factor", "=", "self", ".", "params", ".", "get", "(", "'random_shift_factor'", ",", "0", ")", "\n", "if", "random_shift_factor", ">", "0", ":", "\n", "            ", "get_rand_shift", "=", "lambda", ":", "(", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "*", "self", ".", "img_sample_sz", "*", "random_shift_factor", "+", "global_shift", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Always put identity transformation first, since it is the unaugmented sample that is always used", "\n", "", "self", ".", "transforms", "=", "[", "augmentation", ".", "Identity", "(", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "]", "\n", "\n", "augs", "=", "self", ".", "params", ".", "augmentation", "if", "self", ".", "params", ".", "get", "(", "'use_augmentation'", ",", "True", ")", "else", "{", "}", "\n", "\n", "# Add all augmentations", "\n", "if", "'shift'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "shift", ",", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "for", "shift", "in", "augs", "[", "'shift'", "]", "]", ")", "\n", "", "if", "'relativeshift'", "in", "augs", ":", "\n", "            ", "get_absolute", "=", "lambda", "shift", ":", "(", "torch", ".", "Tensor", "(", "shift", ")", "*", "self", ".", "img_sample_sz", "/", "2", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Translation", "(", "get_absolute", "(", "shift", ")", ",", "aug_output_sz", ",", "global_shift", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "for", "shift", "in", "augs", "[", "'relativeshift'", "]", "]", ")", "\n", "", "if", "'fliplr'", "in", "augs", "and", "augs", "[", "'fliplr'", "]", ":", "\n", "            ", "self", ".", "transforms", ".", "append", "(", "augmentation", ".", "FlipHorizontal", "(", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", ")", "\n", "", "if", "'blur'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Blur", "(", "sigma", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "sigma", "in", "augs", "[", "'blur'", "]", "]", ")", "\n", "", "if", "'scale'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Scale", "(", "scale_factor", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "scale_factor", "in", "augs", "[", "'scale'", "]", "]", ")", "\n", "", "if", "'rotate'", "in", "augs", ":", "\n", "            ", "self", ".", "transforms", ".", "extend", "(", "[", "augmentation", ".", "Rotate", "(", "angle", ",", "aug_output_sz", ",", "get_rand_shift", "(", ")", ")", "for", "angle", "in", "augs", "[", "'rotate'", "]", "]", ")", "\n", "\n", "# Extract augmented image patches", "\n", "", "im_patches", "=", "sample_patch_transformed", "(", "im", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ",", "aug_expansion_sz", ",", "self", ".", "transforms", ")", "\n", "\n", "# Extract initial backbone features", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "init_backbone_feat", "=", "self", ".", "net", ".", "extract_backbone", "(", "im_patches", ")", "\n", "\n", "", "return", "init_backbone_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_target_boxes": [[495, 505], ["tomp.ToMP.get_iounet_box", "pytracking.TensorList", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to.new_zeros", "torch.cat().to.new_zeros", "torch.cat().to.append", "torch.cat().to.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.cat().to.view", "torch.cat().to.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "init_target_boxes", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the target bounding boxes for the initial augmented samples.\"\"\"", "\n", "self", ".", "classifier_target_box", "=", "self", ".", "get_iounet_box", "(", "self", ".", "pos", ",", "self", ".", "target_sz", ",", "self", ".", "init_sample_pos", ",", "self", ".", "init_sample_scale", ")", "\n", "init_target_boxes", "=", "TensorList", "(", ")", "\n", "for", "T", "in", "self", ".", "transforms", ":", "\n", "            ", "init_target_boxes", ".", "append", "(", "self", ".", "classifier_target_box", "+", "torch", ".", "Tensor", "(", "[", "T", ".", "shift", "[", "1", "]", ",", "T", ".", "shift", "[", "0", "]", ",", "0", ",", "0", "]", ")", ")", "\n", "", "init_target_boxes", "=", "torch", ".", "cat", "(", "init_target_boxes", ".", "view", "(", "1", ",", "4", ")", ",", "0", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "self", ".", "target_boxes", "=", "init_target_boxes", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "4", ")", "\n", "self", ".", "target_boxes", "[", ":", "init_target_boxes", ".", "shape", "[", "0", "]", ",", ":", "]", "=", "init_target_boxes", "\n", "return", "init_target_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_target_labels": [[506, 526], ["pytracking.TensorList", "tomp.ToMP.params.get", "zip", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "enumerate", "x.new_zeros", "pytracking.dcf.label_function_spatial", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "int", "int", "tomp.ToMP.kernel_size[].item", "tomp.ToMP.kernel_size[].item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.label_function_spatial"], ["", "def", "init_target_labels", "(", "self", ",", "train_x", ":", "TensorList", ")", ":", "\n", "        ", "self", ".", "target_labels", "=", "TensorList", "(", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "1", ",", "\n", "x", ".", "shape", "[", "2", "]", "+", "(", "int", "(", "self", ".", "kernel_size", "[", "0", "]", ".", "item", "(", ")", ")", "+", "1", ")", "%", "2", ",", "\n", "x", ".", "shape", "[", "3", "]", "+", "(", "int", "(", "self", ".", "kernel_size", "[", "1", "]", ".", "item", "(", ")", ")", "+", "1", ")", "%", "2", ")", "\n", "for", "x", "in", "train_x", "]", ")", "\n", "# Output sigma factor", "\n", "output_sigma_factor", "=", "self", ".", "params", ".", "get", "(", "'output_sigma_factor'", ",", "1", "/", "4", ")", "\n", "self", ".", "sigma", "=", "(", "self", ".", "feature_sz", "/", "self", ".", "img_support_sz", "*", "self", ".", "base_target_sz", ")", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "output_sigma_factor", "*", "torch", ".", "ones", "(", "2", ")", "\n", "\n", "# Center pos in normalized img_coords", "\n", "target_center_norm", "=", "(", "self", ".", "pos", "-", "self", ".", "init_sample_pos", ")", "/", "(", "self", ".", "init_sample_scale", "*", "self", ".", "img_support_sz", ")", "\n", "\n", "for", "target", ",", "x", "in", "zip", "(", "self", ".", "target_labels", ",", "train_x", ")", ":", "\n", "            ", "ksz_even", "=", "torch", ".", "Tensor", "(", "[", "(", "self", ".", "kernel_size", "[", "0", "]", "+", "1", ")", "%", "2", ",", "(", "self", ".", "kernel_size", "[", "1", "]", "+", "1", ")", "%", "2", "]", ")", "\n", "center_pos", "=", "self", ".", "feature_sz", "*", "target_center_norm", "+", "0.5", "*", "ksz_even", "\n", "for", "i", ",", "T", "in", "enumerate", "(", "self", ".", "transforms", "[", ":", "x", ".", "shape", "[", "0", "]", "]", ")", ":", "\n", "                ", "sample_center", "=", "center_pos", "+", "torch", ".", "Tensor", "(", "T", ".", "shift", ")", "/", "self", ".", "img_support_sz", "*", "self", ".", "feature_sz", "\n", "target", "[", "i", ",", "0", ",", "...", "]", "=", "dcf", ".", "label_function_spatial", "(", "self", ".", "feature_sz", ",", "self", ".", "sigma", ",", "sample_center", ",", "end_pad", "=", "ksz_even", ")", "\n", "\n", "", "", "return", "self", ".", "target_labels", "[", "0", "]", "[", ":", "train_x", "[", "0", "]", ".", "shape", "[", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_memory": [[527, 545], ["train_x.size", "pytracking.TensorList", "tomp.ToMP.num_init_samples.copy", "pytracking.TensorList", "zip", "pytracking.TensorList", "zip", "len", "x.new_zeros", "x.new_zeros", "x.new_ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "def", "init_memory", "(", "self", ",", "train_x", ":", "TensorList", ")", ":", "\n", "# Initialize first-frame spatial training samples", "\n", "        ", "self", ".", "num_init_samples", "=", "train_x", ".", "size", "(", "0", ")", "\n", "init_sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_ones", "(", "1", ")", "/", "x", ".", "shape", "[", "0", "]", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "# Sample counters and weights for spatial", "\n", "self", ".", "num_stored_samples", "=", "self", ".", "num_init_samples", ".", "copy", "(", ")", "\n", "self", ".", "previous_replace_ind", "=", "[", "None", "]", "*", "len", "(", "self", ".", "num_stored_samples", ")", "\n", "self", ".", "sample_weights", "=", "TensorList", "(", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ")", "for", "x", "in", "train_x", "]", ")", "\n", "for", "sw", ",", "init_sw", ",", "num", "in", "zip", "(", "self", ".", "sample_weights", ",", "init_sample_weights", ",", "self", ".", "num_init_samples", ")", ":", "\n", "            ", "sw", "[", ":", "num", "]", "=", "init_sw", "\n", "\n", "# Initialize memory", "\n", "", "self", ".", "training_samples", "=", "TensorList", "(", "\n", "[", "x", ".", "new_zeros", "(", "self", ".", "params", ".", "sample_memory_size", ",", "x", ".", "shape", "[", "1", "]", ",", "x", ".", "shape", "[", "2", "]", ",", "x", ".", "shape", "[", "3", "]", ")", "for", "x", "in", "train_x", "]", ")", "\n", "\n", "for", "ts", ",", "x", "in", "zip", "(", "self", ".", "training_samples", ",", "train_x", ")", ":", "\n", "            ", "ts", "[", ":", "x", ".", "shape", "[", "0", "]", ",", "...", "]", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_memory": [[546, 562], ["tomp.ToMP.update_sample_weights", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_sample_weights"], ["", "", "def", "update_memory", "(", "self", ",", "sample_x", ":", "TensorList", ",", "sample_y", ":", "TensorList", ",", "target_box", ",", "learning_rate", "=", "None", ")", ":", "\n", "# Update weights and get replace ind", "\n", "        ", "replace_ind", "=", "self", ".", "update_sample_weights", "(", "self", ".", "sample_weights", ",", "self", ".", "previous_replace_ind", ",", "self", ".", "num_stored_samples", ",", "self", ".", "num_init_samples", ",", "learning_rate", ")", "\n", "self", ".", "previous_replace_ind", "=", "replace_ind", "\n", "\n", "# Update sample and label memory", "\n", "for", "train_samp", ",", "x", ",", "ind", "in", "zip", "(", "self", ".", "training_samples", ",", "sample_x", ",", "replace_ind", ")", ":", "\n", "            ", "train_samp", "[", "ind", ":", "ind", "+", "1", ",", "...", "]", "=", "x", "\n", "\n", "", "for", "y_memory", ",", "y", ",", "ind", "in", "zip", "(", "self", ".", "target_labels", ",", "sample_y", ",", "replace_ind", ")", ":", "\n", "            ", "y_memory", "[", "ind", ":", "ind", "+", "1", ",", "...", "]", "=", "y", "\n", "\n", "# Update bb memory", "\n", "", "self", ".", "target_boxes", "[", "replace_ind", "[", "0", "]", ",", ":", "]", "=", "target_box", "\n", "\n", "self", ".", "num_stored_samples", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_sample_weights": [[563, 603], ["zip", "tomp.ToMP.params.get", "sw.sum", "replace_ind.append", "torch.min", "torch.min", "torch.min", "torch.min", "sw[].sum", "sw[].sum", "r_ind.item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "update_sample_weights", "(", "self", ",", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ",", "learning_rate", "=", "None", ")", ":", "\n", "# Update weights and get index to replace", "\n", "        ", "replace_ind", "=", "[", "]", "\n", "for", "sw", ",", "prev_ind", ",", "num_samp", ",", "num_init", "in", "zip", "(", "sample_weights", ",", "previous_replace_ind", ",", "num_stored_samples", ",", "num_init_samples", ")", ":", "\n", "            ", "lr", "=", "learning_rate", "\n", "if", "lr", "is", "None", ":", "\n", "                ", "lr", "=", "self", ".", "params", ".", "learning_rate", "\n", "\n", "", "init_samp_weight", "=", "self", ".", "params", ".", "get", "(", "'init_samples_minimum_weight'", ",", "None", ")", "\n", "if", "init_samp_weight", "==", "0", ":", "\n", "                ", "init_samp_weight", "=", "None", "\n", "", "s_ind", "=", "0", "if", "init_samp_weight", "is", "None", "else", "num_init", "\n", "\n", "if", "num_samp", "==", "0", "or", "lr", "==", "1", ":", "\n", "                ", "sw", "[", ":", "]", "=", "0", "\n", "sw", "[", "0", "]", "=", "1", "\n", "r_ind", "=", "0", "\n", "", "else", ":", "\n", "# Get index to replace", "\n", "                ", "if", "num_samp", "<", "sw", ".", "shape", "[", "0", "]", ":", "\n", "                    ", "r_ind", "=", "num_samp", "\n", "", "else", ":", "\n", "                    ", "_", ",", "r_ind", "=", "torch", ".", "min", "(", "sw", "[", "s_ind", ":", "]", ",", "0", ")", "\n", "r_ind", "=", "r_ind", ".", "item", "(", ")", "+", "s_ind", "\n", "\n", "# Update weights", "\n", "", "if", "prev_ind", "is", "None", ":", "\n", "                    ", "sw", "/=", "1", "-", "lr", "\n", "sw", "[", "r_ind", "]", "=", "lr", "\n", "", "else", ":", "\n", "                    ", "sw", "[", "r_ind", "]", "=", "sw", "[", "prev_ind", "]", "/", "(", "1", "-", "lr", ")", "\n", "\n", "", "", "sw", "/=", "sw", ".", "sum", "(", ")", "\n", "if", "init_samp_weight", "is", "not", "None", "and", "sw", "[", ":", "num_init", "]", ".", "sum", "(", ")", "<", "init_samp_weight", ":", "\n", "                ", "sw", "/=", "init_samp_weight", "+", "sw", "[", "num_init", ":", "]", ".", "sum", "(", ")", "\n", "sw", "[", ":", "num_init", "]", "=", "init_samp_weight", "/", "num_init", "\n", "\n", "", "replace_ind", ".", "append", "(", "r_ind", ")", "\n", "\n", "", "return", "replace_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_label_function": [[604, 614], ["pytracking.TensorList", "zip", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "pytracking.TensorList.append", "pytracking.dcf.label_function_spatial"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.label_function_spatial"], ["", "def", "get_label_function", "(", "self", ",", "pos", ",", "sample_pos", ",", "sample_scale", ")", ":", "\n", "        ", "train_y", "=", "TensorList", "(", ")", "\n", "target_center_norm", "=", "(", "pos", "-", "sample_pos", ")", "/", "(", "sample_scale", "*", "self", ".", "img_support_sz", ")", "\n", "\n", "for", "sig", ",", "sz", ",", "ksz", "in", "zip", "(", "[", "self", ".", "sigma", "]", ",", "[", "self", ".", "feature_sz", "]", ",", "[", "self", ".", "kernel_size", "]", ")", ":", "\n", "            ", "ksz_even", "=", "torch", ".", "Tensor", "(", "[", "(", "self", ".", "kernel_size", "[", "0", "]", "+", "1", ")", "%", "2", ",", "(", "self", ".", "kernel_size", "[", "1", "]", "+", "1", ")", "%", "2", "]", ")", "\n", "center", "=", "sz", "*", "target_center_norm", "+", "0.5", "*", "ksz_even", "\n", "train_y", ".", "append", "(", "dcf", ".", "label_function_spatial", "(", "sz", ",", "sig", ",", "center", ",", "end_pad", "=", "ksz_even", ")", ")", "\n", "\n", "", "return", "train_y", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.update_state": [[615, 625], ["tomp.ToMP.params.get", "torch.max", "torch.max", "torch.max", "torch.max", "new_scale.clamp", "torch.min", "torch.min", "torch.min", "torch.min"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "update_state", "(", "self", ",", "new_pos", ",", "new_scale", "=", "None", ")", ":", "\n", "# Update scale", "\n", "        ", "if", "new_scale", "is", "not", "None", ":", "\n", "            ", "self", ".", "target_scale", "=", "new_scale", ".", "clamp", "(", "self", ".", "min_scale_factor", ",", "self", ".", "max_scale_factor", ")", "\n", "self", ".", "target_sz", "=", "self", ".", "base_target_sz", "*", "self", ".", "target_scale", "\n", "\n", "# Update pos", "\n", "", "inside_ratio", "=", "self", ".", "params", ".", "get", "(", "'target_inside_ratio'", ",", "0.2", ")", "\n", "inside_offset", "=", "(", "inside_ratio", "-", "0.5", ")", "*", "self", ".", "target_sz", "\n", "self", ".", "pos", "=", "torch", ".", "max", "(", "torch", ".", "min", "(", "new_pos", ",", "self", ".", "image_sz", "-", "inside_offset", ")", ",", "inside_offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_iounet_box": [[626, 633], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "target_ul.flip", "box_sz.flip"], "methods", ["None"], ["", "def", "get_iounet_box", "(", "self", ",", "pos", ",", "sz", ",", "sample_pos", ",", "sample_scale", ")", ":", "\n", "        ", "\"\"\"All inputs in original image coordinates.\n        Generates a box in the cropped image sample reference frame, in the format used by the IoUNet.\"\"\"", "\n", "box_center", "=", "(", "pos", "-", "sample_pos", ")", "/", "sample_scale", "+", "(", "self", ".", "img_sample_sz", "-", "1", ")", "/", "2", "\n", "box_sz", "=", "sz", "/", "sample_scale", "\n", "target_ul", "=", "box_center", "-", "(", "box_sz", "-", "1", ")", "/", "2", "\n", "return", "torch", ".", "cat", "(", "[", "target_ul", ".", "flip", "(", "(", "0", ",", ")", ")", ",", "box_sz", ".", "flip", "(", "(", "0", ",", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_classifier": [[634, 671], ["tomp.ToMP.get_backbone_head_feat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "getattr", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "tomp.ToMP.params.get", "tomp.ToMP.init_target_boxes", "tomp.ToMP.init_target_labels", "hasattr", "tomp.ToMP.init_memory", "tomp.ToMP.params.get", "tomp.ToMP.transforms.extend", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "list", "tomp.ToMP.params.get", "tomp.ToMP.output_window.squeeze", "pytracking.TensorList", "pytracking.TensorList", "isinstance", "pytracking.dcf.hann2d_clipped().to", "pytracking.dcf.hann2d().to", "torch.dropout2d", "torch.dropout2d", "x[].expand", "pytracking.dcf.hann2d_clipped", "pytracking.dcf.hann2d", "tomp.ToMP.output_sz.long", "tomp.ToMP.output_sz.long"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.ToMPnet.get_backbone_head_feat", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_target_boxes", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_target_labels", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.init_memory", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d_clipped", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d"], ["", "def", "init_classifier", "(", "self", ",", "init_backbone_feat", ")", ":", "\n", "# Get classification features", "\n", "        ", "x", "=", "self", ".", "get_backbone_head_feat", "(", "init_backbone_feat", ")", "\n", "\n", "# Add the dropout augmentation here, since it requires extraction of the classification features", "\n", "if", "'dropout'", "in", "self", ".", "params", ".", "augmentation", "and", "self", ".", "params", ".", "get", "(", "'use_augmentation'", ",", "True", ")", ":", "\n", "            ", "num", ",", "prob", "=", "self", ".", "params", ".", "augmentation", "[", "'dropout'", "]", "\n", "self", ".", "transforms", ".", "extend", "(", "self", ".", "transforms", "[", ":", "1", "]", "*", "num", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "F", ".", "dropout2d", "(", "x", "[", "0", ":", "1", ",", "...", "]", ".", "expand", "(", "num", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", ",", "p", "=", "prob", ",", "training", "=", "True", ")", "]", ")", "\n", "\n", "# Set feature size and other related sizes", "\n", "", "self", ".", "feature_sz", "=", "torch", ".", "Tensor", "(", "list", "(", "x", ".", "shape", "[", "-", "2", ":", "]", ")", ")", "\n", "ksz", "=", "getattr", "(", "self", ".", "net", ".", "head", ".", "filter_predictor", ",", "'filter_size'", ",", "1", ")", "\n", "self", ".", "kernel_size", "=", "torch", ".", "Tensor", "(", "[", "ksz", ",", "ksz", "]", "if", "isinstance", "(", "ksz", ",", "(", "int", ",", "float", ")", ")", "else", "ksz", ")", "\n", "self", ".", "output_sz", "=", "self", ".", "feature_sz", "+", "(", "self", ".", "kernel_size", "+", "1", ")", "%", "2", "\n", "\n", "# Construct output window", "\n", "self", ".", "output_window", "=", "None", "\n", "if", "self", ".", "params", ".", "get", "(", "'window_output'", ",", "False", ")", ":", "\n", "            ", "if", "self", ".", "params", ".", "get", "(", "'use_clipped_window'", ",", "False", ")", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d_clipped", "(", "self", ".", "output_sz", ".", "long", "(", ")", ",", "(", "self", ".", "output_sz", "*", "self", ".", "params", ".", "effective_search_area", "/", "self", ".", "params", ".", "search_area_scale", ")", ".", "long", "(", ")", ",", "centered", "=", "True", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d", "(", "self", ".", "output_sz", ".", "long", "(", ")", ",", "centered", "=", "True", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "", "self", ".", "output_window", "=", "self", ".", "output_window", ".", "squeeze", "(", "0", ")", "\n", "\n", "# Get target boxes for the different augmentations", "\n", "", "target_boxes", "=", "self", ".", "init_target_boxes", "(", ")", "\n", "\n", "# Get target labels for the different augmentations", "\n", "self", ".", "init_target_labels", "(", "TensorList", "(", "[", "x", "]", ")", ")", "\n", "\n", "self", ".", "num_gth_frames", "=", "target_boxes", ".", "shape", "[", "0", "]", "\n", "\n", "if", "hasattr", "(", "self", ".", "net", ".", "head", ".", "filter_predictor", ",", "'num_gth_frames'", ")", ":", "\n", "            ", "self", ".", "net", ".", "head", ".", "filter_predictor", ".", "num_gth_frames", "=", "self", ".", "num_gth_frames", "\n", "\n", "", "self", ".", "init_memory", "(", "TensorList", "(", "[", "x", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.visdom_draw_tracking": [[672, 677], ["hasattr", "tomp.ToMP.visdom.register", "tomp.ToMP.visdom.register"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register"], ["", "def", "visdom_draw_tracking", "(", "self", ",", "image", ",", "box", ",", "segmentation", "=", "None", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "'search_area_box'", ")", ":", "\n", "                ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "box", ",", "self", ".", "search_area_box", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "box", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.__init__.get_tracker_class": [[3, 5], ["None"], "function", ["None"], ["import", "pytracking", ".", "libs", ".", "operation", "as", "operation", "\n", "import", "pytracking", ".", "libs", ".", "fourier", "as", "fourier", "\n", "import", "pytracking", ".", "libs", ".", "dcf", "as", "dcf", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp101.run": [[13, 151], ["ltr.dataset.Lasot", "ltr.dataset.Got10k", "ltr.dataset.TrackingNet", "ltr.dataset.MSCOCOSeq", "ltr.dataset.Got10k", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.LTRBDenseRegressionProcessing", "ltr.data.processing.LTRBDenseRegressionProcessing", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.models.tracking.tompnet.tompnet101", "ltr.ToMPActor", "torch.AdamW", "torch.lr_scheduler.MultiStepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.RandomHorizontalFlip", "ltr.ToTensorAndJitter", "ltr.RandomHorizontalFlip", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "ltr.MultiGPU", "ltr.models.loss.bbr_loss.GIoULoss", "ltr.LBHinge", "list", "range", "actors.ToMPActor.net.head.parameters", "actors.ToMPActor.net.feature_extractor.layer3.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.tompnet101", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["params", ".", "feature_stride", "=", "16", "\n", "params", ".", "image_sample_size", "=", "params", ".", "train_feature_size", "*", "params", ".", "feature_stride", "\n", "params", ".", "search_area_scale", "=", "5", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "1.5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "2", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "False", "\n", "params", ".", "augmentation", "=", "{", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "params", ".", "conf_ths", "=", "0.9", "\n", "params", ".", "search_area_rescaling_at_occlusion", "=", "True", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'tomp101.pth.tar'", ",", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "params", ".", "use_gt_box", "=", "True", "\n", "params", ".", "plot_iou", "=", "True", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.run": [[13, 150], ["ltr.dataset.Lasot", "ltr.dataset.Got10k", "ltr.dataset.TrackingNet", "ltr.dataset.MSCOCOSeq", "ltr.dataset.Got10k", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.LTRBDenseRegressionProcessing", "ltr.data.processing.LTRBDenseRegressionProcessing", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.data.sampler.DiMPSampler", "ltr.data.LTRLoader", "ltr.models.tracking.tompnet.tompnet50", "ltr.ToMPActor", "torch.AdamW", "torch.lr_scheduler.MultiStepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.RandomHorizontalFlip", "ltr.ToTensorAndJitter", "ltr.RandomHorizontalFlip", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "ltr.MultiGPU", "ltr.models.loss.bbr_loss.GIoULoss", "ltr.LBHinge", "list", "range", "actors.ToMPActor.net.head.parameters", "actors.ToMPActor.net.feature_extractor.layer3.parameters"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.tompnet50", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["params", ".", "feature_stride", "=", "16", "\n", "params", ".", "image_sample_size", "=", "params", ".", "train_feature_size", "*", "params", ".", "feature_stride", "\n", "params", ".", "search_area_scale", "=", "5", "\n", "params", ".", "border_mode", "=", "'inside_major'", "\n", "params", ".", "patch_max_scale_change", "=", "1.5", "\n", "\n", "# Learning parameters", "\n", "params", ".", "sample_memory_size", "=", "2", "\n", "params", ".", "learning_rate", "=", "0.01", "\n", "params", ".", "init_samples_minimum_weight", "=", "0.25", "\n", "params", ".", "train_skipping", "=", "20", "\n", "\n", "# Net optimization params", "\n", "params", ".", "update_classifier", "=", "True", "\n", "params", ".", "net_opt_iter", "=", "10", "\n", "params", ".", "net_opt_update_iter", "=", "2", "\n", "params", ".", "net_opt_hn_iter", "=", "1", "\n", "\n", "# Detection parameters", "\n", "params", ".", "window_output", "=", "False", "\n", "\n", "# Init augmentation parameters", "\n", "params", ".", "use_augmentation", "=", "False", "\n", "params", ".", "augmentation", "=", "{", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "\n", "params", ".", "distractor_threshold", "=", "0.8", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "\n", "params", ".", "conf_ths", "=", "0.9", "\n", "params", ".", "search_area_rescaling_at_occlusion", "=", "True", "\n", "\n", "params", ".", "net", "=", "NetWithBackbone", "(", "net_path", "=", "'tomp50.pth.tar'", ",", "use_gpu", "=", "params", ".", "use_gpu", ")", "\n", "\n", "params", ".", "vot_anno_conversion_type", "=", "'preserve_area'", "\n", "\n", "params", ".", "use_gt_box", "=", "True", "\n", "params", ".", "plot_iou", "=", "True", "\n", "\n", "return", "params", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.experiments.myexperiments.atom_nfs_uav": [[4, 10], ["pytracking.evaluation.trackerlist", "pytracking.evaluation.get_dataset", "range"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.trackerlist", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.datasets.get_dataset"], ["def", "atom_nfs_uav", "(", ")", ":", "\n", "# Run three runs of ATOM on NFS and UAV datasets", "\n", "    ", "trackers", "=", "trackerlist", "(", "'atom'", ",", "'default'", ",", "range", "(", "3", ")", ")", "\n", "\n", "dataset", "=", "get_dataset", "(", "'nfs'", ",", "'uav'", ")", "\n", "return", "trackers", ",", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.experiments.myexperiments.uav_test": [[12, 20], ["pytracking.evaluation.get_dataset", "pytracking.evaluation.trackerlist", "pytracking.evaluation.trackerlist", "pytracking.evaluation.trackerlist", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.datasets.get_dataset", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.trackerlist", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.trackerlist", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.trackerlist"], ["", "def", "uav_test", "(", ")", ":", "\n", "# Run DiMP18, ATOM and ECO on the UAV dataset", "\n", "    ", "trackers", "=", "trackerlist", "(", "'dimp'", ",", "'dimp18'", ",", "range", "(", "1", ")", ")", "+", "trackerlist", "(", "'atom'", ",", "'default'", ",", "range", "(", "1", ")", ")", "+", "trackerlist", "(", "'eco'", ",", "'default'", ",", "range", "(", "1", ")", ")", "\n", "\n", "dataset", "=", "get_dataset", "(", "'uav'", ")", "\n", "return", "trackers", ",", "dataset", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWrapper.__init__": [[9, 16], ["net_wrappers.NetWrapper.initialize"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["def", "__init__", "(", "self", ",", "net_path", ",", "use_gpu", "=", "True", ",", "initialize", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "net_path", "=", "net_path", "\n", "self", ".", "use_gpu", "=", "use_gpu", "\n", "self", ".", "net", "=", "None", "\n", "self", ".", "net_kwargs", "=", "kwargs", "\n", "if", "initialize", ":", "\n", "            ", "self", ".", "initialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWrapper.__getattr__": [[17, 29], ["getattr"], "methods", ["None"], ["", "", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "self", ".", "_rec_iter", ">", "0", ":", "\n", "            ", "self", ".", "_rec_iter", "=", "0", "\n", "return", "None", "\n", "", "self", ".", "_rec_iter", "+=", "1", "\n", "try", ":", "\n", "            ", "ret_val", "=", "getattr", "(", "self", ".", "net", ",", "name", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "self", ".", "_rec_iter", "=", "0", "\n", "raise", "e", "\n", "", "self", ".", "_rec_iter", "=", "0", "\n", "return", "ret_val", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWrapper.load_network": [[30, 35], ["pytracking.utils.loading.load_network", "net_wrappers.NetWrapper.eval", "net_wrappers.NetWrapper.cuda"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_network", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval"], ["", "def", "load_network", "(", "self", ")", ":", "\n", "        ", "self", ".", "net", "=", "load_network", "(", "self", ".", "net_path", ",", "**", "self", ".", "net_kwargs", ")", "\n", "if", "self", ".", "use_gpu", ":", "\n", "            ", "self", ".", "cuda", "(", ")", "\n", "", "self", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWrapper.initialize": [[36, 38], ["net_wrappers.NetWrapper.load_network"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_network"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "self", ".", "load_network", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.__init__": [[44, 51], ["net_wrappers.NetWrapper.__init__", "torch.Tensor().view", "torch.Tensor().view", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "net_path", ",", "use_gpu", "=", "True", ",", "initialize", "=", "False", ",", "image_format", "=", "'rgb'", ",", "\n", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.229", ",", "0.224", ",", "0.225", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "net_path", ",", "use_gpu", ",", "initialize", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "image_format", "=", "image_format", "\n", "self", ".", "_mean", "=", "torch", ".", "Tensor", "(", "mean", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "_std", "=", "torch", ".", "Tensor", "(", "std", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.initialize": [[52, 54], ["net_wrappers.NetWrapper.initialize"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["", "def", "initialize", "(", "self", ",", "image_format", "=", "'rgb'", ",", "mean", "=", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "std", "=", "(", "0.229", ",", "0.224", ",", "0.225", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "initialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.preprocess_image": [[55, 70], ["im.cuda.cuda.cuda"], "methods", ["None"], ["", "def", "preprocess_image", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Normalize the image with the mean and standard deviation used by the network.\"\"\"", "\n", "\n", "if", "self", ".", "image_format", "in", "[", "'rgb'", ",", "'bgr'", "]", ":", "\n", "            ", "im", "=", "im", "/", "255", "\n", "\n", "", "if", "self", ".", "image_format", "in", "[", "'bgr'", ",", "'bgr255'", "]", ":", "\n", "            ", "im", "=", "im", "[", ":", ",", "[", "2", ",", "1", ",", "0", "]", ",", ":", ",", ":", "]", "\n", "", "im", "-=", "self", ".", "_mean", "\n", "im", "/=", "self", ".", "_std", "\n", "\n", "if", "self", ".", "use_gpu", ":", "\n", "            ", "im", "=", "im", ".", "cuda", "(", ")", "\n", "\n", "", "return", "im", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.extract_backbone": [[71, 76], ["net_wrappers.NetWithBackbone.preprocess_image", "net_wrappers.NetWithBackbone.net.extract_backbone_features"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.net_wrappers.NetWithBackbone.preprocess_image", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features"], ["", "def", "extract_backbone", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Extract backbone features from the network.\n        Expects a float tensor image with pixel range [0, 255].\"\"\"", "\n", "im", "=", "self", ".", "preprocess_image", "(", "im", ")", "\n", "return", "self", ".", "net", ".", "extract_backbone_features", "(", "im", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.FeatureBase.__init__": [[16, 23], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "fparams", "=", "None", ",", "pool_stride", "=", "None", ",", "output_size", "=", "None", ",", "normalize_power", "=", "None", ",", "use_for_color", "=", "True", ",", "use_for_gray", "=", "True", ")", ":", "\n", "        ", "self", ".", "fparams", "=", "fparams", "\n", "self", ".", "pool_stride", "=", "1", "if", "pool_stride", "is", "None", "else", "pool_stride", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "normalize_power", "=", "normalize_power", "\n", "self", ".", "use_for_color", "=", "use_for_color", "\n", "self", ".", "use_for_gray", "=", "use_for_gray", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.FeatureBase.initialize": [[24, 26], ["None"], "methods", ["None"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.FeatureBase.dim": [[27, 29], ["None"], "methods", ["None"], ["", "def", "dim", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.FeatureBase.stride": [[30, 32], ["None"], "methods", ["None"], ["", "def", "stride", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.FeatureBase.size": [[33, 39], ["isinstance", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "featurebase.FeatureBase.stride"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.stride"], ["", "def", "size", "(", "self", ",", "im_sz", ")", ":", "\n", "        ", "if", "self", ".", "output_size", "is", "None", ":", "\n", "            ", "return", "im_sz", "//", "self", ".", "stride", "(", ")", "\n", "", "if", "isinstance", "(", "im_sz", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "torch", ".", "Tensor", "(", "[", "self", ".", "output_size", "[", "0", "]", ",", "self", ".", "output_size", "[", "1", "]", "]", ")", "\n", "", "return", "self", ".", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.FeatureBase.extract": [[40, 43], ["None"], "methods", ["None"], ["", "def", "extract", "(", "self", ",", "im", ")", ":", "\n", "        ", "\"\"\"Performs feature extraction.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.FeatureBase.get_feature": [[44, 70], ["featurebase.FeatureBase.extract", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.avg_pool2d.abs().view", "torch.avg_pool2d.abs"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.extract", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs"], ["", "def", "get_feature", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Get the feature. Generally, call this function.\n        args:\n            im: image patch as a torch.Tensor.\n        \"\"\"", "\n", "\n", "# Return empty tensor if it should not be used", "\n", "is_color", "=", "im", ".", "shape", "[", "1", "]", "==", "3", "\n", "if", "is_color", "and", "not", "self", ".", "use_for_color", "or", "not", "is_color", "and", "not", "self", ".", "use_for_gray", ":", "\n", "            ", "return", "torch", ".", "Tensor", "(", "[", "]", ")", "\n", "\n", "# Extract feature", "\n", "", "feat", "=", "self", ".", "extract", "(", "im", ")", "\n", "\n", "# Pool/downsample", "\n", "if", "self", ".", "output_size", "is", "not", "None", ":", "\n", "            ", "feat", "=", "F", ".", "adaptive_avg_pool2d", "(", "feat", ",", "self", ".", "output_size", ")", "\n", "", "elif", "self", ".", "pool_stride", "!=", "1", ":", "\n", "            ", "feat", "=", "F", ".", "avg_pool2d", "(", "feat", ",", "self", ".", "pool_stride", ",", "self", ".", "pool_stride", ")", "\n", "\n", "# Normalize", "\n", "", "if", "self", ".", "normalize_power", "is", "not", "None", ":", "\n", "            ", "feat", "/=", "(", "torch", ".", "sum", "(", "feat", ".", "abs", "(", ")", ".", "view", "(", "feat", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "-", "1", ")", "**", "self", ".", "normalize_power", ",", "dim", "=", "3", ",", "keepdim", "=", "True", ")", "/", "\n", "(", "feat", ".", "shape", "[", "1", "]", "*", "feat", ".", "shape", "[", "2", "]", "*", "feat", ".", "shape", "[", "3", "]", ")", "+", "1e-10", ")", "**", "(", "1", "/", "self", ".", "normalize_power", ")", "\n", "\n", "", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.MultiFeatureBase.size": [[76, 81], ["isinstance", "pytracking.TensorList", "pytracking.TensorList", "featurebase.MultiFeatureBase.stride", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "zip", "featurebase.MultiFeatureBase.stride"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.stride", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.stride"], ["def", "size", "(", "self", ",", "im_sz", ")", ":", "\n", "        ", "if", "self", ".", "output_size", "is", "None", ":", "\n", "            ", "return", "TensorList", "(", "[", "im_sz", "//", "s", "for", "s", "in", "self", ".", "stride", "(", ")", "]", ")", "\n", "", "if", "isinstance", "(", "im_sz", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "im_sz", "//", "s", "if", "sz", "is", "None", "else", "torch", ".", "Tensor", "(", "[", "sz", "[", "0", "]", ",", "sz", "[", "1", "]", "]", ")", "for", "sz", ",", "s", "in", "zip", "(", "self", ".", "output_size", ",", "self", ".", "stride", "(", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.MultiFeatureBase.get_feature": [[82, 111], ["featurebase.MultiFeatureBase.extract", "enumerate", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "zip", "len", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "feat.abs().view", "feat.abs"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.extract", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs"], ["", "", "def", "get_feature", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Get the feature. Generally, call this function.\n        args:\n            im: image patch as a torch.Tensor.\n        \"\"\"", "\n", "\n", "# Return empty tensor if it should not be used", "\n", "is_color", "=", "im", ".", "shape", "[", "1", "]", "==", "3", "\n", "if", "is_color", "and", "not", "self", ".", "use_for_color", "or", "not", "is_color", "and", "not", "self", ".", "use_for_gray", ":", "\n", "            ", "return", "torch", ".", "Tensor", "(", "[", "]", ")", "\n", "\n", "", "feat_list", "=", "self", ".", "extract", "(", "im", ")", "\n", "\n", "output_sz", "=", "[", "None", "]", "*", "len", "(", "feat_list", ")", "if", "self", ".", "output_size", "is", "None", "else", "self", ".", "output_size", "\n", "\n", "# Pool/downsample", "\n", "for", "i", ",", "(", "sz", ",", "s", ")", "in", "enumerate", "(", "zip", "(", "output_sz", ",", "self", ".", "pool_stride", ")", ")", ":", "\n", "            ", "if", "sz", "is", "not", "None", ":", "\n", "                ", "feat_list", "[", "i", "]", "=", "F", ".", "adaptive_avg_pool2d", "(", "feat_list", "[", "i", "]", ",", "sz", ")", "\n", "", "elif", "s", "!=", "1", ":", "\n", "                ", "feat_list", "[", "i", "]", "=", "F", ".", "avg_pool2d", "(", "feat_list", "[", "i", "]", ",", "s", ",", "s", ")", "\n", "\n", "# Normalize", "\n", "", "", "if", "self", ".", "normalize_power", "is", "not", "None", ":", "\n", "            ", "for", "feat", "in", "feat_list", ":", "\n", "                ", "feat", "/=", "(", "torch", ".", "sum", "(", "feat", ".", "abs", "(", ")", ".", "view", "(", "feat", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "-", "1", ")", "**", "self", ".", "normalize_power", ",", "dim", "=", "3", ",", "keepdim", "=", "True", ")", "/", "\n", "(", "feat", ".", "shape", "[", "1", "]", "*", "feat", ".", "shape", "[", "2", "]", "*", "feat", ".", "shape", "[", "3", "]", ")", "+", "1e-10", ")", "**", "(", "1", "/", "self", ".", "normalize_power", ")", "\n", "\n", "", "", "return", "feat_list", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.ExtractorBase.__init__": [[10, 12], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "features", ")", ":", "\n", "        ", "self", ".", "features", "=", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.ExtractorBase.initialize": [[13, 16], ["f.initialize"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "for", "f", "in", "self", ".", "features", ":", "\n", "            ", "f", ".", "initialize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.SingleResolutionExtractor.__init__": [[23, 29], ["extractor.ExtractorBase.__init__", "extractor.SingleResolutionExtractor.features[].stride", "isinstance"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.stride"], ["def", "__init__", "(", "self", ",", "features", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "features", ")", "\n", "\n", "self", ".", "feature_stride", "=", "self", ".", "features", "[", "0", "]", ".", "stride", "(", ")", "\n", "if", "isinstance", "(", "self", ".", "feature_stride", ",", "(", "list", ",", "TensorList", ")", ")", ":", "\n", "            ", "self", ".", "feature_stride", "=", "self", ".", "feature_stride", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.SingleResolutionExtractor.stride": [[30, 32], ["None"], "methods", ["None"], ["", "", "def", "stride", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "feature_stride", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.SingleResolutionExtractor.size": [[33, 35], ["extractor.SingleResolutionExtractor.stride"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.stride"], ["", "def", "size", "(", "self", ",", "input_sz", ")", ":", "\n", "        ", "return", "input_sz", "//", "self", ".", "stride", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.SingleResolutionExtractor.extract": [[36, 47], ["isinstance", "torch.cat", "torch.cat", "pytracking.TensorList().unroll", "pytracking.features.preprocessing.sample_patch", "pytracking.TensorList", "f.get_feature"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.unroll", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch", "home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.MultiFeatureBase.get_feature"], ["", "def", "extract", "(", "self", ",", "im", ",", "pos", ",", "scales", ",", "image_sz", ")", ":", "\n", "        ", "if", "isinstance", "(", "scales", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "            ", "scales", "=", "[", "scales", "]", "\n", "\n", "# Get image patches", "\n", "", "im_patches", "=", "torch", ".", "cat", "(", "[", "sample_patch", "(", "im", ",", "pos", ",", "s", "*", "image_sz", ",", "image_sz", ")", "for", "s", "in", "scales", "]", ")", "\n", "\n", "# Compute features", "\n", "feature_map", "=", "torch", ".", "cat", "(", "TensorList", "(", "[", "f", ".", "get_feature", "(", "im_patches", ")", "for", "f", "in", "self", ".", "features", "]", ")", ".", "unroll", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "feature_map", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.__init__": [[54, 59], ["extractor.ExtractorBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "features", ",", "patch_mode", "=", "'replicate'", ",", "max_scale_change", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "features", ")", "\n", "self", ".", "patch_mode", "=", "patch_mode", "\n", "self", ".", "max_scale_change", "=", "max_scale_change", "\n", "self", ".", "is_color", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.stride": [[60, 62], ["torch.Tensor", "pytracking.TensorList().unroll().list", "pytracking.TensorList().unroll", "pytracking.TensorList", "f.stride", "extractor.MultiResolutionExtractor._return_feature"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.unroll", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.stride", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor._return_feature"], ["", "def", "stride", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "Tensor", "(", "TensorList", "(", "[", "f", ".", "stride", "(", ")", "for", "f", "in", "self", ".", "features", "if", "self", ".", "_return_feature", "(", "f", ")", "]", ")", ".", "unroll", "(", ")", ".", "list", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size": [[63, 65], ["pytracking.TensorList().unroll", "pytracking.TensorList", "f.size", "extractor.MultiResolutionExtractor._return_feature"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.unroll", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor._return_feature"], ["", "def", "size", "(", "self", ",", "input_sz", ")", ":", "\n", "        ", "return", "TensorList", "(", "[", "f", ".", "size", "(", "input_sz", ")", "for", "f", "in", "self", ".", "features", "if", "self", ".", "_return_feature", "(", "f", ")", "]", ")", ".", "unroll", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.dim": [[66, 68], ["pytracking.TensorList().unroll", "pytracking.TensorList", "f.dim", "extractor.MultiResolutionExtractor._return_feature"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.unroll", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor._return_feature"], ["", "def", "dim", "(", "self", ")", ":", "\n", "        ", "return", "TensorList", "(", "[", "f", ".", "dim", "(", ")", "for", "f", "in", "self", ".", "features", "if", "self", ".", "_return_feature", "(", "f", ")", "]", ")", ".", "unroll", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.get_fparams": [[69, 73], ["pytracking.TensorList().unroll", "pytracking.TensorList", "extractor.MultiResolutionExtractor._return_feature", "getattr", "extractor.MultiResolutionExtractor._return_feature"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.unroll", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor._return_feature", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor._return_feature"], ["", "def", "get_fparams", "(", "self", ",", "name", ":", "str", "=", "None", ")", ":", "\n", "        ", "if", "name", "is", "None", ":", "\n", "            ", "return", "[", "f", ".", "fparams", "for", "f", "in", "self", ".", "features", "if", "self", ".", "_return_feature", "(", "f", ")", "]", "\n", "", "return", "TensorList", "(", "[", "getattr", "(", "f", ".", "fparams", ",", "name", ")", "for", "f", "in", "self", ".", "features", "if", "self", ".", "_return_feature", "(", "f", ")", "]", ")", ".", "unroll", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.get_attribute": [[74, 79], ["pytracking.TensorList", "pytracking.TensorList", "getattr", "getattr", "extractor.MultiResolutionExtractor._return_feature", "extractor.MultiResolutionExtractor._return_feature", "hasattr"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor._return_feature", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor._return_feature"], ["", "def", "get_attribute", "(", "self", ",", "name", ":", "str", ",", "ignore_missing", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "ignore_missing", ":", "\n", "            ", "return", "TensorList", "(", "[", "getattr", "(", "f", ",", "name", ")", "for", "f", "in", "self", ".", "features", "if", "self", ".", "_return_feature", "(", "f", ")", "and", "hasattr", "(", "f", ",", "name", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "TensorList", "(", "[", "getattr", "(", "f", ",", "name", ",", "None", ")", "for", "f", "in", "self", ".", "features", "if", "self", ".", "_return_feature", "(", "f", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.get_unique_attribute": [[80, 90], ["getattr", "RuntimeError", "extractor.MultiResolutionExtractor._return_feature", "hasattr", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor._return_feature"], ["", "", "def", "get_unique_attribute", "(", "self", ",", "name", ":", "str", ")", ":", "\n", "        ", "feat", "=", "None", "\n", "for", "f", "in", "self", ".", "features", ":", "\n", "            ", "if", "self", ".", "_return_feature", "(", "f", ")", "and", "hasattr", "(", "f", ",", "name", ")", ":", "\n", "                ", "if", "feat", "is", "not", "None", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'The attribute was not unique.'", ")", "\n", "", "feat", "=", "f", "\n", "", "", "if", "feat", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "'The attribute did not exist'", ")", "\n", "", "return", "getattr", "(", "feat", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor._return_feature": [[91, 93], ["None"], "methods", ["None"], ["", "def", "_return_feature", "(", "self", ",", "f", ")", ":", "\n", "        ", "return", "self", ".", "is_color", "is", "None", "or", "self", ".", "is_color", "and", "f", ".", "use_for_color", "or", "not", "self", ".", "is_color", "and", "f", ".", "use_for_gray", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.set_is_color": [[94, 96], ["None"], "methods", ["None"], ["", "def", "set_is_color", "(", "self", ",", "is_color", ":", "bool", ")", ":", "\n", "        ", "self", ".", "is_color", "=", "is_color", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.extract": [[97, 123], ["isinstance", "zip", "torch.cat", "torch.cat", "pytracking.TensorList().unroll", "list", "list", "pytracking.TensorList", "pytracking.features.preprocessing.sample_patch", "f.get_feature"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.unroll", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch", "home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.MultiFeatureBase.get_feature"], ["", "def", "extract", "(", "self", ",", "im", ",", "pos", ",", "scales", ",", "image_sz", ",", "return_patches", "=", "False", ")", ":", "\n", "        ", "\"\"\"Extract features.\n        args:\n            im: Image.\n            pos: Center position for extraction.\n            scales: Image scales to extract features from.\n            image_sz: Size to resize the image samples to before extraction.\n        \"\"\"", "\n", "if", "isinstance", "(", "scales", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "            ", "scales", "=", "[", "scales", "]", "\n", "\n", "# Get image patches", "\n", "", "patch_iter", ",", "coord_iter", "=", "zip", "(", "*", "(", "sample_patch", "(", "im", ",", "pos", ",", "s", "*", "image_sz", ",", "image_sz", ",", "mode", "=", "self", ".", "patch_mode", ",", "\n", "max_scale_change", "=", "self", ".", "max_scale_change", ")", "for", "s", "in", "scales", ")", ")", "\n", "im_patches", "=", "torch", ".", "cat", "(", "list", "(", "patch_iter", ")", ")", "\n", "patch_coords", "=", "torch", ".", "cat", "(", "list", "(", "coord_iter", ")", ")", "\n", "\n", "# im_patches = torch.cat([sample_patch(im, pos, s*image_sz, image_sz) for s in scales])", "\n", "\n", "# Compute features", "\n", "feature_map", "=", "TensorList", "(", "[", "f", ".", "get_feature", "(", "im_patches", ")", "for", "f", "in", "self", ".", "features", "]", ")", ".", "unroll", "(", ")", "\n", "\n", "if", "return_patches", ":", "\n", "            ", "return", "feature_map", ",", "patch_coords", ",", "im_patches", "\n", "", "else", ":", "\n", "            ", "return", "feature_map", ",", "patch_coords", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.extract_transformed": [[124, 144], ["pytracking.features.preprocessing.sample_patch", "torch.cat", "pytracking.TensorList().unroll", "T", "pytracking.TensorList", "f.get_feature"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.unroll", "home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.MultiFeatureBase.get_feature"], ["", "", "def", "extract_transformed", "(", "self", ",", "im", ",", "pos", ",", "scale", ",", "image_sz", ",", "transforms", ")", ":", "\n", "        ", "\"\"\"Extract features from a set of transformed image samples.\n        args:\n            im: Image.\n            pos: Center position for extraction.\n            scale: Image scale to extract features from.\n            image_sz: Size to resize the image samples to before extraction.\n            transforms: A set of image transforms to apply.\n        \"\"\"", "\n", "\n", "# Get image patche", "\n", "im_patch", ",", "_", "=", "sample_patch", "(", "im", ",", "pos", ",", "scale", "*", "image_sz", ",", "image_sz", ")", "\n", "\n", "# Apply transforms", "\n", "im_patches", "=", "torch", ".", "cat", "(", "[", "T", "(", "im_patch", ")", "for", "T", "in", "transforms", "]", ")", "\n", "\n", "# Compute features", "\n", "feature_map", "=", "TensorList", "(", "[", "f", ".", "get_feature", "(", "im_patches", ")", "for", "f", "in", "self", ".", "features", "]", ")", ".", "unroll", "(", ")", "\n", "\n", "return", "feature_map", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.ResNet18m1.__init__": [[23, 33], ["pytracking.features.featurebase.MultiFeatureBase.__init__", "list", "ValueError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["def", "__init__", "(", "self", ",", "output_layers", ",", "net_path", "=", "None", ",", "use_gpu", "=", "True", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ResNet18m1", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "for", "l", "in", "output_layers", ":", "\n", "            ", "if", "l", "not", "in", "[", "'vggconv1'", ",", "'conv1'", ",", "'layer1'", ",", "'layer2'", ",", "'layer3'", ",", "'layer4'", ",", "'fc'", "]", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown layer'", ")", "\n", "\n", "", "", "self", ".", "output_layers", "=", "list", "(", "output_layers", ")", "\n", "self", ".", "use_gpu", "=", "use_gpu", "\n", "self", ".", "net_path", "=", "'resnet18_vggmconv1/resnet18_vggmconv1.pth'", "if", "net_path", "is", "None", "else", "net_path", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.ResNet18m1.initialize": [[34, 68], ["torch.Tensor().view", "torch.Tensor().view", "os.path.isabs", "deep.ResNet18m1.net.eval", "isinstance", "isinstance", "Exception", "deep.ResNet18m1.net.cuda", "len", "torch.Tensor", "torch.Tensor", "pytracking.evaluation.environment.env_settings", "os.path.join", "ltr.models.backbone.resnet18_vggm.resnet18_vggmconv1"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet18_vggm.resnet18_vggmconv1"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "self", ".", "pool_stride", ",", "int", ")", "and", "self", ".", "pool_stride", "==", "1", ":", "\n", "            ", "self", ".", "pool_stride", "=", "[", "1", "]", "*", "len", "(", "self", ".", "output_layers", ")", "\n", "\n", "", "self", ".", "layer_stride", "=", "{", "'vggconv1'", ":", "2", ",", "'conv1'", ":", "2", ",", "'layer1'", ":", "4", ",", "'layer2'", ":", "8", ",", "'layer3'", ":", "16", ",", "'layer4'", ":", "32", ",", "\n", "'fc'", ":", "None", "}", "\n", "self", ".", "layer_dim", "=", "{", "'vggconv1'", ":", "96", ",", "'conv1'", ":", "64", ",", "'layer1'", ":", "64", ",", "'layer2'", ":", "128", ",", "'layer3'", ":", "256", ",", "'layer4'", ":", "512", ",", "\n", "'fc'", ":", "None", "}", "\n", "\n", "self", ".", "mean", "=", "torch", ".", "Tensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "std", "=", "torch", ".", "Tensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "if", "os", ".", "path", ".", "isabs", "(", "self", ".", "net_path", ")", ":", "\n", "            ", "net_path_full", "=", "[", "self", ".", "net_path", "]", "\n", "", "else", ":", "\n", "            ", "root_paths", "=", "env_settings", "(", ")", ".", "network_path", "\n", "if", "isinstance", "(", "root_paths", ",", "str", ")", ":", "\n", "                ", "root_paths", "=", "[", "root_paths", "]", "\n", "", "net_path_full", "=", "[", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "net_path", ")", "for", "root", "in", "root_paths", "]", "\n", "\n", "", "self", ".", "net", "=", "None", "\n", "for", "net_path", "in", "net_path_full", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "net", "=", "resnet18_vggmconv1", "(", "self", ".", "output_layers", ",", "path", "=", "net_path", ")", "\n", "break", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "", "", "if", "self", ".", "net", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "'Did not find network file {}'", ".", "format", "(", "self", ".", "net_path", ")", ")", "\n", "\n", "", "if", "self", ".", "use_gpu", ":", "\n", "            ", "self", ".", "net", ".", "cuda", "(", ")", "\n", "", "self", ".", "net", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.ResNet18m1.dim": [[69, 71], ["pytracking.TensorList"], "methods", ["None"], ["", "def", "dim", "(", "self", ")", ":", "\n", "        ", "return", "TensorList", "(", "[", "self", ".", "layer_dim", "[", "l", "]", "for", "l", "in", "self", ".", "output_layers", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.ResNet18m1.stride": [[72, 74], ["pytracking.TensorList", "zip"], "methods", ["None"], ["", "def", "stride", "(", "self", ")", ":", "\n", "        ", "return", "TensorList", "(", "[", "s", "*", "self", ".", "layer_stride", "[", "l", "]", "for", "l", ",", "s", "in", "zip", "(", "self", ".", "output_layers", ",", "self", ".", "pool_stride", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.ResNet18m1.extract": [[75, 85], ["im.cuda.cuda.cuda", "torch.no_grad", "pytracking.TensorList", "deep.ResNet18m1.net().values", "deep.ResNet18m1.net"], "methods", ["None"], ["", "def", "extract", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "im", "=", "im", "/", "255", "\n", "im", "-=", "self", ".", "mean", "\n", "im", "/=", "self", ".", "std", "\n", "\n", "if", "self", ".", "use_gpu", ":", "\n", "            ", "im", "=", "im", ".", "cuda", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "TensorList", "(", "self", ".", "net", "(", "im", ")", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.Mobilenet.__init__": [[94, 104], ["pytracking.features.featurebase.MultiFeatureBase.__init__", "list", "ValueError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["def", "__init__", "(", "self", ",", "output_layers", ",", "net_path", "=", "None", ",", "use_gpu", "=", "True", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ResNet18m1", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "for", "l", "in", "output_layers", ":", "\n", "            ", "if", "l", "not", "in", "[", "'init_conv'", ",", "'layer1'", ",", "'layer2'", ",", "'layer3'", ",", "'layer4'", ",", "'layer5'", ",", "'layer6'", ",", "'layer_out'", "]", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown layer'", ")", "\n", "\n", "", "", "self", ".", "output_layers", "=", "list", "(", "output_layers", ")", "\n", "self", ".", "use_gpu", "=", "use_gpu", "\n", "self", ".", "net_path", "=", "'mobilev3_test.t7'", "if", "net_path", "is", "None", "else", "net_path", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.Mobilenet.initialize": [[105, 138], ["torch.Tensor().view", "torch.Tensor().view", "os.path.isabs", "deep.Mobilenet.net.eval", "isinstance", "isinstance", "Exception", "deep.Mobilenet.net.cuda", "len", "torch.Tensor", "torch.Tensor", "pytracking.evaluation.environment.env_settings", "os.path.join", "ltr.models.backbone.mobilenetv3.mobilenet3"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.mobilenet3"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "self", ".", "pool_stride", ",", "int", ")", "and", "self", ".", "pool_stride", "==", "1", ":", "\n", "            ", "self", ".", "pool_stride", "=", "[", "1", "]", "*", "len", "(", "self", ".", "output_layers", ")", "\n", "\n", "", "self", ".", "layer_stride", "=", "{", "'init_conv'", ":", "2", ",", "'layer1'", ":", "2", ",", "'layer2'", ":", "4", ",", "'layer3'", ":", "8", ",", "'layer4'", ":", "16", ",", "'layer5'", ":", "16", ",", "'layer6'", ":", "32", ",", "'layer_out'", ":", "32", "}", "\n", "self", ".", "layer_dim", "=", "{", "'init_conv'", ":", "16", ",", "'layer1'", ":", "16", ",", "'layer2'", ":", "24", ",", "'layer3'", ":", "40", ",", "'layer4'", ":", "80", ",", "'layer5'", ":", "112", ",", "'layer6'", ":", "160", ",", "'layer_out'", ":", "960", "}", "\n", "\n", "\n", "self", ".", "mean", "=", "torch", ".", "Tensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "std", "=", "torch", ".", "Tensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "if", "os", ".", "path", ".", "isabs", "(", "self", ".", "net_path", ")", ":", "\n", "            ", "net_path_full", "=", "[", "self", ".", "net_path", "]", "\n", "", "else", ":", "\n", "            ", "root_paths", "=", "env_settings", "(", ")", ".", "network_path", "\n", "if", "isinstance", "(", "root_paths", ",", "str", ")", ":", "\n", "                ", "root_paths", "=", "[", "root_paths", "]", "\n", "", "net_path_full", "=", "[", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "net_path", ")", "for", "root", "in", "root_paths", "]", "\n", "\n", "", "self", ".", "net", "=", "None", "\n", "for", "net_path", "in", "net_path_full", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "net", "=", "mobilenet3", "(", "self", ".", "output_layers", ",", "path", "=", "net_path_full", ")", "\n", "break", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "", "", "if", "self", ".", "net", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "'Did not find network file {}'", ".", "format", "(", "self", ".", "net_path", ")", ")", "\n", "\n", "", "if", "self", ".", "use_gpu", ":", "\n", "            ", "self", ".", "net", ".", "cuda", "(", ")", "\n", "", "self", ".", "net", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.Mobilenet.dim": [[139, 141], ["pytracking.TensorList"], "methods", ["None"], ["", "def", "dim", "(", "self", ")", ":", "\n", "        ", "return", "TensorList", "(", "[", "self", ".", "layer_dim", "[", "l", "]", "for", "l", "in", "self", ".", "output_layers", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.Mobilenet.stride": [[142, 144], ["pytracking.TensorList", "zip"], "methods", ["None"], ["", "def", "stride", "(", "self", ")", ":", "\n", "        ", "return", "TensorList", "(", "[", "s", "*", "self", ".", "layer_stride", "[", "l", "]", "for", "l", ",", "s", "in", "zip", "(", "self", ".", "output_layers", ",", "self", ".", "pool_stride", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.Mobilenet.extract": [[145, 155], ["im.cuda.cuda.cuda", "torch.no_grad", "pytracking.TensorList", "deep.Mobilenet.net().values", "deep.Mobilenet.net"], "methods", ["None"], ["", "def", "extract", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "im", "=", "im", "/", "255", "\n", "im", "-=", "self", ".", "mean", "\n", "im", "/=", "self", ".", "std", "\n", "\n", "if", "self", ".", "use_gpu", ":", "\n", "            ", "im", "=", "im", ".", "cuda", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "return", "TensorList", "(", "self", ".", "net", "(", "im", ")", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.ATOMResNet18.__init__": [[164, 170], ["pytracking.features.featurebase.MultiFeatureBase.__init__", "list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["def", "__init__", "(", "self", ",", "output_layers", "=", "(", "'layer3'", ",", ")", ",", "net_path", "=", "'atom_iou'", ",", "use_gpu", "=", "True", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "output_layers", "=", "list", "(", "output_layers", ")", "\n", "self", ".", "use_gpu", "=", "use_gpu", "\n", "self", ".", "net_path", "=", "net_path", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.ATOMResNet18.initialize": [[171, 194], ["pytracking.utils.loading.load_network", "deep.ATOMResNet18.net.eval", "sorted", "torch.Tensor().view", "torch.Tensor().view", "deep.ATOMResNet18.net.cuda", "isinstance", "list", "len", "set", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_network", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "self", ".", "net", "=", "load_network", "(", "self", ".", "net_path", ")", "\n", "\n", "if", "self", ".", "use_gpu", ":", "\n", "            ", "self", ".", "net", ".", "cuda", "(", ")", "\n", "", "self", ".", "net", ".", "eval", "(", ")", "\n", "\n", "self", ".", "iou_predictor", "=", "self", ".", "net", ".", "bb_regressor", "\n", "\n", "self", ".", "layer_stride", "=", "{", "'conv1'", ":", "2", ",", "'layer1'", ":", "4", ",", "'layer2'", ":", "8", ",", "'layer3'", ":", "16", ",", "'layer4'", ":", "32", ",", "'classification'", ":", "16", ",", "\n", "'fc'", ":", "None", "}", "\n", "self", ".", "layer_dim", "=", "{", "'conv1'", ":", "64", ",", "'layer1'", ":", "64", ",", "'layer2'", ":", "128", ",", "'layer3'", ":", "256", ",", "'layer4'", ":", "512", ",", "'classification'", ":", "256", ",", "\n", "'fc'", ":", "None", "}", "\n", "\n", "self", ".", "iounet_feature_layers", "=", "self", ".", "net", ".", "bb_regressor_layer", "\n", "\n", "if", "isinstance", "(", "self", ".", "pool_stride", ",", "int", ")", "and", "self", ".", "pool_stride", "==", "1", ":", "\n", "            ", "self", ".", "pool_stride", "=", "[", "1", "]", "*", "len", "(", "self", ".", "output_layers", ")", "\n", "\n", "", "self", ".", "feature_layers", "=", "sorted", "(", "list", "(", "set", "(", "self", ".", "output_layers", "+", "self", ".", "iounet_feature_layers", ")", ")", ")", "\n", "\n", "self", ".", "mean", "=", "torch", ".", "Tensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "std", "=", "torch", ".", "Tensor", "(", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.ATOMResNet18.dim": [[195, 197], ["pytracking.TensorList"], "methods", ["None"], ["", "def", "dim", "(", "self", ")", ":", "\n", "        ", "return", "TensorList", "(", "[", "self", ".", "layer_dim", "[", "l", "]", "for", "l", "in", "self", ".", "output_layers", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.ATOMResNet18.stride": [[198, 200], ["pytracking.TensorList", "zip"], "methods", ["None"], ["", "def", "stride", "(", "self", ")", ":", "\n", "        ", "return", "TensorList", "(", "[", "s", "*", "self", ".", "layer_stride", "[", "l", "]", "for", "l", ",", "s", "in", "zip", "(", "self", ".", "output_layers", ",", "self", ".", "pool_stride", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.deep.ATOMResNet18.extract": [[201, 221], ["pytracking.TensorList", "pytracking.TensorList", "im.cuda.cuda.cuda", "torch.no_grad", "deep.ATOMResNet18.net.extract_features", "torch.no_grad", "pytracking.TensorList", "output_features[].clone", "deep.ATOMResNet18.iou_predictor.get_iou_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_features", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_iou_feat"], ["", "def", "extract", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "im", "=", "im", "/", "255", "\n", "im", "-=", "self", ".", "mean", "\n", "im", "/=", "self", ".", "std", "\n", "\n", "if", "self", ".", "use_gpu", ":", "\n", "            ", "im", "=", "im", ".", "cuda", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "output_features", "=", "self", ".", "net", ".", "extract_features", "(", "im", ",", "self", ".", "feature_layers", ")", "\n", "\n", "# Store the raw resnet features which are input to iounet", "\n", "", "self", ".", "iounet_backbone_features", "=", "TensorList", "(", "\n", "[", "output_features", "[", "layer", "]", ".", "clone", "(", ")", "for", "layer", "in", "self", ".", "iounet_feature_layers", "]", ")", "\n", "\n", "# Store the processed features from iounet, just before pooling", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "iounet_features", "=", "TensorList", "(", "self", ".", "iou_predictor", ".", "get_iou_feat", "(", "self", ".", "iounet_backbone_features", ")", ")", "\n", "\n", "", "return", "TensorList", "(", "[", "output_features", "[", "layer", "]", "for", "layer", "in", "self", ".", "output_layers", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.features.color.RGB.dim": [[7, 9], ["None"], "methods", ["None"], ["def", "dim", "(", "self", ")", ":", "\n", "        ", "return", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.color.RGB.stride": [[10, 12], ["None"], "methods", ["None"], ["", "def", "stride", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pool_stride", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.color.RGB.extract": [[13, 15], ["None"], "methods", ["None"], ["", "def", "extract", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "im", "/", "255", "-", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.color.Grayscale.dim": [[19, 21], ["None"], "methods", ["None"], ["def", "dim", "(", "self", ")", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.color.Grayscale.stride": [[22, 24], ["None"], "methods", ["None"], ["", "def", "stride", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pool_stride", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.color.Grayscale.extract": [[25, 27], ["torch.mean"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "extract", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "torch", ".", "mean", "(", "im", "/", "255", "-", "0.5", ",", "1", ",", "keepdim", "=", "True", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch": [[6, 8], ["torch.from_numpy().float().permute().unsqueeze", "torch.from_numpy().float().permute().unsqueeze", "torch.from_numpy().float().permute", "torch.from_numpy().float().permute", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["def", "numpy_to_torch", "(", "a", ":", "np", ".", "ndarray", ")", ":", "\n", "    ", "return", "torch", ".", "from_numpy", "(", "a", ")", ".", "float", "(", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.torch_to_numpy": [[10, 12], ["a.squeeze().permute().numpy", "a.squeeze().permute", "a.squeeze"], "function", ["None"], ["", "def", "torch_to_numpy", "(", "a", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "return", "a", ".", "squeeze", "(", "0", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_transformed": [[14, 31], ["preprocessing.sample_patch", "torch.cat", "torch.cat", "T"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch"], ["", "def", "sample_patch_transformed", "(", "im", ",", "pos", ",", "scale", ",", "image_sz", ",", "transforms", ",", "is_mask", "=", "False", ")", ":", "\n", "    ", "\"\"\"Extract transformed image samples.\n    args:\n        im: Image.\n        pos: Center position for extraction.\n        scale: Image scale to extract features from.\n        image_sz: Size to resize the image samples to before extraction.\n        transforms: A set of image transforms to apply.\n    \"\"\"", "\n", "\n", "# Get image patche", "\n", "im_patch", ",", "_", "=", "sample_patch", "(", "im", ",", "pos", ",", "scale", "*", "image_sz", ",", "image_sz", ",", "is_mask", "=", "is_mask", ")", "\n", "\n", "# Apply transforms", "\n", "im_patches", "=", "torch", ".", "cat", "(", "[", "T", "(", "im_patch", ",", "is_mask", "=", "is_mask", ")", "for", "T", "in", "transforms", "]", ")", "\n", "\n", "return", "im_patches", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch_multiscale": [[33, 53], ["isinstance", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "list", "list", "preprocessing.sample_patch"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch"], ["", "def", "sample_patch_multiscale", "(", "im", ",", "pos", ",", "scales", ",", "image_sz", ",", "mode", ":", "str", "=", "'replicate'", ",", "max_scale_change", "=", "None", ")", ":", "\n", "    ", "\"\"\"Extract image patches at multiple scales.\n    args:\n        im: Image.\n        pos: Center position for extraction.\n        scales: Image scales to extract image patches from.\n        image_sz: Size to resize the image samples to\n        mode: how to treat image borders: 'replicate' (default), 'inside' or 'inside_major'\n        max_scale_change: maximum allowed scale change when using 'inside' and 'inside_major' mode\n    \"\"\"", "\n", "if", "isinstance", "(", "scales", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "        ", "scales", "=", "[", "scales", "]", "\n", "\n", "# Get image patches", "\n", "", "patch_iter", ",", "coord_iter", "=", "zip", "(", "*", "(", "sample_patch", "(", "im", ",", "pos", ",", "s", "*", "image_sz", ",", "image_sz", ",", "mode", "=", "mode", ",", "\n", "max_scale_change", "=", "max_scale_change", ")", "for", "s", "in", "scales", ")", ")", "\n", "im_patches", "=", "torch", ".", "cat", "(", "list", "(", "patch_iter", ")", ")", "\n", "patch_coords", "=", "torch", ".", "cat", "(", "list", "(", "coord_iter", ")", ")", "\n", "\n", "return", "im_patches", ",", "patch_coords", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.sample_patch": [[55, 149], ["pos.long().clone", "torch.max().long", "torch.max().long", "torch.Tensor", "torch.Tensor", "shrink_factor.min.clamp_", "torch.min().item", "torch.min().item", "int", "int", "sample_sz.float", "torch.LongTensor", "torch.LongTensor", "torch.pad", "torch.pad", "torch.cat().view", "torch.cat().view", "torch.interpolate", "torch.interpolate", "pos.long", "sample_sz.float", "shrink_factor.min.max", "max", "torch.max", "torch.max", "tl[].int().item", "br[].int().item", "tl[].int().item", "br[].int().item", "F.interpolate.clone", "output_sz.long().tolist", "output_sz.long().tolist", "shrink_factor.min.min", "torch.min", "torch.min", "int", "sz.round", "torch.Tensor", "torch.Tensor", "torch.cat", "torch.cat", "sample_sz.float", "os[].item", "os[].item", "tl[].int", "br[].int", "tl[].int", "br[].int", "output_sz.long", "output_sz.long", "sample_sz.float", "output_sz.float"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate", "home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate"], ["", "def", "sample_patch", "(", "im", ":", "torch", ".", "Tensor", ",", "pos", ":", "torch", ".", "Tensor", ",", "sample_sz", ":", "torch", ".", "Tensor", ",", "output_sz", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "mode", ":", "str", "=", "'replicate'", ",", "max_scale_change", "=", "None", ",", "is_mask", "=", "False", ")", ":", "\n", "    ", "\"\"\"Sample an image patch.\n\n    args:\n        im: Image\n        pos: center position of crop\n        sample_sz: size to crop\n        output_sz: size to resize to\n        mode: how to treat image borders: 'replicate' (default), 'inside' or 'inside_major'\n        max_scale_change: maximum allowed scale change when using 'inside' and 'inside_major' mode\n    \"\"\"", "\n", "\n", "# if mode not in ['replicate', 'inside']:", "\n", "#     raise ValueError('Unknown border mode \\'{}\\'.'.format(mode))", "\n", "\n", "# copy and convert", "\n", "posl", "=", "pos", ".", "long", "(", ")", ".", "clone", "(", ")", "\n", "\n", "pad_mode", "=", "mode", "\n", "\n", "# Get new sample size if forced inside the image", "\n", "if", "mode", "==", "'inside'", "or", "mode", "==", "'inside_major'", ":", "\n", "        ", "pad_mode", "=", "'replicate'", "\n", "im_sz", "=", "torch", ".", "Tensor", "(", "[", "im", ".", "shape", "[", "2", "]", ",", "im", ".", "shape", "[", "3", "]", "]", ")", "\n", "shrink_factor", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "im_sz", ")", "\n", "if", "mode", "==", "'inside'", ":", "\n", "            ", "shrink_factor", "=", "shrink_factor", ".", "max", "(", ")", "\n", "", "elif", "mode", "==", "'inside_major'", ":", "\n", "            ", "shrink_factor", "=", "shrink_factor", ".", "min", "(", ")", "\n", "", "shrink_factor", ".", "clamp_", "(", "min", "=", "1", ",", "max", "=", "max_scale_change", ")", "\n", "sample_sz", "=", "(", "sample_sz", ".", "float", "(", ")", "/", "shrink_factor", ")", ".", "long", "(", ")", "\n", "\n", "# Compute pre-downsampling factor", "\n", "", "if", "output_sz", "is", "not", "None", ":", "\n", "        ", "resize_factor", "=", "torch", ".", "min", "(", "sample_sz", ".", "float", "(", ")", "/", "output_sz", ".", "float", "(", ")", ")", ".", "item", "(", ")", "\n", "df", "=", "int", "(", "max", "(", "int", "(", "resize_factor", "-", "0.1", ")", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "        ", "df", "=", "int", "(", "1", ")", "\n", "\n", "", "sz", "=", "sample_sz", ".", "float", "(", ")", "/", "df", "# new size", "\n", "\n", "# Do downsampling", "\n", "if", "df", ">", "1", ":", "\n", "        ", "os", "=", "posl", "%", "df", "# offset", "\n", "posl", "=", "(", "posl", "-", "os", ")", "/", "df", "# new position", "\n", "im2", "=", "im", "[", "...", ",", "os", "[", "0", "]", ".", "item", "(", ")", ":", ":", "df", ",", "os", "[", "1", "]", ".", "item", "(", ")", ":", ":", "df", "]", "# downsample", "\n", "", "else", ":", "\n", "        ", "im2", "=", "im", "\n", "\n", "# compute size to crop", "\n", "", "szl", "=", "torch", ".", "max", "(", "sz", ".", "round", "(", ")", ",", "torch", ".", "Tensor", "(", "[", "2", "]", ")", ")", ".", "long", "(", ")", "\n", "\n", "# Extract top and bottom coordinates", "\n", "tl", "=", "posl", "-", "(", "szl", "-", "1", ")", "/", "2", "\n", "br", "=", "posl", "+", "szl", "/", "2", "+", "1", "\n", "\n", "# Shift the crop to inside", "\n", "if", "mode", "==", "'inside'", "or", "mode", "==", "'inside_major'", ":", "\n", "        ", "im2_sz", "=", "torch", ".", "LongTensor", "(", "[", "im2", ".", "shape", "[", "2", "]", ",", "im2", ".", "shape", "[", "3", "]", "]", ")", "\n", "shift", "=", "(", "-", "tl", ")", ".", "clamp", "(", "0", ")", "-", "(", "br", "-", "im2_sz", ")", ".", "clamp", "(", "0", ")", "\n", "tl", "+=", "shift", "\n", "br", "+=", "shift", "\n", "\n", "outside", "=", "(", "(", "-", "tl", ")", ".", "clamp", "(", "0", ")", "+", "(", "br", "-", "im2_sz", ")", ".", "clamp", "(", "0", ")", ")", "//", "2", "\n", "shift", "=", "(", "-", "tl", "-", "outside", ")", "*", "(", "outside", ">", "0", ")", ".", "long", "(", ")", "\n", "tl", "+=", "shift", "\n", "br", "+=", "shift", "\n", "\n", "# Get image patch", "\n", "# im_patch = im2[...,tl[0].item():br[0].item(),tl[1].item():br[1].item()]", "\n", "\n", "# Get image patch", "\n", "", "pad", "=", "(", "-", "tl", "[", "1", "]", ".", "int", "(", ")", ".", "item", "(", ")", ",", "br", "[", "1", "]", ".", "int", "(", ")", ".", "item", "(", ")", "-", "im2", ".", "shape", "[", "3", "]", ",", "\n", "-", "tl", "[", "0", "]", ".", "int", "(", ")", ".", "item", "(", ")", ",", "br", "[", "0", "]", ".", "int", "(", ")", ".", "item", "(", ")", "-", "im2", ".", "shape", "[", "2", "]", ")", "\n", "\n", "if", "not", "is_mask", ":", "\n", "        ", "im_patch", "=", "F", ".", "pad", "(", "im2", ",", "pad", ",", "pad_mode", ")", "\n", "", "else", ":", "\n", "        ", "im_patch", "=", "F", ".", "pad", "(", "im2", ",", "pad", ")", "\n", "\n", "# Get image coordinates", "\n", "", "patch_coord", "=", "df", "*", "torch", ".", "cat", "(", "(", "tl", ",", "br", ")", ")", ".", "view", "(", "1", ",", "4", ")", "\n", "\n", "if", "output_sz", "is", "None", "or", "(", "im_patch", ".", "shape", "[", "-", "2", "]", "==", "output_sz", "[", "0", "]", "and", "im_patch", ".", "shape", "[", "-", "1", "]", "==", "output_sz", "[", "1", "]", ")", ":", "\n", "        ", "return", "im_patch", ".", "clone", "(", ")", ",", "patch_coord", "\n", "\n", "# Resample", "\n", "", "if", "not", "is_mask", ":", "\n", "        ", "im_patch", "=", "F", ".", "interpolate", "(", "im_patch", ",", "output_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", ",", "mode", "=", "'bilinear'", ")", "\n", "", "else", ":", "\n", "        ", "im_patch", "=", "F", ".", "interpolate", "(", "im_patch", ",", "output_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", ",", "mode", "=", "'nearest'", ")", "\n", "\n", "", "return", "im_patch", ",", "patch_coord", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.__init__": [[10, 19], ["pytracking.features.featurebase.FeatureBase.__init__", "util.Concatenate.features[].stride", "feat.stride", "ValueError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.stride", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.stride"], ["def", "__init__", "(", "self", ",", "features", ",", "pool_stride", "=", "None", ",", "normalize_power", "=", "None", ",", "use_for_color", "=", "True", ",", "use_for_gray", "=", "True", ")", ":", "\n", "        ", "super", "(", "Concatenate", ",", "self", ")", ".", "__init__", "(", "pool_stride", ",", "normalize_power", ",", "use_for_color", ",", "use_for_gray", ")", "\n", "self", ".", "features", "=", "features", "\n", "\n", "self", ".", "input_stride", "=", "self", ".", "features", "[", "0", "]", ".", "stride", "(", ")", "\n", "\n", "for", "feat", "in", "self", ".", "features", ":", "\n", "            ", "if", "self", ".", "input_stride", "!=", "feat", ".", "stride", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'Strides for the features must be the same for a bultiresolution feature.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim": [[20, 22], ["sum", "f.dim"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "", "", "def", "dim", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "[", "f", ".", "dim", "(", ")", "for", "f", "in", "self", ".", "features", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.stride": [[23, 25], ["None"], "methods", ["None"], ["", "def", "stride", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pool_stride", "*", "self", ".", "input_stride", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.extract": [[26, 28], ["torch.cat", "f.get_feature"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.featurebase.MultiFeatureBase.get_feature"], ["", "def", "extract", "(", "self", ",", "im", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "[", "f", ".", "get_feature", "(", "im", ")", "for", "f", "in", "self", ".", "features", "]", ",", "1", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Transform.__init__": [[13, 16], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "output_sz", "=", "None", ",", "shift", "=", "None", ")", ":", "\n", "        ", "self", ".", "output_sz", "=", "output_sz", "\n", "self", ".", "shift", "=", "(", "0", ",", "0", ")", "if", "shift", "is", "None", "else", "shift", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Transform.__call__": [[17, 19], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "image", ",", "is_mask", "=", "False", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Transform.crop_to_output": [[20, 38], ["isinstance", "torch.pad", "torch.pad", "math.floor", "math.ceil", "math.floor", "math.ceil"], "methods", ["None"], ["", "def", "crop_to_output", "(", "self", ",", "image", ")", ":", "\n", "        ", "if", "isinstance", "(", "image", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "imsz", "=", "image", ".", "shape", "[", "2", ":", "]", "\n", "if", "self", ".", "output_sz", "is", "None", ":", "\n", "                ", "pad_h", "=", "0", "\n", "pad_w", "=", "0", "\n", "", "else", ":", "\n", "                ", "pad_h", "=", "(", "self", ".", "output_sz", "[", "0", "]", "-", "imsz", "[", "0", "]", ")", "/", "2", "\n", "pad_w", "=", "(", "self", ".", "output_sz", "[", "1", "]", "-", "imsz", "[", "1", "]", ")", "/", "2", "\n", "\n", "", "pad_left", "=", "math", ".", "floor", "(", "pad_w", ")", "+", "self", ".", "shift", "[", "1", "]", "\n", "pad_right", "=", "math", ".", "ceil", "(", "pad_w", ")", "-", "self", ".", "shift", "[", "1", "]", "\n", "pad_top", "=", "math", ".", "floor", "(", "pad_h", ")", "+", "self", ".", "shift", "[", "0", "]", "\n", "pad_bottom", "=", "math", ".", "ceil", "(", "pad_h", ")", "-", "self", ".", "shift", "[", "0", "]", "\n", "\n", "return", "F", ".", "pad", "(", "image", ",", "(", "pad_left", ",", "pad_right", ",", "pad_top", ",", "pad_bottom", ")", ",", "'replicate'", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Identity.__call__": [[41, 43], ["augmentation.Identity.crop_to_output"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Transform.crop_to_output"], ["def", "__call__", "(", "self", ",", "image", ",", "is_mask", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "crop_to_output", "(", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.FlipHorizontal.__call__": [[46, 51], ["isinstance", "augmentation.FlipHorizontal.crop_to_output", "numpy.fliplr", "image.flip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Transform.crop_to_output"], ["def", "__call__", "(", "self", ",", "image", ",", "is_mask", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "image", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "self", ".", "crop_to_output", "(", "image", ".", "flip", "(", "(", "3", ",", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "fliplr", "(", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.FlipVertical.__call__": [[54, 59], ["isinstance", "augmentation.FlipVertical.crop_to_output", "numpy.flipud", "image.flip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Transform.crop_to_output"], ["def", "__call__", "(", "self", ",", "image", ":", "torch", ".", "Tensor", ",", "is_mask", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "image", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "self", ".", "crop_to_output", "(", "image", ".", "flip", "(", "(", "2", ",", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "flipud", "(", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Translation.__init__": [[62, 65], ["augmentation.Transform.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "translation", ",", "output_sz", "=", "None", ",", "shift", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "output_sz", ",", "shift", ")", "\n", "self", ".", "shift", "=", "(", "self", ".", "shift", "[", "0", "]", "+", "translation", "[", "0", "]", ",", "self", ".", "shift", "[", "1", "]", "+", "translation", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Translation.__call__": [[66, 71], ["isinstance", "augmentation.Translation.crop_to_output"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Transform.crop_to_output"], ["", "def", "__call__", "(", "self", ",", "image", ",", "is_mask", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "image", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "self", ".", "crop_to_output", "(", "image", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Scale.__init__": [[74, 77], ["augmentation.Transform.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "scale_factor", ",", "output_sz", "=", "None", ",", "shift", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "output_sz", ",", "shift", ")", "\n", "self", ".", "scale_factor", "=", "scale_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Scale.__call__": [[78, 96], ["isinstance", "round", "round", "torch.interpolate", "torch.interpolate", "augmentation.Scale.crop_to_output"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate", "home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate", "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Transform.crop_to_output"], ["", "def", "__call__", "(", "self", ",", "image", ",", "is_mask", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "image", ",", "torch", ".", "Tensor", ")", ":", "\n", "# Calculate new size. Ensure that it is even so that crop/pad becomes easier", "\n", "            ", "h_orig", ",", "w_orig", "=", "image", ".", "shape", "[", "2", ":", "]", "\n", "\n", "if", "h_orig", "!=", "w_orig", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "h_new", "=", "round", "(", "h_orig", "/", "self", ".", "scale_factor", ")", "\n", "h_new", "+=", "(", "h_new", "-", "h_orig", ")", "%", "2", "\n", "w_new", "=", "round", "(", "w_orig", "/", "self", ".", "scale_factor", ")", "\n", "w_new", "+=", "(", "w_new", "-", "w_orig", ")", "%", "2", "\n", "\n", "image_resized", "=", "F", ".", "interpolate", "(", "image", ",", "[", "h_new", ",", "w_new", "]", ",", "mode", "=", "'bilinear'", ")", "\n", "\n", "return", "self", ".", "crop_to_output", "(", "image_resized", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Affine.__init__": [[100, 103], ["augmentation.Transform.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "transform_matrix", ",", "output_sz", "=", "None", ",", "shift", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "output_sz", ",", "shift", ")", "\n", "self", ".", "transform_matrix", "=", "transform_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Affine.__call__": [[104, 109], ["isinstance", "augmentation.Affine.crop_to_output", "cv2.warpAffine", "pytracking.features.preprocessing.numpy_to_torch", "augmentation.Affine.", "pytracking.features.preprocessing.torch_to_numpy"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Transform.crop_to_output", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.torch_to_numpy"], ["", "def", "__call__", "(", "self", ",", "image", ",", "is_mask", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "image", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "self", ".", "crop_to_output", "(", "numpy_to_torch", "(", "self", "(", "torch_to_numpy", "(", "image", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "cv", ".", "warpAffine", "(", "image", ",", "self", ".", "transform_matrix", ",", "image", ".", "shape", "[", "1", ":", ":", "-", "1", "]", ",", "borderMode", "=", "cv", ".", "BORDER_REPLICATE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Rotate.__init__": [[113, 116], ["augmentation.Transform.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "angle", ",", "output_sz", "=", "None", ",", "shift", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "output_sz", ",", "shift", ")", "\n", "self", ".", "angle", "=", "math", ".", "pi", "*", "angle", "/", "180", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Rotate.__call__": [[117, 126], ["isinstance", "augmentation.Rotate.crop_to_output", "numpy.array", "numpy.concatenate", "cv2.warpAffine", "pytracking.features.preprocessing.numpy_to_torch", "augmentation.Rotate.", "numpy.expand_dims", "pytracking.features.preprocessing.torch_to_numpy", "numpy.array", "math.cos", "math.sin", "math.cos", "math.sin"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Transform.crop_to_output", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.torch_to_numpy"], ["", "def", "__call__", "(", "self", ",", "image", ",", "is_mask", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "image", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "return", "self", ".", "crop_to_output", "(", "numpy_to_torch", "(", "self", "(", "torch_to_numpy", "(", "image", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "c", "=", "(", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "image", ".", "shape", "[", ":", "2", "]", ")", ",", "1", ")", "-", "1", ")", "/", "2", "\n", "R", "=", "np", ".", "array", "(", "[", "[", "math", ".", "cos", "(", "self", ".", "angle", ")", ",", "math", ".", "sin", "(", "self", ".", "angle", ")", "]", ",", "\n", "[", "-", "math", ".", "sin", "(", "self", ".", "angle", ")", ",", "math", ".", "cos", "(", "self", ".", "angle", ")", "]", "]", ")", "\n", "H", "=", "np", ".", "concatenate", "(", "[", "R", ",", "c", "-", "R", "@", "c", "]", ",", "1", ")", "\n", "return", "cv", ".", "warpAffine", "(", "image", ",", "H", ",", "image", ".", "shape", "[", "1", ":", ":", "-", "1", "]", ",", "borderMode", "=", "cv", ".", "BORDER_REPLICATE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Blur.__init__": [[130, 140], ["augmentation.Transform.__init__", "isinstance", "math.ceil", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "augmentation.Blur.filter[].view", "augmentation.Blur.filter[].sum", "augmentation.Blur.filter[].view", "augmentation.Blur.filter[].sum", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "sigma", ",", "output_sz", "=", "None", ",", "shift", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "output_sz", ",", "shift", ")", "\n", "if", "isinstance", "(", "sigma", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "            ", "sigma", "=", "(", "sigma", ",", "sigma", ")", "\n", "", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "filter_size", "=", "[", "math", ".", "ceil", "(", "2", "*", "s", ")", "for", "s", "in", "self", ".", "sigma", "]", "\n", "x_coord", "=", "[", "torch", ".", "arange", "(", "-", "sz", ",", "sz", "+", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "sz", "in", "self", ".", "filter_size", "]", "\n", "self", ".", "filter", "=", "[", "torch", ".", "exp", "(", "-", "(", "x", "**", "2", ")", "/", "(", "2", "*", "s", "**", "2", ")", ")", "for", "x", ",", "s", "in", "zip", "(", "x_coord", ",", "self", ".", "sigma", ")", "]", "\n", "self", ".", "filter", "[", "0", "]", "=", "self", ".", "filter", "[", "0", "]", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", "/", "self", ".", "filter", "[", "0", "]", ".", "sum", "(", ")", "\n", "self", ".", "filter", "[", "1", "]", "=", "self", ".", "filter", "[", "1", "]", ".", "view", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", "/", "self", ".", "filter", "[", "1", "]", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Blur.__call__": [[141, 148], ["isinstance", "torch.conv2d", "torch.conv2d", "augmentation.Blur.crop_to_output", "image.view", "torch.conv2d().view", "torch.conv2d().view", "torch.conv2d", "torch.conv2d"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Transform.crop_to_output", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["", "def", "__call__", "(", "self", ",", "image", ",", "is_mask", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "image", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "sz", "=", "image", ".", "shape", "[", "2", ":", "]", "\n", "im1", "=", "F", ".", "conv2d", "(", "image", ".", "view", "(", "-", "1", ",", "1", ",", "sz", "[", "0", "]", ",", "sz", "[", "1", "]", ")", ",", "self", ".", "filter", "[", "0", "]", ",", "padding", "=", "(", "self", ".", "filter_size", "[", "0", "]", ",", "0", ")", ")", "\n", "return", "self", ".", "crop_to_output", "(", "F", ".", "conv2d", "(", "im1", ",", "self", ".", "filter", "[", "1", "]", ",", "padding", "=", "(", "0", ",", "self", ".", "filter_size", "[", "1", "]", ")", ")", ".", "view", "(", "1", ",", "-", "1", ",", "sz", "[", "0", "]", ",", "sz", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.RandomAffine.__init__": [[152, 170], ["augmentation.Transform.__init__", "augmentation.RandomAffine.roll"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine.roll"], ["def", "__init__", "(", "self", ",", "p_flip", "=", "0.0", ",", "max_rotation", "=", "0.0", ",", "max_shear", "=", "0.0", ",", "max_scale", "=", "0.0", ",", "max_ar_factor", "=", "0.0", ",", "\n", "border_mode", "=", "'constant'", ",", "output_sz", "=", "None", ",", "shift", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "output_sz", ",", "shift", ")", "\n", "self", ".", "p_flip", "=", "p_flip", "\n", "self", ".", "max_rotation", "=", "max_rotation", "\n", "self", ".", "max_shear", "=", "max_shear", "\n", "self", ".", "max_scale", "=", "max_scale", "\n", "self", ".", "max_ar_factor", "=", "max_ar_factor", "\n", "\n", "self", ".", "pad_amount", "=", "0", "\n", "if", "border_mode", "==", "'constant'", ":", "\n", "            ", "self", ".", "border_flag", "=", "cv", ".", "BORDER_CONSTANT", "\n", "", "elif", "border_mode", "==", "'replicate'", ":", "\n", "            ", "self", ".", "border_flag", "==", "cv", ".", "BORDER_REPLICATE", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "\n", "\n", "", "self", ".", "roll_values", "=", "self", ".", "roll", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.RandomAffine.roll": [[171, 182], ["random.uniform", "random.uniform", "random.uniform", "numpy.exp", "numpy.exp", "random.random", "random.uniform", "random.uniform"], "methods", ["None"], ["", "def", "roll", "(", "self", ")", ":", "\n", "        ", "do_flip", "=", "random", ".", "random", "(", ")", "<", "self", ".", "p_flip", "\n", "theta", "=", "random", ".", "uniform", "(", "-", "self", ".", "max_rotation", ",", "self", ".", "max_rotation", ")", "\n", "\n", "shear_x", "=", "random", ".", "uniform", "(", "-", "self", ".", "max_shear", ",", "self", ".", "max_shear", ")", "\n", "shear_y", "=", "random", ".", "uniform", "(", "-", "self", ".", "max_shear", ",", "self", ".", "max_shear", ")", "\n", "\n", "ar_factor", "=", "np", ".", "exp", "(", "random", ".", "uniform", "(", "-", "self", ".", "max_ar_factor", ",", "self", ".", "max_ar_factor", ")", ")", "\n", "scale_factor", "=", "np", ".", "exp", "(", "random", ".", "uniform", "(", "-", "self", ".", "max_scale", ",", "self", ".", "max_scale", ")", ")", "\n", "\n", "return", "do_flip", ",", "theta", ",", "(", "shear_x", ",", "shear_y", ")", ",", "(", "scale_factor", ",", "scale_factor", "*", "ar_factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.RandomAffine._construct_t_mat": [[183, 211], ["numpy.identity", "cv2.getRotationMatrix2D", "numpy.concatenate", "numpy.array", "numpy.array", "numpy.array().reshape", "numpy.array"], "methods", ["None"], ["", "def", "_construct_t_mat", "(", "self", ",", "image_shape", ",", "do_flip", ",", "theta", ",", "shear_values", ",", "scale_factors", ")", ":", "\n", "        ", "im_h", ",", "im_w", "=", "image_shape", "\n", "t_mat", "=", "np", ".", "identity", "(", "3", ")", "\n", "\n", "if", "do_flip", ":", "\n", "            ", "if", "do_flip", ":", "\n", "                ", "t_mat", "[", "0", ",", "0", "]", "=", "-", "1.0", "\n", "t_mat", "[", "0", ",", "2", "]", "=", "im_w", "\n", "\n", "", "", "t_rot", "=", "cv", ".", "getRotationMatrix2D", "(", "(", "im_w", "*", "0.5", ",", "im_h", "*", "0.5", ")", ",", "theta", ",", "1.0", ")", "\n", "t_rot", "=", "np", ".", "concatenate", "(", "(", "t_rot", ",", "np", ".", "array", "(", "[", "0.0", ",", "0.0", ",", "1.0", "]", ")", ".", "reshape", "(", "1", ",", "3", ")", ")", ")", "\n", "\n", "t_shear", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "shear_values", "[", "0", "]", ",", "-", "shear_values", "[", "0", "]", "*", "0.5", "*", "im_w", "]", ",", "\n", "[", "shear_values", "[", "1", "]", ",", "1.0", ",", "-", "shear_values", "[", "1", "]", "*", "0.5", "*", "im_h", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", "\n", "\n", "t_scale", "=", "np", ".", "array", "(", "[", "[", "scale_factors", "[", "0", "]", ",", "0.0", ",", "(", "1.0", "-", "scale_factors", "[", "0", "]", ")", "*", "0.5", "*", "im_w", "]", ",", "\n", "[", "0.0", ",", "scale_factors", "[", "1", "]", ",", "(", "1.0", "-", "scale_factors", "[", "1", "]", ")", "*", "0.5", "*", "im_h", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", "\n", "\n", "t_mat", "=", "t_scale", "@", "t_rot", "@", "t_shear", "@", "t_mat", "\n", "\n", "t_mat", "[", "0", ",", "2", "]", "+=", "self", ".", "pad_amount", "\n", "t_mat", "[", "1", ",", "2", "]", "+=", "self", ".", "pad_amount", "\n", "\n", "t_mat", "=", "t_mat", "[", ":", "2", ",", ":", "]", "\n", "\n", "return", "t_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.RandomAffine.__call__": [[212, 233], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "augmentation.RandomAffine._construct_t_mat", "augmentation.RandomAffine.crop_to_output", "pytracking.features.preprocessing.torch_to_numpy", "cv2.warpAffine", "cv2.warpAffine", "pytracking.features.preprocessing.numpy_to_torch.reshape", "pytracking.features.preprocessing.numpy_to_torch"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine._construct_t_mat", "home.repos.pwc.inspect_result.visionml_pytracking.features.augmentation.Transform.crop_to_output", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.torch_to_numpy", "home.repos.pwc.inspect_result.visionml_pytracking.features.preprocessing.numpy_to_torch"], ["", "def", "__call__", "(", "self", ",", "image", ",", "is_mask", "=", "False", ")", ":", "\n", "        ", "input_tensor", "=", "torch", ".", "is_tensor", "(", "image", ")", "\n", "if", "input_tensor", ":", "\n", "            ", "image", "=", "torch_to_numpy", "(", "image", ")", "\n", "\n", "", "do_flip", ",", "theta", ",", "shear_values", ",", "scale_factors", "=", "self", ".", "roll_values", "\n", "t_mat", "=", "self", ".", "_construct_t_mat", "(", "image", ".", "shape", "[", ":", "2", "]", ",", "do_flip", ",", "theta", ",", "shear_values", ",", "scale_factors", ")", "\n", "output_sz", "=", "(", "image", ".", "shape", "[", "1", "]", "+", "2", "*", "self", ".", "pad_amount", ",", "image", ".", "shape", "[", "0", "]", "+", "2", "*", "self", ".", "pad_amount", ")", "\n", "\n", "if", "not", "is_mask", ":", "\n", "            ", "image_t", "=", "cv", ".", "warpAffine", "(", "image", ",", "t_mat", ",", "output_sz", ",", "flags", "=", "cv", ".", "INTER_LINEAR", ",", "\n", "borderMode", "=", "self", ".", "border_flag", ")", "\n", "", "else", ":", "\n", "            ", "image_t", "=", "cv", ".", "warpAffine", "(", "image", ",", "t_mat", ",", "output_sz", ",", "flags", "=", "cv", ".", "INTER_NEAREST", ",", "\n", "borderMode", "=", "self", ".", "border_flag", ")", "\n", "image_t", "=", "image_t", ".", "reshape", "(", "image", ".", "shape", ")", "\n", "\n", "", "if", "input_tensor", ":", "\n", "            ", "image_t", "=", "numpy_to_torch", "(", "image_t", ")", "\n", "\n", "", "return", "self", ".", "crop_to_output", "(", "image_t", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.text_bargraph": [[7, 22], ["numpy.array", "numpy.array", "numpy.isnan", "str.join", "len", "len"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan"], ["def", "text_bargraph", "(", "values", ")", ":", "\n", "\n", "    ", "blocks", "=", "np", ".", "array", "(", "(", "'u'", ",", "' '", ",", "'\u2581'", ",", "'\u2582'", ",", "'\u2583'", ",", "'\u2584'", ",", "'\u2585'", ",", "'\u2586'", ",", "'\u2587'", ",", "'\u2588'", ",", "'o'", ")", ")", "\n", "nsteps", "=", "len", "(", "blocks", ")", "-", "2", "-", "1", "\n", "hstep", "=", "1", "/", "(", "2", "*", "nsteps", ")", "\n", "values", "=", "np", ".", "array", "(", "values", ")", "\n", "nans", "=", "np", ".", "isnan", "(", "values", ")", "\n", "values", "[", "nans", "]", "=", "0", "# '\u2591'", "\n", "indices", "=", "(", "(", "values", "+", "hstep", ")", "*", "nsteps", "+", "1", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "indices", "[", "values", "<", "0", "]", "=", "0", "\n", "indices", "[", "values", ">", "1", "]", "=", "len", "(", "blocks", ")", "-", "1", "\n", "graph", "=", "blocks", "[", "indices", "]", "\n", "graph", "[", "nans", "]", "=", "'\u2591'", "\n", "graph", "=", "str", ".", "join", "(", "''", ",", "graph", ")", "\n", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.davis_jaccard_measure": [[34, 50], ["gt_mask.astype.astype", "fg_mask.astype.astype", "numpy.isclose", "numpy.isclose", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum"], "function", ["None"], ["", "def", "davis_jaccard_measure", "(", "fg_mask", ",", "gt_mask", ")", ":", "\n", "    ", "\"\"\" Compute region similarity as the Jaccard Index.\n\n    :param fg_mask: (ndarray): binary segmentation map.\n    :param gt_mask: (ndarray): binary annotation map.\n    :return: jaccard (float): region similarity\n    \"\"\"", "\n", "\n", "gt_mask", "=", "gt_mask", ".", "astype", "(", "np", ".", "bool", ")", "\n", "fg_mask", "=", "fg_mask", ".", "astype", "(", "np", ".", "bool", ")", "\n", "\n", "if", "np", ".", "isclose", "(", "np", ".", "sum", "(", "gt_mask", ")", ",", "0", ")", "and", "np", ".", "isclose", "(", "np", ".", "sum", "(", "fg_mask", ")", ",", "0", ")", ":", "\n", "        ", "return", "1", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "sum", "(", "(", "gt_mask", "&", "fg_mask", ")", ")", "/", "np", ".", "sum", "(", "(", "gt_mask", "|", "fg_mask", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.davis_jaccard_measure_torch": [[52, 68], ["gt_mask.sum", "fg_mask.sum"], "function", ["None"], ["", "", "def", "davis_jaccard_measure_torch", "(", "fg_mask", ",", "gt_mask", ")", ":", "\n", "    ", "\"\"\" Compute region similarity as the Jaccard Index.\n\n    :param fg_mask: (ndarray): binary segmentation map.\n    :param gt_mask: (ndarray): binary annotation map.\n    :return: jaccard (float): region similarity\n    \"\"\"", "\n", "\n", "#gt_mask = gt_mask.astype(np.bool)", "\n", "#fg_mask = fg_mask.astype(np.bool)", "\n", "\n", "if", "gt_mask", ".", "sum", "(", ")", "==", "0", "and", "fg_mask", ".", "sum", "(", ")", "==", "0", ":", "\n", "        ", "return", "1", "\n", "", "else", ":", "\n", "        ", "return", "(", "gt_mask", "&", "fg_mask", ")", ".", "sum", "(", ")", "/", "(", "gt_mask", "|", "fg_mask", ")", ".", "sum", "(", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.davis_f_measure": [[70, 126], ["vos_utils.seg2bmap", "vos_utils.seg2bmap", "skimage.morphology.binary_dilation", "skimage.morphology.binary_dilation", "numpy.sum", "numpy.sum", "numpy.ceil", "skimage.morphology.disk", "skimage.morphology.disk", "numpy.atleast_3d", "numpy.linalg.norm", "numpy.sum", "float", "numpy.sum", "float"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.seg2bmap", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.seg2bmap"], ["", "", "def", "davis_f_measure", "(", "foreground_mask", ",", "gt_mask", ",", "bound_th", "=", "0.008", ")", ":", "\n", "    ", "\"\"\"\n    Compute mean,recall and decay from per-frame evaluation.\n    Calculates precision/recall for boundaries between foreground_mask and\n    gt_mask using morphological operators to speed it up.\n\n    Arguments:\n        foreground_mask (ndarray): binary segmentation image.\n        gt_mask         (ndarray): binary annotated image.\n\n    Returns:\n        F (float): boundaries F-measure\n        P (float): boundaries precision\n        R (float): boundaries recall\n    \"\"\"", "\n", "assert", "np", ".", "atleast_3d", "(", "foreground_mask", ")", ".", "shape", "[", "2", "]", "==", "1", "\n", "\n", "bound_pix", "=", "bound_th", "if", "bound_th", ">=", "1", "else", "np", ".", "ceil", "(", "bound_th", "*", "np", ".", "linalg", ".", "norm", "(", "foreground_mask", ".", "shape", ")", ")", "\n", "\n", "# Get the pixel boundaries of both masks", "\n", "fg_boundary", "=", "seg2bmap", "(", "foreground_mask", ")", "\n", "gt_boundary", "=", "seg2bmap", "(", "gt_mask", ")", "\n", "\n", "fg_dil", "=", "binary_dilation", "(", "fg_boundary", ",", "disk", "(", "bound_pix", ")", ")", "\n", "gt_dil", "=", "binary_dilation", "(", "gt_boundary", ",", "disk", "(", "bound_pix", ")", ")", "\n", "\n", "# Get the intersection", "\n", "gt_match", "=", "gt_boundary", "*", "fg_dil", "\n", "fg_match", "=", "fg_boundary", "*", "gt_dil", "\n", "\n", "# Area of the intersection", "\n", "n_fg", "=", "np", ".", "sum", "(", "fg_boundary", ")", "\n", "n_gt", "=", "np", ".", "sum", "(", "gt_boundary", ")", "\n", "\n", "# % Compute precision and recall", "\n", "if", "n_fg", "==", "0", "and", "n_gt", ">", "0", ":", "\n", "        ", "precision", "=", "1", "\n", "recall", "=", "0", "\n", "", "elif", "n_fg", ">", "0", "and", "n_gt", "==", "0", ":", "\n", "        ", "precision", "=", "0", "\n", "recall", "=", "1", "\n", "", "elif", "n_fg", "==", "0", "and", "n_gt", "==", "0", ":", "\n", "        ", "precision", "=", "1", "\n", "recall", "=", "1", "\n", "", "else", ":", "\n", "        ", "precision", "=", "np", ".", "sum", "(", "fg_match", ")", "/", "float", "(", "n_fg", ")", "\n", "recall", "=", "np", ".", "sum", "(", "gt_match", ")", "/", "float", "(", "n_gt", ")", "\n", "\n", "# Compute F measure", "\n", "", "if", "precision", "+", "recall", "==", "0", ":", "\n", "        ", "F", "=", "0", "\n", "", "else", ":", "\n", "        ", "F", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "\n", "", "return", "F", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.seg2bmap": [[128, 187], ["seg.astype.astype", "numpy.zeros_like", "numpy.zeros_like", "numpy.zeros_like", "float", "float", "float", "float", "numpy.zeros", "range", "range", "numpy.atleast_3d", "abs", "math.floor", "math.floor"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs"], ["", "def", "seg2bmap", "(", "seg", ",", "width", "=", "None", ",", "height", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    From a segmentation, compute a binary boundary map with 1 pixel wide\n    boundaries.  The boundary pixels are offset by 1/2 pixel towards the\n    origin from the actual segment boundary.\n\n    Arguments:\n        seg     : Segments labeled from 1..k.\n        width\t  :\tWidth of desired bmap  <= seg.shape[1]\n        height  :\tHeight of desired bmap <= seg.shape[0]\n\n    Returns:\n        bmap (ndarray):\tBinary boundary map.\n\n     David Martin <dmartin@eecs.berkeley.edu>\n     January 2003\n \"\"\"", "\n", "\n", "seg", "=", "seg", ".", "astype", "(", "np", ".", "bool", ")", "\n", "seg", "[", "seg", ">", "0", "]", "=", "1", "\n", "\n", "assert", "np", ".", "atleast_3d", "(", "seg", ")", ".", "shape", "[", "2", "]", "==", "1", "\n", "\n", "width", "=", "seg", ".", "shape", "[", "1", "]", "if", "width", "is", "None", "else", "width", "\n", "height", "=", "seg", ".", "shape", "[", "0", "]", "if", "height", "is", "None", "else", "height", "\n", "\n", "h", ",", "w", "=", "seg", ".", "shape", "[", ":", "2", "]", "\n", "\n", "ar1", "=", "float", "(", "width", ")", "/", "float", "(", "height", ")", "\n", "ar2", "=", "float", "(", "w", ")", "/", "float", "(", "h", ")", "\n", "\n", "assert", "not", "(", "width", ">", "w", "|", "height", ">", "h", "|", "abs", "(", "ar1", "-", "ar2", ")", ">", "0.01", ")", ",", "'Can'", "'t convert %dx%d seg to %dx%d bmap.'", "%", "(", "w", ",", "h", ",", "width", ",", "height", ")", "\n", "\n", "e", "=", "np", ".", "zeros_like", "(", "seg", ")", "\n", "s", "=", "np", ".", "zeros_like", "(", "seg", ")", "\n", "se", "=", "np", ".", "zeros_like", "(", "seg", ")", "\n", "\n", "e", "[", ":", ",", ":", "-", "1", "]", "=", "seg", "[", ":", ",", "1", ":", "]", "\n", "s", "[", ":", "-", "1", ",", ":", "]", "=", "seg", "[", "1", ":", ",", ":", "]", "\n", "se", "[", ":", "-", "1", ",", ":", "-", "1", "]", "=", "seg", "[", "1", ":", ",", "1", ":", "]", "\n", "\n", "b", "=", "seg", "^", "e", "|", "seg", "^", "s", "|", "seg", "^", "se", "\n", "b", "[", "-", "1", ",", ":", "]", "=", "seg", "[", "-", "1", ",", ":", "]", "^", "e", "[", "-", "1", ",", ":", "]", "\n", "b", "[", ":", ",", "-", "1", "]", "=", "seg", "[", ":", ",", "-", "1", "]", "^", "s", "[", ":", ",", "-", "1", "]", "\n", "b", "[", "-", "1", ",", "-", "1", "]", "=", "0", "\n", "\n", "if", "w", "==", "width", "and", "h", "==", "height", ":", "\n", "        ", "bmap", "=", "b", "\n", "", "else", ":", "\n", "        ", "bmap", "=", "np", ".", "zeros", "(", "(", "height", ",", "width", ")", ")", "\n", "for", "x", "in", "range", "(", "w", ")", ":", "\n", "            ", "for", "y", "in", "range", "(", "h", ")", ":", "\n", "                ", "if", "b", "[", "y", ",", "x", "]", ":", "\n", "                    ", "j", "=", "1", "+", "floor", "(", "(", "y", "-", "1", ")", "+", "height", "/", "h", ")", "\n", "i", "=", "1", "+", "floor", "(", "(", "x", "-", "1", ")", "+", "width", "/", "h", ")", "\n", "bmap", "[", "j", ",", "i", "]", "=", "1", "\n", "\n", "", "", "", "", "return", "bmap", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.nanmean": [[189, 193], ["warnings.catch_warnings", "warnings.simplefilter", "numpy.nanmean"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.nanmean"], ["", "def", "nanmean", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "with", "warnings", ".", "catch_warnings", "(", ")", ":", "\n", "        ", "warnings", ".", "simplefilter", "(", "\"ignore\"", ",", "category", "=", "RuntimeWarning", ")", "\n", "return", "np", ".", "nanmean", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.mean": [[195, 200], ["numpy.nanmean"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.nanmean"], ["", "", "def", "mean", "(", "X", ")", ":", "\n", "    ", "\"\"\"\n    Compute average ignoring NaN values.\n    \"\"\"", "\n", "return", "np", ".", "nanmean", "(", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.recall": [[202, 211], ["warnings.catch_warnings", "warnings.simplefilter", "vos_utils.mean", "numpy.isnan"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan"], ["", "def", "recall", "(", "X", ",", "threshold", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"\n    Fraction of values of X scoring higher than 'threshold'\n    \"\"\"", "\n", "with", "warnings", ".", "catch_warnings", "(", ")", ":", "\n", "        ", "warnings", ".", "simplefilter", "(", "\"ignore\"", ",", "category", "=", "RuntimeWarning", ")", "\n", "x", "=", "X", "[", "~", "np", ".", "isnan", "(", "X", ")", "]", "\n", "x", "=", "mean", "(", "x", ">", "threshold", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.decay": [[213, 227], ["ids.astype.astype", "numpy.round", "warnings.catch_warnings", "warnings.simplefilter", "range", "numpy.nanmean", "numpy.nanmean", "numpy.isnan", "numpy.linspace", "len"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.nanmean", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.nanmean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan"], ["", "def", "decay", "(", "X", ",", "n_bins", "=", "4", ")", ":", "\n", "    ", "\"\"\"\n    Performance loss over time.\n    \"\"\"", "\n", "X", "=", "X", "[", "~", "np", ".", "isnan", "(", "X", ")", "]", "\n", "ids", "=", "np", ".", "round", "(", "np", ".", "linspace", "(", "1", ",", "len", "(", "X", ")", ",", "n_bins", "+", "1", ")", "+", "1e-10", ")", "-", "1", "\n", "ids", "=", "ids", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "D_bins", "=", "[", "X", "[", "ids", "[", "i", "]", ":", "ids", "[", "i", "+", "1", "]", "+", "1", "]", "for", "i", "in", "range", "(", "0", ",", "4", ")", "]", "\n", "\n", "with", "warnings", ".", "catch_warnings", "(", ")", ":", "\n", "        ", "warnings", ".", "simplefilter", "(", "\"ignore\"", ",", "category", "=", "RuntimeWarning", ")", "\n", "D", "=", "np", ".", "nanmean", "(", "D_bins", "[", "0", "]", ")", "-", "np", ".", "nanmean", "(", "D_bins", "[", "3", "]", ")", "\n", "", "return", "D", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.std": [[229, 234], ["numpy.nanstd"], "function", ["None"], ["", "def", "std", "(", "X", ")", ":", "\n", "    ", "\"\"\"\n    Compute standard deviation.\n    \"\"\"", "\n", "return", "np", ".", "nanstd", "(", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_plot_draw_styles": [[12, 32], ["None"], "function", ["None"], ["def", "get_plot_draw_styles", "(", ")", ":", "\n", "    ", "plot_draw_style", "=", "[", "{", "'color'", ":", "(", "1.0", ",", "0.0", ",", "0.0", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "0.0", ",", "1.0", ",", "0.0", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "0.0", ",", "0.0", ",", "1.0", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "0.0", ",", "0.0", ",", "0.0", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "1.0", ",", "0.0", ",", "1.0", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "0.0", ",", "1.0", ",", "1.0", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "136.0", "/", "255.0", ",", "0.0", ",", "21.0", "/", "255.0", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "1.0", ",", "127.0", "/", "255.0", ",", "39.0", "/", "255.0", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "0.0", ",", "162.0", "/", "255.0", ",", "232.0", "/", "255.0", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "0.0", ",", "0.5", ",", "0.0", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "1.0", ",", "0.5", ",", "0.2", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "0.1", ",", "0.4", ",", "0.0", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "0.6", ",", "0.3", ",", "0.9", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "0.4", ",", "0.7", ",", "0.1", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "0.2", ",", "0.1", ",", "0.7", ")", ",", "'line_style'", ":", "'-'", "}", ",", "\n", "{", "'color'", ":", "(", "0.7", ",", "0.6", ",", "0.2", ")", ",", "'line_style'", ":", "'-'", "}", "]", "\n", "\n", "return", "plot_draw_style", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.check_eval_data_is_valid": [[34, 43], ["None"], "function", ["None"], ["", "def", "check_eval_data_is_valid", "(", "eval_data", ",", "trackers", ",", "dataset", ")", ":", "\n", "    ", "\"\"\" Checks if the pre-computed results are valid\"\"\"", "\n", "seq_names", "=", "[", "s", ".", "name", "for", "s", "in", "dataset", "]", "\n", "seq_names_saved", "=", "eval_data", "[", "'sequences'", "]", "\n", "\n", "tracker_names_f", "=", "[", "(", "t", ".", "name", ",", "t", ".", "parameter_name", ",", "t", ".", "run_id", ")", "for", "t", "in", "trackers", "]", "\n", "tracker_names_f_saved", "=", "[", "(", "t", "[", "'name'", "]", ",", "t", "[", "'param'", "]", ",", "t", "[", "'run_id'", "]", ")", "for", "t", "in", "eval_data", "[", "'trackers'", "]", "]", "\n", "\n", "return", "seq_names", "==", "seq_names_saved", "and", "tracker_names_f", "==", "tracker_names_f_saved", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.merge_multiple_runs": [[45, 87], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack.tolist", "torch.stack.tolist", "torch.stack.tolist", "torch.stack.tolist", "len", "len", "new_tracker_names.append", "torch.tensor", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "ave_success_rate_plot_overlap[].mean", "ave_success_rate_plot_center[].mean", "ave_success_rate_plot_center_norm[].mean", "avg_overlap_all[].mean"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "merge_multiple_runs", "(", "eval_data", ")", ":", "\n", "    ", "new_tracker_names", "=", "[", "]", "\n", "ave_success_rate_plot_overlap_merged", "=", "[", "]", "\n", "ave_success_rate_plot_center_merged", "=", "[", "]", "\n", "ave_success_rate_plot_center_norm_merged", "=", "[", "]", "\n", "avg_overlap_all_merged", "=", "[", "]", "\n", "\n", "ave_success_rate_plot_overlap", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'ave_success_rate_plot_overlap'", "]", ")", "\n", "ave_success_rate_plot_center", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'ave_success_rate_plot_center'", "]", ")", "\n", "ave_success_rate_plot_center_norm", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'ave_success_rate_plot_center_norm'", "]", ")", "\n", "avg_overlap_all", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'avg_overlap_all'", "]", ")", "\n", "\n", "trackers", "=", "eval_data", "[", "'trackers'", "]", "\n", "merged", "=", "torch", ".", "zeros", "(", "len", "(", "trackers", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "trackers", ")", ")", ":", "\n", "        ", "if", "merged", "[", "i", "]", ":", "\n", "            ", "continue", "\n", "", "base_tracker", "=", "trackers", "[", "i", "]", "\n", "new_tracker_names", ".", "append", "(", "base_tracker", ")", "\n", "\n", "match", "=", "[", "t", "[", "'name'", "]", "==", "base_tracker", "[", "'name'", "]", "and", "t", "[", "'param'", "]", "==", "base_tracker", "[", "'param'", "]", "for", "t", "in", "trackers", "]", "\n", "match", "=", "torch", ".", "tensor", "(", "match", ")", "\n", "\n", "ave_success_rate_plot_overlap_merged", ".", "append", "(", "ave_success_rate_plot_overlap", "[", ":", ",", "match", ",", ":", "]", ".", "mean", "(", "1", ")", ")", "\n", "ave_success_rate_plot_center_merged", ".", "append", "(", "ave_success_rate_plot_center", "[", ":", ",", "match", ",", ":", "]", ".", "mean", "(", "1", ")", ")", "\n", "ave_success_rate_plot_center_norm_merged", ".", "append", "(", "ave_success_rate_plot_center_norm", "[", ":", ",", "match", ",", ":", "]", ".", "mean", "(", "1", ")", ")", "\n", "avg_overlap_all_merged", ".", "append", "(", "avg_overlap_all", "[", ":", ",", "match", "]", ".", "mean", "(", "1", ")", ")", "\n", "\n", "merged", "[", "match", "]", "=", "1", "\n", "\n", "", "ave_success_rate_plot_overlap_merged", "=", "torch", ".", "stack", "(", "ave_success_rate_plot_overlap_merged", ",", "dim", "=", "1", ")", "\n", "ave_success_rate_plot_center_merged", "=", "torch", ".", "stack", "(", "ave_success_rate_plot_center_merged", ",", "dim", "=", "1", ")", "\n", "ave_success_rate_plot_center_norm_merged", "=", "torch", ".", "stack", "(", "ave_success_rate_plot_center_norm_merged", ",", "dim", "=", "1", ")", "\n", "avg_overlap_all_merged", "=", "torch", ".", "stack", "(", "avg_overlap_all_merged", ",", "dim", "=", "1", ")", "\n", "\n", "eval_data", "[", "'trackers'", "]", "=", "new_tracker_names", "\n", "eval_data", "[", "'ave_success_rate_plot_overlap'", "]", "=", "ave_success_rate_plot_overlap_merged", ".", "tolist", "(", ")", "\n", "eval_data", "[", "'ave_success_rate_plot_center'", "]", "=", "ave_success_rate_plot_center_merged", ".", "tolist", "(", ")", "\n", "eval_data", "[", "'ave_success_rate_plot_center_norm'", "]", "=", "ave_success_rate_plot_center_norm_merged", ".", "tolist", "(", ")", "\n", "eval_data", "[", "'avg_overlap_all'", "]", "=", "avg_overlap_all_merged", ".", "tolist", "(", ")", "\n", "\n", "return", "eval_data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_tracker_display_name": [[89, 100], ["None"], "function", ["None"], ["", "def", "get_tracker_display_name", "(", "tracker", ")", ":", "\n", "    ", "if", "tracker", "[", "'disp_name'", "]", "is", "None", ":", "\n", "        ", "if", "tracker", "[", "'run_id'", "]", "is", "None", ":", "\n", "            ", "disp_name", "=", "'{}_{}'", ".", "format", "(", "tracker", "[", "'name'", "]", ",", "tracker", "[", "'param'", "]", ")", "\n", "", "else", ":", "\n", "            ", "disp_name", "=", "'{}_{}_{:03d}'", ".", "format", "(", "tracker", "[", "'name'", "]", ",", "tracker", "[", "'param'", "]", ",", "\n", "tracker", "[", "'run_id'", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "disp_name", "=", "tracker", "[", "'disp_name'", "]", "\n", "\n", "", "return", "disp_name", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.plot_draw_save": [[102, 158], ["plot_opts.get", "plot_opts.get", "plot_opts.get", "plot_opts.get", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.subplots", "scores.argsort", "enumerate", "ax.legend", "ax.set", "ax.grid", "fig.tight_layout", "tikzplotlib.save", "fig.savefig", "matplotlib.draw", "ax.plot", "plotted_lines.append", "plot_results.get_tracker_display_name", "legend_text.append", "x.tolist", "y[].tolist", "scores.argsort.numel", "scores.argsort.numel"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.save", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_tracker_display_name"], ["", "def", "plot_draw_save", "(", "y", ",", "x", ",", "scores", ",", "trackers", ",", "plot_draw_styles", ",", "result_plot_path", ",", "plot_opts", ")", ":", "\n", "# Plot settings", "\n", "    ", "font_size", "=", "plot_opts", ".", "get", "(", "'font_size'", ",", "12", ")", "\n", "font_size_axis", "=", "plot_opts", ".", "get", "(", "'font_size_axis'", ",", "13", ")", "\n", "line_width", "=", "plot_opts", ".", "get", "(", "'line_width'", ",", "2", ")", "\n", "font_size_legend", "=", "plot_opts", ".", "get", "(", "'font_size_legend'", ",", "13", ")", "\n", "\n", "plot_type", "=", "plot_opts", "[", "'plot_type'", "]", "\n", "legend_loc", "=", "plot_opts", "[", "'legend_loc'", "]", "\n", "\n", "xlabel", "=", "plot_opts", "[", "'xlabel'", "]", "\n", "ylabel", "=", "plot_opts", "[", "'ylabel'", "]", "\n", "xlim", "=", "plot_opts", "[", "'xlim'", "]", "\n", "ylim", "=", "plot_opts", "[", "'ylim'", "]", "\n", "\n", "title", "=", "plot_opts", "[", "'title'", "]", "\n", "\n", "matplotlib", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "font_size", "}", ")", "\n", "matplotlib", ".", "rcParams", ".", "update", "(", "{", "'axes.titlesize'", ":", "font_size_axis", "}", ")", "\n", "matplotlib", ".", "rcParams", ".", "update", "(", "{", "'axes.titleweight'", ":", "'black'", "}", ")", "\n", "matplotlib", ".", "rcParams", ".", "update", "(", "{", "'axes.labelsize'", ":", "font_size_axis", "}", ")", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "\n", "index_sort", "=", "scores", ".", "argsort", "(", "descending", "=", "False", ")", "\n", "\n", "plotted_lines", "=", "[", "]", "\n", "legend_text", "=", "[", "]", "\n", "\n", "for", "id", ",", "id_sort", "in", "enumerate", "(", "index_sort", ")", ":", "\n", "        ", "line", "=", "ax", ".", "plot", "(", "x", ".", "tolist", "(", ")", ",", "y", "[", "id_sort", ",", ":", "]", ".", "tolist", "(", ")", ",", "\n", "linewidth", "=", "line_width", ",", "\n", "color", "=", "plot_draw_styles", "[", "index_sort", ".", "numel", "(", ")", "-", "id", "-", "1", "]", "[", "'color'", "]", ",", "\n", "linestyle", "=", "plot_draw_styles", "[", "index_sort", ".", "numel", "(", ")", "-", "id", "-", "1", "]", "[", "'line_style'", "]", ")", "\n", "\n", "plotted_lines", ".", "append", "(", "line", "[", "0", "]", ")", "\n", "\n", "tracker", "=", "trackers", "[", "id_sort", "]", "\n", "disp_name", "=", "get_tracker_display_name", "(", "tracker", ")", "\n", "\n", "legend_text", ".", "append", "(", "'{} [{:.1f}]'", ".", "format", "(", "disp_name", ",", "scores", "[", "id_sort", "]", ")", ")", "\n", "\n", "", "ax", ".", "legend", "(", "plotted_lines", "[", ":", ":", "-", "1", "]", ",", "legend_text", "[", ":", ":", "-", "1", "]", ",", "loc", "=", "legend_loc", ",", "fancybox", "=", "False", ",", "edgecolor", "=", "'black'", ",", "\n", "fontsize", "=", "font_size_legend", ",", "framealpha", "=", "1.0", ")", "\n", "\n", "ax", ".", "set", "(", "xlabel", "=", "xlabel", ",", "\n", "ylabel", "=", "ylabel", ",", "\n", "xlim", "=", "xlim", ",", "ylim", "=", "ylim", ",", "\n", "title", "=", "title", ")", "\n", "\n", "ax", ".", "grid", "(", "True", ",", "linestyle", "=", "'-.'", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "\n", "tikzplotlib", ".", "save", "(", "'{}/{}_plot.tex'", ".", "format", "(", "result_plot_path", ",", "plot_type", ")", ")", "\n", "fig", ".", "savefig", "(", "'{}/{}_plot.pdf'", ".", "format", "(", "result_plot_path", ",", "plot_type", ")", ",", "dpi", "=", "300", ",", "format", "=", "'pdf'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "draw", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.check_and_load_precomputed_results": [[160, 185], ["pytracking.evaluation.environment.env_settings", "os.path.join", "os.path.join", "os.path.isfile", "pytracking.analysis.extract_results.extract_results", "plot_results.check_eval_data_is_valid", "pytracking.analysis.extract_results.extract_results", "open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.extract_results.extract_results", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.check_eval_data_is_valid", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.extract_results.extract_results", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load"], ["", "def", "check_and_load_precomputed_results", "(", "trackers", ",", "dataset", ",", "report_name", ",", "force_evaluation", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "# Load data", "\n", "    ", "settings", "=", "env_settings", "(", ")", "\n", "\n", "# Load pre-computed results", "\n", "result_plot_path", "=", "os", ".", "path", ".", "join", "(", "settings", ".", "result_plot_path", ",", "report_name", ")", "\n", "eval_data_path", "=", "os", ".", "path", ".", "join", "(", "result_plot_path", ",", "'eval_data.pkl'", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "eval_data_path", ")", "and", "not", "force_evaluation", ":", "\n", "        ", "with", "open", "(", "eval_data_path", ",", "'rb'", ")", "as", "fh", ":", "\n", "            ", "eval_data", "=", "pickle", ".", "load", "(", "fh", ")", "\n", "", "", "else", ":", "\n", "# print('Pre-computed evaluation data not found. Computing results!')", "\n", "        ", "eval_data", "=", "extract_results", "(", "trackers", ",", "dataset", ",", "report_name", ",", "**", "kwargs", ")", "\n", "\n", "", "if", "not", "check_eval_data_is_valid", "(", "eval_data", ",", "trackers", ",", "dataset", ")", ":", "\n", "# print('Pre-computed evaluation data invalid. Re-computing results!')", "\n", "        ", "eval_data", "=", "extract_results", "(", "trackers", ",", "dataset", ",", "report_name", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "# Update display names", "\n", "        ", "tracker_names", "=", "[", "{", "'name'", ":", "t", ".", "name", ",", "'param'", ":", "t", ".", "parameter_name", ",", "'run_id'", ":", "t", ".", "run_id", ",", "'disp_name'", ":", "t", ".", "display_name", "}", "\n", "for", "t", "in", "trackers", "]", "\n", "eval_data", "[", "'trackers'", "]", "=", "tracker_names", "\n", "\n", "", "return", "eval_data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_auc_curve": [[187, 193], ["auc_curve.mean", "ave_success_rate_plot_overlap.mean"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "get_auc_curve", "(", "ave_success_rate_plot_overlap", ",", "valid_sequence", ")", ":", "\n", "    ", "ave_success_rate_plot_overlap", "=", "ave_success_rate_plot_overlap", "[", "valid_sequence", ",", ":", ",", ":", "]", "\n", "auc_curve", "=", "ave_success_rate_plot_overlap", ".", "mean", "(", "0", ")", "*", "100.0", "\n", "auc", "=", "auc_curve", ".", "mean", "(", "-", "1", ")", "\n", "\n", "return", "auc_curve", ",", "auc", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_prec_curve": [[195, 201], ["ave_success_rate_plot_center.mean"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "get_prec_curve", "(", "ave_success_rate_plot_center", ",", "valid_sequence", ")", ":", "\n", "    ", "ave_success_rate_plot_center", "=", "ave_success_rate_plot_center", "[", "valid_sequence", ",", ":", ",", ":", "]", "\n", "prec_curve", "=", "ave_success_rate_plot_center", ".", "mean", "(", "0", ")", "*", "100.0", "\n", "prec_score", "=", "prec_curve", "[", ":", ",", "20", "]", "\n", "\n", "return", "prec_curve", ",", "prec_score", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.plot_results": [[203, 278], ["pytracking.evaluation.environment.env_settings", "plot_results.get_plot_draw_styles", "os.path.join", "plot_results.check_and_load_precomputed_results", "torch.tensor", "print", "print", "matplotlib.show", "plot_results.merge_multiple_runs", "torch.tensor", "plot_results.get_auc_curve", "torch.tensor", "plot_results.plot_draw_save", "torch.tensor", "plot_results.get_prec_curve", "torch.tensor", "plot_results.plot_draw_save", "torch.tensor", "plot_results.get_prec_curve", "torch.tensor", "plot_results.plot_draw_save", "torch.tensor.long().sum().item", "torch.tensor.long().sum", "torch.tensor.long"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_plot_draw_styles", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.check_and_load_precomputed_results", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display.show", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.merge_multiple_runs", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_auc_curve", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.plot_draw_save", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_prec_curve", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.plot_draw_save", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_prec_curve", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.plot_draw_save"], ["", "def", "plot_results", "(", "trackers", ",", "dataset", ",", "report_name", ",", "merge_results", "=", "False", ",", "\n", "plot_types", "=", "(", "'success'", ")", ",", "force_evaluation", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Plot results for the given trackers\n\n    args:\n        trackers - List of trackers to evaluate\n        dataset - List of sequences to evaluate\n        report_name - Name of the folder in env_settings.perm_mat_path where the computed results and plots are saved\n        merge_results - If True, multiple random runs for a non-deterministic trackers are averaged\n        plot_types - List of scores to display. Can contain 'success',\n                    'prec' (precision), and 'norm_prec' (normalized precision)\n    \"\"\"", "\n", "# Load data", "\n", "settings", "=", "env_settings", "(", ")", "\n", "\n", "plot_draw_styles", "=", "get_plot_draw_styles", "(", ")", "\n", "\n", "# Load pre-computed results", "\n", "result_plot_path", "=", "os", ".", "path", ".", "join", "(", "settings", ".", "result_plot_path", ",", "report_name", ")", "\n", "eval_data", "=", "check_and_load_precomputed_results", "(", "trackers", ",", "dataset", ",", "report_name", ",", "force_evaluation", ",", "**", "kwargs", ")", "\n", "\n", "# Merge results from multiple runs", "\n", "if", "merge_results", ":", "\n", "        ", "eval_data", "=", "merge_multiple_runs", "(", "eval_data", ")", "\n", "\n", "", "tracker_names", "=", "eval_data", "[", "'trackers'", "]", "\n", "\n", "valid_sequence", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'valid_sequence'", "]", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "\n", "print", "(", "'\\nPlotting results over {} / {} sequences'", ".", "format", "(", "valid_sequence", ".", "long", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "valid_sequence", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "print", "(", "'\\nGenerating plots for: {}'", ".", "format", "(", "report_name", ")", ")", "\n", "\n", "# ********************************  Success Plot **************************************", "\n", "if", "'success'", "in", "plot_types", ":", "\n", "        ", "ave_success_rate_plot_overlap", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'ave_success_rate_plot_overlap'", "]", ")", "\n", "\n", "# Index out valid sequences", "\n", "auc_curve", ",", "auc", "=", "get_auc_curve", "(", "ave_success_rate_plot_overlap", ",", "valid_sequence", ")", "\n", "threshold_set_overlap", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'threshold_set_overlap'", "]", ")", "\n", "\n", "success_plot_opts", "=", "{", "'plot_type'", ":", "'success'", ",", "'legend_loc'", ":", "'lower left'", ",", "'xlabel'", ":", "'Overlap threshold'", ",", "\n", "'ylabel'", ":", "'Overlap Precision [%]'", ",", "'xlim'", ":", "(", "0", ",", "1.0", ")", ",", "'ylim'", ":", "(", "0", ",", "100", ")", ",", "'title'", ":", "'Success plot'", "}", "\n", "plot_draw_save", "(", "auc_curve", ",", "threshold_set_overlap", ",", "auc", ",", "tracker_names", ",", "plot_draw_styles", ",", "result_plot_path", ",", "success_plot_opts", ")", "\n", "\n", "# ********************************  Precision Plot **************************************", "\n", "", "if", "'prec'", "in", "plot_types", ":", "\n", "        ", "ave_success_rate_plot_center", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'ave_success_rate_plot_center'", "]", ")", "\n", "\n", "# Index out valid sequences", "\n", "prec_curve", ",", "prec_score", "=", "get_prec_curve", "(", "ave_success_rate_plot_center", ",", "valid_sequence", ")", "\n", "threshold_set_center", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'threshold_set_center'", "]", ")", "\n", "\n", "precision_plot_opts", "=", "{", "'plot_type'", ":", "'precision'", ",", "'legend_loc'", ":", "'lower right'", ",", "\n", "'xlabel'", ":", "'Location error threshold [pixels]'", ",", "'ylabel'", ":", "'Distance Precision [%]'", ",", "\n", "'xlim'", ":", "(", "0", ",", "50", ")", ",", "'ylim'", ":", "(", "0", ",", "100", ")", ",", "'title'", ":", "'Precision plot'", "}", "\n", "plot_draw_save", "(", "prec_curve", ",", "threshold_set_center", ",", "prec_score", ",", "tracker_names", ",", "plot_draw_styles", ",", "result_plot_path", ",", "\n", "precision_plot_opts", ")", "\n", "\n", "# ********************************  Norm Precision Plot **************************************", "\n", "", "if", "'norm_prec'", "in", "plot_types", ":", "\n", "        ", "ave_success_rate_plot_center_norm", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'ave_success_rate_plot_center_norm'", "]", ")", "\n", "\n", "# Index out valid sequences", "\n", "prec_curve", ",", "prec_score", "=", "get_prec_curve", "(", "ave_success_rate_plot_center_norm", ",", "valid_sequence", ")", "\n", "threshold_set_center_norm", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'threshold_set_center_norm'", "]", ")", "\n", "\n", "norm_precision_plot_opts", "=", "{", "'plot_type'", ":", "'norm_precision'", ",", "'legend_loc'", ":", "'lower right'", ",", "\n", "'xlabel'", ":", "'Location error threshold'", ",", "'ylabel'", ":", "'Distance Precision [%]'", ",", "\n", "'xlim'", ":", "(", "0", ",", "0.5", ")", ",", "'ylim'", ":", "(", "0", ",", "100", ")", ",", "'title'", ":", "'Normalized Precision plot'", "}", "\n", "plot_draw_save", "(", "prec_curve", ",", "threshold_set_center_norm", ",", "prec_score", ",", "tracker_names", ",", "plot_draw_styles", ",", "result_plot_path", ",", "\n", "norm_precision_plot_opts", ")", "\n", "\n", "", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.generate_formatted_report": [[280, 304], ["zip", "enumerate", "max", "max", "scores.keys", "zip", "scores.keys", "scores.items", "len", "len", "len", "score_value[].item"], "function", ["None"], ["", "def", "generate_formatted_report", "(", "row_labels", ",", "scores", ",", "table_name", "=", "''", ")", ":", "\n", "    ", "name_width", "=", "max", "(", "[", "len", "(", "d", ")", "for", "d", "in", "row_labels", "]", "+", "[", "len", "(", "table_name", ")", "]", ")", "+", "5", "\n", "min_score_width", "=", "10", "\n", "\n", "report_text", "=", "'\\n{label: <{width}} |'", ".", "format", "(", "label", "=", "table_name", ",", "width", "=", "name_width", ")", "\n", "\n", "score_widths", "=", "[", "max", "(", "min_score_width", ",", "len", "(", "k", ")", "+", "3", ")", "for", "k", "in", "scores", ".", "keys", "(", ")", "]", "\n", "\n", "for", "s", ",", "s_w", "in", "zip", "(", "scores", ".", "keys", "(", ")", ",", "score_widths", ")", ":", "\n", "        ", "report_text", "=", "'{prev} {s: <{width}} |'", ".", "format", "(", "prev", "=", "report_text", ",", "s", "=", "s", ",", "width", "=", "s_w", ")", "\n", "\n", "", "report_text", "=", "'{prev}\\n'", ".", "format", "(", "prev", "=", "report_text", ")", "\n", "\n", "for", "trk_id", ",", "d_name", "in", "enumerate", "(", "row_labels", ")", ":", "\n", "# display name", "\n", "        ", "report_text", "=", "'{prev}{tracker: <{width}} |'", ".", "format", "(", "prev", "=", "report_text", ",", "tracker", "=", "d_name", ",", "\n", "width", "=", "name_width", ")", "\n", "for", "(", "score_type", ",", "score_value", ")", ",", "s_w", "in", "zip", "(", "scores", ".", "items", "(", ")", ",", "score_widths", ")", ":", "\n", "            ", "report_text", "=", "'{prev} {score: <{width}} |'", ".", "format", "(", "prev", "=", "report_text", ",", "\n", "score", "=", "'{:0.2f}'", ".", "format", "(", "score_value", "[", "trk_id", "]", ".", "item", "(", ")", ")", ",", "\n", "width", "=", "s_w", ")", "\n", "", "report_text", "=", "'{prev}\\n'", ".", "format", "(", "prev", "=", "report_text", ")", "\n", "\n", "", "return", "report_text", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.print_results": [[306, 362], ["plot_results.check_and_load_precomputed_results", "torch.tensor", "print", "plot_results.generate_formatted_report", "print", "plot_results.merge_multiple_runs", "torch.tensor", "torch.tensor", "plot_results.get_auc_curve", "torch.tensor", "plot_results.get_prec_curve", "torch.tensor", "plot_results.get_prec_curve", "plot_results.get_tracker_display_name", "torch.tensor.long().sum().item", "torch.tensor.long().sum", "torch.tensor.long"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.check_and_load_precomputed_results", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.generate_formatted_report", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.merge_multiple_runs", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_auc_curve", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_prec_curve", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_prec_curve", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_tracker_display_name"], ["", "def", "print_results", "(", "trackers", ",", "dataset", ",", "report_name", ",", "merge_results", "=", "False", ",", "\n", "plot_types", "=", "(", "'success'", ")", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Print the results for the given trackers in a formatted table\n    args:\n        trackers - List of trackers to evaluate\n        dataset - List of sequences to evaluate\n        report_name - Name of the folder in env_settings.perm_mat_path where the computed results and plots are saved\n        merge_results - If True, multiple random runs for a non-deterministic trackers are averaged\n        plot_types - List of scores to display. Can contain 'success' (prints AUC, OP50, and OP75 scores),\n                    'prec' (prints precision score), and 'norm_prec' (prints normalized precision score)\n    \"\"\"", "\n", "# Load pre-computed results", "\n", "eval_data", "=", "check_and_load_precomputed_results", "(", "trackers", ",", "dataset", ",", "report_name", ",", "**", "kwargs", ")", "\n", "\n", "# Merge results from multiple runs", "\n", "if", "merge_results", ":", "\n", "        ", "eval_data", "=", "merge_multiple_runs", "(", "eval_data", ")", "\n", "\n", "", "tracker_names", "=", "eval_data", "[", "'trackers'", "]", "\n", "valid_sequence", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'valid_sequence'", "]", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "\n", "print", "(", "'\\nReporting results over {} / {} sequences'", ".", "format", "(", "valid_sequence", ".", "long", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "valid_sequence", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "scores", "=", "{", "}", "\n", "\n", "# ********************************  Success Plot **************************************", "\n", "if", "'success'", "in", "plot_types", ":", "\n", "        ", "threshold_set_overlap", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'threshold_set_overlap'", "]", ")", "\n", "ave_success_rate_plot_overlap", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'ave_success_rate_plot_overlap'", "]", ")", "\n", "\n", "# Index out valid sequences", "\n", "auc_curve", ",", "auc", "=", "get_auc_curve", "(", "ave_success_rate_plot_overlap", ",", "valid_sequence", ")", "\n", "scores", "[", "'AUC'", "]", "=", "auc", "\n", "scores", "[", "'OP50'", "]", "=", "auc_curve", "[", ":", ",", "threshold_set_overlap", "==", "0.50", "]", "\n", "scores", "[", "'OP75'", "]", "=", "auc_curve", "[", ":", ",", "threshold_set_overlap", "==", "0.75", "]", "\n", "\n", "# ********************************  Precision Plot **************************************", "\n", "", "if", "'prec'", "in", "plot_types", ":", "\n", "        ", "ave_success_rate_plot_center", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'ave_success_rate_plot_center'", "]", ")", "\n", "\n", "# Index out valid sequences", "\n", "prec_curve", ",", "prec_score", "=", "get_prec_curve", "(", "ave_success_rate_plot_center", ",", "valid_sequence", ")", "\n", "scores", "[", "'Precision'", "]", "=", "prec_score", "\n", "\n", "# ********************************  Norm Precision Plot *********************************", "\n", "", "if", "'norm_prec'", "in", "plot_types", ":", "\n", "        ", "ave_success_rate_plot_center_norm", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'ave_success_rate_plot_center_norm'", "]", ")", "\n", "\n", "# Index out valid sequences", "\n", "norm_prec_curve", ",", "norm_prec_score", "=", "get_prec_curve", "(", "ave_success_rate_plot_center_norm", ",", "valid_sequence", ")", "\n", "scores", "[", "'Norm Precision'", "]", "=", "norm_prec_score", "\n", "\n", "# Print", "\n", "", "tracker_disp_names", "=", "[", "get_tracker_display_name", "(", "trk", ")", "for", "trk", "in", "tracker_names", "]", "\n", "report_text", "=", "generate_formatted_report", "(", "tracker_disp_names", ",", "scores", ",", "table_name", "=", "report_name", ")", "\n", "print", "(", "report_text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.plot_got_success": [[364, 423], ["pytracking.evaluation.environment.env_settings", "plot_results.get_plot_draw_styles", "os.path.join", "torch.zeros", "torch.zeros", "enumerate", "torch.arange", "plot_results.plot_draw_save", "matplotlib.show", "len", "os.path.isfile", "tracker_names.append", "len", "Exception", "len", "json.load.keys", "torch.tensor", "open", "json.load", "json.load.keys", "Exception", "list", "json.load.keys", "eval_data[].keys", "json.load.keys"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_plot_draw_styles", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.plot_draw_save", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display.show", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "plot_got_success", "(", "trackers", ",", "report_name", ")", ":", "\n", "    ", "\"\"\" Plot success plot for GOT-10k dataset using the json reports.\n    Save the json reports from http://got-10k.aitestunion.com/leaderboard in the directory set to\n    env_settings.got_reports_path\n\n    The tracker name in the experiment file should be set to the name of the report file for that tracker,\n    e.g. DiMP50_report_2019_09_02_15_44_25 if the report is name DiMP50_report_2019_09_02_15_44_25.json\n\n    args:\n        trackers - List of trackers to evaluate\n        report_name - Name of the folder in env_settings.perm_mat_path where the computed results and plots are saved\n    \"\"\"", "\n", "# Load data", "\n", "settings", "=", "env_settings", "(", ")", "\n", "plot_draw_styles", "=", "get_plot_draw_styles", "(", ")", "\n", "\n", "result_plot_path", "=", "os", ".", "path", ".", "join", "(", "settings", ".", "result_plot_path", ",", "report_name", ")", "\n", "\n", "auc_curve", "=", "torch", ".", "zeros", "(", "(", "len", "(", "trackers", ")", ",", "101", ")", ")", "\n", "scores", "=", "torch", ".", "zeros", "(", "len", "(", "trackers", ")", ")", "\n", "\n", "# Load results", "\n", "tracker_names", "=", "[", "]", "\n", "for", "trk_id", ",", "trk", "in", "enumerate", "(", "trackers", ")", ":", "\n", "        ", "json_path", "=", "'{}/{}.json'", ".", "format", "(", "settings", ".", "got_reports_path", ",", "trk", ".", "name", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "json_path", ")", ":", "\n", "            ", "with", "open", "(", "json_path", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "eval_data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Report not found {}'", ".", "format", "(", "json_path", ")", ")", "\n", "\n", "", "if", "len", "(", "eval_data", ".", "keys", "(", ")", ")", ">", "1", ":", "\n", "            ", "raise", "Exception", "\n", "\n", "# First field is the tracker name. Index it out", "\n", "", "eval_data", "=", "eval_data", "[", "list", "(", "eval_data", ".", "keys", "(", ")", ")", "[", "0", "]", "]", "\n", "if", "'succ_curve'", "in", "eval_data", ".", "keys", "(", ")", ":", "\n", "            ", "curve", "=", "eval_data", "[", "'succ_curve'", "]", "\n", "ao", "=", "eval_data", "[", "'ao'", "]", "\n", "", "elif", "'overall'", "in", "eval_data", ".", "keys", "(", ")", "and", "'succ_curve'", "in", "eval_data", "[", "'overall'", "]", ".", "keys", "(", ")", ":", "\n", "            ", "curve", "=", "eval_data", "[", "'overall'", "]", "[", "'succ_curve'", "]", "\n", "ao", "=", "eval_data", "[", "'overall'", "]", "[", "'ao'", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Invalid JSON file {}'", ".", "format", "(", "json_path", ")", ")", "\n", "\n", "", "auc_curve", "[", "trk_id", ",", ":", "]", "=", "torch", ".", "tensor", "(", "curve", ")", "*", "100.0", "\n", "scores", "[", "trk_id", "]", "=", "ao", "*", "100.0", "\n", "\n", "tracker_names", ".", "append", "(", "{", "'name'", ":", "trk", ".", "name", ",", "'param'", ":", "trk", ".", "parameter_name", ",", "'run_id'", ":", "trk", ".", "run_id", ",", "\n", "'disp_name'", ":", "trk", ".", "display_name", "}", ")", "\n", "\n", "", "threshold_set_overlap", "=", "torch", ".", "arange", "(", "0.0", ",", "1.01", ",", "0.01", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "\n", "success_plot_opts", "=", "{", "'plot_type'", ":", "'success'", ",", "'legend_loc'", ":", "'lower left'", ",", "'xlabel'", ":", "'Overlap threshold'", ",", "\n", "'ylabel'", ":", "'Overlap Precision [%]'", ",", "'xlim'", ":", "(", "0", ",", "1.0", ")", ",", "'ylim'", ":", "(", "0", ",", "100", ")", ",", "'title'", ":", "'Success plot'", "}", "\n", "plot_draw_save", "(", "auc_curve", ",", "threshold_set_overlap", ",", "scores", ",", "tracker_names", ",", "plot_draw_styles", ",", "result_plot_path", ",", "\n", "success_plot_opts", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.print_per_sequence_results": [[425, 484], ["plot_results.check_and_load_precomputed_results", "torch.tensor", "plot_results.generate_formatted_report", "print", "plot_results.merge_multiple_runs", "torch.tensor", "plot_results.get_tracker_display_name", "enumerate", "enumerate", "avg_overlap_all.min", "zip", "avg_overlap_all.max", "torch.tensor.tolist", "avg_overlap_all.min", "avg_overlap_all.max"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.check_and_load_precomputed_results", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.generate_formatted_report", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.merge_multiple_runs", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_tracker_display_name"], ["", "def", "print_per_sequence_results", "(", "trackers", ",", "dataset", ",", "report_name", ",", "merge_results", "=", "False", ",", "\n", "filter_criteria", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\" Print per-sequence results for the given trackers. Additionally, the sequences to list can be filtered using\n    the filter criteria.\n\n    args:\n        trackers - List of trackers to evaluate\n        dataset - List of sequences to evaluate\n        report_name - Name of the folder in env_settings.perm_mat_path where the computed results and plots are saved\n        merge_results - If True, multiple random runs for a non-deterministic trackers are averaged\n        filter_criteria - Filter sequence results which are reported. Following modes are supported\n                        None: No filtering. Display results for all sequences in dataset\n                        'ao_min': Only display sequences for which the minimum average overlap (AO) score over the\n                                  trackers is less than a threshold filter_criteria['threshold']. This mode can\n                                  be used to select sequences where at least one tracker performs poorly.\n                        'ao_max': Only display sequences for which the maximum average overlap (AO) score over the\n                                  trackers is less than a threshold filter_criteria['threshold']. This mode can\n                                  be used to select sequences all tracker performs poorly.\n                        'delta_ao': Only display sequences for which the performance of different trackers vary by at\n                                    least filter_criteria['threshold'] in average overlap (AO) score. This mode can\n                                    be used to select sequences where the behaviour of the trackers greatly differ\n                                    between each other.\n    \"\"\"", "\n", "# Load pre-computed results", "\n", "eval_data", "=", "check_and_load_precomputed_results", "(", "trackers", ",", "dataset", ",", "report_name", ",", "**", "kwargs", ")", "\n", "\n", "# Merge results from multiple runs", "\n", "if", "merge_results", ":", "\n", "        ", "eval_data", "=", "merge_multiple_runs", "(", "eval_data", ")", "\n", "\n", "", "tracker_names", "=", "eval_data", "[", "'trackers'", "]", "\n", "valid_sequence", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'valid_sequence'", "]", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "sequence_names", "=", "eval_data", "[", "'sequences'", "]", "\n", "avg_overlap_all", "=", "torch", ".", "tensor", "(", "eval_data", "[", "'avg_overlap_all'", "]", ")", "*", "100.0", "\n", "\n", "# Filter sequences", "\n", "if", "filter_criteria", "is", "not", "None", ":", "\n", "        ", "if", "filter_criteria", "[", "'mode'", "]", "==", "'ao_min'", ":", "\n", "            ", "min_ao", "=", "avg_overlap_all", ".", "min", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "valid_sequence", "=", "valid_sequence", "&", "(", "min_ao", "<", "filter_criteria", "[", "'threshold'", "]", ")", "\n", "", "elif", "filter_criteria", "[", "'mode'", "]", "==", "'ao_max'", ":", "\n", "            ", "max_ao", "=", "avg_overlap_all", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "valid_sequence", "=", "valid_sequence", "&", "(", "max_ao", "<", "filter_criteria", "[", "'threshold'", "]", ")", "\n", "", "elif", "filter_criteria", "[", "'mode'", "]", "==", "'delta_ao'", ":", "\n", "            ", "min_ao", "=", "avg_overlap_all", ".", "min", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "max_ao", "=", "avg_overlap_all", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "valid_sequence", "=", "valid_sequence", "&", "(", "(", "max_ao", "-", "min_ao", ")", ">", "filter_criteria", "[", "'threshold'", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "\n", "\n", "", "", "avg_overlap_all", "=", "avg_overlap_all", "[", "valid_sequence", ",", ":", "]", "\n", "sequence_names", "=", "[", "s", "+", "' (ID={})'", ".", "format", "(", "i", ")", "for", "i", ",", "(", "s", ",", "v", ")", "in", "enumerate", "(", "zip", "(", "sequence_names", ",", "valid_sequence", ".", "tolist", "(", ")", ")", ")", "if", "v", "]", "\n", "\n", "tracker_disp_names", "=", "[", "get_tracker_display_name", "(", "trk", ")", "for", "trk", "in", "tracker_names", "]", "\n", "\n", "scores_per_tracker", "=", "{", "k", ":", "avg_overlap_all", "[", ":", ",", "i", "]", "for", "i", ",", "k", "in", "enumerate", "(", "tracker_disp_names", ")", "}", "\n", "report_text", "=", "generate_formatted_report", "(", "sequence_names", ",", "scores_per_tracker", ")", "\n", "\n", "print", "(", "report_text", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display.__init__": [[20, 33], ["matplotlib.subplots", "matplotlib.subplots", "playback_results.Display.fig.canvas.mpl_connect", "matplotlib.tight_layout", "matplotlib.tight_layout"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sequence_length", ",", "plot_draw_styles", ",", "sequence_name", ")", ":", "\n", "        ", "self", ".", "active", "=", "True", "\n", "self", ".", "frame_number", "=", "0", "\n", "self", ".", "pause_mode", "=", "True", "\n", "self", ".", "step_size", "=", "0", "\n", "self", ".", "step_direction", "=", "'forward'", "\n", "self", ".", "fig", ",", "self", ".", "ax", "=", "plt", ".", "subplots", "(", "1", ")", "\n", "self", ".", "fig", ".", "canvas", ".", "mpl_connect", "(", "'key_press_event'", ",", "self", ".", "key_callback_fn", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "self", ".", "sequence_length", "=", "sequence_length", "\n", "self", ".", "sequence_name", "=", "sequence_name", "\n", "self", ".", "plot_draw_styles", "=", "plot_draw_styles", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display.key_callback_fn": [[34, 67], ["None"], "methods", ["None"], ["", "def", "key_callback_fn", "(", "self", ",", "event", ")", ":", "\n", "        ", "if", "event", ".", "key", "==", "' '", ":", "\n", "            ", "self", ".", "pause_mode", "=", "not", "self", ".", "pause_mode", "\n", "self", ".", "step_size", "=", "0", "\n", "self", ".", "step_direction", "=", "'forward'", "\n", "", "elif", "event", ".", "key", "==", "'right'", ":", "\n", "            ", "if", "self", ".", "pause_mode", ":", "\n", "                ", "self", ".", "frame_number", "+=", "1", "\n", "\n", "if", "self", ".", "frame_number", ">=", "self", ".", "sequence_length", ":", "\n", "                    ", "self", ".", "frame_number", "=", "self", ".", "sequence_length", "-", "1", "\n", "", "", "elif", "self", ".", "step_direction", "==", "'stop'", ":", "\n", "                ", "self", ".", "step_direction", "=", "'forward'", "\n", "self", ".", "step_size", "=", "0", "\n", "", "elif", "self", ".", "step_direction", "==", "'backward'", "and", "self", ".", "step_size", "==", "0", ":", "\n", "                ", "self", ".", "step_direction", "=", "'stop'", "\n", "", "else", ":", "\n", "                ", "self", ".", "step_size", "+=", "1", "\n", "", "", "elif", "event", ".", "key", "==", "'left'", ":", "\n", "            ", "if", "self", ".", "pause_mode", ":", "\n", "                ", "self", ".", "frame_number", "-=", "1", "\n", "\n", "if", "self", ".", "frame_number", "<", "0", ":", "\n", "                    ", "self", ".", "frame_number", "=", "0", "\n", "", "", "elif", "self", ".", "step_direction", "==", "'stop'", ":", "\n", "                ", "self", ".", "step_direction", "=", "'backward'", "\n", "self", ".", "step_size", "=", "0", "\n", "", "elif", "self", ".", "step_direction", "==", "'forward'", "and", "self", ".", "step_size", "==", "0", ":", "\n", "                ", "self", ".", "step_direction", "=", "'stop'", "\n", "", "else", ":", "\n", "                ", "self", ".", "step_size", "-=", "1", "\n", "", "", "elif", "event", ".", "key", "==", "'escape'", "or", "event", ".", "key", "==", "'q'", ":", "\n", "            ", "self", ".", "active", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display._get_speed": [[68, 76], ["abs", "abs"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs"], ["", "", "def", "_get_speed", "(", "self", ")", ":", "\n", "        ", "delta", "=", "0", "\n", "if", "self", ".", "step_direction", "==", "'forward'", ":", "\n", "            ", "delta", "=", "2", "**", "abs", "(", "self", ".", "step_size", ")", "\n", "", "elif", "self", ".", "step_direction", "==", "'backward'", ":", "\n", "            ", "delta", "=", "-", "1", "*", "2", "**", "abs", "(", "self", ".", "step_size", ")", "\n", "\n", "", "return", "delta", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display.step": [[77, 85], ["playback_results.Display._get_speed"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display._get_speed"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "delta", "=", "self", ".", "_get_speed", "(", ")", "\n", "\n", "self", ".", "frame_number", "+=", "delta", "\n", "if", "self", ".", "frame_number", "<", "0", ":", "\n", "            ", "self", ".", "frame_number", "=", "0", "\n", "", "elif", "self", ".", "frame_number", ">=", "self", ".", "sequence_length", ":", "\n", "            ", "self", ".", "frame_number", "=", "self", ".", "sequence_length", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display.show": [[86, 116], ["playback_results.Display.ax.cla", "playback_results.Display.ax.imshow", "enumerate", "playback_results.Display.ax.set_axis_off", "playback_results.Display.ax.axis", "matplotlib.legend", "matplotlib.legend", "playback_results.Display._get_speed", "playback_results.Display.fig.suptitle", "pytracking.utils.plotting.draw_figure", "matplotlib.Rectangle", "matplotlib.Rectangle", "playback_results.Display.ax.add_patch", "rect_handles.append", "matplotlib.Rectangle", "matplotlib.Rectangle", "playback_results.Display.ax.add_patch", "rect_handles.append", "matplotlib.Rectangle", "matplotlib.Rectangle"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display._get_speed", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.draw_figure"], ["", "", "def", "show", "(", "self", ",", "image", ",", "bb_list", ",", "trackers", ",", "gt", "=", "None", ")", ":", "\n", "        ", "self", ".", "ax", ".", "cla", "(", ")", "\n", "self", ".", "ax", ".", "imshow", "(", "image", ")", "\n", "\n", "# Draw rects", "\n", "rect_handles", "=", "[", "]", "\n", "for", "i", ",", "bb", "in", "enumerate", "(", "bb_list", ")", ":", "\n", "            ", "rect", "=", "patches", ".", "Rectangle", "(", "(", "bb", "[", "0", "]", ",", "bb", "[", "1", "]", ")", ",", "bb", "[", "2", "]", ",", "bb", "[", "3", "]", ",", "linewidth", "=", "1", ",", "\n", "edgecolor", "=", "self", ".", "plot_draw_styles", "[", "i", "]", "[", "'color'", "]", ",", "facecolor", "=", "'none'", ")", "\n", "self", ".", "ax", ".", "add_patch", "(", "rect", ")", "\n", "\n", "rect_handles", ".", "append", "(", "patches", ".", "Rectangle", "(", "(", "bb", "[", "0", "]", ",", "bb", "[", "1", "]", ")", ",", "bb", "[", "2", "]", ",", "bb", "[", "3", "]", ",", "linewidth", "=", "1", ",", "\n", "edgecolor", "=", "self", ".", "plot_draw_styles", "[", "i", "]", "[", "'color'", "]", ",", "\n", "facecolor", "=", "self", ".", "plot_draw_styles", "[", "i", "]", "[", "'color'", "]", ",", "\n", "label", "=", "trackers", "[", "i", "]", ")", ")", "\n", "\n", "", "if", "gt", "is", "not", "None", ":", "\n", "            ", "rect", "=", "patches", ".", "Rectangle", "(", "(", "gt", "[", "0", "]", ",", "gt", "[", "1", "]", ")", ",", "gt", "[", "2", "]", ",", "gt", "[", "3", "]", ",", "linewidth", "=", "2", ",", "edgecolor", "=", "'g'", ",", "\n", "facecolor", "=", "'none'", ")", "\n", "self", ".", "ax", ".", "add_patch", "(", "rect", ")", "\n", "rect_handles", ".", "append", "(", "rect", ")", "\n", "\n", "", "self", ".", "ax", ".", "set_axis_off", "(", ")", "\n", "self", ".", "ax", ".", "axis", "(", "'equal'", ")", "\n", "plt", ".", "legend", "(", "handles", "=", "rect_handles", ",", "loc", "=", "4", ",", "borderaxespad", "=", "0.", ")", "\n", "mode", "=", "'manual'", "if", "self", ".", "pause_mode", "else", "'auto     '", "\n", "speed", "=", "self", ".", "_get_speed", "(", ")", "\n", "self", ".", "fig", ".", "suptitle", "(", "'Sequence: {}    Mode: {}    Speed: {:d}x'", ".", "format", "(", "self", ".", "sequence_name", ",", "mode", ",", "speed", ")", ",", "\n", "fontsize", "=", "14", ")", "\n", "draw_figure", "(", "self", ".", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.read_image": [[118, 121], ["cv2.imread", "cv2.cvtColor"], "function", ["None"], ["", "", "def", "read_image", "(", "image_file", ":", "str", ")", ":", "\n", "    ", "im", "=", "cv", ".", "imread", "(", "image_file", ")", "\n", "return", "cv", ".", "cvtColor", "(", "im", ",", "cv", ".", "COLOR_BGR2RGB", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results._get_display_name": [[123, 131], ["None"], "function", ["None"], ["", "def", "_get_display_name", "(", "tracker", ")", ":", "\n", "    ", "if", "tracker", ".", "display_name", "is", "None", ":", "\n", "        ", "if", "tracker", ".", "run_id", "is", "not", "None", ":", "\n", "            ", "return", "'{}_{}_{:03d}'", ".", "format", "(", "tracker", ".", "name", ",", "tracker", ".", "parameter_name", ",", "tracker", ".", "run_id", ")", "\n", "", "else", ":", "\n", "            ", "return", "'{}_{}'", ".", "format", "(", "tracker", ".", "name", ",", "tracker", ".", "parameter_name", ")", "\n", "", "", "else", ":", "\n", "        ", "return", "tracker", ".", "display_name", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.playback_results": [[133, 176], ["pytracking.analysis.plot_results.get_plot_draw_styles", "enumerate", "torch.stack().tolist", "playback_results.Display", "os.path.isfile", "torch.stack().tolist.append", "playback_results._get_display_name", "len", "playback_results.read_image", "playback_results.Display.show", "time.sleep", "Exception", "torch.stack", "time.sleep", "torch.tensor", "playback_results.Display.step", "numpy.loadtxt", "torch.tensor", "str", "numpy.loadtxt", "str"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.get_plot_draw_styles", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results._get_display_name", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.read_image", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display.show", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display.step"], ["", "", "def", "playback_results", "(", "trackers", ",", "sequence", ")", ":", "\n", "    ", "\"\"\"\n    Playback saved results of input trackers for a particular sequence. You can navigate the sequence using left/right\n    arrow keys. You can also change to 'auto' mode by pressing space bar, in which case the sequence will be replayed\n    at a particular speed. The speed for playback in 'auto' mode can be controlled using the left/right arrow keys.\n    You can exit the application using escape or q keys.\n    \"\"\"", "\n", "plot_draw_styles", "=", "get_plot_draw_styles", "(", ")", "\n", "\n", "tracker_results", "=", "[", "]", "\n", "# Load results", "\n", "for", "trk_id", ",", "trk", "in", "enumerate", "(", "trackers", ")", ":", "\n", "# Load results", "\n", "        ", "base_results_path", "=", "'{}/{}'", ".", "format", "(", "trk", ".", "results_dir", ",", "sequence", ".", "name", ")", "\n", "results_path", "=", "'{}.txt'", ".", "format", "(", "base_results_path", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "results_path", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "pred_bb", "=", "torch", ".", "tensor", "(", "np", ".", "loadtxt", "(", "str", "(", "results_path", ")", ",", "dtype", "=", "np", ".", "float64", ")", ")", "\n", "", "except", ":", "\n", "                ", "pred_bb", "=", "torch", ".", "tensor", "(", "np", ".", "loadtxt", "(", "str", "(", "results_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Result not found. {}'", ".", "format", "(", "results_path", ")", ")", "\n", "\n", "", "tracker_results", ".", "append", "(", "pred_bb", ")", "\n", "\n", "# Convert to list of shape seq_length * num_trackers * 4", "\n", "", "tracker_results", "=", "torch", ".", "stack", "(", "tracker_results", ",", "dim", "=", "1", ")", ".", "tolist", "(", ")", "\n", "tracker_names", "=", "[", "_get_display_name", "(", "t", ")", "for", "t", "in", "trackers", "]", "\n", "\n", "display", "=", "Display", "(", "len", "(", "tracker_results", ")", ",", "plot_draw_styles", ",", "sequence", ".", "name", ")", "\n", "\n", "while", "display", ".", "active", ":", "\n", "        ", "frame_number", "=", "display", ".", "frame_number", "\n", "image", "=", "read_image", "(", "sequence", ".", "frames", "[", "frame_number", "]", ")", "\n", "\n", "display", ".", "show", "(", "image", ",", "tracker_results", "[", "frame_number", "]", ",", "tracker_names", ")", "\n", "\n", "time", ".", "sleep", "(", "0.01", ")", "\n", "if", "display", ".", "pause_mode", "and", "display", ".", "frame_number", "==", "frame_number", ":", "\n", "            ", "time", ".", "sleep", "(", "0.1", ")", "\n", "", "elif", "not", "display", ".", "pause_mode", ":", "\n", "            ", "display", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.extract_results.calc_err_center": [[17, 27], ["None"], "function", ["None"], ["def", "calc_err_center", "(", "pred_bb", ",", "anno_bb", ",", "normalized", "=", "False", ")", ":", "\n", "    ", "pred_center", "=", "pred_bb", "[", ":", ",", ":", "2", "]", "+", "0.5", "*", "(", "pred_bb", "[", ":", ",", "2", ":", "]", "-", "1.0", ")", "\n", "anno_center", "=", "anno_bb", "[", ":", ",", ":", "2", "]", "+", "0.5", "*", "(", "anno_bb", "[", ":", ",", "2", ":", "]", "-", "1.0", ")", "\n", "\n", "if", "normalized", ":", "\n", "        ", "pred_center", "=", "pred_center", "/", "anno_bb", "[", ":", ",", "2", ":", "]", "\n", "anno_center", "=", "anno_center", "/", "anno_bb", "[", ":", ",", "2", ":", "]", "\n", "\n", "", "err_center", "=", "(", "(", "pred_center", "-", "anno_center", ")", "**", "2", ")", ".", "sum", "(", "1", ")", ".", "sqrt", "(", ")", "\n", "return", "err_center", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.extract_results.calc_iou_overlap": [[29, 39], ["torch.max", "torch.min", "sz.prod", "pred_bb[].prod", "anno_bb[].prod"], "function", ["None"], ["", "def", "calc_iou_overlap", "(", "pred_bb", ",", "anno_bb", ")", ":", "\n", "    ", "tl", "=", "torch", ".", "max", "(", "pred_bb", "[", ":", ",", ":", "2", "]", ",", "anno_bb", "[", ":", ",", ":", "2", "]", ")", "\n", "br", "=", "torch", ".", "min", "(", "pred_bb", "[", ":", ",", ":", "2", "]", "+", "pred_bb", "[", ":", ",", "2", ":", "]", "-", "1.0", ",", "anno_bb", "[", ":", ",", ":", "2", "]", "+", "anno_bb", "[", ":", ",", "2", ":", "]", "-", "1.0", ")", "\n", "sz", "=", "(", "br", "-", "tl", "+", "1.0", ")", ".", "clamp", "(", "0", ")", "\n", "\n", "# Area", "\n", "intersection", "=", "sz", ".", "prod", "(", "dim", "=", "1", ")", "\n", "union", "=", "pred_bb", "[", ":", ",", "2", ":", "]", ".", "prod", "(", "dim", "=", "1", ")", "+", "anno_bb", "[", ":", ",", "2", ":", "]", ".", "prod", "(", "dim", "=", "1", ")", "-", "intersection", "\n", "\n", "return", "intersection", "/", "union", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.extract_results.calc_seq_err_robust": [[41, 101], ["torch.cat.clone", "torch.isnan().any", "extract_results.calc_err_center", "extract_results.calc_err_center", "extract_results.calc_iou_overlap", "torch.isnan().any", "torch.isnan().any", "Exception", "range", "target_visible.bool.bool", "float", "float", "float", "Exception", "torch.isnan", "Exception", "torch.isnan", "torch.isnan", "Exception", "torch.zeros().type_as", "torch.cat", "torch.isnan().any", "torch.zeros", "torch.isnan"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.analysis.extract_results.calc_err_center", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.extract_results.calc_err_center", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.extract_results.calc_iou_overlap", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan"], ["", "def", "calc_seq_err_robust", "(", "pred_bb", ",", "anno_bb", ",", "dataset", ",", "target_visible", "=", "None", ")", ":", "\n", "    ", "pred_bb", "=", "pred_bb", ".", "clone", "(", ")", "\n", "\n", "# Check if invalid values are present", "\n", "if", "torch", ".", "isnan", "(", "pred_bb", ")", ".", "any", "(", ")", "or", "(", "pred_bb", "[", ":", ",", "2", ":", "]", "<", "0.0", ")", ".", "any", "(", ")", ":", "\n", "        ", "raise", "Exception", "(", "'Error: Invalid results'", ")", "\n", "\n", "", "if", "torch", ".", "isnan", "(", "anno_bb", ")", ".", "any", "(", ")", ":", "\n", "        ", "if", "dataset", "==", "'uav'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Warning: NaNs in annotation'", ")", "\n", "\n", "", "", "if", "(", "pred_bb", "[", ":", ",", "2", ":", "]", "==", "0.0", ")", ".", "any", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "1", ",", "pred_bb", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "if", "(", "pred_bb", "[", "i", ",", "2", ":", "]", "==", "0.0", ")", ".", "any", "(", ")", "and", "not", "torch", ".", "isnan", "(", "anno_bb", "[", "i", ",", ":", "]", ")", ".", "any", "(", ")", ":", "\n", "                ", "pred_bb", "[", "i", ",", ":", "]", "=", "pred_bb", "[", "i", "-", "1", ",", ":", "]", "\n", "\n", "", "", "", "if", "pred_bb", ".", "shape", "[", "0", "]", "!=", "anno_bb", ".", "shape", "[", "0", "]", ":", "\n", "        ", "if", "dataset", "==", "'lasot'", ":", "\n", "            ", "if", "pred_bb", ".", "shape", "[", "0", "]", ">", "anno_bb", ".", "shape", "[", "0", "]", ":", "\n", "# For monkey-17, there is a mismatch for some trackers.", "\n", "                ", "pred_bb", "=", "pred_bb", "[", ":", "anno_bb", ".", "shape", "[", "0", "]", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'Mis-match in tracker prediction and GT lengths'", ")", "\n", "", "", "else", ":", "\n", "# print('Warning: Mis-match in tracker prediction and GT lengths')", "\n", "            ", "if", "pred_bb", ".", "shape", "[", "0", "]", ">", "anno_bb", ".", "shape", "[", "0", "]", ":", "\n", "                ", "pred_bb", "=", "pred_bb", "[", ":", "anno_bb", ".", "shape", "[", "0", "]", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "pad", "=", "torch", ".", "zeros", "(", "(", "anno_bb", ".", "shape", "[", "0", "]", "-", "pred_bb", ".", "shape", "[", "0", "]", ",", "4", ")", ")", ".", "type_as", "(", "pred_bb", ")", "\n", "pred_bb", "=", "torch", ".", "cat", "(", "(", "pred_bb", ",", "pad", ")", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "", "pred_bb", "[", "0", ",", ":", "]", "=", "anno_bb", "[", "0", ",", ":", "]", "\n", "\n", "if", "target_visible", "is", "not", "None", ":", "\n", "        ", "target_visible", "=", "target_visible", ".", "bool", "(", ")", "\n", "valid", "=", "(", "(", "anno_bb", "[", ":", ",", "2", ":", "]", ">", "0.0", ")", ".", "sum", "(", "1", ")", "==", "2", ")", "&", "target_visible", "\n", "", "else", ":", "\n", "        ", "valid", "=", "(", "(", "anno_bb", "[", ":", ",", "2", ":", "]", ">", "0.0", ")", ".", "sum", "(", "1", ")", "==", "2", ")", "\n", "\n", "", "err_center", "=", "calc_err_center", "(", "pred_bb", ",", "anno_bb", ")", "\n", "err_center_normalized", "=", "calc_err_center", "(", "pred_bb", ",", "anno_bb", ",", "normalized", "=", "True", ")", "\n", "err_overlap", "=", "calc_iou_overlap", "(", "pred_bb", ",", "anno_bb", ")", "\n", "\n", "# handle invalid anno cases", "\n", "if", "dataset", "in", "[", "'uav'", "]", ":", "\n", "        ", "err_center", "[", "~", "valid", "]", "=", "-", "1.0", "\n", "", "else", ":", "\n", "        ", "err_center", "[", "~", "valid", "]", "=", "float", "(", "\"Inf\"", ")", "\n", "", "err_center_normalized", "[", "~", "valid", "]", "=", "-", "1.0", "\n", "err_overlap", "[", "~", "valid", "]", "=", "-", "1.0", "\n", "\n", "if", "dataset", "==", "'lasot'", ":", "\n", "        ", "err_center_normalized", "[", "~", "target_visible", "]", "=", "float", "(", "\"Inf\"", ")", "\n", "err_center", "[", "~", "target_visible", "]", "=", "float", "(", "\"Inf\"", ")", "\n", "\n", "", "if", "torch", ".", "isnan", "(", "err_overlap", ")", ".", "any", "(", ")", ":", "\n", "        ", "raise", "Exception", "(", "'Nans in calculated overlap'", ")", "\n", "", "return", "err_overlap", ",", "err_center", ",", "err_center_normalized", ",", "valid", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.extract_results.extract_results": [[103, 184], ["pytracking.evaluation.environment.env_settings", "os.path.join", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "enumerate", "print", "os.path.exists", "os.makedirs", "torch.arange", "len", "tqdm.tqdm", "torch.tensor", "enumerate", "torch.ones.tolist", "torch.zeros.tolist", "torch.zeros.tolist", "torch.zeros.tolist", "torch.zeros.tolist", "torch.arange.tolist", "torch.arange.tolist", "threshold_set_center_norm.tolist", "open", "pickle.dump", "len", "len", "len", "len", "torch.arange.numel", "len", "len", "torch.arange.numel", "len", "len", "torch.arange.numel", "torch.tensor", "os.path.isfile", "extract_results.calc_seq_err_robust", "err_overlap[].mean", "torch.ones.long().sum().item", "torch.tensor", "valid_frame.long().sum", "Exception", "pytracking.utils.load_text.load_text", "Exception", "torch.ones.long().sum", "str", "valid_frame.long", "torch.ones.long", "err_overlap.view", "torch.arange.view", "err_center.view", "torch.arange.view", "err_center_normalized.view", "threshold_set_center_norm.view"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.extract_results.calc_seq_err_robust", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text"], ["", "def", "extract_results", "(", "trackers", ",", "dataset", ",", "report_name", ",", "skip_missing_seq", "=", "False", ",", "plot_bin_gap", "=", "0.05", ",", "\n", "exclude_invalid_frames", "=", "False", ")", ":", "\n", "    ", "settings", "=", "env_settings", "(", ")", "\n", "eps", "=", "1e-16", "\n", "\n", "result_plot_path", "=", "os", ".", "path", ".", "join", "(", "settings", ".", "result_plot_path", ",", "report_name", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "result_plot_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "result_plot_path", ")", "\n", "\n", "", "threshold_set_overlap", "=", "torch", ".", "arange", "(", "0.0", ",", "1.0", "+", "plot_bin_gap", ",", "plot_bin_gap", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "threshold_set_center", "=", "torch", ".", "arange", "(", "0", ",", "51", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "threshold_set_center_norm", "=", "torch", ".", "arange", "(", "0", ",", "51", ",", "dtype", "=", "torch", ".", "float64", ")", "/", "100.0", "\n", "\n", "avg_overlap_all", "=", "torch", ".", "zeros", "(", "(", "len", "(", "dataset", ")", ",", "len", "(", "trackers", ")", ")", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "ave_success_rate_plot_overlap", "=", "torch", ".", "zeros", "(", "(", "len", "(", "dataset", ")", ",", "len", "(", "trackers", ")", ",", "threshold_set_overlap", ".", "numel", "(", ")", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ")", "\n", "ave_success_rate_plot_center", "=", "torch", ".", "zeros", "(", "(", "len", "(", "dataset", ")", ",", "len", "(", "trackers", ")", ",", "threshold_set_center", ".", "numel", "(", ")", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ")", "\n", "ave_success_rate_plot_center_norm", "=", "torch", ".", "zeros", "(", "(", "len", "(", "dataset", ")", ",", "len", "(", "trackers", ")", ",", "threshold_set_center", ".", "numel", "(", ")", ")", ",", "\n", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "valid_sequence", "=", "torch", ".", "ones", "(", "len", "(", "dataset", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "\n", "for", "seq_id", ",", "seq", "in", "enumerate", "(", "tqdm", "(", "dataset", ")", ")", ":", "\n", "# Load anno", "\n", "        ", "anno_bb", "=", "torch", ".", "tensor", "(", "seq", ".", "ground_truth_rect", ")", "\n", "target_visible", "=", "torch", ".", "tensor", "(", "seq", ".", "target_visible", ",", "dtype", "=", "torch", ".", "uint8", ")", "if", "seq", ".", "target_visible", "is", "not", "None", "else", "None", "\n", "for", "trk_id", ",", "trk", "in", "enumerate", "(", "trackers", ")", ":", "\n", "# Load results", "\n", "            ", "base_results_path", "=", "'{}/{}'", ".", "format", "(", "trk", ".", "results_dir", ",", "seq", ".", "name", ")", "\n", "results_path", "=", "'{}.txt'", ".", "format", "(", "base_results_path", ")", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "results_path", ")", ":", "\n", "                ", "pred_bb", "=", "torch", ".", "tensor", "(", "load_text", "(", "str", "(", "results_path", ")", ",", "delimiter", "=", "(", "'\\t'", ",", "','", ")", ",", "dtype", "=", "np", ".", "float64", ")", ")", "\n", "", "else", ":", "\n", "                ", "if", "skip_missing_seq", ":", "\n", "                    ", "valid_sequence", "[", "seq_id", "]", "=", "0", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "'Result not found. {}'", ".", "format", "(", "results_path", ")", ")", "\n", "\n", "# Calculate measures", "\n", "", "", "err_overlap", ",", "err_center", ",", "err_center_normalized", ",", "valid_frame", "=", "calc_seq_err_robust", "(", "\n", "pred_bb", ",", "anno_bb", ",", "seq", ".", "dataset", ",", "target_visible", ")", "\n", "\n", "avg_overlap_all", "[", "seq_id", ",", "trk_id", "]", "=", "err_overlap", "[", "valid_frame", "]", ".", "mean", "(", ")", "\n", "\n", "if", "exclude_invalid_frames", ":", "\n", "                ", "seq_length", "=", "valid_frame", ".", "long", "(", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "                ", "seq_length", "=", "anno_bb", ".", "shape", "[", "0", "]", "\n", "\n", "", "if", "seq_length", "<=", "0", ":", "\n", "                ", "raise", "Exception", "(", "'Seq length zero'", ")", "\n", "\n", "", "ave_success_rate_plot_overlap", "[", "seq_id", ",", "trk_id", ",", ":", "]", "=", "(", "err_overlap", ".", "view", "(", "-", "1", ",", "1", ")", ">", "threshold_set_overlap", ".", "view", "(", "1", ",", "-", "1", ")", ")", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "/", "seq_length", "\n", "ave_success_rate_plot_center", "[", "seq_id", ",", "trk_id", ",", ":", "]", "=", "(", "err_center", ".", "view", "(", "-", "1", ",", "1", ")", "<=", "threshold_set_center", ".", "view", "(", "1", ",", "-", "1", ")", ")", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "/", "seq_length", "\n", "ave_success_rate_plot_center_norm", "[", "seq_id", ",", "trk_id", ",", ":", "]", "=", "(", "err_center_normalized", ".", "view", "(", "-", "1", ",", "1", ")", "<=", "threshold_set_center_norm", ".", "view", "(", "1", ",", "-", "1", ")", ")", ".", "sum", "(", "0", ")", ".", "float", "(", ")", "/", "seq_length", "\n", "\n", "", "", "print", "(", "'\\n\\nComputed results over {} / {} sequences'", ".", "format", "(", "valid_sequence", ".", "long", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "valid_sequence", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "# Prepare dictionary for saving data", "\n", "seq_names", "=", "[", "s", ".", "name", "for", "s", "in", "dataset", "]", "\n", "tracker_names", "=", "[", "{", "'name'", ":", "t", ".", "name", ",", "'param'", ":", "t", ".", "parameter_name", ",", "'run_id'", ":", "t", ".", "run_id", ",", "'disp_name'", ":", "t", ".", "display_name", "}", "\n", "for", "t", "in", "trackers", "]", "\n", "\n", "eval_data", "=", "{", "'sequences'", ":", "seq_names", ",", "'trackers'", ":", "tracker_names", ",", "\n", "'valid_sequence'", ":", "valid_sequence", ".", "tolist", "(", ")", ",", "\n", "'ave_success_rate_plot_overlap'", ":", "ave_success_rate_plot_overlap", ".", "tolist", "(", ")", ",", "\n", "'ave_success_rate_plot_center'", ":", "ave_success_rate_plot_center", ".", "tolist", "(", ")", ",", "\n", "'ave_success_rate_plot_center_norm'", ":", "ave_success_rate_plot_center_norm", ".", "tolist", "(", ")", ",", "\n", "'avg_overlap_all'", ":", "avg_overlap_all", ".", "tolist", "(", ")", ",", "\n", "'threshold_set_overlap'", ":", "threshold_set_overlap", ".", "tolist", "(", ")", ",", "\n", "'threshold_set_center'", ":", "threshold_set_center", ".", "tolist", "(", ")", ",", "\n", "'threshold_set_center_norm'", ":", "threshold_set_center_norm", ".", "tolist", "(", ")", "}", "\n", "\n", "with", "open", "(", "result_plot_path", "+", "'/eval_data.pkl'", ",", "'wb'", ")", "as", "fh", ":", "\n", "        ", "pickle", ".", "dump", "(", "eval_data", ",", "fh", ")", "\n", "\n", "", "return", "eval_data", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.evaluate_vos.evaluate_sequence": [[14, 45], ["dict", "object_info.items", "_statistics.items", "enumerate", "collections.OrderedDict", "numpy.ones", "zip", "float", "len", "list().index", "stat_fn", "results[].values", "len", "list", "annotations.keys"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["def", "evaluate_sequence", "(", "seq_name", ",", "segmentations", ",", "annotations", ",", "object_info", ",", "measure", "=", "'J'", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate video sequence results.\n\n      Arguments:\n          segmentations (dict of ndarray): segmentation labels.\n          annotations   (dict of ndarray): ground-truth labels.\n          object_info   dict: {object_id: first_frame_index}\n\n      measure       evaluation metric (J,F)\n    \"\"\"", "\n", "\n", "results", "=", "dict", "(", "raw", "=", "OrderedDict", "(", ")", ")", "\n", "\n", "_measures", "=", "{", "'J'", ":", "utils", ".", "davis_jaccard_measure", ",", "'F'", ":", "utils", ".", "davis_f_measure", "}", "\n", "_statistics", "=", "{", "'decay'", ":", "utils", ".", "decay", ",", "'mean'", ":", "utils", ".", "mean", ",", "'recall'", ":", "utils", ".", "recall", ",", "'std'", ":", "utils", ".", "std", "}", "\n", "\n", "for", "obj_id", ",", "first_frame", "in", "object_info", ".", "items", "(", ")", ":", "\n", "\n", "        ", "r", "=", "np", ".", "ones", "(", "(", "len", "(", "annotations", ")", ")", ")", "*", "np", ".", "nan", "\n", "\n", "for", "i", ",", "(", "an", ",", "sg", ")", "in", "enumerate", "(", "zip", "(", "annotations", ",", "segmentations", ")", ")", ":", "\n", "            ", "if", "list", "(", "annotations", ".", "keys", "(", ")", ")", ".", "index", "(", "first_frame", ")", "<", "i", "<", "len", "(", "annotations", ")", "-", "1", ":", "\n", "                ", "r", "[", "i", "]", "=", "_measures", "[", "measure", "]", "(", "annotations", "[", "an", "]", "==", "obj_id", ",", "segmentations", "[", "sg", "]", "==", "obj_id", ")", "\n", "\n", "", "", "results", "[", "'raw'", "]", "[", "obj_id", "]", "=", "r", "\n", "\n", "", "for", "stat", ",", "stat_fn", "in", "_statistics", ".", "items", "(", ")", ":", "\n", "        ", "results", "[", "stat", "]", "=", "[", "float", "(", "stat_fn", "(", "r", ")", ")", "for", "r", "in", "results", "[", "'raw'", "]", ".", "values", "(", ")", "]", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.evaluate_vos.evaluate_dataset": [[47, 138], ["pytracking.evaluation.get_dataset", "collections.OrderedDict", "enumerate", "evaluate_vos.evaluate_dataset._print"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.datasets.get_dataset"], ["", "def", "evaluate_dataset", "(", "results_path", ",", "dset_name", ",", "measure", "=", "'J'", ",", "to_file", "=", "True", ",", "scores", "=", "False", ",", "sequences", "=", "None", ",", "quiet", "=", "False", ")", ":", "\n", "    ", "dset", "=", "get_dataset", "(", "dset_name", ")", "\n", "results", "=", "OrderedDict", "(", ")", "\n", "dset_scores", "=", "[", "]", "\n", "dset_decay", "=", "[", "]", "\n", "dset_recall", "=", "[", "]", "\n", "\n", "if", "to_file", ":", "\n", "        ", "f", "=", "open", "(", "results_path", "/", "(", "\"evaluation-%s.txt\"", "%", "measure", ")", ",", "\"w\"", ")", "\n", "\n", "", "def", "_print", "(", "msg", ")", ":", "\n", "        ", "if", "not", "quiet", ":", "\n", "            ", "print", "(", "msg", ")", "\n", "", "if", "to_file", ":", "\n", "            ", "print", "(", "msg", ",", "file", "=", "f", ")", "\n", "\n", "", "", "if", "sequences", "is", "not", "None", ":", "\n", "        ", "sequences", "=", "[", "sequences", "]", "if", "not", "isinstance", "(", "sequences", ",", "(", "list", ",", "tuple", ")", ")", "else", "sequences", "\n", "\n", "", "target_names", "=", "[", "]", "\n", "for", "j", ",", "sequence", "in", "enumerate", "(", "dset", ")", ":", "\n", "        ", "if", "(", "sequences", "is", "not", "None", ")", "and", "(", "sequence", ".", "name", "not", "in", "sequences", ")", ":", "\n", "            ", "continue", "\n", "\n", "# Load all frames", "\n", "", "frames", "=", "sequence", ".", "ground_truth_seg", "\n", "\n", "annotations", "=", "OrderedDict", "(", ")", "\n", "segmentations", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "f", "in", "frames", ":", "\n", "            ", "if", "f", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "file", "=", "Path", "(", "f", ")", "\n", "annotations", "[", "file", ".", "name", "]", "=", "imread_indexed", "(", "file", ")", "\n", "if", "not", "scores", ":", "\n", "                ", "segmentations", "[", "file", ".", "name", "]", "=", "imread_indexed", "(", "os", ".", "path", ".", "join", "(", "results_path", ",", "sequence", ".", "name", ",", "file", ".", "name", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "# Find object ids and starting frames", "\n", "\n", "", "", "object_info", "=", "dict", "(", ")", "\n", "\n", "for", "f_id", ",", "d", "in", "sequence", ".", "init_data", ".", "items", "(", ")", ":", "\n", "            ", "for", "obj_id", "in", "d", "[", "'object_ids'", "]", ":", "\n", "                ", "object_info", "[", "int", "(", "obj_id", ")", "]", "=", "Path", "(", "d", "[", "'mask'", "]", ")", ".", "name", "\n", "\n", "", "", "if", "0", "in", "object_info", ":", "# Remove background", "\n", "            ", "object_info", ".", "pop", "(", "0", ")", "\n", "\n", "# Evaluate", "\n", "", "n_seqs", "=", "len", "(", "dset", ")", "\n", "n_objs", "=", "len", "(", "object_info", ")", "\n", "seq_name", "=", "sequence", ".", "name", "\n", "\n", "_print", "(", "\"%d/%d: %s: %d object%s\"", "%", "(", "j", "+", "1", ",", "n_seqs", ",", "seq_name", ",", "n_objs", ",", "\"s\"", "if", "n_objs", ">", "1", "else", "\"\"", ")", ")", "\n", "r", "=", "evaluate_sequence", "(", "seq_name", ",", "segmentations", ",", "annotations", ",", "object_info", ",", "measure", "=", "measure", ")", "\n", "results", "[", "seq_name", "]", "=", "r", "\n", "\n", "# Print scores, per frame and object, ignoring NaNs", "\n", "\n", "per_obj_score", "=", "[", "]", "# Per-object accuracies, averaged over the sequence", "\n", "per_frame_score", "=", "[", "]", "# Per-frame accuracies, averaged over the objects", "\n", "\n", "for", "obj_id", ",", "score", "in", "r", "[", "'raw'", "]", ".", "items", "(", ")", ":", "\n", "            ", "target_names", ".", "append", "(", "'{}_{}'", ".", "format", "(", "seq_name", ",", "obj_id", ")", ")", "\n", "per_frame_score", ".", "append", "(", "score", ")", "\n", "s", "=", "utils", ".", "mean", "(", "score", ")", "# Sequence average for one object", "\n", "per_obj_score", ".", "append", "(", "s", ")", "\n", "if", "n_objs", ">", "1", ":", "\n", "                ", "_print", "(", "\"joint {obj}: acc {score:.3f} \u250a{apf}\u250a\"", ".", "format", "(", "obj", "=", "obj_id", ",", "score", "=", "s", ",", "apf", "=", "utils", ".", "text_bargraph", "(", "score", ")", ")", ")", "\n", "\n", "# Print mean object score per frame and final score", "\n", "", "", "dset_decay", ".", "extend", "(", "r", "[", "'decay'", "]", ")", "\n", "dset_recall", ".", "extend", "(", "r", "[", "'recall'", "]", ")", "\n", "dset_scores", ".", "extend", "(", "per_obj_score", ")", "\n", "\n", "seq_score", "=", "utils", ".", "mean", "(", "per_obj_score", ")", "# Final score", "\n", "seq_mean_score", "=", "utils", ".", "nanmean", "(", "np", ".", "array", "(", "per_frame_score", ")", ",", "axis", "=", "0", ")", "# Mean object score per frame", "\n", "\n", "# Print sequence results", "\n", "_print", "(", "\"final  : acc {seq:.3f} ({dset:.3f}) \u250a{apf}\u250a\"", ".", "format", "(", "\n", "seq", "=", "seq_score", ",", "dset", "=", "np", ".", "mean", "(", "dset_scores", ")", ",", "apf", "=", "utils", ".", "text_bargraph", "(", "seq_mean_score", ")", ")", ")", "\n", "\n", "", "_print", "(", "\"%s: %.3f, recall: %.3f, decay: %.3f\"", "%", "(", "measure", ",", "utils", ".", "mean", "(", "dset_scores", ")", ",", "utils", ".", "mean", "(", "dset_recall", ")", ",", "utils", ".", "mean", "(", "dset_decay", ")", ")", ")", "\n", "\n", "if", "to_file", ":", "\n", "        ", "f", ".", "close", "(", ")", "\n", "\n", "", "return", "target_names", ",", "dset_scores", ",", "dset_recall", ",", "dset_decay", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.analysis.evaluate_vos.evaluate_vos": [[140, 200], ["pytracking.analysis.plot_results.generate_formatted_report", "print", "display_names.append", "os.path.join", "os.path.join", "scores[].append", "scores[].append", "scores[].append", "table_g_all.append", "table_seq_all.append", "os.path.exists", "os.path.exists", "pandas.read_csv", "pandas.read_csv", "evaluate_vos.evaluate_dataset", "numpy.array", "numpy.reshape", "pandas.DataFrame", "pandas.DataFrame", "open", "pd.DataFrame.to_csv", "open", "pd.DataFrame.to_csv", "pytracking.mean", "pytracking.mean", "pytracking.mean", "len", "list", "zip"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.analysis.plot_results.generate_formatted_report", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.evaluate_vos.evaluate_dataset", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "evaluate_vos", "(", "trackers", ",", "dataset", "=", "'yt2019_jjval'", ",", "force", "=", "False", ")", ":", "\n", "    ", "\"\"\" evaluate a list of trackers on a vos dataset.\n\n    args:\n        trackers - list of trackers to evaluate\n        dataset - name of the dataset\n        force - Force re-evaluation. If False, the pre-computed results are loaded if available\n    \"\"\"", "\n", "csv_name_global", "=", "f'{dataset}_global_results.csv'", "\n", "csv_name_per_sequence", "=", "f'{dataset}_per-sequence_results.csv'", "\n", "\n", "table_g_all", "=", "[", "]", "\n", "table_seq_all", "=", "[", "]", "\n", "scores", "=", "{", "'J-Mean'", ":", "[", "]", ",", "'J-Recall'", ":", "[", "]", ",", "'J-Decay'", ":", "[", "]", "}", "\n", "display_names", "=", "[", "]", "\n", "for", "t", "in", "trackers", ":", "\n", "        ", "if", "t", ".", "display_name", "is", "not", "None", ":", "\n", "            ", "disp_name", "=", "t", ".", "display_name", "\n", "", "elif", "t", ".", "run_id", "is", "not", "None", ":", "\n", "            ", "disp_name", "=", "'{} {}_{:03d}'", ".", "format", "(", "t", ".", "name", ",", "t", ".", "parameter_name", ",", "t", ".", "run_id", ")", "\n", "", "else", ":", "\n", "            ", "disp_name", "=", "'{} {}'", ".", "format", "(", "t", ".", "name", ",", "t", ".", "parameter_name", ")", "\n", "\n", "", "display_names", ".", "append", "(", "disp_name", ")", "\n", "results_path", "=", "t", ".", "segmentation_dir", "\n", "\n", "csv_name_global_path", "=", "os", ".", "path", ".", "join", "(", "results_path", ",", "csv_name_global", ")", "\n", "csv_name_per_sequence_path", "=", "os", ".", "path", ".", "join", "(", "results_path", ",", "csv_name_per_sequence", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "csv_name_global_path", ")", "and", "os", ".", "path", ".", "exists", "(", "csv_name_per_sequence_path", ")", "and", "not", "force", ":", "\n", "            ", "table_g", "=", "pd", ".", "read_csv", "(", "csv_name_global_path", ")", "\n", "table_seq", "=", "pd", ".", "read_csv", "(", "csv_name_per_sequence_path", ")", "\n", "", "else", ":", "\n", "            ", "seq_names", ",", "dset_scores", ",", "dset_recall", ",", "dset_decay", "=", "evaluate_dataset", "(", "results_path", ",", "dataset", ",", "measure", "=", "'J'", ",", "\n", "to_file", "=", "False", ",", "scores", "=", "False", ",", "\n", "sequences", "=", "None", ")", "\n", "g_measures", "=", "[", "'J-Mean'", ",", "'J-Recall'", ",", "'J-Decay'", "]", "\n", "g_res", "=", "np", ".", "array", "(", "[", "utils", ".", "mean", "(", "dset_scores", ")", ",", "utils", ".", "mean", "(", "dset_recall", ")", ",", "utils", ".", "mean", "(", "dset_decay", ")", "]", ")", "\n", "g_res", "=", "np", ".", "reshape", "(", "g_res", ",", "[", "1", ",", "len", "(", "g_res", ")", "]", ")", "\n", "\n", "table_g", "=", "pd", ".", "DataFrame", "(", "data", "=", "g_res", ",", "columns", "=", "g_measures", ")", "\n", "with", "open", "(", "csv_name_global_path", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "table_g", ".", "to_csv", "(", "f", ",", "index", "=", "False", ",", "float_format", "=", "\"%.3f\"", ")", "\n", "\n", "", "seq_measures", "=", "[", "'Sequence'", ",", "'J-Mean'", ",", "'J-Recall'", ",", "'J-Decay'", "]", "\n", "\n", "table_seq", "=", "pd", ".", "DataFrame", "(", "data", "=", "list", "(", "zip", "(", "seq_names", ",", "dset_scores", ",", "dset_recall", ",", "dset_decay", ")", ")", ",", "columns", "=", "seq_measures", ")", "\n", "with", "open", "(", "csv_name_per_sequence_path", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "table_seq", ".", "to_csv", "(", "f", ",", "index", "=", "False", ",", "float_format", "=", "\"%.3f\"", ")", "\n", "\n", "", "", "scores", "[", "'J-Mean'", "]", ".", "append", "(", "table_g", "[", "'J-Mean'", "]", ".", "values", "[", "0", "]", "*", "100", ")", "\n", "scores", "[", "'J-Recall'", "]", ".", "append", "(", "table_g", "[", "'J-Recall'", "]", ".", "values", "[", "0", "]", "*", "100", ")", "\n", "scores", "[", "'J-Decay'", "]", ".", "append", "(", "table_g", "[", "'J-Decay'", "]", ".", "values", "[", "0", "]", "*", "100", ")", "\n", "\n", "table_g_all", ".", "append", "(", "table_g", ")", "\n", "table_seq_all", ".", "append", "(", "table_seq", ")", "\n", "\n", "", "report", "=", "generate_formatted_report", "(", "display_names", ",", "scores", ")", "\n", "print", "(", "report", ")", "\n", "\n", "return", "table_g_all", ",", "table_seq_all", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.base.basetracker.BaseTracker.__init__": [[6, 9], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "params", "=", "params", "\n", "self", ".", "visdom", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.base.basetracker.BaseTracker.predicts_segmentation_mask": [[11, 13], ["None"], "methods", ["None"], ["", "def", "predicts_segmentation_mask", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.base.basetracker.BaseTracker.initialize": [[15, 18], ["None"], "methods", ["None"], ["", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "        ", "\"\"\"Overload this function in your tracker. This should initialize the model.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.base.basetracker.BaseTracker.track": [[20, 23], ["None"], "methods", ["None"], ["", "def", "track", "(", "self", ",", "image", ",", "info", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "        ", "\"\"\"Overload this function in your tracker. This should track in the frame and update the model.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.base.basetracker.BaseTracker.visdom_draw_tracking": [[25, 34], ["isinstance", "basetracker.BaseTracker.visdom.register", "basetracker.BaseTracker.visdom.register", "box.items"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register"], ["", "def", "visdom_draw_tracking", "(", "self", ",", "image", ",", "box", ",", "segmentation", "=", "None", ")", ":", "\n", "        ", "if", "isinstance", "(", "box", ",", "OrderedDict", ")", ":", "\n", "            ", "box", "=", "[", "v", "for", "k", ",", "v", "in", "box", ".", "items", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "box", "=", "(", "box", ",", ")", "\n", "", "if", "segmentation", "is", "None", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "*", "box", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "*", "box", ",", "segmentation", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.rfftshift2": [[7, 11], ["torch.cat", "torch.cat"], "function", ["None"], ["@", "tensor_operation", "\n", "def", "rfftshift2", "(", "a", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "h", "=", "a", ".", "shape", "[", "2", "]", "+", "2", "\n", "return", "torch", ".", "cat", "(", "(", "a", "[", ":", ",", ":", ",", "(", "h", "-", "1", ")", "//", "2", ":", ",", "...", "]", ",", "a", "[", ":", ",", ":", ",", ":", "h", "//", "2", ",", "...", "]", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.irfftshift2": [[13, 17], ["int", "torch.cat", "torch.cat"], "function", ["None"], ["", "@", "tensor_operation", "\n", "def", "irfftshift2", "(", "a", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "mid", "=", "int", "(", "(", "a", ".", "shape", "[", "2", "]", "-", "1", ")", "/", "2", ")", "\n", "return", "torch", ".", "cat", "(", "(", "a", "[", ":", ",", ":", ",", "mid", ":", ",", "...", "]", ",", "a", "[", ":", ",", ":", ",", ":", "mid", ",", "...", "]", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.cfft2": [[19, 25], ["fourier.rfftshift2", "torch.rfft", "torch.rfft"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.rfftshift2"], ["", "@", "tensor_operation", "\n", "def", "cfft2", "(", "a", ")", ":", "\n", "    ", "\"\"\"Do FFT and center the low frequency component.\n    Always produces odd (full) output sizes.\"\"\"", "\n", "\n", "return", "rfftshift2", "(", "torch", ".", "rfft", "(", "a", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.cifft2": [[27, 32], ["torch.irfft", "torch.irfft", "fourier.irfftshift2"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.irfftshift2"], ["", "@", "tensor_operation", "\n", "def", "cifft2", "(", "a", ",", "signal_sizes", "=", "None", ")", ":", "\n", "    ", "\"\"\"Do inverse FFT corresponding to cfft2.\"\"\"", "\n", "\n", "return", "torch", ".", "irfft", "(", "irfftshift2", "(", "a", ")", ",", "2", ",", "signal_sizes", "=", "signal_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.sample_fs": [[34, 62], ["torch.Tensor().float", "torch.Tensor().float", "int", "int", "fourier.cifft2", "ValueError", "int", "int", "fourier.cifft2", "torch.Tensor", "torch.Tensor", "grid_sz.prod().item", "fourier.cifft2", "torch.pad", "torch.Tensor().float.prod().item", "fourier.cifft2", "s.item", "torch.pad", "grid_sz.long().tolist", "grid_sz.prod", "grid_sz.long().tolist", "torch.Tensor().float.prod", "grid_sz.long", "grid_sz.long"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.cifft2", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.cifft2", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.cifft2", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.cifft2"], ["", "@", "tensor_operation", "\n", "def", "sample_fs", "(", "a", ":", "torch", ".", "Tensor", ",", "grid_sz", ":", "torch", ".", "Tensor", "=", "None", ",", "rescale", "=", "True", ")", ":", "\n", "    ", "\"\"\"Samples the Fourier series.\"\"\"", "\n", "\n", "# Size of the fourier series", "\n", "sz", "=", "torch", ".", "Tensor", "(", "[", "a", ".", "shape", "[", "2", "]", ",", "2", "*", "a", ".", "shape", "[", "3", "]", "-", "1", "]", ")", ".", "float", "(", ")", "\n", "\n", "# Default grid", "\n", "if", "grid_sz", "is", "None", "or", "sz", "[", "0", "]", "==", "grid_sz", "[", "0", "]", "and", "sz", "[", "1", "]", "==", "grid_sz", "[", "1", "]", ":", "\n", "        ", "if", "rescale", ":", "\n", "            ", "return", "sz", ".", "prod", "(", ")", ".", "item", "(", ")", "*", "cifft2", "(", "a", ")", "\n", "", "return", "cifft2", "(", "a", ")", "\n", "\n", "", "if", "sz", "[", "0", "]", ">", "grid_sz", "[", "0", "]", "or", "sz", "[", "1", "]", ">", "grid_sz", "[", "1", "]", ":", "\n", "        ", "raise", "ValueError", "(", "\"Only grid sizes that are smaller than the Fourier series size are supported.\"", ")", "\n", "\n", "", "tot_pad", "=", "(", "grid_sz", "-", "sz", ")", ".", "tolist", "(", ")", "\n", "is_even", "=", "[", "s", ".", "item", "(", ")", "%", "2", "==", "0", "for", "s", "in", "sz", "]", "\n", "\n", "# Compute paddings", "\n", "pad_top", "=", "int", "(", "(", "tot_pad", "[", "0", "]", "+", "1", ")", "/", "2", ")", "if", "is_even", "[", "0", "]", "else", "int", "(", "tot_pad", "[", "0", "]", "/", "2", ")", "\n", "pad_bottom", "=", "int", "(", "tot_pad", "[", "0", "]", "-", "pad_top", ")", "\n", "pad_right", "=", "int", "(", "(", "tot_pad", "[", "1", "]", "+", "1", ")", "/", "2", ")", "\n", "\n", "if", "rescale", ":", "\n", "        ", "return", "grid_sz", ".", "prod", "(", ")", ".", "item", "(", ")", "*", "cifft2", "(", "F", ".", "pad", "(", "a", ",", "(", "0", ",", "0", ",", "0", ",", "pad_right", ",", "pad_top", ",", "pad_bottom", ")", ")", ",", "signal_sizes", "=", "grid_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "cifft2", "(", "F", ".", "pad", "(", "a", ",", "(", "0", ",", "0", ",", "0", ",", "pad_right", ",", "pad_top", ",", "pad_bottom", ")", ")", ",", "signal_sizes", "=", "grid_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.get_frequency_coord": [[64, 75], ["torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "ky.unsqueeze.unsqueeze", "kx.unsqueeze.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "int", "int", "int"], "function", ["None"], ["", "", "def", "get_frequency_coord", "(", "sz", ",", "add_complex_dim", "=", "False", ",", "device", "=", "'cpu'", ")", ":", "\n", "    ", "\"\"\"Frequency coordinates.\"\"\"", "\n", "\n", "ky", "=", "torch", ".", "arange", "(", "-", "int", "(", "(", "sz", "[", "0", "]", "-", "1", ")", "/", "2", ")", ",", "int", "(", "sz", "[", "0", "]", "/", "2", "+", "1", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", "\n", "kx", "=", "torch", ".", "arange", "(", "0", ",", "int", "(", "sz", "[", "1", "]", "/", "2", "+", "1", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", ".", "view", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", "\n", "\n", "if", "add_complex_dim", ":", "\n", "        ", "ky", "=", "ky", ".", "unsqueeze", "(", "-", "1", ")", "\n", "kx", "=", "kx", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "return", "ky", ",", "kx", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.shift_fs": [[77, 93], ["fourier.get_frequency_coord", "pytracking.complex.mult", "a.dim", "ValueError", "pytracking.complex.mult", "pytracking.complex.exp_imag", "pytracking.complex.exp_imag", "shift[].item", "shift[].item"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.get_frequency_coord", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.exp_imag", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.exp_imag"], ["", "@", "tensor_operation", "\n", "def", "shift_fs", "(", "a", ":", "torch", ".", "Tensor", ",", "shift", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Shift a sample a in the Fourier domain.\n    Params:\n        a : The fourier coefficiens of the sample.\n        shift : The shift to be performed normalized to the range [-pi, pi].\"\"\"", "\n", "\n", "if", "a", ".", "dim", "(", ")", "!=", "5", ":", "\n", "        ", "raise", "ValueError", "(", "'a must be the Fourier coefficients, a 5-dimensional tensor.'", ")", "\n", "\n", "", "if", "shift", "[", "0", "]", "==", "0", "and", "shift", "[", "1", "]", "==", "0", ":", "\n", "        ", "return", "a", "\n", "\n", "", "ky", ",", "kx", "=", "get_frequency_coord", "(", "(", "a", ".", "shape", "[", "2", "]", ",", "2", "*", "a", ".", "shape", "[", "3", "]", "-", "1", ")", ",", "device", "=", "a", ".", "device", ")", "\n", "\n", "return", "complex", ".", "mult", "(", "complex", ".", "mult", "(", "a", ",", "complex", ".", "exp_imag", "(", "shift", "[", "0", "]", ".", "item", "(", ")", "*", "ky", ")", ")", ",", "complex", ".", "exp_imag", "(", "shift", "[", "1", "]", ".", "item", "(", ")", "*", "kx", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.sum_fs": [[95, 115], ["sorted", "e.clone", "int", "int", "int"], "function", ["None"], ["", "def", "sum_fs", "(", "a", ":", "TensorList", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Sum a list of Fourier series expansions.\"\"\"", "\n", "\n", "s", "=", "None", "\n", "mid", "=", "None", "\n", "\n", "for", "e", "in", "sorted", "(", "a", ",", "key", "=", "lambda", "elem", ":", "elem", ".", "shape", "[", "-", "3", "]", ",", "reverse", "=", "True", ")", ":", "\n", "        ", "if", "s", "is", "None", ":", "\n", "            ", "s", "=", "e", ".", "clone", "(", ")", "\n", "mid", "=", "int", "(", "(", "s", ".", "shape", "[", "-", "3", "]", "-", "1", ")", "/", "2", ")", "\n", "", "else", ":", "\n", "# Compute coordinates", "\n", "            ", "top", "=", "mid", "-", "int", "(", "(", "e", ".", "shape", "[", "-", "3", "]", "-", "1", ")", "/", "2", ")", "\n", "bottom", "=", "mid", "+", "int", "(", "e", ".", "shape", "[", "-", "3", "]", "/", "2", ")", "+", "1", "\n", "right", "=", "e", ".", "shape", "[", "-", "2", "]", "\n", "\n", "# Add the data", "\n", "s", "[", "...", ",", "top", ":", "bottom", ",", ":", "right", ",", ":", "]", "+=", "e", "\n", "\n", "", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.sum_fs12": [[117, 137], ["sorted", "e.clone", "int", "int", "int"], "function", ["None"], ["", "def", "sum_fs12", "(", "a", ":", "TensorList", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Sum a list of Fourier series expansions.\"\"\"", "\n", "\n", "s", "=", "None", "\n", "mid", "=", "None", "\n", "\n", "for", "e", "in", "sorted", "(", "a", ",", "key", "=", "lambda", "elem", ":", "elem", ".", "shape", "[", "0", "]", ",", "reverse", "=", "True", ")", ":", "\n", "        ", "if", "s", "is", "None", ":", "\n", "            ", "s", "=", "e", ".", "clone", "(", ")", "\n", "mid", "=", "int", "(", "(", "s", ".", "shape", "[", "0", "]", "-", "1", ")", "/", "2", ")", "\n", "", "else", ":", "\n", "# Compute coordinates", "\n", "            ", "top", "=", "mid", "-", "int", "(", "(", "e", ".", "shape", "[", "0", "]", "-", "1", ")", "/", "2", ")", "\n", "bottom", "=", "mid", "+", "int", "(", "e", ".", "shape", "[", "0", "]", "/", "2", ")", "+", "1", "\n", "right", "=", "e", ".", "shape", "[", "1", "]", "\n", "\n", "# Add the data", "\n", "s", "[", "top", ":", "bottom", ",", ":", "right", ",", "...", "]", "+=", "e", "\n", "\n", "", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.inner_prod_fs": [[139, 147], ["pytracking.complex.is_complex", "pytracking.complex.is_complex", "pytracking.complex.is_real", "pytracking.complex.is_real", "NotImplementedError", "a[].reshape", "b[].reshape", "a.reshape", "b.reshape", "a[].reshape", "b[].reshape", "a.reshape", "b.reshape"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_complex", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_complex", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real"], ["", "@", "tensor_operation", "\n", "def", "inner_prod_fs", "(", "a", ":", "torch", ".", "Tensor", ",", "b", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "if", "complex", ".", "is_complex", "(", "a", ")", "and", "complex", ".", "is_complex", "(", "b", ")", ":", "\n", "        ", "return", "2", "*", "(", "a", ".", "reshape", "(", "-", "1", ")", "@", "b", ".", "reshape", "(", "-", "1", ")", ")", "-", "a", "[", ":", ",", ":", ",", ":", ",", "0", ",", ":", "]", ".", "reshape", "(", "-", "1", ")", "@", "b", "[", ":", ",", ":", ",", ":", ",", "0", ",", ":", "]", ".", "reshape", "(", "-", "1", ")", "\n", "", "elif", "complex", ".", "is_real", "(", "a", ")", "and", "complex", ".", "is_real", "(", "b", ")", ":", "\n", "        ", "return", "2", "*", "(", "a", ".", "reshape", "(", "-", "1", ")", "@", "b", ".", "reshape", "(", "-", "1", ")", ")", "-", "a", "[", ":", ",", ":", ",", ":", ",", "0", "]", ".", "reshape", "(", "-", "1", ")", "@", "b", "[", ":", ",", ":", ",", ":", ",", "0", "]", ".", "reshape", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Not implemented for mixed real and complex.'", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.__call__": [[12, 15], ["None"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "x", ":", "TensorList", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Shall compute the residuals of the problem.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.ip_input": [[16, 19], ["sum", "a.view", "b.view"], "methods", ["None"], ["", "def", "ip_input", "(", "self", ",", "a", ",", "b", ")", ":", "\n", "        ", "\"\"\"Inner product of the input space.\"\"\"", "\n", "return", "sum", "(", "a", ".", "view", "(", "-", "1", ")", "@", "b", ".", "view", "(", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.ip_output": [[20, 23], ["sum", "a.view", "b.view"], "methods", ["None"], ["", "def", "ip_output", "(", "self", ",", "a", ",", "b", ")", ":", "\n", "        ", "\"\"\"Inner product of the output space.\"\"\"", "\n", "return", "sum", "(", "a", ".", "view", "(", "-", "1", ")", "@", "b", ".", "view", "(", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.M1": [[24, 27], ["None"], "methods", ["None"], ["", "def", "M1", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"M1 preconditioner.\"\"\"", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.M2": [[28, 31], ["None"], "methods", ["None"], ["", "def", "M2", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"M2 preconditioner.\"\"\"", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.MinimizationProblem.__call__": [[34, 37], ["None"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "x", ":", "TensorList", ")", "->", "TensorList", ":", "\n", "        ", "\"\"\"Shall compute the loss.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.MinimizationProblem.ip_input": [[38, 41], ["sum", "a.view", "b.view"], "methods", ["None"], ["", "def", "ip_input", "(", "self", ",", "a", ",", "b", ")", ":", "\n", "        ", "\"\"\"Inner product of the input space.\"\"\"", "\n", "return", "sum", "(", "a", ".", "view", "(", "-", "1", ")", "@", "b", ".", "view", "(", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.MinimizationProblem.M1": [[42, 44], ["None"], "methods", ["None"], ["", "def", "M1", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.MinimizationProblem.M2": [[45, 47], ["None"], "methods", ["None"], ["", "def", "M2", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.__init__": [[52, 65], ["torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "fletcher_reeves", "=", "True", ",", "standard_alpha", "=", "True", ",", "direction_forget_factor", "=", "0", ",", "debug", "=", "False", ")", ":", "\n", "        ", "self", ".", "fletcher_reeves", "=", "fletcher_reeves", "\n", "self", ".", "standard_alpha", "=", "standard_alpha", "\n", "self", ".", "direction_forget_factor", "=", "direction_forget_factor", "\n", "self", ".", "debug", "=", "debug", "\n", "\n", "# State", "\n", "self", ".", "p", "=", "None", "\n", "self", ".", "rho", "=", "torch", ".", "ones", "(", "1", ")", "\n", "self", ".", "r_prev", "=", "None", "\n", "\n", "# Right hand side", "\n", "self", ".", "b", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.reset_state": [[66, 70], ["torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "reset_state", "(", "self", ")", ":", "\n", "        ", "self", ".", "p", "=", "None", "\n", "self", ".", "rho", "=", "torch", ".", "ones", "(", "1", ")", "\n", "self", ".", "r_prev", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.run_CG": [[72, 164], ["range", "optimization.ConjugateGradientBase.reset_state", "optimization.ConjugateGradientBase.b.clone", "optimization.ConjugateGradientBase.residual_norm", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "optimization.ConjugateGradientBase.M1", "optimization.ConjugateGradientBase.M2", "optimization.ConjugateGradientBase.ip", "optimization.ConjugateGradientBase.check_zero", "optimization.ConjugateGradientBase.A", "optimization.ConjugateGradientBase.ip", "optimization.ConjugateGradientBase.A", "optimization.ConjugateGradientBase.clone", "beta.clamp.clamp.clamp", "optimization.ConjugateGradientBase.clone", "optimization.ConjugateGradientBase.residual_norm", "optimization.ConjugateGradientBase.evaluate_CG_iteration", "print", "optimization.ConjugateGradientBase.ip", "optimization.ConjugateGradientBase.ip", "print"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.reset_state", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.residual_norm", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.M1", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.M2", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.ip", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.check_zero", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.A", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.ip", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.A", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.residual_norm", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.evaluate_CG_iteration", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.ip", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.ip"], ["", "def", "run_CG", "(", "self", ",", "num_iter", ",", "x", "=", "None", ",", "eps", "=", "0.0", ")", ":", "\n", "        ", "\"\"\"Main conjugate gradient method.\n\n        args:\n            num_iter: Number of iterations.\n            x: Initial guess. Assumed zero if None.\n            eps: Stop if the residual norm gets smaller than this.\n        \"\"\"", "\n", "\n", "# Apply forgetting factor", "\n", "if", "self", ".", "direction_forget_factor", "==", "0", ":", "\n", "            ", "self", ".", "reset_state", "(", ")", "\n", "", "elif", "self", ".", "p", "is", "not", "None", ":", "\n", "            ", "self", ".", "rho", "/=", "self", ".", "direction_forget_factor", "\n", "\n", "", "if", "x", "is", "None", ":", "\n", "            ", "r", "=", "self", ".", "b", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "            ", "r", "=", "self", ".", "b", "-", "self", ".", "A", "(", "x", ")", "\n", "\n", "# Norms of residuals etc for debugging", "\n", "", "resvec", "=", "None", "\n", "if", "self", ".", "debug", ":", "\n", "            ", "normr", "=", "self", ".", "residual_norm", "(", "r", ")", "\n", "resvec", "=", "torch", ".", "zeros", "(", "num_iter", "+", "1", ")", "\n", "resvec", "[", "0", "]", "=", "normr", "\n", "\n", "# Loop over iterations", "\n", "", "for", "ii", "in", "range", "(", "num_iter", ")", ":", "\n", "# Preconditioners", "\n", "            ", "y", "=", "self", ".", "M1", "(", "r", ")", "\n", "z", "=", "self", ".", "M2", "(", "y", ")", "\n", "\n", "rho1", "=", "self", ".", "rho", "\n", "self", ".", "rho", "=", "self", ".", "ip", "(", "r", ",", "z", ")", "\n", "\n", "if", "self", ".", "check_zero", "(", "self", ".", "rho", ")", ":", "\n", "                ", "if", "self", ".", "debug", ":", "\n", "                    ", "print", "(", "'Stopped CG since rho = 0'", ")", "\n", "if", "resvec", "is", "not", "None", ":", "\n", "                        ", "resvec", "=", "resvec", "[", ":", "ii", "+", "1", "]", "\n", "", "", "return", "x", ",", "resvec", "\n", "\n", "", "if", "self", ".", "p", "is", "None", ":", "\n", "                ", "self", ".", "p", "=", "z", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "fletcher_reeves", ":", "\n", "                    ", "beta", "=", "self", ".", "rho", "/", "rho1", "\n", "", "else", ":", "\n", "                    ", "rho2", "=", "self", ".", "ip", "(", "self", ".", "r_prev", ",", "z", ")", "\n", "beta", "=", "(", "self", ".", "rho", "-", "rho2", ")", "/", "rho1", "\n", "\n", "", "beta", "=", "beta", ".", "clamp", "(", "0", ")", "\n", "self", ".", "p", "=", "z", "+", "self", ".", "p", "*", "beta", "\n", "\n", "", "q", "=", "self", ".", "A", "(", "self", ".", "p", ")", "\n", "pq", "=", "self", ".", "ip", "(", "self", ".", "p", ",", "q", ")", "\n", "\n", "if", "self", ".", "standard_alpha", ":", "\n", "                ", "alpha", "=", "self", ".", "rho", "/", "pq", "\n", "", "else", ":", "\n", "                ", "alpha", "=", "self", ".", "ip", "(", "self", ".", "p", ",", "r", ")", "/", "pq", "\n", "\n", "# Save old r for PR formula", "\n", "", "if", "not", "self", ".", "fletcher_reeves", ":", "\n", "                ", "self", ".", "r_prev", "=", "r", ".", "clone", "(", ")", "\n", "\n", "# Form new iterate", "\n", "", "if", "x", "is", "None", ":", "\n", "                ", "x", "=", "self", ".", "p", "*", "alpha", "\n", "", "else", ":", "\n", "                ", "x", "+=", "self", ".", "p", "*", "alpha", "\n", "\n", "", "if", "ii", "<", "num_iter", "-", "1", "or", "self", ".", "debug", ":", "\n", "                ", "r", "-=", "q", "*", "alpha", "\n", "\n", "", "if", "eps", ">", "0.0", "or", "self", ".", "debug", ":", "\n", "                ", "normr", "=", "self", ".", "residual_norm", "(", "r", ")", "\n", "\n", "", "if", "self", ".", "debug", ":", "\n", "                ", "self", ".", "evaluate_CG_iteration", "(", "x", ")", "\n", "resvec", "[", "ii", "+", "1", "]", "=", "normr", "\n", "\n", "", "if", "eps", ">", "0", "and", "normr", "<=", "eps", ":", "\n", "                ", "if", "self", ".", "debug", ":", "\n", "                    ", "print", "(", "'Stopped CG since norm smaller than eps'", ")", "\n", "", "break", "\n", "\n", "", "", "if", "resvec", "is", "not", "None", ":", "\n", "            ", "resvec", "=", "resvec", "[", ":", "ii", "+", "2", "]", "\n", "\n", "", "return", "x", ",", "resvec", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.A": [[166, 169], ["None"], "methods", ["None"], ["", "def", "A", "(", "self", ",", "x", ")", ":", "\n", "# Implements the left hand operation", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.ip": [[170, 173], ["a.view", "b.view"], "methods", ["None"], ["", "def", "ip", "(", "self", ",", "a", ",", "b", ")", ":", "\n", "# Implements the inner product", "\n", "        ", "return", "a", ".", "view", "(", "-", "1", ")", "@", "b", ".", "view", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.residual_norm": [[174, 179], ["optimization.ConjugateGradientBase.ip().sum", "isinstance", "sum.sqrt", "sum", "optimization.ConjugateGradientBase.ip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.ip"], ["", "def", "residual_norm", "(", "self", ",", "r", ")", ":", "\n", "        ", "res", "=", "self", ".", "ip", "(", "r", ",", "r", ")", ".", "sum", "(", ")", "\n", "if", "isinstance", "(", "res", ",", "(", "TensorList", ",", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "res", "=", "sum", "(", "res", ")", "\n", "", "return", "res", ".", "sqrt", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.check_zero": [[180, 185], ["isinstance", "s.abs", "sum", "sum.item"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs"], ["", "def", "check_zero", "(", "self", ",", "s", ",", "eps", "=", "0.0", ")", ":", "\n", "        ", "ss", "=", "s", ".", "abs", "(", ")", "<=", "eps", "\n", "if", "isinstance", "(", "ss", ",", "(", "TensorList", ",", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "ss", "=", "sum", "(", "ss", ")", "\n", "", "return", "ss", ".", "item", "(", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.M1": [[186, 189], ["None"], "methods", ["None"], ["", "def", "M1", "(", "self", ",", "x", ")", ":", "\n", "# M1 preconditioner", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.M2": [[190, 193], ["None"], "methods", ["None"], ["", "def", "M2", "(", "self", ",", "x", ")", ":", "\n", "# M2 preconditioner", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.evaluate_CG_iteration": [[194, 196], ["None"], "methods", ["None"], ["", "def", "evaluate_CG_iteration", "(", "self", ",", "x", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradient.__init__": [[202, 220], ["optimization.ConjugateGradientBase.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "problem", ":", "L2Problem", ",", "variable", ":", "TensorList", ",", "cg_eps", "=", "0.0", ",", "fletcher_reeves", "=", "True", ",", "\n", "standard_alpha", "=", "True", ",", "direction_forget_factor", "=", "0", ",", "debug", "=", "False", ",", "plotting", "=", "False", ",", "visdom", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "fletcher_reeves", ",", "standard_alpha", ",", "direction_forget_factor", ",", "debug", "or", "plotting", ")", "\n", "\n", "self", ".", "problem", "=", "problem", "\n", "self", ".", "x", "=", "variable", "\n", "\n", "self", ".", "plotting", "=", "plotting", "\n", "self", ".", "fig_num", "=", "(", "10", ",", "11", ")", "\n", "self", ".", "visdom", "=", "visdom", "\n", "\n", "self", ".", "cg_eps", "=", "cg_eps", "\n", "self", ".", "f0", "=", "None", "\n", "self", ".", "g", "=", "None", "\n", "self", ".", "dfdxt_g", "=", "None", "\n", "\n", "self", ".", "residuals", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "self", ".", "losses", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradient.clear_temp": [[221, 225], ["None"], "methods", ["None"], ["", "def", "clear_temp", "(", "self", ")", ":", "\n", "        ", "self", ".", "f0", "=", "None", "\n", "self", ".", "g", "=", "None", "\n", "self", ".", "dfdxt_g", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradient.run": [[227, 276], ["optimization.ConjugateGradient.x.requires_grad_", "optimization.ConjugateGradient.problem", "optimization.ConjugateGradient.f0.detach", "optimization.ConjugateGradient.g.requires_grad_", "pytracking.libs.TensorList", "optimization.ConjugateGradient.run_CG", "optimization.ConjugateGradient.x.detach_", "optimization.ConjugateGradient.x.detach_", "optimization.ConjugateGradient.clear_temp", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "optimization.ConjugateGradient.problem.ip_output", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "optimization.ConjugateGradient.dfdxt_g.detach", "optimization.ConjugateGradient.problem", "optimization.ConjugateGradient.problem.ip_output", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "optimization.ConjugateGradient.visdom.register", "optimization.ConjugateGradient.visdom.register", "pytracking.utils.plotting.plot_graph", "pytracking.utils.plotting.plot_graph"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.run_CG", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescent.clear_temp", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.ip_output", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.ip_output", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph"], ["", "def", "run", "(", "self", ",", "num_cg_iter", ")", ":", "\n", "        ", "\"\"\"Run the optimizer with the provided number of iterations.\"\"\"", "\n", "\n", "if", "num_cg_iter", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "lossvec", "=", "None", "\n", "if", "self", ".", "debug", ":", "\n", "            ", "lossvec", "=", "torch", ".", "zeros", "(", "2", ")", "\n", "\n", "", "self", ".", "x", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "# Evaluate function at current estimate", "\n", "self", ".", "f0", "=", "self", ".", "problem", "(", "self", ".", "x", ")", "\n", "\n", "# Create copy with graph detached", "\n", "self", ".", "g", "=", "self", ".", "f0", ".", "detach", "(", ")", "\n", "\n", "if", "self", ".", "debug", ":", "\n", "            ", "lossvec", "[", "0", "]", "=", "self", ".", "problem", ".", "ip_output", "(", "self", ".", "g", ",", "self", ".", "g", ")", "\n", "\n", "", "self", ".", "g", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "# Get df/dx^t @ f0", "\n", "self", ".", "dfdxt_g", "=", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "self", ".", "f0", ",", "self", ".", "x", ",", "self", ".", "g", ",", "create_graph", "=", "True", ")", ")", "\n", "\n", "# Get the right hand side", "\n", "self", ".", "b", "=", "-", "self", ".", "dfdxt_g", ".", "detach", "(", ")", "\n", "\n", "# Run CG", "\n", "delta_x", ",", "res", "=", "self", ".", "run_CG", "(", "num_cg_iter", ",", "eps", "=", "self", ".", "cg_eps", ")", "\n", "\n", "self", ".", "x", ".", "detach_", "(", ")", "\n", "self", ".", "x", "+=", "delta_x", "\n", "\n", "if", "self", ".", "debug", ":", "\n", "            ", "self", ".", "f0", "=", "self", ".", "problem", "(", "self", ".", "x", ")", "\n", "lossvec", "[", "-", "1", "]", "=", "self", ".", "problem", ".", "ip_output", "(", "self", ".", "f0", ",", "self", ".", "f0", ")", "\n", "self", ".", "residuals", "=", "torch", ".", "cat", "(", "(", "self", ".", "residuals", ",", "res", ")", ")", "\n", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "lossvec", ")", ")", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                ", "self", ".", "visdom", ".", "register", "(", "self", ".", "losses", ",", "'lineplot'", ",", "3", ",", "'Loss'", ")", "\n", "self", ".", "visdom", ".", "register", "(", "self", ".", "residuals", ",", "'lineplot'", ",", "3", ",", "'CG residuals'", ")", "\n", "", "elif", "self", ".", "plotting", ":", "\n", "                ", "plot_graph", "(", "self", ".", "losses", ",", "self", ".", "fig_num", "[", "0", "]", ",", "title", "=", "'Loss'", ")", "\n", "plot_graph", "(", "self", ".", "residuals", ",", "self", ".", "fig_num", "[", "1", "]", ",", "title", "=", "'CG residuals'", ")", "\n", "\n", "", "", "self", ".", "x", ".", "detach_", "(", ")", "\n", "self", ".", "clear_temp", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradient.A": [[278, 281], ["torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "pytracking.libs.TensorList", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad"], "methods", ["None"], ["", "def", "A", "(", "self", ",", "x", ")", ":", "\n", "        ", "dfdx_x", "=", "torch", ".", "autograd", ".", "grad", "(", "self", ".", "dfdxt_g", ",", "self", ".", "g", ",", "x", ",", "retain_graph", "=", "True", ")", "\n", "return", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "self", ".", "f0", ",", "self", ".", "x", ",", "dfdx_x", ",", "retain_graph", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradient.ip": [[282, 284], ["optimization.ConjugateGradient.problem.ip_input"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.MinimizationProblem.ip_input"], ["", "def", "ip", "(", "self", ",", "a", ",", "b", ")", ":", "\n", "        ", "return", "self", ".", "problem", ".", "ip_input", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradient.M1": [[285, 287], ["optimization.ConjugateGradient.problem.M1"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.M1"], ["", "def", "M1", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "problem", ".", "M1", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradient.M2": [[288, 290], ["optimization.ConjugateGradient.problem.M2"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.M2"], ["", "def", "M2", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "problem", ".", "M2", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GaussNewtonCG.__init__": [[296, 317], ["optimization.ConjugateGradientBase.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "problem", ":", "L2Problem", ",", "variable", ":", "TensorList", ",", "cg_eps", "=", "0.0", ",", "fletcher_reeves", "=", "True", ",", "\n", "standard_alpha", "=", "True", ",", "direction_forget_factor", "=", "0", ",", "debug", "=", "False", ",", "analyze", "=", "False", ",", "plotting", "=", "False", ",", "\n", "visdom", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "fletcher_reeves", ",", "standard_alpha", ",", "direction_forget_factor", ",", "debug", "or", "analyze", "or", "plotting", ")", "\n", "\n", "self", ".", "problem", "=", "problem", "\n", "self", ".", "x", "=", "variable", "\n", "\n", "self", ".", "analyze_convergence", "=", "analyze", "\n", "self", ".", "plotting", "=", "plotting", "\n", "self", ".", "fig_num", "=", "(", "10", ",", "11", ",", "12", ")", "\n", "self", ".", "visdom", "=", "visdom", "\n", "\n", "self", ".", "cg_eps", "=", "cg_eps", "\n", "self", ".", "f0", "=", "None", "\n", "self", ".", "g", "=", "None", "\n", "self", ".", "dfdxt_g", "=", "None", "\n", "\n", "self", ".", "residuals", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "self", ".", "losses", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "self", ".", "gradient_mags", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GaussNewtonCG.clear_temp": [[318, 322], ["None"], "methods", ["None"], ["", "def", "clear_temp", "(", "self", ")", ":", "\n", "        ", "self", ".", "f0", "=", "None", "\n", "self", ".", "g", "=", "None", "\n", "self", ".", "dfdxt_g", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GaussNewtonCG.run_GN": [[324, 326], ["optimization.GaussNewtonCG.run"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.run"], ["", "def", "run_GN", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "run", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GaussNewtonCG.run": [[328, 375], ["isinstance", "len", "optimization.GaussNewtonCG.x.detach_", "optimization.GaussNewtonCG.clear_temp", "optimization.GaussNewtonCG.evaluate_CG_iteration", "optimization.GaussNewtonCG.run_GN_iter", "ValueError", "optimization.GaussNewtonCG.problem", "optimization.GaussNewtonCG.problem.ip_output", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "optimization.GaussNewtonCG.visdom.register", "optimization.GaussNewtonCG.visdom.register", "optimization.GaussNewtonCG.visdom.register", "pytracking.utils.plotting.plot_graph", "pytracking.utils.plotting.plot_graph", "optimization.GaussNewtonCG.detach().cpu().view", "pytracking.utils.plotting.plot_graph", "optimization.GaussNewtonCG.detach().cpu", "optimization.GaussNewtonCG.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescent.clear_temp", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.evaluate_CG_iteration", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GaussNewtonCG.run_GN_iter", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.ip_output", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph"], ["", "def", "run", "(", "self", ",", "num_cg_iter", ",", "num_gn_iter", "=", "None", ")", ":", "\n", "        ", "\"\"\"Run the optimizer.\n        args:\n            num_cg_iter: Number of CG iterations per GN iter. If list, then each entry specifies number of CG iterations\n                         and number of GN iterations is given by the length of the list.\n            num_gn_iter: Number of GN iterations. Shall only be given if num_cg_iter is an integer.\n        \"\"\"", "\n", "\n", "if", "isinstance", "(", "num_cg_iter", ",", "int", ")", ":", "\n", "            ", "if", "num_gn_iter", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "'Must specify number of GN iter if CG iter is constant'", ")", "\n", "", "num_cg_iter", "=", "[", "num_cg_iter", "]", "*", "num_gn_iter", "\n", "\n", "", "num_gn_iter", "=", "len", "(", "num_cg_iter", ")", "\n", "if", "num_gn_iter", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "if", "self", ".", "analyze_convergence", ":", "\n", "            ", "self", ".", "evaluate_CG_iteration", "(", "0", ")", "\n", "\n", "# Outer loop for running the GN iterations.", "\n", "", "for", "cg_iter", "in", "num_cg_iter", ":", "\n", "            ", "self", ".", "run_GN_iter", "(", "cg_iter", ")", "\n", "\n", "", "if", "self", ".", "debug", ":", "\n", "            ", "if", "not", "self", ".", "analyze_convergence", ":", "\n", "                ", "self", ".", "f0", "=", "self", ".", "problem", "(", "self", ".", "x", ")", "\n", "loss", "=", "self", ".", "problem", ".", "ip_output", "(", "self", ".", "f0", ",", "self", ".", "f0", ")", "\n", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                ", "self", ".", "visdom", ".", "register", "(", "self", ".", "losses", ",", "'lineplot'", ",", "3", ",", "'Loss'", ")", "\n", "self", ".", "visdom", ".", "register", "(", "self", ".", "residuals", ",", "'lineplot'", ",", "3", ",", "'CG residuals'", ")", "\n", "\n", "if", "self", ".", "analyze_convergence", ":", "\n", "                    ", "self", ".", "visdom", ".", "register", "(", "self", ".", "gradient_mags", ",", "'lineplot'", ",", "4", ",", "'Gradient magnitude'", ")", "\n", "", "", "elif", "self", ".", "plotting", ":", "\n", "                ", "plot_graph", "(", "self", ".", "losses", ",", "self", ".", "fig_num", "[", "0", "]", ",", "title", "=", "'Loss'", ")", "\n", "plot_graph", "(", "self", ".", "residuals", ",", "self", ".", "fig_num", "[", "1", "]", ",", "title", "=", "'CG residuals'", ")", "\n", "if", "self", ".", "analyze_convergence", ":", "\n", "                    ", "plot_graph", "(", "self", ".", "gradient_mags", ",", "self", ".", "fig_num", "[", "2", "]", ",", "'Gradient magnitude'", ")", "\n", "\n", "\n", "", "", "", "self", ".", "x", ".", "detach_", "(", ")", "\n", "self", ".", "clear_temp", "(", ")", "\n", "\n", "return", "self", ".", "losses", ",", "self", ".", "residuals", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GaussNewtonCG.run_GN_iter": [[377, 408], ["optimization.GaussNewtonCG.x.requires_grad_", "optimization.GaussNewtonCG.problem", "optimization.GaussNewtonCG.f0.detach", "optimization.GaussNewtonCG.g.requires_grad_", "pytracking.libs.TensorList", "optimization.GaussNewtonCG.run_CG", "optimization.GaussNewtonCG.x.detach_", "optimization.GaussNewtonCG.problem.ip_output", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "optimization.GaussNewtonCG.dfdxt_g.detach", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "optimization.GaussNewtonCG.detach().cpu().view", "optimization.GaussNewtonCG.detach().cpu", "optimization.GaussNewtonCG.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.run_CG", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.ip_output"], ["", "def", "run_GN_iter", "(", "self", ",", "num_cg_iter", ")", ":", "\n", "        ", "\"\"\"Runs a single GN iteration.\"\"\"", "\n", "\n", "self", ".", "x", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "# Evaluate function at current estimate", "\n", "self", ".", "f0", "=", "self", ".", "problem", "(", "self", ".", "x", ")", "\n", "\n", "# Create copy with graph detached", "\n", "self", ".", "g", "=", "self", ".", "f0", ".", "detach", "(", ")", "\n", "\n", "if", "self", ".", "debug", "and", "not", "self", ".", "analyze_convergence", ":", "\n", "            ", "loss", "=", "self", ".", "problem", ".", "ip_output", "(", "self", ".", "g", ",", "self", ".", "g", ")", "\n", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "\n", "", "self", ".", "g", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "# Get df/dx^t @ f0", "\n", "self", ".", "dfdxt_g", "=", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "self", ".", "f0", ",", "self", ".", "x", ",", "self", ".", "g", ",", "create_graph", "=", "True", ")", ")", "\n", "\n", "# Get the right hand side", "\n", "self", ".", "b", "=", "-", "self", ".", "dfdxt_g", ".", "detach", "(", ")", "\n", "\n", "# Run CG", "\n", "delta_x", ",", "res", "=", "self", ".", "run_CG", "(", "num_cg_iter", ",", "eps", "=", "self", ".", "cg_eps", ")", "\n", "\n", "self", ".", "x", ".", "detach_", "(", ")", "\n", "self", ".", "x", "+=", "delta_x", "\n", "\n", "if", "self", ".", "debug", ":", "\n", "            ", "self", ".", "residuals", "=", "torch", ".", "cat", "(", "(", "self", ".", "residuals", ",", "res", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GaussNewtonCG.A": [[410, 413], ["torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "pytracking.libs.TensorList", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad"], "methods", ["None"], ["", "", "def", "A", "(", "self", ",", "x", ")", ":", "\n", "        ", "dfdx_x", "=", "torch", ".", "autograd", ".", "grad", "(", "self", ".", "dfdxt_g", ",", "self", ".", "g", ",", "x", ",", "retain_graph", "=", "True", ")", "\n", "return", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "self", ".", "f0", ",", "self", ".", "x", ",", "dfdx_x", ",", "retain_graph", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GaussNewtonCG.ip": [[414, 416], ["optimization.GaussNewtonCG.problem.ip_input"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.MinimizationProblem.ip_input"], ["", "def", "ip", "(", "self", ",", "a", ",", "b", ")", ":", "\n", "        ", "return", "self", ".", "problem", ".", "ip_input", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GaussNewtonCG.M1": [[417, 419], ["optimization.GaussNewtonCG.problem.M1"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.M1"], ["", "def", "M1", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "problem", ".", "M1", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GaussNewtonCG.M2": [[420, 422], ["optimization.GaussNewtonCG.problem.M2"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.M2"], ["", "def", "M2", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "problem", ".", "M2", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GaussNewtonCG.evaluate_CG_iteration": [[423, 436], ["x.requires_grad_", "optimization.GaussNewtonCG.problem", "optimization.GaussNewtonCG.problem.ip_output", "pytracking.libs.TensorList", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "optimization.GaussNewtonCG.detach().cpu().view", "sum().cpu().sqrt().detach().view", "optimization.GaussNewtonCG.detach().cpu", "sum().cpu().sqrt().detach", "optimization.GaussNewtonCG.detach", "sum().cpu().sqrt", "sum().cpu", "sum", "pytracking.libs.TensorList.view", "pytracking.libs.TensorList.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.ip_output"], ["", "def", "evaluate_CG_iteration", "(", "self", ",", "delta_x", ")", ":", "\n", "        ", "if", "self", ".", "analyze_convergence", ":", "\n", "            ", "x", "=", "(", "self", ".", "x", "+", "delta_x", ")", ".", "detach", "(", ")", "\n", "x", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "# compute loss and gradient", "\n", "f", "=", "self", ".", "problem", "(", "x", ")", "\n", "loss", "=", "self", ".", "problem", ".", "ip_output", "(", "f", ",", "f", ")", "\n", "grad", "=", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "x", ")", ")", "\n", "\n", "# store in the vectors", "\n", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "self", ".", "gradient_mags", "=", "torch", ".", "cat", "(", "(", "self", ".", "gradient_mags", ",", "sum", "(", "grad", ".", "view", "(", "-", "1", ")", "@", "grad", ".", "view", "(", "-", "1", ")", ")", ".", "cpu", "(", ")", ".", "sqrt", "(", ")", ".", "detach", "(", ")", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescentL2.__init__": [[441, 458], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "optimization.GradientDescentL2.clear_temp"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescent.clear_temp"], ["def", "__init__", "(", "self", ",", "problem", ":", "L2Problem", ",", "variable", ":", "TensorList", ",", "step_length", ":", "float", ",", "momentum", ":", "float", "=", "0.0", ",", "debug", "=", "False", ",", "plotting", "=", "False", ",", "visdom", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "problem", "=", "problem", "\n", "self", ".", "x", "=", "variable", "\n", "\n", "self", ".", "step_legnth", "=", "step_length", "\n", "self", ".", "momentum", "=", "momentum", "\n", "\n", "self", ".", "debug", "=", "debug", "or", "plotting", "\n", "self", ".", "plotting", "=", "plotting", "\n", "self", ".", "fig_num", "=", "(", "10", ",", "11", ")", "\n", "self", ".", "visdom", "=", "visdom", "\n", "self", ".", "losses", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "self", ".", "gradient_mags", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "self", ".", "residuals", "=", "None", "\n", "\n", "self", ".", "clear_temp", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescentL2.clear_temp": [[460, 463], ["None"], "methods", ["None"], ["", "def", "clear_temp", "(", "self", ")", ":", "\n", "        ", "self", ".", "f0", "=", "None", "\n", "self", ".", "dir", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescentL2.run": [[465, 519], ["range", "optimization.GradientDescentL2.x.detach_", "optimization.GradientDescentL2.clear_temp", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "optimization.GradientDescentL2.x.requires_grad_", "optimization.GradientDescentL2.problem", "optimization.GradientDescentL2.problem.ip_output", "pytracking.libs.TensorList", "optimization.GradientDescentL2.x.detach_", "optimization.GradientDescentL2.x.requires_grad_", "optimization.GradientDescentL2.problem", "optimization.GradientDescentL2.problem.ip_output", "pytracking.libs.TensorList", "optimization.GradientDescentL2.problem.ip_output().item", "sum().cpu().sqrt().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "optimization.GradientDescentL2.item", "sum().sqrt().item", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "optimization.GradientDescentL2.visdom.register", "optimization.GradientDescentL2.visdom.register", "optimization.GradientDescentL2.problem.ip_output", "sum().cpu().sqrt", "pytracking.utils.plotting.plot_graph", "pytracking.utils.plotting.plot_graph", "sum().sqrt", "sum().cpu", "sum", "sum", "pytracking.libs.TensorList.view", "pytracking.libs.TensorList.view", "pytracking.libs.TensorList.view", "pytracking.libs.TensorList.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescent.clear_temp", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.ip_output", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.ip_output", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.L2Problem.ip_output", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph"], ["", "def", "run", "(", "self", ",", "num_iter", ",", "dummy", "=", "None", ")", ":", "\n", "\n", "        ", "if", "num_iter", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "lossvec", "=", "None", "\n", "if", "self", ".", "debug", ":", "\n", "            ", "lossvec", "=", "torch", ".", "zeros", "(", "num_iter", "+", "1", ")", "\n", "grad_mags", "=", "torch", ".", "zeros", "(", "num_iter", "+", "1", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "num_iter", ")", ":", "\n", "            ", "self", ".", "x", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "# Evaluate function at current estimate", "\n", "self", ".", "f0", "=", "self", ".", "problem", "(", "self", ".", "x", ")", "\n", "\n", "# Compute loss", "\n", "loss", "=", "self", ".", "problem", ".", "ip_output", "(", "self", ".", "f0", ",", "self", ".", "f0", ")", "\n", "\n", "# Compute grad", "\n", "grad", "=", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "x", ")", ")", "\n", "\n", "# Update direction", "\n", "if", "self", ".", "dir", "is", "None", ":", "\n", "                ", "self", ".", "dir", "=", "grad", "\n", "", "else", ":", "\n", "                ", "self", ".", "dir", "=", "grad", "+", "self", ".", "momentum", "*", "self", ".", "dir", "\n", "\n", "", "self", ".", "x", ".", "detach_", "(", ")", "\n", "self", ".", "x", "-=", "self", ".", "step_legnth", "*", "self", ".", "dir", "\n", "\n", "if", "self", ".", "debug", ":", "\n", "                ", "lossvec", "[", "i", "]", "=", "loss", ".", "item", "(", ")", "\n", "grad_mags", "[", "i", "]", "=", "sum", "(", "grad", ".", "view", "(", "-", "1", ")", "@", "grad", ".", "view", "(", "-", "1", ")", ")", ".", "sqrt", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "", "if", "self", ".", "debug", ":", "\n", "            ", "self", ".", "x", ".", "requires_grad_", "(", "True", ")", "\n", "self", ".", "f0", "=", "self", ".", "problem", "(", "self", ".", "x", ")", "\n", "loss", "=", "self", ".", "problem", ".", "ip_output", "(", "self", ".", "f0", ",", "self", ".", "f0", ")", "\n", "grad", "=", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "x", ")", ")", "\n", "lossvec", "[", "-", "1", "]", "=", "self", ".", "problem", ".", "ip_output", "(", "self", ".", "f0", ",", "self", ".", "f0", ")", ".", "item", "(", ")", "\n", "grad_mags", "[", "-", "1", "]", "=", "sum", "(", "grad", ".", "view", "(", "-", "1", ")", "@", "grad", ".", "view", "(", "-", "1", ")", ")", ".", "cpu", "(", ")", ".", "sqrt", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "lossvec", ")", ")", "\n", "self", ".", "gradient_mags", "=", "torch", ".", "cat", "(", "(", "self", ".", "gradient_mags", ",", "grad_mags", ")", ")", "\n", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                ", "self", ".", "visdom", ".", "register", "(", "self", ".", "losses", ",", "'lineplot'", ",", "3", ",", "'Loss'", ")", "\n", "self", ".", "visdom", ".", "register", "(", "self", ".", "gradient_mags", ",", "'lineplot'", ",", "4", ",", "'Gradient magnitude'", ")", "\n", "", "elif", "self", ".", "plotting", ":", "\n", "                ", "plot_graph", "(", "self", ".", "losses", ",", "self", ".", "fig_num", "[", "0", "]", ",", "title", "=", "'Loss'", ")", "\n", "plot_graph", "(", "self", ".", "gradient_mags", ",", "self", ".", "fig_num", "[", "1", "]", ",", "title", "=", "'Gradient magnitude'", ")", "\n", "\n", "", "", "self", ".", "x", ".", "detach_", "(", ")", "\n", "self", ".", "clear_temp", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.__init__": [[525, 546], ["optimization.ConjugateGradientBase.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "problem", ":", "MinimizationProblem", ",", "variable", ":", "TensorList", ",", "init_hessian_reg", "=", "0.0", ",", "hessian_reg_factor", "=", "1.0", ",", "\n", "cg_eps", "=", "0.0", ",", "fletcher_reeves", "=", "True", ",", "standard_alpha", "=", "True", ",", "direction_forget_factor", "=", "0", ",", "\n", "debug", "=", "False", ",", "analyze", "=", "False", ",", "plotting", "=", "False", ",", "fig_num", "=", "(", "10", ",", "11", ",", "12", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "fletcher_reeves", ",", "standard_alpha", ",", "direction_forget_factor", ",", "debug", "or", "analyze", "or", "plotting", ")", "\n", "\n", "self", ".", "problem", "=", "problem", "\n", "self", ".", "x", "=", "variable", "\n", "\n", "self", ".", "analyze_convergence", "=", "analyze", "\n", "self", ".", "plotting", "=", "plotting", "\n", "self", ".", "fig_num", "=", "fig_num", "\n", "\n", "self", ".", "hessian_reg", "=", "init_hessian_reg", "\n", "self", ".", "hessian_reg_factor", "=", "hessian_reg_factor", "\n", "self", ".", "cg_eps", "=", "cg_eps", "\n", "self", ".", "f0", "=", "None", "\n", "self", ".", "g", "=", "None", "\n", "\n", "self", ".", "residuals", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "self", ".", "losses", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "self", ".", "gradient_mags", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.clear_temp": [[547, 550], ["None"], "methods", ["None"], ["", "def", "clear_temp", "(", "self", ")", ":", "\n", "        ", "self", ".", "f0", "=", "None", "\n", "self", ".", "g", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.run": [[552, 587], ["isinstance", "len", "optimization.NewtonCG.x.detach_", "optimization.NewtonCG.clear_temp", "optimization.NewtonCG.evaluate_CG_iteration", "optimization.NewtonCG.run_newton_iter", "optimization.NewtonCG.problem", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pytracking.utils.plotting.plot_graph", "pytracking.utils.plotting.plot_graph", "pytracking.utils.plotting.plot_graph", "optimization.NewtonCG.detach().cpu().view", "optimization.NewtonCG.detach().cpu", "optimization.NewtonCG.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescent.clear_temp", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.evaluate_CG_iteration", "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.run_newton_iter", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph"], ["", "def", "run", "(", "self", ",", "num_cg_iter", ",", "num_newton_iter", "=", "None", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "num_cg_iter", ",", "int", ")", ":", "\n", "            ", "if", "num_cg_iter", "==", "0", ":", "\n", "                ", "return", "\n", "", "if", "num_newton_iter", "is", "None", ":", "\n", "                ", "num_newton_iter", "=", "1", "\n", "", "num_cg_iter", "=", "[", "num_cg_iter", "]", "*", "num_newton_iter", "\n", "\n", "", "num_newton_iter", "=", "len", "(", "num_cg_iter", ")", "\n", "if", "num_newton_iter", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "if", "self", ".", "analyze_convergence", ":", "\n", "            ", "self", ".", "evaluate_CG_iteration", "(", "0", ")", "\n", "\n", "", "for", "cg_iter", "in", "num_cg_iter", ":", "\n", "            ", "self", ".", "run_newton_iter", "(", "cg_iter", ")", "\n", "self", ".", "hessian_reg", "*=", "self", ".", "hessian_reg_factor", "\n", "\n", "", "if", "self", ".", "debug", ":", "\n", "            ", "if", "not", "self", ".", "analyze_convergence", ":", "\n", "                ", "loss", "=", "self", ".", "problem", "(", "self", ".", "x", ")", "\n", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "\n", "", "if", "self", ".", "plotting", ":", "\n", "                ", "plot_graph", "(", "self", ".", "losses", ",", "self", ".", "fig_num", "[", "0", "]", ",", "title", "=", "'Loss'", ")", "\n", "plot_graph", "(", "self", ".", "residuals", ",", "self", ".", "fig_num", "[", "1", "]", ",", "title", "=", "'CG residuals'", ")", "\n", "if", "self", ".", "analyze_convergence", ":", "\n", "                    ", "plot_graph", "(", "self", ".", "gradient_mags", ",", "self", ".", "fig_num", "[", "2", "]", ",", "'Gradient magnitude'", ")", "\n", "\n", "", "", "", "self", ".", "x", ".", "detach_", "(", ")", "\n", "self", ".", "clear_temp", "(", ")", "\n", "\n", "return", "self", ".", "losses", ",", "self", ".", "residuals", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.run_newton_iter": [[589, 613], ["optimization.NewtonCG.x.requires_grad_", "optimization.NewtonCG.problem", "pytracking.libs.TensorList", "optimization.NewtonCG.run_CG", "optimization.NewtonCG.x.detach_", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "optimization.NewtonCG.g.detach", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "optimization.NewtonCG.f0.detach().cpu().view", "optimization.NewtonCG.f0.detach().cpu", "optimization.NewtonCG.f0.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.ConjugateGradientBase.run_CG"], ["", "def", "run_newton_iter", "(", "self", ",", "num_cg_iter", ")", ":", "\n", "\n", "        ", "self", ".", "x", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "# Evaluate function at current estimate", "\n", "self", ".", "f0", "=", "self", ".", "problem", "(", "self", ".", "x", ")", "\n", "\n", "if", "self", ".", "debug", "and", "not", "self", ".", "analyze_convergence", ":", "\n", "            ", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "self", ".", "f0", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "\n", "# Gradient of loss", "\n", "", "self", ".", "g", "=", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "self", ".", "f0", ",", "self", ".", "x", ",", "create_graph", "=", "True", ")", ")", "\n", "\n", "# Get the right hand side", "\n", "self", ".", "b", "=", "-", "self", ".", "g", ".", "detach", "(", ")", "\n", "\n", "# Run CG", "\n", "delta_x", ",", "res", "=", "self", ".", "run_CG", "(", "num_cg_iter", ",", "eps", "=", "self", ".", "cg_eps", ")", "\n", "\n", "self", ".", "x", ".", "detach_", "(", ")", "\n", "self", ".", "x", "+=", "delta_x", "\n", "\n", "if", "self", ".", "debug", ":", "\n", "            ", "self", ".", "residuals", "=", "torch", ".", "cat", "(", "(", "self", ".", "residuals", ",", "res", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.A": [[615, 617], ["pytracking.libs.TensorList", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad"], "methods", ["None"], ["", "", "def", "A", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "self", ".", "g", ",", "self", ".", "x", ",", "x", ",", "retain_graph", "=", "True", ")", ")", "+", "self", ".", "hessian_reg", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.ip": [[618, 621], ["optimization.NewtonCG.problem.ip_input"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.MinimizationProblem.ip_input"], ["", "def", "ip", "(", "self", ",", "a", ",", "b", ")", ":", "\n", "# Implements the inner product", "\n", "        ", "return", "self", ".", "problem", ".", "ip_input", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.M1": [[622, 624], ["optimization.NewtonCG.problem.M1"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.M1"], ["", "def", "M1", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "problem", ".", "M1", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.M2": [[625, 627], ["optimization.NewtonCG.problem.M2"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.M2"], ["", "def", "M2", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "problem", ".", "M2", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.NewtonCG.evaluate_CG_iteration": [[628, 640], ["x.requires_grad_", "optimization.NewtonCG.problem", "pytracking.libs.TensorList", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "optimization.NewtonCG.detach().cpu().view", "sum().cpu().sqrt().detach().view", "optimization.NewtonCG.detach().cpu", "sum().cpu().sqrt().detach", "optimization.NewtonCG.detach", "sum().cpu().sqrt", "sum().cpu", "sum", "pytracking.libs.TensorList.view", "pytracking.libs.TensorList.view"], "methods", ["None"], ["", "def", "evaluate_CG_iteration", "(", "self", ",", "delta_x", ")", ":", "\n", "        ", "if", "self", ".", "analyze_convergence", ":", "\n", "            ", "x", "=", "(", "self", ".", "x", "+", "delta_x", ")", ".", "detach", "(", ")", "\n", "x", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "# compute loss and gradient", "\n", "loss", "=", "self", ".", "problem", "(", "x", ")", "\n", "grad", "=", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "x", ")", ")", "\n", "\n", "# store in the vectors", "\n", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "loss", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "self", ".", "gradient_mags", "=", "torch", ".", "cat", "(", "(", "self", ".", "gradient_mags", ",", "sum", "(", "grad", ".", "view", "(", "-", "1", ")", "@", "grad", ".", "view", "(", "-", "1", ")", ")", ".", "cpu", "(", ")", ".", "sqrt", "(", ")", ".", "detach", "(", ")", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescent.__init__": [[645, 663], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "optimization.GradientDescent.clear_temp"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescent.clear_temp"], ["def", "__init__", "(", "self", ",", "problem", ":", "MinimizationProblem", ",", "variable", ":", "TensorList", ",", "step_length", ":", "float", ",", "momentum", ":", "float", "=", "0.0", ",", "\n", "debug", "=", "False", ",", "plotting", "=", "False", ",", "fig_num", "=", "(", "10", ",", "11", ")", ")", ":", "\n", "\n", "        ", "self", ".", "problem", "=", "problem", "\n", "self", ".", "x", "=", "variable", "\n", "\n", "self", ".", "step_legnth", "=", "step_length", "\n", "self", ".", "momentum", "=", "momentum", "\n", "\n", "self", ".", "debug", "=", "debug", "or", "plotting", "\n", "self", ".", "plotting", "=", "plotting", "\n", "self", ".", "fig_num", "=", "fig_num", "\n", "\n", "self", ".", "losses", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "self", ".", "gradient_mags", "=", "torch", ".", "zeros", "(", "0", ")", "\n", "self", ".", "residuals", "=", "None", "\n", "\n", "self", ".", "clear_temp", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescent.clear_temp": [[665, 667], ["None"], "methods", ["None"], ["", "def", "clear_temp", "(", "self", ")", ":", "\n", "        ", "self", ".", "dir", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescent.run": [[669, 715], ["range", "optimization.GradientDescent.x.detach_", "optimization.GradientDescent.clear_temp", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "optimization.GradientDescent.x.requires_grad_", "optimization.GradientDescent.problem", "pytracking.libs.TensorList", "optimization.GradientDescent.x.detach_", "optimization.GradientDescent.x.requires_grad_", "optimization.GradientDescent.problem", "pytracking.libs.TensorList", "optimization.GradientDescent.item", "sum().cpu().sqrt().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "optimization.GradientDescent.item", "sum().sqrt().item", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "pytracking.utils.plotting.plot_graph", "pytracking.utils.plotting.plot_graph", "sum().cpu().sqrt", "sum().sqrt", "sum().cpu", "sum", "sum", "pytracking.libs.TensorList.view", "pytracking.libs.TensorList.view", "pytracking.libs.TensorList.view", "pytracking.libs.TensorList.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.optimization.GradientDescent.clear_temp", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.plot_graph"], ["", "def", "run", "(", "self", ",", "num_iter", ",", "dummy", "=", "None", ")", ":", "\n", "\n", "        ", "if", "num_iter", "==", "0", ":", "\n", "            ", "return", "\n", "\n", "", "lossvec", "=", "None", "\n", "if", "self", ".", "debug", ":", "\n", "            ", "lossvec", "=", "torch", ".", "zeros", "(", "num_iter", "+", "1", ")", "\n", "grad_mags", "=", "torch", ".", "zeros", "(", "num_iter", "+", "1", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "num_iter", ")", ":", "\n", "            ", "self", ".", "x", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "# Evaluate function at current estimate", "\n", "loss", "=", "self", ".", "problem", "(", "self", ".", "x", ")", "\n", "\n", "# Compute grad", "\n", "grad", "=", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "x", ")", ")", "\n", "\n", "# Update direction", "\n", "if", "self", ".", "dir", "is", "None", ":", "\n", "                ", "self", ".", "dir", "=", "grad", "\n", "", "else", ":", "\n", "                ", "self", ".", "dir", "=", "grad", "+", "self", ".", "momentum", "*", "self", ".", "dir", "\n", "\n", "", "self", ".", "x", ".", "detach_", "(", ")", "\n", "self", ".", "x", "-=", "self", ".", "step_legnth", "*", "self", ".", "dir", "\n", "\n", "if", "self", ".", "debug", ":", "\n", "                ", "lossvec", "[", "i", "]", "=", "loss", ".", "item", "(", ")", "\n", "grad_mags", "[", "i", "]", "=", "sum", "(", "grad", ".", "view", "(", "-", "1", ")", "@", "grad", ".", "view", "(", "-", "1", ")", ")", ".", "sqrt", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "", "if", "self", ".", "debug", ":", "\n", "            ", "self", ".", "x", ".", "requires_grad_", "(", "True", ")", "\n", "loss", "=", "self", ".", "problem", "(", "self", ".", "x", ")", "\n", "grad", "=", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "x", ")", ")", "\n", "lossvec", "[", "-", "1", "]", "=", "loss", ".", "item", "(", ")", "\n", "grad_mags", "[", "-", "1", "]", "=", "sum", "(", "grad", ".", "view", "(", "-", "1", ")", "@", "grad", ".", "view", "(", "-", "1", ")", ")", ".", "cpu", "(", ")", ".", "sqrt", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "losses", "=", "torch", ".", "cat", "(", "(", "self", ".", "losses", ",", "lossvec", ")", ")", "\n", "self", ".", "gradient_mags", "=", "torch", ".", "cat", "(", "(", "self", ".", "gradient_mags", ",", "grad_mags", ")", ")", "\n", "if", "self", ".", "plotting", ":", "\n", "                ", "plot_graph", "(", "self", ".", "losses", ",", "self", ".", "fig_num", "[", "0", "]", ",", "title", "=", "'Loss'", ")", "\n", "plot_graph", "(", "self", ".", "gradient_mags", ",", "self", ".", "fig_num", "[", "1", "]", ",", "title", "=", "'Gradient magnitude'", ")", "\n", "\n", "", "", "self", ".", "x", ".", "detach_", "(", ")", "\n", "self", ".", "clear_temp", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_complex": [[5, 7], ["a.dim"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["def", "is_complex", "(", "a", ":", "torch", ".", "Tensor", ")", "->", "bool", ":", "\n", "    ", "return", "a", ".", "dim", "(", ")", ">=", "4", "and", "a", ".", "shape", "[", "-", "1", "]", "==", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real": [[9, 11], ["complex.is_complex"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_complex"], ["", "def", "is_real", "(", "a", ":", "torch", ".", "Tensor", ")", "->", "bool", ":", "\n", "    ", "return", "not", "is_complex", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult": [[13, 33], ["complex.is_real", "complex.is_real", "complex.mult_real_cplx", "complex.mult_real_cplx", "complex.mult_real_cplx", "a.dim", "b.dim", "ValueError", "b.dim", "a.dim", "ValueError"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult_real_cplx", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult_real_cplx", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult_real_cplx", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "@", "tensor_operation", "\n", "def", "mult", "(", "a", ":", "torch", ".", "Tensor", ",", "b", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Pointwise complex multiplication of complex tensors.\"\"\"", "\n", "\n", "if", "is_real", "(", "a", ")", ":", "\n", "        ", "if", "a", ".", "dim", "(", ")", ">=", "b", ".", "dim", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Incorrect dimensions.'", ")", "\n", "# a is real", "\n", "", "return", "mult_real_cplx", "(", "a", ",", "b", ")", "\n", "", "if", "is_real", "(", "b", ")", ":", "\n", "        ", "if", "b", ".", "dim", "(", ")", ">=", "a", ".", "dim", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Incorrect dimensions.'", ")", "\n", "# b is real", "\n", "", "return", "mult_real_cplx", "(", "b", ",", "a", ")", "\n", "\n", "# Both complex", "\n", "", "c", "=", "mult_real_cplx", "(", "a", "[", "...", ",", "0", "]", ",", "b", ")", "\n", "c", "[", "...", ",", "0", "]", "-=", "a", "[", "...", ",", "1", "]", "*", "b", "[", "...", ",", "1", "]", "\n", "c", "[", "...", ",", "1", "]", "+=", "a", "[", "...", ",", "1", "]", "*", "b", "[", "...", ",", "0", "]", "\n", "return", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult_conj": [[35, 55], ["complex.is_real", "complex.is_real", "complex.mult_real_cplx", "complex.mult_real_cplx", "complex.mult_real_cplx", "a.dim", "b.dim", "ValueError", "complex.conj", "b.dim", "a.dim", "ValueError"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult_real_cplx", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult_real_cplx", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult_real_cplx", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.conj", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "@", "tensor_operation", "\n", "def", "mult_conj", "(", "a", ":", "torch", ".", "Tensor", ",", "b", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Pointwise complex multiplication of complex tensors, with conjugate on b: a*conj(b).\"\"\"", "\n", "\n", "if", "is_real", "(", "a", ")", ":", "\n", "        ", "if", "a", ".", "dim", "(", ")", ">=", "b", ".", "dim", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Incorrect dimensions.'", ")", "\n", "# a is real", "\n", "", "return", "mult_real_cplx", "(", "a", ",", "conj", "(", "b", ")", ")", "\n", "", "if", "is_real", "(", "b", ")", ":", "\n", "        ", "if", "b", ".", "dim", "(", ")", ">=", "a", ".", "dim", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Incorrect dimensions.'", ")", "\n", "# b is real", "\n", "", "return", "mult_real_cplx", "(", "b", ",", "a", ")", "\n", "\n", "# Both complex", "\n", "", "c", "=", "mult_real_cplx", "(", "b", "[", "...", ",", "0", "]", ",", "a", ")", "\n", "c", "[", "...", ",", "0", "]", "+=", "a", "[", "...", ",", "1", "]", "*", "b", "[", "...", ",", "1", "]", "\n", "c", "[", "...", ",", "1", "]", "-=", "a", "[", "...", ",", "0", "]", "*", "b", "[", "...", ",", "1", "]", "\n", "return", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult_real_cplx": [[57, 65], ["complex.is_real", "ValueError", "a.unsqueeze"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real"], ["", "@", "tensor_operation", "\n", "def", "mult_real_cplx", "(", "a", ":", "torch", ".", "Tensor", ",", "b", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Pointwise complex multiplication of real tensor a with complex tensor b.\"\"\"", "\n", "\n", "if", "is_real", "(", "b", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Last dimension must have length 2.'", ")", "\n", "\n", "", "return", "a", ".", "unsqueeze", "(", "-", "1", ")", "*", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.div": [[67, 78], ["complex.is_real", "complex.div_cplx_real", "complex.div_cplx_real", "complex.mult_conj", "complex.abs_sqr", "b.dim", "a.dim", "ValueError"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.div_cplx_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.div_cplx_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult_conj", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs_sqr", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "@", "tensor_operation", "\n", "def", "div", "(", "a", ":", "torch", ".", "Tensor", ",", "b", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Pointwise complex division of complex tensors.\"\"\"", "\n", "\n", "if", "is_real", "(", "b", ")", ":", "\n", "        ", "if", "b", ".", "dim", "(", ")", ">=", "a", ".", "dim", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Incorrect dimensions.'", ")", "\n", "# b is real", "\n", "", "return", "div_cplx_real", "(", "a", ",", "b", ")", "\n", "\n", "", "return", "div_cplx_real", "(", "mult_conj", "(", "a", ",", "b", ")", ",", "abs_sqr", "(", "b", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.div_cplx_real": [[80, 88], ["complex.is_real", "ValueError", "b.unsqueeze"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real"], ["", "@", "tensor_operation", "\n", "def", "div_cplx_real", "(", "a", ":", "torch", ".", "Tensor", ",", "b", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Pointwise complex division of complex tensor a with real tensor b.\"\"\"", "\n", "\n", "if", "is_real", "(", "a", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Last dimension must have length 2.'", ")", "\n", "\n", "", "return", "a", "/", "b", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs_sqr": [[90, 98], ["complex.is_real", "torch.sum", "ValueError"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real"], ["", "@", "tensor_operation", "\n", "def", "abs_sqr", "(", "a", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Squared absolute value.\"\"\"", "\n", "\n", "if", "is_real", "(", "a", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Last dimension must have length 2.'", ")", "\n", "\n", "", "return", "torch", ".", "sum", "(", "a", "*", "a", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs": [[100, 108], ["complex.is_real", "torch.sqrt", "ValueError", "complex.abs_sqr"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs_sqr"], ["", "@", "tensor_operation", "\n", "def", "abs", "(", "a", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Absolute value.\"\"\"", "\n", "\n", "if", "is_real", "(", "a", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Last dimension must have length 2.'", ")", "\n", "\n", "", "return", "torch", ".", "sqrt", "(", "abs_sqr", "(", "a", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.conj": [[110, 119], ["complex.is_real", "complex.complex", "ValueError"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.complex"], ["", "@", "tensor_operation", "\n", "def", "conj", "(", "a", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Complex conjugate.\"\"\"", "\n", "\n", "if", "is_real", "(", "a", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Last dimension must have length 2.'", ")", "\n", "\n", "# return a * torch.Tensor([1, -1], device=a.device)", "\n", "", "return", "complex", "(", "a", "[", "...", ",", "0", "]", ",", "-", "a", "[", "...", ",", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.real": [[121, 129], ["complex.is_real", "ValueError"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real"], ["", "@", "tensor_operation", "\n", "def", "real", "(", "a", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Real part.\"\"\"", "\n", "\n", "if", "is_real", "(", "a", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Last dimension must have length 2.'", ")", "\n", "\n", "", "return", "a", "[", "...", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.imag": [[131, 139], ["complex.is_real", "ValueError"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real"], ["", "@", "tensor_operation", "\n", "def", "imag", "(", "a", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Imaginary part.\"\"\"", "\n", "\n", "if", "is_real", "(", "a", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Last dimension must have length 2.'", ")", "\n", "\n", "", "return", "a", "[", "...", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.complex": [[141, 151], ["torch.cat", "b.new_zeros.new_zeros", "a.new_zeros.new_zeros", "b.new_zeros.unsqueeze", "a.new_zeros.unsqueeze"], "function", ["None"], ["", "@", "tensor_operation", "\n", "def", "complex", "(", "a", ":", "torch", ".", "Tensor", ",", "b", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "    ", "\"\"\"Create complex tensor from real and imaginary part.\"\"\"", "\n", "\n", "if", "b", "is", "None", ":", "\n", "        ", "b", "=", "a", ".", "new_zeros", "(", "a", ".", "shape", ")", "\n", "", "elif", "a", "is", "None", ":", "\n", "        ", "a", "=", "b", ".", "new_zeros", "(", "b", ".", "shape", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "(", "a", ".", "unsqueeze", "(", "-", "1", ")", ",", "b", ".", "unsqueeze", "(", "-", "1", ")", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mtimes": [[153, 179], ["complex.is_real", "complex.is_real", "complex.mtimes_real_complex", "complex.mtimes_complex_real", "complex.complex", "complex.complex", "complex.complex", "complex.complex", "a.dim", "b.dim", "ValueError", "b.dim", "a.dim", "ValueError", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mtimes_real_complex", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mtimes_complex_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.complex", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.complex", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.complex", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.complex", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "@", "tensor_operation", "\n", "def", "mtimes", "(", "a", ":", "torch", ".", "Tensor", ",", "b", ":", "torch", ".", "Tensor", ",", "conj_a", "=", "False", ",", "conj_b", "=", "False", ")", ":", "\n", "    ", "\"\"\"Complex matrix multiplication of complex tensors.\n    The dimensions (-3, -2) are matrix multiplied. -1 is the complex dimension.\"\"\"", "\n", "\n", "if", "is_real", "(", "a", ")", ":", "\n", "        ", "if", "a", ".", "dim", "(", ")", ">=", "b", ".", "dim", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Incorrect dimensions.'", ")", "\n", "", "return", "mtimes_real_complex", "(", "a", ",", "b", ",", "conj_b", "=", "conj_b", ")", "\n", "", "if", "is_real", "(", "b", ")", ":", "\n", "        ", "if", "b", ".", "dim", "(", ")", ">=", "a", ".", "dim", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'Incorrect dimensions.'", ")", "\n", "", "return", "mtimes_complex_real", "(", "a", ",", "b", ",", "conj_a", "=", "conj_a", ")", "\n", "\n", "", "if", "not", "conj_a", "and", "not", "conj_b", ":", "\n", "        ", "return", "complex", "(", "torch", ".", "matmul", "(", "a", "[", "...", ",", "0", "]", ",", "b", "[", "...", ",", "0", "]", ")", "-", "torch", ".", "matmul", "(", "a", "[", "...", ",", "1", "]", ",", "b", "[", "...", ",", "1", "]", ")", ",", "\n", "torch", ".", "matmul", "(", "a", "[", "...", ",", "0", "]", ",", "b", "[", "...", ",", "1", "]", ")", "+", "torch", ".", "matmul", "(", "a", "[", "...", ",", "1", "]", ",", "b", "[", "...", ",", "0", "]", ")", ")", "\n", "", "if", "conj_a", "and", "not", "conj_b", ":", "\n", "        ", "return", "complex", "(", "torch", ".", "matmul", "(", "a", "[", "...", ",", "0", "]", ",", "b", "[", "...", ",", "0", "]", ")", "+", "torch", ".", "matmul", "(", "a", "[", "...", ",", "1", "]", ",", "b", "[", "...", ",", "1", "]", ")", ",", "\n", "torch", ".", "matmul", "(", "a", "[", "...", ",", "0", "]", ",", "b", "[", "...", ",", "1", "]", ")", "-", "torch", ".", "matmul", "(", "a", "[", "...", ",", "1", "]", ",", "b", "[", "...", ",", "0", "]", ")", ")", "\n", "", "if", "not", "conj_a", "and", "conj_b", ":", "\n", "        ", "return", "complex", "(", "torch", ".", "matmul", "(", "a", "[", "...", ",", "0", "]", ",", "b", "[", "...", ",", "0", "]", ")", "+", "torch", ".", "matmul", "(", "a", "[", "...", ",", "1", "]", ",", "b", "[", "...", ",", "1", "]", ")", ",", "\n", "torch", ".", "matmul", "(", "a", "[", "...", ",", "1", "]", ",", "b", "[", "...", ",", "0", "]", ")", "-", "torch", ".", "matmul", "(", "a", "[", "...", ",", "0", "]", ",", "b", "[", "...", ",", "1", "]", ")", ")", "\n", "", "if", "conj_a", "and", "conj_b", ":", "\n", "        ", "return", "complex", "(", "torch", ".", "matmul", "(", "a", "[", "...", ",", "0", "]", ",", "b", "[", "...", ",", "0", "]", ")", "-", "torch", ".", "matmul", "(", "a", "[", "...", ",", "1", "]", ",", "b", "[", "...", ",", "1", "]", ")", ",", "\n", "-", "torch", ".", "matmul", "(", "a", "[", "...", ",", "0", "]", ",", "b", "[", "...", ",", "1", "]", ")", "-", "torch", ".", "matmul", "(", "a", "[", "...", ",", "1", "]", ",", "b", "[", "...", ",", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mtimes_real_complex": [[181, 190], ["complex.is_real", "ValueError", "complex.complex", "complex.complex", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.complex", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.complex"], ["", "", "@", "tensor_operation", "\n", "def", "mtimes_real_complex", "(", "a", ":", "torch", ".", "Tensor", ",", "b", ":", "torch", ".", "Tensor", ",", "conj_b", "=", "False", ")", ":", "\n", "    ", "if", "is_real", "(", "b", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Incorrect dimensions.'", ")", "\n", "\n", "", "if", "not", "conj_b", ":", "\n", "        ", "return", "complex", "(", "torch", ".", "matmul", "(", "a", ",", "b", "[", "...", ",", "0", "]", ")", ",", "torch", ".", "matmul", "(", "a", ",", "b", "[", "...", ",", "1", "]", ")", ")", "\n", "", "if", "conj_b", ":", "\n", "        ", "return", "complex", "(", "torch", ".", "matmul", "(", "a", ",", "b", "[", "...", ",", "0", "]", ")", ",", "-", "torch", ".", "matmul", "(", "a", ",", "b", "[", "...", ",", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mtimes_complex_real": [[192, 201], ["complex.is_real", "ValueError", "complex.complex", "complex.complex", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.is_real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.complex", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.complex"], ["", "", "@", "tensor_operation", "\n", "def", "mtimes_complex_real", "(", "a", ":", "torch", ".", "Tensor", ",", "b", ":", "torch", ".", "Tensor", ",", "conj_a", "=", "False", ")", ":", "\n", "    ", "if", "is_real", "(", "a", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Incorrect dimensions.'", ")", "\n", "\n", "", "if", "not", "conj_a", ":", "\n", "        ", "return", "complex", "(", "torch", ".", "matmul", "(", "a", "[", "...", ",", "0", "]", ",", "b", ")", ",", "torch", ".", "matmul", "(", "a", "[", "...", ",", "1", "]", ",", "b", ")", ")", "\n", "", "if", "conj_a", ":", "\n", "        ", "return", "complex", "(", "torch", ".", "matmul", "(", "a", "[", "...", ",", "0", "]", ",", "b", ")", ",", "-", "torch", ".", "matmul", "(", "a", "[", "...", ",", "1", "]", ",", "b", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.exp_imag": [[203, 209], ["a.unsqueeze.unsqueeze", "torch.cat", "torch.cos", "torch.sin"], "function", ["None"], ["", "", "@", "tensor_operation", "\n", "def", "exp_imag", "(", "a", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Complex exponential with imaginary input: e^(i*a)\"\"\"", "\n", "\n", "a", "=", "a", ".", "unsqueeze", "(", "-", "1", ")", "\n", "return", "torch", ".", "cat", "(", "(", "torch", ".", "cos", "(", "a", ")", ",", "torch", ".", "sin", "(", "a", ")", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensordict.TensorDict.concat": [[9, 12], ["tensordict.TensorDict"], "methods", ["None"], ["def", "concat", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\"Concatenates two dicts without copying internal data.\"\"\"", "\n", "return", "TensorDict", "(", "self", ",", "**", "other", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensordict.TensorDict.copy": [[13, 15], ["tensordict.TensorDict", "super().copy"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "return", "TensorDict", "(", "super", "(", "TensorDict", ",", "self", ")", ".", "copy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensordict.TensorDict.__deepcopy__": [[16, 18], ["tensordict.TensorDict", "copy.deepcopy", "list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "__deepcopy__", "(", "self", ",", "memodict", "=", "{", "}", ")", ":", "\n", "        ", "return", "TensorDict", "(", "copy", ".", "deepcopy", "(", "list", "(", "self", ")", ",", "memodict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensordict.TensorDict.__getattr__": [[19, 26], ["hasattr", "AttributeError", "tensordict.TensorDict", "hasattr", "tensordict.TensorDict.items", "getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "torch", ".", "Tensor", ",", "name", ")", ":", "\n", "            ", "raise", "AttributeError", "(", "'\\'TensorDict\\' object has not attribute \\'{}\\''", ".", "format", "(", "name", ")", ")", "\n", "\n", "", "def", "apply_attr", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "TensorDict", "(", "{", "n", ":", "getattr", "(", "e", ",", "name", ")", "(", "*", "args", ",", "**", "kwargs", ")", "if", "hasattr", "(", "e", ",", "name", ")", "else", "e", "for", "n", ",", "e", "in", "self", ".", "items", "(", ")", "}", ")", "\n", "", "return", "apply_attr", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensordict.TensorDict.attribute": [[27, 29], ["tensordict.TensorDict", "getattr", "tensordict.TensorDict.items"], "methods", ["None"], ["", "def", "attribute", "(", "self", ",", "attr", ":", "str", ",", "*", "args", ")", ":", "\n", "        ", "return", "TensorDict", "(", "{", "n", ":", "getattr", "(", "e", ",", "attr", ",", "*", "args", ")", "for", "n", ",", "e", "in", "self", ".", "items", "(", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensordict.TensorDict.apply": [[30, 32], ["tensordict.TensorDict", "fn", "tensordict.TensorDict.items"], "methods", ["None"], ["", "def", "apply", "(", "self", ",", "fn", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "TensorDict", "(", "{", "n", ":", "fn", "(", "e", ",", "*", "args", ",", "**", "kwargs", ")", "for", "n", ",", "e", "in", "self", ".", "items", "(", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensordict.TensorDict._iterable": [[33, 36], ["isinstance"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_iterable", "(", "a", ")", ":", "\n", "        ", "return", "isinstance", "(", "a", ",", "(", "TensorDict", ",", "list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__init__": [[9, 13], ["list.__init__", "tensorlist.TensorList.list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["def", "__init__", "(", "self", ",", "list_of_tensors", "=", "None", ")", ":", "\n", "        ", "if", "list_of_tensors", "is", "None", ":", "\n", "            ", "list_of_tensors", "=", "list", "(", ")", "\n", "", "super", "(", "TensorList", ",", "self", ")", ".", "__init__", "(", "list_of_tensors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__deepcopy__": [[14, 16], ["tensorlist.TensorList", "copy.deepcopy", "tensorlist.TensorList.list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "__deepcopy__", "(", "self", ",", "memodict", "=", "{", "}", ")", ":", "\n", "        ", "return", "TensorList", "(", "copy", ".", "deepcopy", "(", "list", "(", "self", ")", ",", "memodict", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__getitem__": [[17, 24], ["isinstance", "list.__getitem__", "isinstance", "tensorlist.TensorList", "tensorlist.TensorList", "list.__getitem__", "list.__getitem__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler.__getitem__", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler.__getitem__", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "if", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "return", "super", "(", "TensorList", ",", "self", ")", ".", "__getitem__", "(", "item", ")", "\n", "", "elif", "isinstance", "(", "item", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "super", "(", "TensorList", ",", "self", ")", ".", "__getitem__", "(", "i", ")", "for", "i", "in", "item", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "TensorList", "(", "super", "(", "TensorList", ",", "self", ")", ".", "__getitem__", "(", "item", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__add__": [[25, 29], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "", "def", "__add__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e1", "+", "e2", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "e", "+", "other", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__radd__": [[30, 34], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__radd__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e2", "+", "e1", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "other", "+", "e", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__iadd__": [[35, 43], ["tensorlist.TensorList._iterable", "enumerate", "range", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__iadd__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "for", "i", ",", "e2", "in", "enumerate", "(", "other", ")", ":", "\n", "                ", "self", "[", "i", "]", "+=", "e2", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "                ", "self", "[", "i", "]", "+=", "other", "\n", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__sub__": [[44, 48], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__sub__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e1", "-", "e2", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "e", "-", "other", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__rsub__": [[49, 53], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__rsub__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e2", "-", "e1", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "other", "-", "e", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__isub__": [[54, 62], ["tensorlist.TensorList._iterable", "enumerate", "range", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__isub__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "for", "i", ",", "e2", "in", "enumerate", "(", "other", ")", ":", "\n", "                ", "self", "[", "i", "]", "-=", "e2", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "                ", "self", "[", "i", "]", "-=", "other", "\n", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__mul__": [[63, 67], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__mul__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e1", "*", "e2", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "e", "*", "other", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__rmul__": [[68, 72], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__rmul__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e2", "*", "e1", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "other", "*", "e", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__imul__": [[73, 81], ["tensorlist.TensorList._iterable", "enumerate", "range", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__imul__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "for", "i", ",", "e2", "in", "enumerate", "(", "other", ")", ":", "\n", "                ", "self", "[", "i", "]", "*=", "e2", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "                ", "self", "[", "i", "]", "*=", "other", "\n", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__truediv__": [[82, 86], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__truediv__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e1", "/", "e2", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "e", "/", "other", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__rtruediv__": [[87, 91], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__rtruediv__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e2", "/", "e1", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "other", "/", "e", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__itruediv__": [[92, 100], ["tensorlist.TensorList._iterable", "enumerate", "range", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__itruediv__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "for", "i", ",", "e2", "in", "enumerate", "(", "other", ")", ":", "\n", "                ", "self", "[", "i", "]", "/=", "e2", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "                ", "self", "[", "i", "]", "/=", "other", "\n", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__matmul__": [[101, 105], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__matmul__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e1", "@", "e2", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "e", "@", "other", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__rmatmul__": [[106, 110], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__rmatmul__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e2", "@", "e1", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "other", "@", "e", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__imatmul__": [[111, 119], ["tensorlist.TensorList._iterable", "enumerate", "range", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__imatmul__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "for", "i", ",", "e2", "in", "enumerate", "(", "other", ")", ":", "\n", "                ", "self", "[", "i", "]", "@=", "e2", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "                ", "self", "[", "i", "]", "@=", "other", "\n", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__mod__": [[120, 124], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__mod__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e1", "%", "e2", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "e", "%", "other", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__rmod__": [[125, 129], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__rmod__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e2", "%", "e1", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "other", "%", "e", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__pos__": [[130, 132], ["tensorlist.TensorList"], "methods", ["None"], ["", "def", "__pos__", "(", "self", ")", ":", "\n", "        ", "return", "TensorList", "(", "[", "+", "e", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__neg__": [[133, 135], ["tensorlist.TensorList"], "methods", ["None"], ["", "def", "__neg__", "(", "self", ")", ":", "\n", "        ", "return", "TensorList", "(", "[", "-", "e", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__le__": [[136, 140], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__le__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e1", "<=", "e2", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "e", "<=", "other", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__ge__": [[141, 145], ["tensorlist.TensorList._iterable", "tensorlist.TensorList", "tensorlist.TensorList", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable"], ["", "def", "__ge__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "TensorList", ".", "_iterable", "(", "other", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "e1", ">=", "e2", "for", "e1", ",", "e2", "in", "zip", "(", "self", ",", "other", ")", "]", ")", "\n", "", "return", "TensorList", "(", "[", "e", ">=", "other", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.concat": [[146, 148], ["tensorlist.TensorList", "list.__add__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.__add__"], ["", "def", "concat", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "TensorList", "(", "super", "(", "TensorList", ",", "self", ")", ".", "__add__", "(", "other", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.copy": [[149, 151], ["tensorlist.TensorList", "super().copy"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "return", "TensorList", "(", "super", "(", "TensorList", ",", "self", ")", ".", "copy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.unroll": [[152, 163], ["tensorlist.TensorList", "any", "isinstance", "TensorList.extend", "TensorList.append", "isinstance", "t.unroll"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.unroll"], ["", "def", "unroll", "(", "self", ")", ":", "\n", "        ", "if", "not", "any", "(", "isinstance", "(", "t", ",", "TensorList", ")", "for", "t", "in", "self", ")", ":", "\n", "            ", "return", "self", "\n", "\n", "", "new_list", "=", "TensorList", "(", ")", "\n", "for", "t", "in", "self", ":", "\n", "            ", "if", "isinstance", "(", "t", ",", "TensorList", ")", ":", "\n", "                ", "new_list", ".", "extend", "(", "t", ".", "unroll", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "new_list", ".", "append", "(", "t", ")", "\n", "", "", "return", "new_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list": [[164, 166], ["tensorlist.TensorList.list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "list", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.attribute": [[167, 169], ["tensorlist.TensorList", "getattr"], "methods", ["None"], ["", "def", "attribute", "(", "self", ",", "attr", ":", "str", ",", "*", "args", ")", ":", "\n", "        ", "return", "TensorList", "(", "[", "getattr", "(", "e", ",", "attr", ",", "*", "args", ")", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply": [[170, 172], ["tensorlist.TensorList", "fn"], "methods", ["None"], ["", "def", "apply", "(", "self", ",", "fn", ")", ":", "\n", "        ", "return", "TensorList", "(", "[", "fn", "(", "e", ")", "for", "e", "in", "self", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.__getattr__": [[173, 181], ["hasattr", "AttributeError", "tensorlist.TensorList", "getattr"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "not", "hasattr", "(", "torch", ".", "Tensor", ",", "name", ")", ":", "\n", "            ", "raise", "AttributeError", "(", "'\\'TensorList\\' object has not attribute \\'{}\\''", ".", "format", "(", "name", ")", ")", "\n", "\n", "", "def", "apply_attr", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "TensorList", "(", "[", "getattr", "(", "e", ",", "name", ")", "(", "*", "args", ",", "**", "kwargs", ")", "for", "e", "in", "self", "]", ")", "\n", "\n", "", "return", "apply_attr", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList._iterable": [[182, 185], ["isinstance"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_iterable", "(", "a", ")", ":", "\n", "        ", "return", "isinstance", "(", "a", ",", "(", "TensorList", ",", "list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.tensor_operation": [[188, 213], ["functools.wraps", "isinstance", "op", "len", "ValueError", "len", "tensorlist.tensor_operation.islist"], "function", ["None"], ["", "", "def", "tensor_operation", "(", "op", ")", ":", "\n", "    ", "def", "islist", "(", "a", ")", ":", "\n", "        ", "return", "isinstance", "(", "a", ",", "TensorList", ")", "\n", "\n", "", "@", "functools", ".", "wraps", "(", "op", ")", "\n", "def", "oplist", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "len", "(", "args", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'Must be at least one argument without keyword (i.e. operand).'", ")", "\n", "\n", "", "if", "len", "(", "args", ")", "==", "1", ":", "\n", "            ", "if", "islist", "(", "args", "[", "0", "]", ")", ":", "\n", "                ", "return", "TensorList", "(", "[", "op", "(", "a", ",", "**", "kwargs", ")", "for", "a", "in", "args", "[", "0", "]", "]", ")", "\n", "", "", "else", ":", "\n", "# Multiple operands, assume max two", "\n", "            ", "if", "islist", "(", "args", "[", "0", "]", ")", "and", "islist", "(", "args", "[", "1", "]", ")", ":", "\n", "                ", "return", "TensorList", "(", "[", "op", "(", "a", ",", "b", ",", "*", "args", "[", "2", ":", "]", ",", "**", "kwargs", ")", "for", "a", ",", "b", "in", "zip", "(", "*", "args", "[", ":", "2", "]", ")", "]", ")", "\n", "", "if", "islist", "(", "args", "[", "0", "]", ")", ":", "\n", "                ", "return", "TensorList", "(", "[", "op", "(", "a", ",", "*", "args", "[", "1", ":", "]", ",", "**", "kwargs", ")", "for", "a", "in", "args", "[", "0", "]", "]", ")", "\n", "", "if", "islist", "(", "args", "[", "1", "]", ")", ":", "\n", "                ", "return", "TensorList", "(", "[", "op", "(", "args", "[", "0", "]", ",", "b", ",", "*", "args", "[", "2", ":", "]", ",", "**", "kwargs", ")", "for", "b", "in", "args", "[", "1", "]", "]", ")", "\n", "\n", "# None of the operands are lists", "\n", "", "", "return", "op", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "oplist", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d": [[6, 33], ["torch.conv2d", "ValueError", "ValueError", "slice", "slice", "slice", "slice"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["@", "tensor_operation", "\n", "def", "conv2d", "(", "input", ":", "torch", ".", "Tensor", ",", "weight", ":", "torch", ".", "Tensor", ",", "bias", ":", "torch", ".", "Tensor", "=", "None", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "mode", "=", "None", ")", ":", "\n", "    ", "\"\"\"Standard conv2d. Returns the input if weight=None.\"\"\"", "\n", "\n", "if", "weight", "is", "None", ":", "\n", "        ", "return", "input", "\n", "\n", "", "ind", "=", "None", "\n", "if", "mode", "is", "not", "None", ":", "\n", "        ", "if", "padding", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'Cannot input both padding and mode.'", ")", "\n", "", "if", "mode", "==", "'same'", ":", "\n", "            ", "padding", "=", "(", "weight", ".", "shape", "[", "2", "]", "//", "2", ",", "weight", ".", "shape", "[", "3", "]", "//", "2", ")", "\n", "if", "weight", ".", "shape", "[", "2", "]", "%", "2", "==", "0", "or", "weight", ".", "shape", "[", "3", "]", "%", "2", "==", "0", ":", "\n", "                ", "ind", "=", "(", "slice", "(", "-", "1", ")", "if", "weight", ".", "shape", "[", "2", "]", "%", "2", "==", "0", "else", "slice", "(", "None", ")", ",", "\n", "slice", "(", "-", "1", ")", "if", "weight", ".", "shape", "[", "3", "]", "%", "2", "==", "0", "else", "slice", "(", "None", ")", ")", "\n", "", "", "elif", "mode", "==", "'valid'", ":", "\n", "            ", "padding", "=", "(", "0", ",", "0", ")", "\n", "", "elif", "mode", "==", "'full'", ":", "\n", "            ", "padding", "=", "(", "weight", ".", "shape", "[", "2", "]", "-", "1", ",", "weight", ".", "shape", "[", "3", "]", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown mode for padding.'", ")", "\n", "\n", "", "", "out", "=", "F", ".", "conv2d", "(", "input", ",", "weight", ",", "bias", "=", "bias", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "groups", "=", "groups", ")", "\n", "if", "ind", "is", "None", ":", "\n", "        ", "return", "out", "\n", "", "return", "out", "[", ":", ",", ":", ",", "ind", "[", "0", "]", ",", "ind", "[", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv1x1": [[35, 43], ["torch.conv2d", "torch.conv2d"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["", "@", "tensor_operation", "\n", "def", "conv1x1", "(", "input", ":", "torch", ".", "Tensor", ",", "weight", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Do a convolution with a 1x1 kernel weights. Implemented with matmul, which can be faster than using conv.\"\"\"", "\n", "\n", "if", "weight", "is", "None", ":", "\n", "        ", "return", "input", "\n", "\n", "", "return", "torch", ".", "conv2d", "(", "input", ",", "weight", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann1d": [[8, 14], ["torch.cat", "torch.cat", "torch.cos", "torch.cos", "w[].flip", "torch.cos", "torch.cos", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "function", ["None"], ["def", "hann1d", "(", "sz", ":", "int", ",", "centered", "=", "True", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"1D cosine window.\"\"\"", "\n", "if", "centered", ":", "\n", "        ", "return", "0.5", "*", "(", "1", "-", "torch", ".", "cos", "(", "(", "2", "*", "math", ".", "pi", "/", "(", "sz", "+", "1", ")", ")", "*", "torch", ".", "arange", "(", "1", ",", "sz", "+", "1", ")", ".", "float", "(", ")", ")", ")", "\n", "", "w", "=", "0.5", "*", "(", "1", "+", "torch", ".", "cos", "(", "(", "2", "*", "math", ".", "pi", "/", "(", "sz", "+", "2", ")", ")", "*", "torch", ".", "arange", "(", "0", ",", "sz", "//", "2", "+", "1", ")", ".", "float", "(", ")", ")", ")", "\n", "return", "torch", ".", "cat", "(", "[", "w", ",", "w", "[", "1", ":", "sz", "-", "sz", "//", "2", "]", ".", "flip", "(", "(", "0", ",", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d": [[16, 19], ["hann1d().reshape", "hann1d().reshape", "dcf.hann1d", "dcf.hann1d", "sz[].item", "sz[].item"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann1d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann1d"], ["", "def", "hann2d", "(", "sz", ":", "torch", ".", "Tensor", ",", "centered", "=", "True", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"2D cosine window.\"\"\"", "\n", "return", "hann1d", "(", "sz", "[", "0", "]", ".", "item", "(", ")", ",", "centered", ")", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", "*", "hann1d", "(", "sz", "[", "1", "]", ".", "item", "(", ")", ",", "centered", ")", ".", "reshape", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann2d_clipped": [[21, 38], ["torch.pad", "hann1d().reshape", "hann1d().reshape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pad[].item", "pad[].item", "pad[].item", "pad[].item", "dcf.hann1d", "dcf.hann1d", "effective_sz[].item", "effective_sz[].item"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann1d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.hann1d"], ["", "def", "hann2d_clipped", "(", "sz", ":", "torch", ".", "Tensor", ",", "effective_sz", ":", "torch", ".", "Tensor", ",", "centered", "=", "True", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"1D clipped cosine window.\"\"\"", "\n", "\n", "# Ensure that the difference is even", "\n", "effective_sz", "+=", "(", "effective_sz", "-", "sz", ")", "%", "2", "\n", "effective_window", "=", "hann1d", "(", "effective_sz", "[", "0", "]", ".", "item", "(", ")", ",", "True", ")", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", "*", "hann1d", "(", "effective_sz", "[", "1", "]", ".", "item", "(", ")", ",", "True", ")", ".", "reshape", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", "\n", "\n", "pad", "=", "(", "sz", "-", "effective_sz", ")", "//", "2", "\n", "\n", "window", "=", "F", ".", "pad", "(", "effective_window", ",", "(", "pad", "[", "1", "]", ".", "item", "(", ")", ",", "pad", "[", "1", "]", ".", "item", "(", ")", ",", "pad", "[", "0", "]", ".", "item", "(", ")", ",", "pad", "[", "0", "]", ".", "item", "(", ")", ")", ",", "'replicate'", ")", "\n", "\n", "if", "centered", ":", "\n", "        ", "return", "window", "\n", "", "else", ":", "\n", "        ", "mid", "=", "(", "sz", "/", "2", ")", ".", "int", "(", ")", "\n", "window_shift_lr", "=", "torch", ".", "cat", "(", "(", "window", "[", ":", ",", ":", ",", ":", ",", "mid", "[", "1", "]", ":", "]", ",", "window", "[", ":", ",", ":", ",", ":", ",", ":", "mid", "[", "1", "]", "]", ")", ",", "3", ")", "\n", "return", "torch", ".", "cat", "(", "(", "window_shift_lr", "[", ":", ",", ":", ",", "mid", "[", "0", "]", ":", ",", ":", "]", ",", "window_shift_lr", "[", ":", ",", ":", ",", ":", "mid", "[", "0", "]", ",", ":", "]", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.gauss_fourier": [[40, 46], ["torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.exp", "torch.exp", "int", "int", "int", "math.sqrt", "torch.arange.float"], "function", ["None"], ["", "", "def", "gauss_fourier", "(", "sz", ":", "int", ",", "sigma", ":", "float", ",", "half", ":", "bool", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "if", "half", ":", "\n", "        ", "k", "=", "torch", ".", "arange", "(", "0", ",", "int", "(", "sz", "/", "2", "+", "1", ")", ")", "\n", "", "else", ":", "\n", "        ", "k", "=", "torch", ".", "arange", "(", "-", "int", "(", "(", "sz", "-", "1", ")", "/", "2", ")", ",", "int", "(", "sz", "/", "2", "+", "1", ")", ")", "\n", "", "return", "(", "math", ".", "sqrt", "(", "2", "*", "math", ".", "pi", ")", "*", "sigma", "/", "sz", ")", "*", "torch", ".", "exp", "(", "-", "2", "*", "(", "math", ".", "pi", "*", "sigma", "*", "k", ".", "float", "(", ")", "/", "sz", ")", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.gauss_spatial": [[48, 51], ["torch.arange", "torch.arange", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "gauss_spatial", "(", "sz", ",", "sigma", ",", "center", "=", "0", ",", "end_pad", "=", "0", ")", ":", "\n", "    ", "k", "=", "torch", ".", "arange", "(", "-", "(", "sz", "-", "1", ")", "/", "2", ",", "(", "sz", "+", "1", ")", "/", "2", "+", "end_pad", ")", "\n", "return", "torch", ".", "exp", "(", "-", "1.0", "/", "(", "2", "*", "sigma", "**", "2", ")", "*", "(", "k", "-", "center", ")", "**", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.label_function": [[53, 55], ["gauss_fourier().reshape", "gauss_fourier().reshape", "dcf.gauss_fourier", "dcf.gauss_fourier", "sz[].item", "sigma[].item", "sz[].item", "sigma[].item"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.gauss_fourier", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.gauss_fourier"], ["", "def", "label_function", "(", "sz", ":", "torch", ".", "Tensor", ",", "sigma", ":", "torch", ".", "Tensor", ")", ":", "\n", "    ", "return", "gauss_fourier", "(", "sz", "[", "0", "]", ".", "item", "(", ")", ",", "sigma", "[", "0", "]", ".", "item", "(", ")", ")", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", "*", "gauss_fourier", "(", "sz", "[", "1", "]", ".", "item", "(", ")", ",", "sigma", "[", "1", "]", ".", "item", "(", ")", ",", "True", ")", ".", "reshape", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.label_function_spatial": [[56, 60], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "gauss_spatial().reshape", "gauss_spatial().reshape", "dcf.gauss_spatial", "dcf.gauss_spatial", "sz[].item", "sigma[].item", "end_pad[].item", "sz[].item", "sigma[].item", "end_pad[].item"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.gauss_spatial", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.gauss_spatial"], ["", "def", "label_function_spatial", "(", "sz", ":", "torch", ".", "Tensor", ",", "sigma", ":", "torch", ".", "Tensor", ",", "center", ":", "torch", ".", "Tensor", "=", "torch", ".", "zeros", "(", "2", ")", ",", "end_pad", ":", "torch", ".", "Tensor", "=", "torch", ".", "zeros", "(", "2", ")", ")", ":", "\n", "    ", "\"\"\"The origin is in the middle of the image.\"\"\"", "\n", "return", "gauss_spatial", "(", "sz", "[", "0", "]", ".", "item", "(", ")", ",", "sigma", "[", "0", "]", ".", "item", "(", ")", ",", "center", "[", "0", "]", ",", "end_pad", "[", "0", "]", ".", "item", "(", ")", ")", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", "*", "gauss_spatial", "(", "sz", "[", "1", "]", ".", "item", "(", ")", ",", "sigma", "[", "1", "]", ".", "item", "(", ")", ",", "center", "[", "1", "]", ",", "end_pad", "[", "1", "]", ".", "item", "(", ")", ")", ".", "reshape", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.cubic_spline_fourier": [[62, 72], ["torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "function", ["None"], ["", "def", "cubic_spline_fourier", "(", "f", ",", "a", ")", ":", "\n", "    ", "\"\"\"The continuous Fourier transform of a cubic spline kernel.\"\"\"", "\n", "\n", "bf", "=", "(", "6", "*", "(", "1", "-", "torch", ".", "cos", "(", "2", "*", "math", ".", "pi", "*", "f", ")", ")", "+", "3", "*", "a", "*", "(", "1", "-", "torch", ".", "cos", "(", "4", "*", "math", ".", "pi", "*", "f", ")", ")", "\n", "-", "(", "6", "+", "8", "*", "a", ")", "*", "math", ".", "pi", "*", "f", "*", "torch", ".", "sin", "(", "2", "*", "math", ".", "pi", "*", "f", ")", "-", "2", "*", "a", "*", "math", ".", "pi", "*", "f", "*", "torch", ".", "sin", "(", "4", "*", "math", ".", "pi", "*", "f", ")", ")", "/", "(", "4", "*", "math", ".", "pi", "**", "4", "*", "f", "**", "4", ")", "\n", "\n", "bf", "[", "f", "==", "0", "]", "=", "1", "\n", "\n", "return", "bf", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.get_interp_fourier": [[74, 95], ["pytracking.fourier.get_frequency_coord", "pytracking.complex.mult", "pytracking.complex.mult", "complex.mult.to", "complex.mult.to", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "ValueError", "pytracking.complex.exp_imag", "pytracking.complex.exp_imag", "dcf.cubic_spline_fourier", "dcf.cubic_spline_fourier"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.get_frequency_coord", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.exp_imag", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.exp_imag", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.cubic_spline_fourier", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.cubic_spline_fourier"], ["", "def", "get_interp_fourier", "(", "sz", ":", "torch", ".", "Tensor", ",", "method", "=", "'ideal'", ",", "bicubic_param", "=", "0.5", ",", "centering", "=", "True", ",", "windowing", "=", "False", ",", "device", "=", "'cpu'", ")", ":", "\n", "\n", "    ", "ky", ",", "kx", "=", "fourier", ".", "get_frequency_coord", "(", "sz", ")", "\n", "\n", "if", "method", "==", "'ideal'", ":", "\n", "        ", "interp_y", "=", "torch", ".", "ones", "(", "ky", ".", "shape", ")", "/", "sz", "[", "0", "]", "\n", "interp_x", "=", "torch", ".", "ones", "(", "kx", ".", "shape", ")", "/", "sz", "[", "1", "]", "\n", "", "elif", "method", "==", "'bicubic'", ":", "\n", "        ", "interp_y", "=", "cubic_spline_fourier", "(", "ky", "/", "sz", "[", "0", "]", ",", "bicubic_param", ")", "/", "sz", "[", "0", "]", "\n", "interp_x", "=", "cubic_spline_fourier", "(", "kx", "/", "sz", "[", "1", "]", ",", "bicubic_param", ")", "/", "sz", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown method.'", ")", "\n", "\n", "", "if", "centering", ":", "\n", "        ", "interp_y", "=", "complex", ".", "mult", "(", "interp_y", ",", "complex", ".", "exp_imag", "(", "(", "-", "math", ".", "pi", "/", "sz", "[", "0", "]", ")", "*", "ky", ")", ")", "\n", "interp_x", "=", "complex", ".", "mult", "(", "interp_x", ",", "complex", ".", "exp_imag", "(", "(", "-", "math", ".", "pi", "/", "sz", "[", "1", "]", ")", "*", "kx", ")", ")", "\n", "\n", "", "if", "windowing", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "return", "interp_y", ".", "to", "(", "device", ")", ",", "interp_x", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.interpolate_dft": [[97, 104], ["isinstance", "isinstance", "ValueError", "pytracking.complex.mult", "pytracking.complex.mult", "pytracking.complex.mult"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.mult"], ["", "def", "interpolate_dft", "(", "a", ":", "torch", ".", "Tensor", ",", "interp_fs", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "    ", "if", "isinstance", "(", "interp_fs", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "complex", ".", "mult", "(", "a", ",", "interp_fs", ")", "\n", "", "if", "isinstance", "(", "interp_fs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "return", "complex", ".", "mult", "(", "complex", ".", "mult", "(", "a", ",", "interp_fs", "[", "0", "]", ")", ",", "interp_fs", "[", "1", "]", ")", "\n", "", "raise", "ValueError", "(", "'\"interp_fs\" must be tensor or tuple of tensors.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.get_reg_filter": [[106, 154], ["getattr", "getattr", "pytracking.complex.abs", "torch.irfft", "torch.irfft", "pytracking.complex.real", "torch.cat.nonzero().max", "int", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.rfft", "torch.rfft", "sz.prod", "pytracking.fourier.rfftshift2", "max_inds[].item", "max_inds[].item", "max_inds[].item", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "target_sz.prod().sqrt", "torch.ones", "torch.ones", "sz.long().tolist", "sz.prod", "torch.irfft.min", "torch.cat.nonzero", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "reg_window_dft[].flip", "target_sz.prod", "int", "int", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "sz.long", "int", "int", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "complex.abs.max", "int", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.real", "home.repos.pwc.inspect_result.visionml_pytracking.libs.fourier.rfftshift2", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs"], ["", "def", "get_reg_filter", "(", "sz", ":", "torch", ".", "Tensor", ",", "target_sz", ":", "torch", ".", "Tensor", ",", "params", ")", ":", "\n", "    ", "\"\"\"Computes regularization filter in CCOT and ECO.\"\"\"", "\n", "\n", "if", "not", "params", ".", "use_reg_window", ":", "\n", "        ", "return", "params", ".", "reg_window_min", "*", "torch", ".", "ones", "(", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "if", "getattr", "(", "params", ",", "'reg_window_square'", ",", "False", ")", ":", "\n", "        ", "target_sz", "=", "target_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "torch", ".", "ones", "(", "2", ")", "\n", "\n", "# Normalization factor", "\n", "", "reg_scale", "=", "0.5", "*", "target_sz", "\n", "\n", "# Construct grid", "\n", "if", "getattr", "(", "params", ",", "'reg_window_centered'", ",", "True", ")", ":", "\n", "        ", "wrg", "=", "torch", ".", "arange", "(", "-", "int", "(", "(", "sz", "[", "0", "]", "-", "1", ")", "/", "2", ")", ",", "int", "(", "sz", "[", "0", "]", "/", "2", "+", "1", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", "\n", "wcg", "=", "torch", ".", "arange", "(", "-", "int", "(", "(", "sz", "[", "1", "]", "-", "1", ")", "/", "2", ")", ",", "int", "(", "sz", "[", "1", "]", "/", "2", "+", "1", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "view", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "wrg", "=", "torch", ".", "cat", "(", "[", "torch", ".", "arange", "(", "0", ",", "int", "(", "sz", "[", "0", "]", "/", "2", "+", "1", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "torch", ".", "arange", "(", "-", "int", "(", "(", "sz", "[", "0", "]", "-", "1", ")", "/", "2", ")", ",", "0", ",", "dtype", "=", "torch", ".", "float32", ")", "]", ")", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", "\n", "wcg", "=", "torch", ".", "cat", "(", "[", "torch", ".", "arange", "(", "0", ",", "int", "(", "sz", "[", "1", "]", "/", "2", "+", "1", ")", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "torch", ".", "arange", "(", "-", "int", "(", "(", "sz", "[", "1", "]", "-", "1", ")", "/", "2", ")", ",", "0", ",", "dtype", "=", "torch", ".", "float32", ")", "]", ")", ".", "view", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", "\n", "\n", "# Construct regularization window", "\n", "", "reg_window", "=", "(", "params", ".", "reg_window_edge", "-", "params", ".", "reg_window_min", ")", "*", "(", "torch", ".", "abs", "(", "wrg", "/", "reg_scale", "[", "0", "]", ")", "**", "params", ".", "reg_window_power", "+", "\n", "torch", ".", "abs", "(", "wcg", "/", "reg_scale", "[", "1", "]", ")", "**", "params", ".", "reg_window_power", ")", "+", "params", ".", "reg_window_min", "\n", "\n", "# Compute DFT and enforce sparsity", "\n", "reg_window_dft", "=", "torch", ".", "rfft", "(", "reg_window", ",", "2", ")", "/", "sz", ".", "prod", "(", ")", "\n", "reg_window_dft_abs", "=", "complex", ".", "abs", "(", "reg_window_dft", ")", "\n", "reg_window_dft", "[", "reg_window_dft_abs", "<", "params", ".", "reg_sparsity_threshold", "*", "reg_window_dft_abs", ".", "max", "(", ")", ",", ":", "]", "=", "0", "\n", "\n", "# Do the inverse transform to correct for the window minimum", "\n", "reg_window_sparse", "=", "torch", ".", "irfft", "(", "reg_window_dft", ",", "2", ",", "signal_sizes", "=", "sz", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", "\n", "reg_window_dft", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", "+=", "params", ".", "reg_window_min", "-", "sz", ".", "prod", "(", ")", "*", "reg_window_sparse", ".", "min", "(", ")", "\n", "reg_window_dft", "=", "complex", ".", "real", "(", "fourier", ".", "rfftshift2", "(", "reg_window_dft", ")", ")", "\n", "\n", "# Remove zeros", "\n", "max_inds", ",", "_", "=", "reg_window_dft", ".", "nonzero", "(", ")", ".", "max", "(", "dim", "=", "0", ")", "\n", "mid_ind", "=", "int", "(", "(", "reg_window_dft", ".", "shape", "[", "2", "]", "-", "1", ")", "/", "2", ")", "\n", "top", "=", "max_inds", "[", "-", "2", "]", ".", "item", "(", ")", "+", "1", "\n", "bottom", "=", "2", "*", "mid_ind", "-", "max_inds", "[", "-", "2", "]", ".", "item", "(", ")", "\n", "right", "=", "max_inds", "[", "-", "1", "]", ".", "item", "(", ")", "+", "1", "\n", "reg_window_dft", "=", "reg_window_dft", "[", "...", ",", "bottom", ":", "top", ",", ":", "right", "]", "\n", "if", "reg_window_dft", ".", "shape", "[", "-", "1", "]", ">", "1", ":", "\n", "        ", "reg_window_dft", "=", "torch", ".", "cat", "(", "[", "reg_window_dft", "[", "...", ",", "1", ":", "]", ".", "flip", "(", "(", "2", ",", "3", ")", ")", ",", "reg_window_dft", "]", ",", "-", "1", ")", "\n", "\n", "", "return", "reg_window_dft", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d": [[156, 165], ["torch.max", "torch.max", "torch.max", "torch.max", "argmax_row.reshape.reshape", "torch.cat", "torch.cat", "argmax_row.reshape.view", "argmax_col.numel", "argmax_row.reshape.unsqueeze", "argmax_col.unsqueeze", "torch.arange", "torch.arange", "argmax_col.view", "argmax_col.numel"], "function", ["None"], ["", "def", "max2d", "(", "a", ":", "torch", ".", "Tensor", ")", "->", "(", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ")", ":", "\n", "    ", "\"\"\"Computes maximum and argmax in the last two dimensions.\"\"\"", "\n", "\n", "max_val_row", ",", "argmax_row", "=", "torch", ".", "max", "(", "a", ",", "dim", "=", "-", "2", ")", "\n", "max_val", ",", "argmax_col", "=", "torch", ".", "max", "(", "max_val_row", ",", "dim", "=", "-", "1", ")", "\n", "argmax_row", "=", "argmax_row", ".", "view", "(", "argmax_col", ".", "numel", "(", ")", ",", "-", "1", ")", "[", "torch", ".", "arange", "(", "argmax_col", ".", "numel", "(", ")", ")", ",", "argmax_col", ".", "view", "(", "-", "1", ")", "]", "\n", "argmax_row", "=", "argmax_row", ".", "reshape", "(", "argmax_col", ".", "shape", ")", "\n", "argmax", "=", "torch", ".", "cat", "(", "(", "argmax_row", ".", "unsqueeze", "(", "-", "1", ")", ",", "argmax_col", ".", "unsqueeze", "(", "-", "1", ")", ")", ",", "-", "1", ")", "\n", "return", "max_val", ",", "argmax", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.trackingnetdataset.TrackingNetDataset.__init__": [[18, 30], ["pytracking.evaluation.data.BaseDataset.__init__", "trackingnetdataset.TrackingNetDataset._list_sequences", "isinstance", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.trackingnetdataset.TrackingNetDataset._list_sequences"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_path", "=", "self", ".", "env_settings", ".", "trackingnet_path", "\n", "\n", "sets", "=", "'TEST'", "\n", "if", "not", "isinstance", "(", "sets", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "if", "sets", "==", "'TEST'", ":", "\n", "                ", "sets", "=", "[", "'TEST'", "]", "\n", "", "elif", "sets", "==", "'TRAIN'", ":", "\n", "                ", "sets", "=", "[", "'TRAIN_{}'", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "5", ")", "]", "\n", "\n", "", "", "self", ".", "sequence_list", "=", "self", ".", "_list_sequences", "(", "self", ".", "base_path", ",", "sets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.trackingnetdataset.TrackingNetDataset.get_sequence_list": [[31, 33], ["pytracking.evaluation.data.SequenceList", "trackingnetdataset.TrackingNetDataset._construct_sequence"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence"], ["", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "return", "SequenceList", "(", "[", "self", ".", "_construct_sequence", "(", "set", ",", "seq_name", ")", "for", "set", ",", "seq_name", "in", "self", ".", "sequence_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.trackingnetdataset.TrackingNetDataset._construct_sequence": [[34, 45], ["pytracking.utils.load_text.load_text", "frame_list.sort", "pytracking.evaluation.data.Sequence", "str", "os.path.join", "pytracking.utils.load_text.load_text.reshape", "os.listdir", "frame.endswith", "int"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text"], ["", "def", "_construct_sequence", "(", "self", ",", "set", ",", "sequence_name", ")", ":", "\n", "        ", "anno_path", "=", "'{}/{}/anno/{}.txt'", ".", "format", "(", "self", ".", "base_path", ",", "set", ",", "sequence_name", ")", "\n", "\n", "ground_truth_rect", "=", "load_text", "(", "str", "(", "anno_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ",", "backend", "=", "'numpy'", ")", "\n", "\n", "frames_path", "=", "'{}/{}/frames/{}'", ".", "format", "(", "self", ".", "base_path", ",", "set", ",", "sequence_name", ")", "\n", "frame_list", "=", "[", "frame", "for", "frame", "in", "os", ".", "listdir", "(", "frames_path", ")", "if", "frame", ".", "endswith", "(", "\".jpg\"", ")", "]", "\n", "frame_list", ".", "sort", "(", "key", "=", "lambda", "f", ":", "int", "(", "f", "[", ":", "-", "4", "]", ")", ")", "\n", "frames_list", "=", "[", "os", ".", "path", ".", "join", "(", "frames_path", ",", "frame", ")", "for", "frame", "in", "frame_list", "]", "\n", "\n", "return", "Sequence", "(", "sequence_name", ",", "frames_list", ",", "'trackingnet'", ",", "ground_truth_rect", ".", "reshape", "(", "-", "1", ",", "4", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.trackingnetdataset.TrackingNetDataset.__len__": [[46, 48], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.trackingnetdataset.TrackingNetDataset._list_sequences": [[49, 59], ["os.path.join", "os.listdir", "f.endswith", "os.path.splitext"], "methods", ["None"], ["", "def", "_list_sequences", "(", "self", ",", "root", ",", "set_ids", ")", ":", "\n", "        ", "sequence_list", "=", "[", "]", "\n", "\n", "for", "s", "in", "set_ids", ":", "\n", "            ", "anno_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "s", ",", "\"anno\"", ")", "\n", "sequences_cur_set", "=", "[", "(", "s", ",", "os", ".", "path", ".", "splitext", "(", "f", ")", "[", "0", "]", ")", "for", "f", "in", "os", ".", "listdir", "(", "anno_dir", ")", "if", "f", ".", "endswith", "(", "'.txt'", ")", "]", "\n", "\n", "sequence_list", "+=", "sequences_cur_set", "\n", "\n", "", "return", "sequence_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.running._save_tracker_output_oxuva": [[15, 56], ["numpy.array", "numpy.array", "tracked_bb.clip.clip", "numpy.array", "os.path.join", "os.path.exists", "os.makedirs", "numpy.vstack", "list", "seq.name.split", "open", "csv.DictWriter", "range", "os.path.splitext", "map", "len", "csv.DictWriter.writerow", "os.path.basename", "str().lower", "str"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["def", "_save_tracker_output_oxuva", "(", "seq", ":", "Sequence", ",", "tracker", ":", "Tracker", ",", "output", ":", "dict", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "tracker", ".", "results_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "tracker", ".", "results_dir", ")", "\n", "\n", "", "frame_names", "=", "[", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "f", ")", ")", "[", "0", "]", "for", "f", "in", "seq", ".", "frames", "]", "\n", "\n", "img_h", ",", "img_w", "=", "output", "[", "'image_shape'", "]", "\n", "tracked_bb", "=", "np", ".", "array", "(", "output", "[", "'target_bbox'", "]", ")", "\n", "object_presence_scores", "=", "np", ".", "array", "(", "output", "[", "'object_presence_score'", "]", ")", "\n", "\n", "tracked_bb", "=", "np", ".", "vstack", "(", "[", "\n", "tracked_bb", "[", ":", ",", "0", "]", "/", "img_w", ",", "\n", "(", "tracked_bb", "[", ":", ",", "0", "]", "+", "tracked_bb", "[", ":", ",", "2", "]", ")", "/", "img_w", ",", "\n", "tracked_bb", "[", ":", ",", "1", "]", "/", "img_h", ",", "\n", "(", "tracked_bb", "[", ":", ",", "1", "]", "+", "tracked_bb", "[", ":", ",", "3", "]", ")", "/", "img_h", ",", "\n", "]", ")", ".", "T", "\n", "tracked_bb", "=", "tracked_bb", ".", "clip", "(", "0.", ",", "1.", ")", "\n", "\n", "tracked_bb", "=", "tracked_bb", "[", "1", ":", "]", "\n", "object_presence_scores", "=", "object_presence_scores", "[", "1", ":", "]", "\n", "frame_numbers", "=", "np", ".", "array", "(", "list", "(", "map", "(", "int", ",", "frame_names", "[", "1", ":", "]", ")", ")", ")", "\n", "vid_id", ",", "obj_id", "=", "seq", ".", "name", ".", "split", "(", "'_'", ")", "[", ":", "2", "]", "\n", "\n", "pred_file", "=", "os", ".", "path", ".", "join", "(", "tracker", ".", "results_dir", ",", "'{}_{}.csv'", ".", "format", "(", "vid_id", ",", "obj_id", ")", ")", "\n", "\n", "with", "open", "(", "pred_file", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "writer", "=", "csv", ".", "DictWriter", "(", "fp", ",", "fieldnames", "=", "PREDICTION_FIELD_NAMES", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "frame_numbers", ")", ")", ":", "\n", "            ", "row", "=", "{", "\n", "'video'", ":", "vid_id", ",", "\n", "'object'", ":", "obj_id", ",", "\n", "'frame_num'", ":", "frame_numbers", "[", "i", "]", ",", "\n", "'present'", ":", "str", "(", "object_presence_scores", "[", "i", "]", ">", "output", "[", "'object_presence_score_threshold'", "]", ")", ".", "lower", "(", ")", ",", "# True or False", "\n", "'score'", ":", "object_presence_scores", "[", "i", "]", ",", "\n", "'xmin'", ":", "tracked_bb", "[", "i", ",", "0", "]", ",", "\n", "'xmax'", ":", "tracked_bb", "[", "i", ",", "1", "]", ",", "\n", "'ymin'", ":", "tracked_bb", "[", "i", ",", "2", "]", ",", "\n", "'ymax'", ":", "tracked_bb", "[", "i", ",", "3", "]", ",", "\n", "}", "\n", "writer", ".", "writerow", "(", "row", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.running._save_tracker_output": [[58, 121], ["os.path.join", "os.path.join", "output.items", "os.path.exists", "os.makedirs", "numpy.array().astype", "numpy.savetxt", "numpy.array().astype", "numpy.savetxt", "os.path.splitext", "elem.items", "isinstance", "os.path.basename", "numpy.array", "numpy.array", "running._save_tracker_output._convert_dict"], "function", ["None"], ["", "", "", "def", "_save_tracker_output", "(", "seq", ":", "Sequence", ",", "tracker", ":", "Tracker", ",", "output", ":", "dict", ")", ":", "\n", "    ", "\"\"\"Saves the output of the tracker.\"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "tracker", ".", "results_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "tracker", ".", "results_dir", ")", "\n", "\n", "", "base_results_path", "=", "os", ".", "path", ".", "join", "(", "tracker", ".", "results_dir", ",", "seq", ".", "name", ")", "\n", "segmentation_path", "=", "os", ".", "path", ".", "join", "(", "tracker", ".", "segmentation_dir", ",", "seq", ".", "name", ")", "\n", "\n", "frame_names", "=", "[", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "f", ")", ")", "[", "0", "]", "for", "f", "in", "seq", ".", "frames", "]", "\n", "\n", "def", "save_bb", "(", "file", ",", "data", ")", ":", "\n", "        ", "tracked_bb", "=", "np", ".", "array", "(", "data", ")", ".", "astype", "(", "int", ")", "\n", "np", ".", "savetxt", "(", "file", ",", "tracked_bb", ",", "delimiter", "=", "'\\t'", ",", "fmt", "=", "'%d'", ")", "\n", "\n", "", "def", "save_time", "(", "file", ",", "data", ")", ":", "\n", "        ", "exec_times", "=", "np", ".", "array", "(", "data", ")", ".", "astype", "(", "float", ")", "\n", "np", ".", "savetxt", "(", "file", ",", "exec_times", ",", "delimiter", "=", "'\\t'", ",", "fmt", "=", "'%f'", ")", "\n", "\n", "", "def", "_convert_dict", "(", "input_dict", ")", ":", "\n", "        ", "data_dict", "=", "{", "}", "\n", "for", "elem", "in", "input_dict", ":", "\n", "            ", "for", "k", ",", "v", "in", "elem", ".", "items", "(", ")", ":", "\n", "                ", "if", "k", "in", "data_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "data_dict", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "", "else", ":", "\n", "                    ", "data_dict", "[", "k", "]", "=", "[", "v", ",", "]", "\n", "", "", "", "return", "data_dict", "\n", "\n", "", "for", "key", ",", "data", "in", "output", ".", "items", "(", ")", ":", "\n", "# If data is empty", "\n", "        ", "if", "not", "data", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "key", "==", "'target_bbox'", ":", "\n", "            ", "if", "isinstance", "(", "data", "[", "0", "]", ",", "(", "dict", ",", "OrderedDict", ")", ")", ":", "\n", "                ", "data_dict", "=", "_convert_dict", "(", "data", ")", "\n", "\n", "for", "obj_id", ",", "d", "in", "data_dict", ".", "items", "(", ")", ":", "\n", "                    ", "bbox_file", "=", "'{}_{}.txt'", ".", "format", "(", "base_results_path", ",", "obj_id", ")", "\n", "save_bb", "(", "bbox_file", ",", "d", ")", "\n", "", "", "else", ":", "\n", "# Single-object mode", "\n", "                ", "bbox_file", "=", "'{}.txt'", ".", "format", "(", "base_results_path", ")", "\n", "save_bb", "(", "bbox_file", ",", "data", ")", "\n", "\n", "", "", "elif", "key", "==", "'time'", ":", "\n", "            ", "if", "isinstance", "(", "data", "[", "0", "]", ",", "dict", ")", ":", "\n", "                ", "data_dict", "=", "_convert_dict", "(", "data", ")", "\n", "\n", "for", "obj_id", ",", "d", "in", "data_dict", ".", "items", "(", ")", ":", "\n", "                    ", "timings_file", "=", "'{}_{}_time.txt'", ".", "format", "(", "base_results_path", ",", "obj_id", ")", "\n", "save_time", "(", "timings_file", ",", "d", ")", "\n", "", "", "else", ":", "\n", "                ", "timings_file", "=", "'{}_time.txt'", ".", "format", "(", "base_results_path", ")", "\n", "save_time", "(", "timings_file", ",", "data", ")", "\n", "\n", "", "", "elif", "key", "==", "'segmentation'", ":", "\n", "            ", "assert", "len", "(", "frame_names", ")", "==", "len", "(", "data", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "segmentation_path", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "segmentation_path", ")", "\n", "", "for", "frame_name", ",", "frame_seg", "in", "zip", "(", "frame_names", ",", "data", ")", ":", "\n", "                ", "imwrite_indexed", "(", "os", ".", "path", ".", "join", "(", "segmentation_path", ",", "'{}.png'", ".", "format", "(", "frame_name", ")", ")", ",", "frame_seg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.running.run_sequence": [[123, 172], ["print", "sys.stdout.flush", "isinstance", "print", "running.run_sequence._results_exist"], "function", ["None"], ["", "", "", "", "def", "run_sequence", "(", "seq", ":", "Sequence", ",", "tracker", ":", "Tracker", ",", "debug", "=", "False", ",", "visdom_info", "=", "None", ")", ":", "\n", "    ", "\"\"\"Runs a tracker on a sequence.\"\"\"", "\n", "\n", "def", "_results_exist", "(", ")", ":", "\n", "        ", "if", "seq", ".", "dataset", "==", "'oxuva'", ":", "\n", "            ", "vid_id", ",", "obj_id", "=", "seq", ".", "name", ".", "split", "(", "'_'", ")", "[", ":", "2", "]", "\n", "pred_file", "=", "os", ".", "path", ".", "join", "(", "tracker", ".", "results_dir", ",", "'{}_{}.csv'", ".", "format", "(", "vid_id", ",", "obj_id", ")", ")", "\n", "return", "os", ".", "path", ".", "isfile", "(", "pred_file", ")", "\n", "", "elif", "seq", ".", "object_ids", "is", "None", ":", "\n", "            ", "bbox_file", "=", "'{}/{}.txt'", ".", "format", "(", "tracker", ".", "results_dir", ",", "seq", ".", "name", ")", "\n", "return", "os", ".", "path", ".", "isfile", "(", "bbox_file", ")", "\n", "", "else", ":", "\n", "            ", "bbox_files", "=", "[", "'{}/{}_{}.txt'", ".", "format", "(", "tracker", ".", "results_dir", ",", "seq", ".", "name", ",", "obj_id", ")", "for", "obj_id", "in", "seq", ".", "object_ids", "]", "\n", "missing", "=", "[", "not", "os", ".", "path", ".", "isfile", "(", "f", ")", "for", "f", "in", "bbox_files", "]", "\n", "return", "sum", "(", "missing", ")", "==", "0", "\n", "\n", "", "", "visdom_info", "=", "{", "}", "if", "visdom_info", "is", "None", "else", "visdom_info", "\n", "\n", "if", "_results_exist", "(", ")", "and", "not", "debug", ":", "\n", "        ", "print", "(", "'FPS: {}'", ".", "format", "(", "-", "1", ")", ")", "\n", "return", "\n", "\n", "", "print", "(", "'Tracker: {} {} {} ,  Sequence: {}'", ".", "format", "(", "tracker", ".", "name", ",", "tracker", ".", "parameter_name", ",", "tracker", ".", "run_id", ",", "seq", ".", "name", ")", ")", "\n", "\n", "if", "debug", ":", "\n", "        ", "output", "=", "tracker", ".", "run_sequence", "(", "seq", ",", "debug", "=", "debug", ",", "visdom_info", "=", "visdom_info", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "output", "=", "tracker", ".", "run_sequence", "(", "seq", ",", "debug", "=", "debug", ",", "visdom_info", "=", "visdom_info", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "e", ")", "\n", "return", "\n", "\n", "", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "if", "isinstance", "(", "output", "[", "'time'", "]", "[", "0", "]", ",", "(", "dict", ",", "OrderedDict", ")", ")", ":", "\n", "        ", "exec_time", "=", "sum", "(", "[", "sum", "(", "times", ".", "values", "(", ")", ")", "for", "times", "in", "output", "[", "'time'", "]", "]", ")", "\n", "num_frames", "=", "len", "(", "output", "[", "'time'", "]", ")", "\n", "", "else", ":", "\n", "        ", "exec_time", "=", "sum", "(", "output", "[", "'time'", "]", ")", "\n", "num_frames", "=", "len", "(", "output", "[", "'time'", "]", ")", "\n", "\n", "", "print", "(", "'FPS: {}'", ".", "format", "(", "num_frames", "/", "exec_time", ")", ")", "\n", "\n", "if", "not", "debug", ":", "\n", "        ", "if", "seq", ".", "dataset", "==", "'oxuva'", ":", "\n", "            ", "_save_tracker_output_oxuva", "(", "seq", ",", "tracker", ",", "output", ")", "\n", "", "else", ":", "\n", "            ", "_save_tracker_output", "(", "seq", ",", "tracker", ",", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.running.run_dataset": [[174, 205], ["multiprocessing.set_start_method", "print", "multiprocessing.set_start_method", "print", "len", "len", "running.run_sequence", "multiprocessing.Pool", "pool.starmap", "itertools.product"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.run_sequence"], ["", "", "", "def", "run_dataset", "(", "dataset", ",", "trackers", ",", "debug", "=", "False", ",", "threads", "=", "0", ",", "visdom_info", "=", "None", ")", ":", "\n", "    ", "\"\"\"Runs a list of trackers on a dataset.\n    args:\n        dataset: List of Sequence instances, forming a dataset.\n        trackers: List of Tracker instances.\n        debug: Debug level.\n        threads: Number of threads to use (default 0).\n        visdom_info: Dict containing information about the server for visdom\n    \"\"\"", "\n", "multiprocessing", ".", "set_start_method", "(", "'spawn'", ",", "force", "=", "True", ")", "\n", "\n", "print", "(", "'Evaluating {:4d} trackers on {:5d} sequences'", ".", "format", "(", "len", "(", "trackers", ")", ",", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "multiprocessing", ".", "set_start_method", "(", "'spawn'", ",", "force", "=", "True", ")", "\n", "\n", "visdom_info", "=", "{", "}", "if", "visdom_info", "is", "None", "else", "visdom_info", "\n", "\n", "if", "threads", "==", "0", ":", "\n", "        ", "mode", "=", "'sequential'", "\n", "", "else", ":", "\n", "        ", "mode", "=", "'parallel'", "\n", "\n", "", "if", "mode", "==", "'sequential'", ":", "\n", "        ", "for", "seq", "in", "dataset", ":", "\n", "            ", "for", "tracker_info", "in", "trackers", ":", "\n", "                ", "run_sequence", "(", "seq", ",", "tracker_info", ",", "debug", "=", "debug", ",", "visdom_info", "=", "visdom_info", ")", "\n", "", "", "", "elif", "mode", "==", "'parallel'", ":", "\n", "        ", "param_list", "=", "[", "(", "seq", ",", "tracker_info", ",", "debug", ",", "visdom_info", ")", "for", "seq", ",", "tracker_info", "in", "product", "(", "dataset", ",", "trackers", ")", "]", "\n", "with", "multiprocessing", ".", "Pool", "(", "processes", "=", "threads", ")", "as", "pool", ":", "\n", "            ", "pool", ".", "starmap", "(", "run_sequence", ",", "param_list", ")", "\n", "", "", "print", "(", "'Done'", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.otbdataset.OTBDataset.__init__": [[17, 21], ["pytracking.evaluation.data.BaseDataset.__init__", "otbdataset.OTBDataset._get_sequence_info_list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.uavdataset.UAVDataset._get_sequence_info_list"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_path", "=", "self", ".", "env_settings", ".", "otb_path", "\n", "self", ".", "sequence_info_list", "=", "self", ".", "_get_sequence_info_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.otbdataset.OTBDataset.get_sequence_list": [[22, 24], ["pytracking.evaluation.data.SequenceList", "otbdataset.OTBDataset._construct_sequence"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence"], ["", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "return", "SequenceList", "(", "[", "self", ".", "_construct_sequence", "(", "s", ")", "for", "s", "in", "self", ".", "sequence_info_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.otbdataset.OTBDataset._construct_sequence": [[25, 46], ["pytracking.utils.load_text.load_text", "pytracking.evaluation.data.Sequence", "str", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text"], ["", "def", "_construct_sequence", "(", "self", ",", "sequence_info", ")", ":", "\n", "        ", "sequence_path", "=", "sequence_info", "[", "'path'", "]", "\n", "nz", "=", "sequence_info", "[", "'nz'", "]", "\n", "ext", "=", "sequence_info", "[", "'ext'", "]", "\n", "start_frame", "=", "sequence_info", "[", "'startFrame'", "]", "\n", "end_frame", "=", "sequence_info", "[", "'endFrame'", "]", "\n", "\n", "init_omit", "=", "0", "\n", "if", "'initOmit'", "in", "sequence_info", ":", "\n", "            ", "init_omit", "=", "sequence_info", "[", "'initOmit'", "]", "\n", "\n", "", "frames", "=", "[", "'{base_path}/{sequence_path}/{frame:0{nz}}.{ext}'", ".", "format", "(", "base_path", "=", "self", ".", "base_path", ",", "\n", "sequence_path", "=", "sequence_path", ",", "frame", "=", "frame_num", ",", "nz", "=", "nz", ",", "ext", "=", "ext", ")", "for", "frame_num", "in", "range", "(", "start_frame", "+", "init_omit", ",", "end_frame", "+", "1", ")", "]", "\n", "\n", "anno_path", "=", "'{}/{}'", ".", "format", "(", "self", ".", "base_path", ",", "sequence_info", "[", "'anno_path'", "]", ")", "\n", "\n", "# NOTE: OTB has some weird annos which panda cannot handle", "\n", "ground_truth_rect", "=", "load_text", "(", "str", "(", "anno_path", ")", ",", "delimiter", "=", "(", "','", ",", "None", ")", ",", "dtype", "=", "np", ".", "float64", ",", "backend", "=", "'numpy'", ")", "\n", "\n", "return", "Sequence", "(", "sequence_info", "[", "'name'", "]", ",", "frames", ",", "'otb'", ",", "ground_truth_rect", "[", "init_omit", ":", ",", ":", "]", ",", "\n", "object_class", "=", "sequence_info", "[", "'object_class'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.otbdataset.OTBDataset.__len__": [[47, 49], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_info_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.otbdataset.OTBDataset._get_sequence_info_list": [[50, 255], ["None"], "methods", ["None"], ["", "def", "_get_sequence_info_list", "(", "self", ")", ":", "\n", "        ", "sequence_info_list", "=", "[", "\n", "{", "\"name\"", ":", "\"Basketball\"", ",", "\"path\"", ":", "\"Basketball/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "725", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Basketball/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Biker\"", ",", "\"path\"", ":", "\"Biker/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "142", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Biker/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person head\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Bird1\"", ",", "\"path\"", ":", "\"Bird1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "408", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Bird1/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"bird\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Bird2\"", ",", "\"path\"", ":", "\"Bird2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "99", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Bird2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"bird\"", "}", ",", "\n", "{", "\"name\"", ":", "\"BlurBody\"", ",", "\"path\"", ":", "\"BlurBody/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "334", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"BlurBody/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"BlurCar1\"", ",", "\"path\"", ":", "\"BlurCar1/img\"", ",", "\"startFrame\"", ":", "247", ",", "\"endFrame\"", ":", "988", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"BlurCar1/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"BlurCar2\"", ",", "\"path\"", ":", "\"BlurCar2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "585", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"BlurCar2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"BlurCar3\"", ",", "\"path\"", ":", "\"BlurCar3/img\"", ",", "\"startFrame\"", ":", "3", ",", "\"endFrame\"", ":", "359", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"BlurCar3/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"BlurCar4\"", ",", "\"path\"", ":", "\"BlurCar4/img\"", ",", "\"startFrame\"", ":", "18", ",", "\"endFrame\"", ":", "397", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"BlurCar4/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"BlurFace\"", ",", "\"path\"", ":", "\"BlurFace/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "493", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"BlurFace/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"BlurOwl\"", ",", "\"path\"", ":", "\"BlurOwl/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "631", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"BlurOwl/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Board\"", ",", "\"path\"", ":", "\"Board/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "698", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Board/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Bolt\"", ",", "\"path\"", ":", "\"Bolt/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "350", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Bolt/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Bolt2\"", ",", "\"path\"", ":", "\"Bolt2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "293", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Bolt2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Box\"", ",", "\"path\"", ":", "\"Box/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1161", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Box/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Boy\"", ",", "\"path\"", ":", "\"Boy/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "602", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Boy/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Car1\"", ",", "\"path\"", ":", "\"Car1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1020", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Car1/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Car2\"", ",", "\"path\"", ":", "\"Car2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "913", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Car2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Car24\"", ",", "\"path\"", ":", "\"Car24/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "3059", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Car24/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Car4\"", ",", "\"path\"", ":", "\"Car4/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "659", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Car4/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"CarDark\"", ",", "\"path\"", ":", "\"CarDark/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "393", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"CarDark/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"CarScale\"", ",", "\"path\"", ":", "\"CarScale/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "252", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"CarScale/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"ClifBar\"", ",", "\"path\"", ":", "\"ClifBar/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "472", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"ClifBar/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Coke\"", ",", "\"path\"", ":", "\"Coke/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "291", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Coke/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Couple\"", ",", "\"path\"", ":", "\"Couple/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "140", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Couple/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Coupon\"", ",", "\"path\"", ":", "\"Coupon/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "327", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Coupon/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Crossing\"", ",", "\"path\"", ":", "\"Crossing/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "120", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Crossing/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Crowds\"", ",", "\"path\"", ":", "\"Crowds/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "347", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Crowds/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Dancer\"", ",", "\"path\"", ":", "\"Dancer/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "225", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Dancer/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Dancer2\"", ",", "\"path\"", ":", "\"Dancer2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "150", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Dancer2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"David\"", ",", "\"path\"", ":", "\"David/img\"", ",", "\"startFrame\"", ":", "300", ",", "\"endFrame\"", ":", "770", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"David/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"David2\"", ",", "\"path\"", ":", "\"David2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "537", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"David2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"David3\"", ",", "\"path\"", ":", "\"David3/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "252", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"David3/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Deer\"", ",", "\"path\"", ":", "\"Deer/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "71", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Deer/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"mammal\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Diving\"", ",", "\"path\"", ":", "\"Diving/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "215", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Diving/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Dog\"", ",", "\"path\"", ":", "\"Dog/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "127", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Dog/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"dog\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Dog1\"", ",", "\"path\"", ":", "\"Dog1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1350", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Dog1/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"dog\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Doll\"", ",", "\"path\"", ":", "\"Doll/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "3872", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Doll/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"DragonBaby\"", ",", "\"path\"", ":", "\"DragonBaby/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "113", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"DragonBaby/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Dudek\"", ",", "\"path\"", ":", "\"Dudek/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1145", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Dudek/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"FaceOcc1\"", ",", "\"path\"", ":", "\"FaceOcc1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "892", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"FaceOcc1/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"FaceOcc2\"", ",", "\"path\"", ":", "\"FaceOcc2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "812", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"FaceOcc2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Fish\"", ",", "\"path\"", ":", "\"Fish/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "476", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Fish/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"FleetFace\"", ",", "\"path\"", ":", "\"FleetFace/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "707", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"FleetFace/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Football\"", ",", "\"path\"", ":", "\"Football/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "362", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Football/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person head\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Football1\"", ",", "\"path\"", ":", "\"Football1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "74", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Football1/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Freeman1\"", ",", "\"path\"", ":", "\"Freeman1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "326", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Freeman1/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Freeman3\"", ",", "\"path\"", ":", "\"Freeman3/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "460", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Freeman3/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Freeman4\"", ",", "\"path\"", ":", "\"Freeman4/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "283", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Freeman4/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Girl\"", ",", "\"path\"", ":", "\"Girl/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "500", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Girl/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Girl2\"", ",", "\"path\"", ":", "\"Girl2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1500", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Girl2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Gym\"", ",", "\"path\"", ":", "\"Gym/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "767", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Gym/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Human2\"", ",", "\"path\"", ":", "\"Human2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1128", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Human2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Human3\"", ",", "\"path\"", ":", "\"Human3/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1698", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Human3/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Human4_2\"", ",", "\"path\"", ":", "\"Human4/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "667", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Human4/groundtruth_rect.2.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Human5\"", ",", "\"path\"", ":", "\"Human5/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "713", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Human5/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Human6\"", ",", "\"path\"", ":", "\"Human6/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "792", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Human6/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Human7\"", ",", "\"path\"", ":", "\"Human7/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "250", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Human7/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Human8\"", ",", "\"path\"", ":", "\"Human8/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "128", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Human8/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Human9\"", ",", "\"path\"", ":", "\"Human9/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "305", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Human9/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Ironman\"", ",", "\"path\"", ":", "\"Ironman/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "166", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Ironman/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person head\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Jogging_1\"", ",", "\"path\"", ":", "\"Jogging/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "307", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Jogging/groundtruth_rect.1.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Jogging_2\"", ",", "\"path\"", ":", "\"Jogging/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "307", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Jogging/groundtruth_rect.2.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Jump\"", ",", "\"path\"", ":", "\"Jump/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "122", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Jump/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Jumping\"", ",", "\"path\"", ":", "\"Jumping/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "313", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Jumping/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"KiteSurf\"", ",", "\"path\"", ":", "\"KiteSurf/jpg\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "84", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"png\"", ",", "\"anno_path\"", ":", "\"KiteSurf/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Lemming\"", ",", "\"path\"", ":", "\"Lemming/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1336", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Lemming/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Liquor\"", ",", "\"path\"", ":", "\"Liquor/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1741", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Liquor/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Man\"", ",", "\"path\"", ":", "\"Man/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "134", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Man/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Matrix\"", ",", "\"path\"", ":", "\"Matrix/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "100", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Matrix/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person head\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Mhyang\"", ",", "\"path\"", ":", "\"Mhyang/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1490", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Mhyang/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"MotorRolling\"", ",", "\"path\"", ":", "\"MotorRolling/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "164", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"MotorRolling/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"vehicle\"", "}", ",", "\n", "{", "\"name\"", ":", "\"MountainBike\"", ",", "\"path\"", ":", "\"MountainBike/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "228", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"MountainBike/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"bicycle\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Panda\"", ",", "\"path\"", ":", "\"Panda/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1000", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Panda/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"mammal\"", "}", ",", "\n", "{", "\"name\"", ":", "\"RedTeam\"", ",", "\"path\"", ":", "\"RedTeam/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1918", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"RedTeam/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"vehicle\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Rubik\"", ",", "\"path\"", ":", "\"Rubik/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1997", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Rubik/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Shaking\"", ",", "\"path\"", ":", "\"Shaking/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "365", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Shaking/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Singer1\"", ",", "\"path\"", ":", "\"Singer1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "351", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Singer1/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Singer2\"", ",", "\"path\"", ":", "\"Singer2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "366", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Singer2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Skater\"", ",", "\"path\"", ":", "\"Skater/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "160", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Skater/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Skater2\"", ",", "\"path\"", ":", "\"Skater2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "435", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Skater2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Skating1\"", ",", "\"path\"", ":", "\"Skating1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "400", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Skating1/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Skating2_1\"", ",", "\"path\"", ":", "\"Skating2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "473", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Skating2/groundtruth_rect.1.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Skating2_2\"", ",", "\"path\"", ":", "\"Skating2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "473", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Skating2/groundtruth_rect.2.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Skiing\"", ",", "\"path\"", ":", "\"Skiing/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "81", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Skiing/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Soccer\"", ",", "\"path\"", ":", "\"Soccer/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "392", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Soccer/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Subway\"", ",", "\"path\"", ":", "\"Subway/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "175", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Subway/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Surfer\"", ",", "\"path\"", ":", "\"Surfer/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "376", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Surfer/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person head\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Suv\"", ",", "\"path\"", ":", "\"Suv/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "945", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Suv/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Sylvester\"", ",", "\"path\"", ":", "\"Sylvester/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1345", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Sylvester/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Tiger1\"", ",", "\"path\"", ":", "\"Tiger1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "354", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Tiger1/groundtruth_rect.txt\"", ",", "\"initOmit\"", ":", "5", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Tiger2\"", ",", "\"path\"", ":", "\"Tiger2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "365", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Tiger2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Toy\"", ",", "\"path\"", ":", "\"Toy/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "271", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Toy/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Trans\"", ",", "\"path\"", ":", "\"Trans/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "124", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Trans/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Trellis\"", ",", "\"path\"", ":", "\"Trellis/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "569", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Trellis/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"face\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Twinnings\"", ",", "\"path\"", ":", "\"Twinnings/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "472", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Twinnings/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Vase\"", ",", "\"path\"", ":", "\"Vase/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "271", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Vase/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Walking\"", ",", "\"path\"", ":", "\"Walking/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "412", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Walking/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Walking2\"", ",", "\"path\"", ":", "\"Walking2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "500", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Walking2/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"Woman\"", ",", "\"path\"", ":", "\"Woman/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "597", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"Woman/groundtruth_rect.txt\"", ",", "\n", "\"object_class\"", ":", "\"person\"", "}", "\n", "]", "\n", "\n", "return", "sequence_info_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot.VOT.__init__": [[84, 108], ["trax.server.ServerOptions", "trax.server.Server", "vot.VOT._trax.wait", "str", "vot.VOT._trax.status", "vot.convert_region", "Polygon", "Rectangle", "x.strip", "vot.parse_region", "open().readlines", "open().readline", "Point", "open", "open"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot.convert_region", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot.parse_region"], ["            ", "properties", "[", "'confidence'", "]", "=", "confidence", "\n", "", "self", ".", "_trax", ".", "status", "(", "tregion", ",", "properties", ")", "\n", "\n", "", "def", "frame", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get a frame (image path) from client\n\n        Returns:\n            absolute path of the image\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ",", "\"_image\"", ")", ":", "\n", "            ", "image", "=", "self", ".", "_image", "\n", "del", "self", ".", "_image", "\n", "return", "tuple", "(", "image", ")", "\n", "\n", "", "request", "=", "self", ".", "_trax", ".", "wait", "(", ")", "\n", "\n", "if", "request", ".", "type", "==", "'frame'", ":", "\n", "            ", "image", "=", "[", "str", "(", "x", ")", "for", "k", ",", "x", "in", "request", ".", "image", ".", "items", "(", ")", "]", "\n", "if", "len", "(", "image", ")", "==", "1", ":", "\n", "                ", "image", "=", "image", "[", "0", "]", "\n", "", "return", "tuple", "(", "image", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot.VOT.region": [[109, 119], ["None"], "methods", ["None"], ["\n", "", "", "def", "quit", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "'_trax'", ")", ":", "\n", "            ", "self", ".", "_trax", ".", "quit", "(", ")", "\n", "\n", "", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "quit", "(", ")", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot.VOT.report": [[120, 137], ["isinstance", "isinstance", "isinstance", "vot.VOT._trax.status", "vot.VOT._result.append", "trax.region.Polygon", "trax.region.Rectangle"], "methods", ["None"], []], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot.VOT.frame": [[138, 162], ["hasattr", "vot.VOT._trax.wait", "str", "str", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot.VOT.quit": [[163, 171], ["vot.VOT._trax.quit", "hasattr", "open", "f.write", "f.write", "vot.encode_region"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.quit", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot.encode_region"], []], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot.VOT.__del__": [[172, 174], ["vot.VOT.quit"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.quit"], []], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot.parse_region": [[27, 34], ["map", "string.split", "len", "Rectangle", "Polygon", "len", "len", "Point", "xrange", "len"], "function", ["None"], ["def", "__init__", "(", "self", ",", "region_format", ",", "channels", "=", "None", ")", ":", "\n", "        ", "\"\"\" Constructor\n\n        Args:\n            region_format: Region format options\n        \"\"\"", "\n", "assert", "(", "region_format", "in", "[", "trax", ".", "Region", ".", "RECTANGLE", ",", "trax", ".", "Region", ".", "POLYGON", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot.encode_region": [[35, 42], ["isinstance", "isinstance"], "function", ["None"], ["if", "channels", "is", "None", ":", "\n", "            ", "channels", "=", "[", "'color'", "]", "\n", "", "elif", "channels", "==", "'rgbd'", ":", "\n", "            ", "channels", "=", "[", "'color'", ",", "'depth'", "]", "\n", "", "elif", "channels", "==", "'rgbt'", ":", "\n", "            ", "channels", "=", "[", "'color'", ",", "'ir'", "]", "\n", "", "elif", "channels", "==", "'ir'", ":", "\n", "            ", "channels", "=", "[", "'ir'", "]", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot.convert_region": [[43, 81], ["isinstance", "isinstance", "copy.copy", "isinstance", "points.append", "points.append", "points.append", "points.append", "Polygon", "isinstance", "Rectangle", "copy.copy", "min", "max", "min", "max"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Illegal configuration {}.'", ".", "format", "(", "channels", ")", ")", "\n", "\n", "", "self", ".", "_trax", "=", "trax", ".", "Server", "(", "[", "region_format", "]", ",", "[", "trax", ".", "Image", ".", "PATH", "]", ",", "channels", ")", "\n", "\n", "request", "=", "self", ".", "_trax", ".", "wait", "(", ")", "\n", "assert", "(", "request", ".", "type", "==", "'initialize'", ")", "\n", "if", "isinstance", "(", "request", ".", "region", ",", "trax", ".", "Polygon", ")", ":", "\n", "            ", "self", ".", "_region", "=", "Polygon", "(", "[", "Point", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", "for", "x", "in", "request", ".", "region", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_region", "=", "Rectangle", "(", "*", "request", ".", "region", ".", "bounds", "(", ")", ")", "\n", "", "self", ".", "_image", "=", "[", "str", "(", "x", ")", "for", "k", ",", "x", "in", "request", ".", "image", ".", "items", "(", ")", "]", "\n", "if", "len", "(", "self", ".", "_image", ")", "==", "1", ":", "\n", "            ", "self", ".", "_image", "=", "self", ".", "_image", "[", "0", "]", "\n", "", "self", ".", "_trax", ".", "status", "(", "request", ".", "region", ")", "\n", "\n", "", "def", "region", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Send configuration message to the client and receive the initialization\n        region and the path of the first image\n\n        Returns:\n            initialization region\n        \"\"\"", "\n", "\n", "return", "self", ".", "_region", "\n", "\n", "", "def", "report", "(", "self", ",", "region", ",", "confidence", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Report the tracking results to the client\n\n        Arguments:\n            region: region for the frame\n        \"\"\"", "\n", "assert", "(", "isinstance", "(", "region", ",", "Rectangle", ")", "or", "isinstance", "(", "region", ",", "Polygon", ")", ")", "\n", "if", "isinstance", "(", "region", ",", "Polygon", ")", ":", "\n", "            ", "tregion", "=", "trax", ".", "Polygon", ".", "create", "(", "[", "(", "x", ".", "x", ",", "x", ".", "y", ")", "for", "x", "in", "region", ".", "points", "]", ")", "\n", "", "else", ":", "\n", "            ", "tregion", "=", "trax", ".", "Rectangle", ".", "create", "(", "region", ".", "x", ",", "region", ".", "y", ",", "region", ".", "width", ",", "region", ".", "height", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.__init__": [[8, 22], ["collections.OrderedDict", "multi_object_wrapper.MultiObjectWrapper.base_tracker_class", "hasattr", "multi_object_wrapper.MultiObjectWrapper.tracker_copy.initialize_features"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features"], ["    ", "def", "__init__", "(", "self", ",", "base_tracker_class", ",", "params", ",", "visdom", "=", "None", ",", "fast_load", "=", "False", ",", "frame_reader", "=", "None", ")", ":", "\n", "        ", "self", ".", "base_tracker_class", "=", "base_tracker_class", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "visdom", "=", "visdom", "\n", "self", ".", "frame_reader", "=", "frame_reader", "\n", "\n", "self", ".", "initialized_ids", "=", "[", "]", "\n", "self", ".", "trackers", "=", "OrderedDict", "(", ")", "\n", "\n", "self", ".", "fast_load", "=", "fast_load", "\n", "if", "self", ".", "fast_load", ":", "\n", "            ", "self", ".", "tracker_copy", "=", "self", ".", "base_tracker_class", "(", "self", ".", "params", ")", "\n", "if", "hasattr", "(", "self", ".", "tracker_copy", ",", "'initialize_features'", ")", ":", "\n", "                ", "self", ".", "tracker_copy", ".", "initialize_features", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.create_tracker": [[23, 36], ["multi_object_wrapper.MultiObjectWrapper.base_tracker_class", "copy.deepcopy"], "methods", ["None"], ["", "", "", "def", "create_tracker", "(", "self", ")", ":", "\n", "        ", "tracker", "=", "None", "\n", "if", "self", ".", "fast_load", ":", "\n", "            ", "try", ":", "\n", "                ", "tracker", "=", "copy", ".", "deepcopy", "(", "self", ".", "tracker_copy", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "", "", "if", "tracker", "is", "None", ":", "\n", "            ", "tracker", "=", "self", ".", "base_tracker_class", "(", "self", ".", "params", ")", "\n", "", "tracker", ".", "visdom", "=", "self", ".", "visdom", "\n", "\n", "tracker", ".", "frame_reader", "=", "self", ".", "frame_reader", "\n", "return", "tracker", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper._split_info": [[37, 54], ["collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict.values", "dict", "dict", "int"], "methods", ["None"], ["", "def", "_split_info", "(", "self", ",", "info", ")", ":", "\n", "        ", "info_split", "=", "OrderedDict", "(", ")", "\n", "init_other", "=", "OrderedDict", "(", ")", "# Init other contains init info for all other objects", "\n", "for", "obj_id", "in", "info", "[", "'init_object_ids'", "]", ":", "\n", "            ", "info_split", "[", "obj_id", "]", "=", "dict", "(", ")", "\n", "init_other", "[", "obj_id", "]", "=", "dict", "(", ")", "\n", "info_split", "[", "obj_id", "]", "[", "'object_ids'", "]", "=", "[", "obj_id", "]", "\n", "info_split", "[", "obj_id", "]", "[", "'sequence_object_ids'", "]", "=", "info", "[", "'sequence_object_ids'", "]", "\n", "if", "'init_bbox'", "in", "info", ":", "\n", "                ", "info_split", "[", "obj_id", "]", "[", "'init_bbox'", "]", "=", "info", "[", "'init_bbox'", "]", "[", "obj_id", "]", "\n", "init_other", "[", "obj_id", "]", "[", "'init_bbox'", "]", "=", "info", "[", "'init_bbox'", "]", "[", "obj_id", "]", "\n", "", "if", "'init_mask'", "in", "info", ":", "\n", "                ", "info_split", "[", "obj_id", "]", "[", "'init_mask'", "]", "=", "(", "info", "[", "'init_mask'", "]", "==", "int", "(", "obj_id", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "init_other", "[", "obj_id", "]", "[", "'init_mask'", "]", "=", "info_split", "[", "obj_id", "]", "[", "'init_mask'", "]", "\n", "", "", "for", "obj_info", "in", "info_split", ".", "values", "(", ")", ":", "\n", "            ", "obj_info", "[", "'init_other'", "]", "=", "init_other", "\n", "", "return", "info_split", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper._set_defaults": [[55, 63], ["defaults.items", "tracker_out.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "_set_defaults", "(", "self", ",", "tracker_out", ":", "dict", ",", "defaults", "=", "None", ")", ":", "\n", "        ", "defaults", "=", "{", "}", "if", "defaults", "is", "None", "else", "defaults", "\n", "\n", "for", "key", ",", "val", "in", "defaults", ".", "items", "(", ")", ":", "\n", "            ", "if", "tracker_out", ".", "get", "(", "key", ")", "is", "None", ":", "\n", "                ", "tracker_out", "[", "key", "]", "=", "val", "\n", "\n", "", "", "return", "tracker_out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.default_merge": [[64, 92], ["collections.OrderedDict", "out_first.keys", "list", "numpy.stack", "numpy.array", "getattr", "out_all.values", "out.get", "out_all.values", "numpy.where", "map", "out_all.items", "out_all.keys", "numpy.stack.max", "numpy.stack.argmax"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "default_merge", "(", "self", ",", "out_all", ")", ":", "\n", "        ", "out_merged", "=", "OrderedDict", "(", ")", "\n", "\n", "out_first", "=", "list", "(", "out_all", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "out_types", "=", "out_first", ".", "keys", "(", ")", "\n", "\n", "# Merge segmentation mask", "\n", "if", "'segmentation'", "in", "out_types", "and", "out_first", "[", "'segmentation'", "]", "is", "not", "None", ":", "\n", "# Stack all masks", "\n", "# If a tracker outputs soft segmentation mask, use that. Else use the binary segmentation", "\n", "            ", "segmentation_maps", "=", "[", "out", ".", "get", "(", "'segmentation_soft'", ",", "out", "[", "'segmentation'", "]", ")", "for", "out", "in", "out_all", ".", "values", "(", ")", "]", "\n", "segmentation_maps", "=", "np", ".", "stack", "(", "segmentation_maps", ")", "\n", "\n", "obj_ids", "=", "np", ".", "array", "(", "[", "0", ",", "*", "map", "(", "int", ",", "out_all", ".", "keys", "(", ")", ")", "]", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "segm_threshold", "=", "getattr", "(", "self", ".", "params", ",", "'segmentation_threshold'", ",", "0.5", ")", "\n", "merged_segmentation", "=", "obj_ids", "[", "np", ".", "where", "(", "segmentation_maps", ".", "max", "(", "axis", "=", "0", ")", ">", "segm_threshold", ",", "\n", "segmentation_maps", ".", "argmax", "(", "axis", "=", "0", ")", "+", "1", ",", "0", ")", "]", "\n", "\n", "out_merged", "[", "'segmentation'", "]", "=", "merged_segmentation", "\n", "\n", "# Merge other fields", "\n", "", "for", "key", "in", "out_types", ":", "\n", "            ", "if", "key", "==", "'segmentation'", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "out_merged", "[", "key", "]", "=", "{", "obj_id", ":", "out", "[", "key", "]", "for", "obj_id", ",", "out", "in", "out_all", ".", "items", "(", ")", "}", "\n", "\n", "", "", "return", "out_merged", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.merge_outputs": [[93, 100], ["hasattr", "multi_object_wrapper.MultiObjectWrapper.trackers[].merge_results", "multi_object_wrapper.MultiObjectWrapper.default_merge"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl.LWL.merge_results", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.default_merge"], ["", "def", "merge_outputs", "(", "self", ",", "out_all", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "base_tracker_class", ",", "'merge_results'", ")", ":", "\n", "            ", "out_merged", "=", "self", ".", "trackers", "[", "self", ".", "initialized_ids", "[", "0", "]", "]", ".", "merge_results", "(", "out_all", ")", "\n", "", "else", ":", "\n", "            ", "out_merged", "=", "self", ".", "default_merge", "(", "out_all", ")", "\n", "\n", "", "return", "out_merged", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize": [[101, 134], ["collections.OrderedDict", "multi_object_wrapper.MultiObjectWrapper._split_info", "collections.OrderedDict", "collections.OrderedDict", "info[].copy", "multi_object_wrapper.MultiObjectWrapper.merge_outputs", "len", "time.time", "multi_object_wrapper.MultiObjectWrapper.trackers[].initialize", "multi_object_wrapper.MultiObjectWrapper._set_defaults", "multi_object_wrapper.MultiObjectWrapper.create_tracker", "init_info_split[].get", "init_info_split[].get", "time.time"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper._split_info", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.merge_outputs", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper._set_defaults", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.create_tracker", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "        ", "self", ".", "initialized_ids", "=", "[", "]", "\n", "self", ".", "trackers", "=", "OrderedDict", "(", ")", "\n", "\n", "if", "len", "(", "info", "[", "'init_object_ids'", "]", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "object_ids", "=", "info", "[", "'object_ids'", "]", "\n", "\n", "init_info_split", "=", "self", ".", "_split_info", "(", "info", ")", "\n", "self", ".", "trackers", "=", "OrderedDict", "(", "{", "obj_id", ":", "self", ".", "create_tracker", "(", ")", "for", "obj_id", "in", "object_ids", "}", ")", "\n", "\n", "out_all", "=", "OrderedDict", "(", ")", "\n", "# Run individual trackers for each object", "\n", "for", "obj_id", "in", "info", "[", "'init_object_ids'", "]", ":", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "out", "=", "self", ".", "trackers", "[", "obj_id", "]", ".", "initialize", "(", "image", ",", "init_info_split", "[", "obj_id", "]", ")", "\n", "if", "out", "is", "None", ":", "\n", "                ", "out", "=", "{", "}", "\n", "\n", "", "init_default", "=", "{", "'target_bbox'", ":", "init_info_split", "[", "obj_id", "]", ".", "get", "(", "'init_bbox'", ")", ",", "\n", "'time'", ":", "time", ".", "time", "(", ")", "-", "start_time", ",", "\n", "'segmentation'", ":", "init_info_split", "[", "obj_id", "]", ".", "get", "(", "'init_mask'", ")", "}", "\n", "\n", "out", "=", "self", ".", "_set_defaults", "(", "out", ",", "init_default", ")", "\n", "out_all", "[", "obj_id", "]", "=", "out", "\n", "\n", "", "self", ".", "initialized_ids", "=", "info", "[", "'init_object_ids'", "]", ".", "copy", "(", ")", "\n", "\n", "# Merge results", "\n", "out_merged", "=", "self", ".", "merge_outputs", "(", "out_all", ")", "\n", "\n", "return", "out_merged", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.track": [[135, 182], ["info.get", "info.get", "collections.OrderedDict", "info.get", "multi_object_wrapper.MultiObjectWrapper.merge_outputs", "collections.OrderedDict", "multi_object_wrapper.MultiObjectWrapper._split_info", "multi_object_wrapper.MultiObjectWrapper.values", "time.time", "multi_object_wrapper.MultiObjectWrapper.trackers[].track", "multi_object_wrapper.MultiObjectWrapper._set_defaults", "multi_object_wrapper.MultiObjectWrapper.initialized_ids.extend", "time.time", "multi_object_wrapper.MultiObjectWrapper.trackers[].initialize", "multi_object_wrapper.MultiObjectWrapper._set_defaults", "list", "time.time", "multi_object_wrapper.MultiObjectWrapper.create_tracker", "init_info_split[].get", "init_info_split[].get", "multi_object_wrapper.MultiObjectWrapper.values", "time.time"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.merge_outputs", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper._split_info", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.track", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper._set_defaults", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper._set_defaults", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.create_tracker", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "track", "(", "self", ",", "image", ",", "info", ":", "dict", "=", "None", ")", "->", "dict", ":", "\n", "        ", "if", "info", "is", "None", ":", "\n", "            ", "info", "=", "{", "}", "\n", "\n", "", "prev_output", "=", "info", ".", "get", "(", "'previous_output'", ",", "OrderedDict", "(", ")", ")", "\n", "\n", "if", "info", ".", "get", "(", "'init_object_ids'", ",", "False", ")", ":", "\n", "            ", "init_info_split", "=", "self", ".", "_split_info", "(", "info", ")", "\n", "for", "obj_init_info", "in", "init_info_split", ".", "values", "(", ")", ":", "\n", "                ", "obj_init_info", "[", "'previous_output'", "]", "=", "prev_output", "\n", "\n", "", "info", "[", "'init_other'", "]", "=", "list", "(", "init_info_split", ".", "values", "(", ")", ")", "[", "0", "]", "[", "'init_other'", "]", "\n", "\n", "", "out_all", "=", "OrderedDict", "(", ")", "\n", "for", "obj_id", "in", "self", ".", "initialized_ids", ":", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "out", "=", "self", ".", "trackers", "[", "obj_id", "]", ".", "track", "(", "image", ",", "info", ")", "\n", "\n", "default", "=", "{", "'time'", ":", "time", ".", "time", "(", ")", "-", "start_time", "}", "\n", "out", "=", "self", ".", "_set_defaults", "(", "out", ",", "default", ")", "\n", "out_all", "[", "obj_id", "]", "=", "out", "\n", "\n", "# Initialize new", "\n", "", "if", "info", ".", "get", "(", "'init_object_ids'", ",", "False", ")", ":", "\n", "            ", "for", "obj_id", "in", "info", "[", "'init_object_ids'", "]", ":", "\n", "                ", "if", "not", "obj_id", "in", "self", ".", "trackers", ":", "\n", "                    ", "self", ".", "trackers", "[", "obj_id", "]", "=", "self", ".", "create_tracker", "(", ")", "\n", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "out", "=", "self", ".", "trackers", "[", "obj_id", "]", ".", "initialize", "(", "image", ",", "init_info_split", "[", "obj_id", "]", ")", "\n", "if", "out", "is", "None", ":", "\n", "                    ", "out", "=", "{", "}", "\n", "\n", "", "init_default", "=", "{", "'target_bbox'", ":", "init_info_split", "[", "obj_id", "]", ".", "get", "(", "'init_bbox'", ")", ",", "\n", "'time'", ":", "time", ".", "time", "(", ")", "-", "start_time", ",", "\n", "'segmentation'", ":", "init_info_split", "[", "obj_id", "]", ".", "get", "(", "'init_mask'", ")", "}", "\n", "\n", "out", "=", "self", ".", "_set_defaults", "(", "out", ",", "init_default", ")", "\n", "out_all", "[", "obj_id", "]", "=", "out", "\n", "\n", "", "self", ".", "initialized_ids", ".", "extend", "(", "info", "[", "'init_object_ids'", "]", ")", "\n", "\n", "# Merge results", "\n", "", "out_merged", "=", "self", ".", "merge_outputs", "(", "out_all", ")", "\n", "\n", "return", "out_merged", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.visdom_draw_tracking": [[183, 192], ["isinstance", "multi_object_wrapper.MultiObjectWrapper.visdom.register", "multi_object_wrapper.MultiObjectWrapper.visdom.register", "box.items"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register"], ["", "def", "visdom_draw_tracking", "(", "self", ",", "image", ",", "box", ",", "segmentation", ")", ":", "\n", "        ", "if", "isinstance", "(", "box", ",", "(", "OrderedDict", ",", "dict", ")", ")", ":", "\n", "            ", "box", "=", "[", "v", "for", "k", ",", "v", "in", "box", ".", "items", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "box", "=", "(", "box", ",", ")", "\n", "", "if", "segmentation", "is", "None", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "*", "box", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "visdom", ".", "register", "(", "(", "image", ",", "*", "box", ",", "segmentation", ")", ",", "'Tracking'", ",", "1", ",", "'Tracking'", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.__init__": [[50, 84], ["trax.Server", "vot2020.VOT._trax.wait", "isinstance", "isinstance", "vot2020.VOT._trax.status", "Polygon", "vot2020.VOT.region.array", "Rectangle", "x.path", "len", "dict", "vot2020.VOT.image.items", "Point", "vot2020.VOT.region.bounds", "Exception"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "region_format", ",", "channels", "=", "None", ")", ":", "\n", "        ", "\"\"\" Constructor\n\n        Args:\n            region_format: Region format options\n        \"\"\"", "\n", "assert", "(", "region_format", "in", "[", "trax", ".", "Region", ".", "RECTANGLE", ",", "trax", ".", "Region", ".", "POLYGON", ",", "trax", ".", "Region", ".", "MASK", "]", ")", "\n", "\n", "if", "channels", "is", "None", ":", "\n", "            ", "channels", "=", "[", "'color'", "]", "\n", "", "elif", "channels", "==", "'rgbd'", ":", "\n", "            ", "channels", "=", "[", "'color'", ",", "'depth'", "]", "\n", "", "elif", "channels", "==", "'rgbt'", ":", "\n", "            ", "channels", "=", "[", "'color'", ",", "'ir'", "]", "\n", "", "elif", "channels", "==", "'ir'", ":", "\n", "            ", "channels", "=", "[", "'ir'", "]", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Illegal configuration {}.'", ".", "format", "(", "channels", ")", ")", "\n", "\n", "", "self", ".", "_trax", "=", "trax", ".", "Server", "(", "[", "region_format", "]", ",", "[", "trax", ".", "Image", ".", "PATH", "]", ",", "channels", ",", "customMetadata", "=", "dict", "(", "vot", "=", "\"python\"", ")", ")", "\n", "\n", "request", "=", "self", ".", "_trax", ".", "wait", "(", ")", "\n", "assert", "(", "request", ".", "type", "==", "'initialize'", ")", "\n", "if", "isinstance", "(", "request", ".", "region", ",", "trax", ".", "Polygon", ")", ":", "\n", "            ", "self", ".", "_region", "=", "Polygon", "(", "[", "Point", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", "for", "x", "in", "request", ".", "region", "]", ")", "\n", "", "if", "isinstance", "(", "request", ".", "region", ",", "trax", ".", "Mask", ")", ":", "\n", "            ", "self", ".", "_region", "=", "request", ".", "region", ".", "array", "(", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_region", "=", "Rectangle", "(", "*", "request", ".", "region", ".", "bounds", "(", ")", ")", "\n", "", "self", ".", "_image", "=", "[", "x", ".", "path", "(", ")", "for", "k", ",", "x", "in", "request", ".", "image", ".", "items", "(", ")", "]", "\n", "if", "len", "(", "self", ".", "_image", ")", "==", "1", ":", "\n", "            ", "self", ".", "_image", "=", "self", ".", "_image", "[", "0", "]", "\n", "\n", "", "self", ".", "_trax", ".", "status", "(", "request", ".", "region", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.region": [[85, 95], ["None"], "methods", ["None"], ["", "def", "region", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Send configuration message to the client and receive the initialization\n        region and the path of the first image\n\n        Returns:\n            initialization region\n        \"\"\"", "\n", "\n", "return", "self", ".", "_region", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.report": [[96, 114], ["isinstance", "isinstance", "isinstance", "vot2020.VOT._trax.status", "trax.Polygon.create", "trax.Mask.create", "trax.Rectangle.create"], "methods", ["None"], ["", "def", "report", "(", "self", ",", "region", ",", "confidence", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Report the tracking results to the client\n\n        Arguments:\n            region: region for the frame\n        \"\"\"", "\n", "assert", "(", "isinstance", "(", "region", ",", "(", "Rectangle", ",", "Polygon", ",", "np", ".", "ndarray", ")", ")", ")", "\n", "if", "isinstance", "(", "region", ",", "Polygon", ")", ":", "\n", "            ", "tregion", "=", "trax", ".", "Polygon", ".", "create", "(", "[", "(", "x", ".", "x", ",", "x", ".", "y", ")", "for", "x", "in", "region", ".", "points", "]", ")", "\n", "", "if", "isinstance", "(", "region", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "tregion", "=", "trax", ".", "Mask", ".", "create", "(", "region", ")", "\n", "", "else", ":", "\n", "            ", "tregion", "=", "trax", ".", "Rectangle", ".", "create", "(", "region", ".", "x", ",", "region", ".", "y", ",", "region", ".", "width", ",", "region", ".", "height", ")", "\n", "", "properties", "=", "{", "}", "\n", "if", "not", "confidence", "is", "None", ":", "\n", "            ", "properties", "[", "'confidence'", "]", "=", "confidence", "\n", "", "self", ".", "_trax", ".", "status", "(", "tregion", ",", "properties", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.frame": [[115, 136], ["hasattr", "vot2020.VOT._trax.wait", "x.path", "len", "vot2020.VOT.image.items"], "methods", ["None"], ["", "def", "frame", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get a frame (image path) from client\n\n        Returns:\n            absolute path of the image\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ",", "\"_image\"", ")", ":", "\n", "            ", "image", "=", "self", ".", "_image", "\n", "del", "self", ".", "_image", "\n", "return", "image", "\n", "\n", "", "request", "=", "self", ".", "_trax", ".", "wait", "(", ")", "\n", "\n", "if", "request", ".", "type", "==", "'frame'", ":", "\n", "            ", "image", "=", "[", "x", ".", "path", "(", ")", "for", "k", ",", "x", "in", "request", ".", "image", ".", "items", "(", ")", "]", "\n", "if", "len", "(", "image", ")", "==", "1", ":", "\n", "                ", "return", "image", "[", "0", "]", "\n", "", "return", "image", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.quit": [[138, 141], ["hasattr", "vot2020.VOT._trax.quit"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.quit"], ["", "", "def", "quit", "(", "self", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ",", "'_trax'", ")", ":", "\n", "            ", "self", ".", "_trax", ".", "quit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.__del__": [[142, 144], ["vot2020.VOT.quit"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.quit"], ["", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "quit", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.make_full_size": [[23, 42], ["numpy.pad"], "function", ["None"], ["", "def", "make_full_size", "(", "x", ",", "output_sz", ")", ":", "\n", "    ", "'''\n    zero-pad input x (right and down) to match output_sz\n    x: numpy array e.g., binary mask\n    output_sz: size of the output [width, height]\n    '''", "\n", "if", "x", ".", "shape", "[", "0", "]", "==", "output_sz", "[", "1", "]", "and", "x", ".", "shape", "[", "1", "]", "==", "output_sz", "[", "0", "]", ":", "\n", "        ", "return", "x", "\n", "", "pad_x", "=", "output_sz", "[", "0", "]", "-", "x", ".", "shape", "[", "1", "]", "\n", "if", "pad_x", "<", "0", ":", "\n", "        ", "x", "=", "x", "[", ":", ",", ":", "x", ".", "shape", "[", "1", "]", "+", "pad_x", "]", "\n", "# padding has to be set to zero, otherwise pad function fails", "\n", "pad_x", "=", "0", "\n", "", "pad_y", "=", "output_sz", "[", "1", "]", "-", "x", ".", "shape", "[", "0", "]", "\n", "if", "pad_y", "<", "0", ":", "\n", "        ", "x", "=", "x", "[", ":", "x", ".", "shape", "[", "0", "]", "+", "pad_y", ",", ":", "]", "\n", "# padding has to be set to zero, otherwise pad function fails", "\n", "pad_y", "=", "0", "\n", "", "return", "np", ".", "pad", "(", "x", ",", "(", "(", "0", ",", "pad_y", ")", ",", "(", "0", ",", "pad_x", ")", ")", ",", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.nfsdataset.NFSDataset.__init__": [[17, 21], ["pytracking.evaluation.data.BaseDataset.__init__", "nfsdataset.NFSDataset._get_sequence_info_list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.uavdataset.UAVDataset._get_sequence_info_list"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_path", "=", "self", ".", "env_settings", ".", "nfs_path", "\n", "self", ".", "sequence_info_list", "=", "self", ".", "_get_sequence_info_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.nfsdataset.NFSDataset.get_sequence_list": [[22, 24], ["pytracking.evaluation.data.SequenceList", "nfsdataset.NFSDataset._construct_sequence"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence"], ["", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "return", "SequenceList", "(", "[", "self", ".", "_construct_sequence", "(", "s", ")", "for", "s", "in", "self", ".", "sequence_info_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.nfsdataset.NFSDataset._construct_sequence": [[25, 45], ["pytracking.utils.load_text.load_text", "pytracking.evaluation.data.Sequence", "str", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text"], ["", "def", "_construct_sequence", "(", "self", ",", "sequence_info", ")", ":", "\n", "        ", "sequence_path", "=", "sequence_info", "[", "'path'", "]", "\n", "nz", "=", "sequence_info", "[", "'nz'", "]", "\n", "ext", "=", "sequence_info", "[", "'ext'", "]", "\n", "start_frame", "=", "sequence_info", "[", "'startFrame'", "]", "\n", "end_frame", "=", "sequence_info", "[", "'endFrame'", "]", "\n", "\n", "init_omit", "=", "0", "\n", "if", "'initOmit'", "in", "sequence_info", ":", "\n", "            ", "init_omit", "=", "sequence_info", "[", "'initOmit'", "]", "\n", "\n", "", "frames", "=", "[", "'{base_path}/{sequence_path}/{frame:0{nz}}.{ext}'", ".", "format", "(", "base_path", "=", "self", ".", "base_path", ",", "\n", "sequence_path", "=", "sequence_path", ",", "frame", "=", "frame_num", ",", "nz", "=", "nz", ",", "ext", "=", "ext", ")", "for", "frame_num", "in", "range", "(", "start_frame", "+", "init_omit", ",", "end_frame", "+", "1", ")", "]", "\n", "\n", "anno_path", "=", "'{}/{}'", ".", "format", "(", "self", ".", "base_path", ",", "sequence_info", "[", "'anno_path'", "]", ")", "\n", "\n", "ground_truth_rect", "=", "load_text", "(", "str", "(", "anno_path", ")", ",", "delimiter", "=", "'\\t'", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "return", "Sequence", "(", "sequence_info", "[", "'name'", "]", ",", "frames", ",", "'nfs'", ",", "ground_truth_rect", "[", "init_omit", ":", ",", ":", "]", ",", "\n", "object_class", "=", "sequence_info", "[", "'object_class'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.nfsdataset.NFSDataset.__len__": [[46, 48], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_info_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.nfsdataset.NFSDataset._get_sequence_info_list": [[49, 154], ["None"], "methods", ["None"], ["", "def", "_get_sequence_info_list", "(", "self", ")", ":", "\n", "        ", "sequence_info_list", "=", "[", "\n", "{", "\"name\"", ":", "\"nfs_Gymnastics\"", ",", "\"path\"", ":", "\"sequences/Gymnastics\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "368", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_Gymnastics.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_MachLoop_jet\"", ",", "\"path\"", ":", "\"sequences/MachLoop_jet\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "99", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_MachLoop_jet.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_Skiing_red\"", ",", "\"path\"", ":", "\"sequences/Skiing_red\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "69", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_Skiing_red.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_Skydiving\"", ",", "\"path\"", ":", "\"sequences/Skydiving\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "196", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_Skydiving.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_airboard_1\"", ",", "\"path\"", ":", "\"sequences/airboard_1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "425", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_airboard_1.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_airplane_landing\"", ",", "\"path\"", ":", "\"sequences/airplane_landing\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "81", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_airplane_landing.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_airtable_3\"", ",", "\"path\"", ":", "\"sequences/airtable_3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "482", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_airtable_3.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_basketball_1\"", ",", "\"path\"", ":", "\"sequences/basketball_1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "282", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_basketball_1.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_basketball_2\"", ",", "\"path\"", ":", "\"sequences/basketball_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "102", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_basketball_2.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_basketball_3\"", ",", "\"path\"", ":", "\"sequences/basketball_3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "421", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_basketball_3.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_basketball_6\"", ",", "\"path\"", ":", "\"sequences/basketball_6\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "224", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_basketball_6.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_basketball_7\"", ",", "\"path\"", ":", "\"sequences/basketball_7\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "240", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_basketball_7.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_basketball_player\"", ",", "\"path\"", ":", "\"sequences/basketball_player\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "369", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_basketball_player.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_basketball_player_2\"", ",", "\"path\"", ":", "\"sequences/basketball_player_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "437", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_basketball_player_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_beach_flipback_person\"", ",", "\"path\"", ":", "\"sequences/beach_flipback_person\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "61", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_beach_flipback_person.txt\"", ",", "\"object_class\"", ":", "\"person head\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_bee\"", ",", "\"path\"", ":", "\"sequences/bee\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "45", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_bee.txt\"", ",", "\"object_class\"", ":", "\"insect\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_biker_acrobat\"", ",", "\"path\"", ":", "\"sequences/biker_acrobat\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "128", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_biker_acrobat.txt\"", ",", "\"object_class\"", ":", "\"bicycle\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_biker_all_1\"", ",", "\"path\"", ":", "\"sequences/biker_all_1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "113", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_biker_all_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_biker_head_2\"", ",", "\"path\"", ":", "\"sequences/biker_head_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "132", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_biker_head_2.txt\"", ",", "\"object_class\"", ":", "\"person head\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_biker_head_3\"", ",", "\"path\"", ":", "\"sequences/biker_head_3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "254", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_biker_head_3.txt\"", ",", "\"object_class\"", ":", "\"person head\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_biker_upper_body\"", ",", "\"path\"", ":", "\"sequences/biker_upper_body\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "194", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_biker_upper_body.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_biker_whole_body\"", ",", "\"path\"", ":", "\"sequences/biker_whole_body\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "572", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_biker_whole_body.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_billiard_2\"", ",", "\"path\"", ":", "\"sequences/billiard_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "604", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_billiard_2.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_billiard_3\"", ",", "\"path\"", ":", "\"sequences/billiard_3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "698", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_billiard_3.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_billiard_6\"", ",", "\"path\"", ":", "\"sequences/billiard_6\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "771", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_billiard_6.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_billiard_7\"", ",", "\"path\"", ":", "\"sequences/billiard_7\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "724", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_billiard_7.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_billiard_8\"", ",", "\"path\"", ":", "\"sequences/billiard_8\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "778", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_billiard_8.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_bird_2\"", ",", "\"path\"", ":", "\"sequences/bird_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "476", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_bird_2.txt\"", ",", "\"object_class\"", ":", "\"bird\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_book\"", ",", "\"path\"", ":", "\"sequences/book\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "288", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_book.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_bottle\"", ",", "\"path\"", ":", "\"sequences/bottle\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "2103", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_bottle.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_bowling_1\"", ",", "\"path\"", ":", "\"sequences/bowling_1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "303", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_bowling_1.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_bowling_2\"", ",", "\"path\"", ":", "\"sequences/bowling_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "710", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_bowling_2.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_bowling_3\"", ",", "\"path\"", ":", "\"sequences/bowling_3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "271", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_bowling_3.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_bowling_6\"", ",", "\"path\"", ":", "\"sequences/bowling_6\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "260", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_bowling_6.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_bowling_ball\"", ",", "\"path\"", ":", "\"sequences/bowling_ball\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "275", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_bowling_ball.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_bunny\"", ",", "\"path\"", ":", "\"sequences/bunny\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "705", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_bunny.txt\"", ",", "\"object_class\"", ":", "\"mammal\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_car\"", ",", "\"path\"", ":", "\"sequences/car\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "2020", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_car.txt\"", ",", "\"object_class\"", ":", "\"car\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_car_camaro\"", ",", "\"path\"", ":", "\"sequences/car_camaro\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "36", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_car_camaro.txt\"", ",", "\"object_class\"", ":", "\"car\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_car_drifting\"", ",", "\"path\"", ":", "\"sequences/car_drifting\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "173", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_car_drifting.txt\"", ",", "\"object_class\"", ":", "\"car\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_car_jumping\"", ",", "\"path\"", ":", "\"sequences/car_jumping\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "22", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_car_jumping.txt\"", ",", "\"object_class\"", ":", "\"car\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_car_rc_rolling\"", ",", "\"path\"", ":", "\"sequences/car_rc_rolling\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "62", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_car_rc_rolling.txt\"", ",", "\"object_class\"", ":", "\"car\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_car_rc_rotating\"", ",", "\"path\"", ":", "\"sequences/car_rc_rotating\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "80", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_car_rc_rotating.txt\"", ",", "\"object_class\"", ":", "\"car\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_car_side\"", ",", "\"path\"", ":", "\"sequences/car_side\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "108", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_car_side.txt\"", ",", "\"object_class\"", ":", "\"car\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_car_white\"", ",", "\"path\"", ":", "\"sequences/car_white\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "2063", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_car_white.txt\"", ",", "\"object_class\"", ":", "\"car\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_cheetah\"", ",", "\"path\"", ":", "\"sequences/cheetah\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "167", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_cheetah.txt\"", ",", "\"object_class\"", ":", "\"mammal\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_cup\"", ",", "\"path\"", ":", "\"sequences/cup\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1281", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_cup.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_cup_2\"", ",", "\"path\"", ":", "\"sequences/cup_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "182", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_cup_2.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_dog\"", ",", "\"path\"", ":", "\"sequences/dog\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1030", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_dog.txt\"", ",", "\"object_class\"", ":", "\"dog\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_dog_1\"", ",", "\"path\"", ":", "\"sequences/dog_1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "168", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_dog_1.txt\"", ",", "\"object_class\"", ":", "\"dog\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_dog_2\"", ",", "\"path\"", ":", "\"sequences/dog_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "594", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_dog_2.txt\"", ",", "\"object_class\"", ":", "\"dog\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_dog_3\"", ",", "\"path\"", ":", "\"sequences/dog_3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "200", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_dog_3.txt\"", ",", "\"object_class\"", ":", "\"dog\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_dogs\"", ",", "\"path\"", ":", "\"sequences/dogs\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "198", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_dogs.txt\"", ",", "\"object_class\"", ":", "\"dog\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_dollar\"", ",", "\"path\"", ":", "\"sequences/dollar\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1426", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_dollar.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_drone\"", ",", "\"path\"", ":", "\"sequences/drone\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "70", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_drone.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_ducks_lake\"", ",", "\"path\"", ":", "\"sequences/ducks_lake\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "107", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_ducks_lake.txt\"", ",", "\"object_class\"", ":", "\"bird\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_exit\"", ",", "\"path\"", ":", "\"sequences/exit\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "359", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_exit.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_first\"", ",", "\"path\"", ":", "\"sequences/first\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "435", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_first.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_flower\"", ",", "\"path\"", ":", "\"sequences/flower\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "448", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_flower.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_footbal_skill\"", ",", "\"path\"", ":", "\"sequences/footbal_skill\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "131", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_footbal_skill.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_helicopter\"", ",", "\"path\"", ":", "\"sequences/helicopter\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "310", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_helicopter.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_horse_jumping\"", ",", "\"path\"", ":", "\"sequences/horse_jumping\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "117", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_horse_jumping.txt\"", ",", "\"object_class\"", ":", "\"horse\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_horse_running\"", ",", "\"path\"", ":", "\"sequences/horse_running\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "139", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_horse_running.txt\"", ",", "\"object_class\"", ":", "\"horse\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_iceskating_6\"", ",", "\"path\"", ":", "\"sequences/iceskating_6\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "603", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_iceskating_6.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_jellyfish_5\"", ",", "\"path\"", ":", "\"sequences/jellyfish_5\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "746", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_jellyfish_5.txt\"", ",", "\"object_class\"", ":", "\"invertebrate\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_kid_swing\"", ",", "\"path\"", ":", "\"sequences/kid_swing\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "169", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_kid_swing.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_motorcross\"", ",", "\"path\"", ":", "\"sequences/motorcross\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "39", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_motorcross.txt\"", ",", "\"object_class\"", ":", "\"vehicle\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_motorcross_kawasaki\"", ",", "\"path\"", ":", "\"sequences/motorcross_kawasaki\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "65", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_motorcross_kawasaki.txt\"", ",", "\"object_class\"", ":", "\"vehicle\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_parkour\"", ",", "\"path\"", ":", "\"sequences/parkour\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "58", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_parkour.txt\"", ",", "\"object_class\"", ":", "\"person head\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_person_scooter\"", ",", "\"path\"", ":", "\"sequences/person_scooter\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "413", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_person_scooter.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_pingpong_2\"", ",", "\"path\"", ":", "\"sequences/pingpong_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1277", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_pingpong_2.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_pingpong_7\"", ",", "\"path\"", ":", "\"sequences/pingpong_7\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1290", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_pingpong_7.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_pingpong_8\"", ",", "\"path\"", ":", "\"sequences/pingpong_8\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "296", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_pingpong_8.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_purse\"", ",", "\"path\"", ":", "\"sequences/purse\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "968", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_purse.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_rubber\"", ",", "\"path\"", ":", "\"sequences/rubber\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1328", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_rubber.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_running\"", ",", "\"path\"", ":", "\"sequences/running\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "677", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_running.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_running_100_m\"", ",", "\"path\"", ":", "\"sequences/running_100_m\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "313", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_running_100_m.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_running_100_m_2\"", ",", "\"path\"", ":", "\"sequences/running_100_m_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "337", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_running_100_m_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_running_2\"", ",", "\"path\"", ":", "\"sequences/running_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "363", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_running_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_shuffleboard_1\"", ",", "\"path\"", ":", "\"sequences/shuffleboard_1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "42", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_shuffleboard_1.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_shuffleboard_2\"", ",", "\"path\"", ":", "\"sequences/shuffleboard_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "41", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_shuffleboard_2.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_shuffleboard_4\"", ",", "\"path\"", ":", "\"sequences/shuffleboard_4\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "62", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_shuffleboard_4.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_shuffleboard_5\"", ",", "\"path\"", ":", "\"sequences/shuffleboard_5\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "32", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_shuffleboard_5.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_shuffleboard_6\"", ",", "\"path\"", ":", "\"sequences/shuffleboard_6\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "52", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_shuffleboard_6.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_shuffletable_2\"", ",", "\"path\"", ":", "\"sequences/shuffletable_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "372", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_shuffletable_2.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_shuffletable_3\"", ",", "\"path\"", ":", "\"sequences/shuffletable_3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "368", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_shuffletable_3.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_shuffletable_4\"", ",", "\"path\"", ":", "\"sequences/shuffletable_4\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "101", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_shuffletable_4.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_ski_long\"", ",", "\"path\"", ":", "\"sequences/ski_long\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "274", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_ski_long.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_soccer_ball\"", ",", "\"path\"", ":", "\"sequences/soccer_ball\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "163", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_soccer_ball.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_soccer_ball_2\"", ",", "\"path\"", ":", "\"sequences/soccer_ball_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1934", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_soccer_ball_2.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_soccer_ball_3\"", ",", "\"path\"", ":", "\"sequences/soccer_ball_3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1381", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_soccer_ball_3.txt\"", ",", "\"object_class\"", ":", "\"ball\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_soccer_player_2\"", ",", "\"path\"", ":", "\"sequences/soccer_player_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "475", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_soccer_player_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_soccer_player_3\"", ",", "\"path\"", ":", "\"sequences/soccer_player_3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "319", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_soccer_player_3.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "True", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_stop_sign\"", ",", "\"path\"", ":", "\"sequences/stop_sign\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "302", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_stop_sign.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_suv\"", ",", "\"path\"", ":", "\"sequences/suv\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "2584", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_suv.txt\"", ",", "\"object_class\"", ":", "\"car\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_tiger\"", ",", "\"path\"", ":", "\"sequences/tiger\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1556", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_tiger.txt\"", ",", "\"object_class\"", ":", "\"mammal\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_walking\"", ",", "\"path\"", ":", "\"sequences/walking\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "555", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_walking.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_walking_3\"", ",", "\"path\"", ":", "\"sequences/walking_3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1427", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_walking_3.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_water_ski_2\"", ",", "\"path\"", ":", "\"sequences/water_ski_2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "47", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_water_ski_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_yoyo\"", ",", "\"path\"", ":", "\"sequences/yoyo\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "67", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_yoyo.txt\"", ",", "\"object_class\"", ":", "\"other\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "{", "\"name\"", ":", "\"nfs_zebra_fish\"", ",", "\"path\"", ":", "\"sequences/zebra_fish\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "671", ",", "\"nz\"", ":", "5", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/nfs_zebra_fish.txt\"", ",", "\"object_class\"", ":", "\"fish\"", ",", "'occlusion'", ":", "False", "}", ",", "\n", "]", "\n", "\n", "return", "sequence_info_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.BaseDataset.__init__": [[9, 11], ["pytracking.evaluation.environment.env_settings"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "env_settings", "=", "env_settings", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.BaseDataset.__len__": [[12, 15], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Overload this function in your dataset. This should return number of sequences in the dataset.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.BaseDataset.get_sequence_list": [[16, 19], ["None"], "methods", ["None"], ["", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "\"\"\"Overload this in your dataset. Should return the list of sequences in the dataset.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.__init__": [[23, 36], ["data.Sequence._construct_init_data", "data.Sequence._ensure_start_frame"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence._construct_init_data", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence._ensure_start_frame"], ["def", "__init__", "(", "self", ",", "name", ",", "frames", ",", "dataset", ",", "ground_truth_rect", ",", "ground_truth_seg", "=", "None", ",", "init_data", "=", "None", ",", "\n", "object_class", "=", "None", ",", "target_visible", "=", "None", ",", "object_ids", "=", "None", ",", "multiobj_mode", "=", "False", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "frames", "=", "frames", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "ground_truth_rect", "=", "ground_truth_rect", "\n", "self", ".", "ground_truth_seg", "=", "ground_truth_seg", "\n", "self", ".", "object_class", "=", "object_class", "\n", "self", ".", "target_visible", "=", "target_visible", "\n", "self", ".", "object_ids", "=", "object_ids", "\n", "self", ".", "multiobj_mode", "=", "multiobj_mode", "\n", "self", ".", "init_data", "=", "self", ".", "_construct_init_data", "(", "init_data", ")", "\n", "self", ".", "_ensure_start_frame", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence._ensure_start_frame": [[37, 55], ["min", "list", "data.Sequence.init_data.keys", "isinstance", "data.Sequence.ground_truth_rect.items", "len", "len", "data.Sequence.init_data.items"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "_ensure_start_frame", "(", "self", ")", ":", "\n", "# Ensure start frame is 0", "\n", "        ", "start_frame", "=", "min", "(", "list", "(", "self", ".", "init_data", ".", "keys", "(", ")", ")", ")", "\n", "if", "start_frame", ">", "0", ":", "\n", "            ", "self", ".", "frames", "=", "self", ".", "frames", "[", "start_frame", ":", "]", "\n", "if", "self", ".", "ground_truth_rect", "is", "not", "None", ":", "\n", "                ", "if", "isinstance", "(", "self", ".", "ground_truth_rect", ",", "(", "dict", ",", "OrderedDict", ")", ")", ":", "\n", "                    ", "for", "obj_id", ",", "gt", "in", "self", ".", "ground_truth_rect", ".", "items", "(", ")", ":", "\n", "                        ", "self", ".", "ground_truth_rect", "[", "obj_id", "]", "=", "gt", "[", "start_frame", ":", ",", ":", "]", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "ground_truth_rect", "=", "self", ".", "ground_truth_rect", "[", "start_frame", ":", ",", ":", "]", "\n", "", "", "if", "self", ".", "ground_truth_seg", "is", "not", "None", ":", "\n", "                ", "self", ".", "ground_truth_seg", "=", "self", ".", "ground_truth_seg", "[", "start_frame", ":", "]", "\n", "assert", "len", "(", "self", ".", "frames", ")", "==", "len", "(", "self", ".", "ground_truth_seg", ")", "\n", "\n", "", "if", "self", ".", "target_visible", "is", "not", "None", ":", "\n", "                ", "self", ".", "target_visible", "=", "self", ".", "target_visible", "[", "start_frame", ":", "]", "\n", "", "self", ".", "init_data", "=", "{", "frame", "-", "start_frame", ":", "val", "for", "frame", ",", "val", "in", "self", ".", "init_data", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence._construct_init_data": [[56, 91], ["init_data.items", "init_data.items", "dict", "isinstance", "isinstance", "collections.OrderedDict", "isinstance", "len", "isinstance", "collections.OrderedDict", "list", "list", "list", "list", "len", "list", "data.Sequence.ground_truth_rect.items", "init_val[].items"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "", "def", "_construct_init_data", "(", "self", ",", "init_data", ")", ":", "\n", "        ", "if", "init_data", "is", "not", "None", ":", "\n", "            ", "if", "not", "self", ".", "multiobj_mode", ":", "\n", "                ", "assert", "self", ".", "object_ids", "is", "None", "or", "len", "(", "self", ".", "object_ids", ")", "==", "1", "\n", "for", "frame", ",", "init_val", "in", "init_data", ".", "items", "(", ")", ":", "\n", "                    ", "if", "'bbox'", "in", "init_val", "and", "isinstance", "(", "init_val", "[", "'bbox'", "]", ",", "(", "dict", ",", "OrderedDict", ")", ")", ":", "\n", "                        ", "init_val", "[", "'bbox'", "]", "=", "init_val", "[", "'bbox'", "]", "[", "self", ".", "object_ids", "[", "0", "]", "]", "\n", "# convert to list", "\n", "", "", "", "for", "frame", ",", "init_val", "in", "init_data", ".", "items", "(", ")", ":", "\n", "                ", "if", "'bbox'", "in", "init_val", ":", "\n", "                    ", "if", "isinstance", "(", "init_val", "[", "'bbox'", "]", ",", "(", "dict", ",", "OrderedDict", ")", ")", ":", "\n", "                        ", "init_val", "[", "'bbox'", "]", "=", "OrderedDict", "(", "{", "obj_id", ":", "list", "(", "init", ")", "for", "obj_id", ",", "init", "in", "init_val", "[", "'bbox'", "]", ".", "items", "(", ")", "}", ")", "\n", "", "else", ":", "\n", "                        ", "init_val", "[", "'bbox'", "]", "=", "list", "(", "init_val", "[", "'bbox'", "]", ")", "\n", "", "", "", "", "else", ":", "\n", "            ", "init_data", "=", "{", "0", ":", "dict", "(", ")", "}", "# Assume start from frame 0", "\n", "\n", "if", "self", ".", "object_ids", "is", "not", "None", ":", "\n", "                ", "init_data", "[", "0", "]", "[", "'object_ids'", "]", "=", "self", ".", "object_ids", "\n", "\n", "", "if", "self", ".", "ground_truth_rect", "is", "not", "None", ":", "\n", "                ", "if", "self", ".", "multiobj_mode", ":", "\n", "                    ", "assert", "isinstance", "(", "self", ".", "ground_truth_rect", ",", "(", "dict", ",", "OrderedDict", ")", ")", "\n", "init_data", "[", "0", "]", "[", "'bbox'", "]", "=", "OrderedDict", "(", "{", "obj_id", ":", "list", "(", "gt", "[", "0", ",", ":", "]", ")", "for", "obj_id", ",", "gt", "in", "self", ".", "ground_truth_rect", ".", "items", "(", ")", "}", ")", "\n", "", "else", ":", "\n", "                    ", "assert", "self", ".", "object_ids", "is", "None", "or", "len", "(", "self", ".", "object_ids", ")", "==", "1", "\n", "if", "isinstance", "(", "self", ".", "ground_truth_rect", ",", "(", "dict", ",", "OrderedDict", ")", ")", ":", "\n", "                        ", "init_data", "[", "0", "]", "[", "'bbox'", "]", "=", "list", "(", "self", ".", "ground_truth_rect", "[", "self", ".", "object_ids", "[", "0", "]", "]", "[", "0", ",", ":", "]", ")", "\n", "", "else", ":", "\n", "                        ", "init_data", "[", "0", "]", "[", "'bbox'", "]", "=", "list", "(", "self", ".", "ground_truth_rect", "[", "0", ",", ":", "]", ")", "\n", "\n", "", "", "", "if", "self", ".", "ground_truth_seg", "is", "not", "None", ":", "\n", "                ", "init_data", "[", "0", "]", "[", "'mask'", "]", "=", "self", ".", "ground_truth_seg", "[", "0", "]", "\n", "\n", "", "", "return", "init_data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.init_info": [[92, 95], ["data.Sequence.frame_info"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.frame_info"], ["", "def", "init_info", "(", "self", ")", ":", "\n", "        ", "info", "=", "self", ".", "frame_info", "(", "frame_num", "=", "0", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.frame_info": [[96, 99], ["data.Sequence.object_init_data"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.object_init_data"], ["", "def", "frame_info", "(", "self", ",", "frame_num", ")", ":", "\n", "        ", "info", "=", "self", ".", "object_init_data", "(", "frame_num", "=", "frame_num", ")", "\n", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.init_bbox": [[100, 102], ["data.Sequence.object_init_data().get", "data.Sequence.object_init_data"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.object_init_data"], ["", "def", "init_bbox", "(", "self", ",", "frame_num", "=", "0", ")", ":", "\n", "        ", "return", "self", ".", "object_init_data", "(", "frame_num", "=", "frame_num", ")", ".", "get", "(", "'init_bbox'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.init_mask": [[103, 105], ["data.Sequence.object_init_data().get", "data.Sequence.object_init_data"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.object_init_data"], ["", "def", "init_mask", "(", "self", ",", "frame_num", "=", "0", ")", ":", "\n", "        ", "return", "self", ".", "object_init_data", "(", "frame_num", "=", "frame_num", ")", ".", "get", "(", "'init_mask'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.get_bbox": [[106, 111], ["None"], "methods", ["None"], ["", "def", "get_bbox", "(", "self", ",", "frame_num", ",", "object_id", "=", "None", ")", ":", "\n", "        ", "if", "object_id", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "ground_truth_rect", "[", "object_id", "]", "[", "frame_num", "]", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "ground_truth_rect", "[", "frame_num", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.get_info": [[112, 119], ["dict", "data.Sequence.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "", "def", "get_info", "(", "self", ",", "keys", ",", "frame_num", "=", "None", ")", ":", "\n", "        ", "info", "=", "dict", "(", ")", "\n", "for", "k", "in", "keys", ":", "\n", "            ", "val", "=", "self", ".", "get", "(", "k", ",", "frame_num", "=", "frame_num", ")", "\n", "if", "val", "is", "not", "None", ":", "\n", "                ", "info", "[", "k", "]", "=", "val", "\n", "", "", "return", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.object_init_data": [[120, 144], ["dict", "data.Sequence.init_data[].items", "dict", "ltr.data.image_loader.imread_indexed", "len", "int"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.imread_indexed"], ["", "def", "object_init_data", "(", "self", ",", "frame_num", "=", "None", ")", "->", "dict", ":", "\n", "        ", "if", "frame_num", "is", "None", ":", "\n", "            ", "frame_num", "=", "0", "\n", "", "if", "frame_num", "not", "in", "self", ".", "init_data", ":", "\n", "            ", "return", "dict", "(", ")", "\n", "\n", "", "init_data", "=", "dict", "(", ")", "\n", "for", "key", ",", "val", "in", "self", ".", "init_data", "[", "frame_num", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "val", "is", "None", ":", "\n", "                ", "continue", "\n", "", "init_data", "[", "'init_'", "+", "key", "]", "=", "val", "\n", "\n", "", "if", "'init_mask'", "in", "init_data", "and", "init_data", "[", "'init_mask'", "]", "is", "not", "None", ":", "\n", "            ", "anno", "=", "imread_indexed", "(", "init_data", "[", "'init_mask'", "]", ")", "\n", "if", "not", "self", ".", "multiobj_mode", "and", "self", ".", "object_ids", "is", "not", "None", ":", "\n", "                ", "assert", "len", "(", "self", ".", "object_ids", ")", "==", "1", "\n", "anno", "=", "(", "anno", "==", "int", "(", "self", ".", "object_ids", "[", "0", "]", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "", "init_data", "[", "'init_mask'", "]", "=", "anno", "\n", "\n", "", "if", "self", ".", "object_ids", "is", "not", "None", ":", "\n", "            ", "init_data", "[", "'object_ids'", "]", "=", "self", ".", "object_ids", "\n", "init_data", "[", "'sequence_object_ids'", "]", "=", "self", ".", "object_ids", "\n", "\n", "", "return", "init_data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.target_class": [[145, 147], ["None"], "methods", ["None"], ["", "def", "target_class", "(", "self", ",", "frame_num", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "object_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.get": [[148, 150], ["getattr"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "name", ",", "frame_num", "=", "None", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ",", "name", ")", "(", "frame_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.__repr__": [[151, 153], ["len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"{self.__class__.__name__} {self.name}, length={len} frames\"", ".", "format", "(", "self", "=", "self", ",", "len", "=", "len", "(", "self", ".", "frames", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.__getitem__": [[158, 170], ["isinstance", "IndexError", "isinstance", "list.__getitem__", "isinstance", "data.SequenceList", "data.SequenceList", "list.__getitem__", "list.__getitem__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler.__getitem__", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler.__getitem__", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler.__getitem__"], ["def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "if", "isinstance", "(", "item", ",", "str", ")", ":", "\n", "            ", "for", "seq", "in", "self", ":", "\n", "                ", "if", "seq", ".", "name", "==", "item", ":", "\n", "                    ", "return", "seq", "\n", "", "", "raise", "IndexError", "(", "'Sequence name not in the dataset.'", ")", "\n", "", "elif", "isinstance", "(", "item", ",", "int", ")", ":", "\n", "            ", "return", "super", "(", "SequenceList", ",", "self", ")", ".", "__getitem__", "(", "item", ")", "\n", "", "elif", "isinstance", "(", "item", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "return", "SequenceList", "(", "[", "super", "(", "SequenceList", ",", "self", ")", ".", "__getitem__", "(", "i", ")", "for", "i", "in", "item", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "SequenceList", "(", "super", "(", "SequenceList", ",", "self", ")", ".", "__getitem__", "(", "item", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.__add__": [[171, 173], ["data.SequenceList", "list.__add__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.__add__"], ["", "", "def", "__add__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "SequenceList", "(", "super", "(", "SequenceList", ",", "self", ")", ".", "__add__", "(", "other", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy": [[174, 176], ["data.SequenceList", "super().copy"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "def", "copy", "(", "self", ")", ":", "\n", "        ", "return", "SequenceList", "(", "super", "(", "SequenceList", ",", "self", ")", ".", "copy", "(", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.mobifacedataset.MobifaceDataset.__init__": [[19, 28], ["pytracking.evaluation.data.BaseDataset.__init__", "mobifacedataset.MobifaceDataset._get_sequence_list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._get_sequence_list"], ["def", "__init__", "(", "self", ",", "split", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            split - Split to use. Can be i) 'train': official training set, ii) 'test': official test set, iii) 'all': whole dataset.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_path", "=", "self", ".", "env_settings", ".", "mobiface_path", "\n", "self", ".", "sequence_list", "=", "self", ".", "_get_sequence_list", "(", "split", ")", "\n", "self", ".", "split", "=", "split", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.mobifacedataset.MobifaceDataset.get_sequence_list": [[29, 31], ["pytracking.evaluation.data.SequenceList", "mobifacedataset.MobifaceDataset._construct_sequence"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence"], ["", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "return", "SequenceList", "(", "[", "self", ".", "_construct_sequence", "(", "s", ")", "for", "s", "in", "self", ".", "sequence_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.mobifacedataset.MobifaceDataset._get_sequence_list": [[32, 54], ["os.join", "os.join", "pandas.read_csv().transpose().to_dict", "pandas.read_csv().transpose().to_dict", "collections.OrderedDict", "mobifacedataset.MobifaceDataset.meta.items", "sorted", "sorted", "list", "pandas.read_csv().transpose", "pandas.read_csv().transpose", "mobifacedataset.MobifaceDataset.meta.items", "mobifacedataset.MobifaceDataset.train_meta.keys", "mobifacedataset.MobifaceDataset.anno_files.append", "mobifacedataset.MobifaceDataset.anno_files.append", "mobifacedataset.MobifaceDataset.meta.keys", "os.abspath", "os.abspath", "pandas.read_csv", "pandas.read_csv", "os.join", "os.join", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "_get_sequence_list", "(", "self", ",", "split", ")", ":", "\n", "\n", "        ", "self", ".", "train_meta_fn", "=", "osp", ".", "join", "(", "self", ".", "base_path", ",", "'train.meta.csv'", ")", "\n", "self", ".", "test_meta_fn", "=", "osp", ".", "join", "(", "self", ".", "base_path", ",", "'test.meta.csv'", ")", "\n", "self", ".", "train_meta", "=", "pd", ".", "read_csv", "(", "self", ".", "train_meta_fn", ",", "index_col", "=", "0", ")", ".", "transpose", "(", ")", ".", "to_dict", "(", ")", "\n", "self", ".", "test_meta", "=", "pd", ".", "read_csv", "(", "self", ".", "test_meta_fn", ",", "index_col", "=", "0", ")", ".", "transpose", "(", ")", ".", "to_dict", "(", ")", "\n", "if", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "meta", "=", "self", ".", "train_meta", "\n", "", "elif", "split", "==", "'test'", ":", "\n", "            ", "self", ".", "meta", "=", "self", ".", "test_meta", "\n", "", "else", ":", "\n", "            ", "self", ".", "meta", "=", "{", "**", "self", ".", "train_meta", ",", "**", "self", ".", "test_meta", "}", "# In Python 3.5 or greater", "\n", "", "self", ".", "meta", "=", "OrderedDict", "(", "sorted", "(", "self", ".", "meta", ".", "items", "(", ")", ",", "key", "=", "lambda", "t", ":", "t", "[", "0", "]", ")", ")", "\n", "self", ".", "anno_files", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "self", ".", "meta", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "in", "self", ".", "train_meta", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "anno_files", ".", "append", "(", "osp", ".", "abspath", "(", "osp", ".", "join", "(", "self", ".", "base_path", ",", "'train'", ",", "k", "+", "'.annot.csv'", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "anno_files", ".", "append", "(", "osp", ".", "abspath", "(", "osp", ".", "join", "(", "self", ".", "base_path", ",", "'test'", ",", "k", "+", "'.annot.csv'", ")", ")", ")", "\n", "", "", "self", ".", "seq_names", "=", "sorted", "(", "list", "(", "self", ".", "meta", ".", "keys", "(", ")", ")", ")", "\n", "self", ".", "seq_dirs", "=", "[", "fn", "[", ":", "-", "len", "(", "'.annot.csv'", ")", "]", "for", "fn", "in", "self", ".", "anno_files", "]", "\n", "return", "self", ".", "seq_names", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.mobifacedataset.MobifaceDataset._construct_sequence": [[55, 66], ["mobifacedataset.MobifaceDataset.seq_names.index", "sorted", "pytracking.evaluation.data.Sequence", "glob.glob", "len", "sorted", "open", "numpy.loadtxt", "numpy.loadtxt.reshape", "glob.glob"], "methods", ["None"], ["", "def", "_construct_sequence", "(", "self", ",", "sequence_name", ")", ":", "\n", "        ", "index", "=", "self", ".", "seq_names", ".", "index", "(", "sequence_name", ")", "\n", "img_files", "=", "sorted", "(", "glob", ".", "glob", "(", "self", ".", "seq_dirs", "[", "index", "]", "+", "'/*.jpg'", ")", ")", "\n", "if", "len", "(", "img_files", ")", "==", "0", ":", "\n", "            ", "img_files", "=", "sorted", "(", "glob", ".", "glob", "(", "self", ".", "seq_dirs", "[", "index", "]", "+", "'.png'", ")", ")", "\n", "", "with", "open", "(", "self", ".", "anno_files", "[", "index", "]", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "anno", "=", "np", ".", "loadtxt", "(", "f", ",", "delimiter", "=", "','", ",", "skiprows", "=", "1", ",", "dtype", "=", "int", ")", "\n", "", "anno", "=", "anno", "[", ":", ",", "1", ":", "]", "\n", "assert", "anno", ".", "shape", "[", "1", "]", "==", "4", "\n", "\n", "return", "Sequence", "(", "sequence_name", ",", "img_files", ",", "anno", ".", "reshape", "(", "-", "1", ",", "4", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.mobifacedataset.MobifaceDataset.__len__": [[67, 69], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_list", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.__init__": [[46, 70], ["pytracking.evaluation.environment.env_settings", "os.path.abspath", "os.path.isdir", "isinstance", "os.path.join", "importlib.import_module", "importlib.import_module.get_tracker_class", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.__init__.get_tracker_class"], ["def", "__init__", "(", "self", ",", "name", ":", "str", ",", "parameter_name", ":", "str", ",", "run_id", ":", "int", "=", "None", ",", "display_name", ":", "str", "=", "None", ")", ":", "\n", "        ", "assert", "run_id", "is", "None", "or", "isinstance", "(", "run_id", ",", "int", ")", "\n", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "parameter_name", "=", "parameter_name", "\n", "self", ".", "run_id", "=", "run_id", "\n", "self", ".", "display_name", "=", "display_name", "\n", "\n", "env", "=", "env_settings", "(", ")", "\n", "if", "self", ".", "run_id", "is", "None", ":", "\n", "            ", "self", ".", "results_dir", "=", "'{}/{}/{}'", ".", "format", "(", "env", ".", "results_path", ",", "self", ".", "name", ",", "self", ".", "parameter_name", ")", "\n", "self", ".", "segmentation_dir", "=", "'{}/{}/{}'", ".", "format", "(", "env", ".", "segmentation_path", ",", "self", ".", "name", ",", "self", ".", "parameter_name", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "results_dir", "=", "'{}/{}/{}_{:03d}'", ".", "format", "(", "env", ".", "results_path", ",", "self", ".", "name", ",", "self", ".", "parameter_name", ",", "self", ".", "run_id", ")", "\n", "self", ".", "segmentation_dir", "=", "'{}/{}/{}_{:03d}'", ".", "format", "(", "env", ".", "segmentation_path", ",", "self", ".", "name", ",", "self", ".", "parameter_name", ",", "self", ".", "run_id", ")", "\n", "\n", "", "tracker_module_abspath", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'..'", ",", "'tracker'", ",", "self", ".", "name", ")", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "tracker_module_abspath", ")", ":", "\n", "            ", "tracker_module", "=", "importlib", ".", "import_module", "(", "'pytracking.tracker.{}'", ".", "format", "(", "self", ".", "name", ")", ")", "\n", "self", ".", "tracker_class", "=", "tracker_module", ".", "get_tracker_class", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tracker_class", "=", "None", "\n", "\n", "", "self", ".", "visdom", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._init_visdom": [[72, 90], ["visdom_info.get", "pytracking.utils.visdom.Visdom", "tracker.Tracker.visdom.register", "time.sleep", "print"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.eco.optim.FilterOptim.register"], ["", "def", "_init_visdom", "(", "self", ",", "visdom_info", ",", "debug", ")", ":", "\n", "        ", "visdom_info", "=", "{", "}", "if", "visdom_info", "is", "None", "else", "visdom_info", "\n", "self", ".", "pause_mode", "=", "False", "\n", "self", ".", "step", "=", "False", "\n", "if", "debug", ">", "0", "and", "visdom_info", ".", "get", "(", "'use_visdom'", ",", "True", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "visdom", "=", "Visdom", "(", "debug", ",", "{", "'handler'", ":", "self", ".", "_visdom_ui_handler", ",", "'win_id'", ":", "'Tracking'", "}", ",", "\n", "visdom_info", "=", "visdom_info", ")", "\n", "\n", "# Show help", "\n", "help_text", "=", "'You can pause/unpause the tracker by pressing '", "'space'", "' with the '", "'Tracking'", "' window '", "'selected. During paused mode, you can track for one frame by pressing the right arrow key.'", "'To enable/disable plotting of a data block, tick/untick the corresponding entry in '", "'block list.'", "\n", "self", ".", "visdom", ".", "register", "(", "help_text", ",", "'text'", ",", "1", ",", "'Help'", ")", "\n", "", "except", ":", "\n", "                ", "time", ".", "sleep", "(", "0.5", ")", "\n", "print", "(", "'!!! WARNING: Visdom could not start, so using matplotlib visualization instead !!!\\n'", "\n", "'!!! Start Visdom in a separate terminal window by typing \\'visdom\\' !!!'", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._visdom_ui_handler": [[92, 99], ["None"], "methods", ["None"], ["", "", "", "def", "_visdom_ui_handler", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "data", "[", "'event_type'", "]", "==", "'KeyPress'", ":", "\n", "            ", "if", "data", "[", "'key'", "]", "==", "' '", ":", "\n", "                ", "self", ".", "pause_mode", "=", "not", "self", ".", "pause_mode", "\n", "\n", "", "elif", "data", "[", "'key'", "]", "==", "'ArrowRight'", "and", "self", ".", "pause_mode", ":", "\n", "                ", "self", ".", "step", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.create_tracker": [[101, 105], ["tracker.Tracker.Tracker.tracker_class"], "methods", ["None"], ["", "", "", "def", "create_tracker", "(", "self", ",", "params", ")", ":", "\n", "        ", "tracker", "=", "self", ".", "tracker_class", "(", "params", ")", "\n", "tracker", ".", "visdom", "=", "self", ".", "visdom", "\n", "return", "tracker", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.run_sequence": [[106, 150], ["pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker.get_parameters", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker._init_visdom", "seq.init_info", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker._track_sequence", "getattr", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker.init_visualization", "getattr", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker.create_tracker", "getattr", "getattr", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper", "ValueError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.get_parameters", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._init_visdom", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.init_info", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._track_sequence", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.init_visualization", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.create_tracker"], ["", "def", "run_sequence", "(", "self", ",", "seq", ",", "visualization", "=", "None", ",", "debug", "=", "None", ",", "visdom_info", "=", "None", ",", "multiobj_mode", "=", "None", ")", ":", "\n", "        ", "\"\"\"Run tracker on sequence.\n        args:\n            seq: Sequence to run the tracker on.\n            visualization: Set visualization flag (None means default value specified in the parameters).\n            debug: Set debug level (None means default value specified in the parameters).\n            visdom_info: Visdom info.\n            multiobj_mode: Which mode to use for multiple objects.\n        \"\"\"", "\n", "params", "=", "self", ".", "get_parameters", "(", ")", "\n", "visualization_", "=", "visualization", "\n", "\n", "debug_", "=", "debug", "\n", "if", "debug", "is", "None", ":", "\n", "            ", "debug_", "=", "getattr", "(", "params", ",", "'debug'", ",", "0", ")", "\n", "", "if", "visualization", "is", "None", ":", "\n", "            ", "if", "debug", "is", "None", ":", "\n", "                ", "visualization_", "=", "getattr", "(", "params", ",", "'visualization'", ",", "False", ")", "\n", "", "else", ":", "\n", "                ", "visualization_", "=", "True", "if", "debug", "else", "False", "\n", "\n", "", "", "params", ".", "visualization", "=", "visualization_", "\n", "params", ".", "debug", "=", "debug_", "\n", "\n", "self", ".", "_init_visdom", "(", "visdom_info", ",", "debug_", ")", "\n", "if", "visualization_", "and", "self", ".", "visdom", "is", "None", ":", "\n", "            ", "self", ".", "init_visualization", "(", ")", "\n", "\n", "# Get init information", "\n", "", "init_info", "=", "seq", ".", "init_info", "(", ")", "\n", "is_single_object", "=", "not", "seq", ".", "multiobj_mode", "\n", "\n", "if", "multiobj_mode", "is", "None", ":", "\n", "            ", "multiobj_mode", "=", "getattr", "(", "params", ",", "'multiobj_mode'", ",", "getattr", "(", "self", ".", "tracker_class", ",", "'multiobj_mode'", ",", "'default'", ")", ")", "\n", "\n", "", "if", "multiobj_mode", "==", "'default'", "or", "is_single_object", ":", "\n", "            ", "tracker", "=", "self", ".", "create_tracker", "(", "params", ")", "\n", "", "elif", "multiobj_mode", "==", "'parallel'", ":", "\n", "            ", "tracker", "=", "MultiObjectWrapper", "(", "self", ".", "tracker_class", ",", "params", ",", "self", ".", "visdom", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown multi object mode {}'", ".", "format", "(", "multiobj_mode", ")", ")", "\n", "\n", "", "output", "=", "self", ".", "_track_sequence", "(", "tracker", ",", "seq", ",", "init_info", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._track_sequence": [[151, 234], ["tracker.Tracker._read_image", "time.time", "tracker.initialize", "collections.OrderedDict", "tracker.Tracker._track_sequence._store_outputs"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._read_image", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["", "def", "_track_sequence", "(", "self", ",", "tracker", ",", "seq", ",", "init_info", ")", ":", "\n", "# Define outputs", "\n", "# Each field in output is a list containing tracker prediction for each frame.", "\n", "\n", "# In case of single object tracking mode:", "\n", "# target_bbox[i] is the predicted bounding box for frame i", "\n", "# time[i] is the processing time for frame i", "\n", "# segmentation[i] is the segmentation mask for frame i (numpy array)", "\n", "\n", "# In case of multi object tracking mode:", "\n", "# target_bbox[i] is an OrderedDict, where target_bbox[i][obj_id] is the predicted box for target obj_id in", "\n", "# frame i", "\n", "# time[i] is either the processing time for frame i, or an OrderedDict containing processing times for each", "\n", "# object in frame i", "\n", "# segmentation[i] is the multi-label segmentation mask for frame i (numpy array)", "\n", "\n", "        ", "output", "=", "{", "'target_bbox'", ":", "[", "]", ",", "\n", "'time'", ":", "[", "]", ",", "\n", "'segmentation'", ":", "[", "]", ",", "\n", "'object_presence_score'", ":", "[", "]", "}", "\n", "\n", "def", "_store_outputs", "(", "tracker_out", ":", "dict", ",", "defaults", "=", "None", ")", ":", "\n", "            ", "defaults", "=", "{", "}", "if", "defaults", "is", "None", "else", "defaults", "\n", "for", "key", "in", "output", ".", "keys", "(", ")", ":", "\n", "                ", "val", "=", "tracker_out", ".", "get", "(", "key", ",", "defaults", ".", "get", "(", "key", ",", "None", ")", ")", "\n", "if", "key", "in", "tracker_out", "or", "val", "is", "not", "None", ":", "\n", "                    ", "output", "[", "key", "]", ".", "append", "(", "val", ")", "\n", "\n", "# Initialize", "\n", "", "", "", "image", "=", "self", ".", "_read_image", "(", "seq", ".", "frames", "[", "0", "]", ")", "\n", "\n", "if", "tracker", ".", "params", ".", "visualization", "and", "self", ".", "visdom", "is", "None", ":", "\n", "            ", "self", ".", "visualize", "(", "image", ",", "init_info", ".", "get", "(", "'init_bbox'", ")", ")", "\n", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "out", "=", "tracker", ".", "initialize", "(", "image", ",", "init_info", ")", "\n", "if", "out", "is", "None", ":", "\n", "            ", "out", "=", "{", "}", "\n", "\n", "", "prev_output", "=", "OrderedDict", "(", "out", ")", "\n", "\n", "init_default", "=", "{", "'target_bbox'", ":", "init_info", ".", "get", "(", "'init_bbox'", ")", ",", "\n", "'time'", ":", "time", ".", "time", "(", ")", "-", "start_time", ",", "\n", "'segmentation'", ":", "init_info", ".", "get", "(", "'init_mask'", ")", ",", "\n", "'object_presence_score'", ":", "1.", "}", "\n", "\n", "_store_outputs", "(", "out", ",", "init_default", ")", "\n", "\n", "for", "frame_num", ",", "frame_path", "in", "enumerate", "(", "seq", ".", "frames", "[", "1", ":", "]", ",", "start", "=", "1", ")", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "if", "not", "self", ".", "pause_mode", ":", "\n", "                    ", "break", "\n", "", "elif", "self", ".", "step", ":", "\n", "                    ", "self", ".", "step", "=", "False", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "time", ".", "sleep", "(", "0.1", ")", "\n", "\n", "", "", "image", "=", "self", ".", "_read_image", "(", "frame_path", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "info", "=", "seq", ".", "frame_info", "(", "frame_num", ")", "\n", "info", "[", "'previous_output'", "]", "=", "prev_output", "\n", "\n", "out", "=", "tracker", ".", "track", "(", "image", ",", "info", ")", "\n", "prev_output", "=", "OrderedDict", "(", "out", ")", "\n", "_store_outputs", "(", "out", ",", "{", "'time'", ":", "time", ".", "time", "(", ")", "-", "start_time", "}", ")", "\n", "\n", "segmentation", "=", "out", "[", "'segmentation'", "]", "if", "'segmentation'", "in", "out", "else", "None", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                ", "tracker", ".", "visdom_draw_tracking", "(", "image", ",", "out", "[", "'target_bbox'", "]", ",", "segmentation", ")", "\n", "", "elif", "tracker", ".", "params", ".", "visualization", ":", "\n", "                ", "self", ".", "visualize", "(", "image", ",", "out", "[", "'target_bbox'", "]", ",", "segmentation", ")", "\n", "\n", "", "", "for", "key", "in", "[", "'target_bbox'", ",", "'segmentation'", "]", ":", "\n", "            ", "if", "key", "in", "output", "and", "len", "(", "output", "[", "key", "]", ")", "<=", "1", ":", "\n", "                ", "output", ".", "pop", "(", "key", ")", "\n", "\n", "", "", "output", "[", "'image_shape'", "]", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "output", "[", "'object_presence_score_threshold'", "]", "=", "tracker", ".", "params", ".", "get", "(", "'object_presence_score_threshold'", ",", "0.55", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.run_video": [[235, 357], ["pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker.get_parameters", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker._init_visdom", "getattr", "os.path.isfile", "cv2.VideoCapture", "cv2.namedWindow", "cv2.resizeWindow", "cv2.VideoCapture.read", "cv2.imshow", "cv2.VideoCapture.release", "cv2.destroyAllWindows", "getattr", "getattr", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker.create_tracker", "hasattr", "print", "exit", "isinstance", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize", "output_boxes.append", "cv2.VideoCapture.read", "frame.copy", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.track", "output_boxes.append", "cv2.rectangle", "cv2.putText", "cv2.putText", "cv2.putText", "cv2.imshow", "cv2.waitKey", "os.path.join", "numpy.array().astype", "numpy.savetxt", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize_features", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper", "ValueError", "collections.OrderedDict", "len", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker.run_video._build_init_info"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.get_parameters", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._init_visdom", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.create_tracker", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.track", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features"], ["", "def", "run_video", "(", "self", ",", "videofilepath", ",", "optional_box", "=", "None", ",", "debug", "=", "None", ",", "visdom_info", "=", "None", ",", "save_results", "=", "False", ")", ":", "\n", "        ", "\"\"\"Run the tracker with the video file.\n        args:\n            debug: Debug level.\n        \"\"\"", "\n", "\n", "params", "=", "self", ".", "get_parameters", "(", ")", "\n", "\n", "debug_", "=", "debug", "\n", "if", "debug", "is", "None", ":", "\n", "            ", "debug_", "=", "getattr", "(", "params", ",", "'debug'", ",", "0", ")", "\n", "", "params", ".", "debug", "=", "debug_", "\n", "\n", "params", ".", "tracker_name", "=", "self", ".", "name", "\n", "params", ".", "param_name", "=", "self", ".", "parameter_name", "\n", "self", ".", "_init_visdom", "(", "visdom_info", ",", "debug_", ")", "\n", "\n", "multiobj_mode", "=", "getattr", "(", "params", ",", "'multiobj_mode'", ",", "getattr", "(", "self", ".", "tracker_class", ",", "'multiobj_mode'", ",", "'default'", ")", ")", "\n", "\n", "if", "multiobj_mode", "==", "'default'", ":", "\n", "            ", "tracker", "=", "self", ".", "create_tracker", "(", "params", ")", "\n", "if", "hasattr", "(", "tracker", ",", "'initialize_features'", ")", ":", "\n", "                ", "tracker", ".", "initialize_features", "(", ")", "\n", "\n", "", "", "elif", "multiobj_mode", "==", "'parallel'", ":", "\n", "            ", "tracker", "=", "MultiObjectWrapper", "(", "self", ".", "tracker_class", ",", "params", ",", "self", ".", "visdom", ",", "fast_load", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown multi object mode {}'", ".", "format", "(", "multiobj_mode", ")", ")", "\n", "\n", "", "assert", "os", ".", "path", ".", "isfile", "(", "videofilepath", ")", ",", "\"Invalid param {}\"", ".", "format", "(", "videofilepath", ")", "\n", "\", videofilepath must be a valid videofile\"", "\n", "\n", "output_boxes", "=", "[", "]", "\n", "\n", "cap", "=", "cv", ".", "VideoCapture", "(", "videofilepath", ")", "\n", "display_name", "=", "'Display: '", "+", "tracker", ".", "params", ".", "tracker_name", "\n", "cv", ".", "namedWindow", "(", "display_name", ",", "cv", ".", "WINDOW_NORMAL", "|", "cv", ".", "WINDOW_KEEPRATIO", ")", "\n", "cv", ".", "resizeWindow", "(", "display_name", ",", "960", ",", "720", ")", "\n", "success", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "cv", ".", "imshow", "(", "display_name", ",", "frame", ")", "\n", "\n", "def", "_build_init_info", "(", "box", ")", ":", "\n", "            ", "return", "{", "'init_bbox'", ":", "OrderedDict", "(", "{", "1", ":", "box", "}", ")", ",", "'init_object_ids'", ":", "[", "1", ",", "]", ",", "'object_ids'", ":", "[", "1", ",", "]", ",", "\n", "'sequence_object_ids'", ":", "[", "1", ",", "]", "}", "\n", "\n", "", "if", "success", "is", "not", "True", ":", "\n", "            ", "print", "(", "\"Read frame from {} failed.\"", ".", "format", "(", "videofilepath", ")", ")", "\n", "exit", "(", "-", "1", ")", "\n", "", "if", "optional_box", "is", "not", "None", ":", "\n", "            ", "assert", "isinstance", "(", "optional_box", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "optional_box", ")", "==", "4", ",", "\"valid box's foramt is [x,y,w,h]\"", "\n", "tracker", ".", "initialize", "(", "frame", ",", "_build_init_info", "(", "optional_box", ")", ")", "\n", "output_boxes", ".", "append", "(", "optional_box", ")", "\n", "", "else", ":", "\n", "            ", "while", "True", ":", "\n", "# cv.waitKey()", "\n", "                ", "frame_disp", "=", "frame", ".", "copy", "(", ")", "\n", "\n", "cv", ".", "putText", "(", "frame_disp", ",", "'Select target ROI and press ENTER'", ",", "(", "20", ",", "30", ")", ",", "cv", ".", "FONT_HERSHEY_COMPLEX_SMALL", ",", "\n", "1.5", ",", "(", "0", ",", "0", ",", "0", ")", ",", "1", ")", "\n", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "cv", ".", "selectROI", "(", "display_name", ",", "frame_disp", ",", "fromCenter", "=", "False", ")", "\n", "init_state", "=", "[", "x", ",", "y", ",", "w", ",", "h", "]", "\n", "tracker", ".", "initialize", "(", "frame", ",", "_build_init_info", "(", "init_state", ")", ")", "\n", "output_boxes", ".", "append", "(", "init_state", ")", "\n", "break", "\n", "\n", "", "", "while", "True", ":", "\n", "            ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "\n", "if", "frame", "is", "None", ":", "\n", "                ", "break", "\n", "\n", "", "frame_disp", "=", "frame", ".", "copy", "(", ")", "\n", "\n", "# Draw box", "\n", "out", "=", "tracker", ".", "track", "(", "frame", ")", "\n", "state", "=", "[", "int", "(", "s", ")", "for", "s", "in", "out", "[", "'target_bbox'", "]", "[", "1", "]", "]", "\n", "output_boxes", ".", "append", "(", "state", ")", "\n", "\n", "cv", ".", "rectangle", "(", "frame_disp", ",", "(", "state", "[", "0", "]", ",", "state", "[", "1", "]", ")", ",", "(", "state", "[", "2", "]", "+", "state", "[", "0", "]", ",", "state", "[", "3", "]", "+", "state", "[", "1", "]", ")", ",", "\n", "(", "0", ",", "255", ",", "0", ")", ",", "5", ")", "\n", "\n", "font_color", "=", "(", "0", ",", "0", ",", "0", ")", "\n", "cv", ".", "putText", "(", "frame_disp", ",", "'Tracking!'", ",", "(", "20", ",", "30", ")", ",", "cv", ".", "FONT_HERSHEY_COMPLEX_SMALL", ",", "1", ",", "\n", "font_color", ",", "1", ")", "\n", "cv", ".", "putText", "(", "frame_disp", ",", "'Press r to reset'", ",", "(", "20", ",", "55", ")", ",", "cv", ".", "FONT_HERSHEY_COMPLEX_SMALL", ",", "1", ",", "\n", "font_color", ",", "1", ")", "\n", "cv", ".", "putText", "(", "frame_disp", ",", "'Press q to quit'", ",", "(", "20", ",", "80", ")", ",", "cv", ".", "FONT_HERSHEY_COMPLEX_SMALL", ",", "1", ",", "\n", "font_color", ",", "1", ")", "\n", "\n", "# Display the resulting frame", "\n", "cv", ".", "imshow", "(", "display_name", ",", "frame_disp", ")", "\n", "key", "=", "cv", ".", "waitKey", "(", "1", ")", "\n", "if", "key", "==", "ord", "(", "'q'", ")", ":", "\n", "                ", "break", "\n", "", "elif", "key", "==", "ord", "(", "'r'", ")", ":", "\n", "                ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "frame_disp", "=", "frame", ".", "copy", "(", ")", "\n", "\n", "cv", ".", "putText", "(", "frame_disp", ",", "'Select target ROI and press ENTER'", ",", "(", "20", ",", "30", ")", ",", "cv", ".", "FONT_HERSHEY_COMPLEX_SMALL", ",", "1.5", ",", "\n", "(", "0", ",", "0", ",", "0", ")", ",", "1", ")", "\n", "\n", "cv", ".", "imshow", "(", "display_name", ",", "frame_disp", ")", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "cv", ".", "selectROI", "(", "display_name", ",", "frame_disp", ",", "fromCenter", "=", "False", ")", "\n", "init_state", "=", "[", "x", ",", "y", ",", "w", ",", "h", "]", "\n", "tracker", ".", "initialize", "(", "frame", ",", "_build_init_info", "(", "init_state", ")", ")", "\n", "output_boxes", ".", "append", "(", "init_state", ")", "\n", "\n", "# When everything done, release the capture", "\n", "", "", "cap", ".", "release", "(", ")", "\n", "cv", ".", "destroyAllWindows", "(", ")", "\n", "\n", "if", "save_results", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "results_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "results_dir", ")", "\n", "", "video_name", "=", "Path", "(", "videofilepath", ")", ".", "stem", "\n", "base_results_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "results_dir", ",", "'video_{}'", ".", "format", "(", "video_name", ")", ")", "\n", "\n", "tracked_bb", "=", "np", ".", "array", "(", "output_boxes", ")", ".", "astype", "(", "int", ")", "\n", "bbox_file", "=", "'{}.txt'", ".", "format", "(", "base_results_path", ")", "\n", "np", ".", "savetxt", "(", "bbox_file", ",", "tracked_bb", ",", "delimiter", "=", "'\\t'", ",", "fmt", "=", "'%d'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.run_webcam": [[358, 492], ["pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker.get_parameters", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker._init_visdom", "getattr", "UIControl", "cv2.VideoCapture", "cv2.namedWindow", "cv2.resizeWindow", "cv2.setMouseCallback", "collections.OrderedDict", "cv2.VideoCapture.release", "cv2.destroyAllWindows", "getattr", "getattr", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker.create_tracker", "cv2.VideoCapture.read", "frame.copy", "collections.OrderedDict", "cv2.putText", "cv2.putText", "cv2.putText", "cv2.imshow", "cv2.waitKey", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper", "ValueError", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker.get_tl", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.Tracker.get_br", "UIControl.get_bb", "collections.OrderedDict", "sequence_object_ids.append", "cv2.rectangle", "len", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.track", "collections.OrderedDict", "ord", "min", "min", "abs", "abs", "UIControl.get_tl", "UIControl.get_br", "pytracking.utils.plotting.overlay_mask", "out[].items", "ord", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize", "cv2.rectangle", "int"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.get_parameters", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._init_visdom", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.create_tracker", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.track", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.overlay_mask", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize"], ["", "", "def", "run_webcam", "(", "self", ",", "debug", "=", "None", ",", "visdom_info", "=", "None", ")", ":", "\n", "        ", "\"\"\"Run the tracker with the webcam.\n        args:\n            debug: Debug level.\n        \"\"\"", "\n", "\n", "params", "=", "self", ".", "get_parameters", "(", ")", "\n", "\n", "debug_", "=", "debug", "\n", "if", "debug", "is", "None", ":", "\n", "            ", "debug_", "=", "getattr", "(", "params", ",", "'debug'", ",", "0", ")", "\n", "", "params", ".", "debug", "=", "debug_", "\n", "\n", "params", ".", "tracker_name", "=", "self", ".", "name", "\n", "params", ".", "param_name", "=", "self", ".", "parameter_name", "\n", "\n", "self", ".", "_init_visdom", "(", "visdom_info", ",", "debug_", ")", "\n", "\n", "multiobj_mode", "=", "getattr", "(", "params", ",", "'multiobj_mode'", ",", "getattr", "(", "self", ".", "tracker_class", ",", "'multiobj_mode'", ",", "'default'", ")", ")", "\n", "\n", "if", "multiobj_mode", "==", "'default'", ":", "\n", "            ", "tracker", "=", "self", ".", "create_tracker", "(", "params", ")", "\n", "", "elif", "multiobj_mode", "==", "'parallel'", ":", "\n", "            ", "tracker", "=", "MultiObjectWrapper", "(", "self", ".", "tracker_class", ",", "params", ",", "self", ".", "visdom", ",", "fast_load", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown multi object mode {}'", ".", "format", "(", "multiobj_mode", ")", ")", "\n", "\n", "", "class", "UIControl", ":", "\n", "            ", "def", "__init__", "(", "self", ")", ":", "\n", "                ", "self", ".", "mode", "=", "'init'", "# init, select, track", "\n", "self", ".", "target_tl", "=", "(", "-", "1", ",", "-", "1", ")", "\n", "self", ".", "target_br", "=", "(", "-", "1", ",", "-", "1", ")", "\n", "self", ".", "new_init", "=", "False", "\n", "\n", "", "def", "mouse_callback", "(", "self", ",", "event", ",", "x", ",", "y", ",", "flags", ",", "param", ")", ":", "\n", "                ", "if", "event", "==", "cv", ".", "EVENT_LBUTTONDOWN", "and", "self", ".", "mode", "==", "'init'", ":", "\n", "                    ", "self", ".", "target_tl", "=", "(", "x", ",", "y", ")", "\n", "self", ".", "target_br", "=", "(", "x", ",", "y", ")", "\n", "self", ".", "mode", "=", "'select'", "\n", "", "elif", "event", "==", "cv", ".", "EVENT_MOUSEMOVE", "and", "self", ".", "mode", "==", "'select'", ":", "\n", "                    ", "self", ".", "target_br", "=", "(", "x", ",", "y", ")", "\n", "", "elif", "event", "==", "cv", ".", "EVENT_LBUTTONDOWN", "and", "self", ".", "mode", "==", "'select'", ":", "\n", "                    ", "self", ".", "target_br", "=", "(", "x", ",", "y", ")", "\n", "self", ".", "mode", "=", "'init'", "\n", "self", ".", "new_init", "=", "True", "\n", "\n", "", "", "def", "get_tl", "(", "self", ")", ":", "\n", "                ", "return", "self", ".", "target_tl", "if", "self", ".", "target_tl", "[", "0", "]", "<", "self", ".", "target_br", "[", "0", "]", "else", "self", ".", "target_br", "\n", "\n", "", "def", "get_br", "(", "self", ")", ":", "\n", "                ", "return", "self", ".", "target_br", "if", "self", ".", "target_tl", "[", "0", "]", "<", "self", ".", "target_br", "[", "0", "]", "else", "self", ".", "target_tl", "\n", "\n", "", "def", "get_bb", "(", "self", ")", ":", "\n", "                ", "tl", "=", "self", ".", "get_tl", "(", ")", "\n", "br", "=", "self", ".", "get_br", "(", ")", "\n", "\n", "bb", "=", "[", "min", "(", "tl", "[", "0", "]", ",", "br", "[", "0", "]", ")", ",", "min", "(", "tl", "[", "1", "]", ",", "br", "[", "1", "]", ")", ",", "abs", "(", "br", "[", "0", "]", "-", "tl", "[", "0", "]", ")", ",", "abs", "(", "br", "[", "1", "]", "-", "tl", "[", "1", "]", ")", "]", "\n", "return", "bb", "\n", "\n", "", "", "ui_control", "=", "UIControl", "(", ")", "\n", "cap", "=", "cv", ".", "VideoCapture", "(", "0", ")", "\n", "display_name", "=", "'Display: '", "+", "self", ".", "name", "\n", "cv", ".", "namedWindow", "(", "display_name", ",", "cv", ".", "WINDOW_NORMAL", "|", "cv", ".", "WINDOW_KEEPRATIO", ")", "\n", "cv", ".", "resizeWindow", "(", "display_name", ",", "960", ",", "720", ")", "\n", "cv", ".", "setMouseCallback", "(", "display_name", ",", "ui_control", ".", "mouse_callback", ")", "\n", "\n", "next_object_id", "=", "1", "\n", "sequence_object_ids", "=", "[", "]", "\n", "prev_output", "=", "OrderedDict", "(", ")", "\n", "while", "True", ":", "\n", "# Capture frame-by-frame", "\n", "            ", "ret", ",", "frame", "=", "cap", ".", "read", "(", ")", "\n", "frame_disp", "=", "frame", ".", "copy", "(", ")", "\n", "\n", "info", "=", "OrderedDict", "(", ")", "\n", "info", "[", "'previous_output'", "]", "=", "prev_output", "\n", "\n", "if", "ui_control", ".", "new_init", ":", "\n", "                ", "ui_control", ".", "new_init", "=", "False", "\n", "init_state", "=", "ui_control", ".", "get_bb", "(", ")", "\n", "\n", "info", "[", "'init_object_ids'", "]", "=", "[", "next_object_id", ",", "]", "\n", "info", "[", "'init_bbox'", "]", "=", "OrderedDict", "(", "{", "next_object_id", ":", "init_state", "}", ")", "\n", "sequence_object_ids", ".", "append", "(", "next_object_id", ")", "\n", "\n", "next_object_id", "+=", "1", "\n", "\n", "# Draw box", "\n", "", "if", "ui_control", ".", "mode", "==", "'select'", ":", "\n", "                ", "cv", ".", "rectangle", "(", "frame_disp", ",", "ui_control", ".", "get_tl", "(", ")", ",", "ui_control", ".", "get_br", "(", ")", ",", "(", "255", ",", "0", ",", "0", ")", ",", "2", ")", "\n", "\n", "", "if", "len", "(", "sequence_object_ids", ")", ">", "0", ":", "\n", "                ", "info", "[", "'sequence_object_ids'", "]", "=", "sequence_object_ids", "\n", "out", "=", "tracker", ".", "track", "(", "frame", ",", "info", ")", "\n", "prev_output", "=", "OrderedDict", "(", "out", ")", "\n", "\n", "if", "'segmentation'", "in", "out", ":", "\n", "                    ", "frame_disp", "=", "overlay_mask", "(", "frame_disp", ",", "out", "[", "'segmentation'", "]", ")", "\n", "\n", "", "if", "'target_bbox'", "in", "out", ":", "\n", "                    ", "for", "obj_id", ",", "state", "in", "out", "[", "'target_bbox'", "]", ".", "items", "(", ")", ":", "\n", "                        ", "state", "=", "[", "int", "(", "s", ")", "for", "s", "in", "state", "]", "\n", "cv", ".", "rectangle", "(", "frame_disp", ",", "(", "state", "[", "0", "]", ",", "state", "[", "1", "]", ")", ",", "(", "state", "[", "2", "]", "+", "state", "[", "0", "]", ",", "state", "[", "3", "]", "+", "state", "[", "1", "]", ")", ",", "\n", "_tracker_disp_colors", "[", "obj_id", "]", ",", "5", ")", "\n", "\n", "# Put text", "\n", "", "", "", "font_color", "=", "(", "0", ",", "0", ",", "0", ")", "\n", "cv", ".", "putText", "(", "frame_disp", ",", "'Select target'", ",", "(", "20", ",", "30", ")", ",", "cv", ".", "FONT_HERSHEY_COMPLEX_SMALL", ",", "1", ",", "font_color", ",", "1", ")", "\n", "cv", ".", "putText", "(", "frame_disp", ",", "'Press r to reset'", ",", "(", "20", ",", "55", ")", ",", "cv", ".", "FONT_HERSHEY_COMPLEX_SMALL", ",", "1", ",", "\n", "font_color", ",", "1", ")", "\n", "cv", ".", "putText", "(", "frame_disp", ",", "'Press q to quit'", ",", "(", "20", ",", "85", ")", ",", "cv", ".", "FONT_HERSHEY_COMPLEX_SMALL", ",", "1", ",", "\n", "font_color", ",", "1", ")", "\n", "\n", "# Display the resulting frame", "\n", "cv", ".", "imshow", "(", "display_name", ",", "frame_disp", ")", "\n", "key", "=", "cv", ".", "waitKey", "(", "1", ")", "\n", "if", "key", "==", "ord", "(", "'q'", ")", ":", "\n", "                ", "break", "\n", "", "elif", "key", "==", "ord", "(", "'r'", ")", ":", "\n", "                ", "next_object_id", "=", "1", "\n", "sequence_object_ids", "=", "[", "]", "\n", "prev_output", "=", "OrderedDict", "(", ")", "\n", "\n", "info", "=", "OrderedDict", "(", ")", "\n", "\n", "info", "[", "'object_ids'", "]", "=", "[", "]", "\n", "info", "[", "'init_object_ids'", "]", "=", "[", "]", "\n", "info", "[", "'init_bbox'", "]", "=", "OrderedDict", "(", ")", "\n", "tracker", ".", "initialize", "(", "frame", ",", "info", ")", "\n", "ui_control", ".", "mode", "=", "'init'", "\n", "\n", "# When everything done, release the capture", "\n", "", "", "cap", ".", "release", "(", ")", "\n", "cv", ".", "destroyAllWindows", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.run_vot2020": [[493, 583], ["tracker.Tracker.Tracker.get_parameters", "tracker.Tracker.Tracker._init_visdom", "tracker.Tracker.Tracker.create_tracker", "tracker.Tracker.Tracker.initialize_features", "tracker.Tracker.Tracker.predicts_segmentation_mask", "vot.VOT.region", "vot.VOT.frame", "tracker.Tracker.Tracker.run_vot2020._convert_image_path"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.get_parameters", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._init_visdom", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.create_tracker", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features", "home.repos.pwc.inspect_result.visionml_pytracking.base.basetracker.BaseTracker.predicts_segmentation_mask", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.region", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.frame"], ["", "def", "run_vot2020", "(", "self", ",", "debug", "=", "None", ",", "visdom_info", "=", "None", ")", ":", "\n", "        ", "params", "=", "self", ".", "get_parameters", "(", ")", "\n", "params", ".", "tracker_name", "=", "self", ".", "name", "\n", "params", ".", "param_name", "=", "self", ".", "parameter_name", "\n", "params", ".", "run_id", "=", "self", ".", "run_id", "\n", "\n", "debug_", "=", "debug", "\n", "if", "debug", "is", "None", ":", "\n", "            ", "debug_", "=", "getattr", "(", "params", ",", "'debug'", ",", "0", ")", "\n", "\n", "", "if", "debug", "is", "None", ":", "\n", "            ", "visualization_", "=", "getattr", "(", "params", ",", "'visualization'", ",", "False", ")", "\n", "", "else", ":", "\n", "            ", "visualization_", "=", "True", "if", "debug", "else", "False", "\n", "\n", "", "params", ".", "visualization", "=", "visualization_", "\n", "params", ".", "debug", "=", "debug_", "\n", "\n", "self", ".", "_init_visdom", "(", "visdom_info", ",", "debug_", ")", "\n", "\n", "tracker", "=", "self", ".", "create_tracker", "(", "params", ")", "\n", "tracker", ".", "initialize_features", "(", ")", "\n", "\n", "output_segmentation", "=", "tracker", ".", "predicts_segmentation_mask", "(", ")", "\n", "\n", "import", "pytracking", ".", "evaluation", ".", "vot2020", "as", "vot", "\n", "\n", "def", "_convert_anno_to_list", "(", "vot_anno", ")", ":", "\n", "            ", "vot_anno", "=", "[", "vot_anno", "[", "0", "]", ",", "vot_anno", "[", "1", "]", ",", "vot_anno", "[", "2", "]", ",", "vot_anno", "[", "3", "]", "]", "\n", "return", "vot_anno", "\n", "\n", "", "def", "_convert_image_path", "(", "image_path", ")", ":", "\n", "            ", "return", "image_path", "\n", "\n", "", "\"\"\"Run tracker on VOT.\"\"\"", "\n", "\n", "if", "output_segmentation", ":", "\n", "            ", "handle", "=", "vot", ".", "VOT", "(", "\"mask\"", ")", "\n", "", "else", ":", "\n", "            ", "handle", "=", "vot", ".", "VOT", "(", "\"rectangle\"", ")", "\n", "\n", "", "vot_anno", "=", "handle", ".", "region", "(", ")", "\n", "\n", "image_path", "=", "handle", ".", "frame", "(", ")", "\n", "if", "not", "image_path", ":", "\n", "            ", "return", "\n", "", "image_path", "=", "_convert_image_path", "(", "image_path", ")", "\n", "\n", "image", "=", "self", ".", "_read_image", "(", "image_path", ")", "\n", "\n", "if", "output_segmentation", ":", "\n", "            ", "vot_anno_mask", "=", "vot", ".", "make_full_size", "(", "vot_anno", ",", "(", "image", ".", "shape", "[", "1", "]", ",", "image", ".", "shape", "[", "0", "]", ")", ")", "\n", "bbox", "=", "masks_to_bboxes", "(", "torch", ".", "from_numpy", "(", "vot_anno_mask", ")", ",", "fmt", "=", "'t'", ")", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "bbox", "=", "_convert_anno_to_list", "(", "vot_anno", ")", "\n", "vot_anno_mask", "=", "None", "\n", "\n", "", "out", "=", "tracker", ".", "initialize", "(", "image", ",", "{", "'init_mask'", ":", "vot_anno_mask", ",", "'init_bbox'", ":", "bbox", "}", ")", "\n", "\n", "if", "out", "is", "None", ":", "\n", "            ", "out", "=", "{", "}", "\n", "", "prev_output", "=", "OrderedDict", "(", "out", ")", "\n", "\n", "# Track", "\n", "while", "True", ":", "\n", "            ", "image_path", "=", "handle", ".", "frame", "(", ")", "\n", "if", "not", "image_path", ":", "\n", "                ", "break", "\n", "", "image_path", "=", "_convert_image_path", "(", "image_path", ")", "\n", "\n", "image", "=", "self", ".", "_read_image", "(", "image_path", ")", "\n", "\n", "info", "=", "OrderedDict", "(", ")", "\n", "info", "[", "'previous_output'", "]", "=", "prev_output", "\n", "\n", "out", "=", "tracker", ".", "track", "(", "image", ",", "info", ")", "\n", "prev_output", "=", "OrderedDict", "(", "out", ")", "\n", "\n", "if", "output_segmentation", ":", "\n", "                ", "pred", "=", "out", "[", "'segmentation'", "]", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "", "else", ":", "\n", "                ", "state", "=", "out", "[", "'target_bbox'", "]", "\n", "pred", "=", "vot", ".", "Rectangle", "(", "*", "state", ")", "\n", "", "handle", ".", "report", "(", "pred", ",", "1.0", ")", "\n", "\n", "segmentation", "=", "out", "[", "'segmentation'", "]", "if", "'segmentation'", "in", "out", "else", "None", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                ", "tracker", ".", "visdom_draw_tracking", "(", "image", ",", "out", "[", "'target_bbox'", "]", ",", "segmentation", ")", "\n", "", "elif", "tracker", ".", "params", ".", "visualization", ":", "\n", "                ", "self", ".", "visualize", "(", "image", ",", "out", "[", "'target_bbox'", "]", ",", "segmentation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.run_vot": [[585, 654], ["tracker.Tracker.Tracker.get_parameters", "tracker.Tracker.Tracker._init_visdom", "tracker.Tracker.Tracker.create_tracker", "tracker.Tracker.Tracker.initialize_features", "vot.VOT", "vot.VOT.region", "tracker.Tracker.Tracker.run_vot2020._convert_anno_to_list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.get_parameters", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._init_visdom", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.create_tracker", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.initialize_features", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.vot2020.VOT.region"], ["", "", "", "def", "run_vot", "(", "self", ",", "debug", "=", "None", ",", "visdom_info", "=", "None", ")", ":", "\n", "        ", "params", "=", "self", ".", "get_parameters", "(", ")", "\n", "params", ".", "tracker_name", "=", "self", ".", "name", "\n", "params", ".", "param_name", "=", "self", ".", "parameter_name", "\n", "params", ".", "run_id", "=", "self", ".", "run_id", "\n", "\n", "debug_", "=", "debug", "\n", "if", "debug", "is", "None", ":", "\n", "            ", "debug_", "=", "getattr", "(", "params", ",", "'debug'", ",", "0", ")", "\n", "\n", "", "if", "debug", "is", "None", ":", "\n", "            ", "visualization_", "=", "getattr", "(", "params", ",", "'visualization'", ",", "False", ")", "\n", "", "else", ":", "\n", "            ", "visualization_", "=", "True", "if", "debug", "else", "False", "\n", "\n", "", "params", ".", "visualization", "=", "visualization_", "\n", "params", ".", "debug", "=", "debug_", "\n", "\n", "self", ".", "_init_visdom", "(", "visdom_info", ",", "debug_", ")", "\n", "\n", "tracker", "=", "self", ".", "create_tracker", "(", "params", ")", "\n", "tracker", ".", "initialize_features", "(", ")", "\n", "\n", "import", "pytracking", ".", "evaluation", ".", "vot", "as", "vot", "\n", "\n", "def", "_convert_anno_to_list", "(", "vot_anno", ")", ":", "\n", "            ", "vot_anno", "=", "[", "vot_anno", "[", "0", "]", "[", "0", "]", "[", "0", "]", ",", "vot_anno", "[", "0", "]", "[", "0", "]", "[", "1", "]", ",", "vot_anno", "[", "0", "]", "[", "1", "]", "[", "0", "]", ",", "vot_anno", "[", "0", "]", "[", "1", "]", "[", "1", "]", ",", "\n", "vot_anno", "[", "0", "]", "[", "2", "]", "[", "0", "]", ",", "vot_anno", "[", "0", "]", "[", "2", "]", "[", "1", "]", ",", "vot_anno", "[", "0", "]", "[", "3", "]", "[", "0", "]", ",", "vot_anno", "[", "0", "]", "[", "3", "]", "[", "1", "]", "]", "\n", "return", "vot_anno", "\n", "\n", "", "def", "_convert_image_path", "(", "image_path", ")", ":", "\n", "            ", "image_path_new", "=", "image_path", "[", "20", ":", "-", "2", "]", "\n", "return", "\"\"", ".", "join", "(", "image_path_new", ")", "\n", "\n", "", "\"\"\"Run tracker on VOT.\"\"\"", "\n", "\n", "handle", "=", "vot", ".", "VOT", "(", "\"polygon\"", ")", "\n", "\n", "vot_anno_polygon", "=", "handle", ".", "region", "(", ")", "\n", "vot_anno_polygon", "=", "_convert_anno_to_list", "(", "vot_anno_polygon", ")", "\n", "\n", "init_state", "=", "convert_vot_anno_to_rect", "(", "vot_anno_polygon", ",", "tracker", ".", "params", ".", "vot_anno_conversion_type", ")", "\n", "\n", "image_path", "=", "handle", ".", "frame", "(", ")", "\n", "if", "not", "image_path", ":", "\n", "            ", "return", "\n", "", "image_path", "=", "_convert_image_path", "(", "image_path", ")", "\n", "\n", "image", "=", "self", ".", "_read_image", "(", "image_path", ")", "\n", "tracker", ".", "initialize", "(", "image", ",", "{", "'init_bbox'", ":", "init_state", "}", ")", "\n", "\n", "# Track", "\n", "while", "True", ":", "\n", "            ", "image_path", "=", "handle", ".", "frame", "(", ")", "\n", "if", "not", "image_path", ":", "\n", "                ", "break", "\n", "", "image_path", "=", "_convert_image_path", "(", "image_path", ")", "\n", "\n", "image", "=", "self", ".", "_read_image", "(", "image_path", ")", "\n", "out", "=", "tracker", ".", "track", "(", "image", ")", "\n", "state", "=", "out", "[", "'target_bbox'", "]", "\n", "\n", "handle", ".", "report", "(", "vot", ".", "Rectangle", "(", "state", "[", "0", "]", ",", "state", "[", "1", "]", ",", "state", "[", "2", "]", ",", "state", "[", "3", "]", ")", ")", "\n", "\n", "segmentation", "=", "out", "[", "'segmentation'", "]", "if", "'segmentation'", "in", "out", "else", "None", "\n", "if", "self", ".", "visdom", "is", "not", "None", ":", "\n", "                ", "tracker", ".", "visdom_draw_tracking", "(", "image", ",", "out", "[", "'target_bbox'", "]", ",", "segmentation", ")", "\n", "", "elif", "tracker", ".", "params", ".", "visualization", ":", "\n", "                ", "self", ".", "visualize", "(", "image", ",", "out", "[", "'target_bbox'", "]", ",", "segmentation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.get_parameters": [[655, 660], ["importlib.import_module", "importlib.import_module.parameters"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["", "", "", "def", "get_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get parameters.\"\"\"", "\n", "param_module", "=", "importlib", ".", "import_module", "(", "'pytracking.parameter.{}.{}'", ".", "format", "(", "self", ".", "name", ",", "self", ".", "parameter_name", ")", ")", "\n", "params", "=", "param_module", ".", "parameters", "(", ")", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.init_visualization": [[662, 667], ["matplotlib.subplots", "matplotlib.subplots", "tracker.Tracker.fig.canvas.mpl_connect", "matplotlib.tight_layout", "matplotlib.tight_layout"], "methods", ["None"], ["", "def", "init_visualization", "(", "self", ")", ":", "\n", "        ", "self", ".", "pause_mode", "=", "False", "\n", "self", ".", "fig", ",", "self", ".", "ax", "=", "plt", ".", "subplots", "(", "1", ")", "\n", "self", ".", "fig", ".", "canvas", ".", "mpl_connect", "(", "'key_press_event'", ",", "self", ".", "press", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.visualize": [[669, 698], ["tracker.Tracker.ax.cla", "tracker.Tracker.ax.imshow", "isinstance", "enumerate", "tracker.Tracker.ax.set_axis_off", "tracker.Tracker.ax.axis", "pytracking.utils.plotting.draw_figure", "tracker.Tracker.ax.imshow", "matplotlib.Rectangle", "matplotlib.Rectangle", "tracker.Tracker.ax.add_patch", "getattr", "matplotlib.Rectangle", "matplotlib.Rectangle", "tracker.Tracker.ax.add_patch", "matplotlib.waitforbuttonpress", "matplotlib.waitforbuttonpress", "state.items", "float"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.plotting.draw_figure"], ["", "def", "visualize", "(", "self", ",", "image", ",", "state", ",", "segmentation", "=", "None", ")", ":", "\n", "        ", "self", ".", "ax", ".", "cla", "(", ")", "\n", "self", ".", "ax", ".", "imshow", "(", "image", ")", "\n", "if", "segmentation", "is", "not", "None", ":", "\n", "            ", "self", ".", "ax", ".", "imshow", "(", "segmentation", ",", "alpha", "=", "0.5", ")", "\n", "\n", "", "if", "isinstance", "(", "state", ",", "(", "OrderedDict", ",", "dict", ")", ")", ":", "\n", "            ", "boxes", "=", "[", "v", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "boxes", "=", "(", "state", ",", ")", "\n", "\n", "", "for", "i", ",", "box", "in", "enumerate", "(", "boxes", ",", "start", "=", "1", ")", ":", "\n", "            ", "col", "=", "_tracker_disp_colors", "[", "i", "]", "\n", "col", "=", "[", "float", "(", "c", ")", "/", "255.0", "for", "c", "in", "col", "]", "\n", "rect", "=", "patches", ".", "Rectangle", "(", "(", "box", "[", "0", "]", ",", "box", "[", "1", "]", ")", ",", "box", "[", "2", "]", ",", "box", "[", "3", "]", ",", "linewidth", "=", "1", ",", "edgecolor", "=", "col", ",", "facecolor", "=", "'none'", ")", "\n", "self", ".", "ax", ".", "add_patch", "(", "rect", ")", "\n", "\n", "", "if", "getattr", "(", "self", ",", "'gt_state'", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "gt_state", "=", "self", ".", "gt_state", "\n", "rect", "=", "patches", ".", "Rectangle", "(", "(", "gt_state", "[", "0", "]", ",", "gt_state", "[", "1", "]", ")", ",", "gt_state", "[", "2", "]", ",", "gt_state", "[", "3", "]", ",", "linewidth", "=", "1", ",", "edgecolor", "=", "'g'", ",", "facecolor", "=", "'none'", ")", "\n", "self", ".", "ax", ".", "add_patch", "(", "rect", ")", "\n", "", "self", ".", "ax", ".", "set_axis_off", "(", ")", "\n", "self", ".", "ax", ".", "axis", "(", "'equal'", ")", "\n", "draw_figure", "(", "self", ".", "fig", ")", "\n", "\n", "if", "self", ".", "pause_mode", ":", "\n", "            ", "keypress", "=", "False", "\n", "while", "not", "keypress", ":", "\n", "                ", "keypress", "=", "plt", ".", "waitforbuttonpress", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.reset_tracker": [[699, 701], ["None"], "methods", ["None"], ["", "", "", "def", "reset_tracker", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.press": [[702, 709], ["print", "tracker.Tracker.reset_tracker", "print"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.reset_tracker"], ["", "def", "press", "(", "self", ",", "event", ")", ":", "\n", "        ", "if", "event", ".", "key", "==", "'p'", ":", "\n", "            ", "self", ".", "pause_mode", "=", "not", "self", ".", "pause_mode", "\n", "print", "(", "\"Switching pause mode!\"", ")", "\n", "", "elif", "event", ".", "key", "==", "'r'", ":", "\n", "            ", "self", ".", "reset_tracker", "(", ")", "\n", "print", "(", "\"Resetting target pos to gt!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._read_image": [[710, 713], ["cv2.imread", "cv2.cvtColor"], "methods", ["None"], ["", "", "def", "_read_image", "(", "self", ",", "image_file", ":", "str", ")", ":", "\n", "        ", "im", "=", "cv", ".", "imread", "(", "image_file", ")", "\n", "return", "cv", ".", "cvtColor", "(", "im", ",", "cv", ".", "COLOR_BGR2RGB", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.trackerlist": [[24, 35], ["isinstance", "tracker.Tracker"], "function", ["None"], ["def", "trackerlist", "(", "name", ":", "str", ",", "parameter_name", ":", "str", ",", "run_ids", "=", "None", ",", "display_name", ":", "str", "=", "None", ")", ":", "\n", "    ", "\"\"\"Generate list of trackers.\n    args:\n        name: Name of tracking method.\n        parameter_name: Name of parameter file.\n        run_ids: A single or list of run_ids.\n        display_name: Name to be displayed in the result plots.\n    \"\"\"", "\n", "if", "run_ids", "is", "None", "or", "isinstance", "(", "run_ids", ",", "int", ")", ":", "\n", "        ", "run_ids", "=", "[", "run_ids", "]", "\n", "", "return", "[", "Tracker", "(", "name", ",", "parameter_name", ",", "run_id", ",", "display_name", ")", "for", "run_id", "in", "run_ids", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.votdataset.VOTDataset.__init__": [[18, 22], ["pytracking.evaluation.data.BaseDataset.__init__", "votdataset.VOTDataset._get_sequence_list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._get_sequence_list"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_path", "=", "self", ".", "env_settings", ".", "vot_path", "\n", "self", ".", "sequence_list", "=", "self", ".", "_get_sequence_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.votdataset.VOTDataset.get_sequence_list": [[23, 25], ["pytracking.evaluation.data.SequenceList", "votdataset.VOTDataset._construct_sequence"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence"], ["", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "return", "SequenceList", "(", "[", "self", ".", "_construct_sequence", "(", "s", ")", "for", "s", "in", "self", ".", "sequence_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.votdataset.VOTDataset._construct_sequence": [[26, 56], ["pytracking.evaluation.data.Sequence", "numpy.loadtxt", "numpy.amin().reshape", "numpy.amin().reshape", "numpy.amax().reshape", "numpy.amax().reshape", "numpy.concatenate", "str", "numpy.loadtxt", "range", "str", "numpy.amin", "numpy.amin", "numpy.amax", "numpy.amax"], "methods", ["None"], ["", "def", "_construct_sequence", "(", "self", ",", "sequence_name", ")", ":", "\n", "        ", "sequence_path", "=", "sequence_name", "\n", "nz", "=", "8", "\n", "ext", "=", "'jpg'", "\n", "start_frame", "=", "1", "\n", "\n", "anno_path", "=", "'{}/{}/groundtruth.txt'", ".", "format", "(", "self", ".", "base_path", ",", "sequence_name", ")", "\n", "try", ":", "\n", "            ", "ground_truth_rect", "=", "np", ".", "loadtxt", "(", "str", "(", "anno_path", ")", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "", "except", ":", "\n", "            ", "ground_truth_rect", "=", "np", ".", "loadtxt", "(", "str", "(", "anno_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "", "end_frame", "=", "ground_truth_rect", ".", "shape", "[", "0", "]", "\n", "\n", "frames", "=", "[", "'{base_path}/{sequence_path}/color/{frame:0{nz}}.{ext}'", ".", "format", "(", "base_path", "=", "self", ".", "base_path", ",", "\n", "sequence_path", "=", "sequence_path", ",", "frame", "=", "frame_num", ",", "nz", "=", "nz", ",", "ext", "=", "ext", ")", "\n", "for", "frame_num", "in", "range", "(", "start_frame", ",", "end_frame", "+", "1", ")", "]", "\n", "\n", "# Convert gt", "\n", "if", "ground_truth_rect", ".", "shape", "[", "1", "]", ">", "4", ":", "\n", "            ", "gt_x_all", "=", "ground_truth_rect", "[", ":", ",", "[", "0", ",", "2", ",", "4", ",", "6", "]", "]", "\n", "gt_y_all", "=", "ground_truth_rect", "[", ":", ",", "[", "1", ",", "3", ",", "5", ",", "7", "]", "]", "\n", "\n", "x1", "=", "np", ".", "amin", "(", "gt_x_all", ",", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "y1", "=", "np", ".", "amin", "(", "gt_y_all", ",", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "x2", "=", "np", ".", "amax", "(", "gt_x_all", ",", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "y2", "=", "np", ".", "amax", "(", "gt_y_all", ",", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "ground_truth_rect", "=", "np", ".", "concatenate", "(", "(", "x1", ",", "y1", ",", "x2", "-", "x1", ",", "y2", "-", "y1", ")", ",", "1", ")", "\n", "", "return", "Sequence", "(", "sequence_name", ",", "frames", ",", "'vot'", ",", "ground_truth_rect", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.votdataset.VOTDataset.__len__": [[57, 59], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.votdataset.VOTDataset._get_sequence_list": [[60, 123], ["None"], "methods", ["None"], ["", "def", "_get_sequence_list", "(", "self", ")", ":", "\n", "        ", "sequence_list", "=", "[", "'ants1'", ",", "\n", "'ants3'", ",", "\n", "'bag'", ",", "\n", "'ball1'", ",", "\n", "'ball2'", ",", "\n", "'basketball'", ",", "\n", "'birds1'", ",", "\n", "'blanket'", ",", "\n", "'bmx'", ",", "\n", "'bolt1'", ",", "\n", "'bolt2'", ",", "\n", "'book'", ",", "\n", "'butterfly'", ",", "\n", "'car1'", ",", "\n", "'conduction1'", ",", "\n", "'crabs1'", ",", "\n", "'crossing'", ",", "\n", "'dinosaur'", ",", "\n", "'drone_across'", ",", "\n", "'drone_flip'", ",", "\n", "'drone1'", ",", "\n", "'fernando'", ",", "\n", "'fish1'", ",", "\n", "'fish2'", ",", "\n", "'fish3'", ",", "\n", "'flamingo1'", ",", "\n", "'frisbee'", ",", "\n", "'girl'", ",", "\n", "'glove'", ",", "\n", "'godfather'", ",", "\n", "'graduate'", ",", "\n", "'gymnastics1'", ",", "\n", "'gymnastics2'", ",", "\n", "'gymnastics3'", ",", "\n", "'hand'", ",", "\n", "'handball1'", ",", "\n", "'handball2'", ",", "\n", "'helicopter'", ",", "\n", "'iceskater1'", ",", "\n", "'iceskater2'", ",", "\n", "'leaves'", ",", "\n", "'matrix'", ",", "\n", "'motocross1'", ",", "\n", "'motocross2'", ",", "\n", "'nature'", ",", "\n", "'pedestrian1'", ",", "\n", "'rabbit'", ",", "\n", "'racing'", ",", "\n", "'road'", ",", "\n", "'shaking'", ",", "\n", "'sheep'", ",", "\n", "'singer2'", ",", "\n", "'singer3'", ",", "\n", "'soccer1'", ",", "\n", "'soccer2'", ",", "\n", "'soldier'", ",", "\n", "'tiger'", ",", "\n", "'traffic'", ",", "\n", "'wiper'", ",", "\n", "'zebrafish1'", "]", "\n", "\n", "return", "sequence_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tpldataset.TPLDataset.__init__": [[18, 26], ["pytracking.evaluation.data.BaseDataset.__init__", "tpldataset.TPLDataset._get_sequence_info_list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.uavdataset.UAVDataset._get_sequence_info_list"], ["def", "__init__", "(", "self", ",", "exclude_otb", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            exclude_otb (bool) - If True, sequences overlapping with the OTB dataset are excluded\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_path", "=", "self", ".", "env_settings", ".", "tpl_path", "\n", "self", ".", "sequence_info_list", "=", "self", ".", "_get_sequence_info_list", "(", "exclude_otb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tpldataset.TPLDataset.get_sequence_list": [[27, 29], ["pytracking.evaluation.data.SequenceList", "tpldataset.TPLDataset._construct_sequence"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence"], ["", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "return", "SequenceList", "(", "[", "self", ".", "_construct_sequence", "(", "s", ")", "for", "s", "in", "self", ".", "sequence_info_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tpldataset.TPLDataset._construct_sequence": [[30, 49], ["pytracking.utils.load_text.load_text", "pytracking.evaluation.data.Sequence", "str", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text"], ["", "def", "_construct_sequence", "(", "self", ",", "sequence_info", ")", ":", "\n", "        ", "sequence_path", "=", "sequence_info", "[", "'path'", "]", "\n", "nz", "=", "sequence_info", "[", "'nz'", "]", "\n", "ext", "=", "sequence_info", "[", "'ext'", "]", "\n", "start_frame", "=", "sequence_info", "[", "'startFrame'", "]", "\n", "end_frame", "=", "sequence_info", "[", "'endFrame'", "]", "\n", "\n", "init_omit", "=", "0", "\n", "if", "'initOmit'", "in", "sequence_info", ":", "\n", "            ", "init_omit", "=", "sequence_info", "[", "'initOmit'", "]", "\n", "\n", "", "frames", "=", "[", "'{base_path}/{sequence_path}/{frame:0{nz}}.{ext}'", ".", "format", "(", "base_path", "=", "self", ".", "base_path", ",", "\n", "sequence_path", "=", "sequence_path", ",", "frame", "=", "frame_num", ",", "nz", "=", "nz", ",", "ext", "=", "ext", ")", "for", "frame_num", "in", "range", "(", "start_frame", "+", "init_omit", ",", "end_frame", "+", "1", ")", "]", "\n", "\n", "anno_path", "=", "'{}/{}'", ".", "format", "(", "self", ".", "base_path", ",", "sequence_info", "[", "'anno_path'", "]", ")", "\n", "\n", "ground_truth_rect", "=", "load_text", "(", "str", "(", "anno_path", ")", ",", "delimiter", "=", "(", "','", ",", "None", ")", ",", "dtype", "=", "np", ".", "float64", ",", "backend", "=", "'numpy'", ")", "\n", "\n", "return", "Sequence", "(", "sequence_info", "[", "'name'", "]", ",", "frames", ",", "'tpl'", ",", "ground_truth_rect", "[", "init_omit", ":", ",", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tpldataset.TPLDataset.__len__": [[50, 52], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_info_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tpldataset.TPLDataset._get_sequence_info_list": [[53, 329], ["sequence_info_list_nootb.append"], "methods", ["None"], ["", "def", "_get_sequence_info_list", "(", "self", ",", "exclude_otb", "=", "False", ")", ":", "\n", "        ", "sequence_info_list", "=", "[", "\n", "{", "\"name\"", ":", "\"tpl_Skating2\"", ",", "\"path\"", ":", "\"tpl_Skating2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "707", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Skating2/Skating2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Pool_ce3\"", ",", "\"path\"", ":", "\"tpl_Pool_ce3/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "124", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Pool_ce3/Pool_ce3_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Microphone_ce1\"", ",", "\"path\"", ":", "\"tpl_Microphone_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "204", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Microphone_ce1/Microphone_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Torus\"", ",", "\"path\"", ":", "\"tpl_Torus/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "264", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Torus/Torus_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Lemming\"", ",", "\"path\"", ":", "\"tpl_Lemming/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1336", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Lemming/Lemming_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Eagle_ce\"", ",", "\"path\"", ":", "\"tpl_Eagle_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "112", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Eagle_ce/Eagle_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Skating_ce2\"", ",", "\"path\"", ":", "\"tpl_Skating_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "497", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Skating_ce2/Skating_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Yo_yos_ce3\"", ",", "\"path\"", ":", "\"tpl_Yo_yos_ce3/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "201", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Yo_yos_ce3/Yo-yos_ce3_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Board\"", ",", "\"path\"", ":", "\"tpl_Board/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "598", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Board/Board_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Tennis_ce3\"", ",", "\"path\"", ":", "\"tpl_Tennis_ce3/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "204", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Tennis_ce3/Tennis_ce3_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_SuperMario_ce\"", ",", "\"path\"", ":", "\"tpl_SuperMario_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "146", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_SuperMario_ce/SuperMario_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Yo_yos_ce1\"", ",", "\"path\"", ":", "\"tpl_Yo_yos_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "235", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Yo_yos_ce1/Yo-yos_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Soccer\"", ",", "\"path\"", ":", "\"tpl_Soccer/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "392", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Soccer/Soccer_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Fish_ce2\"", ",", "\"path\"", ":", "\"tpl_Fish_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "573", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Fish_ce2/Fish_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Liquor\"", ",", "\"path\"", ":", "\"tpl_Liquor/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1741", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Liquor/Liquor_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Plane_ce2\"", ",", "\"path\"", ":", "\"tpl_Plane_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "653", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Plane_ce2/Plane_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Couple\"", ",", "\"path\"", ":", "\"tpl_Couple/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "140", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Couple/Couple_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Logo_ce\"", ",", "\"path\"", ":", "\"tpl_Logo_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "610", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Logo_ce/Logo_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Hand_ce2\"", ",", "\"path\"", ":", "\"tpl_Hand_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "251", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Hand_ce2/Hand_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Kite_ce2\"", ",", "\"path\"", ":", "\"tpl_Kite_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "658", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Kite_ce2/Kite_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Walking\"", ",", "\"path\"", ":", "\"tpl_Walking/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "412", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Walking/Walking_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_David\"", ",", "\"path\"", ":", "\"tpl_David/img\"", ",", "\"startFrame\"", ":", "300", ",", "\"endFrame\"", ":", "770", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_David/David_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Boat_ce1\"", ",", "\"path\"", ":", "\"tpl_Boat_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "377", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Boat_ce1/Boat_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Airport_ce\"", ",", "\"path\"", ":", "\"tpl_Airport_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "148", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Airport_ce/Airport_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Tiger2\"", ",", "\"path\"", ":", "\"tpl_Tiger2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "365", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Tiger2/Tiger2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Suitcase_ce\"", ",", "\"path\"", ":", "\"tpl_Suitcase_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "184", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Suitcase_ce/Suitcase_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_TennisBall_ce\"", ",", "\"path\"", ":", "\"tpl_TennisBall_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "288", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_TennisBall_ce/TennisBall_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Singer_ce1\"", ",", "\"path\"", ":", "\"tpl_Singer_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "214", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Singer_ce1/Singer_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Pool_ce2\"", ",", "\"path\"", ":", "\"tpl_Pool_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "133", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Pool_ce2/Pool_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Surf_ce3\"", ",", "\"path\"", ":", "\"tpl_Surf_ce3/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "279", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Surf_ce3/Surf_ce3_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Bird\"", ",", "\"path\"", ":", "\"tpl_Bird/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "99", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Bird/Bird_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Crossing\"", ",", "\"path\"", ":", "\"tpl_Crossing/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "120", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Crossing/Crossing_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Plate_ce1\"", ",", "\"path\"", ":", "\"tpl_Plate_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "142", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Plate_ce1/Plate_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Cup\"", ",", "\"path\"", ":", "\"tpl_Cup/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "303", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Cup/Cup_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Surf_ce2\"", ",", "\"path\"", ":", "\"tpl_Surf_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "391", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Surf_ce2/Surf_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Busstation_ce2\"", ",", "\"path\"", ":", "\"tpl_Busstation_ce2/img\"", ",", "\"startFrame\"", ":", "6", ",", "\"endFrame\"", ":", "400", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Busstation_ce2/Busstation_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Charger_ce\"", ",", "\"path\"", ":", "\"tpl_Charger_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "298", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Charger_ce/Charger_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Pool_ce1\"", ",", "\"path\"", ":", "\"tpl_Pool_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "166", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Pool_ce1/Pool_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_MountainBike\"", ",", "\"path\"", ":", "\"tpl_MountainBike/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "228", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_MountainBike/MountainBike_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Guitar_ce1\"", ",", "\"path\"", ":", "\"tpl_Guitar_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "268", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Guitar_ce1/Guitar_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Busstation_ce1\"", ",", "\"path\"", ":", "\"tpl_Busstation_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "363", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Busstation_ce1/Busstation_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Diving\"", ",", "\"path\"", ":", "\"tpl_Diving/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "231", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Diving/Diving_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Skating_ce1\"", ",", "\"path\"", ":", "\"tpl_Skating_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "409", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Skating_ce1/Skating_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Hurdle_ce2\"", ",", "\"path\"", ":", "\"tpl_Hurdle_ce2/img\"", ",", "\"startFrame\"", ":", "27", ",", "\"endFrame\"", ":", "330", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Hurdle_ce2/Hurdle_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Plate_ce2\"", ",", "\"path\"", ":", "\"tpl_Plate_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "181", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Plate_ce2/Plate_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_CarDark\"", ",", "\"path\"", ":", "\"tpl_CarDark/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "393", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_CarDark/CarDark_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Singer_ce2\"", ",", "\"path\"", ":", "\"tpl_Singer_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "999", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Singer_ce2/Singer_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Shaking\"", ",", "\"path\"", ":", "\"tpl_Shaking/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "365", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Shaking/Shaking_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Iceskater\"", ",", "\"path\"", ":", "\"tpl_Iceskater/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "500", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Iceskater/Iceskater_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Badminton_ce2\"", ",", "\"path\"", ":", "\"tpl_Badminton_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "705", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Badminton_ce2/Badminton_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Spiderman_ce\"", ",", "\"path\"", ":", "\"tpl_Spiderman_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "351", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Spiderman_ce/Spiderman_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Kite_ce1\"", ",", "\"path\"", ":", "\"tpl_Kite_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "484", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Kite_ce1/Kite_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Skyjumping_ce\"", ",", "\"path\"", ":", "\"tpl_Skyjumping_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "938", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Skyjumping_ce/Skyjumping_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Ball_ce1\"", ",", "\"path\"", ":", "\"tpl_Ball_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "391", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Ball_ce1/Ball_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Yo_yos_ce2\"", ",", "\"path\"", ":", "\"tpl_Yo_yos_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "454", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Yo_yos_ce2/Yo-yos_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Ironman\"", ",", "\"path\"", ":", "\"tpl_Ironman/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "166", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Ironman/Ironman_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_FaceOcc1\"", ",", "\"path\"", ":", "\"tpl_FaceOcc1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "892", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_FaceOcc1/FaceOcc1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Surf_ce1\"", ",", "\"path\"", ":", "\"tpl_Surf_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "404", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Surf_ce1/Surf_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Ring_ce\"", ",", "\"path\"", ":", "\"tpl_Ring_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "201", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Ring_ce/Ring_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Surf_ce4\"", ",", "\"path\"", ":", "\"tpl_Surf_ce4/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "135", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Surf_ce4/Surf_ce4_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Ball_ce4\"", ",", "\"path\"", ":", "\"tpl_Ball_ce4/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "538", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Ball_ce4/Ball_ce4_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Bikeshow_ce\"", ",", "\"path\"", ":", "\"tpl_Bikeshow_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "361", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Bikeshow_ce/Bikeshow_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Kobe_ce\"", ",", "\"path\"", ":", "\"tpl_Kobe_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "582", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Kobe_ce/Kobe_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Tiger1\"", ",", "\"path\"", ":", "\"tpl_Tiger1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "354", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Tiger1/Tiger1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Skiing\"", ",", "\"path\"", ":", "\"tpl_Skiing/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "81", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Skiing/Skiing_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Tennis_ce1\"", ",", "\"path\"", ":", "\"tpl_Tennis_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "454", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Tennis_ce1/Tennis_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Carchasing_ce4\"", ",", "\"path\"", ":", "\"tpl_Carchasing_ce4/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "442", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Carchasing_ce4/Carchasing_ce4_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Walking2\"", ",", "\"path\"", ":", "\"tpl_Walking2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "500", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Walking2/Walking2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Sailor_ce\"", ",", "\"path\"", ":", "\"tpl_Sailor_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "402", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Sailor_ce/Sailor_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Railwaystation_ce\"", ",", "\"path\"", ":", "\"tpl_Railwaystation_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "413", ",", "\n", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Railwaystation_ce/Railwaystation_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Bee_ce\"", ",", "\"path\"", ":", "\"tpl_Bee_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "90", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Bee_ce/Bee_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Girl\"", ",", "\"path\"", ":", "\"tpl_Girl/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "500", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Girl/Girl_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Subway\"", ",", "\"path\"", ":", "\"tpl_Subway/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "175", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Subway/Subway_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_David3\"", ",", "\"path\"", ":", "\"tpl_David3/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "252", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_David3/David3_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Electricalbike_ce\"", ",", "\"path\"", ":", "\"tpl_Electricalbike_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "818", ",", "\n", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Electricalbike_ce/Electricalbike_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Michaeljackson_ce\"", ",", "\"path\"", ":", "\"tpl_Michaeljackson_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "393", ",", "\n", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Michaeljackson_ce/Michaeljackson_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Woman\"", ",", "\"path\"", ":", "\"tpl_Woman/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "597", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Woman/Woman_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_TableTennis_ce\"", ",", "\"path\"", ":", "\"tpl_TableTennis_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "198", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_TableTennis_ce/TableTennis_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Motorbike_ce\"", ",", "\"path\"", ":", "\"tpl_Motorbike_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "563", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Motorbike_ce/Motorbike_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Baby_ce\"", ",", "\"path\"", ":", "\"tpl_Baby_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "296", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Baby_ce/Baby_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Gym\"", ",", "\"path\"", ":", "\"tpl_Gym/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "766", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Gym/Gym_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Matrix\"", ",", "\"path\"", ":", "\"tpl_Matrix/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "100", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Matrix/Matrix_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Kite_ce3\"", ",", "\"path\"", ":", "\"tpl_Kite_ce3/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "528", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Kite_ce3/Kite_ce3_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Fish_ce1\"", ",", "\"path\"", ":", "\"tpl_Fish_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "401", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Fish_ce1/Fish_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Hand_ce1\"", ",", "\"path\"", ":", "\"tpl_Hand_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "401", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Hand_ce1/Hand_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Doll\"", ",", "\"path\"", ":", "\"tpl_Doll/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "3872", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Doll/Doll_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Carchasing_ce3\"", ",", "\"path\"", ":", "\"tpl_Carchasing_ce3/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "572", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Carchasing_ce3/Carchasing_ce3_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Thunder_ce\"", ",", "\"path\"", ":", "\"tpl_Thunder_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "375", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Thunder_ce/Thunder_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Singer2\"", ",", "\"path\"", ":", "\"tpl_Singer2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "366", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Singer2/Singer2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Basketball\"", ",", "\"path\"", ":", "\"tpl_Basketball/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "725", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Basketball/Basketball_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Hand\"", ",", "\"path\"", ":", "\"tpl_Hand/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "244", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Hand/Hand_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Cup_ce\"", ",", "\"path\"", ":", "\"tpl_Cup_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "338", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Cup_ce/Cup_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_MotorRolling\"", ",", "\"path\"", ":", "\"tpl_MotorRolling/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "164", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_MotorRolling/MotorRolling_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Boat_ce2\"", ",", "\"path\"", ":", "\"tpl_Boat_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "412", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Boat_ce2/Boat_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_CarScale\"", ",", "\"path\"", ":", "\"tpl_CarScale/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "252", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_CarScale/CarScale_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Sunshade\"", ",", "\"path\"", ":", "\"tpl_Sunshade/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "172", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Sunshade/Sunshade_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Football1\"", ",", "\"path\"", ":", "\"tpl_Football1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "74", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Football1/Football1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Singer1\"", ",", "\"path\"", ":", "\"tpl_Singer1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "351", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Singer1/Singer1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Hurdle_ce1\"", ",", "\"path\"", ":", "\"tpl_Hurdle_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "300", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Hurdle_ce1/Hurdle_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Basketball_ce3\"", ",", "\"path\"", ":", "\"tpl_Basketball_ce3/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "441", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Basketball_ce3/Basketball_ce3_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Toyplane_ce\"", ",", "\"path\"", ":", "\"tpl_Toyplane_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "405", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Toyplane_ce/Toyplane_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Skating1\"", ",", "\"path\"", ":", "\"tpl_Skating1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "400", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Skating1/Skating1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Juice\"", ",", "\"path\"", ":", "\"tpl_Juice/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "404", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Juice/Juice_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Biker\"", ",", "\"path\"", ":", "\"tpl_Biker/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "180", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Biker/Biker_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Boy\"", ",", "\"path\"", ":", "\"tpl_Boy/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "602", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Boy/Boy_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Jogging1\"", ",", "\"path\"", ":", "\"tpl_Jogging1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "307", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Jogging1/Jogging1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Deer\"", ",", "\"path\"", ":", "\"tpl_Deer/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "71", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Deer/Deer_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Panda\"", ",", "\"path\"", ":", "\"tpl_Panda/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "241", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Panda/Panda_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Coke\"", ",", "\"path\"", ":", "\"tpl_Coke/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "291", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Coke/Coke_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Carchasing_ce1\"", ",", "\"path\"", ":", "\"tpl_Carchasing_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "501", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Carchasing_ce1/Carchasing_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Badminton_ce1\"", ",", "\"path\"", ":", "\"tpl_Badminton_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "579", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Badminton_ce1/Badminton_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Trellis\"", ",", "\"path\"", ":", "\"tpl_Trellis/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "569", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Trellis/Trellis_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Face_ce2\"", ",", "\"path\"", ":", "\"tpl_Face_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "148", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Face_ce2/Face_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Ball_ce2\"", ",", "\"path\"", ":", "\"tpl_Ball_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "603", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Ball_ce2/Ball_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Skiing_ce\"", ",", "\"path\"", ":", "\"tpl_Skiing_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "511", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Skiing_ce/Skiing_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Jogging2\"", ",", "\"path\"", ":", "\"tpl_Jogging2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "307", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Jogging2/Jogging2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Bike_ce1\"", ",", "\"path\"", ":", "\"tpl_Bike_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "801", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Bike_ce1/Bike_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Bike_ce2\"", ",", "\"path\"", ":", "\"tpl_Bike_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "812", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Bike_ce2/Bike_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Ball_ce3\"", ",", "\"path\"", ":", "\"tpl_Ball_ce3/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "273", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Ball_ce3/Ball_ce3_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Girlmov\"", ",", "\"path\"", ":", "\"tpl_Girlmov/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1500", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Girlmov/Girlmov_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Bolt\"", ",", "\"path\"", ":", "\"tpl_Bolt/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "350", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Bolt/Bolt_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Basketball_ce2\"", ",", "\"path\"", ":", "\"tpl_Basketball_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "455", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Basketball_ce2/Basketball_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Bicycle\"", ",", "\"path\"", ":", "\"tpl_Bicycle/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "271", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Bicycle/Bicycle_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Face_ce\"", ",", "\"path\"", ":", "\"tpl_Face_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "620", ",", "\"nz\"", ":", "4", ",", "\"ext\"", ":", "\"jpg\"", ",", "\n", "\"anno_path\"", ":", "\"tpl_Face_ce/Face_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Basketball_ce1\"", ",", "\"path\"", ":", "\"tpl_Basketball_ce1/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "496", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Basketball_ce1/Basketball_ce1_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Messi_ce\"", ",", "\"path\"", ":", "\"tpl_Messi_ce/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "272", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Messi_ce/Messi_ce_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Tennis_ce2\"", ",", "\"path\"", ":", "\"tpl_Tennis_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "305", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Tennis_ce2/Tennis_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Microphone_ce2\"", ",", "\"path\"", ":", "\"tpl_Microphone_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "103", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Microphone_ce2/Microphone_ce2_gt.txt\"", "}", ",", "\n", "{", "\"name\"", ":", "\"tpl_Guitar_ce2\"", ",", "\"path\"", ":", "\"tpl_Guitar_ce2/img\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "313", ",", "\"nz\"", ":", "4", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"tpl_Guitar_ce2/Guitar_ce2_gt.txt\"", "}", "\n", "\n", "]", "\n", "\n", "otb_sequences", "=", "[", "'tpl_Skating2'", ",", "'tpl_Lemming'", ",", "'tpl_Board'", ",", "'tpl_Soccer'", ",", "'tpl_Liquor'", ",", "'tpl_Couple'", ",", "'tpl_Walking'", ",", "'tpl_David'", ",", "'tpl_Tiger2'", ",", "'tpl_Bird'", ",", "'tpl_Crossing'", ",", "'tpl_MountainBike'", ",", "\n", "'tpl_Diving'", ",", "'tpl_CarDark'", ",", "'tpl_Shaking'", ",", "'tpl_Ironman'", ",", "'tpl_FaceOcc1'", ",", "'tpl_Tiger1'", ",", "'tpl_Skiing'", ",", "'tpl_Walking2'", ",", "'tpl_Girl'", ",", "'tpl_Girlmov'", ",", "'tpl_Subway'", ",", "'tpl_David3'", ",", "'tpl_Woman'", ",", "\n", "'tpl_Gym'", ",", "'tpl_Matrix'", ",", "'tpl_Doll'", ",", "'tpl_Singer2'", ",", "'tpl_Basketball'", ",", "'tpl_MotorRolling'", ",", "'tpl_CarScale'", ",", "'tpl_Football1'", ",", "'tpl_Singer1'", ",", "'tpl_Skating1'", ",", "'tpl_Biker'", ",", "\n", "'tpl_Boy'", ",", "'tpl_Jogging1'", ",", "'tpl_Deer'", ",", "'tpl_Panda'", ",", "'tpl_Coke'", ",", "'tpl_Trellis'", ",", "'tpl_Jogging2'", ",", "'tpl_Bolt'", ",", "]", "\n", "if", "exclude_otb", ":", "\n", "            ", "sequence_info_list_nootb", "=", "[", "]", "\n", "for", "seq", "in", "sequence_info_list", ":", "\n", "                ", "if", "seq", "[", "'name'", "]", "not", "in", "otb_sequences", ":", "\n", "                    ", "sequence_info_list_nootb", ".", "append", "(", "seq", ")", "\n", "\n", "", "", "sequence_info_list", "=", "sequence_info_list_nootb", "\n", "\n", "", "return", "sequence_info_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.uavdataset.UAVDataset.__init__": [[17, 21], ["pytracking.evaluation.data.BaseDataset.__init__", "uavdataset.UAVDataset._get_sequence_info_list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.uavdataset.UAVDataset._get_sequence_info_list"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_path", "=", "self", ".", "env_settings", ".", "uav_path", "\n", "self", ".", "sequence_info_list", "=", "self", ".", "_get_sequence_info_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.uavdataset.UAVDataset.get_sequence_list": [[22, 24], ["pytracking.evaluation.data.SequenceList", "uavdataset.UAVDataset._construct_sequence"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence"], ["", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "return", "SequenceList", "(", "[", "self", ".", "_construct_sequence", "(", "s", ")", "for", "s", "in", "self", ".", "sequence_info_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.uavdataset.UAVDataset._construct_sequence": [[25, 45], ["pytracking.utils.load_text.load_text", "pytracking.evaluation.data.Sequence", "str", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text"], ["", "def", "_construct_sequence", "(", "self", ",", "sequence_info", ")", ":", "\n", "        ", "sequence_path", "=", "sequence_info", "[", "'path'", "]", "\n", "nz", "=", "sequence_info", "[", "'nz'", "]", "\n", "ext", "=", "sequence_info", "[", "'ext'", "]", "\n", "start_frame", "=", "sequence_info", "[", "'startFrame'", "]", "\n", "end_frame", "=", "sequence_info", "[", "'endFrame'", "]", "\n", "\n", "init_omit", "=", "0", "\n", "if", "'initOmit'", "in", "sequence_info", ":", "\n", "            ", "init_omit", "=", "sequence_info", "[", "'initOmit'", "]", "\n", "\n", "", "frames", "=", "[", "'{base_path}/{sequence_path}/{frame:0{nz}}.{ext}'", ".", "format", "(", "base_path", "=", "self", ".", "base_path", ",", "\n", "sequence_path", "=", "sequence_path", ",", "frame", "=", "frame_num", ",", "nz", "=", "nz", ",", "ext", "=", "ext", ")", "for", "frame_num", "in", "range", "(", "start_frame", "+", "init_omit", ",", "end_frame", "+", "1", ")", "]", "\n", "\n", "anno_path", "=", "'{}/{}'", ".", "format", "(", "self", ".", "base_path", ",", "sequence_info", "[", "'anno_path'", "]", ")", "\n", "\n", "ground_truth_rect", "=", "load_text", "(", "str", "(", "anno_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ",", "backend", "=", "'numpy'", ")", "\n", "\n", "return", "Sequence", "(", "sequence_info", "[", "'name'", "]", ",", "frames", ",", "'uav'", ",", "ground_truth_rect", "[", "init_omit", ":", ",", ":", "]", ",", "\n", "object_class", "=", "sequence_info", "[", "'object_class'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.uavdataset.UAVDataset.__len__": [[46, 48], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_info_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.uavdataset.UAVDataset._get_sequence_info_list": [[49, 300], ["None"], "methods", ["None"], ["", "def", "_get_sequence_info_list", "(", "self", ")", ":", "\n", "        ", "sequence_info_list", "=", "[", "\n", "{", "\"name\"", ":", "\"uav_bike1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/bike1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "3085", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/bike1.txt\"", ",", "\"object_class\"", ":", "\"vehicle\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_bike2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/bike2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "553", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/bike2.txt\"", ",", "\"object_class\"", ":", "\"vehicle\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_bike3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/bike3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "433", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/bike3.txt\"", ",", "\"object_class\"", ":", "\"vehicle\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_bird1_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/bird1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "253", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/bird1_1.txt\"", ",", "\"object_class\"", ":", "\"bird\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_bird1_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/bird1\"", ",", "\"startFrame\"", ":", "775", ",", "\"endFrame\"", ":", "1477", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/bird1_2.txt\"", ",", "\"object_class\"", ":", "\"bird\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_bird1_3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/bird1\"", ",", "\"startFrame\"", ":", "1573", ",", "\"endFrame\"", ":", "2437", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/bird1_3.txt\"", ",", "\"object_class\"", ":", "\"bird\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_boat1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/boat1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "901", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/boat1.txt\"", ",", "\"object_class\"", ":", "\"vessel\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_boat2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/boat2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "799", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/boat2.txt\"", ",", "\"object_class\"", ":", "\"vessel\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_boat3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/boat3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "901", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/boat3.txt\"", ",", "\"object_class\"", ":", "\"vessel\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_boat4\"", ",", "\"path\"", ":", "\"data_seq/UAV123/boat4\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "553", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/boat4.txt\"", ",", "\"object_class\"", ":", "\"vessel\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_boat5\"", ",", "\"path\"", ":", "\"data_seq/UAV123/boat5\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "505", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/boat5.txt\"", ",", "\"object_class\"", ":", "\"vessel\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_boat6\"", ",", "\"path\"", ":", "\"data_seq/UAV123/boat6\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "805", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/boat6.txt\"", ",", "\"object_class\"", ":", "\"vessel\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_boat7\"", ",", "\"path\"", ":", "\"data_seq/UAV123/boat7\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "535", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/boat7.txt\"", ",", "\"object_class\"", ":", "\"vessel\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_boat8\"", ",", "\"path\"", ":", "\"data_seq/UAV123/boat8\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "685", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/boat8.txt\"", ",", "\"object_class\"", ":", "\"vessel\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_boat9\"", ",", "\"path\"", ":", "\"data_seq/UAV123/boat9\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1399", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/boat9.txt\"", ",", "\"object_class\"", ":", "\"vessel\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_building1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/building1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "469", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/building1.txt\"", ",", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_building2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/building2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "577", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/building2.txt\"", ",", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_building3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/building3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "829", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/building3.txt\"", ",", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_building4\"", ",", "\"path\"", ":", "\"data_seq/UAV123/building4\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "787", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/building4.txt\"", ",", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_building5\"", ",", "\"path\"", ":", "\"data_seq/UAV123/building5\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "481", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/building5.txt\"", ",", "\"object_class\"", ":", "\"other\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car1_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "751", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car1_1.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car1_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car1\"", ",", "\"startFrame\"", ":", "751", ",", "\"endFrame\"", ":", "1627", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car1_2.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car1_3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car1\"", ",", "\"startFrame\"", ":", "1627", ",", "\"endFrame\"", ":", "2629", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car1_3.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car10\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car10\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1405", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car10.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car11\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car11\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "337", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car11.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car12\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car12\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "499", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car12.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car13\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car13\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "415", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car13.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car14\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car14\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1327", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car14.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car15\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car15\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "469", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car15.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car16_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car16\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "415", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car16_1.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car16_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car16\"", ",", "\"startFrame\"", ":", "415", ",", "\"endFrame\"", ":", "1993", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car16_2.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car17\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car17\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1057", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car17.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car18\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car18\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1207", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car18.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car1_s\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car1_s\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1475", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car1_s.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1321", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car2.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car2_s\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car2_s\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "320", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car2_s.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1717", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car3.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car3_s\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car3_s\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1300", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car3_s.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car4\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car4\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1345", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car4.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car4_s\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car4_s\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "830", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car4_s.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car5\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car5\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "745", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car5.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car6_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car6\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "487", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car6_1.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car6_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car6\"", ",", "\"startFrame\"", ":", "487", ",", "\"endFrame\"", ":", "1807", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car6_2.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car6_3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car6\"", ",", "\"startFrame\"", ":", "1807", ",", "\"endFrame\"", ":", "2953", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car6_3.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car6_4\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car6\"", ",", "\"startFrame\"", ":", "2953", ",", "\"endFrame\"", ":", "3925", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car6_4.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car6_5\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car6\"", ",", "\"startFrame\"", ":", "3925", ",", "\"endFrame\"", ":", "4861", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car6_5.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car7\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car7\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1033", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car7.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car8_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car8\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1357", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car8_1.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car8_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car8\"", ",", "\"startFrame\"", ":", "1357", ",", "\"endFrame\"", ":", "2575", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car8_2.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_car9\"", ",", "\"path\"", ":", "\"data_seq/UAV123/car9\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1879", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/car9.txt\"", ",", "\"object_class\"", ":", "\"car\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_group1_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/group1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1333", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/group1_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_group1_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/group1\"", ",", "\"startFrame\"", ":", "1333", ",", "\"endFrame\"", ":", "2515", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/group1_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_group1_3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/group1\"", ",", "\"startFrame\"", ":", "2515", ",", "\"endFrame\"", ":", "3925", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/group1_3.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_group1_4\"", ",", "\"path\"", ":", "\"data_seq/UAV123/group1\"", ",", "\"startFrame\"", ":", "3925", ",", "\"endFrame\"", ":", "4873", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/group1_4.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_group2_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/group2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "907", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/group2_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_group2_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/group2\"", ",", "\"startFrame\"", ":", "907", ",", "\"endFrame\"", ":", "1771", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/group2_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_group2_3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/group2\"", ",", "\"startFrame\"", ":", "1771", ",", "\"endFrame\"", ":", "2683", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/group2_3.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_group3_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/group3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1567", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/group3_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_group3_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/group3\"", ",", "\"startFrame\"", ":", "1567", ",", "\"endFrame\"", ":", "2827", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/group3_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_group3_3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/group3\"", ",", "\"startFrame\"", ":", "2827", ",", "\"endFrame\"", ":", "4369", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/group3_3.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_group3_4\"", ",", "\"path\"", ":", "\"data_seq/UAV123/group3\"", ",", "\"startFrame\"", ":", "4369", ",", "\"endFrame\"", ":", "5527", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/group3_4.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "799", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person10\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person10\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1021", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person10.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person11\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person11\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "721", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person11.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person12_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person12\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "601", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person12_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person12_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person12\"", ",", "\"startFrame\"", ":", "601", ",", "\"endFrame\"", ":", "1621", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person12_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person13\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person13\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "883", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person13.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person14_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person14\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "847", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person14_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person14_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person14\"", ",", "\"startFrame\"", ":", "847", ",", "\"endFrame\"", ":", "1813", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person14_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person14_3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person14\"", ",", "\"startFrame\"", ":", "1813", ",", "\"endFrame\"", ":", "2923", ",", "\n", "\"nz\"", ":", "6", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person14_3.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person15\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person15\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1339", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person15.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person16\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person16\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1147", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person16.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person17_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person17\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1501", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person17_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person17_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person17\"", ",", "\"startFrame\"", ":", "1501", ",", "\"endFrame\"", ":", "2347", ",", "\n", "\"nz\"", ":", "6", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person17_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person18\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person18\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1393", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person18.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person19_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person19\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1243", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person19_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person19_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person19\"", ",", "\"startFrame\"", ":", "1243", ",", "\"endFrame\"", ":", "2791", ",", "\n", "\"nz\"", ":", "6", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person19_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person19_3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person19\"", ",", "\"startFrame\"", ":", "2791", ",", "\"endFrame\"", ":", "4357", ",", "\n", "\"nz\"", ":", "6", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person19_3.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person1_s\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person1_s\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1600", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person1_s.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person2_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1189", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person2_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person2_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person2\"", ",", "\"startFrame\"", ":", "1189", ",", "\"endFrame\"", ":", "2623", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person2_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person20\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person20\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1783", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person20.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person21\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person21\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "487", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person21.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person22\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person22\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "199", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person22.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person23\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person23\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "397", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person23.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person2_s\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person2_s\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "250", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person2_s.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "643", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person3.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person3_s\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person3_s\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "505", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person3_s.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person4_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person4\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1501", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person4_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person4_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person4\"", ",", "\"startFrame\"", ":", "1501", ",", "\"endFrame\"", ":", "2743", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person4_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person5_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person5\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "877", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person5_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person5_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person5\"", ",", "\"startFrame\"", ":", "877", ",", "\"endFrame\"", ":", "2101", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person5_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person6\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person6\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "901", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person6.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person7_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person7\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1249", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person7_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person7_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person7\"", ",", "\"startFrame\"", ":", "1249", ",", "\"endFrame\"", ":", "2065", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person7_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person8_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person8\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1075", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person8_1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person8_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person8\"", ",", "\"startFrame\"", ":", "1075", ",", "\"endFrame\"", ":", "1525", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person8_2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_person9\"", ",", "\"path\"", ":", "\"data_seq/UAV123/person9\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "661", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/person9.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_truck1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/truck1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "463", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/truck1.txt\"", ",", "\"object_class\"", ":", "\"truck\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_truck2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/truck2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "385", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/truck2.txt\"", ",", "\"object_class\"", ":", "\"truck\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_truck3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/truck3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "535", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/truck3.txt\"", ",", "\"object_class\"", ":", "\"truck\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_truck4_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/truck4\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "577", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/truck4_1.txt\"", ",", "\"object_class\"", ":", "\"truck\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_truck4_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/truck4\"", ",", "\"startFrame\"", ":", "577", ",", "\"endFrame\"", ":", "1261", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/truck4_2.txt\"", ",", "\"object_class\"", ":", "\"truck\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_uav1_1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/uav1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1555", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/uav1_1.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_uav1_2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/uav1\"", ",", "\"startFrame\"", ":", "1555", ",", "\"endFrame\"", ":", "2377", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/uav1_2.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_uav1_3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/uav1\"", ",", "\"startFrame\"", ":", "2473", ",", "\"endFrame\"", ":", "3469", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/uav1_3.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_uav2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/uav2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "133", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/uav2.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_uav3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/uav3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "265", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/uav3.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_uav4\"", ",", "\"path\"", ":", "\"data_seq/UAV123/uav4\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "157", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/uav4.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_uav5\"", ",", "\"path\"", ":", "\"data_seq/UAV123/uav5\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "139", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/uav5.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_uav6\"", ",", "\"path\"", ":", "\"data_seq/UAV123/uav6\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "109", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/uav6.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_uav7\"", ",", "\"path\"", ":", "\"data_seq/UAV123/uav7\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "373", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/uav7.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_uav8\"", ",", "\"path\"", ":", "\"data_seq/UAV123/uav8\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "301", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/uav8.txt\"", ",", "\"object_class\"", ":", "\"aircraft\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_wakeboard1\"", ",", "\"path\"", ":", "\"data_seq/UAV123/wakeboard1\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "421", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/wakeboard1.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_wakeboard10\"", ",", "\"path\"", ":", "\"data_seq/UAV123/wakeboard10\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "469", ",", "\n", "\"nz\"", ":", "6", ",", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/wakeboard10.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_wakeboard2\"", ",", "\"path\"", ":", "\"data_seq/UAV123/wakeboard2\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "733", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/wakeboard2.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_wakeboard3\"", ",", "\"path\"", ":", "\"data_seq/UAV123/wakeboard3\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "823", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/wakeboard3.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_wakeboard4\"", ",", "\"path\"", ":", "\"data_seq/UAV123/wakeboard4\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "697", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/wakeboard4.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_wakeboard5\"", ",", "\"path\"", ":", "\"data_seq/UAV123/wakeboard5\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1675", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/wakeboard5.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_wakeboard6\"", ",", "\"path\"", ":", "\"data_seq/UAV123/wakeboard6\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1165", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/wakeboard6.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_wakeboard7\"", ",", "\"path\"", ":", "\"data_seq/UAV123/wakeboard7\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "199", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/wakeboard7.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_wakeboard8\"", ",", "\"path\"", ":", "\"data_seq/UAV123/wakeboard8\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "1543", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/wakeboard8.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", ",", "\n", "{", "\"name\"", ":", "\"uav_wakeboard9\"", ",", "\"path\"", ":", "\"data_seq/UAV123/wakeboard9\"", ",", "\"startFrame\"", ":", "1", ",", "\"endFrame\"", ":", "355", ",", "\"nz\"", ":", "6", ",", "\n", "\"ext\"", ":", "\"jpg\"", ",", "\"anno_path\"", ":", "\"anno/UAV123/wakeboard9.txt\"", ",", "\"object_class\"", ":", "\"person\"", "}", "\n", "]", "\n", "\n", "return", "sequence_info_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.got10kdataset.GOT10KDataset.__init__": [[18, 28], ["pytracking.evaluation.data.BaseDataset.__init__", "got10kdataset.GOT10KDataset._get_sequence_list", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._get_sequence_list"], ["def", "__init__", "(", "self", ",", "split", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# Split can be test, val, or ltrval (a validation split consisting of videos from the official train set)", "\n", "if", "split", "==", "'test'", "or", "split", "==", "'val'", ":", "\n", "            ", "self", ".", "base_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "env_settings", ".", "got10k_path", ",", "split", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "base_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "env_settings", ".", "got10k_path", ",", "'train'", ")", "\n", "\n", "", "self", ".", "sequence_list", "=", "self", ".", "_get_sequence_list", "(", "split", ")", "\n", "self", ".", "split", "=", "split", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.got10kdataset.GOT10KDataset.get_sequence_list": [[29, 31], ["pytracking.evaluation.data.SequenceList", "got10kdataset.GOT10KDataset._construct_sequence"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence"], ["", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "return", "SequenceList", "(", "[", "self", ".", "_construct_sequence", "(", "s", ")", "for", "s", "in", "self", ".", "sequence_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.got10kdataset.GOT10KDataset._construct_sequence": [[32, 43], ["pytracking.utils.load_text.load_text", "frame_list.sort", "pytracking.evaluation.data.Sequence", "str", "os.path.join", "pytracking.utils.load_text.load_text.reshape", "os.listdir", "frame.endswith", "int"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text"], ["", "def", "_construct_sequence", "(", "self", ",", "sequence_name", ")", ":", "\n", "        ", "anno_path", "=", "'{}/{}/groundtruth.txt'", ".", "format", "(", "self", ".", "base_path", ",", "sequence_name", ")", "\n", "\n", "ground_truth_rect", "=", "load_text", "(", "str", "(", "anno_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "frames_path", "=", "'{}/{}'", ".", "format", "(", "self", ".", "base_path", ",", "sequence_name", ")", "\n", "frame_list", "=", "[", "frame", "for", "frame", "in", "os", ".", "listdir", "(", "frames_path", ")", "if", "frame", ".", "endswith", "(", "\".jpg\"", ")", "]", "\n", "frame_list", ".", "sort", "(", "key", "=", "lambda", "f", ":", "int", "(", "f", "[", ":", "-", "4", "]", ")", ")", "\n", "frames_list", "=", "[", "os", ".", "path", ".", "join", "(", "frames_path", ",", "frame", ")", "for", "frame", "in", "frame_list", "]", "\n", "\n", "return", "Sequence", "(", "sequence_name", ",", "frames_list", ",", "'got10k'", ",", "ground_truth_rect", ".", "reshape", "(", "-", "1", ",", "4", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.got10kdataset.GOT10KDataset.__len__": [[44, 46], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.got10kdataset.GOT10KDataset._get_sequence_list": [[47, 57], ["open", "f.read().splitlines", "open", "f.read().splitlines", "f.read", "f.read", "int"], "methods", ["None"], ["", "def", "_get_sequence_list", "(", "self", ",", "split", ")", ":", "\n", "        ", "with", "open", "(", "'{}/list.txt'", ".", "format", "(", "self", ".", "base_path", ")", ")", "as", "f", ":", "\n", "            ", "sequence_list", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "if", "split", "==", "'ltrval'", ":", "\n", "            ", "with", "open", "(", "'{}/got10k_val_split.txt'", ".", "format", "(", "self", ".", "env_settings", ".", "dataspec_path", ")", ")", "as", "f", ":", "\n", "                ", "seq_ids", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "\n", "", "sequence_list", "=", "[", "sequence_list", "[", "int", "(", "x", ")", "]", "for", "x", "in", "seq_ids", "]", "\n", "", "return", "sequence_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotextensionsubsetdataset.LaSOTExtensionSubsetDataset.__init__": [[19, 24], ["pytracking.evaluation.data.BaseDataset.__init__", "lasotextensionsubsetdataset.LaSOTExtensionSubsetDataset._get_sequence_list", "lasotextensionsubsetdataset.LaSOTExtensionSubsetDataset.clean_seq_list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._get_sequence_list", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotdataset.LaSOTDataset.clean_seq_list"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_path", "=", "self", ".", "env_settings", ".", "lasot_extension_subset_path", "\n", "self", ".", "sequence_list", "=", "self", ".", "_get_sequence_list", "(", ")", "\n", "self", ".", "clean_list", "=", "self", ".", "clean_seq_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotextensionsubsetdataset.LaSOTExtensionSubsetDataset.clean_seq_list": [[25, 31], ["range", "len", "lasotextensionsubsetdataset.LaSOTExtensionSubsetDataset.sequence_list[].split", "clean_lst.append"], "methods", ["None"], ["", "def", "clean_seq_list", "(", "self", ")", ":", "\n", "        ", "clean_lst", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "sequence_list", ")", ")", ":", "\n", "            ", "cls", ",", "_", "=", "self", ".", "sequence_list", "[", "i", "]", ".", "split", "(", "'-'", ")", "\n", "clean_lst", ".", "append", "(", "cls", ")", "\n", "", "return", "clean_lst", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotextensionsubsetdataset.LaSOTExtensionSubsetDataset.get_sequence_list": [[32, 34], ["pytracking.evaluation.data.SequenceList", "lasotextensionsubsetdataset.LaSOTExtensionSubsetDataset._construct_sequence"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence"], ["", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "return", "SequenceList", "(", "[", "self", ".", "_construct_sequence", "(", "s", ")", "for", "s", "in", "self", ".", "sequence_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotextensionsubsetdataset.LaSOTExtensionSubsetDataset._construct_sequence": [[35, 58], ["pytracking.utils.load_text.load_text", "pytracking.utils.load_text.load_text", "pytracking.utils.load_text.load_text", "numpy.logical_and", "pytracking.evaluation.data.Sequence", "sequence_name.split", "str", "str", "str", "pytracking.utils.load_text.load_text.reshape", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text", "home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text", "home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text"], ["", "def", "_construct_sequence", "(", "self", ",", "sequence_name", ")", ":", "\n", "        ", "class_name", "=", "sequence_name", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "anno_path", "=", "'{}/{}/{}/groundtruth.txt'", ".", "format", "(", "self", ".", "base_path", ",", "class_name", ",", "sequence_name", ")", "\n", "\n", "ground_truth_rect", "=", "load_text", "(", "str", "(", "anno_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "occlusion_label_path", "=", "'{}/{}/{}/full_occlusion.txt'", ".", "format", "(", "self", ".", "base_path", ",", "class_name", ",", "sequence_name", ")", "\n", "\n", "# NOTE: pandas backed seems super super slow for loading occlusion/oov masks", "\n", "full_occlusion", "=", "load_text", "(", "str", "(", "occlusion_label_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ",", "backend", "=", "'numpy'", ")", "\n", "\n", "out_of_view_label_path", "=", "'{}/{}/{}/out_of_view.txt'", ".", "format", "(", "self", ".", "base_path", ",", "class_name", ",", "sequence_name", ")", "\n", "out_of_view", "=", "load_text", "(", "str", "(", "out_of_view_label_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ",", "backend", "=", "'numpy'", ")", "\n", "\n", "target_visible", "=", "np", ".", "logical_and", "(", "full_occlusion", "==", "0", ",", "out_of_view", "==", "0", ")", "\n", "\n", "frames_path", "=", "'{}/{}/{}/img'", ".", "format", "(", "self", ".", "base_path", ",", "class_name", ",", "sequence_name", ")", "\n", "\n", "frames_list", "=", "[", "'{}/{:08d}.jpg'", ".", "format", "(", "frames_path", ",", "frame_number", ")", "for", "frame_number", "in", "range", "(", "1", ",", "ground_truth_rect", ".", "shape", "[", "0", "]", "+", "1", ")", "]", "\n", "\n", "target_class", "=", "class_name", "\n", "return", "Sequence", "(", "sequence_name", ",", "frames_list", ",", "'lasot_extension_subset'", ",", "ground_truth_rect", ".", "reshape", "(", "-", "1", ",", "4", ")", ",", "\n", "object_class", "=", "target_class", ",", "target_visible", "=", "target_visible", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotextensionsubsetdataset.LaSOTExtensionSubsetDataset.__len__": [[59, 61], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotextensionsubsetdataset.LaSOTExtensionSubsetDataset._get_sequence_list": [[62, 214], ["None"], "methods", ["None"], ["", "def", "_get_sequence_list", "(", "self", ")", ":", "\n", "        ", "sequence_list", "=", "[", "'atv-1'", ",", "\n", "'atv-2'", ",", "\n", "'atv-3'", ",", "\n", "'atv-4'", ",", "\n", "'atv-5'", ",", "\n", "'atv-6'", ",", "\n", "'atv-7'", ",", "\n", "'atv-8'", ",", "\n", "'atv-9'", ",", "\n", "'atv-10'", ",", "\n", "'badminton-1'", ",", "\n", "'badminton-2'", ",", "\n", "'badminton-3'", ",", "\n", "'badminton-4'", ",", "\n", "'badminton-5'", ",", "\n", "'badminton-6'", ",", "\n", "'badminton-7'", ",", "\n", "'badminton-8'", ",", "\n", "'badminton-9'", ",", "\n", "'badminton-10'", ",", "\n", "'cosplay-1'", ",", "\n", "'cosplay-10'", ",", "\n", "'cosplay-2'", ",", "\n", "'cosplay-3'", ",", "\n", "'cosplay-4'", ",", "\n", "'cosplay-5'", ",", "\n", "'cosplay-6'", ",", "\n", "'cosplay-7'", ",", "\n", "'cosplay-8'", ",", "\n", "'cosplay-9'", ",", "\n", "'dancingshoe-1'", ",", "\n", "'dancingshoe-2'", ",", "\n", "'dancingshoe-3'", ",", "\n", "'dancingshoe-4'", ",", "\n", "'dancingshoe-5'", ",", "\n", "'dancingshoe-6'", ",", "\n", "'dancingshoe-7'", ",", "\n", "'dancingshoe-8'", ",", "\n", "'dancingshoe-9'", ",", "\n", "'dancingshoe-10'", ",", "\n", "'footbag-1'", ",", "\n", "'footbag-2'", ",", "\n", "'footbag-3'", ",", "\n", "'footbag-4'", ",", "\n", "'footbag-5'", ",", "\n", "'footbag-6'", ",", "\n", "'footbag-7'", ",", "\n", "'footbag-8'", ",", "\n", "'footbag-9'", ",", "\n", "'footbag-10'", ",", "\n", "'frisbee-1'", ",", "\n", "'frisbee-2'", ",", "\n", "'frisbee-3'", ",", "\n", "'frisbee-4'", ",", "\n", "'frisbee-5'", ",", "\n", "'frisbee-6'", ",", "\n", "'frisbee-7'", ",", "\n", "'frisbee-8'", ",", "\n", "'frisbee-9'", ",", "\n", "'frisbee-10'", ",", "\n", "'jianzi-1'", ",", "\n", "'jianzi-2'", ",", "\n", "'jianzi-3'", ",", "\n", "'jianzi-4'", ",", "\n", "'jianzi-5'", ",", "\n", "'jianzi-6'", ",", "\n", "'jianzi-7'", ",", "\n", "'jianzi-8'", ",", "\n", "'jianzi-9'", ",", "\n", "'jianzi-10'", ",", "\n", "'lantern-1'", ",", "\n", "'lantern-2'", ",", "\n", "'lantern-3'", ",", "\n", "'lantern-4'", ",", "\n", "'lantern-5'", ",", "\n", "'lantern-6'", ",", "\n", "'lantern-7'", ",", "\n", "'lantern-8'", ",", "\n", "'lantern-9'", ",", "\n", "'lantern-10'", ",", "\n", "'misc-1'", ",", "\n", "'misc-2'", ",", "\n", "'misc-3'", ",", "\n", "'misc-4'", ",", "\n", "'misc-5'", ",", "\n", "'misc-6'", ",", "\n", "'misc-7'", ",", "\n", "'misc-8'", ",", "\n", "'misc-9'", ",", "\n", "'misc-10'", ",", "\n", "'opossum-1'", ",", "\n", "'opossum-2'", ",", "\n", "'opossum-3'", ",", "\n", "'opossum-4'", ",", "\n", "'opossum-5'", ",", "\n", "'opossum-6'", ",", "\n", "'opossum-7'", ",", "\n", "'opossum-8'", ",", "\n", "'opossum-9'", ",", "\n", "'opossum-10'", ",", "\n", "'paddle-1'", ",", "\n", "'paddle-2'", ",", "\n", "'paddle-3'", ",", "\n", "'paddle-4'", ",", "\n", "'paddle-5'", ",", "\n", "'paddle-6'", ",", "\n", "'paddle-7'", ",", "\n", "'paddle-8'", ",", "\n", "'paddle-9'", ",", "\n", "'paddle-10'", ",", "\n", "'raccoon-1'", ",", "\n", "'raccoon-2'", ",", "\n", "'raccoon-3'", ",", "\n", "'raccoon-4'", ",", "\n", "'raccoon-5'", ",", "\n", "'raccoon-6'", ",", "\n", "'raccoon-7'", ",", "\n", "'raccoon-8'", ",", "\n", "'raccoon-9'", ",", "\n", "'raccoon-10'", ",", "\n", "'rhino-1'", ",", "\n", "'rhino-2'", ",", "\n", "'rhino-3'", ",", "\n", "'rhino-4'", ",", "\n", "'rhino-5'", ",", "\n", "'rhino-6'", ",", "\n", "'rhino-7'", ",", "\n", "'rhino-8'", ",", "\n", "'rhino-9'", ",", "\n", "'rhino-10'", ",", "\n", "'skatingshoe-1'", ",", "\n", "'skatingshoe-2'", ",", "\n", "'skatingshoe-3'", ",", "\n", "'skatingshoe-4'", ",", "\n", "'skatingshoe-5'", ",", "\n", "'skatingshoe-6'", ",", "\n", "'skatingshoe-7'", ",", "\n", "'skatingshoe-8'", ",", "\n", "'skatingshoe-9'", ",", "\n", "'skatingshoe-10'", ",", "\n", "'wingsuit-1'", ",", "\n", "'wingsuit-2'", ",", "\n", "'wingsuit-3'", ",", "\n", "'wingsuit-4'", ",", "\n", "'wingsuit-5'", ",", "\n", "'wingsuit-6'", ",", "\n", "'wingsuit-7'", ",", "\n", "'wingsuit-8'", ",", "\n", "'wingsuit-9'", ",", "\n", "'wingsuit-10'", "]", "\n", "return", "sequence_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotdataset.LaSOTDataset.__init__": [[18, 23], ["pytracking.evaluation.data.BaseDataset.__init__", "lasotdataset.LaSOTDataset._get_sequence_list", "lasotdataset.LaSOTDataset.clean_seq_list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._get_sequence_list", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotdataset.LaSOTDataset.clean_seq_list"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_path", "=", "self", ".", "env_settings", ".", "lasot_path", "\n", "self", ".", "sequence_list", "=", "self", ".", "_get_sequence_list", "(", ")", "\n", "self", ".", "clean_list", "=", "self", ".", "clean_seq_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotdataset.LaSOTDataset.clean_seq_list": [[24, 30], ["range", "len", "lasotdataset.LaSOTDataset.sequence_list[].split", "clean_lst.append"], "methods", ["None"], ["", "def", "clean_seq_list", "(", "self", ")", ":", "\n", "        ", "clean_lst", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "sequence_list", ")", ")", ":", "\n", "            ", "cls", ",", "_", "=", "self", ".", "sequence_list", "[", "i", "]", ".", "split", "(", "'-'", ")", "\n", "clean_lst", ".", "append", "(", "cls", ")", "\n", "", "return", "clean_lst", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotdataset.LaSOTDataset.get_sequence_list": [[31, 33], ["pytracking.evaluation.data.SequenceList", "lasotdataset.LaSOTDataset._construct_sequence"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence"], ["", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "return", "SequenceList", "(", "[", "self", ".", "_construct_sequence", "(", "s", ")", "for", "s", "in", "self", ".", "sequence_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotdataset.LaSOTDataset._construct_sequence": [[34, 57], ["pytracking.utils.load_text.load_text", "pytracking.utils.load_text.load_text", "pytracking.utils.load_text.load_text", "numpy.logical_and", "pytracking.evaluation.data.Sequence", "sequence_name.split", "str", "str", "str", "pytracking.utils.load_text.load_text.reshape", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text", "home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text", "home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text"], ["", "def", "_construct_sequence", "(", "self", ",", "sequence_name", ")", ":", "\n", "        ", "class_name", "=", "sequence_name", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "anno_path", "=", "'{}/{}/{}/groundtruth.txt'", ".", "format", "(", "self", ".", "base_path", ",", "class_name", ",", "sequence_name", ")", "\n", "\n", "ground_truth_rect", "=", "load_text", "(", "str", "(", "anno_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "occlusion_label_path", "=", "'{}/{}/{}/full_occlusion.txt'", ".", "format", "(", "self", ".", "base_path", ",", "class_name", ",", "sequence_name", ")", "\n", "\n", "# NOTE: pandas backed seems super super slow for loading occlusion/oov masks", "\n", "full_occlusion", "=", "load_text", "(", "str", "(", "occlusion_label_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ",", "backend", "=", "'numpy'", ")", "\n", "\n", "out_of_view_label_path", "=", "'{}/{}/{}/out_of_view.txt'", ".", "format", "(", "self", ".", "base_path", ",", "class_name", ",", "sequence_name", ")", "\n", "out_of_view", "=", "load_text", "(", "str", "(", "out_of_view_label_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ",", "backend", "=", "'numpy'", ")", "\n", "\n", "target_visible", "=", "np", ".", "logical_and", "(", "full_occlusion", "==", "0", ",", "out_of_view", "==", "0", ")", "\n", "\n", "frames_path", "=", "'{}/{}/{}/img'", ".", "format", "(", "self", ".", "base_path", ",", "class_name", ",", "sequence_name", ")", "\n", "\n", "frames_list", "=", "[", "'{}/{:08d}.jpg'", ".", "format", "(", "frames_path", ",", "frame_number", ")", "for", "frame_number", "in", "range", "(", "1", ",", "ground_truth_rect", ".", "shape", "[", "0", "]", "+", "1", ")", "]", "\n", "\n", "target_class", "=", "class_name", "\n", "return", "Sequence", "(", "sequence_name", ",", "frames_list", ",", "'lasot'", ",", "ground_truth_rect", ".", "reshape", "(", "-", "1", ",", "4", ")", ",", "\n", "object_class", "=", "target_class", ",", "target_visible", "=", "target_visible", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotdataset.LaSOTDataset.__len__": [[58, 60], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotdataset.LaSOTDataset._get_sequence_list": [[61, 343], ["None"], "methods", ["None"], ["", "def", "_get_sequence_list", "(", "self", ")", ":", "\n", "        ", "sequence_list", "=", "[", "'airplane-1'", ",", "\n", "'airplane-9'", ",", "\n", "'airplane-13'", ",", "\n", "'airplane-15'", ",", "\n", "'basketball-1'", ",", "\n", "'basketball-6'", ",", "\n", "'basketball-7'", ",", "\n", "'basketball-11'", ",", "\n", "'bear-2'", ",", "\n", "'bear-4'", ",", "\n", "'bear-6'", ",", "\n", "'bear-17'", ",", "\n", "'bicycle-2'", ",", "\n", "'bicycle-7'", ",", "\n", "'bicycle-9'", ",", "\n", "'bicycle-18'", ",", "\n", "'bird-2'", ",", "\n", "'bird-3'", ",", "\n", "'bird-15'", ",", "\n", "'bird-17'", ",", "\n", "'boat-3'", ",", "\n", "'boat-4'", ",", "\n", "'boat-12'", ",", "\n", "'boat-17'", ",", "\n", "'book-3'", ",", "\n", "'book-10'", ",", "\n", "'book-11'", ",", "\n", "'book-19'", ",", "\n", "'bottle-1'", ",", "\n", "'bottle-12'", ",", "\n", "'bottle-14'", ",", "\n", "'bottle-18'", ",", "\n", "'bus-2'", ",", "\n", "'bus-5'", ",", "\n", "'bus-17'", ",", "\n", "'bus-19'", ",", "\n", "'car-2'", ",", "\n", "'car-6'", ",", "\n", "'car-9'", ",", "\n", "'car-17'", ",", "\n", "'cat-1'", ",", "\n", "'cat-3'", ",", "\n", "'cat-18'", ",", "\n", "'cat-20'", ",", "\n", "'cattle-2'", ",", "\n", "'cattle-7'", ",", "\n", "'cattle-12'", ",", "\n", "'cattle-13'", ",", "\n", "'spider-14'", ",", "\n", "'spider-16'", ",", "\n", "'spider-18'", ",", "\n", "'spider-20'", ",", "\n", "'coin-3'", ",", "\n", "'coin-6'", ",", "\n", "'coin-7'", ",", "\n", "'coin-18'", ",", "\n", "'crab-3'", ",", "\n", "'crab-6'", ",", "\n", "'crab-12'", ",", "\n", "'crab-18'", ",", "\n", "'surfboard-12'", ",", "\n", "'surfboard-4'", ",", "\n", "'surfboard-5'", ",", "\n", "'surfboard-8'", ",", "\n", "'cup-1'", ",", "\n", "'cup-4'", ",", "\n", "'cup-7'", ",", "\n", "'cup-17'", ",", "\n", "'deer-4'", ",", "\n", "'deer-8'", ",", "\n", "'deer-10'", ",", "\n", "'deer-14'", ",", "\n", "'dog-1'", ",", "\n", "'dog-7'", ",", "\n", "'dog-15'", ",", "\n", "'dog-19'", ",", "\n", "'guitar-3'", ",", "\n", "'guitar-8'", ",", "\n", "'guitar-10'", ",", "\n", "'guitar-16'", ",", "\n", "'person-1'", ",", "\n", "'person-5'", ",", "\n", "'person-10'", ",", "\n", "'person-12'", ",", "\n", "'pig-2'", ",", "\n", "'pig-10'", ",", "\n", "'pig-13'", ",", "\n", "'pig-18'", ",", "\n", "'rubicCube-1'", ",", "\n", "'rubicCube-6'", ",", "\n", "'rubicCube-14'", ",", "\n", "'rubicCube-19'", ",", "\n", "'swing-10'", ",", "\n", "'swing-14'", ",", "\n", "'swing-17'", ",", "\n", "'swing-20'", ",", "\n", "'drone-13'", ",", "\n", "'drone-15'", ",", "\n", "'drone-2'", ",", "\n", "'drone-7'", ",", "\n", "'pool-12'", ",", "\n", "'pool-15'", ",", "\n", "'pool-3'", ",", "\n", "'pool-7'", ",", "\n", "'rabbit-10'", ",", "\n", "'rabbit-13'", ",", "\n", "'rabbit-17'", ",", "\n", "'rabbit-19'", ",", "\n", "'racing-10'", ",", "\n", "'racing-15'", ",", "\n", "'racing-16'", ",", "\n", "'racing-20'", ",", "\n", "'robot-1'", ",", "\n", "'robot-19'", ",", "\n", "'robot-5'", ",", "\n", "'robot-8'", ",", "\n", "'sepia-13'", ",", "\n", "'sepia-16'", ",", "\n", "'sepia-6'", ",", "\n", "'sepia-8'", ",", "\n", "'sheep-3'", ",", "\n", "'sheep-5'", ",", "\n", "'sheep-7'", ",", "\n", "'sheep-9'", ",", "\n", "'skateboard-16'", ",", "\n", "'skateboard-19'", ",", "\n", "'skateboard-3'", ",", "\n", "'skateboard-8'", ",", "\n", "'tank-14'", ",", "\n", "'tank-16'", ",", "\n", "'tank-6'", ",", "\n", "'tank-9'", ",", "\n", "'tiger-12'", ",", "\n", "'tiger-18'", ",", "\n", "'tiger-4'", ",", "\n", "'tiger-6'", ",", "\n", "'train-1'", ",", "\n", "'train-11'", ",", "\n", "'train-20'", ",", "\n", "'train-7'", ",", "\n", "'truck-16'", ",", "\n", "'truck-3'", ",", "\n", "'truck-6'", ",", "\n", "'truck-7'", ",", "\n", "'turtle-16'", ",", "\n", "'turtle-5'", ",", "\n", "'turtle-8'", ",", "\n", "'turtle-9'", ",", "\n", "'umbrella-17'", ",", "\n", "'umbrella-19'", ",", "\n", "'umbrella-2'", ",", "\n", "'umbrella-9'", ",", "\n", "'yoyo-15'", ",", "\n", "'yoyo-17'", ",", "\n", "'yoyo-19'", ",", "\n", "'yoyo-7'", ",", "\n", "'zebra-10'", ",", "\n", "'zebra-14'", ",", "\n", "'zebra-16'", ",", "\n", "'zebra-17'", ",", "\n", "'elephant-1'", ",", "\n", "'elephant-12'", ",", "\n", "'elephant-16'", ",", "\n", "'elephant-18'", ",", "\n", "'goldfish-3'", ",", "\n", "'goldfish-7'", ",", "\n", "'goldfish-8'", ",", "\n", "'goldfish-10'", ",", "\n", "'hat-1'", ",", "\n", "'hat-2'", ",", "\n", "'hat-5'", ",", "\n", "'hat-18'", ",", "\n", "'kite-4'", ",", "\n", "'kite-6'", ",", "\n", "'kite-10'", ",", "\n", "'kite-15'", ",", "\n", "'motorcycle-1'", ",", "\n", "'motorcycle-3'", ",", "\n", "'motorcycle-9'", ",", "\n", "'motorcycle-18'", ",", "\n", "'mouse-1'", ",", "\n", "'mouse-8'", ",", "\n", "'mouse-9'", ",", "\n", "'mouse-17'", ",", "\n", "'flag-3'", ",", "\n", "'flag-9'", ",", "\n", "'flag-5'", ",", "\n", "'flag-2'", ",", "\n", "'frog-3'", ",", "\n", "'frog-4'", ",", "\n", "'frog-20'", ",", "\n", "'frog-9'", ",", "\n", "'gametarget-1'", ",", "\n", "'gametarget-2'", ",", "\n", "'gametarget-7'", ",", "\n", "'gametarget-13'", ",", "\n", "'hand-2'", ",", "\n", "'hand-3'", ",", "\n", "'hand-9'", ",", "\n", "'hand-16'", ",", "\n", "'helmet-5'", ",", "\n", "'helmet-11'", ",", "\n", "'helmet-19'", ",", "\n", "'helmet-13'", ",", "\n", "'licenseplate-6'", ",", "\n", "'licenseplate-12'", ",", "\n", "'licenseplate-13'", ",", "\n", "'licenseplate-15'", ",", "\n", "'electricfan-1'", ",", "\n", "'electricfan-10'", ",", "\n", "'electricfan-18'", ",", "\n", "'electricfan-20'", ",", "\n", "'chameleon-3'", ",", "\n", "'chameleon-6'", ",", "\n", "'chameleon-11'", ",", "\n", "'chameleon-20'", ",", "\n", "'crocodile-3'", ",", "\n", "'crocodile-4'", ",", "\n", "'crocodile-10'", ",", "\n", "'crocodile-14'", ",", "\n", "'gecko-1'", ",", "\n", "'gecko-5'", ",", "\n", "'gecko-16'", ",", "\n", "'gecko-19'", ",", "\n", "'fox-2'", ",", "\n", "'fox-3'", ",", "\n", "'fox-5'", ",", "\n", "'fox-20'", ",", "\n", "'giraffe-2'", ",", "\n", "'giraffe-10'", ",", "\n", "'giraffe-13'", ",", "\n", "'giraffe-15'", ",", "\n", "'gorilla-4'", ",", "\n", "'gorilla-6'", ",", "\n", "'gorilla-9'", ",", "\n", "'gorilla-13'", ",", "\n", "'hippo-1'", ",", "\n", "'hippo-7'", ",", "\n", "'hippo-9'", ",", "\n", "'hippo-20'", ",", "\n", "'horse-1'", ",", "\n", "'horse-4'", ",", "\n", "'horse-12'", ",", "\n", "'horse-15'", ",", "\n", "'kangaroo-2'", ",", "\n", "'kangaroo-5'", ",", "\n", "'kangaroo-11'", ",", "\n", "'kangaroo-14'", ",", "\n", "'leopard-1'", ",", "\n", "'leopard-7'", ",", "\n", "'leopard-16'", ",", "\n", "'leopard-20'", ",", "\n", "'lion-1'", ",", "\n", "'lion-5'", ",", "\n", "'lion-12'", ",", "\n", "'lion-20'", ",", "\n", "'lizard-1'", ",", "\n", "'lizard-3'", ",", "\n", "'lizard-6'", ",", "\n", "'lizard-13'", ",", "\n", "'microphone-2'", ",", "\n", "'microphone-6'", ",", "\n", "'microphone-14'", ",", "\n", "'microphone-16'", ",", "\n", "'monkey-3'", ",", "\n", "'monkey-4'", ",", "\n", "'monkey-9'", ",", "\n", "'monkey-17'", ",", "\n", "'shark-2'", ",", "\n", "'shark-3'", ",", "\n", "'shark-5'", ",", "\n", "'shark-6'", ",", "\n", "'squirrel-8'", ",", "\n", "'squirrel-11'", ",", "\n", "'squirrel-13'", ",", "\n", "'squirrel-19'", ",", "\n", "'volleyball-1'", ",", "\n", "'volleyball-13'", ",", "\n", "'volleyball-18'", ",", "\n", "'volleyball-19'", "]", "\n", "return", "sequence_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotdataset.LaSOTTrainSequencesDataset.__init__": [[346, 348], ["lasotdataset.LaSOTDataset.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.lasotdataset.LaSOTTrainSequencesDataset._get_sequence_list": [[349, 1474], ["None"], "methods", ["None"], ["", "def", "_get_sequence_list", "(", "self", ")", ":", "\n", "        ", "sequence_list", "=", "[", "\n", "'airplane-10'", ",", "\n", "'airplane-11'", ",", "\n", "'airplane-12'", ",", "\n", "'airplane-14'", ",", "\n", "'airplane-16'", ",", "\n", "'airplane-17'", ",", "\n", "'airplane-18'", ",", "\n", "'airplane-19'", ",", "\n", "'airplane-2'", ",", "\n", "'airplane-20'", ",", "\n", "'airplane-3'", ",", "\n", "'airplane-4'", ",", "\n", "'airplane-5'", ",", "\n", "'airplane-6'", ",", "\n", "'airplane-7'", ",", "\n", "'airplane-8'", ",", "\n", "'basketball-10'", ",", "\n", "'basketball-12'", ",", "\n", "'basketball-13'", ",", "\n", "'basketball-14'", ",", "\n", "'basketball-15'", ",", "\n", "'basketball-16'", ",", "\n", "'basketball-17'", ",", "\n", "'basketball-18'", ",", "\n", "'basketball-19'", ",", "\n", "'basketball-2'", ",", "\n", "'basketball-20'", ",", "\n", "'basketball-3'", ",", "\n", "'basketball-4'", ",", "\n", "'basketball-5'", ",", "\n", "'basketball-8'", ",", "\n", "'basketball-9'", ",", "\n", "'bear-1'", ",", "\n", "'bear-10'", ",", "\n", "'bear-11'", ",", "\n", "'bear-12'", ",", "\n", "'bear-13'", ",", "\n", "'bear-14'", ",", "\n", "'bear-15'", ",", "\n", "'bear-16'", ",", "\n", "'bear-18'", ",", "\n", "'bear-19'", ",", "\n", "'bear-20'", ",", "\n", "'bear-3'", ",", "\n", "'bear-5'", ",", "\n", "'bear-7'", ",", "\n", "'bear-8'", ",", "\n", "'bear-9'", ",", "\n", "'bicycle-1'", ",", "\n", "'bicycle-10'", ",", "\n", "'bicycle-11'", ",", "\n", "'bicycle-12'", ",", "\n", "'bicycle-13'", ",", "\n", "'bicycle-14'", ",", "\n", "'bicycle-15'", ",", "\n", "'bicycle-16'", ",", "\n", "'bicycle-17'", ",", "\n", "'bicycle-19'", ",", "\n", "'bicycle-20'", ",", "\n", "'bicycle-3'", ",", "\n", "'bicycle-4'", ",", "\n", "'bicycle-5'", ",", "\n", "'bicycle-6'", ",", "\n", "'bicycle-8'", ",", "\n", "'bird-1'", ",", "\n", "'bird-10'", ",", "\n", "'bird-11'", ",", "\n", "'bird-12'", ",", "\n", "'bird-13'", ",", "\n", "'bird-14'", ",", "\n", "'bird-16'", ",", "\n", "'bird-18'", ",", "\n", "'bird-19'", ",", "\n", "'bird-20'", ",", "\n", "'bird-4'", ",", "\n", "'bird-5'", ",", "\n", "'bird-6'", ",", "\n", "'bird-7'", ",", "\n", "'bird-8'", ",", "\n", "'bird-9'", ",", "\n", "'boat-1'", ",", "\n", "'boat-10'", ",", "\n", "'boat-11'", ",", "\n", "'boat-13'", ",", "\n", "'boat-14'", ",", "\n", "'boat-15'", ",", "\n", "'boat-16'", ",", "\n", "'boat-18'", ",", "\n", "'boat-19'", ",", "\n", "'boat-2'", ",", "\n", "'boat-20'", ",", "\n", "'boat-5'", ",", "\n", "'boat-6'", ",", "\n", "'boat-7'", ",", "\n", "'boat-8'", ",", "\n", "'boat-9'", ",", "\n", "'book-1'", ",", "\n", "'book-12'", ",", "\n", "'book-13'", ",", "\n", "'book-14'", ",", "\n", "'book-15'", ",", "\n", "'book-16'", ",", "\n", "'book-17'", ",", "\n", "'book-18'", ",", "\n", "'book-2'", ",", "\n", "'book-20'", ",", "\n", "'book-4'", ",", "\n", "'book-5'", ",", "\n", "'book-6'", ",", "\n", "'book-7'", ",", "\n", "'book-8'", ",", "\n", "'book-9'", ",", "\n", "'bottle-10'", ",", "\n", "'bottle-11'", ",", "\n", "'bottle-13'", ",", "\n", "'bottle-15'", ",", "\n", "'bottle-16'", ",", "\n", "'bottle-17'", ",", "\n", "'bottle-19'", ",", "\n", "'bottle-2'", ",", "\n", "'bottle-20'", ",", "\n", "'bottle-3'", ",", "\n", "'bottle-4'", ",", "\n", "'bottle-5'", ",", "\n", "'bottle-6'", ",", "\n", "'bottle-7'", ",", "\n", "'bottle-8'", ",", "\n", "'bottle-9'", ",", "\n", "'bus-1'", ",", "\n", "'bus-10'", ",", "\n", "'bus-11'", ",", "\n", "'bus-12'", ",", "\n", "'bus-13'", ",", "\n", "'bus-14'", ",", "\n", "'bus-15'", ",", "\n", "'bus-16'", ",", "\n", "'bus-18'", ",", "\n", "'bus-20'", ",", "\n", "'bus-3'", ",", "\n", "'bus-4'", ",", "\n", "'bus-6'", ",", "\n", "'bus-7'", ",", "\n", "'bus-8'", ",", "\n", "'bus-9'", ",", "\n", "'car-1'", ",", "\n", "'car-10'", ",", "\n", "'car-11'", ",", "\n", "'car-12'", ",", "\n", "'car-13'", ",", "\n", "'car-14'", ",", "\n", "'car-15'", ",", "\n", "'car-16'", ",", "\n", "'car-18'", ",", "\n", "'car-19'", ",", "\n", "'car-20'", ",", "\n", "'car-3'", ",", "\n", "'car-4'", ",", "\n", "'car-5'", ",", "\n", "'car-7'", ",", "\n", "'car-8'", ",", "\n", "'cat-10'", ",", "\n", "'cat-11'", ",", "\n", "'cat-12'", ",", "\n", "'cat-13'", ",", "\n", "'cat-14'", ",", "\n", "'cat-15'", ",", "\n", "'cat-16'", ",", "\n", "'cat-17'", ",", "\n", "'cat-19'", ",", "\n", "'cat-2'", ",", "\n", "'cat-4'", ",", "\n", "'cat-5'", ",", "\n", "'cat-6'", ",", "\n", "'cat-7'", ",", "\n", "'cat-8'", ",", "\n", "'cat-9'", ",", "\n", "'cattle-1'", ",", "\n", "'cattle-10'", ",", "\n", "'cattle-11'", ",", "\n", "'cattle-14'", ",", "\n", "'cattle-15'", ",", "\n", "'cattle-16'", ",", "\n", "'cattle-17'", ",", "\n", "'cattle-18'", ",", "\n", "'cattle-19'", ",", "\n", "'cattle-20'", ",", "\n", "'cattle-3'", ",", "\n", "'cattle-4'", ",", "\n", "'cattle-5'", ",", "\n", "'cattle-6'", ",", "\n", "'cattle-8'", ",", "\n", "'cattle-9'", ",", "\n", "'chameleon-1'", ",", "\n", "'chameleon-10'", ",", "\n", "'chameleon-12'", ",", "\n", "'chameleon-13'", ",", "\n", "'chameleon-14'", ",", "\n", "'chameleon-15'", ",", "\n", "'chameleon-16'", ",", "\n", "'chameleon-17'", ",", "\n", "'chameleon-18'", ",", "\n", "'chameleon-19'", ",", "\n", "'chameleon-2'", ",", "\n", "'chameleon-4'", ",", "\n", "'chameleon-5'", ",", "\n", "'chameleon-7'", ",", "\n", "'chameleon-8'", ",", "\n", "'chameleon-9'", ",", "\n", "'coin-1'", ",", "\n", "'coin-10'", ",", "\n", "'coin-11'", ",", "\n", "'coin-12'", ",", "\n", "'coin-13'", ",", "\n", "'coin-14'", ",", "\n", "'coin-15'", ",", "\n", "'coin-16'", ",", "\n", "'coin-17'", ",", "\n", "'coin-19'", ",", "\n", "'coin-2'", ",", "\n", "'coin-20'", ",", "\n", "'coin-4'", ",", "\n", "'coin-5'", ",", "\n", "'coin-8'", ",", "\n", "'coin-9'", ",", "\n", "'crab-1'", ",", "\n", "'crab-10'", ",", "\n", "'crab-11'", ",", "\n", "'crab-13'", ",", "\n", "'crab-14'", ",", "\n", "'crab-15'", ",", "\n", "'crab-16'", ",", "\n", "'crab-17'", ",", "\n", "'crab-19'", ",", "\n", "'crab-2'", ",", "\n", "'crab-20'", ",", "\n", "'crab-4'", ",", "\n", "'crab-5'", ",", "\n", "'crab-7'", ",", "\n", "'crab-8'", ",", "\n", "'crab-9'", ",", "\n", "'crocodile-1'", ",", "\n", "'crocodile-11'", ",", "\n", "'crocodile-12'", ",", "\n", "'crocodile-13'", ",", "\n", "'crocodile-15'", ",", "\n", "'crocodile-16'", ",", "\n", "'crocodile-17'", ",", "\n", "'crocodile-18'", ",", "\n", "'crocodile-19'", ",", "\n", "'crocodile-2'", ",", "\n", "'crocodile-20'", ",", "\n", "'crocodile-5'", ",", "\n", "'crocodile-6'", ",", "\n", "'crocodile-7'", ",", "\n", "'crocodile-8'", ",", "\n", "'crocodile-9'", ",", "\n", "'cup-10'", ",", "\n", "'cup-11'", ",", "\n", "'cup-12'", ",", "\n", "'cup-13'", ",", "\n", "'cup-14'", ",", "\n", "'cup-15'", ",", "\n", "'cup-16'", ",", "\n", "'cup-18'", ",", "\n", "'cup-19'", ",", "\n", "'cup-2'", ",", "\n", "'cup-20'", ",", "\n", "'cup-3'", ",", "\n", "'cup-5'", ",", "\n", "'cup-6'", ",", "\n", "'cup-8'", ",", "\n", "'cup-9'", ",", "\n", "'deer-1'", ",", "\n", "'deer-11'", ",", "\n", "'deer-12'", ",", "\n", "'deer-13'", ",", "\n", "'deer-15'", ",", "\n", "'deer-16'", ",", "\n", "'deer-17'", ",", "\n", "'deer-18'", ",", "\n", "'deer-19'", ",", "\n", "'deer-2'", ",", "\n", "'deer-20'", ",", "\n", "'deer-3'", ",", "\n", "'deer-5'", ",", "\n", "'deer-6'", ",", "\n", "'deer-7'", ",", "\n", "'deer-9'", ",", "\n", "'dog-10'", ",", "\n", "'dog-11'", ",", "\n", "'dog-12'", ",", "\n", "'dog-13'", ",", "\n", "'dog-14'", ",", "\n", "'dog-16'", ",", "\n", "'dog-17'", ",", "\n", "'dog-18'", ",", "\n", "'dog-2'", ",", "\n", "'dog-20'", ",", "\n", "'dog-3'", ",", "\n", "'dog-4'", ",", "\n", "'dog-5'", ",", "\n", "'dog-6'", ",", "\n", "'dog-8'", ",", "\n", "'dog-9'", ",", "\n", "'drone-1'", ",", "\n", "'drone-10'", ",", "\n", "'drone-11'", ",", "\n", "'drone-12'", ",", "\n", "'drone-14'", ",", "\n", "'drone-16'", ",", "\n", "'drone-17'", ",", "\n", "'drone-18'", ",", "\n", "'drone-19'", ",", "\n", "'drone-20'", ",", "\n", "'drone-3'", ",", "\n", "'drone-4'", ",", "\n", "'drone-5'", ",", "\n", "'drone-6'", ",", "\n", "'drone-8'", ",", "\n", "'drone-9'", ",", "\n", "'electricfan-11'", ",", "\n", "'electricfan-12'", ",", "\n", "'electricfan-13'", ",", "\n", "'electricfan-14'", ",", "\n", "'electricfan-15'", ",", "\n", "'electricfan-16'", ",", "\n", "'electricfan-17'", ",", "\n", "'electricfan-19'", ",", "\n", "'electricfan-2'", ",", "\n", "'electricfan-3'", ",", "\n", "'electricfan-4'", ",", "\n", "'electricfan-5'", ",", "\n", "'electricfan-6'", ",", "\n", "'electricfan-7'", ",", "\n", "'electricfan-8'", ",", "\n", "'electricfan-9'", ",", "\n", "'elephant-10'", ",", "\n", "'elephant-11'", ",", "\n", "'elephant-13'", ",", "\n", "'elephant-14'", ",", "\n", "'elephant-15'", ",", "\n", "'elephant-17'", ",", "\n", "'elephant-19'", ",", "\n", "'elephant-2'", ",", "\n", "'elephant-20'", ",", "\n", "'elephant-3'", ",", "\n", "'elephant-4'", ",", "\n", "'elephant-5'", ",", "\n", "'elephant-6'", ",", "\n", "'elephant-7'", ",", "\n", "'elephant-8'", ",", "\n", "'elephant-9'", ",", "\n", "'flag-1'", ",", "\n", "'flag-10'", ",", "\n", "'flag-11'", ",", "\n", "'flag-12'", ",", "\n", "'flag-13'", ",", "\n", "'flag-14'", ",", "\n", "'flag-15'", ",", "\n", "'flag-16'", ",", "\n", "'flag-17'", ",", "\n", "'flag-18'", ",", "\n", "'flag-19'", ",", "\n", "'flag-20'", ",", "\n", "'flag-4'", ",", "\n", "'flag-6'", ",", "\n", "'flag-7'", ",", "\n", "'flag-8'", ",", "\n", "'fox-1'", ",", "\n", "'fox-10'", ",", "\n", "'fox-11'", ",", "\n", "'fox-12'", ",", "\n", "'fox-13'", ",", "\n", "'fox-14'", ",", "\n", "'fox-15'", ",", "\n", "'fox-16'", ",", "\n", "'fox-17'", ",", "\n", "'fox-18'", ",", "\n", "'fox-19'", ",", "\n", "'fox-4'", ",", "\n", "'fox-6'", ",", "\n", "'fox-7'", ",", "\n", "'fox-8'", ",", "\n", "'fox-9'", ",", "\n", "'frog-1'", ",", "\n", "'frog-10'", ",", "\n", "'frog-11'", ",", "\n", "'frog-12'", ",", "\n", "'frog-13'", ",", "\n", "'frog-14'", ",", "\n", "'frog-15'", ",", "\n", "'frog-16'", ",", "\n", "'frog-17'", ",", "\n", "'frog-18'", ",", "\n", "'frog-19'", ",", "\n", "'frog-2'", ",", "\n", "'frog-5'", ",", "\n", "'frog-6'", ",", "\n", "'frog-7'", ",", "\n", "'frog-8'", ",", "\n", "'gametarget-10'", ",", "\n", "'gametarget-11'", ",", "\n", "'gametarget-12'", ",", "\n", "'gametarget-14'", ",", "\n", "'gametarget-15'", ",", "\n", "'gametarget-16'", ",", "\n", "'gametarget-17'", ",", "\n", "'gametarget-18'", ",", "\n", "'gametarget-19'", ",", "\n", "'gametarget-20'", ",", "\n", "'gametarget-3'", ",", "\n", "'gametarget-4'", ",", "\n", "'gametarget-5'", ",", "\n", "'gametarget-6'", ",", "\n", "'gametarget-8'", ",", "\n", "'gametarget-9'", ",", "\n", "'gecko-10'", ",", "\n", "'gecko-11'", ",", "\n", "'gecko-12'", ",", "\n", "'gecko-13'", ",", "\n", "'gecko-14'", ",", "\n", "'gecko-15'", ",", "\n", "'gecko-17'", ",", "\n", "'gecko-18'", ",", "\n", "'gecko-2'", ",", "\n", "'gecko-20'", ",", "\n", "'gecko-3'", ",", "\n", "'gecko-4'", ",", "\n", "'gecko-6'", ",", "\n", "'gecko-7'", ",", "\n", "'gecko-8'", ",", "\n", "'gecko-9'", ",", "\n", "'giraffe-1'", ",", "\n", "'giraffe-11'", ",", "\n", "'giraffe-12'", ",", "\n", "'giraffe-14'", ",", "\n", "'giraffe-16'", ",", "\n", "'giraffe-17'", ",", "\n", "'giraffe-18'", ",", "\n", "'giraffe-19'", ",", "\n", "'giraffe-20'", ",", "\n", "'giraffe-3'", ",", "\n", "'giraffe-4'", ",", "\n", "'giraffe-5'", ",", "\n", "'giraffe-6'", ",", "\n", "'giraffe-7'", ",", "\n", "'giraffe-8'", ",", "\n", "'giraffe-9'", ",", "\n", "'goldfish-1'", ",", "\n", "'goldfish-11'", ",", "\n", "'goldfish-12'", ",", "\n", "'goldfish-13'", ",", "\n", "'goldfish-14'", ",", "\n", "'goldfish-15'", ",", "\n", "'goldfish-16'", ",", "\n", "'goldfish-17'", ",", "\n", "'goldfish-18'", ",", "\n", "'goldfish-19'", ",", "\n", "'goldfish-2'", ",", "\n", "'goldfish-20'", ",", "\n", "'goldfish-4'", ",", "\n", "'goldfish-5'", ",", "\n", "'goldfish-6'", ",", "\n", "'goldfish-9'", ",", "\n", "'gorilla-1'", ",", "\n", "'gorilla-10'", ",", "\n", "'gorilla-11'", ",", "\n", "'gorilla-12'", ",", "\n", "'gorilla-14'", ",", "\n", "'gorilla-15'", ",", "\n", "'gorilla-16'", ",", "\n", "'gorilla-17'", ",", "\n", "'gorilla-18'", ",", "\n", "'gorilla-19'", ",", "\n", "'gorilla-2'", ",", "\n", "'gorilla-20'", ",", "\n", "'gorilla-3'", ",", "\n", "'gorilla-5'", ",", "\n", "'gorilla-7'", ",", "\n", "'gorilla-8'", ",", "\n", "'guitar-1'", ",", "\n", "'guitar-11'", ",", "\n", "'guitar-12'", ",", "\n", "'guitar-13'", ",", "\n", "'guitar-14'", ",", "\n", "'guitar-15'", ",", "\n", "'guitar-17'", ",", "\n", "'guitar-18'", ",", "\n", "'guitar-19'", ",", "\n", "'guitar-2'", ",", "\n", "'guitar-20'", ",", "\n", "'guitar-4'", ",", "\n", "'guitar-5'", ",", "\n", "'guitar-6'", ",", "\n", "'guitar-7'", ",", "\n", "'guitar-9'", ",", "\n", "'hand-1'", ",", "\n", "'hand-10'", ",", "\n", "'hand-11'", ",", "\n", "'hand-12'", ",", "\n", "'hand-13'", ",", "\n", "'hand-14'", ",", "\n", "'hand-15'", ",", "\n", "'hand-17'", ",", "\n", "'hand-18'", ",", "\n", "'hand-19'", ",", "\n", "'hand-20'", ",", "\n", "'hand-4'", ",", "\n", "'hand-5'", ",", "\n", "'hand-6'", ",", "\n", "'hand-7'", ",", "\n", "'hand-8'", ",", "\n", "'hat-10'", ",", "\n", "'hat-11'", ",", "\n", "'hat-12'", ",", "\n", "'hat-13'", ",", "\n", "'hat-14'", ",", "\n", "'hat-15'", ",", "\n", "'hat-16'", ",", "\n", "'hat-17'", ",", "\n", "'hat-19'", ",", "\n", "'hat-20'", ",", "\n", "'hat-3'", ",", "\n", "'hat-4'", ",", "\n", "'hat-6'", ",", "\n", "'hat-7'", ",", "\n", "'hat-8'", ",", "\n", "'hat-9'", ",", "\n", "'helmet-1'", ",", "\n", "'helmet-10'", ",", "\n", "'helmet-12'", ",", "\n", "'helmet-14'", ",", "\n", "'helmet-15'", ",", "\n", "'helmet-16'", ",", "\n", "'helmet-17'", ",", "\n", "'helmet-18'", ",", "\n", "'helmet-2'", ",", "\n", "'helmet-20'", ",", "\n", "'helmet-3'", ",", "\n", "'helmet-4'", ",", "\n", "'helmet-6'", ",", "\n", "'helmet-7'", ",", "\n", "'helmet-8'", ",", "\n", "'helmet-9'", ",", "\n", "'hippo-10'", ",", "\n", "'hippo-11'", ",", "\n", "'hippo-12'", ",", "\n", "'hippo-13'", ",", "\n", "'hippo-14'", ",", "\n", "'hippo-15'", ",", "\n", "'hippo-16'", ",", "\n", "'hippo-17'", ",", "\n", "'hippo-18'", ",", "\n", "'hippo-19'", ",", "\n", "'hippo-2'", ",", "\n", "'hippo-3'", ",", "\n", "'hippo-4'", ",", "\n", "'hippo-5'", ",", "\n", "'hippo-6'", ",", "\n", "'hippo-8'", ",", "\n", "'horse-10'", ",", "\n", "'horse-11'", ",", "\n", "'horse-13'", ",", "\n", "'horse-14'", ",", "\n", "'horse-16'", ",", "\n", "'horse-17'", ",", "\n", "'horse-18'", ",", "\n", "'horse-19'", ",", "\n", "'horse-2'", ",", "\n", "'horse-20'", ",", "\n", "'horse-3'", ",", "\n", "'horse-5'", ",", "\n", "'horse-6'", ",", "\n", "'horse-7'", ",", "\n", "'horse-8'", ",", "\n", "'horse-9'", ",", "\n", "'kangaroo-1'", ",", "\n", "'kangaroo-10'", ",", "\n", "'kangaroo-12'", ",", "\n", "'kangaroo-13'", ",", "\n", "'kangaroo-15'", ",", "\n", "'kangaroo-16'", ",", "\n", "'kangaroo-17'", ",", "\n", "'kangaroo-18'", ",", "\n", "'kangaroo-19'", ",", "\n", "'kangaroo-20'", ",", "\n", "'kangaroo-3'", ",", "\n", "'kangaroo-4'", ",", "\n", "'kangaroo-6'", ",", "\n", "'kangaroo-7'", ",", "\n", "'kangaroo-8'", ",", "\n", "'kangaroo-9'", ",", "\n", "'kite-1'", ",", "\n", "'kite-11'", ",", "\n", "'kite-12'", ",", "\n", "'kite-13'", ",", "\n", "'kite-14'", ",", "\n", "'kite-16'", ",", "\n", "'kite-17'", ",", "\n", "'kite-18'", ",", "\n", "'kite-19'", ",", "\n", "'kite-2'", ",", "\n", "'kite-20'", ",", "\n", "'kite-3'", ",", "\n", "'kite-5'", ",", "\n", "'kite-7'", ",", "\n", "'kite-8'", ",", "\n", "'kite-9'", ",", "\n", "'leopard-10'", ",", "\n", "'leopard-11'", ",", "\n", "'leopard-12'", ",", "\n", "'leopard-13'", ",", "\n", "'leopard-14'", ",", "\n", "'leopard-15'", ",", "\n", "'leopard-17'", ",", "\n", "'leopard-18'", ",", "\n", "'leopard-19'", ",", "\n", "'leopard-2'", ",", "\n", "'leopard-3'", ",", "\n", "'leopard-4'", ",", "\n", "'leopard-5'", ",", "\n", "'leopard-6'", ",", "\n", "'leopard-8'", ",", "\n", "'leopard-9'", ",", "\n", "'licenseplate-1'", ",", "\n", "'licenseplate-10'", ",", "\n", "'licenseplate-11'", ",", "\n", "'licenseplate-14'", ",", "\n", "'licenseplate-16'", ",", "\n", "'licenseplate-17'", ",", "\n", "'licenseplate-18'", ",", "\n", "'licenseplate-19'", ",", "\n", "'licenseplate-2'", ",", "\n", "'licenseplate-20'", ",", "\n", "'licenseplate-3'", ",", "\n", "'licenseplate-4'", ",", "\n", "'licenseplate-5'", ",", "\n", "'licenseplate-7'", ",", "\n", "'licenseplate-8'", ",", "\n", "'licenseplate-9'", ",", "\n", "'lion-10'", ",", "\n", "'lion-11'", ",", "\n", "'lion-13'", ",", "\n", "'lion-14'", ",", "\n", "'lion-15'", ",", "\n", "'lion-16'", ",", "\n", "'lion-17'", ",", "\n", "'lion-18'", ",", "\n", "'lion-19'", ",", "\n", "'lion-2'", ",", "\n", "'lion-3'", ",", "\n", "'lion-4'", ",", "\n", "'lion-6'", ",", "\n", "'lion-7'", ",", "\n", "'lion-8'", ",", "\n", "'lion-9'", ",", "\n", "'lizard-10'", ",", "\n", "'lizard-11'", ",", "\n", "'lizard-12'", ",", "\n", "'lizard-14'", ",", "\n", "'lizard-15'", ",", "\n", "'lizard-16'", ",", "\n", "'lizard-17'", ",", "\n", "'lizard-18'", ",", "\n", "'lizard-19'", ",", "\n", "'lizard-2'", ",", "\n", "'lizard-20'", ",", "\n", "'lizard-4'", ",", "\n", "'lizard-5'", ",", "\n", "'lizard-7'", ",", "\n", "'lizard-8'", ",", "\n", "'lizard-9'", ",", "\n", "'microphone-1'", ",", "\n", "'microphone-10'", ",", "\n", "'microphone-11'", ",", "\n", "'microphone-12'", ",", "\n", "'microphone-13'", ",", "\n", "'microphone-15'", ",", "\n", "'microphone-17'", ",", "\n", "'microphone-18'", ",", "\n", "'microphone-19'", ",", "\n", "'microphone-20'", ",", "\n", "'microphone-3'", ",", "\n", "'microphone-4'", ",", "\n", "'microphone-5'", ",", "\n", "'microphone-7'", ",", "\n", "'microphone-8'", ",", "\n", "'microphone-9'", ",", "\n", "'monkey-1'", ",", "\n", "'monkey-10'", ",", "\n", "'monkey-11'", ",", "\n", "'monkey-12'", ",", "\n", "'monkey-13'", ",", "\n", "'monkey-14'", ",", "\n", "'monkey-15'", ",", "\n", "'monkey-16'", ",", "\n", "'monkey-18'", ",", "\n", "'monkey-19'", ",", "\n", "'monkey-2'", ",", "\n", "'monkey-20'", ",", "\n", "'monkey-5'", ",", "\n", "'monkey-6'", ",", "\n", "'monkey-7'", ",", "\n", "'monkey-8'", ",", "\n", "'motorcycle-10'", ",", "\n", "'motorcycle-11'", ",", "\n", "'motorcycle-12'", ",", "\n", "'motorcycle-13'", ",", "\n", "'motorcycle-14'", ",", "\n", "'motorcycle-15'", ",", "\n", "'motorcycle-16'", ",", "\n", "'motorcycle-17'", ",", "\n", "'motorcycle-19'", ",", "\n", "'motorcycle-2'", ",", "\n", "'motorcycle-20'", ",", "\n", "'motorcycle-4'", ",", "\n", "'motorcycle-5'", ",", "\n", "'motorcycle-6'", ",", "\n", "'motorcycle-7'", ",", "\n", "'motorcycle-8'", ",", "\n", "'mouse-10'", ",", "\n", "'mouse-11'", ",", "\n", "'mouse-12'", ",", "\n", "'mouse-13'", ",", "\n", "'mouse-14'", ",", "\n", "'mouse-15'", ",", "\n", "'mouse-16'", ",", "\n", "'mouse-18'", ",", "\n", "'mouse-19'", ",", "\n", "'mouse-2'", ",", "\n", "'mouse-20'", ",", "\n", "'mouse-3'", ",", "\n", "'mouse-4'", ",", "\n", "'mouse-5'", ",", "\n", "'mouse-6'", ",", "\n", "'mouse-7'", ",", "\n", "'person-11'", ",", "\n", "'person-13'", ",", "\n", "'person-14'", ",", "\n", "'person-15'", ",", "\n", "'person-16'", ",", "\n", "'person-17'", ",", "\n", "'person-18'", ",", "\n", "'person-19'", ",", "\n", "'person-2'", ",", "\n", "'person-20'", ",", "\n", "'person-3'", ",", "\n", "'person-4'", ",", "\n", "'person-6'", ",", "\n", "'person-7'", ",", "\n", "'person-8'", ",", "\n", "'person-9'", ",", "\n", "'pig-1'", ",", "\n", "'pig-11'", ",", "\n", "'pig-12'", ",", "\n", "'pig-14'", ",", "\n", "'pig-15'", ",", "\n", "'pig-16'", ",", "\n", "'pig-17'", ",", "\n", "'pig-19'", ",", "\n", "'pig-20'", ",", "\n", "'pig-3'", ",", "\n", "'pig-4'", ",", "\n", "'pig-5'", ",", "\n", "'pig-6'", ",", "\n", "'pig-7'", ",", "\n", "'pig-8'", ",", "\n", "'pig-9'", ",", "\n", "'pool-1'", ",", "\n", "'pool-10'", ",", "\n", "'pool-11'", ",", "\n", "'pool-13'", ",", "\n", "'pool-14'", ",", "\n", "'pool-16'", ",", "\n", "'pool-17'", ",", "\n", "'pool-18'", ",", "\n", "'pool-19'", ",", "\n", "'pool-2'", ",", "\n", "'pool-20'", ",", "\n", "'pool-4'", ",", "\n", "'pool-5'", ",", "\n", "'pool-6'", ",", "\n", "'pool-8'", ",", "\n", "'pool-9'", ",", "\n", "'rabbit-1'", ",", "\n", "'rabbit-11'", ",", "\n", "'rabbit-12'", ",", "\n", "'rabbit-14'", ",", "\n", "'rabbit-15'", ",", "\n", "'rabbit-16'", ",", "\n", "'rabbit-18'", ",", "\n", "'rabbit-2'", ",", "\n", "'rabbit-20'", ",", "\n", "'rabbit-3'", ",", "\n", "'rabbit-4'", ",", "\n", "'rabbit-5'", ",", "\n", "'rabbit-6'", ",", "\n", "'rabbit-7'", ",", "\n", "'rabbit-8'", ",", "\n", "'rabbit-9'", ",", "\n", "'racing-1'", ",", "\n", "'racing-11'", ",", "\n", "'racing-12'", ",", "\n", "'racing-13'", ",", "\n", "'racing-14'", ",", "\n", "'racing-17'", ",", "\n", "'racing-18'", ",", "\n", "'racing-19'", ",", "\n", "'racing-2'", ",", "\n", "'racing-3'", ",", "\n", "'racing-4'", ",", "\n", "'racing-5'", ",", "\n", "'racing-6'", ",", "\n", "'racing-7'", ",", "\n", "'racing-8'", ",", "\n", "'racing-9'", ",", "\n", "'robot-10'", ",", "\n", "'robot-11'", ",", "\n", "'robot-12'", ",", "\n", "'robot-13'", ",", "\n", "'robot-14'", ",", "\n", "'robot-15'", ",", "\n", "'robot-16'", ",", "\n", "'robot-17'", ",", "\n", "'robot-18'", ",", "\n", "'robot-2'", ",", "\n", "'robot-20'", ",", "\n", "'robot-3'", ",", "\n", "'robot-4'", ",", "\n", "'robot-6'", ",", "\n", "'robot-7'", ",", "\n", "'robot-9'", ",", "\n", "'rubicCube-10'", ",", "\n", "'rubicCube-11'", ",", "\n", "'rubicCube-12'", ",", "\n", "'rubicCube-13'", ",", "\n", "'rubicCube-15'", ",", "\n", "'rubicCube-16'", ",", "\n", "'rubicCube-17'", ",", "\n", "'rubicCube-18'", ",", "\n", "'rubicCube-2'", ",", "\n", "'rubicCube-20'", ",", "\n", "'rubicCube-3'", ",", "\n", "'rubicCube-4'", ",", "\n", "'rubicCube-5'", ",", "\n", "'rubicCube-7'", ",", "\n", "'rubicCube-8'", ",", "\n", "'rubicCube-9'", ",", "\n", "'sepia-1'", ",", "\n", "'sepia-10'", ",", "\n", "'sepia-11'", ",", "\n", "'sepia-12'", ",", "\n", "'sepia-14'", ",", "\n", "'sepia-15'", ",", "\n", "'sepia-17'", ",", "\n", "'sepia-18'", ",", "\n", "'sepia-19'", ",", "\n", "'sepia-2'", ",", "\n", "'sepia-20'", ",", "\n", "'sepia-3'", ",", "\n", "'sepia-4'", ",", "\n", "'sepia-5'", ",", "\n", "'sepia-7'", ",", "\n", "'sepia-9'", ",", "\n", "'shark-1'", ",", "\n", "'shark-10'", ",", "\n", "'shark-11'", ",", "\n", "'shark-12'", ",", "\n", "'shark-13'", ",", "\n", "'shark-14'", ",", "\n", "'shark-15'", ",", "\n", "'shark-16'", ",", "\n", "'shark-17'", ",", "\n", "'shark-18'", ",", "\n", "'shark-19'", ",", "\n", "'shark-20'", ",", "\n", "'shark-4'", ",", "\n", "'shark-7'", ",", "\n", "'shark-8'", ",", "\n", "'shark-9'", ",", "\n", "'sheep-1'", ",", "\n", "'sheep-10'", ",", "\n", "'sheep-11'", ",", "\n", "'sheep-12'", ",", "\n", "'sheep-13'", ",", "\n", "'sheep-14'", ",", "\n", "'sheep-15'", ",", "\n", "'sheep-16'", ",", "\n", "'sheep-17'", ",", "\n", "'sheep-18'", ",", "\n", "'sheep-19'", ",", "\n", "'sheep-2'", ",", "\n", "'sheep-20'", ",", "\n", "'sheep-4'", ",", "\n", "'sheep-6'", ",", "\n", "'sheep-8'", ",", "\n", "'skateboard-1'", ",", "\n", "'skateboard-10'", ",", "\n", "'skateboard-11'", ",", "\n", "'skateboard-12'", ",", "\n", "'skateboard-13'", ",", "\n", "'skateboard-14'", ",", "\n", "'skateboard-15'", ",", "\n", "'skateboard-17'", ",", "\n", "'skateboard-18'", ",", "\n", "'skateboard-2'", ",", "\n", "'skateboard-20'", ",", "\n", "'skateboard-4'", ",", "\n", "'skateboard-5'", ",", "\n", "'skateboard-6'", ",", "\n", "'skateboard-7'", ",", "\n", "'skateboard-9'", ",", "\n", "'spider-1'", ",", "\n", "'spider-10'", ",", "\n", "'spider-11'", ",", "\n", "'spider-12'", ",", "\n", "'spider-13'", ",", "\n", "'spider-15'", ",", "\n", "'spider-17'", ",", "\n", "'spider-19'", ",", "\n", "'spider-2'", ",", "\n", "'spider-3'", ",", "\n", "'spider-4'", ",", "\n", "'spider-5'", ",", "\n", "'spider-6'", ",", "\n", "'spider-7'", ",", "\n", "'spider-8'", ",", "\n", "'spider-9'", ",", "\n", "'squirrel-1'", ",", "\n", "'squirrel-10'", ",", "\n", "'squirrel-12'", ",", "\n", "'squirrel-14'", ",", "\n", "'squirrel-15'", ",", "\n", "'squirrel-16'", ",", "\n", "'squirrel-17'", ",", "\n", "'squirrel-18'", ",", "\n", "'squirrel-2'", ",", "\n", "'squirrel-20'", ",", "\n", "'squirrel-3'", ",", "\n", "'squirrel-4'", ",", "\n", "'squirrel-5'", ",", "\n", "'squirrel-6'", ",", "\n", "'squirrel-7'", ",", "\n", "'squirrel-9'", ",", "\n", "'surfboard-1'", ",", "\n", "'surfboard-10'", ",", "\n", "'surfboard-11'", ",", "\n", "'surfboard-13'", ",", "\n", "'surfboard-14'", ",", "\n", "'surfboard-15'", ",", "\n", "'surfboard-16'", ",", "\n", "'surfboard-17'", ",", "\n", "'surfboard-18'", ",", "\n", "'surfboard-19'", ",", "\n", "'surfboard-2'", ",", "\n", "'surfboard-20'", ",", "\n", "'surfboard-3'", ",", "\n", "'surfboard-6'", ",", "\n", "'surfboard-7'", ",", "\n", "'surfboard-9'", ",", "\n", "'swing-1'", ",", "\n", "'swing-11'", ",", "\n", "'swing-12'", ",", "\n", "'swing-13'", ",", "\n", "'swing-15'", ",", "\n", "'swing-16'", ",", "\n", "'swing-18'", ",", "\n", "'swing-19'", ",", "\n", "'swing-2'", ",", "\n", "'swing-3'", ",", "\n", "'swing-4'", ",", "\n", "'swing-5'", ",", "\n", "'swing-6'", ",", "\n", "'swing-7'", ",", "\n", "'swing-8'", ",", "\n", "'swing-9'", ",", "\n", "'tank-1'", ",", "\n", "'tank-10'", ",", "\n", "'tank-11'", ",", "\n", "'tank-12'", ",", "\n", "'tank-13'", ",", "\n", "'tank-15'", ",", "\n", "'tank-17'", ",", "\n", "'tank-18'", ",", "\n", "'tank-19'", ",", "\n", "'tank-2'", ",", "\n", "'tank-20'", ",", "\n", "'tank-3'", ",", "\n", "'tank-4'", ",", "\n", "'tank-5'", ",", "\n", "'tank-7'", ",", "\n", "'tank-8'", ",", "\n", "'tiger-1'", ",", "\n", "'tiger-10'", ",", "\n", "'tiger-11'", ",", "\n", "'tiger-13'", ",", "\n", "'tiger-14'", ",", "\n", "'tiger-15'", ",", "\n", "'tiger-16'", ",", "\n", "'tiger-17'", ",", "\n", "'tiger-19'", ",", "\n", "'tiger-2'", ",", "\n", "'tiger-20'", ",", "\n", "'tiger-3'", ",", "\n", "'tiger-5'", ",", "\n", "'tiger-7'", ",", "\n", "'tiger-8'", ",", "\n", "'tiger-9'", ",", "\n", "'train-10'", ",", "\n", "'train-12'", ",", "\n", "'train-13'", ",", "\n", "'train-14'", ",", "\n", "'train-15'", ",", "\n", "'train-16'", ",", "\n", "'train-17'", ",", "\n", "'train-18'", ",", "\n", "'train-19'", ",", "\n", "'train-2'", ",", "\n", "'train-3'", ",", "\n", "'train-4'", ",", "\n", "'train-5'", ",", "\n", "'train-6'", ",", "\n", "'train-8'", ",", "\n", "'train-9'", ",", "\n", "'truck-1'", ",", "\n", "'truck-10'", ",", "\n", "'truck-11'", ",", "\n", "'truck-12'", ",", "\n", "'truck-13'", ",", "\n", "'truck-14'", ",", "\n", "'truck-15'", ",", "\n", "'truck-17'", ",", "\n", "'truck-18'", ",", "\n", "'truck-19'", ",", "\n", "'truck-2'", ",", "\n", "'truck-20'", ",", "\n", "'truck-4'", ",", "\n", "'truck-5'", ",", "\n", "'truck-8'", ",", "\n", "'truck-9'", ",", "\n", "'turtle-1'", ",", "\n", "'turtle-10'", ",", "\n", "'turtle-11'", ",", "\n", "'turtle-12'", ",", "\n", "'turtle-13'", ",", "\n", "'turtle-14'", ",", "\n", "'turtle-15'", ",", "\n", "'turtle-17'", ",", "\n", "'turtle-18'", ",", "\n", "'turtle-19'", ",", "\n", "'turtle-2'", ",", "\n", "'turtle-20'", ",", "\n", "'turtle-3'", ",", "\n", "'turtle-4'", ",", "\n", "'turtle-6'", ",", "\n", "'turtle-7'", ",", "\n", "'umbrella-1'", ",", "\n", "'umbrella-10'", ",", "\n", "'umbrella-11'", ",", "\n", "'umbrella-12'", ",", "\n", "'umbrella-13'", ",", "\n", "'umbrella-14'", ",", "\n", "'umbrella-15'", ",", "\n", "'umbrella-16'", ",", "\n", "'umbrella-18'", ",", "\n", "'umbrella-20'", ",", "\n", "'umbrella-3'", ",", "\n", "'umbrella-4'", ",", "\n", "'umbrella-5'", ",", "\n", "'umbrella-6'", ",", "\n", "'umbrella-7'", ",", "\n", "'umbrella-8'", ",", "\n", "'volleyball-10'", ",", "\n", "'volleyball-11'", ",", "\n", "'volleyball-12'", ",", "\n", "'volleyball-14'", ",", "\n", "'volleyball-15'", ",", "\n", "'volleyball-16'", ",", "\n", "'volleyball-17'", ",", "\n", "'volleyball-2'", ",", "\n", "'volleyball-20'", ",", "\n", "'volleyball-3'", ",", "\n", "'volleyball-4'", ",", "\n", "'volleyball-5'", ",", "\n", "'volleyball-6'", ",", "\n", "'volleyball-7'", ",", "\n", "'volleyball-8'", ",", "\n", "'volleyball-9'", ",", "\n", "'yoyo-1'", ",", "\n", "'yoyo-10'", ",", "\n", "'yoyo-11'", ",", "\n", "'yoyo-12'", ",", "\n", "'yoyo-13'", ",", "\n", "'yoyo-14'", ",", "\n", "'yoyo-16'", ",", "\n", "'yoyo-18'", ",", "\n", "'yoyo-2'", ",", "\n", "'yoyo-20'", ",", "\n", "'yoyo-3'", ",", "\n", "'yoyo-4'", ",", "\n", "'yoyo-5'", ",", "\n", "'yoyo-6'", ",", "\n", "'yoyo-8'", ",", "\n", "'yoyo-9'", ",", "\n", "'zebra-1'", ",", "\n", "'zebra-11'", ",", "\n", "'zebra-12'", ",", "\n", "'zebra-13'", ",", "\n", "'zebra-15'", ",", "\n", "'zebra-18'", ",", "\n", "'zebra-19'", ",", "\n", "'zebra-2'", ",", "\n", "'zebra-20'", ",", "\n", "'zebra-3'", ",", "\n", "'zebra-4'", ",", "\n", "'zebra-5'", ",", "\n", "'zebra-6'", ",", "\n", "'zebra-7'", ",", "\n", "'zebra-8'", ",", "\n", "'zebra-9'", "\n", "]", "\n", "\n", "return", "sequence_list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.environment.EnvSettings.__init__": [[6, 29], ["os.path.abspath", "os.path.join", "os.path.dirname"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pytracking_path", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'..'", ")", ")", "\n", "\n", "self", ".", "results_path", "=", "'{}/tracking_results/'", ".", "format", "(", "pytracking_path", ")", "\n", "self", ".", "segmentation_path", "=", "'{}/segmentation_results/'", ".", "format", "(", "pytracking_path", ")", "\n", "self", ".", "network_path", "=", "'{}/networks/'", ".", "format", "(", "pytracking_path", ")", "\n", "self", ".", "result_plot_path", "=", "'{}/result_plots/'", ".", "format", "(", "pytracking_path", ")", "\n", "self", ".", "otb_path", "=", "''", "\n", "self", ".", "nfs_path", "=", "''", "\n", "self", ".", "uav_path", "=", "''", "\n", "self", ".", "tpl_path", "=", "''", "\n", "self", ".", "vot_path", "=", "''", "\n", "self", ".", "got10k_path", "=", "''", "\n", "self", ".", "lasot_path", "=", "''", "\n", "self", ".", "lasot_extension_subset_path", "=", "''", "\n", "self", ".", "trackingnet_path", "=", "''", "\n", "self", ".", "oxuva_path", "=", "''", "\n", "self", ".", "davis_dir", "=", "''", "\n", "self", ".", "youtubevos_dir", "=", "''", "\n", "\n", "self", ".", "got_packed_results_path", "=", "''", "\n", "self", ".", "got_reports_path", "=", "''", "\n", "self", ".", "tn_packed_results_path", "=", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.environment.create_default_local_file": [[31, 55], ["os.path.join", "os.path.dirname", "open", "environment.EnvSettings", "f.write", "f.write", "f.write", "f.write", "dir", "f.write", "getattr", "attr.startswith", "callable", "f.write", "f.write"], "function", ["None"], ["", "", "def", "create_default_local_file", "(", ")", ":", "\n", "    ", "comment", "=", "{", "'results_path'", ":", "'Where to store tracking results'", ",", "\n", "'network_path'", ":", "'Where tracking networks are stored.'", "}", "\n", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'local.py'", ")", "\n", "with", "open", "(", "path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "settings", "=", "EnvSettings", "(", ")", "\n", "\n", "f", ".", "write", "(", "'from pytracking.evaluation.environment import EnvSettings\\n\\n'", ")", "\n", "f", ".", "write", "(", "'def local_env_settings():\\n'", ")", "\n", "f", ".", "write", "(", "'    settings = EnvSettings()\\n\\n'", ")", "\n", "f", ".", "write", "(", "'    # Set your local paths here.\\n\\n'", ")", "\n", "\n", "for", "attr", "in", "dir", "(", "settings", ")", ":", "\n", "            ", "comment_str", "=", "None", "\n", "if", "attr", "in", "comment", ":", "\n", "                ", "comment_str", "=", "comment", "[", "attr", "]", "\n", "", "attr_val", "=", "getattr", "(", "settings", ",", "attr", ")", "\n", "if", "not", "attr", ".", "startswith", "(", "'__'", ")", "and", "not", "callable", "(", "attr_val", ")", ":", "\n", "                ", "if", "comment_str", "is", "None", ":", "\n", "                    ", "f", ".", "write", "(", "'    settings.{} = \\'{}\\'\\n'", ".", "format", "(", "attr", ",", "attr_val", ")", ")", "\n", "", "else", ":", "\n", "                    ", "f", ".", "write", "(", "'    settings.{} = \\'{}\\'    # {}\\n'", ".", "format", "(", "attr", ",", "attr_val", ",", "comment_str", ")", ")", "\n", "", "", "", "f", ".", "write", "(", "'\\n    return settings\\n\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.environment.env_settings": [[57, 69], ["importlib.import_module", "importlib.import_module.local_env_settings", "os.path.join", "environment.create_default_local_file", "RuntimeError", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.create_default_local_file"], ["", "", "def", "env_settings", "(", ")", ":", "\n", "    ", "env_module_name", "=", "'pytracking.evaluation.local'", "\n", "try", ":", "\n", "        ", "env_module", "=", "importlib", ".", "import_module", "(", "env_module_name", ")", "\n", "return", "env_module", ".", "local_env_settings", "(", ")", "\n", "", "except", ":", "\n", "        ", "env_file", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'local.py'", ")", "\n", "\n", "# Create a default file", "\n", "create_default_local_file", "(", ")", "\n", "raise", "RuntimeError", "(", "'YOU HAVE NOT SETUP YOUR local.py!!!\\n Go to \"{}\" and set all the paths you need. '", "\n", "'Then try to run again.'", ".", "format", "(", "env_file", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.datasets.load_dataset": [[49, 59], ["name.lower.lower", "dataset_dict.get", "importlib.import_module", "dataset.get_sequence_list", "ValueError", "getattr"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.get_sequence_list"], ["def", "load_dataset", "(", "name", ":", "str", ")", ":", "\n", "    ", "\"\"\" Import and load a single dataset.\"\"\"", "\n", "name", "=", "name", ".", "lower", "(", ")", "\n", "dset_info", "=", "dataset_dict", ".", "get", "(", "name", ")", "\n", "if", "dset_info", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown dataset \\'%s\\''", "%", "name", ")", "\n", "\n", "", "m", "=", "importlib", ".", "import_module", "(", "dset_info", ".", "module", ")", "\n", "dataset", "=", "getattr", "(", "m", ",", "dset_info", ".", "class_name", ")", "(", "**", "dset_info", ".", "kwargs", ")", "# Call the constructor", "\n", "return", "dataset", ".", "get_sequence_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.datasets.get_dataset": [[61, 67], ["pytracking.evaluation.data.SequenceList", "pytracking.evaluation.data.SequenceList.extend", "datasets.load_dataset"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.datasets.load_dataset"], ["", "def", "get_dataset", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\" Get a single or set of datasets.\"\"\"", "\n", "dset", "=", "SequenceList", "(", ")", "\n", "for", "name", "in", "args", ":", "\n", "        ", "dset", ".", "extend", "(", "load_dataset", "(", "name", ")", ")", "\n", "", "return", "dset", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.oxuvadataset.OxUvADataset.__init__": [[21, 55], ["pytracking.evaluation.data.BaseDataset.__init__", "pandas.read_csv", "pandas.read_csv", "pandas.read_csv", "os.path.join", "os.path.join", "os.path.join", "ValueError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "split", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_path", "=", "self", ".", "env_settings", ".", "oxuva_path", "\n", "self", ".", "split", "=", "split", "\n", "\n", "dev_tasks_df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "self", ".", "base_path", ",", "'tasks'", ",", "'dev.csv'", ")", ",", "header", "=", "None", ",", "\n", "names", "=", "[", "'video_id'", ",", "'object_id'", ",", "'init_frame'", ",", "'last_frame'", ",", "'xmin'", ",", "'xmax'", ",", "\n", "'ymin'", ",", "'ymax'", "]", ",", "\n", "dtype", "=", "{", "'video_id'", ":", "str", ",", "'object_id'", ":", "str", ",", "'init_frame'", ":", "int", ",", "'last_frame'", ":", "int", ",", "\n", "'xmin'", ":", "float", ",", "'xmax'", ":", "float", ",", "'ymin'", ":", "float", ",", "'ymax'", ":", "float", "}", "\n", ")", "\n", "\n", "test_tasks_df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "self", ".", "base_path", ",", "'tasks'", ",", "'test.csv'", ")", ",", "header", "=", "None", ",", "\n", "names", "=", "[", "'video_id'", ",", "'object_id'", ",", "'init_frame'", ",", "'last_frame'", ",", "'xmin'", ",", "'xmax'", ",", "\n", "'ymin'", ",", "'ymax'", "]", ",", "\n", "dtype", "=", "{", "'video_id'", ":", "str", ",", "'object_id'", ":", "str", ",", "'init_frame'", ":", "int", ",", "'last_frame'", ":", "int", ",", "\n", "'xmin'", ":", "float", ",", "'xmax'", ":", "float", ",", "'ymin'", ":", "float", ",", "'ymax'", ":", "float", "}", "\n", ")", "\n", "\n", "self", ".", "dev_annotations_df", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "self", ".", "base_path", ",", "'annotations'", ",", "'dev.csv'", ")", ",", "header", "=", "None", ",", "\n", "names", "=", "[", "'video_id'", ",", "'object_id'", ",", "'class_id'", ",", "'class_name'", ",", "\n", "'contains_cuts'", ",", "'always_visible'", ",", "'frame_num'", ",", "'object_presence'", ",", "\n", "'xmin'", ",", "'xmax'", ",", "'ymin'", ",", "'ymax'", "]", ",", "\n", "dtype", "=", "{", "'video_id'", ":", "str", ",", "'object_id'", ":", "str", ",", "'class_id'", ":", "int", ",", "\n", "'class_name'", ":", "str", ",", "'contains_cuts'", ":", "str", ",", "'always_visible'", ":", "str", ",", "\n", "'frame_num'", ":", "int", ",", "'object_presence'", ":", "str", ",", "'xmin'", ":", "float", ",", "\n", "'xmax'", ":", "float", ",", "'ymin'", ":", "float", ",", "'ymax'", ":", "float", "}", "\n", ")", "\n", "if", "self", ".", "split", "==", "'dev'", ":", "\n", "            ", "self", ".", "tasks_df", "=", "dev_tasks_df", "\n", "", "elif", "self", ".", "split", "==", "'test'", ":", "\n", "            ", "self", ".", "tasks_df", "=", "test_tasks_df", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Split {} is not a valid option for OxUva'", ".", "format", "(", "self", ".", "split", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.oxuvadataset.OxUvADataset.get_sequence_list": [[57, 59], ["pytracking.evaluation.data.SequenceList", "oxuvadataset.OxUvADataset._construct_sequence", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence"], ["", "", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "return", "SequenceList", "(", "[", "self", ".", "_construct_sequence", "(", "i", ")", "for", "i", "in", "range", "(", "0", ",", "self", ".", "tasks_df", ".", "shape", "[", "0", "]", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.oxuvadataset.OxUvADataset._construct_sequence": [[60, 81], ["os.path.join().format", "pytracking.evaluation.data.Sequence", "os.path.join", "oxuvadataset.OxUvADataset.build_dev_annotations", "oxuvadataset.OxUvADataset.build_test_annotations", "oxuvadataset.OxUvADataset.reshape", "os.path.join", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.oxuvadataset.OxUvADataset.build_dev_annotations", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.oxuvadataset.OxUvADataset.build_test_annotations"], ["", "def", "_construct_sequence", "(", "self", ",", "sequence_id", ")", ":", "\n", "        ", "video_id", "=", "self", ".", "tasks_df", "[", "'video_id'", "]", "[", "sequence_id", "]", "\n", "object_id", "=", "self", ".", "tasks_df", "[", "'object_id'", "]", "[", "sequence_id", "]", "\n", "init_frame", "=", "self", ".", "tasks_df", "[", "'init_frame'", "]", "[", "sequence_id", "]", "\n", "last_frame", "=", "self", ".", "tasks_df", "[", "'last_frame'", "]", "[", "sequence_id", "]", "\n", "\n", "sequence_name", "=", "'{}_{}_frames[{:06d}:{:06d}]'", ".", "format", "(", "video_id", ",", "object_id", ",", "init_frame", ",", "last_frame", "+", "1", ")", "\n", "\n", "\n", "frames_path", "=", "os", ".", "path", ".", "join", "(", "'{}'", ",", "'images'", ",", "self", ".", "split", ",", "'{}'", ")", ".", "format", "(", "self", ".", "base_path", ",", "video_id", ")", "\n", "\n", "frames_list", "=", "[", "os", ".", "path", ".", "join", "(", "frames_path", ",", "'{:06d}.jpeg'", ".", "format", "(", "frame_number", ")", ")", "for", "frame_number", "in", "\n", "range", "(", "init_frame", ",", "last_frame", "+", "1", ")", "]", "\n", "\n", "if", "self", ".", "split", "==", "'dev'", ":", "\n", "            ", "ground_truth_rect", "=", "self", ".", "build_dev_annotations", "(", "frames_list", ",", "init_frame", ",", "last_frame", ",", "object_id", ",", "video_id", ")", "\n", "", "else", ":", "\n", "            ", "ground_truth_rect", "=", "self", ".", "build_test_annotations", "(", "frames_list", ",", "init_frame", ",", "last_frame", ",", "object_id", ",", "video_id", ")", "\n", "\n", "", "return", "Sequence", "(", "sequence_name", ",", "frames_list", ",", "'oxuva'", ",", "ground_truth_rect", ".", "reshape", "(", "-", "1", ",", "4", ")", ",", "\n", "object_class", "=", "None", ",", "target_visible", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.oxuvadataset.OxUvADataset.build_test_annotations": [[82, 94], ["numpy.logical_and", "annotation[].to_numpy", "PIL.Image.open", "numpy.ones", "numpy.vstack"], "methods", ["None"], ["", "def", "build_test_annotations", "(", "self", ",", "frames_list", ",", "init_frame", ",", "last_frame", ",", "object_id", ",", "video_id", ")", ":", "\n", "# Load first image in sequence to extract width and height to compute bbox coordinates in images.", "\n", "        ", "w", ",", "h", "=", "Image", ".", "open", "(", "frames_list", "[", "0", "]", ")", ".", "size", "\n", "ground_truth_rect", "=", "-", "np", ".", "ones", "(", "(", "last_frame", "-", "init_frame", "+", "1", ",", "4", ")", ")", "\n", "annotation_mask", "=", "np", ".", "logical_and", "(", "self", ".", "tasks_df", "[", "'video_id'", "]", "==", "video_id", ",", "self", ".", "tasks_df", "[", "'object_id'", "]", "==", "object_id", ")", "\n", "annotation", "=", "self", ".", "tasks_df", "[", "annotation_mask", "]", "\n", "xxyy", "=", "annotation", "[", "[", "'xmin'", ",", "'xmax'", ",", "'ymin'", ",", "'ymax'", "]", "]", ".", "to_numpy", "(", ")", "\n", "xxyy", "[", ":", ",", ":", "2", "]", "*=", "w", "\n", "xxyy", "[", ":", ",", "2", ":", "]", "*=", "h", "\n", "xywh", "=", "np", ".", "vstack", "(", "[", "xxyy", "[", ":", ",", "0", "]", ",", "xxyy", "[", ":", ",", "2", "]", ",", "xxyy", "[", ":", ",", "1", "]", "-", "xxyy", "[", ":", ",", "0", "]", ",", "xxyy", "[", ":", ",", "3", "]", "-", "xxyy", "[", ":", ",", "2", "]", "]", ")", ".", "T", "\n", "ground_truth_rect", "[", "0", "]", "=", "xywh", "\n", "return", "ground_truth_rect", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.oxuvadataset.OxUvADataset.build_dev_annotations": [[95, 112], ["numpy.logical_and", "annotations[].to_numpy", "numpy.logical_and", "[].to_numpy", "PIL.Image.open", "numpy.ones", "numpy.vstack"], "methods", ["None"], ["", "def", "build_dev_annotations", "(", "self", ",", "frames_list", ",", "init_frame", ",", "last_frame", ",", "object_id", ",", "video_id", ")", ":", "\n", "# Load first image in sequence to extract width and height to compute bbox coordinates in images.", "\n", "        ", "w", ",", "h", "=", "Image", ".", "open", "(", "frames_list", "[", "0", "]", ")", ".", "size", "\n", "annotation_mask", "=", "np", ".", "logical_and", "(", "self", ".", "dev_annotations_df", "[", "'video_id'", "]", "==", "video_id", ",", "\n", "self", ".", "dev_annotations_df", "[", "'object_id'", "]", "==", "object_id", ")", "\n", "annotations", "=", "self", ".", "dev_annotations_df", "[", "annotation_mask", "]", "\n", "ground_truth_rect", "=", "-", "np", ".", "ones", "(", "(", "last_frame", "-", "init_frame", "+", "1", ",", "4", ")", ")", "\n", "time", "=", "annotations", "[", "'frame_num'", "]", ".", "to_numpy", "(", ")", "\n", "time_mask", "=", "np", ".", "logical_and", "(", "time", ">=", "init_frame", ",", "time", "<=", "last_frame", ")", "\n", "xxyy", "=", "annotations", "[", "[", "'xmin'", ",", "'xmax'", ",", "'ymin'", ",", "'ymax'", "]", "]", "[", "time_mask", "]", ".", "to_numpy", "(", ")", "\n", "xxyy", "[", ":", ",", ":", "2", "]", "*=", "w", "\n", "xxyy", "[", ":", ",", "2", ":", "]", "*=", "h", "\n", "xywh", "=", "np", ".", "vstack", "(", "[", "xxyy", "[", ":", ",", "0", "]", ",", "xxyy", "[", ":", ",", "2", "]", ",", "xxyy", "[", ":", ",", "1", "]", "-", "xxyy", "[", ":", ",", "0", "]", ",", "xxyy", "[", ":", ",", "3", "]", "-", "xxyy", "[", ":", ",", "2", "]", "]", ")", ".", "T", "\n", "time", "-=", "init_frame", "\n", "ground_truth_rect", "[", "time", "]", "=", "xywh", "\n", "\n", "return", "ground_truth_rect", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.oxuvadataset.OxUvADataset.old_construct_sequence": [[113, 136], ["pytracking.utils.load_text.load_text", "pytracking.utils.load_text.load_text", "pytracking.utils.load_text.load_text", "numpy.logical_and", "pytracking.evaluation.data.Sequence", "sequence_name.split", "str", "str", "str", "pytracking.utils.load_text.load_text.reshape", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text", "home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text", "home.repos.pwc.inspect_result.visionml_pytracking.utils.load_text.load_text"], ["", "def", "old_construct_sequence", "(", "self", ",", "sequence_name", ")", ":", "\n", "        ", "class_name", "=", "sequence_name", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "anno_path", "=", "'{}/{}/{}/groundtruth.txt'", ".", "format", "(", "self", ".", "base_path", ",", "class_name", ",", "sequence_name", ")", "\n", "\n", "ground_truth_rect", "=", "load_text", "(", "str", "(", "anno_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "occlusion_label_path", "=", "'{}/{}/{}/full_occlusion.txt'", ".", "format", "(", "self", ".", "base_path", ",", "class_name", ",", "sequence_name", ")", "\n", "\n", "# NOTE: pandas backed seems super super slow for loading occlusion/oov masks", "\n", "full_occlusion", "=", "load_text", "(", "str", "(", "occlusion_label_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ",", "backend", "=", "'numpy'", ")", "\n", "\n", "out_of_view_label_path", "=", "'{}/{}/{}/out_of_view.txt'", ".", "format", "(", "self", ".", "base_path", ",", "class_name", ",", "sequence_name", ")", "\n", "out_of_view", "=", "load_text", "(", "str", "(", "out_of_view_label_path", ")", ",", "delimiter", "=", "','", ",", "dtype", "=", "np", ".", "float64", ",", "backend", "=", "'numpy'", ")", "\n", "\n", "target_visible", "=", "np", ".", "logical_and", "(", "full_occlusion", "==", "0", ",", "out_of_view", "==", "0", ")", "\n", "\n", "frames_path", "=", "'{}/{}/{}/img'", ".", "format", "(", "self", ".", "base_path", ",", "class_name", ",", "sequence_name", ")", "\n", "\n", "frames_list", "=", "[", "'{}/{:08d}.jpg'", ".", "format", "(", "frames_path", ",", "frame_number", ")", "for", "frame_number", "in", "range", "(", "1", ",", "ground_truth_rect", ".", "shape", "[", "0", "]", "+", "1", ")", "]", "\n", "\n", "target_class", "=", "class_name", "\n", "return", "Sequence", "(", "sequence_name", ",", "frames_list", ",", "'lasot'", ",", "ground_truth_rect", ".", "reshape", "(", "-", "1", ",", "4", ")", ",", "\n", "object_class", "=", "target_class", ",", "target_visible", "=", "target_visible", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.oxuvadataset.OxUvADataset.__len__": [[137, 139], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tasks_df", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.load_dump_seq_data_from_disk": [[15, 23], ["os.path.exists", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load"], ["def", "load_dump_seq_data_from_disk", "(", "path", ")", ":", "\n", "    ", "d", "=", "{", "}", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "d", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.dump_seq_data_to_disk": [[25, 32], ["create_distractor_dataset.load_dump_seq_data_from_disk", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.load_dump_seq_data_from_disk"], ["", "def", "dump_seq_data_to_disk", "(", "save_path", ",", "seq_name", ",", "seq_data", ")", ":", "\n", "    ", "d", "=", "load_dump_seq_data_from_disk", "(", "save_path", ")", "\n", "\n", "d", "[", "seq_name", "]", "=", "seq_data", "\n", "\n", "with", "open", "(", "save_path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "d", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.update_seq_data": [[34, 50], ["frame_candidate_data.items", "[].append", "collections.defaultdict", "collections.defaultdict", "seq_candidate_data[].append", "[].append", "torch.is_tensor", "val.float().tolist", "val.float"], "function", ["None"], ["", "", "def", "update_seq_data", "(", "seq_candidate_data", ",", "frame_candidate_data", ",", "frame_state", ",", "subseq_state", ")", ":", "\n", "    ", "if", "'frame_states'", "not", "in", "seq_candidate_data", "and", "frame_state", "is", "not", "None", ":", "\n", "        ", "seq_candidate_data", "[", "'frame_states'", "]", "=", "defaultdict", "(", "list", ")", "\n", "", "if", "'subseq_states'", "not", "in", "seq_candidate_data", "and", "subseq_state", "is", "not", "None", ":", "\n", "        ", "seq_candidate_data", "[", "'subseq_states'", "]", "=", "defaultdict", "(", "list", ")", "\n", "\n", "", "index", "=", "frame_candidate_data", "[", "'index'", "]", "\n", "\n", "for", "key", ",", "val", "in", "frame_candidate_data", ".", "items", "(", ")", ":", "\n", "        ", "val", "=", "val", ".", "float", "(", ")", ".", "tolist", "(", ")", "if", "torch", ".", "is_tensor", "(", "val", ")", "else", "val", "\n", "seq_candidate_data", "[", "key", "]", ".", "append", "(", "val", ")", "\n", "\n", "", "seq_candidate_data", "[", "'frame_states'", "]", "[", "frame_state", "]", ".", "append", "(", "index", ")", "\n", "\n", "if", "subseq_state", "in", "[", "'HH'", ",", "'HK'", ",", "'HG'", "]", ":", "\n", "        ", "seq_candidate_data", "[", "'subseq_states'", "]", "[", "subseq_state", "]", ".", "append", "(", "index", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.determine_frame_state": [[52, 82], ["tracking_data[].max", "torch.sqrt", "torch.argsort", "torch.sum().float", "torch.sum"], "function", ["None"], ["", "", "def", "determine_frame_state", "(", "tracking_data", ",", "tracker", ",", "seq", ",", "th", "=", "0.25", ")", ":", "\n", "    ", "visible", "=", "seq", ".", "target_visible", "[", "tracker", ".", "frame_num", "-", "1", "]", "\n", "num_candidates", "=", "tracking_data", "[", "'target_candidate_scores'", "]", ".", "shape", "[", "0", "]", "\n", "\n", "state", "=", "None", "\n", "if", "num_candidates", ">=", "2", ":", "\n", "        ", "max_candidate_score", "=", "tracking_data", "[", "'target_candidate_scores'", "]", ".", "max", "(", ")", "\n", "\n", "anno_and_target_candidate_score_dists", "=", "torch", ".", "sqrt", "(", "\n", "torch", ".", "sum", "(", "(", "tracking_data", "[", "'target_anno_coord'", "]", "-", "tracking_data", "[", "'target_candidate_coords'", "]", ")", "**", "2", ",", "dim", "=", "1", ")", ".", "float", "(", ")", ")", "\n", "\n", "ids", "=", "torch", ".", "argsort", "(", "anno_and_target_candidate_score_dists", ")", "\n", "\n", "score_dist_pred_anno", "=", "anno_and_target_candidate_score_dists", "[", "ids", "[", "0", "]", "]", "\n", "sortindex_correct_candidate", "=", "ids", "[", "0", "]", "\n", "score_dist_anno_2nd_highest_score_candidate", "=", "anno_and_target_candidate_score_dists", "[", "ids", "[", "1", "]", "]", "if", "num_candidates", ">", "1", "else", "10000", "\n", "\n", "if", "(", "num_candidates", ">", "1", "and", "score_dist_pred_anno", "<=", "2", "and", "score_dist_anno_2nd_highest_score_candidate", ">", "4", "and", "\n", "sortindex_correct_candidate", "==", "0", "and", "max_candidate_score", "<", "th", "and", "visible", "!=", "0", ")", ":", "\n", "            ", "state", "=", "'G'", "\n", "", "elif", "(", "num_candidates", ">", "1", "and", "score_dist_pred_anno", "<=", "2", "and", "score_dist_anno_2nd_highest_score_candidate", ">", "4", "and", "\n", "sortindex_correct_candidate", "==", "0", "and", "max_candidate_score", ">=", "th", "and", "visible", "!=", "0", ")", ":", "\n", "            ", "state", "=", "'H'", "\n", "", "elif", "(", "num_candidates", ">", "1", "and", "score_dist_pred_anno", ">", "4", "and", "max_candidate_score", ">=", "th", "and", "visible", "!=", "0", ")", ":", "\n", "            ", "state", "=", "'J'", "\n", "", "elif", "(", "num_candidates", ">", "1", "and", "score_dist_pred_anno", "<=", "2", "and", "score_dist_anno_2nd_highest_score_candidate", ">", "4", "and", "\n", "sortindex_correct_candidate", ">", "0", "and", "max_candidate_score", ">=", "th", "and", "visible", "!=", "0", ")", ":", "\n", "            ", "state", "=", "'K'", "\n", "\n", "", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.determine_subseq_state": [[84, 89], ["None"], "function", ["None"], ["", "def", "determine_subseq_state", "(", "frame_state", ",", "frame_state_previous", ")", ":", "\n", "    ", "if", "frame_state", "is", "not", "None", "and", "frame_state_previous", "is", "not", "None", ":", "\n", "        ", "return", "'{}{}'", ".", "format", "(", "frame_state_previous", ",", "frame_state", ")", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.extract_candidate_data": [[91, 106], ["seq.get_bbox", "pytracking.dcf.max2d", "tracker_data[].cpu", "ltr.find_local_maxima", "dict", "torch.tensor", "tracker.get_label_function", "anno_label.squeeze", "tracker_data[].cpu.squeeze"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.get_bbox", "home.repos.pwc.inspect_result.visionml_pytracking.libs.dcf.max2d", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.find_local_maxima", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp.ToMP.get_label_function"], ["", "", "def", "extract_candidate_data", "(", "tracker", ",", "seq", ")", ":", "\n", "    ", "tracker_data", "=", "tracker", ".", "distractor_dataset_data", "\n", "search_area_box", "=", "tracker_data", "[", "'search_area_box'", "]", "\n", "\n", "gth_box", "=", "seq", ".", "get_bbox", "(", "tracker", ".", "frame_num", "-", "1", ",", "None", ")", "\n", "gth_center", "=", "torch", ".", "tensor", "(", "gth_box", "[", ":", "2", "]", "+", "(", "gth_box", "[", "2", ":", "]", "-", "1", ")", "/", "2", ")", "[", "[", "1", ",", "0", "]", "]", "\n", "anno_label", "=", "tracker", ".", "get_label_function", "(", "gth_center", ",", "tracker_data", "[", "'sample_pos'", "]", ",", "tracker_data", "[", "'sample_scale'", "]", ")", "[", "0", "]", "\n", "_", ",", "target_anno_coord", "=", "dcf", ".", "max2d", "(", "anno_label", ".", "squeeze", "(", ")", ")", "\n", "\n", "score_map", "=", "tracker_data", "[", "'score_map'", "]", ".", "cpu", "(", ")", "\n", "\n", "target_candidate_coords", ",", "target_candidate_scores", "=", "prutils", ".", "find_local_maxima", "(", "score_map", ".", "squeeze", "(", ")", ",", "th", "=", "0.05", ",", "ks", "=", "5", ")", "\n", "\n", "return", "dict", "(", "search_area_box", "=", "search_area_box", ",", "index", "=", "tracker", ".", "frame_num", "-", "1", ",", "target_anno_coord", "=", "target_anno_coord", ",", "\n", "target_candidate_scores", "=", "target_candidate_scores", ",", "target_candidate_coords", "=", "target_candidate_coords", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.run_sequence": [[108, 139], ["tracker.get_parameters", "seq.init_info", "tracker.create_tracker", "tracker._read_image", "tracker.create_tracker.initialize", "collections.defaultdict", "enumerate", "create_distractor_dataset.dump_seq_data_to_disk", "tqdm.tqdm", "tracker._read_image", "seq.frame_info", "tracker.create_tracker.track", "create_distractor_dataset.extract_candidate_data", "create_distractor_dataset.determine_frame_state", "create_distractor_dataset.determine_subseq_state", "create_distractor_dataset.update_seq_data"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.get_parameters", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.init_info", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker.create_tracker", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._read_image", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.initialize", "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.dump_seq_data_to_disk", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.tracker.Tracker._read_image", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.Sequence.frame_info", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.multi_object_wrapper.MultiObjectWrapper.track", "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.extract_candidate_data", "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.determine_frame_state", "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.determine_subseq_state", "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.update_seq_data"], ["", "def", "run_sequence", "(", "seq", ",", "tracker", ",", "save_dir", ")", ":", "\n", "    ", "params", "=", "tracker", ".", "get_parameters", "(", ")", "\n", "\n", "# Get init information", "\n", "init_info", "=", "seq", ".", "init_info", "(", ")", "\n", "\n", "tracker_inst", "=", "tracker", ".", "create_tracker", "(", "params", ")", "\n", "\n", "image", "=", "tracker", ".", "_read_image", "(", "seq", ".", "frames", "[", "0", "]", ")", "\n", "\n", "_", "=", "tracker_inst", ".", "initialize", "(", "image", ",", "init_info", ")", "\n", "\n", "seq_candidate_data", "=", "defaultdict", "(", "list", ")", "\n", "frame_state_of_previous_frame", "=", "None", "\n", "\n", "for", "frame_num", ",", "frame_path", "in", "enumerate", "(", "tqdm", "(", "seq", ".", "frames", "[", "1", ":", "]", ",", "leave", "=", "False", ")", ",", "start", "=", "1", ")", ":", "\n", "        ", "image", "=", "tracker", ".", "_read_image", "(", "frame_path", ")", "\n", "info", "=", "seq", ".", "frame_info", "(", "frame_num", ")", "\n", "\n", "_", "=", "tracker_inst", ".", "track", "(", "image", ",", "info", ")", "\n", "frame_candidate_data", "=", "extract_candidate_data", "(", "tracker_inst", ",", "seq", ")", "\n", "\n", "frame_state", "=", "determine_frame_state", "(", "frame_candidate_data", ",", "tracker_inst", ",", "seq", ")", "\n", "subseq_state", "=", "determine_subseq_state", "(", "frame_state", ",", "frame_state_of_previous_frame", ")", "\n", "\n", "if", "frame_state", "is", "not", "None", ":", "\n", "            ", "update_seq_data", "(", "seq_candidate_data", ",", "frame_candidate_data", ",", "frame_state", ",", "subseq_state", ")", "\n", "\n", "", "frame_state_of_previous_frame", "=", "frame_state", "\n", "\n", "", "dump_seq_data_to_disk", "(", "save_dir", ",", "seq", ".", "name", ",", "seq_candidate_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.run_tracker": [[141, 152], ["os.path.join", "create_distractor_dataset.load_dump_seq_data_from_disk", "pytracking.evaluation.Tracker", "pytracking.evaluation.get_dataset", "tqdm.tqdm", "create_distractor_dataset.run_sequence"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.load_dump_seq_data_from_disk", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.datasets.get_dataset", "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.run_sequence"], ["", "def", "run_tracker", "(", "tracker_name", ",", "parameter_file_name", ",", "dataset_name", ",", "save_dir", ")", ":", "\n", "    ", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'target_candidates_dataset_{}_{}.json'", ".", "format", "(", "tracker_name", ",", "parameter_file_name", ")", ")", "\n", "\n", "dumped_data", "=", "load_dump_seq_data_from_disk", "(", "save_path", ")", "\n", "\n", "tracker", "=", "Tracker", "(", "tracker_name", ",", "parameter_file_name", ")", "\n", "dataset", "=", "get_dataset", "(", "dataset_name", ")", "\n", "\n", "for", "seq", "in", "tqdm", "(", "dataset", ")", ":", "\n", "        ", "if", "seq", ".", "name", "not", "in", "dumped_data", ":", "\n", "            ", "run_sequence", "(", "seq", ",", "tracker", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.main": [[154, 164], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "create_distractor_dataset.run_tracker"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.create_distractor_dataset.run_tracker"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Run tracker and dump tracker states to form distractor dataset.'", ")", "\n", "parser", ".", "add_argument", "(", "'tracker_name'", ",", "type", "=", "str", ",", "help", "=", "'Name of tracker.'", ")", "\n", "parser", ".", "add_argument", "(", "'parameter_file_name'", ",", "type", "=", "str", ",", "help", "=", "'Name of parameter file in the tracker folder.'", ")", "\n", "parser", ".", "add_argument", "(", "'dataset_name'", ",", "type", "=", "str", ",", "help", "=", "'Name of the dataset.'", ")", "\n", "parser", ".", "add_argument", "(", "'save_dir'", ",", "type", "=", "str", ",", "help", "=", "'Path to storage folder'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "run_tracker", "(", "args", ".", "tracker_name", ",", "args", ".", "parameter_file_name", ",", "args", ".", "dataset_name", ",", "args", ".", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.download_results._download_file": [[117, 120], ["gdown.download"], "function", ["None"], ["def", "_download_file", "(", "file_id", ",", "path", ")", ":", "\n", "    ", "link", "=", "'https://drive.google.com/uc?id='", "+", "file_id", "\n", "gdown", ".", "download", "(", "link", ",", "path", ",", "quiet", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.download_results.download_results": [[122, 180], ["print", "os.makedirs", "isinstance", "external_results_link_dict.items", "trackers.items", "isinstance", "os.path.join", "Exception", "os.path.exists", "os.makedirs", "common_link_dict[].items", "isinstance", "list", "list", "print", "download_results._download_file", "Exception", "pytracking_results_link_dict.keys", "external_results_link_dict.keys", "os.path.join", "common_link_dict[].items", "pytracking_results_link_dict.keys", "Exception", "external_results_link_dict.keys", "re.match", "print", "download_results._download_file", "os.path.join"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.download_results._download_file", "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.download_results._download_file"], ["", "def", "download_results", "(", "download_path", ",", "trackers", "=", "'pytracking'", ")", ":", "\n", "    ", "\"\"\"\n    Script to automatically download tracker results for PyTracking.\n\n    args:\n        download_path - Directory where the zipped results are downloaded\n        trackers - Tracker results which are to be downloaded.\n                   If set to 'pytracking', results for all pytracking based trackers will be downloaded.\n                   If set to 'external', results for available external trackers will be downloaded.\n                   If set to 'all', all available results are downloaded.\n                   If set to a name of a tracker (e.g. atom), all results for that tracker are downloaded.\n                   Otherwise, it can be set to a dict, where the keys are the names of the trackers for which results are\n                   downloaded. The value can be set to either 'all', in which case all available results for the\n                    tracker are downloaded. Else the value should be a list of parameter file names.\n    \"\"\"", "\n", "print", "(", "'Using download path '", "'{}'", "''", ".", "format", "(", "download_path", ")", ")", "\n", "\n", "os", ".", "makedirs", "(", "download_path", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "isinstance", "(", "trackers", ",", "str", ")", ":", "\n", "        ", "if", "trackers", "==", "'all'", ":", "\n", "            ", "all_trackers", "=", "list", "(", "pytracking_results_link_dict", ".", "keys", "(", ")", ")", "+", "list", "(", "external_results_link_dict", ".", "keys", "(", ")", ")", "\n", "trackers", "=", "{", "k", ":", "'all'", "for", "k", "in", "all_trackers", "}", "\n", "", "elif", "trackers", "==", "'pytracking'", ":", "\n", "            ", "trackers", "=", "{", "k", ":", "'all'", "for", "k", "in", "pytracking_results_link_dict", ".", "keys", "(", ")", "}", "\n", "", "elif", "trackers", "==", "'external'", ":", "\n", "            ", "trackers", "=", "{", "k", ":", "'all'", "for", "k", "in", "external_results_link_dict", ".", "keys", "(", ")", "}", "\n", "", "elif", "trackers", "in", "pytracking_results_link_dict", "or", "trackers", "in", "external_results_link_dict", ":", "\n", "            ", "trackers", "=", "{", "trackers", ":", "'all'", "}", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'tracker_list must be set to '", "'all'", "', a tracker name, or be a dict'", ")", "\n", "", "", "elif", "isinstance", "(", "trackers", ",", "dict", ")", ":", "\n", "        ", "pass", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'tracker_list must be set to '", "'all'", "', or be a dict'", ")", "\n", "\n", "", "common_link_dict", "=", "pytracking_results_link_dict", "\n", "for", "k", ",", "v", "in", "external_results_link_dict", ".", "items", "(", ")", ":", "\n", "        ", "common_link_dict", "[", "k", "]", "=", "v", "\n", "\n", "", "for", "trk", ",", "runfiles", "in", "trackers", ".", "items", "(", ")", ":", "\n", "        ", "trk_path", "=", "os", ".", "path", ".", "join", "(", "download_path", ",", "trk", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "trk_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "trk_path", ")", "\n", "\n", "", "if", "runfiles", "==", "'all'", ":", "\n", "            ", "for", "params", ",", "fileid", "in", "common_link_dict", "[", "trk", "]", ".", "items", "(", ")", ":", "\n", "                ", "print", "(", "'Downloading: {}/{}'", ".", "format", "(", "trk", ",", "params", ")", ")", "\n", "_download_file", "(", "fileid", ",", "os", ".", "path", ".", "join", "(", "trk_path", ",", "params", ")", ")", "\n", "", "", "elif", "isinstance", "(", "runfiles", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "for", "p", "in", "runfiles", ":", "\n", "                ", "for", "params", ",", "fileid", "in", "common_link_dict", "[", "trk", "]", ".", "items", "(", ")", ":", "\n", "                    ", "if", "re", ".", "match", "(", "r'{}(|_(\\d\\d\\d)).zip'", ".", "format", "(", "p", ")", ",", "params", ")", "is", "not", "None", ":", "\n", "                        ", "print", "(", "'Downloading: {}/{}'", ".", "format", "(", "trk", ",", "params", ")", ")", "\n", "_download_file", "(", "fileid", ",", "os", ".", "path", ".", "join", "(", "trk_path", ",", "params", ")", ")", "\n", "\n", "", "", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'tracker_list values must either be set to '", "'all'", "', or be a list of param names'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.download_results.unpack_tracking_results": [[183, 220], ["os.listdir", "os.path.exists", "os.makedirs", "os.listdir", "pytracking.evaluation.environment.env_settings", "os.path.join", "os.path.join", "shutil.unpack_archive", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["", "", "", "def", "unpack_tracking_results", "(", "download_path", ",", "output_path", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Unpacks zipped benchmark results. The directory 'download_path' should have the following structure\n    - root\n        - tracker1\n            - param1.zip\n            - param2.zip\n            .\n            .\n        - tracker2\n            - param1.zip\n            - param2.zip\n        .\n        .\n\n    args:\n        download_path - Path to the directory where the zipped results are stored\n        output_path - Path to the directory where the results will be unpacked. Set to env_settings().results_path\n                      by default\n    \"\"\"", "\n", "\n", "if", "output_path", "is", "None", ":", "\n", "        ", "output_path", "=", "env_settings", "(", ")", ".", "results_path", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_path", ")", "\n", "\n", "", "trackers", "=", "os", ".", "listdir", "(", "download_path", ")", "\n", "\n", "for", "t", "in", "trackers", ":", "\n", "        ", "runfiles", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "download_path", ",", "t", ")", ")", "\n", "\n", "for", "r", "in", "runfiles", ":", "\n", "            ", "save_path", "=", "os", ".", "path", ".", "join", "(", "output_path", ",", "t", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_path", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "save_path", ")", "\n", "", "shutil", ".", "unpack_archive", "(", "os", ".", "path", ".", "join", "(", "download_path", ",", "t", ",", "r", ")", ",", "os", ".", "path", ".", "join", "(", "save_path", ",", "r", "[", ":", "-", "4", "]", ")", ",", "'zip'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.download_results.main": [[222, 243], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "download_results.unpack_tracking_results", "download_results.download_results", "tempfile.gettempdir"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.download_results.unpack_tracking_results", "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.download_results.download_results"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Download and unpack zipped results'", ")", "\n", "parser", ".", "add_argument", "(", "'--tracker'", ",", "type", "=", "str", ",", "default", "=", "'pytracking'", ",", "\n", "help", "=", "'Name of tracker results to download, or \"pytracking\" (downloads results for PyTracking'", "\n", "' based trackers, or \"external\" (downloads results for external trackers) or \"all\"'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_path'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'Path to the directory where the results will be unpacked.'", ")", "\n", "parser", ".", "add_argument", "(", "'--temp_download_path'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "'Temporary path used for downloading the Zip files.'", ")", "\n", "parser", ".", "add_argument", "(", "'--download'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "\n", "help", "=", "'Whether to download results or unpack existing downloaded files.'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "download_path", "=", "args", ".", "temp_download_path", "\n", "if", "download_path", "is", "None", ":", "\n", "        ", "download_path", "=", "'{}/pytracking_results/'", ".", "format", "(", "tempfile", ".", "gettempdir", "(", ")", ")", "\n", "\n", "", "if", "args", ".", "download", ":", "\n", "        ", "download_results", "(", "download_path", ",", "args", ".", "tracker", ")", "\n", "\n", "", "unpack_tracking_results", "(", "download_path", ",", "args", ".", "output_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.pack_trackingnet_results.pack_trackingnet_results": [[8, 51], ["os.path.join", "pytracking.evaluation.datasets.get_dataset", "shutil.make_archive", "shutil.rmtree", "os.path.exists", "os.makedirs", "pytracking.evaluation.environment.env_settings", "numpy.loadtxt", "numpy.savetxt", "pytracking.evaluation.environment.env_settings"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.datasets.get_dataset", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "pack_trackingnet_results", "(", "tracker_name", ",", "param_name", ",", "run_id", "=", "None", ",", "output_name", "=", "None", ")", ":", "\n", "    ", "\"\"\" Packs trackingnet results into a zip folder which can be directly uploaded to the evaluation server. The packed\n    file is saved in the folder env_settings().tn_packed_results_path\n\n    args:\n        tracker_name - name of the tracker\n        param_name - name of the parameter file\n        run_id - run id for the tracker\n        output_name - name of the packed zip file\n    \"\"\"", "\n", "\n", "if", "output_name", "is", "None", ":", "\n", "        ", "if", "run_id", "is", "None", ":", "\n", "            ", "output_name", "=", "'{}_{}'", ".", "format", "(", "tracker_name", ",", "param_name", ")", "\n", "", "else", ":", "\n", "            ", "output_name", "=", "'{}_{}_{:03d}'", ".", "format", "(", "tracker_name", ",", "param_name", ",", "run_id", ")", "\n", "\n", "", "", "output_path", "=", "os", ".", "path", ".", "join", "(", "env_settings", "(", ")", ".", "tn_packed_results_path", ",", "output_name", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_path", ")", "\n", "\n", "", "results_path", "=", "env_settings", "(", ")", ".", "results_path", "\n", "\n", "tn_dataset", "=", "get_dataset", "(", "'trackingnet'", ")", "\n", "\n", "for", "seq", "in", "tn_dataset", ":", "\n", "        ", "seq_name", "=", "seq", ".", "name", "\n", "\n", "if", "run_id", "is", "None", ":", "\n", "            ", "seq_results_path", "=", "'{}/{}/{}/{}.txt'", ".", "format", "(", "results_path", ",", "tracker_name", ",", "param_name", ",", "seq_name", ")", "\n", "", "else", ":", "\n", "            ", "seq_results_path", "=", "'{}/{}/{}_{:03d}/{}.txt'", ".", "format", "(", "results_path", ",", "tracker_name", ",", "param_name", ",", "run_id", ",", "seq_name", ")", "\n", "\n", "", "results", "=", "np", ".", "loadtxt", "(", "seq_results_path", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "np", ".", "savetxt", "(", "'{}/{}.txt'", ".", "format", "(", "output_path", ",", "seq_name", ")", ",", "results", ",", "delimiter", "=", "','", ",", "fmt", "=", "'%.2f'", ")", "\n", "\n", "# Generate ZIP file", "\n", "", "shutil", ".", "make_archive", "(", "output_path", ",", "'zip'", ",", "output_path", ")", "\n", "\n", "# Remove raw text files", "\n", "shutil", ".", "rmtree", "(", "output_path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.util_scripts.pack_got10k_results.pack_got10k_results": [[7, 43], ["os.path.join", "range", "shutil.make_archive", "shutil.rmtree", "os.path.exists", "os.makedirs", "pytracking.evaluation.environment.env_settings", "range", "pytracking.evaluation.environment.env_settings", "os.path.exists", "os.makedirs", "numpy.loadtxt", "numpy.loadtxt", "numpy.savetxt", "numpy.savetxt"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "pack_got10k_results", "(", "tracker_name", ",", "param_name", ",", "output_name", ")", ":", "\n", "    ", "\"\"\" Packs got10k results into a zip folder which can be directly uploaded to the evaluation server. The packed\n    file is saved in the folder env_settings().got_packed_results_path\n\n    args:\n        tracker_name - name of the tracker\n        param_name - name of the parameter file\n        output_name - name of the packed zip file\n    \"\"\"", "\n", "output_path", "=", "os", ".", "path", ".", "join", "(", "env_settings", "(", ")", ".", "got_packed_results_path", ",", "output_name", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_path", ")", "\n", "\n", "", "results_path", "=", "env_settings", "(", ")", ".", "results_path", "\n", "for", "i", "in", "range", "(", "1", ",", "181", ")", ":", "\n", "        ", "seq_name", "=", "'GOT-10k_Test_{:06d}'", ".", "format", "(", "i", ")", "\n", "\n", "seq_output_path", "=", "'{}/{}'", ".", "format", "(", "output_path", ",", "seq_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "seq_output_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "seq_output_path", ")", "\n", "\n", "", "for", "run_id", "in", "range", "(", "3", ")", ":", "\n", "            ", "res", "=", "np", ".", "loadtxt", "(", "'{}/{}/{}_{:03d}/{}.txt'", ".", "format", "(", "results_path", ",", "tracker_name", ",", "param_name", ",", "run_id", ",", "seq_name", ")", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "times", "=", "np", ".", "loadtxt", "(", "\n", "'{}/{}/{}_{:03d}/{}_time.txt'", ".", "format", "(", "results_path", ",", "tracker_name", ",", "param_name", ",", "run_id", ",", "seq_name", ")", ",", "\n", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "np", ".", "savetxt", "(", "'{}/{}_{:03d}.txt'", ".", "format", "(", "seq_output_path", ",", "seq_name", ",", "run_id", "+", "1", ")", ",", "res", ",", "delimiter", "=", "','", ",", "fmt", "=", "'%f'", ")", "\n", "np", ".", "savetxt", "(", "'{}/{}_time.txt'", ".", "format", "(", "seq_output_path", ",", "seq_name", ")", ",", "times", ",", "fmt", "=", "'%f'", ")", "\n", "\n", "# Generate ZIP file", "\n", "", "", "shutil", ".", "make_archive", "(", "output_path", ",", "'zip'", ",", "output_path", ")", "\n", "\n", "# Remove raw text files", "\n", "shutil", ".", "rmtree", "(", "output_path", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.ltr.run_training.run_training": [[16, 40], ["cv2.setNumThreads", "print", "ltr.Settings", "importlib.import_module", "getattr", "getattr."], "function", ["None"], ["def", "run_training", "(", "train_module", ",", "train_name", ",", "cudnn_benchmark", "=", "True", ")", ":", "\n", "    ", "\"\"\"Run a train scripts in train_settings.\n    args:\n        train_module: Name of module in the \"train_settings/\" folder.\n        train_name: Name of the train settings file.\n        cudnn_benchmark: Use cudnn benchmark or not (default is True).\n    \"\"\"", "\n", "\n", "# This is needed to avoid strange crashes related to opencv", "\n", "cv", ".", "setNumThreads", "(", "0", ")", "\n", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "cudnn_benchmark", "\n", "\n", "print", "(", "'Training:  {}  {}'", ".", "format", "(", "train_module", ",", "train_name", ")", ")", "\n", "\n", "settings", "=", "ws_settings", ".", "Settings", "(", ")", "\n", "settings", ".", "module_name", "=", "train_module", "\n", "settings", ".", "script_name", "=", "train_name", "\n", "settings", ".", "project_path", "=", "'ltr/{}/{}'", ".", "format", "(", "train_module", ",", "train_name", ")", "\n", "\n", "expr_module", "=", "importlib", ".", "import_module", "(", "'ltr.train_settings.{}.{}'", ".", "format", "(", "train_module", ",", "train_name", ")", ")", "\n", "expr_func", "=", "getattr", "(", "expr_module", ",", "'run'", ")", "\n", "\n", "expr_func", "(", "settings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.ltr.run_training.main": [[42, 51], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "run_training.run_training"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.ltr.run_training.run_training"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Run a train scripts in train_settings.'", ")", "\n", "parser", ".", "add_argument", "(", "'train_module'", ",", "type", "=", "str", ",", "help", "=", "'Name of module in the \"train_settings/\" folder.'", ")", "\n", "parser", ".", "add_argument", "(", "'train_name'", ",", "type", "=", "str", ",", "help", "=", "'Name of the train settings file.'", ")", "\n", "parser", ".", "add_argument", "(", "'--cudnn_benchmark'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "help", "=", "'Set cudnn benchmark on (1) or off (0) (default is on).'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "run_training", "(", "args", ".", "train_module", ",", "args", ".", "train_name", ",", "args", ".", "cudnn_benchmark", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_gmm_sampl.run": [[11, 97], ["ltr.dataset.Lasot", "ltr.dataset.Got10k", "ltr.dataset.TrackingNet", "ltr.dataset.MSCOCOSeq", "ltr.dataset.Got10k", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.ATOMProcessing", "ltr.data.processing.ATOMProcessing", "ltr.data.sampler.ATOMSampler", "ltr.data.LTRLoader", "ltr.data.sampler.ATOMSampler", "ltr.data.LTRLoader", "ltr.atom_resnet18", "torch.MSELoss", "ltr.actors.AtomActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "actors.AtomActor.net.bb_regressor.parameters", "list", "range"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.atom_resnet18", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["params", ".", "visualization", "=", "False", "# Do visualization", "\n", "\n", "# Use GPU or not (IoUNet requires this to be True)", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "# Feature specific parameters", "\n", "deep_params", "=", "TrackerParams", "(", ")", "\n", "\n", "# Patch sampling parameters", "\n", "params", ".", "max_image_sample_size", "=", "(", "18", "*", "16", ")", "**", "2", "# Maximum image sample size", "\n", "params", ".", "min_image_sample_size", "=", "(", "18", "*", "16", ")", "**", "2", "# Minimum image sample size", "\n", "params", ".", "search_area_scale", "=", "5", "# Scale relative to target size", "\n", "params", ".", "feature_size_odd", "=", "False", "# Good to use False for even-sized kernels and vice versa", "\n", "\n", "# Optimization parameters", "\n", "params", ".", "CG_iter", "=", "5", "# The number of Conjugate Gradient iterations in each update after the first frame", "\n", "params", ".", "init_CG_iter", "=", "60", "# The total number of Conjugate Gradient iterations used in the first frame", "\n", "params", ".", "init_GN_iter", "=", "6", "# The number of Gauss-Newton iterations used in the first frame (only if the projection matrix is updated)", "\n", "params", ".", "post_init_CG_iter", "=", "0", "# CG iterations to run after GN", "\n", "params", ".", "fletcher_reeves", "=", "False", "# Use the Fletcher-Reeves (true) or Polak-Ribiere (false) formula in the Conjugate Gradient", "\n", "params", ".", "standard_alpha", "=", "True", "# Use the standard formula for computing the step length in Conjugate Gradient", "\n", "params", ".", "CG_forgetting_rate", "=", "None", "# Forgetting rate of the last conjugate direction", "\n", "\n", "# Learning parameters for each feature type", "\n", "deep_params", ".", "learning_rate", "=", "0.01", "# Learning rate", "\n", "deep_params", ".", "init_samples_minimum_weight", "=", "0.25", "# Minimum weight of initial samples in memory", "\n", "deep_params", ".", "output_sigma_factor", "=", "1", "/", "4", "# Standard deviation of Gaussian label relative to target size", "\n", "\n", "# Training parameters", "\n", "params", ".", "sample_memory_size", "=", "250", "# Memory size", "\n", "params", ".", "train_skipping", "=", "10", "# How often to run training (every n-th frame)", "\n", "\n", "# Online model parameters", "\n", "deep_params", ".", "kernel_size", "=", "(", "4", ",", "4", ")", "# Kernel size of filter", "\n", "deep_params", ".", "compressed_dim", "=", "64", "# Dimension output of projection matrix", "\n", "deep_params", ".", "filter_reg", "=", "1e-1", "# Filter regularization factor", "\n", "deep_params", ".", "projection_reg", "=", "1e-4", "# Projection regularization factor", "\n", "\n", "# Windowing", "\n", "params", ".", "feature_window", "=", "False", "# Perform windowing of features", "\n", "params", ".", "window_output", "=", "False", "# Perform windowing of output scores", "\n", "\n", "# Detection parameters", "\n", "params", ".", "scale_factors", "=", "torch", ".", "ones", "(", "1", ")", "# What scales to use for localization (only one scale if IoUNet is used)", "\n", "params", ".", "score_upsample_factor", "=", "1", "# How much Fourier upsampling to use", "\n", "\n", "# Init data augmentation parameters", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "# How much to expand sample when doing augmentation", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "# How much random shift to do on each augmented sample", "\n", "deep_params", ".", "use_augmentation", "=", "True", "# Whether to use augmentation for this feature", "\n", "\n", "# Factorized convolution parameters", "\n", "# params.use_projection_matrix = True       # Use projection matrix, i.e. use the factorized convolution formulation", "\n", "params", ".", "update_projection_matrix", "=", "True", "# Whether the projection matrix should be optimized or not", "\n", "params", ".", "proj_init_method", "=", "'randn'", "# Method for initializing the projection matrix", "\n", "params", ".", "filter_init_method", "=", "'randn'", "# Method for initializing the spatial filter", "\n", "params", ".", "projection_activation", "=", "'none'", "# Activation function after projection ('none', 'relu', 'elu' or 'mlu')", "\n", "params", ".", "response_activation", "=", "(", "'mlu'", ",", "0.05", ")", "# Activation function on the output scores ('none', 'relu', 'elu' or 'mlu')", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "# Use this or not", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "# Absolute score threshold to detect target missing", "\n", "params", ".", "distractor_threshold", "=", "0.8", "# Relative threshold to find distractors", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "# Relative threshold to find hard negative samples", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "# Target neighborhood to remove", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "# Dispacement to consider for distractors", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "# Learning rate if hard negative detected", "\n", "params", ".", "hard_negative_CG_iter", "=", "5", "# Number of optimization iterations to use if hard negative detected", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "# Update scale or not if distractor is close", "\n", "\n", "# IoUNet parameters", "\n", "params", ".", "use_iou_net", "=", "True", "# Use IoU net or not", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "(", "1e-2", ",", "5e-2", ")", "# 1   # Gradient step length in the bounding box refinement 5e-3 2e-2", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_paper.run": [[11, 95], ["ltr.dataset.Lasot", "ltr.dataset.TrackingNet", "ltr.dataset.MSCOCOSeq", "ltr.dataset.TrackingNet", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.ATOMProcessing", "ltr.data.processing.ATOMProcessing", "ltr.data.sampler.ATOMSampler", "ltr.data.LTRLoader", "ltr.data.sampler.ATOMSampler", "ltr.data.LTRLoader", "ltr.atom_resnet18", "torch.MSELoss", "ltr.actors.AtomActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "actors.AtomActor.net.bb_regressor.parameters", "list", "list", "range", "range"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.atom_resnet18", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["def", "run", "(", "settings", ")", ":", "\n", "# Most common settings are assigned in the settings struct", "\n", "    ", "settings", ".", "description", "=", "'ATOM IoUNet with default settings according to the paper.'", "\n", "settings", ".", "batch_size", "=", "64", "\n", "settings", ".", "num_workers", "=", "8", "\n", "settings", ".", "print_interval", "=", "1", "\n", "settings", ".", "normalize_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "settings", ".", "normalize_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "settings", ".", "search_area_factor", "=", "5.0", "\n", "settings", ".", "feature_sz", "=", "18", "\n", "settings", ".", "output_sz", "=", "settings", ".", "feature_sz", "*", "16", "\n", "settings", ".", "center_jitter_factor", "=", "{", "'train'", ":", "0", ",", "'test'", ":", "4.5", "}", "\n", "settings", ".", "scale_jitter_factor", "=", "{", "'train'", ":", "0", ",", "'test'", ":", "0.5", "}", "\n", "\n", "# Train datasets", "\n", "lasot_train", "=", "Lasot", "(", "settings", ".", "env", ".", "lasot_dir", ",", "split", "=", "'train'", ")", "\n", "trackingnet_train", "=", "TrackingNet", "(", "settings", ".", "env", ".", "trackingnet_dir", ",", "set_ids", "=", "list", "(", "range", "(", "11", ")", ")", ")", "\n", "coco_train", "=", "MSCOCOSeq", "(", "settings", ".", "env", ".", "coco_dir", ")", "\n", "\n", "# Validation datasets", "\n", "trackingnet_val", "=", "TrackingNet", "(", "settings", ".", "env", ".", "trackingnet_dir", ",", "set_ids", "=", "list", "(", "range", "(", "11", ",", "12", ")", ")", ")", "\n", "\n", "# The joint augmentation transform, that is applied to the pairs jointly", "\n", "transform_joint", "=", "tfm", ".", "Transform", "(", "tfm", ".", "ToGrayscale", "(", "probability", "=", "0.05", ")", ")", "\n", "\n", "# The augmentation transform applied to the training set (individually to each image in the pair)", "\n", "transform_train", "=", "tfm", ".", "Transform", "(", "tfm", ".", "ToTensorAndJitter", "(", "0.2", ")", ",", "\n", "tfm", ".", "Normalize", "(", "mean", "=", "settings", ".", "normalize_mean", ",", "std", "=", "settings", ".", "normalize_std", ")", ")", "\n", "\n", "# The augmentation transform applied to the validation set (individually to each image in the pair)", "\n", "transform_val", "=", "tfm", ".", "Transform", "(", "tfm", ".", "ToTensor", "(", ")", ",", "\n", "tfm", ".", "Normalize", "(", "mean", "=", "settings", ".", "normalize_mean", ",", "std", "=", "settings", ".", "normalize_std", ")", ")", "\n", "\n", "# Data processing to do on the training pairs", "\n", "proposal_params", "=", "{", "'min_iou'", ":", "0.1", ",", "'boxes_per_frame'", ":", "16", ",", "'sigma_factor'", ":", "[", "0.01", ",", "0.05", ",", "0.1", ",", "0.2", ",", "0.3", "]", "}", "\n", "data_processing_train", "=", "processing", ".", "ATOMProcessing", "(", "search_area_factor", "=", "settings", ".", "search_area_factor", ",", "\n", "output_sz", "=", "settings", ".", "output_sz", ",", "\n", "center_jitter_factor", "=", "settings", ".", "center_jitter_factor", ",", "\n", "scale_jitter_factor", "=", "settings", ".", "scale_jitter_factor", ",", "\n", "mode", "=", "'sequence'", ",", "\n", "proposal_params", "=", "proposal_params", ",", "\n", "transform", "=", "transform_train", ",", "\n", "joint_transform", "=", "transform_joint", ")", "\n", "\n", "# Data processing to do on the validation pairs", "\n", "data_processing_val", "=", "processing", ".", "ATOMProcessing", "(", "search_area_factor", "=", "settings", ".", "search_area_factor", ",", "\n", "output_sz", "=", "settings", ".", "output_sz", ",", "\n", "center_jitter_factor", "=", "settings", ".", "center_jitter_factor", ",", "\n", "scale_jitter_factor", "=", "settings", ".", "scale_jitter_factor", ",", "\n", "mode", "=", "'sequence'", ",", "\n", "proposal_params", "=", "proposal_params", ",", "\n", "transform", "=", "transform_val", ",", "\n", "joint_transform", "=", "transform_joint", ")", "\n", "\n", "# The sampler for training", "\n", "dataset_train", "=", "sampler", ".", "ATOMSampler", "(", "[", "lasot_train", ",", "trackingnet_train", ",", "coco_train", "]", ",", "[", "1", ",", "1", ",", "1", "]", ",", "\n", "samples_per_epoch", "=", "1000", "*", "settings", ".", "batch_size", ",", "max_gap", "=", "50", ",", "processing", "=", "data_processing_train", ")", "\n", "\n", "# The loader for training", "\n", "loader_train", "=", "LTRLoader", "(", "'train'", ",", "dataset_train", ",", "training", "=", "True", ",", "batch_size", "=", "settings", ".", "batch_size", ",", "num_workers", "=", "settings", ".", "num_workers", ",", "\n", "shuffle", "=", "True", ",", "drop_last", "=", "True", ",", "stack_dim", "=", "1", ")", "\n", "\n", "# The sampler for validation", "\n", "dataset_val", "=", "sampler", ".", "ATOMSampler", "(", "[", "trackingnet_val", "]", ",", "[", "1", "]", ",", "samples_per_epoch", "=", "500", "*", "settings", ".", "batch_size", ",", "max_gap", "=", "50", ",", "\n", "processing", "=", "data_processing_val", ")", "\n", "\n", "# The loader for validation", "\n", "loader_val", "=", "LTRLoader", "(", "'val'", ",", "dataset_val", ",", "training", "=", "False", ",", "batch_size", "=", "settings", ".", "batch_size", ",", "num_workers", "=", "settings", ".", "num_workers", ",", "\n", "shuffle", "=", "False", ",", "drop_last", "=", "True", ",", "epoch_interval", "=", "5", ",", "stack_dim", "=", "1", ")", "\n", "\n", "# Create network and actor", "\n", "net", "=", "atom_models", ".", "atom_resnet18", "(", "backbone_pretrained", "=", "True", ")", "\n", "objective", "=", "nn", ".", "MSELoss", "(", ")", "\n", "actor", "=", "actors", ".", "AtomActor", "(", "net", "=", "net", ",", "objective", "=", "objective", ")", "\n", "\n", "# Optimizer", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "actor", ".", "net", ".", "bb_regressor", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "lr_scheduler", "=", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "optimizer", ",", "step_size", "=", "15", ",", "gamma", "=", "0.2", ")", "\n", "\n", "# Create trainer", "\n", "trainer", "=", "LTRTrainer", "(", "actor", ",", "[", "loader_train", ",", "loader_val", "]", ",", "optimizer", ",", "settings", ",", "lr_scheduler", ")", "\n", "\n", "# Run training (set fail_safe=False if you are debugging)", "\n", "trainer", ".", "train", "(", "50", ",", "load_latest", "=", "True", ",", "fail_safe", "=", "True", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_prob_ml.run": [[11, 98], ["ltr.dataset.Lasot", "ltr.dataset.Got10k", "ltr.dataset.TrackingNet", "ltr.dataset.MSCOCOSeq", "ltr.dataset.Got10k", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.KLBBregProcessing", "ltr.data.processing.KLBBregProcessing", "ltr.data.sampler.ATOMSampler", "ltr.data.LTRLoader", "ltr.data.sampler.ATOMSampler", "ltr.data.LTRLoader", "ltr.atom_resnet18", "ltr.MLRegression", "ltr.AtomBBKLActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "bbreg_actors.AtomBBKLActor.net.bb_regressor.parameters", "list", "range"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.atom_resnet18", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["params", ".", "visualization", "=", "False", "# Do visualization", "\n", "\n", "# Use GPU or not (IoUNet requires this to be True)", "\n", "params", ".", "use_gpu", "=", "True", "\n", "\n", "# Feature specific parameters", "\n", "deep_params", "=", "TrackerParams", "(", ")", "\n", "\n", "# Patch sampling parameters", "\n", "params", ".", "max_image_sample_size", "=", "(", "18", "*", "16", ")", "**", "2", "# Maximum image sample size", "\n", "params", ".", "min_image_sample_size", "=", "(", "18", "*", "16", ")", "**", "2", "# Minimum image sample size", "\n", "params", ".", "search_area_scale", "=", "5", "# Scale relative to target size", "\n", "params", ".", "feature_size_odd", "=", "False", "# Good to use False for even-sized kernels and vice versa", "\n", "\n", "# Optimization parameters", "\n", "params", ".", "CG_iter", "=", "5", "# The number of Conjugate Gradient iterations in each update after the first frame", "\n", "params", ".", "init_CG_iter", "=", "60", "# The total number of Conjugate Gradient iterations used in the first frame", "\n", "params", ".", "init_GN_iter", "=", "6", "# The number of Gauss-Newton iterations used in the first frame (only if the projection matrix is updated)", "\n", "params", ".", "post_init_CG_iter", "=", "0", "# CG iterations to run after GN", "\n", "params", ".", "fletcher_reeves", "=", "False", "# Use the Fletcher-Reeves (true) or Polak-Ribiere (false) formula in the Conjugate Gradient", "\n", "params", ".", "standard_alpha", "=", "True", "# Use the standard formula for computing the step length in Conjugate Gradient", "\n", "params", ".", "CG_forgetting_rate", "=", "None", "# Forgetting rate of the last conjugate direction", "\n", "\n", "# Learning parameters for each feature type", "\n", "deep_params", ".", "learning_rate", "=", "0.01", "# Learning rate", "\n", "deep_params", ".", "init_samples_minimum_weight", "=", "0.25", "# Minimum weight of initial samples in memory", "\n", "deep_params", ".", "output_sigma_factor", "=", "1", "/", "4", "# Standard deviation of Gaussian label relative to target size", "\n", "\n", "# Training parameters", "\n", "params", ".", "sample_memory_size", "=", "250", "# Memory size", "\n", "params", ".", "train_skipping", "=", "10", "# How often to run training (every n-th frame)", "\n", "\n", "# Online model parameters", "\n", "deep_params", ".", "kernel_size", "=", "(", "4", ",", "4", ")", "# Kernel size of filter", "\n", "deep_params", ".", "compressed_dim", "=", "64", "# Dimension output of projection matrix", "\n", "deep_params", ".", "filter_reg", "=", "1e-1", "# Filter regularization factor", "\n", "deep_params", ".", "projection_reg", "=", "1e-4", "# Projection regularization factor", "\n", "\n", "# Windowing", "\n", "params", ".", "feature_window", "=", "False", "# Perform windowing of features", "\n", "params", ".", "window_output", "=", "False", "# Perform windowing of output scores", "\n", "\n", "# Detection parameters", "\n", "params", ".", "scale_factors", "=", "torch", ".", "ones", "(", "1", ")", "# What scales to use for localization (only one scale if IoUNet is used)", "\n", "params", ".", "score_upsample_factor", "=", "1", "# How much Fourier upsampling to use", "\n", "\n", "# Init data augmentation parameters", "\n", "params", ".", "augmentation", "=", "{", "'fliplr'", ":", "True", ",", "\n", "'rotate'", ":", "[", "5", ",", "-", "5", ",", "10", ",", "-", "10", ",", "20", ",", "-", "20", ",", "30", ",", "-", "30", ",", "45", ",", "-", "45", ",", "-", "60", ",", "60", "]", ",", "\n", "'blur'", ":", "[", "(", "2", ",", "0.2", ")", ",", "(", "0.2", ",", "2", ")", ",", "(", "3", ",", "1", ")", ",", "(", "1", ",", "3", ")", ",", "(", "2", ",", "2", ")", "]", ",", "\n", "'relativeshift'", ":", "[", "(", "0.6", ",", "0.6", ")", ",", "(", "-", "0.6", ",", "0.6", ")", ",", "(", "0.6", ",", "-", "0.6", ")", ",", "(", "-", "0.6", ",", "-", "0.6", ")", "]", ",", "\n", "'dropout'", ":", "(", "7", ",", "0.2", ")", "}", "\n", "\n", "params", ".", "augmentation_expansion_factor", "=", "2", "# How much to expand sample when doing augmentation", "\n", "params", ".", "random_shift_factor", "=", "1", "/", "3", "# How much random shift to do on each augmented sample", "\n", "deep_params", ".", "use_augmentation", "=", "True", "# Whether to use augmentation for this feature", "\n", "\n", "# Factorized convolution parameters", "\n", "# params.use_projection_matrix = True       # Use projection matrix, i.e. use the factorized convolution formulation", "\n", "params", ".", "update_projection_matrix", "=", "True", "# Whether the projection matrix should be optimized or not", "\n", "params", ".", "proj_init_method", "=", "'randn'", "# Method for initializing the projection matrix", "\n", "params", ".", "filter_init_method", "=", "'randn'", "# Method for initializing the spatial filter", "\n", "params", ".", "projection_activation", "=", "'none'", "# Activation function after projection ('none', 'relu', 'elu' or 'mlu')", "\n", "params", ".", "response_activation", "=", "(", "'mlu'", ",", "0.05", ")", "# Activation function on the output scores ('none', 'relu', 'elu' or 'mlu')", "\n", "\n", "# Advanced localization parameters", "\n", "params", ".", "advanced_localization", "=", "True", "# Use this or not", "\n", "params", ".", "target_not_found_threshold", "=", "0.25", "# Absolute score threshold to detect target missing", "\n", "params", ".", "distractor_threshold", "=", "0.8", "# Relative threshold to find distractors", "\n", "params", ".", "hard_negative_threshold", "=", "0.5", "# Relative threshold to find hard negative samples", "\n", "params", ".", "target_neighborhood_scale", "=", "2.2", "# Target neighborhood to remove", "\n", "params", ".", "dispalcement_scale", "=", "0.8", "# Dispacement to consider for distractors", "\n", "params", ".", "hard_negative_learning_rate", "=", "0.02", "# Learning rate if hard negative detected", "\n", "params", ".", "hard_negative_CG_iter", "=", "5", "# Number of optimization iterations to use if hard negative detected", "\n", "params", ".", "update_scale_when_uncertain", "=", "True", "# Update scale or not if distractor is close", "\n", "\n", "# IoUNet parameters", "\n", "params", ".", "use_iou_net", "=", "True", "# Use IoU net or not", "\n", "params", ".", "box_refinement_space", "=", "'relative'", "\n", "params", ".", "iounet_augmentation", "=", "False", "# Use the augmented samples to compute the modulation vector", "\n", "params", ".", "iounet_k", "=", "3", "# Top-k average to estimate final box", "\n", "params", ".", "num_init_random_boxes", "=", "9", "# Num extra random boxes in addition to the classifier prediction", "\n", "params", ".", "box_jitter_pos", "=", "0.1", "# How much to jitter the translation for random boxes", "\n", "params", ".", "box_jitter_sz", "=", "0.5", "# How much to jitter the scale for random boxes", "\n", "params", ".", "maximal_aspect_ratio", "=", "6", "# Limit on the aspect ratio", "\n", "params", ".", "box_refinement_iter", "=", "10", "# Number of iterations for refining the boxes", "\n", "params", ".", "box_refinement_step_length", "=", "(", "2e-4", ",", "10e-4", ")", "# 1   # Gradient step length in the bounding box refinement", "\n", "params", ".", "box_refinement_step_decay", "=", "1", "# Multiplicative step length decay (1 means no decay)", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.run": [[11, 96], ["ltr.dataset.Lasot", "ltr.dataset.Got10k", "ltr.dataset.TrackingNet", "ltr.dataset.MSCOCOSeq", "ltr.dataset.Got10k", "ltr.Transform", "ltr.Transform", "ltr.Transform", "ltr.data.processing.ATOMProcessing", "ltr.data.processing.ATOMProcessing", "ltr.data.sampler.ATOMSampler", "ltr.data.LTRLoader", "ltr.data.sampler.ATOMSampler", "ltr.data.LTRLoader", "ltr.atom_resnet18", "torch.MSELoss", "ltr.actors.AtomActor", "torch.Adam", "torch.lr_scheduler.StepLR", "ltr.trainers.LTRTrainer", "ltr.trainers.LTRTrainer.train", "ltr.ToGrayscale", "ltr.ToTensorAndJitter", "ltr.Normalize", "ltr.ToTensor", "ltr.Normalize", "actors.AtomActor.net.bb_regressor.parameters", "list", "range"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.atom_resnet18", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["from", ".", "optim", "import", "ConvProblem", ",", "FactorizedConvProblem", "\n", "from", "pytracking", ".", "features", "import", "augmentation", "\n", "import", "ltr", ".", "data", ".", "bounding_box_utils", "as", "bbutils", "\n", "\n", "\n", "class", "ATOM", "(", "BaseTracker", ")", ":", "\n", "\n", "    ", "multiobj_mode", "=", "'parallel'", "\n", "\n", "def", "initialize_features", "(", "self", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "self", ",", "'features_initialized'", ",", "False", ")", ":", "\n", "            ", "self", ".", "params", ".", "features", ".", "initialize", "(", ")", "\n", "", "self", ".", "features_initialized", "=", "True", "\n", "\n", "\n", "", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "        ", "state", "=", "info", "[", "'init_bbox'", "]", "\n", "\n", "# Initialize some stuff", "\n", "self", ".", "frame_num", "=", "1", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'device'", ")", ":", "\n", "            ", "self", ".", "params", ".", "device", "=", "'cuda'", "if", "self", ".", "params", ".", "use_gpu", "else", "'cpu'", "\n", "\n", "# Initialize features", "\n", "", "self", ".", "initialize_features", "(", ")", "\n", "\n", "# Check if image is color", "\n", "self", ".", "params", ".", "features", ".", "set_is_color", "(", "image", ".", "shape", "[", "2", "]", "==", "3", ")", "\n", "\n", "# Get feature specific params", "\n", "self", ".", "fparams", "=", "self", ".", "params", ".", "features", ".", "get_fparams", "(", "'feature_params'", ")", "\n", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Get position and size", "\n", "self", ".", "pos", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "1", "]", "+", "(", "state", "[", "3", "]", "-", "1", ")", "/", "2", ",", "state", "[", "0", "]", "+", "(", "state", "[", "2", "]", "-", "1", ")", "/", "2", "]", ")", "\n", "self", ".", "target_sz", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "3", "]", ",", "state", "[", "2", "]", "]", ")", "\n", "\n", "# Set search area", "\n", "self", ".", "target_scale", "=", "1.0", "\n", "search_area", "=", "torch", ".", "prod", "(", "self", ".", "target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ".", "item", "(", ")", "\n", "if", "search_area", ">", "self", ".", "params", ".", "max_image_sample_size", ":", "\n", "            ", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", "/", "self", ".", "params", ".", "max_image_sample_size", ")", "\n", "", "elif", "search_area", "<", "self", ".", "params", ".", "min_image_sample_size", ":", "\n", "            ", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", "/", "self", ".", "params", ".", "min_image_sample_size", ")", "\n", "\n", "# Check if IoUNet is used", "\n", "", "self", ".", "use_iou_net", "=", "self", ".", "params", ".", "get", "(", "'use_iou_net'", ",", "True", ")", "\n", "\n", "# Target size in base scale", "\n", "self", ".", "base_target_sz", "=", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "\n", "# Use odd square search area and set sizes", "\n", "feat_max_stride", "=", "max", "(", "self", ".", "params", ".", "features", ".", "stride", "(", ")", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'search_area_shape'", ",", "'square'", ")", "==", "'square'", ":", "\n", "            ", "self", ".", "img_sample_sz", "=", "torch", ".", "round", "(", "torch", ".", "sqrt", "(", "torch", ".", "prod", "(", "self", ".", "base_target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ")", ")", "*", "torch", ".", "ones", "(", "2", ")", "\n", "", "elif", "self", ".", "params", ".", "search_area_shape", "==", "'initrect'", ":", "\n", "            ", "self", ".", "img_sample_sz", "=", "torch", ".", "round", "(", "self", ".", "base_target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown search area shape'", ")", "\n", "", "if", "self", ".", "params", ".", "feature_size_odd", ":", "\n", "            ", "self", ".", "img_sample_sz", "+=", "feat_max_stride", "-", "self", ".", "img_sample_sz", "%", "(", "2", "*", "feat_max_stride", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "img_sample_sz", "+=", "feat_max_stride", "-", "(", "self", ".", "img_sample_sz", "+", "feat_max_stride", ")", "%", "(", "2", "*", "feat_max_stride", ")", "\n", "\n", "# Set sizes", "\n", "", "self", ".", "img_support_sz", "=", "self", ".", "img_sample_sz", "\n", "self", ".", "feature_sz", "=", "self", ".", "params", ".", "features", ".", "size", "(", "self", ".", "img_sample_sz", ")", "\n", "self", ".", "output_sz", "=", "self", ".", "params", ".", "score_upsample_factor", "*", "self", ".", "img_support_sz", "# Interpolated size of the output", "\n", "self", ".", "kernel_size", "=", "self", ".", "fparams", ".", "attribute", "(", "'kernel_size'", ")", "\n", "\n", "self", ".", "iou_img_sample_sz", "=", "self", ".", "img_sample_sz", "\n", "\n", "# Optimization options", "\n", "self", ".", "params", ".", "precond_learning_rate", "=", "self", ".", "fparams", ".", "attribute", "(", "'learning_rate'", ")", "\n", "if", "self", ".", "params", ".", "CG_forgetting_rate", "is", "None", "or", "max", "(", "self", ".", "params", ".", "precond_learning_rate", ")", ">=", "1", ":", "\n", "            ", "self", ".", "params", ".", "direction_forget_factor", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "params", ".", "direction_forget_factor", "=", "(", "1", "-", "max", "(", "self", ".", "params", ".", "precond_learning_rate", ")", ")", "**", "self", ".", "params", ".", "CG_forgetting_rate", "\n", "\n", "", "self", ".", "output_window", "=", "None", "\n", "if", "self", ".", "params", ".", "get", "(", "'window_output'", ",", "False", ")", ":", "\n", "            ", "if", "self", ".", "params", ".", "get", "(", "'use_clipped_window'", ",", "False", ")", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d_clipped", "(", "self", ".", "output_sz", ".", "long", "(", ")", ",", "self", ".", "output_sz", ".", "long", "(", ")", "*", "self", ".", "params", ".", "effective_search_area", "/", "self", ".", "params", ".", "search_area_scale", ",", "centered", "=", "False", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "output_window", "=", "dcf", ".", "hann2d", "(", "self", ".", "output_sz", ".", "long", "(", ")", ",", "centered", "=", "False", ")", ".", "to", "(", "self", ".", "params", ".", "device", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.__init__": [[23, 65], ["torch.Module.__init__", "atom_iou_net.conv", "atom_iou_net.conv", "atom_iou_net.conv", "ltr.external.PreciseRoIPooling.pytorch.prroi_pool.PrRoIPool2D", "ltr.external.PreciseRoIPooling.pytorch.prroi_pool.PrRoIPool2D", "atom_iou_net.conv", "atom_iou_net.conv", "atom_iou_net.conv", "atom_iou_net.conv", "ltr.external.PreciseRoIPooling.pytorch.prroi_pool.PrRoIPool2D", "ltr.external.PreciseRoIPooling.pytorch.prroi_pool.PrRoIPool2D", "atom_iou_net.conv", "atom_iou_net.conv", "ltr.models.layers.blocks.LinearBlock", "ltr.models.layers.blocks.LinearBlock", "torch.Linear", "torch.Linear", "atom_iou_net.AtomIoUNet.modules", "isinstance", "isinstance", "isinstance", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "m.bias.data.zero_", "m.weight.data.uniform_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv"], ["def", "__init__", "(", "self", ",", "input_dim", "=", "(", "128", ",", "256", ")", ",", "pred_input_dim", "=", "(", "256", ",", "256", ")", ",", "pred_inter_dim", "=", "(", "256", ",", "256", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# _r for reference, _t for test", "\n", "self", ".", "conv3_1r", "=", "conv", "(", "input_dim", "[", "0", "]", ",", "128", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "self", ".", "conv3_1t", "=", "conv", "(", "input_dim", "[", "0", "]", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "conv3_2t", "=", "conv", "(", "256", ",", "pred_input_dim", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "prroi_pool3r", "=", "PrRoIPool2D", "(", "3", ",", "3", ",", "1", "/", "8", ")", "\n", "self", ".", "prroi_pool3t", "=", "PrRoIPool2D", "(", "5", ",", "5", ",", "1", "/", "8", ")", "\n", "\n", "self", ".", "fc3_1r", "=", "conv", "(", "128", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "\n", "self", ".", "conv4_1r", "=", "conv", "(", "input_dim", "[", "1", "]", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "self", ".", "conv4_1t", "=", "conv", "(", "input_dim", "[", "1", "]", ",", "256", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "conv4_2t", "=", "conv", "(", "256", ",", "pred_input_dim", "[", "1", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", "\n", "\n", "self", ".", "prroi_pool4r", "=", "PrRoIPool2D", "(", "1", ",", "1", ",", "1", "/", "16", ")", "\n", "self", ".", "prroi_pool4t", "=", "PrRoIPool2D", "(", "3", ",", "3", ",", "1", "/", "16", ")", "\n", "\n", "self", ".", "fc34_3r", "=", "conv", "(", "256", "+", "256", ",", "pred_input_dim", "[", "0", "]", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "self", ".", "fc34_4r", "=", "conv", "(", "256", "+", "256", ",", "pred_input_dim", "[", "1", "]", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "\n", "self", ".", "fc3_rt", "=", "LinearBlock", "(", "pred_input_dim", "[", "0", "]", ",", "pred_inter_dim", "[", "0", "]", ",", "5", ")", "\n", "self", ".", "fc4_rt", "=", "LinearBlock", "(", "pred_input_dim", "[", "1", "]", ",", "pred_inter_dim", "[", "1", "]", ",", "3", ")", "\n", "\n", "self", ".", "iou_predictor", "=", "nn", ".", "Linear", "(", "pred_inter_dim", "[", "0", "]", "+", "pred_inter_dim", "[", "1", "]", ",", "1", ",", "bias", "=", "True", ")", "\n", "\n", "# Init weights", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "ConvTranspose2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ".", "data", ",", "mode", "=", "'fan_in'", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "# In earlier versions batch norm parameters was initialized with default initialization,", "\n", "# which changed in pytorch 1.2. In 1.1 and earlier the weight was set to U(0,1).", "\n", "# So we use the same initialization here.", "\n", "# m.weight.data.fill_(1)", "\n", "                ", "m", ".", "weight", ".", "data", ".", "uniform_", "(", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.forward": [[66, 95], ["atom_iou_net.AtomIoUNet.get_modulation", "atom_iou_net.AtomIoUNet.get_iou_feat", "proposals2.reshape.reshape.reshape", "atom_iou_net.AtomIoUNet.predict_iou", "atom_iou_net.AtomIoUNet.reshape", "bb1.dim", "proposals2.reshape.reshape.dim", "f.reshape().repeat().reshape", "f.dim", "f.reshape", "f.reshape().repeat", "f.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_modulation", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_iou_feat", "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "", "", "def", "forward", "(", "self", ",", "feat1", ",", "feat2", ",", "bb1", ",", "proposals2", ")", ":", "\n", "        ", "\"\"\"Runs the ATOM IoUNet during training operation.\n        This forward pass is mainly used for training. Call the individual functions during tracking instead.\n        args:\n            feat1:  Features from the reference frames (4 or 5 dims).\n            feat2:  Features from the test frames (4 or 5 dims).\n            bb1:  Target boxes (x,y,w,h) in image coords in the reference samples. Dims (images, sequences, 4).\n            proposals2:  Proposal boxes for which the IoU will be predicted (images, sequences, num_proposals, 4).\"\"\"", "\n", "\n", "assert", "bb1", ".", "dim", "(", ")", "==", "3", "\n", "assert", "proposals2", ".", "dim", "(", ")", "==", "4", "\n", "\n", "num_images", "=", "proposals2", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "proposals2", ".", "shape", "[", "1", "]", "\n", "\n", "# Extract first train sample", "\n", "feat1", "=", "[", "f", "[", "0", ",", "...", "]", "if", "f", ".", "dim", "(", ")", "==", "5", "else", "f", ".", "reshape", "(", "-", "1", ",", "num_sequences", ",", "*", "f", ".", "shape", "[", "-", "3", ":", "]", ")", "[", "0", ",", "...", "]", "for", "f", "in", "feat1", "]", "\n", "bb1", "=", "bb1", "[", "0", ",", "...", "]", "\n", "\n", "# Get modulation vector", "\n", "modulation", "=", "self", ".", "get_modulation", "(", "feat1", ",", "bb1", ")", "\n", "\n", "iou_feat", "=", "self", ".", "get_iou_feat", "(", "feat2", ")", "\n", "\n", "modulation", "=", "[", "f", ".", "reshape", "(", "1", ",", "num_sequences", ",", "-", "1", ")", ".", "repeat", "(", "num_images", ",", "1", ",", "1", ")", ".", "reshape", "(", "num_sequences", "*", "num_images", ",", "-", "1", ")", "for", "f", "in", "modulation", "]", "\n", "\n", "proposals2", "=", "proposals2", ".", "reshape", "(", "num_sequences", "*", "num_images", ",", "-", "1", ",", "4", ")", "\n", "pred_iou", "=", "self", ".", "predict_iou", "(", "modulation", ",", "iou_feat", ",", "proposals2", ")", "\n", "return", "pred_iou", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.predict_iou": [[96, 137], ["torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "roi2.reshape().to.reshape().to.reshape().to", "atom_iou_net.AtomIoUNet.prroi_pool3t", "atom_iou_net.AtomIoUNet.prroi_pool4t", "atom_iou_net.AtomIoUNet.fc3_rt", "atom_iou_net.AtomIoUNet.fc4_rt", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "atom_iou_net.AtomIoUNet.iou_predictor().reshape", "c3_t.size", "fc34_3_r.reshape", "fc34_4_r.reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape().to.reshape().expand", "torch.arange().reshape().to.reshape().expand", "roi2.reshape().to.reshape().to.reshape", "atom_iou_net.AtomIoUNet.iou_predictor", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange().reshape().to.reshape", "torch.arange().reshape().to.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size"], ["", "def", "predict_iou", "(", "self", ",", "modulation", ",", "feat", ",", "proposals", ")", ":", "\n", "        ", "\"\"\"Predicts IoU for the give proposals.\n        args:\n            modulation:  Modulation vectors for the targets. Dims (batch, feature_dim).\n            feat:  IoU features (from get_iou_feat) for test images. Dims (batch, feature_dim, H, W).\n            proposals:  Proposal boxes for which the IoU will be predicted (batch, num_proposals, 4).\"\"\"", "\n", "\n", "fc34_3_r", ",", "fc34_4_r", "=", "modulation", "\n", "c3_t", ",", "c4_t", "=", "feat", "\n", "\n", "batch_size", "=", "c3_t", ".", "size", "(", ")", "[", "0", "]", "\n", "\n", "# Modulation", "\n", "c3_t_att", "=", "c3_t", "*", "fc34_3_r", ".", "reshape", "(", "batch_size", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "c4_t_att", "=", "c4_t", "*", "fc34_4_r", ".", "reshape", "(", "batch_size", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "# Add batch_index to rois", "\n", "batch_index", "=", "torch", ".", "arange", "(", "batch_size", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", ".", "to", "(", "c3_t", ".", "device", ")", "\n", "\n", "# Push the different rois for the same image along the batch dimension", "\n", "num_proposals_per_batch", "=", "proposals", ".", "shape", "[", "1", "]", "\n", "\n", "# input proposals2 is in format xywh, convert it to x0y0x1y1 format", "\n", "proposals_xyxy", "=", "torch", ".", "cat", "(", "(", "proposals", "[", ":", ",", ":", ",", "0", ":", "2", "]", ",", "proposals", "[", ":", ",", ":", ",", "0", ":", "2", "]", "+", "proposals", "[", ":", ",", ":", ",", "2", ":", "4", "]", ")", ",", "dim", "=", "2", ")", "\n", "\n", "# Add batch index", "\n", "roi2", "=", "torch", ".", "cat", "(", "(", "batch_index", ".", "reshape", "(", "batch_size", ",", "-", "1", ",", "1", ")", ".", "expand", "(", "-", "1", ",", "num_proposals_per_batch", ",", "-", "1", ")", ",", "\n", "proposals_xyxy", ")", ",", "dim", "=", "2", ")", "\n", "roi2", "=", "roi2", ".", "reshape", "(", "-", "1", ",", "5", ")", ".", "to", "(", "proposals_xyxy", ".", "device", ")", "\n", "\n", "roi3t", "=", "self", ".", "prroi_pool3t", "(", "c3_t_att", ",", "roi2", ")", "\n", "roi4t", "=", "self", ".", "prroi_pool4t", "(", "c4_t_att", ",", "roi2", ")", "\n", "\n", "fc3_rt", "=", "self", ".", "fc3_rt", "(", "roi3t", ")", "\n", "fc4_rt", "=", "self", ".", "fc4_rt", "(", "roi4t", ")", "\n", "\n", "fc34_rt_cat", "=", "torch", ".", "cat", "(", "(", "fc3_rt", ",", "fc4_rt", ")", ",", "dim", "=", "1", ")", "\n", "\n", "iou_pred", "=", "self", ".", "iou_predictor", "(", "fc34_rt_cat", ")", ".", "reshape", "(", "batch_size", ",", "num_proposals_per_batch", ")", "\n", "\n", "return", "iou_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_modulation": [[138, 171], ["atom_iou_net.AtomIoUNet.conv3_1r", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "bb.clone.clone.clone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "atom_iou_net.AtomIoUNet.prroi_pool3r", "atom_iou_net.AtomIoUNet.conv4_1r", "atom_iou_net.AtomIoUNet.prroi_pool4r", "atom_iou_net.AtomIoUNet.fc3_1r", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "atom_iou_net.AtomIoUNet.fc34_3r", "atom_iou_net.AtomIoUNet.fc34_4r", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "get_modulation", "(", "self", ",", "feat", ",", "bb", ")", ":", "\n", "        ", "\"\"\"Get modulation vectors for the targets.\n        args:\n            feat: Backbone features from reference images. Dims (batch, feature_dim, H, W).\n            bb:  Target boxes (x,y,w,h) in image coords in the reference samples. Dims (batch, 4).\"\"\"", "\n", "\n", "feat3_r", ",", "feat4_r", "=", "feat", "\n", "\n", "c3_r", "=", "self", ".", "conv3_1r", "(", "feat3_r", ")", "\n", "\n", "# Add batch_index to rois", "\n", "batch_size", "=", "bb", ".", "shape", "[", "0", "]", "\n", "batch_index", "=", "torch", ".", "arange", "(", "batch_size", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", ".", "to", "(", "bb", ".", "device", ")", "\n", "\n", "# input bb is in format xywh, convert it to x0y0x1y1 format", "\n", "bb", "=", "bb", ".", "clone", "(", ")", "\n", "bb", "[", ":", ",", "2", ":", "4", "]", "=", "bb", "[", ":", ",", "0", ":", "2", "]", "+", "bb", "[", ":", ",", "2", ":", "4", "]", "\n", "roi1", "=", "torch", ".", "cat", "(", "(", "batch_index", ",", "bb", ")", ",", "dim", "=", "1", ")", "\n", "\n", "roi3r", "=", "self", ".", "prroi_pool3r", "(", "c3_r", ",", "roi1", ")", "\n", "\n", "c4_r", "=", "self", ".", "conv4_1r", "(", "feat4_r", ")", "\n", "roi4r", "=", "self", ".", "prroi_pool4r", "(", "c4_r", ",", "roi1", ")", "\n", "\n", "fc3_r", "=", "self", ".", "fc3_1r", "(", "roi3r", ")", "\n", "\n", "# Concatenate from block 3 and 4", "\n", "fc34_r", "=", "torch", ".", "cat", "(", "(", "fc3_r", ",", "roi4r", ")", ",", "dim", "=", "1", ")", "\n", "\n", "fc34_3_r", "=", "self", ".", "fc34_3r", "(", "fc34_r", ")", "\n", "fc34_4_r", "=", "self", ".", "fc34_4r", "(", "fc34_r", ")", "\n", "\n", "return", "fc34_3_r", ",", "fc34_4_r", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.AtomIoUNet.get_iou_feat": [[172, 180], ["atom_iou_net.AtomIoUNet.conv3_2t", "atom_iou_net.AtomIoUNet.conv4_2t", "atom_iou_net.AtomIoUNet.conv3_1t", "atom_iou_net.AtomIoUNet.conv4_1t", "f.reshape", "f.dim"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "get_iou_feat", "(", "self", ",", "feat2", ")", ":", "\n", "        ", "\"\"\"Get IoU prediction features from a 4 or 5 dimensional backbone input.\"\"\"", "\n", "feat2", "=", "[", "f", ".", "reshape", "(", "-", "1", ",", "*", "f", ".", "shape", "[", "-", "3", ":", "]", ")", "if", "f", ".", "dim", "(", ")", "==", "5", "else", "f", "for", "f", "in", "feat2", "]", "\n", "feat3_t", ",", "feat4_t", "=", "feat2", "\n", "c3_t", "=", "self", ".", "conv3_2t", "(", "self", ".", "conv3_1t", "(", "feat3_t", ")", ")", "\n", "c4_t", "=", "self", ".", "conv4_2t", "(", "self", ".", "conv4_1t", "(", "feat4_t", ")", ")", "\n", "\n", "return", "c3_t", ",", "c4_t", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv": [[7, 13], ["torch.Sequential", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU"], "function", ["None"], ["def", "conv", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "return", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "bias", "=", "True", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_planes", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.ATOMnet.__init__": [[9, 27], ["torch.Module.__init__", "atom.ATOMnet.feature_extractor.parameters", "p.requires_grad_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["from", "pytracking", ".", "utils", ".", "plotting", "import", "show_tensor", "\n", "from", "pytracking", ".", "libs", ".", "optimization", "import", "GaussNewtonCG", ",", "ConjugateGradient", ",", "GradientDescentL2", "\n", "from", ".", "optim", "import", "ConvProblem", ",", "FactorizedConvProblem", "\n", "from", "pytracking", ".", "features", "import", "augmentation", "\n", "import", "ltr", ".", "data", ".", "bounding_box_utils", "as", "bbutils", "\n", "\n", "\n", "class", "ATOM", "(", "BaseTracker", ")", ":", "\n", "\n", "    ", "multiobj_mode", "=", "'parallel'", "\n", "\n", "def", "initialize_features", "(", "self", ")", ":", "\n", "        ", "if", "not", "getattr", "(", "self", ",", "'features_initialized'", ",", "False", ")", ":", "\n", "            ", "self", ".", "params", ".", "features", ".", "initialize", "(", ")", "\n", "", "self", ".", "features_initialized", "=", "True", "\n", "\n", "\n", "", "def", "initialize", "(", "self", ",", "image", ",", "info", ":", "dict", ")", "->", "dict", ":", "\n", "        ", "state", "=", "info", "[", "'init_bbox'", "]", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.ATOMnet.forward": [[28, 49], ["atom.ATOMnet.extract_backbone_features", "atom.ATOMnet.extract_backbone_features", "atom.ATOMnet.bb_regressor", "train_imgs.reshape", "test_imgs.reshape", "train_bb.reshape", "test_proposals.reshape", "train_imgs.dim", "test_imgs.dim", "atom.ATOMnet.values", "atom.ATOMnet.values"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["\n", "# Initialize some stuff", "\n", "self", ".", "frame_num", "=", "1", "\n", "if", "not", "self", ".", "params", ".", "has", "(", "'device'", ")", ":", "\n", "            ", "self", ".", "params", ".", "device", "=", "'cuda'", "if", "self", ".", "params", ".", "use_gpu", "else", "'cpu'", "\n", "\n", "# Initialize features", "\n", "", "self", ".", "initialize_features", "(", ")", "\n", "\n", "# Check if image is color", "\n", "self", ".", "params", ".", "features", ".", "set_is_color", "(", "image", ".", "shape", "[", "2", "]", "==", "3", ")", "\n", "\n", "# Get feature specific params", "\n", "self", ".", "fparams", "=", "self", ".", "params", ".", "features", ".", "get_fparams", "(", "'feature_params'", ")", "\n", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Get position and size", "\n", "self", ".", "pos", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "1", "]", "+", "(", "state", "[", "3", "]", "-", "1", ")", "/", "2", ",", "state", "[", "0", "]", "+", "(", "state", "[", "2", "]", "-", "1", ")", "/", "2", "]", ")", "\n", "self", ".", "target_sz", "=", "torch", ".", "Tensor", "(", "[", "state", "[", "3", "]", ",", "state", "[", "2", "]", "]", ")", "\n", "\n", "# Set search area", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.ATOMnet.extract_backbone_features": [[50, 54], ["atom.ATOMnet.feature_extractor"], "methods", ["None"], ["self", ".", "target_scale", "=", "1.0", "\n", "search_area", "=", "torch", ".", "prod", "(", "self", ".", "target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ".", "item", "(", ")", "\n", "if", "search_area", ">", "self", ".", "params", ".", "max_image_sample_size", ":", "\n", "            ", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", "/", "self", ".", "params", ".", "max_image_sample_size", ")", "\n", "", "elif", "search_area", "<", "self", ".", "params", ".", "min_image_sample_size", ":", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.ATOMnet.extract_features": [[55, 57], ["atom.ATOMnet.feature_extractor"], "methods", ["None"], ["            ", "self", ".", "target_scale", "=", "math", ".", "sqrt", "(", "search_area", "/", "self", ".", "params", ".", "min_image_sample_size", ")", "\n", "\n", "# Check if IoUNet is used", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.atom_resnet18": [[60, 72], ["ltr.resnet18", "ltr.AtomIoUNet", "atom.ATOMnet"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.resnet18"], ["# Target size in base scale", "\n", "self", ".", "base_target_sz", "=", "self", ".", "target_sz", "/", "self", ".", "target_scale", "\n", "\n", "# Use odd square search area and set sizes", "\n", "feat_max_stride", "=", "max", "(", "self", ".", "params", ".", "features", ".", "stride", "(", ")", ")", "\n", "if", "self", ".", "params", ".", "get", "(", "'search_area_shape'", ",", "'square'", ")", "==", "'square'", ":", "\n", "            ", "self", ".", "img_sample_sz", "=", "torch", ".", "round", "(", "torch", ".", "sqrt", "(", "torch", ".", "prod", "(", "self", ".", "base_target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", ")", ")", "*", "torch", ".", "ones", "(", "2", ")", "\n", "", "elif", "self", ".", "params", ".", "search_area_shape", "==", "'initrect'", ":", "\n", "            ", "self", ".", "img_sample_sz", "=", "torch", ".", "round", "(", "self", ".", "base_target_sz", "*", "self", ".", "params", ".", "search_area_scale", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown search area shape'", ")", "\n", "", "if", "self", ".", "params", ".", "feature_size_odd", ":", "\n", "            ", "self", ".", "img_sample_sz", "+=", "feat_max_stride", "-", "self", ".", "img_sample_sz", "%", "(", "2", "*", "feat_max_stride", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom.atom_resnet50": [[74, 86], ["ltr.resnet50", "ltr.AtomIoUNet", "atom.ATOMnet"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet50"], ["            ", "self", ".", "img_sample_sz", "+=", "feat_max_stride", "-", "(", "self", ".", "img_sample_sz", "+", "feat_max_stride", ")", "%", "(", "2", "*", "feat_max_stride", ")", "\n", "\n", "# Set sizes", "\n", "", "self", ".", "img_support_sz", "=", "self", ".", "img_sample_sz", "\n", "self", ".", "feature_sz", "=", "self", ".", "params", ".", "features", ".", "size", "(", "self", ".", "img_sample_sz", ")", "\n", "self", ".", "output_sz", "=", "self", ".", "params", ".", "score_upsample_factor", "*", "self", ".", "img_support_sz", "# Interpolated size of the output", "\n", "self", ".", "kernel_size", "=", "self", ".", "fparams", ".", "attribute", "(", "'kernel_size'", ")", "\n", "\n", "self", ".", "iou_img_sample_sz", "=", "self", ".", "img_sample_sz", "\n", "\n", "# Optimization options", "\n", "self", ".", "params", ".", "precond_learning_rate", "=", "self", ".", "fparams", ".", "attribute", "(", "'learning_rate'", ")", "\n", "if", "self", ".", "params", ".", "CG_forgetting_rate", "is", "None", "or", "max", "(", "self", ".", "params", ".", "precond_learning_rate", ")", ">=", "1", ":", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.tensorboard.TensorboardWriter.__init__": [[11, 14], ["collections.OrderedDict", "SummaryWriter", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "directory", ",", "loader_names", ")", ":", "\n", "        ", "self", ".", "directory", "=", "directory", "\n", "self", ".", "writer", "=", "OrderedDict", "(", "{", "name", ":", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "directory", ",", "name", ")", ")", "for", "name", "in", "loader_names", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.tensorboard.TensorboardWriter.write_info": [[15, 21], ["SummaryWriter", "SummaryWriter.add_text", "SummaryWriter.add_text", "SummaryWriter.add_text", "SummaryWriter.close", "os.path.join"], "methods", ["None"], ["", "def", "write_info", "(", "self", ",", "module_name", ",", "script_name", ",", "description", ")", ":", "\n", "        ", "tb_info_writer", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "self", ".", "directory", ",", "'info'", ")", ")", "\n", "tb_info_writer", ".", "add_text", "(", "'Modulet_name'", ",", "module_name", ")", "\n", "tb_info_writer", ".", "add_text", "(", "'Script_name'", ",", "script_name", ")", "\n", "tb_info_writer", ".", "add_text", "(", "'Description'", ",", "description", ")", "\n", "tb_info_writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.tensorboard.TensorboardWriter.write_epoch": [[22, 29], ["stats.items", "loader_stats.items", "hasattr", "getattr", "tensorboard.TensorboardWriter.writer[].add_scalar"], "methods", ["None"], ["", "def", "write_epoch", "(", "self", ",", "stats", ":", "OrderedDict", ",", "epoch", ":", "int", ",", "ind", "=", "-", "1", ")", ":", "\n", "        ", "for", "loader_name", ",", "loader_stats", "in", "stats", ".", "items", "(", ")", ":", "\n", "            ", "if", "loader_stats", "is", "None", ":", "\n", "                ", "continue", "\n", "", "for", "var_name", ",", "val", "in", "loader_stats", ".", "items", "(", ")", ":", "\n", "                ", "if", "hasattr", "(", "val", ",", "'history'", ")", "and", "getattr", "(", "val", ",", "'has_new_data'", ",", "True", ")", ":", "\n", "                    ", "self", ".", "writer", "[", "loader_name", "]", ".", "add_scalar", "(", "var_name", ",", "val", ".", "history", "[", "ind", "]", ",", "epoch", ")", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.multigpu.MultiGPU.__getattr__": [[10, 16], ["getattr", "super().__getattr__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.multigpu.MultiGPU.__getattr__"], ["def", "__getattr__", "(", "self", ",", "item", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "super", "(", ")", ".", "__getattr__", "(", "item", ")", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "", "return", "getattr", "(", "self", ".", "module", ",", "item", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.multigpu.is_multi_gpu": [[4, 6], ["isinstance"], "function", ["None"], ["def", "is_multi_gpu", "(", "net", ")", ":", "\n", "    ", "return", "isinstance", "(", "net", ",", "(", "MultiGPU", ",", "nn", ".", "DataParallel", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.settings.Settings.__init__": [[6, 8], ["settings.Settings.set_default"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.settings.Settings.set_default"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_default", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.settings.Settings.set_default": [[9, 12], ["ltr.admin.environment.env_settings"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["", "def", "set_default", "(", "self", ")", ":", "\n", "        ", "self", ".", "env", "=", "env_settings", "(", ")", "\n", "self", ".", "use_gpu", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.__init__": [[28, 40], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "fun_name", ",", "fun_module", ",", "args", ",", "kwds", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            fun_name - The function which returns the network\n            fun_module - the module which contains the network function\n            args - arguments which are passed to the network function\n            kwds - arguments which are passed to the network function\n        \"\"\"", "\n", "self", ".", "fun_name", "=", "fun_name", "\n", "self", ".", "fun_module", "=", "fun_module", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "kwds", "=", "kwds", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get": [[41, 46], ["importlib.import_module", "getattr", "getattr."], "methods", ["None"], ["", "def", "get", "(", "self", ")", ":", "\n", "        ", "\"\"\" Rebuild the network by calling the network function with the correct arguments. \"\"\"", "\n", "net_module", "=", "importlib", ".", "import_module", "(", "self", ".", "fun_module", ")", "\n", "net_fun", "=", "getattr", "(", "net_module", ",", "self", ".", "fun_name", ")", "\n", "return", "net_fun", "(", "*", "self", ".", "args", ",", "**", "self", ".", "kwds", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.model_constructor": [[5, 22], ["functools.wraps", "model_constructor.NetConstructor", "f", "isinstance"], "function", ["None"], ["def", "model_constructor", "(", "f", ")", ":", "\n", "    ", "\"\"\" Wraps the function 'f' which returns the network. An extra field 'constructor' is added to the network returned\n    by 'f'. This field contains an instance of the  'NetConstructor' class, which contains the information needed to\n    re-construct the network, such as the name of the function 'f', the function arguments etc. Thus, the network can\n    be easily constructed from a saved checkpoint by calling NetConstructor.get() function.\n    \"\"\"", "\n", "@", "wraps", "(", "f", ")", "\n", "def", "f_wrapper", "(", "*", "args", ",", "**", "kwds", ")", ":", "\n", "        ", "net_constr", "=", "NetConstructor", "(", "f", ".", "__name__", ",", "f", ".", "__module__", ",", "args", ",", "kwds", ")", "\n", "output", "=", "f", "(", "*", "args", ",", "**", "kwds", ")", "\n", "if", "isinstance", "(", "output", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "# Assume first argument is the network", "\n", "            ", "output", "[", "0", "]", ".", "constructor", "=", "net_constr", "\n", "", "else", ":", "\n", "            ", "output", ".", "constructor", "=", "net_constr", "\n", "", "return", "output", "\n", "", "return", "f_wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_trained_network": [[10, 17], ["os.path.join", "loading.load_network"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_network"], ["\n", "kwargs", "[", "'backbone_pretrained'", "]", "=", "False", "\n", "if", "os", ".", "path", ".", "isabs", "(", "net_path", ")", ":", "\n", "        ", "path_full", "=", "net_path", "\n", "net", ",", "_", "=", "ltr_loading", ".", "load_network", "(", "path_full", ",", "**", "kwargs", ")", "\n", "", "elif", "isinstance", "(", "env_settings", "(", ")", ".", "network_path", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_pretrained": [[19, 32], ["ltr.Settings", "os.path.join", "loading.load_network"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_network"], ["for", "p", "in", "env_settings", "(", ")", ".", "network_path", ":", "\n", "            ", "path_full", "=", "os", ".", "path", ".", "join", "(", "p", ",", "net_path", ")", "\n", "try", ":", "\n", "                ", "net", ",", "_", "=", "ltr_loading", ".", "load_network", "(", "path_full", ",", "**", "kwargs", ")", "\n", "break", "\n", "", "except", "Exception", "as", "e", ":", "\n", "# print(e)", "\n", "                ", "pass", "\n", "\n", "", "", "assert", "net", "is", "not", "None", ",", "'Failed to load network'", "\n", "", "else", ":", "\n", "        ", "path_full", "=", "os", ".", "path", ".", "join", "(", "env_settings", "(", ")", ".", "network_path", ",", "net_path", ")", "\n", "net", ",", "_", "=", "ltr_loading", ".", "load_network", "(", "path_full", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_network": [[34, 109], ["loading.torch_load_legacy", "net_constr.get.load_state_dict", "pathlib.Path", "pathlib.Path.is_file", "str", "sorted", "isinstance", "net_constr.fun_module.startswith", "getattr", "list", "kwargs.items", "net_constr.get", "RuntimeError", "pathlib.Path.glob", "Exception", "sorted", "isinstance", "importlib.import_module", "inspect.signature().parameters.keys", "pathlib.Path.glob", "Exception", "len", "Exception", "os.path.expanduser", "print", "len", "len", "inspect.signature"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.torch_load_legacy", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.load_weights": [[111, 116], ["torch.load", "net.load_state_dict"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load"], []], "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.torch_load_legacy": [[118, 131], ["loading._setup_legacy_env", "torch.load", "loading._cleanup_legacy_env"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.loading._setup_legacy_env", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load", "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading._cleanup_legacy_env"], []], "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading._setup_legacy_env": [[133, 142], ["importlib.import_module", "importlib.import_module", "importlib.import_module"], "function", ["None"], []], "home.repos.pwc.inspect_result.visionml_pytracking.admin.loading._cleanup_legacy_env": [[144, 151], ["sys.modules.keys", "m.startswith", "del_modules.append"], "function", ["None"], []], "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.StatValue.__init__": [[4, 6], ["stats.StatValue.clear"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.clear"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.StatValue.reset": [[7, 9], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.StatValue.clear": [[10, 13], ["stats.StatValue.reset"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.reset"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "self", ".", "history", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.StatValue.update": [[14, 17], ["stats.StatValue.history.append"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "history", ".", "append", "(", "self", ".", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.__init__": [[21, 24], ["stats.AverageMeter.clear"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.clear"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "clear", "(", ")", "\n", "self", ".", "has_new_data", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.reset": [[25, 30], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "avg", "=", "0", "\n", "self", ".", "val", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.clear": [[31, 34], ["stats.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.reset"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "self", ".", "history", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update": [[35, 40], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.new_epoch": [[41, 48], ["stats.AverageMeter.history.append", "stats.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.reset"], ["", "def", "new_epoch", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "count", ">", "0", ":", "\n", "            ", "self", ".", "history", ".", "append", "(", "self", ".", "avg", ")", "\n", "self", ".", "reset", "(", ")", "\n", "self", ".", "has_new_data", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "has_new_data", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.topk_accuracy": [[50, 72], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "isinstance", "target.view().expand_as", "res.append", "correct[].view().float().sum", "target.view", "correct[].view().float", "correct[].view"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size"], ["", "", "", "def", "topk_accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "single_input", "=", "not", "isinstance", "(", "topk", ",", "(", "tuple", ",", "list", ")", ")", "\n", "if", "single_input", ":", "\n", "        ", "topk", "=", "(", "topk", ",", ")", "\n", "\n", "", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "[", "0", "]", "\n", "res", ".", "append", "(", "correct_k", "*", "100.0", "/", "batch_size", ")", "\n", "\n", "", "if", "single_input", ":", "\n", "        ", "return", "res", "[", "0", "]", "\n", "\n", "", "return", "res", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.create_default_local_file": [[6, 44], ["os.path.join", "collections.OrderedDict", "os.path.dirname", "open", "f.write", "f.write", "collections.OrderedDict.items", "f.write", "f.write"], "function", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pytracking_path", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'..'", ")", ")", "\n", "\n", "self", ".", "results_path", "=", "'{}/tracking_results/'", ".", "format", "(", "pytracking_path", ")", "\n", "self", ".", "segmentation_path", "=", "'{}/segmentation_results/'", ".", "format", "(", "pytracking_path", ")", "\n", "self", ".", "network_path", "=", "'{}/networks/'", ".", "format", "(", "pytracking_path", ")", "\n", "self", ".", "result_plot_path", "=", "'{}/result_plots/'", ".", "format", "(", "pytracking_path", ")", "\n", "self", ".", "otb_path", "=", "''", "\n", "self", ".", "nfs_path", "=", "''", "\n", "self", ".", "uav_path", "=", "''", "\n", "self", ".", "tpl_path", "=", "''", "\n", "self", ".", "vot_path", "=", "''", "\n", "self", ".", "got10k_path", "=", "''", "\n", "self", ".", "lasot_path", "=", "''", "\n", "self", ".", "lasot_extension_subset_path", "=", "''", "\n", "self", ".", "trackingnet_path", "=", "''", "\n", "self", ".", "oxuva_path", "=", "''", "\n", "self", ".", "davis_dir", "=", "''", "\n", "self", ".", "youtubevos_dir", "=", "''", "\n", "\n", "self", ".", "got_packed_results_path", "=", "''", "\n", "self", ".", "got_reports_path", "=", "''", "\n", "self", ".", "tn_packed_results_path", "=", "''", "\n", "\n", "\n", "", "", "def", "create_default_local_file", "(", ")", ":", "\n", "    ", "comment", "=", "{", "'results_path'", ":", "'Where to store tracking results'", ",", "\n", "'network_path'", ":", "'Where tracking networks are stored.'", "}", "\n", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ",", "'local.py'", ")", "\n", "with", "open", "(", "path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "settings", "=", "EnvSettings", "(", ")", "\n", "\n", "f", ".", "write", "(", "'from pytracking.evaluation.environment import EnvSettings\\n\\n'", ")", "\n", "f", ".", "write", "(", "'def local_env_settings():\\n'", ")", "\n", "f", ".", "write", "(", "'    settings = EnvSettings()\\n\\n'", ")", "\n", "f", ".", "write", "(", "'    # Set your local paths here.\\n\\n'", ")", "\n", "\n", "for", "attr", "in", "dir", "(", "settings", ")", ":", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings": [[46, 56], ["importlib.import_module", "importlib.import_module.EnvironmentSettings", "os.path.join", "environment.create_default_local_file", "RuntimeError", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.create_default_local_file"], ["if", "attr", "in", "comment", ":", "\n", "                ", "comment_str", "=", "comment", "[", "attr", "]", "\n", "", "attr_val", "=", "getattr", "(", "settings", ",", "attr", ")", "\n", "if", "not", "attr", ".", "startswith", "(", "'__'", ")", "and", "not", "callable", "(", "attr_val", ")", ":", "\n", "                ", "if", "comment_str", "is", "None", ":", "\n", "                    ", "f", ".", "write", "(", "'    settings.{} = \\'{}\\'\\n'", ".", "format", "(", "attr", ",", "attr_val", ")", ")", "\n", "", "else", ":", "\n", "                    ", "f", ".", "write", "(", "'    settings.{} = \\'{}\\'    # {}\\n'", ".", "format", "(", "attr", ",", "attr_val", ",", "comment_str", ")", ")", "\n", "", "", "", "f", ".", "write", "(", "'\\n    return settings\\n\\n'", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO.__init__": [[34, 64], ["base_image_dataset.BaseImageDataset.__init__", "os.path.join", "os.path.join", "pycocotools.coco.COCO", "coco.MSCOCO.get_class_list", "coco.MSCOCO._get_image_list", "coco.MSCOCO._build_im_per_class", "random.sample", "ltr.admin.environment.env_settings", "int", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_class_list", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._get_image_list", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._build_im_per_class", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "image_loader", "=", "jpeg4py_loader", ",", "data_fraction", "=", "None", ",", "min_area", "=", "None", ",", "\n", "split", "=", "\"train\"", ",", "version", "=", "\"2014\"", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - path to coco root folder\n            image_loader (jpeg4py_loader) - The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                                            is used by default.\n            data_fraction - Fraction of dataset to be used. The complete dataset is used by default\n            min_area - Objects with area less than min_area are filtered out. Default is 0.0\n            split - 'train' or 'val'.\n            version - version of coco dataset (2014 or 2017)\n        \"\"\"", "\n", "\n", "root", "=", "env_settings", "(", ")", ".", "coco_dir", "if", "root", "is", "None", "else", "root", "\n", "super", "(", ")", ".", "__init__", "(", "'COCO'", ",", "root", ",", "image_loader", ")", "\n", "\n", "self", ".", "img_pth", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'images/{}{}/'", ".", "format", "(", "split", ",", "version", ")", ")", "\n", "self", ".", "anno_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'annotations/instances_{}{}.json'", ".", "format", "(", "split", ",", "version", ")", ")", "\n", "\n", "self", ".", "coco_set", "=", "COCO", "(", "self", ".", "anno_path", ")", "\n", "\n", "self", ".", "cats", "=", "self", ".", "coco_set", ".", "cats", "\n", "\n", "self", ".", "class_list", "=", "self", ".", "get_class_list", "(", ")", "# the parent class thing would happen in the sampler", "\n", "\n", "self", ".", "image_list", "=", "self", ".", "_get_image_list", "(", "min_area", "=", "min_area", ")", "\n", "\n", "if", "data_fraction", "is", "not", "None", ":", "\n", "            ", "self", ".", "image_list", "=", "random", ".", "sample", "(", "self", ".", "image_list", ",", "int", "(", "len", "(", "self", ".", "image_list", ")", "*", "data_fraction", ")", ")", "\n", "", "self", ".", "im_per_class", "=", "self", ".", "_build_im_per_class", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO._get_image_list": [[65, 73], ["list", "coco.MSCOCO.coco_set.anns.keys"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "_get_image_list", "(", "self", ",", "min_area", "=", "None", ")", ":", "\n", "        ", "ann_list", "=", "list", "(", "self", ".", "coco_set", ".", "anns", ".", "keys", "(", ")", ")", "\n", "image_list", "=", "[", "a", "for", "a", "in", "ann_list", "if", "self", ".", "coco_set", ".", "anns", "[", "a", "]", "[", "'iscrowd'", "]", "==", "0", "]", "\n", "\n", "if", "min_area", "is", "not", "None", ":", "\n", "            ", "image_list", "=", "[", "a", "for", "a", "in", "image_list", "if", "self", ".", "coco_set", ".", "anns", "[", "a", "]", "[", "'area'", "]", ">", "min_area", "]", "\n", "\n", "", "return", "image_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO.get_num_classes": [[74, 76], ["len"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "class_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO.get_name": [[77, 79], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "'coco'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO.has_class_info": [[80, 82], ["None"], "methods", ["None"], ["", "def", "has_class_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO.has_segmentation_info": [[83, 85], ["None"], "methods", ["None"], ["", "def", "has_segmentation_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO.get_class_list": [[86, 91], ["coco.MSCOCO.cats.keys", "class_list.append"], "methods", ["None"], ["", "def", "get_class_list", "(", "self", ")", ":", "\n", "        ", "class_list", "=", "[", "]", "\n", "for", "cat_id", "in", "self", ".", "cats", ".", "keys", "(", ")", ":", "\n", "            ", "class_list", ".", "append", "(", "self", ".", "cats", "[", "cat_id", "]", "[", "'name'", "]", ")", "\n", "", "return", "class_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO._build_im_per_class": [[92, 102], ["enumerate", "im_per_class[].append"], "methods", ["None"], ["", "def", "_build_im_per_class", "(", "self", ")", ":", "\n", "        ", "im_per_class", "=", "{", "}", "\n", "for", "i", ",", "im", "in", "enumerate", "(", "self", ".", "image_list", ")", ":", "\n", "            ", "class_name", "=", "self", ".", "cats", "[", "self", ".", "coco_set", ".", "anns", "[", "im", "]", "[", "'category_id'", "]", "]", "[", "'name'", "]", "\n", "if", "class_name", "not", "in", "im_per_class", ":", "\n", "                ", "im_per_class", "[", "class_name", "]", "=", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "im_per_class", "[", "class_name", "]", ".", "append", "(", "i", ")", "\n", "\n", "", "", "return", "im_per_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO.get_images_in_class": [[103, 105], ["None"], "methods", ["None"], ["", "def", "get_images_in_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "return", "self", ".", "im_per_class", "[", "class_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO.get_image_info": [[106, 117], ["coco.MSCOCO._get_anno", "torch.Tensor().view", "torch.Tensor", "valid.clone().byte", "coco.MSCOCO.coco_set.annToMask", "torch.Tensor", "valid.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._get_anno"], ["", "def", "get_image_info", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "anno", "=", "self", ".", "_get_anno", "(", "im_id", ")", "\n", "\n", "bbox", "=", "torch", ".", "Tensor", "(", "anno", "[", "'bbox'", "]", ")", ".", "view", "(", "4", ",", ")", "\n", "\n", "mask", "=", "torch", ".", "Tensor", "(", "self", ".", "coco_set", ".", "annToMask", "(", "anno", ")", ")", "\n", "\n", "valid", "=", "(", "bbox", "[", "2", "]", ">", "0", ")", "&", "(", "bbox", "[", "3", "]", ">", "0", ")", "\n", "visible", "=", "valid", ".", "clone", "(", ")", ".", "byte", "(", ")", "\n", "\n", "return", "{", "'bbox'", ":", "bbox", ",", "'mask'", ":", "mask", ",", "'valid'", ":", "valid", ",", "'visible'", ":", "visible", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO._get_anno": [[118, 122], ["None"], "methods", ["None"], ["", "def", "_get_anno", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "anno", "=", "self", ".", "coco_set", ".", "anns", "[", "self", ".", "image_list", "[", "im_id", "]", "]", "\n", "\n", "return", "anno", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO._get_image": [[123, 127], ["coco.MSCOCO.image_loader", "os.path.join", "coco.MSCOCO.coco_set.loadImgs"], "methods", ["None"], ["", "def", "_get_image", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "path", "=", "self", ".", "coco_set", ".", "loadImgs", "(", "[", "self", ".", "coco_set", ".", "anns", "[", "self", ".", "image_list", "[", "im_id", "]", "]", "[", "'image_id'", "]", "]", ")", "[", "0", "]", "[", "'file_name'", "]", "\n", "img", "=", "self", ".", "image_loader", "(", "os", ".", "path", ".", "join", "(", "self", ".", "img_pth", ",", "path", ")", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO.get_meta_info": [[128, 143], ["collections.OrderedDict", "collections.OrderedDict"], "methods", ["None"], ["", "def", "get_meta_info", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "cat_dict_current", "=", "self", ".", "cats", "[", "self", ".", "coco_set", ".", "anns", "[", "self", ".", "image_list", "[", "im_id", "]", "]", "[", "'category_id'", "]", "]", "\n", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "cat_dict_current", "[", "'name'", "]", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "cat_dict_current", "[", "'supercategory'", "]", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "", "except", ":", "\n", "            ", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "None", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "", "return", "object_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO.get_class_name": [[144, 147], ["None"], "methods", ["None"], ["", "def", "get_class_name", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "cat_dict_current", "=", "self", ".", "cats", "[", "self", ".", "coco_set", ".", "anns", "[", "self", ".", "image_list", "[", "im_id", "]", "]", "[", "'category_id'", "]", "]", "\n", "return", "cat_dict_current", "[", "'name'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco.MSCOCO.get_image": [[148, 157], ["coco.MSCOCO._get_image", "coco.MSCOCO.get_meta_info", "coco.MSCOCO.get_image_info"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._get_image", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_meta_info", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image_info"], ["", "def", "get_image", "(", "self", ",", "image_id", ",", "anno", "=", "None", ")", ":", "\n", "        ", "frame", "=", "self", ".", "_get_image", "(", "image_id", ")", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_image_info", "(", "image_id", ")", "\n", "\n", "", "object_meta", "=", "self", ".", "get_meta_info", "(", "image_id", ")", "\n", "\n", "return", "frame", ",", "anno", ",", "object_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot.__init__": [[26, 51], ["base_video_dataset.BaseVideoDataset.__init__", "lasot.Lasot._build_sequence_list", "lasot.Lasot._build_class_list", "random.sample", "ltr.admin.environment.env_settings", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "enumerate", "int", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._build_sequence_list", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._build_class_list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "image_loader", "=", "jpeg4py_loader", ",", "vid_ids", "=", "None", ",", "split", "=", "None", ",", "data_fraction", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - path to the lasot dataset.\n            image_loader (jpeg4py_loader) -  The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                                            is used by default.\n            vid_ids - List containing the ids of the videos (1 - 20) used for training. If vid_ids = [1, 3, 5], then the\n                    videos with subscripts -1, -3, and -5 from each class will be used for training.\n            split - If split='train', the official train split (protocol-II) is used for training. Note: Only one of\n                    vid_ids or split option can be used at a time.\n            data_fraction - Fraction of dataset to be used. The complete dataset is used by default\n        \"\"\"", "\n", "root", "=", "env_settings", "(", ")", ".", "lasot_dir", "if", "root", "is", "None", "else", "root", "\n", "super", "(", ")", ".", "__init__", "(", "'LaSOT'", ",", "root", ",", "image_loader", ")", "\n", "\n", "# Keep a list of all classes", "\n", "self", ".", "class_list", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "self", ".", "root", ")", "]", "\n", "self", ".", "class_to_id", "=", "{", "cls_name", ":", "cls_id", "for", "cls_id", ",", "cls_name", "in", "enumerate", "(", "self", ".", "class_list", ")", "}", "\n", "\n", "self", ".", "sequence_list", "=", "self", ".", "_build_sequence_list", "(", "vid_ids", ",", "split", ")", "\n", "\n", "if", "data_fraction", "is", "not", "None", ":", "\n", "            ", "self", ".", "sequence_list", "=", "random", ".", "sample", "(", "self", ".", "sequence_list", ",", "int", "(", "len", "(", "self", ".", "sequence_list", ")", "*", "data_fraction", ")", ")", "\n", "\n", "", "self", ".", "seq_per_class", "=", "self", ".", "_build_class_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot._build_sequence_list": [[52, 68], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "pandas.read_csv().values.tolist", "ValueError", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "ValueError", "ValueError", "os.path.realpath", "os.path.realpath", "os.path.realpath", "os.path.realpath", "pandas.read_csv", "str"], "methods", ["None"], ["", "def", "_build_sequence_list", "(", "self", ",", "vid_ids", "=", "None", ",", "split", "=", "None", ")", ":", "\n", "        ", "if", "split", "is", "not", "None", ":", "\n", "            ", "if", "vid_ids", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "'Cannot set both split_name and vid_ids.'", ")", "\n", "", "ltr_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ",", "'..'", ")", "\n", "if", "split", "==", "'train'", ":", "\n", "                ", "file_path", "=", "os", ".", "path", ".", "join", "(", "ltr_path", ",", "'data_specs'", ",", "'lasot_train_split.txt'", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown split name.'", ")", "\n", "", "sequence_list", "=", "pandas", ".", "read_csv", "(", "file_path", ",", "header", "=", "None", ",", "squeeze", "=", "True", ")", ".", "values", ".", "tolist", "(", ")", "\n", "", "elif", "vid_ids", "is", "not", "None", ":", "\n", "            ", "sequence_list", "=", "[", "c", "+", "'-'", "+", "str", "(", "v", ")", "for", "c", "in", "self", ".", "class_list", "for", "v", "in", "vid_ids", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Set either split_name or vid_ids.'", ")", "\n", "\n", "", "return", "sequence_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot._build_class_list": [[69, 79], ["enumerate", "seq_name.split", "seq_per_class[].append"], "methods", ["None"], ["", "def", "_build_class_list", "(", "self", ")", ":", "\n", "        ", "seq_per_class", "=", "{", "}", "\n", "for", "seq_id", ",", "seq_name", "in", "enumerate", "(", "self", ".", "sequence_list", ")", ":", "\n", "            ", "class_name", "=", "seq_name", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "if", "class_name", "in", "seq_per_class", ":", "\n", "                ", "seq_per_class", "[", "class_name", "]", ".", "append", "(", "seq_id", ")", "\n", "", "else", ":", "\n", "                ", "seq_per_class", "[", "class_name", "]", "=", "[", "seq_id", "]", "\n", "\n", "", "", "return", "seq_per_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot.get_name": [[80, 82], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "'lasot'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot.has_class_info": [[83, 85], ["None"], "methods", ["None"], ["", "def", "has_class_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot.has_occlusion_info": [[86, 88], ["None"], "methods", ["None"], ["", "def", "has_occlusion_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot.get_num_sequences": [[89, 91], ["len"], "methods", ["None"], ["", "def", "get_num_sequences", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot.get_num_classes": [[92, 94], ["len"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "class_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot.get_sequences_in_class": [[95, 97], ["None"], "methods", ["None"], ["", "def", "get_sequences_in_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "return", "self", ".", "seq_per_class", "[", "class_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot._read_bb_anno": [[98, 102], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.tensor", "pandas.read_csv"], "methods", ["None"], ["", "def", "_read_bb_anno", "(", "self", ",", "seq_path", ")", ":", "\n", "        ", "bb_anno_file", "=", "os", ".", "path", ".", "join", "(", "seq_path", ",", "\"groundtruth.txt\"", ")", "\n", "gt", "=", "pandas", ".", "read_csv", "(", "bb_anno_file", ",", "delimiter", "=", "','", ",", "header", "=", "None", ",", "dtype", "=", "np", ".", "float32", ",", "na_filter", "=", "False", ",", "low_memory", "=", "False", ")", ".", "values", "\n", "return", "torch", ".", "tensor", "(", "gt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot._read_target_visible": [[103, 116], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "torch.ByteTensor", "open", "torch.ByteTensor", "int", "int", "list", "list", "csv.reader", "csv.reader"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "_read_target_visible", "(", "self", ",", "seq_path", ")", ":", "\n", "# Read full occlusion and out_of_view", "\n", "        ", "occlusion_file", "=", "os", ".", "path", ".", "join", "(", "seq_path", ",", "\"full_occlusion.txt\"", ")", "\n", "out_of_view_file", "=", "os", ".", "path", ".", "join", "(", "seq_path", ",", "\"out_of_view.txt\"", ")", "\n", "\n", "with", "open", "(", "occlusion_file", ",", "'r'", ",", "newline", "=", "''", ")", "as", "f", ":", "\n", "            ", "occlusion", "=", "torch", ".", "ByteTensor", "(", "[", "int", "(", "v", ")", "for", "v", "in", "list", "(", "csv", ".", "reader", "(", "f", ")", ")", "[", "0", "]", "]", ")", "\n", "", "with", "open", "(", "out_of_view_file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "out_of_view", "=", "torch", ".", "ByteTensor", "(", "[", "int", "(", "v", ")", "for", "v", "in", "list", "(", "csv", ".", "reader", "(", "f", ")", ")", "[", "0", "]", "]", ")", "\n", "\n", "", "target_visible", "=", "~", "occlusion", "&", "~", "out_of_view", "\n", "\n", "return", "target_visible", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot._get_sequence_path": [[117, 123], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "seq_name.split", "seq_name.split"], "methods", ["None"], ["", "def", "_get_sequence_path", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "seq_name", "=", "self", ".", "sequence_list", "[", "seq_id", "]", "\n", "class_name", "=", "seq_name", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "vid_id", "=", "seq_name", ".", "split", "(", "'-'", ")", "[", "1", "]", "\n", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "class_name", ",", "class_name", "+", "'-'", "+", "vid_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot.get_sequence_info": [[124, 132], ["lasot.Lasot._get_sequence_path", "lasot.Lasot._read_bb_anno", "lasot.Lasot._read_target_visible", "valid.byte"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_sequence_path", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._read_bb_anno", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._read_target_visible"], ["", "def", "get_sequence_info", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "seq_path", "=", "self", ".", "_get_sequence_path", "(", "seq_id", ")", "\n", "bbox", "=", "self", ".", "_read_bb_anno", "(", "seq_path", ")", "\n", "\n", "valid", "=", "(", "bbox", "[", ":", ",", "2", "]", ">", "0", ")", "&", "(", "bbox", "[", ":", ",", "3", "]", ">", "0", ")", "\n", "visible", "=", "self", ".", "_read_target_visible", "(", "seq_path", ")", "&", "valid", ".", "byte", "(", ")", "\n", "\n", "return", "{", "'bbox'", ":", "bbox", ",", "'valid'", ":", "valid", ",", "'visible'", ":", "visible", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot._get_frame_path": [[133, 135], ["os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "_get_frame_path", "(", "self", ",", "seq_path", ",", "frame_id", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "seq_path", ",", "'img'", ",", "'{:08}.jpg'", ".", "format", "(", "frame_id", "+", "1", ")", ")", "# frames start from 1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot._get_frame": [[136, 138], ["lasot.Lasot.image_loader", "lasot.Lasot._get_frame_path"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_frame_path"], ["", "def", "_get_frame", "(", "self", ",", "seq_path", ",", "frame_id", ")", ":", "\n", "        ", "return", "self", ".", "image_loader", "(", "self", ".", "_get_frame_path", "(", "seq_path", ",", "frame_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot._get_class": [[139, 142], ["seq_path.split"], "methods", ["None"], ["", "def", "_get_class", "(", "self", ",", "seq_path", ")", ":", "\n", "        ", "raw_class", "=", "seq_path", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "return", "raw_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot.get_class_name": [[143, 148], ["lasot.Lasot._get_sequence_path", "lasot.Lasot._get_class"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_sequence_path", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_class"], ["", "def", "get_class_name", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "seq_path", "=", "self", ".", "_get_sequence_path", "(", "seq_id", ")", "\n", "obj_class", "=", "self", ".", "_get_class", "(", "seq_path", ")", "\n", "\n", "return", "obj_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot.Lasot.get_frames": [[149, 169], ["lasot.Lasot._get_sequence_path", "lasot.Lasot._get_class", "lasot.Lasot.items", "collections.OrderedDict", "lasot.Lasot._get_frame", "lasot.Lasot.get_sequence_info", "value[].clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_sequence_path", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_class", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID._get_frame", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info"], ["", "def", "get_frames", "(", "self", ",", "seq_id", ",", "frame_ids", ",", "anno", "=", "None", ")", ":", "\n", "        ", "seq_path", "=", "self", ".", "_get_sequence_path", "(", "seq_id", ")", "\n", "\n", "obj_class", "=", "self", ".", "_get_class", "(", "seq_path", ")", "\n", "frame_list", "=", "[", "self", ".", "_get_frame", "(", "seq_path", ",", "f_id", ")", "for", "f_id", "in", "frame_ids", "]", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_sequence_info", "(", "seq_id", ")", "\n", "\n", "", "anno_frames", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "anno", ".", "items", "(", ")", ":", "\n", "            ", "anno_frames", "[", "key", "]", "=", "[", "value", "[", "f_id", ",", "...", "]", ".", "clone", "(", ")", "for", "f_id", "in", "frame_ids", "]", "\n", "\n", "", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "obj_class", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "\n", "return", "frame_list", ",", "anno_frames", ",", "object_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.msra10k.MSRA10k.__init__": [[23, 39], ["base_image_dataset.BaseImageDataset.__init__", "msra10k.MSRA10k._load_dataset", "ltr.admin.environment.env_settings"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._load_dataset", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "image_loader", "=", "jpeg4py_loader", ",", "data_fraction", "=", "None", ",", "min_area", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - path to MSRA10k root folder\n            image_loader (jpeg4py_loader) - The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                                            is used by default.\n            data_fraction - Fraction of dataset to be used. The complete dataset is used by default\n            min_area - Objects with area less than min_area are filtered out. Default is 0.0\n        \"\"\"", "\n", "root", "=", "env_settings", "(", ")", ".", "msra10k_dir", "if", "root", "is", "None", "else", "root", "\n", "super", "(", ")", ".", "__init__", "(", "'MSRA10k'", ",", "root", ",", "image_loader", ")", "\n", "\n", "self", ".", "image_list", "=", "self", ".", "_load_dataset", "(", "min_area", "=", "min_area", ")", "\n", "\n", "if", "data_fraction", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.msra10k.MSRA10k._load_dataset": [[40, 53], ["os.listdir", "os.path.join", "ltr.data.image_loader.imread_indexed", "os.path.join", "images.append"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.imread_indexed"], ["", "", "def", "_load_dataset", "(", "self", ",", "min_area", "=", "None", ")", ":", "\n", "        ", "files_list", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'Imgs'", ")", ")", "\n", "image_list", "=", "[", "f", "[", ":", "-", "4", "]", "for", "f", "in", "files_list", "if", "f", "[", "-", "3", ":", "]", "==", "'jpg'", "]", "\n", "\n", "images", "=", "[", "]", "\n", "\n", "for", "f", "in", "image_list", ":", "\n", "            ", "a", "=", "imread_indexed", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'Imgs'", ",", "'{}.png'", ".", "format", "(", "f", ")", ")", ")", "\n", "\n", "if", "min_area", "is", "None", "or", "(", "a", ">", "0", ")", ".", "sum", "(", ")", ">", "min_area", ":", "\n", "                ", "images", ".", "append", "(", "f", ")", "\n", "\n", "", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.msra10k.MSRA10k.get_name": [[54, 56], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "'msra10k'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.msra10k.MSRA10k.has_segmentation_info": [[57, 59], ["None"], "methods", ["None"], ["", "def", "has_segmentation_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.msra10k.MSRA10k.get_image_info": [[60, 69], ["ltr.data.image_loader.imread_indexed", "torch.Tensor", "ltr.data.bounding_box_utils.masks_to_bboxes().view", "valid.clone().byte", "os.path.join", "ltr.data.bounding_box_utils.masks_to_bboxes", "valid.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.imread_indexed", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.masks_to_bboxes"], ["", "def", "get_image_info", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "mask", "=", "imread_indexed", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'Imgs'", ",", "'{}.png'", ".", "format", "(", "self", ".", "image_list", "[", "im_id", "]", ")", ")", ")", "\n", "mask", "=", "torch", ".", "Tensor", "(", "mask", "==", "255", ")", "\n", "bbox", "=", "masks_to_bboxes", "(", "mask", ",", "fmt", "=", "'t'", ")", ".", "view", "(", "4", ",", ")", "\n", "\n", "valid", "=", "(", "bbox", "[", "2", "]", ">", "0", ")", "&", "(", "bbox", "[", "3", "]", ">", "0", ")", "\n", "visible", "=", "valid", ".", "clone", "(", ")", ".", "byte", "(", ")", "\n", "\n", "return", "{", "'bbox'", ":", "bbox", ",", "'mask'", ":", "mask", ",", "'valid'", ":", "valid", ",", "'visible'", ":", "visible", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.msra10k.MSRA10k.get_meta_info": [[70, 78], ["collections.OrderedDict"], "methods", ["None"], ["", "def", "get_meta_info", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "None", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "\n", "return", "object_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.msra10k.MSRA10k.get_image": [[79, 88], ["msra10k.MSRA10k.image_loader", "msra10k.MSRA10k.get_meta_info", "os.path.join", "msra10k.MSRA10k.get_image_info"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_meta_info", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image_info"], ["", "def", "get_image", "(", "self", ",", "image_id", ",", "anno", "=", "None", ")", ":", "\n", "        ", "frame", "=", "self", ".", "image_loader", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'Imgs'", ",", "'{}.jpg'", ".", "format", "(", "self", ".", "image_list", "[", "image_id", "]", ")", ")", ")", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_image_info", "(", "image_id", ")", "\n", "\n", "", "object_meta", "=", "self", ".", "get_meta_info", "(", "image_id", ")", "\n", "\n", "return", "frame", ",", "anno", ",", "object_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.davis.Davis.__init__": [[19, 75], ["ltr.dataset.vos_base.VOSDatasetBase.__init__", "meta_path.exists", "print", "ltr.dataset.vos_base.VOSMeta", "ltr.dataset.vos_base.VOSMeta.generate", "davis.Davis.gmeta.save", "davis.Davis.gmeta.get_obj_ids", "pathlib.Path", "open().read().splitlines", "davis.Davis._samples.append", "davis.Davis._samples.extend", "davis.Davis.get_name", "Exception", "ltr.admin.environment.env_settings", "ltr.admin.environment.env_settings", "open().read", "sorted", "p.is_dir", "ltr.admin.environment.env_settings", "davis.Davis._jpeg_path.glob", "open"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.generate", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.save", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_obj_ids", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_name", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "sequences", "=", "None", ",", "version", "=", "'2017'", ",", "split", "=", "'train'", ",", "multiobj", "=", "True", ",", "\n", "vis_threshold", "=", "10", ",", "image_loader", "=", "jpeg4py_loader", ")", ":", "\n", "        ", "\"\"\"\n        args:\n             root - Dataset root path. If unset, it uses the path in your local.py config.\n             sequences - List of sequence names. Limit to a subset of sequences if not None.\n             version - '2016' or '2017\n             split - Any name in DAVIS/ImageSets/<year>\n             multiobj - Whether the dataset will return all objects in a sequence or multiple sequences with one object\n                        in each.\n             vis_threshold - Minimum number of pixels required to consider a target object \"visible\".\n             image_loader (jpeg4py_loader) - The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                                            is used by default.\n        \"\"\"", "\n", "if", "version", "==", "'2017'", ":", "\n", "            ", "if", "split", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "                ", "root", "=", "env_settings", "(", ")", ".", "davis_dir", "if", "root", "is", "None", "else", "root", "\n", "", "elif", "split", "in", "[", "'test-dev'", "]", ":", "\n", "                ", "root", "=", "env_settings", "(", ")", ".", "davis_testdev_dir", "if", "root", "is", "None", "else", "root", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'Unknown split {}'", ".", "format", "(", "split", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "root", "=", "env_settings", "(", ")", ".", "davis16_dir", "if", "root", "is", "None", "else", "root", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "name", "=", "'DAVIS'", ",", "root", "=", "Path", "(", "root", ")", ",", "version", "=", "version", ",", "split", "=", "split", ",", "multiobj", "=", "multiobj", ",", "\n", "vis_threshold", "=", "vis_threshold", ",", "image_loader", "=", "image_loader", ")", "\n", "\n", "dset_path", "=", "self", ".", "root", "\n", "self", ".", "_jpeg_path", "=", "dset_path", "/", "'JPEGImages'", "/", "'480p'", "\n", "self", ".", "_anno_path", "=", "dset_path", "/", "'Annotations'", "/", "'480p'", "\n", "\n", "meta_path", "=", "dset_path", "/", "\"generated_meta.json\"", "\n", "if", "meta_path", ".", "exists", "(", ")", ":", "\n", "            ", "self", ".", "gmeta", "=", "VOSMeta", "(", "filename", "=", "meta_path", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "gmeta", "=", "VOSMeta", ".", "generate", "(", "'DAVIS'", ",", "self", ".", "_jpeg_path", ",", "self", ".", "_anno_path", ")", "\n", "self", ".", "gmeta", ".", "save", "(", "meta_path", ")", "\n", "\n", "", "if", "sequences", "is", "None", ":", "\n", "            ", "if", "self", ".", "split", "!=", "'all'", ":", "\n", "                ", "fname", "=", "dset_path", "/", "'ImageSets'", "/", "self", ".", "version", "/", "(", "self", ".", "split", "+", "'.txt'", ")", "\n", "sequences", "=", "open", "(", "fname", ")", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "else", ":", "\n", "                ", "sequences", "=", "[", "p", "for", "p", "in", "sorted", "(", "self", ".", "_jpeg_path", ".", "glob", "(", "\"*\"", ")", ")", "if", "p", ".", "is_dir", "(", ")", "]", "\n", "\n", "", "", "self", ".", "sequence_names", "=", "sequences", "\n", "self", ".", "_samples", "=", "[", "]", "\n", "\n", "for", "seq", "in", "sequences", ":", "\n", "            ", "obj_ids", "=", "self", ".", "gmeta", ".", "get_obj_ids", "(", "seq", ")", "\n", "if", "self", ".", "multiobj", ":", "# Multiple objects per sample", "\n", "                ", "self", ".", "_samples", ".", "append", "(", "(", "seq", ",", "obj_ids", ")", ")", "\n", "", "else", ":", "# One object per sample", "\n", "                ", "self", ".", "_samples", ".", "extend", "(", "[", "(", "seq", ",", "[", "obj_id", "]", ")", "for", "obj_id", "in", "obj_ids", "]", ")", "\n", "\n", "", "", "print", "(", "\"%s loaded.\"", "%", "self", ".", "get_name", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.davis.Davis._construct_sequence": [[76, 84], ["davis.Davis.get_paths_and_bboxes", "pytracking.evaluation.Sequence"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.get_paths_and_bboxes"], ["", "def", "_construct_sequence", "(", "self", ",", "sequence_info", ")", ":", "\n", "\n", "        ", "seq_name", "=", "sequence_info", "[", "'sequence'", "]", "\n", "images", ",", "gt_labels", ",", "gt_bboxes", "=", "self", ".", "get_paths_and_bboxes", "(", "sequence_info", ")", "\n", "\n", "return", "Sequence", "(", "name", "=", "seq_name", ",", "frames", "=", "images", ",", "dataset", "=", "'DAVIS'", ",", "ground_truth_rect", "=", "gt_bboxes", ",", "\n", "ground_truth_seg", "=", "gt_labels", ",", "object_ids", "=", "sequence_info", "[", "'object_ids'", "]", ",", "\n", "multiobj_mode", "=", "self", ".", "multiobj", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD.__init__": [[24, 48], ["base_image_dataset.BaseImageDataset.__init__", "sbd.SBD._load_dataset", "sbd.SBD._construct_image_list", "scipy.io.loadmat", "ltr.admin.environment.env_settings"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._load_dataset", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD._construct_image_list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "image_loader", "=", "jpeg4py_loader_w_failsafe", ",", "data_fraction", "=", "None", ",", "split", "=", "\"train\"", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - path to SBD root folder\n            image_loader - The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                           is used by default.\n            data_fraction - Fraction of dataset to be used. The complete dataset is used by default\n            split - dataset split (\"train\", \"train_noval\", \"val\")\n        \"\"\"", "\n", "root", "=", "env_settings", "(", ")", ".", "sbd_dir", "if", "root", "is", "None", "else", "root", "\n", "super", "(", ")", ".", "__init__", "(", "'SBD'", ",", "root", ",", "image_loader", ")", "\n", "\n", "assert", "split", "in", "[", "\"train\"", ",", "\"train_noval\"", ",", "\"val\"", "]", "\n", "\n", "self", ".", "root", "=", "root", "\n", "\n", "self", ".", "image_path_list", ",", "self", ".", "anno_file_list", "=", "self", ".", "_load_dataset", "(", "split", ")", "\n", "\n", "# Load mat fine", "\n", "anno_list", "=", "[", "loadmat", "(", "a", ")", "for", "a", "in", "self", ".", "anno_file_list", "]", "\n", "\n", "self", ".", "image_list", "=", "self", ".", "_construct_image_list", "(", "anno_list", ")", "\n", "if", "data_fraction", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD._load_dataset": [[49, 61], ["os.path.join", "open", "os.path.join", "os.path.join", "len", "len", "split.rstrip", "os.path.join", "x.strip", "f.readlines"], "methods", ["None"], ["", "", "def", "_load_dataset", "(", "self", ",", "split", ")", ":", "\n", "        ", "split_f", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "split", ".", "rstrip", "(", "'\\n'", ")", "+", "'.txt'", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "split_f", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "file_names", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n", "", "image_list", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'img'", ",", "x", "+", "\".jpg\"", ")", "for", "x", "in", "file_names", "]", "\n", "anno_list", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'inst'", ",", "x", "+", "\".mat\"", ")", "for", "x", "in", "file_names", "]", "\n", "\n", "assert", "(", "len", "(", "image_list", ")", "==", "len", "(", "anno_list", ")", ")", "\n", "\n", "return", "image_list", ",", "anno_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD._get_mask_from_mat": [[62, 64], ["torch.tensor"], "methods", ["None"], ["", "def", "_get_mask_from_mat", "(", "self", ",", "mat", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "mat", "[", "'GTinst'", "]", "[", "0", "]", "[", "'Segmentation'", "]", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD._construct_image_list": [[65, 74], ["enumerate", "sbd.SBD._get_mask_from_mat", "range", "image_list.append", "sbd.SBD.max().item", "sbd.SBD.max"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD._get_mask_from_mat"], ["", "def", "_construct_image_list", "(", "self", ",", "anno_list", ")", ":", "\n", "        ", "image_list", "=", "[", "]", "\n", "\n", "for", "im_id", ",", "a", "in", "enumerate", "(", "anno_list", ")", ":", "\n", "            ", "mask", "=", "self", ".", "_get_mask_from_mat", "(", "a", ")", "\n", "for", "instance_id", "in", "range", "(", "1", ",", "mask", ".", "max", "(", ")", ".", "item", "(", ")", "+", "1", ")", ":", "\n", "                ", "image_list", ".", "append", "(", "(", "im_id", ",", "instance_id", ")", ")", "\n", "\n", "", "", "return", "image_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD.get_name": [[75, 77], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "'sbd'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD.has_segmentation_info": [[78, 80], ["None"], "methods", ["None"], ["", "def", "has_segmentation_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD.get_image_info": [[81, 92], ["scipy.io.loadmat", "sbd.SBD._get_mask_from_mat", "ltr.data.bounding_box_utils.masks_to_bboxes", "valid.clone().byte", "valid.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD._get_mask_from_mat", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.masks_to_bboxes"], ["", "def", "get_image_info", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "image_id", ",", "instance_id", "=", "self", ".", "image_list", "[", "im_id", "]", "\n", "anno_mat", "=", "loadmat", "(", "self", ".", "anno_file_list", "[", "image_id", "]", ")", "\n", "mask", "=", "self", ".", "_get_mask_from_mat", "(", "anno_mat", ")", "\n", "\n", "mask", "=", "(", "mask", "==", "instance_id", ")", ".", "float", "(", ")", "\n", "bbox", "=", "masks_to_bboxes", "(", "mask", ",", "fmt", "=", "'t'", ")", "\n", "valid", "=", "(", "bbox", "[", "2", "]", ">", "0", ")", "&", "(", "bbox", "[", "3", "]", ">", "0", ")", "\n", "visible", "=", "valid", ".", "clone", "(", ")", ".", "byte", "(", ")", "\n", "\n", "return", "{", "'bbox'", ":", "bbox", ",", "'mask'", ":", "mask", ",", "'valid'", ":", "valid", ",", "'visible'", ":", "visible", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD._get_image": [[93, 98], ["sbd.SBD.image_loader"], "methods", ["None"], ["", "def", "_get_image", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "image_id", ",", "_", "=", "self", ".", "image_list", "[", "im_id", "]", "\n", "\n", "img", "=", "self", ".", "image_loader", "(", "self", ".", "image_path_list", "[", "image_id", "]", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD.get_meta_info": [[99, 106], ["collections.OrderedDict"], "methods", ["None"], ["", "def", "get_meta_info", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "None", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "return", "object_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.sbd.SBD.get_image": [[107, 116], ["sbd.SBD._get_image", "sbd.SBD.get_meta_info", "sbd.SBD.get_image_info"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._get_image", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_meta_info", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image_info"], ["", "def", "get_image", "(", "self", ",", "image_id", ",", "anno", "=", "None", ")", ":", "\n", "        ", "image", "=", "self", ".", "_get_image", "(", "image_id", ")", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_image_info", "(", "image_id", ")", "\n", "\n", "", "object_meta", "=", "self", ".", "get_meta_info", "(", "image_id", ")", "\n", "\n", "return", "image", ",", "anno", ",", "object_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.TrackingNet.__init__": [[46, 76], ["base_video_dataset.BaseVideoDataset.__init__", "tracking_net.list_sequences", "tracking_net.TrackingNet._load_class_info", "list", "tracking_net.TrackingNet.class_list.sort", "random.sample", "tracking_net.TrackingNet.seq_per_class.keys", "ltr.admin.environment.env_settings", "int", "range", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.list_sequences", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.TrackingNet._load_class_info", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "image_loader", "=", "jpeg4py_loader", ",", "set_ids", "=", "None", ",", "data_fraction", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root        - The path to the TrackingNet folder, containing the training sets.\n            image_loader (jpeg4py_loader) -  The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                                            is used by default.\n            set_ids (None) - List containing the ids of the TrackingNet sets to be used for training. If None, all the\n                            sets (0 - 11) will be used.\n            data_fraction - Fraction of dataset to be used. The complete dataset is used by default\n        \"\"\"", "\n", "root", "=", "env_settings", "(", ")", ".", "trackingnet_dir", "if", "root", "is", "None", "else", "root", "\n", "super", "(", ")", ".", "__init__", "(", "'TrackingNet'", ",", "root", ",", "image_loader", ")", "\n", "\n", "if", "set_ids", "is", "None", ":", "\n", "            ", "set_ids", "=", "[", "i", "for", "i", "in", "range", "(", "12", ")", "]", "\n", "\n", "", "self", ".", "set_ids", "=", "set_ids", "\n", "\n", "# Keep a list of all videos. Sequence list is a list of tuples (set_id, video_name) containing the set_id and", "\n", "# video_name for each sequence", "\n", "self", ".", "sequence_list", "=", "list_sequences", "(", "self", ".", "root", ",", "self", ".", "set_ids", ")", "\n", "\n", "if", "data_fraction", "is", "not", "None", ":", "\n", "            ", "self", ".", "sequence_list", "=", "random", ".", "sample", "(", "self", ".", "sequence_list", ",", "int", "(", "len", "(", "self", ".", "sequence_list", ")", "*", "data_fraction", ")", ")", "\n", "\n", "", "self", ".", "seq_to_class_map", ",", "self", ".", "seq_per_class", "=", "self", ".", "_load_class_info", "(", ")", "\n", "\n", "# we do not have the class_lists for the tracking net", "\n", "self", ".", "class_list", "=", "list", "(", "self", ".", "seq_per_class", ".", "keys", "(", ")", ")", "\n", "self", ".", "class_list", ".", "sort", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.TrackingNet._load_class_info": [[77, 93], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "enumerate", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname", "open", "seq_to_class_map.get", "os.path.realpath", "os.path.realpath", "os.path.realpath", "os.path.realpath", "seq_per_class[].append", "seq_class.split", "seq_class.rstrip().split", "seq_class.rstrip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "_load_class_info", "(", "self", ")", ":", "\n", "        ", "ltr_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ",", "'..'", ")", "\n", "class_map_path", "=", "os", ".", "path", ".", "join", "(", "ltr_path", ",", "'data_specs'", ",", "'trackingnet_classmap.txt'", ")", "\n", "\n", "with", "open", "(", "class_map_path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "seq_to_class_map", "=", "{", "seq_class", ".", "split", "(", "'\\t'", ")", "[", "0", "]", ":", "seq_class", ".", "rstrip", "(", ")", ".", "split", "(", "'\\t'", ")", "[", "1", "]", "for", "seq_class", "in", "f", "}", "\n", "\n", "", "seq_per_class", "=", "{", "}", "\n", "for", "i", ",", "seq", "in", "enumerate", "(", "self", ".", "sequence_list", ")", ":", "\n", "            ", "class_name", "=", "seq_to_class_map", ".", "get", "(", "seq", "[", "1", "]", ",", "'Unknown'", ")", "\n", "if", "class_name", "not", "in", "seq_per_class", ":", "\n", "                ", "seq_per_class", "[", "class_name", "]", "=", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "seq_per_class", "[", "class_name", "]", ".", "append", "(", "i", ")", "\n", "\n", "", "", "return", "seq_to_class_map", ",", "seq_per_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.TrackingNet.get_name": [[94, 96], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "'trackingnet'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.TrackingNet.has_class_info": [[97, 99], ["None"], "methods", ["None"], ["", "def", "has_class_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.TrackingNet.get_sequences_in_class": [[100, 102], ["None"], "methods", ["None"], ["", "def", "get_sequences_in_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "return", "self", ".", "seq_per_class", "[", "class_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.TrackingNet._read_bb_anno": [[103, 110], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.tensor", "pandas.read_csv", "str"], "methods", ["None"], ["", "def", "_read_bb_anno", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "set_id", "=", "self", ".", "sequence_list", "[", "seq_id", "]", "[", "0", "]", "\n", "vid_name", "=", "self", ".", "sequence_list", "[", "seq_id", "]", "[", "1", "]", "\n", "bb_anno_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"TRAIN_\"", "+", "str", "(", "set_id", ")", ",", "\"anno\"", ",", "vid_name", "+", "\".txt\"", ")", "\n", "gt", "=", "pandas", ".", "read_csv", "(", "bb_anno_file", ",", "delimiter", "=", "','", ",", "header", "=", "None", ",", "dtype", "=", "np", ".", "float32", ",", "na_filter", "=", "False", ",", "\n", "low_memory", "=", "False", ")", ".", "values", "\n", "return", "torch", ".", "tensor", "(", "gt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.TrackingNet.get_sequence_info": [[111, 117], ["tracking_net.TrackingNet._read_bb_anno", "valid.clone().byte", "valid.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._read_bb_anno"], ["", "def", "get_sequence_info", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "bbox", "=", "self", ".", "_read_bb_anno", "(", "seq_id", ")", "\n", "\n", "valid", "=", "(", "bbox", "[", ":", ",", "2", "]", ">", "0", ")", "&", "(", "bbox", "[", ":", ",", "3", "]", ">", "0", ")", "\n", "visible", "=", "valid", ".", "clone", "(", ")", ".", "byte", "(", ")", "\n", "return", "{", "'bbox'", ":", "bbox", ",", "'valid'", ":", "valid", ",", "'visible'", ":", "visible", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.TrackingNet._get_frame": [[118, 123], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "tracking_net.TrackingNet.image_loader", "str", "str"], "methods", ["None"], ["", "def", "_get_frame", "(", "self", ",", "seq_id", ",", "frame_id", ")", ":", "\n", "        ", "set_id", "=", "self", ".", "sequence_list", "[", "seq_id", "]", "[", "0", "]", "\n", "vid_name", "=", "self", ".", "sequence_list", "[", "seq_id", "]", "[", "1", "]", "\n", "frame_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"TRAIN_\"", "+", "str", "(", "set_id", ")", ",", "\"frames\"", ",", "vid_name", ",", "str", "(", "frame_id", ")", "+", "\".jpg\"", ")", "\n", "return", "self", ".", "image_loader", "(", "frame_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.TrackingNet._get_class": [[124, 127], ["None"], "methods", ["None"], ["", "def", "_get_class", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "seq_name", "=", "self", ".", "sequence_list", "[", "seq_id", "]", "[", "1", "]", "\n", "return", "self", ".", "seq_to_class_map", "[", "seq_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.TrackingNet.get_class_name": [[128, 132], ["tracking_net.TrackingNet._get_class"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_class"], ["", "def", "get_class_name", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "obj_class", "=", "self", ".", "_get_class", "(", "seq_id", ")", "\n", "\n", "return", "obj_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.TrackingNet.get_frames": [[133, 152], ["tracking_net.TrackingNet.items", "tracking_net.TrackingNet._get_class", "collections.OrderedDict", "tracking_net.TrackingNet._get_frame", "tracking_net.TrackingNet.get_sequence_info", "value[].clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_class", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID._get_frame", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info"], ["", "def", "get_frames", "(", "self", ",", "seq_id", ",", "frame_ids", ",", "anno", "=", "None", ")", ":", "\n", "        ", "frame_list", "=", "[", "self", ".", "_get_frame", "(", "seq_id", ",", "f", ")", "for", "f", "in", "frame_ids", "]", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_sequence_info", "(", "seq_id", ")", "\n", "\n", "", "anno_frames", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "anno", ".", "items", "(", ")", ":", "\n", "            ", "anno_frames", "[", "key", "]", "=", "[", "value", "[", "f_id", ",", "...", "]", ".", "clone", "(", ")", "for", "f_id", "in", "frame_ids", "]", "\n", "\n", "", "obj_class", "=", "self", ".", "_get_class", "(", "seq_id", ")", "\n", "\n", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "obj_class", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "\n", "return", "frame_list", ",", "anno_frames", ",", "object_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.tracking_net.list_sequences": [[14, 33], ["os.path.join", "os.path.join", "str", "os.listdir", "os.listdir", "f.endswith", "os.path.splitext", "os.path.splitext"], "function", ["None"], ["def", "list_sequences", "(", "root", ",", "set_ids", ")", ":", "\n", "    ", "\"\"\" Lists all the videos in the input set_ids. Returns a list of tuples (set_id, video_name)\n\n    args:\n        root: Root directory to TrackingNet\n        set_ids: Sets (0-11) which are to be used\n\n    returns:\n        list - list of tuples (set_id, video_name) containing the set_id and video_name for each sequence\n    \"\"\"", "\n", "sequence_list", "=", "[", "]", "\n", "\n", "for", "s", "in", "set_ids", ":", "\n", "        ", "anno_dir", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"TRAIN_\"", "+", "str", "(", "s", ")", ",", "\"anno\"", ")", "\n", "\n", "sequences_cur_set", "=", "[", "(", "s", ",", "os", ".", "path", ".", "splitext", "(", "f", ")", "[", "0", "]", ")", "for", "f", "in", "os", ".", "listdir", "(", "anno_dir", ")", "if", "f", ".", "endswith", "(", "'.txt'", ")", "]", "\n", "sequence_list", "+=", "sequences_cur_set", "\n", "\n", "", "return", "sequence_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k.__init__": [[26, 74], ["base_video_dataset.BaseVideoDataset.__init__", "got10k.Got10k._get_sequence_list", "got10k.Got10k._load_meta_info", "got10k.Got10k._build_seq_per_class", "list", "got10k.Got10k.class_list.sort", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "pandas.read_csv().values.tolist", "random.sample", "got10k.Got10k.seq_per_class.keys", "ltr.admin.environment.env_settings", "ValueError", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "list", "int", "os.path.realpath", "os.path.realpath", "os.path.realpath", "os.path.realpath", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "range", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "pandas.read_csv", "len", "len", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "ValueError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._get_sequence_list", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k._load_meta_info", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._build_seq_per_class", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "image_loader", "=", "jpeg4py_loader", ",", "split", "=", "None", ",", "seq_ids", "=", "None", ",", "data_fraction", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - path to the got-10k training data. Note: This should point to the 'train' folder inside GOT-10k\n            image_loader (jpeg4py_loader) -  The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                                            is used by default.\n            split - 'train' or 'val'. Note: The validation split here is a subset of the official got-10k train split,\n                    not NOT the official got-10k validation split. To use the official validation split, provide that as\n                    the root folder instead.\n            seq_ids - List containing the ids of the videos to be used for training. Note: Only one of 'split' or 'seq_ids'\n                        options can be used at the same time.\n            data_fraction - Fraction of dataset to be used. The complete dataset is used by default\n        \"\"\"", "\n", "root", "=", "env_settings", "(", ")", ".", "got10k_dir", "if", "root", "is", "None", "else", "root", "\n", "super", "(", ")", ".", "__init__", "(", "'GOT10k'", ",", "root", ",", "image_loader", ")", "\n", "\n", "# all folders inside the root", "\n", "self", ".", "sequence_list", "=", "self", ".", "_get_sequence_list", "(", ")", "\n", "\n", "# seq_id is the index of the folder inside the got10k root path", "\n", "if", "split", "is", "not", "None", ":", "\n", "            ", "if", "seq_ids", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "'Cannot set both split_name and seq_ids.'", ")", "\n", "", "ltr_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ",", "'..'", ")", "\n", "if", "split", "==", "'train'", ":", "\n", "                ", "file_path", "=", "os", ".", "path", ".", "join", "(", "ltr_path", ",", "'data_specs'", ",", "'got10k_train_split.txt'", ")", "\n", "", "elif", "split", "==", "'val'", ":", "\n", "                ", "file_path", "=", "os", ".", "path", ".", "join", "(", "ltr_path", ",", "'data_specs'", ",", "'got10k_val_split.txt'", ")", "\n", "", "elif", "split", "==", "'vottrain'", ":", "\n", "                ", "file_path", "=", "os", ".", "path", ".", "join", "(", "ltr_path", ",", "'data_specs'", ",", "'got10k_vot_train_split.txt'", ")", "\n", "", "elif", "split", "==", "'votval'", ":", "\n", "                ", "file_path", "=", "os", ".", "path", ".", "join", "(", "ltr_path", ",", "'data_specs'", ",", "'got10k_vot_val_split.txt'", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown split name.'", ")", "\n", "", "seq_ids", "=", "pandas", ".", "read_csv", "(", "file_path", ",", "header", "=", "None", ",", "squeeze", "=", "True", ",", "dtype", "=", "np", ".", "int64", ")", ".", "values", ".", "tolist", "(", ")", "\n", "", "elif", "seq_ids", "is", "None", ":", "\n", "            ", "seq_ids", "=", "list", "(", "range", "(", "0", ",", "len", "(", "self", ".", "sequence_list", ")", ")", ")", "\n", "\n", "", "self", ".", "sequence_list", "=", "[", "self", ".", "sequence_list", "[", "i", "]", "for", "i", "in", "seq_ids", "]", "\n", "\n", "if", "data_fraction", "is", "not", "None", ":", "\n", "            ", "self", ".", "sequence_list", "=", "random", ".", "sample", "(", "self", ".", "sequence_list", ",", "int", "(", "len", "(", "self", ".", "sequence_list", ")", "*", "data_fraction", ")", ")", "\n", "\n", "", "self", ".", "sequence_meta_info", "=", "self", ".", "_load_meta_info", "(", ")", "\n", "self", ".", "seq_per_class", "=", "self", ".", "_build_seq_per_class", "(", ")", "\n", "\n", "self", ".", "class_list", "=", "list", "(", "self", ".", "seq_per_class", ".", "keys", "(", ")", ")", "\n", "self", ".", "class_list", ".", "sort", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k.get_name": [[75, 77], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "'got10k'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k.has_class_info": [[78, 80], ["None"], "methods", ["None"], ["", "def", "has_class_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k.has_occlusion_info": [[81, 83], ["None"], "methods", ["None"], ["", "def", "has_occlusion_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k._load_meta_info": [[84, 87], ["got10k.Got10k._read_meta", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k._read_meta"], ["", "def", "_load_meta_info", "(", "self", ")", ":", "\n", "        ", "sequence_meta_info", "=", "{", "s", ":", "self", ".", "_read_meta", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "s", ")", ")", "for", "s", "in", "self", ".", "sequence_list", "}", "\n", "return", "sequence_meta_info", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k._read_meta": [[88, 104], ["collections.OrderedDict", "open", "f.readlines", "collections.OrderedDict", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "meta_info[].split", "meta_info[].split", "meta_info[].split", "meta_info[].split", "meta_info[].split"], "methods", ["None"], ["", "def", "_read_meta", "(", "self", ",", "seq_path", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "seq_path", ",", "'meta_info.ini'", ")", ")", "as", "f", ":", "\n", "                ", "meta_info", "=", "f", ".", "readlines", "(", ")", "\n", "", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "meta_info", "[", "5", "]", ".", "split", "(", "': '", ")", "[", "-", "1", "]", "[", ":", "-", "1", "]", ",", "\n", "'motion_class'", ":", "meta_info", "[", "6", "]", ".", "split", "(", "': '", ")", "[", "-", "1", "]", "[", ":", "-", "1", "]", ",", "\n", "'major_class'", ":", "meta_info", "[", "7", "]", ".", "split", "(", "': '", ")", "[", "-", "1", "]", "[", ":", "-", "1", "]", ",", "\n", "'root_class'", ":", "meta_info", "[", "8", "]", ".", "split", "(", "': '", ")", "[", "-", "1", "]", "[", ":", "-", "1", "]", ",", "\n", "'motion_adverb'", ":", "meta_info", "[", "9", "]", ".", "split", "(", "': '", ")", "[", "-", "1", "]", "[", ":", "-", "1", "]", "}", ")", "\n", "", "except", ":", "\n", "            ", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "None", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "", "return", "object_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k._build_seq_per_class": [[105, 116], ["enumerate", "seq_per_class[].append"], "methods", ["None"], ["", "def", "_build_seq_per_class", "(", "self", ")", ":", "\n", "        ", "seq_per_class", "=", "{", "}", "\n", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "self", ".", "sequence_list", ")", ":", "\n", "            ", "object_class", "=", "self", ".", "sequence_meta_info", "[", "s", "]", "[", "'object_class_name'", "]", "\n", "if", "object_class", "in", "seq_per_class", ":", "\n", "                ", "seq_per_class", "[", "object_class", "]", ".", "append", "(", "i", ")", "\n", "", "else", ":", "\n", "                ", "seq_per_class", "[", "object_class", "]", "=", "[", "i", "]", "\n", "\n", "", "", "return", "seq_per_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k.get_sequences_in_class": [[117, 119], ["None"], "methods", ["None"], ["", "def", "get_sequences_in_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "return", "self", ".", "seq_per_class", "[", "class_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k._get_sequence_list": [[120, 125], ["open", "list", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "csv.reader"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "_get_sequence_list", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'list.txt'", ")", ")", "as", "f", ":", "\n", "            ", "dir_list", "=", "list", "(", "csv", ".", "reader", "(", "f", ")", ")", "\n", "", "dir_list", "=", "[", "dir_name", "[", "0", "]", "for", "dir_name", "in", "dir_list", "]", "\n", "return", "dir_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k._read_bb_anno": [[126, 130], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.tensor", "pandas.read_csv"], "methods", ["None"], ["", "def", "_read_bb_anno", "(", "self", ",", "seq_path", ")", ":", "\n", "        ", "bb_anno_file", "=", "os", ".", "path", ".", "join", "(", "seq_path", ",", "\"groundtruth.txt\"", ")", "\n", "gt", "=", "pandas", ".", "read_csv", "(", "bb_anno_file", ",", "delimiter", "=", "','", ",", "header", "=", "None", ",", "dtype", "=", "np", ".", "float32", ",", "na_filter", "=", "False", ",", "low_memory", "=", "False", ")", ".", "values", "\n", "return", "torch", ".", "tensor", "(", "gt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k._read_target_visible": [[131, 145], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "torch.ByteTensor", "open", "torch.ByteTensor", "torch.ByteTensor.float", "int", "int", "csv.reader", "csv.reader"], "methods", ["None"], ["", "def", "_read_target_visible", "(", "self", ",", "seq_path", ")", ":", "\n", "# Read full occlusion and out_of_view", "\n", "        ", "occlusion_file", "=", "os", ".", "path", ".", "join", "(", "seq_path", ",", "\"absence.label\"", ")", "\n", "cover_file", "=", "os", ".", "path", ".", "join", "(", "seq_path", ",", "\"cover.label\"", ")", "\n", "\n", "with", "open", "(", "occlusion_file", ",", "'r'", ",", "newline", "=", "''", ")", "as", "f", ":", "\n", "            ", "occlusion", "=", "torch", ".", "ByteTensor", "(", "[", "int", "(", "v", "[", "0", "]", ")", "for", "v", "in", "csv", ".", "reader", "(", "f", ")", "]", ")", "\n", "", "with", "open", "(", "cover_file", ",", "'r'", ",", "newline", "=", "''", ")", "as", "f", ":", "\n", "            ", "cover", "=", "torch", ".", "ByteTensor", "(", "[", "int", "(", "v", "[", "0", "]", ")", "for", "v", "in", "csv", ".", "reader", "(", "f", ")", "]", ")", "\n", "\n", "", "target_visible", "=", "~", "occlusion", "&", "(", "cover", ">", "0", ")", ".", "byte", "(", ")", "\n", "\n", "visible_ratio", "=", "cover", ".", "float", "(", ")", "/", "8", "\n", "return", "target_visible", ",", "visible_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k._get_sequence_path": [[146, 148], ["os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "_get_sequence_path", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "sequence_list", "[", "seq_id", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k.get_sequence_info": [[149, 158], ["got10k.Got10k._get_sequence_path", "got10k.Got10k._read_bb_anno", "got10k.Got10k._read_target_visible", "valid.byte"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_sequence_path", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._read_bb_anno", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._read_target_visible"], ["", "def", "get_sequence_info", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "seq_path", "=", "self", ".", "_get_sequence_path", "(", "seq_id", ")", "\n", "bbox", "=", "self", ".", "_read_bb_anno", "(", "seq_path", ")", "\n", "\n", "valid", "=", "(", "bbox", "[", ":", ",", "2", "]", ">", "0", ")", "&", "(", "bbox", "[", ":", ",", "3", "]", ">", "0", ")", "\n", "visible", ",", "visible_ratio", "=", "self", ".", "_read_target_visible", "(", "seq_path", ")", "\n", "visible", "=", "visible", "&", "valid", ".", "byte", "(", ")", "\n", "\n", "return", "{", "'bbox'", ":", "bbox", ",", "'valid'", ":", "valid", ",", "'visible'", ":", "visible", ",", "'visible_ratio'", ":", "visible_ratio", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k._get_frame_path": [[159, 161], ["os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "_get_frame_path", "(", "self", ",", "seq_path", ",", "frame_id", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "seq_path", ",", "'{:08}.jpg'", ".", "format", "(", "frame_id", "+", "1", ")", ")", "# frames start from 1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k._get_frame": [[162, 164], ["got10k.Got10k.image_loader", "got10k.Got10k._get_frame_path"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_frame_path"], ["", "def", "_get_frame", "(", "self", ",", "seq_path", ",", "frame_id", ")", ":", "\n", "        ", "return", "self", ".", "image_loader", "(", "self", ".", "_get_frame_path", "(", "seq_path", ",", "frame_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k.get_class_name": [[165, 169], ["None"], "methods", ["None"], ["", "def", "get_class_name", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "obj_meta", "=", "self", ".", "sequence_meta_info", "[", "self", ".", "sequence_list", "[", "seq_id", "]", "]", "\n", "\n", "return", "obj_meta", "[", "'object_class_name'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.got10k.Got10k.get_frames": [[170, 184], ["got10k.Got10k._get_sequence_path", "got10k.Got10k.items", "got10k.Got10k._get_frame", "got10k.Got10k.get_sequence_info", "value[].clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_sequence_path", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID._get_frame", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info"], ["", "def", "get_frames", "(", "self", ",", "seq_id", ",", "frame_ids", ",", "anno", "=", "None", ")", ":", "\n", "        ", "seq_path", "=", "self", ".", "_get_sequence_path", "(", "seq_id", ")", "\n", "obj_meta", "=", "self", ".", "sequence_meta_info", "[", "self", ".", "sequence_list", "[", "seq_id", "]", "]", "\n", "\n", "frame_list", "=", "[", "self", ".", "_get_frame", "(", "seq_path", ",", "f_id", ")", "for", "f_id", "in", "frame_ids", "]", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_sequence_info", "(", "seq_id", ")", "\n", "\n", "", "anno_frames", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "anno", ".", "items", "(", ")", ":", "\n", "            ", "anno_frames", "[", "key", "]", "=", "[", "value", "[", "f_id", ",", "...", "]", ".", "clone", "(", ")", "for", "f_id", "in", "frame_ids", "]", "\n", "\n", "", "return", "frame_list", ",", "anno_frames", ",", "obj_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.hku_is.HKUIS.__init__": [[23, 39], ["base_image_dataset.BaseImageDataset.__init__", "hku_is.HKUIS._load_dataset", "ltr.admin.environment.env_settings"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._load_dataset", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "image_loader", "=", "jpeg4py_loader", ",", "data_fraction", "=", "None", ",", "min_area", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - path to HKU-IS root folder\n            image_loader (jpeg4py_loader) - The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                                            is used by default.\n            data_fraction - Fraction of dataset to be used. The complete dataset is used by default\n            min_area - Objects with area less than min_area are filtered out. Default is 0.0\n        \"\"\"", "\n", "root", "=", "env_settings", "(", ")", ".", "hkuis_dir", "if", "root", "is", "None", "else", "root", "\n", "super", "(", ")", ".", "__init__", "(", "'HKUIS'", ",", "root", ",", "image_loader", ")", "\n", "\n", "self", ".", "image_list", ",", "self", ".", "anno_list", "=", "self", ".", "_load_dataset", "(", "min_area", "=", "min_area", ")", "\n", "\n", "if", "data_fraction", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.hku_is.HKUIS._load_dataset": [[40, 56], ["os.listdir", "os.path.join", "ltr.data.image_loader.imread_indexed", "os.path.join", "ltr.data.image_loader.opencv_loader", "images.append", "annos.append", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.imread_indexed", "home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.opencv_loader"], ["", "", "def", "_load_dataset", "(", "self", ",", "min_area", "=", "None", ")", ":", "\n", "        ", "files_list", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'imgs'", ")", ")", "\n", "image_list", "=", "[", "f", "[", ":", "-", "4", "]", "for", "f", "in", "files_list", "]", "\n", "\n", "images", "=", "[", "]", "\n", "annos", "=", "[", "]", "\n", "\n", "for", "f", "in", "image_list", ":", "\n", "            ", "a", "=", "imread_indexed", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'gt'", ",", "'{}.png'", ".", "format", "(", "f", ")", ")", ")", "\n", "\n", "if", "min_area", "is", "None", "or", "(", "a", ">", "0", ")", ".", "sum", "(", ")", ">", "min_area", ":", "\n", "                ", "im", "=", "opencv_loader", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'imgs'", ",", "'{}.png'", ".", "format", "(", "f", ")", ")", ")", "\n", "images", ".", "append", "(", "im", ")", "\n", "annos", ".", "append", "(", "a", ")", "\n", "\n", "", "", "return", "images", ",", "annos", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.hku_is.HKUIS.get_name": [[57, 59], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "'hku-is'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.hku_is.HKUIS.has_segmentation_info": [[60, 62], ["None"], "methods", ["None"], ["", "def", "has_segmentation_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.hku_is.HKUIS.get_image_info": [[63, 72], ["torch.Tensor", "ltr.data.bounding_box_utils.masks_to_bboxes().view", "valid.clone().byte", "ltr.data.bounding_box_utils.masks_to_bboxes", "valid.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.masks_to_bboxes"], ["", "def", "get_image_info", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "mask", "=", "self", ".", "anno_list", "[", "im_id", "]", "\n", "mask", "=", "torch", ".", "Tensor", "(", "mask", "==", "255", ")", "\n", "bbox", "=", "masks_to_bboxes", "(", "mask", ",", "fmt", "=", "'t'", ")", ".", "view", "(", "4", ",", ")", "\n", "\n", "valid", "=", "(", "bbox", "[", "2", "]", ">", "0", ")", "&", "(", "bbox", "[", "3", "]", ">", "0", ")", "\n", "visible", "=", "valid", ".", "clone", "(", ")", ".", "byte", "(", ")", "\n", "\n", "return", "{", "'bbox'", ":", "bbox", ",", "'mask'", ":", "mask", ",", "'valid'", ":", "valid", ",", "'visible'", ":", "visible", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.hku_is.HKUIS.get_meta_info": [[73, 81], ["collections.OrderedDict"], "methods", ["None"], ["", "def", "get_meta_info", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "None", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "\n", "return", "object_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.hku_is.HKUIS.get_image": [[82, 91], ["hku_is.HKUIS.get_meta_info", "hku_is.HKUIS.get_image_info"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_meta_info", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image_info"], ["", "def", "get_image", "(", "self", ",", "image_id", ",", "anno", "=", "None", ")", ":", "\n", "        ", "frame", "=", "self", ".", "image_list", "[", "image_id", "]", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_image_info", "(", "image_id", ")", "\n", "\n", "", "object_meta", "=", "self", ".", "get_meta_info", "(", "image_id", ")", "\n", "\n", "return", "frame", ",", "anno", ",", "object_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.__init__": [[14, 21], ["vos_base.VOSMeta.load", "ValueError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load"], ["    ", "def", "__init__", "(", "self", ",", "data", "=", "None", ",", "filename", "=", "None", ")", ":", "\n", "        ", "if", "filename", "is", "not", "None", ":", "\n", "            ", "self", ".", "load", "(", "filename", ")", "\n", "", "elif", "data", "is", "not", "None", ":", "\n", "            ", "self", ".", "_data", "=", "data", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Must set either data or filename parameter\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.save": [[22, 25], ["gen_meta.parent.mkdir", "json.dump", "open"], "methods", ["None"], ["", "", "def", "save", "(", "self", ",", "gen_meta", ":", "Path", ")", ":", "\n", "        ", "gen_meta", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "json", ".", "dump", "(", "self", ".", "_data", ",", "open", "(", "gen_meta", ",", "\"w\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load": [[26, 32], ["json.load", "gen_meta.exists", "print", "print", "FileNotFoundError", "open"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load"], ["", "def", "load", "(", "self", ",", "gen_meta", ":", "Path", ")", ":", "\n", "        ", "if", "not", "gen_meta", ".", "exists", "(", ")", ":", "\n", "            ", "print", "(", "\"Generated metadata file %s is not found.\"", "%", "gen_meta", ")", "\n", "print", "(", "\"Find and run VOSMeta.generate() to create it.\"", ")", "\n", "raise", "FileNotFoundError", "(", "gen_meta", ")", "\n", "", "self", ".", "_data", "=", "json", ".", "load", "(", "open", "(", "gen_meta", ")", ",", "object_pairs_hook", "=", "OrderedDict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.generate": [[33, 106], ["dset_annos_path.exists", "collections.OrderedDict", "vos_base.VOSMeta.generate.tqdm"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "generate", "(", "cls", ",", "dset_name", ":", "str", ",", "dset_images_path", ":", "Path", ",", "dset_annos_path", ":", "Path", ")", ":", "\n", "        ", "\"\"\"\n        Count the annotation mask pixels per object, per frame, in all sequences in a dataset\n        :param dset_name:        Dataset name, for printing the progress bar.\n        :param dset_annos_path:  Path to annotations directory, containing sequence directories,\n                                 with annotation frames in them.\n\n        :return: Dataset meta dict:\n\n        {'sequence0':\n            {\n             'shape': (height, width)\n\n             'obj_sizes':  # Object pixels per frame\n                {'frame0': {'object0': px_count, 'object1': px_count, ...},\n                 'frame1': {'object0': px_count, 'object1': px_count, ...},\n                ... },\n\n             'bboxes':  # Bounding boxes per frame\n                {'frame0': {'object0': bbox, 'object1': bbox, ...},\n                 'frame1': {'object0': bbox, 'object1': bbox, ...},\n                ... },\n            ...\n        }\n        \"\"\"", "\n", "assert", "(", "dset_annos_path", ".", "exists", "(", ")", ")", "\n", "\n", "dset_meta", "=", "OrderedDict", "(", ")", "\n", "sequences", "=", "[", "p", ".", "stem", "for", "p", "in", "sorted", "(", "dset_annos_path", ".", "glob", "(", "\"*\"", ")", ")", "if", "p", ".", "is_dir", "(", ")", "]", "\n", "\n", "try", ":", "\n", "            ", "from", "tqdm", "import", "tqdm", "\n", "", "except", ":", "\n", "            ", "def", "tqdm", "(", "x", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                ", "return", "x", "\n", "\n", "", "", "for", "seq", "in", "tqdm", "(", "sequences", ",", "desc", "=", "dset_name", ",", "unit", "=", "\"seq\"", ")", ":", "\n", "\n", "            ", "obj_sizes2", "=", "defaultdict", "(", "OrderedDict", ")", "\n", "bboxes", "=", "defaultdict", "(", "OrderedDict", ")", "\n", "shape", "=", "None", "\n", "frame_names", "=", "[", "file", ".", "stem", "for", "file", "in", "sorted", "(", "(", "dset_images_path", "/", "seq", ")", ".", "glob", "(", "\"*.jpg\"", ")", ")", "]", "\n", "anno_paths", "=", "list", "(", "sorted", "(", "(", "dset_annos_path", "/", "seq", ")", ".", "glob", "(", "\"*.png\"", ")", ")", ")", "\n", "\n", "# Extract information from the given label frames", "\n", "for", "path", "in", "anno_paths", ":", "\n", "                ", "f_id", "=", "path", ".", "stem", "\n", "\n", "# Count label-pixels per frame", "\n", "labels", "=", "imread_indexed", "(", "path", ")", "\n", "# labels = np.array(Image.open(path))", "\n", "obj_ids", ",", "obj_sizes", "=", "np", ".", "unique", "(", "labels", ",", "return_counts", "=", "True", ")", "\n", "obj_ids", "=", "[", "str", "(", "oid", ")", "for", "oid", "in", "obj_ids", "]", "\n", "obj_sizes", "=", "obj_sizes", ".", "tolist", "(", ")", "\n", "\n", "if", "'0'", "in", "obj_ids", ":", "# Remove background id", "\n", "                    ", "obj_ids", "=", "obj_ids", "[", "1", ":", "]", "\n", "obj_sizes", "=", "obj_sizes", "[", "1", ":", "]", "\n", "", "obj_sizes2", "[", "f_id", "]", "=", "OrderedDict", "(", "zip", "(", "obj_ids", ",", "obj_sizes", ")", ")", "\n", "\n", "# Generate per-label bounding boxes", "\n", "for", "obj_id", "in", "obj_ids", ":", "\n", "                    ", "bboxes", "[", "f_id", "]", "[", "obj_id", "]", "=", "cls", ".", "_mask_to_bbox", "(", "labels", "==", "int", "(", "obj_id", ")", ")", "\n", "\n", "", "if", "shape", "is", "None", ":", "\n", "                    ", "shape", "=", "labels", ".", "shape", "[", ":", "2", "]", "\n", "\n", "# Format result", "\n", "\n", "", "", "dset_meta", "[", "seq", "]", "=", "dict", "(", "shape", "=", "shape", ",", "obj_sizes", "=", "obj_sizes2", ",", "bboxes", "=", "bboxes", ",", "frame_names", "=", "frame_names", ")", "\n", "\n", "", "return", "VOSMeta", "(", "dset_meta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta._mask_to_bbox": [[107, 120], ["mask.astype.astype.astype", "[].tolist", "[].tolist", "len", "len", "mask.astype.astype.sum().nonzero", "mask.astype.astype.sum().nonzero", "mask.astype.astype.sum", "mask.astype.astype.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_mask_to_bbox", "(", "mask", ":", "np", ".", "ndarray", ")", ":", "\n", "\n", "        ", "mask", "=", "mask", ".", "astype", "(", "int", ")", "\n", "xs", "=", "mask", ".", "sum", "(", "axis", "=", "-", "2", ")", ".", "nonzero", "(", ")", "[", "0", "]", ".", "tolist", "(", ")", "\n", "ys", "=", "mask", ".", "sum", "(", "axis", "=", "-", "1", ")", ".", "nonzero", "(", ")", "[", "0", "]", ".", "tolist", "(", ")", "\n", "\n", "if", "len", "(", "ys", ")", ">", "0", "and", "len", "(", "xs", ")", ">", "0", ":", "\n", "            ", "x", ",", "y", ",", "w", ",", "h", "=", "xs", "[", "0", "]", ",", "ys", "[", "0", "]", ",", "xs", "[", "-", "1", "]", "-", "xs", "[", "0", "]", ",", "ys", "[", "-", "1", "]", "-", "ys", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "x", ",", "y", ",", "w", ",", "h", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "\n", "", "return", "[", "x", ",", "y", ",", "w", ",", "h", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta._transpose_nested_dict": [[121, 129], ["collections.defaultdict", "d.items", "inner.items"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_transpose_nested_dict", "(", "d", ")", ":", "\n", "        ", "\"\"\" Permute a 2-level nested dict such that the inner and outer keys swap places. \"\"\"", "\n", "d2", "=", "defaultdict", "(", "OrderedDict", ")", "\n", "for", "key1", ",", "inner", "in", "d", ".", "items", "(", ")", ":", "\n", "            ", "for", "key2", ",", "value", "in", "inner", ".", "items", "(", ")", ":", "\n", "                ", "d2", "[", "key2", "]", "[", "key1", "]", "=", "value", "\n", "", "", "return", "d2", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.select_split": [[130, 137], ["os.path.join", "set", "set", "set.difference", "os.path.dirname", "vos_base.VOSMeta._data.keys", "vos_base.VOSMeta._data.pop", "os.path.realpath", "s.strip", "open().readlines", "open", "os.path.join"], "methods", ["None"], ["", "def", "select_split", "(", "self", ",", "dataset_name", ",", "split", ")", ":", "\n", "        ", "ltr_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ",", "'..'", ")", "\n", "sequences", "=", "set", "(", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "open", "(", "os", ".", "path", ".", "join", "(", "ltr_path", ",", "'data_specs'", ",", "dataset_name", "+", "'_'", "+", "split", "+", "'.txt'", ")", ")", ".", "readlines", "(", ")", "]", ")", "\n", "all_sequences", "=", "set", "(", "self", ".", "_data", ".", "keys", "(", ")", ")", "\n", "to_remove", "=", "all_sequences", ".", "difference", "(", "sequences", ")", "\n", "for", "seq_name", "in", "to_remove", ":", "\n", "            ", "self", ".", "_data", ".", "pop", "(", "seq_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_sequence_names": [[138, 140], ["list", "vos_base.VOSMeta._data.keys"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "", "def", "get_sequence_names", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "self", ".", "_data", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_shape": [[141, 145], ["None"], "methods", ["None"], ["", "def", "get_shape", "(", "self", ",", "seq_name", ")", ":", "\n", "        ", "\"\"\" Sequence image shape (h,w) \"\"\"", "\n", "h", ",", "w", "=", "self", ".", "_data", "[", "seq_name", "]", "[", "'shape'", "]", "\n", "return", "h", ",", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_obj_ids": [[146, 149], ["list", "vos_base.VOSMeta.get_obj_sizes_per_object().keys", "vos_base.VOSMeta.get_obj_sizes_per_object"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_obj_sizes_per_object"], ["", "def", "get_obj_ids", "(", "self", ",", "seq_name", ")", ":", "\n", "        ", "\"\"\" All objects in the sequence \"\"\"", "\n", "return", "list", "(", "self", ".", "get_obj_sizes_per_object", "(", "seq_name", ")", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_frame_names": [[150, 153], ["None"], "methods", ["None"], ["", "def", "get_frame_names", "(", "self", ",", "seq_name", ")", ":", "\n", "        ", "\"\"\" All filename stems of the frames in the sequence \"\"\"", "\n", "return", "self", ".", "_data", "[", "seq_name", "]", "[", "'frame_names'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.enable_all_frames": [[154, 178], ["idx_file.exists", "dict.items", "print", "json.load", "dict", "print", "json.dump", "print", "open", "pathlib.Path.home", "open", "sorted"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load"], ["", "def", "enable_all_frames", "(", "self", ",", "dset_images_path", ")", ":", "\n", "        ", "\"\"\" For YouTubeVOS: Update the frame names with (jpeg) files from the <split>_all_frames set\n        :param dset_images_path:  /path/to/train_all_frames/JPEGImages (or valid or test)\n        :param seq: Sequence name\n        :return:\n        \"\"\"", "\n", "\n", "# Try load the cached index", "\n", "idx_file", "=", "dset_images_path", ".", "parent", "/", "\"frame_names.json\"", "\n", "if", "idx_file", ".", "exists", "(", ")", ":", "\n", "            ", "print", "(", "'Loading cached frame names from %s'", "%", "idx_file", ")", "\n", "all_frame_names", "=", "json", ".", "load", "(", "open", "(", "idx_file", ")", ")", "\n", "", "else", ":", "\n", "# Cache the data to the user's home directory (guaranteed to be writable)", "\n", "            ", "all_frame_names", "=", "dict", "(", ")", "\n", "user_idx_file", "=", "Path", ".", "home", "(", ")", "/", "(", "dset_images_path", ".", "parent", ".", "stem", "+", "\"_frame_names.json\"", ")", "\n", "print", "(", "'Indexing YouTubeVOS \"all_frames\" frame names to %s'", "%", "user_idx_file", ")", "\n", "for", "seq", "in", "self", ".", "_data", ":", "\n", "                ", "all_frame_names", "[", "seq", "]", "=", "[", "file", ".", "stem", "for", "file", "in", "sorted", "(", "(", "dset_images_path", "/", "seq", ")", ".", "glob", "(", "\"*.jpg\"", ")", ")", "]", "\n", "", "json", ".", "dump", "(", "all_frame_names", ",", "open", "(", "user_idx_file", ",", "\"w\"", ")", ")", "\n", "print", "(", "'Done. Move %s to %s to load faster next time.'", "%", "(", "user_idx_file", ",", "idx_file", ")", ")", "\n", "\n", "", "for", "seq", ",", "frame_names", "in", "all_frame_names", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "_data", "[", "seq", "]", "[", "'frame_names'", "]", "=", "frame_names", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_aspect_ratio": [[179, 183], ["None"], "methods", ["None"], ["", "", "def", "get_aspect_ratio", "(", "self", ",", "seq_name", ")", ":", "\n", "        ", "\"\"\" Sequence aspect ratio \"\"\"", "\n", "h", ",", "w", "=", "self", ".", "_data", "[", "seq_name", "]", "[", "'shape'", "]", "\n", "return", "w", "/", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_obj_sizes_per_frame": [[184, 187], ["None"], "methods", ["None"], ["", "def", "get_obj_sizes_per_frame", "(", "self", ",", "seq_name", ")", ":", "\n", "        ", "\"\"\" Get object pixel counts, grouped by frame names \"\"\"", "\n", "return", "self", ".", "_data", "[", "seq_name", "]", "[", "'obj_sizes'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_bboxes_per_frame": [[188, 191], ["None"], "methods", ["None"], ["", "def", "get_bboxes_per_frame", "(", "self", ",", "seq_name", ")", ":", "\n", "        ", "\"\"\" Object bounding boxes, grouped by frame names \"\"\"", "\n", "return", "self", ".", "_data", "[", "seq_name", "]", "[", "'bboxes'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_obj_sizes_per_object": [[192, 195], ["vos_base.VOSMeta._transpose_nested_dict", "vos_base.VOSMeta.get_obj_sizes_per_frame"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta._transpose_nested_dict", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_obj_sizes_per_frame"], ["", "def", "get_obj_sizes_per_object", "(", "self", ",", "seq_name", ")", ":", "\n", "        ", "\"\"\" Object pixel counts, grouped by object \"\"\"", "\n", "return", "self", ".", "_transpose_nested_dict", "(", "self", ".", "get_obj_sizes_per_frame", "(", "seq_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_bboxes_per_object": [[196, 199], ["vos_base.VOSMeta._transpose_nested_dict", "vos_base.VOSMeta.get_bboxes_per_frame"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta._transpose_nested_dict", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_bboxes_per_frame"], ["", "def", "get_bboxes_per_object", "(", "self", ",", "seq_name", ")", ":", "\n", "        ", "\"\"\" Object bounding boxes, grouped by object \"\"\"", "\n", "return", "self", ".", "_transpose_nested_dict", "(", "self", ".", "get_bboxes_per_frame", "(", "seq_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.generate_datasets_meta": [[200, 203], ["pathlib.Path().expanduser", "VOSMeta.generate().save", "pathlib.Path", "vos_base.VOSMeta.generate"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.save", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.generate"], ["", "@", "staticmethod", "\n", "def", "generate_datasets_meta", "(", "src", ",", "dst", "=", "Path", "(", "\"~/vosdataset_meta\"", ")", ".", "expanduser", "(", ")", ")", ":", "\n", "        ", "VOSMeta", ".", "generate", "(", "\"SyntheticCoco\"", ",", "src", "/", "\"JPEGImages\"", ",", "src", "/", "\"Annotations\"", ")", ".", "save", "(", "src", "/", "\"generated_meta.json\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.__init__": [[209, 233], ["base_video_dataset.BaseVideoDataset.__init__", "root.exists", "root.is_dir"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "name", ":", "str", ",", "root", ":", "Path", ",", "version", "=", "None", ",", "split", "=", "'train'", ",", "\n", "multiobj", "=", "True", ",", "vis_threshold", "=", "10", ",", "image_loader", "=", "jpeg4py_loader", ")", ":", "\n", "        ", "\"\"\"\n        :param root:            Dataset root path, eg /path/to/DAVIS or /path/to/YouTubeVOS/\n                                Note: YouTubeVOS 2018 and 2019 are expected to be in\n                                /path/to/YouTubeVOS/2018 and /path/to/YouTubeVOS/2019, respectively\n        :param name:            'DAVIS' or 'YouTubeVOS' (case sensitive)\n        :param version:         DAVIS: '2016', '2017, YouTubeVOS: '2018' or '2019'\n        :param split:           DAVIS: Any name in DAVIS/ImageSets/<year>,\n                                YouTubeVOS: 'test', 'train', 'valid' or 'jjtrain', 'jjvalid'\n        :param multiobj:        Whether the dataset will return all objects in a sequence or\n                                multiple sequences with one object in each.\n        :param vis_threshold:   Minimum number of pixels required to consider a target object \"visible\".\n        :param image_loader:    Image loader.\n        \"\"\"", "\n", "\n", "assert", "root", ".", "exists", "(", ")", "and", "root", ".", "is_dir", "(", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "name", ",", "root", ",", "image_loader", ")", "\n", "\n", "self", ".", "version", "=", "version", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "vis_threshold", "=", "vis_threshold", "\n", "self", ".", "multiobj", "=", "multiobj", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase._load_image": [[234, 239], ["vos_base.VOSDatasetBase.image_loader", "numpy.atleast_3d", "str"], "methods", ["None"], ["", "def", "_load_image", "(", "self", ",", "path", ")", ":", "\n", "        ", "im", "=", "self", ".", "image_loader", "(", "str", "(", "path", ")", ")", "\n", "assert", "im", "is", "not", "None", "\n", "im", "=", "np", ".", "atleast_3d", "(", "im", ")", "\n", "return", "im", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase._load_anno": [[240, 247], ["ltr.data.image_loader.imread_indexed", "path.exists"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.imread_indexed"], ["", "@", "staticmethod", "\n", "def", "_load_anno", "(", "path", ")", ":", "\n", "        ", "if", "not", "path", ".", "exists", "(", ")", ":", "\n", "            ", "return", "None", "\n", "# im = np.atleast_3d(np.array(Image.open(path)))", "\n", "", "im", "=", "imread_indexed", "(", "path", ")", "\n", "return", "im", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.get_num_sequences": [[248, 250], ["len"], "methods", ["None"], ["", "def", "get_num_sequences", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.get_sequence_info": [[251, 285], ["m.get_frame_names", "torch.zeros", "m.get_obj_sizes_per_object", "dict", "frames.items", "enumerate", "enumerate", "len", "len", "m.get_shape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_frame_names", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_obj_sizes_per_object", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_shape"], ["", "def", "get_sequence_info", "(", "self", ",", "sample_id", ")", ":", "\n", "        ", "\"\"\" Get sample meta data.\n        :param sample_id:  Sample to query.\n        :return: dict of metadata:\n                sequence:    Sequence name\n                frame_shape: (height, width) of the images\n                frame_names: List of frame filename stems in the sequence\n                object_ids:  Id numbers of all objects occurring in the sequence\n                obj_sizes:   Matrix shape=(frames, object) of the number of pixels for each object in each frame\n                             Coordinates in this matrix relate to the frame_names and object_ids\n                visible:     Boolean matrix of the same shape as obj_sizes. Entries with more pixels\n                             than self.visible_threshold are True.\n        \"\"\"", "\n", "m", "=", "self", ".", "gmeta", "\n", "seq_name", ",", "obj_ids", "=", "self", ".", "_samples", "[", "sample_id", "]", "\n", "f_names", "=", "m", ".", "get_frame_names", "(", "seq_name", ")", "# All frames", "\n", "\n", "f2i", "=", "{", "f", ":", "i", "for", "i", ",", "f", "in", "enumerate", "(", "f_names", ")", "}", "# Frame name to matrix index", "\n", "o2i", "=", "{", "o", ":", "i", "for", "i", ",", "o", "in", "enumerate", "(", "obj_ids", ")", "}", "# Object id to matrix index", "\n", "\n", "# Get a matrix of object sizes: shape=(frames, objects)", "\n", "obj_sizes", "=", "torch", ".", "zeros", "(", "(", "len", "(", "f_names", ")", ",", "len", "(", "obj_ids", ")", ")", ",", "dtype", "=", "torch", ".", "int", ")", "\n", "sizes_per_object", "=", "m", ".", "get_obj_sizes_per_object", "(", "seq_name", ")", "\n", "\n", "for", "obj_id", "in", "obj_ids", ":", "\n", "            ", "frames", "=", "sizes_per_object", "[", "obj_id", "]", "\n", "oid", "=", "o2i", "[", "obj_id", "]", "\n", "for", "f", ",", "sz", "in", "frames", ".", "items", "(", ")", ":", "\n", "                ", "obj_sizes", "[", "f2i", "[", "f", "]", ",", "oid", "]", "=", "sz", "\n", "\n", "", "", "visible", "=", "(", "obj_sizes", ">", "self", ".", "vis_threshold", ")", ".", "byte", "(", ")", "\n", "\n", "return", "dict", "(", "sequence", "=", "seq_name", ",", "frame_shape", "=", "m", ".", "get_shape", "(", "seq_name", ")", ",", "frame_names", "=", "f_names", ",", "object_ids", "=", "obj_ids", ",", "\n", "object_sizes", "=", "obj_sizes", ",", "visible", "=", "visible", ",", "valid", "=", "visible", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.get_paths_and_bboxes": [[286, 307], ["vos_base.VOSDatasetBase.gmeta.get_bboxes_per_frame", "collections.OrderedDict", "str", "numpy.array", "enumerate", "str", "vos_base.VOSDatasetBase.keys", "vos_base.VOSDatasetBase.get().get", "vos_base.VOSDatasetBase.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_bboxes_per_frame", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "get_paths_and_bboxes", "(", "self", ",", "sequence_info", ")", ":", "\n", "\n", "        ", "seq_name", "=", "sequence_info", "[", "'sequence'", "]", "\n", "annos_root", "=", "self", ".", "_anno_path", "/", "seq_name", "\n", "images_root", "=", "self", ".", "_jpeg_path", "/", "seq_name", "\n", "\n", "frame_names", "=", "sequence_info", "[", "'frame_names'", "]", "\n", "f2i", "=", "{", "f", ":", "i", "for", "i", ",", "f", "in", "enumerate", "(", "frame_names", ")", "}", "\n", "\n", "images", "=", "[", "str", "(", "images_root", "/", "(", "f", "+", "\".jpg\"", ")", ")", "for", "f", "in", "frame_names", "]", "\n", "\n", "# Find the frames where ground truth is available and", "\n", "# get the bounding boxes and segmentation labels of those frames", "\n", "all_bboxes", "=", "self", ".", "gmeta", ".", "get_bboxes_per_frame", "(", "seq_name", ")", "\n", "gt_labels", "=", "[", "str", "(", "annos_root", "/", "(", "f", "+", "\".png\"", ")", ")", "if", "f", "in", "all_bboxes", ".", "keys", "(", ")", "else", "None", "for", "f", "in", "frame_names", "]", "\n", "\n", "gt_bboxes", "=", "OrderedDict", "(", ")", "\n", "for", "obj_id", "in", "sequence_info", "[", "'object_ids'", "]", ":", "\n", "            ", "gt_bboxes", "[", "obj_id", "]", "=", "np", ".", "array", "(", "[", "all_bboxes", ".", "get", "(", "frame", ",", "{", "}", ")", ".", "get", "(", "obj_id", ",", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", ")", "for", "frame", "in", "frame_names", "]", ")", "\n", "\n", "", "return", "images", ",", "gt_labels", ",", "gt_bboxes", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase._construct_sequence": [[308, 310], ["None"], "methods", ["None"], ["", "def", "_construct_sequence", "(", "self", ",", "sequence_info", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.get_sequence_list": [[311, 316], ["len", "vos_base.VOSDatasetBase._construct_sequence", "vos_base.VOSDatasetBase.get_sequence_info", "range", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info"], ["", "def", "get_sequence_list", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "sequence_list", ")", ">", "0", ":", "\n", "            ", "return", "self", ".", "sequence_list", "\n", "", "self", ".", "sequence_list", "=", "[", "self", ".", "_construct_sequence", "(", "self", ".", "get_sequence_info", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "_samples", ")", ")", "]", "\n", "return", "self", ".", "sequence_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.__len__": [[317, 319], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase._get_image_path": [[320, 322], ["None"], "methods", ["None"], ["", "def", "_get_image_path", "(", "self", ",", "meta", ",", "frame_id", ")", ":", "\n", "        ", "return", "self", ".", "_jpeg_path", "/", "meta", "[", "'sequence'", "]", "/", "(", "meta", "[", "'frame_names'", "]", "[", "frame_id", "]", "+", "\".jpg\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase._get_anno_path": [[323, 325], ["None"], "methods", ["None"], ["", "def", "_get_anno_path", "(", "self", ",", "meta", ",", "frame_id", ")", ":", "\n", "        ", "return", "self", ".", "_anno_path", "/", "meta", "[", "'sequence'", "]", "/", "(", "meta", "[", "'frame_names'", "]", "[", "frame_id", "]", "+", "\".png\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.get_frames": [[326, 378], ["dict", "vos_base.VOSDatasetBase.get_sequence_info", "vos_base.VOSDatasetBase._load_image", "vos_base.VOSDatasetBase._load_anno", "torch.from_numpy", "bboxes.append", "torch.from_numpy.squeeze", "ltr.data.bounding_box_utils.masks_to_bboxes", "len", "torch.Tensor", "torch.Tensor", "value[].clone", "print", "torch.zeros", "int", "int"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase._load_image", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase._load_anno", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.masks_to_bboxes"], ["", "def", "get_frames", "(", "self", ",", "sample_id", ",", "frame_ids", ",", "anno", "=", "None", ")", ":", "\n", "        ", "\"\"\"  Fetch frames with the given ids.\n        :param sample_id:  Sample to get.\n        :param frame_ids:  List of frame indices in the sequence belonging to the sample_id\n        :return: dict of metadata and data:\n                sequence:  Sequence name\n                images:    List of images. No entries may be None\n                labels:    List of label/mask images. Entries may be None if the data is missing\n                bboxes:    List of bounding boxes. Entries may be None if the data is missing\n        \"\"\"", "\n", "seq_name", ",", "obj_ids", "=", "self", ".", "_samples", "[", "sample_id", "]", "\n", "\n", "meta", "=", "self", ".", "get_sequence_info", "(", "sample_id", ")", "if", "anno", "is", "None", "else", "anno", "\n", "frame_names", "=", "meta", "[", "'frame_names'", "]", "\n", "images", "=", "[", "self", ".", "_load_image", "(", "self", ".", "_jpeg_path", "/", "seq_name", "/", "(", "frame_names", "[", "f", "]", "+", "\".jpg\"", ")", ")", "for", "f", "in", "frame_ids", "]", "\n", "labels", "=", "[", "self", ".", "_load_anno", "(", "self", ".", "_anno_path", "/", "seq_name", "/", "(", "frame_names", "[", "f", "]", "+", "\".png\"", ")", ")", "for", "f", "in", "frame_ids", "]", "\n", "\n", "# Generate bounding boxes for the requested objects", "\n", "bboxes", "=", "[", "]", "\n", "for", "lb", "in", "labels", ":", "\n", "            ", "lb", "=", "torch", ".", "from_numpy", "(", "lb", ".", "squeeze", "(", ")", ")", "\n", "frame_bbs", "=", "{", "}", "\n", "for", "obj_id", "in", "obj_ids", ":", "\n", "                ", "bbox", "=", "masks_to_bboxes", "(", "lb", "==", "int", "(", "obj_id", ")", ",", "fmt", "=", "'t'", ")", "\n", "if", "bbox", "[", "3", "]", "==", "0", "or", "bbox", "[", "2", "]", "==", "0", ":", "\n", "                    ", "print", "(", "\"!\"", ")", "\n", "", "frame_bbs", "[", "obj_id", "]", "=", "bbox", "\n", "", "bboxes", ".", "append", "(", "frame_bbs", ")", "\n", "\n", "# Insert empty bboxes for missing object ids", "\n", "", "for", "bbox", "in", "bboxes", ":", "\n", "            ", "for", "obj_id", "in", "obj_ids", ":", "\n", "                ", "if", "obj_id", "not", "in", "bbox", ":", "\n", "                    ", "bbox", "[", "obj_id", "]", "=", "torch", ".", "zeros", "(", "4", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "# Remap to object id 1, if requested - for training", "\n", "", "", "", "if", "not", "self", ".", "multiobj", ":", "\n", "            ", "assert", "len", "(", "obj_ids", ")", "==", "1", "\n", "obj_id", "=", "obj_ids", "[", "0", "]", "\n", "labels", "=", "[", "torch", ".", "Tensor", "(", "lb", "==", "int", "(", "obj_id", ")", ")", "for", "lb", "in", "labels", "]", "\n", "bboxes", "=", "[", "bbox", "[", "obj_id", "]", "for", "bbox", "in", "bboxes", "]", "\n", "", "else", ":", "\n", "            ", "labels", "=", "[", "torch", ".", "Tensor", "(", "lb", ")", "for", "lb", "in", "labels", "]", "\n", "\n", "", "object_meta", "=", "{", "key", ":", "meta", "[", "key", "]", "for", "key", "in", "[", "'sequence'", ",", "'frame_shape'", ",", "'frame_names'", ",", "'object_ids'", "]", "}", "\n", "\n", "anno_frames", "=", "dict", "(", "bbox", "=", "bboxes", ",", "mask", "=", "labels", ")", "\n", "for", "key", "in", "[", "'object_sizes'", ",", "'visible'", ",", "'valid'", "]", ":", "\n", "            ", "value", "=", "meta", "[", "key", "]", "\n", "anno_frames", "[", "key", "]", "=", "[", "value", "[", "f_id", ",", "...", "]", ".", "clone", "(", ")", "for", "f_id", "in", "frame_ids", "]", "\n", "\n", "", "return", "images", ",", "anno_frames", ",", "object_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.get_name": [[379, 381], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "\"%s/%s/%s\"", "%", "(", "self", ".", "name", ",", "self", ".", "version", ",", "self", ".", "split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.has_class_info": [[382, 384], ["None"], "methods", ["None"], ["", "def", "has_class_info", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.has_occlusion_info": [[385, 387], ["None"], "methods", ["None"], ["", "def", "has_occlusion_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.get_num_classes": [[388, 390], ["None"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.get_class_list": [[391, 393], ["None"], "methods", ["None"], ["", "def", "get_class_list", "(", "self", ")", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.get_sequences_in_class": [[394, 396], ["None"], "methods", ["None"], ["", "def", "get_sequences_in_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "raise", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.has_segmentation_info": [[397, 399], ["None"], "methods", ["None"], ["", "def", "has_segmentation_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.__init__": [[32, 34], ["json.load", "open"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load"], ["def", "__init__", "(", "self", ",", "dset_split_path", ")", ":", "\n", "        ", "self", ".", "_data", "=", "json", ".", "load", "(", "open", "(", "dset_split_path", "/", "'meta.json'", ")", ")", "[", "'videos'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.sequences": [[35, 37], ["list", "youtubevos.YouTubeVOSMeta._data.keys"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "sequences", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "self", ".", "_data", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.seq_frames": [[38, 45], ["set", "youtubevos.YouTubeVOSMeta.object_ids", "list", "youtubevos.YouTubeVOSMeta.object_frames", "sorted", "set.add"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.object_ids", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.object_frames"], ["", "def", "seq_frames", "(", "self", ",", "seq_name", ")", ":", "\n", "        ", "\"\"\" All filename stems of the frames in the sequence \"\"\"", "\n", "frames", "=", "set", "(", ")", "\n", "for", "obj_id", "in", "self", ".", "object_ids", "(", "seq_name", ")", ":", "\n", "            ", "for", "f", "in", "self", ".", "object_frames", "(", "seq_name", ",", "obj_id", ")", ":", "\n", "                ", "frames", ".", "add", "(", "f", ")", "\n", "", "", "return", "list", "(", "sorted", "(", "frames", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.object_ids": [[46, 49], ["list", "[].keys"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "object_ids", "(", "self", ",", "seq_name", ")", ":", "\n", "        ", "\"\"\" All objects in the sequence \"\"\"", "\n", "return", "list", "(", "self", ".", "_data", "[", "seq_name", "]", "[", "'objects'", "]", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.object_category": [[50, 52], ["str"], "methods", ["None"], ["", "def", "object_category", "(", "self", ",", "seq_name", ",", "obj_id", ")", ":", "\n", "        ", "return", "self", ".", "_data", "[", "seq_name", "]", "[", "'objects'", "]", "[", "str", "(", "obj_id", ")", "]", "[", "'category'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.object_frames": [[53, 55], ["str"], "methods", ["None"], ["", "def", "object_frames", "(", "self", ",", "seq_name", ",", "obj_id", ")", ":", "\n", "        ", "return", "self", ".", "_data", "[", "seq_name", "]", "[", "'objects'", "]", "[", "str", "(", "obj_id", ")", "]", "[", "'frames'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.object_first_frame": [[56, 58], ["youtubevos.YouTubeVOSMeta.object_frames"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.object_frames"], ["", "def", "object_first_frame", "(", "self", ",", "seq_name", ",", "obj_id", ")", ":", "\n", "        ", "return", "self", ".", "object_frames", "(", "seq_name", ",", "obj_id", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS.__init__": [[72, 167], ["ltr.dataset.vos_base.VOSDatasetBase.__init__", "youtubevos.YouTubeVOS.split.startswith", "youtubevos.YouTubeVOSMeta", "meta_path.exists", "set", "print", "ltr.dataset.vos_base.VOSMeta", "ltr.dataset.vos_base.VOSMeta.generate", "youtubevos.YouTubeVOS.gmeta.save", "youtubevos.YouTubeVOS.gmeta.enable_all_frames", "youtubevos.YouTubeVOS.gmeta.select_split", "youtubevos.YouTubeVOS.gmeta.get_sequence_names", "set", "youtubevos.YouTubeVOS.meta.object_ids", "len", "print", "ltr.admin.environment.env_settings", "pathlib.Path", "youtubevos.YouTubeVOS.gmeta.get_aspect_ratio", "youtubevos.YouTubeVOS._samples.append", "youtubevos.YouTubeVOS._samples.extend", "youtubevos.YouTubeVOS.get_name", "set.add", "youtubevos.YouTubeVOS.meta.object_frames", "youtubevos.YouTubeVOS.remove", "len", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.generate", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.save", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.enable_all_frames", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.select_split", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_sequence_names", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.object_ids", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.get_aspect_ratio", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_name", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.object_frames"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "version", "=", "'2019'", ",", "split", "=", "'train'", ",", "cleanup", "=", "None", ",", "all_frames", "=", "False", ",", "sequences", "=", "None", ",", "\n", "multiobj", "=", "True", ",", "vis_threshold", "=", "10", ",", "image_loader", "=", "jpeg4py_loader", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - Dataset root path. If unset, it uses the path in your local.py config.\n            version - '2018' or '2019'\n            split - 'test', 'train', 'valid', or 'jjtrain', 'jjvalid'. 'jjvalid' corresponds to a custom validation\n                    dataset consisting of 300 videos randomly sampled from the train set. 'jjtrain' contains the\n                    remaining videos used for training.\n            cleanup - List of actions to take to to clean up known problems in the dataset.\n                      'aspects': remove frames with weird aspect ratios,\n                      'starts': fix up start frames from original meta data\n            all_frames - Whether to use an \"all_frames\" split.\n            sequences - List of sequence names. Limit to a subset of sequences if not None.\n            multiobj - Whether the dataset will return all objects in a sequence or multiple sequences with one\n                       object in each.\n            vis_threshold - Minimum number of pixels required to consider a target object \"visible\".\n            image_loader - Image loader.\n        \"\"\"", "\n", "root", "=", "env_settings", "(", ")", ".", "youtubevos_dir", "if", "root", "is", "None", "else", "root", "\n", "super", "(", ")", ".", "__init__", "(", "name", "=", "\"YouTubeVOS\"", ",", "root", "=", "Path", "(", "root", ")", ",", "version", "=", "version", ",", "split", "=", "split", ",", "multiobj", "=", "multiobj", ",", "\n", "vis_threshold", "=", "vis_threshold", ",", "image_loader", "=", "image_loader", ")", "\n", "\n", "split_folder", "=", "self", ".", "split", "\n", "if", "self", ".", "split", ".", "startswith", "(", "\"jj\"", ")", ":", "\n", "            ", "split_folder", "=", "\"train\"", "\n", "\n", "", "dset_path", "=", "self", ".", "root", "/", "self", ".", "version", "/", "split_folder", "\n", "\n", "self", ".", "_anno_path", "=", "dset_path", "/", "'Annotations'", "\n", "\n", "if", "all_frames", ":", "\n", "            ", "self", ".", "_jpeg_path", "=", "self", ".", "root", "/", "self", ".", "version", "/", "(", "split_folder", "+", "\"_all_frames\"", ")", "/", "'JPEGImages'", "\n", "", "else", ":", "\n", "            ", "self", ".", "_jpeg_path", "=", "dset_path", "/", "'JPEGImages'", "\n", "\n", "", "self", ".", "meta", "=", "YouTubeVOSMeta", "(", "dset_path", ")", "\n", "meta_path", "=", "dset_path", "/", "\"generated_meta.json\"", "\n", "if", "meta_path", ".", "exists", "(", ")", ":", "\n", "            ", "self", ".", "gmeta", "=", "VOSMeta", "(", "filename", "=", "meta_path", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "gmeta", "=", "VOSMeta", ".", "generate", "(", "'YouTubeVOS'", ",", "self", ".", "_jpeg_path", ",", "self", ".", "_anno_path", ")", "\n", "self", ".", "gmeta", ".", "save", "(", "meta_path", ")", "\n", "\n", "", "if", "all_frames", ":", "\n", "            ", "self", ".", "gmeta", ".", "enable_all_frames", "(", "self", ".", "_jpeg_path", ")", "\n", "\n", "", "if", "self", ".", "split", "not", "in", "[", "'train'", ",", "'valid'", ",", "'test'", "]", ":", "\n", "            ", "self", ".", "gmeta", ".", "select_split", "(", "'youtubevos'", ",", "self", ".", "split", ")", "\n", "\n", "", "if", "sequences", "is", "None", ":", "\n", "            ", "sequences", "=", "self", ".", "gmeta", ".", "get_sequence_names", "(", ")", "\n", "\n", "", "to_remove", "=", "set", "(", ")", "\n", "cleanup", "=", "{", "}", "if", "cleanup", "is", "None", "else", "set", "(", "cleanup", ")", "\n", "\n", "if", "'aspect'", "in", "cleanup", ":", "\n", "# Remove sequences with unusual aspect ratios", "\n", "            ", "for", "seq_name", "in", "sequences", ":", "\n", "                ", "a", "=", "self", ".", "gmeta", ".", "get_aspect_ratio", "(", "seq_name", ")", "\n", "if", "a", "<", "1.45", "or", "a", ">", "1.9", ":", "\n", "                    ", "to_remove", ".", "add", "(", "seq_name", ")", "\n", "\n", "", "", "", "if", "'starts'", "in", "cleanup", ":", "\n", "# Fix incorrect start frames for some objects found with ytvos_start_frames_test()", "\n", "            ", "bad_start_frames", "=", "[", "(", "\"0e27472bea\"", ",", "'2'", ",", "[", "'00055'", ",", "'00060'", "]", ",", "'00065'", ")", ",", "\n", "(", "\"5937b08d69\"", ",", "'4'", ",", "[", "'00000'", "]", ",", "'00005'", ")", ",", "\n", "(", "\"5e1ce354fd\"", ",", "'5'", ",", "[", "'00010'", ",", "'00015'", "]", ",", "'00020'", ")", ",", "\n", "(", "\"7053e4f41e\"", ",", "'2'", ",", "[", "'00000'", ",", "'00005'", ",", "'00010'", ",", "'00015'", "]", ",", "'00020'", ")", ",", "\n", "(", "\"720e3fa04c\"", ",", "'2'", ",", "[", "'00050'", "]", ",", "'00055'", ")", ",", "\n", "(", "\"c73c8e747f\"", ",", "'2'", ",", "[", "'00035'", "]", ",", "'00040'", ")", "]", "\n", "for", "seq_name", ",", "obj_id", ",", "bad_frames", ",", "good_frame", "in", "bad_start_frames", ":", "\n", "# bad_frames is from meta.json included with the dataset", "\n", "# good_frame is from the generated meta - and the first actual frame where the object was seen.", "\n", "                ", "if", "seq_name", "in", "self", ".", "meta", ".", "_data", ":", "\n", "                    ", "frames", "=", "self", ".", "meta", ".", "object_frames", "(", "seq_name", ",", "obj_id", ")", "\n", "for", "f", "in", "bad_frames", ":", "\n", "                        ", "frames", ".", "remove", "(", "f", ")", "\n", "", "assert", "frames", "[", "0", "]", "==", "good_frame", "\n", "\n", "", "", "", "sequences", "=", "[", "seq", "for", "seq", "in", "sequences", "if", "seq", "not", "in", "to_remove", "]", "\n", "\n", "self", ".", "sequence_names", "=", "sequences", "\n", "self", ".", "_samples", "=", "[", "]", "\n", "\n", "for", "seq", "in", "sequences", ":", "\n", "            ", "obj_ids", "=", "self", ".", "meta", ".", "object_ids", "(", "seq", ")", "\n", "if", "self", ".", "multiobj", ":", "# Multiple objects per sample", "\n", "                ", "self", ".", "_samples", ".", "append", "(", "(", "seq", ",", "obj_ids", ")", ")", "\n", "", "else", ":", "# One object per sample", "\n", "                ", "self", ".", "_samples", ".", "extend", "(", "[", "(", "seq", ",", "[", "obj_id", "]", ")", "for", "obj_id", "in", "obj_ids", "]", ")", "\n", "\n", "", "", "print", "(", "\"%s loaded.\"", "%", "self", ".", "get_name", "(", ")", ")", "\n", "if", "len", "(", "to_remove", ")", ">", "0", ":", "\n", "            ", "print", "(", "\"   %d sequences were removed, (%d remaining).\"", "%", "(", "len", "(", "to_remove", ")", ",", "len", "(", "sequences", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOS._construct_sequence": [[168, 193], ["youtubevos.YouTubeVOS.get_paths_and_bboxes", "dict", "pytracking.evaluation.Sequence", "youtubevos.YouTubeVOS.meta.object_first_frame", "enumerate", "print", "[].append", "os.path.join", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSDatasetBase.get_paths_and_bboxes", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.youtubevos.YouTubeVOSMeta.object_first_frame"], ["", "", "def", "_construct_sequence", "(", "self", ",", "sequence_info", ")", ":", "\n", "\n", "        ", "seq_name", "=", "sequence_info", "[", "'sequence'", "]", "\n", "frame_names", "=", "sequence_info", "[", "'frame_names'", "]", "\n", "fname_to_fid", "=", "{", "f", ":", "i", "for", "i", ",", "f", "in", "enumerate", "(", "frame_names", ")", "}", "\n", "images", ",", "gt_segs", ",", "gt_bboxes", "=", "self", ".", "get_paths_and_bboxes", "(", "sequence_info", ")", "\n", "\n", "init_data", "=", "dict", "(", ")", "\n", "for", "obj_id", "in", "sequence_info", "[", "'object_ids'", "]", ":", "\n", "            ", "if", "obj_id", "==", "'0'", ":", "\n", "                ", "print", "(", "\"!\"", ")", "\n", "", "f_name", "=", "self", ".", "meta", ".", "object_first_frame", "(", "seq_name", ",", "obj_id", ")", "\n", "f_id", "=", "fname_to_fid", "[", "f_name", "]", "\n", "if", "f_id", "not", "in", "init_data", ":", "\n", "                ", "init_data", "[", "f_id", "]", "=", "{", "'object_ids'", ":", "[", "obj_id", "]", ",", "\n", "'bbox'", ":", "{", "obj_id", ":", "gt_bboxes", "[", "obj_id", "]", "[", "f_id", ",", ":", "]", "}", ",", "\n", "'mask'", ":", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "gt_segs", "[", "f_id", "]", ")", ",", "(", "f_name", "+", "\".png\"", ")", ")", "}", "\n", "assert", "init_data", "[", "f_id", "]", "[", "'mask'", "]", "in", "gt_segs", "# If this fails, some file is missing", "\n", "", "else", ":", "\n", "                ", "init_data", "[", "f_id", "]", "[", "'object_ids'", "]", ".", "append", "(", "obj_id", ")", "\n", "init_data", "[", "f_id", "]", "[", "'bbox'", "]", "[", "obj_id", "]", "=", "gt_bboxes", "[", "obj_id", "]", "[", "f_id", ",", ":", "]", "\n", "\n", "", "", "return", "Sequence", "(", "name", "=", "seq_name", ",", "frames", "=", "images", ",", "dataset", "=", "'YouTubeVOS'", ",", "ground_truth_rect", "=", "gt_bboxes", ",", "\n", "init_data", "=", "init_data", ",", "ground_truth_seg", "=", "gt_segs", ",", "object_ids", "=", "sequence_info", "[", "'object_ids'", "]", ",", "\n", "multiobj_mode", "=", "self", ".", "multiobj", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.ecssd.ECSSD.__init__": [[22, 38], ["base_image_dataset.BaseImageDataset.__init__", "ecssd.ECSSD._load_dataset", "ltr.admin.environment.env_settings"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._load_dataset", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "image_loader", "=", "jpeg4py_loader", ",", "data_fraction", "=", "None", ",", "min_area", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - path to ECSSD root folder\n            image_loader (jpeg4py_loader) - The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                                            is used by default.\n            data_fraction - Fraction of dataset to be used. The complete dataset is used by default\n            min_area - Objects with area less than min_area are filtered out. Default is 0.0\n        \"\"\"", "\n", "root", "=", "env_settings", "(", ")", ".", "ecssd_dir", "if", "root", "is", "None", "else", "root", "\n", "super", "(", ")", ".", "__init__", "(", "'ECSSD'", ",", "root", ",", "image_loader", ")", "\n", "\n", "self", ".", "image_list", "=", "self", ".", "_load_dataset", "(", "min_area", "=", "min_area", ")", "\n", "\n", "if", "data_fraction", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.ecssd.ECSSD._load_dataset": [[39, 49], ["range", "ltr.data.image_loader.imread_indexed", "os.path.join", "images.append"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.imread_indexed"], ["", "", "def", "_load_dataset", "(", "self", ",", "min_area", "=", "None", ")", ":", "\n", "        ", "images", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "1001", ")", ":", "\n", "            ", "a", "=", "imread_indexed", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'ground_truth_mask'", ",", "'{:04d}.png'", ".", "format", "(", "i", ")", ")", ")", "\n", "\n", "if", "min_area", "is", "None", "or", "(", "a", ">", "0", ")", ".", "sum", "(", ")", ">", "min_area", ":", "\n", "                ", "images", ".", "append", "(", "i", ")", "\n", "\n", "", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.ecssd.ECSSD.get_name": [[50, 52], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "'ecssd'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.ecssd.ECSSD.has_segmentation_info": [[53, 55], ["None"], "methods", ["None"], ["", "def", "has_segmentation_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.ecssd.ECSSD.get_image_info": [[56, 66], ["ltr.data.image_loader.imread_indexed", "torch.Tensor", "ltr.data.bounding_box_utils.masks_to_bboxes().view", "valid.clone().byte", "os.path.join", "ltr.data.bounding_box_utils.masks_to_bboxes", "valid.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.imread_indexed", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.masks_to_bboxes"], ["", "def", "get_image_info", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "mask", "=", "imread_indexed", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'ground_truth_mask'", ",", "'{:04d}.png'", ".", "format", "(", "self", ".", "image_list", "[", "im_id", "]", ")", ")", ")", "\n", "\n", "mask", "=", "torch", ".", "Tensor", "(", "mask", "==", "255", ")", "\n", "bbox", "=", "masks_to_bboxes", "(", "mask", ",", "fmt", "=", "'t'", ")", ".", "view", "(", "4", ",", ")", "\n", "\n", "valid", "=", "(", "bbox", "[", "2", "]", ">", "0", ")", "&", "(", "bbox", "[", "3", "]", ">", "0", ")", "\n", "visible", "=", "valid", ".", "clone", "(", ")", ".", "byte", "(", ")", "\n", "\n", "return", "{", "'bbox'", ":", "bbox", ",", "'mask'", ":", "mask", ",", "'valid'", ":", "valid", ",", "'visible'", ":", "visible", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.ecssd.ECSSD.get_meta_info": [[67, 75], ["collections.OrderedDict"], "methods", ["None"], ["", "def", "get_meta_info", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "None", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "\n", "return", "object_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.ecssd.ECSSD.get_image": [[76, 85], ["ecssd.ECSSD.image_loader", "ecssd.ECSSD.get_meta_info", "os.path.join", "ecssd.ECSSD.get_image_info"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_meta_info", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image_info"], ["", "def", "get_image", "(", "self", ",", "image_id", ",", "anno", "=", "None", ")", ":", "\n", "        ", "frame", "=", "self", ".", "image_loader", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'images'", ",", "'{:04d}.jpg'", ".", "format", "(", "self", ".", "image_list", "[", "image_id", "]", ")", ")", ")", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_image_info", "(", "image_id", ")", "\n", "\n", "", "object_meta", "=", "self", ".", "get_meta_info", "(", "image_id", ")", "\n", "\n", "return", "frame", ",", "anno", ",", "object_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.__init__": [[34, 64], ["base_video_dataset.BaseVideoDataset.__init__", "os.path.join", "os.path.join", "pycocotools.coco.COCO", "coco_seq.MSCOCOSeq.get_class_list", "coco_seq.MSCOCOSeq._get_sequence_list", "coco_seq.MSCOCOSeq._build_seq_per_class", "random.sample", "ltr.admin.environment.env_settings", "int", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_class_list", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._get_sequence_list", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._build_seq_per_class", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "image_loader", "=", "jpeg4py_loader", ",", "data_fraction", "=", "None", ",", "split", "=", "\"train\"", ",", "version", "=", "\"2014\"", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - path to the coco dataset.\n            image_loader (default_image_loader) -  The function to read the images. If installed,\n                                                   jpeg4py (https://github.com/ajkxyz/jpeg4py) is used by default. Else,\n                                                   opencv's imread is used.\n            data_fraction (None) - Fraction of images to be used. The images are selected randomly. If None, all the\n                                  images  will be used\n            split - 'train' or 'val'.\n            version - version of coco dataset (2014 or 2017)\n        \"\"\"", "\n", "root", "=", "env_settings", "(", ")", ".", "coco_dir", "if", "root", "is", "None", "else", "root", "\n", "super", "(", ")", ".", "__init__", "(", "'COCO'", ",", "root", ",", "image_loader", ")", "\n", "\n", "self", ".", "img_pth", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'images/{}{}/'", ".", "format", "(", "split", ",", "version", ")", ")", "\n", "self", ".", "anno_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'annotations/instances_{}{}.json'", ".", "format", "(", "split", ",", "version", ")", ")", "\n", "\n", "# Load the COCO set.", "\n", "self", ".", "coco_set", "=", "COCO", "(", "self", ".", "anno_path", ")", "\n", "\n", "self", ".", "cats", "=", "self", ".", "coco_set", ".", "cats", "\n", "\n", "self", ".", "class_list", "=", "self", ".", "get_class_list", "(", ")", "\n", "\n", "self", ".", "sequence_list", "=", "self", ".", "_get_sequence_list", "(", ")", "\n", "\n", "if", "data_fraction", "is", "not", "None", ":", "\n", "            ", "self", ".", "sequence_list", "=", "random", ".", "sample", "(", "self", ".", "sequence_list", ",", "int", "(", "len", "(", "self", ".", "sequence_list", ")", "*", "data_fraction", ")", ")", "\n", "", "self", ".", "seq_per_class", "=", "self", ".", "_build_seq_per_class", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._get_sequence_list": [[65, 70], ["list", "coco_seq.MSCOCOSeq.coco_set.anns.keys"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "_get_sequence_list", "(", "self", ")", ":", "\n", "        ", "ann_list", "=", "list", "(", "self", ".", "coco_set", ".", "anns", ".", "keys", "(", ")", ")", "\n", "seq_list", "=", "[", "a", "for", "a", "in", "ann_list", "if", "self", ".", "coco_set", ".", "anns", "[", "a", "]", "[", "'iscrowd'", "]", "==", "0", "]", "\n", "\n", "return", "seq_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.is_video_sequence": [[71, 73], ["None"], "methods", ["None"], ["", "def", "is_video_sequence", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.get_num_classes": [[74, 76], ["len"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "class_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.get_name": [[77, 79], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "'coco'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.has_class_info": [[80, 82], ["None"], "methods", ["None"], ["", "def", "has_class_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.get_class_list": [[83, 88], ["coco_seq.MSCOCOSeq.cats.keys", "class_list.append"], "methods", ["None"], ["", "def", "get_class_list", "(", "self", ")", ":", "\n", "        ", "class_list", "=", "[", "]", "\n", "for", "cat_id", "in", "self", ".", "cats", ".", "keys", "(", ")", ":", "\n", "            ", "class_list", ".", "append", "(", "self", ".", "cats", "[", "cat_id", "]", "[", "'name'", "]", ")", "\n", "", "return", "class_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.has_segmentation_info": [[89, 91], ["None"], "methods", ["None"], ["", "def", "has_segmentation_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.get_num_sequences": [[92, 94], ["len"], "methods", ["None"], ["", "def", "get_num_sequences", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._build_seq_per_class": [[95, 105], ["enumerate", "seq_per_class[].append"], "methods", ["None"], ["", "def", "_build_seq_per_class", "(", "self", ")", ":", "\n", "        ", "seq_per_class", "=", "{", "}", "\n", "for", "i", ",", "seq", "in", "enumerate", "(", "self", ".", "sequence_list", ")", ":", "\n", "            ", "class_name", "=", "self", ".", "cats", "[", "self", ".", "coco_set", ".", "anns", "[", "seq", "]", "[", "'category_id'", "]", "]", "[", "'name'", "]", "\n", "if", "class_name", "not", "in", "seq_per_class", ":", "\n", "                ", "seq_per_class", "[", "class_name", "]", "=", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "seq_per_class", "[", "class_name", "]", ".", "append", "(", "i", ")", "\n", "\n", "", "", "return", "seq_per_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.get_sequences_in_class": [[106, 108], ["None"], "methods", ["None"], ["", "def", "get_sequences_in_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "return", "self", ".", "seq_per_class", "[", "class_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.get_sequence_info": [[109, 120], ["coco_seq.MSCOCOSeq._get_anno", "torch.Tensor().view", "torch.Tensor().unsqueeze", "valid.clone().byte", "torch.Tensor", "torch.Tensor", "valid.clone", "coco_seq.MSCOCOSeq.coco_set.annToMask"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._get_anno"], ["", "def", "get_sequence_info", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "anno", "=", "self", ".", "_get_anno", "(", "seq_id", ")", "\n", "\n", "bbox", "=", "torch", ".", "Tensor", "(", "anno", "[", "'bbox'", "]", ")", ".", "view", "(", "1", ",", "4", ")", "\n", "\n", "mask", "=", "torch", ".", "Tensor", "(", "self", ".", "coco_set", ".", "annToMask", "(", "anno", ")", ")", ".", "unsqueeze", "(", "dim", "=", "0", ")", "\n", "\n", "valid", "=", "(", "bbox", "[", ":", ",", "2", "]", ">", "0", ")", "&", "(", "bbox", "[", ":", ",", "3", "]", ">", "0", ")", "\n", "visible", "=", "valid", ".", "clone", "(", ")", ".", "byte", "(", ")", "\n", "\n", "return", "{", "'bbox'", ":", "bbox", ",", "'mask'", ":", "mask", ",", "'valid'", ":", "valid", ",", "'visible'", ":", "visible", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._get_anno": [[121, 125], ["None"], "methods", ["None"], ["", "def", "_get_anno", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "anno", "=", "self", ".", "coco_set", ".", "anns", "[", "self", ".", "sequence_list", "[", "seq_id", "]", "]", "\n", "\n", "return", "anno", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._get_frames": [[126, 130], ["coco_seq.MSCOCOSeq.image_loader", "os.path.join", "coco_seq.MSCOCOSeq.coco_set.loadImgs"], "methods", ["None"], ["", "def", "_get_frames", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "path", "=", "self", ".", "coco_set", ".", "loadImgs", "(", "[", "self", ".", "coco_set", ".", "anns", "[", "self", ".", "sequence_list", "[", "seq_id", "]", "]", "[", "'image_id'", "]", "]", ")", "[", "0", "]", "[", "'file_name'", "]", "\n", "img", "=", "self", ".", "image_loader", "(", "os", ".", "path", ".", "join", "(", "self", ".", "img_pth", ",", "path", ")", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.get_meta_info": [[131, 146], ["collections.OrderedDict", "collections.OrderedDict"], "methods", ["None"], ["", "def", "get_meta_info", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "cat_dict_current", "=", "self", ".", "cats", "[", "self", ".", "coco_set", ".", "anns", "[", "self", ".", "sequence_list", "[", "seq_id", "]", "]", "[", "'category_id'", "]", "]", "\n", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "cat_dict_current", "[", "'name'", "]", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "cat_dict_current", "[", "'supercategory'", "]", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "", "except", ":", "\n", "            ", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "None", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "", "return", "object_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.get_class_name": [[148, 151], ["None"], "methods", ["None"], ["", "def", "get_class_name", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "cat_dict_current", "=", "self", ".", "cats", "[", "self", ".", "coco_set", ".", "anns", "[", "self", ".", "sequence_list", "[", "seq_id", "]", "]", "[", "'category_id'", "]", "]", "\n", "return", "cat_dict_current", "[", "'name'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq.get_frames": [[152, 169], ["coco_seq.MSCOCOSeq._get_frames", "coco_seq.MSCOCOSeq.items", "coco_seq.MSCOCOSeq.get_meta_info", "coco_seq.MSCOCOSeq.copy", "coco_seq.MSCOCOSeq.get_sequence_info"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.coco_seq.MSCOCOSeq._get_frames", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_meta_info", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info"], ["", "def", "get_frames", "(", "self", ",", "seq_id", "=", "None", ",", "frame_ids", "=", "None", ",", "anno", "=", "None", ")", ":", "\n", "# COCO is an image dataset. Thus we replicate the image denoted by seq_id len(frame_ids) times, and return a", "\n", "# list containing these replicated images.", "\n", "        ", "frame", "=", "self", ".", "_get_frames", "(", "seq_id", ")", "\n", "\n", "frame_list", "=", "[", "frame", ".", "copy", "(", ")", "for", "_", "in", "frame_ids", "]", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_sequence_info", "(", "seq_id", ")", "\n", "\n", "", "anno_frames", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "anno", ".", "items", "(", ")", ":", "\n", "            ", "anno_frames", "[", "key", "]", "=", "[", "value", "[", "0", ",", "...", "]", "for", "_", "in", "frame_ids", "]", "\n", "\n", "", "object_meta", "=", "self", ".", "get_meta_info", "(", "seq_id", ")", "\n", "\n", "return", "frame_list", ",", "anno_frames", ",", "object_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend.__init__": [[13, 32], ["foreground_image_dataset.has_segmentation_info", "base_video_dataset.BaseVideoDataset.__init__", "foreground_image_dataset.get_name"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.has_segmentation_info", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_name"], ["def", "__init__", "(", "self", ",", "foreground_image_dataset", ",", "background_image_dataset", ",", "foreground_transform", "=", "None", ",", "\n", "background_transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            foreground_image_dataset - A segmentation dataset from which foreground objects are cropped using the\n                                       segmentation mask\n            background_image_dataset - Dataset used to sample background image for the synthetic video\n            foreground_transform - Random transformations to be applied to the foreground object in every frame\n            background_transform - Random transformations to be applied to the background image in every frame\n        \"\"\"", "\n", "assert", "foreground_image_dataset", ".", "has_segmentation_info", "(", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "foreground_image_dataset", ".", "get_name", "(", ")", "+", "'_syn_vid_blend'", ",", "foreground_image_dataset", ".", "root", ",", "\n", "foreground_image_dataset", ".", "image_loader", ")", "\n", "self", ".", "foreground_image_dataset", "=", "foreground_image_dataset", "\n", "self", ".", "background_image_dataset", "=", "background_image_dataset", "\n", "\n", "self", ".", "foreground_transform", "=", "foreground_transform", "\n", "self", ".", "background_transform", "=", "background_transform", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend.get_name": [[33, 35], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend.is_video_sequence": [[36, 38], ["None"], "methods", ["None"], ["", "def", "is_video_sequence", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend.has_class_info": [[39, 41], ["synthetic_video_blend.SyntheticVideoBlend.foreground_image_dataset.has_class_info"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.has_class_info"], ["", "def", "has_class_info", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "foreground_image_dataset", ".", "has_class_info", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend.has_occlusion_info": [[42, 44], ["None"], "methods", ["None"], ["", "def", "has_occlusion_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend.get_num_sequences": [[45, 47], ["synthetic_video_blend.SyntheticVideoBlend.foreground_image_dataset.get_num_images"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_num_images"], ["", "def", "get_num_sequences", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "foreground_image_dataset", ".", "get_num_images", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend.get_num_classes": [[48, 50], ["len"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "class_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend.get_sequences_in_class": [[51, 53], ["None"], "methods", ["None"], ["", "def", "get_sequences_in_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "return", "self", ".", "get_images_in_class", "[", "class_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend.get_sequence_info": [[54, 59], ["synthetic_video_blend.SyntheticVideoBlend.foreground_image_dataset.get_image_info", "v.unsqueeze", "synthetic_video_blend.SyntheticVideoBlend.items"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image_info"], ["", "def", "get_sequence_info", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "image_info", "=", "self", ".", "foreground_image_dataset", ".", "get_image_info", "(", "seq_id", ")", "\n", "\n", "image_info", "=", "{", "k", ":", "v", ".", "unsqueeze", "(", "0", ")", "for", "k", ",", "v", "in", "image_info", ".", "items", "(", ")", "}", "\n", "return", "image_info", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend.get_class_name": [[60, 62], ["synthetic_video_blend.SyntheticVideoBlend.foreground_image_dataset.get_class_name"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_class_name"], ["", "def", "get_class_name", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "return", "self", ".", "foreground_image_dataset", ".", "get_class_name", "(", "seq_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend._paste_target": [[63, 99], ["fg_mask.view.view.view", "fg_box.long().tolist.long().tolist.long().tolist", "int", "int", "max", "max", "max", "max", "torch.zeros", "torch.zeros.squeeze", "fg_box.long().tolist.long().tolist.long", "torch.zeros.squeeze", "fg_mask_patch.numpy", "fg_mask_patch.numpy"], "methods", ["None"], ["", "def", "_paste_target", "(", "self", ",", "fg_image", ",", "fg_box", ",", "fg_mask", ",", "bg_image", ",", "paste_loc", ")", ":", "\n", "        ", "fg_mask", "=", "fg_mask", ".", "view", "(", "fg_mask", ".", "shape", "[", "0", "]", ",", "fg_mask", ".", "shape", "[", "1", "]", ",", "1", ")", "\n", "fg_box", "=", "fg_box", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "x1", "=", "int", "(", "paste_loc", "[", "0", "]", "-", "0.5", "*", "fg_box", "[", "2", "]", ")", "\n", "x2", "=", "x1", "+", "fg_box", "[", "2", "]", "\n", "\n", "y1", "=", "int", "(", "paste_loc", "[", "1", "]", "-", "0.5", "*", "fg_box", "[", "3", "]", ")", "\n", "y2", "=", "y1", "+", "fg_box", "[", "3", "]", "\n", "\n", "x1_pad", "=", "max", "(", "-", "x1", ",", "0", ")", "\n", "y1_pad", "=", "max", "(", "-", "y1", ",", "0", ")", "\n", "\n", "x2_pad", "=", "max", "(", "x2", "-", "bg_image", ".", "shape", "[", "1", "]", ",", "0", ")", "\n", "y2_pad", "=", "max", "(", "y2", "-", "bg_image", ".", "shape", "[", "0", "]", ",", "0", ")", "\n", "\n", "bg_mask", "=", "torch", ".", "zeros", "(", "(", "bg_image", ".", "shape", "[", "0", "]", ",", "bg_image", ".", "shape", "[", "1", "]", ",", "1", ")", ",", "dtype", "=", "fg_mask", ".", "dtype", ",", "\n", "device", "=", "fg_mask", ".", "device", ")", "\n", "\n", "if", "x1_pad", ">=", "fg_mask", ".", "shape", "[", "1", "]", "or", "x2_pad", ">=", "fg_mask", ".", "shape", "[", "1", "]", "or", "y1_pad", ">=", "fg_mask", ".", "shape", "[", "0", "]", "or", "y2_pad", ">=", "fg_mask", ".", "shape", "[", "0", "]", ":", "\n", "            ", "return", "bg_image", ",", "bg_mask", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "", "fg_mask_patch", "=", "fg_mask", "[", "fg_box", "[", "1", "]", "+", "y1_pad", ":", "fg_box", "[", "1", "]", "+", "fg_box", "[", "3", "]", "-", "y2_pad", ",", "\n", "fg_box", "[", "0", "]", "+", "x1_pad", ":", "fg_box", "[", "0", "]", "+", "fg_box", "[", "2", "]", "-", "x2_pad", ",", ":", "]", "\n", "\n", "fg_image_patch", "=", "fg_image", "[", "fg_box", "[", "1", "]", "+", "y1_pad", ":", "fg_box", "[", "1", "]", "+", "fg_box", "[", "3", "]", "-", "y2_pad", ",", "\n", "fg_box", "[", "0", "]", "+", "x1_pad", ":", "fg_box", "[", "0", "]", "+", "fg_box", "[", "2", "]", "-", "x2_pad", ",", ":", "]", "\n", "\n", "bg_image", "[", "y1", "+", "y1_pad", ":", "y2", "-", "y2_pad", ",", "x1", "+", "x1_pad", ":", "x2", "-", "x2_pad", ",", ":", "]", "=", "bg_image", "[", "y1", "+", "y1_pad", ":", "y2", "-", "y2_pad", ",", "x1", "+", "x1_pad", ":", "x2", "-", "x2_pad", ",", ":", "]", "*", "(", "1", "-", "fg_mask_patch", ".", "numpy", "(", ")", ")", "+", "fg_mask_patch", ".", "numpy", "(", ")", "*", "fg_image_patch", "\n", "\n", "bg_mask", "[", "y1", "+", "y1_pad", ":", "y2", "-", "y2_pad", ",", "x1", "+", "x1_pad", ":", "x2", "-", "x2_pad", ",", ":", "]", "=", "fg_mask_patch", "\n", "\n", "return", "bg_image", ",", "bg_mask", ".", "squeeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend.get_frames": [[100, 163], ["synthetic_video_blend.SyntheticVideoBlend.foreground_image_dataset.get_image", "fg_anno.items", "random.randint", "synthetic_video_blend.SyntheticVideoBlend.background_image_dataset.get_image", "bg_anno.items", "range", "collections.OrderedDict", "fg_frame.copy", "synthetic_video_blend.SyntheticVideoBlend.foreground_transform", "bg_frame.copy", "len", "ltr.data.bounding_box_utils.masks_to_bboxes", "random.randint", "random.randint", "synthetic_video_blend.SyntheticVideoBlend._paste_target", "ltr.data.bounding_box_utils.masks_to_bboxes", "value[].clone", "synthetic_video_blend.SyntheticVideoBlend.background_image_dataset.get_num_images", "value.clone", "bg_anno_frames.keys", "synthetic_video_blend.SyntheticVideoBlend.background_transform", "synthetic_video_blend.SyntheticVideoBlend.background_transform", "synthetic_video_blend.SyntheticVideoBlend.get_class_name"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.masks_to_bboxes", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video_blend.SyntheticVideoBlend._paste_target", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.masks_to_bboxes", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_num_images", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_class_name"], ["", "def", "get_frames", "(", "self", ",", "seq_id", ",", "frame_ids", ",", "anno", "=", "None", ")", ":", "\n", "# Handle foreground", "\n", "        ", "fg_frame", ",", "fg_anno", ",", "fg_object_meta", "=", "self", ".", "foreground_image_dataset", ".", "get_image", "(", "seq_id", ",", "anno", "=", "anno", ")", "\n", "\n", "fg_frame_list", "=", "[", "fg_frame", ".", "copy", "(", ")", "for", "_", "in", "frame_ids", "]", "\n", "\n", "fg_anno_frames", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "fg_anno", ".", "items", "(", ")", ":", "\n", "            ", "fg_anno_frames", "[", "key", "]", "=", "[", "value", "[", "0", "]", ".", "clone", "(", ")", "for", "f_id", "in", "frame_ids", "]", "\n", "\n", "", "if", "self", ".", "foreground_transform", "is", "not", "None", ":", "\n", "            ", "fg_frame_list", ",", "fg_anno_frames", "[", "'bbox'", "]", ",", "fg_anno_frames", "[", "'mask'", "]", "=", "self", ".", "foreground_transform", "(", "\n", "image", "=", "fg_frame_list", ",", "\n", "bbox", "=", "fg_anno_frames", "[", "'bbox'", "]", ",", "\n", "mask", "=", "fg_anno_frames", "[", "'mask'", "]", ",", "\n", "joint", "=", "False", ")", "\n", "\n", "# Sample a random background", "\n", "", "bg_seq_id", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "background_image_dataset", ".", "get_num_images", "(", ")", "-", "1", ")", "\n", "\n", "bg_frame", ",", "bg_anno", ",", "_", "=", "self", ".", "background_image_dataset", ".", "get_image", "(", "bg_seq_id", ")", "\n", "\n", "bg_frame_list", "=", "[", "bg_frame", ".", "copy", "(", ")", "for", "_", "in", "frame_ids", "]", "\n", "\n", "bg_anno_frames", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "bg_anno", ".", "items", "(", ")", ":", "\n", "# Note: Since we get bg anno from image dataset, it does not has frame dimension", "\n", "            ", "bg_anno_frames", "[", "key", "]", "=", "[", "value", ".", "clone", "(", ")", "for", "f_id", "in", "frame_ids", "]", "\n", "\n", "", "if", "self", ".", "background_transform", "is", "not", "None", ":", "\n", "            ", "if", "'mask'", "in", "bg_anno_frames", ".", "keys", "(", ")", ":", "\n", "                ", "bg_frame_list", ",", "bg_anno_frames", "[", "'bbox'", "]", ",", "bg_anno_frames", "[", "'mask'", "]", "=", "self", ".", "background_transform", "(", "\n", "image", "=", "bg_frame_list", ",", "\n", "bbox", "=", "bg_anno_frames", "[", "'bbox'", "]", ",", "\n", "mask", "=", "bg_anno_frames", "[", "'mask'", "]", ",", "\n", "joint", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "bg_frame_list", ",", "bg_anno_frames", "[", "'bbox'", "]", "=", "self", ".", "background_transform", "(", "\n", "image", "=", "bg_frame_list", ",", "\n", "bbox", "=", "bg_anno_frames", "[", "'bbox'", "]", ",", "\n", "joint", "=", "False", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "frame_ids", ")", ")", ":", "\n", "# To be safe, get target bb for the mask", "\n", "            ", "bbox", "=", "masks_to_bboxes", "(", "fg_anno_frames", "[", "'mask'", "]", "[", "i", "]", ",", "fmt", "=", "'t'", ")", "\n", "\n", "loc_y", "=", "random", ".", "randint", "(", "0", ",", "bg_frame_list", "[", "i", "]", ".", "shape", "[", "0", "]", "-", "1", ")", "\n", "loc_x", "=", "random", ".", "randint", "(", "0", ",", "bg_frame_list", "[", "i", "]", ".", "shape", "[", "1", "]", "-", "1", ")", "\n", "\n", "paste_loc", "=", "(", "loc_x", ",", "loc_y", ")", "\n", "fg_frame_list", "[", "i", "]", ",", "fg_anno_frames", "[", "'mask'", "]", "[", "i", "]", "=", "self", ".", "_paste_target", "(", "fg_frame_list", "[", "i", "]", ",", "bbox", ",", "\n", "fg_anno_frames", "[", "'mask'", "]", "[", "i", "]", ",", "\n", "bg_frame_list", "[", "i", "]", ",", "paste_loc", ")", "\n", "\n", "fg_anno_frames", "[", "'bbox'", "]", "[", "i", "]", "=", "masks_to_bboxes", "(", "fg_anno_frames", "[", "'mask'", "]", "[", "i", "]", ",", "fmt", "=", "'t'", ")", "\n", "\n", "", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "self", ".", "get_class_name", "(", "seq_id", ")", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "\n", "return", "fg_frame_list", ",", "fg_anno_frames", ",", "object_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.__init__": [[8, 21], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ",", "root", ",", "image_loader", "=", "jpeg4py_loader", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - The root path to the dataset\n            image_loader (jpeg4py_loader) -  The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                                            is used by default.\n        \"\"\"", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "image_loader", "=", "image_loader", "\n", "\n", "self", ".", "sequence_list", "=", "[", "]", "# Contains the list of sequences.", "\n", "self", ".", "class_list", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.__len__": [[22, 28], ["base_video_dataset.BaseVideoDataset.get_num_sequences"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_num_sequences"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns size of the dataset\n        returns:\n            int - number of samples in the dataset\n        \"\"\"", "\n", "return", "self", ".", "get_num_sequences", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.__getitem__": [[29, 33], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\" Not to be used! Check get_frames() instead.\n        \"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.is_video_sequence": [[34, 41], ["None"], "methods", ["None"], ["", "def", "is_video_sequence", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns whether the dataset is a video dataset or an image dataset\n\n        returns:\n            bool - True if a video dataset\n        \"\"\"", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.is_synthetic_video_dataset": [[42, 49], ["None"], "methods", ["None"], ["", "def", "is_synthetic_video_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns whether the dataset contains real videos or synthetic\n\n        returns:\n            bool - True if a video dataset\n        \"\"\"", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.get_name": [[50, 57], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "\"\"\" Name of the dataset\n\n        returns:\n            string - Name of the dataset\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.get_num_sequences": [[58, 64], ["len"], "methods", ["None"], ["", "def", "get_num_sequences", "(", "self", ")", ":", "\n", "        ", "\"\"\" Number of sequences in a dataset\n\n        returns:\n            int - number of sequences in the dataset.\"\"\"", "\n", "return", "len", "(", "self", ".", "sequence_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.has_class_info": [[65, 67], ["None"], "methods", ["None"], ["", "def", "has_class_info", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.has_occlusion_info": [[68, 70], ["None"], "methods", ["None"], ["", "def", "has_occlusion_info", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.get_num_classes": [[71, 73], ["len"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "class_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.get_class_list": [[74, 76], ["None"], "methods", ["None"], ["", "def", "get_class_list", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "class_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.get_sequences_in_class": [[77, 79], ["None"], "methods", ["None"], ["", "def", "get_sequences_in_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.has_segmentation_info": [[80, 82], ["None"], "methods", ["None"], ["", "def", "has_segmentation_info", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.get_sequence_info": [[83, 93], ["None"], "methods", ["None"], ["", "def", "get_sequence_info", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "\"\"\" Returns information about a particular sequences,\n\n        args:\n            seq_id - index of the sequence\n\n        returns:\n            Dict\n            \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_video_dataset.BaseVideoDataset.get_frames": [[94, 109], ["None"], "methods", ["None"], ["", "def", "get_frames", "(", "self", ",", "seq_id", ",", "frame_ids", ",", "anno", "=", "None", ")", ":", "\n", "        ", "\"\"\" Get a set of frames from a particular sequence\n\n        args:\n            seq_id      - index of sequence\n            frame_ids   - a list of frame numbers\n            anno(None)  - The annotation for the sequence (see get_sequence_info). If None, they will be loaded.\n\n        returns:\n            list - List of frames corresponding to frame_ids\n            list - List of dicts for each frame\n            dict - A dict containing meta information about the sequence, e.g. class of the target object.\n\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.__init__": [[19, 49], ["ltr.dataset.base_video_dataset.BaseVideoDataset.__init__", "lasot_candidate_matching.LasotCandidateMatching._build_sequence_list", "lasot_candidate_matching.LasotCandidateMatching._build_class_list", "lasot_candidate_matching.LasotCandidateMatching._load_dataset", "random.sample", "ltr.admin.environment.env_settings", "ltr.admin.environment.env_settings", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "enumerate", "int", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._build_sequence_list", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._build_class_list", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._load_dataset", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "path_to_json", "=", "None", ",", "image_loader", "=", "jpeg4py_loader", ",", "vid_ids", "=", "None", ",", "split", "=", "None", ",", "data_fraction", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - path to the lasot candidate matching dataset json file.\n            image_loader (jpeg4py_loader) -  The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                                            is used by default.\n            vid_ids - List containing the ids of the videos (1 - 20) used for training. If vid_ids = [1, 3, 5], then the\n                    videos with subscripts -1, -3, and -5 from each class will be used for training.\n            split - If split='train', the official train split (protocol-II) is used for training. Note: Only one of\n                    vid_ids or split option can be used at a time.\n            data_fraction - Fraction of dataset to be used. The complete dataset is used by default\n        \"\"\"", "\n", "root", "=", "env_settings", "(", ")", ".", "lasot_dir", "if", "root", "is", "None", "else", "root", "\n", "path_to_json", "=", "env_settings", "(", ")", ".", "lasot_candidate_matching_dataset_path", "if", "path_to_json", "is", "None", "else", "path_to_json", "\n", "super", "(", ")", ".", "__init__", "(", "'LaSOTCandidateMatching'", ",", "root", ",", "image_loader", ")", "\n", "\n", "self", ".", "sequence_info_cache", "=", "{", "}", "\n", "\n", "# Keep a list of all classes", "\n", "self", ".", "class_list", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "self", ".", "root", ")", "]", "\n", "self", ".", "class_to_id", "=", "{", "cls_name", ":", "cls_id", "for", "cls_id", ",", "cls_name", "in", "enumerate", "(", "self", ".", "class_list", ")", "}", "\n", "\n", "self", ".", "sequence_list", "=", "self", ".", "_build_sequence_list", "(", "vid_ids", ",", "split", ")", "\n", "\n", "if", "data_fraction", "is", "not", "None", ":", "\n", "            ", "self", ".", "sequence_list", "=", "random", ".", "sample", "(", "self", ".", "sequence_list", ",", "int", "(", "len", "(", "self", ".", "sequence_list", ")", "*", "data_fraction", ")", ")", "\n", "\n", "", "self", ".", "seq_per_class", "=", "self", ".", "_build_class_list", "(", ")", "\n", "\n", "self", ".", "dataset", "=", "self", ".", "_load_dataset", "(", "path_to_json", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._load_dataset": [[50, 54], ["open", "json.load"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load"], ["", "def", "_load_dataset", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_frame_states": [[55, 70], ["collections.defaultdict", "enumerate", "collections.defaultdict.keys", "torch.cat", "[].items", "torch.tensor().view", "torch.cat", "frame_states_all[].append", "torch.ones_like().view", "torch.tensor", "torch.ones_like"], "methods", ["None"], ["", "def", "get_frame_states", "(", "self", ")", ":", "\n", "        ", "frame_states_all", "=", "defaultdict", "(", "list", ")", "\n", "\n", "for", "seq_id", ",", "seq_name", "in", "enumerate", "(", "self", ".", "sequence_list", ")", ":", "\n", "            ", "if", "'frame_states'", "in", "self", ".", "dataset", "[", "seq_name", "]", ":", "\n", "                ", "for", "frame_state_name", ",", "frame_state_indices", "in", "self", ".", "dataset", "[", "seq_name", "]", "[", "'frame_states'", "]", ".", "items", "(", ")", ":", "\n", "                    ", "frame_state_indices", "=", "torch", ".", "tensor", "(", "frame_state_indices", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "seq_ids", "=", "seq_id", "*", "torch", ".", "ones_like", "(", "frame_state_indices", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "data", "=", "torch", ".", "cat", "(", "[", "seq_ids", ",", "frame_state_indices", "]", ",", "dim", "=", "1", ")", "\n", "frame_states_all", "[", "frame_state_name", "]", ".", "append", "(", "data", ")", "\n", "\n", "", "", "", "for", "state_name", "in", "frame_states_all", ".", "keys", "(", ")", ":", "\n", "            ", "frame_states_all", "[", "state_name", "]", "=", "torch", ".", "cat", "(", "frame_states_all", "[", "state_name", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "return", "frame_states_all", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_subseq_states": [[71, 86], ["collections.defaultdict", "enumerate", "collections.defaultdict.keys", "torch.cat", "[].items", "torch.tensor().view", "torch.cat", "subseq_states_all[].append", "torch.ones_like().view", "torch.tensor", "torch.ones_like"], "methods", ["None"], ["", "def", "get_subseq_states", "(", "self", ")", ":", "\n", "        ", "subseq_states_all", "=", "defaultdict", "(", "list", ")", "\n", "\n", "for", "seq_id", ",", "seq_name", "in", "enumerate", "(", "self", ".", "sequence_list", ")", ":", "\n", "            ", "if", "'subseq_states'", "in", "self", ".", "dataset", "[", "seq_name", "]", ":", "\n", "                ", "for", "subseq_state_name", ",", "subseq_state_indices", "in", "self", ".", "dataset", "[", "seq_name", "]", "[", "'subseq_states'", "]", ".", "items", "(", ")", ":", "\n", "                    ", "subseq_state_indices", "=", "torch", ".", "tensor", "(", "subseq_state_indices", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "seq_ids", "=", "seq_id", "*", "torch", ".", "ones_like", "(", "subseq_state_indices", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "data", "=", "torch", ".", "cat", "(", "[", "seq_ids", ",", "subseq_state_indices", "]", ",", "dim", "=", "1", ")", "\n", "subseq_states_all", "[", "subseq_state_name", "]", ".", "append", "(", "data", ")", "\n", "\n", "", "", "", "for", "state_name", "in", "subseq_states_all", ".", "keys", "(", ")", ":", "\n", "            ", "subseq_states_all", "[", "state_name", "]", "=", "torch", ".", "cat", "(", "subseq_states_all", "[", "state_name", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "return", "subseq_states_all", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._build_sequence_list": [[87, 109], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "pandas.read_csv().values.tolist", "ValueError", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.dirname", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "ValueError", "os.path.realpath", "os.path.realpath", "os.path.realpath", "os.path.realpath", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "pandas.read_csv", "str", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "ValueError"], "methods", ["None"], ["", "def", "_build_sequence_list", "(", "self", ",", "vid_ids", "=", "None", ",", "split", "=", "None", ")", ":", "\n", "        ", "if", "split", "is", "not", "None", ":", "\n", "            ", "if", "vid_ids", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "'Cannot set both split_name and vid_ids.'", ")", "\n", "", "ltr_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ",", "'..'", ")", "\n", "if", "split", "==", "'train'", ":", "\n", "                ", "file_path", "=", "os", ".", "path", ".", "join", "(", "ltr_path", ",", "'data_specs'", ",", "'lasot_train_split.txt'", ")", "\n", "", "elif", "split", "==", "'val'", ":", "\n", "                ", "file_path", "=", "os", ".", "path", ".", "join", "(", "ltr_path", ",", "'data_specs'", ",", "'lasot_val_split.txt'", ")", "\n", "", "elif", "split", "==", "'train-train'", ":", "\n", "                ", "file_path", "=", "os", ".", "path", ".", "join", "(", "ltr_path", ",", "'data_specs'", ",", "'lasot_train_train_split.txt'", ")", "\n", "", "elif", "split", "==", "'train-val'", ":", "\n", "                ", "file_path", "=", "os", ".", "path", ".", "join", "(", "ltr_path", ",", "'data_specs'", ",", "'lasot_train_val_split.txt'", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown split name.'", ")", "\n", "", "sequence_list", "=", "pandas", ".", "read_csv", "(", "file_path", ",", "header", "=", "None", ",", "squeeze", "=", "True", ")", ".", "values", ".", "tolist", "(", ")", "\n", "", "elif", "vid_ids", "is", "not", "None", ":", "\n", "            ", "sequence_list", "=", "[", "c", "+", "'-'", "+", "str", "(", "v", ")", "for", "c", "in", "self", ".", "class_list", "for", "v", "in", "vid_ids", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Set either split_name or vid_ids.'", ")", "\n", "\n", "", "return", "sequence_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._build_class_list": [[110, 120], ["enumerate", "seq_name.split", "seq_per_class[].append"], "methods", ["None"], ["", "def", "_build_class_list", "(", "self", ")", ":", "\n", "        ", "seq_per_class", "=", "{", "}", "\n", "for", "seq_id", ",", "seq_name", "in", "enumerate", "(", "self", ".", "sequence_list", ")", ":", "\n", "            ", "class_name", "=", "seq_name", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "if", "class_name", "in", "seq_per_class", ":", "\n", "                ", "seq_per_class", "[", "class_name", "]", ".", "append", "(", "seq_id", ")", "\n", "", "else", ":", "\n", "                ", "seq_per_class", "[", "class_name", "]", "=", "[", "seq_id", "]", "\n", "\n", "", "", "return", "seq_per_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_name": [[121, 123], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "'lasot_candidate_matching_new'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.has_class_info": [[124, 126], ["None"], "methods", ["None"], ["", "def", "has_class_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.has_occlusion_info": [[127, 129], ["None"], "methods", ["None"], ["", "def", "has_occlusion_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_num_sequences": [[130, 132], ["len"], "methods", ["None"], ["", "def", "get_num_sequences", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_num_classes": [[133, 135], ["len"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "class_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_sequences_in_class": [[136, 138], ["None"], "methods", ["None"], ["", "def", "get_sequences_in_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "return", "self", ".", "seq_per_class", "[", "class_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._read_bb_anno": [[139, 143], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.tensor", "pandas.read_csv"], "methods", ["None"], ["", "def", "_read_bb_anno", "(", "self", ",", "seq_path", ")", ":", "\n", "        ", "bb_anno_file", "=", "os", ".", "path", ".", "join", "(", "seq_path", ",", "'groundtruth.txt'", ")", "\n", "gt", "=", "pandas", ".", "read_csv", "(", "bb_anno_file", ",", "delimiter", "=", "','", ",", "header", "=", "None", ",", "dtype", "=", "np", ".", "float32", ",", "na_filter", "=", "False", ",", "low_memory", "=", "False", ")", ".", "values", "\n", "return", "torch", ".", "tensor", "(", "gt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._read_target_visible": [[144, 157], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "torch.ByteTensor", "open", "torch.ByteTensor", "int", "int", "list", "list", "csv.reader", "csv.reader"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "_read_target_visible", "(", "self", ",", "seq_path", ")", ":", "\n", "# Read full occlusion and out_of_view", "\n", "        ", "occlusion_file", "=", "os", ".", "path", ".", "join", "(", "seq_path", ",", "'full_occlusion.txt'", ")", "\n", "out_of_view_file", "=", "os", ".", "path", ".", "join", "(", "seq_path", ",", "'out_of_view.txt'", ")", "\n", "\n", "with", "open", "(", "occlusion_file", ",", "'r'", ",", "newline", "=", "''", ")", "as", "f", ":", "\n", "            ", "occlusion", "=", "torch", ".", "ByteTensor", "(", "[", "int", "(", "v", ")", "for", "v", "in", "list", "(", "csv", ".", "reader", "(", "f", ")", ")", "[", "0", "]", "]", ")", "\n", "", "with", "open", "(", "out_of_view_file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "out_of_view", "=", "torch", ".", "ByteTensor", "(", "[", "int", "(", "v", ")", "for", "v", "in", "list", "(", "csv", ".", "reader", "(", "f", ")", ")", "[", "0", "]", "]", ")", "\n", "\n", "", "target_visible", "=", "~", "occlusion", "&", "~", "out_of_view", "\n", "\n", "return", "target_visible", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_sequence_path": [[158, 164], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "seq_name.split", "seq_name.split"], "methods", ["None"], ["", "def", "_get_sequence_path", "(", "self", ",", "root", ",", "seq_id", ")", ":", "\n", "        ", "seq_name", "=", "self", ".", "sequence_list", "[", "seq_id", "]", "\n", "class_name", "=", "seq_name", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "vid_id", "=", "seq_name", ".", "split", "(", "'-'", ")", "[", "1", "]", "\n", "\n", "return", "os", ".", "path", ".", "join", "(", "root", ",", "class_name", ",", "class_name", "+", "'-'", "+", "vid_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_sequence_info": [[165, 176], ["lasot_candidate_matching.LasotCandidateMatching._get_sequence_path", "lasot_candidate_matching.LasotCandidateMatching._read_bb_anno", "dict", "lasot_candidate_matching.LasotCandidateMatching._read_target_visible", "valid.byte", "ltr.admin.environment.env_settings"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_sequence_path", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._read_bb_anno", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._read_target_visible", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["", "def", "get_sequence_info", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "if", "seq_id", "not", "in", "self", ".", "sequence_info_cache", ":", "\n", "            ", "seq_path_img", "=", "self", ".", "_get_sequence_path", "(", "env_settings", "(", ")", ".", "lasot_dir", ",", "seq_id", ")", "\n", "bbox", "=", "self", ".", "_read_bb_anno", "(", "seq_path_img", ")", "\n", "\n", "valid", "=", "(", "bbox", "[", ":", ",", "2", "]", ">", "0", ")", "&", "(", "bbox", "[", ":", ",", "3", "]", ">", "0", ")", "\n", "visible", "=", "self", ".", "_read_target_visible", "(", "seq_path_img", ")", "&", "valid", ".", "byte", "(", ")", "\n", "\n", "self", ".", "sequence_info_cache", "[", "seq_id", "]", "=", "dict", "(", "bbox", "=", "bbox", ",", "valid", "=", "valid", ",", "visible", "=", "visible", ")", "\n", "\n", "", "return", "self", ".", "sequence_info_cache", "[", "seq_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_frame_path": [[177, 179], ["os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "_get_frame_path", "(", "self", ",", "seq_path", ",", "frame_id", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "seq_path", ",", "'img'", ",", "'{:08}.jpg'", ".", "format", "(", "frame_id", "+", "1", ")", ")", "# frames start from 1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_frame": [[180, 182], ["lasot_candidate_matching.LasotCandidateMatching.image_loader", "lasot_candidate_matching.LasotCandidateMatching._get_frame_path"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_frame_path"], ["", "def", "_get_frame", "(", "self", ",", "seq_path", ",", "frame_id", ")", ":", "\n", "        ", "return", "self", ".", "image_loader", "(", "self", ".", "_get_frame_path", "(", "seq_path", ",", "frame_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_class": [[183, 186], ["seq_path.split"], "methods", ["None"], ["", "def", "_get_class", "(", "self", ",", "seq_path", ")", ":", "\n", "        ", "raw_class", "=", "seq_path", ".", "split", "(", "'/'", ")", "[", "-", "2", "]", "\n", "return", "raw_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_data": [[187, 201], ["data[].index", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "lasot_candidate_matching.LasotCandidateMatching.image_loader", "dict", "lasot_candidate_matching.LasotCandidateMatching._get_frame_path", "lasot_candidate_matching.LasotCandidateMatching.get_sequence_name"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_frame_path", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_sequence_name"], ["", "def", "_get_data", "(", "self", ",", "seq_id", ",", "seq_img_path", ",", "frame_id", ")", ":", "\n", "        ", "data", "=", "self", ".", "dataset", "[", "self", ".", "get_sequence_name", "(", "seq_id", ")", "]", "\n", "\n", "idx", "=", "data", "[", "'index'", "]", ".", "index", "(", "frame_id", ")", "\n", "\n", "search_area_box", "=", "torch", ".", "FloatTensor", "(", "data", "[", "'search_area_box'", "]", "[", "idx", "]", ")", "\n", "target_candidate_scores", "=", "torch", ".", "FloatTensor", "(", "data", "[", "'target_candidate_scores'", "]", "[", "idx", "]", ")", "\n", "target_candidate_coords", "=", "torch", ".", "FloatTensor", "(", "data", "[", "'target_candidate_coords'", "]", "[", "idx", "]", ")", "\n", "target_anno_coord", "=", "torch", ".", "FloatTensor", "(", "data", "[", "'target_anno_coord'", "]", "[", "idx", "]", ")", "\n", "\n", "img", "=", "self", ".", "image_loader", "(", "self", ".", "_get_frame_path", "(", "seq_img_path", ",", "frame_id", ")", ")", "\n", "\n", "return", "dict", "(", "search_area_box", "=", "search_area_box", ",", "img", "=", "img", ",", "target_anno_coord", "=", "target_anno_coord", ",", "\n", "target_candidate_coords", "=", "target_candidate_coords", ",", "target_candidate_scores", "=", "target_candidate_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_class_name": [[202, 207], ["lasot_candidate_matching.LasotCandidateMatching._get_sequence_path", "lasot_candidate_matching.LasotCandidateMatching._get_class"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_sequence_path", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_class"], ["", "def", "get_class_name", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "seq_path", "=", "self", ".", "_get_sequence_path", "(", "self", ".", "root", ",", "seq_id", ")", "\n", "obj_class", "=", "self", ".", "_get_class", "(", "seq_path", ")", "\n", "\n", "return", "obj_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_sequence_name": [[208, 210], ["None"], "methods", ["None"], ["", "def", "get_sequence_name", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "return", "self", ".", "sequence_list", "[", "seq_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_frames": [[211, 236], ["dict", "lasot_candidate_matching.LasotCandidateMatching._get_sequence_path", "lasot_candidate_matching.LasotCandidateMatching._get_class", "dumped_data_frame_list[].keys", "lasot_candidate_matching.LasotCandidateMatching.items", "collections.OrderedDict", "lasot_candidate_matching.LasotCandidateMatching.get_sequence_info", "lasot_candidate_matching.LasotCandidateMatching._get_data", "ltr.admin.environment.env_settings", "value[].clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_sequence_path", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_class", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching._get_data", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["", "def", "get_frames", "(", "self", ",", "seq_id", ",", "frame_ids", ",", "anno", "=", "None", ")", ":", "\n", "        ", "frames_dict", "=", "dict", "(", ")", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_sequence_info", "(", "seq_id", ")", "\n", "\n", "", "seq_path_img", "=", "self", ".", "_get_sequence_path", "(", "env_settings", "(", ")", ".", "lasot_dir", ",", "seq_id", ")", "\n", "\n", "obj_class", "=", "self", ".", "_get_class", "(", "seq_path_img", ")", "\n", "\n", "dumped_data_frame_list", "=", "[", "self", ".", "_get_data", "(", "seq_id", ",", "seq_path_img", ",", "f_id", ")", "for", "f_id", "in", "frame_ids", "]", "\n", "\n", "for", "key", "in", "dumped_data_frame_list", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "frames_dict", "[", "key", "]", "=", "[", "data", "[", "key", "]", "for", "data", "in", "dumped_data_frame_list", "]", "# is cloning needed here?", "\n", "\n", "", "for", "key", ",", "value", "in", "anno", ".", "items", "(", ")", ":", "\n", "            ", "frames_dict", "[", "key", "]", "=", "[", "value", "[", "f_id", ",", "...", "]", ".", "clone", "(", ")", "for", "f_id", "in", "frame_ids", "]", "\n", "\n", "", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "obj_class", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "\n", "return", "frames_dict", ",", "object_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.__init__": [[33, 61], ["base_image_dataset.BaseImageDataset.__init__", "os.path.join", "os.path.join", "lvis.LVIS", "lvis.LVIS.get_class_list", "lvis.LVIS._get_image_list", "lvis.LVIS._build_im_per_class", "random.sample", "ltr.admin.environment.env_settings", "int", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_class_list", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._get_image_list", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._build_im_per_class", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "image_loader", "=", "jpeg4py_loader_w_failsafe", ",", "data_fraction", "=", "None", ",", "min_area", "=", "None", ",", "split", "=", "\"train\"", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - path to lvis root folder\n            image_loader (jpeg4py_loader) - The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                                            is used by default.\n            data_fraction - Fraction of dataset to be used. The complete dataset is used by default\n            min_area - Objects with area less than min_area are filtered out. Default is 0.0\n            split - 'train' or 'val'.\n        \"\"\"", "\n", "root", "=", "env_settings", "(", ")", ".", "lvis_dir", "if", "root", "is", "None", "else", "root", "\n", "super", "(", ")", ".", "__init__", "(", "'LVIS'", ",", "root", ",", "image_loader", ")", "\n", "\n", "self", ".", "img_pth", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'images'", ",", "f'{split}2017/'", ")", "\n", "self", ".", "anno_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'annotations'", ",", "f'lvis_v0.5_{split}.json'", ")", "\n", "\n", "# Load the LVIS set.", "\n", "self", ".", "lvis_set", "=", "lvis_pk", ".", "LVIS", "(", "self", ".", "anno_path", ")", "\n", "\n", "self", ".", "cats", "=", "self", ".", "lvis_set", ".", "cats", "\n", "\n", "self", ".", "class_list", "=", "self", ".", "get_class_list", "(", ")", "# the parent class thing would happen in the sampler", "\n", "\n", "self", ".", "image_list", "=", "self", ".", "_get_image_list", "(", "min_area", "=", "min_area", ")", "\n", "\n", "if", "data_fraction", "is", "not", "None", ":", "\n", "            ", "self", ".", "image_list", "=", "random", ".", "sample", "(", "self", ".", "image_list", ",", "int", "(", "len", "(", "self", ".", "image_list", ")", "*", "data_fraction", ")", ")", "\n", "", "self", ".", "im_per_class", "=", "self", ".", "_build_im_per_class", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._get_image_list": [[62, 69], ["list", "lvis.LVIS.lvis_set.anns.keys"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "_get_image_list", "(", "self", ",", "min_area", "=", "None", ")", ":", "\n", "        ", "im_list", "=", "list", "(", "self", ".", "lvis_set", ".", "anns", ".", "keys", "(", ")", ")", "# No 'iscrowd' information in LVIS", "\n", "\n", "if", "min_area", "is", "not", "None", ":", "\n", "            ", "im_list", "=", "[", "s", "for", "s", "in", "im_list", "if", "self", ".", "lvis_set", ".", "anns", "[", "s", "]", "[", "'area'", "]", ">", "min_area", "]", "\n", "\n", "", "return", "im_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_num_classes": [[70, 72], ["len"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "class_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_name": [[73, 75], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "'lvis'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.has_class_info": [[76, 78], ["None"], "methods", ["None"], ["", "def", "has_class_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_class_list": [[79, 84], ["lvis.LVIS.cats.keys", "class_list.append"], "methods", ["None"], ["", "def", "get_class_list", "(", "self", ")", ":", "\n", "        ", "class_list", "=", "[", "]", "\n", "for", "cat_id", "in", "self", ".", "cats", ".", "keys", "(", ")", ":", "\n", "            ", "class_list", ".", "append", "(", "self", ".", "cats", "[", "cat_id", "]", "[", "'name'", "]", ")", "\n", "", "return", "class_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.has_segmentation_info": [[85, 87], ["None"], "methods", ["None"], ["", "def", "has_segmentation_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._build_im_per_class": [[88, 98], ["enumerate", "im_per_class[].append"], "methods", ["None"], ["", "def", "_build_im_per_class", "(", "self", ")", ":", "\n", "        ", "im_per_class", "=", "{", "}", "\n", "for", "i", ",", "im", "in", "enumerate", "(", "self", ".", "image_list", ")", ":", "\n", "            ", "class_name", "=", "self", ".", "cats", "[", "self", ".", "lvis_set", ".", "anns", "[", "im", "]", "[", "'category_id'", "]", "]", "[", "'name'", "]", "\n", "if", "class_name", "not", "in", "im_per_class", ":", "\n", "                ", "im_per_class", "[", "class_name", "]", "=", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "im_per_class", "[", "class_name", "]", ".", "append", "(", "i", ")", "\n", "\n", "", "", "return", "im_per_class", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_images_in_class": [[99, 101], ["None"], "methods", ["None"], ["", "def", "get_images_in_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "return", "self", ".", "im_per_class", "[", "class_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_image_info": [[102, 113], ["lvis.LVIS._get_anno", "torch.Tensor().view", "torch.Tensor", "valid.clone().byte", "lvis.LVIS.lvis_set.ann_to_mask", "torch.Tensor", "valid.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._get_anno"], ["", "def", "get_image_info", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "anno", "=", "self", ".", "_get_anno", "(", "im_id", ")", "\n", "\n", "bbox", "=", "torch", ".", "Tensor", "(", "anno", "[", "'bbox'", "]", ")", ".", "view", "(", "4", ",", ")", "\n", "\n", "mask", "=", "torch", ".", "Tensor", "(", "self", ".", "lvis_set", ".", "ann_to_mask", "(", "anno", ")", ")", "\n", "\n", "valid", "=", "(", "bbox", "[", "2", "]", ">", "0", ")", "&", "(", "bbox", "[", "3", "]", ">", "0", ")", "\n", "visible", "=", "valid", ".", "clone", "(", ")", ".", "byte", "(", ")", "\n", "\n", "return", "{", "'bbox'", ":", "bbox", ",", "'mask'", ":", "mask", ",", "'valid'", ":", "valid", ",", "'visible'", ":", "visible", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._get_anno": [[114, 118], ["None"], "methods", ["None"], ["", "def", "_get_anno", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "anno", "=", "self", ".", "lvis_set", ".", "anns", "[", "self", ".", "image_list", "[", "im_id", "]", "]", "\n", "\n", "return", "anno", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._get_image": [[119, 123], ["lvis.LVIS.image_loader", "os.path.join", "lvis.LVIS.lvis_set.load_imgs"], "methods", ["None"], ["", "def", "_get_image", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "path", "=", "self", ".", "lvis_set", ".", "load_imgs", "(", "[", "self", ".", "lvis_set", ".", "anns", "[", "self", ".", "image_list", "[", "im_id", "]", "]", "[", "'image_id'", "]", "]", ")", "[", "0", "]", "[", "'file_name'", "]", "\n", "img", "=", "self", ".", "image_loader", "(", "os", ".", "path", ".", "join", "(", "self", ".", "img_pth", ",", "path", ")", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_meta_info": [[124, 139], ["collections.OrderedDict", "collections.OrderedDict"], "methods", ["None"], ["", "def", "get_meta_info", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "cat_dict_current", "=", "self", ".", "cats", "[", "self", ".", "lvis_set", ".", "anns", "[", "self", ".", "image_list", "[", "im_id", "]", "]", "[", "'category_id'", "]", "]", "\n", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "cat_dict_current", "[", "'name'", "]", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "# No 'supercategory' information available in LVIS", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "", "except", ":", "\n", "            ", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "None", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "", "return", "object_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_class_name": [[140, 143], ["None"], "methods", ["None"], ["", "def", "get_class_name", "(", "self", ",", "im_id", ")", ":", "\n", "        ", "cat_dict_current", "=", "self", ".", "cats", "[", "self", ".", "lvis_set", ".", "anns", "[", "self", ".", "image_list", "[", "im_id", "]", "]", "[", "'category_id'", "]", "]", "\n", "return", "cat_dict_current", "[", "'name'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_image": [[144, 153], ["lvis.LVIS._get_image", "lvis.LVIS.get_meta_info", "lvis.LVIS.get_image_info"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS._get_image", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lvis.LVIS.get_meta_info", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image_info"], ["", "def", "get_image", "(", "self", ",", "image_id", ",", "anno", "=", "None", ")", ":", "\n", "        ", "frame", "=", "self", ".", "_get_image", "(", "image_id", ")", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_image_info", "(", "image_id", ")", "\n", "\n", "", "object_meta", "=", "self", ".", "get_meta_info", "(", "image_id", ")", "\n", "\n", "return", "frame", ",", "anno", ",", "object_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.__init__": [[10, 20], ["base_video_dataset.BaseVideoDataset.__init__", "base_image_dataset.get_name"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_name"], ["def", "__init__", "(", "self", ",", "base_image_dataset", ",", "transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            base_image_dataset - Image dataset used for generating synthetic videos\n            transform - Set of transforms to be applied to the images to generate synthetic video.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "base_image_dataset", ".", "get_name", "(", ")", "+", "'_syn_vid'", ",", "base_image_dataset", ".", "root", ",", "\n", "base_image_dataset", ".", "image_loader", ")", "\n", "self", ".", "base_image_dataset", "=", "base_image_dataset", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.get_name": [[21, 23], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.is_video_sequence": [[24, 26], ["None"], "methods", ["None"], ["", "def", "is_video_sequence", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.has_class_info": [[27, 29], ["synthetic_video.SyntheticVideo.base_image_dataset.has_class_info"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.has_class_info"], ["", "def", "has_class_info", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "base_image_dataset", ".", "has_class_info", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.has_occlusion_info": [[30, 32], ["None"], "methods", ["None"], ["", "def", "has_occlusion_info", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.get_num_sequences": [[33, 35], ["synthetic_video.SyntheticVideo.base_image_dataset.get_num_images"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_num_images"], ["", "def", "get_num_sequences", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "base_image_dataset", ".", "get_num_images", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.get_num_classes": [[36, 38], ["len"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "class_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.get_sequences_in_class": [[39, 41], ["None"], "methods", ["None"], ["", "def", "get_sequences_in_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "return", "self", ".", "get_images_in_class", "[", "class_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.get_sequence_info": [[42, 47], ["synthetic_video.SyntheticVideo.base_image_dataset.get_image_info", "v.unsqueeze", "synthetic_video.SyntheticVideo.items"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image_info"], ["", "def", "get_sequence_info", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "image_info", "=", "self", ".", "base_image_dataset", ".", "get_image_info", "(", "seq_id", ")", "\n", "\n", "image_info", "=", "{", "k", ":", "v", ".", "unsqueeze", "(", "0", ")", "for", "k", ",", "v", "in", "image_info", ".", "items", "(", ")", "}", "\n", "return", "image_info", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.get_class_name": [[48, 50], ["synthetic_video.SyntheticVideo.base_image_dataset.get_class_name"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_class_name"], ["", "def", "get_class_name", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "return", "self", ".", "base_image_dataset", ".", "get_class_name", "(", "seq_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.get_frames": [[51, 83], ["synthetic_video.SyntheticVideo.base_image_dataset.get_image", "synthetic_video.SyntheticVideo.items", "collections.OrderedDict", "frame.copy", "synthetic_video.SyntheticVideo.get_sequence_info", "value[].clone", "anno_frames.keys", "synthetic_video.SyntheticVideo.transform", "synthetic_video.SyntheticVideo.transform", "synthetic_video.SyntheticVideo.get_class_name", "ltr.data.bounding_box_utils.masks_to_bboxes"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info", "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomBlur.transform", "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomBlur.transform", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_class_name", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.masks_to_bboxes"], ["", "def", "get_frames", "(", "self", ",", "seq_id", ",", "frame_ids", ",", "anno", "=", "None", ")", ":", "\n", "        ", "frame", ",", "anno", ",", "object_meta", "=", "self", ".", "base_image_dataset", ".", "get_image", "(", "seq_id", ",", "anno", "=", "anno", ")", "\n", "\n", "frame_list", "=", "[", "frame", ".", "copy", "(", ")", "for", "_", "in", "frame_ids", "]", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_sequence_info", "(", "seq_id", ")", "\n", "\n", "", "anno_frames", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "anno", ".", "items", "(", ")", ":", "\n", "            ", "anno_frames", "[", "key", "]", "=", "[", "value", "[", "0", "]", ".", "clone", "(", ")", "for", "f_id", "in", "frame_ids", "]", "\n", "\n", "", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "if", "'mask'", "in", "anno_frames", ".", "keys", "(", ")", ":", "\n", "                ", "frame_list", ",", "anno_frames", "[", "'bbox'", "]", ",", "anno_frames", "[", "'mask'", "]", "=", "self", ".", "transform", "(", "image", "=", "frame_list", ",", "\n", "bbox", "=", "anno_frames", "[", "'bbox'", "]", ",", "\n", "mask", "=", "anno_frames", "[", "'mask'", "]", ",", "\n", "joint", "=", "False", ")", "\n", "\n", "anno_frames", "[", "'bbox'", "]", "=", "[", "masks_to_bboxes", "(", "m", ",", "fmt", "=", "'t'", ")", "for", "m", "in", "anno_frames", "[", "'mask'", "]", "]", "\n", "", "else", ":", "\n", "                ", "frame_list", ",", "anno_frames", "[", "'bbox'", "]", "=", "self", ".", "transform", "(", "image", "=", "frame_list", ",", "\n", "bbox", "=", "anno_frames", "[", "'bbox'", "]", ",", "\n", "joint", "=", "False", ")", "\n", "\n", "", "", "object_meta", "=", "OrderedDict", "(", "{", "'object_class_name'", ":", "self", ".", "get_class_name", "(", "seq_id", ")", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "\n", "return", "frame_list", ",", "anno_frames", ",", "object_meta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.__init__": [[30, 61], ["base_video_dataset.BaseVideoDataset.__init__", "os.path.join", "os.path.isfile", "imagenetvid.ImagenetVID._process_anno", "ltr.admin.environment.env_settings", "open", "json.load", "open", "json.dump", "len", "imagenetvid.get_target_to_image_ratio"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID._process_anno", "home.repos.pwc.inspect_result.visionml_pytracking.admin.environment.env_settings", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.get_target_to_image_ratio"], ["def", "__init__", "(", "self", ",", "root", "=", "None", ",", "image_loader", "=", "default_image_loader", ",", "min_length", "=", "0", ",", "max_target_area", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - path to the imagenet vid dataset.\n            image_loader (default_image_loader) -  The function to read the images. If installed,\n                                                   jpeg4py (https://github.com/ajkxyz/jpeg4py) is used by default. Else,\n                                                   opencv's imread is used.\n            min_length - Minimum allowed sequence length.\n            max_target_area - max allowed ratio between target area and image area. Can be used to filter out targets\n                                which cover complete image.\n        \"\"\"", "\n", "root", "=", "env_settings", "(", ")", ".", "imagenet_dir", "if", "root", "is", "None", "else", "root", "\n", "super", "(", ")", ".", "__init__", "(", "root", ",", "image_loader", ")", "\n", "\n", "cache_file", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'cache.json'", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "cache_file", ")", ":", "\n", "# If available, load the pre-processed cache file containing meta-info for each sequence", "\n", "            ", "with", "open", "(", "cache_file", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "sequence_list_dict", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "sequence_list", "=", "sequence_list_dict", "\n", "", "else", ":", "\n", "# Else process the imagenet annotations and generate the cache file", "\n", "            ", "self", ".", "sequence_list", "=", "self", ".", "_process_anno", "(", "root", ")", "\n", "\n", "with", "open", "(", "cache_file", ",", "'w'", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "self", ".", "sequence_list", ",", "f", ")", "\n", "\n", "# Filter the sequences based on min_length and max_target_area in the first frame", "\n", "", "", "self", ".", "sequence_list", "=", "[", "x", "for", "x", "in", "self", ".", "sequence_list", "if", "len", "(", "x", "[", "'anno'", "]", ")", ">=", "min_length", "and", "\n", "get_target_to_image_ratio", "(", "x", ")", "<", "max_target_area", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_name": [[62, 64], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "return", "'imagenetvid'", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_num_sequences": [[65, 67], ["len"], "methods", ["None"], ["", "def", "get_num_sequences", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sequence_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info": [[68, 73], ["torch.Tensor", "torch.ByteTensor", "valid.byte"], "methods", ["None"], ["", "def", "get_sequence_info", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "bb_anno", "=", "torch", ".", "Tensor", "(", "self", ".", "sequence_list", "[", "seq_id", "]", "[", "'anno'", "]", ")", "\n", "valid", "=", "(", "bb_anno", "[", ":", ",", "2", "]", ">", "0", ")", "&", "(", "bb_anno", "[", ":", ",", "3", "]", ">", "0", ")", "\n", "visible", "=", "torch", ".", "ByteTensor", "(", "self", ".", "sequence_list", "[", "seq_id", "]", "[", "'target_visible'", "]", ")", "&", "valid", ".", "byte", "(", ")", "\n", "return", "{", "'bbox'", ":", "bb_anno", ",", "'valid'", ":", "valid", ",", "'visible'", ":", "visible", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID._get_frame": [[74, 82], ["os.path.join", "imagenetvid.ImagenetVID.image_loader"], "methods", ["None"], ["", "def", "_get_frame", "(", "self", ",", "sequence", ",", "frame_id", ")", ":", "\n", "        ", "set_name", "=", "'ILSVRC2015_VID_train_{:04d}'", ".", "format", "(", "sequence", "[", "'set_id'", "]", ")", "\n", "vid_name", "=", "'ILSVRC2015_train_{:08d}'", ".", "format", "(", "sequence", "[", "'vid_id'", "]", ")", "\n", "frame_number", "=", "frame_id", "+", "sequence", "[", "'start_frame'", "]", "\n", "\n", "frame_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'Data'", ",", "'VID'", ",", "'train'", ",", "set_name", ",", "vid_name", ",", "\n", "'{:06d}.JPEG'", ".", "format", "(", "frame_number", ")", ")", "\n", "return", "self", ".", "image_loader", "(", "frame_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_frames": [[83, 104], ["imagenetvid.ImagenetVID.items", "collections.OrderedDict", "imagenetvid.ImagenetVID._get_frame", "imagenetvid.ImagenetVID.get_sequence_info", "value[].clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID._get_frame", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info"], ["", "def", "get_frames", "(", "self", ",", "seq_id", ",", "frame_ids", ",", "anno", "=", "None", ")", ":", "\n", "        ", "sequence", "=", "self", ".", "sequence_list", "[", "seq_id", "]", "\n", "\n", "frame_list", "=", "[", "self", ".", "_get_frame", "(", "sequence", ",", "f", ")", "for", "f", "in", "frame_ids", "]", "\n", "\n", "if", "anno", "is", "None", ":", "\n", "            ", "anno", "=", "self", ".", "get_sequence_info", "(", "seq_id", ")", "\n", "\n", "# Create anno dict", "\n", "", "anno_frames", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "anno", ".", "items", "(", ")", ":", "\n", "            ", "anno_frames", "[", "key", "]", "=", "[", "value", "[", "f_id", ",", "...", "]", ".", "clone", "(", ")", "for", "f_id", "in", "frame_ids", "]", "\n", "\n", "# added the class info to the meta info", "\n", "", "object_meta", "=", "OrderedDict", "(", "{", "'object_class'", ":", "sequence", "[", "'class_name'", "]", ",", "\n", "'motion_class'", ":", "None", ",", "\n", "'major_class'", ":", "None", ",", "\n", "'root_class'", ":", "None", ",", "\n", "'motion_adverb'", ":", "None", "}", ")", "\n", "\n", "return", "frame_list", ",", "anno_frames", ",", "object_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID._process_anno": [[105, 162], ["os.path.join", "sorted", "os.listdir", "int", "sorted", "os.listdir", "int", "sorted", "xml.parse", "enumerate", "tracklets.items", "set.split", "os.path.join", "os.listdir", "os.path.join", "int", "int", "xml.ElementTree().findall", "range", "all_sequences.append", "vid.split", "os.path.join", "len", "xml.parse.find", "xml.parse.find", "xml.ElementTree", "target.find", "int", "int", "int", "int", "tracklet_anno.append", "target_visible.append", "os.path.join", "target.find", "target.find", "target.find", "target.find", "target.find", "target.find", "target.find"], "methods", ["None"], ["", "def", "_process_anno", "(", "self", ",", "root", ")", ":", "\n", "# Builds individual tracklets", "\n", "        ", "base_vid_anno_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'Annotations'", ",", "'VID'", ",", "'train'", ")", "\n", "\n", "all_sequences", "=", "[", "]", "\n", "for", "set", "in", "sorted", "(", "os", ".", "listdir", "(", "base_vid_anno_path", ")", ")", ":", "\n", "            ", "set_id", "=", "int", "(", "set", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "for", "vid", "in", "sorted", "(", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "base_vid_anno_path", ",", "set", ")", ")", ")", ":", "\n", "\n", "                ", "vid_id", "=", "int", "(", "vid", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", ")", "\n", "anno_files", "=", "sorted", "(", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "base_vid_anno_path", ",", "set", ",", "vid", ")", ")", ")", "\n", "\n", "frame1_anno", "=", "ET", ".", "parse", "(", "os", ".", "path", ".", "join", "(", "base_vid_anno_path", ",", "set", ",", "vid", ",", "anno_files", "[", "0", "]", ")", ")", "\n", "image_size", "=", "[", "int", "(", "frame1_anno", ".", "find", "(", "'size/width'", ")", ".", "text", ")", ",", "int", "(", "frame1_anno", ".", "find", "(", "'size/height'", ")", ".", "text", ")", "]", "\n", "\n", "objects", "=", "[", "ET", ".", "ElementTree", "(", "file", "=", "os", ".", "path", ".", "join", "(", "base_vid_anno_path", ",", "set", ",", "vid", ",", "f", ")", ")", ".", "findall", "(", "'object'", ")", "\n", "for", "f", "in", "anno_files", "]", "\n", "\n", "tracklets", "=", "{", "}", "\n", "\n", "# Find all tracklets along with start frame", "\n", "for", "f_id", ",", "all_targets", "in", "enumerate", "(", "objects", ")", ":", "\n", "                    ", "for", "target", "in", "all_targets", ":", "\n", "                        ", "tracklet_id", "=", "target", ".", "find", "(", "'trackid'", ")", ".", "text", "\n", "if", "tracklet_id", "not", "in", "tracklets", ":", "\n", "                            ", "tracklets", "[", "tracklet_id", "]", "=", "f_id", "\n", "\n", "", "", "", "for", "tracklet_id", ",", "tracklet_start", "in", "tracklets", ".", "items", "(", ")", ":", "\n", "                    ", "tracklet_anno", "=", "[", "]", "\n", "target_visible", "=", "[", "]", "\n", "class_name_id", "=", "None", "\n", "\n", "for", "f_id", "in", "range", "(", "tracklet_start", ",", "len", "(", "objects", ")", ")", ":", "\n", "                        ", "found", "=", "False", "\n", "for", "target", "in", "objects", "[", "f_id", "]", ":", "\n", "                            ", "if", "target", ".", "find", "(", "'trackid'", ")", ".", "text", "==", "tracklet_id", ":", "\n", "                                ", "if", "not", "class_name_id", ":", "\n", "                                    ", "class_name_id", "=", "target", ".", "find", "(", "'name'", ")", ".", "text", "\n", "", "x1", "=", "int", "(", "target", ".", "find", "(", "'bndbox/xmin'", ")", ".", "text", ")", "\n", "y1", "=", "int", "(", "target", ".", "find", "(", "'bndbox/ymin'", ")", ".", "text", ")", "\n", "x2", "=", "int", "(", "target", ".", "find", "(", "'bndbox/xmax'", ")", ".", "text", ")", "\n", "y2", "=", "int", "(", "target", ".", "find", "(", "'bndbox/ymax'", ")", ".", "text", ")", "\n", "\n", "tracklet_anno", ".", "append", "(", "[", "x1", ",", "y1", ",", "x2", "-", "x1", ",", "y2", "-", "y1", "]", ")", "\n", "target_visible", ".", "append", "(", "target", ".", "find", "(", "'occluded'", ")", ".", "text", "==", "'0'", ")", "\n", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "not", "found", ":", "\n", "                            ", "break", "\n", "\n", "", "", "new_sequence", "=", "{", "'set_id'", ":", "set_id", ",", "'vid_id'", ":", "vid_id", ",", "'class_name'", ":", "class_name_id", ",", "\n", "'start_frame'", ":", "tracklet_start", ",", "'anno'", ":", "tracklet_anno", ",", "\n", "'target_visible'", ":", "target_visible", ",", "'image_size'", ":", "image_size", "}", "\n", "all_sequences", ".", "append", "(", "new_sequence", ")", "\n", "\n", "", "", "", "return", "all_sequences", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.get_target_to_image_ratio": [[12, 16], ["torch.Tensor", "torch.Tensor", "anno[].prod", "torch.Tensor.prod"], "function", ["None"], ["def", "get_target_to_image_ratio", "(", "seq", ")", ":", "\n", "    ", "anno", "=", "torch", ".", "Tensor", "(", "seq", "[", "'anno'", "]", ")", "\n", "img_sz", "=", "torch", ".", "Tensor", "(", "seq", "[", "'image_size'", "]", ")", "\n", "return", "(", "anno", "[", "0", ",", "2", ":", "4", "]", ".", "prod", "(", ")", "/", "(", "img_sz", ".", "prod", "(", ")", ")", ")", ".", "sqrt", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.__init__": [[8, 21], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "name", ",", "root", ",", "image_loader", "=", "jpeg4py_loader", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            root - The root path to the dataset\n            image_loader (jpeg4py_loader) -  The function to read the images. jpeg4py (https://github.com/ajkxyz/jpeg4py)\n                                            is used by default.\n        \"\"\"", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "root", "=", "root", "\n", "self", ".", "image_loader", "=", "image_loader", "\n", "\n", "self", ".", "image_list", "=", "[", "]", "# Contains the list of sequences.", "\n", "self", ".", "class_list", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.__len__": [[22, 28], ["base_image_dataset.BaseImageDataset.get_num_images"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_num_images"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns size of the dataset\n        returns:\n            int - number of samples in the dataset\n        \"\"\"", "\n", "return", "self", ".", "get_num_images", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.__getitem__": [[29, 33], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\" Not to be used! Check get_frames() instead.\n        \"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_name": [[34, 41], ["None"], "methods", ["None"], ["", "def", "get_name", "(", "self", ")", ":", "\n", "        ", "\"\"\" Name of the dataset\n\n        returns:\n            string - Name of the dataset\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_num_images": [[42, 48], ["len"], "methods", ["None"], ["", "def", "get_num_images", "(", "self", ")", ":", "\n", "        ", "\"\"\" Number of sequences in a dataset\n\n        returns:\n            int - number of sequences in the dataset.\"\"\"", "\n", "return", "len", "(", "self", ".", "image_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.has_class_info": [[49, 51], ["None"], "methods", ["None"], ["", "def", "has_class_info", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_class_name": [[52, 54], ["None"], "methods", ["None"], ["", "def", "get_class_name", "(", "self", ",", "image_id", ")", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_num_classes": [[55, 57], ["len"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "class_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_class_list": [[58, 60], ["None"], "methods", ["None"], ["", "def", "get_class_list", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "class_list", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_images_in_class": [[61, 63], ["None"], "methods", ["None"], ["", "def", "get_images_in_class", "(", "self", ",", "class_name", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.has_segmentation_info": [[64, 66], ["None"], "methods", ["None"], ["", "def", "has_segmentation_info", "(", "self", ")", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image_info": [[67, 77], ["None"], "methods", ["None"], ["", "def", "get_image_info", "(", "self", ",", "seq_id", ")", ":", "\n", "        ", "\"\"\" Returns information about a particular image,\n\n        args:\n            seq_id - index of the image\n\n        returns:\n            Dict\n            \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_image": [[78, 92], ["None"], "methods", ["None"], ["", "def", "get_image", "(", "self", ",", "image_id", ",", "anno", "=", "None", ")", ":", "\n", "        ", "\"\"\" Get a image\n\n        args:\n            image_id      - index of image\n            anno(None)  - The annotation for the sequence (see get_sequence_info). If None, they will be loaded.\n\n        returns:\n            image -\n            anno -\n            dict - A dict containing meta information about the sequence, e.g. class of the target object.\n\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer.__init__": [[18, 43], ["ltr.trainers.BaseTrainer.__init__", "ltr_trainer.LTRTrainer._set_default_settings", "collections.OrderedDict", "os.path.join", "ltr.admin.tensorboard.TensorboardWriter", "getattr"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer._set_default_settings"], ["    ", "def", "__init__", "(", "self", ",", "actor", ",", "loaders", ",", "optimizer", ",", "settings", ",", "lr_scheduler", "=", "None", ",", "freeze_backbone_bn_layers", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            actor - The actor for training the network\n            loaders - list of dataset loaders, e.g. [train_loader, val_loader]. In each epoch, the trainer runs one\n                        epoch for each loader.\n            optimizer - The optimizer used for training, e.g. Adam\n            settings - Training settings\n            lr_scheduler - Learning rate scheduler\n            freeze_backbone_bn_layers - Set to True to freeze the bach norm statistics in the backbone during training.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "actor", ",", "loaders", ",", "optimizer", ",", "settings", ",", "lr_scheduler", ")", "\n", "\n", "self", ".", "_set_default_settings", "(", ")", "\n", "\n", "# Initialize statistics variables", "\n", "self", ".", "stats", "=", "OrderedDict", "(", "{", "loader", ".", "name", ":", "None", "for", "loader", "in", "self", ".", "loaders", "}", ")", "\n", "\n", "# Initialize tensorboard", "\n", "tensorboard_writer_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "settings", ".", "env", ".", "tensorboard_dir", ",", "self", ".", "settings", ".", "project_path", ")", "\n", "self", ".", "tensorboard_writer", "=", "TensorboardWriter", "(", "tensorboard_writer_dir", ",", "[", "l", ".", "name", "for", "l", "in", "loaders", "]", ")", "\n", "\n", "self", ".", "move_data_to_gpu", "=", "getattr", "(", "settings", ",", "'move_data_to_gpu'", ",", "True", ")", "\n", "\n", "self", ".", "freeze_backbone_bn_layers", "=", "freeze_backbone_bn_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer._set_default_settings": [[44, 53], ["default.items", "getattr", "setattr"], "methods", ["None"], ["", "def", "_set_default_settings", "(", "self", ")", ":", "\n", "# Dict of all default values", "\n", "        ", "default", "=", "{", "'print_interval'", ":", "10", ",", "\n", "'print_stats'", ":", "None", ",", "\n", "'description'", ":", "''", "}", "\n", "\n", "for", "param", ",", "default_value", "in", "default", ".", "items", "(", ")", ":", "\n", "            ", "if", "getattr", "(", "self", ".", "settings", ",", "param", ",", "None", ")", "is", "None", ":", "\n", "                ", "setattr", "(", "self", ".", "settings", ",", "param", ",", "default_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer.cycle_dataset": [[54, 88], ["ltr_trainer.LTRTrainer.actor.train", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "ltr_trainer.LTRTrainer._init_timing", "enumerate", "ltr_trainer.freeze_batchnorm_layers", "ltr_trainer.LTRTrainer.actor", "ltr_trainer.LTRTrainer._update_stats", "ltr_trainer.LTRTrainer._print_stats", "data.to.to.to", "ltr_trainer.LTRTrainer.optimizer.zero_grad", "loss.backward", "ltr_trainer.LTRTrainer.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer._init_timing", "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.freeze_batchnorm_layers", "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer._update_stats", "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer._print_stats", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display.step"], ["", "", "", "def", "cycle_dataset", "(", "self", ",", "loader", ")", ":", "\n", "        ", "\"\"\"Do a cycle of training or validation.\"\"\"", "\n", "\n", "self", ".", "actor", ".", "train", "(", "loader", ".", "training", ")", "\n", "\n", "if", "self", ".", "freeze_backbone_bn_layers", ":", "\n", "            ", "freeze_batchnorm_layers", "(", "self", ".", "actor", ".", "net", ".", "feature_extractor", ")", "\n", "\n", "", "torch", ".", "set_grad_enabled", "(", "loader", ".", "training", ")", "\n", "\n", "self", ".", "_init_timing", "(", ")", "\n", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "loader", ",", "1", ")", ":", "\n", "# get inputs", "\n", "            ", "if", "self", ".", "move_data_to_gpu", ":", "\n", "                ", "data", "=", "data", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "data", "[", "'epoch'", "]", "=", "self", ".", "epoch", "\n", "data", "[", "'settings'", "]", "=", "self", ".", "settings", "\n", "\n", "# forward pass", "\n", "loss", ",", "stats", "=", "self", ".", "actor", "(", "data", ")", "\n", "\n", "# backward pass and update weights", "\n", "if", "loader", ".", "training", ":", "\n", "                ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# update statistics", "\n", "", "self", ".", "_update_stats", "(", "stats", ",", "loader", ".", "batch_size", ",", "loader", ")", "\n", "\n", "# print statistics", "\n", "self", ".", "_print_stats", "(", "i", ",", "loader", ",", "loader", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer.train_epoch": [[89, 97], ["ltr_trainer.LTRTrainer._stats_new_epoch", "ltr_trainer.LTRTrainer._write_tensorboard", "ltr_trainer.LTRTrainer.cycle_dataset"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer._stats_new_epoch", "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer._write_tensorboard", "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer.cycle_dataset"], ["", "", "def", "train_epoch", "(", "self", ")", ":", "\n", "        ", "\"\"\"Do one epoch for each loader.\"\"\"", "\n", "for", "loader", "in", "self", ".", "loaders", ":", "\n", "            ", "if", "self", ".", "epoch", "%", "loader", ".", "epoch_interval", "==", "0", ":", "\n", "                ", "self", ".", "cycle_dataset", "(", "loader", ")", "\n", "\n", "", "", "self", ".", "_stats_new_epoch", "(", ")", "\n", "self", ".", "_write_tensorboard", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer._init_timing": [[98, 102], ["time.time"], "methods", ["None"], ["", "def", "_init_timing", "(", "self", ")", ":", "\n", "        ", "self", ".", "num_frames", "=", "0", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "prev_time", "=", "self", ".", "start_time", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer._update_stats": [[103, 112], ["new_stats.items", "collections.OrderedDict", "[].update", "ltr_trainer.LTRTrainer.stats.keys", "ltr_trainer.LTRTrainer.stats[].keys", "ltr.admin.stats.AverageMeter", "ltr.admin.stats.AverageMeter", "new_stats.keys"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update"], ["", "def", "_update_stats", "(", "self", ",", "new_stats", ":", "OrderedDict", ",", "batch_size", ",", "loader", ")", ":", "\n", "# Initialize stats if not initialized yet", "\n", "        ", "if", "loader", ".", "name", "not", "in", "self", ".", "stats", ".", "keys", "(", ")", "or", "self", ".", "stats", "[", "loader", ".", "name", "]", "is", "None", ":", "\n", "            ", "self", ".", "stats", "[", "loader", ".", "name", "]", "=", "OrderedDict", "(", "{", "name", ":", "AverageMeter", "(", ")", "for", "name", "in", "new_stats", ".", "keys", "(", ")", "}", ")", "\n", "\n", "", "for", "name", ",", "val", "in", "new_stats", ".", "items", "(", ")", ":", "\n", "            ", "if", "name", "not", "in", "self", ".", "stats", "[", "loader", ".", "name", "]", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "stats", "[", "loader", ".", "name", "]", "[", "name", "]", "=", "AverageMeter", "(", ")", "\n", "", "self", ".", "stats", "[", "loader", ".", "name", "]", "[", "name", "]", ".", "update", "(", "val", ",", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer._print_stats": [[113, 126], ["time.time", "ltr_trainer.LTRTrainer.stats[].items", "print", "loader.__len__", "loader.__len__", "hasattr"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler.__len__", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler.__len__"], ["", "", "def", "_print_stats", "(", "self", ",", "i", ",", "loader", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "num_frames", "+=", "batch_size", "\n", "current_time", "=", "time", ".", "time", "(", ")", "\n", "batch_fps", "=", "batch_size", "/", "(", "current_time", "-", "self", ".", "prev_time", ")", "\n", "average_fps", "=", "self", ".", "num_frames", "/", "(", "current_time", "-", "self", ".", "start_time", ")", "\n", "self", ".", "prev_time", "=", "current_time", "\n", "if", "i", "%", "self", ".", "settings", ".", "print_interval", "==", "0", "or", "i", "==", "loader", ".", "__len__", "(", ")", ":", "\n", "            ", "print_str", "=", "'[%s: %d, %d / %d] '", "%", "(", "loader", ".", "name", ",", "self", ".", "epoch", ",", "i", ",", "loader", ".", "__len__", "(", ")", ")", "\n", "print_str", "+=", "'FPS: %.1f (%.1f)  ,  '", "%", "(", "average_fps", ",", "batch_fps", ")", "\n", "for", "name", ",", "val", "in", "self", ".", "stats", "[", "loader", ".", "name", "]", ".", "items", "(", ")", ":", "\n", "                ", "if", "(", "self", ".", "settings", ".", "print_stats", "is", "None", "or", "name", "in", "self", ".", "settings", ".", "print_stats", ")", "and", "hasattr", "(", "val", ",", "'avg'", ")", ":", "\n", "                    ", "print_str", "+=", "'%s: %.5f  ,  '", "%", "(", "name", ",", "val", ".", "avg", ")", "\n", "", "", "print", "(", "print_str", "[", ":", "-", "5", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer._stats_new_epoch": [[127, 144], ["ltr_trainer.LTRTrainer.stats.values", "loader_stats.values", "ltr_trainer.LTRTrainer.lr_scheduler.get_lr", "enumerate", "hasattr", "[].update", "stat_value.new_epoch", "ltr_trainer.LTRTrainer.stats[].keys", "ltr.admin.stats.StatValue"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.new_epoch"], ["", "", "def", "_stats_new_epoch", "(", "self", ")", ":", "\n", "# Record learning rate", "\n", "        ", "for", "loader", "in", "self", ".", "loaders", ":", "\n", "            ", "if", "loader", ".", "training", ":", "\n", "                ", "lr_list", "=", "self", ".", "lr_scheduler", ".", "get_lr", "(", ")", "\n", "for", "i", ",", "lr", "in", "enumerate", "(", "lr_list", ")", ":", "\n", "                    ", "var_name", "=", "'LearningRate/group{}'", ".", "format", "(", "i", ")", "\n", "if", "var_name", "not", "in", "self", ".", "stats", "[", "loader", ".", "name", "]", ".", "keys", "(", ")", ":", "\n", "                        ", "self", ".", "stats", "[", "loader", ".", "name", "]", "[", "var_name", "]", "=", "StatValue", "(", ")", "\n", "", "self", ".", "stats", "[", "loader", ".", "name", "]", "[", "var_name", "]", ".", "update", "(", "lr", ")", "\n", "\n", "", "", "", "for", "loader_stats", "in", "self", ".", "stats", ".", "values", "(", ")", ":", "\n", "            ", "if", "loader_stats", "is", "None", ":", "\n", "                ", "continue", "\n", "", "for", "stat_value", "in", "loader_stats", ".", "values", "(", ")", ":", "\n", "                ", "if", "hasattr", "(", "stat_value", ",", "'new_epoch'", ")", ":", "\n", "                    ", "stat_value", ".", "new_epoch", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.LTRTrainer._write_tensorboard": [[145, 150], ["ltr_trainer.LTRTrainer.tensorboard_writer.write_epoch", "ltr_trainer.LTRTrainer.tensorboard_writer.write_info"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.tensorboard.TensorboardWriter.write_epoch", "home.repos.pwc.inspect_result.visionml_pytracking.admin.tensorboard.TensorboardWriter.write_info"], ["", "", "", "", "def", "_write_tensorboard", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "epoch", "==", "1", ":", "\n", "            ", "self", ".", "tensorboard_writer", ".", "write_info", "(", "self", ".", "settings", ".", "module_name", ",", "self", ".", "settings", ".", "script_name", ",", "self", ".", "settings", ".", "description", ")", "\n", "\n", "", "self", ".", "tensorboard_writer", ".", "write_epoch", "(", "self", ".", "stats", ",", "self", ".", "epoch", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.ltr_trainer.freeze_batchnorm_layers": [[11, 15], ["net.modules", "isinstance", "module.eval"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval"], ["def", "freeze_batchnorm_layers", "(", "net", ")", ":", "\n", "    ", "for", "module", "in", "net", ".", "modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "module", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "            ", "module", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.base_trainer.BaseTrainer.__init__": [[12, 37], ["base_trainer.BaseTrainer.update_settings", "getattr", "base_trainer.BaseTrainer.actor.to", "torch.device", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.trainers.base_trainer.BaseTrainer.update_settings", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["def", "__init__", "(", "self", ",", "actor", ",", "loaders", ",", "optimizer", ",", "settings", ",", "lr_scheduler", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            actor - The actor for training the network\n            loaders - list of dataset loaders, e.g. [train_loader, val_loader]. In each epoch, the trainer runs one\n                        epoch for each loader.\n            optimizer - The optimizer used for training, e.g. Adam\n            settings - Training settings\n            lr_scheduler - Learning rate scheduler\n        \"\"\"", "\n", "self", ".", "actor", "=", "actor", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "lr_scheduler", "=", "lr_scheduler", "\n", "self", ".", "loaders", "=", "loaders", "\n", "\n", "self", ".", "update_settings", "(", "settings", ")", "\n", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "stats", "=", "{", "}", "\n", "\n", "self", ".", "device", "=", "getattr", "(", "settings", ",", "'device'", ",", "None", ")", "\n", "if", "self", ".", "device", "is", "None", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "settings", ".", "use_gpu", "else", "\"cpu\"", ")", "\n", "\n", "", "self", ".", "actor", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.base_trainer.BaseTrainer.update_settings": [[38, 50], ["os.path.expanduser", "os.path.join", "os.path.exists", "os.makedirs"], "methods", ["None"], ["", "def", "update_settings", "(", "self", ",", "settings", "=", "None", ")", ":", "\n", "        ", "\"\"\"Updates the trainer settings. Must be called to update internal settings.\"\"\"", "\n", "if", "settings", "is", "not", "None", ":", "\n", "            ", "self", ".", "settings", "=", "settings", "\n", "\n", "", "if", "self", ".", "settings", ".", "env", ".", "workspace_dir", "is", "not", "None", ":", "\n", "            ", "self", ".", "settings", ".", "env", ".", "workspace_dir", "=", "os", ".", "path", ".", "expanduser", "(", "self", ".", "settings", ".", "env", ".", "workspace_dir", ")", "\n", "self", ".", "_checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "settings", ".", "env", ".", "workspace_dir", ",", "'checkpoints'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "_checkpoint_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "self", ".", "_checkpoint_dir", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "_checkpoint_dir", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.base_trainer.BaseTrainer.train": [[52, 89], ["range", "print", "range", "base_trainer.BaseTrainer.load_checkpoint", "base_trainer.BaseTrainer.train_epoch", "print", "base_trainer.BaseTrainer.lr_scheduler.step", "base_trainer.BaseTrainer.save_checkpoint", "print", "print", "print", "traceback.format_exc"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.trainers.base_trainer.BaseTrainer.load_checkpoint", "home.repos.pwc.inspect_result.visionml_pytracking.trainers.base_trainer.BaseTrainer.train_epoch", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.playback_results.Display.step", "home.repos.pwc.inspect_result.visionml_pytracking.trainers.base_trainer.BaseTrainer.save_checkpoint"], ["", "", "def", "train", "(", "self", ",", "max_epochs", ",", "load_latest", "=", "False", ",", "fail_safe", "=", "True", ")", ":", "\n", "        ", "\"\"\"Do training for the given number of epochs.\n        args:\n            max_epochs - Max number of training epochs,\n            load_latest - Bool indicating whether to resume from latest epoch.\n            fail_safe - Bool indicating whether the training to automatically restart in case of any crashes.\n        \"\"\"", "\n", "\n", "epoch", "=", "-", "1", "\n", "num_tries", "=", "10", "\n", "for", "i", "in", "range", "(", "num_tries", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "load_latest", ":", "\n", "                    ", "self", ".", "load_checkpoint", "(", ")", "\n", "\n", "", "for", "epoch", "in", "range", "(", "self", ".", "epoch", "+", "1", ",", "max_epochs", "+", "1", ")", ":", "\n", "                    ", "self", ".", "epoch", "=", "epoch", "\n", "\n", "self", ".", "train_epoch", "(", ")", "\n", "\n", "if", "self", ".", "lr_scheduler", "is", "not", "None", ":", "\n", "                        ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "\n", "", "if", "self", ".", "_checkpoint_dir", ":", "\n", "                        ", "self", ".", "save_checkpoint", "(", ")", "\n", "", "", "", "except", ":", "\n", "                ", "print", "(", "'Training crashed at epoch {}'", ".", "format", "(", "epoch", ")", ")", "\n", "if", "fail_safe", ":", "\n", "                    ", "self", ".", "epoch", "-=", "1", "\n", "load_latest", "=", "True", "\n", "print", "(", "'Traceback for the error!'", ")", "\n", "print", "(", "traceback", ".", "format_exc", "(", ")", ")", "\n", "print", "(", "'Restarting training from last epoch ...'", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "\n", "\n", "", "", "", "print", "(", "'Finished training!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.base_trainer.BaseTrainer.train_epoch": [[91, 93], ["None"], "methods", ["None"], ["", "def", "train_epoch", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.base_trainer.BaseTrainer.save_checkpoint": [[95, 127], ["torch.save", "os.rename", "ltr.admin.multigpu.is_multi_gpu", "type", "type", "net.state_dict", "getattr", "getattr", "base_trainer.BaseTrainer.optimizer.state_dict", "os.path.exists", "os.makedirs"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.save", "home.repos.pwc.inspect_result.visionml_pytracking.admin.multigpu.is_multi_gpu"], ["", "def", "save_checkpoint", "(", "self", ")", ":", "\n", "        ", "\"\"\"Saves a checkpoint of the network and other variables.\"\"\"", "\n", "\n", "net", "=", "self", ".", "actor", ".", "net", ".", "module", "if", "multigpu", ".", "is_multi_gpu", "(", "self", ".", "actor", ".", "net", ")", "else", "self", ".", "actor", ".", "net", "\n", "\n", "actor_type", "=", "type", "(", "self", ".", "actor", ")", ".", "__name__", "\n", "net_type", "=", "type", "(", "net", ")", ".", "__name__", "\n", "state", "=", "{", "\n", "'epoch'", ":", "self", ".", "epoch", ",", "\n", "'actor_type'", ":", "actor_type", ",", "\n", "'net_type'", ":", "net_type", ",", "\n", "'net'", ":", "net", ".", "state_dict", "(", ")", ",", "\n", "'net_info'", ":", "getattr", "(", "net", ",", "'info'", ",", "None", ")", ",", "\n", "'constructor'", ":", "getattr", "(", "net", ",", "'constructor'", ",", "None", ")", ",", "\n", "'optimizer'", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'stats'", ":", "self", ".", "stats", ",", "\n", "'settings'", ":", "self", ".", "settings", "\n", "}", "\n", "\n", "\n", "directory", "=", "'{}/{}'", ".", "format", "(", "self", ".", "_checkpoint_dir", ",", "self", ".", "settings", ".", "project_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "directory", ")", "\n", "\n", "# First save as a tmp file", "\n", "", "tmp_file_path", "=", "'{}/{}_ep{:04d}.tmp'", ".", "format", "(", "directory", ",", "net_type", ",", "self", ".", "epoch", ")", "\n", "torch", ".", "save", "(", "state", ",", "tmp_file_path", ")", "\n", "\n", "file_path", "=", "'{}/{}_ep{:04d}.pth.tar'", ".", "format", "(", "directory", ",", "net_type", ",", "self", ".", "epoch", ")", "\n", "\n", "# Now rename to actual checkpoint. os.rename seems to be atomic if files are on same filesystem. Not 100% sure", "\n", "os", ".", "rename", "(", "tmp_file_path", ",", "file_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.trainers.base_trainer.BaseTrainer.load_checkpoint": [[129, 207], ["ltr.admin.loading.torch_load_legacy", "ignore_fields.extend", "ltr.admin.multigpu.is_multi_gpu", "type", "type", "sorted", "isinstance", "ltr.admin.loading.torch_load_legacy.keys", "glob.glob", "print", "isinstance", "net.load_state_dict", "os.path.isdir", "base_trainer.BaseTrainer.optimizer.load_state_dict", "setattr", "sorted", "os.path.expanduser", "glob.glob", "Exception"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.loading.torch_load_legacy", "home.repos.pwc.inspect_result.visionml_pytracking.admin.multigpu.is_multi_gpu"], ["", "def", "load_checkpoint", "(", "self", ",", "checkpoint", "=", "None", ",", "fields", "=", "None", ",", "ignore_fields", "=", "None", ",", "load_constructor", "=", "False", ")", ":", "\n", "        ", "\"\"\"Loads a network checkpoint file.\n\n        Can be called in three different ways:\n            load_checkpoint():\n                Loads the latest epoch from the workspace. Use this to continue training.\n            load_checkpoint(epoch_num):\n                Loads the network at the given epoch number (int).\n            load_checkpoint(path_to_checkpoint):\n                Loads the file from the given absolute path (str).\n        \"\"\"", "\n", "\n", "net", "=", "self", ".", "actor", ".", "net", ".", "module", "if", "multigpu", ".", "is_multi_gpu", "(", "self", ".", "actor", ".", "net", ")", "else", "self", ".", "actor", ".", "net", "\n", "\n", "actor_type", "=", "type", "(", "self", ".", "actor", ")", ".", "__name__", "\n", "net_type", "=", "type", "(", "net", ")", ".", "__name__", "\n", "\n", "if", "checkpoint", "is", "None", ":", "\n", "# Load most recent checkpoint", "\n", "            ", "checkpoint_list", "=", "sorted", "(", "glob", ".", "glob", "(", "'{}/{}/{}_ep*.pth.tar'", ".", "format", "(", "self", ".", "_checkpoint_dir", ",", "\n", "self", ".", "settings", ".", "project_path", ",", "net_type", ")", ")", ")", "\n", "if", "checkpoint_list", ":", "\n", "                ", "checkpoint_path", "=", "checkpoint_list", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "print", "(", "'No matching checkpoint file found'", ")", "\n", "return", "\n", "", "", "elif", "isinstance", "(", "checkpoint", ",", "int", ")", ":", "\n", "# Checkpoint is the epoch number", "\n", "            ", "checkpoint_path", "=", "'{}/{}/{}_ep{:04d}.pth.tar'", ".", "format", "(", "self", ".", "_checkpoint_dir", ",", "self", ".", "settings", ".", "project_path", ",", "\n", "net_type", ",", "checkpoint", ")", "\n", "", "elif", "isinstance", "(", "checkpoint", ",", "str", ")", ":", "\n", "# checkpoint is the path", "\n", "            ", "if", "os", ".", "path", ".", "isdir", "(", "checkpoint", ")", ":", "\n", "                ", "checkpoint_list", "=", "sorted", "(", "glob", ".", "glob", "(", "'{}/*_ep*.pth.tar'", ".", "format", "(", "checkpoint", ")", ")", ")", "\n", "if", "checkpoint_list", ":", "\n", "                    ", "checkpoint_path", "=", "checkpoint_list", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "'No checkpoint found'", ")", "\n", "", "", "else", ":", "\n", "                ", "checkpoint_path", "=", "os", ".", "path", ".", "expanduser", "(", "checkpoint", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "\n", "\n", "# Load network", "\n", "", "checkpoint_dict", "=", "loading", ".", "torch_load_legacy", "(", "checkpoint_path", ")", "\n", "\n", "assert", "net_type", "==", "checkpoint_dict", "[", "'net_type'", "]", ",", "'Network is not of correct type.'", "\n", "\n", "if", "fields", "is", "None", ":", "\n", "            ", "fields", "=", "checkpoint_dict", ".", "keys", "(", ")", "\n", "", "if", "ignore_fields", "is", "None", ":", "\n", "            ", "ignore_fields", "=", "[", "'settings'", "]", "\n", "\n", "# Never load the scheduler. It exists in older checkpoints.", "\n", "", "ignore_fields", ".", "extend", "(", "[", "'lr_scheduler'", ",", "'constructor'", ",", "'net_type'", ",", "'actor_type'", ",", "'net_info'", "]", ")", "\n", "\n", "# Load all fields", "\n", "for", "key", "in", "fields", ":", "\n", "            ", "if", "key", "in", "ignore_fields", ":", "\n", "                ", "continue", "\n", "", "if", "key", "==", "'net'", ":", "\n", "                ", "net", ".", "load_state_dict", "(", "checkpoint_dict", "[", "key", "]", ")", "\n", "", "elif", "key", "==", "'optimizer'", ":", "\n", "                ", "self", ".", "optimizer", ".", "load_state_dict", "(", "checkpoint_dict", "[", "key", "]", ")", "\n", "", "else", ":", "\n", "                ", "setattr", "(", "self", ",", "key", ",", "checkpoint_dict", "[", "key", "]", ")", "\n", "\n", "# Set the net info", "\n", "", "", "if", "load_constructor", "and", "'constructor'", "in", "checkpoint_dict", "and", "checkpoint_dict", "[", "'constructor'", "]", "is", "not", "None", ":", "\n", "            ", "net", ".", "constructor", "=", "checkpoint_dict", "[", "'constructor'", "]", "\n", "", "if", "'net_info'", "in", "checkpoint_dict", "and", "checkpoint_dict", "[", "'net_info'", "]", "is", "not", "None", ":", "\n", "            ", "net", ".", "info", "=", "checkpoint_dict", "[", "'net_info'", "]", "\n", "\n", "# Update the epoch in lr scheduler", "\n", "", "if", "'epoch'", "in", "fields", ":", "\n", "            ", "self", ".", "lr_scheduler", ".", "last_epoch", "=", "self", ".", "epoch", "\n", "\n", "", "return", "True", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.meta.steepestdescent.GNSteepestDescent.__init__": [[10, 21], ["float", "torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "residual_module", ",", "num_iter", "=", "1", ",", "compute_losses", "=", "False", ",", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "\n", "parameter_batch_dim", "=", "0", ",", "residual_batch_dim", "=", "0", ",", "steplength_reg", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "residual_module", "=", "residual_module", "\n", "self", ".", "num_iter", "=", "num_iter", "\n", "self", ".", "compute_losses", "=", "compute_losses", "\n", "self", ".", "detach_length", "=", "detach_length", "\n", "self", ".", "steplength_reg", "=", "steplength_reg", "\n", "self", ".", "_parameter_batch_dim", "=", "parameter_batch_dim", "\n", "self", ".", "_residual_batch_dim", "=", "residual_batch_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.meta.steepestdescent.GNSteepestDescent._sqr_norm": [[23, 26], ["sum", "e.sum", "range", "e.dim"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "_sqr_norm", "(", "self", ",", "x", ":", "TensorList", ",", "batch_dim", "=", "0", ")", ":", "\n", "        ", "sum_keep_batch_dim", "=", "lambda", "e", ":", "e", ".", "sum", "(", "dim", "=", "[", "d", "for", "d", "in", "range", "(", "e", ".", "dim", "(", ")", ")", "if", "d", "!=", "batch_dim", "]", ")", "\n", "return", "sum", "(", "(", "x", "*", "x", ")", ".", "apply", "(", "sum_keep_batch_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.meta.steepestdescent.GNSteepestDescent._compute_loss": [[28, 30], ["sum", "sum", "res.numel"], "methods", ["None"], ["", "def", "_compute_loss", "(", "self", ",", "res", ")", ":", "\n", "        ", "return", "sum", "(", "(", "res", "*", "res", ")", ".", "sum", "(", ")", ")", "/", "sum", "(", "res", ".", "numel", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.meta.steepestdescent.GNSteepestDescent.forward": [[32, 106], ["torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "steepestdescent.GNSteepestDescent.forward._add_iterate"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "meta_parameter", ":", "TensorList", ",", "num_iter", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "input_is_list", "=", "True", "\n", "if", "not", "isinstance", "(", "meta_parameter", ",", "TensorList", ")", ":", "\n", "            ", "meta_parameter", "=", "TensorList", "(", "[", "meta_parameter", "]", ")", "\n", "input_is_list", "=", "False", "\n", "\n", "\n", "# Make sure grad is enabled", "\n", "", "torch_grad_enabled", "=", "torch", ".", "is_grad_enabled", "(", ")", "\n", "torch", ".", "set_grad_enabled", "(", "True", ")", "\n", "\n", "num_iter", "=", "self", ".", "num_iter", "if", "num_iter", "is", "None", "else", "num_iter", "\n", "\n", "meta_parameter_iterates", "=", "[", "]", "\n", "def", "_add_iterate", "(", "meta_par", ")", ":", "\n", "            ", "if", "input_is_list", ":", "\n", "                ", "meta_parameter_iterates", ".", "append", "(", "meta_par", ")", "\n", "", "else", ":", "\n", "                ", "meta_parameter_iterates", ".", "append", "(", "meta_par", "[", "0", "]", ")", "\n", "\n", "", "", "_add_iterate", "(", "meta_parameter", ")", "\n", "\n", "losses", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_iter", ")", ":", "\n", "            ", "if", "i", ">", "0", "and", "i", "%", "self", ".", "detach_length", "==", "0", ":", "\n", "                ", "meta_parameter", "=", "meta_parameter", ".", "detach", "(", ")", "\n", "\n", "", "meta_parameter", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "# Compute residual vector", "\n", "r", "=", "self", ".", "residual_module", "(", "meta_parameter", ",", "**", "kwargs", ")", "\n", "\n", "if", "self", ".", "compute_losses", ":", "\n", "                ", "losses", ".", "append", "(", "self", ".", "_compute_loss", "(", "r", ")", ")", "\n", "\n", "# Compute gradient of loss", "\n", "", "u", "=", "r", ".", "clone", "(", ")", "\n", "g", "=", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "r", ",", "meta_parameter", ",", "u", ",", "create_graph", "=", "True", ")", ")", "\n", "\n", "# Multiply gradient with Jacobian", "\n", "h", "=", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "g", ",", "u", ",", "g", ",", "create_graph", "=", "True", ")", ")", "\n", "\n", "# Compute squared norms", "\n", "ip_gg", "=", "self", ".", "_sqr_norm", "(", "g", ",", "batch_dim", "=", "self", ".", "_parameter_batch_dim", ")", "\n", "ip_hh", "=", "self", ".", "_sqr_norm", "(", "h", ",", "batch_dim", "=", "self", ".", "_residual_batch_dim", ")", "\n", "\n", "# Compute step length", "\n", "alpha", "=", "ip_gg", "/", "(", "ip_hh", "+", "self", ".", "steplength_reg", "*", "ip_gg", ")", ".", "clamp", "(", "1e-8", ")", "\n", "\n", "# Compute optimization step", "\n", "step", "=", "g", ".", "apply", "(", "lambda", "e", ":", "alpha", ".", "reshape", "(", "[", "-", "1", "if", "d", "==", "self", ".", "_parameter_batch_dim", "else", "1", "for", "d", "in", "range", "(", "e", ".", "dim", "(", ")", ")", "]", ")", "*", "e", ")", "\n", "\n", "# Add step to parameter", "\n", "meta_parameter", "=", "meta_parameter", "-", "step", "\n", "\n", "_add_iterate", "(", "meta_parameter", ")", "\n", "\n", "", "if", "self", ".", "compute_losses", ":", "\n", "            ", "losses", ".", "append", "(", "self", ".", "_compute_loss", "(", "self", ".", "residual_module", "(", "meta_parameter", ",", "**", "kwargs", ")", ")", ")", "\n", "\n", "# Reset the grad enabled flag", "\n", "", "torch", ".", "set_grad_enabled", "(", "torch_grad_enabled", ")", "\n", "if", "not", "torch_grad_enabled", ":", "\n", "            ", "meta_parameter", ".", "detach_", "(", ")", "\n", "for", "w", "in", "meta_parameter_iterates", ":", "\n", "                ", "w", ".", "detach_", "(", ")", "\n", "", "for", "l", "in", "losses", ":", "\n", "                ", "l", ".", "detach_", "(", ")", "\n", "\n", "", "", "if", "not", "input_is_list", ":", "\n", "            ", "meta_parameter", "=", "meta_parameter", "[", "0", "]", "\n", "\n", "", "return", "meta_parameter", ",", "meta_parameter_iterates", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.meta.steepestdescent.KLRegSteepestDescent.__init__": [[110, 124], ["float", "torch.Module.__init__", "torch.Parameter", "torch.Parameter", "math.log", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "score_predictor", ",", "num_iter", "=", "1", ",", "compute_losses", "=", "True", ",", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "\n", "parameter_batch_dim", "=", "0", ",", "steplength_reg", "=", "0.0", ",", "hessian_reg", "=", "0", ",", "init_step_length", "=", "1.0", ",", "\n", "softmax_reg", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "score_predictor", "=", "score_predictor", "\n", "self", ".", "num_iter", "=", "num_iter", "\n", "self", ".", "compute_losses", "=", "compute_losses", "\n", "self", ".", "detach_length", "=", "detach_length", "\n", "self", ".", "steplength_reg", "=", "steplength_reg", "\n", "self", ".", "hessian_reg", "=", "hessian_reg", "\n", "self", ".", "log_step_length", "=", "nn", ".", "Parameter", "(", "math", ".", "log", "(", "init_step_length", ")", "*", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "softmax_reg", "=", "softmax_reg", "\n", "self", ".", "_parameter_batch_dim", "=", "parameter_batch_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.meta.steepestdescent.KLRegSteepestDescent.forward": [[126, 210], ["torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.is_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "steepestdescent.KLRegSteepestDescent.score_predictor.init_data", "range", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "isinstance", "pytracking.TensorList", "math.exp", "meta_parameter.detach.detach.requires_grad_", "steepestdescent.KLRegSteepestDescent.score_predictor", "ltr.models.layers.activation.softmax_reg().reshape", "sum", "weights_grad.apply", "meta_parameter_iterates.append", "losses.append", "meta_parameter.detach.detach.detach_", "meta_parameter.detach.detach.detach", "losses.append", "pytracking.TensorList", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "steepestdescent.KLRegSteepestDescent.forward._compute_loss"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.meta.steepestdescent.GNSteepestDescent._compute_loss"], ["", "def", "forward", "(", "self", ",", "meta_parameter", ":", "TensorList", ",", "num_iter", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "meta_parameter", ",", "TensorList", ")", ":", "\n", "            ", "meta_parameter", "=", "TensorList", "(", "[", "meta_parameter", "]", ")", "\n", "\n", "", "_residual_batch_dim", "=", "1", "\n", "\n", "# Make sure grad is enabled", "\n", "torch_grad_enabled", "=", "torch", ".", "is_grad_enabled", "(", ")", "\n", "torch", ".", "set_grad_enabled", "(", "True", ")", "\n", "\n", "num_iter", "=", "self", ".", "num_iter", "if", "num_iter", "is", "None", "else", "num_iter", "\n", "\n", "step_length_factor", "=", "torch", ".", "exp", "(", "self", ".", "log_step_length", ")", "\n", "\n", "label_density", ",", "sample_weight", ",", "reg_weight", "=", "self", ".", "score_predictor", ".", "init_data", "(", "meta_parameter", ",", "**", "kwargs", ")", "\n", "\n", "exp_reg", "=", "0", "if", "self", ".", "softmax_reg", "is", "None", "else", "math", ".", "exp", "(", "self", ".", "softmax_reg", ")", "\n", "\n", "def", "_compute_loss", "(", "scores", ",", "weights", ")", ":", "\n", "            ", "num_sequences", "=", "scores", ".", "shape", "[", "_residual_batch_dim", "]", "\n", "return", "torch", ".", "sum", "(", "sample_weight", ".", "reshape", "(", "sample_weight", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "*", "\n", "(", "torch", ".", "log", "(", "scores", ".", "exp", "(", ")", ".", "sum", "(", "dim", "=", "(", "-", "2", ",", "-", "1", ")", ")", "+", "exp_reg", ")", "-", "(", "label_density", "*", "scores", ")", ".", "sum", "(", "dim", "=", "(", "-", "2", ",", "-", "1", ")", ")", ")", ")", "/", "num_sequences", "+", "reg_weight", "*", "sum", "(", "(", "weights", "*", "weights", ")", ".", "sum", "(", ")", ")", "/", "num_sequences", "\n", "\n", "", "meta_parameter_iterates", "=", "[", "meta_parameter", "]", "\n", "losses", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_iter", ")", ":", "\n", "            ", "if", "i", ">", "0", "and", "i", "%", "self", ".", "detach_length", "==", "0", ":", "\n", "                ", "meta_parameter", "=", "meta_parameter", ".", "detach", "(", ")", "\n", "\n", "", "meta_parameter", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "# Compute residual vector", "\n", "scores", "=", "self", ".", "score_predictor", "(", "meta_parameter", ",", "**", "kwargs", ")", "\n", "\n", "if", "self", ".", "compute_losses", ":", "\n", "                ", "losses", ".", "append", "(", "_compute_loss", "(", "scores", ",", "meta_parameter", ")", ")", "\n", "\n", "", "scores_softmax", "=", "activation", ".", "softmax_reg", "(", "scores", ".", "reshape", "(", "*", "scores", ".", "shape", "[", ":", "2", "]", ",", "-", "1", ")", ",", "dim", "=", "2", ",", "\n", "reg", "=", "self", ".", "softmax_reg", ")", ".", "reshape", "(", "scores", ".", "shape", ")", "\n", "dLds", "=", "sample_weight", "*", "(", "scores_softmax", "-", "label_density", ")", "\n", "\n", "# Compute gradient of loss", "\n", "weights_grad", "=", "TensorList", "(", "torch", ".", "autograd", ".", "grad", "(", "scores", ",", "meta_parameter", ",", "dLds", ",", "create_graph", "=", "True", ")", ")", "+", "meta_parameter", "*", "reg_weight", "\n", "\n", "# Multiply gradient with Jacobian", "\n", "scores_grad", "=", "torch", ".", "autograd", ".", "grad", "(", "weights_grad", ",", "dLds", ",", "weights_grad", ",", "create_graph", "=", "True", ")", "[", "0", "]", "\n", "\n", "sm_scores_grad", "=", "scores_softmax", "*", "scores_grad", "\n", "hes_scores_grad", "=", "sm_scores_grad", "-", "scores_softmax", "*", "torch", ".", "sum", "(", "sm_scores_grad", ",", "dim", "=", "(", "-", "2", ",", "-", "1", ")", ",", "keepdim", "=", "True", ")", "+", "self", ".", "hessian_reg", "*", "scores_grad", "\n", "grad_hes_grad", "=", "(", "scores_grad", "*", "hes_scores_grad", ")", ".", "reshape", "(", "*", "scores", ".", "shape", "[", ":", "2", "]", ",", "-", "1", ")", ".", "sum", "(", "dim", "=", "2", ")", ".", "clamp", "(", "min", "=", "0", ")", "\n", "grad_hes_grad", "=", "(", "sample_weight", ".", "reshape", "(", "sample_weight", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "*", "grad_hes_grad", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n", "# Compute optimal step length", "\n", "gg", "=", "(", "weights_grad", "*", "weights_grad", ")", ".", "reshape", "(", "scores", ".", "shape", "[", "1", "]", ",", "-", "1", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "alpha_num", "=", "sum", "(", "gg", ")", "\n", "alpha_den", "=", "(", "grad_hes_grad", "+", "sum", "(", "gg", "*", "reg_weight", ")", "+", "self", ".", "steplength_reg", "*", "alpha_num", ")", ".", "clamp", "(", "1e-8", ")", "\n", "alpha", "=", "step_length_factor", "*", "(", "alpha_num", "/", "alpha_den", ")", "\n", "\n", "# Compute optimization step", "\n", "step", "=", "weights_grad", ".", "apply", "(", "\n", "lambda", "e", ":", "alpha", ".", "reshape", "(", "[", "-", "1", "if", "d", "==", "self", ".", "_parameter_batch_dim", "else", "1", "for", "d", "in", "range", "(", "e", ".", "dim", "(", ")", ")", "]", ")", "*", "e", ")", "\n", "\n", "# Add step to parameter", "\n", "meta_parameter", "=", "meta_parameter", "-", "step", "\n", "\n", "meta_parameter_iterates", ".", "append", "(", "meta_parameter", ")", "\n", "\n", "", "if", "self", ".", "compute_losses", ":", "\n", "            ", "losses", ".", "append", "(", "_compute_loss", "(", "self", ".", "score_predictor", "(", "meta_parameter", ",", "**", "kwargs", ")", ",", "meta_parameter", ")", ")", "\n", "\n", "# Reset the grad enabled flag", "\n", "", "torch", ".", "set_grad_enabled", "(", "torch_grad_enabled", ")", "\n", "if", "not", "torch_grad_enabled", ":", "\n", "            ", "meta_parameter", ".", "detach_", "(", ")", "\n", "for", "w", "in", "meta_parameter_iterates", ":", "\n", "                ", "w", ".", "detach_", "(", ")", "\n", "", "for", "l", "in", "losses", ":", "\n", "                ", "l", ".", "detach_", "(", ")", "\n", "\n", "", "", "return", "meta_parameter", ",", "meta_parameter_iterates", ",", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.__init__": [[14, 34], ["torch.Module.__init__", "linear_filter.LinearFilter.feature_extractor.modules", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["\n", "self", ".", "filter_size", "=", "filter_size", "\n", "\n", "self", ".", "feature_extractor", "=", "feature_extractor", "# Extracts features input to the target model", "\n", "\n", "self", ".", "filter_initializer", "=", "filter_initializer", "# Predicts an initial filter in a feed-forward manner", "\n", "self", ".", "filter_optimizer", "=", "filter_optimizer", "# Iteratively updates the filter by minimizing the few-shot", "\n", "# learning loss", "\n", "\n", "self", ".", "filter_dilation_factors", "=", "filter_dilation_factors", "\n", "\n", "# Init weights", "\n", "for", "m", "in", "self", ".", "feature_extractor", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.forward": [[35, 67], ["linear_filter.LinearFilter.extract_classification_feat", "linear_filter.LinearFilter.extract_classification_feat", "linear_filter.LinearFilter.get_filter", "train_bb.dim", "train_feat.reshape.reshape.dim", "train_feat.reshape.reshape.reshape", "test_feat.reshape.reshape.dim", "test_feat.reshape.reshape.reshape", "linear_filter.LinearFilter.classify"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat", "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.get_filter", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.classify"], ["\n", "", "", "", "def", "forward", "(", "self", ",", "train_feat", ",", "test_feat", ",", "train_label", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" the mask should be 5d\"\"\"", "\n", "assert", "train_label", ".", "dim", "(", ")", "==", "5", "\n", "\n", "num_sequences", "=", "train_label", ".", "shape", "[", "1", "]", "\n", "\n", "if", "train_feat", ".", "dim", "(", ")", "==", "5", ":", "\n", "            ", "train_feat", "=", "train_feat", ".", "view", "(", "-", "1", ",", "*", "train_feat", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "", "if", "test_feat", ".", "dim", "(", ")", "==", "5", ":", "\n", "            ", "test_feat", "=", "test_feat", ".", "view", "(", "-", "1", ",", "*", "test_feat", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "# Extract target model features", "\n", "", "train_feat", "=", "self", ".", "extract_target_model_features", "(", "train_feat", ",", "num_sequences", ")", "\n", "test_feat", "=", "self", ".", "extract_target_model_features", "(", "test_feat", ",", "num_sequences", ")", "\n", "\n", "# Train filter", "\n", "filter", ",", "filter_iter", ",", "_", "=", "self", ".", "get_filter", "(", "train_feat", ",", "train_label", ",", "\n", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Predict mask encodings for the test frames", "\n", "mask_encodings", "=", "[", "self", ".", "apply_target_model", "(", "f", ",", "test_feat", ")", "for", "f", "in", "filter_iter", "]", "\n", "\n", "return", "mask_encodings", "\n", "\n", "", "def", "extract_target_model_features", "(", "self", ",", "feat", ",", "num_sequences", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "feature_extractor", "is", "None", ":", "\n", "            ", "return", "feat", "\n", "", "if", "num_sequences", "is", "None", ":", "\n", "            ", "return", "self", ".", "feature_extractor", "(", "feat", ")", "\n", "\n", "", "output", "=", "self", ".", "feature_extractor", "(", "feat", ")", "\n", "return", "output", ".", "view", "(", "-", "1", ",", "num_sequences", ",", "*", "output", ".", "shape", "[", "-", "3", ":", "]", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.extract_classification_feat": [[68, 77], ["linear_filter.LinearFilter.feature_extractor", "linear_filter.LinearFilter.reshape", "linear_filter.LinearFilter.feature_extractor"], "methods", ["None"], ["\n", "", "def", "apply_target_model", "(", "self", ",", "weights", ",", "feat", ")", ":", "\n", "        ", "\"\"\" Apply the target model to obtain the mask encodings\"\"\"", "\n", "mask_encoding", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "weights", ",", "dilation_factors", "=", "self", ".", "filter_dilation_factors", ")", "\n", "return", "mask_encoding", "\n", "\n", "", "def", "get_filter", "(", "self", ",", "feat", ",", "train_label", ",", "train_sw", ",", "num_objects", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Get the initial target model parameters given the few-shot labels \"\"\"", "\n", "if", "num_objects", "is", "None", ":", "\n", "            ", "weights", "=", "self", ".", "filter_initializer", "(", "feat", ",", "train_label", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.classify": [[78, 84], ["ltr.apply_filter"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter"], ["", "else", ":", "\n", "            ", "weights", "=", "self", ".", "filter_initializer", "(", "feat", ",", "train_label", ")", "\n", "weights", "=", "weights", ".", "repeat", "(", "1", ",", "num_objects", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "", "if", "self", ".", "filter_optimizer", "is", "not", "None", ":", "\n", "            ", "weights", ",", "weights_iter", ",", "losses", "=", "self", ".", "filter_optimizer", "(", "TensorList", "(", "[", "weights", "]", ")", ",", "feat", "=", "feat", ",", "label", "=", "train_label", ",", "\n", "sample_weight", "=", "train_sw", ",", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.get_filter": [[85, 106], ["linear_filter.LinearFilter.filter_initializer", "linear_filter.LinearFilter.filter_optimizer"], "methods", ["None"], ["*", "args", ",", "**", "kwargs", ")", "\n", "weights", "=", "weights", "[", "0", "]", "\n", "weights_iter", "=", "[", "w", "[", "0", "]", "for", "w", "in", "weights_iter", "]", "\n", "", "else", ":", "\n", "            ", "weights_iter", "=", "[", "weights", "]", "\n", "losses", "=", "None", "\n", "\n", "", "return", "weights", ",", "weights_iter", ",", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.train_classifier": [[107, 119], ["linear_filter.LinearFilter.extract_classification_feat", "linear_filter.LinearFilter.get_filter", "backbone_feat.reshape.reshape.dim", "backbone_feat.reshape.reshape.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.get_filter", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], []], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.track_frame": [[120, 132], ["linear_filter.LinearFilter.extract_classification_feat", "ltr.apply_filter", "backbone_feat.reshape.reshape.dim", "backbone_feat.reshape.reshape.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], []], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.initializer.FilterPool.__init__": [[16, 20], ["torch.Module.__init__", "ltr.external.PreciseRoIPooling.pytorch.prroi_pool.PrRoIPool2D"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["        ", "assert", "feat", ".", "dim", "(", ")", "==", "5", "\n", "# num_sequences = feat.shape[1] if feat.dim() == 5 else 1", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "\n", "\n", "return", "feat", ".", "new_zeros", "(", "num_sequences", ",", "*", "self", ".", "filter_size", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.initializer.FilterPool.forward": [[21, 46], ["bb.reshape.reshape.reshape", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "bb.reshape.reshape.clone", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "initializer.FilterPool.prroi_pool", "pool_bb[].prod().sqrt", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "pool_bb[].prod", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.initializer.FilterInitializer.__init__": [[60, 90], ["torch.Module.__init__", "initializer.FilterPool", "range", "range", "post_conv_layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "initializer.FilterInitializer.modules", "pre_conv_layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "post_conv_layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "isinstance", "ltr.models.layers.blocks.conv_block", "ltr.models.layers.blocks.conv_block", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block", "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block"], []], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.initializer.FilterInitializer.forward": [[92, 116], ["initializer.FilterInitializer.filter_pool", "initializer.FilterInitializer.filter_post_layers", "initializer.FilterInitializer.filter_pre_layers", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "bb.dim", "initializer.FilterInitializer.reshape", "torch.mean.reshape", "torch.mean.reshape", "torch.mean.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], []], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.initializer.FilterInitializerLinear.__init__": [[128, 149], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "initializer.FilterPool", "initializer.FilterInitializerLinear.modules", "isinstance", "isinstance", "m.weight.data.normal_", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_", "math.sqrt", "m.weight.data.zero_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], []], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.initializer.FilterInitializerLinear.forward": [[151, 174], ["initializer.FilterInitializerLinear.filter_conv", "initializer.FilterInitializerLinear.filter_pool", "initializer.FilterInitializerLinear.reshape", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.reshape", "torch.mean.reshape", "torch.mean.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], []], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.initializer.FilterInitializerZero.__init__": [[183, 187], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], []], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.initializer.FilterInitializerZero.forward": [[188, 200], ["feat.new_zeros", "feat.dim"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], []], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.initializer.FilterInitializerSiamese.__init__": [[210, 226], ["torch.Module.__init__", "initializer.FilterPool", "initializer.FilterInitializerSiamese.modules", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.bias.data.zero_", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], []], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.initializer.FilterInitializerSiamese.forward": [[228, 249], ["feat.reshape.reshape.reshape", "initializer.FilterInitializerSiamese.filter_pool", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.reshape", "torch.mean.reshape", "torch.mean.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], []], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.optimizer.DiMPSteepestDescentGN.__init__": [[31, 83], ["float", "torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "ltr.models.layers.distance.DistanceMap", "ltr.models.layers.distance.DistanceMap", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "optimizer.DiMPSteepestDescentGN.spatial_weight_predictor.weight.data.fill_", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp.min", "torch.exp.min", "torch.exp.min", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "mask_layers.append", "ltr.BentIdentPar", "ltr.BentIdentPar", "ltr.BentIdentParDeriv", "ltr.BentIdentParDeriv", "math.log", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "ValueError", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "ltr.LeakyReluPar", "ltr.LeakyReluPar", "ltr.LeakyReluParDeriv", "ltr.LeakyReluParDeriv", "ValueError", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "num_iter", "=", "1", ",", "feat_stride", "=", "16", ",", "init_step_length", "=", "1.0", ",", "\n", "init_filter_reg", "=", "1e-2", ",", "init_gauss_sigma", "=", "1.0", ",", "num_dist_bins", "=", "5", ",", "bin_displacement", "=", "1.0", ",", "mask_init_factor", "=", "4.0", ",", "\n", "score_act", "=", "'relu'", ",", "act_param", "=", "None", ",", "min_filter_reg", "=", "1e-3", ",", "mask_act", "=", "'sigmoid'", ",", "\n", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "alpha_eps", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_iter", "=", "num_iter", "\n", "self", ".", "feat_stride", "=", "feat_stride", "\n", "self", ".", "log_step_length", "=", "nn", ".", "Parameter", "(", "math", ".", "log", "(", "init_step_length", ")", "*", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "filter_reg", "=", "nn", ".", "Parameter", "(", "init_filter_reg", "*", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "distance_map", "=", "DistanceMap", "(", "num_dist_bins", ",", "bin_displacement", ")", "\n", "self", ".", "min_filter_reg", "=", "min_filter_reg", "\n", "self", ".", "detach_length", "=", "detach_length", "\n", "self", ".", "alpha_eps", "=", "alpha_eps", "\n", "\n", "# Distance coordinates", "\n", "d", "=", "torch", ".", "arange", "(", "num_dist_bins", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "reshape", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "*", "bin_displacement", "\n", "if", "init_gauss_sigma", "==", "0", ":", "\n", "            ", "init_gauss", "=", "torch", ".", "zeros_like", "(", "d", ")", "\n", "init_gauss", "[", "0", ",", "0", ",", "0", ",", "0", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "init_gauss", "=", "torch", ".", "exp", "(", "-", "1", "/", "2", "*", "(", "d", "/", "init_gauss_sigma", ")", "**", "2", ")", "\n", "\n", "# Module that predicts the target label function (y in the paper)", "\n", "", "self", ".", "label_map_predictor", "=", "nn", ".", "Conv2d", "(", "num_dist_bins", ",", "1", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "label_map_predictor", ".", "weight", ".", "data", "=", "init_gauss", "-", "init_gauss", ".", "min", "(", ")", "\n", "\n", "# Module that predicts the target mask (m in the paper)", "\n", "mask_layers", "=", "[", "nn", ".", "Conv2d", "(", "num_dist_bins", ",", "1", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "]", "\n", "if", "mask_act", "==", "'sigmoid'", ":", "\n", "            ", "mask_layers", ".", "append", "(", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "init_bias", "=", "0.0", "\n", "", "elif", "mask_act", "==", "'linear'", ":", "\n", "            ", "init_bias", "=", "0.5", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown activation'", ")", "\n", "", "self", ".", "target_mask_predictor", "=", "nn", ".", "Sequential", "(", "*", "mask_layers", ")", "\n", "self", ".", "target_mask_predictor", "[", "0", "]", ".", "weight", ".", "data", "=", "mask_init_factor", "*", "torch", ".", "tanh", "(", "2.0", "-", "d", ")", "+", "init_bias", "\n", "\n", "# Module that predicts the residual weights (v in the paper)", "\n", "self", ".", "spatial_weight_predictor", "=", "nn", ".", "Conv2d", "(", "num_dist_bins", ",", "1", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "spatial_weight_predictor", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n", "# The score actvation and its derivative", "\n", "if", "score_act", "==", "'bentpar'", ":", "\n", "            ", "self", ".", "score_activation", "=", "activation", ".", "BentIdentPar", "(", "act_param", ")", "\n", "self", ".", "score_activation_deriv", "=", "activation", ".", "BentIdentParDeriv", "(", "act_param", ")", "\n", "", "elif", "score_act", "==", "'relu'", ":", "\n", "            ", "self", ".", "score_activation", "=", "activation", ".", "LeakyReluPar", "(", ")", "\n", "self", ".", "score_activation_deriv", "=", "activation", ".", "LeakyReluParDeriv", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown score activation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.optimizer.DiMPSteepestDescentGN.forward": [[85, 171], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "optimizer.DiMPSteepestDescentGN.distance_map", "optimizer.DiMPSteepestDescentGN.label_map_predictor().reshape", "optimizer.DiMPSteepestDescentGN.target_mask_predictor().reshape", "optimizer.DiMPSteepestDescentGN.spatial_weight_predictor().reshape", "range", "isinstance", "ltr.apply_filter", "ltr.apply_filter", "optimizer.DiMPSteepestDescentGN.score_activation", "optimizer.DiMPSteepestDescentGN.score_activation_deriv", "ltr.apply_filter", "ltr.apply_filter", "weight_iterates.append", "ltr.apply_filter", "ltr.apply_filter", "optimizer.DiMPSteepestDescentGN.score_activation", "losses.append", "feat.dim", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "optimizer.DiMPSteepestDescentGN.label_map_predictor", "optimizer.DiMPSteepestDescentGN.target_mask_predictor", "optimizer.DiMPSteepestDescentGN.spatial_weight_predictor", "math.sqrt", "weights.detach.detach.detach", "losses.append", "ltr.apply_feat_transpose", "ltr.apply_feat_transpose", "sample_weight.sqrt().reshape", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "alpha.reshape", "sample_weight.sqrt"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_feat_transpose", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_feat_transpose"], ["", "", "def", "forward", "(", "self", ",", "weights", ",", "feat", ",", "bb", ",", "sample_weight", "=", "None", ",", "num_iter", "=", "None", ",", "compute_losses", "=", "True", ")", ":", "\n", "        ", "\"\"\"Runs the optimizer module.\n        Note that [] denotes an optional dimension.\n        args:\n            weights:  Initial weights. Dims (sequences, feat_dim, wH, wW).\n            feat:  Input feature maps. Dims (images_in_sequence, [sequences], feat_dim, H, W).\n            bb:  Target bounding boxes (x, y, w, h) in the image coords. Dims (images_in_sequence, [sequences], 4).\n            sample_weight:  Optional weight for each sample. Dims: (images_in_sequence, [sequences]).\n            num_iter:  Number of iterations to run.\n            compute_losses:  Whether to compute the (train) loss in each iteration.\n        returns:\n            weights:  The final oprimized weights.\n            weight_iterates:  The weights computed in each iteration (including initial input and final output).\n            losses:  Train losses.\"\"\"", "\n", "\n", "# Sizes", "\n", "num_iter", "=", "self", ".", "num_iter", "if", "num_iter", "is", "None", "else", "num_iter", "\n", "num_images", "=", "feat", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "if", "feat", ".", "dim", "(", ")", "==", "5", "else", "1", "\n", "filter_sz", "=", "(", "weights", ".", "shape", "[", "-", "2", "]", ",", "weights", ".", "shape", "[", "-", "1", "]", ")", "\n", "output_sz", "=", "(", "feat", ".", "shape", "[", "-", "2", "]", "+", "(", "weights", ".", "shape", "[", "-", "2", "]", "+", "1", ")", "%", "2", ",", "feat", ".", "shape", "[", "-", "1", "]", "+", "(", "weights", ".", "shape", "[", "-", "1", "]", "+", "1", ")", "%", "2", ")", "\n", "\n", "# Get learnable scalars", "\n", "step_length_factor", "=", "torch", ".", "exp", "(", "self", ".", "log_step_length", ")", "\n", "reg_weight", "=", "(", "self", ".", "filter_reg", "*", "self", ".", "filter_reg", ")", ".", "clamp", "(", "min", "=", "self", ".", "min_filter_reg", "**", "2", ")", "\n", "\n", "# Compute distance map", "\n", "dmap_offset", "=", "(", "torch", ".", "Tensor", "(", "filter_sz", ")", ".", "to", "(", "bb", ".", "device", ")", "%", "2", ")", "/", "2.0", "\n", "center", "=", "(", "(", "bb", "[", "...", ",", ":", "2", "]", "+", "bb", "[", "...", ",", "2", ":", "]", "/", "2", ")", "/", "self", ".", "feat_stride", ")", ".", "reshape", "(", "-", "1", ",", "2", ")", ".", "flip", "(", "(", "1", ",", ")", ")", "-", "dmap_offset", "\n", "dist_map", "=", "self", ".", "distance_map", "(", "center", ",", "output_sz", ")", "\n", "\n", "# Compute label map masks and weight", "\n", "label_map", "=", "self", ".", "label_map_predictor", "(", "dist_map", ")", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "*", "dist_map", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "target_mask", "=", "self", ".", "target_mask_predictor", "(", "dist_map", ")", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "*", "dist_map", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "spatial_weight", "=", "self", ".", "spatial_weight_predictor", "(", "dist_map", ")", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "*", "dist_map", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "\n", "# Get total sample weights", "\n", "if", "sample_weight", "is", "None", ":", "\n", "            ", "sample_weight", "=", "math", ".", "sqrt", "(", "1.0", "/", "num_images", ")", "*", "spatial_weight", "\n", "", "elif", "isinstance", "(", "sample_weight", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "sample_weight", "=", "sample_weight", ".", "sqrt", "(", ")", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "1", ",", "1", ")", "*", "spatial_weight", "\n", "\n", "", "backprop_through_learning", "=", "(", "self", ".", "detach_length", ">", "0", ")", "\n", "\n", "weight_iterates", "=", "[", "weights", "]", "\n", "losses", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_iter", ")", ":", "\n", "            ", "if", "not", "backprop_through_learning", "or", "(", "i", ">", "0", "and", "i", "%", "self", ".", "detach_length", "==", "0", ")", ":", "\n", "                ", "weights", "=", "weights", ".", "detach", "(", ")", "\n", "\n", "# Compute residuals", "\n", "", "scores", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "weights", ")", "\n", "scores_act", "=", "self", ".", "score_activation", "(", "scores", ",", "target_mask", ")", "\n", "score_mask", "=", "self", ".", "score_activation_deriv", "(", "scores", ",", "target_mask", ")", "\n", "residuals", "=", "sample_weight", "*", "(", "scores_act", "-", "label_map", ")", "\n", "\n", "if", "compute_losses", ":", "\n", "                ", "losses", ".", "append", "(", "(", "(", "residuals", "**", "2", ")", ".", "sum", "(", ")", "+", "reg_weight", "*", "(", "weights", "**", "2", ")", ".", "sum", "(", ")", ")", "/", "num_sequences", ")", "\n", "\n", "# Compute gradient", "\n", "", "residuals_mapped", "=", "score_mask", "*", "(", "sample_weight", "*", "residuals", ")", "\n", "weights_grad", "=", "filter_layer", ".", "apply_feat_transpose", "(", "feat", ",", "residuals_mapped", ",", "filter_sz", ",", "training", "=", "self", ".", "training", ")", "+", "reg_weight", "*", "weights", "\n", "\n", "# Map the gradient with the Jacobian", "\n", "scores_grad", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "weights_grad", ")", "\n", "scores_grad", "=", "sample_weight", "*", "(", "score_mask", "*", "scores_grad", ")", "\n", "\n", "# Compute optimal step length", "\n", "alpha_num", "=", "(", "weights_grad", "*", "weights_grad", ")", ".", "sum", "(", "dim", "=", "(", "1", ",", "2", ",", "3", ")", ")", "\n", "alpha_den", "=", "(", "(", "scores_grad", "*", "scores_grad", ")", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "-", "1", ")", ".", "sum", "(", "dim", "=", "(", "0", ",", "2", ")", ")", "+", "(", "reg_weight", "+", "self", ".", "alpha_eps", ")", "*", "alpha_num", ")", ".", "clamp", "(", "1e-8", ")", "\n", "alpha", "=", "alpha_num", "/", "alpha_den", "\n", "\n", "# Update filter", "\n", "weights", "=", "weights", "-", "(", "step_length_factor", "*", "alpha", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ")", "*", "weights_grad", "\n", "\n", "# Add the weight iterate", "\n", "weight_iterates", ".", "append", "(", "weights", ")", "\n", "\n", "", "if", "compute_losses", ":", "\n", "            ", "scores", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "weights", ")", "\n", "scores", "=", "self", ".", "score_activation", "(", "scores", ",", "target_mask", ")", "\n", "losses", ".", "append", "(", "(", "(", "(", "sample_weight", "*", "(", "scores", "-", "label_map", ")", ")", "**", "2", ")", ".", "sum", "(", ")", "+", "reg_weight", "*", "(", "weights", "**", "2", ")", ".", "sum", "(", ")", ")", "/", "num_sequences", ")", "\n", "\n", "", "return", "weights", ",", "weight_iterates", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.optimizer.DiMPL2SteepestDescentGN.__init__": [[187, 200], ["float", "torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "math.log", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "num_iter", "=", "1", ",", "feat_stride", "=", "16", ",", "init_step_length", "=", "1.0", ",", "gauss_sigma", "=", "1.0", ",", "hinge_threshold", "=", "-", "999", ",", "\n", "init_filter_reg", "=", "1e-2", ",", "min_filter_reg", "=", "1e-3", ",", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "alpha_eps", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_iter", "=", "num_iter", "\n", "self", ".", "feat_stride", "=", "feat_stride", "\n", "self", ".", "log_step_length", "=", "nn", ".", "Parameter", "(", "math", ".", "log", "(", "init_step_length", ")", "*", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "filter_reg", "=", "nn", ".", "Parameter", "(", "init_filter_reg", "*", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "min_filter_reg", "=", "min_filter_reg", "\n", "self", ".", "detach_length", "=", "detach_length", "\n", "self", ".", "hinge_threshold", "=", "hinge_threshold", "\n", "self", ".", "gauss_sigma", "=", "gauss_sigma", "\n", "self", ".", "alpha_eps", "=", "alpha_eps", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.optimizer.DiMPL2SteepestDescentGN.get_label": [[201, 209], ["center.reshape.reshape.reshape", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "center[].reshape", "center[].reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "get_label", "(", "self", ",", "center", ",", "output_sz", ")", ":", "\n", "        ", "center", "=", "center", ".", "reshape", "(", "center", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "center", ".", "shape", "[", "-", "1", "]", ")", "\n", "k0", "=", "torch", ".", "arange", "(", "output_sz", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", ".", "to", "(", "center", ".", "device", ")", "\n", "k1", "=", "torch", ".", "arange", "(", "output_sz", "[", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "reshape", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", ".", "to", "(", "center", ".", "device", ")", "\n", "g0", "=", "torch", ".", "exp", "(", "-", "1.0", "/", "(", "2", "*", "self", ".", "gauss_sigma", "**", "2", ")", "*", "(", "k0", "-", "center", "[", ":", ",", ":", ",", "0", "]", ".", "reshape", "(", "*", "center", ".", "shape", "[", ":", "2", "]", ",", "1", ",", "1", ")", ")", "**", "2", ")", "\n", "g1", "=", "torch", ".", "exp", "(", "-", "1.0", "/", "(", "2", "*", "self", ".", "gauss_sigma", "**", "2", ")", "*", "(", "k1", "-", "center", "[", ":", ",", ":", ",", "1", "]", ".", "reshape", "(", "*", "center", ".", "shape", "[", ":", "2", "]", ",", "1", ",", "1", ")", ")", "**", "2", ")", "\n", "gauss", "=", "g0", "*", "g1", "\n", "return", "gauss", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.optimizer.DiMPL2SteepestDescentGN.forward": [[211, 292], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "optimizer.DiMPL2SteepestDescentGN.get_label", "range", "math.sqrt", "isinstance", "ltr.apply_filter", "ltr.apply_filter", "ltr.apply_filter", "ltr.apply_filter", "weight_iterates.append", "ltr.apply_filter", "ltr.apply_filter", "losses.append", "feat.dim", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "sample_weight.sqrt().reshape.sqrt().reshape.sqrt().reshape", "weights.detach.detach.detach", "losses.append", "ltr.apply_feat_transpose", "ltr.apply_feat_transpose", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "sample_weight.sqrt().reshape.sqrt().reshape.sqrt", "alpha.reshape", "ltr.apply_filter.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.optimizer.DiMPL2SteepestDescentGN.get_label", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_feat_transpose", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_feat_transpose", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu"], ["", "def", "forward", "(", "self", ",", "weights", ",", "feat", ",", "bb", ",", "sample_weight", "=", "None", ",", "num_iter", "=", "None", ",", "compute_losses", "=", "True", ")", ":", "\n", "        ", "\"\"\"Runs the optimizer module.\n        Note that [] denotes an optional dimension.\n        args:\n            weights:  Initial weights. Dims (sequences, feat_dim, wH, wW).\n            feat:  Input feature maps. Dims (images_in_sequence, [sequences], feat_dim, H, W).\n            bb:  Target bounding boxes (x, y, w, h) in the image coords. Dims (images_in_sequence, [sequences], 4).\n            sample_weight:  Optional weight for each sample. Dims: (images_in_sequence, [sequences]).\n            num_iter:  Number of iterations to run.\n            compute_losses:  Whether to compute the (train) loss in each iteration.\n        returns:\n            weights:  The final oprimized weights.\n            weight_iterates:  The weights computed in each iteration (including initial input and final output).\n            losses:  Train losses.\"\"\"", "\n", "\n", "# Sizes", "\n", "num_iter", "=", "self", ".", "num_iter", "if", "num_iter", "is", "None", "else", "num_iter", "\n", "num_images", "=", "feat", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "if", "feat", ".", "dim", "(", ")", "==", "5", "else", "1", "\n", "filter_sz", "=", "(", "weights", ".", "shape", "[", "-", "2", "]", ",", "weights", ".", "shape", "[", "-", "1", "]", ")", "\n", "output_sz", "=", "(", "feat", ".", "shape", "[", "-", "2", "]", "+", "(", "weights", ".", "shape", "[", "-", "2", "]", "+", "1", ")", "%", "2", ",", "feat", ".", "shape", "[", "-", "1", "]", "+", "(", "weights", ".", "shape", "[", "-", "1", "]", "+", "1", ")", "%", "2", ")", "\n", "\n", "# Get learnable scalars", "\n", "step_length_factor", "=", "torch", ".", "exp", "(", "self", ".", "log_step_length", ")", "\n", "reg_weight", "=", "(", "self", ".", "filter_reg", "*", "self", ".", "filter_reg", ")", ".", "clamp", "(", "min", "=", "self", ".", "min_filter_reg", "**", "2", ")", "\n", "\n", "# Compute distance map", "\n", "dmap_offset", "=", "(", "torch", ".", "Tensor", "(", "filter_sz", ")", ".", "to", "(", "bb", ".", "device", ")", "%", "2", ")", "/", "2.0", "\n", "center", "=", "(", "(", "bb", "[", "...", ",", ":", "2", "]", "+", "bb", "[", "...", ",", "2", ":", "]", "/", "2", ")", "/", "self", ".", "feat_stride", ")", ".", "flip", "(", "(", "-", "1", ",", ")", ")", "-", "dmap_offset", "\n", "label_map", "=", "self", ".", "get_label", "(", "center", ",", "output_sz", ")", "\n", "target_mask", "=", "(", "label_map", ">", "self", ".", "hinge_threshold", ")", ".", "float", "(", ")", "\n", "label_map", "*=", "target_mask", "\n", "\n", "# Get total sample weights", "\n", "if", "sample_weight", "is", "None", ":", "\n", "            ", "sample_weight", "=", "math", ".", "sqrt", "(", "1.0", "/", "num_images", ")", "\n", "", "elif", "isinstance", "(", "sample_weight", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "sample_weight", "=", "sample_weight", ".", "sqrt", "(", ")", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "1", ",", "1", ")", "\n", "\n", "", "weight_iterates", "=", "[", "weights", "]", "\n", "losses", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_iter", ")", ":", "\n", "            ", "if", "i", ">", "0", "and", "i", "%", "self", ".", "detach_length", "==", "0", ":", "\n", "                ", "weights", "=", "weights", ".", "detach", "(", ")", "\n", "\n", "# Compute residuals", "\n", "", "scores", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "weights", ")", "\n", "scores_act", "=", "target_mask", "*", "scores", "+", "(", "1.0", "-", "target_mask", ")", "*", "F", ".", "relu", "(", "scores", ")", "\n", "score_mask", "=", "target_mask", "+", "(", "1.0", "-", "target_mask", ")", "*", "(", "scores", ".", "detach", "(", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "residuals", "=", "sample_weight", "*", "(", "scores_act", "-", "label_map", ")", "\n", "\n", "if", "compute_losses", ":", "\n", "                ", "losses", ".", "append", "(", "(", "(", "residuals", "**", "2", ")", ".", "sum", "(", ")", "+", "reg_weight", "*", "(", "weights", "**", "2", ")", ".", "sum", "(", ")", ")", "/", "num_sequences", ")", "\n", "\n", "# Compute gradient", "\n", "", "residuals_mapped", "=", "score_mask", "*", "(", "sample_weight", "*", "residuals", ")", "\n", "weights_grad", "=", "filter_layer", ".", "apply_feat_transpose", "(", "feat", ",", "residuals_mapped", ",", "filter_sz", ",", "training", "=", "self", ".", "training", ")", "+", "reg_weight", "*", "weights", "\n", "\n", "# Map the gradient with the Jacobian", "\n", "scores_grad", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "weights_grad", ")", "\n", "scores_grad", "=", "sample_weight", "*", "(", "score_mask", "*", "scores_grad", ")", "\n", "\n", "# Compute optimal step length", "\n", "alpha_num", "=", "(", "weights_grad", "*", "weights_grad", ")", ".", "sum", "(", "dim", "=", "(", "1", ",", "2", ",", "3", ")", ")", "\n", "alpha_den", "=", "(", "(", "scores_grad", "*", "scores_grad", ")", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "-", "1", ")", ".", "sum", "(", "dim", "=", "(", "0", ",", "2", ")", ")", "+", "(", "reg_weight", "+", "self", ".", "alpha_eps", ")", "*", "alpha_num", ")", ".", "clamp", "(", "1e-8", ")", "\n", "alpha", "=", "alpha_num", "/", "alpha_den", "\n", "\n", "# Update filter", "\n", "weights", "=", "weights", "-", "(", "step_length_factor", "*", "alpha", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ")", "*", "weights_grad", "\n", "\n", "# Add the weight iterate", "\n", "weight_iterates", ".", "append", "(", "weights", ")", "\n", "\n", "", "if", "compute_losses", ":", "\n", "            ", "scores", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "weights", ")", "\n", "scores", "=", "target_mask", "*", "scores", "+", "(", "1.0", "-", "target_mask", ")", "*", "F", ".", "relu", "(", "scores", ")", "\n", "losses", ".", "append", "(", "(", "(", "(", "sample_weight", "*", "(", "scores", "-", "label_map", ")", ")", "**", "2", ")", ".", "sum", "(", ")", "+", "reg_weight", "*", "(", "weights", "**", "2", ")", ".", "sum", "(", ")", ")", "/", "num_sequences", ")", "\n", "\n", "", "return", "weights", ",", "weight_iterates", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.optimizer.PrDiMPSteepestDescentNewton.__init__": [[312, 330], ["float", "torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "math.log", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "num_iter", "=", "1", ",", "feat_stride", "=", "16", ",", "init_step_length", "=", "1.0", ",", "\n", "init_filter_reg", "=", "1e-2", ",", "gauss_sigma", "=", "1.0", ",", "min_filter_reg", "=", "1e-3", ",", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "\n", "alpha_eps", "=", "0.0", ",", "init_uni_weight", "=", "None", ",", "normalize_label", "=", "False", ",", "label_shrink", "=", "0", ",", "softmax_reg", "=", "None", ",", "label_threshold", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_iter", "=", "num_iter", "\n", "self", ".", "feat_stride", "=", "feat_stride", "\n", "self", ".", "log_step_length", "=", "nn", ".", "Parameter", "(", "math", ".", "log", "(", "init_step_length", ")", "*", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "filter_reg", "=", "nn", ".", "Parameter", "(", "init_filter_reg", "*", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "gauss_sigma", "=", "gauss_sigma", "\n", "self", ".", "min_filter_reg", "=", "min_filter_reg", "\n", "self", ".", "detach_length", "=", "detach_length", "\n", "self", ".", "alpha_eps", "=", "alpha_eps", "\n", "self", ".", "uni_weight", "=", "0", "if", "init_uni_weight", "is", "None", "else", "init_uni_weight", "\n", "self", ".", "normalize_label", "=", "normalize_label", "\n", "self", ".", "label_shrink", "=", "label_shrink", "\n", "self", ".", "softmax_reg", "=", "softmax_reg", "\n", "self", ".", "label_threshold", "=", "label_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.optimizer.PrDiMPSteepestDescentNewton.get_label_density": [[331, 354], ["center.reshape.reshape.reshape", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "torch.arange().reshape().to", "dist0.reshape", "dist1.reshape", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "center[].reshape", "center[].reshape", "torch.zeros_like.reshape", "torch.zeros_like.reshape", "torch.zeros_like.reshape", "torch.zeros_like.reshape", "torch.zeros_like.reshape", "torch.zeros_like.reshape", "gauss.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "dist0.reshape.argmin", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "dist1.reshape.argmin"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "get_label_density", "(", "self", ",", "center", ",", "output_sz", ")", ":", "\n", "        ", "center", "=", "center", ".", "reshape", "(", "center", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "center", ".", "shape", "[", "-", "1", "]", ")", "\n", "k0", "=", "torch", ".", "arange", "(", "output_sz", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", ".", "to", "(", "center", ".", "device", ")", "\n", "k1", "=", "torch", ".", "arange", "(", "output_sz", "[", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "reshape", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", ".", "to", "(", "center", ".", "device", ")", "\n", "dist0", "=", "(", "k0", "-", "center", "[", ":", ",", ":", ",", "0", "]", ".", "reshape", "(", "*", "center", ".", "shape", "[", ":", "2", "]", ",", "1", ",", "1", ")", ")", "**", "2", "\n", "dist1", "=", "(", "k1", "-", "center", "[", ":", ",", ":", ",", "1", "]", ".", "reshape", "(", "*", "center", ".", "shape", "[", ":", "2", "]", ",", "1", ",", "1", ")", ")", "**", "2", "\n", "if", "self", ".", "gauss_sigma", "==", "0", ":", "\n", "            ", "dist0_view", "=", "dist0", ".", "reshape", "(", "-", "1", ",", "dist0", ".", "shape", "[", "-", "2", "]", ")", "\n", "dist1_view", "=", "dist1", ".", "reshape", "(", "-", "1", ",", "dist1", ".", "shape", "[", "-", "1", "]", ")", "\n", "one_hot0", "=", "torch", ".", "zeros_like", "(", "dist0_view", ")", "\n", "one_hot1", "=", "torch", ".", "zeros_like", "(", "dist1_view", ")", "\n", "one_hot0", "[", "torch", ".", "arange", "(", "one_hot0", ".", "shape", "[", "0", "]", ")", ",", "dist0_view", ".", "argmin", "(", "dim", "=", "-", "1", ")", "]", "=", "1.0", "\n", "one_hot1", "[", "torch", ".", "arange", "(", "one_hot1", ".", "shape", "[", "0", "]", ")", ",", "dist1_view", ".", "argmin", "(", "dim", "=", "-", "1", ")", "]", "=", "1.0", "\n", "gauss", "=", "one_hot0", ".", "reshape", "(", "dist0", ".", "shape", ")", "*", "one_hot1", ".", "reshape", "(", "dist1", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "g0", "=", "torch", ".", "exp", "(", "-", "1.0", "/", "(", "2", "*", "self", ".", "gauss_sigma", "**", "2", ")", "*", "dist0", ")", "\n", "g1", "=", "torch", ".", "exp", "(", "-", "1.0", "/", "(", "2", "*", "self", ".", "gauss_sigma", "**", "2", ")", "*", "dist1", ")", "\n", "gauss", "=", "(", "g0", "/", "(", "2", "*", "math", ".", "pi", "*", "self", ".", "gauss_sigma", "**", "2", ")", ")", "*", "g1", "\n", "", "gauss", "=", "gauss", "*", "(", "gauss", ">", "self", ".", "label_threshold", ")", ".", "float", "(", ")", "\n", "if", "self", ".", "normalize_label", ":", "\n", "            ", "gauss", "/=", "(", "gauss", ".", "sum", "(", "dim", "=", "(", "-", "2", ",", "-", "1", ")", ",", "keepdim", "=", "True", ")", "+", "1e-8", ")", "\n", "", "label_dens", "=", "(", "1.0", "-", "self", ".", "label_shrink", ")", "*", "(", "(", "1.0", "-", "self", ".", "uni_weight", ")", "*", "gauss", "+", "self", ".", "uni_weight", "/", "(", "output_sz", "[", "0", "]", "*", "output_sz", "[", "1", "]", ")", ")", "\n", "return", "label_dens", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.optimizer.PrDiMPSteepestDescentNewton.forward": [[355, 440], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "optimizer.PrDiMPSteepestDescentNewton.get_label_density", "range", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "isinstance", "math.exp", "ltr.apply_filter", "ltr.apply_filter", "ltr.softmax_reg().reshape", "ltr.softmax_reg().reshape", "ltr.apply_filter", "ltr.apply_filter", "weight_iterates.append", "ltr.apply_filter", "ltr.apply_filter", "losses.append", "feat.dim", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "sample_weight.reshape.reshape.reshape", "weights.detach.detach.detach", "losses.append", "ltr.apply_feat_transpose", "ltr.apply_feat_transpose", "optimizer.PrDiMPSteepestDescentNewton.forward._compute_loss"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.optimizer.PrDiMPSteepestDescentNewton.get_label_density", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_feat_transpose", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_feat_transpose", "home.repos.pwc.inspect_result.visionml_pytracking.meta.steepestdescent.GNSteepestDescent._compute_loss"], ["", "def", "forward", "(", "self", ",", "weights", ",", "feat", ",", "bb", ",", "sample_weight", "=", "None", ",", "num_iter", "=", "None", ",", "compute_losses", "=", "True", ")", ":", "\n", "        ", "\"\"\"Runs the optimizer module.\n        Note that [] denotes an optional dimension.\n        args:\n            weights:  Initial weights. Dims (sequences, feat_dim, wH, wW).\n            feat:  Input feature maps. Dims (images_in_sequence, [sequences], feat_dim, H, W).\n            bb:  Target bounding boxes (x, y, w, h) in the image coords. Dims (images_in_sequence, [sequences], 4).\n            sample_weight:  Optional weight for each sample. Dims: (images_in_sequence, [sequences]).\n            num_iter:  Number of iterations to run.\n            compute_losses:  Whether to compute the (train) loss in each iteration.\n        returns:\n            weights:  The final oprimized weights.\n            weight_iterates:  The weights computed in each iteration (including initial input and final output).\n            losses:  Train losses.\"\"\"", "\n", "\n", "# Sizes", "\n", "num_iter", "=", "self", ".", "num_iter", "if", "num_iter", "is", "None", "else", "num_iter", "\n", "num_images", "=", "feat", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "if", "feat", ".", "dim", "(", ")", "==", "5", "else", "1", "\n", "filter_sz", "=", "(", "weights", ".", "shape", "[", "-", "2", "]", ",", "weights", ".", "shape", "[", "-", "1", "]", ")", "\n", "output_sz", "=", "(", "feat", ".", "shape", "[", "-", "2", "]", "+", "(", "weights", ".", "shape", "[", "-", "2", "]", "+", "1", ")", "%", "2", ",", "feat", ".", "shape", "[", "-", "1", "]", "+", "(", "weights", ".", "shape", "[", "-", "1", "]", "+", "1", ")", "%", "2", ")", "\n", "\n", "# Get learnable scalars", "\n", "step_length_factor", "=", "torch", ".", "exp", "(", "self", ".", "log_step_length", ")", "\n", "reg_weight", "=", "(", "self", ".", "filter_reg", "*", "self", ".", "filter_reg", ")", ".", "clamp", "(", "min", "=", "self", ".", "min_filter_reg", "**", "2", ")", "\n", "\n", "# Compute label density", "\n", "offset", "=", "(", "torch", ".", "Tensor", "(", "filter_sz", ")", ".", "to", "(", "bb", ".", "device", ")", "%", "2", ")", "/", "2.0", "\n", "center", "=", "(", "(", "bb", "[", "...", ",", ":", "2", "]", "+", "bb", "[", "...", ",", "2", ":", "]", "/", "2", ")", "/", "self", ".", "feat_stride", ")", ".", "flip", "(", "(", "-", "1", ",", ")", ")", "-", "offset", "\n", "label_density", "=", "self", ".", "get_label_density", "(", "center", ",", "output_sz", ")", "\n", "\n", "# Get total sample weights", "\n", "if", "sample_weight", "is", "None", ":", "\n", "            ", "sample_weight", "=", "torch", ".", "Tensor", "(", "[", "1.0", "/", "num_images", "]", ")", ".", "to", "(", "feat", ".", "device", ")", "\n", "", "elif", "isinstance", "(", "sample_weight", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "sample_weight", "=", "sample_weight", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "1", ",", "1", ")", "\n", "\n", "", "exp_reg", "=", "0", "if", "self", ".", "softmax_reg", "is", "None", "else", "math", ".", "exp", "(", "self", ".", "softmax_reg", ")", "\n", "def", "_compute_loss", "(", "scores", ",", "weights", ")", ":", "\n", "            ", "return", "torch", ".", "sum", "(", "sample_weight", ".", "reshape", "(", "sample_weight", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "*", "\n", "(", "torch", ".", "log", "(", "scores", ".", "exp", "(", ")", ".", "sum", "(", "dim", "=", "(", "-", "2", ",", "-", "1", ")", ")", "+", "exp_reg", ")", "-", "(", "label_density", "*", "scores", ")", ".", "sum", "(", "dim", "=", "(", "-", "2", ",", "-", "1", ")", ")", ")", ")", "/", "num_sequences", "+", "reg_weight", "*", "(", "weights", "**", "2", ")", ".", "sum", "(", ")", "/", "num_sequences", "\n", "\n", "", "weight_iterates", "=", "[", "weights", "]", "\n", "losses", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_iter", ")", ":", "\n", "            ", "if", "i", ">", "0", "and", "i", "%", "self", ".", "detach_length", "==", "0", ":", "\n", "                ", "weights", "=", "weights", ".", "detach", "(", ")", "\n", "\n", "# Compute \"residuals\"", "\n", "", "scores", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "weights", ")", "\n", "scores_softmax", "=", "activation", ".", "softmax_reg", "(", "scores", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "-", "1", ")", ",", "dim", "=", "2", ",", "reg", "=", "self", ".", "softmax_reg", ")", ".", "reshape", "(", "scores", ".", "shape", ")", "\n", "res", "=", "sample_weight", "*", "(", "scores_softmax", "-", "label_density", ")", "\n", "\n", "if", "compute_losses", ":", "\n", "                ", "losses", ".", "append", "(", "_compute_loss", "(", "scores", ",", "weights", ")", ")", "\n", "\n", "# Compute gradient", "\n", "", "weights_grad", "=", "filter_layer", ".", "apply_feat_transpose", "(", "feat", ",", "res", ",", "filter_sz", ",", "training", "=", "self", ".", "training", ")", "+", "reg_weight", "*", "weights", "\n", "\n", "# Map the gradient with the Hessian", "\n", "scores_grad", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "weights_grad", ")", "\n", "sm_scores_grad", "=", "scores_softmax", "*", "scores_grad", "\n", "hes_scores_grad", "=", "sm_scores_grad", "-", "scores_softmax", "*", "torch", ".", "sum", "(", "sm_scores_grad", ",", "dim", "=", "(", "-", "2", ",", "-", "1", ")", ",", "keepdim", "=", "True", ")", "\n", "grad_hes_grad", "=", "(", "scores_grad", "*", "hes_scores_grad", ")", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "-", "1", ")", ".", "sum", "(", "dim", "=", "2", ")", ".", "clamp", "(", "min", "=", "0", ")", "\n", "grad_hes_grad", "=", "(", "sample_weight", ".", "reshape", "(", "sample_weight", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "*", "grad_hes_grad", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n", "# Compute optimal step length", "\n", "alpha_num", "=", "(", "weights_grad", "*", "weights_grad", ")", ".", "sum", "(", "dim", "=", "(", "1", ",", "2", ",", "3", ")", ")", "\n", "alpha_den", "=", "(", "grad_hes_grad", "+", "(", "reg_weight", "+", "self", ".", "alpha_eps", ")", "*", "alpha_num", ")", ".", "clamp", "(", "1e-8", ")", "\n", "alpha", "=", "alpha_num", "/", "alpha_den", "\n", "\n", "# Update filter", "\n", "weights", "=", "weights", "-", "(", "step_length_factor", "*", "alpha", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ")", "*", "weights_grad", "\n", "\n", "# Add the weight iterate", "\n", "weight_iterates", ".", "append", "(", "weights", ")", "\n", "\n", "", "if", "compute_losses", ":", "\n", "            ", "scores", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "weights", ")", "\n", "losses", ".", "append", "(", "_compute_loss", "(", "scores", ",", "weights", ")", ")", "\n", "\n", "", "return", "weights", ",", "weight_iterates", ",", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_basic_block": [[9, 29], ["range", "torch.nn.Sequential", "feat_layers.append", "feat_layers.append", "feat_layers.append", "feat_layers.append", "feat_layers.append", "ltr.models.layers.transform.InterpCat", "torch.nn.MaxPool2d", "torchvision.models.resnet.BasicBlock", "torch.nn.Conv2d", "feat_layers.append", "ltr.models.layers.normalization.InstanceL2Norm", "torch.nn.ReLU", "int"], "function", ["None"], ["def", "residual_basic_block", "(", "feature_dim", "=", "256", ",", "num_blocks", "=", "1", ",", "l2norm", "=", "True", ",", "final_conv", "=", "False", ",", "norm_scale", "=", "1.0", ",", "out_dim", "=", "None", ",", "\n", "interp_cat", "=", "False", ",", "final_relu", "=", "False", ",", "init_pool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Construct a network block based on the BasicBlock used in ResNet 18 and 34.\"\"\"", "\n", "if", "out_dim", "is", "None", ":", "\n", "        ", "out_dim", "=", "feature_dim", "\n", "", "feat_layers", "=", "[", "]", "\n", "if", "interp_cat", ":", "\n", "        ", "feat_layers", ".", "append", "(", "InterpCat", "(", ")", ")", "\n", "", "if", "init_pool", ":", "\n", "        ", "feat_layers", ".", "append", "(", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", "\n", "", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "        ", "odim", "=", "feature_dim", "if", "i", "<", "num_blocks", "-", "1", "+", "int", "(", "final_conv", ")", "else", "out_dim", "\n", "feat_layers", ".", "append", "(", "BasicBlock", "(", "feature_dim", ",", "odim", ")", ")", "\n", "", "if", "final_conv", ":", "\n", "        ", "feat_layers", ".", "append", "(", "nn", ".", "Conv2d", "(", "feature_dim", ",", "out_dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "if", "final_relu", ":", "\n", "            ", "feat_layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "", "", "if", "l2norm", ":", "\n", "        ", "feat_layers", ".", "append", "(", "InstanceL2Norm", "(", "scale", "=", "norm_scale", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "feat_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_basic_block_pool": [[31, 48], ["range", "torch.nn.Sequential", "feat_layers.append", "feat_layers.append", "feat_layers.append", "feat_layers.append", "torchvision.models.resnet.BasicBlock", "torch.nn.Conv2d", "torch.nn.MaxPool2d", "ltr.models.layers.normalization.InstanceL2Norm", "int"], "function", ["None"], ["", "def", "residual_basic_block_pool", "(", "feature_dim", "=", "256", ",", "num_blocks", "=", "1", ",", "l2norm", "=", "True", ",", "final_conv", "=", "False", ",", "norm_scale", "=", "1.0", ",", "out_dim", "=", "None", ",", "\n", "pool", "=", "True", ")", ":", "\n", "    ", "\"\"\"Construct a network block based on the BasicBlock used in ResNet.\"\"\"", "\n", "if", "out_dim", "is", "None", ":", "\n", "        ", "out_dim", "=", "feature_dim", "\n", "", "feat_layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "        ", "odim", "=", "feature_dim", "if", "i", "<", "num_blocks", "-", "1", "+", "int", "(", "final_conv", ")", "else", "out_dim", "\n", "feat_layers", ".", "append", "(", "BasicBlock", "(", "feature_dim", ",", "odim", ")", ")", "\n", "", "if", "final_conv", ":", "\n", "        ", "feat_layers", ".", "append", "(", "nn", ".", "Conv2d", "(", "feature_dim", ",", "out_dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "", "if", "pool", ":", "\n", "        ", "feat_layers", ".", "append", "(", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", "\n", "", "if", "l2norm", ":", "\n", "        ", "feat_layers", ".", "append", "(", "InstanceL2Norm", "(", "scale", "=", "norm_scale", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "feat_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_bottleneck": [[50, 70], ["range", "torch.nn.Sequential", "feat_layers.append", "feat_layers.append", "feat_layers.append", "feat_layers.append", "ltr.models.layers.transform.InterpCat", "torchvision.models.resnet.Bottleneck", "torch.nn.Conv2d", "feat_layers.append", "feat_layers.append", "ltr.models.layers.normalization.InstanceL2Norm", "torch.nn.ReLU", "torch.nn.MaxPool2d", "int"], "function", ["None"], ["", "def", "residual_bottleneck", "(", "feature_dim", "=", "256", ",", "num_blocks", "=", "1", ",", "l2norm", "=", "True", ",", "final_conv", "=", "False", ",", "norm_scale", "=", "1.0", ",", "out_dim", "=", "None", ",", "\n", "interp_cat", "=", "False", ",", "final_relu", "=", "False", ",", "final_pool", "=", "False", ")", ":", "\n", "    ", "\"\"\"Construct a network block based on the Bottleneck block used in ResNet.\"\"\"", "\n", "if", "out_dim", "is", "None", ":", "\n", "        ", "out_dim", "=", "feature_dim", "\n", "", "feat_layers", "=", "[", "]", "\n", "if", "interp_cat", ":", "\n", "        ", "feat_layers", ".", "append", "(", "InterpCat", "(", ")", ")", "\n", "", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "        ", "planes", "=", "feature_dim", "if", "i", "<", "num_blocks", "-", "1", "+", "int", "(", "final_conv", ")", "else", "out_dim", "//", "4", "\n", "feat_layers", ".", "append", "(", "Bottleneck", "(", "4", "*", "feature_dim", ",", "planes", ")", ")", "\n", "", "if", "final_conv", ":", "\n", "        ", "feat_layers", ".", "append", "(", "nn", ".", "Conv2d", "(", "4", "*", "feature_dim", ",", "out_dim", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ")", "\n", "if", "final_relu", ":", "\n", "            ", "feat_layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "", "if", "final_pool", ":", "\n", "            ", "feat_layers", ".", "append", "(", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ")", "\n", "", "", "if", "l2norm", ":", "\n", "        ", "feat_layers", ".", "append", "(", "InstanceL2Norm", "(", "scale", "=", "norm_scale", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "feat_layers", ")", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.residual_modules.LinearFilterLearnGen.__init__": [[11, 50], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "ltr.models.layers.distance.DistanceMap", "ltr.models.layers.distance.DistanceMap", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "residual_modules.LinearFilterLearnGen.spatial_weight_predictor.weight.data.fill_", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.arange().reshape", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp.min", "torch.exp.min", "torch.Conv2d", "torch.Conv2d", "mask_layers.append", "ltr.BentIdentPar", "ltr.BentIdentPar", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Sigmoid", "torch.Sigmoid", "ValueError", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "ltr.LeakyReluPar", "ltr.LeakyReluPar", "ValueError", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "feat_stride", "=", "16", ",", "init_filter_reg", "=", "1e-2", ",", "init_gauss_sigma", "=", "1.0", ",", "num_dist_bins", "=", "5", ",", "bin_displacement", "=", "1.0", ",", "\n", "mask_init_factor", "=", "4.0", ",", "score_act", "=", "'bentpar'", ",", "act_param", "=", "None", ",", "mask_act", "=", "'sigmoid'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "filter_reg", "=", "nn", ".", "Parameter", "(", "init_filter_reg", "*", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "feat_stride", "=", "feat_stride", "\n", "self", ".", "distance_map", "=", "DistanceMap", "(", "num_dist_bins", ",", "bin_displacement", ")", "\n", "\n", "# Distance coordinates", "\n", "d", "=", "torch", ".", "arange", "(", "num_dist_bins", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "reshape", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "*", "bin_displacement", "\n", "if", "init_gauss_sigma", "==", "0", ":", "\n", "            ", "init_gauss", "=", "torch", ".", "zeros_like", "(", "d", ")", "\n", "init_gauss", "[", "0", ",", "0", ",", "0", ",", "0", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "init_gauss", "=", "torch", ".", "exp", "(", "-", "1", "/", "2", "*", "(", "d", "/", "init_gauss_sigma", ")", "**", "2", ")", "\n", "\n", "", "self", ".", "label_map_predictor", "=", "nn", ".", "Conv2d", "(", "num_dist_bins", ",", "1", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "label_map_predictor", ".", "weight", ".", "data", "=", "init_gauss", "-", "init_gauss", ".", "min", "(", ")", "\n", "\n", "mask_layers", "=", "[", "nn", ".", "Conv2d", "(", "num_dist_bins", ",", "1", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "]", "\n", "if", "mask_act", "==", "'sigmoid'", ":", "\n", "            ", "mask_layers", ".", "append", "(", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "init_bias", "=", "0.0", "\n", "", "elif", "mask_act", "==", "'linear'", ":", "\n", "            ", "init_bias", "=", "0.5", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown activation'", ")", "\n", "", "self", ".", "target_mask_predictor", "=", "nn", ".", "Sequential", "(", "*", "mask_layers", ")", "\n", "self", ".", "target_mask_predictor", "[", "0", "]", ".", "weight", ".", "data", "=", "mask_init_factor", "*", "torch", ".", "tanh", "(", "2.0", "-", "d", ")", "+", "init_bias", "\n", "\n", "self", ".", "spatial_weight_predictor", "=", "nn", ".", "Conv2d", "(", "num_dist_bins", ",", "1", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "spatial_weight_predictor", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n", "if", "score_act", "==", "'bentpar'", ":", "\n", "            ", "self", ".", "score_activation", "=", "activation", ".", "BentIdentPar", "(", "act_param", ")", "\n", "", "elif", "score_act", "==", "'relu'", ":", "\n", "            ", "self", ".", "score_activation", "=", "activation", ".", "LeakyReluPar", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown activation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.residual_modules.LinearFilterLearnGen.forward": [[52, 86], ["ltr.apply_filter", "ltr.apply_filter", "residual_modules.LinearFilterLearnGen.distance_map", "residual_modules.LinearFilterLearnGen.label_map_predictor().reshape", "residual_modules.LinearFilterLearnGen.target_mask_predictor().reshape", "residual_modules.LinearFilterLearnGen.spatial_weight_predictor().reshape", "residual_modules.LinearFilterLearnGen.score_activation", "pytracking.TensorList", "isinstance", "filter.reshape", "feat.dim", "residual_modules.LinearFilterLearnGen.label_map_predictor", "residual_modules.LinearFilterLearnGen.target_mask_predictor", "residual_modules.LinearFilterLearnGen.spatial_weight_predictor", "math.sqrt", "sample_weight.sqrt().reshape", "is_distractor.reshape", "sample_weight.sqrt"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "", "def", "forward", "(", "self", ",", "meta_parameter", ":", "TensorList", ",", "feat", ",", "bb", ",", "sample_weight", "=", "None", ",", "is_distractor", "=", "None", ")", ":", "\n", "        ", "filter", "=", "meta_parameter", "[", "0", "]", "\n", "\n", "num_images", "=", "feat", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "if", "feat", ".", "dim", "(", ")", "==", "5", "else", "1", "\n", "filter_sz", "=", "(", "filter", ".", "shape", "[", "-", "2", "]", ",", "filter", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "# Compute scores", "\n", "scores", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "filter", ")", "\n", "\n", "# Compute distance map", "\n", "center", "=", "(", "(", "bb", "[", "...", ",", ":", "2", "]", "+", "bb", "[", "...", ",", "2", ":", "]", "/", "2", ")", "/", "self", ".", "feat_stride", ")", ".", "reshape", "(", "-", "1", ",", "2", ")", ".", "flip", "(", "(", "1", ",", ")", ")", "\n", "if", "is_distractor", "is", "not", "None", ":", "\n", "            ", "center", "[", "is_distractor", ".", "reshape", "(", "-", "1", ")", ",", ":", "]", "=", "99999", "\n", "", "dist_map", "=", "self", ".", "distance_map", "(", "center", ",", "scores", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "\n", "# Compute label map masks and weight", "\n", "label_map", "=", "self", ".", "label_map_predictor", "(", "dist_map", ")", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "dist_map", ".", "shape", "[", "-", "2", "]", ",", "dist_map", ".", "shape", "[", "-", "1", "]", ")", "\n", "target_mask", "=", "self", ".", "target_mask_predictor", "(", "dist_map", ")", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "dist_map", ".", "shape", "[", "-", "2", "]", ",", "dist_map", ".", "shape", "[", "-", "1", "]", ")", "\n", "spatial_weight", "=", "self", ".", "spatial_weight_predictor", "(", "dist_map", ")", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "dist_map", ".", "shape", "[", "-", "2", "]", ",", "dist_map", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "if", "sample_weight", "is", "None", ":", "\n", "            ", "sample_weight", "=", "math", ".", "sqrt", "(", "1.0", "/", "num_images", ")", "*", "spatial_weight", "\n", "", "elif", "isinstance", "(", "sample_weight", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "sample_weight", "=", "sample_weight", ".", "sqrt", "(", ")", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "*", "spatial_weight", "\n", "\n", "# Compute data residual", "\n", "", "scores_act", "=", "self", ".", "score_activation", "(", "scores", ",", "target_mask", ")", "\n", "data_residual", "=", "sample_weight", "*", "(", "scores_act", "-", "label_map", ")", "\n", "\n", "# Compute regularization residual. Put batch in second dimension", "\n", "reg_residual", "=", "self", ".", "filter_reg", "*", "filter", ".", "reshape", "(", "1", ",", "num_sequences", ",", "-", "1", ")", "\n", "\n", "return", "TensorList", "(", "[", "data_residual", ",", "reg_residual", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.residual_modules.LinearFilterHinge.__init__": [[89, 103], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "ltr.BentIdentPar", "ltr.BentIdentPar", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "ltr.LeakyReluPar", "ltr.LeakyReluPar", "ValueError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "feat_stride", "=", "16", ",", "init_filter_reg", "=", "1e-2", ",", "hinge_threshold", "=", "-", "999", ",", "activation_leak", "=", "0.0", ",", "score_act", "=", "'bentpar'", ",", "act_param", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "filter_reg", "=", "nn", ".", "Parameter", "(", "init_filter_reg", "*", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "feat_stride", "=", "feat_stride", "\n", "self", ".", "hinge_threshold", "=", "hinge_threshold", "\n", "self", ".", "activation_leak", "=", "activation_leak", "\n", "\n", "if", "score_act", "==", "'bentpar'", ":", "\n", "            ", "self", ".", "score_activation", "=", "activation", ".", "BentIdentPar", "(", "act_param", ")", "\n", "", "elif", "score_act", "==", "'relu'", ":", "\n", "            ", "self", ".", "score_activation", "=", "activation", ".", "LeakyReluPar", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown activation'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.residual_modules.LinearFilterHinge.forward": [[105, 132], ["isinstance", "ltr.apply_filter", "ltr.apply_filter", "residual_modules.LinearFilterHinge.score_activation", "pytracking.TensorList", "math.sqrt", "isinstance", "filter.view", "feat.dim", "sample_weight.sqrt.sqrt.sqrt", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "", "def", "forward", "(", "self", ",", "meta_parameter", ":", "TensorList", ",", "feat", ",", "bb", "=", "None", ",", "train_label", "=", "None", ",", "sample_weight", "=", "None", ",", "is_distractor", "=", "None", ")", ":", "\n", "        ", "assert", "isinstance", "(", "meta_parameter", ",", "TensorList", ")", "\n", "\n", "filter", "=", "meta_parameter", "[", "0", "]", "\n", "\n", "num_images", "=", "feat", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "if", "feat", ".", "dim", "(", ")", "==", "5", "else", "1", "\n", "\n", "# Compute scores", "\n", "scores", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "filter", ")", "\n", "\n", "if", "sample_weight", "is", "None", ":", "\n", "            ", "sample_weight", "=", "math", ".", "sqrt", "(", "1.0", "/", "num_images", ")", "\n", "", "elif", "isinstance", "(", "sample_weight", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "sample_weight", "=", "sample_weight", ".", "sqrt", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "# Compute data residual", "\n", "", "target_mask", "=", "(", "(", "train_label", ">", "self", ".", "hinge_threshold", ")", ".", "float", "(", ")", "+", "self", ".", "activation_leak", ")", ".", "clamp", "(", "max", "=", "1.0", ")", "\n", "scores_act", "=", "self", ".", "score_activation", "(", "scores", ",", "target_mask", ")", "\n", "data_residual", "=", "sample_weight", "*", "(", "scores_act", "-", "target_mask", "*", "train_label", ")", "\n", "\n", "# Compute regularization residual. Put batch in second dimension", "\n", "reg_residual", "=", "self", ".", "filter_reg", "*", "filter", ".", "view", "(", "1", ",", "num_sequences", ",", "-", "1", ")", "\n", "\n", "return", "TensorList", "(", "[", "data_residual", ",", "reg_residual", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.MLU.__init__": [[23, 27], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "min_val", ",", "inplace", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "min_val", "=", "min_val", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.MLU.forward": [[28, 30], ["torch.elu", "torch.elu", "torch.elu", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "F", ".", "elu", "(", "F", ".", "leaky_relu", "(", "input", ",", "1", "/", "self", ".", "min_val", ",", "inplace", "=", "self", ".", "inplace", ")", ",", "self", ".", "min_val", ",", "inplace", "=", "self", ".", "inplace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.LeakyReluPar.forward": [[36, 38], ["torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs"], ["def", "forward", "(", "self", ",", "x", ",", "a", ")", ":", "\n", "        ", "return", "(", "1.0", "-", "a", ")", "/", "2.0", "*", "torch", ".", "abs", "(", "x", ")", "+", "(", "1.0", "+", "a", ")", "/", "2.0", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.LeakyReluParDeriv.forward": [[43, 45], ["torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "x.detach"], "methods", ["None"], ["def", "forward", "(", "self", ",", "x", ",", "a", ")", ":", "\n", "        ", "return", "(", "1.0", "-", "a", ")", "/", "2.0", "*", "torch", ".", "sign", "(", "x", ".", "detach", "(", ")", ")", "+", "(", "1.0", "+", "a", ")", "/", "2.0", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.BentIdentPar.__init__": [[50, 53], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "b", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "b", "=", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.BentIdentPar.forward": [[54, 56], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "a", ")", ":", "\n", "        ", "return", "(", "1.0", "-", "a", ")", "/", "2.0", "*", "(", "torch", ".", "sqrt", "(", "x", "*", "x", "+", "4.0", "*", "self", ".", "b", "*", "self", ".", "b", ")", "-", "2.0", "*", "self", ".", "b", ")", "+", "(", "1.0", "+", "a", ")", "/", "2.0", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.BentIdentParDeriv.__init__": [[61, 64], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "b", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "b", "=", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.BentIdentParDeriv.forward": [[65, 67], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "a", ")", ":", "\n", "        ", "return", "(", "1.0", "-", "a", ")", "/", "2.0", "*", "(", "x", "/", "torch", ".", "sqrt", "(", "x", "*", "x", "+", "4.0", "*", "self", ".", "b", "*", "self", ".", "b", ")", ")", "+", "(", "1.0", "+", "a", ")", "/", "2.0", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.activation.softmax_reg": [[7, 17], ["torch.cat.dim", "isinstance", "x.new_tensor.expand", "torch.cat", "torch.cat", "torch.cat", "torch.softmax", "torch.softmax", "torch.softmax", "torch.cat.new_tensor", "torch.softmax", "torch.softmax", "torch.softmax", "range", "torch.cat.dim", "slice", "slice", "range", "torch.cat.dim"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["def", "softmax_reg", "(", "x", ":", "torch", ".", "Tensor", ",", "dim", ",", "reg", "=", "None", ")", ":", "\n", "    ", "\"\"\"Softmax with optional denominator regularization.\"\"\"", "\n", "if", "reg", "is", "None", ":", "\n", "        ", "return", "torch", ".", "softmax", "(", "x", ",", "dim", "=", "dim", ")", "\n", "", "dim", "%=", "x", ".", "dim", "(", ")", "\n", "if", "isinstance", "(", "reg", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "        ", "reg", "=", "x", ".", "new_tensor", "(", "[", "reg", "]", ")", "\n", "", "reg", "=", "reg", ".", "expand", "(", "[", "1", "if", "d", "==", "dim", "else", "x", ".", "shape", "[", "d", "]", "for", "d", "in", "range", "(", "x", ".", "dim", "(", ")", ")", "]", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "reg", ")", ",", "dim", "=", "dim", ")", "\n", "return", "torch", ".", "softmax", "(", "x", ",", "dim", "=", "dim", ")", "[", "[", "slice", "(", "-", "1", ")", "if", "d", "==", "dim", "else", "slice", "(", "None", ")", "for", "d", "in", "range", "(", "x", ".", "dim", "(", ")", ")", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.normalization.InstanceL2Norm.__init__": [[9, 14], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "size_average", "=", "True", ",", "eps", "=", "1e-5", ",", "scale", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size_average", "=", "size_average", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.normalization.InstanceL2Norm.forward": [[15, 21], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "self", ".", "size_average", ":", "\n", "            ", "return", "input", "*", "(", "self", ".", "scale", "*", "(", "(", "input", ".", "shape", "[", "1", "]", "*", "input", ".", "shape", "[", "2", "]", "*", "input", ".", "shape", "[", "3", "]", ")", "/", "(", "\n", "torch", ".", "sum", "(", "(", "input", "*", "input", ")", ".", "view", "(", "input", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "-", "1", ")", ",", "dim", "=", "3", ",", "keepdim", "=", "True", ")", "+", "self", ".", "eps", ")", ")", ".", "sqrt", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "input", "*", "(", "self", ".", "scale", "/", "(", "torch", ".", "sum", "(", "(", "input", "*", "input", ")", ".", "view", "(", "input", ".", "shape", "[", "0", "]", ",", "1", ",", "1", ",", "-", "1", ")", ",", "dim", "=", "3", ",", "keepdim", "=", "True", ")", "+", "self", ".", "eps", ")", ".", "sqrt", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.distance.DistanceMap.__init__": [[12, 16], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "num_bins", ",", "bin_displacement", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_bins", "=", "num_bins", "\n", "self", ".", "bin_displacement", "=", "bin_displacement", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.distance.DistanceMap.forward": [[17, 40], ["center.view.view.view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "center[].view", "center[].view", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.relu", "torch.relu", "torch.relu", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs"], ["", "def", "forward", "(", "self", ",", "center", ",", "output_sz", ")", ":", "\n", "        ", "\"\"\"Create the distance map.\n        args:\n            center: Torch tensor with (y,x) center position. Dims (batch, 2)\n            output_sz: Size of output distance map. 2-dimensional tuple.\"\"\"", "\n", "\n", "center", "=", "center", ".", "view", "(", "-", "1", ",", "2", ")", "\n", "\n", "bin_centers", "=", "torch", ".", "arange", "(", "self", ".", "num_bins", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "center", ".", "device", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "k0", "=", "torch", ".", "arange", "(", "output_sz", "[", "0", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "center", ".", "device", ")", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", "\n", "k1", "=", "torch", ".", "arange", "(", "output_sz", "[", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "center", ".", "device", ")", ".", "view", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", "\n", "\n", "d0", "=", "k0", "-", "center", "[", ":", ",", "0", "]", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "d1", "=", "k1", "-", "center", "[", ":", ",", "1", "]", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "\n", "dist", "=", "torch", ".", "sqrt", "(", "d0", "*", "d0", "+", "d1", "*", "d1", ")", "\n", "bin_diff", "=", "dist", "/", "self", ".", "bin_displacement", "-", "bin_centers", "\n", "\n", "bin_val", "=", "torch", ".", "cat", "(", "(", "F", ".", "relu", "(", "1.0", "-", "torch", ".", "abs", "(", "bin_diff", "[", ":", ",", ":", "-", "1", ",", ":", ",", ":", "]", ")", ",", "inplace", "=", "True", ")", ",", "\n", "(", "1.0", "+", "bin_diff", "[", ":", ",", "-", "1", ":", ",", ":", ",", ":", "]", ")", ".", "clamp", "(", "0", ",", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "return", "bin_val", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.LinearBlock.__init__": [[24, 29], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.BatchNorm2d", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ",", "out_planes", ",", "input_sz", ",", "bias", "=", "True", ",", "batch_norm", "=", "True", ",", "relu", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "in_planes", "*", "input_sz", "*", "input_sz", ",", "out_planes", ",", "bias", "=", "bias", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "out_planes", ")", "if", "batch_norm", "else", "None", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "if", "relu", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.LinearBlock.forward": [[30, 37], ["blocks.LinearBlock.linear", "blocks.LinearBlock.reshape", "blocks.LinearBlock.reshape", "blocks.LinearBlock.bn", "blocks.LinearBlock.relu", "blocks.LinearBlock.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "linear", "(", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "if", "self", ".", "bn", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "bn", "(", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", ",", "1", ",", "1", ")", ")", "\n", "", "if", "self", ".", "relu", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "", "return", "x", ".", "reshape", "(", "x", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.blocks.conv_block": [[4, 21], ["layers.append", "torch.nn.Sequential", "isinstance", "layers.append", "torch.nn.Conv2d", "layers.append", "layers.append", "torch.nn.ReflectionPad2d", "torch.nn.BatchNorm2d", "torch.nn.ReLU"], "function", ["None"], ["def", "conv_block", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "dilation", "=", "1", ",", "bias", "=", "True", ",", "\n", "batch_norm", "=", "True", ",", "relu", "=", "True", ",", "padding_mode", "=", "'zeros'", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "assert", "padding_mode", "==", "'zeros'", "or", "padding_mode", "==", "'replicate'", "\n", "\n", "if", "padding_mode", "==", "'replicate'", "and", "padding", ">", "0", ":", "\n", "        ", "assert", "isinstance", "(", "padding", ",", "int", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReflectionPad2d", "(", "padding", ")", ")", "\n", "padding", "=", "0", "\n", "\n", "", "layers", ".", "append", "(", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "bias", "=", "bias", ")", ")", "\n", "if", "batch_norm", ":", "\n", "        ", "layers", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "out_planes", ")", ")", "\n", "", "if", "relu", ":", "\n", "        ", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.InterpCat.forward": [[16, 26], ["isinstance", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "list", "list.values", "transform.interpolate"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate"], ["def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "isinstance", "(", "input", ",", "(", "dict", ",", "OrderedDict", ")", ")", ":", "\n", "            ", "input", "=", "list", "(", "input", ".", "values", "(", ")", ")", "\n", "\n", "", "output_shape", "=", "None", "\n", "for", "x", "in", "input", ":", "\n", "            ", "if", "output_shape", "is", "None", "or", "output_shape", "[", "0", "]", ">", "x", ".", "shape", "[", "-", "2", "]", ":", "\n", "                ", "output_shape", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "", "", "return", "torch", ".", "cat", "(", "[", "interpolate", "(", "x", ",", "output_shape", ")", "for", "x", "in", "input", "]", ",", "dim", "=", "-", "3", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate": [[7, 11], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "sz.tolist", "torch.interpolate"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate"], ["def", "interpolate", "(", "x", ",", "sz", ")", ":", "\n", "    ", "\"\"\"Interpolate 4D tensor x to size sz.\"\"\"", "\n", "sz", "=", "sz", ".", "tolist", "(", ")", "if", "torch", ".", "is_tensor", "(", "sz", ")", "else", "sz", "\n", "return", "F", ".", "interpolate", "(", "x", ",", "sz", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", "if", "x", ".", "shape", "[", "-", "2", ":", "]", "!=", "sz", "else", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter": [[5, 58], ["torch.conv2d", "torch.cat.view", "filter.dim", "filter._apply_filter_ksz1", "feat.reshape", "feat.dim", "torch.conv2d", "torch.cat.view", "dilation_factors.items", "torch.cat", "torch.cat", "feat.reshape", "filter.view", "filter[].contiguous", "torch.conv2d", "scores_d.view.view", "scores_all.append", "feat.reshape", "filter[].contiguous.view"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter._apply_filter_ksz1", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["def", "apply_filter", "(", "feat", ",", "filter", ",", "dilation_factors", "=", "None", ")", ":", "\n", "    ", "\"\"\"Applies the filter on the input features (feat). The number of groups is automatically calculated.\n    args:\n        feat: These are the input features. Must have dimensions (images_in_sequence, sequences, feat_dim, H, W)\n        filter: The filter to apply. Must have dimensions (sequences, feat_dim, fH, fW) or (sequences, filters, feat_dim/groups, fH, fW)\n    output:\n        scores: Output of filtering. Dimensions (images_in_sequence, sequences, yH, yW) or (images_in_sequence, sequences, filters, yH, yW)\n    \"\"\"", "\n", "\n", "multiple_filters", "=", "(", "filter", ".", "dim", "(", ")", "==", "5", ")", "\n", "\n", "padding", "=", "(", "filter", ".", "shape", "[", "-", "2", "]", "//", "2", ",", "filter", ".", "shape", "[", "-", "1", "]", "//", "2", ")", "\n", "\n", "num_images", "=", "feat", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "if", "feat", ".", "dim", "(", ")", "==", "5", "else", "1", "\n", "num_filters", "=", "filter", ".", "shape", "[", "1", "]", "if", "multiple_filters", "else", "1", "\n", "num_channels", "=", "feat", ".", "shape", "[", "-", "3", "]", "\n", "groups", "=", "num_channels", "//", "filter", ".", "shape", "[", "-", "3", "]", "\n", "\n", "assert", "num_filters", "%", "groups", "==", "0", "and", "num_channels", "%", "groups", "==", "0", "\n", "\n", "if", "filter", ".", "shape", "[", "-", "2", "]", "==", "1", "and", "filter", ".", "shape", "[", "-", "1", "]", "==", "1", "and", "groups", "==", "1", ":", "\n", "        ", "return", "_apply_filter_ksz1", "(", "feat", ",", "filter", ")", "\n", "\n", "", "if", "multiple_filters", ":", "\n", "        ", "if", "dilation_factors", "is", "None", ":", "\n", "            ", "scores", "=", "F", ".", "conv2d", "(", "feat", ".", "reshape", "(", "num_images", ",", "-", "1", ",", "feat", ".", "shape", "[", "-", "2", "]", ",", "feat", ".", "shape", "[", "-", "1", "]", ")", ",", "filter", ".", "view", "(", "-", "1", ",", "*", "filter", ".", "shape", "[", "-", "3", ":", "]", ")", ",", "\n", "padding", "=", "padding", ",", "groups", "=", "num_sequences", "*", "groups", ")", "\n", "\n", "return", "scores", ".", "view", "(", "num_images", ",", "num_sequences", ",", "-", "1", ",", "scores", ".", "shape", "[", "-", "2", "]", ",", "scores", ".", "shape", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "scores_all", "=", "[", "]", "\n", "start_id", "=", "0", "\n", "\n", "for", "d_factor", ",", "num_filters_with_d", "in", "dilation_factors", ".", "items", "(", ")", ":", "\n", "                ", "f_d", "=", "filter", "[", ":", ",", "start_id", ":", "start_id", "+", "num_filters_with_d", ",", "...", "]", ".", "contiguous", "(", ")", "\n", "\n", "padding_d", "=", "[", "p", "+", "d_factor", "-", "1", "for", "p", "in", "padding", "]", "\n", "scores_d", "=", "F", ".", "conv2d", "(", "feat", ".", "reshape", "(", "num_images", ",", "-", "1", ",", "feat", ".", "shape", "[", "-", "2", "]", ",", "feat", ".", "shape", "[", "-", "1", "]", ")", ",", "\n", "f_d", ".", "view", "(", "-", "1", ",", "*", "f_d", ".", "shape", "[", "-", "3", ":", "]", ")", ",", "\n", "padding", "=", "padding_d", ",", "groups", "=", "num_sequences", "*", "groups", ",", "\n", "dilation", "=", "d_factor", ")", "\n", "scores_d", "=", "scores_d", ".", "view", "(", "num_images", ",", "num_sequences", ",", "-", "1", ",", "scores_d", ".", "shape", "[", "-", "2", "]", ",", "scores_d", ".", "shape", "[", "-", "1", "]", ")", "\n", "scores_all", ".", "append", "(", "scores_d", ")", "\n", "start_id", "+=", "num_filters_with_d", "\n", "\n", "", "scores", "=", "torch", ".", "cat", "(", "scores_all", ",", "dim", "=", "2", ")", "\n", "return", "scores", "\n", "\n", "", "", "scores", "=", "F", ".", "conv2d", "(", "feat", ".", "reshape", "(", "num_images", ",", "-", "1", ",", "feat", ".", "shape", "[", "-", "2", "]", ",", "feat", ".", "shape", "[", "-", "1", "]", ")", ",", "filter", ",", "\n", "padding", "=", "padding", ",", "groups", "=", "num_sequences", ")", "\n", "\n", "return", "scores", ".", "view", "(", "num_images", ",", "num_sequences", ",", "scores", ".", "shape", "[", "-", "2", "]", ",", "scores", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter._apply_filter_ksz1": [[60, 88], ["torch.matmul", "torch.matmul", "torch.matmul.reshape", "filter.dim", "filter.reshape", "feat.reshape", "torch.matmul.reshape", "feat.dim"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "_apply_filter_ksz1", "(", "feat", ",", "filter", ")", ":", "\n", "    ", "\"\"\"Applies the filter on the input features (feat). The number of groups is automatically calculated.\n    args:\n        feat: These are the input features. Must have dimensions (images_in_sequence, sequences, feat_dim, H, W)\n        filter: The filter to apply. Must have dimensions (sequences, feat_dim, fH, fW) or (sequences, filters, feat_dim/groups, fH, fW)\n    output:\n        scores: Output of filtering. Dimensions (images_in_sequence, sequences, yH, yW) or (images_in_sequence, sequences, filters, yH, yW)\n    \"\"\"", "\n", "\n", "multiple_filters", "=", "(", "filter", ".", "dim", "(", ")", "==", "5", ")", "\n", "\n", "assert", "filter", ".", "shape", "[", "-", "2", "]", "==", "1", "and", "filter", ".", "shape", "[", "-", "1", "]", "==", "1", "\n", "\n", "num_images", "=", "feat", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "if", "feat", ".", "dim", "(", ")", "==", "5", "else", "1", "\n", "num_channels", "=", "feat", ".", "shape", "[", "-", "3", "]", "\n", "groups", "=", "num_channels", "//", "filter", ".", "shape", "[", "-", "3", "]", "\n", "\n", "assert", "groups", "==", "1", "\n", "\n", "# scores = torch.einsum('nc, incs->nis', filter.reshape(filter.shape[:-2]), feat.reshape(*feat.shape[:-2], -1))", "\n", "scores", "=", "torch", ".", "matmul", "(", "filter", ".", "reshape", "(", "num_sequences", ",", "1", ",", "1", ",", "num_channels", ")", ",", "\n", "feat", ".", "reshape", "(", "num_sequences", ",", "num_images", ",", "num_channels", ",", "-", "1", ")", ")", "\n", "\n", "if", "multiple_filters", ":", "\n", "        ", "return", "scores", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "-", "1", ",", "feat", ".", "shape", "[", "-", "2", "]", ",", "feat", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "", "return", "scores", ".", "reshape", "(", "num_images", ",", "num_sequences", ",", "feat", ".", "shape", "[", "-", "2", "]", ",", "feat", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_feat_transpose": [[90, 107], ["filter._apply_feat_transpose_v2", "NotImplementedError", "filter._apply_feat_transpose_v3", "input.dim"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.filter._apply_feat_transpose_v2", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter._apply_feat_transpose_v3", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "apply_feat_transpose", "(", "feat", ",", "input", ",", "filter_ksz", ",", "training", "=", "True", ",", "groups", "=", "1", ")", ":", "\n", "    ", "\"\"\"Applies the transposed operation off apply_filter w.r.t. filter itself. Can be used to compute the filter gradient.\n    args:\n        feat: These are the input features. Must have dimensions (images_in_sequence, sequences, feat_dim, H, W)\n        input: Input activation (e.g. residuals). Must have dimensions (images_in_sequence, sequences, yH, yW) or\n                (images_in_sequence, sequences, filters, yH, yW)\n        training: Choose the faster implementation whether training or not.\n    output:\n        Output of transposed operation. Dimensions (sequences, feat_dim, fH, fW)\n    \"\"\"", "\n", "\n", "if", "groups", "!=", "1", ":", "\n", "        ", "raise", "NotImplementedError", "(", "'Not implemented other values of group.'", ")", "\n", "\n", "", "if", "training", "or", "input", ".", "dim", "(", ")", "==", "5", ":", "\n", "        ", "return", "_apply_feat_transpose_v3", "(", "feat", ",", "input", ",", "filter_ksz", ")", "\n", "", "return", "_apply_feat_transpose_v2", "(", "feat", ",", "input", ",", "filter_ksz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter._apply_feat_transpose_v1": [[109, 126], ["isinstance", "torch.conv_transpose2d", "F.conv_transpose2d.view().sum", "input.flip().view", "feat.reshape", "feat.dim", "zip", "F.conv_transpose2d.view", "input.flip"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "_apply_feat_transpose_v1", "(", "feat", ",", "input", ",", "filter_ksz", ")", ":", "\n", "    ", "\"\"\"This one is slow as hell!!!!\"\"\"", "\n", "\n", "num_images", "=", "feat", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "if", "feat", ".", "dim", "(", ")", "==", "5", "else", "1", "\n", "feat_sz", "=", "(", "feat", ".", "shape", "[", "-", "2", "]", ",", "feat", ".", "shape", "[", "-", "1", "]", ")", "\n", "if", "isinstance", "(", "filter_ksz", ",", "int", ")", ":", "\n", "        ", "filter_ksz", "=", "(", "filter_ksz", ",", "filter_ksz", ")", "\n", "\n", "# trans_pad = sz + padding - filter_ksz", "\n", "", "trans_pad", "=", "[", "sz", "+", "ksz", "//", "2", "-", "ksz", "for", "sz", ",", "ksz", "in", "zip", "(", "feat_sz", ",", "filter_ksz", ")", "]", "\n", "\n", "filter_grad", "=", "F", ".", "conv_transpose2d", "(", "input", ".", "flip", "(", "(", "2", ",", "3", ")", ")", ".", "view", "(", "1", ",", "-", "1", ",", "input", ".", "shape", "[", "-", "2", "]", ",", "input", ".", "shape", "[", "-", "1", "]", ")", ",", "\n", "feat", ".", "reshape", "(", "-", "1", ",", "feat", ".", "shape", "[", "-", "3", "]", ",", "feat", ".", "shape", "[", "-", "2", "]", ",", "feat", ".", "shape", "[", "-", "1", "]", ")", ",", "\n", "padding", "=", "trans_pad", ",", "groups", "=", "num_images", "*", "num_sequences", ")", "\n", "\n", "return", "filter_grad", ".", "view", "(", "num_images", ",", "num_sequences", ",", "-", "1", ",", "filter_grad", ".", "shape", "[", "-", "2", "]", ",", "filter_grad", ".", "shape", "[", "-", "1", "]", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter._apply_feat_transpose_v2": [[128, 155], ["isinstance", "torch.conv2d", "F.conv2d.view().sum().flip", "input.dim", "torch.conv2d", "F.conv2d.view().sum().flip().permute", "input.reshape", "feat.reshape", "feat.dim", "input.reshape().permute", "feat.reshape", "F.conv2d.view().flip().permute", "F.conv2d.view().sum", "F.conv2d.view().sum().flip", "input.reshape", "F.conv2d.view().flip", "F.conv2d.view", "F.conv2d.view().sum", "F.conv2d.view", "F.conv2d.view"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "_apply_feat_transpose_v2", "(", "feat", ",", "input", ",", "filter_ksz", ")", ":", "\n", "    ", "\"\"\"Fast forward and slow backward\"\"\"", "\n", "\n", "multiple_filters", "=", "(", "input", ".", "dim", "(", ")", "==", "5", ")", "\n", "\n", "num_images", "=", "feat", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "if", "feat", ".", "dim", "(", ")", "==", "5", "else", "1", "\n", "num_filters", "=", "input", ".", "shape", "[", "2", "]", "if", "multiple_filters", "else", "1", "\n", "if", "isinstance", "(", "filter_ksz", ",", "int", ")", ":", "\n", "        ", "filter_ksz", "=", "(", "filter_ksz", ",", "filter_ksz", ")", "\n", "\n", "", "trans_pad", "=", "[", "(", "ksz", "-", "1", ")", "//", "2", "for", "ksz", "in", "filter_ksz", "]", "\n", "\n", "if", "multiple_filters", ":", "\n", "        ", "filter_grad", "=", "F", ".", "conv2d", "(", "input", ".", "reshape", "(", "-", "1", ",", "num_filters", ",", "input", ".", "shape", "[", "-", "2", "]", ",", "input", ".", "shape", "[", "-", "1", "]", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ",", "\n", "feat", ".", "reshape", "(", "-", "1", ",", "1", ",", "feat", ".", "shape", "[", "-", "2", "]", ",", "feat", ".", "shape", "[", "-", "1", "]", ")", ",", "\n", "padding", "=", "trans_pad", ",", "groups", "=", "num_images", "*", "num_sequences", ")", "\n", "\n", "if", "num_images", "==", "1", ":", "\n", "            ", "return", "filter_grad", ".", "view", "(", "num_filters", ",", "num_sequences", ",", "-", "1", ",", "filter_grad", ".", "shape", "[", "-", "2", "]", ",", "filter_grad", ".", "shape", "[", "-", "1", "]", ")", ".", "flip", "(", "(", "3", ",", "4", ")", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ",", "4", ")", "\n", "", "return", "filter_grad", ".", "view", "(", "num_filters", ",", "num_images", ",", "num_sequences", ",", "-", "1", ",", "filter_grad", ".", "shape", "[", "-", "2", "]", ",", "filter_grad", ".", "shape", "[", "-", "1", "]", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "flip", "(", "(", "3", ",", "4", ")", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ",", "4", ")", "\n", "\n", "", "filter_grad", "=", "F", ".", "conv2d", "(", "input", ".", "reshape", "(", "1", ",", "-", "1", ",", "input", ".", "shape", "[", "-", "2", "]", ",", "input", ".", "shape", "[", "-", "1", "]", ")", ",", "\n", "feat", ".", "reshape", "(", "-", "1", ",", "1", ",", "feat", ".", "shape", "[", "-", "2", "]", ",", "feat", ".", "shape", "[", "-", "1", "]", ")", ",", "\n", "padding", "=", "trans_pad", ",", "groups", "=", "num_images", "*", "num_sequences", ")", "\n", "\n", "return", "filter_grad", ".", "view", "(", "num_images", ",", "num_sequences", ",", "-", "1", ",", "filter_grad", ".", "shape", "[", "-", "2", "]", ",", "filter_grad", ".", "shape", "[", "-", "1", "]", ")", ".", "sum", "(", "dim", "=", "0", ")", ".", "flip", "(", "(", "2", ",", "3", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter._apply_feat_transpose_v3": [[157, 182], ["isinstance", "torch.conv2d", "F.conv2d.view().sum().permute", "input.dim", "feat.reshape().permute", "input.reshape", "F.conv2d.view().sum().permute", "F.conv2d.permute", "feat.dim", "F.conv2d.view().permute", "F.conv2d.view().sum", "feat.reshape", "F.conv2d.view().sum", "F.conv2d.view", "F.conv2d.view", "F.conv2d.view"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "_apply_feat_transpose_v3", "(", "feat", ",", "input", ",", "filter_ksz", ")", ":", "\n", "    ", "\"\"\"Slow forward fast backward\"\"\"", "\n", "\n", "multiple_filters", "=", "(", "input", ".", "dim", "(", ")", "==", "5", ")", "\n", "\n", "num_images", "=", "feat", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "if", "feat", ".", "dim", "(", ")", "==", "5", "else", "1", "\n", "num_filters", "=", "input", ".", "shape", "[", "2", "]", "if", "multiple_filters", "else", "1", "\n", "if", "isinstance", "(", "filter_ksz", ",", "int", ")", ":", "\n", "        ", "filter_ksz", "=", "(", "filter_ksz", ",", "filter_ksz", ")", "\n", "\n", "", "trans_pad", "=", "[", "ksz", "//", "2", "for", "ksz", "in", "filter_ksz", "]", "\n", "\n", "filter_grad", "=", "F", ".", "conv2d", "(", "feat", ".", "reshape", "(", "-", "1", ",", "feat", ".", "shape", "[", "-", "3", "]", ",", "feat", ".", "shape", "[", "-", "2", "]", ",", "feat", ".", "shape", "[", "-", "1", "]", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ",", "\n", "input", ".", "reshape", "(", "-", "1", ",", "1", ",", "input", ".", "shape", "[", "-", "2", "]", ",", "input", ".", "shape", "[", "-", "1", "]", ")", ",", "\n", "padding", "=", "trans_pad", ",", "groups", "=", "num_images", "*", "num_sequences", ")", "\n", "\n", "if", "multiple_filters", ":", "\n", "        ", "if", "num_images", "==", "1", ":", "\n", "            ", "return", "filter_grad", ".", "view", "(", "-", "1", ",", "num_sequences", ",", "num_filters", ",", "filter_grad", ".", "shape", "[", "-", "2", "]", ",", "filter_grad", ".", "shape", "[", "-", "1", "]", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ",", "4", ")", "\n", "", "return", "filter_grad", ".", "view", "(", "-", "1", ",", "num_images", ",", "num_sequences", ",", "num_filters", ",", "filter_grad", ".", "shape", "[", "-", "2", "]", ",", "filter_grad", ".", "shape", "[", "-", "1", "]", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ",", "4", ")", "\n", "\n", "", "if", "num_images", "==", "1", ":", "\n", "        ", "return", "filter_grad", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "", "return", "filter_grad", ".", "view", "(", "-", "1", ",", "num_images", ",", "num_sequences", ",", "filter_grad", ".", "shape", "[", "-", "2", "]", ",", "filter_grad", ".", "shape", "[", "-", "1", "]", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter._apply_feat_transpose_v4": [[184, 199], ["isinstance", "torch.conv2d", "F.conv2d.permute", "feat.permute().reshape", "input.permute", "feat.dim", "feat.permute"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "_apply_feat_transpose_v4", "(", "feat", ",", "input", ",", "filter_ksz", ")", ":", "\n", "    ", "\"\"\"Slow forward fast backward\"\"\"", "\n", "\n", "num_images", "=", "feat", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "feat", ".", "shape", "[", "1", "]", "if", "feat", ".", "dim", "(", ")", "==", "5", "else", "1", "\n", "if", "isinstance", "(", "filter_ksz", ",", "int", ")", ":", "\n", "        ", "filter_ksz", "=", "(", "filter_ksz", ",", "filter_ksz", ")", "\n", "\n", "", "trans_pad", "=", "[", "ksz", "//", "2", "for", "ksz", "in", "filter_ksz", "]", "\n", "\n", "filter_grad", "=", "F", ".", "conv2d", "(", "feat", ".", "permute", "(", "2", ",", "1", ",", "0", ",", "3", ",", "4", ")", ".", "reshape", "(", "feat", ".", "shape", "[", "-", "3", "]", ",", "-", "1", ",", "feat", ".", "shape", "[", "-", "2", "]", ",", "feat", ".", "shape", "[", "-", "1", "]", ")", ",", "\n", "input", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ",", "\n", "padding", "=", "trans_pad", ",", "groups", "=", "num_sequences", ")", "\n", "\n", "return", "filter_grad", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.filter_gradient": [[202, 217], ["filter.apply_filter", "filter.apply_feat_transpose"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter", "home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_feat_transpose"], ["", "def", "filter_gradient", "(", "feat", ",", "filter", ",", "label", "=", "None", ",", "training", "=", "True", ")", ":", "\n", "    ", "\"\"\"Computes gradient of the filter when applied on the input features and ground truth label.\n    args:\n        feat: These are the input features. Must have dimensions (images_in_sequence, sequences, feat_dim, H, W)\n        filter: The filter to apply. Must have dimensions (sequences, feat_dim, fH, fW)\n        label: Ground truth label in the L2 loss. Dimensions (images_in_sequence, sequences, yH, yW)\n    output:\n        filter_gradient: Dimensions same as input filter (sequences, feat_dim, fH, fW)\n    \"\"\"", "\n", "\n", "residuals", "=", "apply_filter", "(", "feat", ",", "filter", ")", "\n", "if", "label", "is", "not", "None", ":", "\n", "        ", "residuals", "=", "residuals", "-", "label", "\n", "", "filter_ksz", "=", "(", "filter", ".", "shape", "[", "-", "2", "]", ",", "filter", ".", "shape", "[", "-", "1", "]", ")", "\n", "return", "apply_feat_transpose", "(", "feat", ",", "residuals", ",", "filter_ksz", ",", "training", "=", "training", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.ToMPnet.__init__": [[20, 27], ["torch.Module.__init__", "sorted", "isinstance", "list", "set"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["def", "__init__", "(", "self", ",", "feature_extractor", ",", "head", ",", "head_layer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "feature_extractor", "=", "feature_extractor", "\n", "self", ".", "head", "=", "head", "\n", "self", ".", "head_layer", "=", "[", "head_layer", "]", "if", "isinstance", "(", "head_layer", ",", "str", ")", "else", "head_layer", "\n", "self", ".", "output_layers", "=", "sorted", "(", "list", "(", "set", "(", "self", ".", "head_layer", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.ToMPnet.forward": [[29, 55], ["tompnet.ToMPnet.extract_backbone_features", "tompnet.ToMPnet.extract_backbone_features", "tompnet.ToMPnet.get_backbone_head_feat", "tompnet.ToMPnet.get_backbone_head_feat", "tompnet.ToMPnet.head", "train_imgs.reshape", "test_imgs.reshape", "train_imgs.dim", "test_imgs.dim"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.ToMPnet.get_backbone_head_feat", "home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.ToMPnet.get_backbone_head_feat", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "forward", "(", "self", ",", "train_imgs", ",", "test_imgs", ",", "train_bb", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Runs the ToMP network the way it is applied during training.\n        The forward function is ONLY used for training. Call the individual functions during tracking.\n        args:\n            train_imgs:  Train image samples (images, sequences, 3, H, W).\n            test_imgs:  Test image samples (images, sequences, 3, H, W).\n            trian_bb:  Target boxes (x,y,w,h) for the train images. Dims (images, sequences, 4).\n            *args, **kwargs:  These are passed to the classifier module.\n        returns:\n            test_scores:  Classification scores on the test samples.\n            bbox_preds:  Predicted bounding box offsets.\"\"\"", "\n", "\n", "assert", "train_imgs", ".", "dim", "(", ")", "==", "5", "and", "test_imgs", ".", "dim", "(", ")", "==", "5", ",", "'Expect 5 dimensional inputs'", "\n", "\n", "# Extract backbone features", "\n", "train_feat", "=", "self", ".", "extract_backbone_features", "(", "train_imgs", ".", "reshape", "(", "-", "1", ",", "*", "train_imgs", ".", "shape", "[", "-", "3", ":", "]", ")", ")", "\n", "test_feat", "=", "self", ".", "extract_backbone_features", "(", "test_imgs", ".", "reshape", "(", "-", "1", ",", "*", "test_imgs", ".", "shape", "[", "-", "3", ":", "]", ")", ")", "\n", "\n", "# Classification features", "\n", "train_feat_head", "=", "self", ".", "get_backbone_head_feat", "(", "train_feat", ")", "\n", "test_feat_head", "=", "self", ".", "get_backbone_head_feat", "(", "test_feat", ")", "\n", "\n", "# Run head module", "\n", "test_scores", ",", "bbox_preds", "=", "self", ".", "head", "(", "train_feat_head", ",", "test_feat_head", ",", "train_bb", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "return", "test_scores", ",", "bbox_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.ToMPnet.get_backbone_head_feat": [[56, 61], ["collections.OrderedDict", "len"], "methods", ["None"], ["", "def", "get_backbone_head_feat", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "feat", "=", "OrderedDict", "(", "{", "l", ":", "backbone_feat", "[", "l", "]", "for", "l", "in", "self", ".", "head_layer", "}", ")", "\n", "if", "len", "(", "self", ".", "head_layer", ")", "==", "1", ":", "\n", "            ", "return", "feat", "[", "self", ".", "head_layer", "[", "0", "]", "]", "\n", "", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.ToMPnet.extract_head_feat": [[62, 64], ["tompnet.ToMPnet.head.extract_head_feat", "tompnet.ToMPnet.get_backbone_clf_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.extract_head_feat", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.get_backbone_clf_feat"], ["", "def", "extract_head_feat", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "return", "self", ".", "head", ".", "extract_head_feat", "(", "self", ".", "get_backbone_clf_feat", "(", "backbone_feat", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.ToMPnet.extract_backbone_features": [[65, 69], ["tompnet.ToMPnet.feature_extractor"], "methods", ["None"], ["", "def", "extract_backbone_features", "(", "self", ",", "im", ",", "layers", "=", "None", ")", ":", "\n", "        ", "if", "layers", "is", "None", ":", "\n", "            ", "layers", "=", "self", ".", "output_layers", "\n", "", "return", "self", ".", "feature_extractor", "(", "im", ",", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.ToMPnet.extract_features": [[70, 79], ["sorted", "tompnet.ToMPnet.feature_extractor", "tompnet.ToMPnet.extract_head_feat", "collections.OrderedDict", "tompnet.ToMPnet.feature_extractor", "list", "set"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.extract_head_feat", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "extract_features", "(", "self", ",", "im", ",", "layers", "=", "None", ")", ":", "\n", "        ", "if", "layers", "is", "None", ":", "\n", "            ", "layers", "=", "[", "'head'", "]", "\n", "", "if", "'head'", "not", "in", "layers", ":", "\n", "            ", "return", "self", ".", "feature_extractor", "(", "im", ",", "layers", ")", "\n", "", "backbone_layers", "=", "sorted", "(", "list", "(", "set", "(", "[", "l", "for", "l", "in", "layers", "+", "self", ".", "head_layer", "if", "l", "!=", "'head'", "]", ")", ")", ")", "\n", "all_feat", "=", "self", ".", "feature_extractor", "(", "im", ",", "backbone_layers", ")", "\n", "all_feat", "[", "'classification'", "]", "=", "self", ".", "extract_head_feat", "(", "all_feat", ")", "\n", "return", "OrderedDict", "(", "{", "l", ":", "all_feat", "[", "l", "]", "for", "l", "in", "layers", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.tompnet50": [[81, 121], ["ltr.resnet50", "math.sqrt", "ltr.residual_bottleneck", "ltr.Transformer", "ltr.FilterPredictor", "ltr.LinearFilterClassifier", "ltr.DenseBoxRegressor", "ltr.Head", "tompnet.ToMPnet"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet50", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_bottleneck"], ["", "", "@", "model_constructor", "\n", "def", "tompnet50", "(", "filter_size", "=", "4", ",", "head_layer", "=", "'layer3'", ",", "backbone_pretrained", "=", "True", ",", "head_feat_blocks", "=", "0", ",", "head_feat_norm", "=", "True", ",", "\n", "final_conv", "=", "True", ",", "out_feature_dim", "=", "512", ",", "frozen_backbone_layers", "=", "(", ")", ",", "nhead", "=", "8", ",", "num_encoder_layers", "=", "6", ",", "\n", "num_decoder_layers", "=", "6", ",", "dim_feedforward", "=", "2048", ",", "feature_sz", "=", "18", ",", "use_test_frame_encoding", "=", "True", ")", ":", "\n", "# Backbone", "\n", "    ", "backbone_net", "=", "backbones", ".", "resnet50", "(", "pretrained", "=", "backbone_pretrained", ",", "frozen_layers", "=", "frozen_backbone_layers", ")", "\n", "\n", "# Feature normalization", "\n", "norm_scale", "=", "math", ".", "sqrt", "(", "1.0", "/", "(", "out_feature_dim", "*", "filter_size", "*", "filter_size", ")", ")", "\n", "\n", "# Classifier features", "\n", "if", "head_layer", "==", "'layer3'", ":", "\n", "        ", "feature_dim", "=", "256", "\n", "", "elif", "head_layer", "==", "'layer4'", ":", "\n", "        ", "feature_dim", "=", "512", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "\n", "\n", "", "head_feature_extractor", "=", "clf_features", ".", "residual_bottleneck", "(", "feature_dim", "=", "feature_dim", ",", "\n", "num_blocks", "=", "head_feat_blocks", ",", "l2norm", "=", "head_feat_norm", ",", "\n", "final_conv", "=", "final_conv", ",", "norm_scale", "=", "norm_scale", ",", "\n", "out_dim", "=", "out_feature_dim", ")", "\n", "\n", "transformer", "=", "trans", ".", "Transformer", "(", "d_model", "=", "out_feature_dim", ",", "nhead", "=", "nhead", ",", "num_encoder_layers", "=", "num_encoder_layers", ",", "\n", "num_decoder_layers", "=", "num_decoder_layers", ",", "dim_feedforward", "=", "dim_feedforward", ")", "\n", "\n", "\n", "filter_predictor", "=", "fp", ".", "FilterPredictor", "(", "transformer", ",", "feature_sz", "=", "feature_sz", ",", "\n", "use_test_frame_encoding", "=", "use_test_frame_encoding", ")", "\n", "\n", "classifier", "=", "heads", ".", "LinearFilterClassifier", "(", "num_channels", "=", "out_feature_dim", ")", "\n", "\n", "bb_regressor", "=", "heads", ".", "DenseBoxRegressor", "(", "num_channels", "=", "out_feature_dim", ")", "\n", "\n", "head", "=", "heads", ".", "Head", "(", "filter_predictor", "=", "filter_predictor", ",", "feature_extractor", "=", "head_feature_extractor", ",", "\n", "classifier", "=", "classifier", ",", "bb_regressor", "=", "bb_regressor", ")", "\n", "\n", "# ToMP network", "\n", "net", "=", "ToMPnet", "(", "feature_extractor", "=", "backbone_net", ",", "head", "=", "head", ",", "head_layer", "=", "head_layer", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.tompnet.tompnet101": [[123, 163], ["ltr.resnet101", "math.sqrt", "ltr.residual_bottleneck", "ltr.Transformer", "ltr.FilterPredictor", "ltr.LinearFilterClassifier", "ltr.DenseBoxRegressor", "ltr.Head", "tompnet.ToMPnet"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet101", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_bottleneck"], ["", "@", "model_constructor", "\n", "def", "tompnet101", "(", "filter_size", "=", "1", ",", "head_layer", "=", "'layer3'", ",", "backbone_pretrained", "=", "True", ",", "head_feat_blocks", "=", "0", ",", "head_feat_norm", "=", "True", ",", "\n", "final_conv", "=", "True", ",", "out_feature_dim", "=", "512", ",", "frozen_backbone_layers", "=", "(", ")", ",", "nhead", "=", "8", ",", "num_encoder_layers", "=", "6", ",", "\n", "num_decoder_layers", "=", "6", ",", "dim_feedforward", "=", "2048", ",", "feature_sz", "=", "18", ",", "use_test_frame_encoding", "=", "True", ")", ":", "\n", "# Backbone", "\n", "    ", "backbone_net", "=", "backbones", ".", "resnet101", "(", "pretrained", "=", "backbone_pretrained", ",", "frozen_layers", "=", "frozen_backbone_layers", ")", "\n", "\n", "# Feature normalization", "\n", "norm_scale", "=", "math", ".", "sqrt", "(", "1.0", "/", "(", "out_feature_dim", "*", "filter_size", "*", "filter_size", ")", ")", "\n", "\n", "# Classifier features", "\n", "if", "head_layer", "==", "'layer3'", ":", "\n", "        ", "feature_dim", "=", "256", "\n", "", "elif", "head_layer", "==", "'layer4'", ":", "\n", "        ", "feature_dim", "=", "512", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "\n", "\n", "", "head_feature_extractor", "=", "clf_features", ".", "residual_bottleneck", "(", "feature_dim", "=", "feature_dim", ",", "\n", "num_blocks", "=", "head_feat_blocks", ",", "l2norm", "=", "head_feat_norm", ",", "\n", "final_conv", "=", "final_conv", ",", "norm_scale", "=", "norm_scale", ",", "\n", "out_dim", "=", "out_feature_dim", ")", "\n", "\n", "transformer", "=", "trans", ".", "Transformer", "(", "d_model", "=", "out_feature_dim", ",", "nhead", "=", "nhead", ",", "num_encoder_layers", "=", "num_encoder_layers", ",", "\n", "num_decoder_layers", "=", "num_decoder_layers", ",", "dim_feedforward", "=", "dim_feedforward", ")", "\n", "\n", "\n", "filter_predictor", "=", "fp", ".", "FilterPredictor", "(", "transformer", ",", "feature_sz", "=", "feature_sz", ",", "\n", "use_test_frame_encoding", "=", "use_test_frame_encoding", ")", "\n", "\n", "classifier", "=", "heads", ".", "LinearFilterClassifier", "(", "num_channels", "=", "out_feature_dim", ")", "\n", "\n", "bb_regressor", "=", "heads", ".", "DenseBoxRegressor", "(", "num_channels", "=", "out_feature_dim", ")", "\n", "\n", "head", "=", "heads", ".", "Head", "(", "filter_predictor", "=", "filter_predictor", ",", "feature_extractor", "=", "head_feature_extractor", ",", "\n", "classifier", "=", "classifier", ",", "bb_regressor", "=", "bb_regressor", ")", "\n", "\n", "# ToMP network", "\n", "net", "=", "ToMPnet", "(", "feature_extractor", "=", "backbone_net", ",", "head", "=", "head", ",", "head_layer", "=", "head_layer", ")", "\n", "return", "net", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.train": [[18, 29], ["kysnet.KYSNet.backbone_feature_extractor.train", "kysnet.KYSNet.dimp_classifier.train", "kysnet.KYSNet.predictor.train", "kysnet.KYSNet.bb_regressor.train", "kysnet.KYSNet.motion_feat_extractor.train"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train"], ["    ", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "self", ".", "training", "=", "mode", "\n", "\n", "self", ".", "backbone_feature_extractor", ".", "train", "(", "False", ")", "\n", "self", ".", "dimp_classifier", ".", "train", "(", "False", ")", "\n", "self", ".", "predictor", ".", "train", "(", "mode", ")", "\n", "self", ".", "bb_regressor", ".", "train", "(", "mode", ")", "\n", "\n", "if", "self", ".", "motion_feat_extractor", "is", "not", "None", ":", "\n", "            ", "self", ".", "motion_feat_extractor", ".", "train", "(", "mode", ")", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.__init__": [[30, 49], ["torch.Module.__init__", "list", "sorted", "list", "kysnet.KYSNet.backbone_feature_extractor.parameters", "set", "p.requires_grad_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["", "def", "__init__", "(", "self", ",", "backbone_feature_extractor", ",", "dimp_classifier", ",", "predictor", ",", "\n", "bb_regressor", ",", "classification_layer", ",", "bb_regressor_layer", ",", "train_feature_extractor", "=", "True", ",", "\n", "train_iounet", "=", "True", ",", "motion_feat_extractor", "=", "None", ",", "motion_layer", "=", "(", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "not", "train_feature_extractor", "\n", "self", ".", "backbone_feature_extractor", "=", "backbone_feature_extractor", "\n", "self", ".", "dimp_classifier", "=", "dimp_classifier", "\n", "self", ".", "predictor", "=", "predictor", "\n", "self", ".", "bb_regressor", "=", "bb_regressor", "\n", "self", ".", "classification_layer", "=", "classification_layer", "\n", "self", ".", "bb_regressor_layer", "=", "bb_regressor_layer", "\n", "self", ".", "motion_layer", "=", "list", "(", "motion_layer", ")", "\n", "self", ".", "output_layers", "=", "sorted", "(", "list", "(", "set", "(", "[", "self", ".", "classification_layer", "]", "+", "self", ".", "bb_regressor_layer", "+", "self", ".", "motion_layer", ")", ")", ")", "\n", "self", ".", "train_iounet", "=", "train_iounet", "\n", "self", ".", "motion_feat_extractor", "=", "motion_feat_extractor", "\n", "\n", "if", "not", "train_feature_extractor", ":", "\n", "            ", "for", "p", "in", "self", ".", "backbone_feature_extractor", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad_", "(", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.forward": [[50, 53], ["None"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "test_image_cur", ",", "dimp_filters", ",", "test_label_cur", ",", "backbone_feat_prev", ",", "label_prev", ",", "\n", "anno_prev", ",", "dimp_scores_prev", ",", "state_prev", ",", "dimp_jitter_fn", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.train_classifier": [[54, 71], ["kysnet.KYSNet.extract_backbone_features", "train_feat_clf.view.view.view", "kysnet.KYSNet.dimp_classifier.train_classifier", "train_imgs.dim", "train_imgs.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.train_classifier", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "train_classifier", "(", "self", ",", "train_imgs", ",", "train_bb", ")", ":", "\n", "        ", "assert", "train_imgs", ".", "dim", "(", ")", "==", "5", ",", "'Expect 5 dimensions for train'", "\n", "\n", "num_sequences", "=", "train_imgs", ".", "shape", "[", "1", "]", "\n", "num_train_images", "=", "train_imgs", ".", "shape", "[", "0", "]", "\n", "\n", "# Extract backbone features", "\n", "train_feat", "=", "self", ".", "extract_backbone_features", "(", "\n", "train_imgs", ".", "view", "(", "-", "1", ",", "train_imgs", ".", "shape", "[", "-", "3", "]", ",", "train_imgs", ".", "shape", "[", "-", "2", "]", ",", "train_imgs", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "\n", "# Classification features", "\n", "train_feat_clf", "=", "train_feat", "[", "self", ".", "classification_layer", "]", "\n", "train_feat_clf", "=", "train_feat_clf", ".", "view", "(", "num_train_images", ",", "num_sequences", ",", "train_feat_clf", ".", "shape", "[", "-", "3", "]", ",", "\n", "train_feat_clf", ".", "shape", "[", "-", "2", "]", ",", "train_feat_clf", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "filter", ",", "train_losses", "=", "self", ".", "dimp_classifier", ".", "train_classifier", "(", "train_feat_clf", ",", "train_bb", ")", "\n", "return", "filter", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.extract_backbone_features": [[72, 78], ["im.view.view.view", "kysnet.KYSNet.backbone_feature_extractor"], "methods", ["None"], ["", "def", "extract_backbone_features", "(", "self", ",", "im", ",", "layers", "=", "None", ")", ":", "\n", "        ", "im", "=", "im", ".", "view", "(", "-", "1", ",", "*", "im", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "if", "layers", "is", "None", ":", "\n", "            ", "layers", "=", "self", ".", "output_layers", "\n", "\n", "", "return", "self", ".", "backbone_feature_extractor", "(", "im", ",", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.get_backbone_clf_feat": [[79, 83], ["None"], "methods", ["None"], ["", "def", "get_backbone_clf_feat", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "feat", "=", "backbone_feat", "[", "self", ".", "classification_layer", "]", "\n", "\n", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.get_backbone_bbreg_feat": [[84, 86], ["None"], "methods", ["None"], ["", "def", "get_backbone_bbreg_feat", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "return", "[", "backbone_feat", "[", "l", "]", "for", "l", "in", "self", ".", "bb_regressor_layer", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.extract_classification_feat": [[87, 89], ["kysnet.KYSNet.dimp_classifier.extract_classification_feat", "kysnet.KYSNet.get_backbone_clf_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.get_backbone_clf_feat"], ["", "def", "extract_classification_feat", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "return", "self", ".", "dimp_classifier", ".", "extract_classification_feat", "(", "self", ".", "get_backbone_clf_feat", "(", "backbone_feat", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.get_motion_feat": [[90, 96], ["kysnet.KYSNet.motion_feat_extractor", "kysnet.KYSNet.predictor.extract_motion_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.extract_motion_feat"], ["", "def", "get_motion_feat", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "if", "self", ".", "motion_feat_extractor", "is", "not", "None", ":", "\n", "            ", "motion_feat", "=", "self", ".", "motion_feat_extractor", "(", "backbone_feat", ")", "\n", "return", "motion_feat", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "predictor", ".", "extract_motion_feat", "(", "backbone_feat", "[", "self", ".", "classification_layer", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.extract_features": [[97, 111], ["sorted", "kysnet.KYSNet.backbone_feature_extractor", "kysnet.KYSNet.dimp_classifier.extract_classification_feat", "collections.OrderedDict", "kysnet.KYSNet.backbone_feature_extractor", "list", "kysnet.KYSNet.motion_feat_extractor", "kysnet.KYSNet.predictor.extract_motion_feat", "set"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.kys.predictor_wrapper.PredictorWrapper.extract_motion_feat"], ["", "", "def", "extract_features", "(", "self", ",", "im", ",", "layers", ")", ":", "\n", "        ", "if", "'classification'", "not", "in", "layers", ":", "\n", "            ", "return", "self", ".", "backbone_feature_extractor", "(", "im", ",", "layers", ")", "\n", "", "backbone_layers", "=", "sorted", "(", "list", "(", "set", "(", "[", "l", "for", "l", "in", "layers", "+", "[", "self", ".", "classification_layer", "]", "if", "l", "!=", "'classification'", "and", "l", "!=", "'motion'", "]", ")", ")", ")", "\n", "all_feat", "=", "self", ".", "backbone_feature_extractor", "(", "im", ",", "backbone_layers", ")", "\n", "all_feat", "[", "'classification'", "]", "=", "self", ".", "dimp_classifier", ".", "extract_classification_feat", "(", "all_feat", "[", "self", ".", "classification_layer", "]", ")", "\n", "\n", "if", "self", ".", "motion_feat_extractor", "is", "not", "None", ":", "\n", "            ", "motion_feat", "=", "self", ".", "motion_feat_extractor", "(", "all_feat", ")", "\n", "all_feat", "[", "'motion'", "]", "=", "motion_feat", "\n", "", "else", ":", "\n", "            ", "all_feat", "[", "'motion'", "]", "=", "self", ".", "predictor", ".", "extract_motion_feat", "(", "all_feat", "[", "self", ".", "classification_layer", "]", ")", "\n", "\n", "", "return", "OrderedDict", "(", "{", "l", ":", "all_feat", "[", "l", "]", "for", "l", "in", "layers", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.kysnet_res50": [[113, 175], ["float", "ltr.resnet50", "math.sqrt", "ltr.residual_bottleneck", "ltr.FilterInitializerLinear", "ltr.DiMPSteepestDescentGN", "ltr.LinearFilter", "ltr.AtomIoUNet", "ltr.CostVolume", "ltr.ResponsePredictor", "ltr.PredictorWrapper", "kysnet.KYSNet"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet50", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_bottleneck"], ["", "", "@", "model_constructor", "\n", "def", "kysnet_res50", "(", "filter_size", "=", "4", ",", "optim_iter", "=", "3", ",", "appearance_feature_dim", "=", "512", ",", "\n", "optim_init_step", "=", "0.9", ",", "optim_init_reg", "=", "0.1", ",", "classification_layer", "=", "'layer3'", ",", "backbone_pretrained", "=", "True", ",", "\n", "clf_feat_blocks", "=", "0", ",", "clf_feat_norm", "=", "True", ",", "final_conv", "=", "True", ",", "init_filter_norm", "=", "False", ",", "\n", "mask_init_factor", "=", "3.0", ",", "score_act", "=", "'relu'", ",", "target_mask_act", "=", "'sigmoid'", ",", "num_dist_bins", "=", "100", ",", "\n", "bin_displacement", "=", "0.1", ",", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "train_feature_extractor", "=", "True", ",", "train_iounet", "=", "True", ",", "\n", "iou_input_dim", "=", "(", "256", ",", "256", ")", ",", "iou_inter_dim", "=", "(", "256", ",", "256", ")", ",", "\n", "cv_kernel_size", "=", "3", ",", "cv_max_displacement", "=", "9", ",", "cv_stride", "=", "1", ",", "\n", "init_gauss_sigma", "=", "1.0", ",", "\n", "state_dim", "=", "8", ",", "representation_predictor_dims", "=", "(", "64", ",", "32", ")", ",", "gru_ksz", "=", "3", ",", "\n", "conf_measure", "=", "'max'", ",", "dimp_thresh", "=", "None", ")", ":", "\n", "\n", "# ######################## backbone ########################", "\n", "    ", "backbone_net", "=", "backbones", ".", "resnet50", "(", "pretrained", "=", "backbone_pretrained", ")", "\n", "\n", "norm_scale", "=", "math", ".", "sqrt", "(", "1.0", "/", "(", "appearance_feature_dim", "*", "filter_size", "*", "filter_size", ")", ")", "\n", "\n", "# ######################## classifier ########################", "\n", "clf_feature_extractor", "=", "clf_features", ".", "residual_bottleneck", "(", "num_blocks", "=", "clf_feat_blocks", ",", "l2norm", "=", "clf_feat_norm", ",", "\n", "final_conv", "=", "final_conv", ",", "norm_scale", "=", "norm_scale", ",", "\n", "out_dim", "=", "appearance_feature_dim", ")", "\n", "\n", "# Initializer for the DiMP classifier", "\n", "initializer", "=", "clf_initializer", ".", "FilterInitializerLinear", "(", "filter_size", "=", "filter_size", ",", "filter_norm", "=", "init_filter_norm", ",", "\n", "feature_dim", "=", "appearance_feature_dim", ")", "\n", "\n", "# Optimizer for the DiMP classifier", "\n", "optimizer", "=", "clf_optimizer", ".", "DiMPSteepestDescentGN", "(", "num_iter", "=", "optim_iter", ",", "feat_stride", "=", "16", ",", "\n", "init_step_length", "=", "optim_init_step", ",", "\n", "init_filter_reg", "=", "optim_init_reg", ",", "init_gauss_sigma", "=", "init_gauss_sigma", ",", "\n", "num_dist_bins", "=", "num_dist_bins", ",", "\n", "bin_displacement", "=", "bin_displacement", ",", "\n", "mask_init_factor", "=", "mask_init_factor", ",", "\n", "score_act", "=", "score_act", ",", "act_param", "=", "None", ",", "mask_act", "=", "target_mask_act", ",", "\n", "detach_length", "=", "detach_length", ")", "\n", "\n", "# The classifier module", "\n", "classifier", "=", "target_clf", ".", "LinearFilter", "(", "filter_size", "=", "filter_size", ",", "filter_initializer", "=", "initializer", ",", "\n", "filter_optimizer", "=", "optimizer", ",", "feature_extractor", "=", "clf_feature_extractor", ")", "\n", "\n", "# Bounding box regressor", "\n", "bb_regressor", "=", "bbmodels", ".", "AtomIoUNet", "(", "input_dim", "=", "(", "4", "*", "128", ",", "4", "*", "256", ")", ",", "pred_input_dim", "=", "iou_input_dim", ",", "\n", "pred_inter_dim", "=", "iou_inter_dim", ")", "\n", "\n", "cost_volume_layer", "=", "cost_volume", ".", "CostVolume", "(", "cv_kernel_size", ",", "cv_max_displacement", ",", "stride", "=", "cv_stride", ",", "\n", "abs_coordinate_output", "=", "True", ")", "\n", "\n", "motion_response_predictor", "=", "resp_pred", ".", "ResponsePredictor", "(", "state_dim", "=", "state_dim", ",", "\n", "representation_predictor_dims", "=", "representation_predictor_dims", ",", "\n", "gru_ksz", "=", "gru_ksz", ",", "\n", "conf_measure", "=", "conf_measure", ",", "\n", "dimp_thresh", "=", "dimp_thresh", ")", "\n", "\n", "response_predictor", "=", "predictor_wrappers", ".", "PredictorWrapper", "(", "cost_volume_layer", ",", "motion_response_predictor", ")", "\n", "\n", "net", "=", "KYSNet", "(", "backbone_feature_extractor", "=", "backbone_net", ",", "dimp_classifier", "=", "classifier", ",", "\n", "predictor", "=", "response_predictor", ",", "\n", "bb_regressor", "=", "bb_regressor", ",", "\n", "classification_layer", "=", "classification_layer", ",", "bb_regressor_layer", "=", "[", "'layer2'", ",", "'layer3'", "]", ",", "\n", "train_feature_extractor", "=", "train_feature_extractor", ",", "\n", "train_iounet", "=", "train_iounet", ")", "\n", "return", "net", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.__init__": [[25, 34], ["torch.Module.__init__", "sorted", "isinstance", "list", "set"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["def", "__init__", "(", "self", ",", "feature_extractor", ",", "classifier", ",", "bb_regressor", ",", "classification_layer", ",", "bb_regressor_layer", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "feature_extractor", "=", "feature_extractor", "\n", "self", ".", "classifier", "=", "classifier", "\n", "self", ".", "bb_regressor", "=", "bb_regressor", "\n", "self", ".", "classification_layer", "=", "[", "classification_layer", "]", "if", "isinstance", "(", "classification_layer", ",", "str", ")", "else", "classification_layer", "\n", "self", ".", "bb_regressor_layer", "=", "bb_regressor_layer", "\n", "self", ".", "output_layers", "=", "sorted", "(", "list", "(", "set", "(", "self", ".", "classification_layer", "+", "self", ".", "bb_regressor_layer", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.forward": [[36, 70], ["dimpnet.DiMPnet.extract_backbone_features", "dimpnet.DiMPnet.extract_backbone_features", "dimpnet.DiMPnet.get_backbone_clf_feat", "dimpnet.DiMPnet.get_backbone_clf_feat", "dimpnet.DiMPnet.classifier", "dimpnet.DiMPnet.get_backbone_bbreg_feat", "dimpnet.DiMPnet.get_backbone_bbreg_feat", "dimpnet.DiMPnet.bb_regressor", "train_imgs.reshape", "test_imgs.reshape", "train_imgs.dim", "test_imgs.dim"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.get_backbone_clf_feat", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.get_backbone_clf_feat", "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.get_backbone_bbreg_feat", "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.get_backbone_bbreg_feat", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "forward", "(", "self", ",", "train_imgs", ",", "test_imgs", ",", "train_bb", ",", "test_proposals", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Runs the DiMP network the way it is applied during training.\n        The forward function is ONLY used for training. Call the individual functions during tracking.\n        args:\n            train_imgs:  Train image samples (images, sequences, 3, H, W).\n            test_imgs:  Test image samples (images, sequences, 3, H, W).\n            trian_bb:  Target boxes (x,y,w,h) for the train images. Dims (images, sequences, 4).\n            test_proposals:  Proposal boxes to use for the IoUNet (bb_regressor) module.\n            *args, **kwargs:  These are passed to the classifier module.\n        returns:\n            test_scores:  Classification scores on the test samples.\n            iou_pred:  Predicted IoU scores for the test_proposals.\"\"\"", "\n", "\n", "assert", "train_imgs", ".", "dim", "(", ")", "==", "5", "and", "test_imgs", ".", "dim", "(", ")", "==", "5", ",", "'Expect 5 dimensional inputs'", "\n", "\n", "# Extract backbone features", "\n", "train_feat", "=", "self", ".", "extract_backbone_features", "(", "train_imgs", ".", "reshape", "(", "-", "1", ",", "*", "train_imgs", ".", "shape", "[", "-", "3", ":", "]", ")", ")", "\n", "test_feat", "=", "self", ".", "extract_backbone_features", "(", "test_imgs", ".", "reshape", "(", "-", "1", ",", "*", "test_imgs", ".", "shape", "[", "-", "3", ":", "]", ")", ")", "\n", "\n", "# Classification features", "\n", "train_feat_clf", "=", "self", ".", "get_backbone_clf_feat", "(", "train_feat", ")", "\n", "test_feat_clf", "=", "self", ".", "get_backbone_clf_feat", "(", "test_feat", ")", "\n", "\n", "# Run classifier module", "\n", "target_scores", "=", "self", ".", "classifier", "(", "train_feat_clf", ",", "test_feat_clf", ",", "train_bb", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# Get bb_regressor features", "\n", "train_feat_iou", "=", "self", ".", "get_backbone_bbreg_feat", "(", "train_feat", ")", "\n", "test_feat_iou", "=", "self", ".", "get_backbone_bbreg_feat", "(", "test_feat", ")", "\n", "\n", "# Run the IoUNet module", "\n", "iou_pred", "=", "self", ".", "bb_regressor", "(", "train_feat_iou", ",", "test_feat_iou", ",", "train_bb", ",", "test_proposals", ")", "\n", "\n", "return", "target_scores", ",", "iou_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.get_backbone_clf_feat": [[71, 76], ["collections.OrderedDict", "len"], "methods", ["None"], ["", "def", "get_backbone_clf_feat", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "feat", "=", "OrderedDict", "(", "{", "l", ":", "backbone_feat", "[", "l", "]", "for", "l", "in", "self", ".", "classification_layer", "}", ")", "\n", "if", "len", "(", "self", ".", "classification_layer", ")", "==", "1", ":", "\n", "            ", "return", "feat", "[", "self", ".", "classification_layer", "[", "0", "]", "]", "\n", "", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.get_backbone_bbreg_feat": [[77, 79], ["None"], "methods", ["None"], ["", "def", "get_backbone_bbreg_feat", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "return", "[", "backbone_feat", "[", "l", "]", "for", "l", "in", "self", ".", "bb_regressor_layer", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat": [[80, 82], ["dimpnet.DiMPnet.classifier.extract_classification_feat", "dimpnet.DiMPnet.get_backbone_clf_feat"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.get_backbone_clf_feat"], ["", "def", "extract_classification_feat", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "return", "self", ".", "classifier", ".", "extract_classification_feat", "(", "self", ".", "get_backbone_clf_feat", "(", "backbone_feat", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_backbone_features": [[83, 87], ["dimpnet.DiMPnet.feature_extractor"], "methods", ["None"], ["", "def", "extract_backbone_features", "(", "self", ",", "im", ",", "layers", "=", "None", ")", ":", "\n", "        ", "if", "layers", "is", "None", ":", "\n", "            ", "layers", "=", "self", ".", "output_layers", "\n", "", "return", "self", ".", "feature_extractor", "(", "im", ",", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_features": [[88, 97], ["sorted", "dimpnet.DiMPnet.feature_extractor", "dimpnet.DiMPnet.extract_classification_feat", "collections.OrderedDict", "dimpnet.DiMPnet.feature_extractor", "list", "set"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.DiMPnet.extract_classification_feat", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "extract_features", "(", "self", ",", "im", ",", "layers", "=", "None", ")", ":", "\n", "        ", "if", "layers", "is", "None", ":", "\n", "            ", "layers", "=", "self", ".", "bb_regressor_layer", "+", "[", "'classification'", "]", "\n", "", "if", "'classification'", "not", "in", "layers", ":", "\n", "            ", "return", "self", ".", "feature_extractor", "(", "im", ",", "layers", ")", "\n", "", "backbone_layers", "=", "sorted", "(", "list", "(", "set", "(", "[", "l", "for", "l", "in", "layers", "+", "self", ".", "classification_layer", "if", "l", "!=", "'classification'", "]", ")", ")", ")", "\n", "all_feat", "=", "self", ".", "feature_extractor", "(", "im", ",", "backbone_layers", ")", "\n", "all_feat", "[", "'classification'", "]", "=", "self", ".", "extract_classification_feat", "(", "all_feat", ")", "\n", "return", "OrderedDict", "(", "{", "l", ":", "all_feat", "[", "l", "]", "for", "l", "in", "layers", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.dimpnet18": [[100, 144], ["float", "ltr.resnet18", "math.sqrt", "ltr.residual_basic_block", "ltr.FilterInitializerLinear", "ltr.DiMPSteepestDescentGN", "ltr.LinearFilter", "ltr.AtomIoUNet", "dimpnet.DiMPnet"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.resnet18", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_basic_block"], ["", "", "@", "model_constructor", "\n", "def", "dimpnet18", "(", "filter_size", "=", "1", ",", "optim_iter", "=", "5", ",", "optim_init_step", "=", "1.0", ",", "optim_init_reg", "=", "0.01", ",", "\n", "classification_layer", "=", "'layer3'", ",", "feat_stride", "=", "16", ",", "backbone_pretrained", "=", "True", ",", "clf_feat_blocks", "=", "1", ",", "\n", "clf_feat_norm", "=", "True", ",", "init_filter_norm", "=", "False", ",", "final_conv", "=", "True", ",", "\n", "out_feature_dim", "=", "256", ",", "init_gauss_sigma", "=", "1.0", ",", "num_dist_bins", "=", "5", ",", "bin_displacement", "=", "1.0", ",", "\n", "mask_init_factor", "=", "4.0", ",", "iou_input_dim", "=", "(", "256", ",", "256", ")", ",", "iou_inter_dim", "=", "(", "256", ",", "256", ")", ",", "\n", "score_act", "=", "'relu'", ",", "act_param", "=", "None", ",", "target_mask_act", "=", "'sigmoid'", ",", "\n", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "frozen_backbone_layers", "=", "(", ")", ")", ":", "\n", "# Backbone", "\n", "    ", "backbone_net", "=", "backbones", ".", "resnet18", "(", "pretrained", "=", "backbone_pretrained", ",", "frozen_layers", "=", "frozen_backbone_layers", ")", "\n", "\n", "# Feature normalization", "\n", "norm_scale", "=", "math", ".", "sqrt", "(", "1.0", "/", "(", "out_feature_dim", "*", "filter_size", "*", "filter_size", ")", ")", "\n", "\n", "# Classifier features", "\n", "clf_feature_extractor", "=", "clf_features", ".", "residual_basic_block", "(", "num_blocks", "=", "clf_feat_blocks", ",", "l2norm", "=", "clf_feat_norm", ",", "\n", "final_conv", "=", "final_conv", ",", "norm_scale", "=", "norm_scale", ",", "\n", "out_dim", "=", "out_feature_dim", ")", "\n", "\n", "# Initializer for the DiMP classifier", "\n", "initializer", "=", "clf_initializer", ".", "FilterInitializerLinear", "(", "filter_size", "=", "filter_size", ",", "filter_norm", "=", "init_filter_norm", ",", "\n", "feature_dim", "=", "out_feature_dim", ")", "\n", "\n", "# Optimizer for the DiMP classifier", "\n", "optimizer", "=", "clf_optimizer", ".", "DiMPSteepestDescentGN", "(", "num_iter", "=", "optim_iter", ",", "feat_stride", "=", "feat_stride", ",", "\n", "init_step_length", "=", "optim_init_step", ",", "\n", "init_filter_reg", "=", "optim_init_reg", ",", "init_gauss_sigma", "=", "init_gauss_sigma", ",", "\n", "num_dist_bins", "=", "num_dist_bins", ",", "\n", "bin_displacement", "=", "bin_displacement", ",", "\n", "mask_init_factor", "=", "mask_init_factor", ",", "\n", "score_act", "=", "score_act", ",", "act_param", "=", "act_param", ",", "mask_act", "=", "target_mask_act", ",", "\n", "detach_length", "=", "detach_length", ")", "\n", "\n", "# The classifier module", "\n", "classifier", "=", "target_clf", ".", "LinearFilter", "(", "filter_size", "=", "filter_size", ",", "filter_initializer", "=", "initializer", ",", "\n", "filter_optimizer", "=", "optimizer", ",", "feature_extractor", "=", "clf_feature_extractor", ")", "\n", "\n", "# Bounding box regressor", "\n", "bb_regressor", "=", "bbmodels", ".", "AtomIoUNet", "(", "pred_input_dim", "=", "iou_input_dim", ",", "pred_inter_dim", "=", "iou_inter_dim", ")", "\n", "\n", "# DiMP network", "\n", "net", "=", "DiMPnet", "(", "feature_extractor", "=", "backbone_net", ",", "classifier", "=", "classifier", ",", "bb_regressor", "=", "bb_regressor", ",", "\n", "classification_layer", "=", "classification_layer", ",", "bb_regressor_layer", "=", "[", "'layer2'", ",", "'layer3'", "]", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.dimpnet50": [[146, 199], ["float", "ltr.resnet50", "math.sqrt", "ltr.residual_bottleneck", "ltr.FilterInitializerLinear", "ltr.DiMPSteepestDescentGN", "ltr.LinearFilter", "ltr.AtomIoUNet", "dimpnet.DiMPnet"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet50", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_bottleneck"], ["", "@", "model_constructor", "\n", "def", "dimpnet50", "(", "filter_size", "=", "1", ",", "optim_iter", "=", "5", ",", "optim_init_step", "=", "1.0", ",", "optim_init_reg", "=", "0.01", ",", "\n", "classification_layer", "=", "'layer3'", ",", "feat_stride", "=", "16", ",", "backbone_pretrained", "=", "True", ",", "clf_feat_blocks", "=", "0", ",", "\n", "clf_feat_norm", "=", "True", ",", "init_filter_norm", "=", "False", ",", "final_conv", "=", "True", ",", "\n", "out_feature_dim", "=", "512", ",", "init_gauss_sigma", "=", "1.0", ",", "num_dist_bins", "=", "5", ",", "bin_displacement", "=", "1.0", ",", "\n", "mask_init_factor", "=", "4.0", ",", "iou_input_dim", "=", "(", "256", ",", "256", ")", ",", "iou_inter_dim", "=", "(", "256", ",", "256", ")", ",", "\n", "score_act", "=", "'relu'", ",", "act_param", "=", "None", ",", "target_mask_act", "=", "'sigmoid'", ",", "\n", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "frozen_backbone_layers", "=", "(", ")", ")", ":", "\n", "\n", "# Backbone", "\n", "    ", "backbone_net", "=", "backbones", ".", "resnet50", "(", "pretrained", "=", "backbone_pretrained", ",", "frozen_layers", "=", "frozen_backbone_layers", ")", "\n", "\n", "# Feature normalization", "\n", "norm_scale", "=", "math", ".", "sqrt", "(", "1.0", "/", "(", "out_feature_dim", "*", "filter_size", "*", "filter_size", ")", ")", "\n", "\n", "# Classifier features", "\n", "if", "classification_layer", "==", "'layer3'", ":", "\n", "        ", "feature_dim", "=", "256", "\n", "", "elif", "classification_layer", "==", "'layer4'", ":", "\n", "        ", "feature_dim", "=", "512", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "\n", "\n", "", "clf_feature_extractor", "=", "clf_features", ".", "residual_bottleneck", "(", "feature_dim", "=", "feature_dim", ",", "\n", "num_blocks", "=", "clf_feat_blocks", ",", "l2norm", "=", "clf_feat_norm", ",", "\n", "final_conv", "=", "final_conv", ",", "norm_scale", "=", "norm_scale", ",", "\n", "out_dim", "=", "out_feature_dim", ")", "\n", "\n", "# Initializer for the DiMP classifier", "\n", "initializer", "=", "clf_initializer", ".", "FilterInitializerLinear", "(", "filter_size", "=", "filter_size", ",", "filter_norm", "=", "init_filter_norm", ",", "\n", "feature_dim", "=", "out_feature_dim", ")", "\n", "\n", "# Optimizer for the DiMP classifier", "\n", "optimizer", "=", "clf_optimizer", ".", "DiMPSteepestDescentGN", "(", "num_iter", "=", "optim_iter", ",", "feat_stride", "=", "feat_stride", ",", "\n", "init_step_length", "=", "optim_init_step", ",", "\n", "init_filter_reg", "=", "optim_init_reg", ",", "init_gauss_sigma", "=", "init_gauss_sigma", ",", "\n", "num_dist_bins", "=", "num_dist_bins", ",", "\n", "bin_displacement", "=", "bin_displacement", ",", "\n", "mask_init_factor", "=", "mask_init_factor", ",", "\n", "score_act", "=", "score_act", ",", "act_param", "=", "act_param", ",", "mask_act", "=", "target_mask_act", ",", "\n", "detach_length", "=", "detach_length", ")", "\n", "\n", "# The classifier module", "\n", "classifier", "=", "target_clf", ".", "LinearFilter", "(", "filter_size", "=", "filter_size", ",", "filter_initializer", "=", "initializer", ",", "\n", "filter_optimizer", "=", "optimizer", ",", "feature_extractor", "=", "clf_feature_extractor", ")", "\n", "\n", "# Bounding box regressor", "\n", "bb_regressor", "=", "bbmodels", ".", "AtomIoUNet", "(", "input_dim", "=", "(", "4", "*", "128", ",", "4", "*", "256", ")", ",", "pred_input_dim", "=", "iou_input_dim", ",", "pred_inter_dim", "=", "iou_inter_dim", ")", "\n", "\n", "# DiMP network", "\n", "net", "=", "DiMPnet", "(", "feature_extractor", "=", "backbone_net", ",", "classifier", "=", "classifier", ",", "bb_regressor", "=", "bb_regressor", ",", "\n", "classification_layer", "=", "classification_layer", ",", "bb_regressor_layer", "=", "[", "'layer2'", ",", "'layer3'", "]", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.dimpnet50_simple": [[201, 253], ["float", "ltr.resnet50", "math.sqrt", "ltr.residual_bottleneck", "ltr.FilterInitializerLinear", "ltr.models.target_classifier.residual_modules.LinearFilterHinge", "ltr.models.meta.steepestdescent.GNSteepestDescent", "ltr.LinearFilter", "ltr.AtomIoUNet", "dimpnet.DiMPnet"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet50", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_bottleneck"], ["", "@", "model_constructor", "\n", "def", "dimpnet50_simple", "(", "filter_size", "=", "1", ",", "optim_iter", "=", "5", ",", "optim_init_reg", "=", "0.01", ",", "\n", "classification_layer", "=", "'layer3'", ",", "feat_stride", "=", "16", ",", "backbone_pretrained", "=", "True", ",", "clf_feat_blocks", "=", "0", ",", "\n", "clf_feat_norm", "=", "True", ",", "init_filter_norm", "=", "False", ",", "final_conv", "=", "True", ",", "\n", "out_feature_dim", "=", "512", ",", "hinge_threshold", "=", "0.05", ",", "iou_input_dim", "=", "(", "256", ",", "256", ")", ",", "iou_inter_dim", "=", "(", "256", ",", "256", ")", ",", "\n", "activation_leak", "=", "0.0", ",", "score_act", "=", "'relu'", ",", "act_param", "=", "None", ",", "\n", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "frozen_backbone_layers", "=", "(", ")", ")", ":", "\n", "\n", "# Backbone", "\n", "    ", "backbone_net", "=", "backbones", ".", "resnet50", "(", "pretrained", "=", "backbone_pretrained", ",", "frozen_layers", "=", "frozen_backbone_layers", ")", "\n", "\n", "# Feature normalization", "\n", "norm_scale", "=", "math", ".", "sqrt", "(", "1.0", "/", "(", "out_feature_dim", "*", "filter_size", "*", "filter_size", ")", ")", "\n", "\n", "# Classifier features", "\n", "if", "classification_layer", "==", "'layer3'", ":", "\n", "        ", "feature_dim", "=", "256", "\n", "", "elif", "classification_layer", "==", "'layer4'", ":", "\n", "        ", "feature_dim", "=", "512", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "\n", "\n", "", "clf_feature_extractor", "=", "clf_features", ".", "residual_bottleneck", "(", "feature_dim", "=", "feature_dim", ",", "\n", "num_blocks", "=", "clf_feat_blocks", ",", "l2norm", "=", "clf_feat_norm", ",", "\n", "final_conv", "=", "final_conv", ",", "norm_scale", "=", "norm_scale", ",", "\n", "out_dim", "=", "out_feature_dim", ")", "\n", "\n", "# Initializer for the DiMP classifier", "\n", "initializer", "=", "clf_initializer", ".", "FilterInitializerLinear", "(", "filter_size", "=", "filter_size", ",", "filter_norm", "=", "init_filter_norm", ",", "\n", "feature_dim", "=", "out_feature_dim", ")", "\n", "\n", "# Residual module that defined the online loss", "\n", "residual_module", "=", "residual_modules", ".", "LinearFilterHinge", "(", "feat_stride", "=", "feat_stride", ",", "init_filter_reg", "=", "optim_init_reg", ",", "\n", "hinge_threshold", "=", "hinge_threshold", ",", "activation_leak", "=", "activation_leak", ",", "\n", "score_act", "=", "score_act", ",", "act_param", "=", "act_param", ")", "\n", "\n", "# Construct generic optimizer module", "\n", "optimizer", "=", "steepestdescent", ".", "GNSteepestDescent", "(", "residual_module", "=", "residual_module", ",", "num_iter", "=", "optim_iter", ",", "detach_length", "=", "detach_length", ",", "\n", "residual_batch_dim", "=", "1", ",", "compute_losses", "=", "True", ")", "\n", "\n", "# The classifier module", "\n", "classifier", "=", "target_clf", ".", "LinearFilter", "(", "filter_size", "=", "filter_size", ",", "filter_initializer", "=", "initializer", ",", "\n", "filter_optimizer", "=", "optimizer", ",", "feature_extractor", "=", "clf_feature_extractor", ")", "\n", "\n", "# Bounding box regressor", "\n", "bb_regressor", "=", "bbmodels", ".", "AtomIoUNet", "(", "input_dim", "=", "(", "4", "*", "128", ",", "4", "*", "256", ")", ",", "pred_input_dim", "=", "iou_input_dim", ",", "\n", "pred_inter_dim", "=", "iou_inter_dim", ")", "\n", "\n", "# DiMP network", "\n", "net", "=", "DiMPnet", "(", "feature_extractor", "=", "backbone_net", ",", "classifier", "=", "classifier", ",", "bb_regressor", "=", "bb_regressor", ",", "\n", "classification_layer", "=", "classification_layer", ",", "bb_regressor_layer", "=", "[", "'layer2'", ",", "'layer3'", "]", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.L2dimpnet18": [[255, 293], ["float", "ltr.resnet18", "math.sqrt", "ltr.residual_basic_block", "ltr.FilterInitializerLinear", "ltr.DiMPL2SteepestDescentGN", "ltr.LinearFilter", "ltr.AtomIoUNet", "dimpnet.DiMPnet"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.resnet18", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_basic_block"], ["", "@", "model_constructor", "\n", "def", "L2dimpnet18", "(", "filter_size", "=", "1", ",", "optim_iter", "=", "5", ",", "optim_init_step", "=", "1.0", ",", "optim_init_reg", "=", "0.01", ",", "\n", "classification_layer", "=", "'layer3'", ",", "feat_stride", "=", "16", ",", "backbone_pretrained", "=", "True", ",", "clf_feat_blocks", "=", "1", ",", "\n", "clf_feat_norm", "=", "True", ",", "init_filter_norm", "=", "False", ",", "final_conv", "=", "True", ",", "\n", "out_feature_dim", "=", "256", ",", "iou_input_dim", "=", "(", "256", ",", "256", ")", ",", "iou_inter_dim", "=", "(", "256", ",", "256", ")", ",", "\n", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "hinge_threshold", "=", "-", "999", ",", "gauss_sigma", "=", "1.0", ",", "alpha_eps", "=", "0", ")", ":", "\n", "# Backbone", "\n", "    ", "backbone_net", "=", "backbones", ".", "resnet18", "(", "pretrained", "=", "backbone_pretrained", ")", "\n", "\n", "# Feature normalization", "\n", "norm_scale", "=", "math", ".", "sqrt", "(", "1.0", "/", "(", "out_feature_dim", "*", "filter_size", "*", "filter_size", ")", ")", "\n", "\n", "# Classifier features", "\n", "clf_feature_extractor", "=", "clf_features", ".", "residual_basic_block", "(", "num_blocks", "=", "clf_feat_blocks", ",", "l2norm", "=", "clf_feat_norm", ",", "\n", "final_conv", "=", "final_conv", ",", "norm_scale", "=", "norm_scale", ",", "\n", "out_dim", "=", "out_feature_dim", ")", "\n", "\n", "# Initializer for the DiMP classifier", "\n", "initializer", "=", "clf_initializer", ".", "FilterInitializerLinear", "(", "filter_size", "=", "filter_size", ",", "filter_norm", "=", "init_filter_norm", ",", "\n", "feature_dim", "=", "out_feature_dim", ")", "\n", "\n", "# Optimizer for the DiMP classifier", "\n", "optimizer", "=", "clf_optimizer", ".", "DiMPL2SteepestDescentGN", "(", "num_iter", "=", "optim_iter", ",", "feat_stride", "=", "feat_stride", ",", "\n", "init_step_length", "=", "optim_init_step", ",", "hinge_threshold", "=", "hinge_threshold", ",", "\n", "init_filter_reg", "=", "optim_init_reg", ",", "gauss_sigma", "=", "gauss_sigma", ",", "\n", "detach_length", "=", "detach_length", ",", "alpha_eps", "=", "alpha_eps", ")", "\n", "\n", "# The classifier module", "\n", "classifier", "=", "target_clf", ".", "LinearFilter", "(", "filter_size", "=", "filter_size", ",", "filter_initializer", "=", "initializer", ",", "\n", "filter_optimizer", "=", "optimizer", ",", "feature_extractor", "=", "clf_feature_extractor", ")", "\n", "\n", "# Bounding box regressor", "\n", "bb_regressor", "=", "bbmodels", ".", "AtomIoUNet", "(", "pred_input_dim", "=", "iou_input_dim", ",", "pred_inter_dim", "=", "iou_inter_dim", ")", "\n", "\n", "# DiMP network", "\n", "net", "=", "DiMPnet", "(", "feature_extractor", "=", "backbone_net", ",", "classifier", "=", "classifier", ",", "bb_regressor", "=", "bb_regressor", ",", "\n", "classification_layer", "=", "classification_layer", ",", "bb_regressor_layer", "=", "[", "'layer2'", ",", "'layer3'", "]", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.klcedimpnet18": [[295, 346], ["float", "ltr.resnet18", "math.sqrt", "ltr.residual_basic_block", "ltr.FilterInitializerLinear", "ltr.PrDiMPSteepestDescentNewton", "ltr.LinearFilter", "ltr.AtomIoUNet", "dimpnet.DiMPnet"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.resnet18", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_basic_block"], ["", "@", "model_constructor", "\n", "def", "klcedimpnet18", "(", "filter_size", "=", "1", ",", "optim_iter", "=", "5", ",", "optim_init_step", "=", "1.0", ",", "optim_init_reg", "=", "0.01", ",", "\n", "classification_layer", "=", "'layer3'", ",", "feat_stride", "=", "16", ",", "backbone_pretrained", "=", "True", ",", "clf_feat_blocks", "=", "1", ",", "\n", "clf_feat_norm", "=", "True", ",", "init_filter_norm", "=", "False", ",", "final_conv", "=", "True", ",", "\n", "out_feature_dim", "=", "256", ",", "gauss_sigma", "=", "1.0", ",", "\n", "iou_input_dim", "=", "(", "256", ",", "256", ")", ",", "iou_inter_dim", "=", "(", "256", ",", "256", ")", ",", "\n", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "alpha_eps", "=", "0.0", ",", "train_feature_extractor", "=", "True", ",", "\n", "init_uni_weight", "=", "None", ",", "optim_min_reg", "=", "1e-3", ",", "init_initializer", "=", "'default'", ",", "normalize_label", "=", "False", ",", "\n", "label_shrink", "=", "0", ",", "softmax_reg", "=", "None", ",", "label_threshold", "=", "0", ",", "final_relu", "=", "False", ",", "init_pool_square", "=", "False", ",", "\n", "frozen_backbone_layers", "=", "(", ")", ")", ":", "\n", "\n", "    ", "if", "not", "train_feature_extractor", ":", "\n", "        ", "frozen_backbone_layers", "=", "'all'", "\n", "\n", "# Backbone", "\n", "", "backbone_net", "=", "backbones", ".", "resnet18", "(", "pretrained", "=", "backbone_pretrained", ",", "frozen_layers", "=", "frozen_backbone_layers", ")", "\n", "\n", "# Feature normalization", "\n", "norm_scale", "=", "math", ".", "sqrt", "(", "1.0", "/", "(", "out_feature_dim", "*", "filter_size", "*", "filter_size", ")", ")", "\n", "\n", "# Classifier features", "\n", "clf_feature_extractor", "=", "clf_features", ".", "residual_basic_block", "(", "num_blocks", "=", "clf_feat_blocks", ",", "l2norm", "=", "clf_feat_norm", ",", "\n", "final_conv", "=", "final_conv", ",", "norm_scale", "=", "norm_scale", ",", "\n", "out_dim", "=", "out_feature_dim", ",", "final_relu", "=", "final_relu", ")", "\n", "\n", "# Initializer for the DiMP classifier", "\n", "initializer", "=", "clf_initializer", ".", "FilterInitializerLinear", "(", "filter_size", "=", "filter_size", ",", "filter_norm", "=", "init_filter_norm", ",", "\n", "feature_dim", "=", "out_feature_dim", ",", "init_weights", "=", "init_initializer", ",", "\n", "pool_square", "=", "init_pool_square", ")", "\n", "\n", "# Optimizer for the DiMP classifier", "\n", "optimizer", "=", "clf_optimizer", ".", "PrDiMPSteepestDescentNewton", "(", "num_iter", "=", "optim_iter", ",", "feat_stride", "=", "feat_stride", ",", "\n", "init_step_length", "=", "optim_init_step", ",", "\n", "init_filter_reg", "=", "optim_init_reg", ",", "gauss_sigma", "=", "gauss_sigma", ",", "\n", "detach_length", "=", "detach_length", ",", "alpha_eps", "=", "alpha_eps", ",", "\n", "init_uni_weight", "=", "init_uni_weight", ",", "\n", "min_filter_reg", "=", "optim_min_reg", ",", "normalize_label", "=", "normalize_label", ",", "\n", "label_shrink", "=", "label_shrink", ",", "softmax_reg", "=", "softmax_reg", ",", "\n", "label_threshold", "=", "label_threshold", ")", "\n", "\n", "# The classifier module", "\n", "classifier", "=", "target_clf", ".", "LinearFilter", "(", "filter_size", "=", "filter_size", ",", "filter_initializer", "=", "initializer", ",", "\n", "filter_optimizer", "=", "optimizer", ",", "feature_extractor", "=", "clf_feature_extractor", ")", "\n", "\n", "# Bounding box regressor", "\n", "bb_regressor", "=", "bbmodels", ".", "AtomIoUNet", "(", "pred_input_dim", "=", "iou_input_dim", ",", "pred_inter_dim", "=", "iou_inter_dim", ")", "\n", "\n", "# DiMP network", "\n", "net", "=", "DiMPnet", "(", "feature_extractor", "=", "backbone_net", ",", "classifier", "=", "classifier", ",", "bb_regressor", "=", "bb_regressor", ",", "\n", "classification_layer", "=", "classification_layer", ",", "bb_regressor_layer", "=", "[", "'layer2'", ",", "'layer3'", "]", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.tracking.dimpnet.klcedimpnet50": [[348, 397], ["float", "ltr.resnet50", "math.sqrt", "ltr.residual_bottleneck", "ltr.FilterInitializerLinear", "ltr.PrDiMPSteepestDescentNewton", "ltr.LinearFilter", "ltr.AtomIoUNet", "dimpnet.DiMPnet"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet50", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.features.residual_bottleneck"], ["", "@", "model_constructor", "\n", "def", "klcedimpnet50", "(", "filter_size", "=", "1", ",", "optim_iter", "=", "5", ",", "optim_init_step", "=", "1.0", ",", "optim_init_reg", "=", "0.01", ",", "\n", "classification_layer", "=", "'layer3'", ",", "feat_stride", "=", "16", ",", "backbone_pretrained", "=", "True", ",", "clf_feat_blocks", "=", "0", ",", "\n", "clf_feat_norm", "=", "True", ",", "init_filter_norm", "=", "False", ",", "final_conv", "=", "True", ",", "\n", "out_feature_dim", "=", "512", ",", "gauss_sigma", "=", "1.0", ",", "\n", "iou_input_dim", "=", "(", "256", ",", "256", ")", ",", "iou_inter_dim", "=", "(", "256", ",", "256", ")", ",", "\n", "detach_length", "=", "float", "(", "'Inf'", ")", ",", "alpha_eps", "=", "0.0", ",", "train_feature_extractor", "=", "True", ",", "\n", "init_uni_weight", "=", "None", ",", "optim_min_reg", "=", "1e-3", ",", "init_initializer", "=", "'default'", ",", "normalize_label", "=", "False", ",", "\n", "label_shrink", "=", "0", ",", "softmax_reg", "=", "None", ",", "label_threshold", "=", "0", ",", "final_relu", "=", "False", ",", "frozen_backbone_layers", "=", "(", ")", ")", ":", "\n", "\n", "    ", "if", "not", "train_feature_extractor", ":", "\n", "        ", "frozen_backbone_layers", "=", "'all'", "\n", "\n", "# Backbone", "\n", "", "backbone_net", "=", "backbones", ".", "resnet50", "(", "pretrained", "=", "backbone_pretrained", ",", "frozen_layers", "=", "frozen_backbone_layers", ")", "\n", "\n", "# Feature normalization", "\n", "norm_scale", "=", "math", ".", "sqrt", "(", "1.0", "/", "(", "out_feature_dim", "*", "filter_size", "*", "filter_size", ")", ")", "\n", "\n", "# Classifier features", "\n", "clf_feature_extractor", "=", "clf_features", ".", "residual_bottleneck", "(", "num_blocks", "=", "clf_feat_blocks", ",", "l2norm", "=", "clf_feat_norm", ",", "\n", "final_conv", "=", "final_conv", ",", "norm_scale", "=", "norm_scale", ",", "\n", "out_dim", "=", "out_feature_dim", ",", "final_relu", "=", "final_relu", ")", "\n", "\n", "# Initializer for the DiMP classifier", "\n", "initializer", "=", "clf_initializer", ".", "FilterInitializerLinear", "(", "filter_size", "=", "filter_size", ",", "filter_norm", "=", "init_filter_norm", ",", "\n", "feature_dim", "=", "out_feature_dim", ",", "init_weights", "=", "init_initializer", ")", "\n", "\n", "# Optimizer for the DiMP classifier", "\n", "optimizer", "=", "clf_optimizer", ".", "PrDiMPSteepestDescentNewton", "(", "num_iter", "=", "optim_iter", ",", "feat_stride", "=", "feat_stride", ",", "\n", "init_step_length", "=", "optim_init_step", ",", "\n", "init_filter_reg", "=", "optim_init_reg", ",", "gauss_sigma", "=", "gauss_sigma", ",", "\n", "detach_length", "=", "detach_length", ",", "alpha_eps", "=", "alpha_eps", ",", "\n", "init_uni_weight", "=", "init_uni_weight", ",", "\n", "min_filter_reg", "=", "optim_min_reg", ",", "normalize_label", "=", "normalize_label", ",", "\n", "label_shrink", "=", "label_shrink", ",", "softmax_reg", "=", "softmax_reg", ",", "\n", "label_threshold", "=", "label_threshold", ")", "\n", "\n", "# The classifier module", "\n", "classifier", "=", "target_clf", ".", "LinearFilter", "(", "filter_size", "=", "filter_size", ",", "filter_initializer", "=", "initializer", ",", "\n", "filter_optimizer", "=", "optimizer", ",", "feature_extractor", "=", "clf_feature_extractor", ")", "\n", "\n", "# Bounding box regressor", "\n", "bb_regressor", "=", "bbmodels", ".", "AtomIoUNet", "(", "input_dim", "=", "(", "4", "*", "128", ",", "4", "*", "256", ")", ",", "pred_input_dim", "=", "iou_input_dim", ",", "pred_inter_dim", "=", "iou_inter_dim", ")", "\n", "\n", "# DiMP network", "\n", "net", "=", "DiMPnet", "(", "feature_extractor", "=", "backbone_net", ",", "classifier", "=", "classifier", ",", "bb_regressor", "=", "bb_regressor", ",", "\n", "classification_layer", "=", "classification_layer", ",", "bb_regressor_layer", "=", "[", "'layer2'", ",", "'layer3'", "]", ")", "\n", "return", "net", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.BaseModel.__init__": [[48, 62], ["torch.nn.Module.__init__", "superglue.BaseModel.conf.update", "superglue.BaseModel.conf.update", "copy.copy.copy", "superglue.BaseModel.conf.update", "superglue.BaseModel.parameters"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["def", "__init__", "(", "self", ",", "conf", "=", "None", ")", ":", "\n", "        ", "\"\"\"Perform some logic and call the _init method of the child model.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conf", "=", "{", "}", "\n", "self", ".", "conf", ".", "update", "(", "**", "self", ".", "base_default_conf", ")", "\n", "self", ".", "conf", ".", "update", "(", "**", "self", ".", "default_conf", ")", "\n", "if", "conf", "is", "not", "None", ":", "\n", "            ", "self", ".", "conf", ".", "update", "(", "**", "conf", ")", "\n", "\n", "", "self", ".", "required_data_keys", "=", "copy", "(", "self", ".", "required_data_keys", ")", "\n", "\n", "if", "not", "self", ".", "conf", "[", "'trainable'", "]", ":", "\n", "            ", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.BaseModel.train": [[63, 73], ["super().train", "isinstance", "superglue.BaseModel.apply", "module.eval"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval"], ["", "", "", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "train", "(", "mode", ")", "\n", "\n", "def", "freeze_bn", "(", "module", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "nn", ".", "modules", ".", "batchnorm", ".", "_BatchNorm", ")", ":", "\n", "                ", "module", ".", "eval", "(", ")", "\n", "", "", "if", "self", ".", "conf", "[", "'freeze_batch_normalization'", "]", ":", "\n", "            ", "self", ".", "apply", "(", "freeze_bn", ")", "\n", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.BaseModel.forward": [[74, 79], ["superglue.BaseModel._forward"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.SuperGlue._forward"], ["", "def", "forward", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"Check the data and call the _forward method of the child model.\"\"\"", "\n", "for", "key", "in", "self", ".", "required_data_keys", ":", "\n", "            ", "assert", "key", "in", "data", ",", "'Missing key {} in data'", ".", "format", "(", "key", ")", "\n", "", "return", "self", ".", "_forward", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.BaseModel._forward": [[80, 84], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_forward", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"To be implemented by the child class.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.KeypointEncoder.__init__": [[114, 118], ["torch.nn.Module.__init__", "superglue.MLP", "torch.nn.init.constant_", "torch.nn.init.constant_", "list"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.MLP", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["    ", "def", "__init__", "(", "self", ",", "feature_dim", ",", "layers", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "MLP", "(", "[", "3", "]", "+", "list", "(", "layers", ")", "+", "[", "feature_dim", "]", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "encoder", "[", "-", "1", "]", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.KeypointEncoder.forward": [[119, 122], ["superglue.KeypointEncoder.encoder", "kpts.transpose", "scores.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "kpts", ",", "scores", ")", ":", "\n", "        ", "inputs", "=", "[", "kpts", ".", "transpose", "(", "1", ",", "2", ")", ",", "scores", ".", "unsqueeze", "(", "1", ")", "]", "\n", "return", "self", ".", "encoder", "(", "torch", ".", "cat", "(", "inputs", ",", "dim", "=", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.MultiHeadedAttention.__init__": [[132, 139], ["torch.nn.Module.__init__", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.ModuleList", "torch.nn.ModuleList", "copy.copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "h", ",", "d_model", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "d_model", "%", "h", "==", "0", "\n", "self", ".", "dim", "=", "d_model", "//", "h", "\n", "self", ".", "h", "=", "h", "\n", "self", ".", "merge", "=", "nn", ".", "Conv1d", "(", "d_model", ",", "d_model", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "proj", "=", "nn", ".", "ModuleList", "(", "[", "deepcopy", "(", "self", ".", "merge", ")", "for", "_", "in", "range", "(", "3", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.MultiHeadedAttention.forward": [[140, 146], ["query.size", "superglue.attention", "superglue.MultiHeadedAttention.merge", "l().view", "x.contiguous().view", "zip", "l", "x.contiguous"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.attention"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ")", ":", "\n", "        ", "b", "=", "query", ".", "size", "(", "0", ")", "\n", "query", ",", "key", ",", "value", "=", "[", "l", "(", "x", ")", ".", "view", "(", "b", ",", "self", ".", "dim", ",", "self", ".", "h", ",", "-", "1", ")", "\n", "for", "l", ",", "x", "in", "zip", "(", "self", ".", "proj", ",", "(", "query", ",", "key", ",", "value", ")", ")", "]", "\n", "x", ",", "_", "=", "attention", "(", "query", ",", "key", ",", "value", ")", "\n", "return", "self", ".", "merge", "(", "x", ".", "contiguous", "(", ")", ".", "view", "(", "b", ",", "self", ".", "dim", "*", "self", ".", "h", ",", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.AttentionalPropagation.__init__": [[149, 154], ["torch.nn.Module.__init__", "superglue.MultiHeadedAttention", "superglue.MLP", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.MLP"], ["    ", "def", "__init__", "(", "self", ",", "num_dim", ",", "num_heads", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attn", "=", "MultiHeadedAttention", "(", "num_heads", ",", "num_dim", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "[", "num_dim", "*", "2", ",", "num_dim", "*", "2", ",", "num_dim", "]", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "mlp", "[", "-", "1", "]", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.AttentionalPropagation.forward": [[155, 158], ["superglue.AttentionalPropagation.attn", "superglue.AttentionalPropagation.mlp", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "source", ")", ":", "\n", "        ", "message", "=", "self", ".", "attn", "(", "x", ",", "source", ",", "source", ")", "\n", "return", "self", ".", "mlp", "(", "torch", ".", "cat", "(", "[", "x", ",", "message", "]", ",", "dim", "=", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.GNNLayer.__init__": [[161, 166], ["torch.nn.Module.__init__", "superglue.AttentionalPropagation"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "feature_dim", ",", "layer_type", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "update", "=", "AttentionalPropagation", "(", "feature_dim", ",", "4", ")", "\n", "assert", "layer_type", "in", "[", "'cross'", ",", "'self'", "]", "\n", "self", ".", "type", "=", "layer_type", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.GNNLayer.forward": [[167, 177], ["superglue.GNNLayer.update", "superglue.GNNLayer.update", "ValueError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update", "home.repos.pwc.inspect_result.visionml_pytracking.admin.stats.AverageMeter.update"], ["", "def", "forward", "(", "self", ",", "desc0", ",", "desc1", ")", ":", "\n", "        ", "if", "self", ".", "type", "==", "'cross'", ":", "\n", "            ", "src0", ",", "src1", "=", "desc1", ",", "desc0", "\n", "", "elif", "self", ".", "type", "==", "'self'", ":", "\n", "            ", "src0", ",", "src1", "=", "desc0", ",", "desc1", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "self", ".", "type", ")", "\n", "", "delta0", ",", "delta1", "=", "self", ".", "update", "(", "desc0", ",", "src0", ")", ",", "self", ".", "update", "(", "desc1", ",", "src1", ")", "\n", "desc0", ",", "desc1", "=", "(", "desc0", "+", "delta0", ")", ",", "(", "desc1", "+", "delta1", ")", "\n", "return", "desc0", ",", "desc1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.AttentionalGNN.__init__": [[180, 185], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "superglue.GNNLayer"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "feature_dim", ",", "layer_types", ",", "checkpointed", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "checkpointed", "=", "checkpointed", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "\n", "GNNLayer", "(", "feature_dim", ",", "layer_type", ")", "for", "layer_type", "in", "layer_types", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.AttentionalGNN.forward": [[186, 194], ["torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "torch.utils.checkpoint.checkpoint", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "desc0", ",", "desc1", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "if", "self", ".", "checkpointed", ":", "\n", "                ", "desc0", ",", "desc1", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "layer", ",", "desc0", ",", "desc1", ",", "preserve_rng_state", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "desc0", ",", "desc1", "=", "layer", "(", "desc0", ",", "desc1", ")", "\n", "", "", "return", "desc0", ",", "desc1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.SuperGlue.__init__": [[268, 299], ["superglue.BaseModel.__init__", "superglue.KeypointEncoder", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.orthogonal_", "torch.nn.init.orthogonal_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "superglue.SuperGlue.register_parameter", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.init.constant_", "torch.nn.init.constant_", "superglue.AttentionalGNN", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "conf", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "conf", "=", "conf", ")", "\n", "if", "self", ".", "conf", "[", "'bottleneck_dim'", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "bottleneck_down", "=", "nn", ".", "Conv1d", "(", "\n", "self", ".", "conf", "[", "'input_dim'", "]", ",", "self", ".", "conf", "[", "'bottleneck_dim'", "]", ",", "\n", "kernel_size", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "bottleneck_up", "=", "nn", ".", "Conv1d", "(", "\n", "self", ".", "conf", "[", "'bottleneck_dim'", "]", ",", "self", ".", "conf", "[", "'input_dim'", "]", ",", "\n", "kernel_size", "=", "1", ",", "bias", "=", "True", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bottleneck_down", ".", "bias", ",", "0.0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bottleneck_up", ".", "bias", ",", "0.0", ")", "\n", "\n", "", "if", "self", ".", "conf", "[", "'input_dim'", "]", "!=", "self", ".", "conf", "[", "'descriptor_dim'", "]", ":", "\n", "            ", "self", ".", "input_proj", "=", "nn", ".", "Conv1d", "(", "\n", "self", ".", "conf", "[", "'input_dim'", "]", ",", "self", ".", "conf", "[", "'descriptor_dim'", "]", ",", "\n", "kernel_size", "=", "1", ",", "bias", "=", "True", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "input_proj", ".", "bias", ",", "0.0", ")", "\n", "\n", "", "self", ".", "kenc", "=", "KeypointEncoder", "(", "self", ".", "conf", "[", "'descriptor_dim'", "]", ",", "self", ".", "conf", "[", "'keypoint_encoder'", "]", ")", "\n", "\n", "if", "not", "self", ".", "conf", "[", "'skip_gnn'", "]", ":", "\n", "            ", "self", ".", "gnn", "=", "AttentionalGNN", "(", "\n", "self", ".", "conf", "[", "'descriptor_dim'", "]", ",", "self", ".", "conf", "[", "'GNN_layers'", "]", ",", "self", ".", "conf", "[", "'checkpointed'", "]", ")", "\n", "\n", "", "self", ".", "final_proj", "=", "nn", ".", "Conv1d", "(", "\n", "self", ".", "conf", "[", "'descriptor_dim'", "]", ",", "self", ".", "conf", "[", "'descriptor_dim'", "]", ",", "kernel_size", "=", "1", ",", "bias", "=", "True", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "final_proj", ".", "bias", ",", "0.0", ")", "\n", "nn", ".", "init", ".", "orthogonal_", "(", "self", ".", "final_proj", ".", "weight", ",", "gain", "=", "1", ")", "\n", "\n", "bin_score", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "0.0", ")", ")", "\n", "self", ".", "register_parameter", "(", "'bin_score'", ",", "bin_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.SuperGlue._forward": [[300, 372], ["superglue.normalize_keypoints", "superglue.normalize_keypoints", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "log_double_softmax.new_tensor", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "superglue.SuperGlue.bottleneck_down", "superglue.SuperGlue.bottleneck_down", "superglue.SuperGlue.bottleneck_up", "superglue.SuperGlue.bottleneck_up", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "torch.nn.functional.normalize", "superglue.SuperGlue.input_proj", "superglue.SuperGlue.input_proj", "superglue.SuperGlue.kenc", "superglue.SuperGlue.kenc", "superglue.SuperGlue.gnn", "superglue.SuperGlue.final_proj", "superglue.SuperGlue.final_proj", "superglue.log_optimal_transport", "scores[].max", "scores[].max", "torch.where.gather", "torch.where.gather", "torch.where.gather", "torch.where.gather", "max0.values.exp", "torch.where.gather", "torch.where.gather", "valid0.gather", "torch.where.new_tensor", "torch.where.new_tensor", "torch.where.new_tensor", "torch.where.new_tensor", "normalize_keypoints.new_full", "normalize_keypoints.new_full", "normalize_keypoints.new_zeros", "normalize_keypoints.new_zeros", "desc0.detach.detach.detach", "desc1.detach.detach.detach", "superglue.log_double_softmax", "ValueError", "superglue.arange_like", "superglue.arange_like"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.normalize_keypoints", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.normalize_keypoints", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.log_optimal_transport", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.log_double_softmax", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.arange_like", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.arange_like"], ["", "def", "_forward", "(", "self", ",", "data", ")", ":", "\n", "        ", "pred", "=", "{", "}", "\n", "desc0", ",", "desc1", "=", "data", "[", "'descriptors0'", "]", ",", "data", "[", "'descriptors1'", "]", "\n", "kpts0", ",", "kpts1", "=", "data", "[", "'img_coords0'", "]", ",", "data", "[", "'img_coords1'", "]", "\n", "\n", "if", "kpts0", ".", "shape", "[", "1", "]", "==", "0", "or", "kpts1", ".", "shape", "[", "1", "]", "==", "0", ":", "# no keypoints", "\n", "            ", "shape0", ",", "shape1", "=", "kpts0", ".", "shape", "[", ":", "-", "1", "]", ",", "kpts1", ".", "shape", "[", ":", "-", "1", "]", "\n", "return", "{", "\n", "'matches0'", ":", "kpts0", ".", "new_full", "(", "shape0", ",", "-", "1", ",", "dtype", "=", "torch", ".", "int", ")", ",", "\n", "'matches1'", ":", "kpts1", ".", "new_full", "(", "shape1", ",", "-", "1", ",", "dtype", "=", "torch", ".", "int", ")", ",", "\n", "'match_scores0'", ":", "kpts0", ".", "new_zeros", "(", "shape0", ")", ",", "\n", "'match_scores1'", ":", "kpts1", ".", "new_zeros", "(", "shape1", ")", ",", "\n", "}", "\n", "\n", "", "if", "self", ".", "conf", "[", "'bottleneck_dim'", "]", "is", "not", "None", ":", "\n", "            ", "pred", "[", "'down_descriptors0'", "]", "=", "desc0", "=", "self", ".", "bottleneck_down", "(", "desc0", ")", "\n", "pred", "[", "'down_descriptors1'", "]", "=", "desc1", "=", "self", ".", "bottleneck_down", "(", "desc1", ")", "\n", "desc0", "=", "self", ".", "bottleneck_up", "(", "desc0", ")", "\n", "desc1", "=", "self", ".", "bottleneck_up", "(", "desc1", ")", "\n", "desc0", "=", "nn", ".", "functional", ".", "normalize", "(", "desc0", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "desc1", "=", "nn", ".", "functional", ".", "normalize", "(", "desc1", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "pred", "[", "'bottleneck_descriptors0'", "]", "=", "desc0", "\n", "pred", "[", "'bottleneck_descriptors1'", "]", "=", "desc1", "\n", "if", "self", ".", "conf", "[", "'loss'", "]", "[", "'nll_weight'", "]", "==", "0", ":", "\n", "                ", "desc0", "=", "desc0", ".", "detach", "(", ")", "\n", "desc1", "=", "desc1", ".", "detach", "(", ")", "\n", "\n", "", "", "if", "self", ".", "conf", "[", "'input_dim'", "]", "!=", "self", ".", "conf", "[", "'descriptor_dim'", "]", ":", "\n", "            ", "desc0", "=", "self", ".", "input_proj", "(", "desc0", ")", "\n", "desc1", "=", "self", ".", "input_proj", "(", "desc1", ")", "\n", "\n", "", "kpts0", "=", "normalize_keypoints", "(", "kpts0", ",", "data", "[", "'image_size0'", "]", ")", "\n", "kpts1", "=", "normalize_keypoints", "(", "kpts1", ",", "data", "[", "'image_size1'", "]", ")", "\n", "\n", "desc0", "=", "desc0", "+", "self", ".", "kenc", "(", "kpts0", ",", "data", "[", "'scores0'", "]", ")", "\n", "desc1", "=", "desc1", "+", "self", ".", "kenc", "(", "kpts1", ",", "data", "[", "'scores1'", "]", ")", "\n", "\n", "if", "not", "self", ".", "conf", "[", "'skip_gnn'", "]", ":", "\n", "            ", "desc0", ",", "desc1", "=", "self", ".", "gnn", "(", "desc0", ",", "desc1", ")", "\n", "\n", "", "mdesc0", ",", "mdesc1", "=", "self", ".", "final_proj", "(", "desc0", ")", ",", "self", ".", "final_proj", "(", "desc1", ")", "\n", "\n", "scores", "=", "torch", ".", "einsum", "(", "'bdn,bdm->bnm'", ",", "mdesc0", ",", "mdesc1", ")", "\n", "scores", "=", "scores", "/", "self", ".", "conf", "[", "'descriptor_dim'", "]", "**", ".5", "\n", "\n", "if", "self", ".", "conf", "[", "'output_normalization'", "]", "==", "'sinkhorn'", ":", "\n", "            ", "scores", "=", "log_optimal_transport", "(", "scores", ",", "self", ".", "bin_score", ",", "iters", "=", "self", ".", "conf", "[", "'num_sinkhorn_iterations'", "]", ")", "\n", "", "elif", "self", ".", "conf", "[", "'output_normalization'", "]", "==", "'double_softmax'", ":", "\n", "            ", "scores", "=", "log_double_softmax", "(", "scores", ",", "self", ".", "bin_score", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "self", ".", "conf", "[", "'output_normalization'", "]", ")", "\n", "\n", "", "max0", ",", "max1", "=", "scores", "[", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", ".", "max", "(", "2", ")", ",", "scores", "[", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", ".", "max", "(", "1", ")", "\n", "m0", ",", "m1", "=", "max0", ".", "indices", ",", "max1", ".", "indices", "\n", "mutual0", "=", "arange_like", "(", "m0", ",", "1", ")", "[", "None", "]", "==", "m1", ".", "gather", "(", "1", ",", "m0", ")", "\n", "mutual1", "=", "arange_like", "(", "m1", ",", "1", ")", "[", "None", "]", "==", "m0", ".", "gather", "(", "1", ",", "m1", ")", "\n", "zero", "=", "scores", ".", "new_tensor", "(", "0", ")", "\n", "mscores0", "=", "torch", ".", "where", "(", "mutual0", ",", "max0", ".", "values", ".", "exp", "(", ")", ",", "zero", ")", "\n", "mscores1", "=", "torch", ".", "where", "(", "mutual1", ",", "mscores0", ".", "gather", "(", "1", ",", "m1", ")", ",", "zero", ")", "\n", "valid0", "=", "mutual0", "&", "(", "mscores0", ">", "self", ".", "conf", "[", "'filter_threshold'", "]", ")", "\n", "valid1", "=", "mutual1", "&", "valid0", ".", "gather", "(", "1", ",", "m1", ")", "\n", "m0", "=", "torch", ".", "where", "(", "valid0", ",", "m0", ",", "m0", ".", "new_tensor", "(", "-", "1", ")", ")", "\n", "m1", "=", "torch", ".", "where", "(", "valid1", ",", "m1", ",", "m1", ".", "new_tensor", "(", "-", "1", ")", ")", "\n", "\n", "return", "{", "\n", "**", "pred", ",", "\n", "'log_assignment'", ":", "scores", ",", "\n", "'matches0'", ":", "m0", ",", "\n", "'matches1'", ":", "m1", ",", "\n", "'match_scores0'", ":", "mscores0", ",", "\n", "'match_scores1'", ":", "mscores1", ",", "\n", "'bin_score'", ":", "self", ".", "bin_score", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.MLP": [[86, 97], ["len", "range", "torch.nn.Sequential", "layers.append", "torch.nn.Conv1d", "layers.append", "layers.append", "torch.nn.ReLU", "torch.nn.BatchNorm1d"], "function", ["None"], ["", "", "def", "MLP", "(", "channels", ",", "do_bn", "=", "True", ")", ":", "\n", "    ", "n", "=", "len", "(", "channels", ")", "\n", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "n", ")", ":", "\n", "        ", "layers", ".", "append", "(", "\n", "nn", ".", "Conv1d", "(", "channels", "[", "i", "-", "1", "]", ",", "channels", "[", "i", "]", ",", "kernel_size", "=", "1", ",", "bias", "=", "True", ")", ")", "\n", "if", "i", "<", "(", "n", "-", "1", ")", ":", "\n", "            ", "if", "do_bn", ":", "\n", "                ", "layers", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "channels", "[", "i", "]", ")", ")", "\n", "", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.normalize_keypoints": [[99, 111], ["isinstance", "kpts.new_tensor", "isinstance", "shape_or_size.to", "shape_or_size.to.max"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "normalize_keypoints", "(", "kpts", ",", "shape_or_size", ")", ":", "\n", "    ", "if", "isinstance", "(", "shape_or_size", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "# it's a shape", "\n", "        ", "h", ",", "w", "=", "shape_or_size", "[", "-", "2", ":", "]", "\n", "size", "=", "kpts", ".", "new_tensor", "(", "[", "[", "w", ",", "h", "]", "]", ")", "\n", "", "else", ":", "\n", "# it's a size", "\n", "        ", "assert", "isinstance", "(", "shape_or_size", ",", "torch", ".", "Tensor", ")", "\n", "size", "=", "shape_or_size", ".", "to", "(", "kpts", ")", "\n", "", "c", "=", "size", "/", "2", "\n", "f", "=", "size", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", ".", "values", "*", "0.7", "# somehow we used 0.7 for SG", "\n", "return", "(", "kpts", "-", "c", "[", ":", ",", "None", ",", ":", "]", ")", "/", "f", "[", ":", ",", "None", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.attention": [[124, 129], ["torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "function", ["None"], ["", "", "def", "attention", "(", "query", ",", "key", ",", "value", ")", ":", "\n", "    ", "dim", "=", "query", ".", "shape", "[", "1", "]", "\n", "scores", "=", "torch", ".", "einsum", "(", "'bdhn,bdhm->bhnm'", ",", "query", ",", "key", ")", "/", "dim", "**", ".5", "\n", "prob", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "\n", "return", "torch", ".", "einsum", "(", "'bhnm,bdhm->bdhn'", ",", "prob", ",", "value", ")", ",", "prob", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.log_sinkhorn_iterations": [[196, 202], ["range", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "v.unsqueeze", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "u.unsqueeze", "v.unsqueeze", "u.unsqueeze"], "function", ["None"], ["", "", "def", "log_sinkhorn_iterations", "(", "Z", ",", "log_mu", ",", "log_nu", ",", "iters", ")", ":", "\n", "    ", "u", ",", "v", "=", "torch", ".", "zeros_like", "(", "log_mu", ")", ",", "torch", ".", "zeros_like", "(", "log_nu", ")", "\n", "for", "_", "in", "range", "(", "iters", ")", ":", "\n", "        ", "u", "=", "log_mu", "-", "torch", ".", "logsumexp", "(", "Z", "+", "v", ".", "unsqueeze", "(", "1", ")", ",", "dim", "=", "2", ")", "\n", "v", "=", "log_nu", "-", "torch", ".", "logsumexp", "(", "Z", "+", "u", ".", "unsqueeze", "(", "2", ")", ",", "dim", "=", "1", ")", "\n", "", "return", "Z", "+", "u", ".", "unsqueeze", "(", "2", ")", "+", "v", ".", "unsqueeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.log_optimal_transport": [[204, 224], ["scores.new_tensor", "alpha.expand.expand", "alpha.expand.expand", "alpha.expand.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "superglue.log_sinkhorn_iterations", "log_mu[].expand", "log_nu[].expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "norm.expand", "norm.expand", "ns.log", "ms.log"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.log_sinkhorn_iterations"], ["", "def", "log_optimal_transport", "(", "scores", ",", "alpha", ",", "iters", ")", ":", "\n", "    ", "b", ",", "m", ",", "n", "=", "scores", ".", "shape", "\n", "one", "=", "scores", ".", "new_tensor", "(", "1", ")", "\n", "ms", ",", "ns", "=", "(", "m", "*", "one", ")", ".", "to", "(", "scores", ")", ",", "(", "n", "*", "one", ")", ".", "to", "(", "scores", ")", "\n", "\n", "bins0", "=", "alpha", ".", "expand", "(", "b", ",", "m", ",", "1", ")", "\n", "bins1", "=", "alpha", ".", "expand", "(", "b", ",", "1", ",", "n", ")", "\n", "alpha", "=", "alpha", ".", "expand", "(", "b", ",", "1", ",", "1", ")", "\n", "\n", "couplings", "=", "torch", ".", "cat", "(", "[", "torch", ".", "cat", "(", "[", "scores", ",", "bins0", "]", ",", "-", "1", ")", ",", "\n", "torch", ".", "cat", "(", "[", "bins1", ",", "alpha", "]", ",", "-", "1", ")", "]", ",", "1", ")", "\n", "\n", "norm", "=", "-", "(", "ms", "+", "ns", ")", ".", "log", "(", ")", "\n", "log_mu", "=", "torch", ".", "cat", "(", "[", "norm", ".", "expand", "(", "m", ")", ",", "ns", ".", "log", "(", ")", "[", "None", "]", "+", "norm", "]", ")", "\n", "log_nu", "=", "torch", ".", "cat", "(", "[", "norm", ".", "expand", "(", "n", ")", ",", "ms", ".", "log", "(", ")", "[", "None", "]", "+", "norm", "]", ")", "\n", "log_mu", ",", "log_nu", "=", "log_mu", "[", "None", "]", ".", "expand", "(", "b", ",", "-", "1", ")", ",", "log_nu", "[", "None", "]", ".", "expand", "(", "b", ",", "-", "1", ")", "\n", "\n", "Z", "=", "log_sinkhorn_iterations", "(", "couplings", ",", "log_mu", ",", "log_nu", ",", "iters", ")", "\n", "Z", "=", "Z", "-", "norm", "# multiply probabilities by M+N", "\n", "return", "Z", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.log_double_softmax": [[226, 238], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "scores.new_full.new_full", "bin_.expand", "bin_.expand"], "function", ["None"], ["", "def", "log_double_softmax", "(", "scores", ",", "bin_score", ")", ":", "\n", "    ", "b", ",", "m", ",", "n", "=", "scores", ".", "shape", "\n", "bin_", "=", "bin_score", "[", "None", ",", "None", ",", "None", "]", "\n", "scores0", "=", "torch", ".", "cat", "(", "[", "scores", ",", "bin_", ".", "expand", "(", "b", ",", "m", ",", "1", ")", "]", ",", "2", ")", "\n", "scores1", "=", "torch", ".", "cat", "(", "[", "scores", ",", "bin_", ".", "expand", "(", "b", ",", "1", ",", "n", ")", "]", ",", "1", ")", "\n", "scores0", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "scores0", ",", "2", ")", "\n", "scores1", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "scores1", ",", "1", ")", "\n", "scores", "=", "scores", ".", "new_full", "(", "(", "b", ",", "m", "+", "1", ",", "n", "+", "1", ")", ",", "0", ")", "\n", "scores", "[", ":", ",", ":", "m", ",", ":", "n", "]", "=", "(", "scores0", "[", ":", ",", ":", ",", ":", "n", "]", "+", "scores1", "[", ":", ",", ":", "m", ",", ":", "]", ")", "/", "2", "\n", "scores", "[", ":", ",", ":", "-", "1", ",", "-", "1", "]", "=", "scores0", "[", ":", ",", ":", ",", "-", "1", "]", "\n", "scores", "[", ":", ",", "-", "1", ",", ":", "-", "1", "]", "=", "scores1", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.superglue.arange_like": [[240, 242], ["x.new_ones().cumsum", "x.new_ones"], "function", ["None"], ["", "def", "arange_like", "(", "x", ",", "dim", ")", ":", "\n", "    ", "return", "x", ".", "new_ones", "(", "x", ".", "shape", "[", "dim", "]", ")", ".", "cumsum", "(", "0", ")", "-", "1", "# traceable in 1.1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.DescriptorExtractor.__init__": [[14, 19], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "backbone_feat_dim", ",", "descriptor_dim", ",", "kernel_size", "=", "4", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "backbone_feat_dim", ",", "out_channels", "=", "descriptor_dim", ",", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "kernel_size", "//", "2", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.DescriptorExtractor.forward": [[20, 25], ["target_candidate_matching.DescriptorExtractor.conv", "desc.permute", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "coords[].long", "coords[].long", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv"], ["", "def", "forward", "(", "self", ",", "x", ",", "coords", ")", ":", "\n", "        ", "feats", "=", "self", ".", "conv", "(", "x", ")", "\n", "assert", "torch", ".", "all", "(", "coords", ">=", "0", ")", "and", "torch", ".", "all", "(", "coords", "<", "feats", ".", "shape", "[", "3", "]", ")", "\n", "desc", "=", "feats", "[", "torch", ".", "arange", "(", "x", ".", "shape", "[", "0", "]", ")", ".", "unsqueeze", "(", "1", ")", ",", ":", ",", "coords", "[", ":", ",", ":", ",", "0", "]", ".", "long", "(", ")", ",", "coords", "[", ":", ",", ":", ",", "1", "]", ".", "long", "(", ")", "]", "\n", "return", "desc", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.DescriptorExtractor.get_descriptors": [[26, 34], ["target_candidate_matching.DescriptorExtractor.conv", "desc.permute", "coords.unsqueeze.unsqueeze.unsqueeze", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all", "torch.all", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "coords[].long", "coords[].long", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv"], ["", "def", "get_descriptors", "(", "self", ",", "x", ",", "coords", ")", ":", "\n", "        ", "if", "coords", ".", "ndim", "==", "2", ":", "\n", "            ", "coords", "=", "coords", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "feats", "=", "self", ".", "conv", "(", "x", ")", "\n", "assert", "torch", ".", "all", "(", "coords", ">=", "0", ")", "and", "torch", ".", "all", "(", "coords", "<", "feats", ".", "shape", "[", "3", "]", ")", "\n", "desc", "=", "feats", "[", "torch", ".", "arange", "(", "x", ".", "shape", "[", "0", "]", ")", ".", "unsqueeze", "(", "1", ")", ",", ":", ",", "coords", "[", ":", ",", ":", ",", "0", "]", ".", "long", "(", ")", ",", "coords", "[", ":", ",", ":", ",", "1", "]", ".", "long", "(", ")", "]", "\n", "return", "desc", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.__init__": [[37, 45], ["torch.nn.Module.__init__", "sorted", "list", "set"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["    ", "def", "__init__", "(", "self", ",", "feature_extractor", ",", "classification_layer", ",", "descriptor_extractor", ",", "matcher", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "feature_extractor", "=", "feature_extractor", "\n", "self", ".", "classification_layer", "=", "classification_layer", "\n", "self", ".", "output_layers", "=", "sorted", "(", "list", "(", "set", "(", "self", ".", "classification_layer", ")", ")", ")", "\n", "\n", "self", ".", "descriptor_extractor", "=", "descriptor_extractor", "\n", "self", ".", "matcher", "=", "matcher", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.forward": [[47, 76], ["target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "target_candidate_matching.TargetCandidateMatchingNetwork.get_backbone_clf_feat", "target_candidate_matching.TargetCandidateMatchingNetwork.get_backbone_clf_feat", "target_candidate_matching.TargetCandidateMatchingNetwork.descriptor_extractor", "target_candidate_matching.TargetCandidateMatchingNetwork.descriptor_extractor", "target_candidate_matching.TargetCandidateMatchingNetwork.matcher", "img_cropped0.reshape", "img_cropped1.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.get_backbone_clf_feat", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.get_backbone_clf_feat"], ["", "def", "forward", "(", "self", ",", "img_cropped0", ",", "img_cropped1", ",", "candidate_tsm_coords0", ",", "candidate_tsm_coords1", ",", "candidate_img_coords0", ",", "\n", "candidate_img_coords1", ",", "candidate_scores0", ",", "candidate_scores1", ",", "img_shape0", ",", "img_shape1", ",", "**", "kwargs", ")", ":", "\n", "\n", "\n", "# Extract backbone features", "\n", "        ", "frame_feat0", "=", "self", ".", "extract_backbone_features", "(", "img_cropped0", ".", "reshape", "(", "-", "1", ",", "*", "img_cropped0", ".", "shape", "[", "-", "3", ":", "]", ")", ")", "\n", "frame_feat1", "=", "self", ".", "extract_backbone_features", "(", "img_cropped1", ".", "reshape", "(", "-", "1", ",", "*", "img_cropped1", ".", "shape", "[", "-", "3", ":", "]", ")", ")", "\n", "\n", "# Classification features", "\n", "frame_feat_clf0", "=", "self", ".", "get_backbone_clf_feat", "(", "frame_feat0", ")", "\n", "frame_feat_clf1", "=", "self", ".", "get_backbone_clf_feat", "(", "frame_feat1", ")", "\n", "\n", "descriptors0", "=", "self", ".", "descriptor_extractor", "(", "frame_feat_clf0", ",", "candidate_tsm_coords0", "[", "0", "]", ")", "\n", "descriptors1", "=", "self", ".", "descriptor_extractor", "(", "frame_feat_clf1", ",", "candidate_tsm_coords1", "[", "0", "]", ")", "\n", "\n", "data", "=", "{", "\n", "'descriptors0'", ":", "descriptors0", ",", "\n", "'descriptors1'", ":", "descriptors1", ",", "\n", "'img_coords0'", ":", "candidate_img_coords0", "[", "0", "]", ",", "\n", "'img_coords1'", ":", "candidate_img_coords1", "[", "0", "]", ",", "\n", "'scores0'", ":", "candidate_scores0", "[", "0", "]", ",", "\n", "'scores1'", ":", "candidate_scores1", "[", "0", "]", ",", "\n", "'image_size0'", ":", "img_shape0", "[", "0", "]", ",", "\n", "'image_size1'", ":", "img_shape1", "[", "0", "]", ",", "\n", "}", "\n", "\n", "pred", "=", "self", ".", "matcher", "(", "data", ")", "\n", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features": [[77, 81], ["target_candidate_matching.TargetCandidateMatchingNetwork.feature_extractor"], "methods", ["None"], ["", "def", "extract_backbone_features", "(", "self", ",", "im", ",", "layers", "=", "None", ")", ":", "\n", "        ", "if", "layers", "is", "None", ":", "\n", "            ", "layers", "=", "self", ".", "output_layers", "\n", "", "return", "self", ".", "feature_extractor", "(", "im", ",", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.get_backbone_clf_feat": [[82, 87], ["collections.OrderedDict", "len"], "methods", ["None"], ["", "def", "get_backbone_clf_feat", "(", "self", ",", "backbone_feat", ")", ":", "\n", "        ", "feat", "=", "OrderedDict", "(", "{", "l", ":", "backbone_feat", "[", "l", "]", "for", "l", "in", "self", ".", "classification_layer", "}", ")", "\n", "if", "len", "(", "self", ".", "classification_layer", ")", "==", "1", ":", "\n", "            ", "return", "feat", "[", "self", ".", "classification_layer", "[", "0", "]", "]", "\n", "", "return", "feat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.target_candidate_matching_net_resnet50": [[89, 115], ["ltr.resnet50", "target_candidate_matching.DescriptorExtractor", "ltr.models.target_candidate_matching.superglue.SuperGlue", "target_candidate_matching.TargetCandidateMatchingNetwork"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet50"], ["", "", "@", "model_constructor", "\n", "def", "target_candidate_matching_net_resnet50", "(", "backbone_pretrained", "=", "True", ",", "classification_layer", "=", "None", ",", "\n", "frozen_backbone_layers", "=", "(", ")", ",", "skip_gnn", "=", "False", ",", "GNN_layers", "=", "None", ",", "\n", "num_sinkhorn_iterations", "=", "10", ",", "output_normalization", "=", "'sinkhorn'", ")", ":", "\n", "    ", "if", "classification_layer", "is", "None", ":", "\n", "        ", "classification_layer", "=", "[", "'layer3'", "]", "\n", "", "if", "GNN_layers", "is", "None", ":", "\n", "        ", "GNN_layers", "=", "[", "'self'", ",", "'cross'", "]", "*", "2", "\n", "\n", "# Backbone", "\n", "", "backbone_net", "=", "backbones", ".", "resnet50", "(", "pretrained", "=", "backbone_pretrained", ",", "frozen_layers", "=", "frozen_backbone_layers", ")", "\n", "descriptor_extractor", "=", "DescriptorExtractor", "(", "backbone_feat_dim", "=", "1024", ",", "descriptor_dim", "=", "256", ",", "kernel_size", "=", "4", ")", "\n", "\n", "conf", "=", "{", "\n", "'skip_gnn'", ":", "skip_gnn", ",", "\n", "'GNN_layers'", ":", "GNN_layers", ",", "\n", "'num_sinkhorn_iterations'", ":", "num_sinkhorn_iterations", ",", "\n", "'output_normalization'", ":", "output_normalization", "\n", "}", "\n", "\n", "matcher", "=", "SuperGlue", "(", "conf", "=", "conf", ")", "\n", "\n", "net", "=", "TargetCandidateMatchingNetwork", "(", "feature_extractor", "=", "backbone_net", ",", "classification_layer", "=", "classification_layer", ",", "\n", "descriptor_extractor", "=", "descriptor_extractor", ",", "matcher", "=", "matcher", ")", "\n", "\n", "return", "net", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.FilterPredictor.__init__": [[20, 37], ["torch.Module.__init__", "filter_predictor.MLP", "torch.Embedding", "torch.Embedding", "ltr.models.transformer.position_encoding.PositionEmbeddingSine", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.MLP"], ["    ", "def", "__init__", "(", "self", ",", "transformer", ",", "feature_sz", ",", "use_test_frame_encoding", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transformer", "=", "transformer", "\n", "self", ".", "feature_sz", "=", "feature_sz", "\n", "self", ".", "use_test_frame_encoding", "=", "use_test_frame_encoding", "\n", "\n", "self", ".", "box_encoding", "=", "MLP", "(", "[", "4", ",", "self", ".", "transformer", ".", "d_model", "//", "4", ",", "self", ".", "transformer", ".", "d_model", ",", "self", ".", "transformer", ".", "d_model", "]", ")", "\n", "\n", "self", ".", "query_embed_fg", "=", "nn", ".", "Embedding", "(", "1", ",", "self", ".", "transformer", ".", "d_model", ")", "\n", "\n", "if", "self", ".", "use_test_frame_encoding", ":", "\n", "            ", "self", ".", "query_embed_test", "=", "nn", ".", "Embedding", "(", "1", ",", "self", ".", "transformer", ".", "d_model", ")", "\n", "\n", "", "self", ".", "query_embed_fg_decoder", "=", "self", ".", "query_embed_fg", "\n", "\n", "self", ".", "pos_encoding", "=", "PositionEmbeddingSine", "(", "num_pos_feats", "=", "self", ".", "transformer", ".", "d_model", "//", "2", ",", "sine_type", "=", "'lin_sine'", ",", "\n", "avoid_aliazing", "=", "True", ",", "max_spatial_resolution", "=", "feature_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.FilterPredictor.forward": [[38, 40], ["filter_predictor.FilterPredictor.predict_filter"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.FilterPredictor.predict_filter"], ["", "def", "forward", "(", "self", ",", "train_feat", ",", "test_feat", ",", "train_label", ",", "train_ltrb_target", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "predict_filter", "(", "train_feat", ",", "test_feat", ",", "train_label", ",", "train_ltrb_target", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.FilterPredictor.get_positional_encoding": [[41, 48], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "filter_predictor.FilterPredictor.pos_encoding", "filter_predictor.FilterPredictor.reshape"], "methods", ["None"], ["", "def", "get_positional_encoding", "(", "self", ",", "feat", ")", ":", "\n", "        ", "nframes", ",", "nseq", ",", "_", ",", "h", ",", "w", "=", "feat", ".", "shape", "\n", "\n", "mask", "=", "torch", ".", "zeros", "(", "(", "nframes", "*", "nseq", ",", "h", ",", "w", ")", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "feat", ".", "device", ")", "\n", "pos", "=", "self", ".", "pos_encoding", "(", "mask", ")", "\n", "\n", "return", "pos", ".", "reshape", "(", "nframes", ",", "nseq", ",", "-", "1", ",", "h", ",", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.FilterPredictor.predict_filter": [[49, 91], ["filter_predictor.FilterPredictor.get_positional_encoding", "filter_predictor.FilterPredictor.get_positional_encoding", "test_feat.unsqueeze.unsqueeze.permute().flatten().permute", "train_feat.unsqueeze.unsqueeze.permute().flatten().permute", "train_label.permute().flatten().permute().unsqueeze", "train_ltrb_target.unsqueeze.unsqueeze.permute().flatten", "test_pos.permute().flatten().permute.permute().flatten().permute.permute().flatten().permute", "train_pos.permute().flatten().permute.permute().flatten().permute.permute().flatten().permute", "filter_predictor.FilterPredictor.query_embed_fg.weight.reshape", "filter_predictor.FilterPredictor.box_encoding().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "filter_predictor.FilterPredictor.transformer", "enc_mem[].transpose", "output_embed.squeeze().transpose", "train_feat.unsqueeze.unsqueeze.dim", "train_feat.unsqueeze.unsqueeze.unsqueeze", "test_feat.unsqueeze.unsqueeze.dim", "test_feat.unsqueeze.unsqueeze.unsqueeze", "train_ltrb_target.unsqueeze.unsqueeze.dim", "train_ltrb_target.unsqueeze.unsqueeze.unsqueeze", "filter_predictor.FilterPredictor.query_embed_test.weight.reshape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "output_embed.squeeze().transpose.reshape", "enc_mem[].transpose.permute().reshape", "test_feat.unsqueeze.unsqueeze.permute().flatten", "train_feat.unsqueeze.unsqueeze.permute().flatten", "train_label.permute().flatten().permute", "train_ltrb_target.unsqueeze.unsqueeze.permute", "test_pos.permute().flatten().permute.permute().flatten().permute.permute().flatten", "train_pos.permute().flatten().permute.permute().flatten().permute.permute().flatten", "filter_predictor.FilterPredictor.box_encoding", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "output_embed.squeeze", "enc_mem[].transpose.permute", "test_feat.unsqueeze.unsqueeze.permute", "train_feat.unsqueeze.unsqueeze.permute", "train_label.permute().flatten", "test_pos.permute().flatten().permute.permute().flatten().permute.permute", "train_pos.permute().flatten().permute.permute().flatten().permute.permute", "train_label.permute"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.FilterPredictor.get_positional_encoding", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.FilterPredictor.get_positional_encoding", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "predict_filter", "(", "self", ",", "train_feat", ",", "test_feat", ",", "train_label", ",", "train_ltrb_target", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "#train_label size guess: Nf_tr, Ns, H, W.", "\n", "        ", "if", "train_feat", ".", "dim", "(", ")", "==", "4", ":", "\n", "            ", "train_feat", "=", "train_feat", ".", "unsqueeze", "(", "1", ")", "\n", "", "if", "test_feat", ".", "dim", "(", ")", "==", "4", ":", "\n", "            ", "test_feat", "=", "test_feat", ".", "unsqueeze", "(", "1", ")", "\n", "", "if", "train_ltrb_target", ".", "dim", "(", ")", "==", "4", ":", "\n", "            ", "train_ltrb_target", "=", "train_ltrb_target", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "h", ",", "w", "=", "test_feat", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "test_pos", "=", "self", ".", "get_positional_encoding", "(", "test_feat", ")", "# Nf_te, Ns, C, H, W", "\n", "train_pos", "=", "self", ".", "get_positional_encoding", "(", "train_feat", ")", "# Nf_tr, Ns, C, H, W", "\n", "\n", "test_feat_seq", "=", "test_feat", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ",", "4", ")", ".", "flatten", "(", "2", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# Nf_te*H*W, Ns, C", "\n", "train_feat_seq", "=", "train_feat", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ",", "4", ")", ".", "flatten", "(", "2", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# Nf_tr*H*W, Ns, C", "\n", "train_label_seq", "=", "train_label", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "flatten", "(", "1", ")", ".", "permute", "(", "1", ",", "0", ")", ".", "unsqueeze", "(", "2", ")", "# Nf_tr*H*W,Ns,1", "\n", "train_ltrb_target_seq_T", "=", "train_ltrb_target", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ",", "4", ")", ".", "flatten", "(", "2", ")", "# Ns,4,Nf_tr*H*W", "\n", "\n", "test_pos", "=", "test_pos", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ",", "4", ")", ".", "flatten", "(", "2", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "train_pos", "=", "train_pos", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ",", "4", ")", ".", "flatten", "(", "2", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "\n", "fg_token", "=", "self", ".", "query_embed_fg", ".", "weight", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "train_label_enc", "=", "fg_token", "*", "train_label_seq", "\n", "\n", "train_ltrb_target_enc", "=", "self", ".", "box_encoding", "(", "train_ltrb_target_seq_T", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# Nf_tr*H*H,Ns,C", "\n", "\n", "if", "self", ".", "use_test_frame_encoding", ":", "\n", "            ", "test_token", "=", "self", ".", "query_embed_test", ".", "weight", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "test_label_enc", "=", "torch", ".", "ones_like", "(", "test_feat_seq", ")", "*", "test_token", "\n", "feat", "=", "torch", ".", "cat", "(", "[", "train_feat_seq", "+", "train_label_enc", "+", "train_ltrb_target_enc", ",", "test_feat_seq", "+", "test_label_enc", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "feat", "=", "torch", ".", "cat", "(", "[", "train_feat_seq", "+", "train_label_enc", "+", "train_ltrb_target_enc", ",", "test_feat_seq", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "pos", "=", "torch", ".", "cat", "(", "[", "train_pos", ",", "test_pos", "]", ",", "dim", "=", "0", ")", "\n", "\n", "output_embed", ",", "enc_mem", "=", "self", ".", "transformer", "(", "feat", ",", "mask", "=", "None", ",", "query_embed", "=", "self", ".", "query_embed_fg_decoder", ".", "weight", ",", "pos_embed", "=", "pos", ")", "\n", "\n", "enc_opt", "=", "enc_mem", "[", "-", "h", "*", "w", ":", "]", ".", "transpose", "(", "0", ",", "1", ")", "\n", "dec_opt", "=", "output_embed", ".", "squeeze", "(", "0", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "return", "dec_opt", ".", "reshape", "(", "test_feat", ".", "shape", "[", "1", "]", ",", "-", "1", ",", "1", ",", "1", ")", ",", "enc_opt", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "reshape", "(", "test_feat", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.FilterPredictor.predict_cls_bbreg_filters_parallel": [[92, 151], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "filter_predictor.FilterPredictor.get_positional_encoding", "filter_predictor.FilterPredictor.get_positional_encoding", "torch.cat.permute().flatten().permute", "torch.cat.permute().flatten().permute", "torch.cat.permute().flatten().permute", "torch.cat.permute().flatten().permute", "torch.cat.permute().flatten().permute().unsqueeze", "torch.cat.permute().flatten().permute().unsqueeze", "torch.cat.permute().flatten", "torch.cat.permute().flatten", "test_pos.permute().flatten().permute.permute().flatten().permute.permute().flatten().permute", "train_pos.permute().flatten().permute.permute().flatten().permute.permute().flatten().permute", "filter_predictor.FilterPredictor.query_embed_fg.weight.reshape", "filter_predictor.FilterPredictor.box_encoding().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.zeros().bool", "torch.zeros().bool", "torch.zeros().bool", "torch.zeros().bool", "src_key_padding_mask.bool().to.bool().to.bool().to", "filter_predictor.FilterPredictor.transformer", "enc_mem[].transpose().permute().reshape", "output_embed.squeeze().transpose().reshape", "enc_opt[].unsqueeze", "enc_opt[].unsqueeze", "dec_opt[].unsqueeze", "dec_opt[].unsqueeze", "train_feat.unsqueeze.unsqueeze.dim", "train_feat.unsqueeze.unsqueeze.unsqueeze", "test_feat.unsqueeze.unsqueeze.dim", "test_feat.unsqueeze.unsqueeze.unsqueeze", "train_ltrb_target.unsqueeze.unsqueeze.dim", "train_ltrb_target.unsqueeze.unsqueeze.unsqueeze", "filter_predictor.FilterPredictor.query_embed_test.weight.reshape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.permute().flatten", "torch.cat.permute().flatten", "torch.cat.permute().flatten", "torch.cat.permute().flatten", "torch.cat.permute().flatten().permute", "torch.cat.permute().flatten().permute", "torch.cat.permute", "torch.cat.permute", "test_pos.permute().flatten().permute.permute().flatten().permute.permute().flatten", "train_pos.permute().flatten().permute.permute().flatten().permute.permute().flatten", "filter_predictor.FilterPredictor.box_encoding", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "src_key_padding_mask.bool().to.bool().to.bool", "enc_mem[].transpose().permute", "output_embed.squeeze().transpose", "torch.cat.permute", "torch.cat.permute", "torch.cat.permute", "torch.cat.permute", "torch.cat.permute().flatten", "torch.cat.permute().flatten", "test_pos.permute().flatten().permute.permute().flatten().permute.permute", "train_pos.permute().flatten().permute.permute().flatten().permute.permute", "enc_mem[].transpose", "output_embed.squeeze", "torch.cat.permute", "torch.cat.permute"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.FilterPredictor.get_positional_encoding", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.FilterPredictor.get_positional_encoding", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "predict_cls_bbreg_filters_parallel", "(", "self", ",", "train_feat", ",", "test_feat", ",", "train_label", ",", "num_gth_frames", ",", "train_ltrb_target", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# train_label size guess: Nf_tr, Ns, H, W.", "\n", "        ", "if", "train_feat", ".", "dim", "(", ")", "==", "4", ":", "\n", "            ", "train_feat", "=", "train_feat", ".", "unsqueeze", "(", "1", ")", "\n", "", "if", "test_feat", ".", "dim", "(", ")", "==", "4", ":", "\n", "            ", "test_feat", "=", "test_feat", ".", "unsqueeze", "(", "1", ")", "\n", "", "if", "train_ltrb_target", ".", "dim", "(", ")", "==", "4", ":", "\n", "            ", "train_ltrb_target", "=", "train_ltrb_target", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "", "h", ",", "w", "=", "test_feat", ".", "shape", "[", "-", "2", ":", "]", "\n", "H", ",", "W", "=", "train_feat", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "train_feat_stack", "=", "torch", ".", "cat", "(", "[", "train_feat", ",", "train_feat", "]", ",", "dim", "=", "1", ")", "\n", "test_feat_stack", "=", "torch", ".", "cat", "(", "[", "test_feat", ",", "test_feat", "]", ",", "dim", "=", "1", ")", "\n", "train_label_stack", "=", "torch", ".", "cat", "(", "[", "train_label", ",", "train_label", "]", ",", "dim", "=", "1", ")", "\n", "train_ltrb_target_stack", "=", "torch", ".", "cat", "(", "[", "train_ltrb_target", ",", "train_ltrb_target", "]", ",", "dim", "=", "1", ")", "\n", "\n", "test_pos", "=", "self", ".", "get_positional_encoding", "(", "test_feat", ")", "# Nf_te, Ns, C, H, W", "\n", "train_pos", "=", "self", ".", "get_positional_encoding", "(", "train_feat", ")", "# Nf_tr, Ns, C, H, W", "\n", "\n", "test_feat_seq", "=", "test_feat_stack", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ",", "4", ")", ".", "flatten", "(", "2", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# Nf_te*H*W, Ns, C", "\n", "train_feat_seq", "=", "train_feat_stack", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ",", "4", ")", ".", "flatten", "(", "2", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# Nf_tr*H*W, Ns, C", "\n", "train_label_seq", "=", "train_label_stack", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "flatten", "(", "1", ")", ".", "permute", "(", "1", ",", "0", ")", ".", "unsqueeze", "(", "2", ")", "# Nf_tr*H*W,Ns,1", "\n", "train_ltrb_target_seq_T", "=", "train_ltrb_target_stack", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ",", "4", ")", ".", "flatten", "(", "2", ")", "# Ns,4,Nf_tr*H*W", "\n", "\n", "test_pos", "=", "test_pos", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ",", "4", ")", ".", "flatten", "(", "2", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "train_pos", "=", "train_pos", ".", "permute", "(", "1", ",", "2", ",", "0", ",", "3", ",", "4", ")", ".", "flatten", "(", "2", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "\n", "fg_token", "=", "self", ".", "query_embed_fg", ".", "weight", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "train_label_enc", "=", "fg_token", "*", "train_label_seq", "\n", "\n", "train_ltrb_target_enc", "=", "self", ".", "box_encoding", "(", "train_ltrb_target_seq_T", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "# Nf_tr*H*H,Ns,C", "\n", "\n", "if", "self", ".", "use_test_frame_encoding", ":", "\n", "            ", "test_token", "=", "self", ".", "query_embed_test", ".", "weight", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "test_label_enc", "=", "torch", ".", "ones_like", "(", "test_feat_seq", ")", "*", "test_token", "\n", "feat", "=", "torch", ".", "cat", "(", "[", "train_feat_seq", "+", "train_label_enc", "+", "train_ltrb_target_enc", ",", "test_feat_seq", "+", "test_label_enc", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "feat", "=", "torch", ".", "cat", "(", "[", "train_feat_seq", "+", "train_label_enc", "+", "train_ltrb_target_enc", ",", "test_feat_seq", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "pos", "=", "torch", ".", "cat", "(", "[", "train_pos", ",", "test_pos", "]", ",", "dim", "=", "0", ")", "\n", "\n", "src_key_padding_mask", "=", "torch", ".", "zeros", "(", "feat", ".", "shape", "[", "1", "]", ",", "feat", ".", "shape", "[", "0", "]", ")", ".", "bool", "(", ")", "\n", "src_key_padding_mask", "[", "1", ",", "num_gth_frames", "*", "H", "*", "W", ":", "-", "h", "*", "w", "]", "=", "1.", "\n", "src_key_padding_mask", "=", "src_key_padding_mask", ".", "bool", "(", ")", ".", "to", "(", "feat", ".", "device", ")", "\n", "\n", "output_embed", ",", "enc_mem", "=", "self", ".", "transformer", "(", "feat", ",", "mask", "=", "src_key_padding_mask", ",", "\n", "query_embed", "=", "self", ".", "query_embed_fg_decoder", ".", "weight", ",", "\n", "pos_embed", "=", "pos", ")", "\n", "\n", "enc_opt", "=", "enc_mem", "[", "-", "h", "*", "w", ":", "]", ".", "transpose", "(", "0", ",", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "reshape", "(", "test_feat_stack", ".", "shape", ")", "\n", "dec_opt", "=", "output_embed", ".", "squeeze", "(", "0", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "test_feat_stack", ".", "shape", "[", "1", "]", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "\n", "cls_enc_opt", "=", "enc_opt", "[", ":", ",", "0", "]", ".", "unsqueeze", "(", "1", ")", "\n", "bbreg_enc_opt", "=", "enc_opt", "[", ":", ",", "1", "]", ".", "unsqueeze", "(", "1", ")", "\n", "cls_dec_opt", "=", "dec_opt", "[", "0", "]", ".", "unsqueeze", "(", "0", ")", "\n", "bbreg_dec_opt", "=", "dec_opt", "[", "1", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "return", "cls_dec_opt", ",", "bbreg_dec_opt", ",", "cls_enc_opt", ",", "bbreg_enc_opt", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.MLP": [[6, 17], ["len", "range", "torch.Sequential", "layers.append", "torch.Conv1d", "layers.append", "layers.append", "torch.ReLU", "torch.BatchNorm1d"], "function", ["None"], ["def", "MLP", "(", "channels", ",", "do_bn", "=", "True", ")", ":", "\n", "    ", "n", "=", "len", "(", "channels", ")", "\n", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "n", ")", ":", "\n", "        ", "layers", ".", "append", "(", "\n", "nn", ".", "Conv1d", "(", "channels", "[", "i", "-", "1", "]", ",", "channels", "[", "i", "]", ",", "kernel_size", "=", "1", ",", "bias", "=", "True", ")", ")", "\n", "if", "i", "<", "(", "n", "-", "1", ")", ":", "\n", "            ", "if", "do_bn", ":", "\n", "                ", "layers", ".", "append", "(", "nn", ".", "BatchNorm1d", "(", "channels", "[", "i", "]", ")", ")", "\n", "", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.__init__": [[18, 27], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "filter_predictor", ",", "feature_extractor", ",", "classifier", ",", "bb_regressor", ",", "\n", "separate_filters_for_cls_and_bbreg", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "filter_predictor", "=", "filter_predictor", "\n", "self", ".", "feature_extractor", "=", "feature_extractor", "\n", "self", ".", "classifier", "=", "classifier", "\n", "self", ".", "bb_regressor", "=", "bb_regressor", "\n", "self", ".", "separate_filters_for_cls_and_bbreg", "=", "separate_filters_for_cls_and_bbreg", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.forward": [[28, 52], ["heads.Head.extract_head_feat", "heads.Head.extract_head_feat", "heads.Head.get_filter_and_features", "heads.Head.classifier", "heads.Head.bb_regressor", "train_bb.dim", "train_feat.reshape.reshape.dim", "train_feat.reshape.reshape.reshape", "test_feat.reshape.reshape.dim", "test_feat.reshape.reshape.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.extract_head_feat", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.extract_head_feat", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.get_filter_and_features", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "forward", "(", "self", ",", "train_feat", ",", "test_feat", ",", "train_bb", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "train_bb", ".", "dim", "(", ")", "==", "3", "\n", "\n", "num_sequences", "=", "train_bb", ".", "shape", "[", "1", "]", "\n", "\n", "if", "train_feat", ".", "dim", "(", ")", "==", "5", ":", "\n", "            ", "train_feat", "=", "train_feat", ".", "reshape", "(", "-", "1", ",", "*", "train_feat", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "", "if", "test_feat", ".", "dim", "(", ")", "==", "5", ":", "\n", "            ", "test_feat", "=", "test_feat", ".", "reshape", "(", "-", "1", ",", "*", "test_feat", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n", "# Extract features", "\n", "", "train_feat", "=", "self", ".", "extract_head_feat", "(", "train_feat", ",", "num_sequences", ")", "\n", "test_feat", "=", "self", ".", "extract_head_feat", "(", "test_feat", ",", "num_sequences", ")", "\n", "\n", "# Train filter", "\n", "cls_filter", ",", "breg_filter", ",", "test_feat_enc", "=", "self", ".", "get_filter_and_features", "(", "train_feat", ",", "test_feat", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# fuse encoder and decoder features to one feature map", "\n", "target_scores", "=", "self", ".", "classifier", "(", "test_feat_enc", ",", "cls_filter", ")", "\n", "\n", "# compute the final prediction using the output module", "\n", "bbox_preds", "=", "self", ".", "bb_regressor", "(", "test_feat_enc", ",", "breg_filter", ")", "\n", "\n", "return", "target_scores", ",", "bbox_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.extract_head_feat": [[53, 62], ["heads.Head.feature_extractor", "heads.Head.reshape", "heads.Head.feature_extractor"], "methods", ["None"], ["", "def", "extract_head_feat", "(", "self", ",", "feat", ",", "num_sequences", "=", "None", ")", ":", "\n", "        ", "\"\"\"Extract classification features based on the input backbone features.\"\"\"", "\n", "if", "self", ".", "feature_extractor", "is", "None", ":", "\n", "            ", "return", "feat", "\n", "", "if", "num_sequences", "is", "None", ":", "\n", "            ", "return", "self", ".", "feature_extractor", "(", "feat", ")", "\n", "\n", "", "output", "=", "self", ".", "feature_extractor", "(", "feat", ")", "\n", "return", "output", ".", "reshape", "(", "-", "1", ",", "num_sequences", ",", "*", "output", ".", "shape", "[", "-", "3", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.get_filter_and_features": [[63, 72], ["heads.Head.filter_predictor", "heads.Head.filter_predictor"], "methods", ["None"], ["", "def", "get_filter_and_features", "(", "self", ",", "train_feat", ",", "test_feat", ",", "train_label", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# feat:  Input feature maps. Dims (images_in_sequence, sequences, feat_dim, H, W).", "\n", "        ", "if", "self", ".", "separate_filters_for_cls_and_bbreg", ":", "\n", "            ", "cls_weights", ",", "bbreg_weights", ",", "test_feat_enc", "=", "self", ".", "filter_predictor", "(", "train_feat", ",", "test_feat", ",", "train_label", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "weights", ",", "test_feat_enc", "=", "self", ".", "filter_predictor", "(", "train_feat", ",", "test_feat", ",", "train_label", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "cls_weights", "=", "bbreg_weights", "=", "weights", "\n", "\n", "", "return", "cls_weights", ",", "bbreg_weights", ",", "test_feat_enc", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.Head.get_filter_and_features_in_parallel": [[73, 80], ["heads.Head.filter_predictor.predict_cls_bbreg_filters_parallel"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.filter_predictor.FilterPredictor.predict_cls_bbreg_filters_parallel"], ["", "def", "get_filter_and_features_in_parallel", "(", "self", ",", "train_feat", ",", "test_feat", ",", "train_label", ",", "num_gth_frames", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "cls_weights", ",", "bbreg_weights", ",", "cls_test_feat_enc", ",", "bbreg_test_feat_enc", "=", "self", ".", "filter_predictor", ".", "predict_cls_bbreg_filters_parallel", "(", "\n", "train_feat", ",", "test_feat", ",", "train_label", ",", "num_gth_frames", ",", "*", "args", ",", "**", "kwargs", "\n", ")", "\n", "\n", "return", "cls_weights", ",", "bbreg_weights", ",", "cls_test_feat_enc", ",", "bbreg_test_feat_enc", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.LinearFilterClassifier.__init__": [[83, 90], ["torch.Module.__init__", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_channels", ",", "project_filter", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_channels", "=", "num_channels", "\n", "self", ".", "project_filter", "=", "project_filter", "\n", "\n", "if", "project_filter", ":", "\n", "            ", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "self", ".", "num_channels", ",", "self", ".", "num_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.LinearFilterClassifier.forward": [[91, 97], ["ltr.apply_filter", "heads.LinearFilterClassifier.linear().reshape", "heads.LinearFilterClassifier.linear", "filter.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter"], ["", "", "def", "forward", "(", "self", ",", "feat", ",", "filter", ")", ":", "\n", "        ", "if", "self", ".", "project_filter", ":", "\n", "            ", "filter_proj", "=", "self", ".", "linear", "(", "filter", ".", "reshape", "(", "-", "1", ",", "self", ".", "num_channels", ")", ")", ".", "reshape", "(", "filter", ".", "shape", ")", "\n", "", "else", ":", "\n", "            ", "filter_proj", "=", "filter", "\n", "", "return", "filter_layer", ".", "apply_filter", "(", "feat", ",", "filter_proj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.DenseBoxRegressor.__init__": [[100, 116], ["torch.Module.__init__", "layers.extend", "layers.extend", "layers.extend", "layers.extend", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Linear", "torch.Linear", "heads.conv_layer", "heads.conv_layer", "heads.conv_layer", "heads.conv_layer"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.conv_layer", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.conv_layer", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.conv_layer", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.conv_layer"], ["    ", "def", "__init__", "(", "self", ",", "num_channels", ",", "project_filter", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_channels", "=", "num_channels", "\n", "self", ".", "project_filter", "=", "project_filter", "\n", "\n", "if", "self", ".", "project_filter", ":", "\n", "            ", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "self", ".", "num_channels", ",", "self", ".", "num_channels", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "extend", "(", "conv_layer", "(", "num_channels", ",", "num_channels", ")", ")", "\n", "layers", ".", "extend", "(", "conv_layer", "(", "num_channels", ",", "num_channels", ")", ")", "\n", "layers", ".", "extend", "(", "conv_layer", "(", "num_channels", ",", "num_channels", ")", ")", "\n", "layers", ".", "extend", "(", "conv_layer", "(", "num_channels", ",", "num_channels", ")", ")", "\n", "self", ".", "tower", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n", "self", ".", "bbreg_layer", "=", "nn", ".", "Conv2d", "(", "num_channels", ",", "4", ",", "kernel_size", "=", "3", ",", "dilation", "=", "1", ",", "padding", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.DenseBoxRegressor.forward": [[117, 132], ["ltr.apply_filter", "heads.DenseBoxRegressor.tower", "torch.exp().unsqueeze", "torch.exp().unsqueeze", "torch.exp().unsqueeze", "torch.exp().unsqueeze", "heads.DenseBoxRegressor.linear().reshape", "ltr.apply_filter.unsqueeze", "feats_att.reshape", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "heads.DenseBoxRegressor.linear", "heads.DenseBoxRegressor.bbreg_layer", "filter.reshape"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.filter.apply_filter"], ["", "def", "forward", "(", "self", ",", "feat", ",", "filter", ")", ":", "\n", "        ", "nf", ",", "ns", ",", "c", ",", "h", ",", "w", "=", "feat", ".", "shape", "\n", "\n", "if", "self", ".", "project_filter", ":", "\n", "            ", "filter_proj", "=", "self", ".", "linear", "(", "filter", ".", "reshape", "(", "ns", ",", "c", ")", ")", ".", "reshape", "(", "ns", ",", "c", ",", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "filter_proj", "=", "filter", "\n", "\n", "", "attention", "=", "filter_layer", ".", "apply_filter", "(", "feat", ",", "filter_proj", ")", "# (nf, ns, h, w)", "\n", "feats_att", "=", "attention", ".", "unsqueeze", "(", "2", ")", "*", "feat", "# (nf, ns, c, h, w)", "\n", "\n", "feats_tower", "=", "self", ".", "tower", "(", "feats_att", ".", "reshape", "(", "-", "1", ",", "self", ".", "num_channels", ",", "feat", ".", "shape", "[", "-", "2", "]", ",", "feat", ".", "shape", "[", "-", "1", "]", ")", ")", "# (nf*ns, c, h, w)", "\n", "\n", "ltrb", "=", "torch", ".", "exp", "(", "self", ".", "bbreg_layer", "(", "feats_tower", ")", ")", ".", "unsqueeze", "(", "0", ")", "# (nf*ns, 4, h, w)", "\n", "return", "ltrb", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.heads.conv_layer": [[6, 13], ["torch.Conv2d", "torch.GroupNorm", "torch.ReLU"], "function", ["None"], ["def", "conv_layer", "(", "inplanes", ",", "outplanes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "layers", "=", "[", "\n", "nn", ".", "Conv2d", "(", "inplanes", ",", "outplanes", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", ")", ",", "\n", "nn", ".", "GroupNorm", "(", "1", ",", "outplanes", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "]", "\n", "return", "layers", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderInstance.__init__": [[14, 27], ["torch.nn.Module.__init__", "transformer.TransformerDecoderLayer", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "transformer.TransformerDecoder", "transformer.TransformerDecoderInstance._reset_parameters"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.Transformer._reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "d_model", "=", "512", ",", "nhead", "=", "8", ",", "num_decoder_layers", "=", "6", ",", "dim_feedforward", "=", "2048", ",", "\n", "dropout", "=", "0.1", ",", "activation", "=", "\"relu\"", ",", "normalize_before", "=", "False", ",", "return_intermediate_dec", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "decoder_layer", "=", "TransformerDecoderLayer", "(", "d_model", ",", "nhead", ",", "dim_feedforward", ",", "dropout", ",", "activation", ",", "normalize_before", ")", "\n", "decoder_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "decoder", "=", "TransformerDecoder", "(", "decoder_layer", ",", "num_decoder_layers", ",", "decoder_norm", ",", "\n", "return_intermediate", "=", "return_intermediate_dec", ")", "\n", "\n", "self", ".", "_reset_parameters", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "nhead", "=", "nhead", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderInstance._reset_parameters": [[28, 32], ["transformer.TransformerDecoderInstance.parameters", "p.dim", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "_reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderInstance.forward": [[33, 40], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "transformer.TransformerDecoderInstance.decoder", "transformer.TransformerDecoderInstance.transpose", "query_embed.unsqueeze().repeat.unsqueeze().repeat.dim", "query_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "query_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "", "", "def", "forward", "(", "self", ",", "src", ",", "mask", ",", "query_embed", ",", "pos_embed", ")", ":", "\n", "        ", "if", "query_embed", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "query_embed", "=", "query_embed", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "src", ".", "shape", "[", "1", "]", ",", "1", ")", "\n", "\n", "", "tgt", "=", "torch", ".", "zeros_like", "(", "query_embed", ")", "\n", "hs", "=", "self", ".", "decoder", "(", "tgt", ",", "src", ",", "memory_key_padding_mask", "=", "mask", ",", "pos", "=", "pos_embed", ",", "query_pos", "=", "query_embed", ")", "\n", "return", "hs", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerEncoderInstance.__init__": [[43, 55], ["torch.nn.Module.__init__", "transformer.TransformerEncoderLayer", "transformer.TransformerEncoder", "transformer.TransformerEncoderInstance._reset_parameters", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.Transformer._reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "d_model", "=", "512", ",", "nhead", "=", "8", ",", "num_encoder_layers", "=", "6", ",", "dim_feedforward", "=", "2048", ",", "\n", "dropout", "=", "0.1", ",", "activation", "=", "\"relu\"", ",", "normalize_before", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "encoder_layer", "=", "TransformerEncoderLayer", "(", "d_model", ",", "nhead", ",", "dim_feedforward", ",", "dropout", ",", "activation", ",", "normalize_before", ")", "\n", "encoder_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "if", "normalize_before", "else", "None", "\n", "self", ".", "encoder", "=", "TransformerEncoder", "(", "encoder_layer", ",", "num_encoder_layers", ",", "encoder_norm", ")", "\n", "\n", "self", ".", "_reset_parameters", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "nhead", "=", "nhead", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerEncoderInstance._reset_parameters": [[56, 60], ["transformer.TransformerEncoderInstance.parameters", "p.dim", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "_reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerEncoderInstance.forward": [[61, 64], ["transformer.TransformerEncoderInstance.encoder"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "src", ",", "mask", ",", "pos_embed", ")", ":", "\n", "        ", "memory", "=", "self", ".", "encoder", "(", "src", ",", "src_key_padding_mask", "=", "mask", ",", "pos", "=", "pos_embed", ")", "\n", "return", "memory", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.Transformer.__init__": [[67, 84], ["torch.nn.Module.__init__", "transformer.TransformerEncoderLayer", "transformer.TransformerEncoder", "transformer.TransformerDecoderLayer", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "transformer.TransformerDecoder", "transformer.Transformer._reset_parameters", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.Transformer._reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "d_model", "=", "512", ",", "nhead", "=", "8", ",", "num_encoder_layers", "=", "6", ",", "num_decoder_layers", "=", "6", ",", "dim_feedforward", "=", "2048", ",", "\n", "dropout", "=", "0.1", ",", "activation", "=", "\"relu\"", ",", "normalize_before", "=", "False", ",", "return_intermediate_dec", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "encoder_layer", "=", "TransformerEncoderLayer", "(", "d_model", ",", "nhead", ",", "dim_feedforward", ",", "dropout", ",", "activation", ",", "normalize_before", ")", "\n", "encoder_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "if", "normalize_before", "else", "None", "\n", "self", ".", "encoder", "=", "TransformerEncoder", "(", "encoder_layer", ",", "num_encoder_layers", ",", "encoder_norm", ")", "\n", "\n", "decoder_layer", "=", "TransformerDecoderLayer", "(", "d_model", ",", "nhead", ",", "dim_feedforward", ",", "dropout", ",", "activation", ",", "normalize_before", ")", "\n", "decoder_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "decoder", "=", "TransformerDecoder", "(", "decoder_layer", ",", "num_decoder_layers", ",", "decoder_norm", ",", "\n", "return_intermediate", "=", "return_intermediate_dec", ")", "\n", "\n", "self", ".", "_reset_parameters", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "nhead", "=", "nhead", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.Transformer._reset_parameters": [[85, 89], ["transformer.Transformer.parameters", "p.dim", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "_reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.Transformer.forward": [[90, 97], ["query_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "transformer.Transformer.encoder", "transformer.Transformer.decoder", "transformer.Transformer.transpose", "query_embed.unsqueeze().repeat.unsqueeze().repeat.unsqueeze"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "src", ",", "mask", ",", "query_embed", ",", "pos_embed", ")", ":", "\n", "        ", "query_embed", "=", "query_embed", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "src", ".", "shape", "[", "1", "]", ",", "1", ")", "\n", "\n", "tgt", "=", "torch", ".", "zeros_like", "(", "query_embed", ")", "\n", "memory", "=", "self", ".", "encoder", "(", "src", ",", "src_key_padding_mask", "=", "mask", ",", "pos", "=", "pos_embed", ")", "\n", "hs", "=", "self", ".", "decoder", "(", "tgt", ",", "memory", ",", "memory_key_padding_mask", "=", "mask", ",", "pos", "=", "pos_embed", ",", "query_pos", "=", "query_embed", ")", "\n", "return", "hs", ".", "transpose", "(", "1", ",", "2", ")", ",", "memory", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerEncoder.__init__": [[100, 105], ["torch.nn.Module.__init__", "transformer._get_clones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer._get_clones"], ["    ", "def", "__init__", "(", "self", ",", "encoder_layer", ",", "num_layers", ",", "norm", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "_get_clones", "(", "encoder_layer", ",", "num_layers", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "norm", "=", "norm", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerEncoder.forward": [[106, 116], ["layer", "transformer.TransformerEncoder.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ",", "mask", "=", "None", ",", "src_key_padding_mask", "=", "None", ",", "pos", "=", "None", ")", ":", "\n", "        ", "output", "=", "src", "\n", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "output", "=", "layer", "(", "output", ",", "src_mask", "=", "mask", ",", "src_key_padding_mask", "=", "src_key_padding_mask", ",", "pos", "=", "pos", ")", "\n", "\n", "", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "output", "=", "self", ".", "norm", "(", "output", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoder.__init__": [[120, 126], ["torch.nn.Module.__init__", "transformer._get_clones"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer._get_clones"], ["    ", "def", "__init__", "(", "self", ",", "decoder_layer", ",", "num_layers", ",", "norm", "=", "None", ",", "return_intermediate", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "_get_clones", "(", "decoder_layer", ",", "num_layers", ")", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "norm", "=", "norm", "\n", "self", ".", "return_intermediate", "=", "return_intermediate", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoder.forward": [[127, 150], ["transformer.TransformerDecoder.unsqueeze", "layer", "transformer.TransformerDecoder.norm", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "intermediate.append", "intermediate.pop", "intermediate.append", "transformer.TransformerDecoder.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory", ",", "tgt_mask", "=", "None", ",", "memory_mask", "=", "None", ",", "tgt_key_padding_mask", "=", "None", ",", "\n", "memory_key_padding_mask", "=", "None", ",", "pos", "=", "None", ",", "query_pos", "=", "None", ")", ":", "\n", "        ", "output", "=", "tgt", "\n", "\n", "intermediate", "=", "[", "]", "\n", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "output", "=", "layer", "(", "output", ",", "memory", ",", "tgt_mask", "=", "tgt_mask", ",", "memory_mask", "=", "memory_mask", ",", "pos", "=", "pos", ",", "query_pos", "=", "query_pos", ",", "\n", "tgt_key_padding_mask", "=", "tgt_key_padding_mask", ",", "memory_key_padding_mask", "=", "memory_key_padding_mask", ")", "\n", "\n", "if", "self", ".", "return_intermediate", ":", "\n", "                ", "intermediate", ".", "append", "(", "self", ".", "norm", "(", "output", ")", ")", "\n", "\n", "", "", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "output", "=", "self", ".", "norm", "(", "output", ")", "\n", "if", "self", ".", "return_intermediate", ":", "\n", "                ", "intermediate", ".", "pop", "(", ")", "\n", "intermediate", ".", "append", "(", "output", ")", "\n", "\n", "", "", "if", "self", ".", "return_intermediate", ":", "\n", "            ", "return", "torch", ".", "stack", "(", "intermediate", ")", "\n", "\n", "", "return", "output", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerEncoderLayer.__init__": [[154, 169], ["torch.nn.Module.__init__", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "transformer._get_activation_fn"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer._get_activation_fn"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "nhead", ",", "dim_feedforward", "=", "2048", ",", "dropout", "=", "0.1", ",", "activation", "=", "\"relu\"", ",", "normalize_before", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "nn", ".", "MultiheadAttention", "(", "d_model", ",", "nhead", ",", "dropout", "=", "dropout", ")", "\n", "# Implementation of Feedforward model", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "d_model", ",", "dim_feedforward", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "dim_feedforward", ",", "d_model", ")", "\n", "\n", "self", ".", "norm1", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "norm2", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "activation", "=", "_get_activation_fn", "(", "activation", ")", "\n", "self", ".", "normalize_before", "=", "normalize_before", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerEncoderLayer.with_pos_embed": [[170, 172], ["None"], "methods", ["None"], ["", "def", "with_pos_embed", "(", "self", ",", "tensor", ",", "pos", ")", ":", "\n", "        ", "return", "tensor", "if", "pos", "is", "None", "else", "tensor", "+", "pos", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerEncoderLayer.forward_post": [[173, 182], ["transformer.TransformerEncoderLayer.with_pos_embed", "transformer.TransformerEncoderLayer.norm1", "transformer.TransformerEncoderLayer.linear2", "transformer.TransformerEncoderLayer.norm2", "transformer.TransformerEncoderLayer.self_attn", "transformer.TransformerEncoderLayer.dropout1", "transformer.TransformerEncoderLayer.dropout", "transformer.TransformerEncoderLayer.dropout2", "transformer.TransformerEncoderLayer.activation", "transformer.TransformerEncoderLayer.linear1"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.with_pos_embed"], ["", "def", "forward_post", "(", "self", ",", "src", ",", "src_mask", "=", "None", ",", "src_key_padding_mask", "=", "None", ",", "pos", "=", "None", ")", ":", "\n", "        ", "q", "=", "k", "=", "self", ".", "with_pos_embed", "(", "src", ",", "pos", ")", "\n", "src2", "=", "self", ".", "self_attn", "(", "q", ",", "k", ",", "value", "=", "src", ",", "attn_mask", "=", "src_mask", ",", "key_padding_mask", "=", "src_key_padding_mask", ")", "[", "0", "]", "\n", "src", "=", "src", "+", "self", ".", "dropout1", "(", "src2", ")", "\n", "src", "=", "self", ".", "norm1", "(", "src", ")", "\n", "src2", "=", "self", ".", "linear2", "(", "self", ".", "dropout", "(", "self", ".", "activation", "(", "self", ".", "linear1", "(", "src", ")", ")", ")", ")", "\n", "src", "=", "src", "+", "self", ".", "dropout2", "(", "src2", ")", "\n", "src", "=", "self", ".", "norm2", "(", "src", ")", "\n", "return", "src", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerEncoderLayer.forward_pre": [[183, 192], ["transformer.TransformerEncoderLayer.norm1", "transformer.TransformerEncoderLayer.with_pos_embed", "transformer.TransformerEncoderLayer.norm2", "transformer.TransformerEncoderLayer.linear2", "transformer.TransformerEncoderLayer.self_attn", "transformer.TransformerEncoderLayer.dropout1", "transformer.TransformerEncoderLayer.dropout", "transformer.TransformerEncoderLayer.dropout2", "transformer.TransformerEncoderLayer.activation", "transformer.TransformerEncoderLayer.linear1"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.with_pos_embed"], ["", "def", "forward_pre", "(", "self", ",", "src", ",", "src_mask", "=", "None", ",", "src_key_padding_mask", "=", "None", ",", "pos", "=", "None", ")", ":", "\n", "        ", "src2", "=", "self", ".", "norm1", "(", "src", ")", "\n", "q", "=", "k", "=", "self", ".", "with_pos_embed", "(", "src2", ",", "pos", ")", "\n", "src2", "=", "self", ".", "self_attn", "(", "q", ",", "k", ",", "value", "=", "src2", ",", "attn_mask", "=", "src_mask", ",", "key_padding_mask", "=", "src_key_padding_mask", ")", "[", "0", "]", "\n", "src", "=", "src", "+", "self", ".", "dropout1", "(", "src2", ")", "\n", "src2", "=", "self", ".", "norm2", "(", "src", ")", "\n", "src2", "=", "self", ".", "linear2", "(", "self", ".", "dropout", "(", "self", ".", "activation", "(", "self", ".", "linear1", "(", "src2", ")", ")", ")", ")", "\n", "src", "=", "src", "+", "self", ".", "dropout2", "(", "src2", ")", "\n", "return", "src", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerEncoderLayer.forward": [[193, 197], ["transformer.TransformerEncoderLayer.forward_post", "transformer.TransformerEncoderLayer.forward_pre"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.forward_post", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.forward_pre"], ["", "def", "forward", "(", "self", ",", "src", ",", "src_mask", "=", "None", ",", "src_key_padding_mask", "=", "None", ",", "pos", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "normalize_before", ":", "\n", "            ", "return", "self", ".", "forward_pre", "(", "src", ",", "src_mask", ",", "src_key_padding_mask", ",", "pos", ")", "\n", "", "return", "self", ".", "forward_post", "(", "src", ",", "src_mask", ",", "src_key_padding_mask", ",", "pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.__init__": [[201, 220], ["torch.nn.Module.__init__", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "torch.nn.MultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "transformer._get_activation_fn"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer._get_activation_fn"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "nhead", ",", "dim_feedforward", "=", "2048", ",", "dropout", "=", "0.1", ",", "\n", "activation", "=", "\"relu\"", ",", "normalize_before", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "nn", ".", "MultiheadAttention", "(", "d_model", ",", "nhead", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "multihead_attn", "=", "nn", ".", "MultiheadAttention", "(", "d_model", ",", "nhead", ",", "dropout", "=", "dropout", ")", "\n", "# Implementation of Feedforward model", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "d_model", ",", "dim_feedforward", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "dim_feedforward", ",", "d_model", ")", "\n", "\n", "self", ".", "norm1", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "norm2", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "norm3", "=", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout1", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout2", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout3", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "activation", "=", "_get_activation_fn", "(", "activation", ")", "\n", "self", ".", "normalize_before", "=", "normalize_before", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.with_pos_embed": [[221, 223], ["None"], "methods", ["None"], ["", "def", "with_pos_embed", "(", "self", ",", "tensor", ",", "pos", "=", "None", ")", ":", "\n", "        ", "return", "tensor", "if", "pos", "is", "None", "else", "tensor", "+", "pos", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.forward_post": [[224, 239], ["transformer.TransformerDecoderLayer.with_pos_embed", "transformer.TransformerDecoderLayer.norm1", "transformer.TransformerDecoderLayer.norm2", "transformer.TransformerDecoderLayer.linear2", "transformer.TransformerDecoderLayer.norm3", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.dropout1", "transformer.TransformerDecoderLayer.multihead_attn", "transformer.TransformerDecoderLayer.dropout2", "transformer.TransformerDecoderLayer.dropout", "transformer.TransformerDecoderLayer.dropout3", "transformer.TransformerDecoderLayer.activation", "transformer.TransformerDecoderLayer.with_pos_embed", "transformer.TransformerDecoderLayer.with_pos_embed", "transformer.TransformerDecoderLayer.linear1"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.with_pos_embed", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.with_pos_embed", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.with_pos_embed"], ["", "def", "forward_post", "(", "self", ",", "tgt", ",", "memory", ",", "tgt_mask", "=", "None", ",", "memory_mask", "=", "None", ",", "tgt_key_padding_mask", "=", "None", ",", "\n", "memory_key_padding_mask", "=", "None", ",", "pos", "=", "None", ",", "query_pos", "=", "None", ")", ":", "\n", "        ", "q", "=", "k", "=", "self", ".", "with_pos_embed", "(", "tgt", ",", "query_pos", ")", "\n", "tgt2", "=", "self", ".", "self_attn", "(", "q", ",", "k", ",", "value", "=", "tgt", ",", "attn_mask", "=", "tgt_mask", ",", "\n", "key_padding_mask", "=", "tgt_key_padding_mask", ")", "[", "0", "]", "\n", "tgt", "=", "tgt", "+", "self", ".", "dropout1", "(", "tgt2", ")", "\n", "tgt", "=", "self", ".", "norm1", "(", "tgt", ")", "\n", "tgt2", "=", "self", ".", "multihead_attn", "(", "query", "=", "self", ".", "with_pos_embed", "(", "tgt", ",", "query_pos", ")", ",", "key", "=", "self", ".", "with_pos_embed", "(", "memory", ",", "pos", ")", ",", "\n", "value", "=", "memory", ",", "attn_mask", "=", "memory_mask", ",", "key_padding_mask", "=", "memory_key_padding_mask", ")", "[", "0", "]", "\n", "tgt", "=", "tgt", "+", "self", ".", "dropout2", "(", "tgt2", ")", "\n", "tgt", "=", "self", ".", "norm2", "(", "tgt", ")", "\n", "tgt2", "=", "self", ".", "linear2", "(", "self", ".", "dropout", "(", "self", ".", "activation", "(", "self", ".", "linear1", "(", "tgt", ")", ")", ")", ")", "\n", "tgt", "=", "tgt", "+", "self", ".", "dropout3", "(", "tgt2", ")", "\n", "tgt", "=", "self", ".", "norm3", "(", "tgt", ")", "\n", "return", "tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.forward_pre": [[240, 255], ["transformer.TransformerDecoderLayer.norm1", "transformer.TransformerDecoderLayer.with_pos_embed", "transformer.TransformerDecoderLayer.norm2", "transformer.TransformerDecoderLayer.norm3", "transformer.TransformerDecoderLayer.linear2", "transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.dropout1", "transformer.TransformerDecoderLayer.multihead_attn", "transformer.TransformerDecoderLayer.dropout2", "transformer.TransformerDecoderLayer.dropout", "transformer.TransformerDecoderLayer.dropout3", "transformer.TransformerDecoderLayer.activation", "transformer.TransformerDecoderLayer.with_pos_embed", "transformer.TransformerDecoderLayer.with_pos_embed", "transformer.TransformerDecoderLayer.linear1"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.with_pos_embed", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.with_pos_embed", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.with_pos_embed"], ["", "def", "forward_pre", "(", "self", ",", "tgt", ",", "memory", ",", "tgt_mask", "=", "None", ",", "memory_mask", "=", "None", ",", "tgt_key_padding_mask", "=", "None", ",", "\n", "memory_key_padding_mask", "=", "None", ",", "pos", "=", "None", ",", "query_pos", "=", "None", ")", ":", "\n", "        ", "tgt2", "=", "self", ".", "norm1", "(", "tgt", ")", "\n", "q", "=", "k", "=", "self", ".", "with_pos_embed", "(", "tgt2", ",", "query_pos", ")", "\n", "tgt2", "=", "self", ".", "self_attn", "(", "q", ",", "k", ",", "value", "=", "tgt2", ",", "attn_mask", "=", "tgt_mask", ",", "\n", "key_padding_mask", "=", "tgt_key_padding_mask", ")", "[", "0", "]", "\n", "tgt", "=", "tgt", "+", "self", ".", "dropout1", "(", "tgt2", ")", "\n", "tgt2", "=", "self", ".", "norm2", "(", "tgt", ")", "\n", "tgt2", "=", "self", ".", "multihead_attn", "(", "query", "=", "self", ".", "with_pos_embed", "(", "tgt2", ",", "query_pos", ")", ",", "key", "=", "self", ".", "with_pos_embed", "(", "memory", ",", "pos", ")", ",", "\n", "value", "=", "memory", ",", "attn_mask", "=", "memory_mask", ",", "key_padding_mask", "=", "memory_key_padding_mask", ")", "[", "0", "]", "\n", "tgt", "=", "tgt", "+", "self", ".", "dropout2", "(", "tgt2", ")", "\n", "tgt2", "=", "self", ".", "norm3", "(", "tgt", ")", "\n", "tgt2", "=", "self", ".", "linear2", "(", "self", ".", "dropout", "(", "self", ".", "activation", "(", "self", ".", "linear1", "(", "tgt2", ")", ")", ")", ")", "\n", "tgt", "=", "tgt", "+", "self", ".", "dropout3", "(", "tgt2", ")", "\n", "return", "tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.forward": [[256, 263], ["transformer.TransformerDecoderLayer.forward_post", "transformer.TransformerDecoderLayer.forward_pre"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.forward_post", "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.TransformerDecoderLayer.forward_pre"], ["", "def", "forward", "(", "self", ",", "tgt", ",", "memory", ",", "tgt_mask", "=", "None", ",", "memory_mask", "=", "None", ",", "tgt_key_padding_mask", "=", "None", ",", "\n", "memory_key_padding_mask", "=", "None", ",", "pos", "=", "None", ",", "query_pos", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "normalize_before", ":", "\n", "            ", "return", "self", ".", "forward_pre", "(", "tgt", ",", "memory", ",", "tgt_mask", ",", "memory_mask", ",", "\n", "tgt_key_padding_mask", ",", "memory_key_padding_mask", ",", "pos", ",", "query_pos", ")", "\n", "", "return", "self", ".", "forward_post", "(", "tgt", ",", "memory", ",", "tgt_mask", ",", "memory_mask", ",", "\n", "tgt_key_padding_mask", ",", "memory_key_padding_mask", ",", "pos", ",", "query_pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer._get_clones": [[265, 267], ["torch.nn.ModuleList", "copy.deepcopy", "range"], "function", ["None"], ["", "", "def", "_get_clones", "(", "module", ",", "N", ")", ":", "\n", "    ", "return", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "module", ")", "for", "i", "in", "range", "(", "N", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer.build_transformer": [[269, 279], ["transformer.Transformer"], "function", ["None"], ["", "def", "build_transformer", "(", "args", ")", ":", "\n", "    ", "return", "Transformer", "(", "\n", "d_model", "=", "args", ".", "hidden_dim", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "\n", "nhead", "=", "args", ".", "nheads", ",", "\n", "dim_feedforward", "=", "args", ".", "dim_feedforward", ",", "\n", "num_encoder_layers", "=", "args", ".", "enc_layers", ",", "\n", "num_decoder_layers", "=", "args", ".", "dec_layers", ",", "\n", "normalize_before", "=", "args", ".", "pre_norm", ",", "\n", "return_intermediate_dec", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.transformer._get_activation_fn": [[282, 291], ["RuntimeError"], "function", ["None"], ["", "def", "_get_activation_fn", "(", "activation", ")", ":", "\n", "    ", "\"\"\"Return an activation function given a string\"\"\"", "\n", "if", "activation", "==", "\"relu\"", ":", "\n", "        ", "return", "F", ".", "relu", "\n", "", "if", "activation", "==", "\"gelu\"", ":", "\n", "        ", "return", "F", ".", "gelu", "\n", "", "if", "activation", "==", "\"glu\"", ":", "\n", "        ", "return", "F", ".", "glu", "\n", "", "raise", "RuntimeError", "(", "F\"activation should be relu/gelu/glu, not {activation}.\"", ")", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.position_encoding.NerfPositionalEncoding.__init__": [[7, 24], ["torch.nn.Module.__init__", "print", "ValueError", "range", "range"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "depth", "=", "10", ",", "sine_type", "=", "'lin_sine'", ",", "avoid_aliasing", "=", "False", ",", "max_spatial_resolution", "=", "None", ")", ":", "\n", "        ", "'''\n        out_dim = in_dim * depth * 2\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "sine_type", "==", "'lin_sine'", ":", "\n", "            ", "self", ".", "bases", "=", "[", "i", "+", "1", "for", "i", "in", "range", "(", "depth", ")", "]", "\n", "", "elif", "sine_type", "==", "'exp_sine'", ":", "\n", "            ", "self", ".", "bases", "=", "[", "2", "**", "i", "for", "i", "in", "range", "(", "depth", ")", "]", "\n", "", "print", "(", "f'using {sine_type} as positional encoding'", ")", "\n", "\n", "if", "avoid_aliasing", "and", "max_spatial_resolution", "==", "None", ":", "\n", "            ", "raise", "ValueError", "(", "'Please specify the maxima spatial resolution (h, w) of the feature map'", ")", "\n", "", "elif", "avoid_aliasing", ":", "\n", "            ", "self", ".", "factor", "=", "max_spatial_resolution", "/", "depth", "\n", "", "else", ":", "\n", "            ", "self", ".", "factor", "=", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.position_encoding.NerfPositionalEncoding.forward": [[25, 31], ["torch.no_grad", "torch.cat", "torch.isnan().any", "torch.sin", "torch.cos", "torch.isnan"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "out", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "i", "*", "self", ".", "factor", "*", "math", ".", "pi", "*", "inputs", ")", "for", "i", "in", "self", ".", "bases", "]", "+", "\n", "[", "torch", ".", "cos", "(", "i", "*", "self", ".", "factor", "*", "math", ".", "pi", "*", "inputs", ")", "for", "i", "in", "self", ".", "bases", "]", ",", "axis", "=", "-", "1", ")", "\n", "assert", "torch", ".", "isnan", "(", "out", ")", ".", "any", "(", ")", "==", "False", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.position_encoding.PositionEmbeddingSine.__init__": [[38, 45], ["torch.nn.Module.__init__", "position_encoding.NerfPositionalEncoding"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "num_pos_feats", "=", "64", ",", "temperature", "=", "10000", ",", "normalize", "=", "False", ",", "scale", "=", "None", ",", "sine_type", "=", "'lin_sine'", ",", "\n", "avoid_aliazing", "=", "False", ",", "max_spatial_resolution", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_pos_feats", "=", "num_pos_feats", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "sine", "=", "NerfPositionalEncoding", "(", "num_pos_feats", "//", "2", ",", "sine_type", ",", "avoid_aliazing", ",", "max_spatial_resolution", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.transformer.position_encoding.PositionEmbeddingSine.forward": [[46, 57], ["torch.no_grad", "not_mask.cumsum", "not_mask.cumsum", "torch.stack", "position_encoding.PositionEmbeddingSine.sine().permute", "position_encoding.PositionEmbeddingSine.sine"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "forward", "(", "self", ",", "mask", ")", ":", "\n", "        ", "assert", "mask", "is", "not", "None", "\n", "not_mask", "=", "~", "mask", "\n", "y_embed", "=", "not_mask", ".", "cumsum", "(", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "x_embed", "=", "not_mask", ".", "cumsum", "(", "2", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "eps", "=", "1e-6", "\n", "y_embed", "=", "(", "y_embed", "-", "0.5", ")", "/", "(", "y_embed", "[", ":", ",", "-", "1", ":", ",", ":", "]", "+", "eps", ")", "\n", "x_embed", "=", "(", "x_embed", "-", "0.5", ")", "/", "(", "x_embed", "[", ":", ",", ":", ",", "-", "1", ":", "]", "+", "eps", ")", "\n", "pos", "=", "torch", ".", "stack", "(", "[", "x_embed", ",", "y_embed", "]", ",", "dim", "=", "-", "1", ")", "\n", "return", "self", ".", "sine", "(", "pos", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.base.Backbone.__init__": [[10, 21], ["torch.Module.__init__", "isinstance", "frozen_layers.lower", "frozen_layers.lower", "ValueError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "frozen_layers", "=", "(", ")", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "isinstance", "(", "frozen_layers", ",", "str", ")", ":", "\n", "            ", "if", "frozen_layers", ".", "lower", "(", ")", "==", "'none'", ":", "\n", "                ", "frozen_layers", "=", "(", ")", "\n", "", "elif", "frozen_layers", ".", "lower", "(", ")", "!=", "'all'", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown option for frozen layers: \\\"{}\\\". Should be \\\"all\\\", \\\"none\\\" or list of layer names.'", ".", "format", "(", "frozen_layers", ")", ")", "\n", "\n", "", "", "self", ".", "frozen_layers", "=", "frozen_layers", "\n", "self", ".", "_is_frozen_nograd", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.base.Backbone.train": [[23, 31], ["super().train", "base.Backbone._set_frozen_to_eval", "base.Backbone._set_frozen_to_nograd"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.base.Backbone._set_frozen_to_eval", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.base.Backbone._set_frozen_to_nograd"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "train", "(", "mode", ")", "\n", "if", "mode", "==", "True", ":", "\n", "            ", "self", ".", "_set_frozen_to_eval", "(", ")", "\n", "", "if", "not", "self", ".", "_is_frozen_nograd", ":", "\n", "            ", "self", ".", "_set_frozen_to_nograd", "(", ")", "\n", "self", ".", "_is_frozen_nograd", "=", "True", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.base.Backbone._set_frozen_to_eval": [[33, 39], ["isinstance", "base.Backbone.eval", "base.Backbone.frozen_layers.lower", "getattr().eval", "getattr"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval"], ["", "def", "_set_frozen_to_eval", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "frozen_layers", ",", "str", ")", "and", "self", ".", "frozen_layers", ".", "lower", "(", ")", "==", "'all'", ":", "\n", "            ", "self", ".", "eval", "(", ")", "\n", "", "else", ":", "\n", "            ", "for", "layer", "in", "self", ".", "frozen_layers", ":", "\n", "                ", "getattr", "(", "self", ",", "layer", ")", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.base.Backbone._set_frozen_to_nograd": [[41, 49], ["isinstance", "base.Backbone.parameters", "base.Backbone.frozen_layers.lower", "p.requires_grad_", "getattr().parameters", "p.requires_grad_", "getattr"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters"], ["", "", "", "def", "_set_frozen_to_nograd", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ".", "frozen_layers", ",", "str", ")", "and", "self", ".", "frozen_layers", ".", "lower", "(", ")", "==", "'all'", ":", "\n", "            ", "for", "p", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad_", "(", "False", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "layer", "in", "self", ".", "frozen_layers", ":", "\n", "                ", "for", "p", "in", "getattr", "(", "self", ",", "layer", ")", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "requires_grad_", "(", "False", ")", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.h_sigmoid.__init__": [[32, 35], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", "=", "True", ")", ":", "\n", "        ", "super", "(", "h_sigmoid", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.h_sigmoid.forward": [[36, 38], ["torch.relu6", "torch.relu6", "torch.relu6"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "relu6", "(", "x", "+", "3.", ",", "inplace", "=", "self", ".", "inplace", ")", "/", "6.", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.h_swish.__init__": [[41, 44], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inplace", "=", "True", ")", ":", "\n", "        ", "super", "(", "h_swish", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.h_swish.forward": [[45, 48], ["torch.relu6", "torch.relu6", "torch.relu6"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu6", "(", "x", "+", "3.", ",", "self", ".", "inplace", ")", "/", "6.", "\n", "return", "out", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.SqueezeBlock.__init__": [[61, 68], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "mobilenetv3.h_sigmoid"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "exp_size", ",", "divide", "=", "4", ")", ":", "\n", "        ", "super", "(", "SqueezeBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "exp_size", ",", "exp_size", "//", "divide", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "exp_size", "//", "divide", ",", "exp_size", ")", ",", "\n", "h_sigmoid", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.SqueezeBlock.forward": [[70, 78], ["x.size", "torch.avg_pool2d().view", "torch.avg_pool2d().view", "torch.avg_pool2d().view", "mobilenetv3.SqueezeBlock.dense", "out.view.view.view", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch", ",", "channels", ",", "height", ",", "width", "=", "x", ".", "size", "(", ")", "\n", "out", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "[", "height", ",", "width", "]", ")", ".", "view", "(", "batch", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "dense", "(", "out", ")", "\n", "out", "=", "out", ".", "view", "(", "batch", ",", "channels", ",", "1", ",", "1", ")", "\n", "# out = hard_sigmoid(out)", "\n", "\n", "return", "out", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.MobileBlock.__init__": [[81, 112], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "activation", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "mobilenetv3.SqueezeBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "activation"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernal_size", ",", "stride", ",", "nonLinear", ",", "SE", ",", "exp_size", ")", ":", "\n", "        ", "super", "(", "MobileBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "nonLinear", "=", "nonLinear", "\n", "self", ".", "SE", "=", "SE", "\n", "padding", "=", "(", "kernal_size", "-", "1", ")", "//", "2", "\n", "\n", "self", ".", "use_connect", "=", "stride", "==", "1", "and", "in_channels", "==", "out_channels", "\n", "\n", "if", "self", ".", "nonLinear", "==", "\"RE\"", ":", "\n", "            ", "activation", "=", "nn", ".", "ReLU", "\n", "", "else", ":", "\n", "            ", "activation", "=", "h_swish", "\n", "\n", "", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "exp_size", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "exp_size", ")", ",", "\n", "activation", "(", "inplace", "=", "True", ")", "\n", ")", "\n", "self", ".", "depth_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "exp_size", ",", "exp_size", ",", "kernel_size", "=", "kernal_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "groups", "=", "exp_size", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "exp_size", ")", ",", "\n", ")", "\n", "\n", "if", "self", ".", "SE", ":", "\n", "            ", "self", ".", "squeeze_block", "=", "SqueezeBlock", "(", "exp_size", ")", "\n", "\n", "", "self", ".", "point_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "exp_size", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ",", "\n", "activation", "(", "inplace", "=", "True", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.MobileBlock.forward": [[114, 131], ["mobilenetv3.MobileBlock.conv", "mobilenetv3.MobileBlock.depth_conv", "mobilenetv3.MobileBlock.point_conv", "mobilenetv3.MobileBlock.squeeze_block"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.bbreg.atom_iou_net.conv"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# MobileNetV2", "\n", "        ", "out", "=", "self", ".", "conv", "(", "x", ")", "\n", "out", "=", "self", ".", "depth_conv", "(", "out", ")", "\n", "\n", "# Squeeze and Excite", "\n", "if", "self", ".", "SE", ":", "\n", "            ", "out", "=", "self", ".", "squeeze_block", "(", "out", ")", "\n", "\n", "# point-wise conv", "\n", "", "out", "=", "self", ".", "point_conv", "(", "out", ")", "\n", "\n", "# connection", "\n", "if", "self", ".", "use_connect", ":", "\n", "            ", "return", "x", "+", "out", "\n", "", "else", ":", "\n", "            ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.MobileNetV3.__init__": [[134, 256], ["torch.Module.__init__", "mobilenetv3.MobileNetV3.apply", "mobilenetv3._make_divisible", "torch.Sequential", "torch.Sequential", "torch.Sequential", "mobilenetv3.MobileBlock", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "mobilenetv3._make_divisible", "mobilenetv3._make_divisible", "torch.Sequential", "torch.Sequential", "torch.Sequential", "mobilenetv3._make_divisible", "mobilenetv3._make_divisible", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "mobilenetv3.h_swish", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "mobilenetv3.MobileBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "mobilenetv3.h_swish", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "mobilenetv3.h_swish", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "mobilenetv3._make_divisible", "torch.Sequential", "torch.Sequential", "torch.Sequential", "mobilenetv3._make_divisible", "mobilenetv3._make_divisible", "torch.Sequential", "torch.Sequential", "torch.Sequential", "mobilenetv3._make_divisible", "mobilenetv3._make_divisible", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "mobilenetv3.h_swish", "mobilenetv3._make_divisible", "mobilenetv3._make_divisible", "mobilenetv3._make_divisible", "mobilenetv3.MobileNetV3.block.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "mobilenetv3.SqueezeBlock", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "mobilenetv3.h_swish", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "mobilenetv3.h_swish", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "mobilenetv3.MobileBlock"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible"], ["    ", "def", "__init__", "(", "self", ",", "model_mode", "=", "\"LARGE\"", ",", "num_classes", "=", "1000", ",", "multiplier", "=", "1.0", ",", "dropout_rate", "=", "0.0", ",", "output_layers", "=", "[", "'default'", "]", ")", ":", "\n", "        ", "super", "(", "MobileNetV3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "output_layers", "=", "output_layers", "\n", "if", "model_mode", "==", "\"LARGE\"", ":", "\n", "            ", "layers", "=", "[", "\n", "[", "16", ",", "16", ",", "3", ",", "1", ",", "\"RE\"", ",", "False", ",", "16", "]", ",", "\n", "[", "16", ",", "24", ",", "3", ",", "2", ",", "\"RE\"", ",", "False", ",", "64", "]", ",", "\n", "[", "24", ",", "24", ",", "3", ",", "1", ",", "\"RE\"", ",", "False", ",", "72", "]", ",", "\n", "[", "24", ",", "40", ",", "5", ",", "2", ",", "\"RE\"", ",", "True", ",", "72", "]", ",", "\n", "[", "40", ",", "40", ",", "5", ",", "1", ",", "\"RE\"", ",", "True", ",", "120", "]", ",", "\n", "\n", "[", "40", ",", "40", ",", "5", ",", "1", ",", "\"RE\"", ",", "True", ",", "120", "]", ",", "\n", "[", "40", ",", "80", ",", "3", ",", "2", ",", "\"HS\"", ",", "False", ",", "240", "]", ",", "\n", "[", "80", ",", "80", ",", "3", ",", "1", ",", "\"HS\"", ",", "False", ",", "200", "]", ",", "\n", "[", "80", ",", "80", ",", "3", ",", "1", ",", "\"HS\"", ",", "False", ",", "184", "]", ",", "\n", "[", "80", ",", "80", ",", "3", ",", "1", ",", "\"HS\"", ",", "False", ",", "184", "]", ",", "\n", "\n", "[", "80", ",", "112", ",", "3", ",", "1", ",", "\"HS\"", ",", "True", ",", "480", "]", ",", "\n", "[", "112", ",", "112", ",", "3", ",", "1", ",", "\"HS\"", ",", "True", ",", "672", "]", ",", "\n", "[", "112", ",", "160", ",", "5", ",", "1", ",", "\"HS\"", ",", "True", ",", "672", "]", ",", "\n", "[", "160", ",", "160", ",", "5", ",", "2", ",", "\"HS\"", ",", "True", ",", "672", "]", ",", "\n", "[", "160", ",", "160", ",", "5", ",", "1", ",", "\"HS\"", ",", "True", ",", "960", "]", ",", "\n", "]", "\n", "init_conv_out", "=", "_make_divisible", "(", "16", "*", "multiplier", ")", "\n", "self", ".", "init_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "3", ",", "out_channels", "=", "init_conv_out", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "init_conv_out", ")", ",", "\n", "h_swish", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n", "self", ".", "layer1", "=", "MobileBlock", "(", "16", ",", "16", ",", "3", ",", "1", ",", "\"RE\"", ",", "False", ",", "16", ")", "\n", "self", ".", "layer2", "=", "nn", ".", "Sequential", "(", "\n", "MobileBlock", "(", "16", ",", "24", ",", "3", ",", "2", ",", "\"RE\"", ",", "False", ",", "64", ")", ",", "\n", "MobileBlock", "(", "24", ",", "24", ",", "3", ",", "1", ",", "\"RE\"", ",", "False", ",", "72", ")", "\n", ")", "\n", "self", ".", "layer3", "=", "nn", ".", "Sequential", "(", "\n", "MobileBlock", "(", "24", ",", "40", ",", "5", ",", "2", ",", "\"RE\"", ",", "True", ",", "72", ")", ",", "\n", "MobileBlock", "(", "40", ",", "40", ",", "5", ",", "1", ",", "\"RE\"", ",", "True", ",", "120", ")", ",", "\n", "MobileBlock", "(", "40", ",", "40", ",", "5", ",", "1", ",", "\"RE\"", ",", "True", ",", "120", ")", "\n", ")", "\n", "self", ".", "layer4", "=", "nn", ".", "Sequential", "(", "\n", "MobileBlock", "(", "40", ",", "80", ",", "3", ",", "2", ",", "\"HS\"", ",", "False", ",", "240", ")", ",", "\n", "MobileBlock", "(", "80", ",", "80", ",", "3", ",", "1", ",", "\"HS\"", ",", "False", ",", "200", ")", ",", "\n", "MobileBlock", "(", "80", ",", "80", ",", "3", ",", "1", ",", "\"HS\"", ",", "False", ",", "184", ")", ",", "\n", "MobileBlock", "(", "80", ",", "80", ",", "3", ",", "1", ",", "\"HS\"", ",", "False", ",", "184", ")", "\n", ")", "\n", "self", ".", "layer5", "=", "nn", ".", "Sequential", "(", "\n", "MobileBlock", "(", "80", ",", "112", ",", "3", ",", "1", ",", "\"HS\"", ",", "True", ",", "480", ")", ",", "\n", "MobileBlock", "(", "112", ",", "112", ",", "3", ",", "1", ",", "\"HS\"", ",", "True", ",", "672", ")", "\n", ")", "\n", "self", ".", "layer6", "=", "nn", ".", "Sequential", "(", "\n", "MobileBlock", "(", "112", ",", "160", ",", "5", ",", "1", ",", "\"HS\"", ",", "True", ",", "672", ")", ",", "\n", "MobileBlock", "(", "160", ",", "160", ",", "5", ",", "2", ",", "\"HS\"", ",", "True", ",", "672", ")", ",", "\n", "MobileBlock", "(", "160", ",", "160", ",", "5", ",", "1", ",", "\"HS\"", ",", "True", ",", "960", ")", "\n", ")", "\n", "\n", "out_conv1_in", "=", "_make_divisible", "(", "160", "*", "multiplier", ")", "\n", "out_conv1_out", "=", "_make_divisible", "(", "960", "*", "multiplier", ")", "\n", "self", ".", "out_conv1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "out_conv1_in", ",", "out_conv1_out", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_conv1_out", ")", ",", "\n", "h_swish", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n", "\n", "out_conv2_in", "=", "_make_divisible", "(", "960", "*", "multiplier", ")", "\n", "out_conv2_out", "=", "_make_divisible", "(", "1280", "*", "multiplier", ")", "\n", "self", ".", "out_conv2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "out_conv2_in", ",", "out_conv2_out", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "h_swish", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout_rate", ")", ",", "\n", "nn", ".", "Conv2d", "(", "out_conv2_out", ",", "self", ".", "num_classes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", ")", "\n", "\n", "", "elif", "model_mode", "==", "\"SMALL\"", ":", "\n", "            ", "layers", "=", "[", "\n", "[", "16", ",", "16", ",", "3", ",", "2", ",", "\"RE\"", ",", "True", ",", "16", "]", ",", "\n", "[", "16", ",", "24", ",", "3", ",", "2", ",", "\"RE\"", ",", "False", ",", "72", "]", ",", "\n", "[", "24", ",", "24", ",", "3", ",", "1", ",", "\"RE\"", ",", "False", ",", "88", "]", ",", "\n", "[", "24", ",", "40", ",", "5", ",", "2", ",", "\"RE\"", ",", "True", ",", "96", "]", ",", "\n", "[", "40", ",", "40", ",", "5", ",", "1", ",", "\"RE\"", ",", "True", ",", "240", "]", ",", "\n", "[", "40", ",", "40", ",", "5", ",", "1", ",", "\"RE\"", ",", "True", ",", "240", "]", ",", "\n", "[", "40", ",", "48", ",", "5", ",", "1", ",", "\"HS\"", ",", "True", ",", "120", "]", ",", "\n", "[", "48", ",", "48", ",", "5", ",", "1", ",", "\"HS\"", ",", "True", ",", "144", "]", ",", "\n", "[", "48", ",", "96", ",", "5", ",", "2", ",", "\"HS\"", ",", "True", ",", "288", "]", ",", "\n", "[", "96", ",", "96", ",", "5", ",", "1", ",", "\"HS\"", ",", "True", ",", "576", "]", ",", "\n", "[", "96", ",", "96", ",", "5", ",", "1", ",", "\"HS\"", ",", "True", ",", "576", "]", ",", "\n", "]", "\n", "\n", "init_conv_out", "=", "_make_divisible", "(", "16", "*", "multiplier", ")", "\n", "self", ".", "init_conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "3", ",", "out_channels", "=", "init_conv_out", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "init_conv_out", ")", ",", "\n", "h_swish", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n", "\n", "self", ".", "block", "=", "[", "]", "\n", "for", "in_channels", ",", "out_channels", ",", "kernal_size", ",", "stride", ",", "nonlinear", ",", "se", ",", "exp_size", "in", "layers", ":", "\n", "                ", "in_channels", "=", "_make_divisible", "(", "in_channels", "*", "multiplier", ")", "\n", "out_channels", "=", "_make_divisible", "(", "out_channels", "*", "multiplier", ")", "\n", "exp_size", "=", "_make_divisible", "(", "exp_size", "*", "multiplier", ")", "\n", "self", ".", "block", ".", "append", "(", "MobileBlock", "(", "in_channels", ",", "out_channels", ",", "kernal_size", ",", "stride", ",", "nonlinear", ",", "se", ",", "exp_size", ")", ")", "\n", "# self.block = nn.Sequential(*self.block)", "\n", "\n", "", "out_conv1_in", "=", "_make_divisible", "(", "96", "*", "multiplier", ")", "\n", "out_conv1_out", "=", "_make_divisible", "(", "576", "*", "multiplier", ")", "\n", "self", ".", "out_conv1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "out_conv1_in", ",", "out_conv1_out", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "SqueezeBlock", "(", "out_conv1_out", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_conv1_out", ")", ",", "\n", "h_swish", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n", "\n", "out_conv2_in", "=", "_make_divisible", "(", "576", "*", "multiplier", ")", "\n", "out_conv2_out", "=", "_make_divisible", "(", "1280", "*", "multiplier", ")", "\n", "self", ".", "out_conv2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "out_conv2_in", ",", "out_conv2_out", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", "h_swish", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout_rate", ")", ",", "\n", "nn", ".", "Conv2d", "(", "out_conv2_out", ",", "self", ".", "num_classes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", ")", "\n", "\n", "", "self", ".", "apply", "(", "_weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.MobileNetV3._add_output_and_check": [[257, 261], ["len", "len"], "methods", ["None"], ["", "def", "_add_output_and_check", "(", "self", ",", "name", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "        ", "if", "name", "in", "output_layers", ":", "\n", "            ", "outputs", "[", "name", "]", "=", "x", "\n", "", "return", "len", "(", "output_layers", ")", "==", "len", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.MobileNetV3.forward": [[262, 300], ["collections.OrderedDict", "mobilenetv3.MobileNetV3.init_conv", "mobilenetv3.MobileNetV3._add_output_and_check", "mobilenetv3.MobileNetV3.layer1", "mobilenetv3.MobileNetV3._add_output_and_check", "mobilenetv3.MobileNetV3.layer2", "mobilenetv3.MobileNetV3._add_output_and_check", "mobilenetv3.MobileNetV3.layer3", "mobilenetv3.MobileNetV3._add_output_and_check", "mobilenetv3.MobileNetV3.layer4", "mobilenetv3.MobileNetV3._add_output_and_check", "mobilenetv3.MobileNetV3.layer5", "mobilenetv3.MobileNetV3._add_output_and_check", "mobilenetv3.MobileNetV3.layer6", "mobilenetv3.MobileNetV3._add_output_and_check", "mobilenetv3.MobileNetV3.out_conv1", "mobilenetv3.MobileNetV3._add_output_and_check", "mobilenetv3.MobileNetV3.size", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "mobilenetv3.MobileNetV3.out_conv2().view", "mobilenetv3.MobileNetV3.out_conv2", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size"], ["", "def", "forward", "(", "self", ",", "x", ",", "output_layers", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "OrderedDict", "(", ")", "\n", "\n", "if", "output_layers", "is", "None", ":", "\n", "            ", "output_layers", "=", "self", ".", "output_layers", "\n", "\n", "\n", "", "out", "=", "self", ".", "init_conv", "(", "x", ")", "\n", "if", "self", ".", "_add_output_and_check", "(", "'init_conv'", ",", "out", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "#out = self.block(out)", "\n", "", "out", "=", "self", ".", "layer1", "(", "out", ")", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer1'", ",", "out", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "", "out", "=", "self", ".", "layer2", "(", "out", ")", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer2'", ",", "out", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "", "out", "=", "self", ".", "layer3", "(", "out", ")", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer3'", ",", "out", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "", "out", "=", "self", ".", "layer4", "(", "out", ")", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer4'", ",", "out", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "", "out", "=", "self", ".", "layer5", "(", "out", ")", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer5'", ",", "out", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "", "out", "=", "self", ".", "layer6", "(", "out", ")", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer6'", ",", "out", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "", "out", "=", "self", ".", "out_conv1", "(", "out", ")", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer_out'", ",", "out", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "", "batch", ",", "channels", ",", "height", ",", "width", "=", "out", ".", "size", "(", ")", "\n", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "kernel_size", "=", "[", "height", ",", "width", "]", ")", "\n", "out", "=", "self", ".", "out_conv2", "(", "out", ")", ".", "view", "(", "batch", ",", "-", "1", ")", "\n", "if", "len", "(", "output_layers", ")", "==", "1", "and", "output_layers", "[", "0", "]", "==", "'default'", ":", "\n", "            ", "return", "out", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.get_model_parameters": [[7, 15], ["list", "model.parameters", "list", "layer.size"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.tomp.tomp50.parameters", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size"], ["def", "get_model_parameters", "(", "model", ")", ":", "\n", "    ", "total_parameters", "=", "0", "\n", "for", "layer", "in", "list", "(", "model", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "layer_parameter", "=", "1", "\n", "for", "l", "in", "list", "(", "layer", ".", "size", "(", ")", ")", ":", "\n", "            ", "layer_parameter", "*=", "l", "\n", "", "total_parameters", "+=", "layer_parameter", "\n", "", "return", "total_parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._weights_init": [[17, 29], ["isinstance", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "isinstance", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "m.weight.data.fill_", "m.bias.data.zero_", "isinstance", "m.weight.size", "m.weight.data.normal_", "m.bias.data.zero_"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size"], ["", "def", "_weights_init", "(", "m", ")", ":", "\n", "    ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "n", "=", "m", ".", "weight", ".", "size", "(", "1", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3._make_divisible": [[50, 58], ["max", "int"], "function", ["None"], ["", "", "def", "_make_divisible", "(", "v", ",", "divisor", "=", "8", ",", "min_value", "=", "None", ")", ":", "\n", "    ", "if", "min_value", "is", "None", ":", "\n", "        ", "min_value", "=", "divisor", "\n", "", "new_v", "=", "max", "(", "min_value", ",", "int", "(", "v", "+", "divisor", "/", "2", ")", "//", "divisor", "*", "divisor", ")", "\n", "# Make sure that round down does not go down by more than 10%.", "\n", "if", "new_v", "<", "0.9", "*", "v", ":", "\n", "        ", "new_v", "+=", "divisor", "\n", "", "return", "new_v", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.mobilenetv3.mobilenet3": [[301, 318], ["mobilenetv3.MobileNetV3", "print", "torch.load", "torch.load", "torch.load", "MobileNetV3.load_state_dict", "ValueError"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load"], ["", "", "def", "mobilenet3", "(", "output_layers", "=", "None", ",", "path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model with first-layer VGGm features.\n    \"\"\"", "\n", "\n", "if", "output_layers", "is", "None", ":", "\n", "        ", "output_layers", "=", "[", "'default'", "]", "\n", "", "else", ":", "\n", "        ", "for", "l", "in", "output_layers", ":", "\n", "            ", "if", "l", "not", "in", "[", "'init_conv'", ",", "'layer1'", ",", "'layer2'", ",", "'layer3'", ",", "'layer4'", ",", "'layer5'", ",", "'layer6'", ",", "'layer_out'", "]", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown layer: {}'", ".", "format", "(", "l", ")", ")", "\n", "\n", "", "", "", "model", "=", "MobileNetV3", "(", "model_mode", "=", "\"LARGE\"", ",", "num_classes", "=", "100", ",", "multiplier", "=", "1.0", ",", "output_layers", "=", "output_layers", ",", "dropout_rate", "=", "0.8", ")", "\n", "if", "path", "is", "not", "None", ":", "\n", "        ", "print", "(", "path", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "path", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ",", "strict", "=", "False", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.BasicBlock.__init__": [[18, 32], ["torch.Module.__init__", "resnet.conv3x3", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.conv3x3", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "dilation", "=", "1", ",", "use_bn", "=", "True", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "use_bn", "=", "use_bn", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ",", "dilation", "=", "dilation", ")", "\n", "\n", "if", "use_bn", ":", "\n", "            ", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ",", "dilation", "=", "dilation", ")", "\n", "\n", "if", "use_bn", ":", "\n", "            ", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.BasicBlock.forward": [[33, 54], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.relu", "resnet.BasicBlock.bn1", "resnet.BasicBlock.bn2", "resnet.BasicBlock.downsample"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "\n", "if", "self", ".", "use_bn", ":", "\n", "            ", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "\n", "if", "self", ".", "use_bn", ":", "\n", "            ", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.Bottleneck.__init__": [[59, 71], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "4", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.Bottleneck.forward": [[72, 93], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.ResNet.__init__": [[97, 140], ["base.Backbone.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "isinstance", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "isinstance", "isinstance", "max", "max", "max", "Exception", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer"], ["def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "output_layers", ",", "num_classes", "=", "1000", ",", "inplanes", "=", "64", ",", "dilation_factor", "=", "1", ",", "frozen_layers", "=", "(", ")", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "inplanes", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", "frozen_layers", "=", "frozen_layers", ")", "\n", "self", ".", "output_layers", "=", "output_layers", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "inplanes", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "inplanes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "stride", "=", "[", "1", "+", "(", "dilation_factor", "<", "l", ")", "for", "l", "in", "(", "8", ",", "4", ",", "2", ")", "]", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "inplanes", ",", "layers", "[", "0", "]", ",", "dilation", "=", "max", "(", "dilation_factor", "//", "8", ",", "1", ")", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "inplanes", "*", "2", ",", "layers", "[", "1", "]", ",", "stride", "=", "stride", "[", "0", "]", ",", "dilation", "=", "max", "(", "dilation_factor", "//", "4", ",", "1", ")", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "inplanes", "*", "4", ",", "layers", "[", "2", "]", ",", "stride", "=", "stride", "[", "1", "]", ",", "dilation", "=", "max", "(", "dilation_factor", "//", "2", ",", "1", ")", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "inplanes", "*", "8", ",", "layers", "[", "3", "]", ",", "stride", "=", "stride", "[", "2", "]", ",", "dilation", "=", "dilation_factor", ")", "\n", "\n", "out_feature_strides", "=", "{", "'conv1'", ":", "4", ",", "'layer1'", ":", "4", ",", "'layer2'", ":", "4", "*", "stride", "[", "0", "]", ",", "'layer3'", ":", "4", "*", "stride", "[", "0", "]", "*", "stride", "[", "1", "]", ",", "\n", "'layer4'", ":", "4", "*", "stride", "[", "0", "]", "*", "stride", "[", "1", "]", "*", "stride", "[", "2", "]", "}", "\n", "\n", "# TODO better way?", "\n", "if", "isinstance", "(", "self", ".", "layer1", "[", "0", "]", ",", "BasicBlock", ")", ":", "\n", "            ", "out_feature_channels", "=", "{", "'conv1'", ":", "inplanes", ",", "'layer1'", ":", "inplanes", ",", "'layer2'", ":", "inplanes", "*", "2", ",", "'layer3'", ":", "inplanes", "*", "4", ",", "\n", "'layer4'", ":", "inplanes", "*", "8", "}", "\n", "", "elif", "isinstance", "(", "self", ".", "layer1", "[", "0", "]", ",", "Bottleneck", ")", ":", "\n", "            ", "base_num_channels", "=", "4", "*", "inplanes", "\n", "out_feature_channels", "=", "{", "'conv1'", ":", "inplanes", ",", "'layer1'", ":", "base_num_channels", ",", "'layer2'", ":", "base_num_channels", "*", "2", ",", "\n", "'layer3'", ":", "base_num_channels", "*", "4", ",", "'layer4'", ":", "base_num_channels", "*", "8", "}", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'block not supported'", ")", "\n", "\n", "", "self", ".", "_out_feature_strides", "=", "out_feature_strides", "\n", "self", ".", "_out_feature_channels", "=", "out_feature_channels", "\n", "\n", "# self.avgpool = nn.AvgPool2d(7, stride=1)", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "inplanes", "*", "8", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.ResNet.out_feature_strides": [[141, 146], ["None"], "methods", ["None"], ["", "", "", "def", "out_feature_strides", "(", "self", ",", "layer", "=", "None", ")", ":", "\n", "        ", "if", "layer", "is", "None", ":", "\n", "            ", "return", "self", ".", "_out_feature_strides", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_out_feature_strides", "[", "layer", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.ResNet.out_feature_channels": [[147, 152], ["None"], "methods", ["None"], ["", "", "def", "out_feature_channels", "(", "self", ",", "layer", "=", "None", ")", ":", "\n", "        ", "if", "layer", "is", "None", ":", "\n", "            ", "return", "self", ".", "_out_feature_channels", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_out_feature_channels", "[", "layer", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.ResNet._make_layer": [[153, 169], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ",", "dilation", "=", "dilation", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.ResNet._add_output_and_check": [[170, 174], ["len", "len"], "methods", ["None"], ["", "def", "_add_output_and_check", "(", "self", ",", "name", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "        ", "if", "name", "in", "output_layers", ":", "\n", "            ", "outputs", "[", "name", "]", "=", "x", "\n", "", "return", "len", "(", "output_layers", ")", "==", "len", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.ResNet.forward": [[175, 222], ["collections.OrderedDict", "resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet._add_output_and_check", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet._add_output_and_check", "resnet.ResNet.layer2", "resnet.ResNet._add_output_and_check", "resnet.ResNet.layer3", "resnet.ResNet._add_output_and_check", "resnet.ResNet.layer4", "resnet.ResNet._add_output_and_check", "resnet.ResNet.avgpool", "resnet.ResNet.view", "resnet.ResNet.fc", "resnet.ResNet._add_output_and_check", "ValueError", "resnet.ResNet.size", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size"], ["", "def", "forward", "(", "self", ",", "x", ",", "output_layers", "=", "None", ")", ":", "\n", "        ", "\"\"\" Forward pass with input x. The output_layers specify the feature blocks which must be returned \"\"\"", "\n", "outputs", "=", "OrderedDict", "(", ")", "\n", "\n", "if", "output_layers", "is", "None", ":", "\n", "            ", "output_layers", "=", "self", ".", "output_layers", "\n", "\n", "", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'conv1'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer1'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer2'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer3'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer4'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'fc'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "if", "len", "(", "output_layers", ")", "==", "1", "and", "output_layers", "[", "0", "]", "==", "'default'", ":", "\n", "            ", "return", "x", "\n", "\n", "", "raise", "ValueError", "(", "'output_layer is wrong.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.conv3x3": [[9, 13], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.resnet_baby": [[224, 240], ["resnet.ResNet", "ValueError"], "function", ["None"], ["", "", "def", "resnet_baby", "(", "output_layers", "=", "None", ",", "pretrained", "=", "False", ",", "inplanes", "=", "16", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n    \"\"\"", "\n", "\n", "if", "output_layers", "is", "None", ":", "\n", "        ", "output_layers", "=", "[", "'default'", "]", "\n", "", "else", ":", "\n", "        ", "for", "l", "in", "output_layers", ":", "\n", "            ", "if", "l", "not", "in", "[", "'conv1'", ",", "'layer1'", ",", "'layer2'", ",", "'layer3'", ",", "'layer4'", ",", "'fc'", "]", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown layer: {}'", ".", "format", "(", "l", ")", ")", "\n", "\n", "", "", "", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "output_layers", ",", "inplanes", "=", "inplanes", ",", "**", "kwargs", ")", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.resnet18": [[242, 258], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url", "ValueError"], "function", ["None"], ["", "def", "resnet18", "(", "output_layers", "=", "None", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n    \"\"\"", "\n", "\n", "if", "output_layers", "is", "None", ":", "\n", "        ", "output_layers", "=", "[", "'default'", "]", "\n", "", "else", ":", "\n", "        ", "for", "l", "in", "output_layers", ":", "\n", "            ", "if", "l", "not", "in", "[", "'conv1'", ",", "'layer1'", ",", "'layer2'", ",", "'layer3'", ",", "'layer4'", ",", "'fc'", "]", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown layer: {}'", ".", "format", "(", "l", ")", ")", "\n", "\n", "", "", "", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "output_layers", ",", "**", "kwargs", ")", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet18'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.resnet50": [[260, 275], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url", "ValueError"], "function", ["None"], ["", "def", "resnet50", "(", "output_layers", "=", "None", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "\n", "if", "output_layers", "is", "None", ":", "\n", "        ", "output_layers", "=", "[", "'default'", "]", "\n", "", "else", ":", "\n", "        ", "for", "l", "in", "output_layers", ":", "\n", "            ", "if", "l", "not", "in", "[", "'conv1'", ",", "'layer1'", ",", "'layer2'", ",", "'layer3'", ",", "'layer4'", ",", "'fc'", "]", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown layer: {}'", ".", "format", "(", "l", ")", ")", "\n", "\n", "", "", "", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "output_layers", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet50'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet.resnet101": [[277, 292], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url", "ValueError"], "function", ["None"], ["", "def", "resnet101", "(", "output_layers", "=", "None", ",", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    \"\"\"", "\n", "if", "output_layers", "is", "None", ":", "\n", "        ", "output_layers", "=", "[", "'default'", "]", "\n", "", "else", ":", "\n", "        ", "for", "l", "in", "output_layers", ":", "\n", "            ", "if", "l", "not", "in", "[", "'conv1'", ",", "'layer1'", ",", "'layer2'", ",", "'layer3'", ",", "'layer4'", ",", "'fc'", "]", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown layer: {}'", ".", "format", "(", "l", ")", ")", "\n", "\n", "\n", "", "", "", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "output_layers", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet101'", "]", ")", ")", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet18_vggm.SpatialCrossMapLRN.__init__": [[10, 24], ["torch.Module.__init__", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool2d", "torch.AvgPool2d", "int", "int"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "local_size", "=", "1", ",", "alpha", "=", "1.0", ",", "beta", "=", "0.75", ",", "k", "=", "1", ",", "ACROSS_CHANNELS", "=", "True", ")", ":", "\n", "        ", "super", "(", "SpatialCrossMapLRN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "ACROSS_CHANNELS", "=", "ACROSS_CHANNELS", "\n", "if", "ACROSS_CHANNELS", ":", "\n", "            ", "self", ".", "average", "=", "nn", ".", "AvgPool3d", "(", "kernel_size", "=", "(", "local_size", ",", "1", ",", "1", ")", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "(", "int", "(", "(", "local_size", "-", "1.0", ")", "/", "2", ")", ",", "0", ",", "0", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "average", "=", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "local_size", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "int", "(", "(", "local_size", "-", "1.0", ")", "/", "2", ")", ")", "\n", "", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "k", "=", "k", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet18_vggm.SpatialCrossMapLRN.forward": [[25, 36], ["x.div.div.div", "x.div.div.pow().unsqueeze", "resnet18_vggm.SpatialCrossMapLRN.average().squeeze", "div.mul().add().pow.mul().add().pow.mul().add().pow", "x.div.div.pow", "resnet18_vggm.SpatialCrossMapLRN.average", "div.mul().add().pow.mul().add().pow.mul().add().pow", "x.div.div.pow", "resnet18_vggm.SpatialCrossMapLRN.average", "div.mul().add().pow.mul().add().pow.mul().add", "div.mul().add().pow.mul().add().pow.mul().add", "div.mul().add().pow.mul().add().pow.mul", "div.mul().add().pow.mul().add().pow.mul"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.div"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "ACROSS_CHANNELS", ":", "\n", "            ", "div", "=", "x", ".", "pow", "(", "2", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div", "=", "self", ".", "average", "(", "div", ")", ".", "squeeze", "(", "1", ")", "\n", "div", "=", "div", ".", "mul", "(", "self", ".", "alpha", ")", ".", "add", "(", "self", ".", "k", ")", ".", "pow", "(", "self", ".", "beta", ")", "\n", "", "else", ":", "\n", "            ", "div", "=", "x", ".", "pow", "(", "2", ")", "\n", "div", "=", "self", ".", "average", "(", "div", ")", "\n", "div", "=", "div", ".", "mul", "(", "self", ".", "alpha", ")", ".", "add", "(", "self", ".", "k", ")", ".", "pow", "(", "self", ".", "beta", ")", "\n", "", "x", "=", "x", ".", "div", "(", "div", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet18_vggm.ResNetVGGm1.__init__": [[40, 66], ["base.Backbone.__init__", "torch.Conv2d", "torch.Conv2d", "resnet18_vggm.SpatialCrossMapLRN", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "resnet18_vggm.ResNetVGGm1._make_layer", "resnet18_vggm.ResNetVGGm1._make_layer", "resnet18_vggm.ResNetVGGm1._make_layer", "resnet18_vggm.ResNetVGGm1._make_layer", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "resnet18_vggm.ResNetVGGm1.modules", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "output_layers", ",", "num_classes", "=", "1000", ",", "frozen_layers", "=", "(", ")", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNetVGGm1", ",", "self", ")", ".", "__init__", "(", "frozen_layers", "=", "frozen_layers", ")", "\n", "self", ".", "output_layers", "=", "output_layers", "\n", "self", ".", "vggmconv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "96", ",", "(", "7", ",", "7", ")", ",", "(", "2", ",", "2", ")", ",", "padding", "=", "3", ")", "\n", "self", ".", "vgglrn", "=", "SpatialCrossMapLRN", "(", "5", ",", "0.0005", ",", "0.75", ",", "2", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "# self.avgpool = nn.AvgPool2d(7, stride=1)", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet18_vggm.ResNetVGGm1._make_layer": [[67, 83], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet18_vggm.ResNetVGGm1._add_output_and_check": [[85, 89], ["len", "len"], "methods", ["None"], ["", "def", "_add_output_and_check", "(", "self", ",", "name", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "        ", "if", "name", "in", "output_layers", ":", "\n", "            ", "outputs", "[", "name", "]", "=", "x", "\n", "", "return", "len", "(", "output_layers", ")", "==", "len", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet18_vggm.ResNetVGGm1.forward": [[91, 142], ["collections.OrderedDict", "resnet18_vggm.ResNetVGGm1.conv1", "resnet18_vggm.ResNetVGGm1.bn1", "resnet18_vggm.ResNetVGGm1.relu", "resnet18_vggm.ResNetVGGm1._add_output_and_check", "resnet18_vggm.ResNetVGGm1.maxpool", "resnet18_vggm.ResNetVGGm1.layer1", "resnet18_vggm.ResNetVGGm1._add_output_and_check", "resnet18_vggm.ResNetVGGm1.layer2", "resnet18_vggm.ResNetVGGm1._add_output_and_check", "resnet18_vggm.ResNetVGGm1.layer3", "resnet18_vggm.ResNetVGGm1._add_output_and_check", "resnet18_vggm.ResNetVGGm1.layer4", "resnet18_vggm.ResNetVGGm1._add_output_and_check", "resnet18_vggm.ResNetVGGm1.avgpool", "resnet18_vggm.ResNetVGGm1.view", "resnet18_vggm.ResNetVGGm1.fc", "resnet18_vggm.ResNetVGGm1._add_output_and_check", "ValueError", "resnet18_vggm.ResNetVGGm1.vgglrn", "resnet18_vggm.ResNetVGGm1._add_output_and_check", "resnet18_vggm.ResNetVGGm1.size", "resnet18_vggm.ResNetVGGm1.relu", "len", "resnet18_vggm.ResNetVGGm1.vggmconv1"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu"], ["", "def", "forward", "(", "self", ",", "x", ",", "output_layers", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "OrderedDict", "(", ")", "\n", "\n", "if", "output_layers", "is", "None", ":", "\n", "            ", "output_layers", "=", "self", ".", "output_layers", "\n", "\n", "", "if", "'vggconv1'", "in", "output_layers", ":", "\n", "            ", "c1", "=", "self", ".", "vgglrn", "(", "self", ".", "relu", "(", "self", ".", "vggmconv1", "(", "x", ")", ")", ")", "\n", "if", "self", ".", "_add_output_and_check", "(", "'vggconv1'", ",", "c1", ",", "outputs", ",", "output_layers", ")", ":", "\n", "                ", "return", "outputs", "\n", "\n", "", "", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'conv1'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer1'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer2'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer3'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer4'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'fc'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "if", "len", "(", "output_layers", ")", "==", "1", "and", "output_layers", "[", "0", "]", "==", "'default'", ":", "\n", "            ", "return", "x", "\n", "\n", "", "raise", "ValueError", "(", "'output_layer is wrong.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet18_vggm.resnet18_vggmconv1": [[144, 160], ["resnet18_vggm.ResNetVGGm1", "ResNetVGGm1.load_state_dict", "torch.load", "torch.load", "ValueError"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.load"], ["", "", "def", "resnet18_vggmconv1", "(", "output_layers", "=", "None", ",", "path", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model with first-layer VGGm features.\n    \"\"\"", "\n", "\n", "if", "output_layers", "is", "None", ":", "\n", "        ", "output_layers", "=", "[", "'default'", "]", "\n", "", "else", ":", "\n", "        ", "for", "l", "in", "output_layers", ":", "\n", "            ", "if", "l", "not", "in", "[", "'vggconv1'", ",", "'conv1'", ",", "'layer1'", ",", "'layer2'", ",", "'layer3'", ",", "'layer4'", ",", "'fc'", "]", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown layer: {}'", ".", "format", "(", "l", ")", ")", "\n", "\n", "", "", "", "model", "=", "ResNetVGGm1", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "output_layers", ",", "**", "kwargs", ")", "\n", "\n", "if", "path", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "path", ")", ",", "strict", "=", "False", ")", "\n", "", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.Bottleneck.__init__": [[21, 32], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride_1x1", "=", "1", ",", "stride_3x3", "=", "1", ",", "downsample", "=", "None", ",", "dilation", "=", "1", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride_1x1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride_3x3", ",", "\n", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "4", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "# self.stride = stride", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.Bottleneck.forward": [[34, 55], ["resnet_mrcnn.Bottleneck.conv1", "resnet_mrcnn.Bottleneck.bn1", "resnet_mrcnn.Bottleneck.relu", "resnet_mrcnn.Bottleneck.conv2", "resnet_mrcnn.Bottleneck.bn2", "resnet_mrcnn.Bottleneck.relu", "resnet_mrcnn.Bottleneck.conv3", "resnet_mrcnn.Bottleneck.bn3", "resnet_mrcnn.Bottleneck.relu", "resnet_mrcnn.Bottleneck.downsample"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet.__init__": [[59, 97], ["base.Backbone.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "resnet_mrcnn.ResNet._make_layer", "resnet_mrcnn.ResNet._make_layer", "resnet_mrcnn.ResNet._make_layer", "resnet_mrcnn.ResNet._make_layer", "isinstance", "resnet_mrcnn.ResNet.modules", "Exception", "isinstance", "int", "range", "max", "max", "max", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer"], ["def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "output_layers", ",", "num_classes", "=", "1000", ",", "inplanes", "=", "64", ",", "dilation_factor", "=", "1", ",", "frozen_layers", "=", "(", ")", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "inplanes", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", "frozen_layers", "=", "frozen_layers", ")", "\n", "self", ".", "output_layers", "=", "output_layers", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "inplanes", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "inplanes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "\n", "# Change! stride condition", "\n", "stride", "=", "[", "int", "(", "l", ">", "1", ")", "+", "1", "for", "l", "in", "range", "(", "1", ",", "4", ")", "]", "\n", "# stride = [1 + (dilation_factor < l) for l in (8, 4, 2)]", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "inplanes", ",", "layers", "[", "0", "]", ",", "stride", "=", "stride", "[", "0", "]", ",", "dilation", "=", "max", "(", "dilation_factor", "//", "8", ",", "1", ")", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "inplanes", "*", "2", ",", "layers", "[", "1", "]", ",", "stride", "=", "stride", "[", "1", "]", ",", "dilation", "=", "max", "(", "dilation_factor", "//", "4", ",", "1", ")", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "inplanes", "*", "4", ",", "layers", "[", "2", "]", ",", "stride", "=", "stride", "[", "2", "]", ",", "dilation", "=", "max", "(", "dilation_factor", "//", "2", ",", "1", ")", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "inplanes", "*", "8", ",", "layers", "[", "3", "]", ",", "stride", "=", "stride", "[", "2", "]", ",", "dilation", "=", "dilation_factor", ")", "\n", "\n", "out_feature_strides", "=", "{", "'conv1'", ":", "4", ",", "'layer1'", ":", "4", ",", "'layer2'", ":", "4", "*", "stride", "[", "0", "]", ",", "'layer3'", ":", "4", "*", "stride", "[", "0", "]", "*", "stride", "[", "1", "]", ",", "\n", "'layer4'", ":", "4", "*", "stride", "[", "0", "]", "*", "stride", "[", "1", "]", "*", "stride", "[", "2", "]", "}", "\n", "\n", "if", "isinstance", "(", "self", ".", "layer1", "[", "0", "]", ",", "Bottleneck", ")", ":", "\n", "            ", "base_num_channels", "=", "4", "*", "inplanes", "\n", "out_feature_channels", "=", "{", "'conv1'", ":", "inplanes", ",", "'layer1'", ":", "base_num_channels", ",", "'layer2'", ":", "base_num_channels", "*", "2", ",", "\n", "'layer3'", ":", "base_num_channels", "*", "4", ",", "'layer4'", ":", "base_num_channels", "*", "8", "}", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'block not supported'", ")", "\n", "\n", "", "self", ".", "_out_feature_strides", "=", "out_feature_strides", "\n", "self", ".", "_out_feature_channels", "=", "out_feature_channels", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet.out_feature_strides": [[98, 103], ["None"], "methods", ["None"], ["", "", "", "def", "out_feature_strides", "(", "self", ",", "layer", "=", "None", ")", ":", "\n", "        ", "if", "layer", "is", "None", ":", "\n", "            ", "return", "self", ".", "_out_feature_strides", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_out_feature_strides", "[", "layer", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet.out_feature_channels": [[104, 109], ["None"], "methods", ["None"], ["", "", "def", "out_feature_channels", "(", "self", ",", "layer", "=", "None", ")", ":", "\n", "        ", "if", "layer", "is", "None", ":", "\n", "            ", "return", "self", ".", "_out_feature_channels", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_out_feature_channels", "[", "layer", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._make_layer": [[110, 134], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "stride_in_1x1", "=", "True", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "# Change! No condition for stride 1", "\n", "if", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "down_stride", "=", "stride", "if", "dilation", "==", "1", "else", "1", "\n", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "down_stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "# Change! reset stride", "\n", "", "if", "dilation", ">", "1", ":", "\n", "            ", "stride", "=", "1", "\n", "\n", "# Change! Stride", "\n", "", "stride_1x1", ",", "stride_3x3", "=", "(", "stride", ",", "1", ")", "if", "stride_in_1x1", "else", "(", "1", ",", "stride", ")", "\n", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride_1x1", ",", "stride_3x3", ",", "downsample", ",", "dilation", "=", "dilation", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check": [[135, 139], ["len", "len"], "methods", ["None"], ["", "def", "_add_output_and_check", "(", "self", ",", "name", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "        ", "if", "name", "in", "output_layers", ":", "\n", "            ", "outputs", "[", "name", "]", "=", "x", "\n", "", "return", "len", "(", "output_layers", ")", "==", "len", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet.forward": [[140, 187], ["collections.OrderedDict", "resnet_mrcnn.ResNet.conv1", "resnet_mrcnn.ResNet.bn1", "resnet_mrcnn.ResNet.relu", "resnet_mrcnn.ResNet.maxpool", "resnet_mrcnn.ResNet._add_output_and_check", "resnet_mrcnn.ResNet.layer1", "resnet_mrcnn.ResNet._add_output_and_check", "resnet_mrcnn.ResNet.layer2", "resnet_mrcnn.ResNet._add_output_and_check", "resnet_mrcnn.ResNet.layer3", "resnet_mrcnn.ResNet._add_output_and_check", "resnet_mrcnn.ResNet.layer4", "resnet_mrcnn.ResNet._add_output_and_check", "ValueError", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check", "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.ResNet._add_output_and_check"], ["", "def", "forward", "(", "self", ",", "x", ",", "output_layers", "=", "None", ")", ":", "\n", "        ", "\"\"\" Forward pass with input x. The output_layers specify the feature blocks which must be returned \"\"\"", "\n", "outputs", "=", "OrderedDict", "(", ")", "\n", "\n", "if", "output_layers", "is", "None", ":", "\n", "            ", "output_layers", "=", "self", ".", "output_layers", "\n", "\n", "", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'conv1'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer1'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer2'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer3'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "if", "self", ".", "_add_output_and_check", "(", "'layer4'", ",", "x", ",", "outputs", ",", "output_layers", ")", ":", "\n", "            ", "return", "outputs", "\n", "\n", "# x = self.avgpool(x)", "\n", "# x = x.view(x.size(0), -1)", "\n", "# x = self.fc(x)", "\n", "\n", "# if self._add_output_and_check('fc', x, outputs, output_layers):", "\n", "#     return outputs", "\n", "\n", "", "if", "len", "(", "output_layers", ")", "==", "1", "and", "output_layers", "[", "0", "]", "==", "'default'", ":", "\n", "            ", "return", "x", "\n", "\n", "", "raise", "ValueError", "(", "'output_layer is wrong.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.conv3x3": [[12, 16], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet50": [[189, 206], ["resnet_mrcnn.ResNet", "print", "ValueError"], "function", ["None"], ["", "", "def", "resnet50", "(", "output_layers", "=", "None", ",", "pretrained", "=", "False", ",", "weights_path", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "\n", "if", "output_layers", "is", "None", ":", "\n", "        ", "output_layers", "=", "[", "'default'", "]", "\n", "", "else", ":", "\n", "        ", "for", "l", "in", "output_layers", ":", "\n", "            ", "if", "l", "not", "in", "[", "'conv1'", ",", "'layer1'", ",", "'layer2'", ",", "'layer3'", ",", "'layer4'", "]", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown layer: {}'", ".", "format", "(", "l", ")", ")", "\n", "\n", "", "", "", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "output_layers", ",", "**", "kwargs", ")", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "print", "(", "'Pre-trained weights not available. Load it manually'", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.backbone.resnet_mrcnn.resnet101": [[208, 225], ["resnet_mrcnn.ResNet", "print", "ValueError"], "function", ["None"], ["", "def", "resnet101", "(", "output_layers", "=", "None", ",", "pretrained", "=", "False", ",", "weights_path", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    \"\"\"", "\n", "\n", "if", "output_layers", "is", "None", ":", "\n", "        ", "output_layers", "=", "[", "'default'", "]", "\n", "", "else", ":", "\n", "        ", "for", "l", "in", "output_layers", ":", "\n", "            ", "if", "l", "not", "in", "[", "'conv1'", ",", "'layer1'", ",", "'layer2'", ",", "'layer3'", ",", "'layer4'", "]", ":", "\n", "                ", "raise", "ValueError", "(", "'Unknown layer: {}'", ".", "format", "(", "l", ")", ")", "\n", "\n", "", "", "", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "output_layers", ",", "**", "kwargs", ")", "\n", "\n", "if", "pretrained", ":", "\n", "        ", "print", "(", "'Pre-trained weights not available. Load it manually'", ")", "\n", "\n", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.segmentation.LovaszSegLoss.__init__": [[9, 14], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "classes", "=", "[", "1", ",", "]", ",", "per_image", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "classes", "=", "classes", "\n", "self", ".", "per_image", "=", "per_image", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.segmentation.LovaszSegLoss.forward": [[15, 17], ["ltr.lovasz_softmax", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_softmax"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "return", "lovasz_loss", ".", "lovasz_softmax", "(", "probas", "=", "torch", ".", "sigmoid", "(", "input", ")", ",", "labels", "=", "target", ",", "per_image", "=", "self", ".", "per_image", ",", "classes", "=", "self", ".", "classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.segmentation.one_hot": [[19, 61], ["torch.zeros().to", "torch.zeros().to", "torch.is_tensor", "torch.is_tensor", "TypeError", "ValueError", "ValueError", "torch.zeros().to.scatter_", "torch.zeros", "torch.zeros", "labels.unsqueeze", "type"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "", "def", "one_hot", "(", "labels", ":", "torch", ".", "Tensor", ",", "\n", "num_classes", ":", "int", ",", "\n", "device", "=", "None", ",", "\n", "dtype", "=", "None", ",", "\n", "eps", "=", "1e-6", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "r\"\"\"Converts an integer label x-D tensor to a one-hot (x+1)-D tensor.\n    Args:\n        labels (torch.Tensor) : tensor with labels of shape :math:`(N, *)`,\n                                where N is batch size. Each value is an integer\n                                representing correct classification.\n        num_classes (int): number of classes in labels.\n        device (Optional[torch.device]): the desired device of returned tensor.\n         Default: if None, uses the current device for the default tensor type\n         (see torch.set_default_tensor_type()). device will be the CPU for CPU\n         tensor types and the current CUDA device for CUDA tensor types.\n        dtype (Optional[torch.dtype]): the desired data type of returned\n         tensor. Default: if None, infers data type from values.\n    Returns:\n        torch.Tensor: the labels in one hot tensor of shape :math:`(N, C, *)`,\n    Examples::\n        #>>> labels = torch.LongTensor([[[0, 1], [2, 0]]])\n        #>>> kornia.losses.one_hot(labels, num_classes=3)\n        tensor([[[[1., 0.],\n                  [0., 1.]],\n                 [[0., 1.],\n                  [0., 0.]],\n                 [[0., 0.],\n                  [1., 0.]]]]\n    \"\"\"", "\n", "if", "not", "torch", ".", "is_tensor", "(", "labels", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\"Input labels type is not a torch.Tensor. Got {}\"", "\n", ".", "format", "(", "type", "(", "labels", ")", ")", ")", "\n", "", "if", "not", "labels", ".", "dtype", "==", "torch", ".", "int64", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"labels must be of the same dtype torch.int64. Got: {}\"", ".", "format", "(", "\n", "labels", ".", "dtype", ")", ")", "\n", "", "if", "num_classes", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"The number of classes must be bigger than one.\"", "\n", "\" Got: {}\"", ".", "format", "(", "num_classes", ")", ")", "\n", "", "shape", "=", "labels", ".", "shape", "\n", "one_hot", "=", "torch", ".", "zeros", "(", "(", "shape", "[", "0", "]", ",", "num_classes", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", ")", ".", "to", "(", "device", ")", "\n", "return", "one_hot", ".", "scatter_", "(", "1", ",", "labels", ".", "unsqueeze", "(", "1", ")", ",", "1.0", ")", "+", "eps", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_classification.LBHinge.__init__": [[15, 20], ["torch.MSELoss", "torch.MSELoss", "torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "error_metric", "=", "nn", ".", "MSELoss", "(", ")", ",", "threshold", "=", "None", ",", "clip", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "error_metric", "=", "error_metric", "\n", "self", ".", "threshold", "=", "threshold", "if", "threshold", "is", "not", "None", "else", "-", "100", "\n", "self", ".", "clip", "=", "clip", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_classification.LBHinge.forward": [[21, 32], ["target_classification.LBHinge.error_metric", "torch.min", "torch.min", "torch.min", "torch.min", "torch.nn.functional.relu", "torch.nn.functional.relu", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu"], ["", "def", "forward", "(", "self", ",", "prediction", ",", "label", ",", "target_bb", "=", "None", ")", ":", "\n", "        ", "negative_mask", "=", "(", "label", "<", "self", ".", "threshold", ")", ".", "float", "(", ")", "\n", "positive_mask", "=", "(", "1.0", "-", "negative_mask", ")", "\n", "\n", "prediction", "=", "negative_mask", "*", "F", ".", "relu", "(", "prediction", ")", "+", "positive_mask", "*", "prediction", "\n", "\n", "loss", "=", "self", ".", "error_metric", "(", "prediction", ",", "positive_mask", "*", "label", ")", "\n", "\n", "if", "self", ".", "clip", "is", "not", "None", ":", "\n", "            ", "loss", "=", "torch", ".", "min", "(", "loss", ",", "torch", ".", "tensor", "(", "[", "self", ".", "clip", "]", ",", "device", "=", "loss", ".", "device", ")", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_classification.LBHingev2.__init__": [[44, 58], ["torch.Module.__init__", "torch.MSELoss", "torch.MSELoss"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "error_metric", "=", "None", ",", "threshold", "=", "None", ",", "return_per_sequence", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "error_metric", "is", "None", ":", "\n", "            ", "if", "return_per_sequence", ":", "\n", "                ", "reduction", "=", "'none'", "\n", "", "else", ":", "\n", "                ", "reduction", "=", "'mean'", "\n", "", "error_metric", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "reduction", ")", "\n", "\n", "", "self", ".", "error_metric", "=", "error_metric", "\n", "self", ".", "threshold", "=", "threshold", "if", "threshold", "is", "not", "None", "else", "-", "100", "\n", "\n", "self", ".", "return_per_sequence", "=", "return_per_sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_classification.LBHingev2.forward": [[59, 86], ["valid_samples.float.float.float", "target_classification.LBHingev2.error_metric", "target_classification.LBHingev2.error_metric", "prediction.dim", "label.dim", "torch.nn.functional.relu", "torch.nn.functional.relu", "loss.mean.mean.mean", "loss.mean.mean.mean", "valid_samples.float.float.numel", "valid_samples.float.float.sum"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "forward", "(", "self", ",", "prediction", ",", "label", ",", "target_bb", "=", "None", ",", "valid_samples", "=", "None", ")", ":", "\n", "        ", "assert", "prediction", ".", "dim", "(", ")", "==", "4", "and", "label", ".", "dim", "(", ")", "==", "4", "\n", "\n", "negative_mask", "=", "(", "label", "<", "self", ".", "threshold", ")", ".", "float", "(", ")", "\n", "positive_mask", "=", "(", "1.0", "-", "negative_mask", ")", "\n", "\n", "prediction", "=", "negative_mask", "*", "F", ".", "relu", "(", "prediction", ")", "+", "positive_mask", "*", "prediction", "\n", "\n", "# Mask invalid samples", "\n", "if", "valid_samples", "is", "not", "None", ":", "\n", "            ", "valid_samples", "=", "valid_samples", ".", "float", "(", ")", "\n", "prediction", "=", "prediction", "*", "valid_samples", "\n", "label", "=", "label", "*", "valid_samples", "\n", "\n", "loss", "=", "self", ".", "error_metric", "(", "prediction", ",", "positive_mask", "*", "label", ")", "\n", "\n", "if", "self", ".", "return_per_sequence", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss", "*", "valid_samples", ".", "numel", "(", ")", "/", "(", "valid_samples", ".", "sum", "(", ")", "+", "1e-12", ")", "\n", "", "", "else", ":", "\n", "            ", "loss", "=", "self", ".", "error_metric", "(", "prediction", ",", "positive_mask", "*", "label", ")", "\n", "\n", "if", "self", ".", "return_per_sequence", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_classification.IsTargetCellLoss.__init__": [[89, 93], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "return_per_sequence", "=", "False", ",", "use_with_logits", "=", "True", ")", ":", "\n", "        ", "super", "(", "IsTargetCellLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "return_per_sequence", "=", "return_per_sequence", "\n", "self", ".", "use_with_logits", "=", "use_with_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_classification.IsTargetCellLoss.forward": [[94, 129], ["prediction.view.view.view", "label.view.view.view", "valid_samples.float().view.float().view.float().view", "torch.nn.functional.binary_cross_entropy.mean", "torch.nn.functional.binary_cross_entropy_with_logits", "torch.nn.functional.binary_cross_entropy_with_logits", "torch.nn.functional.binary_cross_entropy", "torch.nn.functional.binary_cross_entropy", "valid_samples.float().view.float().view.sum", "torch.nn.functional.binary_cross_entropy_with_logits", "torch.nn.functional.binary_cross_entropy_with_logits", "torch.nn.functional.binary_cross_entropy", "torch.nn.functional.binary_cross_entropy", "prediction_accuracy.mean.mean.mean", "prediction_accuracy.mean.mean.mean", "valid_samples.float().view.float().view.float", "prediction_accuracy.mean.mean.sum", "prediction_accuracy.mean.mean.sum"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "forward", "(", "self", ",", "prediction", ",", "label", ",", "target_bb", "=", "None", ",", "valid_samples", "=", "None", ")", ":", "\n", "        ", "score_shape", "=", "label", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "prediction", "=", "prediction", ".", "view", "(", "-", "1", ",", "score_shape", "[", "0", "]", ",", "score_shape", "[", "1", "]", ")", "\n", "label", "=", "label", ".", "view", "(", "-", "1", ",", "score_shape", "[", "0", "]", ",", "score_shape", "[", "1", "]", ")", "\n", "\n", "if", "valid_samples", "is", "not", "None", ":", "\n", "            ", "valid_samples", "=", "valid_samples", ".", "float", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "if", "self", ".", "use_with_logits", ":", "\n", "                ", "prediction_accuracy_persample", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "prediction", ",", "label", ",", "reduction", "=", "'none'", ")", "\n", "", "else", ":", "\n", "                ", "prediction_accuracy_persample", "=", "F", ".", "binary_cross_entropy", "(", "prediction", ",", "label", ",", "reduction", "=", "'none'", ")", "\n", "\n", "", "prediction_accuracy", "=", "prediction_accuracy_persample", ".", "mean", "(", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "prediction_accuracy", "=", "prediction_accuracy", "*", "valid_samples", "\n", "\n", "if", "not", "self", ".", "return_per_sequence", ":", "\n", "                ", "num_valid_samples", "=", "valid_samples", ".", "sum", "(", ")", "\n", "if", "num_valid_samples", ">", "0", ":", "\n", "                    ", "prediction_accuracy", "=", "prediction_accuracy", ".", "sum", "(", ")", "/", "num_valid_samples", "\n", "", "else", ":", "\n", "                    ", "prediction_accuracy", "=", "0.0", "*", "prediction_accuracy", ".", "sum", "(", ")", "\n", "", "", "", "else", ":", "\n", "            ", "if", "self", ".", "use_with_logits", ":", "\n", "                ", "prediction_accuracy", "=", "F", ".", "binary_cross_entropy_with_logits", "(", "prediction", ",", "label", ",", "reduction", "=", "'none'", ")", "\n", "", "else", ":", "\n", "                ", "prediction_accuracy", "=", "F", ".", "binary_cross_entropy", "(", "prediction", ",", "label", ",", "reduction", "=", "'none'", ")", "\n", "\n", "", "if", "self", ".", "return_per_sequence", ":", "\n", "                ", "prediction_accuracy", "=", "prediction_accuracy", ".", "mean", "(", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "prediction_accuracy", "=", "prediction_accuracy", ".", "mean", "(", ")", "\n", "\n", "", "", "return", "prediction_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_classification.TrackingClassificationAccuracy.__init__": [[135, 142], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "threshold", ",", "neg_threshold", "=", "None", ")", ":", "\n", "        ", "super", "(", "TrackingClassificationAccuracy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "threshold", "=", "threshold", "\n", "\n", "if", "neg_threshold", "is", "None", ":", "\n", "            ", "neg_threshold", "=", "threshold", "\n", "", "self", ".", "neg_threshold", "=", "neg_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_classification.TrackingClassificationAccuracy.forward": [[143, 167], ["prediction.view", "label.view", "prediction.view.max", "label.view.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "valid_samples.float().view.float().view.float().view", "valid_samples.float().view.float().view.sum", "prediction_correct.float().mean", "prediction_correct.float", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "valid_samples.float().view.float().view.float", "prediction_correct.float", "len", "prediction_correct.float"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "forward", "(", "self", ",", "prediction", ",", "label", ",", "valid_samples", "=", "None", ")", ":", "\n", "        ", "prediction_reshaped", "=", "prediction", ".", "view", "(", "-", "1", ",", "prediction", ".", "shape", "[", "-", "2", "]", "*", "prediction", ".", "shape", "[", "-", "1", "]", ")", "\n", "label_reshaped", "=", "label", ".", "view", "(", "-", "1", ",", "label", ".", "shape", "[", "-", "2", "]", "*", "label", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "prediction_max_val", ",", "argmax_id", "=", "prediction_reshaped", ".", "max", "(", "dim", "=", "1", ")", "\n", "label_max_val", ",", "_", "=", "label_reshaped", ".", "max", "(", "dim", "=", "1", ")", "\n", "\n", "label_val_at_peak", "=", "label_reshaped", "[", "torch", ".", "arange", "(", "len", "(", "argmax_id", ")", ")", ",", "argmax_id", "]", "\n", "label_val_at_peak", "=", "torch", ".", "max", "(", "label_val_at_peak", ",", "torch", ".", "zeros_like", "(", "label_val_at_peak", ")", ")", "\n", "\n", "prediction_correct", "=", "(", "(", "label_val_at_peak", ">=", "self", ".", "threshold", ")", "&", "(", "label_max_val", ">", "0.25", ")", ")", "|", "(", "(", "label_val_at_peak", "<", "self", ".", "neg_threshold", ")", "&", "(", "label_max_val", "<", "0.25", ")", ")", "\n", "\n", "if", "valid_samples", "is", "not", "None", ":", "\n", "            ", "valid_samples", "=", "valid_samples", ".", "float", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "num_valid_samples", "=", "valid_samples", ".", "sum", "(", ")", "\n", "if", "num_valid_samples", ">", "0", ":", "\n", "                ", "prediction_accuracy", "=", "(", "valid_samples", "*", "prediction_correct", ".", "float", "(", ")", ")", ".", "sum", "(", ")", "/", "num_valid_samples", "\n", "", "else", ":", "\n", "                ", "prediction_accuracy", "=", "1.0", "\n", "", "", "else", ":", "\n", "            ", "prediction_accuracy", "=", "prediction_correct", ".", "float", "(", ")", ".", "mean", "(", ")", "\n", "\n", "", "return", "prediction_accuracy", ",", "prediction_correct", ".", "float", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_candidate_matching_loss.TargetCandidateMatchingLoss.__init__": [[19, 23], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nll_balancing", "=", "0.5", ",", "nll_weight", "=", "1.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nll_balancing", "=", "nll_balancing", "\n", "self", ".", "nll_weight", "=", "nll_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_candidate_matching_loss.TargetCandidateMatchingLoss.metrics": [[25, 29], ["target_candidate_matching_loss.recall", "target_candidate_matching_loss.precision"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.target_candidate_matching_loss.recall", "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_candidate_matching_loss.precision"], ["", "def", "metrics", "(", "self", ",", "matches1", ",", "gt_matches1", ",", "**", "kwargs", ")", ":", "\n", "        ", "rec", "=", "recall", "(", "matches1", ",", "gt_matches1", "[", "0", "]", ")", "\n", "prec", "=", "precision", "(", "matches1", ",", "gt_matches1", "[", "0", "]", ")", "\n", "return", "{", "'match_recall'", ":", "rec", ",", "'match_precision'", ":", "prec", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_candidate_matching_loss.TargetCandidateMatchingLoss.forward": [[30, 67], ["gt_assignment.float", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "[].sum().mean", "gt_assignment.float.sum", "gt_assignment.float.new_tensor", "neg0.new_tensor", "neg0.sum", "neg1.sum", "[].sum", "log_assignment.exp"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "forward", "(", "self", ",", "gt_assignment", ",", "gt_matches0", ",", "gt_matches1", ",", "log_assignment", ",", "bin_score", ",", "**", "kwargs", ")", ":", "\n", "        ", "gt_assignment", "=", "gt_assignment", "[", "0", "]", "\n", "gt_matches0", "=", "gt_matches0", "[", "0", "]", "\n", "gt_matches1", "=", "gt_matches1", "[", "0", "]", "\n", "\n", "losses", "=", "{", "'total'", ":", "0", "}", "\n", "\n", "positive", "=", "gt_assignment", ".", "float", "(", ")", "\n", "neg0", "=", "(", "gt_matches0", "==", "-", "1", ")", ".", "float", "(", ")", "\n", "neg1", "=", "(", "gt_matches1", "==", "-", "1", ")", ".", "float", "(", ")", "\n", "\n", "num_pos", "=", "torch", ".", "max", "(", "positive", ".", "sum", "(", "(", "1", ",", "2", ")", ")", ",", "positive", ".", "new_tensor", "(", "1", ")", ")", "\n", "num_neg", "=", "torch", ".", "max", "(", "neg0", ".", "sum", "(", "1", ")", "+", "neg1", ".", "sum", "(", "1", ")", ",", "neg0", ".", "new_tensor", "(", "1", ")", ")", "\n", "\n", "nll_pos", "=", "-", "(", "log_assignment", "[", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", "*", "positive", ")", ".", "sum", "(", "(", "1", ",", "2", ")", ")", "\n", "\n", "nll_pos", "/=", "num_pos", "\n", "nll_neg0", "=", "-", "(", "log_assignment", "[", ":", ",", ":", "-", "1", ",", "-", "1", "]", "*", "neg0", ")", ".", "sum", "(", "1", ")", "\n", "nll_neg1", "=", "-", "(", "log_assignment", "[", ":", ",", "-", "1", ",", ":", "-", "1", "]", "*", "neg1", ")", ".", "sum", "(", "1", ")", "\n", "nll_neg", "=", "(", "nll_neg0", "+", "nll_neg1", ")", "/", "num_neg", "\n", "\n", "nll", "=", "(", "self", ".", "nll_balancing", "*", "nll_pos", "+", "(", "1", "-", "self", ".", "nll_balancing", ")", "*", "nll_neg", ")", "\n", "\n", "losses", "[", "'assignment_nll'", "]", "=", "nll", "\n", "\n", "if", "self", ".", "nll_weight", ">", "0", ":", "\n", "            ", "losses", "[", "'total'", "]", "=", "nll", "*", "self", ".", "nll_weight", "\n", "\n", "# Some statistics", "\n", "", "losses", "[", "'nll_pos'", "]", "=", "nll_pos", "\n", "losses", "[", "'nll_neg'", "]", "=", "nll_neg", "\n", "losses", "[", "'num_matchable'", "]", "=", "num_pos", "\n", "losses", "[", "'num_unmatchable'", "]", "=", "num_neg", "\n", "losses", "[", "'sinkhorn_norm'", "]", "=", "log_assignment", ".", "exp", "(", ")", "[", ":", ",", ":", "-", "1", "]", ".", "sum", "(", "2", ")", ".", "mean", "(", "1", ")", "\n", "losses", "[", "'bin_score'", "]", "=", "bin_score", "[", "None", "]", "\n", "\n", "return", "losses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_candidate_matching_loss.recall": [[5, 8], ["mask.sum"], "function", ["None"], ["def", "recall", "(", "m", ",", "gt_m", ")", ":", "\n", "    ", "mask", "=", "(", "gt_m", ">", "-", "1", ")", ".", "float", "(", ")", "\n", "return", "(", "(", "m", "==", "gt_m", ")", "*", "mask", ")", ".", "sum", "(", "1", ")", "/", "mask", ".", "sum", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_candidate_matching_loss.precision": [[10, 16], ["float", "torch.max", "torch.max", "mask.sum", "torch.ones_like", "torch.ones_like", "mask.sum"], "function", ["None"], ["", "def", "precision", "(", "m", ",", "gt_m", ")", ":", "\n", "    ", "mask", "=", "(", "(", "m", ">", "-", "1", ")", "&", "(", "gt_m", ">=", "-", "1", ")", ")", ".", "float", "(", ")", "\n", "prec", "=", "(", "(", "m", "==", "gt_m", ")", "*", "mask", ")", ".", "sum", "(", "1", ")", "/", "torch", ".", "max", "(", "mask", ".", "sum", "(", "1", ")", ",", "torch", ".", "ones_like", "(", "mask", ".", "sum", "(", "1", ")", ")", ")", "\n", "no_match_mask", "=", "(", "gt_m", ">", "-", "1", ")", ".", "sum", "(", "1", ")", "==", "0", "\n", "prec", "[", "no_match_mask", "]", "=", "float", "(", "'NaN'", ")", "\n", "return", "prec", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.kl_regression.KLRegression.__init__": [[11, 14], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "eps", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.kl_regression.KLRegression.forward": [[15, 28], ["L.mean", "torch.log", "torch.log", "torch.log", "torch.log", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "math.log"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "forward", "(", "self", ",", "scores", ",", "sample_density", ",", "gt_density", ",", "mc_dim", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Args:\n            scores: predicted score values\n            sample_density: probability density of the sample distribution\n            gt_density: probability density of the ground truth distribution\n            mc_dim: dimension of the MC samples\"\"\"", "\n", "\n", "exp_val", "=", "scores", "-", "torch", ".", "log", "(", "sample_density", "+", "self", ".", "eps", ")", "\n", "\n", "L", "=", "torch", ".", "logsumexp", "(", "exp_val", ",", "dim", "=", "mc_dim", ")", "-", "math", ".", "log", "(", "scores", ".", "shape", "[", "mc_dim", "]", ")", "-", "torch", ".", "mean", "(", "scores", "*", "(", "gt_density", "/", "(", "sample_density", "+", "self", ".", "eps", ")", ")", ",", "dim", "=", "mc_dim", ")", "\n", "\n", "return", "L", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.kl_regression.MLRegression.__init__": [[34, 37], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "eps", "=", "0.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.kl_regression.MLRegression.forward": [[38, 53], ["L.mean", "torch.log", "torch.log", "torch.log", "torch.log", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "math.log"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "forward", "(", "self", ",", "scores", ",", "sample_density", ",", "gt_density", "=", "None", ",", "mc_dim", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Args:\n            scores: predicted score values. First sample must be ground-truth\n            sample_density: probability density of the sample distribution\n            gt_density: not used\n            mc_dim: dimension of the MC samples. Only mc_dim=1 supported\"\"\"", "\n", "\n", "assert", "mc_dim", "==", "1", "\n", "assert", "(", "sample_density", "[", ":", ",", "0", ",", "...", "]", "==", "-", "1", ")", ".", "all", "(", ")", "\n", "\n", "exp_val", "=", "scores", "[", ":", ",", "1", ":", ",", "...", "]", "-", "torch", ".", "log", "(", "sample_density", "[", ":", ",", "1", ":", ",", "...", "]", "+", "self", ".", "eps", ")", "\n", "\n", "L", "=", "torch", ".", "logsumexp", "(", "exp_val", ",", "dim", "=", "mc_dim", ")", "-", "math", ".", "log", "(", "scores", ".", "shape", "[", "mc_dim", "]", "-", "1", ")", "-", "scores", "[", ":", ",", "0", ",", "...", "]", "\n", "loss", "=", "L", ".", "mean", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.kl_regression.KLRegressionGrid.forward": [[59, 71], ["L.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "math.log"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["def", "forward", "(", "self", ",", "scores", ",", "gt_density", ",", "grid_dim", "=", "-", "1", ",", "grid_scale", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Args:\n            scores: predicted score values\n            gt_density: probability density of the ground truth distribution\n            grid_dim: dimension(s) of the grid\n            grid_scale: area of one grid cell\"\"\"", "\n", "\n", "score_corr", "=", "grid_scale", "*", "torch", ".", "sum", "(", "scores", "*", "gt_density", ",", "dim", "=", "grid_dim", ")", "\n", "\n", "L", "=", "torch", ".", "logsumexp", "(", "scores", ",", "dim", "=", "grid_dim", ")", "+", "math", ".", "log", "(", "grid_scale", ")", "-", "score_corr", "\n", "\n", "return", "L", ".", "mean", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.bbr_loss.GIoULoss.__init__": [[6, 8], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.bbr_loss.GIoULoss.forward": [[9, 52], ["pred.unsqueeze.unsqueeze.permute().reshape", "target.permute().reshape.permute().reshape.permute().reshape", "pred.unsqueeze.unsqueeze.dim", "pred.unsqueeze.unsqueeze.unsqueeze", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "weights.permute().reshape.permute().reshape.permute().reshape", "losses[].mean", "losses.mean", "pred.unsqueeze.unsqueeze.permute", "target.permute().reshape.permute().reshape.permute", "weights.permute().reshape.permute().reshape.sum", "weights.permute().reshape.permute().reshape.permute"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "forward", "(", "self", ",", "pred", ",", "target", ",", "weights", "=", "None", ")", ":", "\n", "        ", "if", "pred", ".", "dim", "(", ")", "==", "4", ":", "\n", "            ", "pred", "=", "pred", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "pred", "=", "pred", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "# nf x ns x x 4 x h x w", "\n", "target", "=", "target", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "#nf x ns x 4 x h x w", "\n", "\n", "pred_left", "=", "pred", "[", ":", ",", "0", "]", "\n", "pred_top", "=", "pred", "[", ":", ",", "1", "]", "\n", "pred_right", "=", "pred", "[", ":", ",", "2", "]", "\n", "pred_bottom", "=", "pred", "[", ":", ",", "3", "]", "\n", "\n", "target_left", "=", "target", "[", ":", ",", "0", "]", "\n", "target_top", "=", "target", "[", ":", ",", "1", "]", "\n", "target_right", "=", "target", "[", ":", ",", "2", "]", "\n", "target_bottom", "=", "target", "[", ":", ",", "3", "]", "\n", "\n", "target_area", "=", "(", "target_left", "+", "target_right", ")", "*", "(", "target_top", "+", "target_bottom", ")", "\n", "pred_area", "=", "(", "pred_left", "+", "pred_right", ")", "*", "(", "pred_top", "+", "pred_bottom", ")", "\n", "\n", "w_intersect", "=", "torch", ".", "min", "(", "pred_left", ",", "target_left", ")", "+", "torch", ".", "min", "(", "pred_right", ",", "target_right", ")", "\n", "g_w_intersect", "=", "torch", ".", "max", "(", "pred_left", ",", "target_left", ")", "+", "torch", ".", "max", "(", "\n", "pred_right", ",", "target_right", ")", "\n", "h_intersect", "=", "torch", ".", "min", "(", "pred_bottom", ",", "target_bottom", ")", "+", "torch", ".", "min", "(", "pred_top", ",", "target_top", ")", "\n", "g_h_intersect", "=", "torch", ".", "max", "(", "pred_bottom", ",", "target_bottom", ")", "+", "torch", ".", "max", "(", "pred_top", ",", "target_top", ")", "\n", "ac_union", "=", "g_w_intersect", "*", "g_h_intersect", "+", "1e-7", "\n", "area_intersect", "=", "w_intersect", "*", "h_intersect", "\n", "area_union", "=", "target_area", "+", "pred_area", "-", "area_intersect", "+", "1e-7", "\n", "ious", "=", "(", "area_intersect", ")", "/", "(", "area_union", ")", "\n", "gious", "=", "ious", "-", "(", "ac_union", "-", "area_union", ")", "/", "ac_union", "\n", "\n", "losses", "=", "1", "-", "gious", "\n", "\n", "if", "weights", "is", "not", "None", "and", "weights", ".", "sum", "(", ")", ">", "0", ":", "\n", "            ", "weights", "=", "weights", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", ".", "reshape", "(", "-", "1", ")", "# nf x ns x x 1 x h x w", "\n", "loss_mean", "=", "losses", "[", "weights", ">", "0", "]", ".", "mean", "(", ")", "\n", "ious", "=", "ious", "[", "weights", ">", "0", "]", "\n", "", "else", ":", "\n", "            ", "loss_mean", "=", "losses", ".", "mean", "(", ")", "\n", "\n", "", "return", "loss_mean", ",", "ious", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.LovaszHingeWithLogitsLoss.__init__": [[97, 100], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "per_image", ")", ":", "\n", "        ", "super", "(", "LovaszHingeWithLogitsLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "per_image", "=", "per_image", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.LovaszHingeWithLogitsLoss.forward": [[101, 103], ["lovasz_loss.lovasz_hinge"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_hinge"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "return", "lovasz_hinge", "(", "input", ",", "target", ",", "per_image", "=", "self", ".", "per_image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.StableBCELoss.__init__": [[141, 143], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "StableBCELoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.StableBCELoss.forward": [[144, 148], ["loss.mean", "input.abs", "input.clamp", "neg_abs.exp"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "neg_abs", "=", "-", "input", ".", "abs", "(", ")", "\n", "loss", "=", "input", ".", "clamp", "(", "min", "=", "0", ")", "-", "input", "*", "target", "+", "(", "1", "+", "neg_abs", ".", "exp", "(", ")", ")", ".", "log", "(", ")", "\n", "return", "loss", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_grad": [[20, 33], ["len", "gt_sorted.sum", "gt_sorted.float().cumsum", "gt_sorted.float"], "function", ["None"], ["", "def", "lovasz_grad", "(", "gt_sorted", ")", ":", "\n", "    ", "\"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"", "\n", "p", "=", "len", "(", "gt_sorted", ")", "\n", "gts", "=", "gt_sorted", ".", "sum", "(", ")", "\n", "intersection", "=", "gts", "-", "gt_sorted", ".", "float", "(", ")", ".", "cumsum", "(", "0", ")", "\n", "union", "=", "gts", "+", "(", "1", "-", "gt_sorted", ")", ".", "float", "(", ")", ".", "cumsum", "(", "0", ")", "\n", "jaccard", "=", "1.", "-", "intersection", "/", "union", "\n", "if", "p", ">", "1", ":", "# cover 1-pixel case", "\n", "        ", "jaccard", "[", "1", ":", "p", "]", "=", "jaccard", "[", "1", ":", "p", "]", "-", "jaccard", "[", "0", ":", "-", "1", "]", "\n", "", "return", "jaccard", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.iou_binary": [[35, 53], ["zip", "lovasz_loss.mean", "ious.append", "float", "float"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "iou_binary", "(", "preds", ",", "labels", ",", "EMPTY", "=", "1.", ",", "ignore", "=", "None", ",", "per_image", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    IoU for foreground class\n    binary: 1 foreground, 0 background\n    \"\"\"", "\n", "if", "not", "per_image", ":", "\n", "        ", "preds", ",", "labels", "=", "(", "preds", ",", ")", ",", "(", "labels", ",", ")", "\n", "", "ious", "=", "[", "]", "\n", "for", "pred", ",", "label", "in", "zip", "(", "preds", ",", "labels", ")", ":", "\n", "        ", "intersection", "=", "(", "(", "label", "==", "1", ")", "&", "(", "pred", "==", "1", ")", ")", ".", "sum", "(", ")", "\n", "union", "=", "(", "(", "label", "==", "1", ")", "|", "(", "(", "pred", "==", "1", ")", "&", "(", "label", "!=", "ignore", ")", ")", ")", ".", "sum", "(", ")", "\n", "if", "not", "union", ":", "\n", "            ", "iou", "=", "EMPTY", "\n", "", "else", ":", "\n", "            ", "iou", "=", "float", "(", "intersection", ")", "/", "float", "(", "union", ")", "\n", "", "ious", ".", "append", "(", "iou", ")", "\n", "", "iou", "=", "mean", "(", "ious", ")", "# mean across images if per_image", "\n", "return", "100", "*", "iou", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.iou": [[55, 75], ["zip", "range", "ious.append", "lovasz_loss.mean", "numpy.array", "zip", "iou.append", "iou.append", "float", "float"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean"], ["", "def", "iou", "(", "preds", ",", "labels", ",", "C", ",", "EMPTY", "=", "1.", ",", "ignore", "=", "None", ",", "per_image", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Array of IoU for each (non ignored) class\n    \"\"\"", "\n", "if", "not", "per_image", ":", "\n", "        ", "preds", ",", "labels", "=", "(", "preds", ",", ")", ",", "(", "labels", ",", ")", "\n", "", "ious", "=", "[", "]", "\n", "for", "pred", ",", "label", "in", "zip", "(", "preds", ",", "labels", ")", ":", "\n", "        ", "iou", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "C", ")", ":", "\n", "            ", "if", "i", "!=", "ignore", ":", "# The ignored label is sometimes among predicted classes (ENet - CityScapes)", "\n", "                ", "intersection", "=", "(", "(", "label", "==", "i", ")", "&", "(", "pred", "==", "i", ")", ")", ".", "sum", "(", ")", "\n", "union", "=", "(", "(", "label", "==", "i", ")", "|", "(", "(", "pred", "==", "i", ")", "&", "(", "label", "!=", "ignore", ")", ")", ")", ".", "sum", "(", ")", "\n", "if", "not", "union", ":", "\n", "                    ", "iou", ".", "append", "(", "EMPTY", ")", "\n", "", "else", ":", "\n", "                    ", "iou", ".", "append", "(", "float", "(", "intersection", ")", "/", "float", "(", "union", ")", ")", "\n", "", "", "", "ious", ".", "append", "(", "iou", ")", "\n", "", "ious", "=", "[", "mean", "(", "iou", ")", "for", "iou", "in", "zip", "(", "*", "ious", ")", "]", "# mean across images if per_image", "\n", "return", "100", "*", "np", ".", "array", "(", "ious", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_hinge": [[80, 94], ["lovasz_loss.mean", "lovasz_loss.lovasz_hinge_flat", "lovasz_loss.lovasz_hinge_flat", "lovasz_loss.flatten_binary_scores", "zip", "lovasz_loss.flatten_binary_scores", "log.unsqueeze", "lab.unsqueeze"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_hinge_flat", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_hinge_flat", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.flatten_binary_scores", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.flatten_binary_scores"], ["", "def", "lovasz_hinge", "(", "logits", ",", "labels", ",", "per_image", "=", "True", ",", "ignore", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"", "\n", "if", "per_image", ":", "\n", "        ", "loss", "=", "mean", "(", "lovasz_hinge_flat", "(", "*", "flatten_binary_scores", "(", "log", ".", "unsqueeze", "(", "0", ")", ",", "lab", ".", "unsqueeze", "(", "0", ")", ",", "ignore", ")", ")", "\n", "for", "log", ",", "lab", "in", "zip", "(", "logits", ",", "labels", ")", ")", "\n", "", "else", ":", "\n", "        ", "loss", "=", "lovasz_hinge_flat", "(", "*", "flatten_binary_scores", "(", "logits", ",", "labels", ",", "ignore", ")", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_hinge_flat": [[105, 123], ["torch.sort", "torch.sort", "torch.sort", "lovasz_loss.lovasz_grad", "torch.dot", "torch.dot", "torch.dot", "len", "torch.relu", "torch.autograd.Variable", "logits.sum", "labels.float", "torch.autograd.Variable"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_grad", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.decoder.relu"], ["", "", "def", "lovasz_hinge_flat", "(", "logits", ",", "labels", ")", ":", "\n", "    ", "\"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"", "\n", "if", "len", "(", "labels", ")", "==", "0", ":", "\n", "# only void pixels, the gradients should be 0", "\n", "        ", "return", "logits", ".", "sum", "(", ")", "*", "0.", "\n", "", "signs", "=", "2.", "*", "labels", ".", "float", "(", ")", "-", "1.", "\n", "errors", "=", "(", "1.", "-", "logits", "*", "Variable", "(", "signs", ")", ")", "\n", "errors_sorted", ",", "perm", "=", "torch", ".", "sort", "(", "errors", ",", "dim", "=", "0", ",", "descending", "=", "True", ")", "\n", "perm", "=", "perm", ".", "data", "\n", "gt_sorted", "=", "labels", "[", "perm", "]", "\n", "grad", "=", "lovasz_grad", "(", "gt_sorted", ")", "\n", "loss", "=", "torch", ".", "dot", "(", "F", ".", "relu", "(", "errors_sorted", ")", ",", "Variable", "(", "grad", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.flatten_binary_scores": [[125, 138], ["scores.view.view", "labels.view.view"], "function", ["None"], ["", "def", "flatten_binary_scores", "(", "scores", ",", "labels", ",", "ignore", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"", "\n", "scores", "=", "scores", ".", "view", "(", "-", "1", ")", "\n", "labels", "=", "labels", ".", "view", "(", "-", "1", ")", "\n", "if", "ignore", "is", "None", ":", "\n", "        ", "return", "scores", ",", "labels", "\n", "", "valid", "=", "(", "labels", "!=", "ignore", ")", "\n", "vscores", "=", "scores", "[", "valid", "]", "\n", "vlabels", "=", "labels", "[", "valid", "]", "\n", "return", "vscores", ",", "vlabels", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.binary_xloss": [[150, 160], ["lovasz_loss.flatten_binary_scores", "lovasz_loss.StableBCELoss", "torch.autograd.Variable", "labels.float"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.flatten_binary_scores"], ["", "", "def", "binary_xloss", "(", "logits", ",", "labels", ",", "ignore", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Binary Cross entropy loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      ignore: void class id\n    \"\"\"", "\n", "logits", ",", "labels", "=", "flatten_binary_scores", "(", "logits", ",", "labels", ",", "ignore", ")", "\n", "loss", "=", "StableBCELoss", "(", ")", "(", "logits", ",", "Variable", "(", "labels", ".", "float", "(", ")", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_softmax": [[165, 181], ["lovasz_loss.mean", "lovasz_loss.lovasz_softmax_flat", "lovasz_loss.lovasz_softmax_flat", "lovasz_loss.flatten_probas", "zip", "lovasz_loss.flatten_probas", "prob.unsqueeze", "lab.unsqueeze"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_softmax_flat", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_softmax_flat", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.flatten_probas", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.flatten_probas"], ["", "def", "lovasz_softmax", "(", "probas", ",", "labels", ",", "classes", "=", "'present'", ",", "per_image", "=", "False", ",", "ignore", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Multi-class Lovasz-Softmax loss\n      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1).\n              Interpreted as binary (sigmoid) output with outputs of size [B, H, W].\n      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n      per_image: compute the loss per image instead of per batch\n      ignore: void class labels\n    \"\"\"", "\n", "if", "per_image", ":", "\n", "        ", "loss", "=", "mean", "(", "lovasz_softmax_flat", "(", "*", "flatten_probas", "(", "prob", ".", "unsqueeze", "(", "0", ")", ",", "lab", ".", "unsqueeze", "(", "0", ")", ",", "ignore", ")", ",", "classes", "=", "classes", ")", "\n", "for", "prob", ",", "lab", "in", "zip", "(", "probas", ",", "labels", ")", ")", "\n", "", "else", ":", "\n", "        ", "loss", "=", "lovasz_softmax_flat", "(", "*", "flatten_probas", "(", "probas", ",", "labels", ",", "ignore", ")", ",", "classes", "=", "classes", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_softmax_flat": [[183, 212], ["probas.size", "lovasz_loss.mean", "probas.numel", "list", "torch.sort", "torch.sort", "torch.sort", "losses.append", "range", "torch.dot", "torch.dot", "torch.dot", "fg.sum", "len", "ValueError", "torch.autograd.Variable", "torch.autograd.Variable", "lovasz_loss.lovasz_grad"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.lovasz_grad"], ["", "def", "lovasz_softmax_flat", "(", "probas", ",", "labels", ",", "classes", "=", "'present'", ")", ":", "\n", "    ", "\"\"\"\n    Multi-class Lovasz-Softmax loss\n      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n      classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.\n    \"\"\"", "\n", "if", "probas", ".", "numel", "(", ")", "==", "0", ":", "\n", "# only void pixels, the gradients should be 0", "\n", "        ", "return", "probas", "*", "0.", "\n", "", "C", "=", "probas", ".", "size", "(", "1", ")", "\n", "losses", "=", "[", "]", "\n", "class_to_sum", "=", "list", "(", "range", "(", "C", ")", ")", "if", "classes", "in", "[", "'all'", ",", "'present'", "]", "else", "classes", "\n", "for", "c", "in", "class_to_sum", ":", "\n", "        ", "fg", "=", "(", "labels", "==", "c", ")", ".", "float", "(", ")", "# foreground for class c", "\n", "if", "(", "classes", "==", "'present'", "and", "fg", ".", "sum", "(", ")", "==", "0", ")", ":", "\n", "            ", "continue", "\n", "", "if", "C", "==", "1", ":", "\n", "            ", "if", "len", "(", "classes", ")", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "'Sigmoid output possible only with 1 class'", ")", "\n", "", "class_pred", "=", "probas", "[", ":", ",", "0", "]", "\n", "", "else", ":", "\n", "            ", "class_pred", "=", "probas", "[", ":", ",", "c", "]", "\n", "", "errors", "=", "(", "Variable", "(", "fg", ")", "-", "class_pred", ")", ".", "abs", "(", ")", "\n", "errors_sorted", ",", "perm", "=", "torch", ".", "sort", "(", "errors", ",", "0", ",", "descending", "=", "True", ")", "\n", "perm", "=", "perm", ".", "data", "\n", "fg_sorted", "=", "fg", "[", "perm", "]", "\n", "losses", ".", "append", "(", "torch", ".", "dot", "(", "errors_sorted", ",", "Variable", "(", "lovasz_grad", "(", "fg_sorted", ")", ")", ")", ")", "\n", "", "return", "mean", "(", "losses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.flatten_probas": [[214, 231], ["probas.view.size", "probas.view.permute().contiguous().view", "labels.view.view", "probas.view.dim", "probas.view.size", "probas.view.view", "probas.view.permute().contiguous", "valid.nonzero().squeeze", "probas.view.permute", "valid.nonzero"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.extractor.MultiResolutionExtractor.size"], ["", "def", "flatten_probas", "(", "probas", ",", "labels", ",", "ignore", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Flattens predictions in the batch\n    \"\"\"", "\n", "if", "probas", ".", "dim", "(", ")", "==", "3", ":", "\n", "# assumes output of a sigmoid layer", "\n", "        ", "B", ",", "H", ",", "W", "=", "probas", ".", "size", "(", ")", "\n", "probas", "=", "probas", ".", "view", "(", "B", ",", "1", ",", "H", ",", "W", ")", "\n", "", "B", ",", "C", ",", "H", ",", "W", "=", "probas", ".", "size", "(", ")", "\n", "probas", "=", "probas", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "C", ")", "# B * H * W, C = P, C", "\n", "labels", "=", "labels", ".", "view", "(", "-", "1", ")", "\n", "if", "ignore", "is", "None", ":", "\n", "        ", "return", "probas", ",", "labels", "\n", "", "valid", "=", "(", "labels", "!=", "ignore", ")", "\n", "vprobas", "=", "probas", "[", "valid", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "]", "\n", "vlabels", "=", "labels", "[", "valid", "]", "\n", "return", "vprobas", ",", "vlabels", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.xloss": [[233, 238], ["torch.cross_entropy", "torch.autograd.Variable"], "function", ["None"], ["", "def", "xloss", "(", "logits", ",", "labels", ",", "ignore", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Cross entropy loss\n    \"\"\"", "\n", "return", "F", ".", "cross_entropy", "(", "logits", ",", "Variable", "(", "labels", ")", ",", "ignore_index", "=", "255", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan": [[241, 243], ["None"], "function", ["None"], ["", "def", "isnan", "(", "x", ")", ":", "\n", "    ", "return", "x", "!=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean": [[245, 264], ["iter", "enumerate", "ifilterfalse", "next", "ValueError", "lovasz_loss.iou"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.iou"], ["", "def", "mean", "(", "l", ",", "ignore_nan", "=", "False", ",", "empty", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    nanmean compatible with generators.\n    \"\"\"", "\n", "l", "=", "iter", "(", "l", ")", "\n", "if", "ignore_nan", ":", "\n", "        ", "l", "=", "ifilterfalse", "(", "isnan", ",", "l", ")", "\n", "", "try", ":", "\n", "        ", "n", "=", "1", "\n", "acc", "=", "next", "(", "l", ")", "\n", "", "except", "StopIteration", ":", "\n", "        ", "if", "empty", "==", "'raise'", ":", "\n", "            ", "raise", "ValueError", "(", "'Empty mean'", ")", "\n", "", "return", "empty", "\n", "", "for", "n", ",", "v", "in", "enumerate", "(", "l", ",", "2", ")", ":", "\n", "        ", "acc", "+=", "v", "\n", "", "if", "n", "==", "1", ":", "\n", "        ", "return", "acc", "\n", "", "return", "acc", "/", "n", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.DiMPActor.__init__": [[7, 12], ["BaseActor.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "net", ",", "objective", ",", "loss_weight", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "net", ",", "objective", ")", "\n", "if", "loss_weight", "is", "None", ":", "\n", "            ", "loss_weight", "=", "{", "'iou'", ":", "1.0", ",", "'test_clf'", ":", "1.0", "}", "\n", "", "self", ".", "loss_weight", "=", "loss_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.DiMPActor.__call__": [[13, 71], ["tracking.DiMPActor.net", "clf_loss_test.item", "tracking.DiMPActor.loss_weight.keys", "tracking.DiMPActor.loss_weight.keys", "isinstance", "loss.item", "loss_iou.item", "loss_target_classifier.item", "tracking.DiMPActor.loss_weight.keys", "loss_test_init_clf.item", "tracking.DiMPActor.loss_weight.keys", "sum.item", "len", "clf_losses_test[].item", "sum", "len", "sum", "sum().item", "len", "zip", "len", "sum"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            data - The input data, should contain the fields 'train_images', 'test_images', 'train_anno',\n                    'test_proposals', 'proposal_iou' and 'test_label'.\n\n        returns:\n            loss    - the training loss\n            stats  -  dict containing detailed losses\n        \"\"\"", "\n", "# Run network", "\n", "target_scores", ",", "iou_pred", "=", "self", ".", "net", "(", "train_imgs", "=", "data", "[", "'train_images'", "]", ",", "\n", "test_imgs", "=", "data", "[", "'test_images'", "]", ",", "\n", "train_bb", "=", "data", "[", "'train_anno'", "]", ",", "\n", "test_proposals", "=", "data", "[", "'test_proposals'", "]", ")", "\n", "\n", "# Classification losses for the different optimization iterations", "\n", "clf_losses_test", "=", "[", "self", ".", "objective", "[", "'test_clf'", "]", "(", "s", ",", "data", "[", "'test_label'", "]", ",", "data", "[", "'test_anno'", "]", ")", "for", "s", "in", "target_scores", "]", "\n", "\n", "# Loss of the final filter", "\n", "clf_loss_test", "=", "clf_losses_test", "[", "-", "1", "]", "\n", "loss_target_classifier", "=", "self", ".", "loss_weight", "[", "'test_clf'", "]", "*", "clf_loss_test", "\n", "\n", "# Compute loss for ATOM IoUNet", "\n", "loss_iou", "=", "self", ".", "loss_weight", "[", "'iou'", "]", "*", "self", ".", "objective", "[", "'iou'", "]", "(", "iou_pred", ",", "data", "[", "'proposal_iou'", "]", ")", "\n", "\n", "# Loss for the initial filter iteration", "\n", "loss_test_init_clf", "=", "0", "\n", "if", "'test_init_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "loss_test_init_clf", "=", "self", ".", "loss_weight", "[", "'test_init_clf'", "]", "*", "clf_losses_test", "[", "0", "]", "\n", "\n", "# Loss for the intermediate filter iterations", "\n", "", "loss_test_iter_clf", "=", "0", "\n", "if", "'test_iter_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "test_iter_weights", "=", "self", ".", "loss_weight", "[", "'test_iter_clf'", "]", "\n", "if", "isinstance", "(", "test_iter_weights", ",", "list", ")", ":", "\n", "                ", "loss_test_iter_clf", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "test_iter_weights", ",", "clf_losses_test", "[", "1", ":", "-", "1", "]", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "loss_test_iter_clf", "=", "(", "test_iter_weights", "/", "(", "len", "(", "clf_losses_test", ")", "-", "2", ")", ")", "*", "sum", "(", "clf_losses_test", "[", "1", ":", "-", "1", "]", ")", "\n", "\n", "# Total loss", "\n", "", "", "loss", "=", "loss_iou", "+", "loss_target_classifier", "+", "loss_test_init_clf", "+", "loss_test_iter_clf", "\n", "\n", "# Log stats", "\n", "stats", "=", "{", "'Loss/total'", ":", "loss", ".", "item", "(", ")", ",", "\n", "'Loss/iou'", ":", "loss_iou", ".", "item", "(", ")", ",", "\n", "'Loss/target_clf'", ":", "loss_target_classifier", ".", "item", "(", ")", "}", "\n", "if", "'test_init_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'Loss/test_init_clf'", "]", "=", "loss_test_init_clf", ".", "item", "(", ")", "\n", "", "if", "'test_iter_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'Loss/test_iter_clf'", "]", "=", "loss_test_iter_clf", ".", "item", "(", ")", "\n", "", "stats", "[", "'ClfTrain/test_loss'", "]", "=", "clf_loss_test", ".", "item", "(", ")", "\n", "if", "len", "(", "clf_losses_test", ")", ">", "0", ":", "\n", "            ", "stats", "[", "'ClfTrain/test_init_loss'", "]", "=", "clf_losses_test", "[", "0", "]", ".", "item", "(", ")", "\n", "if", "len", "(", "clf_losses_test", ")", ">", "2", ":", "\n", "                ", "stats", "[", "'ClfTrain/test_iter_loss'", "]", "=", "sum", "(", "clf_losses_test", "[", "1", ":", "-", "1", "]", ")", ".", "item", "(", ")", "/", "(", "len", "(", "clf_losses_test", ")", "-", "2", ")", "\n", "\n", "", "", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.KLDiMPActor.__init__": [[75, 80], ["BaseActor.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "net", ",", "objective", ",", "loss_weight", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "net", ",", "objective", ")", "\n", "if", "loss_weight", "is", "None", ":", "\n", "            ", "loss_weight", "=", "{", "'bb_ce'", ":", "1.0", "}", "\n", "", "self", ".", "loss_weight", "=", "loss_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.KLDiMPActor.__call__": [[81, 194], ["tracking.KLDiMPActor.net", "tracking.KLDiMPActor.loss_weight.keys", "tracking.KLDiMPActor.loss_weight.keys", "torch.isinf", "torch.isnan", "Exception", "loss.item", "bb_ce.item", "loss_bb_ce.item", "tracking.KLDiMPActor.loss_weight.keys", "loss_target_classifier.item", "tracking.KLDiMPActor.loss_weight.keys", "loss_test_init_clf.item", "tracking.KLDiMPActor.loss_weight.keys", "sum.item", "tracking.KLDiMPActor.loss_weight.keys", "loss_clf_ce.item", "tracking.KLDiMPActor.loss_weight.keys", "loss_clf_ce_init.item", "sum.item", "tracking.KLDiMPActor.loss_weight.keys", "clf_loss_test.item", "tracking.KLDiMPActor.loss_weight.keys", "clf_ce.item", "tracking.KLDiMPActor.loss_weight.keys", "tracking.KLDiMPActor.loss_weight.keys", "isinstance", "tracking.KLDiMPActor.loss_weight.keys", "isinstance", "tracking.KLDiMPActor.loss_weight.keys", "len", "len", "clf_losses_test[].item", "len", "clf_ce_losses[].item", "sum", "tracking.KLDiMPActor.loss_weight.keys", "len", "sum", "len", "len", "sum", "sum", "sum().item", "sum().item", "len", "len", "zip", "len", "zip", "len", "sum", "sum"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            data - The input data, should contain the fields 'train_images', 'test_images', 'train_anno',\n                    'test_proposals', 'proposal_iou' and 'test_label'.\n\n        returns:\n            loss    - the training loss\n            stats  -  dict containing detailed losses\n        \"\"\"", "\n", "# Run network", "\n", "target_scores", ",", "bb_scores", "=", "self", ".", "net", "(", "train_imgs", "=", "data", "[", "'train_images'", "]", ",", "\n", "test_imgs", "=", "data", "[", "'test_images'", "]", ",", "\n", "train_bb", "=", "data", "[", "'train_anno'", "]", ",", "\n", "test_proposals", "=", "data", "[", "'test_proposals'", "]", ")", "\n", "\n", "# Reshape bb reg variables", "\n", "is_valid", "=", "data", "[", "'test_anno'", "]", "[", ":", ",", ":", ",", "0", "]", "<", "99999.0", "\n", "bb_scores", "=", "bb_scores", "[", "is_valid", ",", ":", "]", "\n", "proposal_density", "=", "data", "[", "'proposal_density'", "]", "[", "is_valid", ",", ":", "]", "\n", "gt_density", "=", "data", "[", "'gt_density'", "]", "[", "is_valid", ",", ":", "]", "\n", "\n", "# Compute loss", "\n", "bb_ce", "=", "self", ".", "objective", "[", "'bb_ce'", "]", "(", "bb_scores", ",", "sample_density", "=", "proposal_density", ",", "gt_density", "=", "gt_density", ",", "mc_dim", "=", "1", ")", "\n", "loss_bb_ce", "=", "self", ".", "loss_weight", "[", "'bb_ce'", "]", "*", "bb_ce", "\n", "\n", "# If standard DiMP classifier is used", "\n", "loss_target_classifier", "=", "0", "\n", "loss_test_init_clf", "=", "0", "\n", "loss_test_iter_clf", "=", "0", "\n", "if", "'test_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "# Classification losses for the different optimization iterations", "\n", "            ", "clf_losses_test", "=", "[", "self", ".", "objective", "[", "'test_clf'", "]", "(", "s", ",", "data", "[", "'test_label'", "]", ",", "data", "[", "'test_anno'", "]", ")", "for", "s", "in", "target_scores", "]", "\n", "\n", "# Loss of the final filter", "\n", "clf_loss_test", "=", "clf_losses_test", "[", "-", "1", "]", "\n", "loss_target_classifier", "=", "self", ".", "loss_weight", "[", "'test_clf'", "]", "*", "clf_loss_test", "\n", "\n", "# Loss for the initial filter iteration", "\n", "if", "'test_init_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "                ", "loss_test_init_clf", "=", "self", ".", "loss_weight", "[", "'test_init_clf'", "]", "*", "clf_losses_test", "[", "0", "]", "\n", "\n", "# Loss for the intermediate filter iterations", "\n", "", "if", "'test_iter_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "                ", "test_iter_weights", "=", "self", ".", "loss_weight", "[", "'test_iter_clf'", "]", "\n", "if", "isinstance", "(", "test_iter_weights", ",", "list", ")", ":", "\n", "                    ", "loss_test_iter_clf", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "test_iter_weights", ",", "clf_losses_test", "[", "1", ":", "-", "1", "]", ")", "]", ")", "\n", "", "else", ":", "\n", "                    ", "loss_test_iter_clf", "=", "(", "test_iter_weights", "/", "(", "len", "(", "clf_losses_test", ")", "-", "2", ")", ")", "*", "sum", "(", "clf_losses_test", "[", "1", ":", "-", "1", "]", ")", "\n", "\n", "# If PrDiMP classifier is used", "\n", "", "", "", "loss_clf_ce", "=", "0", "\n", "loss_clf_ce_init", "=", "0", "\n", "loss_clf_ce_iter", "=", "0", "\n", "if", "'clf_ce'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "# Classification losses for the different optimization iterations", "\n", "            ", "clf_ce_losses", "=", "[", "self", ".", "objective", "[", "'clf_ce'", "]", "(", "s", ",", "data", "[", "'test_label_density'", "]", ",", "grid_dim", "=", "(", "-", "2", ",", "-", "1", ")", ")", "for", "s", "in", "target_scores", "]", "\n", "\n", "# Loss of the final filter", "\n", "clf_ce", "=", "clf_ce_losses", "[", "-", "1", "]", "\n", "loss_clf_ce", "=", "self", ".", "loss_weight", "[", "'clf_ce'", "]", "*", "clf_ce", "\n", "\n", "# Loss for the initial filter iteration", "\n", "if", "'clf_ce_init'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "                ", "loss_clf_ce_init", "=", "self", ".", "loss_weight", "[", "'clf_ce_init'", "]", "*", "clf_ce_losses", "[", "0", "]", "\n", "\n", "# Loss for the intermediate filter iterations", "\n", "", "if", "'clf_ce_iter'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", "and", "len", "(", "clf_ce_losses", ")", ">", "2", ":", "\n", "                ", "test_iter_weights", "=", "self", ".", "loss_weight", "[", "'clf_ce_iter'", "]", "\n", "if", "isinstance", "(", "test_iter_weights", ",", "list", ")", ":", "\n", "                    ", "loss_clf_ce_iter", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "test_iter_weights", ",", "clf_ce_losses", "[", "1", ":", "-", "1", "]", ")", "]", ")", "\n", "", "else", ":", "\n", "                    ", "loss_clf_ce_iter", "=", "(", "test_iter_weights", "/", "(", "len", "(", "clf_ce_losses", ")", "-", "2", ")", ")", "*", "sum", "(", "clf_ce_losses", "[", "1", ":", "-", "1", "]", ")", "\n", "\n", "# Total loss", "\n", "", "", "", "loss", "=", "loss_bb_ce", "+", "loss_clf_ce", "+", "loss_clf_ce_init", "+", "loss_clf_ce_iter", "+", "loss_target_classifier", "+", "loss_test_init_clf", "+", "loss_test_iter_clf", "\n", "\n", "if", "torch", ".", "isinf", "(", "loss", ")", "or", "torch", ".", "isnan", "(", "loss", ")", ":", "\n", "            ", "raise", "Exception", "(", "'ERROR: Loss was nan or inf!!!'", ")", "\n", "\n", "# Log stats", "\n", "", "stats", "=", "{", "'Loss/total'", ":", "loss", ".", "item", "(", ")", ",", "\n", "'Loss/bb_ce'", ":", "bb_ce", ".", "item", "(", ")", ",", "\n", "'Loss/loss_bb_ce'", ":", "loss_bb_ce", ".", "item", "(", ")", "}", "\n", "if", "'test_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'Loss/target_clf'", "]", "=", "loss_target_classifier", ".", "item", "(", ")", "\n", "", "if", "'test_init_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'Loss/test_init_clf'", "]", "=", "loss_test_init_clf", ".", "item", "(", ")", "\n", "", "if", "'test_iter_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'Loss/test_iter_clf'", "]", "=", "loss_test_iter_clf", ".", "item", "(", ")", "\n", "", "if", "'clf_ce'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'Loss/clf_ce'", "]", "=", "loss_clf_ce", ".", "item", "(", ")", "\n", "", "if", "'clf_ce_init'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'Loss/clf_ce_init'", "]", "=", "loss_clf_ce_init", ".", "item", "(", ")", "\n", "", "if", "'clf_ce_iter'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", "and", "len", "(", "clf_ce_losses", ")", ">", "2", ":", "\n", "            ", "stats", "[", "'Loss/clf_ce_iter'", "]", "=", "loss_clf_ce_iter", ".", "item", "(", ")", "\n", "\n", "", "if", "'test_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'ClfTrain/test_loss'", "]", "=", "clf_loss_test", ".", "item", "(", ")", "\n", "if", "len", "(", "clf_losses_test", ")", ">", "0", ":", "\n", "                ", "stats", "[", "'ClfTrain/test_init_loss'", "]", "=", "clf_losses_test", "[", "0", "]", ".", "item", "(", ")", "\n", "if", "len", "(", "clf_losses_test", ")", ">", "2", ":", "\n", "                    ", "stats", "[", "'ClfTrain/test_iter_loss'", "]", "=", "sum", "(", "clf_losses_test", "[", "1", ":", "-", "1", "]", ")", ".", "item", "(", ")", "/", "(", "len", "(", "clf_losses_test", ")", "-", "2", ")", "\n", "\n", "", "", "", "if", "'clf_ce'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'ClfTrain/clf_ce'", "]", "=", "clf_ce", ".", "item", "(", ")", "\n", "if", "len", "(", "clf_ce_losses", ")", ">", "0", ":", "\n", "                ", "stats", "[", "'ClfTrain/clf_ce_init'", "]", "=", "clf_ce_losses", "[", "0", "]", ".", "item", "(", ")", "\n", "if", "len", "(", "clf_ce_losses", ")", ">", "2", ":", "\n", "                    ", "stats", "[", "'ClfTrain/clf_ce_iter'", "]", "=", "sum", "(", "clf_ce_losses", "[", "1", ":", "-", "1", "]", ")", ".", "item", "(", ")", "/", "(", "len", "(", "clf_ce_losses", ")", "-", "2", ")", "\n", "\n", "", "", "", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.KYSActor.__init__": [[198, 206], ["BaseActor.__init__", "torch.device"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "net", ",", "objective", ",", "loss_weight", "=", "None", ",", "dimp_jitter_fn", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "net", ",", "objective", ")", "\n", "self", ".", "loss_weight", "=", "loss_weight", "\n", "\n", "self", ".", "dimp_jitter_fn", "=", "dimp_jitter_fn", "\n", "\n", "# TODO set it somewhere", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.KYSActor.__call__": [[207, 386], ["data[].to", "data[].to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().long().to", "torch.ones().to", "torch.ones().to", "torch.zeros().to", "torch.zeros().to", "data[].to", "data[].to", "tracking.KYSActor.net.train_classifier", "[].to", "tracking.KYSActor.net.extract_backbone_features", "backbone_feat_prev.view.view.view", "tracking.KYSActor.net.dimp_classifier.track_frame", "dimp_scores_prev[].contiguous", "[].to", "label_prev[].contiguous", "[].to", "valid_samples[].view().byte", "range", "torch.zeros().to.mean", "torch.zeros().to.mean", "torch.zeros().to.mean", "torch.zeros().to.mean", "torch.zeros().to.mean", "torch.ones().to.mean", "torch.ones().to.mean", "tracking.KYSActor.net.motion_feat_extractor().view", "[].to", "[].to", "test_label_cur[].contiguous", "[].to", "tracking.KYSActor.net.extract_backbone_features", "backbone_feat_cur.view.view.view", "tracking.KYSActor.net.dimp_classifier.track_frame", "dimp_scores_cur[].contiguous", "tracking.KYSActor.net.predictor", "valid_samples[].view().byte", "clf_loss_test_new.squeeze", "dimp_loss_test_new.squeeze", "tracking.KYSActor.clone", "tracking.KYSActor.clone", "test_label_cur[].contiguous.clone", "valid_samples[].view().byte.clone", "tracking.KYSActor.loss_weight.get", "tracking.KYSActor.loss_weight.get", "tracking.KYSActor.loss_weight.get", "loss.item", "clf_loss_test_w.item", "dimp_loss_test_w.item", "torch.zeros().to.mean.item", "torch.zeros().to.mean.item", "torch.zeros().to.mean.item", "test_clf_acc.item", "dimp_clf_acc.item", "torch.zeros().to.mean.item", "torch.zeros().to.mean.item", "torch.ones().to.mean.item", "torch.ones().to.mean.item", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros().long", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "valid_samples[].view", "tracking.KYSActor.net.motion_feat_extractor().view", "tracking.KYSActor.dimp_jitter_fn", "aux_data[].view", "clf_loss_test_orig_new.squeeze", "tracking.KYSActor.net.motion_feat_extractor", "test_label_cur[].contiguous.clone", "valid_samples[].view", "test_visibility[].view", "test_visibility[].view", "tracking.KYSActor.loss_weight.keys", "tracking.KYSActor.loss_weight.keys", "tracking.KYSActor.objective.keys", "tracking.KYSActor.loss_weight.keys", "tracking.KYSActor.objective.keys", "torch.zeros", "tracking.KYSActor.net.motion_feat_extractor", "test_pred_correct.long", "dimp_pred_correct.long"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.tracking.kysnet.KYSNet.train_classifier", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.track_frame", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to", "home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.target_classifier.linear_filter.LinearFilter.track_frame", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "sequence_length", "=", "data", "[", "'test_images'", "]", ".", "shape", "[", "0", "]", "\n", "num_sequences", "=", "data", "[", "'test_images'", "]", ".", "shape", "[", "1", "]", "\n", "\n", "valid_samples", "=", "data", "[", "'test_valid_image'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "test_visibility", "=", "data", "[", "'test_visible_ratio'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Initialize loss variables", "\n", "clf_loss_test_all", "=", "torch", ".", "zeros", "(", "num_sequences", ",", "sequence_length", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "clf_loss_test_orig_all", "=", "torch", ".", "zeros", "(", "num_sequences", ",", "sequence_length", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "dimp_loss_test_all", "=", "torch", ".", "zeros", "(", "num_sequences", ",", "sequence_length", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "test_clf_acc", "=", "0", "\n", "dimp_clf_acc", "=", "0", "\n", "\n", "test_tracked_correct", "=", "torch", ".", "zeros", "(", "num_sequences", ",", "sequence_length", "-", "1", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "test_seq_all_correct", "=", "torch", ".", "ones", "(", "num_sequences", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "dimp_seq_all_correct", "=", "torch", ".", "ones", "(", "num_sequences", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "is_target_loss_all", "=", "torch", ".", "zeros", "(", "num_sequences", ",", "sequence_length", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "is_target_after_prop_loss_all", "=", "torch", ".", "zeros", "(", "num_sequences", ",", "sequence_length", "-", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Initialize target model using the training frames", "\n", "train_images", "=", "data", "[", "'train_images'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "train_anno", "=", "data", "[", "'train_anno'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "dimp_filters", "=", "self", ".", "net", ".", "train_classifier", "(", "train_images", ",", "train_anno", ")", "\n", "\n", "# Track in the first test frame", "\n", "test_image_cur", "=", "data", "[", "'test_images'", "]", "[", "0", ",", "...", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "backbone_feat_prev_all", "=", "self", ".", "net", ".", "extract_backbone_features", "(", "test_image_cur", ")", "\n", "backbone_feat_prev", "=", "backbone_feat_prev_all", "[", "self", ".", "net", ".", "classification_layer", "]", "\n", "backbone_feat_prev", "=", "backbone_feat_prev", ".", "view", "(", "1", ",", "num_sequences", ",", "-", "1", ",", "\n", "backbone_feat_prev", ".", "shape", "[", "-", "2", "]", ",", "backbone_feat_prev", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "if", "self", ".", "net", ".", "motion_feat_extractor", "is", "not", "None", ":", "\n", "            ", "motion_feat_prev", "=", "self", ".", "net", ".", "motion_feat_extractor", "(", "backbone_feat_prev_all", ")", ".", "view", "(", "1", ",", "num_sequences", ",", "-", "1", ",", "\n", "backbone_feat_prev", ".", "shape", "[", "-", "2", "]", ",", "\n", "backbone_feat_prev", ".", "shape", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "motion_feat_prev", "=", "backbone_feat_prev", "\n", "\n", "", "dimp_scores_prev", "=", "self", ".", "net", ".", "dimp_classifier", ".", "track_frame", "(", "dimp_filters", ",", "backbone_feat_prev", ")", "\n", "\n", "# Remove last row and col (added due to even kernel size in the target model)", "\n", "dimp_scores_prev", "=", "dimp_scores_prev", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "\n", "# Set previous frame information", "\n", "label_prev", "=", "data", "[", "'test_label'", "]", "[", "0", ":", "1", ",", "...", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "label_prev", "=", "label_prev", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "\n", "anno_prev", "=", "data", "[", "'test_anno'", "]", "[", "0", ":", "1", ",", "...", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "state_prev", "=", "None", "\n", "\n", "is_valid_prev", "=", "valid_samples", "[", "0", ",", ":", "]", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "byte", "(", ")", "\n", "\n", "# Loop over the sequence", "\n", "for", "i", "in", "range", "(", "1", ",", "sequence_length", ")", ":", "\n", "            ", "test_image_cur", "=", "data", "[", "'test_images'", "]", "[", "i", ",", "...", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "test_label_cur", "=", "data", "[", "'test_label'", "]", "[", "i", ":", "i", "+", "1", ",", "...", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "test_label_cur", "=", "test_label_cur", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "\n", "test_anno_cur", "=", "data", "[", "'test_anno'", "]", "[", "i", ":", "i", "+", "1", ",", "...", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Extract features", "\n", "backbone_feat_cur_all", "=", "self", ".", "net", ".", "extract_backbone_features", "(", "test_image_cur", ")", "\n", "backbone_feat_cur", "=", "backbone_feat_cur_all", "[", "self", ".", "net", ".", "classification_layer", "]", "\n", "backbone_feat_cur", "=", "backbone_feat_cur", ".", "view", "(", "1", ",", "num_sequences", ",", "-", "1", ",", "\n", "backbone_feat_cur", ".", "shape", "[", "-", "2", "]", ",", "backbone_feat_cur", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "if", "self", ".", "net", ".", "motion_feat_extractor", "is", "not", "None", ":", "\n", "                ", "motion_feat_cur", "=", "self", ".", "net", ".", "motion_feat_extractor", "(", "backbone_feat_cur_all", ")", ".", "view", "(", "1", ",", "num_sequences", ",", "-", "1", ",", "\n", "backbone_feat_cur", ".", "shape", "[", "-", "2", "]", ",", "\n", "backbone_feat_cur", ".", "shape", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "motion_feat_cur", "=", "backbone_feat_cur", "\n", "\n", "# Run target model", "\n", "", "dimp_scores_cur", "=", "self", ".", "net", ".", "dimp_classifier", ".", "track_frame", "(", "dimp_filters", ",", "backbone_feat_cur", ")", "\n", "dimp_scores_cur", "=", "dimp_scores_cur", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "\n", "# Jitter target model output for augmentation", "\n", "jitter_info", "=", "None", "\n", "if", "self", ".", "dimp_jitter_fn", "is", "not", "None", ":", "\n", "                ", "dimp_scores_cur", "=", "self", ".", "dimp_jitter_fn", "(", "dimp_scores_cur", ",", "test_label_cur", ".", "clone", "(", ")", ")", "\n", "\n", "# Input target model output along with previous frame information to the predictor", "\n", "", "predictor_input_data", "=", "{", "'input1'", ":", "motion_feat_prev", ",", "'input2'", ":", "motion_feat_cur", ",", "\n", "'label_prev'", ":", "label_prev", ",", "'anno_prev'", ":", "anno_prev", ",", "\n", "'dimp_score_prev'", ":", "dimp_scores_prev", ",", "'dimp_score_cur'", ":", "dimp_scores_cur", ",", "\n", "'state_prev'", ":", "state_prev", ",", "\n", "'jitter_info'", ":", "jitter_info", "}", "\n", "\n", "predictor_output", "=", "self", ".", "net", ".", "predictor", "(", "predictor_input_data", ")", "\n", "\n", "predicted_resp", "=", "predictor_output", "[", "'response'", "]", "\n", "state_prev", "=", "predictor_output", "[", "'state_cur'", "]", "\n", "aux_data", "=", "predictor_output", "[", "'auxiliary_outputs'", "]", "\n", "\n", "is_valid", "=", "valid_samples", "[", "i", ",", ":", "]", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ".", "byte", "(", ")", "\n", "uncertain_frame", "=", "(", "test_visibility", "[", "i", ",", ":", "]", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "<", "0.75", ")", "*", "(", "test_visibility", "[", "i", ",", ":", "]", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", ">", "0.25", ")", "\n", "\n", "is_valid", "=", "is_valid", "*", "~", "uncertain_frame", "\n", "\n", "# Calculate losses", "\n", "clf_loss_test_new", "=", "self", ".", "objective", "[", "'test_clf'", "]", "(", "predicted_resp", ",", "test_label_cur", ",", "\n", "test_anno_cur", ",", "valid_samples", "=", "is_valid", ")", "\n", "clf_loss_test_all", "[", ":", ",", "i", "-", "1", "]", "=", "clf_loss_test_new", ".", "squeeze", "(", ")", "\n", "\n", "dimp_loss_test_new", "=", "self", ".", "objective", "[", "'dimp_clf'", "]", "(", "dimp_scores_cur", ",", "test_label_cur", ",", "\n", "test_anno_cur", ",", "valid_samples", "=", "is_valid", ")", "\n", "dimp_loss_test_all", "[", ":", ",", "i", "-", "1", "]", "=", "dimp_loss_test_new", ".", "squeeze", "(", ")", "\n", "\n", "if", "'fused_score_orig'", "in", "aux_data", "and", "'test_clf_orig'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "                ", "aux_data", "[", "'fused_score_orig'", "]", "=", "aux_data", "[", "'fused_score_orig'", "]", ".", "view", "(", "test_label_cur", ".", "shape", ")", "\n", "clf_loss_test_orig_new", "=", "self", ".", "objective", "[", "'test_clf'", "]", "(", "aux_data", "[", "'fused_score_orig'", "]", ",", "test_label_cur", ",", "test_anno_cur", ",", "valid_samples", "=", "is_valid", ")", "\n", "clf_loss_test_orig_all", "[", ":", ",", "i", "-", "1", "]", "=", "clf_loss_test_orig_new", ".", "squeeze", "(", ")", "\n", "\n", "", "if", "'is_target'", "in", "aux_data", "and", "'is_target'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", "and", "'is_target'", "in", "self", ".", "objective", ".", "keys", "(", ")", ":", "\n", "                ", "is_target_loss_new", "=", "self", ".", "objective", "[", "'is_target'", "]", "(", "aux_data", "[", "'is_target'", "]", ",", "label_prev", ",", "is_valid_prev", ")", "\n", "is_target_loss_all", "[", ":", ",", "i", "-", "1", "]", "=", "is_target_loss_new", "\n", "\n", "", "if", "'is_target_after_prop'", "in", "aux_data", "and", "'is_target_after_prop'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", "and", "'is_target'", "in", "self", ".", "objective", ".", "keys", "(", ")", ":", "\n", "                ", "is_target_after_prop_loss_new", "=", "self", ".", "objective", "[", "'is_target'", "]", "(", "aux_data", "[", "'is_target_after_prop'", "]", ",", "\n", "test_label_cur", ",", "is_valid", ")", "\n", "is_target_after_prop_loss_all", "[", ":", ",", "i", "-", "1", "]", "=", "is_target_after_prop_loss_new", "\n", "\n", "", "test_clf_acc_new", ",", "test_pred_correct", "=", "self", ".", "objective", "[", "'clf_acc'", "]", "(", "predicted_resp", ",", "test_label_cur", ",", "valid_samples", "=", "is_valid", ")", "\n", "test_clf_acc", "+=", "test_clf_acc_new", "\n", "\n", "test_seq_all_correct", "=", "test_seq_all_correct", "*", "(", "test_pred_correct", ".", "long", "(", ")", "|", "(", "1", "-", "is_valid", ")", ".", "long", "(", ")", ")", ".", "float", "(", ")", "\n", "test_tracked_correct", "[", ":", ",", "i", "-", "1", "]", "=", "test_pred_correct", "\n", "\n", "dimp_clf_acc_new", ",", "dimp_pred_correct", "=", "self", ".", "objective", "[", "'clf_acc'", "]", "(", "dimp_scores_cur", ",", "test_label_cur", ",", "valid_samples", "=", "is_valid", ")", "\n", "dimp_clf_acc", "+=", "dimp_clf_acc_new", "\n", "\n", "dimp_seq_all_correct", "=", "dimp_seq_all_correct", "*", "(", "dimp_pred_correct", ".", "long", "(", ")", "|", "(", "1", "-", "is_valid", ")", ".", "long", "(", ")", ")", ".", "float", "(", ")", "\n", "\n", "motion_feat_prev", "=", "motion_feat_cur", ".", "clone", "(", ")", "\n", "dimp_scores_prev", "=", "dimp_scores_cur", ".", "clone", "(", ")", "\n", "label_prev", "=", "test_label_cur", ".", "clone", "(", ")", "\n", "is_valid_prev", "=", "is_valid", ".", "clone", "(", ")", "\n", "\n", "# Compute average loss over the sequence", "\n", "", "clf_loss_test", "=", "clf_loss_test_all", ".", "mean", "(", ")", "\n", "clf_loss_test_orig", "=", "clf_loss_test_orig_all", ".", "mean", "(", ")", "\n", "dimp_loss_test", "=", "dimp_loss_test_all", ".", "mean", "(", ")", "\n", "is_target_loss", "=", "is_target_loss_all", ".", "mean", "(", ")", "\n", "is_target_after_prop_loss", "=", "is_target_after_prop_loss_all", ".", "mean", "(", ")", "\n", "\n", "test_clf_acc", "/=", "(", "sequence_length", "-", "1", ")", "\n", "dimp_clf_acc", "/=", "(", "sequence_length", "-", "1", ")", "\n", "clf_loss_test_orig", "/=", "(", "sequence_length", "-", "1", ")", "\n", "\n", "test_seq_clf_acc", "=", "test_seq_all_correct", ".", "mean", "(", ")", "\n", "dimp_seq_clf_acc", "=", "dimp_seq_all_correct", ".", "mean", "(", ")", "\n", "\n", "clf_loss_test_w", "=", "self", ".", "loss_weight", "[", "'test_clf'", "]", "*", "clf_loss_test", "\n", "clf_loss_test_orig_w", "=", "self", ".", "loss_weight", "[", "'test_clf_orig'", "]", "*", "clf_loss_test_orig", "\n", "dimp_loss_test_w", "=", "self", ".", "loss_weight", ".", "get", "(", "'dimp_clf'", ",", "0.0", ")", "*", "dimp_loss_test", "\n", "\n", "is_target_loss_w", "=", "self", ".", "loss_weight", ".", "get", "(", "'is_target'", ",", "0.0", ")", "*", "is_target_loss", "\n", "is_target_after_prop_loss_w", "=", "self", ".", "loss_weight", ".", "get", "(", "'is_target_after_prop'", ",", "0.0", ")", "*", "is_target_after_prop_loss", "\n", "\n", "loss", "=", "clf_loss_test_w", "+", "dimp_loss_test_w", "+", "is_target_loss_w", "+", "is_target_after_prop_loss_w", "+", "clf_loss_test_orig_w", "\n", "\n", "stats", "=", "{", "'Loss/total'", ":", "loss", ".", "item", "(", ")", ",", "\n", "'Loss/test_clf'", ":", "clf_loss_test_w", ".", "item", "(", ")", ",", "\n", "'Loss/dimp_clf'", ":", "dimp_loss_test_w", ".", "item", "(", ")", ",", "\n", "'Loss/raw/test_clf'", ":", "clf_loss_test", ".", "item", "(", ")", ",", "\n", "'Loss/raw/test_clf_orig'", ":", "clf_loss_test_orig", ".", "item", "(", ")", ",", "\n", "'Loss/raw/dimp_clf'", ":", "dimp_loss_test", ".", "item", "(", ")", ",", "\n", "'Loss/raw/test_clf_acc'", ":", "test_clf_acc", ".", "item", "(", ")", ",", "\n", "'Loss/raw/dimp_clf_acc'", ":", "dimp_clf_acc", ".", "item", "(", ")", ",", "\n", "'Loss/raw/is_target'", ":", "is_target_loss", ".", "item", "(", ")", ",", "\n", "'Loss/raw/is_target_after_prop'", ":", "is_target_after_prop_loss", ".", "item", "(", ")", ",", "\n", "'Loss/raw/test_seq_acc'", ":", "test_seq_clf_acc", ".", "item", "(", ")", ",", "\n", "'Loss/raw/dimp_seq_acc'", ":", "dimp_seq_clf_acc", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.DiMPSimpleActor.__init__": [[390, 395], ["BaseActor.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "net", ",", "objective", ",", "loss_weight", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "net", ",", "objective", ")", "\n", "if", "loss_weight", "is", "None", ":", "\n", "            ", "loss_weight", "=", "{", "'bb_ce'", ":", "1.0", "}", "\n", "", "self", ".", "loss_weight", "=", "loss_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.DiMPSimpleActor.__call__": [[396, 470], ["tracking.DiMPSimpleActor.net", "tracking.DiMPSimpleActor.loss_weight.keys", "tracking.DiMPSimpleActor.loss_weight.keys", "isinstance", "torch.isinf", "torch.isnan", "Exception", "loss.item", "bb_ce.item", "loss_bb_ce.item", "tracking.DiMPSimpleActor.loss_weight.keys", "loss_target_classifier.item", "tracking.DiMPSimpleActor.loss_weight.keys", "loss_test_init_clf.item", "tracking.DiMPSimpleActor.loss_weight.keys", "sum.item", "tracking.DiMPSimpleActor.loss_weight.keys", "clf_loss_test.item", "sum", "len", "clf_losses_test[].item", "sum", "len", "sum().item", "zip", "len", "len", "sum"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            data - The input data, should contain the fields 'train_images', 'test_images', 'train_anno',\n                    'test_proposals', 'proposal_iou' and 'test_label'.\n\n        returns:\n            loss    - the training loss\n            stats  -  dict containing detailed losses\n        \"\"\"", "\n", "# Run network", "\n", "target_scores", ",", "bb_scores", "=", "self", ".", "net", "(", "train_imgs", "=", "data", "[", "'train_images'", "]", ",", "\n", "test_imgs", "=", "data", "[", "'test_images'", "]", ",", "\n", "train_bb", "=", "data", "[", "'train_anno'", "]", ",", "\n", "test_proposals", "=", "data", "[", "'test_proposals'", "]", ",", "\n", "train_label", "=", "data", "[", "'train_label'", "]", ")", "\n", "\n", "# Reshape bb reg variables", "\n", "is_valid", "=", "data", "[", "'test_anno'", "]", "[", ":", ",", ":", ",", "0", "]", "<", "99999.0", "\n", "bb_scores", "=", "bb_scores", "[", "is_valid", ",", ":", "]", "\n", "proposal_density", "=", "data", "[", "'proposal_density'", "]", "[", "is_valid", ",", ":", "]", "\n", "gt_density", "=", "data", "[", "'gt_density'", "]", "[", "is_valid", ",", ":", "]", "\n", "\n", "# Compute loss", "\n", "bb_ce", "=", "self", ".", "objective", "[", "'bb_ce'", "]", "(", "bb_scores", ",", "sample_density", "=", "proposal_density", ",", "gt_density", "=", "gt_density", ",", "mc_dim", "=", "1", ")", "\n", "loss_bb_ce", "=", "self", ".", "loss_weight", "[", "'bb_ce'", "]", "*", "bb_ce", "\n", "\n", "loss_test_init_clf", "=", "0", "\n", "loss_test_iter_clf", "=", "0", "\n", "\n", "# Classification losses for the different optimization iterations", "\n", "clf_losses_test", "=", "[", "self", ".", "objective", "[", "'test_clf'", "]", "(", "s", ",", "data", "[", "'test_label'", "]", ",", "data", "[", "'test_anno'", "]", ")", "for", "s", "in", "target_scores", "]", "\n", "\n", "# Loss of the final filter", "\n", "clf_loss_test", "=", "clf_losses_test", "[", "-", "1", "]", "\n", "loss_target_classifier", "=", "self", ".", "loss_weight", "[", "'test_clf'", "]", "*", "clf_loss_test", "\n", "\n", "# Loss for the initial filter iteration", "\n", "if", "'test_init_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "loss_test_init_clf", "=", "self", ".", "loss_weight", "[", "'test_init_clf'", "]", "*", "clf_losses_test", "[", "0", "]", "\n", "\n", "# Loss for the intermediate filter iterations", "\n", "", "if", "'test_iter_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "test_iter_weights", "=", "self", ".", "loss_weight", "[", "'test_iter_clf'", "]", "\n", "if", "isinstance", "(", "test_iter_weights", ",", "list", ")", ":", "\n", "                ", "loss_test_iter_clf", "=", "sum", "(", "[", "a", "*", "b", "for", "a", ",", "b", "in", "zip", "(", "test_iter_weights", ",", "clf_losses_test", "[", "1", ":", "-", "1", "]", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "loss_test_iter_clf", "=", "(", "test_iter_weights", "/", "(", "len", "(", "clf_losses_test", ")", "-", "2", ")", ")", "*", "sum", "(", "clf_losses_test", "[", "1", ":", "-", "1", "]", ")", "\n", "\n", "# Total loss", "\n", "", "", "loss", "=", "loss_bb_ce", "+", "loss_target_classifier", "+", "loss_test_init_clf", "+", "loss_test_iter_clf", "\n", "\n", "if", "torch", ".", "isinf", "(", "loss", ")", "or", "torch", ".", "isnan", "(", "loss", ")", ":", "\n", "            ", "raise", "Exception", "(", "'ERROR: Loss was nan or inf!!!'", ")", "\n", "\n", "# Log stats", "\n", "", "stats", "=", "{", "'Loss/total'", ":", "loss", ".", "item", "(", ")", ",", "\n", "'Loss/bb_ce'", ":", "bb_ce", ".", "item", "(", ")", ",", "\n", "'Loss/loss_bb_ce'", ":", "loss_bb_ce", ".", "item", "(", ")", "}", "\n", "if", "'test_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'Loss/target_clf'", "]", "=", "loss_target_classifier", ".", "item", "(", ")", "\n", "", "if", "'test_init_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'Loss/test_init_clf'", "]", "=", "loss_test_init_clf", ".", "item", "(", ")", "\n", "", "if", "'test_iter_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'Loss/test_iter_clf'", "]", "=", "loss_test_iter_clf", ".", "item", "(", ")", "\n", "\n", "", "if", "'test_clf'", "in", "self", ".", "loss_weight", ".", "keys", "(", ")", ":", "\n", "            ", "stats", "[", "'ClfTrain/test_loss'", "]", "=", "clf_loss_test", ".", "item", "(", ")", "\n", "if", "len", "(", "clf_losses_test", ")", ">", "0", ":", "\n", "                ", "stats", "[", "'ClfTrain/test_init_loss'", "]", "=", "clf_losses_test", "[", "0", "]", ".", "item", "(", ")", "\n", "if", "len", "(", "clf_losses_test", ")", ">", "2", ":", "\n", "                    ", "stats", "[", "'ClfTrain/test_iter_loss'", "]", "=", "sum", "(", "clf_losses_test", "[", "1", ":", "-", "1", "]", ")", ".", "item", "(", ")", "/", "(", "len", "(", "clf_losses_test", ")", "-", "2", ")", "\n", "\n", "", "", "", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.TargetCandiateMatchingActor.__init__": [[474, 476], ["BaseActor.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "net", ",", "objective", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "net", ",", "objective", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.TargetCandiateMatchingActor.__call__": [[477, 514], ["tracking.TargetCandiateMatchingActor.net", "losses[].mean", "hasattr", "losses[].mean.item", "losses[].mean().item", "losses[].mean().item", "losses[].mean().item", "losses[].mean().item", "losses[].mean().item", "losses[].item", "tracking.TargetCandiateMatchingActor.objective[].metrics", "tracking.TargetCandiateMatchingActor.items", "torch.mean().item", "losses[].mean", "losses[].mean", "losses[].mean", "losses[].mean", "losses[].mean", "torch.mean", "torch.isnan"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.target_candidate_matching_loss.TargetCandidateMatchingLoss.metrics", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            data - The input data.\n\n        returns:\n            loss    - the training loss\n            stats  -  dict containing detailed losses\n        \"\"\"", "\n", "\n", "preds", "=", "self", ".", "net", "(", "**", "data", ")", "\n", "\n", "# Classification losses for the different optimization iterations", "\n", "losses", "=", "self", ".", "objective", "[", "'target_candidate_matching'", "]", "(", "**", "data", ",", "**", "preds", ")", "\n", "\n", "\n", "# Total loss", "\n", "loss", "=", "losses", "[", "'total'", "]", ".", "mean", "(", ")", "\n", "\n", "# Log stats", "\n", "stats", "=", "{", "\n", "'Loss/total'", ":", "loss", ".", "item", "(", ")", ",", "\n", "'Loss/nll_pos'", ":", "losses", "[", "'nll_pos'", "]", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "'Loss/nll_neg'", ":", "losses", "[", "'nll_neg'", "]", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "'Loss/num_matchable'", ":", "losses", "[", "'num_matchable'", "]", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "'Loss/num_unmatchable'", ":", "losses", "[", "'num_unmatchable'", "]", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "'Loss/sinkhorn_norm'", ":", "losses", "[", "'sinkhorn_norm'", "]", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "'Loss/bin_score'", ":", "losses", "[", "'bin_score'", "]", ".", "item", "(", ")", ",", "\n", "}", "\n", "\n", "if", "hasattr", "(", "self", ".", "objective", "[", "'target_candidate_matching'", "]", ",", "'metrics'", ")", ":", "\n", "            ", "metrics", "=", "self", ".", "objective", "[", "'target_candidate_matching'", "]", ".", "metrics", "(", "**", "data", ",", "**", "preds", ")", "\n", "\n", "for", "key", ",", "val", "in", "metrics", ".", "items", "(", ")", ":", "\n", "                ", "stats", "[", "key", "]", "=", "torch", ".", "mean", "(", "val", "[", "~", "torch", ".", "isnan", "(", "val", ")", "]", ")", ".", "item", "(", ")", "\n", "\n", "", "", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.ToMPActor.__init__": [[518, 523], ["BaseActor.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "net", ",", "objective", ",", "loss_weight", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "net", ",", "objective", ")", "\n", "if", "loss_weight", "is", "None", ":", "\n", "            ", "loss_weight", "=", "{", "'bb_ce'", ":", "1.0", "}", "\n", "", "self", ".", "loss_weight", "=", "loss_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.ToMPActor.compute_iou_at_max_score_pos": [[524, 537], ["[].view", "[].view", "ltrb_pred.unsqueeze.unsqueeze.dim", "ltrb_pred.unsqueeze.unsqueeze.unsqueeze", "scores.reshape().max", "scores.reshape", "ltrb_gth.flatten", "ltrb_pred.unsqueeze.unsqueeze.flatten", "[].view.view().min", "torch.arange", "torch.arange", "[].view.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "compute_iou_at_max_score_pos", "(", "self", ",", "scores", ",", "ltrb_gth", ",", "ltrb_pred", ")", ":", "\n", "        ", "if", "ltrb_pred", ".", "dim", "(", ")", "==", "4", ":", "\n", "            ", "ltrb_pred", "=", "ltrb_pred", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "n", "=", "scores", ".", "shape", "[", "1", "]", "\n", "ids", "=", "scores", ".", "reshape", "(", "1", ",", "n", ",", "-", "1", ")", ".", "max", "(", "dim", "=", "2", ")", "[", "1", "]", "\n", "g", "=", "ltrb_gth", ".", "flatten", "(", "3", ")", "[", "0", ",", "torch", ".", "arange", "(", "0", ",", "n", ")", ",", ":", ",", "ids", "]", ".", "view", "(", "1", ",", "n", ",", "4", ",", "1", ",", "1", ")", "\n", "p", "=", "ltrb_pred", ".", "flatten", "(", "3", ")", "[", "0", ",", "torch", ".", "arange", "(", "0", ",", "n", ")", ",", ":", ",", "ids", "]", ".", "view", "(", "1", ",", "n", ",", "4", ",", "1", ",", "1", ")", "\n", "\n", "_", ",", "ious_pred_center", "=", "self", ".", "objective", "[", "'giou'", "]", "(", "p", ",", "g", ")", "# nf x ns x x 4 x h x w", "\n", "ious_pred_center", "[", "g", ".", "view", "(", "n", ",", "4", ")", ".", "min", "(", "dim", "=", "1", ")", "[", "0", "]", "<", "0", "]", "=", "0", "\n", "\n", "return", "ious_pred_center", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.ToMPActor.__call__": [[538, 581], ["tracking.ToMPActor.net", "torch.isnan", "tracking.ToMPActor.compute_iou_at_max_score_pos", "ValueError", "loss.item", "loss_giou.item", "clf_loss_test.item", "ious.mean().item", "ious.max().item", "ious.min().item", "tracking.ToMPActor.mean().item", "ious.max().item", "ious[].std().item", "loss_giou.item", "clf_loss_test.item", "ious.mean", "ious.max", "ious.min", "tracking.ToMPActor.mean", "ious.max", "ious[].std"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan", "home.repos.pwc.inspect_result.visionml_pytracking.actors.tracking.ToMPActor.compute_iou_at_max_score_pos", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.std"], ["", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            data - The input data, should contain the fields 'train_images', 'test_images', 'train_anno',\n                    'test_proposals', 'proposal_iou' and 'test_label'.\n\n        returns:\n            loss    - the training loss\n            stats  -  dict containing detailed losses\n        \"\"\"", "\n", "# Run network", "\n", "target_scores", ",", "bbox_preds", "=", "self", ".", "net", "(", "train_imgs", "=", "data", "[", "'train_images'", "]", ",", "\n", "test_imgs", "=", "data", "[", "'test_images'", "]", ",", "\n", "train_bb", "=", "data", "[", "'train_anno'", "]", ",", "\n", "train_label", "=", "data", "[", "'train_label'", "]", ",", "\n", "train_ltrb_target", "=", "data", "[", "'train_ltrb_target'", "]", ")", "\n", "\n", "loss_giou", ",", "ious", "=", "self", ".", "objective", "[", "'giou'", "]", "(", "bbox_preds", ",", "data", "[", "'test_ltrb_target'", "]", ",", "data", "[", "'test_sample_region'", "]", ")", "\n", "\n", "# Classification losses for the different optimization iterations", "\n", "clf_loss_test", "=", "self", ".", "objective", "[", "'test_clf'", "]", "(", "target_scores", ",", "data", "[", "'test_label'", "]", ",", "data", "[", "'test_anno'", "]", ")", "\n", "\n", "loss", "=", "self", ".", "loss_weight", "[", "'giou'", "]", "*", "loss_giou", "+", "self", ".", "loss_weight", "[", "'test_clf'", "]", "*", "clf_loss_test", "\n", "\n", "if", "torch", ".", "isnan", "(", "loss", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'NaN detected in loss'", ")", "\n", "\n", "", "ious_pred_center", "=", "self", ".", "compute_iou_at_max_score_pos", "(", "target_scores", ",", "data", "[", "'test_ltrb_target'", "]", ",", "bbox_preds", ")", "\n", "\n", "stats", "=", "{", "'Loss/total'", ":", "loss", ".", "item", "(", ")", ",", "\n", "'Loss/GIoU'", ":", "loss_giou", ".", "item", "(", ")", ",", "\n", "'Loss/weighted_GIoU'", ":", "self", ".", "loss_weight", "[", "'giou'", "]", "*", "loss_giou", ".", "item", "(", ")", ",", "\n", "'Loss/clf_loss_test'", ":", "clf_loss_test", ".", "item", "(", ")", ",", "\n", "'Loss/weighted_clf_loss_test'", ":", "self", ".", "loss_weight", "[", "'test_clf'", "]", "*", "clf_loss_test", ".", "item", "(", ")", ",", "\n", "'mIoU'", ":", "ious", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "'maxIoU'", ":", "ious", ".", "max", "(", ")", ".", "item", "(", ")", ",", "\n", "'minIoU'", ":", "ious", ".", "min", "(", ")", ".", "item", "(", ")", ",", "\n", "'mIoU_pred_center'", ":", "ious_pred_center", ".", "mean", "(", ")", ".", "item", "(", ")", "}", "\n", "\n", "if", "ious", ".", "max", "(", ")", ".", "item", "(", ")", ">", "0", ":", "\n", "            ", "stats", "[", "'stdIoU'", "]", "=", "ious", "[", "ious", ">", "0", "]", ".", "std", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.segmentation.LWLActor.__init__": [[10, 33], ["BaseActor.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "classes", "=", "classes", "\n", "self", ".", "per_image", "=", "per_image", "\n", "\n", "", "def", "forward", "(", "self", ",", "input", ",", "target", ")", ":", "\n", "        ", "return", "lovasz_loss", ".", "lovasz_softmax", "(", "probas", "=", "torch", ".", "sigmoid", "(", "input", ")", ",", "labels", "=", "target", ",", "per_image", "=", "self", ".", "per_image", ",", "classes", "=", "self", ".", "classes", ")", "\n", "\n", "\n", "", "", "def", "one_hot", "(", "labels", ":", "torch", ".", "Tensor", ",", "\n", "num_classes", ":", "int", ",", "\n", "device", "=", "None", ",", "\n", "dtype", "=", "None", ",", "\n", "eps", "=", "1e-6", ")", "->", "torch", ".", "Tensor", ":", "\n", "    "]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.segmentation.LWLActor.train": [[34, 47], ["segmentation.LWLActor.net.train", "segmentation.LWLActor.net.eval", "segmentation.LWLActor.net.feature_extractor.modules", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval", "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval"], ["\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.segmentation.LWLActor.__call__": [[48, 88], ["segmentation.LWLActor.net", "segm_pred.view.view.view", "gt_segm.view.view.view", "sum", "len", "pytracking.analysis.vos_utils.davis_jaccard_measure", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isinf", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "Exception", "loss.item", "loss_segm.item", "lb.cpu().numpy", "zip", "torch.sigmoid().cpu().numpy", "torch.sigmoid().cpu().numpy", "torch.sigmoid().cpu().numpy", "torch.sigmoid().cpu().numpy", "segm_pred.view.view.view", "gt_segm.view.view.view", "lb.cpu", "torch.sigmoid().cpu", "torch.sigmoid().cpu", "torch.sigmoid().cpu", "torch.sigmoid().cpu", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "rm.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.davis_jaccard_measure", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan", "home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.isnan"], ["if", "not", "torch", ".", "is_tensor", "(", "labels", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\"Input labels type is not a torch.Tensor. Got {}\"", "\n", ".", "format", "(", "type", "(", "labels", ")", ")", ")", "\n", "", "if", "not", "labels", ".", "dtype", "==", "torch", ".", "int64", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"labels must be of the same dtype torch.int64. Got: {}\"", ".", "format", "(", "\n", "labels", ".", "dtype", ")", ")", "\n", "", "if", "num_classes", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"The number of classes must be bigger than one.\"", "\n", "\" Got: {}\"", ".", "format", "(", "num_classes", ")", ")", "\n", "", "shape", "=", "labels", ".", "shape", "\n", "one_hot", "=", "torch", ".", "zeros", "(", "(", "shape", "[", "0", "]", ",", "num_classes", ",", "shape", "[", "1", "]", ",", "shape", "[", "2", "]", ")", ")", ".", "to", "(", "device", ")", "\n", "return", "one_hot", ".", "scatter_", "(", "1", ",", "labels", ".", "unsqueeze", "(", "1", ")", ",", "1.0", ")", "+", "eps", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.segmentation.LWLBoxActor.__init__": [[92, 97], ["BaseActor.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], []], "home.repos.pwc.inspect_result.visionml_pytracking.actors.segmentation.LWLBoxActor.__call__": [[98, 141], ["segmentation.LWLBoxActor.net.extract_backbone_features", "segmentation.LWLBoxActor.net.extract_target_model_features", "bb_train.view.view.view", "segmentation.LWLBoxActor.net.box_label_encoder", "train_box_enc.view.view.view", "segmentation.LWLBoxActor.net.decoder", "sum", "len", "loss.item", "train_imgs.view", "pytracking.analysis.vos_utils.davis_jaccard_measure", "data[].view", "lb.cpu().numpy", "zip", "torch.sigmoid().cpu().numpy", "torch.sigmoid().cpu().numpy", "torch.sigmoid().cpu().numpy", "torch.sigmoid().cpu().numpy", "mask_pred_box_train.view", "data[].view", "lb.cpu", "torch.sigmoid().cpu", "torch.sigmoid().cpu", "torch.sigmoid().cpu", "torch.sigmoid().cpu", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "rm.detach"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.target_candidate_matching.target_candidate_matching.TargetCandidateMatchingNetwork.extract_backbone_features", "home.repos.pwc.inspect_result.visionml_pytracking.lwl.lwl_net.LWTLNet.extract_target_model_features", "home.repos.pwc.inspect_result.visionml_pytracking.analysis.vos_utils.davis_jaccard_measure"], []], "home.repos.pwc.inspect_result.visionml_pytracking.actors.bbreg.AtomActor.__call__": [[6, 30], ["bbreg.AtomActor.net", "iou_pred.view.view.view", "data[].view", "bbreg.AtomActor.objective", "bbreg.AtomActor.item", "bbreg.AtomActor.item"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            data - The input data, should contain the fields 'train_images', 'test_images', 'train_anno',\n                    'test_proposals' and 'proposal_iou'.\n\n        returns:\n            loss    - the training loss\n            states  -  dict containing detailed losses\n        \"\"\"", "\n", "# Run network to obtain IoU prediction for each proposal in 'test_proposals'", "\n", "iou_pred", "=", "self", ".", "net", "(", "data", "[", "'train_images'", "]", ",", "data", "[", "'test_images'", "]", ",", "data", "[", "'train_anno'", "]", ",", "data", "[", "'test_proposals'", "]", ")", "\n", "\n", "iou_pred", "=", "iou_pred", ".", "view", "(", "-", "1", ",", "iou_pred", ".", "shape", "[", "2", "]", ")", "\n", "iou_gt", "=", "data", "[", "'proposal_iou'", "]", ".", "view", "(", "-", "1", ",", "data", "[", "'proposal_iou'", "]", ".", "shape", "[", "2", "]", ")", "\n", "\n", "# Compute loss", "\n", "loss", "=", "self", ".", "objective", "(", "iou_pred", ",", "iou_gt", ")", "\n", "\n", "# Return training stats", "\n", "stats", "=", "{", "'Loss/total'", ":", "loss", ".", "item", "(", ")", ",", "\n", "'Loss/iou'", ":", "loss", ".", "item", "(", ")", "}", "\n", "\n", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.bbreg.AtomBBKLActor.__call__": [[34, 59], ["bbreg.AtomBBKLActor.net", "bb_scores.view.view.view", "data[].view", "data[].view", "bbreg.AtomBBKLActor.objective", "bbreg.AtomBBKLActor.item", "bbreg.AtomBBKLActor.item"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            data - The input data, should contain the fields 'train_images', 'test_images', 'train_anno',\n                    'test_proposals', 'proposal_density', and 'gt_density'.\n\n        returns:\n            loss    - the training loss\n            states  -  dict containing detailed losses\n        \"\"\"", "\n", "# Run network to obtain IoU prediction for each proposal in 'test_proposals'", "\n", "bb_scores", "=", "self", ".", "net", "(", "data", "[", "'train_images'", "]", ",", "data", "[", "'test_images'", "]", ",", "data", "[", "'train_anno'", "]", ",", "data", "[", "'test_proposals'", "]", ")", "\n", "\n", "bb_scores", "=", "bb_scores", ".", "view", "(", "-", "1", ",", "bb_scores", ".", "shape", "[", "2", "]", ")", "\n", "proposal_density", "=", "data", "[", "'proposal_density'", "]", ".", "view", "(", "-", "1", ",", "data", "[", "'proposal_density'", "]", ".", "shape", "[", "2", "]", ")", "\n", "gt_density", "=", "data", "[", "'gt_density'", "]", ".", "view", "(", "-", "1", ",", "data", "[", "'gt_density'", "]", ".", "shape", "[", "2", "]", ")", "\n", "\n", "# Compute loss", "\n", "loss", "=", "self", ".", "objective", "(", "bb_scores", ",", "sample_density", "=", "proposal_density", ",", "gt_density", "=", "gt_density", ",", "mc_dim", "=", "1", ")", "\n", "\n", "# Return training stats", "\n", "stats", "=", "{", "'Loss/total'", ":", "loss", ".", "item", "(", ")", ",", "\n", "'Loss/bb_ce'", ":", "loss", ".", "item", "(", ")", "}", "\n", "\n", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.__init__": [[7, 15], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "net", ",", "objective", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            net - The network to train\n            objective - The loss function\n        \"\"\"", "\n", "self", ".", "net", "=", "net", "\n", "self", ".", "objective", "=", "objective", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.__call__": [[16, 27], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "        ", "\"\"\" Called in each training iteration. Should pass in input data through the network, calculate the loss, and\n        return the training stats for the input data\n        args:\n            data - A TensorDict containing all the necessary data blocks.\n\n        returns:\n            loss    - loss for the input data\n            stats   - a dict containing detailed losses\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to": [[28, 34], ["base_actor.BaseActor.net.to"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.to"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "\"\"\" Move the network to device\n        args:\n            device - device to use. 'cpu' or 'cuda'\n        \"\"\"", "\n", "self", ".", "net", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train": [[35, 41], ["base_actor.BaseActor.net.train"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train"], ["", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "\"\"\" Set whether the network is in train mode.\n        args:\n            mode (True) - Bool specifying whether in training mode.\n        \"\"\"", "\n", "self", ".", "net", ".", "train", "(", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.eval": [[42, 45], ["base_actor.BaseActor.train"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.actors.base_actor.BaseActor.train"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "\"\"\" Set network to eval mode\"\"\"", "\n", "self", ".", "train", "(", "False", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.Transform.__init__": [[35, 42], ["isinstance", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", "transforms", ")", ":", "\n", "        ", "if", "len", "(", "transforms", ")", "==", "1", "and", "isinstance", "(", "transforms", "[", "0", "]", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "transforms", "=", "transforms", "[", "0", "]", "\n", "", "self", ".", "transforms", "=", "transforms", "\n", "self", ".", "_valid_inputs", "=", "[", "'image'", ",", "'coords'", ",", "'bbox'", ",", "'mask'", "]", "\n", "self", ".", "_valid_args", "=", "[", "'joint'", ",", "'new_roll'", "]", "\n", "self", ".", "_valid_all", "=", "self", ".", "_valid_inputs", "+", "self", ".", "_valid_args", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.Transform.__call__": [[43, 64], ["inputs.keys", "inputs.get", "inputs.get", "tuple", "zip", "tuple", "t", "len", "inputs.keys", "ValueError", "inputs.items", "list", "transforms.Transform.", "transforms.Transform._split_inputs"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.Transform._split_inputs"], ["", "def", "__call__", "(", "self", ",", "**", "inputs", ")", ":", "\n", "        ", "var_names", "=", "[", "k", "for", "k", "in", "inputs", ".", "keys", "(", ")", "if", "k", "in", "self", ".", "_valid_inputs", "]", "\n", "for", "v", "in", "inputs", ".", "keys", "(", ")", ":", "\n", "            ", "if", "v", "not", "in", "self", ".", "_valid_all", ":", "\n", "                ", "raise", "ValueError", "(", "'Incorrect input \\\"{}\\\" to transform. Only supports inputs {} and arguments {}.'", ".", "format", "(", "v", ",", "self", ".", "_valid_inputs", ",", "self", ".", "_valid_args", ")", ")", "\n", "\n", "", "", "joint_mode", "=", "inputs", ".", "get", "(", "'joint'", ",", "True", ")", "\n", "new_roll", "=", "inputs", ".", "get", "(", "'new_roll'", ",", "True", ")", "\n", "\n", "if", "not", "joint_mode", ":", "\n", "            ", "out", "=", "zip", "(", "*", "[", "self", "(", "**", "inp", ")", "for", "inp", "in", "self", ".", "_split_inputs", "(", "inputs", ")", "]", ")", "\n", "return", "tuple", "(", "list", "(", "o", ")", "for", "o", "in", "out", ")", "\n", "\n", "", "out", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "inputs", ".", "items", "(", ")", "if", "k", "in", "self", ".", "_valid_inputs", "}", "\n", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "out", "=", "t", "(", "**", "out", ",", "joint", "=", "joint_mode", ",", "new_roll", "=", "new_roll", ")", "\n", "", "if", "len", "(", "var_names", ")", "==", "1", ":", "\n", "            ", "return", "out", "[", "var_names", "[", "0", "]", "]", "\n", "# Make sure order is correct", "\n", "", "return", "tuple", "(", "out", "[", "v", "]", "for", "v", "in", "var_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.Transform._split_inputs": [[65, 76], ["filter", "inputs.items", "isinstance", "inputs.keys", "zip", "zip", "zip"], "methods", ["None"], ["", "def", "_split_inputs", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "var_names", "=", "[", "k", "for", "k", "in", "inputs", ".", "keys", "(", ")", "if", "k", "in", "self", ".", "_valid_inputs", "]", "\n", "split_inputs", "=", "[", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "var_names", ",", "vals", ")", "}", "for", "vals", "in", "zip", "(", "*", "[", "inputs", "[", "vn", "]", "for", "vn", "in", "var_names", "]", ")", "]", "\n", "for", "arg_name", ",", "arg_val", "in", "filter", "(", "lambda", "it", ":", "it", "[", "0", "]", "!=", "'joint'", "and", "it", "[", "0", "]", "in", "self", ".", "_valid_args", ",", "inputs", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "arg_val", ",", "list", ")", ":", "\n", "                ", "for", "inp", ",", "av", "in", "zip", "(", "split_inputs", ",", "arg_val", ")", ":", "\n", "                    ", "inp", "[", "arg_name", "]", "=", "av", "\n", "", "", "else", ":", "\n", "                ", "for", "inp", "in", "split_inputs", ":", "\n", "                    ", "inp", "[", "arg_name", "]", "=", "arg_val", "\n", "", "", "", "return", "split_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.Transform.__repr__": [[77, 84], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "format_string", "+=", "'\\n'", "\n", "format_string", "+=", "'    {0}'", ".", "format", "(", "t", ")", "\n", "", "format_string", "+=", "'\\n)'", "\n", "return", "format_string", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.TransformBase.__init__": [[88, 93], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_valid_inputs", "=", "[", "'image'", ",", "'coords'", ",", "'bbox'", ",", "'mask'", "]", "\n", "self", ".", "_valid_args", "=", "[", "'new_roll'", "]", "\n", "self", ".", "_valid_all", "=", "self", ".", "_valid_inputs", "+", "self", ".", "_valid_args", "\n", "self", ".", "_rand_params", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.TransformBase.__call__": [[94, 121], ["input_args.get", "dict", "input_vars.items", "transforms.TransformBase.roll", "inputs.items", "inputs.items", "getattr", "isinstance", "isinstance", "getattr.", "getattr.", "transforms.TransformBase._get_image_size"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine.roll", "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.TransformBase._get_image_size"], ["", "def", "__call__", "(", "self", ",", "**", "inputs", ")", ":", "\n", "# Split input", "\n", "        ", "input_vars", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "inputs", ".", "items", "(", ")", "if", "k", "in", "self", ".", "_valid_inputs", "}", "\n", "input_args", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "inputs", ".", "items", "(", ")", "if", "k", "in", "self", ".", "_valid_args", "}", "\n", "\n", "# Roll random parameters for the transform", "\n", "if", "input_args", ".", "get", "(", "'new_roll'", ",", "True", ")", ":", "\n", "            ", "rand_params", "=", "self", ".", "roll", "(", ")", "\n", "if", "rand_params", "is", "None", ":", "\n", "                ", "rand_params", "=", "(", ")", "\n", "", "elif", "not", "isinstance", "(", "rand_params", ",", "tuple", ")", ":", "\n", "                ", "rand_params", "=", "(", "rand_params", ",", ")", "\n", "", "self", ".", "_rand_params", "=", "rand_params", "\n", "\n", "", "outputs", "=", "dict", "(", ")", "\n", "for", "var_name", ",", "var", "in", "input_vars", ".", "items", "(", ")", ":", "\n", "            ", "if", "var", "is", "not", "None", ":", "\n", "                ", "transform_func", "=", "getattr", "(", "self", ",", "'transform_'", "+", "var_name", ")", "\n", "if", "var_name", "in", "[", "'coords'", ",", "'bbox'", "]", ":", "\n", "                    ", "params", "=", "(", "self", ".", "_get_image_size", "(", "input_vars", ")", ",", ")", "+", "self", ".", "_rand_params", "\n", "", "else", ":", "\n", "                    ", "params", "=", "self", ".", "_rand_params", "\n", "", "if", "isinstance", "(", "var", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                    ", "outputs", "[", "var_name", "]", "=", "[", "transform_func", "(", "x", ",", "*", "params", ")", "for", "x", "in", "var", "]", "\n", "", "else", ":", "\n", "                    ", "outputs", "[", "var_name", "]", "=", "transform_func", "(", "var", ",", "*", "params", ")", "\n", "", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.TransformBase._get_image_size": [[122, 137], ["isinstance", "isinstance", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "Exception", "inputs.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "_get_image_size", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "im", "=", "None", "\n", "for", "var_name", "in", "[", "'image'", ",", "'mask'", "]", ":", "\n", "            ", "if", "inputs", ".", "get", "(", "var_name", ")", "is", "not", "None", ":", "\n", "                ", "im", "=", "inputs", "[", "var_name", "]", "\n", "break", "\n", "", "", "if", "im", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "if", "isinstance", "(", "im", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "im", "=", "im", "[", "0", "]", "\n", "", "if", "isinstance", "(", "im", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "return", "im", ".", "shape", "[", ":", "2", "]", "\n", "", "if", "torch", ".", "is_tensor", "(", "im", ")", ":", "\n", "            ", "return", "(", "im", ".", "shape", "[", "-", "2", "]", ",", "im", ".", "shape", "[", "-", "1", "]", ")", "\n", "", "raise", "Exception", "(", "'Unknown image type'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.TransformBase.roll": [[138, 140], ["None"], "methods", ["None"], ["", "def", "roll", "(", "self", ")", ":", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.TransformBase.transform_image": [[141, 144], ["None"], "methods", ["None"], ["", "def", "transform_image", "(", "self", ",", "image", ",", "*", "rand_params", ")", ":", "\n", "        ", "\"\"\"Must be deterministic\"\"\"", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.TransformBase.transform_coords": [[145, 148], ["None"], "methods", ["None"], ["", "def", "transform_coords", "(", "self", ",", "coords", ",", "image_shape", ",", "*", "rand_params", ")", ":", "\n", "        ", "\"\"\"Must be deterministic\"\"\"", "\n", "return", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.TransformBase.transform_bbox": [[149, 170], ["bbox.clone().view().t().flip", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "transforms.TransformBase.transform_coords().flip", "torch.cat().reshape", "torch.cat().reshape", "torch.cat().reshape", "torch.cat().reshape", "torch.min", "torch.min", "torch.min", "torch.min", "bbox.clone().view().t", "transforms.TransformBase.transform_coords", "torch.max", "torch.max", "torch.max", "torch.max", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bbox.clone().view", "bbox.clone"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine.transform_coords"], ["", "def", "transform_bbox", "(", "self", ",", "bbox", ",", "image_shape", ",", "*", "rand_params", ")", ":", "\n", "        ", "\"\"\"Assumes [x, y, w, h]\"\"\"", "\n", "# Check if not overloaded", "\n", "if", "self", ".", "transform_coords", ".", "__code__", "==", "TransformBase", ".", "transform_coords", ".", "__code__", ":", "\n", "            ", "return", "bbox", "\n", "\n", "", "coord", "=", "bbox", ".", "clone", "(", ")", ".", "view", "(", "-", "1", ",", "2", ")", ".", "t", "(", ")", ".", "flip", "(", "0", ")", "\n", "\n", "x1", "=", "coord", "[", "1", ",", "0", "]", "\n", "x2", "=", "coord", "[", "1", ",", "0", "]", "+", "coord", "[", "1", ",", "1", "]", "\n", "\n", "y1", "=", "coord", "[", "0", ",", "0", "]", "\n", "y2", "=", "coord", "[", "0", ",", "0", "]", "+", "coord", "[", "0", ",", "1", "]", "\n", "\n", "coord_all", "=", "torch", ".", "tensor", "(", "[", "[", "y1", ",", "y1", ",", "y2", ",", "y2", "]", ",", "[", "x1", ",", "x2", ",", "x2", ",", "x1", "]", "]", ")", "\n", "\n", "coord_transf", "=", "self", ".", "transform_coords", "(", "coord_all", ",", "image_shape", ",", "*", "rand_params", ")", ".", "flip", "(", "0", ")", "\n", "tl", "=", "torch", ".", "min", "(", "coord_transf", ",", "dim", "=", "1", ")", "[", "0", "]", "\n", "sz", "=", "torch", ".", "max", "(", "coord_transf", ",", "dim", "=", "1", ")", "[", "0", "]", "-", "tl", "\n", "bbox_out", "=", "torch", ".", "cat", "(", "(", "tl", ",", "sz", ")", ",", "dim", "=", "-", "1", ")", ".", "reshape", "(", "bbox", ".", "shape", ")", "\n", "return", "bbox_out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.TransformBase.transform_mask": [[171, 174], ["None"], "methods", ["None"], ["", "def", "transform_mask", "(", "self", ",", "mask", ",", "*", "rand_params", ")", ":", "\n", "        ", "\"\"\"Must be deterministic\"\"\"", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.ToTensor.transform_image": [[179, 190], ["torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "isinstance", "torch.from_numpy.transpose", "torch.from_numpy.transpose", "torch.from_numpy.float().div", "torch.from_numpy.float().div", "torch.from_numpy.float", "torch.from_numpy.float"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.div", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.div"], ["def", "transform_image", "(", "self", ",", "image", ")", ":", "\n", "# handle numpy array", "\n", "        ", "if", "image", ".", "ndim", "==", "2", ":", "\n", "            ", "image", "=", "image", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "image", "=", "torch", ".", "from_numpy", "(", "image", ".", "transpose", "(", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "# backward compatibility", "\n", "if", "isinstance", "(", "image", ",", "torch", ".", "ByteTensor", ")", ":", "\n", "            ", "return", "image", ".", "float", "(", ")", ".", "div", "(", "255", ")", "\n", "", "else", ":", "\n", "            ", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.ToTensor.transfrom_mask": [[191, 194], ["isinstance", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "", "def", "transfrom_mask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "if", "isinstance", "(", "mask", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "return", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.ToTensorAndJitter.__init__": [[199, 203], ["transforms.TransformBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "brightness_jitter", "=", "0.0", ",", "normalize", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "brightness_jitter", "=", "brightness_jitter", "\n", "self", ".", "normalize", "=", "normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.ToTensorAndJitter.roll": [[204, 206], ["numpy.random.uniform", "max"], "methods", ["None"], ["", "def", "roll", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "random", ".", "uniform", "(", "max", "(", "0", ",", "1", "-", "self", ".", "brightness_jitter", ")", ",", "1", "+", "self", ".", "brightness_jitter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.ToTensorAndJitter.transform_image": [[207, 216], ["torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy.transpose", "torch.from_numpy.transpose", "torch.from_numpy.float().mul().clamp", "torch.from_numpy.float().mul().clamp", "torch.from_numpy.float().mul().clamp", "torch.from_numpy.float().mul().clamp", "torch.from_numpy.float().mul", "torch.from_numpy.float().mul", "torch.from_numpy.float().mul", "torch.from_numpy.float().mul", "torch.from_numpy.float", "torch.from_numpy.float", "torch.from_numpy.float", "torch.from_numpy.float"], "methods", ["None"], ["", "def", "transform_image", "(", "self", ",", "image", ",", "brightness_factor", ")", ":", "\n", "# handle numpy array", "\n", "        ", "image", "=", "torch", ".", "from_numpy", "(", "image", ".", "transpose", "(", "(", "2", ",", "0", ",", "1", ")", ")", ")", "\n", "\n", "# backward compatibility", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "return", "image", ".", "float", "(", ")", ".", "mul", "(", "brightness_factor", "/", "255.0", ")", ".", "clamp", "(", "0.0", ",", "1.0", ")", "\n", "", "else", ":", "\n", "            ", "return", "image", ".", "float", "(", ")", ".", "mul", "(", "brightness_factor", ")", ".", "clamp", "(", "0.0", ",", "255.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.ToTensorAndJitter.transform_mask": [[217, 222], ["isinstance", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "", "def", "transform_mask", "(", "self", ",", "mask", ",", "brightness_factor", ")", ":", "\n", "        ", "if", "isinstance", "(", "mask", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "return", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "", "else", ":", "\n", "            ", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.Normalize.__init__": [[226, 231], ["transforms.TransformBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "mean", ",", "std", ",", "inplace", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "self", ".", "inplace", "=", "inplace", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.Normalize.transform_image": [[232, 234], ["torchvision.normalize"], "methods", ["None"], ["", "def", "transform_image", "(", "self", ",", "image", ")", ":", "\n", "        ", "return", "tvisf", ".", "normalize", "(", "image", ",", "self", ".", "mean", ",", "self", ".", "std", ",", "self", ".", "inplace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.ToGrayscale.__init__": [[238, 242], ["transforms.TransformBase.__init__", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "probability", "=", "0.5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "probability", "=", "probability", "\n", "self", ".", "color_weights", "=", "np", ".", "array", "(", "[", "0.2989", ",", "0.5870", ",", "0.1140", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.ToGrayscale.roll": [[243, 245], ["random.random"], "methods", ["None"], ["", "def", "roll", "(", "self", ")", ":", "\n", "        ", "return", "random", ".", "random", "(", ")", "<", "self", ".", "probability", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.ToGrayscale.transform_image": [[246, 254], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "cv2.cvtColor", "numpy.stack", "NotImplementedError"], "methods", ["None"], ["", "def", "transform_image", "(", "self", ",", "image", ",", "do_grayscale", ")", ":", "\n", "        ", "if", "do_grayscale", ":", "\n", "            ", "if", "torch", ".", "is_tensor", "(", "image", ")", ":", "\n", "                ", "raise", "NotImplementedError", "(", "'Implement torch variant.'", ")", "\n", "", "img_gray", "=", "cv", ".", "cvtColor", "(", "image", ",", "cv", ".", "COLOR_RGB2GRAY", ")", "\n", "return", "np", ".", "stack", "(", "[", "img_gray", ",", "img_gray", ",", "img_gray", "]", ",", "axis", "=", "2", ")", "\n", "# return np.repeat(np.sum(img * self.color_weights, axis=2, keepdims=True).astype(np.uint8), 3, axis=2)", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.ToBGR.transform_image": [[258, 263], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "cv2.cvtColor", "NotImplementedError"], "methods", ["None"], ["def", "transform_image", "(", "self", ",", "image", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "image", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'Implement torch variant.'", ")", "\n", "", "img_bgr", "=", "cv", ".", "cvtColor", "(", "image", ",", "cv", ".", "COLOR_RGB2BGR", ")", "\n", "return", "img_bgr", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomHorizontalFlip.__init__": [[267, 270], ["transforms.TransformBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "probability", "=", "0.5", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "probability", "=", "probability", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomHorizontalFlip.roll": [[271, 273], ["random.random"], "methods", ["None"], ["", "def", "roll", "(", "self", ")", ":", "\n", "        ", "return", "random", ".", "random", "(", ")", "<", "self", ".", "probability", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomHorizontalFlip.transform_image": [[274, 280], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "numpy.fliplr().copy", "image.flip", "numpy.fliplr"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "def", "transform_image", "(", "self", ",", "image", ",", "do_flip", ")", ":", "\n", "        ", "if", "do_flip", ":", "\n", "            ", "if", "torch", ".", "is_tensor", "(", "image", ")", ":", "\n", "                ", "return", "image", ".", "flip", "(", "(", "2", ",", ")", ")", "\n", "", "return", "np", ".", "fliplr", "(", "image", ")", ".", "copy", "(", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomHorizontalFlip.transform_coords": [[281, 286], ["coords.clone.clone.clone"], "methods", ["None"], ["", "def", "transform_coords", "(", "self", ",", "coords", ",", "image_shape", ",", "do_flip", ")", ":", "\n", "        ", "if", "do_flip", ":", "\n", "            ", "coords", "=", "coords", ".", "clone", "(", ")", "\n", "coords", "[", "1", ",", ":", "]", "=", "(", "image_shape", "[", "1", "]", "-", "1", ")", "-", "coords", "[", "1", ",", ":", "]", "\n", "", "return", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomHorizontalFlip.transform_mask": [[287, 293], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "numpy.fliplr().copy", "mask.flip", "numpy.fliplr"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.evaluation.data.SequenceList.copy"], ["", "def", "transform_mask", "(", "self", ",", "mask", ",", "do_flip", ")", ":", "\n", "        ", "if", "do_flip", ":", "\n", "            ", "if", "torch", ".", "is_tensor", "(", "mask", ")", ":", "\n", "                ", "return", "mask", ".", "flip", "(", "(", "-", "1", ",", ")", ")", "\n", "", "return", "np", ".", "fliplr", "(", "mask", ")", ".", "copy", "(", ")", "\n", "", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.Blur.__init__": [[297, 307], ["transforms.TransformBase.__init__", "isinstance", "math.ceil", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "transforms.Blur.filter[].view", "transforms.Blur.filter[].sum", "transforms.Blur.filter[].view", "transforms.Blur.filter[].sum", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "sigma", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "sigma", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "            ", "sigma", "=", "(", "sigma", ",", "sigma", ")", "\n", "", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "filter_size", "=", "[", "math", ".", "ceil", "(", "2", "*", "s", ")", "for", "s", "in", "self", ".", "sigma", "]", "\n", "x_coord", "=", "[", "torch", ".", "arange", "(", "-", "sz", ",", "sz", "+", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "sz", "in", "self", ".", "filter_size", "]", "\n", "self", ".", "filter", "=", "[", "torch", ".", "exp", "(", "-", "(", "x", "**", "2", ")", "/", "(", "2", "*", "s", "**", "2", ")", ")", "for", "x", ",", "s", "in", "zip", "(", "x_coord", ",", "self", ".", "sigma", ")", "]", "\n", "self", ".", "filter", "[", "0", "]", "=", "self", ".", "filter", "[", "0", "]", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", "/", "self", ".", "filter", "[", "0", "]", ".", "sum", "(", ")", "\n", "self", ".", "filter", "[", "1", "]", "=", "self", ".", "filter", "[", "1", "]", ".", "view", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", "/", "self", ".", "filter", "[", "1", "]", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.Blur.transform_image": [[308, 315], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.conv2d", "torch.conv2d", "torch.conv2d().view", "torch.conv2d().view", "image.view", "torch.conv2d", "torch.conv2d"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["", "def", "transform_image", "(", "self", ",", "image", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "image", ")", ":", "\n", "            ", "sz", "=", "image", ".", "shape", "[", "2", ":", "]", "\n", "im1", "=", "F", ".", "conv2d", "(", "image", ".", "view", "(", "-", "1", ",", "1", ",", "sz", "[", "0", "]", ",", "sz", "[", "1", "]", ")", ",", "self", ".", "filter", "[", "0", "]", ",", "padding", "=", "(", "self", ".", "filter_size", "[", "0", "]", ",", "0", ")", ")", "\n", "return", "F", ".", "conv2d", "(", "im1", ",", "self", ".", "filter", "[", "1", "]", ",", "padding", "=", "(", "0", ",", "self", ".", "filter_size", "[", "1", "]", ")", ")", ".", "view", "(", "-", "1", ",", "sz", "[", "0", "]", ",", "sz", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomBlur.__init__": [[319, 331], ["transforms.TransformBase.__init__", "isinstance", "math.ceil", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "transforms.RandomBlur.filter[].view", "transforms.RandomBlur.filter[].sum", "transforms.RandomBlur.filter[].view", "transforms.RandomBlur.filter[].sum", "zip"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "sigma", ",", "probability", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "probability", "=", "probability", "\n", "\n", "if", "isinstance", "(", "sigma", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "            ", "sigma", "=", "(", "sigma", ",", "sigma", ")", "\n", "", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "filter_size", "=", "[", "math", ".", "ceil", "(", "2", "*", "s", ")", "for", "s", "in", "self", ".", "sigma", "]", "\n", "x_coord", "=", "[", "torch", ".", "arange", "(", "-", "sz", ",", "sz", "+", "1", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "sz", "in", "self", ".", "filter_size", "]", "\n", "self", ".", "filter", "=", "[", "torch", ".", "exp", "(", "-", "(", "x", "**", "2", ")", "/", "(", "2", "*", "s", "**", "2", ")", ")", "for", "x", ",", "s", "in", "zip", "(", "x_coord", ",", "self", ".", "sigma", ")", "]", "\n", "self", ".", "filter", "[", "0", "]", "=", "self", ".", "filter", "[", "0", "]", ".", "view", "(", "1", ",", "1", ",", "-", "1", ",", "1", ")", "/", "self", ".", "filter", "[", "0", "]", ".", "sum", "(", ")", "\n", "self", ".", "filter", "[", "1", "]", "=", "self", ".", "filter", "[", "1", "]", ".", "view", "(", "1", ",", "1", ",", "1", ",", "-", "1", ")", "/", "self", ".", "filter", "[", "1", "]", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomBlur.roll": [[332, 334], ["random.random"], "methods", ["None"], ["", "def", "roll", "(", "self", ")", ":", "\n", "        ", "return", "random", ".", "random", "(", ")", "<", "self", ".", "probability", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomBlur.transform": [[335, 348], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.conv2d", "torch.conv2d", "torch.conv2d().view", "torch.conv2d().view", "image.view", "torch.conv2d", "torch.conv2d"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d", "home.repos.pwc.inspect_result.visionml_pytracking.libs.operation.conv2d"], ["", "def", "transform", "(", "self", ",", "image", ",", "do_blur", "=", "None", ")", ":", "\n", "        ", "if", "do_blur", "is", "None", ":", "\n", "            ", "do_blur", "=", "False", "\n", "\n", "", "if", "do_blur", ":", "\n", "            ", "if", "torch", ".", "is_tensor", "(", "image", ")", ":", "\n", "                ", "sz", "=", "image", ".", "shape", "[", "1", ":", "]", "\n", "im1", "=", "F", ".", "conv2d", "(", "image", ".", "view", "(", "-", "1", ",", "1", ",", "sz", "[", "0", "]", ",", "sz", "[", "1", "]", ")", ",", "self", ".", "filter", "[", "0", "]", ",", "padding", "=", "(", "self", ".", "filter_size", "[", "0", "]", ",", "0", ")", ")", "\n", "return", "F", ".", "conv2d", "(", "im1", ",", "self", ".", "filter", "[", "1", "]", ",", "padding", "=", "(", "0", ",", "self", ".", "filter_size", "[", "1", "]", ")", ")", ".", "view", "(", "-", "1", ",", "sz", "[", "0", "]", ",", "sz", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "", "else", ":", "\n", "            ", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine.__init__": [[352, 369], ["transforms.TransformBase.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "p_flip", "=", "0.0", ",", "max_rotation", "=", "0.0", ",", "max_shear", "=", "0.0", ",", "max_scale", "=", "0.0", ",", "max_ar_factor", "=", "0.0", ",", "\n", "border_mode", "=", "'constant'", ",", "pad_amount", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "p_flip", "=", "p_flip", "\n", "self", ".", "max_rotation", "=", "max_rotation", "\n", "self", ".", "max_shear", "=", "max_shear", "\n", "self", ".", "max_scale", "=", "max_scale", "\n", "self", ".", "max_ar_factor", "=", "max_ar_factor", "\n", "\n", "if", "border_mode", "==", "'constant'", ":", "\n", "            ", "self", ".", "border_flag", "=", "cv", ".", "BORDER_CONSTANT", "\n", "", "elif", "border_mode", "==", "'replicate'", ":", "\n", "            ", "self", ".", "border_flag", "==", "cv", ".", "BORDER_REPLICATE", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "\n", "\n", "", "self", ".", "pad_amount", "=", "pad_amount", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine.roll": [[370, 381], ["random.uniform", "random.uniform", "random.uniform", "numpy.exp", "numpy.exp", "random.random", "random.uniform", "random.uniform"], "methods", ["None"], ["", "def", "roll", "(", "self", ")", ":", "\n", "        ", "do_flip", "=", "random", ".", "random", "(", ")", "<", "self", ".", "p_flip", "\n", "theta", "=", "random", ".", "uniform", "(", "-", "self", ".", "max_rotation", ",", "self", ".", "max_rotation", ")", "\n", "\n", "shear_x", "=", "random", ".", "uniform", "(", "-", "self", ".", "max_shear", ",", "self", ".", "max_shear", ")", "\n", "shear_y", "=", "random", ".", "uniform", "(", "-", "self", ".", "max_shear", ",", "self", ".", "max_shear", ")", "\n", "\n", "ar_factor", "=", "np", ".", "exp", "(", "random", ".", "uniform", "(", "-", "self", ".", "max_ar_factor", ",", "self", ".", "max_ar_factor", ")", ")", "\n", "scale_factor", "=", "np", ".", "exp", "(", "random", ".", "uniform", "(", "-", "self", ".", "max_scale", ",", "self", ".", "max_scale", ")", ")", "\n", "\n", "return", "do_flip", ",", "theta", ",", "(", "shear_x", ",", "shear_y", ")", ",", "(", "scale_factor", ",", "scale_factor", "*", "ar_factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine._construct_t_mat": [[382, 410], ["numpy.identity", "cv2.getRotationMatrix2D", "numpy.concatenate", "numpy.array", "numpy.array", "numpy.array().reshape", "numpy.array"], "methods", ["None"], ["", "def", "_construct_t_mat", "(", "self", ",", "image_shape", ",", "do_flip", ",", "theta", ",", "shear_values", ",", "scale_factors", ")", ":", "\n", "        ", "im_h", ",", "im_w", "=", "image_shape", "\n", "t_mat", "=", "np", ".", "identity", "(", "3", ")", "\n", "\n", "if", "do_flip", ":", "\n", "            ", "if", "do_flip", ":", "\n", "                ", "t_mat", "[", "0", ",", "0", "]", "=", "-", "1.0", "\n", "t_mat", "[", "0", ",", "2", "]", "=", "im_w", "\n", "\n", "", "", "t_rot", "=", "cv", ".", "getRotationMatrix2D", "(", "(", "im_w", "*", "0.5", ",", "im_h", "*", "0.5", ")", ",", "theta", ",", "1.0", ")", "\n", "t_rot", "=", "np", ".", "concatenate", "(", "(", "t_rot", ",", "np", ".", "array", "(", "[", "0.0", ",", "0.0", ",", "1.0", "]", ")", ".", "reshape", "(", "1", ",", "3", ")", ")", ")", "\n", "\n", "t_shear", "=", "np", ".", "array", "(", "[", "[", "1.0", ",", "shear_values", "[", "0", "]", ",", "-", "shear_values", "[", "0", "]", "*", "0.5", "*", "im_w", "]", ",", "\n", "[", "shear_values", "[", "1", "]", ",", "1.0", ",", "-", "shear_values", "[", "1", "]", "*", "0.5", "*", "im_h", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", "\n", "\n", "t_scale", "=", "np", ".", "array", "(", "[", "[", "scale_factors", "[", "0", "]", ",", "0.0", ",", "(", "1.0", "-", "scale_factors", "[", "0", "]", ")", "*", "0.5", "*", "im_w", "]", ",", "\n", "[", "0.0", ",", "scale_factors", "[", "1", "]", ",", "(", "1.0", "-", "scale_factors", "[", "1", "]", ")", "*", "0.5", "*", "im_h", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", "\n", "\n", "t_mat", "=", "t_scale", "@", "t_rot", "@", "t_shear", "@", "t_mat", "\n", "\n", "t_mat", "[", "0", ",", "2", "]", "+=", "self", ".", "pad_amount", "\n", "t_mat", "[", "1", ",", "2", "]", "+=", "self", ".", "pad_amount", "\n", "\n", "t_mat", "=", "t_mat", "[", ":", "2", ",", ":", "]", "\n", "\n", "return", "t_mat", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine.transform_image": [[411, 421], ["torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "transforms.RandomAffine._construct_t_mat", "cv2.warpAffine", "Exception"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine._construct_t_mat"], ["", "def", "transform_image", "(", "self", ",", "image", ",", "do_flip", ",", "theta", ",", "shear_values", ",", "scale_factors", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "image", ")", ":", "\n", "            ", "raise", "Exception", "(", "'Only supported for numpy input'", ")", "\n", "\n", "", "t_mat", "=", "self", ".", "_construct_t_mat", "(", "image", ".", "shape", "[", ":", "2", "]", ",", "do_flip", ",", "theta", ",", "shear_values", ",", "scale_factors", ")", "\n", "output_sz", "=", "(", "image", ".", "shape", "[", "1", "]", "+", "2", "*", "self", ".", "pad_amount", ",", "image", ".", "shape", "[", "0", "]", "+", "2", "*", "self", ".", "pad_amount", ")", "\n", "image_t", "=", "cv", ".", "warpAffine", "(", "image", ",", "t_mat", ",", "output_sz", ",", "flags", "=", "cv", ".", "INTER_LINEAR", ",", "\n", "borderMode", "=", "self", ".", "border_flag", ")", "\n", "\n", "return", "image_t", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine.transform_coords": [[422, 432], ["transforms.RandomAffine._construct_t_mat", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine._construct_t_mat"], ["", "def", "transform_coords", "(", "self", ",", "coords", ",", "image_shape", ",", "do_flip", ",", "theta", ",", "shear_values", ",", "scale_factors", ")", ":", "\n", "        ", "t_mat", "=", "self", ".", "_construct_t_mat", "(", "image_shape", ",", "do_flip", ",", "theta", ",", "shear_values", ",", "scale_factors", ")", "\n", "\n", "t_mat_tensor", "=", "torch", ".", "from_numpy", "(", "t_mat", ")", ".", "float", "(", ")", "\n", "\n", "coords_xy1", "=", "torch", ".", "stack", "(", "(", "coords", "[", "1", ",", ":", "]", ",", "coords", "[", "0", ",", ":", "]", ",", "torch", ".", "ones_like", "(", "coords", "[", "1", ",", ":", "]", ")", ")", ")", "\n", "\n", "coords_xy_t", "=", "torch", ".", "mm", "(", "t_mat_tensor", ",", "coords_xy1", ")", "\n", "\n", "return", "coords_xy_t", "[", "[", "1", ",", "0", "]", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine.transform_mask": [[433, 441], ["transforms.RandomAffine._construct_t_mat", "cv2.warpAffine", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "mask.numpy"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.transforms.RandomAffine._construct_t_mat"], ["", "def", "transform_mask", "(", "self", ",", "mask", ",", "do_flip", ",", "theta", ",", "shear_values", ",", "scale_factors", ")", ":", "\n", "        ", "t_mat", "=", "self", ".", "_construct_t_mat", "(", "mask", ".", "shape", "[", ":", "2", "]", ",", "do_flip", ",", "theta", ",", "shear_values", ",", "scale_factors", ")", "\n", "output_sz", "=", "(", "mask", ".", "shape", "[", "1", "]", "+", "2", "*", "self", ".", "pad_amount", ",", "mask", ".", "shape", "[", "0", "]", "+", "2", "*", "self", ".", "pad_amount", ")", "\n", "\n", "mask_t", "=", "cv", ".", "warpAffine", "(", "mask", ".", "numpy", "(", ")", ",", "t_mat", ",", "output_sz", ",", "flags", "=", "cv", ".", "INTER_NEAREST", ",", "\n", "borderMode", "=", "self", ".", "border_flag", ")", "\n", "\n", "return", "torch", ".", "from_numpy", "(", "mask_t", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.BaseProcessing.__init__": [[19, 34], ["torchvision.ToTensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transform", "=", "transforms", ".", "ToTensor", "(", ")", ",", "train_transform", "=", "None", ",", "test_transform", "=", "None", ",", "joint_transform", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            transform       - The set of transformations to be applied on the images. Used only if train_transform or\n                                test_transform is None.\n            train_transform - The set of transformations to be applied on the train images. If None, the 'transform'\n                                argument is used instead.\n            test_transform  - The set of transformations to be applied on the test images. If None, the 'transform'\n                                argument is used instead.\n            joint_transform - The set of transformations to be applied 'jointly' on the train and test images.  For\n                                example, it can be used to convert both test and train images to grayscale.\n        \"\"\"", "\n", "self", ".", "transform", "=", "{", "'train'", ":", "transform", "if", "train_transform", "is", "None", "else", "train_transform", ",", "\n", "'test'", ":", "transform", "if", "test_transform", "is", "None", "else", "test_transform", ",", "\n", "'joint'", ":", "joint_transform", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.BaseProcessing.__call__": [[35, 37], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.ATOMProcessing.__init__": [[49, 70], ["processing.BaseProcessing.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "search_area_factor", ",", "output_sz", ",", "center_jitter_factor", ",", "scale_jitter_factor", ",", "proposal_params", ",", "\n", "mode", "=", "'pair'", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            search_area_factor - The size of the search region  relative to the target size.\n            output_sz - An integer, denoting the size to which the search region is resized. The search region is always\n                        square.\n            center_jitter_factor - A dict containing the amount of jittering to be applied to the target center before\n                                    extracting the search region. See _get_jittered_box for how the jittering is done.\n            scale_jitter_factor - A dict containing the amount of jittering to be applied to the target size before\n                                    extracting the search region. See _get_jittered_box for how the jittering is done.\n            proposal_params - Arguments for the proposal generation process. See _generate_proposals for details.\n            mode - Either 'pair' or 'sequence'. If mode='sequence', then output has an extra dimension for frames\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "search_area_factor", "=", "search_area_factor", "\n", "self", ".", "output_sz", "=", "output_sz", "\n", "self", ".", "center_jitter_factor", "=", "center_jitter_factor", "\n", "self", ".", "scale_jitter_factor", "=", "scale_jitter_factor", "\n", "self", ".", "proposal_params", "=", "proposal_params", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.ATOMProcessing._get_jittered_box": [[71, 86], ["torch.cat", "torch.exp", "jittered_size.prod().sqrt", "torch.tensor().float", "torch.randn", "jittered_size.prod", "torch.tensor", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "_get_jittered_box", "(", "self", ",", "box", ",", "mode", ")", ":", "\n", "        ", "\"\"\" Jitter the input box\n        args:\n            box - input bounding box\n            mode - string 'train' or 'test' indicating train or test data\n\n        returns:\n            torch.Tensor - jittered box\n        \"\"\"", "\n", "\n", "jittered_size", "=", "box", "[", "2", ":", "4", "]", "*", "torch", ".", "exp", "(", "torch", ".", "randn", "(", "2", ")", "*", "self", ".", "scale_jitter_factor", "[", "mode", "]", ")", "\n", "max_offset", "=", "(", "jittered_size", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "torch", ".", "tensor", "(", "self", ".", "center_jitter_factor", "[", "mode", "]", ")", ".", "float", "(", ")", ")", "\n", "jittered_center", "=", "box", "[", "0", ":", "2", "]", "+", "0.5", "*", "box", "[", "2", ":", "4", "]", "+", "max_offset", "*", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "jittered_center", "-", "0.5", "*", "jittered_size", ",", "jittered_size", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.ATOMProcessing._generate_proposals": [[87, 115], ["processing.ATOMProcessing.proposal_params.get", "torch.zeros", "torch.zeros", "range", "ltr.perturb_box", "ltr.sample_box_gmm", "ltr.iou", "box.view", "torch.zeros.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.perturb_box", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_box_gmm", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.iou"], ["", "def", "_generate_proposals", "(", "self", ",", "box", ")", ":", "\n", "        ", "\"\"\" Generates proposals by adding noise to the input box\n        args:\n            box - input box\n\n        returns:\n            torch.Tensor - Array of shape (num_proposals, 4) containing proposals\n            torch.Tensor - Array of shape (num_proposals,) containing IoU overlap of each proposal with the input box. The\n                        IoU is mapped to [-1, 1]\n        \"\"\"", "\n", "# Generate proposals", "\n", "num_proposals", "=", "self", ".", "proposal_params", "[", "'boxes_per_frame'", "]", "\n", "proposal_method", "=", "self", ".", "proposal_params", ".", "get", "(", "'proposal_method'", ",", "'default'", ")", "\n", "\n", "if", "proposal_method", "==", "'default'", ":", "\n", "            ", "proposals", "=", "torch", ".", "zeros", "(", "(", "num_proposals", ",", "4", ")", ")", "\n", "gt_iou", "=", "torch", ".", "zeros", "(", "num_proposals", ")", "\n", "for", "i", "in", "range", "(", "num_proposals", ")", ":", "\n", "                ", "proposals", "[", "i", ",", ":", "]", ",", "gt_iou", "[", "i", "]", "=", "prutils", ".", "perturb_box", "(", "box", ",", "min_iou", "=", "self", ".", "proposal_params", "[", "'min_iou'", "]", ",", "\n", "sigma_factor", "=", "self", ".", "proposal_params", "[", "'sigma_factor'", "]", ")", "\n", "", "", "elif", "proposal_method", "==", "'gmm'", ":", "\n", "            ", "proposals", ",", "_", ",", "_", "=", "prutils", ".", "sample_box_gmm", "(", "box", ",", "self", ".", "proposal_params", "[", "'proposal_sigma'", "]", ",", "\n", "num_samples", "=", "num_proposals", ")", "\n", "gt_iou", "=", "prutils", ".", "iou", "(", "box", ".", "view", "(", "1", ",", "4", ")", ",", "proposals", ".", "view", "(", "-", "1", ",", "4", ")", ")", "\n", "\n", "# Map to [-1, 1]", "\n", "", "gt_iou", "=", "gt_iou", "*", "2", "-", "1", "\n", "return", "proposals", ",", "gt_iou", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.ATOMProcessing.__call__": [[116, 157], ["zip", "list", "list", "ltr.jittered_center_crop", "data.apply.apply.apply", "data.apply.apply.apply", "processing.ATOMProcessing._get_jittered_box", "len", "processing.ATOMProcessing._generate_proposals", "isinstance"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.jittered_center_crop", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._get_jittered_box", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing._generate_proposals"], ["", "def", "__call__", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            data - The input data, should contain the following fields:\n                'train_images', test_images', 'train_anno', 'test_anno'\n        returns:\n            TensorDict - output data block with following fields:\n                'train_images', 'test_images', 'train_anno', 'test_anno', 'test_proposals', 'proposal_iou'\n        \"\"\"", "\n", "# Apply joint transforms", "\n", "if", "self", ".", "transform", "[", "'joint'", "]", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_images'", "]", ",", "data", "[", "'train_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'train_images'", "]", ",", "bbox", "=", "data", "[", "'train_anno'", "]", ")", "\n", "data", "[", "'test_images'", "]", ",", "data", "[", "'test_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'test_images'", "]", ",", "bbox", "=", "data", "[", "'test_anno'", "]", ",", "new_roll", "=", "False", ")", "\n", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "assert", "self", ".", "mode", "==", "'sequence'", "or", "len", "(", "data", "[", "s", "+", "'_images'", "]", ")", "==", "1", ",", "\"In pair mode, num train/test frames must be 1\"", "\n", "\n", "# Add a uniform noise to the center pos", "\n", "jittered_anno", "=", "[", "self", ".", "_get_jittered_box", "(", "a", ",", "s", ")", "for", "a", "in", "data", "[", "s", "+", "'_anno'", "]", "]", "\n", "\n", "# Crop image region centered at jittered_anno box", "\n", "crops", ",", "boxes", ",", "_", "=", "prutils", ".", "jittered_center_crop", "(", "data", "[", "s", "+", "'_images'", "]", ",", "jittered_anno", ",", "data", "[", "s", "+", "'_anno'", "]", ",", "\n", "self", ".", "search_area_factor", ",", "self", ".", "output_sz", ")", "\n", "\n", "# Apply transforms", "\n", "data", "[", "s", "+", "'_images'", "]", ",", "data", "[", "s", "+", "'_anno'", "]", "=", "self", ".", "transform", "[", "s", "]", "(", "image", "=", "crops", ",", "bbox", "=", "boxes", ",", "joint", "=", "False", ")", "\n", "\n", "# Generate proposals", "\n", "", "frame2_proposals", ",", "gt_iou", "=", "zip", "(", "*", "[", "self", ".", "_generate_proposals", "(", "a", ")", "for", "a", "in", "data", "[", "'test_anno'", "]", "]", ")", "\n", "\n", "data", "[", "'test_proposals'", "]", "=", "list", "(", "frame2_proposals", ")", "\n", "data", "[", "'proposal_iou'", "]", "=", "list", "(", "gt_iou", ")", "\n", "\n", "# Prepare output", "\n", "if", "self", ".", "mode", "==", "'sequence'", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "stack_tensors", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "lambda", "x", ":", "x", "[", "0", "]", "if", "isinstance", "(", "x", ",", "list", ")", "else", "x", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KLBBregProcessing.__init__": [[164, 185], ["processing.BaseProcessing.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "search_area_factor", ",", "output_sz", ",", "center_jitter_factor", ",", "scale_jitter_factor", ",", "proposal_params", ",", "\n", "mode", "=", "'pair'", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            search_area_factor - The size of the search region  relative to the target size.\n            output_sz - An integer, denoting the size to which the search region is resized. The search region is always\n                        square.\n            center_jitter_factor - A dict containing the amount of jittering to be applied to the target center before\n                                    extracting the search region. See _get_jittered_box for how the jittering is done.\n            scale_jitter_factor - A dict containing the amount of jittering to be applied to the target size before\n                                    extracting the search region. See _get_jittered_box for how the jittering is done.\n            proposal_params - Arguments for the proposal generation process. See _generate_proposals for details.\n            mode - Either 'pair' or 'sequence'. If mode='sequence', then output has an extra dimension for frames\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "search_area_factor", "=", "search_area_factor", "\n", "self", ".", "output_sz", "=", "output_sz", "\n", "self", ".", "center_jitter_factor", "=", "center_jitter_factor", "\n", "self", ".", "scale_jitter_factor", "=", "scale_jitter_factor", "\n", "self", ".", "proposal_params", "=", "proposal_params", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KLBBregProcessing._get_jittered_box": [[186, 201], ["torch.cat", "torch.exp", "jittered_size.prod().sqrt", "torch.tensor().float", "torch.randn", "jittered_size.prod", "torch.tensor", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "_get_jittered_box", "(", "self", ",", "box", ",", "mode", ")", ":", "\n", "        ", "\"\"\" Jitter the input box\n        args:\n            box - input bounding box\n            mode - string 'train' or 'test' indicating train or test data\n\n        returns:\n            torch.Tensor - jittered box\n        \"\"\"", "\n", "\n", "jittered_size", "=", "box", "[", "2", ":", "4", "]", "*", "torch", ".", "exp", "(", "torch", ".", "randn", "(", "2", ")", "*", "self", ".", "scale_jitter_factor", "[", "mode", "]", ")", "\n", "max_offset", "=", "(", "jittered_size", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "torch", ".", "tensor", "(", "self", ".", "center_jitter_factor", "[", "mode", "]", ")", ".", "float", "(", ")", ")", "\n", "jittered_center", "=", "box", "[", "0", ":", "2", "]", "+", "0.5", "*", "box", "[", "2", ":", "4", "]", "+", "max_offset", "*", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "jittered_center", "-", "0.5", "*", "jittered_size", ",", "jittered_size", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KLBBregProcessing._generate_proposals": [[202, 214], ["ltr.sample_box_gmm", "processing.KLBBregProcessing.proposal_params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_box_gmm", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "_generate_proposals", "(", "self", ",", "box", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "# Generate proposals", "\n", "proposals", ",", "proposal_density", ",", "gt_density", "=", "prutils", ".", "sample_box_gmm", "(", "box", ",", "self", ".", "proposal_params", "[", "'proposal_sigma'", "]", ",", "\n", "gt_sigma", "=", "self", ".", "proposal_params", "[", "'gt_sigma'", "]", ",", "\n", "num_samples", "=", "self", ".", "proposal_params", "[", "\n", "'boxes_per_frame'", "]", ",", "\n", "add_mean_box", "=", "self", ".", "proposal_params", ".", "get", "(", "\n", "'add_mean_box'", ",", "False", ")", ")", "\n", "\n", "return", "proposals", ",", "proposal_density", ",", "gt_density", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KLBBregProcessing.__call__": [[215, 257], ["zip", "ltr.jittered_center_crop", "data.apply.apply.apply", "data.apply.apply.apply", "processing.KLBBregProcessing._get_jittered_box", "len", "processing.KLBBregProcessing._generate_proposals", "isinstance"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.jittered_center_crop", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._get_jittered_box", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing._generate_proposals"], ["", "def", "__call__", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            data - The input data, should contain the following fields:\n                'train_images', test_images', 'train_anno', 'test_anno'\n        returns:\n            TensorDict - output data block with following fields:\n                'train_images', 'test_images', 'train_anno', 'test_anno', 'test_proposals', 'proposal_density', 'gt_density'\n        \"\"\"", "\n", "# Apply joint transforms", "\n", "if", "self", ".", "transform", "[", "'joint'", "]", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_images'", "]", ",", "data", "[", "'train_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'train_images'", "]", ",", "bbox", "=", "data", "[", "'train_anno'", "]", ")", "\n", "data", "[", "'test_images'", "]", ",", "data", "[", "'test_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'test_images'", "]", ",", "bbox", "=", "data", "[", "'test_anno'", "]", ",", "new_roll", "=", "False", ")", "\n", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "assert", "self", ".", "mode", "==", "'sequence'", "or", "len", "(", "data", "[", "s", "+", "'_images'", "]", ")", "==", "1", ",", "\"In pair mode, num train/test frames must be 1\"", "\n", "\n", "# Add a uniform noise to the center pos", "\n", "jittered_anno", "=", "[", "self", ".", "_get_jittered_box", "(", "a", ",", "s", ")", "for", "a", "in", "data", "[", "s", "+", "'_anno'", "]", "]", "\n", "\n", "# Crop image region centered at jittered_anno box", "\n", "crops", ",", "boxes", ",", "_", "=", "prutils", ".", "jittered_center_crop", "(", "data", "[", "s", "+", "'_images'", "]", ",", "jittered_anno", ",", "data", "[", "s", "+", "'_anno'", "]", ",", "\n", "self", ".", "search_area_factor", ",", "self", ".", "output_sz", ")", "\n", "\n", "# Apply transforms", "\n", "data", "[", "s", "+", "'_images'", "]", ",", "data", "[", "s", "+", "'_anno'", "]", "=", "self", ".", "transform", "[", "s", "]", "(", "image", "=", "crops", ",", "bbox", "=", "boxes", ",", "joint", "=", "False", ")", "\n", "\n", "# Generate proposals", "\n", "", "proposals", ",", "proposal_density", ",", "gt_density", "=", "zip", "(", "*", "[", "self", ".", "_generate_proposals", "(", "a", ")", "for", "a", "in", "data", "[", "'test_anno'", "]", "]", ")", "\n", "\n", "data", "[", "'test_proposals'", "]", "=", "proposals", "\n", "data", "[", "'proposal_density'", "]", "=", "proposal_density", "\n", "data", "[", "'gt_density'", "]", "=", "gt_density", "\n", "\n", "# Prepare output", "\n", "if", "self", ".", "mode", "==", "'sequence'", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "stack_tensors", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "lambda", "x", ":", "x", "[", "0", "]", "if", "isinstance", "(", "x", ",", "list", ")", "else", "x", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.ATOMwKLProcessing.__init__": [[261, 270], ["processing.BaseProcessing.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "search_area_factor", ",", "output_sz", ",", "center_jitter_factor", ",", "scale_jitter_factor", ",", "proposal_params", ",", "\n", "mode", "=", "'pair'", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "search_area_factor", "=", "search_area_factor", "\n", "self", ".", "output_sz", "=", "output_sz", "\n", "self", ".", "center_jitter_factor", "=", "center_jitter_factor", "\n", "self", ".", "scale_jitter_factor", "=", "scale_jitter_factor", "\n", "self", ".", "proposal_params", "=", "proposal_params", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.ATOMwKLProcessing._get_jittered_box": [[271, 286], ["torch.cat", "torch.exp", "jittered_size.prod().sqrt", "torch.tensor().float", "torch.randn", "jittered_size.prod", "torch.tensor", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "_get_jittered_box", "(", "self", ",", "box", ",", "mode", ")", ":", "\n", "        ", "\"\"\" Jitter the input box\n        args:\n            box - input bounding box\n            mode - string 'train' or 'test' indicating train or test data\n\n        returns:\n            torch.Tensor - jittered box\n        \"\"\"", "\n", "\n", "jittered_size", "=", "box", "[", "2", ":", "4", "]", "*", "torch", ".", "exp", "(", "torch", ".", "randn", "(", "2", ")", "*", "self", ".", "scale_jitter_factor", "[", "mode", "]", ")", "\n", "max_offset", "=", "(", "jittered_size", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "torch", ".", "tensor", "(", "self", ".", "center_jitter_factor", "[", "mode", "]", ")", ".", "float", "(", ")", ")", "\n", "jittered_center", "=", "box", "[", "0", ":", "2", "]", "+", "0.5", "*", "box", "[", "2", ":", "4", "]", "+", "max_offset", "*", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "jittered_center", "-", "0.5", "*", "jittered_size", ",", "jittered_size", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.ATOMwKLProcessing._generate_proposals": [[287, 297], ["ltr.sample_box_gmm", "ltr.iou_gen", "box.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_box_gmm"], ["", "def", "_generate_proposals", "(", "self", ",", "box", ")", ":", "\n", "        ", "\"\"\"\n        \"\"\"", "\n", "# Generate proposals", "\n", "proposals", ",", "proposal_density", ",", "gt_density", "=", "prutils", ".", "sample_box_gmm", "(", "box", ",", "self", ".", "proposal_params", "[", "'proposal_sigma'", "]", ",", "\n", "self", ".", "proposal_params", "[", "'gt_sigma'", "]", ",", "\n", "self", ".", "proposal_params", "[", "'boxes_per_frame'", "]", ")", "\n", "\n", "iou", "=", "prutils", ".", "iou_gen", "(", "proposals", ",", "box", ".", "view", "(", "1", ",", "4", ")", ")", "\n", "return", "proposals", ",", "proposal_density", ",", "gt_density", ",", "iou", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.ATOMwKLProcessing.__call__": [[298, 333], ["zip", "ltr.jittered_center_crop", "data.apply.apply.apply", "data.apply.apply.apply", "processing.ATOMwKLProcessing._get_jittered_box", "len", "processing.ATOMwKLProcessing._generate_proposals", "isinstance"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.jittered_center_crop", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._get_jittered_box", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing._generate_proposals"], ["", "def", "__call__", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "# Apply joint transforms", "\n", "        ", "if", "self", ".", "transform", "[", "'joint'", "]", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_images'", "]", ",", "data", "[", "'train_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'train_images'", "]", ",", "bbox", "=", "data", "[", "'train_anno'", "]", ")", "\n", "data", "[", "'test_images'", "]", ",", "data", "[", "'test_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'test_images'", "]", ",", "bbox", "=", "data", "[", "'test_anno'", "]", ",", "new_roll", "=", "False", ")", "\n", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "assert", "self", ".", "mode", "==", "'sequence'", "or", "len", "(", "data", "[", "s", "+", "'_images'", "]", ")", "==", "1", ",", "\"In pair mode, num train/test frames must be 1\"", "\n", "\n", "# Add a uniform noise to the center pos", "\n", "jittered_anno", "=", "[", "self", ".", "_get_jittered_box", "(", "a", ",", "s", ")", "for", "a", "in", "data", "[", "s", "+", "'_anno'", "]", "]", "\n", "\n", "# Crop image region centered at jittered_anno box", "\n", "crops", ",", "boxes", ",", "_", "=", "prutils", ".", "jittered_center_crop", "(", "data", "[", "s", "+", "'_images'", "]", ",", "jittered_anno", ",", "data", "[", "s", "+", "'_anno'", "]", ",", "\n", "self", ".", "search_area_factor", ",", "self", ".", "output_sz", ")", "\n", "\n", "# Apply transforms", "\n", "data", "[", "s", "+", "'_images'", "]", ",", "data", "[", "s", "+", "'_anno'", "]", "=", "self", ".", "transform", "[", "s", "]", "(", "image", "=", "crops", ",", "bbox", "=", "boxes", ",", "joint", "=", "False", ")", "\n", "\n", "# Generate proposals", "\n", "", "proposals", ",", "proposal_density", ",", "gt_density", ",", "proposal_iou", "=", "zip", "(", "\n", "*", "[", "self", ".", "_generate_proposals", "(", "a", ")", "for", "a", "in", "data", "[", "'test_anno'", "]", "]", ")", "\n", "\n", "data", "[", "'test_proposals'", "]", "=", "proposals", "\n", "data", "[", "'proposal_density'", "]", "=", "proposal_density", "\n", "data", "[", "'gt_density'", "]", "=", "gt_density", "\n", "data", "[", "'proposal_iou'", "]", "=", "proposal_iou", "\n", "# Prepare output", "\n", "if", "self", ".", "mode", "==", "'sequence'", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "stack_tensors", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "lambda", "x", ":", "x", "[", "0", "]", "if", "isinstance", "(", "x", ",", "list", ")", "else", "x", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.DiMPProcessing.__init__": [[349, 379], ["processing.BaseProcessing.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "search_area_factor", ",", "output_sz", ",", "center_jitter_factor", ",", "scale_jitter_factor", ",", "crop_type", "=", "'replicate'", ",", "\n", "max_scale_change", "=", "None", ",", "mode", "=", "'pair'", ",", "proposal_params", "=", "None", ",", "label_function_params", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            search_area_factor - The size of the search region  relative to the target size.\n            output_sz - An integer, denoting the size to which the search region is resized. The search region is always\n                        square.\n            center_jitter_factor - A dict containing the amount of jittering to be applied to the target center before\n                                    extracting the search region. See _get_jittered_box for how the jittering is done.\n            scale_jitter_factor - A dict containing the amount of jittering to be applied to the target size before\n                                    extracting the search region. See _get_jittered_box for how the jittering is done.\n            crop_type - If 'replicate', the boundary pixels are replicated in case the search region crop goes out of image.\n                        If 'inside', the search region crop is shifted/shrunk to fit completely inside the image.\n                        If 'inside_major', the search region crop is shifted/shrunk to fit completely inside one axis of the image.\n            max_scale_change - Maximum allowed scale change when performing the crop (only applicable for 'inside' and 'inside_major')\n            mode - Either 'pair' or 'sequence'. If mode='sequence', then output has an extra dimension for frames\n            proposal_params - Arguments for the proposal generation process. See _generate_proposals for details.\n            label_function_params - Arguments for the label generation process. See _generate_label_function for details.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "search_area_factor", "=", "search_area_factor", "\n", "self", ".", "output_sz", "=", "output_sz", "\n", "self", ".", "center_jitter_factor", "=", "center_jitter_factor", "\n", "self", ".", "scale_jitter_factor", "=", "scale_jitter_factor", "\n", "self", ".", "crop_type", "=", "crop_type", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "max_scale_change", "=", "max_scale_change", "\n", "\n", "self", ".", "proposal_params", "=", "proposal_params", "\n", "self", ".", "label_function_params", "=", "label_function_params", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.DiMPProcessing._get_jittered_box": [[380, 395], ["torch.cat", "torch.exp", "jittered_size.prod().sqrt", "torch.tensor().float", "torch.randn", "jittered_size.prod", "torch.tensor", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "_get_jittered_box", "(", "self", ",", "box", ",", "mode", ")", ":", "\n", "        ", "\"\"\" Jitter the input box\n        args:\n            box - input bounding box\n            mode - string 'train' or 'test' indicating train or test data\n\n        returns:\n            torch.Tensor - jittered box\n        \"\"\"", "\n", "\n", "jittered_size", "=", "box", "[", "2", ":", "4", "]", "*", "torch", ".", "exp", "(", "torch", ".", "randn", "(", "2", ")", "*", "self", ".", "scale_jitter_factor", "[", "mode", "]", ")", "\n", "max_offset", "=", "(", "jittered_size", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "torch", ".", "tensor", "(", "self", ".", "center_jitter_factor", "[", "mode", "]", ")", ".", "float", "(", ")", ")", "\n", "jittered_center", "=", "box", "[", "0", ":", "2", "]", "+", "0.5", "*", "box", "[", "2", ":", "4", "]", "+", "max_offset", "*", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "jittered_center", "-", "0.5", "*", "jittered_size", ",", "jittered_size", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.DiMPProcessing._generate_proposals": [[396, 427], ["processing.DiMPProcessing.proposal_params.get", "torch.zeros", "torch.zeros", "range", "ltr.perturb_box", "ltr.sample_box_gmm", "ltr.iou", "ValueError", "box.view", "torch.zeros.view"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.perturb_box", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_box_gmm", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.iou"], ["", "def", "_generate_proposals", "(", "self", ",", "box", ")", ":", "\n", "        ", "\"\"\" Generates proposals by adding noise to the input box\n        args:\n            box - input box\n\n        returns:\n            torch.Tensor - Array of shape (num_proposals, 4) containing proposals\n            torch.Tensor - Array of shape (num_proposals,) containing IoU overlap of each proposal with the input box. The\n                        IoU is mapped to [-1, 1]\n        \"\"\"", "\n", "# Generate proposals", "\n", "num_proposals", "=", "self", ".", "proposal_params", "[", "'boxes_per_frame'", "]", "\n", "proposal_method", "=", "self", ".", "proposal_params", ".", "get", "(", "'proposal_method'", ",", "'default'", ")", "\n", "\n", "if", "proposal_method", "==", "'default'", ":", "\n", "            ", "proposals", "=", "torch", ".", "zeros", "(", "(", "num_proposals", ",", "4", ")", ")", "\n", "gt_iou", "=", "torch", ".", "zeros", "(", "num_proposals", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_proposals", ")", ":", "\n", "                ", "proposals", "[", "i", ",", ":", "]", ",", "gt_iou", "[", "i", "]", "=", "prutils", ".", "perturb_box", "(", "box", ",", "min_iou", "=", "self", ".", "proposal_params", "[", "'min_iou'", "]", ",", "\n", "sigma_factor", "=", "self", ".", "proposal_params", "[", "'sigma_factor'", "]", ")", "\n", "", "", "elif", "proposal_method", "==", "'gmm'", ":", "\n", "            ", "proposals", ",", "_", ",", "_", "=", "prutils", ".", "sample_box_gmm", "(", "box", ",", "self", ".", "proposal_params", "[", "'proposal_sigma'", "]", ",", "\n", "num_samples", "=", "num_proposals", ")", "\n", "gt_iou", "=", "prutils", ".", "iou", "(", "box", ".", "view", "(", "1", ",", "4", ")", ",", "proposals", ".", "view", "(", "-", "1", ",", "4", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown proposal method.'", ")", "\n", "\n", "# Map to [-1, 1]", "\n", "", "gt_iou", "=", "gt_iou", "*", "2", "-", "1", "\n", "return", "proposals", ",", "gt_iou", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.DiMPProcessing._generate_label_function": [[428, 443], ["ltr.gaussian_label_function", "target_bb.view", "processing.DiMPProcessing.label_function_params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gaussian_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "_generate_label_function", "(", "self", ",", "target_bb", ")", ":", "\n", "        ", "\"\"\" Generates the gaussian label function centered at target_bb\n        args:\n            target_bb - target bounding box (num_images, 4)\n\n        returns:\n            torch.Tensor - Tensor of shape (num_images, label_sz, label_sz) containing the label for each sample\n        \"\"\"", "\n", "\n", "gauss_label", "=", "prutils", ".", "gaussian_label_function", "(", "target_bb", ".", "view", "(", "-", "1", ",", "4", ")", ",", "self", ".", "label_function_params", "[", "'sigma_factor'", "]", ",", "\n", "self", ".", "label_function_params", "[", "'kernel_sz'", "]", ",", "\n", "self", ".", "label_function_params", "[", "'feature_sz'", "]", ",", "self", ".", "output_sz", ",", "\n", "end_pad_if_even", "=", "self", ".", "label_function_params", ".", "get", "(", "'end_pad_if_even'", ",", "True", ")", ")", "\n", "\n", "return", "gauss_label", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.DiMPProcessing.__call__": [[444, 491], ["ltr.target_image_crop", "zip", "list", "list", "data.apply.apply.apply", "data.apply.apply.apply", "processing.DiMPProcessing._generate_label_function", "processing.DiMPProcessing._generate_label_function", "processing.DiMPProcessing._get_jittered_box", "len", "processing.DiMPProcessing._generate_proposals", "isinstance"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.target_image_crop", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._generate_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._generate_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._get_jittered_box", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing._generate_proposals"], ["", "def", "__call__", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            data - The input data, should contain the following fields:\n                'train_images', test_images', 'train_anno', 'test_anno'\n        returns:\n            TensorDict - output data block with following fields:\n                'train_images', 'test_images', 'train_anno', 'test_anno', 'test_proposals', 'proposal_iou',\n                'test_label' (optional), 'train_label' (optional), 'test_label_density' (optional), 'train_label_density' (optional)\n        \"\"\"", "\n", "\n", "if", "self", ".", "transform", "[", "'joint'", "]", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_images'", "]", ",", "data", "[", "'train_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'train_images'", "]", ",", "bbox", "=", "data", "[", "'train_anno'", "]", ")", "\n", "data", "[", "'test_images'", "]", ",", "data", "[", "'test_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'test_images'", "]", ",", "bbox", "=", "data", "[", "'test_anno'", "]", ",", "new_roll", "=", "False", ")", "\n", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "assert", "self", ".", "mode", "==", "'sequence'", "or", "len", "(", "data", "[", "s", "+", "'_images'", "]", ")", "==", "1", ",", "\"In pair mode, num train/test frames must be 1\"", "\n", "\n", "# Add a uniform noise to the center pos", "\n", "jittered_anno", "=", "[", "self", ".", "_get_jittered_box", "(", "a", ",", "s", ")", "for", "a", "in", "data", "[", "s", "+", "'_anno'", "]", "]", "\n", "\n", "crops", ",", "boxes", "=", "prutils", ".", "target_image_crop", "(", "data", "[", "s", "+", "'_images'", "]", ",", "jittered_anno", ",", "data", "[", "s", "+", "'_anno'", "]", ",", "\n", "self", ".", "search_area_factor", ",", "self", ".", "output_sz", ",", "mode", "=", "self", ".", "crop_type", ",", "\n", "max_scale_change", "=", "self", ".", "max_scale_change", ")", "\n", "\n", "data", "[", "s", "+", "'_images'", "]", ",", "data", "[", "s", "+", "'_anno'", "]", "=", "self", ".", "transform", "[", "s", "]", "(", "image", "=", "crops", ",", "bbox", "=", "boxes", ",", "joint", "=", "False", ")", "\n", "\n", "# Generate proposals", "\n", "", "if", "self", ".", "proposal_params", ":", "\n", "            ", "frame2_proposals", ",", "gt_iou", "=", "zip", "(", "*", "[", "self", ".", "_generate_proposals", "(", "a", ")", "for", "a", "in", "data", "[", "'test_anno'", "]", "]", ")", "\n", "\n", "data", "[", "'test_proposals'", "]", "=", "list", "(", "frame2_proposals", ")", "\n", "data", "[", "'proposal_iou'", "]", "=", "list", "(", "gt_iou", ")", "\n", "\n", "# Prepare output", "\n", "", "if", "self", ".", "mode", "==", "'sequence'", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "stack_tensors", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "lambda", "x", ":", "x", "[", "0", "]", "if", "isinstance", "(", "x", ",", "list", ")", "else", "x", ")", "\n", "\n", "# Generate label functions", "\n", "", "if", "self", ".", "label_function_params", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_label'", "]", "=", "self", ".", "_generate_label_function", "(", "data", "[", "'train_anno'", "]", ")", "\n", "data", "[", "'test_label'", "]", "=", "self", ".", "_generate_label_function", "(", "data", "[", "'test_anno'", "]", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KLDiMPProcessing.__init__": [[498, 531], ["processing.BaseProcessing.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "search_area_factor", ",", "output_sz", ",", "center_jitter_factor", ",", "scale_jitter_factor", ",", "crop_type", "=", "'replicate'", ",", "\n", "max_scale_change", "=", "None", ",", "mode", "=", "'pair'", ",", "proposal_params", "=", "None", ",", "\n", "label_function_params", "=", "None", ",", "label_density_params", "=", "None", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            search_area_factor - The size of the search region  relative to the target size.\n            output_sz - An integer, denoting the size to which the search region is resized. The search region is always\n                        square.\n            center_jitter_factor - A dict containing the amount of jittering to be applied to the target center before\n                                    extracting the search region. See _get_jittered_box for how the jittering is done.\n            scale_jitter_factor - A dict containing the amount of jittering to be applied to the target size before\n                                    extracting the search region. See _get_jittered_box for how the jittering is done.\n            crop_type - If 'replicate', the boundary pixels are replicated in case the search region crop goes out of image.\n                        If 'inside', the search region crop is shifted/shrunk to fit completely inside the image.\n                        If 'inside_major', the search region crop is shifted/shrunk to fit completely inside one axis of the image.\n            max_scale_change - Maximum allowed scale change when performing the crop (only applicable for 'inside' and 'inside_major')\n            mode - Either 'pair' or 'sequence'. If mode='sequence', then output has an extra dimension for frames\n            proposal_params - Arguments for the proposal generation process. See _generate_proposals for details.\n            label_function_params - Arguments for the label generation process. See _generate_label_function for details.\n            label_density_params - Arguments for the label density generation process. See _generate_label_function for details.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "search_area_factor", "=", "search_area_factor", "\n", "self", ".", "output_sz", "=", "output_sz", "\n", "self", ".", "center_jitter_factor", "=", "center_jitter_factor", "\n", "self", ".", "scale_jitter_factor", "=", "scale_jitter_factor", "\n", "self", ".", "crop_type", "=", "crop_type", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "max_scale_change", "=", "max_scale_change", "\n", "\n", "self", ".", "proposal_params", "=", "proposal_params", "\n", "self", ".", "label_function_params", "=", "label_function_params", "\n", "self", ".", "label_density_params", "=", "label_density_params", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KLDiMPProcessing._get_jittered_box": [[532, 547], ["torch.cat", "torch.exp", "jittered_size.prod().sqrt", "torch.tensor().float", "torch.randn", "jittered_size.prod", "torch.tensor", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "_get_jittered_box", "(", "self", ",", "box", ",", "mode", ")", ":", "\n", "        ", "\"\"\" Jitter the input box\n        args:\n            box - input bounding box\n            mode - string 'train' or 'test' indicating train or test data\n\n        returns:\n            torch.Tensor - jittered box\n        \"\"\"", "\n", "\n", "jittered_size", "=", "box", "[", "2", ":", "4", "]", "*", "torch", ".", "exp", "(", "torch", ".", "randn", "(", "2", ")", "*", "self", ".", "scale_jitter_factor", "[", "mode", "]", ")", "\n", "max_offset", "=", "(", "jittered_size", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "torch", ".", "tensor", "(", "self", ".", "center_jitter_factor", "[", "mode", "]", ")", ".", "float", "(", ")", ")", "\n", "jittered_center", "=", "box", "[", "0", ":", "2", "]", "+", "0.5", "*", "box", "[", "2", ":", "4", "]", "+", "max_offset", "*", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "jittered_center", "-", "0.5", "*", "jittered_size", ",", "jittered_size", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KLDiMPProcessing._generate_proposals": [[548, 561], ["ltr.sample_box_gmm", "processing.KLDiMPProcessing.proposal_params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_box_gmm", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "_generate_proposals", "(", "self", ",", "box", ")", ":", "\n", "        ", "\"\"\" Generate proposal sample boxes from a GMM proposal distribution and compute their ground-truth density.\n        This is used for ML and KL based regression learning of the bounding box regressor.\n        args:\n            box - input bounding box\n        \"\"\"", "\n", "# Generate proposals", "\n", "proposals", ",", "proposal_density", ",", "gt_density", "=", "prutils", ".", "sample_box_gmm", "(", "box", ",", "self", ".", "proposal_params", "[", "'proposal_sigma'", "]", ",", "\n", "gt_sigma", "=", "self", ".", "proposal_params", "[", "'gt_sigma'", "]", ",", "\n", "num_samples", "=", "self", ".", "proposal_params", "[", "'boxes_per_frame'", "]", ",", "\n", "add_mean_box", "=", "self", ".", "proposal_params", ".", "get", "(", "'add_mean_box'", ",", "False", ")", ")", "\n", "\n", "return", "proposals", ",", "proposal_density", ",", "gt_density", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KLDiMPProcessing._generate_label_function": [[562, 577], ["ltr.gaussian_label_function", "target_bb.view", "processing.KLDiMPProcessing.label_function_params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gaussian_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "_generate_label_function", "(", "self", ",", "target_bb", ")", ":", "\n", "        ", "\"\"\" Generates the gaussian label function centered at target_bb\n        args:\n            target_bb - target bounding box (num_images, 4)\n\n        returns:\n            torch.Tensor - Tensor of shape (num_images, label_sz, label_sz) containing the label for each sample\n        \"\"\"", "\n", "\n", "gauss_label", "=", "prutils", ".", "gaussian_label_function", "(", "target_bb", ".", "view", "(", "-", "1", ",", "4", ")", ",", "self", ".", "label_function_params", "[", "'sigma_factor'", "]", ",", "\n", "self", ".", "label_function_params", "[", "'kernel_sz'", "]", ",", "\n", "self", ".", "label_function_params", "[", "'feature_sz'", "]", ",", "self", ".", "output_sz", ",", "\n", "end_pad_if_even", "=", "self", ".", "label_function_params", ".", "get", "(", "'end_pad_if_even'", ",", "True", ")", ")", "\n", "\n", "return", "gauss_label", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KLDiMPProcessing._generate_label_density": [[578, 606], ["ltr.gaussian_label_function", "processing.KLDiMPProcessing.label_density_params.get", "processing.KLDiMPProcessing.label_density_params.get", "target_bb.view", "ltr.gaussian_label_function.sum", "g_sum[].view", "processing.KLDiMPProcessing.label_density_params.get", "processing.KLDiMPProcessing.label_density_params.get", "processing.KLDiMPProcessing.label_density_params.get", "processing.KLDiMPProcessing.label_density_params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gaussian_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "_generate_label_density", "(", "self", ",", "target_bb", ")", ":", "\n", "        ", "\"\"\" Generates the gaussian label density centered at target_bb\n        args:\n            target_bb - target bounding box (num_images, 4)\n\n        returns:\n            torch.Tensor - Tensor of shape (num_images, label_sz, label_sz) containing the label for each sample\n        \"\"\"", "\n", "\n", "feat_sz", "=", "self", ".", "label_density_params", "[", "'feature_sz'", "]", "*", "self", ".", "label_density_params", ".", "get", "(", "'interp_factor'", ",", "1", ")", "\n", "gauss_label", "=", "prutils", ".", "gaussian_label_function", "(", "target_bb", ".", "view", "(", "-", "1", ",", "4", ")", ",", "self", ".", "label_density_params", "[", "'sigma_factor'", "]", ",", "\n", "self", ".", "label_density_params", "[", "'kernel_sz'", "]", ",", "\n", "feat_sz", ",", "self", ".", "output_sz", ",", "\n", "end_pad_if_even", "=", "self", ".", "label_density_params", ".", "get", "(", "'end_pad_if_even'", ",", "True", ")", ",", "\n", "density", "=", "True", ",", "\n", "uni_bias", "=", "self", ".", "label_density_params", ".", "get", "(", "'uni_weight'", ",", "0.0", ")", ")", "\n", "\n", "gauss_label", "*=", "(", "gauss_label", ">", "self", ".", "label_density_params", ".", "get", "(", "'threshold'", ",", "0.0", ")", ")", ".", "float", "(", ")", "\n", "\n", "if", "self", ".", "label_density_params", ".", "get", "(", "'normalize'", ",", "False", ")", ":", "\n", "            ", "g_sum", "=", "gauss_label", ".", "sum", "(", "dim", "=", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "valid", "=", "g_sum", ">", "0.01", "\n", "gauss_label", "[", "valid", ",", ":", ",", ":", "]", "/=", "g_sum", "[", "valid", "]", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "\n", "gauss_label", "[", "~", "valid", ",", ":", ",", ":", "]", "=", "1.0", "/", "(", "gauss_label", ".", "shape", "[", "-", "2", "]", "*", "gauss_label", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "", "gauss_label", "*=", "1.0", "-", "self", ".", "label_density_params", ".", "get", "(", "'shrink'", ",", "0.0", ")", "\n", "\n", "return", "gauss_label", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KLDiMPProcessing.__call__": [[607, 665], ["zip", "ltr.target_image_crop", "data.apply.apply.get", "data.apply.apply.apply", "data.apply.apply.apply", "processing.KLDiMPProcessing._generate_label_function", "processing.KLDiMPProcessing._generate_label_function", "processing.KLDiMPProcessing._generate_label_density", "processing.KLDiMPProcessing._generate_label_density", "processing.KLDiMPProcessing._get_jittered_box", "zip", "len", "processing.KLDiMPProcessing._generate_proposals", "isinstance"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.target_image_crop", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._generate_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._generate_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KLDiMPProcessing._generate_label_density", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KLDiMPProcessing._generate_label_density", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._get_jittered_box", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing._generate_proposals"], ["", "def", "__call__", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            data - The input data, should contain the following fields:\n                'train_images', test_images', 'train_anno', 'test_anno'\n        returns:\n            TensorDict - output data block with following fields:\n                'train_images', 'test_images', 'train_anno', 'test_anno', 'test_proposals', 'proposal_density', 'gt_density',\n                'test_label' (optional), 'train_label' (optional), 'test_label_density' (optional), 'train_label_density' (optional)\n        \"\"\"", "\n", "\n", "if", "self", ".", "transform", "[", "'joint'", "]", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_images'", "]", ",", "data", "[", "'train_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'train_images'", "]", ",", "bbox", "=", "data", "[", "'train_anno'", "]", ")", "\n", "data", "[", "'test_images'", "]", ",", "data", "[", "'test_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'test_images'", "]", ",", "bbox", "=", "data", "[", "'test_anno'", "]", ",", "new_roll", "=", "False", ")", "\n", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "assert", "self", ".", "mode", "==", "'sequence'", "or", "len", "(", "data", "[", "s", "+", "'_images'", "]", ")", "==", "1", ",", "\"In pair mode, num train/test frames must be 1\"", "\n", "\n", "# Add a uniform noise to the center pos", "\n", "jittered_anno", "=", "[", "self", ".", "_get_jittered_box", "(", "a", ",", "s", ")", "for", "a", "in", "data", "[", "s", "+", "'_anno'", "]", "]", "\n", "\n", "crops", ",", "boxes", "=", "prutils", ".", "target_image_crop", "(", "data", "[", "s", "+", "'_images'", "]", ",", "jittered_anno", ",", "data", "[", "s", "+", "'_anno'", "]", ",", "\n", "self", ".", "search_area_factor", ",", "self", ".", "output_sz", ",", "mode", "=", "self", ".", "crop_type", ",", "\n", "max_scale_change", "=", "self", ".", "max_scale_change", ")", "\n", "\n", "data", "[", "s", "+", "'_images'", "]", ",", "data", "[", "s", "+", "'_anno'", "]", "=", "self", ".", "transform", "[", "s", "]", "(", "image", "=", "crops", ",", "bbox", "=", "boxes", ",", "joint", "=", "False", ")", "\n", "\n", "# Generate proposals", "\n", "", "proposals", ",", "proposal_density", ",", "gt_density", "=", "zip", "(", "*", "[", "self", ".", "_generate_proposals", "(", "a", ")", "for", "a", "in", "data", "[", "'test_anno'", "]", "]", ")", "\n", "\n", "data", "[", "'test_proposals'", "]", "=", "proposals", "\n", "data", "[", "'proposal_density'", "]", "=", "proposal_density", "\n", "data", "[", "'gt_density'", "]", "=", "gt_density", "\n", "\n", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "is_distractor", "=", "data", ".", "get", "(", "'is_distractor_{}_frame'", ".", "format", "(", "s", ")", ",", "None", ")", "\n", "if", "is_distractor", "is", "not", "None", ":", "\n", "                ", "for", "is_dist", ",", "box", "in", "zip", "(", "is_distractor", ",", "data", "[", "s", "+", "'_anno'", "]", ")", ":", "\n", "                    ", "if", "is_dist", ":", "\n", "                        ", "box", "[", "0", "]", "=", "99999999.9", "\n", "box", "[", "1", "]", "=", "99999999.9", "\n", "\n", "# Prepare output", "\n", "", "", "", "", "if", "self", ".", "mode", "==", "'sequence'", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "stack_tensors", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "lambda", "x", ":", "x", "[", "0", "]", "if", "isinstance", "(", "x", ",", "list", ")", "else", "x", ")", "\n", "\n", "# Generate label functions", "\n", "", "if", "self", ".", "label_function_params", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_label'", "]", "=", "self", ".", "_generate_label_function", "(", "data", "[", "'train_anno'", "]", ")", "\n", "data", "[", "'test_label'", "]", "=", "self", ".", "_generate_label_function", "(", "data", "[", "'test_anno'", "]", ")", "\n", "", "if", "self", ".", "label_density_params", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_label_density'", "]", "=", "self", ".", "_generate_label_density", "(", "data", "[", "'train_anno'", "]", ")", "\n", "data", "[", "'test_label_density'", "]", "=", "self", ".", "_generate_label_density", "(", "data", "[", "'test_anno'", "]", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LWLProcessing.__init__": [[680, 719], ["processing.BaseProcessing.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "search_area_factor", ",", "output_sz", ",", "center_jitter_factor", ",", "scale_jitter_factor", ",", "crop_type", "=", "'replicate'", ",", "\n", "max_scale_change", "=", "None", ",", "mode", "=", "'pair'", ",", "new_roll", "=", "False", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            search_area_factor - The size of the search region  relative to the target size.\n            output_sz - The size (width, height) to which the search region is resized. The aspect ratio is always\n                        preserved when resizing the search region\n            center_jitter_factor - A dict containing the amount of jittering to be applied to the target center before\n                                    extracting the search region. See _get_jittered_box for how the jittering is done.\n            scale_jitter_factor - A dict containing the amount of jittering to be applied to the target size before\n                                    extracting the search region. See _get_jittered_box for how the jittering is done.\n            crop_type - Determines how out-of-frame regions are handled when cropping the search region.\n                        If 'replicate', the boundary pixels are replicated in case the search region crop goes out of\n                                        image.\n                        If 'inside', the search region crop is shifted/shrunk to fit completely inside the image.\n                        If 'inside_major', the search region crop is shifted/shrunk to fit completely inside one axis\n                        of the image.\n            max_scale_change - Maximum allowed scale change when shrinking the search region to fit the image\n                               (only applicable to 'inside' and 'inside_major' cropping modes). In case the desired\n                               shrink factor exceeds the max_scale_change, the search region is only shrunk to the\n                               factor max_scale_change. Out-of-frame regions are then handled by replicating the\n                               boundary pixels. If max_scale_change is set to None, unbounded shrinking is allowed.\n\n            mode - Either 'pair' or 'sequence'. If mode='sequence', then output has an extra dimension for frames\n            new_roll - Whether to use the same random roll values for train and test frames when applying the joint\n                       transformation. If True, a new random roll is performed for the test frame transformations. Thus,\n                       if performing random flips, the set of train frames and the set of test frames will be flipped\n                       independently.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "search_area_factor", "=", "search_area_factor", "\n", "self", ".", "output_sz", "=", "output_sz", "\n", "self", ".", "center_jitter_factor", "=", "center_jitter_factor", "\n", "self", ".", "scale_jitter_factor", "=", "scale_jitter_factor", "\n", "self", ".", "crop_type", "=", "crop_type", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "max_scale_change", "=", "max_scale_change", "\n", "\n", "self", ".", "new_roll", "=", "new_roll", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LWLProcessing._get_jittered_box": [[720, 742], ["torch.cat", "processing.LWLProcessing.scale_jitter_factor.get", "torch.exp", "processing.LWLProcessing.scale_jitter_factor.get", "torch.exp", "jittered_size.prod().sqrt", "torch.tensor", "torch.rand", "torch.randn", "torch.FloatTensor().uniform_", "jittered_size.prod", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "_get_jittered_box", "(", "self", ",", "box", ",", "mode", ")", ":", "\n", "        ", "\"\"\" Jitter the input box\n        args:\n            box - input bounding box\n            mode - string 'train' or 'test' indicating train or test data\n\n        returns:\n            torch.Tensor - jittered box\n        \"\"\"", "\n", "\n", "if", "self", ".", "scale_jitter_factor", ".", "get", "(", "'mode'", ",", "'gauss'", ")", "==", "'gauss'", ":", "\n", "            ", "jittered_size", "=", "box", "[", "2", ":", "4", "]", "*", "torch", ".", "exp", "(", "torch", ".", "randn", "(", "2", ")", "*", "self", ".", "scale_jitter_factor", "[", "mode", "]", ")", "\n", "", "elif", "self", ".", "scale_jitter_factor", ".", "get", "(", "'mode'", ",", "'gauss'", ")", "==", "'uniform'", ":", "\n", "            ", "jittered_size", "=", "box", "[", "2", ":", "4", "]", "*", "torch", ".", "exp", "(", "torch", ".", "FloatTensor", "(", "2", ")", ".", "uniform_", "(", "-", "self", ".", "scale_jitter_factor", "[", "mode", "]", ",", "\n", "self", ".", "scale_jitter_factor", "[", "mode", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "\n", "\n", "", "max_offset", "=", "(", "jittered_size", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "torch", ".", "tensor", "(", "self", ".", "center_jitter_factor", "[", "mode", "]", ")", ")", ".", "float", "(", ")", "\n", "jittered_center", "=", "box", "[", "0", ":", "2", "]", "+", "0.5", "*", "box", "[", "2", ":", "4", "]", "+", "max_offset", "*", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "jittered_center", "-", "0.5", "*", "jittered_size", ",", "jittered_size", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LWLProcessing.__call__": [[743, 777], ["ltr.target_image_crop", "data.apply.apply.apply", "data.apply.apply.apply", "processing.LWLProcessing._get_jittered_box", "len", "isinstance"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.target_image_crop", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._get_jittered_box"], ["", "def", "__call__", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "# Apply joint transformations. i.e. All train/test frames in a sequence are applied the transformation with the", "\n", "# same parameters", "\n", "        ", "if", "self", ".", "transform", "[", "'joint'", "]", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_images'", "]", ",", "data", "[", "'train_anno'", "]", ",", "data", "[", "'train_masks'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "\n", "image", "=", "data", "[", "'train_images'", "]", ",", "bbox", "=", "data", "[", "'train_anno'", "]", ",", "mask", "=", "data", "[", "'train_masks'", "]", ")", "\n", "data", "[", "'test_images'", "]", ",", "data", "[", "'test_anno'", "]", ",", "data", "[", "'test_masks'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "\n", "image", "=", "data", "[", "'test_images'", "]", ",", "bbox", "=", "data", "[", "'test_anno'", "]", ",", "mask", "=", "data", "[", "'test_masks'", "]", ",", "new_roll", "=", "self", ".", "new_roll", ")", "\n", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "assert", "self", ".", "mode", "==", "'sequence'", "or", "len", "(", "data", "[", "s", "+", "'_images'", "]", ")", "==", "1", ",", "\"In pair mode, num train/test frames must be 1\"", "\n", "\n", "# Add a uniform noise to the center pos", "\n", "jittered_anno", "=", "[", "self", ".", "_get_jittered_box", "(", "a", ",", "s", ")", "for", "a", "in", "data", "[", "s", "+", "'_anno'", "]", "]", "\n", "orig_anno", "=", "data", "[", "s", "+", "'_anno'", "]", "\n", "\n", "# Extract a crop containing the target", "\n", "crops", ",", "boxes", ",", "mask_crops", "=", "prutils", ".", "target_image_crop", "(", "data", "[", "s", "+", "'_images'", "]", ",", "jittered_anno", ",", "\n", "data", "[", "s", "+", "'_anno'", "]", ",", "self", ".", "search_area_factor", ",", "\n", "self", ".", "output_sz", ",", "mode", "=", "self", ".", "crop_type", ",", "\n", "max_scale_change", "=", "self", ".", "max_scale_change", ",", "\n", "masks", "=", "data", "[", "s", "+", "'_masks'", "]", ")", "\n", "\n", "# Apply independent transformations to each image", "\n", "data", "[", "s", "+", "'_images'", "]", ",", "data", "[", "s", "+", "'_anno'", "]", ",", "data", "[", "s", "+", "'_masks'", "]", "=", "self", ".", "transform", "[", "s", "]", "(", "image", "=", "crops", ",", "bbox", "=", "boxes", ",", "mask", "=", "mask_crops", ",", "joint", "=", "False", ")", "\n", "\n", "# Prepare output", "\n", "", "if", "self", ".", "mode", "==", "'sequence'", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "stack_tensors", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "lambda", "x", ":", "x", "[", "0", "]", "if", "isinstance", "(", "x", ",", "list", ")", "else", "x", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing.__init__": [[790, 816], ["processing.BaseProcessing.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "search_area_factor", ",", "output_sz", ",", "center_jitter_param", ",", "scale_jitter_param", ",", "\n", "proposal_params", "=", "None", ",", "label_function_params", "=", "None", ",", "min_crop_inside_ratio", "=", "0", ",", "\n", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            search_area_factor - The size of the search region  relative to the target size.\n            output_sz - An integer, denoting the size to which the search region is resized. The search region is always\n                        square.\n            center_jitter_factor - A dict containing the amount of jittering to be applied to the target center before\n                                    extracting the search region. See _generate_synthetic_motion for how the jittering is done.\n            scale_jitter_factor - A dict containing the amount of jittering to be applied to the target size before\n                                    extracting the search region. See _generate_synthetic_motion for how the jittering is done.\n            proposal_params - Arguments for the proposal generation process. See _generate_proposals for details.\n            label_function_params - Arguments for the label generation process. See _generate_label_function for details.\n            min_crop_inside_ratio - Minimum amount of cropped search area which should be inside the image.\n                                    See _check_if_crop_inside_image for details.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "search_area_factor", "=", "search_area_factor", "\n", "self", ".", "output_sz", "=", "output_sz", "\n", "self", ".", "center_jitter_param", "=", "center_jitter_param", "\n", "self", ".", "scale_jitter_param", "=", "scale_jitter_param", "\n", "\n", "self", ".", "proposal_params", "=", "proposal_params", "\n", "self", ".", "label_function_params", "=", "label_function_params", "\n", "self", ".", "min_crop_inside_ratio", "=", "min_crop_inside_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing._check_if_crop_inside_image": [[817, 841], ["box.tolist", "math.ceil", "max", "max", "math.sqrt", "min", "max", "min", "max"], "methods", ["None"], ["", "def", "_check_if_crop_inside_image", "(", "self", ",", "box", ",", "im_shape", ")", ":", "\n", "        ", "x", ",", "y", ",", "w", ",", "h", "=", "box", ".", "tolist", "(", ")", "\n", "\n", "if", "w", "<=", "0.0", "or", "h", "<=", "0.0", ":", "\n", "            ", "return", "False", "\n", "\n", "", "crop_sz", "=", "math", ".", "ceil", "(", "math", ".", "sqrt", "(", "w", "*", "h", ")", "*", "self", ".", "search_area_factor", ")", "\n", "\n", "x1", "=", "x", "+", "0.5", "*", "w", "-", "crop_sz", "*", "0.5", "\n", "x2", "=", "x1", "+", "crop_sz", "\n", "\n", "y1", "=", "y", "+", "0.5", "*", "h", "-", "crop_sz", "*", "0.5", "\n", "y2", "=", "y1", "+", "crop_sz", "\n", "\n", "w_inside", "=", "max", "(", "min", "(", "x2", ",", "im_shape", "[", "1", "]", ")", "-", "max", "(", "x1", ",", "0", ")", ",", "0", ")", "\n", "h_inside", "=", "max", "(", "min", "(", "y2", ",", "im_shape", "[", "0", "]", ")", "-", "max", "(", "y1", ",", "0", ")", ",", "0", ")", "\n", "\n", "crop_area", "=", "(", "(", "x2", "-", "x1", ")", "*", "(", "y2", "-", "y1", ")", ")", "\n", "\n", "if", "crop_area", ">", "0", ":", "\n", "            ", "inside_ratio", "=", "w_inside", "*", "h_inside", "/", "crop_area", "\n", "return", "inside_ratio", ">", "self", ".", "min_crop_inside_ratio", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing._generate_synthetic_motion": [[842, 876], ["len", "range", "range", "out_boxes.append", "torch.cat", "processing.KYSProcessing._check_if_crop_inside_image", "torch.exp", "processing.KYSProcessing.center_jitter_param.get", "torch.tensor().float", "torch.rand", "processing.KYSProcessing.center_jitter_param.get", "torch.randn", "abs", "abs", "torch.tensor", "jittered_size.prod().sqrt", "[].prod().sqrt", "[].prod().sqrt", "jittered_size.prod", "[].prod", "[].prod"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing._check_if_crop_inside_image", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs"], ["", "", "def", "_generate_synthetic_motion", "(", "self", ",", "boxes", ",", "images", ",", "mode", ")", ":", "\n", "        ", "num_frames", "=", "len", "(", "boxes", ")", "\n", "\n", "out_boxes", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_frames", ")", ":", "\n", "            ", "jittered_box", "=", "None", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "orig_box", "=", "boxes", "[", "i", "]", "\n", "jittered_size", "=", "orig_box", "[", "2", ":", "4", "]", "*", "torch", ".", "exp", "(", "torch", ".", "randn", "(", "2", ")", "*", "self", ".", "scale_jitter_param", "[", "mode", "+", "'_factor'", "]", ")", "\n", "\n", "if", "self", ".", "center_jitter_param", ".", "get", "(", "mode", "+", "'_mode'", ",", "'uniform'", ")", "==", "'uniform'", ":", "\n", "                    ", "max_offset", "=", "(", "jittered_size", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "self", ".", "center_jitter_param", "[", "mode", "+", "'_factor'", "]", ")", ".", "item", "(", ")", "\n", "offset_factor", "=", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "\n", "jittered_center", "=", "orig_box", "[", "0", ":", "2", "]", "+", "0.5", "*", "orig_box", "[", "2", ":", "4", "]", "+", "max_offset", "*", "offset_factor", "\n", "\n", "if", "self", ".", "center_jitter_param", ".", "get", "(", "mode", "+", "'_limit_motion'", ",", "False", ")", "and", "i", ">", "0", ":", "\n", "                        ", "prev_out_box_center", "=", "out_boxes", "[", "-", "1", "]", "[", ":", "2", "]", "+", "0.5", "*", "out_boxes", "[", "-", "1", "]", "[", "2", ":", "]", "\n", "if", "abs", "(", "jittered_center", "[", "0", "]", "-", "prev_out_box_center", "[", "0", "]", ")", ">", "out_boxes", "[", "-", "1", "]", "[", "2", ":", "]", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "2.5", ":", "\n", "                            ", "jittered_center", "[", "0", "]", "=", "orig_box", "[", "0", "]", "+", "0.5", "*", "orig_box", "[", "2", "]", "+", "max_offset", "*", "offset_factor", "[", "0", "]", "*", "-", "1", "\n", "\n", "", "if", "abs", "(", "jittered_center", "[", "1", "]", "-", "prev_out_box_center", "[", "1", "]", ")", ">", "out_boxes", "[", "-", "1", "]", "[", "2", ":", "]", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "2.5", ":", "\n", "                            ", "jittered_center", "[", "1", "]", "=", "orig_box", "[", "1", "]", "+", "0.5", "*", "orig_box", "[", "3", "]", "+", "max_offset", "*", "offset_factor", "[", "1", "]", "*", "-", "1", "\n", "\n", "", "", "", "jittered_box", "=", "torch", ".", "cat", "(", "(", "jittered_center", "-", "0.5", "*", "jittered_size", ",", "jittered_size", ")", ",", "dim", "=", "0", ")", "\n", "\n", "if", "self", ".", "_check_if_crop_inside_image", "(", "jittered_box", ",", "images", "[", "i", "]", ".", "shape", ")", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "jittered_box", "=", "torch", ".", "tensor", "(", "[", "1", ",", "1", ",", "10", ",", "10", "]", ")", ".", "float", "(", ")", "\n", "\n", "", "", "out_boxes", ".", "append", "(", "jittered_box", ")", "\n", "\n", "", "return", "out_boxes", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing._generate_proposals": [[877, 894], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "ltr.perturb_box"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.perturb_box"], ["", "def", "_generate_proposals", "(", "self", ",", "frame2_gt_crop", ")", ":", "\n", "# Generate proposals", "\n", "        ", "num_proposals", "=", "self", ".", "proposal_params", "[", "'boxes_per_frame'", "]", "\n", "frame2_proposals", "=", "np", ".", "zeros", "(", "(", "num_proposals", ",", "4", ")", ")", "\n", "gt_iou", "=", "np", ".", "zeros", "(", "num_proposals", ")", "\n", "sample_p", "=", "np", ".", "zeros", "(", "num_proposals", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_proposals", ")", ":", "\n", "            ", "frame2_proposals", "[", "i", ",", ":", "]", ",", "gt_iou", "[", "i", "]", ",", "sample_p", "[", "i", "]", "=", "prutils", ".", "perturb_box", "(", "\n", "frame2_gt_crop", ",", "\n", "min_iou", "=", "self", ".", "proposal_params", "[", "'min_iou'", "]", ",", "\n", "sigma_factor", "=", "self", ".", "proposal_params", "[", "'sigma_factor'", "]", "\n", ")", "\n", "\n", "", "gt_iou", "=", "gt_iou", "*", "2", "-", "1", "\n", "\n", "return", "frame2_proposals", ",", "gt_iou", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing._generate_label_function": [[895, 904], ["ltr.gaussian_label_function", "target_bb.view", "processing.KYSProcessing.label_function_params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gaussian_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "_generate_label_function", "(", "self", ",", "target_bb", ",", "target_absent", "=", "None", ")", ":", "\n", "        ", "gauss_label", "=", "prutils", ".", "gaussian_label_function", "(", "target_bb", ".", "view", "(", "-", "1", ",", "4", ")", ",", "self", ".", "label_function_params", "[", "'sigma_factor'", "]", ",", "\n", "self", ".", "label_function_params", "[", "'kernel_sz'", "]", ",", "\n", "self", ".", "label_function_params", "[", "'feature_sz'", "]", ",", "self", ".", "output_sz", ",", "\n", "end_pad_if_even", "=", "self", ".", "label_function_params", ".", "get", "(", "\n", "'end_pad_if_even'", ",", "True", ")", ")", "\n", "if", "target_absent", "is", "not", "None", ":", "\n", "            ", "gauss_label", "*=", "(", "1", "-", "target_absent", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "float", "(", ")", "\n", "", "return", "gauss_label", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing.__call__": [[905, 937], ["data.apply.apply.apply", "processing.KYSProcessing._generate_synthetic_motion", "ltr.jittered_center_crop", "zip", "processing.KYSProcessing._generate_label_function", "processing.KYSProcessing._generate_label_function", "torch.tensor", "torch.tensor", "processing.KYSProcessing._generate_proposals", "a.numpy"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing._generate_synthetic_motion", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.jittered_center_crop", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._generate_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._generate_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.KYSProcessing._generate_proposals"], ["", "def", "__call__", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "        ", "if", "self", ".", "transform", "[", "'joint'", "]", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_images'", "]", ",", "data", "[", "'train_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'train_images'", "]", ",", "\n", "bbox", "=", "data", "[", "'train_anno'", "]", ")", "\n", "data", "[", "'test_images'", "]", ",", "data", "[", "'test_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'test_images'", "]", ",", "bbox", "=", "data", "[", "'test_anno'", "]", ",", "new_roll", "=", "False", ")", "\n", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "# Generate synthetic sequence", "\n", "            ", "jittered_anno", "=", "self", ".", "_generate_synthetic_motion", "(", "data", "[", "s", "+", "'_anno'", "]", ",", "data", "[", "s", "+", "'_images'", "]", ",", "s", ")", "\n", "\n", "# Crop images", "\n", "crops", ",", "boxes", ",", "_", "=", "prutils", ".", "jittered_center_crop", "(", "data", "[", "s", "+", "'_images'", "]", ",", "jittered_anno", ",", "data", "[", "s", "+", "'_anno'", "]", ",", "\n", "self", ".", "search_area_factor", ",", "self", ".", "output_sz", ")", "\n", "\n", "# Add transforms", "\n", "data", "[", "s", "+", "'_images'", "]", ",", "data", "[", "s", "+", "'_anno'", "]", "=", "self", ".", "transform", "[", "s", "]", "(", "image", "=", "crops", ",", "bbox", "=", "boxes", ",", "joint", "=", "False", ")", "\n", "\n", "", "if", "self", ".", "proposal_params", ":", "\n", "            ", "frame2_proposals", ",", "gt_iou", "=", "zip", "(", "*", "[", "self", ".", "_generate_proposals", "(", "a", ".", "numpy", "(", ")", ")", "for", "a", "in", "data", "[", "'test_anno'", "]", "]", ")", "\n", "\n", "data", "[", "'test_proposals'", "]", "=", "[", "torch", ".", "tensor", "(", "p", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "p", "in", "frame2_proposals", "]", "\n", "data", "[", "'proposal_iou'", "]", "=", "[", "torch", ".", "tensor", "(", "gi", ",", "dtype", "=", "torch", ".", "float32", ")", "for", "gi", "in", "gt_iou", "]", "\n", "\n", "", "data", "=", "data", ".", "apply", "(", "stack_tensors", ")", "\n", "\n", "if", "self", ".", "label_function_params", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_label'", "]", "=", "self", ".", "_generate_label_function", "(", "data", "[", "'train_anno'", "]", ")", "\n", "test_target_absent", "=", "1", "-", "(", "data", "[", "'test_visible'", "]", "*", "data", "[", "'test_valid_anno'", "]", ")", "\n", "\n", "data", "[", "'test_label'", "]", "=", "self", ".", "_generate_label_function", "(", "data", "[", "'test_anno'", "]", ",", "test_target_absent", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing.__init__": [[968, 980], ["processing.BaseProcessing.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "output_sz", ",", "num_target_candidates", "=", "None", ",", "mode", "=", "'self_sup'", ",", "\n", "img_aug_transform", "=", "None", ",", "score_map_sz", "=", "None", ",", "enable_search_area_aug", "=", "True", ",", "\n", "search_area_jitter_value", "=", "100", ",", "real_target_candidates_only", "=", "False", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "output_sz", "=", "output_sz", "\n", "self", ".", "num_target_candidates", "=", "num_target_candidates", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "img_aug_transform", "=", "img_aug_transform", "\n", "self", ".", "enable_search_area_aug", "=", "enable_search_area_aug", "\n", "self", ".", "search_area_jitter_value", "=", "search_area_jitter_value", "\n", "self", ".", "real_target_candidates_only", "=", "real_target_candidates_only", "\n", "self", ".", "score_map_sz", "=", "score_map_sz", "if", "score_map_sz", "is", "not", "None", "else", "(", "23", ",", "23", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing.__call__": [[981, 994], ["processing.TargetCandiateMatchingProcessing.apply", "processing.TargetCandiateMatchingProcessing._original_and_augmented_frame", "processing.TargetCandiateMatchingProcessing._previous_and_current_frame", "processing.TargetCandiateMatchingProcessing._previous_and_current_frame_detected_target_candidates_only", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._original_and_augmented_frame", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._previous_and_current_frame", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._previous_and_current_frame_detected_target_candidates_only"], ["", "def", "__call__", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "        ", "if", "data", "[", "'sup_mode'", "]", "==", "'self_sup'", ":", "\n", "            ", "data", "=", "self", ".", "_original_and_augmented_frame", "(", "data", ")", "\n", "", "elif", "data", "[", "'sup_mode'", "]", "==", "'partial_sup'", "and", "self", ".", "real_target_candidates_only", "==", "False", ":", "\n", "            ", "data", "=", "self", ".", "_previous_and_current_frame", "(", "data", ")", "\n", "", "elif", "data", "[", "'sup_mode'", "]", "==", "'partial_sup'", "and", "self", ".", "real_target_candidates_only", "==", "True", ":", "\n", "            ", "data", "=", "self", ".", "_previous_and_current_frame_detected_target_candidates_only", "(", "data", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n", "", "data", "=", "data", ".", "apply", "(", "stack_tensors", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._original_and_augmented_frame": [[995, 1091], ["pytracking.TensorDict", "sa_box.clone", "sa_box.clone", "ltr.sample_target_from_crop_region", "sa_box.long().tolist", "ltr.sample_target_from_crop_region", "processing.TargetCandiateMatchingProcessing.img_aug_transform", "sa_box.clone.tolist", "torch.stack().permute", "processing.TargetCandiateMatchingProcessing._candidate_drop_out", "processing.TargetCandiateMatchingProcessing._pad_with_fake_candidates", "processing.TargetCandiateMatchingProcessing._add_fake_candidate_scores", "processing.TargetCandiateMatchingProcessing._add_fake_candidate_scores", "sa_box.clone.long().tolist", "torch.stack().permute", "torch.tensor.long().tolist", "torch.where", "torch.where", "torch.where", "torch.where", "torch.stack().permute", "processing.TargetCandiateMatchingProcessing._augment_coords", "processing.TargetCandiateMatchingProcessing._augment_scores", "torch.zeros", "torch.arange().float", "torch.arange().float", "data.pop", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack().permute.clone", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.all", "torch.all", "torch.all", "torch.all", "sa_box.long", "torch.stack", "sa_box.clone.long", "torch.stack", "torch.tensor.long", "torch.stack", "torch.all", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.round().long", "torch.round().long", "torch.round().long", "torch.round().long", "torch.round", "torch.round", "torch.round", "torch.round", "tsm_coords[].float", "tsm_coords[].float"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target_from_crop_region", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target_from_crop_region", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._candidate_drop_out", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._pad_with_fake_candidates", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._add_fake_candidate_scores", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._add_fake_candidate_scores", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._augment_coords", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._augment_scores"], ["", "def", "_original_and_augmented_frame", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "        ", "out", "=", "TensorDict", "(", ")", "\n", "img", "=", "data", ".", "pop", "(", "'img'", ")", "[", "0", "]", "\n", "tsm_coords", "=", "data", "[", "'target_candidate_coords'", "]", "[", "0", "]", "\n", "scores", "=", "data", "[", "'target_candidate_scores'", "]", "[", "0", "]", "\n", "sa_box", "=", "data", "[", "'search_area_box'", "]", "[", "0", "]", "\n", "sa_box0", "=", "sa_box", ".", "clone", "(", ")", "\n", "sa_box1", "=", "sa_box", ".", "clone", "(", ")", "\n", "\n", "out", "[", "'img_shape0'", "]", "=", "[", "torch", ".", "tensor", "(", "img", ".", "shape", "[", ":", "2", "]", ")", "]", "\n", "out", "[", "'img_shape1'", "]", "=", "[", "torch", ".", "tensor", "(", "img", ".", "shape", "[", ":", "2", "]", ")", "]", "\n", "\n", "# prepared cropped image", "\n", "frame_crop0", "=", "prutils", ".", "sample_target_from_crop_region", "(", "img", ",", "sa_box0", ",", "self", ".", "output_sz", ")", "\n", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "sa_box", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "if", "self", ".", "enable_search_area_aug", ":", "\n", "            ", "l", "=", "self", ".", "search_area_jitter_value", "\n", "sa_box1", "=", "torch", ".", "tensor", "(", "[", "x", "+", "torch", ".", "randint", "(", "-", "w", "//", "l", ",", "w", "//", "l", "+", "1", ",", "(", "1", ",", ")", ")", ",", "\n", "y", "+", "torch", ".", "randint", "(", "-", "h", "//", "l", ",", "h", "//", "l", "+", "1", ",", "(", "1", ",", ")", ")", ",", "\n", "w", "+", "torch", ".", "randint", "(", "-", "w", "//", "l", ",", "w", "//", "l", "+", "1", ",", "(", "1", ",", ")", ")", ",", "\n", "h", "+", "torch", ".", "randint", "(", "-", "h", "//", "l", ",", "h", "//", "l", "+", "1", ",", "(", "1", ",", ")", ")", "]", ")", "\n", "\n", "", "frame_crop1", "=", "prutils", ".", "sample_target_from_crop_region", "(", "img", ",", "sa_box1", ",", "self", ".", "output_sz", ")", "\n", "\n", "frame_crop0", "=", "self", ".", "transform", "[", "'train'", "]", "(", "image", "=", "frame_crop0", ")", "\n", "frame_crop1", "=", "self", ".", "img_aug_transform", "(", "image", "=", "frame_crop1", ")", "\n", "\n", "out", "[", "'img_cropped0'", "]", "=", "[", "frame_crop0", "]", "\n", "out", "[", "'img_cropped1'", "]", "=", "[", "frame_crop1", "]", "\n", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "sa_box0", ".", "tolist", "(", ")", "\n", "img_coords", "=", "torch", ".", "stack", "(", "[", "\n", "h", "*", "(", "tsm_coords", "[", ":", ",", "0", "]", ".", "float", "(", ")", "/", "(", "self", ".", "score_map_sz", "[", "0", "]", "-", "1", ")", ")", "+", "y", ",", "\n", "w", "*", "(", "tsm_coords", "[", ":", ",", "1", "]", ".", "float", "(", ")", "/", "(", "self", ".", "score_map_sz", "[", "1", "]", "-", "1", ")", ")", "+", "x", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "img_coords_pad0", ",", "img_coords_pad1", ",", "valid0", ",", "valid1", "=", "self", ".", "_candidate_drop_out", "(", "img_coords", ",", "img_coords", ".", "clone", "(", ")", ")", "\n", "\n", "img_coords_pad0", ",", "img_coords_pad1", "=", "self", ".", "_pad_with_fake_candidates", "(", "img_coords_pad0", ",", "img_coords_pad1", ",", "valid0", ",", "valid1", ",", "\n", "sa_box0", ",", "sa_box1", ",", "img", ".", "shape", ")", "\n", "\n", "scores_pad0", "=", "self", ".", "_add_fake_candidate_scores", "(", "scores", ",", "valid0", ")", "\n", "scores_pad1", "=", "self", ".", "_add_fake_candidate_scores", "(", "scores", ",", "valid1", ")", "\n", "\n", "x0", ",", "y0", ",", "w0", ",", "h0", "=", "sa_box0", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "tsm_coords_pad0", "=", "torch", ".", "stack", "(", "[", "\n", "torch", ".", "round", "(", "(", "img_coords_pad0", "[", ":", ",", "0", "]", "-", "y0", ")", "/", "h0", "*", "(", "self", ".", "score_map_sz", "[", "0", "]", "-", "1", ")", ")", ".", "long", "(", ")", ",", "\n", "torch", ".", "round", "(", "(", "img_coords_pad0", "[", ":", ",", "1", "]", "-", "x0", ")", "/", "w0", "*", "(", "self", ".", "score_map_sz", "[", "1", "]", "-", "1", ")", ")", ".", "long", "(", ")", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "# make sure that the augmented search_are_box is only used for the fake img_coords the other need the original.", "\n", "x1", ",", "y1", ",", "w1", ",", "h1", "=", "sa_box1", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "y", "=", "torch", ".", "where", "(", "valid1", "==", "1", ",", "torch", ".", "tensor", "(", "y0", ")", ",", "torch", ".", "tensor", "(", "y1", ")", ")", "\n", "x", "=", "torch", ".", "where", "(", "valid1", "==", "1", ",", "torch", ".", "tensor", "(", "x0", ")", ",", "torch", ".", "tensor", "(", "x1", ")", ")", "\n", "h", "=", "torch", ".", "where", "(", "valid1", "==", "1", ",", "torch", ".", "tensor", "(", "h0", ")", ",", "torch", ".", "tensor", "(", "h1", ")", ")", "\n", "w", "=", "torch", ".", "where", "(", "valid1", "==", "1", ",", "torch", ".", "tensor", "(", "w0", ")", ",", "torch", ".", "tensor", "(", "w1", ")", ")", "\n", "\n", "tsm_coords_pad1", "=", "torch", ".", "stack", "(", "[", "\n", "torch", ".", "round", "(", "(", "img_coords_pad1", "[", ":", ",", "0", "]", "-", "y", ")", "/", "h", "*", "(", "self", ".", "score_map_sz", "[", "0", "]", "-", "1", ")", ")", ".", "long", "(", ")", ",", "\n", "torch", ".", "round", "(", "(", "img_coords_pad1", "[", ":", ",", "1", "]", "-", "x", ")", "/", "w", "*", "(", "self", ".", "score_map_sz", "[", "1", "]", "-", "1", ")", ")", ".", "long", "(", ")", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "assert", "torch", ".", "all", "(", "tsm_coords_pad0", ">=", "0", ")", "and", "torch", ".", "all", "(", "tsm_coords_pad0", "<", "self", ".", "score_map_sz", "[", "0", "]", ")", "\n", "assert", "torch", ".", "all", "(", "tsm_coords_pad1", ">=", "0", ")", "and", "torch", ".", "all", "(", "tsm_coords_pad1", "<", "self", ".", "score_map_sz", "[", "0", "]", ")", "\n", "\n", "img_coords_pad1", "=", "self", ".", "_augment_coords", "(", "img_coords_pad1", ",", "img", ".", "shape", ",", "sa_box1", ")", "\n", "scores_pad1", "=", "self", ".", "_augment_scores", "(", "scores_pad1", ",", "valid1", ",", "~", "torch", ".", "all", "(", "valid0", "==", "valid1", ")", ")", "\n", "\n", "out", "[", "'candidate_img_coords0'", "]", "=", "[", "img_coords_pad0", "]", "\n", "out", "[", "'candidate_img_coords1'", "]", "=", "[", "img_coords_pad1", "]", "\n", "out", "[", "'candidate_tsm_coords0'", "]", "=", "[", "tsm_coords_pad0", "]", "\n", "out", "[", "'candidate_tsm_coords1'", "]", "=", "[", "tsm_coords_pad1", "]", "\n", "out", "[", "'candidate_scores0'", "]", "=", "[", "scores_pad0", "]", "\n", "out", "[", "'candidate_scores1'", "]", "=", "[", "scores_pad1", "]", "\n", "out", "[", "'candidate_valid0'", "]", "=", "[", "valid0", "]", "\n", "out", "[", "'candidate_valid1'", "]", "=", "[", "valid1", "]", "\n", "\n", "# Prepare gt labels", "\n", "\n", "gt_assignment", "=", "torch", ".", "zeros", "(", "(", "self", ".", "num_target_candidates", ",", "self", ".", "num_target_candidates", ")", ")", "\n", "gt_assignment", "[", "torch", ".", "arange", "(", "self", ".", "num_target_candidates", ")", ",", "torch", ".", "arange", "(", "self", ".", "num_target_candidates", ")", "]", "=", "valid0", "*", "valid1", "\n", "\n", "gt_matches0", "=", "torch", ".", "arange", "(", "0", ",", "self", ".", "num_target_candidates", ")", ".", "float", "(", ")", "\n", "gt_matches1", "=", "torch", ".", "arange", "(", "0", ",", "self", ".", "num_target_candidates", ")", ".", "float", "(", ")", "\n", "\n", "gt_matches0", "[", "(", "valid0", "==", "0", ")", "|", "(", "valid1", "==", "0", ")", "]", "=", "-", "1", "\n", "gt_matches1", "[", "(", "valid0", "==", "0", ")", "|", "(", "valid1", "==", "0", ")", "]", "=", "-", "1", "\n", "\n", "out", "[", "'gt_matches0'", "]", "=", "[", "gt_matches0", "]", "\n", "out", "[", "'gt_matches1'", "]", "=", "[", "gt_matches1", "]", "\n", "out", "[", "'gt_assignment'", "]", "=", "[", "gt_assignment", "]", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._previous_and_current_frame": [[1092, 1193], ["pytracking.TensorDict", "data.pop", "ltr.sample_target_from_crop_region", "ltr.sample_target_from_crop_region", "processing.TargetCandiateMatchingProcessing._find_gt_candidate_index", "processing.TargetCandiateMatchingProcessing._find_gt_candidate_index", "sa_box0.tolist", "sa_box1.tolist", "torch.stack().permute", "torch.stack().permute", "processing.TargetCandiateMatchingProcessing._gt_candidate_drop_out", "processing.TargetCandiateMatchingProcessing._pad_with_fake_candidates_drop_gt", "processing.TargetCandiateMatchingProcessing._pad_with_fake_candidates_drop_gt", "processing.TargetCandiateMatchingProcessing._add_fake_candidate_scores", "processing.TargetCandiateMatchingProcessing._add_fake_candidate_scores", "sa_box0.long().tolist", "sa_box1.long().tolist", "torch.stack().permute", "torch.stack().permute", "torch.zeros", "torch.tensor", "torch.tensor", "torch.all", "torch.all", "torch.all", "torch.all", "torch.zeros", "torch.zeros", "torch.stack", "torch.stack", "sa_box0.long", "sa_box1.long", "torch.stack", "torch.stack", "torch.round().long", "torch.round().long", "torch.round().long", "torch.round().long", "torch.round", "torch.round", "torch.round", "torch.round", "tsm_coords0[].float", "tsm_coords0[].float", "tsm_coords1[].float", "tsm_coords1[].float"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target_from_crop_region", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target_from_crop_region", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._find_gt_candidate_index", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._find_gt_candidate_index", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._gt_candidate_drop_out", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._pad_with_fake_candidates_drop_gt", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._pad_with_fake_candidates_drop_gt", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._add_fake_candidate_scores", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._add_fake_candidate_scores"], ["", "def", "_previous_and_current_frame", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "        ", "out", "=", "TensorDict", "(", ")", "\n", "imgs", "=", "data", ".", "pop", "(", "'img'", ")", "\n", "img0", "=", "imgs", "[", "0", "]", "\n", "img1", "=", "imgs", "[", "1", "]", "\n", "sa_box0", "=", "data", "[", "'search_area_box'", "]", "[", "0", "]", "\n", "sa_box1", "=", "data", "[", "'search_area_box'", "]", "[", "1", "]", "\n", "tsm_anno_coord0", "=", "data", "[", "'target_anno_coord'", "]", "[", "0", "]", "\n", "tsm_anno_coord1", "=", "data", "[", "'target_anno_coord'", "]", "[", "1", "]", "\n", "tsm_coords0", "=", "data", "[", "'target_candidate_coords'", "]", "[", "0", "]", "\n", "tsm_coords1", "=", "data", "[", "'target_candidate_coords'", "]", "[", "1", "]", "\n", "scores0", "=", "data", "[", "'target_candidate_scores'", "]", "[", "0", "]", "\n", "scores1", "=", "data", "[", "'target_candidate_scores'", "]", "[", "1", "]", "\n", "\n", "out", "[", "'img_shape0'", "]", "=", "[", "torch", ".", "tensor", "(", "img0", ".", "shape", "[", ":", "2", "]", ")", "]", "\n", "out", "[", "'img_shape1'", "]", "=", "[", "torch", ".", "tensor", "(", "img1", ".", "shape", "[", ":", "2", "]", ")", "]", "\n", "\n", "frame_crop0", "=", "prutils", ".", "sample_target_from_crop_region", "(", "img0", ",", "sa_box0", ",", "self", ".", "output_sz", ")", "\n", "frame_crop1", "=", "prutils", ".", "sample_target_from_crop_region", "(", "img1", ",", "sa_box1", ",", "self", ".", "output_sz", ")", "\n", "\n", "frame_crop0", "=", "self", ".", "transform", "[", "'train'", "]", "(", "image", "=", "frame_crop0", ")", "\n", "frame_crop1", "=", "self", ".", "transform", "[", "'train'", "]", "(", "image", "=", "frame_crop1", ")", "\n", "\n", "out", "[", "'img_cropped0'", "]", "=", "[", "frame_crop0", "]", "\n", "out", "[", "'img_cropped1'", "]", "=", "[", "frame_crop1", "]", "\n", "\n", "gt_idx0", "=", "self", ".", "_find_gt_candidate_index", "(", "tsm_coords0", ",", "tsm_anno_coord0", ")", "\n", "gt_idx1", "=", "self", ".", "_find_gt_candidate_index", "(", "tsm_coords1", ",", "tsm_anno_coord1", ")", "\n", "\n", "x0", ",", "y0", ",", "w0", ",", "h0", "=", "sa_box0", ".", "tolist", "(", ")", "\n", "x1", ",", "y1", ",", "w1", ",", "h1", "=", "sa_box1", ".", "tolist", "(", ")", "\n", "\n", "img_coords0", "=", "torch", ".", "stack", "(", "[", "\n", "h0", "*", "(", "tsm_coords0", "[", ":", ",", "0", "]", ".", "float", "(", ")", "/", "(", "self", ".", "score_map_sz", "[", "0", "]", "-", "1", ")", ")", "+", "y0", ",", "\n", "w0", "*", "(", "tsm_coords0", "[", ":", ",", "1", "]", ".", "float", "(", ")", "/", "(", "self", ".", "score_map_sz", "[", "1", "]", "-", "1", ")", ")", "+", "x0", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "img_coords1", "=", "torch", ".", "stack", "(", "[", "\n", "h1", "*", "(", "tsm_coords1", "[", ":", ",", "0", "]", ".", "float", "(", ")", "/", "(", "self", ".", "score_map_sz", "[", "0", "]", "-", "1", ")", ")", "+", "y1", ",", "\n", "w1", "*", "(", "tsm_coords1", "[", ":", ",", "1", "]", ".", "float", "(", ")", "/", "(", "self", ".", "score_map_sz", "[", "1", "]", "-", "1", ")", ")", "+", "x1", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "frame_id", ",", "dropout", "=", "self", ".", "_gt_candidate_drop_out", "(", ")", "\n", "\n", "drop0", "=", "dropout", "&", "(", "frame_id", "==", "0", ")", "\n", "drop1", "=", "dropout", "&", "(", "frame_id", "==", "1", ")", "\n", "\n", "img_coords_pad0", ",", "valid0", "=", "self", ".", "_pad_with_fake_candidates_drop_gt", "(", "img_coords0", ",", "drop0", ",", "gt_idx0", ",", "sa_box0", ",", "img0", ".", "shape", ")", "\n", "img_coords_pad1", ",", "valid1", "=", "self", ".", "_pad_with_fake_candidates_drop_gt", "(", "img_coords1", ",", "drop1", ",", "gt_idx1", ",", "sa_box1", ",", "img1", ".", "shape", ")", "\n", "\n", "scores_pad0", "=", "self", ".", "_add_fake_candidate_scores", "(", "scores0", ",", "valid0", ")", "\n", "scores_pad1", "=", "self", ".", "_add_fake_candidate_scores", "(", "scores1", ",", "valid1", ")", "\n", "\n", "x0", ",", "y0", ",", "w0", ",", "h0", "=", "sa_box0", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "x1", ",", "y1", ",", "w1", ",", "h1", "=", "sa_box1", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "\n", "tsm_coords_pad0", "=", "torch", ".", "stack", "(", "[", "\n", "torch", ".", "round", "(", "(", "img_coords_pad0", "[", ":", ",", "0", "]", "-", "y0", ")", "/", "h0", "*", "(", "self", ".", "score_map_sz", "[", "0", "]", "-", "1", ")", ")", ".", "long", "(", ")", ",", "\n", "torch", ".", "round", "(", "(", "img_coords_pad0", "[", ":", ",", "1", "]", "-", "x0", ")", "/", "w0", "*", "(", "self", ".", "score_map_sz", "[", "1", "]", "-", "1", ")", ")", ".", "long", "(", ")", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "tsm_coords_pad1", "=", "torch", ".", "stack", "(", "[", "\n", "torch", ".", "round", "(", "(", "img_coords_pad1", "[", ":", ",", "0", "]", "-", "y1", ")", "/", "h1", "*", "(", "self", ".", "score_map_sz", "[", "0", "]", "-", "1", ")", ")", ".", "long", "(", ")", ",", "\n", "torch", ".", "round", "(", "(", "img_coords_pad1", "[", ":", ",", "1", "]", "-", "x1", ")", "/", "w1", "*", "(", "self", ".", "score_map_sz", "[", "1", "]", "-", "1", ")", ")", ".", "long", "(", ")", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "assert", "torch", ".", "all", "(", "tsm_coords_pad0", ">=", "0", ")", "and", "torch", ".", "all", "(", "tsm_coords_pad0", "<", "self", ".", "score_map_sz", "[", "0", "]", ")", "\n", "assert", "torch", ".", "all", "(", "tsm_coords_pad1", ">=", "0", ")", "and", "torch", ".", "all", "(", "tsm_coords_pad1", "<", "self", ".", "score_map_sz", "[", "0", "]", ")", "\n", "\n", "out", "[", "'candidate_img_coords0'", "]", "=", "[", "img_coords_pad0", "]", "\n", "out", "[", "'candidate_img_coords1'", "]", "=", "[", "img_coords_pad1", "]", "\n", "out", "[", "'candidate_tsm_coords0'", "]", "=", "[", "tsm_coords_pad0", "]", "\n", "out", "[", "'candidate_tsm_coords1'", "]", "=", "[", "tsm_coords_pad1", "]", "\n", "out", "[", "'candidate_scores0'", "]", "=", "[", "scores_pad0", "]", "\n", "out", "[", "'candidate_scores1'", "]", "=", "[", "scores_pad1", "]", "\n", "out", "[", "'candidate_valid0'", "]", "=", "[", "valid0", "]", "\n", "out", "[", "'candidate_valid1'", "]", "=", "[", "valid1", "]", "\n", "\n", "# Prepare gt labels", "\n", "gt_assignment", "=", "torch", ".", "zeros", "(", "(", "self", ".", "num_target_candidates", ",", "self", ".", "num_target_candidates", ")", ")", "\n", "gt_assignment", "[", "gt_idx0", ",", "gt_idx1", "]", "=", "valid0", "[", "gt_idx0", "]", "*", "valid1", "[", "gt_idx1", "]", "\n", "\n", "gt_matches0", "=", "torch", ".", "zeros", "(", "self", ".", "num_target_candidates", ")", "-", "2", "\n", "gt_matches1", "=", "torch", ".", "zeros", "(", "self", ".", "num_target_candidates", ")", "-", "2", "\n", "\n", "if", "drop0", ":", "\n", "            ", "gt_matches0", "[", "gt_idx0", "]", "=", "-", "2", "\n", "gt_matches1", "[", "gt_idx1", "]", "=", "-", "1", "\n", "", "elif", "drop1", ":", "\n", "            ", "gt_matches0", "[", "gt_idx0", "]", "=", "-", "1", "\n", "gt_matches0", "[", "gt_idx1", "]", "=", "-", "2", "\n", "", "else", ":", "\n", "            ", "gt_matches0", "[", "gt_idx0", "]", "=", "gt_idx1", "\n", "gt_matches1", "[", "gt_idx1", "]", "=", "gt_idx0", "\n", "\n", "", "out", "[", "'gt_matches0'", "]", "=", "[", "gt_matches0", "]", "\n", "out", "[", "'gt_matches1'", "]", "=", "[", "gt_matches1", "]", "\n", "out", "[", "'gt_assignment'", "]", "=", "[", "gt_assignment", "]", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._previous_and_current_frame_detected_target_candidates_only": [[1194, 1260], ["pytracking.TensorDict", "data.pop", "ltr.sample_target_from_crop_region", "ltr.sample_target_from_crop_region", "processing.TargetCandiateMatchingProcessing._find_gt_candidate_index", "processing.TargetCandiateMatchingProcessing._find_gt_candidate_index", "sa_box0.tolist", "sa_box1.tolist", "torch.stack().permute", "torch.stack().permute", "torch.zeros", "torch.tensor", "torch.tensor", "torch.ones_like", "torch.ones_like", "torch.zeros", "torch.zeros", "torch.stack", "torch.stack", "tsm_coords0[].float", "tsm_coords0[].float", "tsm_coords1[].float", "tsm_coords1[].float"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target_from_crop_region", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target_from_crop_region", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._find_gt_candidate_index", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._find_gt_candidate_index"], ["", "def", "_previous_and_current_frame_detected_target_candidates_only", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "        ", "out", "=", "TensorDict", "(", ")", "\n", "imgs", "=", "data", ".", "pop", "(", "'img'", ")", "\n", "img0", "=", "imgs", "[", "0", "]", "\n", "img1", "=", "imgs", "[", "1", "]", "\n", "sa_box0", "=", "data", "[", "'search_area_box'", "]", "[", "0", "]", "\n", "sa_box1", "=", "data", "[", "'search_area_box'", "]", "[", "1", "]", "\n", "tsm_anno_coord0", "=", "data", "[", "'target_anno_coord'", "]", "[", "0", "]", "\n", "tsm_anno_coord1", "=", "data", "[", "'target_anno_coord'", "]", "[", "1", "]", "\n", "tsm_coords0", "=", "data", "[", "'target_candidate_coords'", "]", "[", "0", "]", "\n", "tsm_coords1", "=", "data", "[", "'target_candidate_coords'", "]", "[", "1", "]", "\n", "scores0", "=", "data", "[", "'target_candidate_scores'", "]", "[", "0", "]", "\n", "scores1", "=", "data", "[", "'target_candidate_scores'", "]", "[", "1", "]", "\n", "\n", "out", "[", "'img_shape0'", "]", "=", "[", "torch", ".", "tensor", "(", "img0", ".", "shape", "[", ":", "2", "]", ")", "]", "\n", "out", "[", "'img_shape1'", "]", "=", "[", "torch", ".", "tensor", "(", "img1", ".", "shape", "[", ":", "2", "]", ")", "]", "\n", "\n", "frame_crop0", "=", "prutils", ".", "sample_target_from_crop_region", "(", "img0", ",", "sa_box0", ",", "self", ".", "output_sz", ")", "\n", "frame_crop1", "=", "prutils", ".", "sample_target_from_crop_region", "(", "img1", ",", "sa_box1", ",", "self", ".", "output_sz", ")", "\n", "\n", "frame_crop0", "=", "self", ".", "transform", "[", "'train'", "]", "(", "image", "=", "frame_crop0", ")", "\n", "frame_crop1", "=", "self", ".", "transform", "[", "'train'", "]", "(", "image", "=", "frame_crop1", ")", "\n", "\n", "out", "[", "'img_cropped0'", "]", "=", "[", "frame_crop0", "]", "\n", "out", "[", "'img_cropped1'", "]", "=", "[", "frame_crop1", "]", "\n", "\n", "gt_idx0", "=", "self", ".", "_find_gt_candidate_index", "(", "tsm_coords0", ",", "tsm_anno_coord0", ")", "\n", "gt_idx1", "=", "self", ".", "_find_gt_candidate_index", "(", "tsm_coords1", ",", "tsm_anno_coord1", ")", "\n", "\n", "x0", ",", "y0", ",", "w0", ",", "h0", "=", "sa_box0", ".", "tolist", "(", ")", "\n", "x1", ",", "y1", ",", "w1", ",", "h1", "=", "sa_box1", ".", "tolist", "(", ")", "\n", "\n", "img_coords0", "=", "torch", ".", "stack", "(", "[", "\n", "h0", "*", "(", "tsm_coords0", "[", ":", ",", "0", "]", ".", "float", "(", ")", "/", "(", "self", ".", "score_map_sz", "[", "0", "]", "-", "1", ")", ")", "+", "y0", ",", "\n", "w0", "*", "(", "tsm_coords0", "[", ":", ",", "1", "]", ".", "float", "(", ")", "/", "(", "self", ".", "score_map_sz", "[", "1", "]", "-", "1", ")", ")", "+", "x0", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "img_coords1", "=", "torch", ".", "stack", "(", "[", "\n", "h1", "*", "(", "tsm_coords1", "[", ":", ",", "0", "]", ".", "float", "(", ")", "/", "(", "self", ".", "score_map_sz", "[", "0", "]", "-", "1", ")", ")", "+", "y1", ",", "\n", "w1", "*", "(", "tsm_coords1", "[", ":", ",", "1", "]", ".", "float", "(", ")", "/", "(", "self", ".", "score_map_sz", "[", "1", "]", "-", "1", ")", ")", "+", "x1", "\n", "]", ")", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "out", "[", "'candidate_img_coords0'", "]", "=", "[", "img_coords0", "]", "\n", "out", "[", "'candidate_img_coords1'", "]", "=", "[", "img_coords1", "]", "\n", "out", "[", "'candidate_tsm_coords0'", "]", "=", "[", "tsm_coords0", "]", "\n", "out", "[", "'candidate_tsm_coords1'", "]", "=", "[", "tsm_coords1", "]", "\n", "out", "[", "'candidate_scores0'", "]", "=", "[", "scores0", "]", "\n", "out", "[", "'candidate_scores1'", "]", "=", "[", "scores1", "]", "\n", "out", "[", "'candidate_valid0'", "]", "=", "[", "torch", ".", "ones_like", "(", "scores0", ")", "]", "\n", "out", "[", "'candidate_valid1'", "]", "=", "[", "torch", ".", "ones_like", "(", "scores1", ")", "]", "\n", "\n", "# Prepare gt labels", "\n", "gt_assignment", "=", "torch", ".", "zeros", "(", "(", "scores0", ".", "shape", "[", "0", "]", ",", "scores1", ".", "shape", "[", "0", "]", ")", ")", "\n", "gt_assignment", "[", "gt_idx0", ",", "gt_idx1", "]", "=", "1", "\n", "\n", "gt_matches0", "=", "torch", ".", "zeros", "(", "scores0", ".", "shape", "[", "0", "]", ")", "-", "2", "\n", "gt_matches1", "=", "torch", ".", "zeros", "(", "scores1", ".", "shape", "[", "0", "]", ")", "-", "2", "\n", "\n", "gt_matches0", "[", "gt_idx0", "]", "=", "gt_idx1", "\n", "gt_matches1", "[", "gt_idx1", "]", "=", "gt_idx0", "\n", "\n", "out", "[", "'gt_matches0'", "]", "=", "[", "gt_matches0", "]", "\n", "out", "[", "'gt_matches1'", "]", "=", "[", "gt_matches1", "]", "\n", "out", "[", "'gt_assignment'", "]", "=", "[", "gt_assignment", "]", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._find_gt_candidate_index": [[1261, 1264], ["torch.argmin", "torch.sum"], "methods", ["None"], ["", "def", "_find_gt_candidate_index", "(", "self", ",", "coords", ",", "target_anno_coord", ")", ":", "\n", "        ", "gt_idx", "=", "torch", ".", "argmin", "(", "torch", ".", "sum", "(", "(", "coords", "-", "target_anno_coord", ")", "**", "2", ",", "dim", "=", "1", ")", ")", "\n", "return", "gt_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._gt_candidate_drop_out": [[1265, 1269], ["torch.randint().item", "torch.randint", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "_gt_candidate_drop_out", "(", "self", ")", ":", "\n", "        ", "dropout", "=", "(", "torch", ".", "rand", "(", "1", ")", "<", "0.25", ")", ".", "item", "(", ")", "\n", "frameid", "=", "torch", ".", "randint", "(", "0", ",", "2", ",", "(", "1", ",", ")", ")", ".", "item", "(", ")", "\n", "return", "frameid", ",", "dropout", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._pad_with_fake_candidates_drop_gt": [[1270, 1306], ["min", "sa_box.long().tolist", "torch.zeros", "torch.zeros", "img_coords_pad[].clone().unsqueeze", "torch.zeros.clone", "range", "max", "max", "min", "min", "sa_box.long", "img_coords_pad[].clone", "torch.cat", "torch.cat", "torch.sqrt", "torch.argmax", "torch.sum", "torch.min", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "_pad_with_fake_candidates_drop_gt", "(", "self", ",", "img_coords", ",", "dropout", ",", "gt_idx", ",", "sa_box", ",", "img_shape", ")", ":", "\n", "        ", "H", ",", "W", "=", "img_shape", "[", ":", "2", "]", "\n", "num_peaks", "=", "min", "(", "img_coords", ".", "shape", "[", "0", "]", ",", "self", ".", "num_target_candidates", ")", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "sa_box", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "lowx", ",", "lowy", ",", "highx", ",", "highy", "=", "max", "(", "0", ",", "x", ")", ",", "max", "(", "0", ",", "y", ")", ",", "min", "(", "W", ",", "x", "+", "w", ")", ",", "min", "(", "H", ",", "y", "+", "h", ")", "\n", "\n", "img_coords_pad", "=", "torch", ".", "zeros", "(", "(", "self", ".", "num_target_candidates", ",", "2", ")", ")", "\n", "valid", "=", "torch", ".", "zeros", "(", "self", ".", "num_target_candidates", ")", "\n", "\n", "img_coords_pad", "[", ":", "num_peaks", "]", "=", "img_coords", "[", ":", "num_peaks", "]", "\n", "valid", "[", ":", "num_peaks", "]", "=", "1", "\n", "\n", "gt_coords", "=", "img_coords_pad", "[", "gt_idx", "]", ".", "clone", "(", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "if", "dropout", ":", "\n", "            ", "valid", "[", "gt_idx", "]", "=", "0", "\n", "img_coords_pad", "[", "gt_idx", "]", "=", "0", "\n", "\n", "", "filled", "=", "valid", ".", "clone", "(", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "self", ".", "num_target_candidates", ")", ":", "\n", "            ", "if", "filled", "[", "i", "]", "==", "0", ":", "\n", "                ", "cs", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "rand", "(", "(", "20", ",", "1", ")", ")", "*", "(", "highy", "-", "lowy", ")", "+", "lowy", ",", "\n", "torch", ".", "rand", "(", "(", "20", ",", "1", ")", ")", "*", "(", "highx", "-", "lowx", ")", "+", "lowx", "\n", "]", ",", "dim", "=", "1", ")", "\n", "\n", "cs_used", "=", "torch", ".", "cat", "(", "[", "img_coords_pad", "[", "filled", "==", "1", "]", ",", "gt_coords", "]", ",", "dim", "=", "0", ")", "\n", "\n", "dist", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "cs_used", "[", ":", ",", "None", ",", ":", "]", "-", "cs", "[", "None", ",", ":", ",", ":", "]", ")", "**", "2", ",", "dim", "=", "2", ")", ")", "\n", "min_dist", "=", "torch", ".", "min", "(", "dist", ",", "dim", "=", "0", ")", ".", "values", "\n", "max_min_dist_idx", "=", "torch", ".", "argmax", "(", "min_dist", ")", "\n", "img_coords_pad", "[", "i", "]", "=", "cs", "[", "max_min_dist_idx", "]", "\n", "filled", "[", "i", "]", "=", "1", "\n", "\n", "", "", "return", "img_coords_pad", ",", "valid", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._candidate_drop_out": [[1307, 1331], ["min", "torch.round().long", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.randperm", "torch.rand", "torch.round", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "_candidate_drop_out", "(", "self", ",", "coords0", ",", "coords1", ")", ":", "\n", "        ", "num_candidates", "=", "min", "(", "coords1", ".", "shape", "[", "0", "]", ",", "self", ".", "num_target_candidates", ")", "\n", "num_candidates_to_drop", "=", "torch", ".", "round", "(", "0.25", "*", "num_candidates", "*", "torch", ".", "rand", "(", "1", ")", ")", ".", "long", "(", ")", "\n", "idx", "=", "torch", ".", "randperm", "(", "num_candidates", ")", "[", ":", "num_candidates_to_drop", "]", "\n", "\n", "coords_pad0", "=", "torch", ".", "zeros", "(", "(", "self", ".", "num_target_candidates", ",", "2", ")", ")", "\n", "valid0", "=", "torch", ".", "zeros", "(", "self", ".", "num_target_candidates", ")", "\n", "coords_pad1", "=", "torch", ".", "zeros", "(", "(", "self", ".", "num_target_candidates", ",", "2", ")", ")", "\n", "valid1", "=", "torch", ".", "zeros", "(", "self", ".", "num_target_candidates", ")", "\n", "\n", "coords_pad0", "[", ":", "num_candidates", "]", "=", "coords0", "[", ":", "num_candidates", "]", "\n", "coords_pad1", "[", ":", "num_candidates", "]", "=", "coords1", "[", ":", "num_candidates", "]", "\n", "\n", "valid0", "[", ":", "num_candidates", "]", "=", "1", "\n", "valid1", "[", ":", "num_candidates", "]", "=", "1", "\n", "\n", "if", "torch", ".", "rand", "(", "1", ")", "<", "0.5", ":", "\n", "            ", "coords_pad0", "[", "idx", "]", "=", "0", "\n", "valid0", "[", "idx", "]", "=", "0", "\n", "", "else", ":", "\n", "            ", "coords_pad1", "[", "idx", "]", "=", "0", "\n", "valid1", "[", "idx", "]", "=", "0", "\n", "\n", "", "return", "coords_pad0", ",", "coords_pad1", ",", "valid0", ",", "valid1", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._pad_with_fake_candidates": [[1332, 1363], ["sa_box0.long().tolist", "sa_box1.long().tolist", "range", "max", "max", "max", "max", "min", "min", "min", "min", "valid0.clone", "valid1.clone", "img_coords_pad0.clone", "img_coords_pad1.clone", "range", "sa_box0.long", "sa_box1.long", "torch.cat", "torch.cat", "torch.sqrt", "torch.argmax", "torch.sum", "torch.min", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "_pad_with_fake_candidates", "(", "self", ",", "img_coords_pad0", ",", "img_coords_pad1", ",", "valid0", ",", "valid1", ",", "sa_box0", ",", "sa_box1", ",", "img_shape", ")", ":", "\n", "        ", "H", ",", "W", "=", "img_shape", "[", ":", "2", "]", "\n", "\n", "x0", ",", "y0", ",", "w0", ",", "h0", "=", "sa_box0", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "x1", ",", "y1", ",", "w1", ",", "h1", "=", "sa_box1", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "lowx", "=", "[", "max", "(", "0", ",", "x0", ")", ",", "max", "(", "0", ",", "x1", ")", "]", "\n", "lowy", "=", "[", "max", "(", "0", ",", "y0", ")", ",", "max", "(", "0", ",", "y1", ")", "]", "\n", "highx", "=", "[", "min", "(", "W", ",", "x0", "+", "w0", ")", ",", "min", "(", "W", ",", "x1", "+", "w1", ")", "]", "\n", "highy", "=", "[", "min", "(", "H", ",", "y0", "+", "h0", ")", ",", "min", "(", "H", ",", "y1", "+", "h1", ")", "]", "\n", "\n", "filled", "=", "[", "valid0", ".", "clone", "(", ")", ",", "valid1", ".", "clone", "(", ")", "]", "\n", "img_coords_pad", "=", "[", "img_coords_pad0", ".", "clone", "(", ")", ",", "img_coords_pad1", ".", "clone", "(", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "self", ".", "num_target_candidates", ")", ":", "\n", "            ", "for", "k", "in", "range", "(", "0", ",", "2", ")", ":", "\n", "                ", "if", "filled", "[", "k", "]", "[", "i", "]", "==", "0", ":", "\n", "                    ", "cs", "=", "torch", ".", "cat", "(", "[", "\n", "torch", ".", "rand", "(", "(", "20", ",", "1", ")", ")", "*", "(", "highy", "[", "k", "]", "-", "lowy", "[", "k", "]", ")", "+", "lowy", "[", "k", "]", ",", "\n", "torch", ".", "rand", "(", "(", "20", ",", "1", ")", ")", "*", "(", "highx", "[", "k", "]", "-", "lowx", "[", "k", "]", ")", "+", "lowx", "[", "k", "]", "\n", "]", ",", "dim", "=", "1", ")", "\n", "\n", "cs_used", "=", "torch", ".", "cat", "(", "[", "img_coords_pad", "[", "0", "]", "[", "filled", "[", "0", "]", "==", "1", "]", ",", "img_coords_pad", "[", "1", "]", "[", "filled", "[", "1", "]", "==", "1", "]", "]", ",", "dim", "=", "0", ")", "\n", "\n", "dist", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "cs_used", "[", ":", ",", "None", ",", ":", "]", "-", "cs", "[", "None", ",", ":", ",", ":", "]", ")", "**", "2", ",", "dim", "=", "2", ")", ")", "\n", "min_dist", "=", "torch", ".", "min", "(", "dist", ",", "dim", "=", "0", ")", ".", "values", "\n", "max_min_dist_idx", "=", "torch", ".", "argmax", "(", "min_dist", ")", "\n", "img_coords_pad", "[", "k", "]", "[", "i", "]", "=", "cs", "[", "max_min_dist_idx", "]", "\n", "filled", "[", "k", "]", "[", "i", "]", "=", "1", "\n", "\n", "", "", "", "return", "img_coords_pad", "[", "0", "]", ",", "img_coords_pad", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._add_fake_candidate_scores": [[1364, 1369], ["torch.zeros", "torch.abs", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs"], ["", "def", "_add_fake_candidate_scores", "(", "self", ",", "scores", ",", "valid", ")", ":", "\n", "        ", "scores_pad", "=", "torch", ".", "zeros", "(", "valid", ".", "shape", "[", "0", "]", ")", "\n", "scores_pad", "[", "valid", "==", "1", "]", "=", "scores", "[", ":", "self", ".", "num_target_candidates", "]", "[", "valid", "[", ":", "scores", ".", "shape", "[", "0", "]", "]", "==", "1", "]", "\n", "scores_pad", "[", "valid", "==", "0", "]", "=", "(", "torch", ".", "abs", "(", "torch", ".", "randn", "(", "(", "valid", "==", "0", ")", ".", "sum", "(", ")", ")", ")", "/", "50", ")", ".", "clamp_max", "(", "0.025", ")", "+", "0.05", "\n", "return", "scores_pad", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._augment_scores": [[1370, 1409], ["scores_aug.clamp_min.clamp_min.clamp_min", "scores_aug.clamp_min.clamp_min.clone", "torch.randn", "torch.all", "torch.randint", "torch.sort", "torch.sort", "torch.sort", "torch.arange", "torch.tensor", "torch.sort", "torch.abs", "torch.abs", "torch.sort", "torch.sort", "torch.abs", "torch.abs", "torch.sort"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs", "home.repos.pwc.inspect_result.visionml_pytracking.libs.complex.abs"], ["", "def", "_augment_scores", "(", "self", ",", "scores", ",", "valid", ",", "drop", ")", ":", "\n", "        ", "num_valid", "=", "(", "valid", "==", "1", ")", ".", "sum", "(", ")", "\n", "\n", "noise", "=", "0.1", "*", "torch", ".", "randn", "(", "num_valid", ")", "\n", "\n", "if", "num_valid", ">", "2", "and", "not", "drop", ":", "\n", "            ", "if", "scores", "[", "1", "]", ">", "0.5", "*", "scores", "[", "0", "]", "and", "torch", ".", "all", "(", "scores", "[", ":", "2", "]", ">", "0.2", ")", ":", "\n", "# two valid peaks with a high score that are relatively close.", "\n", "                ", "mode", "=", "torch", ".", "randint", "(", "0", ",", "3", ",", "size", "=", "(", "1", ",", ")", ")", "\n", "if", "mode", "==", "0", ":", "\n", "# augment randomly.", "\n", "                    ", "scores_aug", "=", "torch", ".", "sort", "(", "noise", "+", "scores", "[", "valid", "==", "1", "]", ",", "descending", "=", "True", ")", "[", "0", "]", "\n", "", "elif", "mode", "==", "1", ":", "\n", "# move peaks closer", "\n", "                    ", "scores_aug", "=", "torch", ".", "sort", "(", "noise", "+", "scores", "[", "valid", "==", "1", "]", ",", "descending", "=", "True", ")", "[", "0", "]", "\n", "scores_aug", "[", "0", "]", "=", "scores", "[", "valid", "==", "1", "]", "[", "0", "]", "-", "torch", ".", "abs", "(", "noise", "[", "0", "]", ")", "\n", "scores_aug", "[", "1", "]", "=", "scores", "[", "valid", "==", "1", "]", "[", "1", "]", "+", "torch", ".", "abs", "(", "noise", "[", "1", "]", ")", "\n", "scores_aug", "[", ":", "2", "]", "=", "torch", ".", "sort", "(", "scores_aug", "[", ":", "2", "]", ",", "descending", "=", "True", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "# move peaks closer and switch", "\n", "                    ", "scores_aug", "=", "torch", ".", "sort", "(", "noise", "+", "scores", "[", "valid", "==", "1", "]", ",", "descending", "=", "True", ")", "[", "0", "]", "\n", "scores_aug", "[", "0", "]", "=", "scores", "[", "valid", "==", "1", "]", "[", "0", "]", "-", "torch", ".", "abs", "(", "noise", "[", "0", "]", ")", "\n", "scores_aug", "[", "1", "]", "=", "scores", "[", "valid", "==", "1", "]", "[", "1", "]", "+", "torch", ".", "abs", "(", "noise", "[", "1", "]", ")", "\n", "scores_aug", "[", ":", "2", "]", "=", "torch", ".", "sort", "(", "scores_aug", "[", ":", "2", "]", ",", "descending", "=", "True", ")", "[", "0", "]", "\n", "\n", "idx", "=", "torch", ".", "arange", "(", "num_valid", ")", "\n", "idx", "[", ":", "2", "]", "=", "torch", ".", "tensor", "(", "[", "1", ",", "0", "]", ")", "\n", "scores_aug", "=", "scores_aug", "[", "idx", "]", "\n", "", "", "else", ":", "\n", "                ", "scores_aug", "=", "torch", ".", "sort", "(", "scores", "[", "valid", "==", "1", "]", "+", "noise", ",", "descending", "=", "True", ")", "[", "0", "]", "\n", "\n", "", "", "else", ":", "\n", "            ", "scores_aug", "=", "torch", ".", "sort", "(", "scores", "[", "valid", "==", "1", "]", "+", "noise", ",", "descending", "=", "True", ")", "[", "0", "]", "\n", "\n", "", "scores_aug", "=", "scores_aug", ".", "clamp_min", "(", "0.075", ")", "\n", "\n", "scores", "[", "valid", "==", "1", "]", "=", "scores_aug", ".", "clone", "(", ")", "\n", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.TargetCandiateMatchingProcessing._augment_coords": [[1410, 1436], ["search_area_box.float", "torch.sqrt", "torch.all", "coords[].clamp", "coords[].clamp", "torch.sum", "torch.min", "torch.rand", "torch.rand", "math.sqrt", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "_augment_coords", "(", "self", ",", "coords", ",", "img_shape", ",", "search_area_box", ")", ":", "\n", "        ", "H", ",", "W", "=", "img_shape", "[", ":", "2", "]", "\n", "\n", "_", ",", "_", ",", "w", ",", "h", "=", "search_area_box", ".", "float", "(", ")", "\n", "\n", "# add independent offset to each coord", "\n", "d", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "(", "coords", "[", "None", ",", ":", "]", "-", "coords", "[", ":", ",", "None", "]", ")", "**", "2", ",", "dim", "=", "2", ")", ")", "\n", "\n", "if", "torch", ".", "all", "(", "d", "==", "0", ")", ":", "\n", "            ", "xmin", "=", "0.5", "*", "w", "/", "self", ".", "score_map_sz", "[", "1", "]", "\n", "ymin", "=", "0.5", "*", "h", "/", "self", ".", "score_map_sz", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "dmin", "=", "torch", ".", "min", "(", "d", "[", "d", ">", "0", "]", ")", "\n", "xmin", "=", "(", "math", ".", "sqrt", "(", "2", ")", "*", "dmin", "/", "4", ")", ".", "clamp_max", "(", "w", "/", "self", ".", "score_map_sz", "[", "1", "]", ")", "\n", "ymin", "=", "(", "math", ".", "sqrt", "(", "2", ")", "*", "dmin", "/", "4", ")", ".", "clamp_max", "(", "h", "/", "self", ".", "score_map_sz", "[", "0", "]", ")", "\n", "\n", "", "txi", "=", "torch", ".", "rand", "(", "coords", ".", "shape", "[", "0", "]", ")", "*", "2", "*", "xmin", "-", "xmin", "\n", "tyi", "=", "torch", ".", "rand", "(", "coords", ".", "shape", "[", "0", "]", ")", "*", "2", "*", "ymin", "-", "ymin", "\n", "\n", "coords", "[", ":", ",", "0", "]", "+=", "tyi", "\n", "coords", "[", ":", ",", "1", "]", "+=", "txi", "\n", "\n", "coords", "[", ":", ",", "0", "]", "=", "coords", "[", ":", ",", "0", "]", ".", "clamp", "(", "0", ",", "H", ")", "\n", "coords", "[", ":", ",", "1", "]", "=", "coords", "[", ":", ",", "1", "]", ".", "clamp", "(", "0", ",", "W", ")", "\n", "\n", "return", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing.__init__": [[1442, 1475], ["processing.BaseProcessing.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "search_area_factor", ",", "output_sz", ",", "center_jitter_factor", ",", "scale_jitter_factor", ",", "crop_type", "=", "'replicate'", ",", "\n", "max_scale_change", "=", "None", ",", "mode", "=", "'pair'", ",", "stride", "=", "16", ",", "label_function_params", "=", "None", ",", "\n", "center_sampling_radius", "=", "0.0", ",", "use_normalized_coords", "=", "True", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            search_area_factor - The size of the search region  relative to the target size.\n            output_sz - An integer, denoting the size to which the search region is resized. The search region is always\n                        square.\n            center_jitter_factor - A dict containing the amount of jittering to be applied to the target center before\n                                    extracting the search region. See _get_jittered_box for how the jittering is done.\n            scale_jitter_factor - A dict containing the amount of jittering to be applied to the target size before\n                                    extracting the search region. See _get_jittered_box for how the jittering is done.\n            crop_type - If 'replicate', the boundary pixels are replicated in case the search region crop goes out of image.\n                        If 'inside', the search region crop is shifted/shrunk to fit completely inside the image.\n                        If 'inside_major', the search region crop is shifted/shrunk to fit completely inside one axis of the image.\n            max_scale_change - Maximum allowed scale change when performing the crop (only applicable for 'inside' and 'inside_major')\n            mode - Either 'pair' or 'sequence'. If mode='sequence', then output has an extra dimension for frames\n            proposal_params - Arguments for the proposal generation process. See _generate_proposals for details.\n            label_function_params - Arguments for the label generation process. See _generate_label_function for details.\n            label_density_params - Arguments for the label density generation process. See _generate_label_function for details.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "search_area_factor", "=", "search_area_factor", "\n", "self", ".", "output_sz", "=", "output_sz", "\n", "self", ".", "center_jitter_factor", "=", "center_jitter_factor", "\n", "self", ".", "scale_jitter_factor", "=", "scale_jitter_factor", "\n", "self", ".", "crop_type", "=", "crop_type", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "max_scale_change", "=", "max_scale_change", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "label_function_params", "=", "label_function_params", "\n", "self", ".", "center_sampling_radius", "=", "center_sampling_radius", "\n", "self", ".", "use_normalized_coords", "=", "use_normalized_coords", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._get_jittered_box": [[1476, 1491], ["torch.cat", "torch.exp", "jittered_size.prod().sqrt", "torch.tensor().float", "torch.randn", "jittered_size.prod", "torch.tensor", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "_get_jittered_box", "(", "self", ",", "box", ",", "mode", ")", ":", "\n", "        ", "\"\"\" Jitter the input box\n        args:\n            box - input bounding box\n            mode - string 'train' or 'test' indicating train or test data\n\n        returns:\n            torch.Tensor - jittered box\n        \"\"\"", "\n", "\n", "jittered_size", "=", "box", "[", "2", ":", "4", "]", "*", "torch", ".", "exp", "(", "torch", ".", "randn", "(", "2", ")", "*", "self", ".", "scale_jitter_factor", "[", "mode", "]", ")", "\n", "max_offset", "=", "(", "jittered_size", ".", "prod", "(", ")", ".", "sqrt", "(", ")", "*", "torch", ".", "tensor", "(", "self", ".", "center_jitter_factor", "[", "mode", "]", ")", ".", "float", "(", ")", ")", "\n", "jittered_center", "=", "box", "[", "0", ":", "2", "]", "+", "0.5", "*", "box", "[", "2", ":", "4", "]", "+", "max_offset", "*", "(", "torch", ".", "rand", "(", "2", ")", "-", "0.5", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "jittered_center", "-", "0.5", "*", "jittered_size", ",", "jittered_size", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._generate_label_function": [[1492, 1509], ["ltr.gaussian_label_function", "target_bb.view", "processing.LTRBDenseRegressionProcessing.label_function_params.get"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gaussian_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get"], ["", "def", "_generate_label_function", "(", "self", ",", "target_bb", ")", ":", "\n", "        ", "\"\"\" Generates the gaussian label function centered at target_bb\n        args:\n            target_bb - target bounding box (num_images, 4)\n\n        returns:\n            torch.Tensor - Tensor of shape (num_images, label_sz, label_sz) containing the label for each sample\n        \"\"\"", "\n", "\n", "gauss_label", "=", "prutils", ".", "gaussian_label_function", "(", "target_bb", ".", "view", "(", "-", "1", ",", "4", ")", ",", "\n", "self", ".", "label_function_params", "[", "'sigma_factor'", "]", ",", "\n", "self", ".", "label_function_params", "[", "'kernel_sz'", "]", ",", "\n", "self", ".", "label_function_params", "[", "'feature_sz'", "]", ",", "self", ".", "output_sz", ",", "\n", "end_pad_if_even", "=", "self", ".", "label_function_params", ".", "get", "(", "\n", "'end_pad_if_even'", ",", "True", ")", ")", "\n", "\n", "return", "gauss_label", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._generate_ltbr_regression_targets": [[1510, 1548], ["torch.arange", "torch.arange", "torch.meshgrid", "shift_x.reshape.reshape.reshape", "shift_y.reshape.reshape.reshape", "torch.stack", "torch.stack().reshape", "reg_targets_per_im.reshape().permute.reshape().permute.reshape().permute", "processing.LTRBDenseRegressionProcessing.reshape().permute", "torch.stack", "processing.LTRBDenseRegressionProcessing._compute_sampling_region", "torch.stack", "reg_targets_per_im.reshape().permute.reshape().permute.reshape", "processing.LTRBDenseRegressionProcessing.reshape", "reg_targets_per_im.reshape().permute.reshape().permute.min"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._compute_sampling_region"], ["", "def", "_generate_ltbr_regression_targets", "(", "self", ",", "target_bb", ")", ":", "\n", "        ", "shifts_x", "=", "torch", ".", "arange", "(", "\n", "0", ",", "self", ".", "output_sz", ",", "step", "=", "self", ".", "stride", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "target_bb", ".", "device", "\n", ")", "\n", "shifts_y", "=", "torch", ".", "arange", "(", "\n", "0", ",", "self", ".", "output_sz", ",", "step", "=", "self", ".", "stride", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "target_bb", ".", "device", "\n", ")", "\n", "shift_y", ",", "shift_x", "=", "torch", ".", "meshgrid", "(", "shifts_y", ",", "shifts_x", ")", "\n", "shift_x", "=", "shift_x", ".", "reshape", "(", "-", "1", ")", "\n", "shift_y", "=", "shift_y", ".", "reshape", "(", "-", "1", ")", "\n", "locations", "=", "torch", ".", "stack", "(", "(", "shift_x", ",", "shift_y", ")", ",", "dim", "=", "1", ")", "+", "self", ".", "stride", "//", "2", "\n", "xs", ",", "ys", "=", "locations", "[", ":", ",", "0", "]", ",", "locations", "[", ":", ",", "1", "]", "\n", "\n", "xyxy", "=", "torch", ".", "stack", "(", "[", "target_bb", "[", ":", ",", "0", "]", ",", "target_bb", "[", ":", ",", "1", "]", ",", "target_bb", "[", ":", ",", "0", "]", "+", "target_bb", "[", ":", ",", "2", "]", ",", "\n", "target_bb", "[", ":", ",", "1", "]", "+", "target_bb", "[", ":", ",", "3", "]", "]", ",", "dim", "=", "1", ")", "\n", "\n", "l", "=", "xs", "[", ":", ",", "None", "]", "-", "xyxy", "[", ":", ",", "0", "]", "[", "None", "]", "\n", "t", "=", "ys", "[", ":", ",", "None", "]", "-", "xyxy", "[", ":", ",", "1", "]", "[", "None", "]", "\n", "r", "=", "xyxy", "[", ":", ",", "2", "]", "[", "None", "]", "-", "xs", "[", ":", ",", "None", "]", "\n", "b", "=", "xyxy", "[", ":", ",", "3", "]", "[", "None", "]", "-", "ys", "[", ":", ",", "None", "]", "\n", "reg_targets_per_im", "=", "torch", ".", "stack", "(", "[", "l", ",", "t", ",", "r", ",", "b", "]", ",", "dim", "=", "2", ")", ".", "reshape", "(", "-", "1", ",", "4", ")", "\n", "\n", "if", "self", ".", "use_normalized_coords", ":", "\n", "            ", "reg_targets_per_im", "=", "reg_targets_per_im", "/", "self", ".", "output_sz", "\n", "\n", "", "if", "self", ".", "center_sampling_radius", ">", "0", ":", "\n", "            ", "is_in_box", "=", "self", ".", "_compute_sampling_region", "(", "xs", ",", "xyxy", ",", "ys", ")", "\n", "", "else", ":", "\n", "            ", "is_in_box", "=", "(", "reg_targets_per_im", ".", "min", "(", "dim", "=", "1", ")", "[", "0", "]", ">", "0", ")", "\n", "\n", "", "sz", "=", "self", ".", "output_sz", "//", "self", ".", "stride", "\n", "nb", "=", "target_bb", ".", "shape", "[", "0", "]", "\n", "reg_targets_per_im", "=", "reg_targets_per_im", ".", "reshape", "(", "sz", ",", "sz", ",", "nb", ",", "4", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", "\n", "is_in_box", "=", "is_in_box", ".", "reshape", "(", "sz", ",", "sz", ",", "nb", ",", "1", ")", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", "\n", "\n", "return", "reg_targets_per_im", ",", "is_in_box", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._compute_sampling_region": [[1549, 1568], ["xyxy.new_zeros", "torch.where", "torch.where", "torch.where", "torch.where", "torch.stack", "torch.stack.min"], "methods", ["None"], ["", "def", "_compute_sampling_region", "(", "self", ",", "xs", ",", "xyxy", ",", "ys", ")", ":", "\n", "        ", "cx", "=", "(", "xyxy", "[", ":", ",", "0", "]", "+", "xyxy", "[", ":", ",", "2", "]", ")", "/", "2", "\n", "cy", "=", "(", "xyxy", "[", ":", ",", "1", "]", "+", "xyxy", "[", ":", ",", "3", "]", ")", "/", "2", "\n", "xmin", "=", "cx", "-", "self", ".", "center_sampling_radius", "*", "self", ".", "stride", "\n", "ymin", "=", "cy", "-", "self", ".", "center_sampling_radius", "*", "self", ".", "stride", "\n", "xmax", "=", "cx", "+", "self", ".", "center_sampling_radius", "*", "self", ".", "stride", "\n", "ymax", "=", "cy", "+", "self", ".", "center_sampling_radius", "*", "self", ".", "stride", "\n", "center_gt", "=", "xyxy", ".", "new_zeros", "(", "xyxy", ".", "shape", ")", "\n", "center_gt", "[", ":", ",", "0", "]", "=", "torch", ".", "where", "(", "xmin", ">", "xyxy", "[", ":", ",", "0", "]", ",", "xmin", ",", "xyxy", "[", ":", ",", "0", "]", ")", "\n", "center_gt", "[", ":", ",", "1", "]", "=", "torch", ".", "where", "(", "ymin", ">", "xyxy", "[", ":", ",", "1", "]", ",", "ymin", ",", "xyxy", "[", ":", ",", "1", "]", ")", "\n", "center_gt", "[", ":", ",", "2", "]", "=", "torch", ".", "where", "(", "xmax", ">", "xyxy", "[", ":", ",", "2", "]", ",", "xyxy", "[", ":", ",", "2", "]", ",", "xmax", ")", "\n", "center_gt", "[", ":", ",", "3", "]", "=", "torch", ".", "where", "(", "ymax", ">", "xyxy", "[", ":", ",", "3", "]", ",", "xyxy", "[", ":", ",", "3", "]", ",", "ymax", ")", "\n", "left", "=", "xs", "[", ":", ",", "None", "]", "-", "center_gt", "[", ":", ",", "0", "]", "\n", "right", "=", "center_gt", "[", ":", ",", "2", "]", "-", "xs", "[", ":", ",", "None", "]", "\n", "top", "=", "ys", "[", ":", ",", "None", "]", "-", "center_gt", "[", ":", ",", "1", "]", "\n", "bottom", "=", "center_gt", "[", ":", ",", "3", "]", "-", "ys", "[", ":", ",", "None", "]", "\n", "center_bbox", "=", "torch", ".", "stack", "(", "(", "left", ",", "top", ",", "right", ",", "bottom", ")", ",", "-", "1", ")", "\n", "is_in_box", "=", "center_bbox", ".", "min", "(", "-", "1", ")", "[", "0", "]", ">", "0", "\n", "return", "is_in_box", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing.__call__": [[1569, 1614], ["processing.LTRBDenseRegressionProcessing._generate_ltbr_regression_targets", "processing.LTRBDenseRegressionProcessing._generate_ltbr_regression_targets", "ltr.target_image_crop", "data.apply.apply.apply", "data.apply.apply.apply", "processing.LTRBDenseRegressionProcessing._generate_label_function", "processing.LTRBDenseRegressionProcessing._generate_label_function", "processing.LTRBDenseRegressionProcessing._get_jittered_box", "len", "isinstance"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._generate_ltbr_regression_targets", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._generate_ltbr_regression_targets", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.target_image_crop", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.apply", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._generate_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._generate_label_function", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.LTRBDenseRegressionProcessing._get_jittered_box"], ["", "def", "__call__", "(", "self", ",", "data", ":", "TensorDict", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            data - The input data, should contain the following fields:\n                'train_images', test_images', 'train_anno', 'test_anno'\n        returns:\n            TensorDict - output data block with following fields:\n                'train_images', 'test_images', 'train_anno', 'test_anno', 'test_proposals', 'proposal_density', 'gt_density',\n                'test_label' (optional), 'train_label' (optional), 'test_label_density' (optional), 'train_label_density' (optional)\n        \"\"\"", "\n", "\n", "if", "self", ".", "transform", "[", "'joint'", "]", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_images'", "]", ",", "data", "[", "'train_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'train_images'", "]", ",", "\n", "bbox", "=", "data", "[", "'train_anno'", "]", ")", "\n", "data", "[", "'test_images'", "]", ",", "data", "[", "'test_anno'", "]", "=", "self", ".", "transform", "[", "'joint'", "]", "(", "image", "=", "data", "[", "'test_images'", "]", ",", "\n", "bbox", "=", "data", "[", "'test_anno'", "]", ",", "new_roll", "=", "False", ")", "\n", "\n", "", "for", "s", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "assert", "self", ".", "mode", "==", "'sequence'", "or", "len", "(", "data", "[", "s", "+", "'_images'", "]", ")", "==", "1", ",", "\"In pair mode, num train/test frames must be 1\"", "\n", "\n", "# Add a uniform noise to the center pos", "\n", "jittered_anno", "=", "[", "self", ".", "_get_jittered_box", "(", "a", ",", "s", ")", "for", "a", "in", "data", "[", "s", "+", "'_anno'", "]", "]", "\n", "\n", "crops", ",", "boxes", "=", "prutils", ".", "target_image_crop", "(", "data", "[", "s", "+", "'_images'", "]", ",", "jittered_anno", ",", "data", "[", "s", "+", "'_anno'", "]", ",", "\n", "self", ".", "search_area_factor", ",", "self", ".", "output_sz", ",", "mode", "=", "self", ".", "crop_type", ",", "\n", "max_scale_change", "=", "self", ".", "max_scale_change", ")", "\n", "\n", "data", "[", "s", "+", "'_images'", "]", ",", "data", "[", "s", "+", "'_anno'", "]", "=", "self", ".", "transform", "[", "s", "]", "(", "image", "=", "crops", ",", "bbox", "=", "boxes", ",", "joint", "=", "False", ")", "\n", "\n", "# Prepare output", "\n", "", "if", "self", ".", "mode", "==", "'sequence'", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "stack_tensors", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "data", ".", "apply", "(", "lambda", "x", ":", "x", "[", "0", "]", "if", "isinstance", "(", "x", ",", "list", ")", "else", "x", ")", "\n", "\n", "# Generate label functions", "\n", "", "if", "self", ".", "label_function_params", "is", "not", "None", ":", "\n", "            ", "data", "[", "'train_label'", "]", "=", "self", ".", "_generate_label_function", "(", "data", "[", "'train_anno'", "]", ")", "\n", "data", "[", "'test_label'", "]", "=", "self", ".", "_generate_label_function", "(", "data", "[", "'test_anno'", "]", ")", "\n", "\n", "", "data", "[", "'test_ltrb_target'", "]", ",", "data", "[", "'test_sample_region'", "]", "=", "self", ".", "_generate_ltbr_regression_targets", "(", "data", "[", "'test_anno'", "]", ")", "\n", "data", "[", "'train_ltrb_target'", "]", ",", "data", "[", "'train_sample_region'", "]", "=", "self", ".", "_generate_ltbr_regression_targets", "(", "data", "[", "'train_anno'", "]", ")", "\n", "\n", "return", "data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing.stack_tensors": [[9, 13], ["isinstance", "isinstance", "torch.stack"], "function", ["None"], ["def", "stack_tensors", "(", "x", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "(", "list", ",", "tuple", ")", ")", "and", "isinstance", "(", "x", "[", "0", "]", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "torch", ".", "stack", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.default_image_loader": [[15, 30], ["image_loader.opencv_loader", "image_loader.jpeg4py_loader", "image_loader.jpeg4py_loader", "print"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.opencv_loader", "home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.jpeg4py_loader", "home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.jpeg4py_loader"], ["def", "default_image_loader", "(", "path", ")", ":", "\n", "    ", "\"\"\"The default image loader, reads the image from the given path. It first tries to use the jpeg4py_loader,\n    but reverts to the opencv_loader if the former is not available.\"\"\"", "\n", "if", "default_image_loader", ".", "use_jpeg4py", "is", "None", ":", "\n", "# Try using jpeg4py", "\n", "        ", "im", "=", "jpeg4py_loader", "(", "path", ")", "\n", "if", "im", "is", "None", ":", "\n", "            ", "default_image_loader", ".", "use_jpeg4py", "=", "False", "\n", "print", "(", "'Using opencv_loader instead.'", ")", "\n", "", "else", ":", "\n", "            ", "default_image_loader", ".", "use_jpeg4py", "=", "True", "\n", "return", "im", "\n", "", "", "if", "default_image_loader", ".", "use_jpeg4py", ":", "\n", "        ", "return", "jpeg4py_loader", "(", "path", ")", "\n", "", "return", "opencv_loader", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.jpeg4py_loader": [[34, 42], ["jpeg4py.JPEG().decode", "print", "print", "jpeg4py.JPEG"], "function", ["None"], ["def", "jpeg4py_loader", "(", "path", ")", ":", "\n", "    ", "\"\"\" Image reading using jpeg4py https://github.com/ajkxyz/jpeg4py\"\"\"", "\n", "try", ":", "\n", "        ", "return", "jpeg4py", ".", "JPEG", "(", "path", ")", ".", "decode", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "'ERROR: Could not read image \"{}\"'", ".", "format", "(", "path", ")", ")", "\n", "print", "(", "e", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.opencv_loader": [[44, 55], ["cv2.imread", "cv2.cvtColor", "print", "print"], "function", ["None"], ["", "", "def", "opencv_loader", "(", "path", ")", ":", "\n", "    ", "\"\"\" Read image using opencv's imread function and returns it in rgb format\"\"\"", "\n", "try", ":", "\n", "        ", "im", "=", "cv", ".", "imread", "(", "path", ",", "cv", ".", "IMREAD_COLOR", ")", "\n", "\n", "# convert to rgb and return", "\n", "return", "cv", ".", "cvtColor", "(", "im", ",", "cv", ".", "COLOR_BGR2RGB", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "'ERROR: Could not read image \"{}\"'", ".", "format", "(", "path", ")", ")", "\n", "print", "(", "e", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.jpeg4py_loader_w_failsafe": [[57, 71], ["jpeg4py.JPEG().decode", "jpeg4py.JPEG", "cv2.imread", "cv2.cvtColor", "print", "print"], "function", ["None"], ["", "", "def", "jpeg4py_loader_w_failsafe", "(", "path", ")", ":", "\n", "    ", "\"\"\" Image reading using jpeg4py https://github.com/ajkxyz/jpeg4py\"\"\"", "\n", "try", ":", "\n", "        ", "return", "jpeg4py", ".", "JPEG", "(", "path", ")", ".", "decode", "(", ")", "\n", "", "except", ":", "\n", "        ", "try", ":", "\n", "            ", "im", "=", "cv", ".", "imread", "(", "path", ",", "cv", ".", "IMREAD_COLOR", ")", "\n", "\n", "# convert to rgb and return", "\n", "return", "cv", ".", "cvtColor", "(", "im", ",", "cv", ".", "COLOR_BGR2RGB", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'ERROR: Could not read image \"{}\"'", ".", "format", "(", "path", ")", ")", "\n", "print", "(", "e", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.opencv_seg_loader": [[73, 81], ["cv2.imread", "print", "print"], "function", ["None"], ["", "", "", "def", "opencv_seg_loader", "(", "path", ")", ":", "\n", "    ", "\"\"\" Read segmentation annotation using opencv's imread function\"\"\"", "\n", "try", ":", "\n", "        ", "return", "cv", ".", "imread", "(", "path", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "'ERROR: Could not read image \"{}\"'", ".", "format", "(", "path", ")", ")", "\n", "print", "(", "e", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.imread_indexed": [[83, 90], ["PIL.Image.open", "numpy.atleast_3d"], "function", ["None"], ["", "", "def", "imread_indexed", "(", "filename", ")", ":", "\n", "    ", "\"\"\" Load indexed image with given filename. Used to read segmentation annotations.\"\"\"", "\n", "\n", "im", "=", "Image", ".", "open", "(", "filename", ")", "\n", "\n", "annotation", "=", "np", ".", "atleast_3d", "(", "im", ")", "[", "...", ",", "0", "]", "\n", "return", "annotation", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.image_loader.imwrite_indexed": [[92, 104], ["PIL.Image.fromarray", "Image.fromarray.putpalette", "Image.fromarray.save", "Exception", "color_palette.ravel", "numpy.atleast_3d"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.vos_base.VOSMeta.save"], ["", "def", "imwrite_indexed", "(", "filename", ",", "array", ",", "color_palette", "=", "None", ")", ":", "\n", "    ", "\"\"\" Save indexed image as png. Used to save segmentation annotation.\"\"\"", "\n", "\n", "if", "color_palette", "is", "None", ":", "\n", "        ", "color_palette", "=", "davis_palette", "\n", "\n", "", "if", "np", ".", "atleast_3d", "(", "array", ")", ".", "shape", "[", "2", "]", "!=", "1", ":", "\n", "        ", "raise", "Exception", "(", "\"Saving indexed PNGs requires 2D array.\"", ")", "\n", "\n", "", "im", "=", "Image", ".", "fromarray", "(", "array", ")", "\n", "im", ".", "putpalette", "(", "color_palette", ".", "ravel", "(", ")", ")", "\n", "im", ".", "save", "(", "filename", ",", "format", "=", "'PNG'", ")", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.TrackingSampler.__init__": [[25, 55], ["sum", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "datasets", ",", "p_datasets", ",", "samples_per_epoch", ",", "max_gap", ",", "\n", "num_test_frames", ",", "num_train_frames", "=", "1", ",", "processing", "=", "no_processing", ",", "frame_sample_mode", "=", "'causal'", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            datasets - List of datasets to be used for training\n            p_datasets - List containing the probabilities by which each dataset will be sampled\n            samples_per_epoch - Number of training samples per epoch\n            max_gap - Maximum gap, in frame numbers, between the train frames and the test frames.\n            num_test_frames - Number of test frames to sample.\n            num_train_frames - Number of train frames to sample.\n            processing - An instance of Processing class which performs the necessary processing of the data.\n            frame_sample_mode - Either 'causal' or 'interval'. If 'causal', then the test frames are sampled in a causally,\n                                otherwise randomly within the interval.\n        \"\"\"", "\n", "self", ".", "datasets", "=", "datasets", "\n", "\n", "# If p not provided, sample uniformly from all videos", "\n", "if", "p_datasets", "is", "None", ":", "\n", "            ", "p_datasets", "=", "[", "len", "(", "d", ")", "for", "d", "in", "self", ".", "datasets", "]", "\n", "\n", "# Normalize", "\n", "", "p_total", "=", "sum", "(", "p_datasets", ")", "\n", "self", ".", "p_datasets", "=", "[", "x", "/", "p_total", "for", "x", "in", "p_datasets", "]", "\n", "\n", "self", ".", "samples_per_epoch", "=", "samples_per_epoch", "\n", "self", ".", "max_gap", "=", "max_gap", "\n", "self", ".", "num_test_frames", "=", "num_test_frames", "\n", "self", ".", "num_train_frames", "=", "num_train_frames", "\n", "self", ".", "processing", "=", "processing", "\n", "self", ".", "frame_sample_mode", "=", "frame_sample_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.TrackingSampler.__len__": [[56, 58], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "samples_per_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.TrackingSampler._sample_visible_ids": [[59, 85], ["random.choices", "len", "len", "len", "range"], "methods", ["None"], ["", "def", "_sample_visible_ids", "(", "self", ",", "visible", ",", "num_ids", "=", "1", ",", "min_id", "=", "None", ",", "max_id", "=", "None", ")", ":", "\n", "        ", "\"\"\" Samples num_ids frames between min_id and max_id for which target is visible\n\n        args:\n            visible - 1d Tensor indicating whether target is visible for each frame\n            num_ids - number of frames to be samples\n            min_id - Minimum allowed frame number\n            max_id - Maximum allowed frame number\n\n        returns:\n            list - List of sampled frame numbers. None if not sufficient visible frames could be found.\n        \"\"\"", "\n", "if", "num_ids", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "if", "min_id", "is", "None", "or", "min_id", "<", "0", ":", "\n", "            ", "min_id", "=", "0", "\n", "", "if", "max_id", "is", "None", "or", "max_id", ">", "len", "(", "visible", ")", ":", "\n", "            ", "max_id", "=", "len", "(", "visible", ")", "\n", "\n", "", "valid_ids", "=", "[", "i", "for", "i", "in", "range", "(", "min_id", ",", "max_id", ")", "if", "visible", "[", "i", "]", "]", "\n", "\n", "# No visible ids", "\n", "if", "len", "(", "valid_ids", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "return", "random", ".", "choices", "(", "valid_ids", ",", "k", "=", "num_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.TrackingSampler.__getitem__": [[86, 170], ["dataset.is_video_sequence", "dataset.get_frames", "dataset.get_frames", "pytracking.TensorDict", "sampler.TrackingSampler.processing", "random.choices", "random.randint", "dataset.get_sequence_info", "dataset.get_name", "meta_obj_test.get", "dataset.get_num_sequences", "visible.type().sum().item", "len", "sampler.TrackingSampler._sample_visible_ids", "sampler.TrackingSampler._sample_visible_ids", "sampler.TrackingSampler._sample_visible_ids", "sampler.TrackingSampler._sample_visible_ids", "sampler.TrackingSampler._sample_visible_ids", "sampler.TrackingSampler._sample_visible_ids", "visible.type().sum", "visible.type", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.is_video_sequence", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_frames", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_frames", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_name", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_num_sequences", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            index (int): Index (Ignored since we sample randomly)\n\n        returns:\n            TensorDict - dict containing all the data blocks\n        \"\"\"", "\n", "\n", "# Select a dataset", "\n", "dataset", "=", "random", ".", "choices", "(", "self", ".", "datasets", ",", "self", ".", "p_datasets", ")", "[", "0", "]", "\n", "is_video_dataset", "=", "dataset", ".", "is_video_sequence", "(", ")", "\n", "\n", "# Sample a sequence with enough visible frames", "\n", "enough_visible_frames", "=", "False", "\n", "while", "not", "enough_visible_frames", ":", "\n", "# Sample a sequence", "\n", "            ", "seq_id", "=", "random", ".", "randint", "(", "0", ",", "dataset", ".", "get_num_sequences", "(", ")", "-", "1", ")", "\n", "\n", "# Sample frames", "\n", "seq_info_dict", "=", "dataset", ".", "get_sequence_info", "(", "seq_id", ")", "\n", "visible", "=", "seq_info_dict", "[", "'visible'", "]", "\n", "\n", "enough_visible_frames", "=", "visible", ".", "type", "(", "torch", ".", "int64", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ">", "2", "*", "(", "\n", "self", ".", "num_test_frames", "+", "self", ".", "num_train_frames", ")", "and", "len", "(", "visible", ")", ">=", "20", "\n", "\n", "enough_visible_frames", "=", "enough_visible_frames", "or", "not", "is_video_dataset", "\n", "\n", "", "if", "is_video_dataset", ":", "\n", "            ", "train_frame_ids", "=", "None", "\n", "test_frame_ids", "=", "None", "\n", "gap_increase", "=", "0", "\n", "\n", "if", "self", ".", "frame_sample_mode", "==", "'interval'", ":", "\n", "# Sample frame numbers within interval defined by the first frame", "\n", "                ", "while", "test_frame_ids", "is", "None", ":", "\n", "                    ", "base_frame_id", "=", "self", ".", "_sample_visible_ids", "(", "visible", ",", "num_ids", "=", "1", ")", "\n", "extra_train_frame_ids", "=", "self", ".", "_sample_visible_ids", "(", "visible", ",", "num_ids", "=", "self", ".", "num_train_frames", "-", "1", ",", "\n", "min_id", "=", "base_frame_id", "[", "\n", "0", "]", "-", "self", ".", "max_gap", "-", "gap_increase", ",", "\n", "max_id", "=", "base_frame_id", "[", "\n", "0", "]", "+", "self", ".", "max_gap", "+", "gap_increase", ")", "\n", "if", "extra_train_frame_ids", "is", "None", ":", "\n", "                        ", "gap_increase", "+=", "5", "\n", "continue", "\n", "", "train_frame_ids", "=", "base_frame_id", "+", "extra_train_frame_ids", "\n", "test_frame_ids", "=", "self", ".", "_sample_visible_ids", "(", "visible", ",", "num_ids", "=", "self", ".", "num_test_frames", ",", "\n", "min_id", "=", "train_frame_ids", "[", "0", "]", "-", "self", ".", "max_gap", "-", "gap_increase", ",", "\n", "max_id", "=", "train_frame_ids", "[", "0", "]", "+", "self", ".", "max_gap", "+", "gap_increase", ")", "\n", "gap_increase", "+=", "5", "# Increase gap until a frame is found", "\n", "\n", "", "", "elif", "self", ".", "frame_sample_mode", "==", "'causal'", ":", "\n", "# Sample test and train frames in a causal manner, i.e. test_frame_ids > train_frame_ids", "\n", "                ", "while", "test_frame_ids", "is", "None", ":", "\n", "                    ", "base_frame_id", "=", "self", ".", "_sample_visible_ids", "(", "visible", ",", "num_ids", "=", "1", ",", "min_id", "=", "self", ".", "num_train_frames", "-", "1", ",", "\n", "max_id", "=", "len", "(", "visible", ")", "-", "self", ".", "num_test_frames", ")", "\n", "prev_frame_ids", "=", "self", ".", "_sample_visible_ids", "(", "visible", ",", "num_ids", "=", "self", ".", "num_train_frames", "-", "1", ",", "\n", "min_id", "=", "base_frame_id", "[", "0", "]", "-", "self", ".", "max_gap", "-", "gap_increase", ",", "\n", "max_id", "=", "base_frame_id", "[", "0", "]", ")", "\n", "if", "prev_frame_ids", "is", "None", ":", "\n", "                        ", "gap_increase", "+=", "5", "\n", "continue", "\n", "", "train_frame_ids", "=", "base_frame_id", "+", "prev_frame_ids", "\n", "test_frame_ids", "=", "self", ".", "_sample_visible_ids", "(", "visible", ",", "min_id", "=", "train_frame_ids", "[", "0", "]", "+", "1", ",", "\n", "max_id", "=", "train_frame_ids", "[", "0", "]", "+", "self", ".", "max_gap", "+", "gap_increase", ",", "\n", "num_ids", "=", "self", ".", "num_test_frames", ")", "\n", "# Increase gap until a frame is found", "\n", "gap_increase", "+=", "5", "\n", "", "", "", "else", ":", "\n", "# In case of image dataset, just repeat the image to generate synthetic video", "\n", "            ", "train_frame_ids", "=", "[", "1", "]", "*", "self", ".", "num_train_frames", "\n", "test_frame_ids", "=", "[", "1", "]", "*", "self", ".", "num_test_frames", "\n", "\n", "", "train_frames", ",", "train_anno", ",", "meta_obj_train", "=", "dataset", ".", "get_frames", "(", "seq_id", ",", "train_frame_ids", ",", "seq_info_dict", ")", "\n", "test_frames", ",", "test_anno", ",", "meta_obj_test", "=", "dataset", ".", "get_frames", "(", "seq_id", ",", "test_frame_ids", ",", "seq_info_dict", ")", "\n", "\n", "data", "=", "TensorDict", "(", "{", "'train_images'", ":", "train_frames", ",", "\n", "'train_anno'", ":", "train_anno", "[", "'bbox'", "]", ",", "\n", "'test_images'", ":", "test_frames", ",", "\n", "'test_anno'", ":", "test_anno", "[", "'bbox'", "]", ",", "\n", "'dataset'", ":", "dataset", ".", "get_name", "(", ")", ",", "\n", "'test_class'", ":", "meta_obj_test", ".", "get", "(", "'object_class_name'", ")", "}", ")", "\n", "\n", "return", "self", ".", "processing", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.DiMPSampler.__init__": [[175, 180], ["sampler.TrackingSampler.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "datasets", ",", "p_datasets", ",", "samples_per_epoch", ",", "max_gap", ",", "\n", "num_test_frames", ",", "num_train_frames", "=", "1", ",", "processing", "=", "no_processing", ",", "frame_sample_mode", "=", "'causal'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "datasets", "=", "datasets", ",", "p_datasets", "=", "p_datasets", ",", "samples_per_epoch", "=", "samples_per_epoch", ",", "max_gap", "=", "max_gap", ",", "\n", "num_test_frames", "=", "num_test_frames", ",", "num_train_frames", "=", "num_train_frames", ",", "processing", "=", "processing", ",", "\n", "frame_sample_mode", "=", "frame_sample_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.ATOMSampler.__init__": [[185, 190], ["sampler.TrackingSampler.__init__"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "datasets", ",", "p_datasets", ",", "samples_per_epoch", ",", "max_gap", ",", "\n", "num_test_frames", "=", "1", ",", "num_train_frames", "=", "1", ",", "processing", "=", "no_processing", ",", "frame_sample_mode", "=", "'interval'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "datasets", "=", "datasets", ",", "p_datasets", "=", "p_datasets", ",", "samples_per_epoch", "=", "samples_per_epoch", ",", "max_gap", "=", "max_gap", ",", "\n", "num_test_frames", "=", "num_test_frames", ",", "num_train_frames", "=", "num_train_frames", ",", "processing", "=", "processing", ",", "\n", "frame_sample_mode", "=", "frame_sample_mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler.__init__": [[209, 239], ["sum", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "datasets", ",", "p_datasets", ",", "samples_per_epoch", ",", "max_gap", ",", "\n", "num_test_frames", ",", "num_train_frames", "=", "1", ",", "processing", "=", "no_processing", ",", "p_reverse", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            datasets - List of datasets to be used for training\n            p_datasets - List containing the probabilities by which each dataset will be sampled\n            samples_per_epoch - Number of training samples per epoch\n            max_gap - Maximum gap, in frame numbers, between the train frames and the test frames.\n            num_test_frames - Number of test frames to sample.\n            num_train_frames - Number of train frames to sample.\n            processing - An instance of Processing class which performs the necessary processing of the data.\n            p_reverse - Probability that a sequence is temporally reversed\n        \"\"\"", "\n", "self", ".", "datasets", "=", "datasets", "\n", "\n", "# If p not provided, sample uniformly from all videos", "\n", "if", "p_datasets", "is", "None", ":", "\n", "            ", "p_datasets", "=", "[", "len", "(", "d", ")", "for", "d", "in", "self", ".", "datasets", "]", "\n", "\n", "# Normalize", "\n", "", "p_total", "=", "sum", "(", "p_datasets", ")", "\n", "self", ".", "p_datasets", "=", "[", "x", "/", "p_total", "for", "x", "in", "p_datasets", "]", "\n", "\n", "self", ".", "samples_per_epoch", "=", "samples_per_epoch", "\n", "self", ".", "max_gap", "=", "max_gap", "\n", "self", ".", "num_test_frames", "=", "num_test_frames", "\n", "self", ".", "num_train_frames", "=", "num_train_frames", "\n", "self", ".", "processing", "=", "processing", "\n", "\n", "self", ".", "p_reverse", "=", "p_reverse", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler.__len__": [[240, 242], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "samples_per_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids": [[243, 267], ["random.choices", "len", "len", "len", "range"], "methods", ["None"], ["", "def", "_sample_visible_ids", "(", "self", ",", "visible", ",", "num_ids", "=", "1", ",", "min_id", "=", "None", ",", "max_id", "=", "None", ")", ":", "\n", "        ", "\"\"\" Samples num_ids frames between min_id and max_id for which target is visible\n\n        args:\n            visible - 1d Tensor indicating whether target is visible for each frame\n            num_ids - number of frames to be samples\n            min_id - Minimum allowed frame number\n            max_id - Maximum allowed frame number\n\n        returns:\n            list - List of sampled frame numbers. None if not sufficient visible frames could be found.\n        \"\"\"", "\n", "if", "min_id", "is", "None", "or", "min_id", "<", "0", ":", "\n", "            ", "min_id", "=", "0", "\n", "", "if", "max_id", "is", "None", "or", "max_id", ">", "len", "(", "visible", ")", ":", "\n", "            ", "max_id", "=", "len", "(", "visible", ")", "\n", "\n", "", "valid_ids", "=", "[", "i", "for", "i", "in", "range", "(", "min_id", ",", "max_id", ")", "if", "visible", "[", "i", "]", "]", "\n", "\n", "# No visible ids", "\n", "if", "len", "(", "valid_ids", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "return", "random", ".", "choices", "(", "valid_ids", ",", "k", "=", "num_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler.__getitem__": [[268, 378], ["dataset.is_video_sequence", "sorted", "sorted", "dataset.get_frames", "all_anno.items", "pytracking.TensorDict", "sampler.LWLSampler.processing", "random.choices", "random.randint", "dataset.get_sequence_info", "random.random", "visible.type().sum().item", "len", "len", "dataset.get_name", "dataset.get_num_sequences", "Exception", "sampler.LWLSampler._sample_visible_ids", "sampler.LWLSampler._sample_visible_ids", "sampler.LWLSampler._sample_visible_ids", "sampler.LWLSampler._sample_visible_ids", "sampler.LWLSampler._sample_visible_ids", "sampler.LWLSampler._sample_visible_ids", "len", "len", "visible.type().sum", "visible.type", "len", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.is_video_sequence", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_frames", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_name", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_num_sequences", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.LWLSampler._sample_visible_ids"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            index (int): Index (dataset index)\n\n        returns:\n            TensorDict - dict containing all the data blocks\n        \"\"\"", "\n", "\n", "# Select a dataset", "\n", "dataset", "=", "random", ".", "choices", "(", "self", ".", "datasets", ",", "self", ".", "p_datasets", ")", "[", "0", "]", "\n", "\n", "is_video_dataset", "=", "dataset", ".", "is_video_sequence", "(", ")", "\n", "\n", "reverse_sequence", "=", "False", "\n", "if", "self", ".", "p_reverse", "is", "not", "None", ":", "\n", "            ", "reverse_sequence", "=", "random", ".", "random", "(", ")", "<", "self", ".", "p_reverse", "\n", "\n", "# Sample a sequence with enough visible frames", "\n", "", "enough_visible_frames", "=", "False", "\n", "while", "not", "enough_visible_frames", ":", "\n", "# Sample a sequence", "\n", "            ", "seq_id", "=", "random", ".", "randint", "(", "0", ",", "dataset", ".", "get_num_sequences", "(", ")", "-", "1", ")", "\n", "\n", "# Sample frames", "\n", "seq_info_dict", "=", "dataset", ".", "get_sequence_info", "(", "seq_id", ")", "\n", "visible", "=", "seq_info_dict", "[", "'visible'", "]", "\n", "\n", "enough_visible_frames", "=", "visible", ".", "type", "(", "torch", ".", "int64", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ">", "2", "*", "(", "self", ".", "num_test_frames", "+", "self", ".", "num_train_frames", ")", "\n", "\n", "enough_visible_frames", "=", "enough_visible_frames", "or", "not", "is_video_dataset", "\n", "\n", "", "if", "is_video_dataset", ":", "\n", "            ", "train_frame_ids", "=", "None", "\n", "test_frame_ids", "=", "None", "\n", "gap_increase", "=", "0", "\n", "\n", "# Sample test and train frames in a causal manner, i.e. test_frame_ids > train_frame_ids", "\n", "while", "test_frame_ids", "is", "None", ":", "\n", "                ", "if", "gap_increase", ">", "1000", ":", "\n", "                    ", "raise", "Exception", "(", "'Frame not found'", ")", "\n", "\n", "", "if", "not", "reverse_sequence", ":", "\n", "                    ", "base_frame_id", "=", "self", ".", "_sample_visible_ids", "(", "visible", ",", "num_ids", "=", "1", ",", "min_id", "=", "self", ".", "num_train_frames", "-", "1", ",", "\n", "max_id", "=", "len", "(", "visible", ")", "-", "self", ".", "num_test_frames", ")", "\n", "prev_frame_ids", "=", "self", ".", "_sample_visible_ids", "(", "visible", ",", "num_ids", "=", "self", ".", "num_train_frames", "-", "1", ",", "\n", "min_id", "=", "base_frame_id", "[", "0", "]", "-", "self", ".", "max_gap", "-", "gap_increase", ",", "\n", "max_id", "=", "base_frame_id", "[", "0", "]", ")", "\n", "if", "prev_frame_ids", "is", "None", ":", "\n", "                        ", "gap_increase", "+=", "5", "\n", "continue", "\n", "", "train_frame_ids", "=", "base_frame_id", "+", "prev_frame_ids", "\n", "test_frame_ids", "=", "self", ".", "_sample_visible_ids", "(", "visible", ",", "min_id", "=", "train_frame_ids", "[", "0", "]", "+", "1", ",", "\n", "max_id", "=", "train_frame_ids", "[", "0", "]", "+", "self", ".", "max_gap", "+", "gap_increase", ",", "\n", "num_ids", "=", "self", ".", "num_test_frames", ")", "\n", "\n", "# Increase gap until a frame is found", "\n", "gap_increase", "+=", "5", "\n", "", "else", ":", "\n", "# Sample in reverse order, i.e. train frames come after the test frames", "\n", "                    ", "base_frame_id", "=", "self", ".", "_sample_visible_ids", "(", "visible", ",", "num_ids", "=", "1", ",", "min_id", "=", "self", ".", "num_test_frames", "+", "1", ",", "\n", "max_id", "=", "len", "(", "visible", ")", "-", "self", ".", "num_train_frames", "-", "1", ")", "\n", "prev_frame_ids", "=", "self", ".", "_sample_visible_ids", "(", "visible", ",", "num_ids", "=", "self", ".", "num_train_frames", "-", "1", ",", "\n", "min_id", "=", "base_frame_id", "[", "0", "]", ",", "\n", "max_id", "=", "base_frame_id", "[", "0", "]", "+", "self", ".", "max_gap", "+", "gap_increase", ")", "\n", "if", "prev_frame_ids", "is", "None", ":", "\n", "                        ", "gap_increase", "+=", "5", "\n", "continue", "\n", "", "train_frame_ids", "=", "base_frame_id", "+", "prev_frame_ids", "\n", "test_frame_ids", "=", "self", ".", "_sample_visible_ids", "(", "visible", ",", "min_id", "=", "0", ",", "\n", "max_id", "=", "train_frame_ids", "[", "0", "]", "-", "1", ",", "\n", "num_ids", "=", "self", ".", "num_test_frames", ")", "\n", "\n", "# Increase gap until a frame is found", "\n", "gap_increase", "+=", "5", "\n", "", "", "", "else", ":", "\n", "# In case of image dataset, just repeat the image to generate synthetic video", "\n", "            ", "train_frame_ids", "=", "[", "1", "]", "*", "self", ".", "num_train_frames", "\n", "test_frame_ids", "=", "[", "1", "]", "*", "self", ".", "num_test_frames", "\n", "\n", "# Sort frames", "\n", "", "train_frame_ids", "=", "sorted", "(", "train_frame_ids", ",", "reverse", "=", "reverse_sequence", ")", "\n", "test_frame_ids", "=", "sorted", "(", "test_frame_ids", ",", "reverse", "=", "reverse_sequence", ")", "\n", "\n", "all_frame_ids", "=", "train_frame_ids", "+", "test_frame_ids", "\n", "\n", "# Load frames", "\n", "all_frames", ",", "all_anno", ",", "meta_obj", "=", "dataset", ".", "get_frames", "(", "seq_id", ",", "all_frame_ids", ",", "seq_info_dict", ")", "\n", "\n", "train_frames", "=", "all_frames", "[", ":", "len", "(", "train_frame_ids", ")", "]", "\n", "test_frames", "=", "all_frames", "[", "len", "(", "train_frame_ids", ")", ":", "]", "\n", "\n", "train_anno", "=", "{", "}", "\n", "test_anno", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "all_anno", ".", "items", "(", ")", ":", "\n", "            ", "train_anno", "[", "key", "]", "=", "value", "[", ":", "len", "(", "train_frame_ids", ")", "]", "\n", "test_anno", "[", "key", "]", "=", "value", "[", "len", "(", "train_frame_ids", ")", ":", "]", "\n", "\n", "", "train_masks", "=", "train_anno", "[", "'mask'", "]", "if", "'mask'", "in", "train_anno", "else", "None", "\n", "test_masks", "=", "test_anno", "[", "'mask'", "]", "if", "'mask'", "in", "test_anno", "else", "None", "\n", "\n", "data", "=", "TensorDict", "(", "{", "'train_images'", ":", "train_frames", ",", "\n", "'train_masks'", ":", "train_masks", ",", "\n", "'train_anno'", ":", "train_anno", "[", "'bbox'", "]", ",", "\n", "'test_images'", ":", "test_frames", ",", "\n", "'test_masks'", ":", "test_masks", ",", "\n", "'test_anno'", ":", "test_anno", "[", "'bbox'", "]", ",", "\n", "'dataset'", ":", "dataset", ".", "get_name", "(", ")", "}", ")", "\n", "\n", "return", "self", ".", "processing", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.KYSSampler.__init__": [[381, 409], ["sum"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "datasets", ",", "p_datasets", ",", "samples_per_epoch", ",", "sequence_sample_info", ",", "processing", "=", "no_processing", ",", "\n", "sample_occluded_sequences", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            datasets - List of datasets to be used for training\n            p_datasets - List containing the probabilities by which each dataset will be sampled\n            samples_per_epoch - Number of training samples per epoch\n            sequence_sample_info - A dict containing information about how to sample a sequence, e.g. number of frames,\n                                    max gap between frames, etc.\n            processing - An instance of Processing class which performs the necessary processing of the data.\n            sample_occluded_sequences - If true, sub-sequence containing occlusion is sampled whenever possible\n        \"\"\"", "\n", "\n", "self", ".", "datasets", "=", "datasets", "\n", "\n", "# If p not provided, sample uniformly from all videos", "\n", "if", "p_datasets", "is", "None", ":", "\n", "            ", "p_datasets", "=", "[", "1", "for", "d", "in", "self", ".", "datasets", "]", "\n", "\n", "# Normalize", "\n", "", "p_total", "=", "sum", "(", "p_datasets", ")", "\n", "self", ".", "p_datasets", "=", "[", "x", "/", "p_total", "for", "x", "in", "p_datasets", "]", "\n", "\n", "self", ".", "samples_per_epoch", "=", "samples_per_epoch", "\n", "self", ".", "sequence_sample_info", "=", "sequence_sample_info", "\n", "self", ".", "processing", "=", "processing", "\n", "\n", "self", ".", "sample_occluded_sequences", "=", "sample_occluded_sequences", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.KYSSampler.__len__": [[410, 412], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "samples_per_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.KYSSampler._sample_ids": [[413, 437], ["random.choices", "len", "len", "len", "range"], "methods", ["None"], ["", "def", "_sample_ids", "(", "self", ",", "valid", ",", "num_ids", "=", "1", ",", "min_id", "=", "None", ",", "max_id", "=", "None", ")", ":", "\n", "        ", "\"\"\" Samples num_ids frames between min_id and max_id for which target is visible\n\n        args:\n            visible - 1d Tensor indicating whether target is visible for each frame\n            num_ids - number of frames to be samples\n            min_id - Minimum allowed frame number\n            max_id - Maximum allowed frame number\n\n        returns:\n            list - List of sampled frame numbers. None if not sufficient visible frames could be found.\n        \"\"\"", "\n", "if", "min_id", "is", "None", "or", "min_id", "<", "0", ":", "\n", "            ", "min_id", "=", "0", "\n", "", "if", "max_id", "is", "None", "or", "max_id", ">", "len", "(", "valid", ")", ":", "\n", "            ", "max_id", "=", "len", "(", "valid", ")", "\n", "\n", "", "valid_ids", "=", "[", "i", "for", "i", "in", "range", "(", "min_id", ",", "max_id", ")", "if", "valid", "[", "i", "]", "]", "\n", "\n", "# No visible ids", "\n", "if", "len", "(", "valid_ids", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "return", "random", ".", "choices", "(", "valid_ids", ",", "k", "=", "num_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.KYSSampler.find_occlusion_end_frame": [[438, 444], ["range", "len", "len"], "methods", ["None"], ["", "def", "find_occlusion_end_frame", "(", "self", ",", "first_occ_frame", ",", "target_not_fully_visible", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "first_occ_frame", ",", "len", "(", "target_not_fully_visible", ")", ")", ":", "\n", "            ", "if", "not", "target_not_fully_visible", "[", "i", "]", ":", "\n", "                ", "return", "i", "\n", "\n", "", "", "return", "len", "(", "target_not_fully_visible", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.KYSSampler.__getitem__": [[445, 597], ["dataset.is_video_sequence", "sampler.KYSSampler.sequence_sample_info.get", "dataset.get_frames", "dataset.get_frames", "test_anno_dict.get", "pytracking.TensorDict", "sampler.KYSSampler.processing", "random.choices", "random.randint", "dataset.get_sequence_info", "dataset.get_sequence_info.get", "visible.type().sum().item", "torch.ones", "torch.zeros", "len", "dataset.get_name", "dataset.get_num_sequences", "visible.type().sum", "len", "dataset.has_occlusion_info", "sampler.KYSSampler.find_occlusion_end_frame", "sampler.KYSSampler._sample_ids", "sampler.KYSSampler._sample_ids", "min", "sampler.KYSSampler._sample_ids", "sampler.KYSSampler._sample_ids", "list", "visible.type", "target_not_fully_visible.float().sum", "target_not_fully_visible.nonzero", "random.randint", "max", "min", "float", "float", "range", "max", "random.randint", "len", "min", "int", "range", "len", "min", "len", "target_not_fully_visible.float", "len", "len", "len", "int", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.is_video_sequence", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_frames", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_frames", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info", "home.repos.pwc.inspect_result.visionml_pytracking.admin.model_constructor.NetConstructor.get", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_name", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_num_sequences", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.synthetic_video.SyntheticVideo.has_occlusion_info", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.KYSSampler.find_occlusion_end_frame", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.KYSSampler._sample_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.KYSSampler._sample_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.KYSSampler._sample_ids", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.KYSSampler._sample_ids", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            index (int): Index (Ignored since we sample randomly)\n\n        returns:\n            TensorDict - dict containing all the data blocks\n        \"\"\"", "\n", "\n", "# Select a dataset", "\n", "p_datasets", "=", "self", ".", "p_datasets", "\n", "\n", "dataset", "=", "random", ".", "choices", "(", "self", ".", "datasets", ",", "p_datasets", ")", "[", "0", "]", "\n", "is_video_dataset", "=", "dataset", ".", "is_video_sequence", "(", ")", "\n", "\n", "num_train_frames", "=", "self", ".", "sequence_sample_info", "[", "'num_train_frames'", "]", "\n", "num_test_frames", "=", "self", ".", "sequence_sample_info", "[", "'num_test_frames'", "]", "\n", "max_train_gap", "=", "self", ".", "sequence_sample_info", "[", "'max_train_gap'", "]", "\n", "allow_missing_target", "=", "self", ".", "sequence_sample_info", "[", "'allow_missing_target'", "]", "\n", "min_fraction_valid_frames", "=", "self", ".", "sequence_sample_info", ".", "get", "(", "'min_fraction_valid_frames'", ",", "0.0", ")", "\n", "\n", "if", "allow_missing_target", ":", "\n", "            ", "min_visible_frames", "=", "0", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "valid_sequence", "=", "False", "\n", "\n", "# Sample a sequence with enough visible frames and get anno for the same", "\n", "while", "not", "valid_sequence", ":", "\n", "            ", "seq_id", "=", "random", ".", "randint", "(", "0", ",", "dataset", ".", "get_num_sequences", "(", ")", "-", "1", ")", "\n", "\n", "seq_info_dict", "=", "dataset", ".", "get_sequence_info", "(", "seq_id", ")", "\n", "visible", "=", "seq_info_dict", "[", "'visible'", "]", "\n", "visible_ratio", "=", "seq_info_dict", ".", "get", "(", "'visible_ratio'", ",", "visible", ")", "\n", "\n", "num_visible", "=", "visible", ".", "type", "(", "torch", ".", "int64", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "enough_visible_frames", "=", "not", "is_video_dataset", "or", "(", "num_visible", ">", "min_visible_frames", "and", "len", "(", "visible", ")", ">=", "20", ")", "\n", "\n", "valid_sequence", "=", "enough_visible_frames", "\n", "\n", "", "if", "self", ".", "sequence_sample_info", "[", "'mode'", "]", "==", "'Sequence'", ":", "\n", "            ", "if", "is_video_dataset", ":", "\n", "                ", "train_frame_ids", "=", "None", "\n", "test_frame_ids", "=", "None", "\n", "gap_increase", "=", "0", "\n", "\n", "test_valid_image", "=", "torch", ".", "zeros", "(", "num_test_frames", ",", "dtype", "=", "torch", ".", "int8", ")", "\n", "# Sample frame numbers in a causal manner, i.e. test_frame_ids > train_frame_ids", "\n", "while", "test_frame_ids", "is", "None", ":", "\n", "                    ", "occlusion_sampling", "=", "False", "\n", "if", "dataset", ".", "has_occlusion_info", "(", ")", "and", "self", ".", "sample_occluded_sequences", ":", "\n", "                        ", "target_not_fully_visible", "=", "visible_ratio", "<", "0.9", "\n", "if", "target_not_fully_visible", ".", "float", "(", ")", ".", "sum", "(", ")", ">", "0", ":", "\n", "                            ", "occlusion_sampling", "=", "True", "\n", "\n", "", "", "if", "occlusion_sampling", ":", "\n", "                        ", "first_occ_frame", "=", "target_not_fully_visible", ".", "nonzero", "(", ")", "[", "0", "]", "\n", "\n", "occ_end_frame", "=", "self", ".", "find_occlusion_end_frame", "(", "first_occ_frame", ",", "target_not_fully_visible", ")", "\n", "\n", "# Make sure target visible in first frame", "\n", "base_frame_id", "=", "self", ".", "_sample_ids", "(", "visible", ",", "num_ids", "=", "1", ",", "min_id", "=", "max", "(", "0", ",", "first_occ_frame", "-", "20", ")", ",", "\n", "max_id", "=", "first_occ_frame", "-", "5", ")", "\n", "\n", "if", "base_frame_id", "is", "None", ":", "\n", "                            ", "base_frame_id", "=", "0", "\n", "", "else", ":", "\n", "                            ", "base_frame_id", "=", "base_frame_id", "[", "0", "]", "\n", "\n", "", "prev_frame_ids", "=", "self", ".", "_sample_ids", "(", "visible", ",", "num_ids", "=", "num_train_frames", ",", "\n", "min_id", "=", "base_frame_id", "-", "max_train_gap", "-", "gap_increase", "-", "1", ",", "\n", "max_id", "=", "base_frame_id", "-", "1", ")", "\n", "\n", "if", "prev_frame_ids", "is", "None", ":", "\n", "                            ", "if", "base_frame_id", "-", "max_train_gap", "-", "gap_increase", "-", "1", "<", "0", ":", "\n", "                                ", "prev_frame_ids", "=", "[", "base_frame_id", "]", "*", "num_train_frames", "\n", "", "else", ":", "\n", "                                ", "gap_increase", "+=", "5", "\n", "continue", "\n", "\n", "", "", "train_frame_ids", "=", "prev_frame_ids", "\n", "\n", "end_frame", "=", "min", "(", "occ_end_frame", "+", "random", ".", "randint", "(", "5", ",", "20", ")", ",", "len", "(", "visible", ")", "-", "1", ")", "\n", "\n", "if", "(", "end_frame", "-", "base_frame_id", ")", "<", "num_test_frames", ":", "\n", "                            ", "rem_frames", "=", "num_test_frames", "-", "(", "end_frame", "-", "base_frame_id", ")", "\n", "end_frame", "=", "random", ".", "randint", "(", "end_frame", ",", "min", "(", "len", "(", "visible", ")", "-", "1", ",", "end_frame", "+", "rem_frames", ")", ")", "\n", "base_frame_id", "=", "max", "(", "0", ",", "end_frame", "-", "num_test_frames", "+", "1", ")", "\n", "\n", "end_frame", "=", "min", "(", "end_frame", ",", "len", "(", "visible", ")", "-", "1", ")", "\n", "\n", "", "step_len", "=", "float", "(", "end_frame", "-", "base_frame_id", ")", "/", "float", "(", "num_test_frames", ")", "\n", "\n", "test_frame_ids", "=", "[", "base_frame_id", "+", "int", "(", "x", "*", "step_len", ")", "for", "x", "in", "range", "(", "0", ",", "num_test_frames", ")", "]", "\n", "test_valid_image", "[", ":", "len", "(", "test_frame_ids", ")", "]", "=", "1", "\n", "\n", "test_frame_ids", "=", "test_frame_ids", "+", "[", "0", "]", "*", "(", "num_test_frames", "-", "len", "(", "test_frame_ids", ")", ")", "\n", "", "else", ":", "\n", "# Make sure target visible in first frame", "\n", "                        ", "base_frame_id", "=", "self", ".", "_sample_ids", "(", "visible", ",", "num_ids", "=", "1", ",", "min_id", "=", "2", "*", "num_train_frames", ",", "\n", "max_id", "=", "len", "(", "visible", ")", "-", "int", "(", "num_test_frames", "*", "min_fraction_valid_frames", ")", ")", "\n", "if", "base_frame_id", "is", "None", ":", "\n", "                            ", "base_frame_id", "=", "0", "\n", "", "else", ":", "\n", "                            ", "base_frame_id", "=", "base_frame_id", "[", "0", "]", "\n", "\n", "", "prev_frame_ids", "=", "self", ".", "_sample_ids", "(", "visible", ",", "num_ids", "=", "num_train_frames", ",", "\n", "min_id", "=", "base_frame_id", "-", "max_train_gap", "-", "gap_increase", "-", "1", ",", "\n", "max_id", "=", "base_frame_id", "-", "1", ")", "\n", "if", "prev_frame_ids", "is", "None", ":", "\n", "                            ", "if", "base_frame_id", "-", "max_train_gap", "-", "gap_increase", "-", "1", "<", "0", ":", "\n", "                                ", "prev_frame_ids", "=", "[", "base_frame_id", "]", "*", "num_train_frames", "\n", "", "else", ":", "\n", "                                ", "gap_increase", "+=", "5", "\n", "continue", "\n", "\n", "", "", "train_frame_ids", "=", "prev_frame_ids", "\n", "\n", "test_frame_ids", "=", "list", "(", "range", "(", "base_frame_id", ",", "min", "(", "len", "(", "visible", ")", ",", "base_frame_id", "+", "num_test_frames", ")", ")", ")", "\n", "test_valid_image", "[", ":", "len", "(", "test_frame_ids", ")", "]", "=", "1", "\n", "\n", "test_frame_ids", "=", "test_frame_ids", "+", "[", "0", "]", "*", "(", "num_test_frames", "-", "len", "(", "test_frame_ids", ")", ")", "\n", "", "", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "# Get frames", "\n", "", "train_frames", ",", "train_anno_dict", ",", "_", "=", "dataset", ".", "get_frames", "(", "seq_id", ",", "train_frame_ids", ",", "seq_info_dict", ")", "\n", "train_anno", "=", "train_anno_dict", "[", "'bbox'", "]", "\n", "\n", "test_frames", ",", "test_anno_dict", ",", "_", "=", "dataset", ".", "get_frames", "(", "seq_id", ",", "test_frame_ids", ",", "seq_info_dict", ")", "\n", "test_anno", "=", "test_anno_dict", "[", "'bbox'", "]", "\n", "test_valid_anno", "=", "test_anno_dict", "[", "'valid'", "]", "\n", "test_visible", "=", "test_anno_dict", "[", "'visible'", "]", "\n", "test_visible_ratio", "=", "test_anno_dict", ".", "get", "(", "'visible_ratio'", ",", "torch", ".", "ones", "(", "len", "(", "test_visible", ")", ")", ")", "\n", "\n", "# Prepare data", "\n", "data", "=", "TensorDict", "(", "{", "'train_images'", ":", "train_frames", ",", "\n", "'train_anno'", ":", "train_anno", ",", "\n", "'test_images'", ":", "test_frames", ",", "\n", "'test_anno'", ":", "test_anno", ",", "\n", "'test_valid_anno'", ":", "test_valid_anno", ",", "\n", "'test_visible'", ":", "test_visible", ",", "\n", "'test_valid_image'", ":", "test_valid_image", ",", "\n", "'test_visible_ratio'", ":", "test_visible_ratio", ",", "\n", "'dataset'", ":", "dataset", ".", "get_name", "(", ")", "}", ")", "\n", "\n", "# Send for processing", "\n", "return", "self", ".", "processing", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler.__init__": [[600, 645], ["sampler.SequentialTargetCandidateMatchingSampler._load_dataset_subsequence_states", "sum", "sampler.SequentialTargetCandidateMatchingSampler._load_dataset_frame_states", "sum", "len", "len"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler._load_dataset_subsequence_states", "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler._load_dataset_frame_states"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "samples_per_epoch", ",", "sup_modes", ",", "p_sup_modes", "=", "None", ",", "processing", "=", "no_processing", ",", "\n", "subseq_modes", "=", "None", ",", "p_subseq_modes", "=", "None", ",", "frame_modes", "=", "None", ",", "p_frame_modes", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            datasets - List of datasets to be used for training\n            samples_per_epoch - Number of training samples per epoch\n            sup_modes - List of different supervision modes to use (partial_sup or self_sup).\n            p_sup_modes - List of sup_mode sample probabilities.\n            processing - An instance of Processing class which performs the necessary processing of the data.\n            subseq_modes - List of different subsequence modes to sample from (HH, HK, HG), see KeepTrack paper for details.\n            p_subseq_modes - List of subseq_mode sample probabilities.\n            frame_modes - List of different frame mode to sample from (H, K, J), see KeepTrack paper for details.\n            p_frame_modes - List of frame_mode sample probabilities.\n\n        \"\"\"", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "samples_per_epoch", "=", "samples_per_epoch", "\n", "self", ".", "processing", "=", "processing", "\n", "self", ".", "subseq_modes", "=", "subseq_modes", "\n", "self", ".", "frame_modes", "=", "frame_modes", "\n", "self", ".", "sup_modes", "=", "sup_modes", "if", "sup_modes", "is", "not", "None", "else", "[", "'self_sup'", "]", "\n", "self", ".", "p_sup_modes", "=", "p_sup_modes", "\n", "\n", "if", "p_sup_modes", "is", "None", ":", "\n", "            ", "self", ".", "p_sup_modes", "=", "[", "1.", "/", "len", "(", "self", ".", "sup_modes", ")", "]", "*", "(", "len", "(", "self", ".", "sup_modes", ")", ")", "\n", "\n", "", "if", "subseq_modes", "is", "not", "None", ":", "\n", "            ", "self", ".", "dataset_subseq_states", "=", "self", ".", "_load_dataset_subsequence_states", "(", ")", "\n", "\n", "if", "p_subseq_modes", "is", "None", ":", "\n", "                ", "p_subseq_modes", "=", "[", "self", ".", "dataset_subseq_states", "[", "mode", "]", ".", "shape", "[", "0", "]", "for", "mode", "in", "self", ".", "subseq_modes", "]", "\n", "\n", "# Normalize", "\n", "", "p_subseq_total", "=", "sum", "(", "p_subseq_modes", ")", "\n", "self", ".", "p_subseq_modes", "=", "[", "x", "/", "p_subseq_total", "for", "x", "in", "p_subseq_modes", "]", "\n", "\n", "", "if", "frame_modes", "is", "not", "None", ":", "\n", "            ", "self", ".", "dataset_frame_states", "=", "self", ".", "_load_dataset_frame_states", "(", ")", "\n", "\n", "if", "p_frame_modes", "is", "None", ":", "\n", "                ", "p_frame_modes", "=", "[", "self", ".", "dataset_frame_states", "[", "mode", "]", ".", "shape", "[", "0", "]", "for", "mode", "in", "self", ".", "frame_modes", "]", "\n", "\n", "# Normalize", "\n", "", "p_frames_total", "=", "sum", "(", "p_frame_modes", ")", "\n", "self", ".", "p_frame_modes", "=", "[", "x", "/", "p_frames_total", "for", "x", "in", "p_frame_modes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler.__len__": [[646, 648], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "samples_per_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler._load_dataset_subsequence_states": [[649, 651], ["sampler.SequentialTargetCandidateMatchingSampler.dataset.get_subseq_states"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_subseq_states"], ["", "def", "_load_dataset_subsequence_states", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "get_subseq_states", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler._load_dataset_frame_states": [[652, 654], ["sampler.SequentialTargetCandidateMatchingSampler.dataset.get_frame_states"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_frame_states"], ["", "def", "_load_dataset_frame_states", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dataset", ".", "get_frame_states", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler._sample_valid_ids": [[655, 685], ["random.sample", "random.sample", "len", "len", "len", "range", "len", "len"], "methods", ["None"], ["", "def", "_sample_valid_ids", "(", "self", ",", "visible", ",", "num_ids", "=", "1", ",", "min_id", "=", "None", ",", "max_id", "=", "None", ")", ":", "\n", "        ", "\"\"\" Samples num_ids frames between min_id and max_id for which dumped data is useful\n\n        args:\n            visible - 1d Tensor indicating whether target is visible for each frame\n            num_ids - number of frames to be sampled\n            min_id - Minimum allowed frame number\n            max_id - Maximum allowed frame number\n\n        returns:\n            list - List of sampled frame numbers. None if not sufficient visible frames could be found.\n        \"\"\"", "\n", "if", "num_ids", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "", "if", "min_id", "is", "None", "or", "min_id", "<", "2", ":", "\n", "            ", "min_id", "=", "2", "\n", "", "if", "max_id", "is", "None", "or", "max_id", ">", "len", "(", "visible", ")", ":", "\n", "            ", "max_id", "=", "len", "(", "visible", ")", "\n", "\n", "", "valid_ids", "=", "[", "i", "for", "i", "in", "range", "(", "min_id", ",", "max_id", ")", "if", "visible", "[", "i", "]", "]", "\n", "\n", "# No visible ids", "\n", "if", "len", "(", "valid_ids", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "num_begin", "=", "num_ids", "//", "2", "\n", "num_end", "=", "num_ids", "-", "num_ids", "//", "2", "\n", "ids_begin", "=", "random", ".", "sample", "(", "valid_ids", "[", ":", "len", "(", "valid_ids", ")", "//", "2", "]", ",", "k", "=", "num_begin", ")", "\n", "ids_end", "=", "random", ".", "sample", "(", "valid_ids", "[", "len", "(", "valid_ids", ")", "//", "2", ":", "]", ",", "k", "=", "num_end", ")", "\n", "return", "ids_begin", "+", "ids_end", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.SequentialTargetCandidateMatchingSampler.__getitem__": [[687, 736], ["sampler.SequentialTargetCandidateMatchingSampler.dataset.get_sequence_info", "sampler.SequentialTargetCandidateMatchingSampler.dataset.get_frames", "pytracking.TensorDict", "frames_dict.items", "sampler.SequentialTargetCandidateMatchingSampler.processing", "random.choices", "state[].item", "state[].item", "random.choices", "random.choices", "state[].item", "state[].item", "ValueError", "sampler.SequentialTargetCandidateMatchingSampler.dataset.get_name", "sampler.SequentialTargetCandidateMatchingSampler.dataset.get_sequence_name", "random.choices", "random.choices"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_sequence_info", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.imagenetvid.ImagenetVID.get_frames", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.base_image_dataset.BaseImageDataset.get_name", "home.repos.pwc.inspect_result.visionml_pytracking.dataset.lasot_candidate_matching.LasotCandidateMatching.get_sequence_name"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        args:\n            index (int): Index (Ignored since we sample randomly).\n\n        returns:\n            TensorDict - dict containing all the data blocks\n        \"\"\"", "\n", "\n", "# select a subseq mode", "\n", "sup_mode", "=", "random", ".", "choices", "(", "self", ".", "sup_modes", ",", "self", ".", "p_sup_modes", ",", "k", "=", "1", ")", "[", "0", "]", "\n", "\n", "if", "sup_mode", "==", "'self_sup'", ":", "\n", "            ", "mode", "=", "random", ".", "choices", "(", "self", ".", "frame_modes", ",", "self", ".", "p_frame_modes", ",", "k", "=", "1", ")", "[", "0", "]", "\n", "\n", "states", "=", "self", ".", "dataset_frame_states", "[", "mode", "]", "\n", "state", "=", "random", ".", "choices", "(", "states", ",", "k", "=", "1", ")", "[", "0", "]", "\n", "seq_id", "=", "state", "[", "0", "]", ".", "item", "(", ")", "\n", "baseframe_id", "=", "state", "[", "1", "]", ".", "item", "(", ")", "\n", "test_frame_ids", "=", "[", "baseframe_id", "]", "\n", "\n", "", "elif", "sup_mode", "==", "'partial_sup'", ":", "\n", "            ", "mode", "=", "random", ".", "choices", "(", "self", ".", "subseq_modes", ",", "self", ".", "p_subseq_modes", ",", "k", "=", "1", ")", "[", "0", "]", "\n", "\n", "states", "=", "self", ".", "dataset_subseq_states", "[", "mode", "]", "\n", "state", "=", "random", ".", "choices", "(", "states", ",", "k", "=", "1", ")", "[", "0", "]", "\n", "seq_id", "=", "state", "[", "0", "]", ".", "item", "(", ")", "\n", "baseframe_id", "=", "state", "[", "1", "]", ".", "item", "(", ")", "\n", "test_frame_ids", "=", "[", "baseframe_id", ",", "baseframe_id", "+", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Supervision mode: \\'{}\\' is invalid.'", ".", "format", "(", "sup_mode", ")", ")", "\n", "\n", "\n", "", "seq_info_dict", "=", "self", ".", "dataset", ".", "get_sequence_info", "(", "seq_id", ")", "\n", "\n", "frames_dict", ",", "_", "=", "self", ".", "dataset", ".", "get_frames", "(", "seq_id", ",", "test_frame_ids", ",", "seq_info_dict", ")", "\n", "\n", "data", "=", "TensorDict", "(", "{", "\n", "'dataset'", ":", "self", ".", "dataset", ".", "get_name", "(", ")", ",", "\n", "'mode'", ":", "mode", ",", "\n", "'seq_name'", ":", "self", ".", "dataset", ".", "get_sequence_name", "(", "seq_id", ")", ",", "\n", "'base_frame_id'", ":", "baseframe_id", ",", "\n", "'sup_mode'", ":", "sup_mode", "\n", "}", ")", "\n", "\n", "for", "key", ",", "val", "in", "frames_dict", ".", "items", "(", ")", ":", "\n", "            ", "data", "[", "key", "]", "=", "val", "\n", "\n", "", "return", "self", ".", "processing", "(", "data", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.data.sampler.no_processing": [[6, 8], ["None"], "function", ["None"], ["def", "no_processing", "(", "data", ")", ":", "\n", "    ", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target": [[10, 67], ["target_bb.tolist", "math.ceil", "round", "round", "max", "max", "max", "max", "cv2.copyMakeBorder", "Exception", "torch.pad", "cv2.resize", "math.sqrt", "torch.interpolate"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate"], ["def", "sample_target", "(", "im", ",", "target_bb", ",", "search_area_factor", ",", "output_sz", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "    ", "\"\"\" Extracts a square crop centered at target_bb box, of area search_area_factor^2 times target_bb area\n\n    args:\n        im - cv image\n        target_bb - target box [x, y, w, h]\n        search_area_factor - Ratio of crop size to target size\n        output_sz - (float) Size to which the extracted crop is resized (always square). If None, no resizing is done.\n\n    returns:\n        cv image - extracted crop\n        float - the factor by which the crop has been resized to make the crop size equal output_size\n    \"\"\"", "\n", "x", ",", "y", ",", "w", ",", "h", "=", "target_bb", ".", "tolist", "(", ")", "\n", "\n", "# Crop image", "\n", "crop_sz", "=", "math", ".", "ceil", "(", "math", ".", "sqrt", "(", "w", "*", "h", ")", "*", "search_area_factor", ")", "\n", "\n", "if", "crop_sz", "<", "1", ":", "\n", "        ", "raise", "Exception", "(", "'Too small bounding box.'", ")", "\n", "\n", "", "x1", "=", "round", "(", "x", "+", "0.5", "*", "w", "-", "crop_sz", "*", "0.5", ")", "\n", "x2", "=", "x1", "+", "crop_sz", "\n", "\n", "y1", "=", "round", "(", "y", "+", "0.5", "*", "h", "-", "crop_sz", "*", "0.5", ")", "\n", "y2", "=", "y1", "+", "crop_sz", "\n", "\n", "x1_pad", "=", "max", "(", "0", ",", "-", "x1", ")", "\n", "x2_pad", "=", "max", "(", "x2", "-", "im", ".", "shape", "[", "1", "]", "+", "1", ",", "0", ")", "\n", "\n", "y1_pad", "=", "max", "(", "0", ",", "-", "y1", ")", "\n", "y2_pad", "=", "max", "(", "y2", "-", "im", ".", "shape", "[", "0", "]", "+", "1", ",", "0", ")", "\n", "\n", "# Crop target", "\n", "im_crop", "=", "im", "[", "y1", "+", "y1_pad", ":", "y2", "-", "y2_pad", ",", "x1", "+", "x1_pad", ":", "x2", "-", "x2_pad", ",", ":", "]", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "mask_crop", "=", "mask", "[", "y1", "+", "y1_pad", ":", "y2", "-", "y2_pad", ",", "x1", "+", "x1_pad", ":", "x2", "-", "x2_pad", "]", "\n", "\n", "# Pad", "\n", "", "im_crop_padded", "=", "cv", ".", "copyMakeBorder", "(", "im_crop", ",", "y1_pad", ",", "y2_pad", ",", "x1_pad", ",", "x2_pad", ",", "cv", ".", "BORDER_REPLICATE", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "mask_crop_padded", "=", "F", ".", "pad", "(", "mask_crop", ",", "pad", "=", "(", "x1_pad", ",", "x2_pad", ",", "y1_pad", ",", "y2_pad", ")", ",", "mode", "=", "'constant'", ",", "value", "=", "0", ")", "\n", "\n", "", "if", "output_sz", "is", "not", "None", ":", "\n", "        ", "resize_factor", "=", "output_sz", "/", "crop_sz", "\n", "im_crop_padded", "=", "cv", ".", "resize", "(", "im_crop_padded", ",", "(", "output_sz", ",", "output_sz", ")", ")", "\n", "\n", "if", "mask", "is", "None", ":", "\n", "            ", "return", "im_crop_padded", ",", "resize_factor", "\n", "", "mask_crop_padded", "=", "F", ".", "interpolate", "(", "mask_crop_padded", "[", "None", ",", "None", "]", ",", "(", "output_sz", ",", "output_sz", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", "[", "0", ",", "0", "]", "\n", "return", "im_crop_padded", ",", "resize_factor", ",", "mask_crop_padded", "\n", "\n", "", "else", ":", "\n", "        ", "if", "mask", "is", "None", ":", "\n", "            ", "return", "im_crop_padded", ",", "1.0", "\n", "", "return", "im_crop_padded", ",", "1.0", ",", "mask_crop_padded", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.transform_image_to_crop": [[69, 90], ["torch.cat", "torch.cat"], "function", ["None"], ["", "", "def", "transform_image_to_crop", "(", "box_in", ":", "torch", ".", "Tensor", ",", "box_extract", ":", "torch", ".", "Tensor", ",", "resize_factor", ":", "float", ",", "\n", "crop_sz", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\" Transform the box co-ordinates from the original image co-ordinates to the co-ordinates of the cropped image\n    args:\n        box_in - the box for which the co-ordinates are to be transformed\n        box_extract - the box about which the image crop has been extracted.\n        resize_factor - the ratio between the original image scale and the scale of the image crop\n        crop_sz - size of the cropped image\n\n    returns:\n        torch.Tensor - transformed co-ordinates of box_in\n    \"\"\"", "\n", "box_extract_center", "=", "box_extract", "[", "0", ":", "2", "]", "+", "0.5", "*", "box_extract", "[", "2", ":", "4", "]", "\n", "\n", "box_in_center", "=", "box_in", "[", "0", ":", "2", "]", "+", "0.5", "*", "box_in", "[", "2", ":", "4", "]", "\n", "\n", "box_out_center", "=", "(", "crop_sz", "-", "1", ")", "/", "2", "+", "(", "box_in_center", "-", "box_extract_center", ")", "*", "resize_factor", "\n", "box_out_wh", "=", "box_in", "[", "2", ":", "4", "]", "*", "resize_factor", "\n", "\n", "box_out", "=", "torch", ".", "cat", "(", "(", "box_out_center", "-", "0.5", "*", "box_out_wh", ",", "box_out_wh", ")", ")", "\n", "return", "box_out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.jittered_center_crop": [[92, 127], ["torch.Tensor", "torch.Tensor", "zip", "zip", "processing_utils.transform_image_to_crop", "processing_utils.sample_target", "processing_utils.sample_target", "zip", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.transform_image_to_crop", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target"], ["", "def", "jittered_center_crop", "(", "frames", ",", "box_extract", ",", "box_gt", ",", "search_area_factor", ",", "output_sz", ",", "masks", "=", "None", ")", ":", "\n", "    ", "\"\"\" For each frame in frames, extracts a square crop centered at box_extract, of area search_area_factor^2\n    times box_extract area. The extracted crops are then resized to output_sz. Further, the co-ordinates of the box\n    box_gt are transformed to the image crop co-ordinates\n\n    args:\n        frames - list of frames\n        box_extract - list of boxes of same length as frames. The crops are extracted using anno_extract\n        box_gt - list of boxes of same length as frames. The co-ordinates of these boxes are transformed from\n                    image co-ordinates to the crop co-ordinates\n        search_area_factor - The area of the extracted crop is search_area_factor^2 times box_extract area\n        output_sz - The size to which the extracted crops are resized\n\n    returns:\n        list - list of image crops\n        list - box_gt location in the crop co-ordinates\n        \"\"\"", "\n", "\n", "if", "masks", "is", "None", ":", "\n", "        ", "crops_resize_factors", "=", "[", "sample_target", "(", "f", ",", "a", ",", "search_area_factor", ",", "output_sz", ")", "\n", "for", "f", ",", "a", "in", "zip", "(", "frames", ",", "box_extract", ")", "]", "\n", "frames_crop", ",", "resize_factors", "=", "zip", "(", "*", "crops_resize_factors", ")", "\n", "masks_crop", "=", "None", "\n", "", "else", ":", "\n", "        ", "crops_resize_factors", "=", "[", "sample_target", "(", "f", ",", "a", ",", "search_area_factor", ",", "output_sz", ",", "m", ")", "\n", "for", "f", ",", "a", ",", "m", "in", "zip", "(", "frames", ",", "box_extract", ",", "masks", ")", "]", "\n", "frames_crop", ",", "resize_factors", ",", "masks_crop", "=", "zip", "(", "*", "crops_resize_factors", ")", "\n", "\n", "", "crop_sz", "=", "torch", ".", "Tensor", "(", "[", "output_sz", ",", "output_sz", "]", ")", "\n", "\n", "# find the bb location in the crop", "\n", "box_crop", "=", "[", "transform_image_to_crop", "(", "a_gt", ",", "a_ex", ",", "rf", ",", "crop_sz", ")", "\n", "for", "a_gt", ",", "a_ex", ",", "rf", "in", "zip", "(", "box_gt", ",", "box_extract", ",", "resize_factors", ")", "]", "\n", "\n", "return", "frames_crop", ",", "box_crop", ",", "masks_crop", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target_adaptive": [[129, 239], ["isinstance", "torch.Tensor", "torch.Tensor", "target_bb.tolist", "round", "round", "max", "max", "max", "max", "cv2.copyMakeBorder", "cv2.resize", "torch.Tensor", "torch.Tensor", "float", "min", "math.floor", "math.floor", "Exception", "max", "min", "max", "min", "torch.pad", "tuple", "max", "max", "max", "max", "max", "max", "torch.Tensor.long().tolist", "torch.interpolate", "min", "tuple", "torch.Tensor.long", "torch.Tensor.flip().long().tolist", "torch.Tensor.flip().long", "torch.Tensor.flip", "target_bb[].prod", "torch.Tensor.prod"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate"], ["", "def", "sample_target_adaptive", "(", "im", ",", "target_bb", ",", "search_area_factor", ",", "output_sz", ",", "mode", ":", "str", "=", "'replicate'", ",", "\n", "max_scale_change", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "    ", "\"\"\" Extracts a crop centered at target_bb box, of area search_area_factor^2. If the crop area contains regions\n    outside the image, it is shifted so that the it is inside the image. Further, if the crop area exceeds the image\n    size, a smaller crop which fits the image is returned instead.\n\n    args:\n        im - Input numpy image to crop.\n        target_bb - target box [x, y, w, h]\n        search_area_factor - Ratio of crop size to target size\n        output_sz - (float) Size to which the extracted crop is resized (always square). If None, no resizing is done.\n        mode - If 'replicate', the boundary pixels are replicated in case the search region crop goes out of image.\n               If 'inside', the search region crop is shifted/shrunk to fit completely inside the image.\n               If 'inside_major', the search region crop is shifted/shrunk to fit completely inside one axis of the image.\n        max_scale_change - Maximum allowed scale change when performing the crop (only applicable for 'inside' and 'inside_major')\n        mask - Optional mask to apply the same crop.\n\n    returns:\n        numpy image - Extracted crop.\n        torch.Tensor - A bounding box denoting the cropped region in the image.\n        numpy mask - Cropped mask returned only if mask is not None.\n    \"\"\"", "\n", "\n", "if", "max_scale_change", "is", "None", ":", "\n", "        ", "max_scale_change", "=", "float", "(", "'inf'", ")", "\n", "", "if", "isinstance", "(", "output_sz", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "        ", "output_sz", "=", "(", "output_sz", ",", "output_sz", ")", "\n", "", "output_sz", "=", "torch", ".", "Tensor", "(", "output_sz", ")", "\n", "\n", "im_h", "=", "im", ".", "shape", "[", "0", "]", "\n", "im_w", "=", "im", ".", "shape", "[", "1", "]", "\n", "\n", "bbx", ",", "bby", ",", "bbw", ",", "bbh", "=", "target_bb", ".", "tolist", "(", ")", "\n", "\n", "# Crop image", "\n", "crop_sz_x", ",", "crop_sz_y", "=", "(", "output_sz", "*", "(", "\n", "target_bb", "[", "2", ":", "]", ".", "prod", "(", ")", "/", "output_sz", ".", "prod", "(", ")", ")", ".", "sqrt", "(", ")", "*", "search_area_factor", ")", ".", "ceil", "(", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", "\n", "\n", "# Get new sample size if forced inside the image", "\n", "if", "mode", "==", "'inside'", "or", "mode", "==", "'inside_major'", ":", "\n", "# Calculate rescaling factor if outside the image", "\n", "        ", "rescale_factor", "=", "[", "crop_sz_x", "/", "im_w", ",", "crop_sz_y", "/", "im_h", "]", "\n", "if", "mode", "==", "'inside'", ":", "\n", "            ", "rescale_factor", "=", "max", "(", "rescale_factor", ")", "\n", "", "elif", "mode", "==", "'inside_major'", ":", "\n", "            ", "rescale_factor", "=", "min", "(", "rescale_factor", ")", "\n", "", "rescale_factor", "=", "min", "(", "max", "(", "1", ",", "rescale_factor", ")", ",", "max_scale_change", ")", "\n", "\n", "crop_sz_x", "=", "math", ".", "floor", "(", "crop_sz_x", "/", "rescale_factor", ")", "\n", "crop_sz_y", "=", "math", ".", "floor", "(", "crop_sz_y", "/", "rescale_factor", ")", "\n", "\n", "", "if", "crop_sz_x", "<", "1", "or", "crop_sz_y", "<", "1", ":", "\n", "        ", "raise", "Exception", "(", "'Too small bounding box.'", ")", "\n", "\n", "", "x1", "=", "round", "(", "bbx", "+", "0.5", "*", "bbw", "-", "crop_sz_x", "*", "0.5", ")", "\n", "x2", "=", "x1", "+", "crop_sz_x", "\n", "\n", "y1", "=", "round", "(", "bby", "+", "0.5", "*", "bbh", "-", "crop_sz_y", "*", "0.5", ")", "\n", "y2", "=", "y1", "+", "crop_sz_y", "\n", "\n", "# Move box inside image", "\n", "shift_x", "=", "max", "(", "0", ",", "-", "x1", ")", "+", "min", "(", "0", ",", "im_w", "-", "x2", ")", "\n", "x1", "+=", "shift_x", "\n", "x2", "+=", "shift_x", "\n", "\n", "shift_y", "=", "max", "(", "0", ",", "-", "y1", ")", "+", "min", "(", "0", ",", "im_h", "-", "y2", ")", "\n", "y1", "+=", "shift_y", "\n", "y2", "+=", "shift_y", "\n", "\n", "out_x", "=", "(", "max", "(", "0", ",", "-", "x1", ")", "+", "max", "(", "0", ",", "x2", "-", "im_w", ")", ")", "//", "2", "\n", "out_y", "=", "(", "max", "(", "0", ",", "-", "y1", ")", "+", "max", "(", "0", ",", "y2", "-", "im_h", ")", ")", "//", "2", "\n", "shift_x", "=", "(", "-", "x1", "-", "out_x", ")", "*", "(", "out_x", ">", "0", ")", "\n", "shift_y", "=", "(", "-", "y1", "-", "out_y", ")", "*", "(", "out_y", ">", "0", ")", "\n", "\n", "x1", "+=", "shift_x", "\n", "x2", "+=", "shift_x", "\n", "y1", "+=", "shift_y", "\n", "y2", "+=", "shift_y", "\n", "\n", "x1_pad", "=", "max", "(", "0", ",", "-", "x1", ")", "\n", "x2_pad", "=", "max", "(", "x2", "-", "im", ".", "shape", "[", "1", "]", "+", "1", ",", "0", ")", "\n", "\n", "y1_pad", "=", "max", "(", "0", ",", "-", "y1", ")", "\n", "y2_pad", "=", "max", "(", "y2", "-", "im", ".", "shape", "[", "0", "]", "+", "1", ",", "0", ")", "\n", "\n", "# Crop target", "\n", "im_crop", "=", "im", "[", "y1", "+", "y1_pad", ":", "y2", "-", "y2_pad", ",", "x1", "+", "x1_pad", ":", "x2", "-", "x2_pad", ",", ":", "]", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "mask_crop", "=", "mask", "[", "y1", "+", "y1_pad", ":", "y2", "-", "y2_pad", ",", "x1", "+", "x1_pad", ":", "x2", "-", "x2_pad", "]", "\n", "\n", "# Pad", "\n", "", "im_crop_padded", "=", "cv", ".", "copyMakeBorder", "(", "im_crop", ",", "y1_pad", ",", "y2_pad", ",", "x1_pad", ",", "x2_pad", ",", "cv", ".", "BORDER_REPLICATE", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "mask_crop_padded", "=", "F", ".", "pad", "(", "mask_crop", ",", "pad", "=", "(", "x1_pad", ",", "x2_pad", ",", "y1_pad", ",", "y2_pad", ")", ",", "mode", "=", "'constant'", ",", "value", "=", "0", ")", "\n", "\n", "# Resize image", "\n", "", "im_out", "=", "cv", ".", "resize", "(", "im_crop_padded", ",", "tuple", "(", "output_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "mask_out", "=", "F", ".", "interpolate", "(", "mask_crop_padded", "[", "None", ",", "None", "]", ",", "tuple", "(", "output_sz", ".", "flip", "(", "0", ")", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", ",", "mode", "=", "'nearest'", ")", "[", "0", ",", "0", "]", "\n", "\n", "", "crop_box", "=", "torch", ".", "Tensor", "(", "[", "x1", ",", "y1", ",", "x2", "-", "x1", ",", "y2", "-", "y1", "]", ")", "\n", "\n", "if", "mask", "is", "None", ":", "\n", "        ", "return", "im_out", ",", "crop_box", "\n", "", "else", ":", "\n", "        ", "return", "im_out", ",", "crop_box", ",", "mask_out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target_from_crop_region": [[241, 277], ["isinstance", "torch.Tensor", "torch.Tensor", "crop_box.int.int", "crop_box.int.tolist", "max", "max", "max", "max", "cv2.copyMakeBorder", "cv2.resize", "tuple", "torch.Tensor.long().tolist", "torch.Tensor.long"], "function", ["None"], ["", "", "def", "sample_target_from_crop_region", "(", "im", ",", "crop_box", ",", "output_sz", ")", ":", "\n", "    ", "\"\"\" Extracts a crop of the image according to the crop box with the specified output size.\n\n        args:\n            im - Input numpy image to crop.\n            crop_box - crop box [x, y, w, h]\n            output_sz - Size to which the extracted crop is resized (always square) or tuple.\n\n        returns:\n            numpy image - Extracted crop.\n    \"\"\"", "\n", "if", "isinstance", "(", "output_sz", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "        ", "output_sz", "=", "(", "output_sz", ",", "output_sz", ")", "\n", "", "output_sz", "=", "torch", ".", "Tensor", "(", "output_sz", ")", "\n", "\n", "crop_box", "=", "crop_box", ".", "int", "(", ")", "\n", "x1", ",", "y1", ",", "w1", ",", "h1", "=", "crop_box", ".", "tolist", "(", ")", "\n", "x2", "=", "x1", "+", "w1", "\n", "y2", "=", "y1", "+", "h1", "\n", "\n", "x1_pad", "=", "max", "(", "0", ",", "-", "x1", ")", "\n", "x2_pad", "=", "max", "(", "x2", "-", "im", ".", "shape", "[", "1", "]", "+", "1", ",", "0", ")", "\n", "\n", "y1_pad", "=", "max", "(", "0", ",", "-", "y1", ")", "\n", "y2_pad", "=", "max", "(", "y2", "-", "im", ".", "shape", "[", "0", "]", "+", "1", ",", "0", ")", "\n", "\n", "# Crop target", "\n", "im_crop", "=", "im", "[", "y1", "+", "y1_pad", ":", "y2", "-", "y2_pad", ",", "x1", "+", "x1_pad", ":", "x2", "-", "x2_pad", ",", ":", "]", "\n", "\n", "# Pad", "\n", "im_crop_padded", "=", "cv", ".", "copyMakeBorder", "(", "im_crop", ",", "y1_pad", ",", "y2_pad", ",", "x1_pad", ",", "x2_pad", ",", "cv", ".", "BORDER_REPLICATE", ")", "\n", "\n", "# Resize image", "\n", "im_out", "=", "cv", ".", "resize", "(", "im_crop_padded", ",", "tuple", "(", "output_sz", ".", "long", "(", ")", ".", "tolist", "(", ")", ")", ")", "\n", "\n", "return", "im_out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.crop_and_resize": [[279, 335], ["isinstance", "max", "max", "max", "max", "cv2.copyMakeBorder", "cv2.resize", "Exception", "torch.pad", "box.clone", "torch.interpolate"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.layers.transform.interpolate"], ["", "def", "crop_and_resize", "(", "im", ",", "box", ",", "crop_bb", ",", "output_sz", ",", "mask", "=", "None", ")", ":", "\n", "    ", "if", "isinstance", "(", "output_sz", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "        ", "output_sz", "=", "(", "output_sz", ",", "output_sz", ")", "\n", "\n", "", "im_h", "=", "im", ".", "shape", "[", "0", "]", "\n", "im_w", "=", "im", ".", "shape", "[", "1", "]", "\n", "\n", "if", "crop_bb", "[", "2", "]", "<", "1", "or", "crop_bb", "[", "3", "]", "<", "1", ":", "\n", "        ", "raise", "Exception", "(", "'Too small bounding box.'", ")", "\n", "\n", "", "x1", "=", "crop_bb", "[", "0", "]", "\n", "x2", "=", "crop_bb", "[", "0", "]", "+", "crop_bb", "[", "2", "]", "\n", "\n", "y1", "=", "crop_bb", "[", "1", "]", "\n", "y2", "=", "crop_bb", "[", "1", "]", "+", "crop_bb", "[", "3", "]", "\n", "\n", "x1_pad", "=", "max", "(", "0", ",", "-", "x1", ")", "\n", "x2_pad", "=", "max", "(", "x2", "-", "im", ".", "shape", "[", "1", "]", "+", "1", ",", "0", ")", "\n", "\n", "y1_pad", "=", "max", "(", "0", ",", "-", "y1", ")", "\n", "y2_pad", "=", "max", "(", "y2", "-", "im", ".", "shape", "[", "0", "]", "+", "1", ",", "0", ")", "\n", "\n", "# Crop target", "\n", "im_crop", "=", "im", "[", "y1", "+", "y1_pad", ":", "y2", "-", "y2_pad", ",", "x1", "+", "x1_pad", ":", "x2", "-", "x2_pad", ",", ":", "]", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "mask_crop", "=", "mask", "[", "y1", "+", "y1_pad", ":", "y2", "-", "y2_pad", ",", "x1", "+", "x1_pad", ":", "x2", "-", "x2_pad", "]", "\n", "\n", "# Pad", "\n", "", "im_crop_padded", "=", "cv", ".", "copyMakeBorder", "(", "im_crop", ",", "y1_pad", ",", "y2_pad", ",", "x1_pad", ",", "x2_pad", ",", "cv", ".", "BORDER_REPLICATE", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "mask_crop_padded", "=", "F", ".", "pad", "(", "mask_crop", ",", "pad", "=", "(", "x1_pad", ",", "x2_pad", ",", "y1_pad", ",", "y2_pad", ")", ",", "mode", "=", "'constant'", ",", "value", "=", "0", ")", "\n", "\n", "# Resize image", "\n", "", "im_out", "=", "cv", ".", "resize", "(", "im_crop_padded", ",", "output_sz", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "mask_out", "=", "F", ".", "interpolate", "(", "mask_crop_padded", "[", "None", ",", "None", "]", ",", "(", "output_sz", "[", "1", "]", ",", "output_sz", "[", "0", "]", ")", ",", "mode", "=", "'nearest'", ")", "[", "0", ",", "0", "]", "\n", "\n", "", "rescale_factor", "=", "output_sz", "[", "0", "]", "/", "crop_bb", "[", "2", "]", "\n", "\n", "# Hack", "\n", "if", "box", "is", "not", "None", ":", "\n", "        ", "box_crop", "=", "box", ".", "clone", "(", ")", "\n", "box_crop", "[", "0", "]", "-=", "crop_bb", "[", "0", "]", "\n", "box_crop", "[", "1", "]", "-=", "crop_bb", "[", "1", "]", "\n", "\n", "box_crop", "*=", "rescale_factor", "\n", "", "else", ":", "\n", "        ", "box_crop", "=", "None", "\n", "\n", "", "if", "mask", "is", "None", ":", "\n", "        ", "return", "im_out", ",", "box_crop", "\n", "", "else", ":", "\n", "        ", "return", "im_out", ",", "box_crop", ",", "mask_out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.transform_box_to_crop": [[337, 356], ["box.clone"], "function", ["None"], ["", "", "def", "transform_box_to_crop", "(", "box", ":", "torch", ".", "Tensor", ",", "crop_box", ":", "torch", ".", "Tensor", ",", "crop_sz", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\" Transform the box co-ordinates from the original image co-ordinates to the co-ordinates of the cropped image\n    args:\n        box - the box for which the co-ordinates are to be transformed\n        crop_box - bounding box defining the crop in the original image\n        crop_sz - size of the cropped image\n\n    returns:\n        torch.Tensor - transformed co-ordinates of box_in\n    \"\"\"", "\n", "\n", "box_out", "=", "box", ".", "clone", "(", ")", "\n", "box_out", "[", ":", "2", "]", "-=", "crop_box", "[", ":", "2", "]", "\n", "\n", "scale_factor", "=", "crop_sz", "/", "crop_box", "[", "2", ":", "]", "\n", "\n", "box_out", "[", ":", "2", "]", "*=", "scale_factor", "\n", "box_out", "[", "2", ":", "]", "*=", "scale_factor", "\n", "return", "box_out", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.target_image_crop": [[358, 408], ["isinstance", "torch.Tensor", "torch.Tensor", "zip", "zip", "processing_utils.transform_box_to_crop", "processing_utils.sample_target_adaptive", "processing_utils.sample_target_adaptive", "zip", "zip", "zip"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.transform_box_to_crop", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target_adaptive", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_target_adaptive"], ["", "def", "target_image_crop", "(", "frames", ",", "box_extract", ",", "box_gt", ",", "search_area_factor", ",", "output_sz", ",", "mode", ":", "str", "=", "'replicate'", ",", "\n", "max_scale_change", "=", "None", ",", "masks", "=", "None", ")", ":", "\n", "    ", "\"\"\" For each frame in frames, extracts a square crop centered at box_extract, of area search_area_factor^2\n    times box_extract area. If the crop area contains regions outside the image, it is shifted / shrunk so that it\n    completely fits inside the image. The extracted crops are then resized to output_sz. Further, the co-ordinates of\n    the box box_gt are transformed to the image crop co-ordinates\n\n    args:\n        frames - list of frames\n        box_extract - list of boxes of same length as frames. The crops are extracted using anno_extract\n        box_gt - list of boxes of same length as frames. The co-ordinates of these boxes are transformed from\n                    image co-ordinates to the crop co-ordinates\n        search_area_factor - The area of the extracted crop is search_area_factor^2 times box_extract area\n        output_sz - The size to which the extracted crops are resized\n        mode - If 'replicate', the boundary pixels are replicated in case the search region crop goes out of image.\n               If 'inside', the search region crop is shifted/shrunk to fit completely inside the image.\n               If 'inside_major', the search region crop is shifted/shrunk to fit completely inside one axis of the image.\n        max_scale_change - Maximum allowed scale change when performing the crop (only applicable for 'inside' and 'inside_major')\n        masks - Optional masks to apply the same crop.\n\n    returns:\n        list - list of image crops\n        list - box_gt location in the crop co-ordinates\n        \"\"\"", "\n", "\n", "if", "isinstance", "(", "output_sz", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "        ", "output_sz", "=", "(", "output_sz", ",", "output_sz", ")", "\n", "\n", "", "if", "masks", "is", "None", ":", "\n", "        ", "frame_crops_boxes", "=", "[", "sample_target_adaptive", "(", "f", ",", "a", ",", "search_area_factor", ",", "output_sz", ",", "mode", ",", "max_scale_change", ")", "\n", "for", "f", ",", "a", "in", "zip", "(", "frames", ",", "box_extract", ")", "]", "\n", "\n", "frames_crop", ",", "crop_boxes", "=", "zip", "(", "*", "frame_crops_boxes", ")", "\n", "", "else", ":", "\n", "        ", "frame_crops_boxes_masks", "=", "[", "\n", "sample_target_adaptive", "(", "f", ",", "a", ",", "search_area_factor", ",", "output_sz", ",", "mode", ",", "max_scale_change", ",", "mask", "=", "m", ")", "\n", "for", "f", ",", "a", ",", "m", "in", "zip", "(", "frames", ",", "box_extract", ",", "masks", ")", "]", "\n", "\n", "frames_crop", ",", "crop_boxes", ",", "masks_crop", "=", "zip", "(", "*", "frame_crops_boxes_masks", ")", "\n", "\n", "", "crop_sz", "=", "torch", ".", "Tensor", "(", "output_sz", ")", "\n", "\n", "# find the bb location in the crop", "\n", "box_crop", "=", "[", "transform_box_to_crop", "(", "bb_gt", ",", "crop_bb", ",", "crop_sz", ")", "\n", "for", "bb_gt", ",", "crop_bb", "in", "zip", "(", "box_gt", ",", "crop_boxes", ")", "]", "\n", "\n", "if", "masks", "is", "None", ":", "\n", "        ", "return", "frames_crop", ",", "box_crop", "\n", "", "else", ":", "\n", "        ", "return", "frames_crop", ",", "box_crop", ",", "masks_crop", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.iou": [[410, 431], ["torch.max", "torch.max", "torch.min", "torch.min", "sz.prod", "reference[].prod", "proposals[].prod"], "function", ["None"], ["", "", "def", "iou", "(", "reference", ",", "proposals", ")", ":", "\n", "    ", "\"\"\"Compute the IoU between a reference box with multiple proposal boxes.\n\n    args:\n        reference - Tensor of shape (1, 4).\n        proposals - Tensor of shape (num_proposals, 4)\n\n    returns:\n        torch.Tensor - Tensor of shape (num_proposals,) containing IoU of reference box with each proposal box.\n    \"\"\"", "\n", "\n", "# Intersection box", "\n", "tl", "=", "torch", ".", "max", "(", "reference", "[", ":", ",", ":", "2", "]", ",", "proposals", "[", ":", ",", ":", "2", "]", ")", "\n", "br", "=", "torch", ".", "min", "(", "reference", "[", ":", ",", ":", "2", "]", "+", "reference", "[", ":", ",", "2", ":", "]", ",", "proposals", "[", ":", ",", ":", "2", "]", "+", "proposals", "[", ":", ",", "2", ":", "]", ")", "\n", "sz", "=", "(", "br", "-", "tl", ")", ".", "clamp", "(", "0", ")", "\n", "\n", "# Area", "\n", "intersection", "=", "sz", ".", "prod", "(", "dim", "=", "1", ")", "\n", "union", "=", "reference", "[", ":", ",", "2", ":", "]", ".", "prod", "(", "dim", "=", "1", ")", "+", "proposals", "[", ":", ",", "2", ":", "]", ".", "prod", "(", "dim", "=", "1", ")", "-", "intersection", "\n", "\n", "return", "intersection", "/", "union", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.rand_uniform": [[433, 444], ["torch.rand", "torch.rand"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand", "home.repos.pwc.inspect_result.visionml_pytracking.kys.utils.DiMPScoreJittering.rand"], ["", "def", "rand_uniform", "(", "a", ",", "b", ",", "shape", "=", "1", ")", ":", "\n", "    ", "\"\"\" sample numbers uniformly between a and b.\n    args:\n        a - lower bound\n        b - upper bound\n        shape - shape of the output tensor\n\n    returns:\n        torch.Tensor - tensor of shape=shape\n    \"\"\"", "\n", "return", "(", "b", "-", "a", ")", "*", "torch", ".", "rand", "(", "shape", ")", "+", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.perturb_box": [[446, 506], ["isinstance", "range", "random.choice", "isinstance", "torch.sqrt", "torch.sqrt", "random.gauss", "random.gauss", "random.gauss", "random.gauss", "torch.Tensor().round", "torch.Tensor().round", "processing_utils.iou", "torch.ones", "torch.ones", "box.view", "torch.Tensor().round.view", "processing_utils.rand_uniform", "processing_utils.rand_uniform", "torch.Tensor", "torch.Tensor", "processing_utils.rand_uniform", "processing_utils.rand_uniform"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.iou", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.rand_uniform", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.rand_uniform", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.rand_uniform", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.rand_uniform"], ["", "def", "perturb_box", "(", "box", ",", "min_iou", "=", "0.5", ",", "sigma_factor", "=", "0.1", ")", ":", "\n", "    ", "\"\"\" Perturb the input box by adding gaussian noise to the co-ordinates\n\n     args:\n        box - input box\n        min_iou - minimum IoU overlap between input box and the perturbed box\n        sigma_factor - amount of perturbation, relative to the box size. Can be either a single element, or a list of\n                        sigma_factors, in which case one of them will be uniformly sampled. Further, each of the\n                        sigma_factor element can be either a float, or a tensor\n                        of shape (4,) specifying the sigma_factor per co-ordinate\n\n    returns:\n        torch.Tensor - the perturbed box\n    \"\"\"", "\n", "\n", "if", "isinstance", "(", "sigma_factor", ",", "list", ")", ":", "\n", "# If list, sample one sigma_factor as current sigma factor", "\n", "        ", "c_sigma_factor", "=", "random", ".", "choice", "(", "sigma_factor", ")", "\n", "", "else", ":", "\n", "        ", "c_sigma_factor", "=", "sigma_factor", "\n", "\n", "", "if", "not", "isinstance", "(", "c_sigma_factor", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "c_sigma_factor", "=", "c_sigma_factor", "*", "torch", ".", "ones", "(", "4", ")", "\n", "\n", "", "perturb_factor", "=", "torch", ".", "sqrt", "(", "box", "[", "2", "]", "*", "box", "[", "3", "]", ")", "*", "c_sigma_factor", "\n", "\n", "# multiple tries to ensure that the perturbed box has iou > min_iou with the input box", "\n", "for", "i_", "in", "range", "(", "100", ")", ":", "\n", "        ", "c_x", "=", "box", "[", "0", "]", "+", "0.5", "*", "box", "[", "2", "]", "\n", "c_y", "=", "box", "[", "1", "]", "+", "0.5", "*", "box", "[", "3", "]", "\n", "c_x_per", "=", "random", ".", "gauss", "(", "c_x", ",", "perturb_factor", "[", "0", "]", ")", "\n", "c_y_per", "=", "random", ".", "gauss", "(", "c_y", ",", "perturb_factor", "[", "1", "]", ")", "\n", "\n", "w_per", "=", "random", ".", "gauss", "(", "box", "[", "2", "]", ",", "perturb_factor", "[", "2", "]", ")", "\n", "h_per", "=", "random", ".", "gauss", "(", "box", "[", "3", "]", ",", "perturb_factor", "[", "3", "]", ")", "\n", "\n", "if", "w_per", "<=", "1", ":", "\n", "            ", "w_per", "=", "box", "[", "2", "]", "*", "rand_uniform", "(", "0.15", ",", "0.5", ")", "\n", "\n", "", "if", "h_per", "<=", "1", ":", "\n", "            ", "h_per", "=", "box", "[", "3", "]", "*", "rand_uniform", "(", "0.15", ",", "0.5", ")", "\n", "\n", "", "box_per", "=", "torch", ".", "Tensor", "(", "[", "c_x_per", "-", "0.5", "*", "w_per", ",", "c_y_per", "-", "0.5", "*", "h_per", ",", "w_per", ",", "h_per", "]", ")", ".", "round", "(", ")", "\n", "\n", "if", "box_per", "[", "2", "]", "<=", "1", ":", "\n", "            ", "box_per", "[", "2", "]", "=", "box", "[", "2", "]", "*", "rand_uniform", "(", "0.15", ",", "0.5", ")", "\n", "\n", "", "if", "box_per", "[", "3", "]", "<=", "1", ":", "\n", "            ", "box_per", "[", "3", "]", "=", "box", "[", "3", "]", "*", "rand_uniform", "(", "0.15", ",", "0.5", ")", "\n", "\n", "", "box_iou", "=", "iou", "(", "box", ".", "view", "(", "1", ",", "4", ")", ",", "box_per", ".", "view", "(", "1", ",", "4", ")", ")", "\n", "\n", "# if there is sufficient overlap, return", "\n", "if", "box_iou", ">", "min_iou", ":", "\n", "            ", "return", "box_per", ",", "box_iou", "\n", "\n", "# else reduce the perturb factor", "\n", "", "perturb_factor", "*=", "0.9", "\n", "\n", "", "return", "box_per", ",", "box_iou", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gauss_1d": [[508, 514], ["torch.arange().reshape", "torch.arange().reshape", "torch.exp", "torch.exp", "torch.arange", "torch.arange", "math.sqrt", "center.reshape"], "function", ["None"], ["", "def", "gauss_1d", "(", "sz", ",", "sigma", ",", "center", ",", "end_pad", "=", "0", ",", "density", "=", "False", ")", ":", "\n", "    ", "k", "=", "torch", ".", "arange", "(", "-", "(", "sz", "-", "1", ")", "/", "2", ",", "(", "sz", "+", "1", ")", "/", "2", "+", "end_pad", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "gauss", "=", "torch", ".", "exp", "(", "-", "1.0", "/", "(", "2", "*", "sigma", "**", "2", ")", "*", "(", "k", "-", "center", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", "**", "2", ")", "\n", "if", "density", ":", "\n", "        ", "gauss", "/=", "math", ".", "sqrt", "(", "2", "*", "math", ".", "pi", ")", "*", "sigma", "\n", "", "return", "gauss", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gauss_2d": [[516, 521], ["isinstance", "gauss_1d().reshape", "gauss_1d().reshape", "processing_utils.gauss_1d", "processing_utils.gauss_1d", "sz[].item", "sz[].item"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gauss_1d", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gauss_1d"], ["", "def", "gauss_2d", "(", "sz", ",", "sigma", ",", "center", ",", "end_pad", "=", "(", "0", ",", "0", ")", ",", "density", "=", "False", ")", ":", "\n", "    ", "if", "isinstance", "(", "sigma", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "        ", "sigma", "=", "(", "sigma", ",", "sigma", ")", "\n", "", "return", "gauss_1d", "(", "sz", "[", "0", "]", ".", "item", "(", ")", ",", "sigma", "[", "0", "]", ",", "center", "[", ":", ",", "0", "]", ",", "end_pad", "[", "0", "]", ",", "density", ")", ".", "reshape", "(", "center", ".", "shape", "[", "0", "]", ",", "1", ",", "-", "1", ")", "*", "gauss_1d", "(", "sz", "[", "1", "]", ".", "item", "(", ")", ",", "sigma", "[", "1", "]", ",", "center", "[", ":", ",", "1", "]", ",", "end_pad", "[", "1", "]", ",", "density", ")", ".", "reshape", "(", "center", ".", "shape", "[", "0", "]", ",", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gaussian_label_function": [[523, 557], ["isinstance", "isinstance", "isinstance", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "processing_utils.gauss_2d", "torch.Tensor.prod().sqrt().item", "torch.Tensor", "torch.Tensor", "int", "int", "torch.Tensor.prod().sqrt", "torch.Tensor", "torch.Tensor", "torch.Tensor.prod"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gauss_2d"], ["", "def", "gaussian_label_function", "(", "target_bb", ",", "sigma_factor", ",", "kernel_sz", ",", "feat_sz", ",", "image_sz", ",", "end_pad_if_even", "=", "True", ",", "density", "=", "False", ",", "\n", "uni_bias", "=", "0", ")", ":", "\n", "    ", "\"\"\"Construct Gaussian label function.\"\"\"", "\n", "\n", "if", "isinstance", "(", "kernel_sz", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "        ", "kernel_sz", "=", "(", "kernel_sz", ",", "kernel_sz", ")", "\n", "", "if", "isinstance", "(", "feat_sz", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "        ", "feat_sz", "=", "(", "feat_sz", ",", "feat_sz", ")", "\n", "", "if", "isinstance", "(", "image_sz", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "        ", "image_sz", "=", "(", "image_sz", ",", "image_sz", ")", "\n", "\n", "", "image_sz", "=", "torch", ".", "Tensor", "(", "image_sz", ")", "\n", "feat_sz", "=", "torch", ".", "Tensor", "(", "feat_sz", ")", "\n", "\n", "target_center", "=", "target_bb", "[", ":", ",", "0", ":", "2", "]", "+", "0.5", "*", "target_bb", "[", ":", ",", "2", ":", "4", "]", "\n", "target_center_norm", "=", "(", "target_center", "-", "image_sz", "/", "2", ")", "/", "image_sz", "\n", "\n", "center", "=", "feat_sz", "*", "target_center_norm", "+", "0.5", "*", "torch", ".", "Tensor", "(", "[", "(", "kernel_sz", "[", "0", "]", "+", "1", ")", "%", "2", ",", "(", "kernel_sz", "[", "1", "]", "+", "1", ")", "%", "2", "]", ")", "\n", "\n", "sigma", "=", "sigma_factor", "*", "feat_sz", ".", "prod", "(", ")", ".", "sqrt", "(", ")", ".", "item", "(", ")", "\n", "\n", "if", "end_pad_if_even", ":", "\n", "        ", "end_pad", "=", "(", "int", "(", "kernel_sz", "[", "0", "]", "%", "2", "==", "0", ")", ",", "int", "(", "kernel_sz", "[", "1", "]", "%", "2", "==", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "end_pad", "=", "(", "0", ",", "0", ")", "\n", "\n", "", "gauss_label", "=", "gauss_2d", "(", "feat_sz", ",", "sigma", ",", "center", ",", "end_pad", ",", "density", "=", "density", ")", "\n", "if", "density", ":", "\n", "        ", "sz", "=", "(", "feat_sz", "+", "torch", ".", "Tensor", "(", "end_pad", ")", ")", ".", "prod", "(", ")", "\n", "label", "=", "(", "1.0", "-", "uni_bias", ")", "*", "gauss_label", "+", "uni_bias", "/", "sz", "\n", "", "else", ":", "\n", "        ", "label", "=", "gauss_label", "+", "uni_bias", "\n", "", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gauss_density_centered": [[559, 566], ["torch.exp", "torch.exp", "math.sqrt"], "function", ["None"], ["", "def", "gauss_density_centered", "(", "x", ",", "std", ")", ":", "\n", "    ", "\"\"\"Evaluate the probability density of a Gaussian centered at zero.\n    args:\n        x - Samples.\n        std - List of standard deviations\n    \"\"\"", "\n", "return", "torch", ".", "exp", "(", "-", "0.5", "*", "(", "x", "/", "std", ")", "**", "2", ")", "/", "(", "math", ".", "sqrt", "(", "2", "*", "math", ".", "pi", ")", "*", "std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gmm_density_centered": [[568, 579], ["gauss_density_centered().prod().mean", "x.unsqueeze.dim", "x.unsqueeze.unsqueeze", "std.dim", "ValueError", "gauss_density_centered().prod", "x.unsqueeze.dim", "std.dim", "processing_utils.gauss_density_centered"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.loss.lovasz_loss.mean", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gauss_density_centered"], ["", "def", "gmm_density_centered", "(", "x", ",", "std", ")", ":", "\n", "    ", "\"\"\"Evaluate the probability density of a GMM centered at zero.\n    args:\n        x - Samples. Assumes dim=-1 is the component dimension and dim=-2 is feature dimension. Rest are sample dimension.\n        std - Tensor of standard deviations\n    \"\"\"", "\n", "if", "x", ".", "dim", "(", ")", "==", "std", ".", "dim", "(", ")", "-", "1", ":", "\n", "        ", "x", "=", "x", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "elif", "not", "(", "x", ".", "dim", "(", ")", "==", "std", ".", "dim", "(", ")", "and", "x", ".", "shape", "[", "-", "1", "]", "==", "1", ")", ":", "\n", "        ", "raise", "ValueError", "(", "'Last dimension must be the gmm stds.'", ")", "\n", "", "return", "gauss_density_centered", "(", "x", ",", "std", ")", ".", "prod", "(", "-", "2", ")", ".", "mean", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_gmm_centered": [[581, 601], ["std.view.view", "torch.randint", "torch.randint", "std[].t", "processing_utils.gmm_density_centered", "std.view.numel", "torch.randn", "torch.randn"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gmm_density_centered"], ["", "def", "sample_gmm_centered", "(", "std", ",", "num_samples", "=", "1", ")", ":", "\n", "    ", "\"\"\"Sample from a GMM distribution centered at zero:\n    args:\n        std - Tensor of standard deviations\n        num_samples - number of samples\n    \"\"\"", "\n", "num_components", "=", "std", ".", "shape", "[", "-", "1", "]", "\n", "num_dims", "=", "std", ".", "numel", "(", ")", "//", "num_components", "\n", "\n", "std", "=", "std", ".", "view", "(", "1", ",", "num_dims", ",", "num_components", ")", "\n", "\n", "# Sample component ids", "\n", "k", "=", "torch", ".", "randint", "(", "num_components", ",", "(", "num_samples", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "std_samp", "=", "std", "[", "0", ",", ":", ",", "k", "]", ".", "t", "(", ")", "\n", "\n", "# Sample", "\n", "x_centered", "=", "std_samp", "*", "torch", ".", "randn", "(", "num_samples", ",", "num_dims", ")", "\n", "prob_dens", "=", "gmm_density_centered", "(", "x_centered", ",", "std", ")", "\n", "\n", "return", "x_centered", ",", "prob_dens", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_gmm": [[603, 626], ["mean.view.numel", "mean.view.view", "std.view.view", "torch.randint", "torch.randint", "std[].t", "processing_utils.gmm_density_centered", "torch.randn", "torch.randn"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gmm_density_centered"], ["", "def", "sample_gmm", "(", "mean", ",", "std", ",", "num_samples", "=", "1", ")", ":", "\n", "    ", "\"\"\"Sample from a GMM distribution:\n    args:\n        mean - a single mean vector\n        std - Tensor of standard deviations\n        num_samples - number of samples\n    \"\"\"", "\n", "num_dims", "=", "mean", ".", "numel", "(", ")", "\n", "num_components", "=", "std", ".", "shape", "[", "-", "1", "]", "\n", "\n", "mean", "=", "mean", ".", "view", "(", "1", ",", "num_dims", ")", "\n", "std", "=", "std", ".", "view", "(", "1", ",", "-", "1", ",", "num_components", ")", "\n", "\n", "# Sample component ids", "\n", "k", "=", "torch", ".", "randint", "(", "num_components", ",", "(", "num_samples", ",", ")", ",", "dtype", "=", "torch", ".", "int64", ")", "\n", "std_samp", "=", "std", "[", "0", ",", ":", ",", "k", "]", ".", "t", "(", ")", "\n", "\n", "# Sample", "\n", "x_centered", "=", "std_samp", "*", "torch", ".", "randn", "(", "num_samples", ",", "num_dims", ")", "\n", "x", "=", "x_centered", "+", "mean", "\n", "prob_dens", "=", "gmm_density_centered", "(", "x_centered", ",", "std", ")", "\n", "\n", "return", "x", ",", "prob_dens", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_box_gmm": [[628, 667], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.stack", "torch.stack", "mean_box.view.view", "mean_box[].clone", "processing_utils.sample_gmm_centered", "bounding_box_utils.rect_to_rel", "bounding_box_utils.rel_to_rect", "torch.zeros_like", "torch.zeros_like", "torch.Tensor().view", "torch.Tensor().view", "gauss_density_centered().prod", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "processing_utils.gauss_density_centered", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.sample_gmm_centered", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rect_to_rel", "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect", "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.gauss_density_centered"], ["", "def", "sample_box_gmm", "(", "mean_box", ",", "proposal_sigma", ",", "gt_sigma", "=", "None", ",", "num_samples", "=", "1", ",", "add_mean_box", "=", "False", ")", ":", "\n", "    ", "\"\"\"Sample boxes from a Gaussian mixture model.\n    args:\n        mean_box - Center (or mean) bounding box\n        proposal_sigma - List of standard deviations for each Gaussian\n        gt_sigma - Standard deviation of the ground truth distribution\n        num_samples - Number of sampled boxes\n        add_mean_box - Also add mean box as first element\n\n    returns:\n        proposals, proposal density and ground truth density for all samples\n    \"\"\"", "\n", "center_std", "=", "torch", ".", "Tensor", "(", "[", "s", "[", "0", "]", "for", "s", "in", "proposal_sigma", "]", ")", "\n", "sz_std", "=", "torch", ".", "Tensor", "(", "[", "s", "[", "1", "]", "for", "s", "in", "proposal_sigma", "]", ")", "\n", "std", "=", "torch", ".", "stack", "(", "[", "center_std", ",", "center_std", ",", "sz_std", ",", "sz_std", "]", ")", "\n", "\n", "mean_box", "=", "mean_box", ".", "view", "(", "1", ",", "4", ")", "\n", "sz_norm", "=", "mean_box", "[", ":", ",", "2", ":", "]", ".", "clone", "(", ")", "\n", "\n", "# Sample boxes", "\n", "proposals_rel_centered", ",", "proposal_density", "=", "sample_gmm_centered", "(", "std", ",", "num_samples", ")", "\n", "\n", "# Add mean and map back", "\n", "mean_box_rel", "=", "rect_to_rel", "(", "mean_box", ",", "sz_norm", ")", "\n", "proposals_rel", "=", "proposals_rel_centered", "+", "mean_box_rel", "\n", "proposals", "=", "rel_to_rect", "(", "proposals_rel", ",", "sz_norm", ")", "\n", "\n", "if", "gt_sigma", "is", "None", "or", "gt_sigma", "[", "0", "]", "==", "0", "and", "gt_sigma", "[", "1", "]", "==", "0", ":", "\n", "        ", "gt_density", "=", "torch", ".", "zeros_like", "(", "proposal_density", ")", "\n", "", "else", ":", "\n", "        ", "std_gt", "=", "torch", ".", "Tensor", "(", "[", "gt_sigma", "[", "0", "]", ",", "gt_sigma", "[", "0", "]", ",", "gt_sigma", "[", "1", "]", ",", "gt_sigma", "[", "1", "]", "]", ")", ".", "view", "(", "1", ",", "4", ")", "\n", "gt_density", "=", "gauss_density_centered", "(", "proposals_rel_centered", ",", "std_gt", ")", ".", "prod", "(", "-", "1", ")", "\n", "\n", "", "if", "add_mean_box", ":", "\n", "        ", "proposals", "=", "torch", ".", "cat", "(", "(", "mean_box", ",", "proposals", ")", ")", "\n", "proposal_density", "=", "torch", ".", "cat", "(", "(", "torch", ".", "Tensor", "(", "[", "-", "1", "]", ")", ",", "proposal_density", ")", ")", "\n", "gt_density", "=", "torch", ".", "cat", "(", "(", "torch", ".", "Tensor", "(", "[", "1", "]", ")", ",", "gt_density", ")", ")", "\n", "\n", "", "return", "proposals", ",", "proposal_density", ",", "gt_density", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.processing_utils.find_local_maxima": [[669, 707], ["torch.max_pool2d", "torch.nonzero", "torch.nonzero", "torch.argsort", "torch.argsort", "scores.view.view", "range", "pytracking.TensorList", "pytracking.TensorList", "coords_batch.append", "intensities_batch.append"], "function", ["None"], ["", "def", "find_local_maxima", "(", "scores", ",", "th", ",", "ks", ")", ":", "\n", "    ", "\"\"\"Find local maxima in a heat map.\n        args:\n            scores - heat map to find the local maxima in.\n            th - threshold that defines the minamal value needed to be considered as a local maximum.\n            ks = local neighbourhood (kernel size) specifiying the minimal distance between two maxima.\n\n        returns:\n            coordinates and values of the local maxima.\n    \"\"\"", "\n", "ndims", "=", "scores", ".", "ndim", "\n", "\n", "if", "ndims", "==", "2", ":", "\n", "        ", "scores", "=", "scores", ".", "view", "(", "1", ",", "1", ",", "scores", ".", "shape", "[", "0", "]", ",", "scores", ".", "shape", "[", "1", "]", ")", "\n", "\n", "", "scores_max", "=", "F", ".", "max_pool2d", "(", "scores", ",", "kernel_size", "=", "ks", ",", "stride", "=", "1", ",", "padding", "=", "ks", "//", "2", ")", "\n", "\n", "peak_mask", "=", "(", "scores", "==", "scores_max", ")", "&", "(", "scores", ">", "th", ")", "\n", "coords", "=", "torch", ".", "nonzero", "(", "peak_mask", ")", "\n", "intensities", "=", "scores", "[", "peak_mask", "]", "\n", "\n", "# Highest peak first", "\n", "idx_maxsort", "=", "torch", ".", "argsort", "(", "-", "intensities", ")", "\n", "coords", "=", "coords", "[", "idx_maxsort", "]", "\n", "intensities", "=", "intensities", "[", "idx_maxsort", "]", "\n", "\n", "if", "ndims", "==", "4", ":", "\n", "\n", "        ", "coords_batch", ",", "intensities_batch", ",", "=", "TensorList", "(", ")", ",", "TensorList", "(", ")", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "mask", "=", "(", "coords", "[", ":", ",", "0", "]", "==", "i", ")", "\n", "coords_batch", ".", "append", "(", "coords", "[", "mask", ",", "2", ":", "]", ")", "\n", "intensities_batch", ".", "append", "(", "intensities", "[", "mask", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "coords_batch", "=", "coords", "[", ":", ",", "2", ":", "]", "\n", "intensities_batch", "=", "intensities", "\n", "\n", "", "return", "coords_batch", ",", "intensities_batch", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rect_to_rel": [[4, 19], ["torch.log", "torch.cat"], "function", ["None"], ["def", "rect_to_rel", "(", "bb", ",", "sz_norm", "=", "None", ")", ":", "\n", "    ", "\"\"\"Convert standard rectangular parametrization of the bounding box [x, y, w, h]\n    to relative parametrization [cx/sw, cy/sh, log(w), log(h)], where [cx, cy] is the center coordinate.\n    args:\n        bb  -  N x 4 tensor of boxes.\n        sz_norm  -  [N] x 2 tensor of value of [sw, sh] (optional). sw=w and sh=h if not given.\n    \"\"\"", "\n", "\n", "c", "=", "bb", "[", "...", ",", ":", "2", "]", "+", "0.5", "*", "bb", "[", "...", ",", "2", ":", "]", "\n", "if", "sz_norm", "is", "None", ":", "\n", "        ", "c_rel", "=", "c", "/", "bb", "[", "...", ",", "2", ":", "]", "\n", "", "else", ":", "\n", "        ", "c_rel", "=", "c", "/", "sz_norm", "\n", "", "sz_rel", "=", "torch", ".", "log", "(", "bb", "[", "...", ",", "2", ":", "]", ")", "\n", "return", "torch", ".", "cat", "(", "(", "c_rel", ",", "sz_rel", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.rel_to_rect": [[21, 31], ["torch.exp", "torch.cat"], "function", ["None"], ["", "def", "rel_to_rect", "(", "bb", ",", "sz_norm", "=", "None", ")", ":", "\n", "    ", "\"\"\"Inverts the effect of rect_to_rel. See above.\"\"\"", "\n", "\n", "sz", "=", "torch", ".", "exp", "(", "bb", "[", "...", ",", "2", ":", "]", ")", "\n", "if", "sz_norm", "is", "None", ":", "\n", "        ", "c", "=", "bb", "[", "...", ",", ":", "2", "]", "*", "sz", "\n", "", "else", ":", "\n", "        ", "c", "=", "bb", "[", "...", ",", ":", "2", "]", "*", "sz_norm", "\n", "", "tl", "=", "c", "-", "0.5", "*", "sz", "\n", "return", "torch", ".", "cat", "(", "(", "tl", ",", "sz", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.masks_to_bboxes": [[33, 68], ["mask.reshape.reshape", "torch.tensor", "bboxes.reshape.reshape", "ValueError", "m.sum().nonzero", "m.sum().nonzero", "bboxes.reshape.append", "torch.cat", "torch.cat", "m.sum", "m.sum", "m.sum().nonzero.min", "m.sum().nonzero.min", "m.sum().nonzero.max", "m.sum().nonzero.max", "len", "len"], "function", ["None"], ["", "def", "masks_to_bboxes", "(", "mask", ",", "fmt", "=", "'c'", ")", ":", "\n", "\n", "    ", "\"\"\" Convert a mask tensor to one or more bounding boxes.\n    Note: This function is a bit new, make sure it does what it says.  /Andreas\n    :param mask: Tensor of masks, shape = (..., H, W)\n    :param fmt: bbox layout. 'c' => \"center + size\" or (x_center, y_center, width, height)\n                             't' => \"top left + size\" or (x_left, y_top, width, height)\n                             'v' => \"vertices\" or (x_left, y_top, x_right, y_bottom)\n    :return: tensor containing a batch of bounding boxes, shape = (..., 4)\n    \"\"\"", "\n", "batch_shape", "=", "mask", ".", "shape", "[", ":", "-", "2", "]", "\n", "mask", "=", "mask", ".", "reshape", "(", "(", "-", "1", ",", "*", "mask", ".", "shape", "[", "-", "2", ":", "]", ")", ")", "\n", "bboxes", "=", "[", "]", "\n", "\n", "for", "m", "in", "mask", ":", "\n", "        ", "mx", "=", "m", ".", "sum", "(", "dim", "=", "-", "2", ")", ".", "nonzero", "(", ")", "\n", "my", "=", "m", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "nonzero", "(", ")", "\n", "bb", "=", "[", "mx", ".", "min", "(", ")", ",", "my", ".", "min", "(", ")", ",", "mx", ".", "max", "(", ")", ",", "my", ".", "max", "(", ")", "]", "if", "(", "len", "(", "mx", ")", ">", "0", "and", "len", "(", "my", ")", ">", "0", ")", "else", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "bboxes", ".", "append", "(", "bb", ")", "\n", "\n", "", "bboxes", "=", "torch", ".", "tensor", "(", "bboxes", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "mask", ".", "device", ")", "\n", "bboxes", "=", "bboxes", ".", "reshape", "(", "batch_shape", "+", "(", "4", ",", ")", ")", "\n", "\n", "if", "fmt", "==", "'v'", ":", "\n", "        ", "return", "bboxes", "\n", "\n", "", "x1", "=", "bboxes", "[", "...", ",", ":", "2", "]", "\n", "s", "=", "bboxes", "[", "...", ",", "2", ":", "]", "-", "x1", "+", "1", "\n", "\n", "if", "fmt", "==", "'c'", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "(", "x1", "+", "0.5", "*", "s", ",", "s", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "elif", "fmt", "==", "'t'", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "(", "x1", ",", "s", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "raise", "ValueError", "(", "\"Undefined bounding box layout '%s'\"", "%", "fmt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.bounding_box_utils.masks_to_bboxes_multi": [[70, 95], ["mask.dim", "torch.tensor", "bboxes.append", "mx.min", "my.min", "mx.max", "my.max", "torch.cat", "len", "len", "torch.cat", "ValueError"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.features.util.Concatenate.dim"], ["", "def", "masks_to_bboxes_multi", "(", "mask", ",", "ids", ",", "fmt", "=", "'c'", ")", ":", "\n", "    ", "assert", "mask", ".", "dim", "(", ")", "==", "2", "\n", "bboxes", "=", "[", "]", "\n", "\n", "for", "id", "in", "ids", ":", "\n", "        ", "mx", "=", "(", "mask", "==", "id", ")", ".", "sum", "(", "dim", "=", "-", "2", ")", ".", "nonzero", "(", ")", "\n", "my", "=", "(", "mask", "==", "id", ")", ".", "float", "(", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "nonzero", "(", ")", "\n", "bb", "=", "[", "mx", ".", "min", "(", ")", ",", "my", ".", "min", "(", ")", ",", "mx", ".", "max", "(", ")", ",", "my", ".", "max", "(", ")", "]", "if", "(", "len", "(", "mx", ")", ">", "0", "and", "len", "(", "my", ")", ">", "0", ")", "else", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "\n", "bb", "=", "torch", ".", "tensor", "(", "bb", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "mask", ".", "device", ")", "\n", "\n", "x1", "=", "bb", "[", ":", "2", "]", "\n", "s", "=", "bb", "[", "2", ":", "]", "-", "x1", "+", "1", "\n", "\n", "if", "fmt", "==", "'v'", ":", "\n", "            ", "pass", "\n", "", "elif", "fmt", "==", "'c'", ":", "\n", "            ", "bb", "=", "torch", ".", "cat", "(", "(", "x1", "+", "0.5", "*", "s", ",", "s", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "elif", "fmt", "==", "'t'", ":", "\n", "            ", "bb", "=", "torch", ".", "cat", "(", "(", "x1", ",", "s", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Undefined bounding box layout '%s'\"", "%", "fmt", ")", "\n", "", "bboxes", ".", "append", "(", "bb", ")", "\n", "\n", "", "return", "bboxes", "\n", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__": [[173, 192], ["super().__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader.LTRLoader.__init__"], ["def", "__init__", "(", "self", ",", "name", ",", "dataset", ",", "training", "=", "True", ",", "batch_size", "=", "1", ",", "shuffle", "=", "False", ",", "sampler", "=", "None", ",", "batch_sampler", "=", "None", ",", "\n", "num_workers", "=", "0", ",", "epoch_interval", "=", "1", ",", "collate_fn", "=", "None", ",", "stack_dim", "=", "0", ",", "pin_memory", "=", "False", ",", "drop_last", "=", "False", ",", "\n", "timeout", "=", "0", ",", "worker_init_fn", "=", "None", ")", ":", "\n", "        ", "if", "collate_fn", "is", "None", ":", "\n", "            ", "if", "stack_dim", "==", "0", ":", "\n", "                ", "collate_fn", "=", "ltr_collate", "\n", "", "elif", "stack_dim", "==", "1", ":", "\n", "                ", "collate_fn", "=", "ltr_collate_stack1", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Stack dim no supported. Must be 0 or 1.'", ")", "\n", "\n", "", "", "super", "(", "LTRLoader", ",", "self", ")", ".", "__init__", "(", "dataset", ",", "batch_size", ",", "shuffle", ",", "sampler", ",", "batch_sampler", ",", "\n", "num_workers", ",", "collate_fn", ",", "pin_memory", ",", "drop_last", ",", "\n", "timeout", ",", "worker_init_fn", ")", "\n", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "training", "=", "training", "\n", "self", ".", "epoch_interval", "=", "epoch_interval", "\n", "self", ".", "stack_dim", "=", "stack_dim", "\n", "", "", ""]], "home.repos.pwc.inspect_result.visionml_pytracking.data.loader._check_use_shared_memory": [[10, 17], ["hasattr", "importlib.import_module", "hasattr", "getattr", "getattr", "torch.utils.data.get_worker_info", "torch.utils.data.get_worker_info"], "function", ["None"], ["def", "_check_use_shared_memory", "(", ")", ":", "\n", "    ", "if", "hasattr", "(", "torch", ".", "utils", ".", "data", ".", "dataloader", ",", "'_use_shared_memory'", ")", ":", "\n", "        ", "return", "getattr", "(", "torch", ".", "utils", ".", "data", ".", "dataloader", ",", "'_use_shared_memory'", ")", "\n", "", "collate_lib", "=", "importlib", ".", "import_module", "(", "'torch.utils.data._utils.collate'", ")", "\n", "if", "hasattr", "(", "collate_lib", ",", "'_use_shared_memory'", ")", ":", "\n", "        ", "return", "getattr", "(", "collate_lib", ",", "'_use_shared_memory'", ")", "\n", "", "return", "torch", ".", "utils", ".", "data", ".", "get_worker_info", "(", ")", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.ltr_collate": [[19, 68], ["type", "isinstance", "TypeError", "loader._check_use_shared_memory", "torch.stack", "torch.stack", "error_msg.format", "sum", "batch[].storage()._new_shared", "batch[].new", "isinstance", "type", "torch.stack", "torch.stack", "torch.LongTensor", "torch.LongTensor", "isinstance", "x.numel", "batch[].storage", "torch.utils.data.dataloader.re.search", "torch.utils.data.dataloader.re.search", "TypeError", "elem.dtype.name.startswith", "list", "torch.DoubleTensor", "torch.DoubleTensor", "isinstance", "error_msg.format", "torch.from_numpy", "torch.from_numpy", "map", "isinstance", "pytracking.TensorDict", "isinstance", "isinstance", "loader.ltr_collate", "loader.ltr_collate", "zip", "pytracking.TensorList", "isinstance", "zip", "loader.ltr_collate", "loader.ltr_collate"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader._check_use_shared_memory", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.ltr_collate", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.ltr_collate", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.ltr_collate", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.ltr_collate"], ["", "def", "ltr_collate", "(", "batch", ")", ":", "\n", "    ", "\"\"\"Puts each data field into a tensor with outer dimension batch size\"\"\"", "\n", "\n", "error_msg", "=", "\"batch must contain tensors, numbers, dicts or lists; found {}\"", "\n", "elem_type", "=", "type", "(", "batch", "[", "0", "]", ")", "\n", "if", "isinstance", "(", "batch", "[", "0", "]", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "out", "=", "None", "\n", "if", "_check_use_shared_memory", "(", ")", ":", "\n", "# If we're in a background process, concatenate directly into a", "\n", "# shared memory tensor to avoid an extra copy", "\n", "            ", "numel", "=", "sum", "(", "[", "x", ".", "numel", "(", ")", "for", "x", "in", "batch", "]", ")", "\n", "storage", "=", "batch", "[", "0", "]", ".", "storage", "(", ")", ".", "_new_shared", "(", "numel", ")", "\n", "out", "=", "batch", "[", "0", "]", ".", "new", "(", "storage", ")", "\n", "", "return", "torch", ".", "stack", "(", "batch", ",", "0", ",", "out", "=", "out", ")", "\n", "# if batch[0].dim() < 4:", "\n", "#     return torch.stack(batch, 0, out=out)", "\n", "# return torch.cat(batch, 0, out=out)", "\n", "", "elif", "elem_type", ".", "__module__", "==", "'numpy'", "and", "elem_type", ".", "__name__", "!=", "'str_'", "and", "elem_type", ".", "__name__", "!=", "'string_'", ":", "\n", "        ", "elem", "=", "batch", "[", "0", "]", "\n", "if", "elem_type", ".", "__name__", "==", "'ndarray'", ":", "\n", "# array of string classes and object", "\n", "            ", "if", "torch", ".", "utils", ".", "data", ".", "dataloader", ".", "re", ".", "search", "(", "'[SaUO]'", ",", "elem", ".", "dtype", ".", "str", ")", "is", "not", "None", ":", "\n", "                ", "raise", "TypeError", "(", "error_msg", ".", "format", "(", "elem", ".", "dtype", ")", ")", "\n", "\n", "", "return", "torch", ".", "stack", "(", "[", "torch", ".", "from_numpy", "(", "b", ")", "for", "b", "in", "batch", "]", ",", "0", ")", "\n", "", "if", "elem", ".", "shape", "==", "(", ")", ":", "# scalars", "\n", "            ", "py_type", "=", "float", "if", "elem", ".", "dtype", ".", "name", ".", "startswith", "(", "'float'", ")", "else", "int", "\n", "return", "torch", ".", "utils", ".", "data", ".", "dataloader", ".", "numpy_type_map", "[", "elem", ".", "dtype", ".", "name", "]", "(", "list", "(", "map", "(", "py_type", ",", "batch", ")", ")", ")", "\n", "", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "int", ")", ":", "\n", "        ", "return", "torch", ".", "LongTensor", "(", "batch", ")", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "float", ")", ":", "\n", "        ", "return", "torch", ".", "DoubleTensor", "(", "batch", ")", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "string_classes", ")", ":", "\n", "        ", "return", "batch", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "TensorDict", ")", ":", "\n", "        ", "return", "TensorDict", "(", "{", "key", ":", "ltr_collate", "(", "[", "d", "[", "key", "]", "for", "d", "in", "batch", "]", ")", "for", "key", "in", "batch", "[", "0", "]", "}", ")", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "collections", ".", "Mapping", ")", ":", "\n", "        ", "return", "{", "key", ":", "ltr_collate", "(", "[", "d", "[", "key", "]", "for", "d", "in", "batch", "]", ")", "for", "key", "in", "batch", "[", "0", "]", "}", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "TensorList", ")", ":", "\n", "        ", "transposed", "=", "zip", "(", "*", "batch", ")", "\n", "return", "TensorList", "(", "[", "ltr_collate", "(", "samples", ")", "for", "samples", "in", "transposed", "]", ")", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "collections", ".", "Sequence", ")", ":", "\n", "        ", "transposed", "=", "zip", "(", "*", "batch", ")", "\n", "return", "[", "ltr_collate", "(", "samples", ")", "for", "samples", "in", "transposed", "]", "\n", "", "elif", "batch", "[", "0", "]", "is", "None", ":", "\n", "        ", "return", "batch", "\n", "\n", "", "raise", "TypeError", "(", "(", "error_msg", ".", "format", "(", "type", "(", "batch", "[", "0", "]", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.ltr_collate_stack1": [[70, 119], ["type", "isinstance", "TypeError", "loader._check_use_shared_memory", "torch.stack", "torch.stack", "error_msg.format", "sum", "batch[].storage()._new_shared", "batch[].new", "isinstance", "type", "torch.stack", "torch.stack", "torch.LongTensor", "torch.LongTensor", "isinstance", "x.numel", "batch[].storage", "torch.utils.data.dataloader.re.search", "torch.utils.data.dataloader.re.search", "TypeError", "elem.dtype.name.startswith", "list", "torch.DoubleTensor", "torch.DoubleTensor", "isinstance", "error_msg.format", "torch.from_numpy", "torch.from_numpy", "map", "isinstance", "pytracking.TensorDict", "isinstance", "isinstance", "loader.ltr_collate_stack1", "loader.ltr_collate_stack1", "zip", "pytracking.TensorList", "isinstance", "zip", "loader.ltr_collate_stack1", "loader.ltr_collate_stack1"], "function", ["home.repos.pwc.inspect_result.visionml_pytracking.data.loader._check_use_shared_memory", "home.repos.pwc.inspect_result.visionml_pytracking.libs.tensorlist.TensorList.list", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.ltr_collate_stack1", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.ltr_collate_stack1", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.ltr_collate_stack1", "home.repos.pwc.inspect_result.visionml_pytracking.data.loader.ltr_collate_stack1"], ["", "def", "ltr_collate_stack1", "(", "batch", ")", ":", "\n", "    ", "\"\"\"Puts each data field into a tensor. The tensors are stacked at dim=1 to form the batch\"\"\"", "\n", "\n", "error_msg", "=", "\"batch must contain tensors, numbers, dicts or lists; found {}\"", "\n", "elem_type", "=", "type", "(", "batch", "[", "0", "]", ")", "\n", "if", "isinstance", "(", "batch", "[", "0", "]", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "out", "=", "None", "\n", "if", "_check_use_shared_memory", "(", ")", ":", "\n", "# If we're in a background process, concatenate directly into a", "\n", "# shared memory tensor to avoid an extra copy", "\n", "            ", "numel", "=", "sum", "(", "[", "x", ".", "numel", "(", ")", "for", "x", "in", "batch", "]", ")", "\n", "storage", "=", "batch", "[", "0", "]", ".", "storage", "(", ")", ".", "_new_shared", "(", "numel", ")", "\n", "out", "=", "batch", "[", "0", "]", ".", "new", "(", "storage", ")", "\n", "", "return", "torch", ".", "stack", "(", "batch", ",", "1", ",", "out", "=", "out", ")", "\n", "# if batch[0].dim() < 4:", "\n", "#     return torch.stack(batch, 0, out=out)", "\n", "# return torch.cat(batch, 0, out=out)", "\n", "", "elif", "elem_type", ".", "__module__", "==", "'numpy'", "and", "elem_type", ".", "__name__", "!=", "'str_'", "and", "elem_type", ".", "__name__", "!=", "'string_'", ":", "\n", "        ", "elem", "=", "batch", "[", "0", "]", "\n", "if", "elem_type", ".", "__name__", "==", "'ndarray'", ":", "\n", "# array of string classes and object", "\n", "            ", "if", "torch", ".", "utils", ".", "data", ".", "dataloader", ".", "re", ".", "search", "(", "'[SaUO]'", ",", "elem", ".", "dtype", ".", "str", ")", "is", "not", "None", ":", "\n", "                ", "raise", "TypeError", "(", "error_msg", ".", "format", "(", "elem", ".", "dtype", ")", ")", "\n", "\n", "", "return", "torch", ".", "stack", "(", "[", "torch", ".", "from_numpy", "(", "b", ")", "for", "b", "in", "batch", "]", ",", "1", ")", "\n", "", "if", "elem", ".", "shape", "==", "(", ")", ":", "# scalars", "\n", "            ", "py_type", "=", "float", "if", "elem", ".", "dtype", ".", "name", ".", "startswith", "(", "'float'", ")", "else", "int", "\n", "return", "torch", ".", "utils", ".", "data", ".", "dataloader", ".", "numpy_type_map", "[", "elem", ".", "dtype", ".", "name", "]", "(", "list", "(", "map", "(", "py_type", ",", "batch", ")", ")", ")", "\n", "", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "int", ")", ":", "\n", "        ", "return", "torch", ".", "LongTensor", "(", "batch", ")", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "float", ")", ":", "\n", "        ", "return", "torch", ".", "DoubleTensor", "(", "batch", ")", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "string_classes", ")", ":", "\n", "        ", "return", "batch", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "TensorDict", ")", ":", "\n", "        ", "return", "TensorDict", "(", "{", "key", ":", "ltr_collate_stack1", "(", "[", "d", "[", "key", "]", "for", "d", "in", "batch", "]", ")", "for", "key", "in", "batch", "[", "0", "]", "}", ")", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "collections", ".", "Mapping", ")", ":", "\n", "        ", "return", "{", "key", ":", "ltr_collate_stack1", "(", "[", "d", "[", "key", "]", "for", "d", "in", "batch", "]", ")", "for", "key", "in", "batch", "[", "0", "]", "}", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "TensorList", ")", ":", "\n", "        ", "transposed", "=", "zip", "(", "*", "batch", ")", "\n", "return", "TensorList", "(", "[", "ltr_collate_stack1", "(", "samples", ")", "for", "samples", "in", "transposed", "]", ")", "\n", "", "elif", "isinstance", "(", "batch", "[", "0", "]", ",", "collections", ".", "Sequence", ")", ":", "\n", "        ", "transposed", "=", "zip", "(", "*", "batch", ")", "\n", "return", "[", "ltr_collate_stack1", "(", "samples", ")", "for", "samples", "in", "transposed", "]", "\n", "", "elif", "batch", "[", "0", "]", "is", "None", ":", "\n", "        ", "return", "batch", "\n", "\n", "", "raise", "TypeError", "(", "(", "error_msg", ".", "format", "(", "type", "(", "batch", "[", "0", "]", ")", ")", ")", ")", "\n", "\n"]]}