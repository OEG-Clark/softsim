{"home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_tutorial.example": [[17, 82], ["bnn.BNNHMCRegressor", "bnn.BNNHMCRegressor.load", "bnn.BNNHMCRegressor.infer", "torch.arange().unsqueeze", "bnn.utils.plot_1dregressor", "bnn.BNNHMCRegressor.clear_all_samples", "bnn.BNNHMCRegressor.debug_mode", "bnn.BNNHMCRegressor.infer", "bnn.utils.plot_1dregressor", "bnn.BNNHMCRegressor.clear_all_samples", "bnn.BNNHMCRegressor.switch_off_debug_mode", "bnn.BNNHMCRegressor.load_bayes_samples", "bnn.utils.plot_1dregressor", "bnn.BNNHMCRegressor.add_deterministic_constraint", "bnn.BNNHMCRegressor.update_config", "bnn.BNNHMCRegressor.infer", "bnn.utils.plot_1dregressor", "bnn.BNNHMCRegressor.clear_all_samples", "bnn.BNNHMCRegressor.load_bayes_samples", "bnn.BNNHMCRegressor.load_bayes_samples", "bnn.utils.plot_1dregressor", "numpy.arange", "matplotlib.fill_between", "matplotlib.fill_between", "data.dataloader.toy1", "torch.arange", "range", "matplotlib.ylim", "matplotlib.ylim", "len"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.clear_all_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.clear_all_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.switch_off_debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_deterministic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.clear_all_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy1"], ["def", "example", "(", ")", ":", "\n", "\n", "################################################################################", "\n", "## Part 1: Running a baseline BNN without constraints, using a Gaussian prior.", "\n", "################################################################################", "\n", "\n", "# First, instantiate the BNN. Various hyperparameters and such are defined as a YAML config file.", "\n", "# See `config.yaml` (root level of the repo) for explanations of each config.", "\n", "# When the BNN is instantiated, a copy of the YAML file will be saved in `history/`.", "\n", "\t", "bnn", "=", "BNNHMCRegressor", "(", "uid", "=", "\"example2\"", ",", "configfile", "=", "\"repro/example.yaml\"", ")", "\n", "\n", "# Load the dataset.", "\n", "# See `data/dataloader.py` to add your own dataset.", "\n", "bnn", ".", "load", "(", "**", "toy1", "(", ")", ")", "\n", "\n", "# Conduct inference. The inference method is already defined by the BNN class you instantiated.", "\n", "# In this case, we use HMC.", "\n", "# After inference is complete, the samples are saved in `history/` as a .pt file.", "\n", "bnn", ".", "infer", "(", ")", "\n", "\n", "# Having collected posterior samples, let us try plotting the posterior predictive.", "\n", "# Plots are automatically saved in the `history/` folder too.", "\n", "domain", "=", "torch", ".", "arange", "(", "-", "5", ",", "5", ",", "0.05", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "(", "-", "9", ",", "7", ")", ")", "\n", "\n", "# BNN inference takes time. If you want to debug the code, you can activate debug mode.", "\n", "# In debug mode, only a few iterations of inference is run.", "\n", "bnn", ".", "clear_all_samples", "(", ")", "\n", "bnn", ".", "debug_mode", "(", ")", "\n", "bnn", ".", "infer", "(", ")", "\n", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"Debug Mode Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "(", "-", "9", ",", "7", ")", ")", "\n", "\n", "# By the way, here's how to load an existing posterior sample file from memory.", "\n", "# We've provided a pretrained set of HMC samples. ", "\n", "bnn", ".", "clear_all_samples", "(", ")", "\n", "bnn", ".", "switch_off_debug_mode", "(", ")", "\n", "bnn", ".", "load_bayes_samples", "(", "'repro/example_hmc1.pt'", ",", "'hmc_gaussian'", ")", "\n", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"Pretrained Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "(", "-", "9", ",", "7", ")", ")", "\n", "\n", "\n", "################################################################################", "\n", "## Part 2: Specifying and obeying output constraints with OC-BNNs.", "\n", "################################################################################", "\n", "\n", "# We will add negative constraints.", "\n", "# See the docstring in `bnn/base.py` for an explanation on how to do so.", "\n", "# When a constraint is added, the BNN automatically uses output-constrained priors for inference.", "\n", "def", "ifunc", "(", "X", ")", ":", "return", "[", "[", "(", "2.5", ",", "3.0", ")", "]", "for", "_", "in", "range", "(", "len", "(", "X", ")", ")", "]", "\n", "bnn", ".", "add_deterministic_constraint", "(", "constrained_domain", "=", "(", "-", "0.3", ",", "0.3", ")", ",", "interval_func", "=", "ifunc", ",", "prior_type", "=", "\"negative_exponential_cocp\"", ")", "\n", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "bnn", ".", "infer", "(", ")", "\n", "\n", "# Let's plot the predictive distribution again, along with the constraint we specified.", "\n", "# We also plot the baseline posterior predictive in Part 1 for comparison.", "\n", "def", "addons", "(", ")", ":", "\n", "\t\t", "dom", "=", "np", ".", "arange", "(", "-", "0.3", ",", "0.3", ",", "0.05", ")", "\n", "plt", ".", "fill_between", "(", "dom", ",", "3.0", ",", "plt", ".", "ylim", "(", ")", "[", "1", "]", ",", "facecolor", "=", "COLORS", "[", "'red'", "]", "[", "0", "]", ",", "alpha", "=", "0.5", ",", "zorder", "=", "101", ")", "\n", "plt", ".", "fill_between", "(", "dom", ",", "plt", ".", "ylim", "(", ")", "[", "0", "]", ",", "2.5", ",", "facecolor", "=", "COLORS", "[", "'red'", "]", "[", "0", "]", ",", "alpha", "=", "0.5", ",", "zorder", "=", "101", ")", "\n", "", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"Posterior Predictive With Constraints\"", ",", "domain", "=", "domain", ",", "ylims", "=", "(", "-", "9", ",", "7", ")", ",", "addons", "=", "addons", ")", "\n", "\n", "# Finally, here's both our pretrained HMC samples for comparison.", "\n", "bnn", ".", "clear_all_samples", "(", ")", "\n", "bnn", ".", "load_bayes_samples", "(", "'repro/example_hmc1.pt'", ",", "'hmc_gaussian'", ")", "\n", "bnn", ".", "load_bayes_samples", "(", "'repro/example_hmc2.pt'", ",", "'hmc_ocbnn'", ")", "\n", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"Pretrained Posterior Predictive With Constraints\"", ",", "domain", "=", "domain", ",", "ylims", "=", "(", "-", "9", ",", "7", ")", ",", "addons", "=", "addons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_bakeoff.bakeoff": [[29, 123], ["torch.arange().unsqueeze", "BNNHMCRegressor", "BNNSVGDClassifier.load", "bnn.utils.plot_1dregressor", "BNNBBBRegressor", "BNNSVGDClassifier.load", "bnn.utils.plot_1dregressor", "BNNSGLDRegressor", "BNNSVGDClassifier.load", "bnn.utils.plot_1dregressor", "BNNSVGDRegressor", "BNNSVGDClassifier.update_config", "BNNSVGDClassifier.load", "bnn.utils.plot_1dregressor", "torch.arange", "BNNHMCClassifier", "BNNSVGDClassifier.load", "bnn.utils.plot_2d3classifier", "BNNBBBClassifier", "BNNSVGDClassifier.load", "bnn.utils.plot_2d3classifier", "BNNSGLDClassifier", "BNNSVGDClassifier.load", "bnn.utils.plot_2d3classifier", "BNNSVGDClassifier", "BNNSVGDClassifier.update_config", "BNNSVGDClassifier.load", "bnn.utils.plot_2d3classifier", "BNNSVGDClassifier.debug_mode", "BNNSVGDClassifier.load_bayes_samples", "BNNSVGDClassifier.infer", "BNNSVGDClassifier.debug_mode", "BNNSVGDClassifier.load_bayes_samples", "BNNSVGDClassifier.infer", "BNNSVGDClassifier.debug_mode", "BNNSVGDClassifier.load_bayes_samples", "BNNSVGDClassifier.infer", "BNNSVGDClassifier.debug_mode", "BNNSVGDClassifier.load_bayes_samples", "BNNSVGDClassifier.infer", "BNNSVGDClassifier.debug_mode", "BNNSVGDClassifier.load_bayes_samples", "BNNSVGDClassifier.infer", "BNNSVGDClassifier.debug_mode", "BNNSVGDClassifier.load_bayes_samples", "BNNSVGDClassifier.infer", "BNNSVGDClassifier.debug_mode", "BNNSVGDClassifier.load_bayes_samples", "BNNSVGDClassifier.infer", "BNNSVGDClassifier.debug_mode", "BNNSVGDClassifier.load_bayes_samples", "BNNSVGDClassifier.infer", "torch.arange", "data.dataloader.toy1", "data.dataloader.toy1", "data.dataloader.toy1", "data.dataloader.toy1", "data.dataloader.toy2", "data.dataloader.toy2", "data.dataloader.toy2", "data.dataloader.toy2"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_2d3classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_2d3classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_2d3classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_2d3classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy1", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy1", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy1", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy1", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy2", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy2", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy2", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy2"], ["def", "bakeoff", "(", ")", ":", "\n", "\n", "# Regression", "\n", "# To allow for better comparison, predictive distribution is plotted as individual functions instead of credible intervals.", "\n", "\t", "domain", "=", "torch", ".", "arange", "(", "-", "5", ",", "5", ",", "0.05", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "ylims", "=", "(", "-", "9", ",", "7", ")", "\n", "\n", "bnn", "=", "BNNHMCRegressor", "(", "uid", "=", "\"rbakeoff\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/rbakeoff.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy1", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/rbakeoff_hmc1.pt'", ",", "'bakeoff'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"HMC Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "ylims", ",", "plot_type", "=", "\"full\"", ")", "\n", "\n", "bnn", "=", "BNNBBBRegressor", "(", "uid", "=", "\"rbakeoff\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/rbakeoff.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy1", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/rbakeoff_bbb1.pt'", ",", "'bakeoff'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"BBB Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "ylims", ",", "plot_type", "=", "\"full\"", ")", "\n", "\n", "bnn", "=", "BNNSGLDRegressor", "(", "uid", "=", "\"rbakeoff\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/rbakeoff.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy1", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/rbakeoff_sgld1.pt'", ",", "'bakeoff'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"SGLD Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "ylims", ",", "plot_type", "=", "\"full\"", ")", "\n", "\n", "bnn", "=", "BNNSVGDRegressor", "(", "uid", "=", "\"rbakeoff\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/rbakeoff.yaml\"", ")", "\n", "bnn", ".", "update_config", "(", "infer_nsamples", "=", "100", ")", "# SVGD has O(n^3) complexity in the number of particles. If too slow, use 50 or 75 particles.", "\n", "bnn", ".", "load", "(", "**", "toy1", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/rbakeoff_svgd1.pt'", ",", "'bakeoff'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"SVGD Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "ylims", ",", "plot_type", "=", "\"full\"", ")", "\n", "\n", "\n", "# Classification (3 output classes)", "\n", "# To allow for better comparison, predictive distribution is plotted as individual functions instead of credible intervals.", "\n", "# (In the 2D classification case, this means the entire plot is shaded with a RGB simplex.) ", "\n", "x1_domain", "=", "x2_domain", "=", "torch", ".", "arange", "(", "-", "5", ",", "5", ",", "0.1", ")", "\n", "\n", "bnn", "=", "BNNHMCClassifier", "(", "uid", "=", "\"cbakeoff\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/cbakeoff.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy2", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/cbakeoff_hmc1.pt'", ",", "'bakeoff'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_2d3classifier", "(", "bnn", ",", "plot_title", "=", "\"HMC Posterior Predictive\"", ",", "x1_domain", "=", "x1_domain", ",", "x2_domain", "=", "x2_domain", ",", "plot_type", "=", "\"full\"", ")", "\n", "\n", "bnn", "=", "BNNBBBClassifier", "(", "uid", "=", "\"cbakeoff\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/cbakeoff.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy2", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/cbakeoff_bbb1.pt'", ",", "'bakeoff'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_2d3classifier", "(", "bnn", ",", "plot_title", "=", "\"BBB Posterior Predictive\"", ",", "x1_domain", "=", "x1_domain", ",", "x2_domain", "=", "x2_domain", ",", "plot_type", "=", "\"full\"", ")", "\n", "\n", "bnn", "=", "BNNSGLDClassifier", "(", "uid", "=", "\"cbakeoff\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/cbakeoff.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy2", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/cbakeoff_sgld1.pt'", ",", "'bakeoff'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_2d3classifier", "(", "bnn", ",", "plot_title", "=", "\"SGLD Posterior Predictive\"", ",", "x1_domain", "=", "x1_domain", ",", "x2_domain", "=", "x2_domain", ",", "plot_type", "=", "\"full\"", ")", "\n", "\n", "bnn", "=", "BNNSVGDClassifier", "(", "uid", "=", "\"cbakeoff\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/cbakeoff.yaml\"", ")", "\n", "bnn", ".", "update_config", "(", "infer_nsamples", "=", "100", ")", "\n", "bnn", ".", "load", "(", "**", "toy2", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/cbakeoff_svgd1.pt'", ",", "'bakeoff'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_2d3classifier", "(", "bnn", ",", "plot_title", "=", "\"SVGD Posterior Predictive\"", ",", "x1_domain", "=", "x1_domain", ",", "x2_domain", "=", "x2_domain", ",", "plot_type", "=", "\"full\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_apps.recid_evaluate_high_risk": [[31, 42], ["torch.stack().t", "len", "len", "len", "len", "torch.stack", "bnn.predict().mean", "bnn.predict"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.predict"], ["def", "recid_evaluate_high_risk", "(", "bnn", ")", ":", "\n", "\t", "\"\"\" Recidivism prediction task: evaluate high-risk fraction of both groups \"\"\"", "\n", "samples", ",", "_", "=", "bnn", ".", "all_bayes_samples", "[", "-", "1", "]", "\n", "preds", "=", "(", "bnn", ".", "predict", "(", "samples", ",", "bnn", ".", "X_train", ",", "return_probs", "=", "True", ")", ".", "mean", "(", "dim", "=", "0", ")", ">=", "0.5", ")", ".", "float", "(", ")", "\n", "\n", "eval_data", "=", "torch", ".", "stack", "(", "(", "bnn", ".", "X_train_race", ",", "preds", ")", ")", ".", "t", "(", ")", "\n", "aa_highrisk", "=", "len", "(", "eval_data", "[", "(", "eval_data", "[", ":", ",", "0", "]", "==", "1.0", ")", "&", "(", "eval_data", "[", ":", ",", "1", "]", "==", "1.0", ")", "]", ")", "\n", "aa_total", "=", "len", "(", "eval_data", "[", "(", "eval_data", "[", ":", ",", "0", "]", "==", "1.0", ")", "]", ")", "\n", "nonaa_highrisk", "=", "len", "(", "eval_data", "[", "(", "eval_data", "[", ":", ",", "0", "]", "==", "0.0", ")", "&", "(", "eval_data", "[", ":", ",", "1", "]", "==", "1.0", ")", "]", ")", "\n", "nonaa_total", "=", "len", "(", "eval_data", "[", "(", "eval_data", "[", ":", ",", "0", "]", "==", "0.0", ")", "]", ")", "\n", "return", "aa_highrisk", ",", "aa_total", ",", "nonaa_highrisk", ",", "nonaa_total", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_apps.recidivism_task": [[44, 128], ["BNNSVGDBinaryClassifier", "BNNSVGDBinaryClassifier.load", "logging.info", "logging.info", "bnn.utils.eval_accuracy_and_f1_score", "logging.info", "logging.info", "run_apps.recid_evaluate_high_risk", "logging.info", "logging.info", "range", "BNNSVGDBinaryClassifier.add_probabilistic_constraint", "BNNSVGDBinaryClassifier.update_config", "logging.info", "bnn.utils.eval_accuracy_and_f1_score", "logging.info", "logging.info", "run_apps.recid_evaluate_high_risk", "logging.info", "logging.info", "BNNSVGDBinaryClassifier", "BNNSVGDBinaryClassifier.load", "logging.info", "bnn.utils.eval_accuracy_and_f1_score", "logging.info", "logging.info", "run_apps.recid_evaluate_high_risk", "logging.info", "logging.info", "BNNSVGDBinaryClassifier.add_probabilistic_constraint", "BNNSVGDBinaryClassifier.update_config", "logging.info", "bnn.utils.eval_accuracy_and_f1_score", "logging.info", "logging.info", "run_apps.recid_evaluate_high_risk", "logging.info", "logging.info", "BNNSVGDBinaryClassifier.debug_mode", "BNNSVGDBinaryClassifier.load_bayes_samples", "BNNSVGDBinaryClassifier.infer", "BNNSVGDBinaryClassifier.load_gaussian_aocp_parameters", "BNNSVGDBinaryClassifier.learn_gaussian_aocp", "BNNSVGDBinaryClassifier.load_bayes_samples", "BNNSVGDBinaryClassifier.infer", "BNNSVGDBinaryClassifier.debug_mode", "BNNSVGDBinaryClassifier.load_bayes_samples", "BNNSVGDBinaryClassifier.infer", "BNNSVGDBinaryClassifier.load_gaussian_aocp_parameters", "BNNSVGDBinaryClassifier.learn_gaussian_aocp", "BNNSVGDBinaryClassifier.load_bayes_samples", "BNNSVGDBinaryClassifier.infer", "data.dataloader.compas_dataset", "BNNSVGDBinaryClassifier.X_train[].mean().item", "BNNSVGDBinaryClassifier.X_train[].std().item", "data.dataloader.compas_dataset", "BNNSVGDBinaryClassifier.X_train[].mean", "BNNSVGDBinaryClassifier.X_train[].std", "sum"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.eval_accuracy_and_f1_score", "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_apps.recid_evaluate_high_risk", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_probabilistic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.eval_accuracy_and_f1_score", "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_apps.recid_evaluate_high_risk", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.eval_accuracy_and_f1_score", "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_apps.recid_evaluate_high_risk", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_probabilistic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.eval_accuracy_and_f1_score", "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_apps.recid_evaluate_high_risk", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_gaussian_aocp_parameters", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.learn_gaussian_aocp", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_gaussian_aocp_parameters", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.learn_gaussian_aocp", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.compas_dataset", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.compas_dataset"], ["", "def", "recidivism_task", "(", ")", ":", "\n", "\t", "\"\"\" Section 6.2: Recidivism Prediction Task \"\"\"", "\n", "\n", "# With race as an explicit feature, baseline.", "\n", "bnn", "=", "BNNSVGDBinaryClassifier", "(", "uid", "=", "\"recid\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/recid.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "compas_dataset", "(", "csv_xfilename", "=", "\"data/compas_X.csv\"", ",", "csv_yfilename", "=", "\"data/compas_Y.csv\"", ")", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}] Dataset <{bnn.dataset_name}>: {(100 * sum(bnn.Y_train) // bnn.N_train):.2f}% of training points are positive.'", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/recid_svgd1.pt'", ",", "'svgd_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "logging", ".", "info", "(", "f'[{bnn.uid}] Baseline evaluation, with race as feature:'", ")", "\n", "acc", ",", "f1", "=", "eval_accuracy_and_f1_score", "(", "bnn", ",", "is_binary", "=", "True", ",", "X_eval", "=", "bnn", ".", "X_train", ",", "Y_eval", "=", "bnn", ".", "Y_train", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Train accuracy: {acc:.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Train F1 score: {f1:.3f}.'", ")", "\n", "aa_highrisk", ",", "aa_total", ",", "nonaa_highrisk", ",", "nonaa_total", "=", "recid_evaluate_high_risk", "(", "bnn", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   African American High-Risk Fraction: {(aa_highrisk / aa_total):.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Non-African American High-Risk Fraction: {(nonaa_highrisk / nonaa_total):.3f}.'", ")", "\n", "\n", "# With race as an explicit feature, OC-BNN.", "\n", "cdomain", "=", "(", ")", "\n", "for", "i", "in", "range", "(", "9", ")", ":", "\n", "\t\t", "if", "i", "==", "1", ":", "\n", "\t\t\t", "cdomain", "+=", "(", "0.", ",", "1.", ")", "\n", "", "else", ":", "\n", "\t\t\t", "mm", "=", "bnn", ".", "X_train", "[", ":", ",", "i", "]", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "ss", "=", "bnn", ".", "X_train", "[", ":", ",", "i", "]", ".", "std", "(", ")", ".", "item", "(", ")", "\n", "cdomain", "+=", "(", "mm", "-", "0.2", "*", "ss", ",", "mm", "+", "0.2", "*", "ss", ")", "\n", "", "", "bnn", ".", "add_probabilistic_constraint", "(", "constrained_domain", "=", "cdomain", ",", "prob_func", "=", "lambda", "X", ":", "X", "[", ":", ",", "1", "]", ",", "prior_type", "=", "\"gaussian_aocp\"", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_gaussian_aocp_parameters", "(", "'repro/recid_aocp.pt'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "learn_gaussian_aocp", "(", ")", "\n", "", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/recid_svgd2.pt'", ",", "'svgd_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "logging", ".", "info", "(", "f'[{bnn.uid}] OC-BNN evaluation, with race as feature:'", ")", "\n", "acc", ",", "f1", "=", "eval_accuracy_and_f1_score", "(", "bnn", ",", "is_binary", "=", "True", ",", "X_eval", "=", "bnn", ".", "X_train", ",", "Y_eval", "=", "bnn", ".", "Y_train", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Train accuracy: {acc:.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Train F1 score: {f1:.3f}.'", ")", "\n", "aa_highrisk", ",", "aa_total", ",", "nonaa_highrisk", ",", "nonaa_total", "=", "recid_evaluate_high_risk", "(", "bnn", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   African American High-Risk Fraction: {(aa_highrisk / aa_total):.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Non-African American High-Risk Fraction: {(nonaa_highrisk / nonaa_total):.3f}.'", ")", "\n", "\n", "\n", "# Without race as feature, baseline.", "\n", "bnn", "=", "BNNSVGDBinaryClassifier", "(", "uid", "=", "\"recid-no-race\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/recid-no-race.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "compas_dataset", "(", "csv_xfilename", "=", "\"data/compas_X.csv\"", ",", "csv_yfilename", "=", "\"data/compas_Y.csv\"", ",", "with_race", "=", "False", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/recid-no-race_svgd1.pt'", ",", "'svgd_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "logging", ".", "info", "(", "f'[{bnn.uid}] Baseline evaluation, with race as feature:'", ")", "\n", "acc", ",", "f1", "=", "eval_accuracy_and_f1_score", "(", "bnn", ",", "is_binary", "=", "True", ",", "X_eval", "=", "bnn", ".", "X_train", ",", "Y_eval", "=", "bnn", ".", "Y_train", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Train accuracy: {acc:.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Train F1 score: {f1:.3f}.'", ")", "\n", "aa_highrisk", ",", "aa_total", ",", "nonaa_highrisk", ",", "nonaa_total", "=", "recid_evaluate_high_risk", "(", "bnn", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   African American High-Risk Fraction: {(aa_highrisk / aa_total):.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Non-African American High-Risk Fraction: {(nonaa_highrisk / nonaa_total):.3f}.'", ")", "\n", "\n", "# Without race as feature, OC-BNN.", "\n", "bnn", ".", "add_probabilistic_constraint", "(", "constrained_domain", "=", "cdomain", "[", ":", "-", "2", "]", ",", "prob_func", "=", "lambda", "X", ":", "X", "[", ":", ",", "1", "]", ",", "prior_type", "=", "\"gaussian_aocp\"", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_gaussian_aocp_parameters", "(", "'repro/recid-no-race_aocp.pt'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "learn_gaussian_aocp", "(", ")", "\n", "", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/recid-no-race_svgd2.pt'", ",", "'svgd_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "logging", ".", "info", "(", "f'[{bnn.uid}] OC-BNN evaluation, with race as feature:'", ")", "\n", "acc", ",", "f1", "=", "eval_accuracy_and_f1_score", "(", "bnn", ",", "is_binary", "=", "True", ",", "X_eval", "=", "bnn", ".", "X_train", ",", "Y_eval", "=", "bnn", ".", "Y_train", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Train accuracy: {acc:.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Train F1 score: {f1:.3f}.'", ")", "\n", "aa_highrisk", ",", "aa_total", ",", "nonaa_highrisk", ",", "nonaa_total", "=", "recid_evaluate_high_risk", "(", "bnn", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   African American High-Risk Fraction: {(aa_highrisk / aa_total):.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Non-African American High-Risk Fraction: {(nonaa_highrisk / nonaa_total):.3f}.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_apps.credit_evaluate_recourse": [[130, 144], ["bnn.predict().mean().argmax", "X_test_young[].mean", "X_test_young[].mean", "X_test_young[].mean", "X_test_young[].mean", "bnn.predict().mean", "bnn.predict"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.predict"], ["", "def", "credit_evaluate_recourse", "(", "bnn", ")", ":", "\n", "\t", "\"\"\" Credit scoring task: evaluate effort of recourse on young adults. \"\"\"", "\n", "samples", ",", "_", "=", "bnn", ".", "all_bayes_samples", "[", "-", "1", "]", "\n", "preds", "=", "bnn", ".", "predict", "(", "samples", ",", "bnn", ".", "X_test", ",", "return_probs", "=", "True", ")", ".", "mean", "(", "dim", "=", "0", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "is_young", "=", "(", "bnn", ".", "X_test", "[", ":", ",", "1", "]", "*", "bnn", ".", "X_train_std", "[", "1", "]", "+", "bnn", ".", "X_train_mean", "[", "1", "]", "<", "35", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "\n", "X_test_young", "=", "bnn", ".", "X_test", "[", "is_young", "]", "\n", "Y_test_young", "=", "bnn", ".", "Y_test", "[", "is_young", "]", "\n", "preds_young", "=", "preds", "[", "is_young", "]", "\n", "\n", "gt_ruul_neg", "=", "X_test_young", "[", "(", "Y_test_young", "==", "0", ")", ".", "nonzero", "(", ")", ",", "0", "]", ".", "mean", "(", ")", "\n", "gt_ruul_pos", "=", "X_test_young", "[", "(", "Y_test_young", "==", "1", ")", ".", "nonzero", "(", ")", ",", "0", "]", ".", "mean", "(", ")", "\n", "preds_ruul_neg", "=", "X_test_young", "[", "(", "preds_young", "==", "0", ")", ".", "nonzero", "(", ")", ",", "0", "]", ".", "mean", "(", ")", "\n", "preds_ruul_pos", "=", "X_test_young", "[", "(", "preds_young", "==", "1", ")", ".", "nonzero", "(", ")", ",", "0", "]", ".", "mean", "(", ")", "\n", "return", "gt_ruul_neg", ",", "gt_ruul_pos", ",", "preds_ruul_neg", ",", "preds_ruul_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_apps.credit_scoring_task": [[146, 214], ["BNNBBBClassifier", "BNNBBBClassifier.load", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "bnn.utils.eval_accuracy_and_f1_score", "logging.info", "logging.info", "run_apps.credit_evaluate_recourse", "logging.info", "logging.info", "BNNBBBClassifier.X_train[].min().item", "numpy.quantile", "numpy.quantile", "range", "logging.info", "bnn.utils.eval_accuracy_and_f1_score", "logging.info", "logging.info", "run_apps.credit_evaluate_recourse", "logging.info", "logging.info", "BNNBBBClassifier.add_deterministic_constraint", "BNNBBBClassifier.update_config", "logging.info", "bnn.utils.eval_accuracy_and_f1_score", "logging.info", "logging.info", "run_apps.credit_evaluate_recourse", "logging.info", "logging.info", "BNNBBBClassifier.debug_mode", "BNNBBBClassifier.load_bayes_samples", "BNNBBBClassifier.infer", "[].item", "[].item", "BNNBBBClassifier.load_bayes_samples", "BNNBBBClassifier.infer", "BNNBBBClassifier.load_bayes_samples", "BNNBBBClassifier.infer", "data.dataloader.credit_dataset", "BNNBBBClassifier.X_train[].min", "BNNBBBClassifier.X_train[].mean", "BNNBBBClassifier.X_train[].std", "sum", "sum", "sum"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.eval_accuracy_and_f1_score", "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_apps.credit_evaluate_recourse", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.eval_accuracy_and_f1_score", "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_apps.credit_evaluate_recourse", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_deterministic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.eval_accuracy_and_f1_score", "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_apps.credit_evaluate_recourse", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.credit_dataset"], ["", "def", "credit_scoring_task", "(", ")", ":", "\n", "\t", "\"\"\" Section 6.3: Credit Scoring Task \"\"\"", "\n", "\n", "bnn", "=", "BNNBBBClassifier", "(", "uid", "=", "'credit'", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/credit.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "credit_dataset", "(", "csv_filename", "=", "\"data/give_me_some_credit.csv\"", ")", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}] Dataset <{bnn.dataset_name}> blind dataset: {bnn.X_train_blind.shape[0]} training points.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}] Dataset <{bnn.dataset_name}>: {(100 * sum(bnn.Y_train) // bnn.N_train):.2f}% of training points are positive.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}] Dataset <{bnn.dataset_name}>: {(100 * sum(bnn.Y_train_blind) // bnn.X_train_blind.shape[0]):.2f}% of blind training points are positive.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}] Dataset <{bnn.dataset_name}>: {(100 * sum(bnn.Y_test) // bnn.N_test):.2f}% of test points are positive.'", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "\n", "# Baseline inference and evaluation on full dataset.", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/credit_bbb1.pt'", ",", "'bbb_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "logging", ".", "info", "(", "f'[{bnn.uid}] Baseline evaluation on full dataset:'", ")", "\n", "acc", ",", "f1", "=", "eval_accuracy_and_f1_score", "(", "bnn", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Test accuracy: {acc:.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Test F1 score: {f1:.3f}.'", ")", "\n", "gt_ruul_neg", ",", "gt_ruul_pos", ",", "preds_ruul_neg", ",", "preds_ruul_pos", "=", "credit_evaluate_recourse", "(", "bnn", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Effort of recourse: {preds_ruul_pos - preds_ruul_neg:.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Ground-truth effort of recourse: {gt_ruul_pos - gt_ruul_neg:.3f}.'", ")", "\n", "\n", "# Calculating constrained domain boundaries for OC-BNNs.", "\n", "# Define constrained region as: young with high RUUL. For other features, sample around training distribution mean.", "\n", "age_lb", "=", "bnn", ".", "X_train", "[", ":", ",", "1", "]", ".", "min", "(", ")", ".", "item", "(", ")", "\n", "age_ub", "=", "(", "35", "-", "bnn", ".", "X_train_mean", "[", "1", "]", ")", "/", "bnn", ".", "X_train_std", "[", "1", "]", "\n", "Y_train_young", "=", "bnn", ".", "Y_train", "[", "(", "bnn", ".", "X_train", "[", ":", ",", "1", "]", "*", "bnn", ".", "X_train_std", "[", "1", "]", "+", "bnn", ".", "X_train_mean", "[", "1", "]", "<", "35", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "]", "\n", "X_train_young", "=", "bnn", ".", "X_train", "[", "(", "bnn", ".", "X_train", "[", ":", ",", "1", "]", "*", "bnn", ".", "X_train_std", "[", "1", "]", "+", "bnn", ".", "X_train_mean", "[", "1", "]", "<", "35", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "]", "\n", "ruul_lb", "=", "np", ".", "quantile", "(", "X_train_young", "[", ":", ",", "0", "]", ",", "0.6", ")", "\n", "ruul_ub", "=", "np", ".", "quantile", "(", "X_train_young", "[", ":", ",", "0", "]", ",", "1.0", ")", "\n", "cdomain", "=", "(", "ruul_lb", ",", "ruul_ub", ",", "age_lb", ",", "age_ub", ")", "\n", "for", "i", "in", "range", "(", "2", ",", "10", ")", ":", "\n", "\t\t", "dim_mean", "=", "bnn", ".", "X_train", "[", "bnn", ".", "X_train", "[", ":", ",", "1", "]", "*", "bnn", ".", "X_train_std", "[", "1", "]", "+", "bnn", ".", "X_train_mean", "[", "1", "]", "<", "35", "]", ".", "mean", "(", "dim", "=", "0", ")", "[", "i", "]", ".", "item", "(", ")", "\n", "dim_std", "=", "bnn", ".", "X_train", "[", "bnn", ".", "X_train", "[", ":", ",", "1", "]", "*", "bnn", ".", "X_train_std", "[", "1", "]", "+", "bnn", ".", "X_train_mean", "[", "1", "]", "<", "35", "]", ".", "std", "(", "dim", "=", "0", ")", "[", "i", "]", ".", "item", "(", ")", "\n", "cdomain", "=", "cdomain", "+", "(", "dim_mean", "-", "0.2", "*", "dim_std", ",", "dim_mean", "+", "0.2", "*", "dim_std", ")", "\n", "\n", "# Baseline inference and evaluation on blind dataset.", "\n", "", "bnn", ".", "X_train", ",", "bnn", ".", "Y_train", "=", "bnn", ".", "X_train_blind", ",", "bnn", ".", "Y_train_blind", "\n", "bnn", ".", "N_train", "=", "bnn", ".", "X_train", ".", "shape", "[", "0", "]", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/credit_bbb2.pt'", ",", "'bbb_blind_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "logging", ".", "info", "(", "f'[{bnn.uid}] Baseline evaluation on blind dataset:'", ")", "\n", "acc", ",", "f1", "=", "eval_accuracy_and_f1_score", "(", "bnn", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Test accuracy: {acc:.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Test F1 score: {f1:.3f}.'", ")", "\n", "gt_ruul_neg", ",", "gt_ruul_pos", ",", "preds_ruul_neg", ",", "preds_ruul_pos", "=", "credit_evaluate_recourse", "(", "bnn", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Effort of recourse: {preds_ruul_pos - preds_ruul_neg:.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Ground-truth effort of recourse: {gt_ruul_pos - gt_ruul_neg:.3f}.'", ")", "\n", "\n", "# OC-BNN inference and evaluation.", "\n", "bnn", ".", "add_deterministic_constraint", "(", "constrained_domain", "=", "cdomain", ",", "forbidden_classes", "=", "[", "1", "]", ",", "prior_type", "=", "\"positive_dirichlet_cocp\"", ")", "\n", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/credit_bbb3.pt'", ",", "'bbb_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "logging", ".", "info", "(", "f'[{bnn.uid}] OC-BNN evaluation:'", ")", "\n", "acc", ",", "f1", "=", "eval_accuracy_and_f1_score", "(", "bnn", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Test accuracy: {acc:.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Test F1 score: {f1:.3f}.'", ")", "\n", "gt_ruul_neg", ",", "gt_ruul_pos", ",", "preds_ruul_neg", ",", "preds_ruul_pos", "=", "credit_evaluate_recourse", "(", "bnn", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Effort of recourse: {preds_ruul_pos - preds_ruul_neg:.3f}.'", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}]   Ground-truth effort of recourse: {gt_ruul_pos - gt_ruul_neg:.3f}.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_toys.figure1and5": [[31, 109], ["torch.arange().unsqueeze", "BNNHMCRegressor", "BNNBBBRegressor.load", "BNNBBBRegressor.add_deterministic_constraint", "BNNBBBRegressor.update_config", "bnn.utils.plot_1dregressor", "BNNBBBRegressor.clear_all_samples", "BNNBBBRegressor.update_config", "BNNBBBRegressor.update_config", "bnn.utils.plot_1dregressor", "BNNSVGDRegressor", "BNNBBBRegressor.load", "BNNBBBRegressor.add_deterministic_constraint", "BNNBBBRegressor.update_config", "bnn.utils.plot_1dregressor", "BNNBBBRegressor", "BNNBBBRegressor.load", "BNNBBBRegressor.add_deterministic_constraint", "BNNBBBRegressor.update_config", "bnn.utils.plot_1dregressor", "numpy.arange", "matplotlib.fill_between", "matplotlib.fill_between", "BNNBBBRegressor.debug_mode", "BNNBBBRegressor.load_bayes_samples", "BNNBBBRegressor.infer", "BNNBBBRegressor.load_bayes_samples", "BNNBBBRegressor.infer", "BNNBBBRegressor.load_bayes_samples", "BNNBBBRegressor.infer", "BNNBBBRegressor.load_bayes_samples", "BNNBBBRegressor.infer", "BNNBBBRegressor.debug_mode", "BNNBBBRegressor.load_bayes_samples", "BNNBBBRegressor.infer", "BNNBBBRegressor.load_bayes_samples", "BNNBBBRegressor.infer", "BNNBBBRegressor.debug_mode", "BNNBBBRegressor.load_bayes_samples", "BNNBBBRegressor.infer", "BNNBBBRegressor.load_bayes_samples", "BNNBBBRegressor.infer", "torch.arange", "data.dataloader.toy1", "data.dataloader.toy1", "data.dataloader.toy1", "range", "matplotlib.ylim", "matplotlib.ylim", "len"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_deterministic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.clear_all_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_deterministic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_deterministic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy1", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy1", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy1"], ["def", "figure1and5", "(", ")", ":", "\n", "\t", "\"\"\" \n\tSection 5, Figure 1a and 1b.\n\tAppendix D, Figure 5a and 5b. \n\t\"\"\"", "\n", "domain", "=", "torch", ".", "arange", "(", "-", "5", ",", "5", ",", "0.05", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "def", "ifunc", "(", "X", ")", ":", "return", "[", "[", "(", "2.5", ",", "3.0", ")", "]", "for", "_", "in", "range", "(", "len", "(", "X", ")", ")", "]", "\n", "\n", "# Plot constraints.", "\n", "def", "addons", "(", ")", ":", "\n", "\t\t", "dom", "=", "np", ".", "arange", "(", "-", "0.3", ",", "0.3", ",", "0.05", ")", "\n", "plt", ".", "fill_between", "(", "dom", ",", "3.0", ",", "plt", ".", "ylim", "(", ")", "[", "1", "]", ",", "facecolor", "=", "COLORS", "[", "'red'", "]", "[", "0", "]", ",", "alpha", "=", "0.5", ",", "zorder", "=", "101", ")", "\n", "plt", ".", "fill_between", "(", "dom", ",", "plt", ".", "ylim", "(", ")", "[", "0", "]", ",", "2.5", ",", "facecolor", "=", "COLORS", "[", "'red'", "]", "[", "0", "]", ",", "alpha", "=", "0.5", ",", "zorder", "=", "101", ")", "\n", "\n", "# Figure 1a: prior predictive", "\n", "", "bnn", "=", "BNNHMCRegressor", "(", "uid", "=", "\"F1a\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/F1a.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy1", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F1a_hmc1.pt'", ",", "'hmc_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", "with_data", "=", "False", ")", "\n", "", "bnn", ".", "add_deterministic_constraint", "(", "constrained_domain", "=", "(", "-", "0.3", ",", "0.3", ")", ",", "interval_func", "=", "ifunc", ",", "prior_type", "=", "\"negative_exponential_cocp\"", ")", "\n", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F1a_hmc2.pt'", ",", "'hmc_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", "with_data", "=", "False", ")", "\n", "", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"Prior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "(", "-", "9", ",", "7", ")", ",", "addons", "=", "addons", ",", "with_data", "=", "False", ")", "\n", "\n", "# Figure 1b: posterior predictive", "\n", "bnn", ".", "clear_all_samples", "(", ")", "\n", "bnn", ".", "update_config", "(", "uid", "=", "\"F1b\"", ",", "use_ocbnn", "=", "False", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F1b_hmc1.pt'", ",", "'hmc_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F1b_hmc2.pt'", ",", "'hmc_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "(", "-", "9", ",", "7", ")", ",", "addons", "=", "addons", ")", "\n", "\n", "# Figure 5a: posterior predictive using SVGD", "\n", "bnn", "=", "BNNSVGDRegressor", "(", "uid", "=", "\"F5a\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/F5a.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy1", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F5a_svgd1.pt'", ",", "'hmc_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "bnn", ".", "add_deterministic_constraint", "(", "constrained_domain", "=", "(", "-", "0.3", ",", "0.3", ")", ",", "interval_func", "=", "ifunc", ",", "prior_type", "=", "\"negative_exponential_cocp\"", ")", "\n", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F5a_svgd2.pt'", ",", "'hmc_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "(", "-", "9", ",", "7", ")", ",", "plot_type", "=", "\"full\"", ",", "addons", "=", "addons", ")", "\n", "\n", "# Figure 5b: posterior predictive using BBB", "\n", "bnn", "=", "BNNBBBRegressor", "(", "uid", "=", "\"F5b\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/F5b.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy1", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F5b_bbb1.pt'", ",", "'hmc_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "bnn", ".", "add_deterministic_constraint", "(", "constrained_domain", "=", "(", "-", "0.3", ",", "0.3", ")", ",", "interval_func", "=", "ifunc", ",", "prior_type", "=", "\"negative_exponential_cocp\"", ")", "\n", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F5b_bbb2.pt'", ",", "'hmc_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "(", "-", "9", ",", "7", ")", ",", "addons", "=", "addons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_toys.figure2": [[111, 153], ["torch.arange", "BNNHMCClassifier", "BNNHMCClassifier.load", "bnn.utils.plot_2d3classifier", "BNNHMCClassifier.add_deterministic_constraint", "BNNHMCClassifier.update_config", "bnn.utils.plot_2d3classifier", "BNNHMCClassifier.clear_all_samples", "BNNHMCClassifier.update_config", "bnn.utils.plot_2d3classifier", "BNNHMCClassifier.update_config", "bnn.utils.plot_2d3classifier", "matplotlib.gca().add_patch", "BNNHMCClassifier.debug_mode", "BNNHMCClassifier.load_bayes_samples", "BNNHMCClassifier.infer", "BNNHMCClassifier.load_bayes_samples", "BNNHMCClassifier.infer", "BNNHMCClassifier.load_bayes_samples", "BNNHMCClassifier.infer", "BNNHMCClassifier.load_bayes_samples", "BNNHMCClassifier.infer", "matplotlib.Rectangle", "data.dataloader.toy2", "matplotlib.gca"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_2d3classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_deterministic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_2d3classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.clear_all_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_2d3classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_2d3classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy2"], ["", "def", "figure2", "(", ")", ":", "\n", "\t", "\"\"\"\n\tSection 5, Figure 2a and 2b (insets are baselines).\n\t\"\"\"", "\n", "domain", "=", "torch", ".", "arange", "(", "-", "5", ",", "5", ",", "0.1", ")", "\n", "\n", "# Plot constraints.", "\n", "def", "addons", "(", ")", ":", "\n", "\t\t", "plt", ".", "gca", "(", ")", ".", "add_patch", "(", "plt", ".", "Rectangle", "(", "(", "1.0", ",", "-", "2.0", ")", ",", "2.0", ",", "2.0", ",", "facecolor", "=", "COLORS", "[", "'green'", "]", "[", "0", "]", ",", "linewidth", "=", "2.0", ",", "edgecolor", "=", "'k'", ",", "alpha", "=", "0.5", ")", ")", "\n", "\n", "# Figure 2a: prior predictive", "\n", "", "bnn", "=", "BNNHMCClassifier", "(", "uid", "=", "'F2a'", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/F2a.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy2", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F2a_hmc1.pt'", ",", "'hmc_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", "with_data", "=", "False", ")", "\n", "", "plot_2d3classifier", "(", "bnn", ",", "plot_title", "=", "\"Prior Predictive (Baseline)\"", ",", "x1_domain", "=", "domain", ",", "x2_domain", "=", "domain", ",", "addons", "=", "addons", ",", "with_data", "=", "False", ")", "\n", "bnn", ".", "add_deterministic_constraint", "(", "constrained_domain", "=", "(", "1.0", ",", "3.0", ",", "-", "2.0", ",", "0.0", ")", ",", "forbidden_classes", "=", "[", "0", ",", "2", "]", ",", "prior_type", "=", "\"positive_dirichlet_cocp\"", ")", "\n", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F2a_hmc2.pt'", ",", "'hmc_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", "with_data", "=", "False", ")", "\n", "", "plot_2d3classifier", "(", "bnn", ",", "plot_title", "=", "\"Prior Predictive\"", ",", "x1_domain", "=", "domain", ",", "x2_domain", "=", "domain", ",", "addons", "=", "addons", ",", "with_data", "=", "False", ")", "\n", "\n", "# Figure 2b: posterior predictive", "\n", "bnn", ".", "clear_all_samples", "(", ")", "\n", "bnn", ".", "update_config", "(", "uid", "=", "\"F2b\"", ",", "use_ocbnn", "=", "False", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F2b_hmc1.pt'", ",", "'hmc_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_2d3classifier", "(", "bnn", ",", "plot_title", "=", "\"Posterior Predictive (Baseline)\"", ",", "x1_domain", "=", "domain", ",", "x2_domain", "=", "domain", ",", "addons", "=", "addons", ")", "\n", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F2b_hmc2.pt'", ",", "'hmc_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_2d3classifier", "(", "bnn", ",", "plot_title", "=", "\"Posterior Predictive\"", ",", "x1_domain", "=", "domain", ",", "x2_domain", "=", "domain", ",", "addons", "=", "addons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_toys.figure3a": [[155, 185], ["torch.arange().unsqueeze", "BNNHMCRegressor", "BNNHMCRegressor.load", "BNNHMCRegressor.add_deterministic_constraint", "BNNHMCRegressor.update_config", "bnn.utils.plot_1dregressor", "matplotlib.fill_between", "matplotlib.fill_between", "BNNHMCRegressor.debug_mode", "BNNHMCRegressor.load_bayes_samples", "BNNHMCRegressor.infer", "BNNHMCRegressor.load_gaussian_aocp_parameters", "BNNHMCRegressor.learn_gaussian_aocp", "BNNHMCRegressor.load_bayes_samples", "BNNHMCRegressor.infer", "torch.arange", "numpy.arange", "numpy.arange", "data.dataloader.toy3", "x.item"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_deterministic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_gaussian_aocp_parameters", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.learn_gaussian_aocp", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy3"], ["", "def", "figure3a", "(", ")", ":", "\n", "\t", "\"\"\"\n\tSection 5, Figure 3a.\n\t\"\"\"", "\n", "domain", "=", "torch", ".", "arange", "(", "-", "8", ",", "8", ",", "0.05", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "def", "ifunc", "(", "X", ")", ":", "return", "[", "[", "(", "-", "np", ".", "inf", ",", "0", ")", "if", "x", ".", "item", "(", ")", "<", "0", "else", "(", "0", ",", "np", ".", "inf", ")", "]", "for", "x", "in", "X", "]", "\n", "\n", "def", "addons", "(", ")", ":", "\n", "\t\t", "plt", ".", "fill_between", "(", "np", ".", "arange", "(", "-", "10", ",", "0", ",", "0.05", ")", ",", "-", "3.0", ",", "0.0", ",", "facecolor", "=", "COLORS", "[", "'green'", "]", "[", "0", "]", ",", "alpha", "=", "COLORS", "[", "'green'", "]", "[", "1", "]", ",", "zorder", "=", "101", ")", "\n", "plt", ".", "fill_between", "(", "np", ".", "arange", "(", "0", ",", "10", ",", "0.05", ")", ",", "0.0", ",", "3.0", ",", "facecolor", "=", "COLORS", "[", "'green'", "]", "[", "0", "]", ",", "alpha", "=", "COLORS", "[", "'green'", "]", "[", "1", "]", ",", "zorder", "=", "101", ")", "\n", "\n", "", "bnn", "=", "BNNHMCRegressor", "(", "uid", "=", "\"F3a\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/F3a.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy3", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F3a_hmc1.pt'", ",", "'hmc_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "bnn", ".", "add_deterministic_constraint", "(", "constrained_domain", "=", "(", "-", "3", ",", "3", ")", ",", "interval_func", "=", "ifunc", ",", "prior_type", "=", "\"gaussian_aocp\"", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_gaussian_aocp_parameters", "(", "'repro/F3a_aocp.pt'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "learn_gaussian_aocp", "(", ")", "\n", "", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F3a_hmc2.pt'", ",", "'hmc_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "(", "-", "3", ",", "3", ")", ",", "addons", "=", "addons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_toys.figure3bc": [[187, 258], ["torch.arange().unsqueeze", "BNNSVGDRegressor", "BNNSVGDRegressor.load", "BNNSVGDRegressor.add_deterministic_constraint", "BNNSVGDRegressor.update_config", "bnn.utils.plot_1dregressor", "torch.arange().unsqueeze", "BNNSVGDRegressor", "BNNSVGDRegressor.load", "BNNSVGDRegressor.predict().squeeze().t", "bnn.utils.generic_plot", "matplotlib.fill_between", "BNNSVGDRegressor.debug_mode", "BNNSVGDRegressor.load_bayes_samples", "BNNSVGDRegressor.infer", "BNNSVGDRegressor.load_bayes_samples", "BNNSVGDRegressor.infer", "BNNSVGDRegressor.debug_mode", "BNNSVGDRegressor.load_bayes_samples", "BNNSVGDRegressor.infer", "any", "len", "BNNSVGDRegressor", "BNNSVGDRegressor.load", "BNNSVGDRegressor.update_config", "BNNSVGDRegressor.add_deterministic_constraint", "BNNSVGDRegressor.predict().squeeze().t", "svgd_ocbnn.append", "matplotlib.plot", "matplotlib.plot", "torch.arange", "numpy.arange", "data.dataloader.toy4", "torch.arange", "data.dataloader.toy4", "BNNSVGDRegressor.predict().squeeze", "BNNSVGDRegressor.debug_mode", "BNNSVGDRegressor.load_bayes_samples", "BNNSVGDRegressor.infer", "any", "numpy.log", "range", "data.dataloader.toy4", "BNNSVGDRegressor.predict().squeeze", "len", "len", "BNNSVGDRegressor.predict", "BNNSVGDRegressor.predict"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_deterministic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.generic_plot", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_deterministic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy4", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy4", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy4", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.predict", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.predict"], ["", "def", "figure3bc", "(", ")", ":", "\n", "\t", "\"\"\"\n\tSection 5, Figure 3b and c.\n\t\"\"\"", "\n", "domain", "=", "torch", ".", "arange", "(", "-", "5", ",", "5", ",", "0.05", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "def", "ifunc", "(", "X", ")", ":", "return", "[", "[", "(", "-", "np", ".", "inf", ",", "1.0", ")", ",", "(", "2.5", ",", "np", ".", "inf", ")", "]", "for", "_", "in", "range", "(", "len", "(", "X", ")", ")", "]", "\n", "\n", "# Plot constraints.", "\n", "def", "addons", "(", ")", ":", "\n", "\t\t", "plt", ".", "fill_between", "(", "np", ".", "arange", "(", "-", "1.0", ",", "1.0", ",", "0.05", ")", ",", "1.0", ",", "2.5", ",", "facecolor", "=", "COLORS", "[", "'red'", "]", "[", "0", "]", ",", "alpha", "=", "0.5", ",", "zorder", "=", "101", ")", "\n", "\n", "# Figure 3b: posterior predictive", "\n", "", "bnn", "=", "BNNSVGDRegressor", "(", "uid", "=", "'F3b'", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/F3b.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy4", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F3b_svgd1.pt'", ",", "'svgd_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "bnn", ".", "add_deterministic_constraint", "(", "constrained_domain", "=", "(", "-", "1.0", ",", "1.0", ")", ",", "interval_func", "=", "ifunc", ",", "prior_type", "=", "\"negative_exponential_cocp\"", ")", "\n", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F3b_svgd2.pt'", ",", "'svgd_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "(", "-", "3", ",", "6", ")", ",", "plot_type", "=", "\"full\"", ",", "addons", "=", "addons", ")", "\n", "\n", "# Figure 3c: rejection sampling efficiency", "\n", "# This plot will be time-consuming because we use 100 SVGD particles for inference.", "\n", "svgd_ocbnn", "=", "[", "]", "\n", "rs_nsamples", "=", "[", "1", ",", "5", ",", "10", ",", "100", ",", "500", ",", "1000", "]", "\n", "rs_domain", "=", "torch", ".", "arange", "(", "-", "1.0", ",", "1.0", ",", "0.05", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "\n", "bnn", "=", "BNNSVGDRegressor", "(", "uid", "=", "f'F3c-base'", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/F3c.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy4", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F3b_svgd1.pt'", ",", "'svgd_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "results", "=", "bnn", ".", "predict", "(", "bnn", ".", "all_bayes_samples", "[", "0", "]", "[", "0", "]", ",", "rs_domain", ")", ".", "squeeze", "(", ")", ".", "t", "(", ")", "\n", "violation_count", "=", "0", "\n", "for", "line", "in", "results", ".", "T", ":", "\n", "\t\t", "violation_count", "+=", "any", "(", "[", "(", "point", ">", "1.0", "and", "point", "<", "2.5", ")", "for", "point", "in", "line", "]", ")", "\n", "", "svgd_baseline", "=", "violation_count", "/", "len", "(", "results", ".", "T", ")", "\n", "\n", "for", "c", "in", "rs_nsamples", ":", "\n", "\t\t", "bnn", "=", "BNNSVGDRegressor", "(", "uid", "=", "f'F3c-{c}'", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/F3c.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy4", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "bnn", ".", "update_config", "(", "ocp_nsamples", "=", "c", ",", "use_ocbnn", "=", "True", ")", "\n", "bnn", ".", "add_deterministic_constraint", "(", "constrained_domain", "=", "(", "-", "1.0", ",", "1.0", ")", ",", "interval_func", "=", "ifunc", ",", "prior_type", "=", "\"negative_exponential_cocp\"", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t\t", "bnn", ".", "load_bayes_samples", "(", "f'repro/F3c-{c}_svgd1.pt'", ",", "f'svgd_ocbnn_{c}'", ")", "\n", "", "else", ":", "\n", "\t\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "results", "=", "bnn", ".", "predict", "(", "bnn", ".", "all_bayes_samples", "[", "0", "]", "[", "0", "]", ",", "rs_domain", ")", ".", "squeeze", "(", ")", ".", "t", "(", ")", "\n", "violation_count", "=", "0", "\n", "for", "line", "in", "results", ".", "T", ":", "\n", "\t\t\t", "violation_count", "+=", "any", "(", "[", "(", "point", ">", "1.0", "and", "point", "<", "2.5", ")", "for", "point", "in", "line", "]", ")", "\n", "", "svgd_ocbnn", ".", "append", "(", "violation_count", "/", "len", "(", "results", ".", "T", ")", ")", "\n", "\n", "", "def", "rs_addons", "(", ")", ":", "\n", "\t\t", "plt", ".", "plot", "(", "[", "0", ",", "7", "]", ",", "[", "svgd_baseline", ",", "svgd_baseline", "]", ",", "'k--'", ")", "\n", "plt", ".", "plot", "(", "np", ".", "log", "(", "rs_nsamples", ")", ",", "svgd_ocbnn", ",", "'bP--'", ")", "\n", "\n", "", "generic_plot", "(", "plot_title", "=", "\"Fraction of Rejected Posterior Samples\"", ",", "xlims", "=", "(", "-", "0.5", ",", "7.5", ")", ",", "ylims", "=", "(", "0.0", ",", "1.1", ")", ",", "\n", "xlabel", "=", "r'log(samples) from $\\mathcal{C}_\\mathbf{x}$'", ",", "ylabel", "=", "'Fraction'", ",", "addons", "=", "rs_addons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_toys.figure4": [[260, 287], ["torch.arange", "BNNHMCBinaryClassifier", "BNNHMCBinaryClassifier.load", "bnn.utils.plot_2d2classifier", "BNNHMCBinaryClassifier.add_probabilistic_constraint", "BNNHMCBinaryClassifier.update_config", "bnn.utils.plot_2d2classifier", "BNNHMCBinaryClassifier.debug_mode", "BNNHMCBinaryClassifier.load_bayes_samples", "BNNHMCBinaryClassifier.infer", "BNNHMCBinaryClassifier.load_gaussian_aocp_parameters", "BNNHMCBinaryClassifier.learn_gaussian_aocp", "BNNHMCBinaryClassifier.load_bayes_samples", "BNNHMCBinaryClassifier.infer", "data.dataloader.toy5"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_2d2classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_probabilistic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_2d2classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_gaussian_aocp_parameters", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.learn_gaussian_aocp", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy5"], ["", "def", "figure4", "(", ")", ":", "\n", "\t", "\"\"\"\n\tSection 5, Figure 4.\n\t\"\"\"", "\n", "domain", "=", "torch", ".", "arange", "(", "-", "0.5", ",", "1.5", ",", "0.01", ")", "\n", "def", "pfunc", "(", "X", ")", ":", "return", "X", "[", ":", ",", "1", "]", "\n", "\n", "bnn", "=", "BNNHMCBinaryClassifier", "(", "uid", "=", "\"F4\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/F4.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy5", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F4_hmc1.pt'", ",", "'hmc_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_2d2classifier", "(", "bnn", ",", "plot_title", "=", "\"Posterior Predictive (Baseline)\"", ",", "x1_domain", "=", "domain", ",", "x2_domain", "=", "domain", ",", "addons", "=", "None", ")", "\n", "bnn", ".", "add_probabilistic_constraint", "(", "constrained_domain", "=", "(", "-", "0.5", ",", "1.5", ",", "0.0", ",", "1.0", ")", ",", "prob_func", "=", "pfunc", ",", "prior_type", "=", "\"gaussian_aocp\"", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_gaussian_aocp_parameters", "(", "'repro/F4_aocp.pt'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "learn_gaussian_aocp", "(", ")", "\n", "", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F4_hmc2.pt'", ",", "'hmc_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_2d2classifier", "(", "bnn", ",", "plot_title", "=", "\"Posterior Predictive\"", ",", "x1_domain", "=", "domain", ",", "x2_domain", "=", "domain", ",", "addons", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.None.run_toys.figure6": [[289, 323], ["torch.arange().unsqueeze", "BNNHMCRegressor", "BNNHMCRegressor.load", "BNNHMCRegressor.update_config", "bnn.utils.plot_1dregressor", "matplotlib.plot", "BNNHMCRegressor.debug_mode", "BNNHMCRegressor.load_bayes_samples", "BNNHMCRegressor.infer", "BNNHMCRegressor.add_deterministic_constraint", "BNNHMCRegressor.load_bayes_samples", "BNNHMCRegressor.infer", "torch.arange", "numpy.cos", "torch.arange().unsqueeze.squeeze", "ground_truth().squeeze", "torch.arange", "matplotlib.fill_between", "data.dataloader.toy6", "torch.ones", "torch.ones", "run_toys.figure6.ground_truth"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_deterministic_constraint", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer", "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy6"], ["", "def", "figure6", "(", ")", ":", "\n", "\t", "\"\"\"\n\tAppendix D, Figure 6.\n\t\"\"\"", "\n", "domain", "=", "torch", ".", "arange", "(", "-", "20", ",", "20", ",", "0.05", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "queries", "=", "[", "3.89", ",", "-", "2.01", ",", "15.03", "]", "\n", "def", "ifunc", "(", "X", ")", ":", "return", "[", "[", "(", "5", "*", "np", ".", "cos", "(", "x", ".", "item", "(", ")", "/", "1.7", ")", ",", "5", "*", "np", ".", "cos", "(", "x", ".", "item", "(", ")", "/", "1.7", ")", ")", "]", "for", "x", "in", "X", "]", "\n", "def", "ground_truth", "(", "x", ")", ":", "return", "5", "*", "np", ".", "cos", "(", "x", "/", "1.7", ")", "\n", "\n", "# Plot constraints and ground-truth function.", "\n", "def", "addons", "(", ")", ":", "\n", "\t\t", "plt", ".", "plot", "(", "domain", ".", "squeeze", "(", ")", ",", "ground_truth", "(", "domain", ")", ".", "squeeze", "(", ")", ",", "'g--'", ",", "linewidth", "=", "2.0", ",", "zorder", "=", "199", ")", "\n", "for", "s", "in", "queries", ":", "\n", "\t\t\t", "dom", "=", "torch", ".", "arange", "(", "s", "-", "0.5", ",", "s", "+", "0.5", ",", "0.05", ")", "\n", "dyl", "=", "torch", ".", "ones", "(", "len", "(", "dom", ")", ")", "*", "-", "10.0", "\n", "dyu", "=", "torch", ".", "ones", "(", "len", "(", "dom", ")", ")", "*", "8.0", "\n", "plt", ".", "fill_between", "(", "dom", ",", "dyl", ",", "dyu", ",", "facecolor", "=", "COLORS", "[", "'green'", "]", "[", "0", "]", ",", "alpha", "=", "COLORS", "[", "'green'", "]", "[", "1", "]", ")", "\n", "\n", "", "", "bnn", "=", "BNNHMCRegressor", "(", "uid", "=", "\"F6\"", ",", "configfile", "=", "args", ".", "custom_config", "or", "\"repro/F6.yaml\"", ")", "\n", "bnn", ".", "load", "(", "**", "toy6", "(", ")", ")", "\n", "if", "args", ".", "debug", ":", "\n", "\t\t", "bnn", ".", "debug_mode", "(", ")", "\n", "", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F6_hmc1.pt'", ",", "'hmc_baseline'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "for", "s", "in", "queries", ":", "\n", "\t\t", "bnn", ".", "add_deterministic_constraint", "(", "constrained_domain", "=", "(", "s", "-", "0.5", ",", "s", "+", "0.5", ")", ",", "interval_func", "=", "ifunc", ",", "prior_type", "=", "\"positive_gaussian_cocp\"", ")", "\n", "", "bnn", ".", "update_config", "(", "use_ocbnn", "=", "True", ")", "\n", "if", "args", ".", "pretrained", ":", "\n", "\t\t", "bnn", ".", "load_bayes_samples", "(", "'repro/F6_hmc2.pt'", ",", "'hmc_ocbnn'", ")", "\n", "", "else", ":", "\n", "\t\t", "bnn", ".", "infer", "(", ")", "\n", "", "plot_1dregressor", "(", "bnn", ",", "plot_title", "=", "\"Posterior Predictive\"", ",", "domain", "=", "domain", ",", "ylims", "=", "(", "-", "9", ",", "7", ")", ",", "addons", "=", "addons", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.models.BNNHMCRegressor.__init__": [[12, 14], ["base.BayesianNeuralNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.models.BNNHMCClassifier.__init__": [[18, 20], ["base.BayesianNeuralNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.models.BNNHMCBinaryClassifier.__init__": [[24, 26], ["base.BayesianNeuralNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.models.BNNBBBRegressor.__init__": [[30, 32], ["base.BayesianNeuralNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.models.BNNBBBClassifier.__init__": [[36, 38], ["base.BayesianNeuralNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.models.BNNBBBBinaryClassifier.__init__": [[42, 44], ["base.BayesianNeuralNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.models.BNNSVGDRegressor.__init__": [[48, 50], ["base.BayesianNeuralNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.models.BNNSVGDClassifier.__init__": [[54, 56], ["base.BayesianNeuralNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.models.BNNSVGDBinaryClassifier.__init__": [[60, 62], ["base.BayesianNeuralNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.models.BNNSGLDRegressor.__init__": [[66, 68], ["base.BayesianNeuralNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.models.BNNSGLDClassifier.__init__": [[72, 74], ["base.BayesianNeuralNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.models.BNNSGLDBinaryClassifier.__init__": [[78, 80], ["base.BayesianNeuralNetwork.__init__"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__"], ["\t", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.__init__": [[30, 49], ["dict", "dict", "logging.info", "open", "yaml.load", "base.BayesianNeuralNetwork.__dict__.update", "os.path.isdir", "os.mkdir", "open", "yaml.dump"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load"], ["def", "__init__", "(", "self", ",", "uid", "=", "\"bnn-0\"", ",", "configfile", "=", "\"config.yaml\"", ")", ":", "\n", "\t\t", "\"\"\" Instantiates the BNN. \"\"\"", "\n", "self", ".", "uid", "=", "uid", "\n", "with", "open", "(", "configfile", ",", "'r'", ")", "as", "rf", ":", "\n", "\t\t\t", "config", "=", "yaml", ".", "load", "(", "rf", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "\n", "self", ".", "__dict__", ".", "update", "(", "config", ")", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "'history'", ")", ":", "\n", "\t\t\t", "os", ".", "mkdir", "(", "'history'", ")", "\n", "# Saves a copy of the configs in the `history/` folder.", "\n", "", "with", "open", "(", "f'history/{self.uid}.yaml'", ",", "'w'", ")", "as", "wf", ":", "\n", "\t\t\t", "yaml", ".", "dump", "(", "config", ",", "wf", ")", "\n", "\n", "", "self", ".", "all_bayes_samples", "=", "[", "]", "\n", "self", ".", "dconstraints", "=", "dict", "(", ")", "\n", "self", ".", "pconstraints", "=", "dict", "(", ")", "\n", "self", ".", "aocp_mean", "=", "None", "\n", "self", ".", "aocp_std", "=", "None", "\n", "\n", "logging", ".", "info", "(", "f'[{self.uid}] BNN instantiated. Configs saved as `history/{self.uid}.yaml`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load": [[50, 71], ["base.BayesianNeuralNetwork.__dict__.update", "hasattr", "list", "sum", "torch.autograd.Variable", "logging.info", "zip", "torch.distributions.normal.Normal().sample", "torch.Size", "torch.distributions.normal.Normal"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "\"\"\" Loads dataset. \"\"\"", "\n", "\n", "# Define train/test sets.", "\n", "self", ".", "__dict__", ".", "update", "(", "kwargs", ")", "\n", "self", ".", "Xdim", "=", "self", ".", "X_train", ".", "shape", "[", "1", "]", "\n", "self", ".", "Ydim", "=", "self", ".", "_Ydim", "\n", "self", ".", "N_train", "=", "self", ".", "Y_train", ".", "shape", "[", "0", "]", "\n", "if", "hasattr", "(", "self", ",", "'Y_test'", ")", ":", "\n", "\t\t\t", "self", ".", "N_test", "=", "self", ".", "Y_test", ".", "shape", "[", "0", "]", "\n", "test_stats", "=", "f\" and {self.N_test} test points\"", "\n", "", "else", ":", "\n", "\t\t\t", "test_stats", "=", "\"\"", "\n", "\n", "# Initialize weights.", "\n", "", "self", ".", "layer_sizes", "=", "[", "self", ".", "Xdim", "]", "+", "self", ".", "architecture", "+", "[", "self", ".", "Ydim", "]", "\n", "self", ".", "layer_shapes", "=", "list", "(", "zip", "(", "self", ".", "layer_sizes", "[", ":", "-", "1", "]", ",", "self", ".", "layer_sizes", "[", "1", ":", "]", ")", ")", "\n", "self", ".", "nweights", "=", "sum", "(", "(", "m", "+", "1", ")", "*", "n", "for", "m", ",", "n", "in", "self", ".", "layer_shapes", ")", "\n", "self", ".", "weights", "=", "Variable", "(", "Normal", "(", "0", ",", "self", ".", "sigma_w", ")", ".", "sample", "(", "torch", ".", "Size", "(", "[", "self", ".", "nweights", "]", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n", "logging", ".", "info", "(", "f'[{self.uid}] Dataset <{self.dataset_name}> loaded: {self.N_train} training points{test_stats}.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork._unpack_layers": [[72, 78], ["weights[].reshape", "weights[].reshape"], "methods", ["None"], ["", "def", "_unpack_layers", "(", "self", ",", "weights", ")", ":", "\n", "\t\t", "\"\"\" Helper function for forward pass. Implementation from PyTorch. \"\"\"", "\n", "num_weight_samples", "=", "weights", ".", "shape", "[", "0", "]", "\n", "for", "m", ",", "n", "in", "self", ".", "layer_shapes", ":", "\n", "\t\t\t", "yield", "weights", "[", ":", ",", ":", "m", "*", "n", "]", ".", "reshape", "(", "(", "num_weight_samples", ",", "m", ",", "n", ")", ")", ",", "weights", "[", ":", ",", "m", "*", "n", ":", "m", "*", "n", "+", "n", "]", ".", "reshape", "(", "(", "num_weight_samples", ",", "1", ",", "n", ")", ")", "\n", "weights", "=", "weights", "[", ":", ",", "(", "m", "+", "1", ")", "*", "n", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork._nonlinearity": [[79, 88], ["torch.exp", "torch.max", "x.pow", "torch.zeros_like"], "methods", ["None"], ["", "", "def", "_nonlinearity", "(", "self", ",", "x", ")", ":", "\n", "\t\t", "\"\"\" Activation function.\n\t\t\tImplement custom functions below with additional control statements.  \n\t\t\"\"\"", "\n", "if", "self", ".", "activation", "==", "\"rbf\"", ":", "\n", "\t\t\t", "return", "torch", ".", "exp", "(", "-", "x", ".", "pow", "(", "2", ")", ")", "\n", "", "elif", "self", ".", "activation", "==", "\"relu\"", ":", "\n", "\t\t\t", "return", "torch", ".", "max", "(", "x", ",", "torch", ".", "zeros_like", "(", "x", ")", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward": [[89, 105], ["base.BayesianNeuralNetwork.expand", "base.BayesianNeuralNetwork._unpack_layers", "outputs.squeeze.squeeze.squeeze", "weights.unsqueeze.unsqueeze.ndimension", "weights.unsqueeze.unsqueeze.unsqueeze", "base.BayesianNeuralNetwork._nonlinearity", "torch.einsum"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork._unpack_layers", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork._nonlinearity"], ["", "def", "forward", "(", "self", ",", "X", ",", "weights", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Forward pass of BNN. Implementation from PyTorch. \"\"\"", "\n", "if", "weights", "is", "None", ":", "\n", "\t\t\t", "weights", "=", "self", ".", "weights", "\n", "\n", "", "if", "weights", ".", "ndimension", "(", ")", "==", "1", ":", "\n", "\t\t\t", "weights", "=", "weights", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "num_weight_samples", "=", "weights", ".", "shape", "[", "0", "]", "\n", "X", "=", "X", ".", "expand", "(", "num_weight_samples", ",", "*", "X", ".", "shape", ")", "\n", "for", "W", ",", "b", "in", "self", ".", "_unpack_layers", "(", "weights", ")", ":", "\n", "\t\t\t", "outputs", "=", "torch", ".", "einsum", "(", "'mnd,mdo->mno'", ",", "[", "X", ",", "W", "]", ")", "+", "b", "\n", "X", "=", "self", ".", "_nonlinearity", "(", "outputs", ")", "\n", "\n", "", "outputs", "=", "outputs", ".", "squeeze", "(", "dim", "=", "0", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.log_prior": [[106, 122], ["base.BayesianNeuralNetwork.isotropic_gaussian_prior", "base.BayesianNeuralNetwork.isotropic_gaussian_prior", "base.BayesianNeuralNetwork.isotropic_gaussian_prior", "base.BayesianNeuralNetwork.positive_gaussian_cocp", "base.BayesianNeuralNetwork.negative_exponential_cocp", "base.BayesianNeuralNetwork.positive_dirichlet_cocp"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.isotropic_gaussian_prior", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.isotropic_gaussian_prior", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.isotropic_gaussian_prior", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin.positive_gaussian_cocp", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin.negative_exponential_cocp", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.ClassifierMixin.positive_dirichlet_cocp"], ["", "def", "log_prior", "(", "self", ")", ":", "\n", "\t\t", "\"\"\" Computes the prior.\n\t\t\tAutomatically decides which output-constrained prior to use, depending on existing constraints.  \n\t\t\"\"\"", "\n", "if", "self", ".", "use_ocbnn", ":", "\n", "\t\t\t", "if", "self", ".", "aocp_mean", "is", "not", "None", ":", "\n", "\t\t\t\t", "return", "self", ".", "isotropic_gaussian_prior", "(", "mean", "=", "self", ".", "aocp_mean", ",", "std", "=", "self", ".", "aocp_std", ")", "\n", "", "logp", "=", "self", ".", "isotropic_gaussian_prior", "(", ")", "\n", "if", "\"positive_gaussian_cocp\"", "in", "self", ".", "dconstraints", ":", "\n", "\t\t\t\t", "logp", "+=", "self", ".", "positive_gaussian_cocp", "(", ")", "\n", "", "if", "\"negative_exponential_cocp\"", "in", "self", ".", "dconstraints", ":", "\n", "\t\t\t\t", "logp", "+=", "self", ".", "negative_exponential_cocp", "(", ")", "\n", "", "if", "\"positive_dirichlet_cocp\"", "in", "self", ".", "dconstraints", ":", "\n", "\t\t\t\t", "logp", "+=", "self", ".", "positive_dirichlet_cocp", "(", ")", "\n", "", "return", "logp", "\n", "", "return", "self", ".", "isotropic_gaussian_prior", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.log_posterior": [[123, 126], ["base.BayesianNeuralNetwork.log_prior", "base.BayesianNeuralNetwork.log_likelihood"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.log_prior", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.log_likelihood"], ["", "def", "log_posterior", "(", "self", ",", "batch_indices", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Computes the posterior. \"\"\"", "\n", "return", "self", ".", "log_prior", "(", ")", "+", "self", ".", "log_likelihood", "(", "batch_indices", "=", "batch_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.isotropic_gaussian_prior": [[127, 134], ["torch.distributions.normal.Normal().log_prob().sum", "torch.distributions.normal.Normal().log_prob", "torch.distributions.normal.Normal"], "methods", ["None"], ["", "def", "isotropic_gaussian_prior", "(", "self", ",", "weights", "=", "None", ",", "mean", "=", "0", ",", "std", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Isotropic Gaussian prior. \"\"\"", "\n", "if", "weights", "is", "None", ":", "\n", "\t\t\t", "weights", "=", "self", ".", "weights", "\n", "", "if", "std", "is", "None", ":", "\n", "\t\t\t", "std", "=", "self", ".", "sigma_w", "\n", "", "return", "Normal", "(", "mean", ",", "std", ")", ".", "log_prob", "(", "weights", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork._sample_from_hypercube": [[135, 158], ["torch.tensor", "range", "torch.t", "float", "float", "torch.distributions.uniform.Uniform().sample().unsqueeze", "torch.cat", "torch.cat", "torch.distributions.uniform.Uniform().sample", "torch.Size", "torch.linspace().unsqueeze", "torch.distributions.uniform.Uniform", "torch.linspace"], "methods", ["None"], ["", "def", "_sample_from_hypercube", "(", "self", ",", "region", ",", "nsamples", ",", "mode", "=", "'uniform'", ")", ":", "\n", "\t\t", "\"\"\" Generate `nsamples` points from the hypercube `region`.\n\n\t\t\tArgs:\n\t\t\t\tmode: 'uniform' for uniform sampling, 'even' for evenly-spaced sampling\n\t\t\tReturns:\n\t\t\t\tTensor of shape (nsamples, self.Xdim)\n\t\t\"\"\"", "\n", "samples", "=", "torch", ".", "tensor", "(", "[", "]", ")", "\n", "for", "d", "in", "range", "(", "self", ".", "Xdim", ")", ":", "\n", "\t\t\t", "lower", "=", "self", ".", "X_train_min", "[", "d", "]", "\n", "if", "region", "[", "2", "*", "d", "]", ">", "-", "np", ".", "inf", ":", "\n", "\t\t\t\t", "lower", "=", "region", "[", "2", "*", "d", "]", "\n", "", "upper", "=", "self", ".", "X_train_max", "[", "d", "]", "\n", "if", "region", "[", "2", "*", "d", "+", "1", "]", "<", "np", ".", "inf", ":", "\n", "\t\t\t\t", "upper", "=", "region", "[", "2", "*", "d", "+", "1", "]", "\n", "", "lower", ",", "upper", "=", "float", "(", "lower", ")", ",", "float", "(", "upper", ")", "\n", "if", "mode", "==", "'uniform'", ":", "\n", "\t\t\t\t", "unif", "=", "Uniform", "(", "lower", ",", "upper", ")", ".", "sample", "(", "torch", ".", "Size", "(", "[", "nsamples", "]", ")", ")", ".", "unsqueeze", "(", "0", ")", "\n", "samples", "=", "torch", ".", "cat", "(", "(", "samples", ",", "unif", ")", ",", "0", ")", "\n", "", "elif", "mode", "==", "'even'", ":", "\n", "\t\t\t\t", "samples", "=", "torch", ".", "cat", "(", "(", "samples", ",", "torch", ".", "linspace", "(", "lower", ",", "upper", ",", "nsamples", ")", ".", "unsqueeze", "(", "0", ")", ")", ",", "0", ")", "\n", "", "", "return", "torch", ".", "t", "(", "samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_bayes_samples": [[159, 163], ["base.BayesianNeuralNetwork.all_bayes_samples.append", "logging.info", "torch.load", "len"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load"], ["", "def", "load_bayes_samples", "(", "self", ",", "filename", ",", "descriptor", "=", "\"sample\"", ")", ":", "\n", "\t\t", "\"\"\" Load prior/posterior samples from file and appends to `self.all_bayes_samples`. \"\"\"", "\n", "self", ".", "all_bayes_samples", ".", "append", "(", "(", "torch", ".", "load", "(", "filename", ")", ",", "descriptor", ")", ")", "\n", "logging", ".", "info", "(", "f\"[{self.uid}] Posterior Sample #{len(self.all_bayes_samples)}: Loaded from `{filename}`.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.learn_gaussian_aocp": [[164, 189], ["torch.autograd.Variable", "torch.optim.Adagrad", "range", "base.BayesianNeuralNetwork._aocp_params.detach_", "torch.save", "logging.info", "torch.randn", "torch.ones", "torch.cat", "torch.optim.Adagrad.zero_grad", "base.BayesianNeuralNetwork.gaussian_aocp_objective", "base.BayesianNeuralNetwork.backward", "torch.optim.Adagrad.step", "torch.logsumexp", "logging.info", "torch.stack", "torch.zeros", "base.BayesianNeuralNetwork.item"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.gaussian_aocp_objective"], ["", "def", "learn_gaussian_aocp", "(", "self", ",", "verbose", "=", "True", ")", ":", "\n", "\t\t", "\"\"\" Amortized output-constrained prior.\n\t\t\tOptimizes the constrained objective directly to learn AOCP parameters.\n\t\t\tAOCP parameters are also saved to file.\n\t\t\"\"\"", "\n", "# Initialize VP parameters.", "\n", "init_means", "=", "self", ".", "aocp_init_mean", "+", "torch", ".", "randn", "(", "self", ".", "nweights", ",", "1", ")", "\n", "init_log_stds", "=", "self", ".", "aocp_init_std", "*", "torch", ".", "ones", "(", "self", ".", "nweights", ",", "1", ")", "\n", "self", ".", "_aocp_params", "=", "Variable", "(", "torch", ".", "cat", "(", "[", "init_means", ",", "init_log_stds", "]", ",", "dim", "=", "1", ")", ",", "requires_grad", "=", "True", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adagrad", "(", "[", "self", ".", "_aocp_params", "]", ",", "lr", "=", "self", ".", "aocp_init_lr", ")", "\n", "\n", "# Optimize VP.", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "aocp_nepochs", "+", "1", ")", ":", "\n", "\t\t\t", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "self", ".", "gaussian_aocp_objective", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "if", "verbose", "and", "epoch", "%", "10", "==", "0", ":", "\n", "\t\t\t\t", "logging", ".", "info", "(", "f'[{self.uid}] Epoch {epoch}: {loss.item():.2f}'", ")", "\n", "\n", "", "", "self", ".", "_aocp_params", ".", "detach_", "(", ")", "\n", "torch", ".", "save", "(", "self", ".", "_aocp_params", ",", "f\"history/{self.uid}_aocp.pt\"", ")", "\n", "self", ".", "aocp_mean", "=", "self", ".", "_aocp_params", "[", ":", ",", "0", "]", "\n", "self", ".", "aocp_std", "=", "torch", ".", "logsumexp", "(", "torch", ".", "stack", "(", "(", "self", ".", "_aocp_params", "[", ":", ",", "1", "]", ",", "torch", ".", "zeros", "(", "self", ".", "nweights", ")", ")", ")", ",", "0", ")", "/", "self", ".", "aocp_std_multiplier", "\n", "logging", ".", "info", "(", "f'[{self.uid}] AOCP parameters learnt. Also saved as `history/{self.uid}_aocp.pt`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load_gaussian_aocp_parameters": [[190, 196], ["torch.load", "logging.info", "torch.logsumexp", "torch.stack", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.load"], ["", "def", "load_gaussian_aocp_parameters", "(", "self", ",", "filename", ")", ":", "\n", "\t\t", "\"\"\" Load AOCP parameters. \"\"\"", "\n", "aocp_params", "=", "torch", ".", "load", "(", "filename", ")", "\n", "self", ".", "aocp_mean", "=", "aocp_params", "[", ":", ",", "0", "]", "\n", "self", ".", "aocp_std", "=", "torch", ".", "logsumexp", "(", "torch", ".", "stack", "(", "(", "aocp_params", "[", ":", ",", "1", "]", ",", "torch", ".", "zeros", "(", "self", ".", "nweights", ")", ")", ")", ",", "0", ")", "/", "self", ".", "aocp_std_multiplier", "\n", "logging", ".", "info", "(", "f'[{self.uid}] Loaded AOCP parameters from `{filename}`. This replaces any previously loaded or learnt AOCP parameters.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.update_config": [[197, 201], ["base.BayesianNeuralNetwork.__dict__.update", "logging.info"], "methods", ["None"], ["", "def", "update_config", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "\"\"\" Helper function for updating configs. \"\"\"", "\n", "self", ".", "__dict__", ".", "update", "(", "**", "kwargs", ")", "\n", "logging", ".", "info", "(", "f'[{self.uid}] Configs updated.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.clear_all_samples": [[202, 206], ["logging.info"], "methods", ["None"], ["", "def", "clear_all_samples", "(", "self", ")", ":", "\n", "\t\t", "\"\"\" Empty self.all_bayes_samples. \"\"\"", "\n", "self", ".", "all_bayes_samples", "=", "[", "]", "\n", "logging", ".", "info", "(", "f'[{self.uid}] All posterior samples cleared from memory.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.debug_mode": [[207, 223], ["logging.info"], "methods", ["None"], ["", "def", "debug_mode", "(", "self", ")", ":", "\n", "\t\t", "\"\"\" Debug mode: collect a few samples only to ensure code/pipeline is working. \"\"\"", "\n", "self", ".", "old_infer_nsamples", "=", "self", ".", "infer_nsamples", "\n", "self", ".", "old_hmc_nburnin", "=", "self", ".", "hmc_nburnin", "\n", "self", ".", "old_bbb_epochs", "=", "self", ".", "bbb_epochs", "\n", "self", ".", "old_svgd_epochs", "=", "self", ".", "svgd_epochs", "\n", "self", ".", "old_sgld_nburnin", "=", "self", ".", "sgld_nburnin", "\n", "\n", "self", ".", "infer_nsamples", "=", "3", "\n", "self", ".", "hmc_nburnin", "=", "5", "\n", "self", ".", "bbb_epochs", "=", "100", "\n", "self", ".", "svgd_epochs", "=", "10", "\n", "self", ".", "sgld_nburnin", "=", "5", "\n", "self", ".", "aocp_nepochs", "=", "1", "\n", "\n", "logging", ".", "info", "(", "f'[{self.uid}] Debug mode activated.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.switch_off_debug_mode": [[224, 243], ["logging.info", "hasattr", "logging.error"], "methods", ["None"], ["", "def", "switch_off_debug_mode", "(", "self", ")", ":", "\n", "\t\t", "\"\"\" Deactivate debug mode. \"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "'old_infer_nsamples'", ")", ":", "\n", "\t\t\t", "logging", ".", "error", "(", "\"You cannot switch off debug mode without having turned it on first!\"", ")", "\n", "raise", "Exception", "\n", "\n", "", "self", ".", "infer_nsamples", "=", "self", ".", "old_infer_nsamples", "\n", "self", ".", "hmc_nburnin", "=", "self", ".", "old_hmc_nburnin", "\n", "self", ".", "bbb_epochs", "=", "self", ".", "old_bbb_epochs", "\n", "self", ".", "svgd_epochs", "=", "self", ".", "old_svgd_epochs", "\n", "self", ".", "sgld_nburnin", "=", "self", ".", "old_sgld_nburnin", "\n", "\n", "del", "self", ".", "old_infer_nsamples", "\n", "del", "self", ".", "old_hmc_nburnin", "\n", "del", "self", ".", "old_bbb_epochs", "\n", "del", "self", ".", "old_svgd_epochs", "\n", "del", "self", ".", "old_sgld_nburnin", "\n", "\n", "logging", ".", "info", "(", "f'[{self.uid}] Debug mode turned off.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin._Ydim": [[248, 251], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "_Ydim", "(", "self", ")", ":", "\n", "\t\t", "return", "self", ".", "Y_train", ".", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin.log_likelihood": [[252, 266], ["base.RegressorMixin.forward", "torch.distributions.multivariate_normal.MultivariateNormal.log_prob().sum", "len", "torch.distributions.normal.Normal().log_prob().sum", "torch.distributions.multivariate_normal.MultivariateNormal.log_prob", "torch.distributions.normal.Normal().log_prob", "torch.distributions.multivariate_normal.MultivariateNormal", "torch.distributions.normal.Normal", "torch.eye"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward"], ["", "def", "log_likelihood", "(", "self", ",", "batch_indices", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Computes the likelihood. \"\"\"", "\n", "if", "batch_indices", "is", "None", ":", "\n", "\t\t\t", "batch", "=", "self", ".", "X_train", "\n", "target", "=", "self", ".", "Y_train", "\n", "multiplier", "=", "1", "\n", "", "else", ":", "\n", "\t\t\t", "batch", "=", "self", ".", "X_train", "[", "batch_indices", "]", "\n", "target", "=", "self", ".", "Y_train", "[", "batch_indices", "]", "\n", "multiplier", "=", "(", "self", ".", "N_train", "/", "len", "(", "batch_indices", ")", ")", "\n", "", "means", "=", "self", ".", "forward", "(", "X", "=", "batch", ")", "\n", "if", "self", ".", "Ydim", "==", "1", ":", "\n", "\t\t\t", "return", "multiplier", "*", "Normal", "(", "0", ",", "self", ".", "sigma_noise", ")", ".", "log_prob", "(", "means", "-", "target", ")", ".", "sum", "(", ")", "\n", "", "return", "multiplier", "*", "MVN", "(", "means", ",", "self", ".", "sigma_noise", "*", "torch", ".", "eye", "(", "self", ".", "Ydim", ")", ")", ".", "log_prob", "(", "target", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin.predict": [[267, 278], ["torch.tensor", "numpy.apply_along_axis", "base.RegressorMixin.forward().numpy", "base.RegressorMixin.forward", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward"], ["", "def", "predict", "(", "self", ",", "bayes_samples", ",", "domain", ")", ":", "\n", "\t\t", "\"\"\" Generate BNN's prediction over `domain` for each sample.\n\n\t\t\tArgs: \n\t\t\t\t`bayes_samples` is a (M, self.nweights) tensor, representing M samples of the prior/posterior.\n\t\t\t\t`domain` is a (K, self.Xdim) tensor, representing K input points passed to the BNN.\n\n\t\t\tReturns:\n\t\t\t\tTensor of (M, K, self.Ydim) of outputs across all posterior samples and all input points.\n\t\t\"\"\"", "\n", "return", "torch", ".", "tensor", "(", "np", ".", "apply_along_axis", "(", "lambda", "w", ":", "self", ".", "forward", "(", "X", "=", "domain", ",", "weights", "=", "torch", ".", "tensor", "(", "w", ")", ")", ".", "numpy", "(", ")", ",", "1", ",", "bayes_samples", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin.add_deterministic_constraint": [[279, 343], ["base.RegressorMixin.dconstraints[].append", "logging.info", "sum", "torch.zeros", "torch.zeros", "base.RegressorMixin._sample_from_hypercube", "ifunc", "base.RegressorMixin._cr_ylens.append", "base.RegressorMixin.repeat", "range", "torch.zeros", "len", "len", "len", "len", "torch.tensor().unsqueeze", "len", "base.RegressorMixin._sample_from_hypercube", "torch.zeros", "len", "len", "base.RegressorMixin._sample_from_hypercube", "ifunc", "torch.tensor", "base.RegressorMixin._sample_from_hypercube"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork._sample_from_hypercube", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork._sample_from_hypercube", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork._sample_from_hypercube", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork._sample_from_hypercube"], ["", "def", "add_deterministic_constraint", "(", "self", ",", "constrained_domain", ",", "interval_func", ",", "prior_type", ")", ":", "\n", "\t\t", "\"\"\" Specify a (positive or negative) deterministic constraint. \n\t\t\tImplemented for 1D output only.\n\n\t\t\tArgs:\n\t\t\t\t`constrained_domain` is a (x1_lower, x1_upper, x2_lower, x2_upper, ...) tuple, i.e. length is Xdim * 2,\n\t\t\t\t\trepresenting the lower and upper bounds of each input dimension of the constrained input region.\n\t\t\t\t\tValues of +/- np.inf will be replaced with the corresponding bounds of the training set.\n\n\t\t\t\t`interval_func` is a function f:\n\t\t\t\t\tf takes as input a tensor X of shape (n_samples, self.Xdim) sampled from `constrained_domain`.\n\t\t\t\t\tf(X) evaluates to a list of length `n_samples`, each containing a sublist of permitted output ranges for X[i].\n\n\t\t\t\t`prior_type` is the COCP/AOCP that we want to use for this constraint. Supported options for regression are:\n\t\t\t\t\t- 'positive_gaussian_cocp'\n\t\t\t\t\t- 'negative_exponential_cocp'\n\t\t\t\t\t- 'gaussian_aocp'\n\n\t\t\t\tE.g. Negative constraint: constrained_domain=(4,5) and interval_func=lambda x: [[(-np.inf, 1 + x), (3 + x, np.inf)] for x in X]\n\t\t\t\t\t\t--> forbidden region is a parallelogram with vertices (4, 5), (4, 7), (5, 6), (5, 8)\n\t\t\t\t\t\t--> prior_type='negative_exponential_cocp' should be used\n\n\t\t\t\tE.g. Positive constraint: constrained_domain=(4,5) and interval_func=lambda x: [[(2, 2), (3, 3)] for _ in X]\n\t\t\t\t\t\t--> For x between 4 and 5, the only permitted values are 2 and 3\n\t\t\t\t\t\t--> prior_type='positive_gaussian_cocp' should be used (bimodal Gaussian)\n\t\t\"\"\"", "\n", "if", "prior_type", "not", "in", "self", ".", "dconstraints", ":", "\n", "\t\t\t", "self", ".", "dconstraints", "[", "prior_type", "]", "=", "[", "]", "\n", "", "self", ".", "dconstraints", "[", "prior_type", "]", ".", "append", "(", "(", "constrained_domain", ",", "interval_func", ")", ")", "\n", "\n", "# Create samples for inference.", "\n", "if", "prior_type", "==", "\"positive_gaussian_cocp\"", ":", "\n", "\t\t\t", "total_nsamples", "=", "sum", "(", "[", "len", "(", "ifunc", "(", "self", ".", "_sample_from_hypercube", "(", "dom", ",", "1", ")", ")", ")", "*", "self", ".", "ocp_nsamples", "for", "dom", ",", "ifunc", "in", "self", ".", "dconstraints", "[", "'positive_gaussian_cocp'", "]", "]", ")", "\n", "self", ".", "_cr_pos_xsamples", "=", "torch", ".", "zeros", "(", "total_nsamples", ",", "self", ".", "Xdim", ")", "\n", "self", ".", "_cr_pos_ysamples", "=", "torch", ".", "zeros", "(", "total_nsamples", ",", "self", ".", "Ydim", ")", "\n", "self", ".", "_cr_ylens", "=", "[", "]", "\n", "index", "=", "0", "\n", "for", "dom", ",", "ifunc", "in", "self", ".", "dconstraints", "[", "'positive_gaussian_cocp'", "]", ":", "\n", "\t\t\t\t", "xsamp", "=", "self", ".", "_sample_from_hypercube", "(", "dom", ",", "self", ".", "ocp_nsamples", ")", "\n", "intervals", "=", "ifunc", "(", "xsamp", ")", "\n", "self", ".", "_cr_ylens", ".", "append", "(", "len", "(", "intervals", "[", "0", "]", ")", ")", "\n", "sub_nsamples", "=", "len", "(", "intervals", "[", "0", "]", ")", "*", "self", ".", "ocp_nsamples", "\n", "self", ".", "_cr_pos_xsamples", "[", "index", ":", "index", "+", "sub_nsamples", ",", ":", "]", "=", "xsamp", ".", "repeat", "(", "len", "(", "intervals", "[", "0", "]", ")", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "intervals", "[", "0", "]", ")", ")", ":", "\n", "\t\t\t\t\t", "self", ".", "_cr_pos_ysamples", "[", "index", ":", "index", "+", "self", ".", "ocp_nsamples", ",", ":", "]", "=", "torch", ".", "tensor", "(", "[", "sublist", "[", "i", "]", "[", "0", "]", "for", "sublist", "in", "intervals", "]", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "index", "+=", "self", ".", "ocp_nsamples", "\n", "", "", "", "elif", "prior_type", "==", "\"negative_exponential_cocp\"", ":", "\n", "\t\t\t", "total_nsamples", "=", "self", ".", "ocp_nsamples", "*", "len", "(", "self", ".", "dconstraints", "[", "'negative_exponential_cocp'", "]", ")", "\n", "self", ".", "_cr_neg_xsamples", "=", "torch", ".", "zeros", "(", "total_nsamples", ",", "self", ".", "Xdim", ")", "\n", "index", "=", "0", "\n", "for", "dom", ",", "_", "in", "self", ".", "dconstraints", "[", "'negative_exponential_cocp'", "]", ":", "\n", "\t\t\t\t", "xsamp", "=", "self", ".", "_sample_from_hypercube", "(", "dom", ",", "self", ".", "ocp_nsamples", ")", "\n", "self", ".", "_cr_neg_xsamples", "[", "index", ":", "index", "+", "self", ".", "ocp_nsamples", ",", ":", "]", "=", "xsamp", "\n", "index", "+=", "self", ".", "ocp_nsamples", "\n", "", "", "elif", "prior_type", "==", "\"gaussian_aocp\"", ":", "\n", "\t\t\t", "total_nsamples", "=", "self", ".", "ocp_nsamples", "*", "len", "(", "self", ".", "dconstraints", "[", "'gaussian_aocp'", "]", ")", "\n", "self", ".", "_cr_aocp_xsamples", "=", "torch", ".", "zeros", "(", "total_nsamples", ",", "self", ".", "Xdim", ")", "\n", "index", "=", "0", "\n", "for", "dom", ",", "ifunc", "in", "self", ".", "dconstraints", "[", "'gaussian_aocp'", "]", ":", "\n", "\t\t\t\t", "xsamp", "=", "self", ".", "_sample_from_hypercube", "(", "dom", ",", "self", ".", "ocp_nsamples", ")", "\n", "self", ".", "_cr_aocp_xsamples", "[", "index", ":", "index", "+", "self", ".", "ocp_nsamples", ",", ":", "]", "=", "xsamp", "\n", "index", "+=", "self", ".", "ocp_nsamples", "\n", "\n", "", "", "logging", ".", "info", "(", "f'[{self.uid}] Defined constrained region for `{prior_type}`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin.positive_gaussian_cocp": [[344, 359], ["base.RegressorMixin.forward", "torch.tensor", "enumerate", "torch.distributions.multivariate_normal.MultivariateNormal.log_prob", "torch.log", "torch.logsumexp().sum", "torch.tensor", "torch.distributions.multivariate_normal.MultivariateNormal", "torch.logsumexp", "torch.stack", "torch.eye", "torch.distributions.multivariate_normal.MultivariateNormal.log_prob.split"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward"], ["", "def", "positive_gaussian_cocp", "(", "self", ")", ":", "\n", "\t\t", "\"\"\" Conditional output-constrained prior: mixture of Gaussian.\n\t\t\tAssume uniform mixing weights for each mixture.\n\t\t\tAssume isotropic Gaussian. \n\t\t\"\"\"", "\n", "nn_mean", "=", "self", ".", "forward", "(", "X", "=", "self", ".", "_cr_pos_xsamples", ")", "\n", "index", "=", "0", "\n", "log_prob", "=", "torch", ".", "tensor", "(", "0.0", ")", "\n", "for", "i", ",", "(", "dom", ",", "ifunc", ")", "in", "enumerate", "(", "self", ".", "dconstraints", "[", "'positive_gaussian_cocp'", "]", ")", ":", "\n", "\t\t\t", "sub_nsamples", "=", "self", ".", "_cr_ylens", "[", "i", "]", "*", "self", ".", "ocp_nsamples", "\n", "dist", "=", "MVN", "(", "self", ".", "_cr_pos_ysamples", "[", "index", ":", "index", "+", "sub_nsamples", ",", ":", "]", ",", "self", ".", "cocp_gaussian_sigma_c", "*", "torch", ".", "eye", "(", "self", ".", "Ydim", ")", ")", ".", "log_prob", "(", "nn_mean", "[", "index", ":", "index", "+", "sub_nsamples", ",", ":", "]", ")", "\n", "dist", "+=", "torch", ".", "log", "(", "torch", ".", "tensor", "(", "1", "/", "self", ".", "_cr_ylens", "[", "i", "]", ")", ")", "\n", "log_prob", "+=", "torch", ".", "logsumexp", "(", "torch", ".", "stack", "(", "dist", ".", "split", "(", "self", ".", "ocp_nsamples", ")", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", ".", "sum", "(", ")", "\n", "index", "+=", "sub_nsamples", "\n", "", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin._constraint_classifier": [[360, 363], ["torch.tanh", "torch.tanh"], "methods", ["None"], ["", "def", "_constraint_classifier", "(", "self", ",", "z", ")", ":", "\n", "\t\t", "\"\"\" Sigmoidal constraint classfier. \"\"\"", "\n", "return", "0.25", "*", "(", "torch", ".", "tanh", "(", "-", "self", ".", "cocp_expo_tau", "[", "0", "]", "*", "z", ")", "+", "1", ")", "*", "(", "torch", ".", "tanh", "(", "-", "self", ".", "cocp_expo_tau", "[", "1", "]", "*", "z", ")", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin.negative_exponential_cocp": [[364, 389], ["torch.zeros", "base.RegressorMixin.forward", "torch.ones", "ifunc", "torch.tensor", "range", "torch.zeros.sum", "len", "torch.tensor", "torch.tensor", "all", "torch.tensor", "all", "len", "range", "base.RegressorMixin._constraint_classifier", "base.RegressorMixin._constraint_classifier", "base.RegressorMixin._constraint_classifier", "base.RegressorMixin._constraint_classifier", "range"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin._constraint_classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin._constraint_classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin._constraint_classifier", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin._constraint_classifier"], ["", "def", "negative_exponential_cocp", "(", "self", ")", ":", "\n", "\t\t", "\"\"\" Conditional output-constrained prior: Exponential. \"\"\"", "\n", "penalty", "=", "torch", ".", "zeros", "(", "self", ".", "ocp_nsamples", ")", "\n", "nn_mean", "=", "self", ".", "forward", "(", "X", "=", "self", ".", "_cr_neg_xsamples", ")", "\n", "index", "=", "0", "\n", "for", "_", ",", "ifunc", "in", "self", ".", "dconstraints", "[", "'negative_exponential_cocp'", "]", ":", "\n", "\t\t\t", "i", ",", "j", "=", "index", ",", "index", "+", "self", ".", "ocp_nsamples", "\n", "nn_mean_subset", "=", "nn_mean", "[", "i", ":", "j", ",", ":", "]", "\n", "mult", "=", "torch", ".", "ones", "(", "nn_mean_subset", ".", "shape", "[", "0", "]", ")", "\n", "intervals", "=", "ifunc", "(", "self", ".", "_cr_neg_xsamples", "[", "i", ":", "j", ",", ":", "]", ")", "\n", "marker", "=", "torch", ".", "tensor", "(", "[", "-", "np", ".", "inf", "for", "_", "in", "range", "(", "self", ".", "ocp_nsamples", ")", "]", ")", "\n", "for", "k", "in", "range", "(", "len", "(", "intervals", "[", "0", "]", ")", ")", ":", "\n", "\t\t\t\t", "lbs", "=", "torch", ".", "tensor", "(", "[", "sublist", "[", "k", "]", "[", "0", "]", "for", "sublist", "in", "intervals", "]", ")", "\n", "ubs", "=", "torch", ".", "tensor", "(", "[", "sublist", "[", "k", "]", "[", "1", "]", "for", "sublist", "in", "intervals", "]", ")", "\n", "if", "all", "(", "marker", "<", "lbs", ")", ":", "\n", "\t\t\t\t\t", "penalty", "+=", "self", ".", "_constraint_classifier", "(", "marker", "-", "nn_mean_subset", "[", ":", ",", "0", "]", ")", "*", "self", ".", "_constraint_classifier", "(", "nn_mean_subset", "[", ":", ",", "0", "]", "-", "lbs", ")", "\n", "", "marker", "=", "ubs", "\n", "", "else", ":", "\n", "\t\t\t\t", "infs", "=", "torch", ".", "tensor", "(", "[", "np", ".", "inf", "for", "_", "in", "range", "(", "self", ".", "ocp_nsamples", ")", "]", ")", "\n", "if", "all", "(", "marker", "<", "infs", ")", ":", "\n", "\t\t\t\t\t", "penalty", "+=", "self", ".", "_constraint_classifier", "(", "marker", "-", "nn_mean_subset", "[", ":", ",", "0", "]", ")", "*", "self", ".", "_constraint_classifier", "(", "nn_mean_subset", "[", ":", ",", "0", "]", "-", "infs", ")", "\n", "", "", "index", "+=", "self", ".", "ocp_nsamples", "\n", "", "violation", "=", "penalty", ".", "sum", "(", ")", "/", "(", "self", ".", "ocp_nsamples", "*", "len", "(", "self", ".", "dconstraints", "[", "'negative_exponential_cocp'", "]", ")", ")", "\n", "log_prob", "=", "-", "self", ".", "cocp_expo_gamma", "*", "violation", "# p(w) = exp(- gamma * constraint_viol)", "\n", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.RegressorMixin.gaussian_aocp_objective": [[390, 420], ["torch.tensor", "ifunc", "enumerate", "len", "torch.autograd.Variable", "base.RegressorMixin.forward().squeeze", "base.RegressorMixin.backward", "base.RegressorMixin.forward().squeeze", "torch.tensor", "torch.eye", "base.RegressorMixin._aocp_params[].clone", "base.RegressorMixin.forward", "torch.logsumexp", "base.RegressorMixin.forward", "x.unsqueeze", "torch.stack", "x.unsqueeze", "torch.distributions.normal.Normal().cdf", "torch.distributions.normal.Normal().cdf", "torch.distributions.normal.Normal().cdf", "torch.distributions.normal.Normal().cdf", "torch.zeros", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal", "torch.distributions.normal.Normal"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward"], ["", "def", "gaussian_aocp_objective", "(", "self", ")", ":", "\n", "\t\t", "\"\"\" Gaussian AOCP optimization objective. \"\"\"", "\n", "pvals", "=", "torch", ".", "tensor", "(", "0.", ")", "\n", "index", "=", "0", "\n", "for", "_", ",", "ifunc", "in", "self", ".", "dconstraints", "[", "'gaussian_aocp'", "]", ":", "\n", "\t\t\t", "i", ",", "j", "=", "index", ",", "index", "+", "self", ".", "ocp_nsamples", "\n", "xsamples", "=", "self", ".", "_cr_aocp_xsamples", "[", "i", ":", "j", ",", ":", "]", "\n", "intervals", "=", "ifunc", "(", "xsamples", ")", "\n", "for", "k", ",", "x", "in", "enumerate", "(", "xsamples", ")", ":", "\n", "# Compute approximate prior predictive.", "\n", "\t\t\t\t", "_mean", "=", "Variable", "(", "self", ".", "_aocp_params", "[", ":", ",", "0", "]", ".", "clone", "(", ")", ".", "data", ",", "requires_grad", "=", "True", ")", "\n", "pp_mean", "=", "self", ".", "forward", "(", "x", ".", "unsqueeze", "(", "dim", "=", "1", ")", ",", "weights", "=", "_mean", ")", ".", "squeeze", "(", ")", "\n", "pp_mean", ".", "backward", "(", "retain_graph", "=", "False", ")", "\n", "g", "=", "_mean", ".", "grad", "\n", "A", "=", "(", "torch", ".", "logsumexp", "(", "torch", ".", "stack", "(", "(", "self", ".", "_aocp_params", "[", ":", ",", "1", "]", ",", "torch", ".", "zeros", "(", "self", ".", "nweights", ")", ")", ")", ",", "0", ")", "**", "2", ")", "*", "torch", ".", "eye", "(", "self", ".", "nweights", ")", "\n", "pp_std", "=", "(", "self", ".", "sigma_noise", "+", "(", "g", "@", "A", "@", "g", ")", ")", "**", "0.5", "\n", "pp_mean", "=", "self", ".", "forward", "(", "x", ".", "unsqueeze", "(", "dim", "=", "1", ")", ",", "weights", "=", "self", ".", "_aocp_params", "[", ":", ",", "0", "]", ")", ".", "squeeze", "(", ")", "\n", "\n", "# Calculate fraction of prior predictive violating the constraint.", "\n", "permitted", "=", "torch", ".", "tensor", "(", "0.", ")", "\n", "for", "lb", ",", "ub", "in", "intervals", "[", "k", "]", ":", "\n", "\t\t\t\t\t", "if", "ub", "==", "np", ".", "inf", ":", "\n", "\t\t\t\t\t\t", "permitted", "+=", "1.0", "-", "Normal", "(", "pp_mean", ",", "pp_std", ")", ".", "cdf", "(", "lb", ")", "\n", "", "elif", "lb", "==", "-", "np", ".", "inf", ":", "\n", "\t\t\t\t\t\t", "permitted", "+=", "Normal", "(", "pp_mean", ",", "pp_std", ")", ".", "cdf", "(", "ub", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "permitted", "+=", "Normal", "(", "pp_mean", ",", "pp_std", ")", ".", "cdf", "(", "ub", ")", "-", "Normal", "(", "pp_mean", ",", "pp_std", ")", ".", "cdf", "(", "lb", ")", "\n", "", "", "pvals", "+=", "1", "-", "permitted", "\n", "", "index", "+=", "self", ".", "ocp_nsamples", "\n", "", "return", "pvals", "/", "len", "(", "self", ".", "_cr_aocp_xsamples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.ClassifierMixin._Ydim": [[428, 431], ["torch.max().int().item", "torch.max().int", "torch.max"], "methods", ["None"], ["@", "property", "\n", "def", "_Ydim", "(", "self", ")", ":", "\n", "\t\t", "return", "torch", ".", "max", "(", "self", ".", "Y_train", ")", ".", "int", "(", ")", ".", "item", "(", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.ClassifierMixin.log_likelihood": [[432, 445], ["base.ClassifierMixin.forward", "torch.nn.LogSoftmax", "probs.gather().sum", "len", "probs.gather", "target.view"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward"], ["", "def", "log_likelihood", "(", "self", ",", "batch_indices", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Computes the likelihood. \"\"\"", "\n", "if", "batch_indices", "is", "None", ":", "\n", "\t\t\t", "batch", "=", "self", ".", "X_train", "\n", "target", "=", "self", ".", "Y_train", "\n", "multiplier", "=", "1", "\n", "", "else", ":", "\n", "\t\t\t", "batch", "=", "self", ".", "X_train", "[", "batch_indices", "]", "\n", "target", "=", "self", ".", "Y_train", "[", "batch_indices", "]", "\n", "multiplier", "=", "(", "self", ".", "N_train", "/", "len", "(", "batch_indices", ")", ")", "\n", "", "means", "=", "self", ".", "forward", "(", "X", "=", "batch", ")", "\n", "probs", "=", "torch", ".", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "(", "means", ")", "\n", "return", "multiplier", "*", "probs", ".", "gather", "(", "1", ",", "target", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.ClassifierMixin.predict": [[446, 462], ["torch.tensor", "softprobs.argmax", "numpy.apply_along_axis", "torch.nn.Softmax", "base.ClassifierMixin.forward().numpy", "base.ClassifierMixin.forward", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward"], ["", "def", "predict", "(", "self", ",", "bayes_samples", ",", "domain", ",", "return_probs", "=", "False", ")", ":", "\n", "\t\t", "\"\"\" Generate BNN's prediction over `domain` for each sample.\n\n\t\t\tArgs: \n\t\t\t\t`bayes_samples` is a (M, self.nweights) tensor, representing M samples of the prior/posterior.\n\t\t\t\t`domain` is a (K, self.Xdim) tensor, representing K input points passed to the BNN.\n\t\t\t\t`return_probs` is a Boolean: true if we want to return the raw softmax probabilities instead of class predictions.\n\n\t\t\tReturns:\n\t\t\t\tTensor of (M, K) of output classes (integer) across all posterior samples and all input points.\n\t\t\"\"\"", "\n", "probs", "=", "torch", ".", "tensor", "(", "np", ".", "apply_along_axis", "(", "lambda", "w", ":", "self", ".", "forward", "(", "X", "=", "domain", ",", "weights", "=", "torch", ".", "tensor", "(", "w", ")", ")", ".", "numpy", "(", ")", ",", "1", ",", "bayes_samples", ")", ")", "# M x K x self.Ydim", "\n", "softprobs", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "2", ")", "(", "probs", ")", "\n", "if", "return_probs", ":", "\n", "\t\t\t", "return", "softprobs", "\n", "", "return", "softprobs", ".", "argmax", "(", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.ClassifierMixin.add_deterministic_constraint": [[463, 497], ["base.ClassifierMixin.dconstraints[].append", "torch.zeros", "logging.info", "logging.error", "len", "base.ClassifierMixin._sample_from_hypercube", "len"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork._sample_from_hypercube"], ["", "def", "add_deterministic_constraint", "(", "self", ",", "constrained_domain", ",", "forbidden_classes", ",", "prior_type", "=", "\"positive_dirichlet_cocp\"", ")", ":", "\n", "\t\t", "\"\"\" Specify a (positive or negative) deterministic constraint. \n\n\t\t\tArgs:\n\t\t\t\t`constrained_domain` is a (x1_lower, x1_upper, x2_lower, x2_upper, ...) tuple, i.e. length is Xdim * 2,\n\t\t\t\t\trepresenting the lower and upper bounds of each input dimension of the constrained input region.\n\t\t\t\t\tValues of +/- np.inf will be replaced with the corresponding bounds of the training set.\n\n\t\t\t\t`forbidden_classes` is an integer list of FORBIDDEN classes for ALL points in `constrained_domain`.\n\n\t\t\t\t`prior_type` is the COCP/AOCP that we want to use for this constraint. Supported options for classification are:\n\t\t\t\t\t- 'positive_dirichlet_cocp'\n\n\t\t\t\tE.g. constrained_domain=(4,5,6,7) and forbidden_classes=[2,3,4]\n\t\t\t\t\t\t--> For the input rectangle bounded by (4,6), (5,6), (4,7), (5,7), output classes 2, 3, and 4 are forbidden.\n\t\t\"\"\"", "\n", "if", "not", "forbidden_classes", "or", "len", "(", "forbidden_classes", ")", ">=", "self", ".", "Ydim", ":", "\n", "\t\t\t", "logging", ".", "error", "(", "\"Number of forbidden classes must be between 0 and total number of classes (exclusive).\"", ")", "\n", "raise", "Exception", "\n", "\n", "", "if", "prior_type", "not", "in", "self", ".", "dconstraints", ":", "\n", "\t\t\t", "self", ".", "dconstraints", "[", "prior_type", "]", "=", "[", "]", "\n", "", "self", ".", "dconstraints", "[", "prior_type", "]", ".", "append", "(", "(", "constrained_domain", ",", "forbidden_classes", ")", ")", "\n", "\n", "# Prepare samples for inference.", "\n", "total_nsamples", "=", "self", ".", "ocp_nsamples", "*", "len", "(", "self", ".", "dconstraints", "[", "prior_type", "]", ")", "\n", "self", ".", "_cr_xsamples", "=", "torch", ".", "zeros", "(", "total_nsamples", ",", "self", ".", "Xdim", ")", "\n", "index", "=", "0", "\n", "for", "domain", ",", "_", "in", "self", ".", "dconstraints", "[", "prior_type", "]", ":", "\n", "\t\t\t", "xsamp", "=", "self", ".", "_sample_from_hypercube", "(", "domain", ",", "self", ".", "ocp_nsamples", ")", "\n", "self", ".", "_cr_xsamples", "[", "index", ":", "index", "+", "self", ".", "ocp_nsamples", ",", ":", "]", "=", "xsamp", "\n", "index", "+=", "self", ".", "ocp_nsamples", "\n", "\n", "", "logging", ".", "info", "(", "f'[{self.uid}] Defined constrained region for `{prior_type}`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.ClassifierMixin.positive_dirichlet_cocp": [[498, 512], ["torch.tensor", "base.ClassifierMixin.forward", "torch.distributions.dirichlet.Dirichlet().log_prob().sum", "torch.nn.Softmax", "torch.tensor().bincount().type", "torch.distributions.dirichlet.Dirichlet().log_prob", "torch.tensor().bincount", "torch.distributions.dirichlet.Dirichlet", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward"], ["", "def", "positive_dirichlet_cocp", "(", "self", ")", ":", "\n", "\t\t", "\"\"\" Conditional output-constrained prior: Dirichlet. \"\"\"", "\n", "log_prob", "=", "torch", ".", "tensor", "(", "0.", ")", "\n", "nn_mean", "=", "self", ".", "forward", "(", "X", "=", "self", ".", "_cr_xsamples", ")", "\n", "index", "=", "0", "\n", "for", "_", ",", "fclasses", "in", "self", ".", "dconstraints", "[", "\"positive_dirichlet_cocp\"", "]", ":", "\n", "\t\t\t", "i", ",", "j", "=", "index", ",", "index", "+", "self", ".", "ocp_nsamples", "\n", "nn_mean_subset", "=", "nn_mean", "[", "i", ":", "j", ",", ":", "]", "\n", "nn_probs", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "nn_mean_subset", ")", "\n", "dirprobs", "=", "self", ".", "cocp_dirichlet_gamma", "*", "torch", ".", "tensor", "(", "fclasses", ")", ".", "bincount", "(", "minlength", "=", "self", ".", "Ydim", ")", ".", "type", "(", "torch", ".", "float", ")", "\n", "dirprobs", "=", "self", ".", "cocp_dirichlet_gamma", "-", "(", "dirprobs", "*", "(", "1", "-", "self", ".", "cocp_dirichlet_alpha", ")", ")", "\n", "log_prob", "+=", "Dirichlet", "(", "dirprobs", ")", ".", "log_prob", "(", "nn_probs", ")", ".", "sum", "(", ")", "\n", "index", "+=", "self", ".", "ocp_nsamples", "\n", "", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin._Ydim": [[520, 523], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "_Ydim", "(", "self", ")", ":", "\n", "\t\t", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin._sigmoid": [[524, 527], ["torch.exp", "torch.exp"], "methods", ["None"], ["", "def", "_sigmoid", "(", "self", ",", "batch", ")", ":", "\n", "\t\t", "\"\"\" Sigmoid fuction. \"\"\"", "\n", "return", "torch", ".", "exp", "(", "batch", ")", "/", "(", "torch", ".", "exp", "(", "batch", ")", "+", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.log_likelihood": [[528, 543], ["target.type.type.type", "base.BinaryClassifierMixin.forward", "base.BinaryClassifierMixin._sigmoid().squeeze", "terms.sum", "len", "base.BinaryClassifierMixin._sigmoid", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin._sigmoid"], ["", "def", "log_likelihood", "(", "self", ",", "batch_indices", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Computes the likelihood. \"\"\"", "\n", "if", "batch_indices", "is", "None", ":", "\n", "\t\t\t", "batch", "=", "self", ".", "X_train", "\n", "target", "=", "self", ".", "Y_train", "\n", "multiplier", "=", "1", "\n", "", "else", ":", "\n", "\t\t\t", "batch", "=", "self", ".", "X_train", "[", "batch_indices", "]", "\n", "target", "=", "self", ".", "Y_train", "[", "batch_indices", "]", "\n", "multiplier", "=", "(", "self", ".", "N_train", "/", "len", "(", "batch_indices", ")", ")", "\n", "", "target", "=", "target", ".", "type", "(", "torch", ".", "float32", ")", "\n", "means", "=", "self", ".", "forward", "(", "X", "=", "batch", ")", "\n", "probs", "=", "self", ".", "_sigmoid", "(", "means", ")", ".", "squeeze", "(", ")", "\n", "terms", "=", "target", "*", "torch", ".", "log", "(", "probs", ")", "+", "(", "1.0", "-", "target", ")", "*", "torch", ".", "log", "(", "1", "-", "probs", ")", "\n", "return", "multiplier", "*", "terms", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.predict": [[544, 560], ["torch.tensor", "numpy.apply_along_axis", "base.BinaryClassifierMixin._sigmoid().numpy", "base.BinaryClassifierMixin._sigmoid", "base.BinaryClassifierMixin.forward().squeeze", "base.BinaryClassifierMixin.forward", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin._sigmoid", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward"], ["", "def", "predict", "(", "self", ",", "bayes_samples", ",", "domain", ",", "return_probs", "=", "False", ")", ":", "\n", "\t\t", "\"\"\" Generate BNN's prediction over `domain` for each sample.\n\n\t\t\tArgs: \n\t\t\t\t`bayes_samples` is a (M, self.nweights) tensor, representing M samples of the prior/posterior.\n\t\t\t\t`domain` is a (K, self.Xdim) tensor, representing K input points passed to the BNN.\n\t\t\t\t`return_probs` is a Boolean: true if we want to return the raw sigmoid probability p(Y=1) instead of class predictions.\n\n\t\t\tReturns:\n\t\t\t\tBoolean tensor of (M, K) of output classes (integer) across all posterior samples and all input points.\n\t\t\"\"\"", "\n", "probs", "=", "torch", ".", "tensor", "(", "np", ".", "apply_along_axis", "(", "lambda", "w", ":", "self", ".", "_sigmoid", "(", "self", ".", "forward", "(", "X", "=", "domain", ",", "\n", "weights", "=", "torch", ".", "tensor", "(", "w", ")", ")", ".", "squeeze", "(", "dim", "=", "1", ")", ")", ".", "numpy", "(", ")", ",", "1", ",", "bayes_samples", ")", ")", "\n", "if", "return_probs", ":", "\n", "\t\t\t", "return", "probs", "\n", "", "return", "probs", ">=", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_deterministic_constraint": [[561, 591], ["base.BinaryClassifierMixin.dconstraints[].append", "torch.zeros", "logging.info", "len", "base.BinaryClassifierMixin._sample_from_hypercube"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork._sample_from_hypercube"], ["", "def", "add_deterministic_constraint", "(", "self", ",", "constrained_domain", ",", "desired_class", ",", "prior_type", "=", "\"gaussian_aocp\"", ")", ":", "\n", "\t\t", "\"\"\" Specify a (positive or negative) deterministic constraint. \n\n\t\t\tArgs:\n\t\t\t\t`constrained_domain` is a (x1_lower, x1_upper, x2_lower, x2_upper, ...) tuple, i.e. length is Xdim * 2,\n\t\t\t\t\trepresenting the lower and upper bounds of each input dimension of the constrained input region.\n\t\t\t\t\tValues of +/- np.inf will be replaced with the corresponding bounds of the training set.\n\n\t\t\t\t`desired_class` is 0 or 1, for the desired output of ALL points in `constrained_domain`.\n\t\t\t\t\t--> For binary classification, this fully specifies a deterministic constraint!\n\n\t\t\t\t`prior_type` is the COCP/AOCP that we want to use for this constraint. Supported options for binary classification are:\n\t\t\t\t\t- 'gaussian_aocp' \n\n\t\t\t\tE.g. constrained_domain=(4,5,6,7) and desired_class=1\n\t\t\t\t\t\t--> For the input rectangle bounded by (4,6), (5,6), (4,7), (5,7), the output should be 1\n\t\t\"\"\"", "\n", "if", "prior_type", "not", "in", "self", ".", "dconstraints", ":", "\n", "\t\t\t", "self", ".", "dconstraints", "[", "prior_type", "]", "=", "[", "]", "\n", "", "self", ".", "dconstraints", "[", "prior_type", "]", ".", "append", "(", "(", "constrained_domain", ",", "desired_class", ")", ")", "\n", "\n", "total_nsamples", "=", "self", ".", "ocp_nsamples", "*", "len", "(", "self", ".", "dconstraints", "[", "prior_type", "]", ")", "\n", "self", ".", "_cr_det_xsamples", "=", "torch", ".", "zeros", "(", "total_nsamples", ",", "self", ".", "Xdim", ")", "\n", "index", "=", "0", "\n", "for", "domain", ",", "_", "in", "self", ".", "dconstraints", "[", "prior_type", "]", ":", "\n", "\t\t\t", "xsamp", "=", "self", ".", "_sample_from_hypercube", "(", "domain", ",", "self", ".", "ocp_nsamples", ")", "\n", "self", ".", "_cr_det_xsamples", "[", "index", ":", "index", "+", "self", ".", "ocp_nsamples", ",", ":", "]", "=", "xsamp", "\n", "index", "+=", "self", ".", "ocp_nsamples", "\n", "\n", "", "logging", ".", "info", "(", "f'[{self.uid}] Defined constrained region for `{prior_type}`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.add_probabilistic_constraint": [[592, 623], ["base.BinaryClassifierMixin.pconstraints[].append", "torch.zeros", "logging.info", "len", "base.BinaryClassifierMixin._sample_from_hypercube"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork._sample_from_hypercube"], ["", "def", "add_probabilistic_constraint", "(", "self", ",", "constrained_domain", ",", "prob_func", ",", "prior_type", "=", "\"gaussian_aocp\"", ")", ":", "\n", "\t\t", "\"\"\" Specify a probabilistic constraint. \n\n\t\t\tArgs:\n\t\t\t\t`constrained_domain` is a (x1_lower, x1_upper, x2_lower, x2_upper, ...) tuple, i.e. length is Xdim * 2,\n\t\t\t\t\trepresenting the lower and upper bounds of each input dimension of the constrained input region.\n\t\t\t\t\tValues of +/- np.inf will be replaced with the corresponding bounds of the training set.\n\n\t\t\t\t`prob_func` is a function f:\n\t\t\t\t\tf takes as input a tensor X of shape (n_samples, self.Xdim) sampled from `constrained_domain`.\n\t\t\t\t\tf(X) evaluates to the (n_samples, ) tensor of desired output probability p(Y=1|X[i]) for each X[i].\n\n\t\t\t\t`prior_type` is the COCP/AOCP that we want to use for this constraint. Supported options for binary classification are:\n\t\t\t\t\t- 'gaussian_aocp' \n\n\t\t\t\tE.g. constrained_domain=(1,2,0,1) and prob_func=lambda x: x[:, 1]\n\t\t\t\t\t\t--> For the input rectangle bounded by (1,0), (2,0), (1,1), (1,1), the output should be X_2\n\t\t\"\"\"", "\n", "if", "prior_type", "not", "in", "self", ".", "pconstraints", ":", "\n", "\t\t\t", "self", ".", "pconstraints", "[", "prior_type", "]", "=", "[", "]", "\n", "", "self", ".", "pconstraints", "[", "prior_type", "]", ".", "append", "(", "(", "constrained_domain", ",", "prob_func", ")", ")", "\n", "\n", "total_nsamples", "=", "self", ".", "ocp_nsamples", "*", "len", "(", "self", ".", "pconstraints", "[", "prior_type", "]", ")", "\n", "self", ".", "_cr_prob_xsamples", "=", "torch", ".", "zeros", "(", "total_nsamples", ",", "self", ".", "Xdim", ")", "\n", "index", "=", "0", "\n", "for", "domain", ",", "_", "in", "self", ".", "pconstraints", "[", "prior_type", "]", ":", "\n", "\t\t\t", "xsamp", "=", "self", ".", "_sample_from_hypercube", "(", "domain", ",", "self", ".", "ocp_nsamples", ")", "\n", "self", ".", "_cr_prob_xsamples", "[", "index", ":", "index", "+", "self", ".", "ocp_nsamples", ",", ":", "]", "=", "xsamp", "\n", "index", "+=", "self", ".", "ocp_nsamples", "\n", "\n", "", "logging", ".", "info", "(", "f'[{self.uid}] Defined constrained region for `{prior_type}`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.gaussian_aocp_objective": [[624, 673], ["torch.zeros", "len", "len", "enumerate", "pfunc", "enumerate", "torch.autograd.Variable", "base.BinaryClassifierMixin.forward().squeeze", "base.BinaryClassifierMixin.backward", "base.BinaryClassifierMixin._sigmoid", "abs", "torch.autograd.Variable", "base.BinaryClassifierMixin.forward().squeeze", "base.BinaryClassifierMixin.backward", "base.BinaryClassifierMixin._sigmoid", "torch.clamp", "torch.clamp", "torch.eye", "torch.eye", "base.BinaryClassifierMixin._aocp_params[].clone", "base.BinaryClassifierMixin.forward", "torch.logsumexp", "base.BinaryClassifierMixin._aocp_params[].clone", "base.BinaryClassifierMixin.forward", "torch.logsumexp", "x.unsqueeze", "torch.stack", "x.unsqueeze", "torch.stack", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin._sigmoid", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin._sigmoid", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.forward"], ["", "def", "gaussian_aocp_objective", "(", "self", ")", ":", "\n", "\t\t", "\"\"\" Gaussian AOCP optimization objective. \"\"\"", "\n", "pvals", "=", "torch", ".", "zeros", "(", "1", ")", "\n", "index", "=", "0", "\n", "denom", "=", "0", "\n", "if", "'gaussian_aocp'", "in", "self", ".", "dconstraints", ":", "\n", "\t\t\t", "for", "_", ",", "dclass", "in", "self", ".", "dconstraints", "[", "'gaussian_aocp'", "]", ":", "\n", "\t\t\t\t", "i", ",", "j", "=", "index", ",", "index", "+", "self", ".", "ocp_nsamples", "\n", "xsamples", "=", "self", ".", "_cr_det_xsamples", "[", "i", ":", "j", ",", ":", "]", "\n", "for", "k", ",", "x", "in", "enumerate", "(", "xsamples", ")", ":", "\n", "# Compute approximate prior predictive.", "\n", "\t\t\t\t\t", "_mean", "=", "Variable", "(", "self", ".", "_aocp_params", "[", ":", ",", "0", "]", ".", "clone", "(", ")", ".", "data", ",", "requires_grad", "=", "True", ")", "\n", "pp_mean", "=", "self", ".", "forward", "(", "x", ".", "unsqueeze", "(", "dim", "=", "0", ")", ",", "weights", "=", "_mean", ")", ".", "squeeze", "(", ")", "\n", "pp_mean", ".", "backward", "(", "retain_graph", "=", "False", ")", "\n", "b", "=", "_mean", ".", "grad", "\n", "A", "=", "(", "torch", ".", "logsumexp", "(", "torch", ".", "stack", "(", "(", "self", ".", "_aocp_params", "[", ":", ",", "1", "]", ",", "torch", ".", "zeros", "(", "self", ".", "nweights", ")", ")", ")", ",", "0", ")", "**", "2", ")", "*", "torch", ".", "eye", "(", "self", ".", "nweights", ")", "\n", "sigma2", "=", "b", "@", "A", "@", "b", "\n", "kappa", "=", "(", "1", "+", "(", "math", ".", "pi", "*", "sigma2", "/", "8", ")", ")", "**", "(", "-", "0.5", ")", "\n", "p1", "=", "self", ".", "_sigmoid", "(", "kappa", "*", "(", "b", "@", "self", ".", "_aocp_params", "[", ":", ",", "0", "]", ")", ")", "\n", "\n", "# Calculate fraction of prior predictive violating the constraint.", "\n", "pvals", "+=", "abs", "(", "dclass", "-", "p1", ")", "\n", "", "", "denom", "+=", "len", "(", "self", ".", "_cr_det_xsamples", ")", "\n", "", "index", "=", "0", "\n", "if", "'gaussian_aocp'", "in", "self", ".", "pconstraints", ":", "\n", "\t\t\t", "for", "_", ",", "pfunc", "in", "self", ".", "pconstraints", "[", "'gaussian_aocp'", "]", ":", "\n", "\t\t\t\t", "i", ",", "j", "=", "index", ",", "index", "+", "self", ".", "ocp_nsamples", "\n", "xsamples", "=", "self", ".", "_cr_prob_xsamples", "[", "i", ":", "j", ",", ":", "]", "\n", "p1prob", "=", "pfunc", "(", "xsamples", ")", "\n", "for", "k", ",", "x", "in", "enumerate", "(", "xsamples", ")", ":", "\n", "# Compute approximate prior predictive.", "\n", "\t\t\t\t\t", "_mean", "=", "Variable", "(", "self", ".", "_aocp_params", "[", ":", ",", "0", "]", ".", "clone", "(", ")", ".", "data", ",", "requires_grad", "=", "True", ")", "\n", "pp_mean", "=", "self", ".", "forward", "(", "x", ".", "unsqueeze", "(", "dim", "=", "0", ")", ",", "weights", "=", "_mean", ")", ".", "squeeze", "(", ")", "\n", "pp_mean", ".", "backward", "(", "retain_graph", "=", "False", ")", "\n", "b", "=", "_mean", ".", "grad", "\n", "A", "=", "(", "torch", ".", "logsumexp", "(", "torch", ".", "stack", "(", "(", "self", ".", "_aocp_params", "[", ":", ",", "1", "]", ",", "torch", ".", "zeros", "(", "self", ".", "nweights", ")", ")", ")", ",", "0", ")", "**", "2", ")", "*", "torch", ".", "eye", "(", "self", ".", "nweights", ")", "\n", "sigma2", "=", "b", "@", "A", "@", "b", "\n", "kappa", "=", "(", "1", "+", "(", "math", ".", "pi", "*", "sigma2", "/", "8", ")", ")", "**", "(", "-", "0.5", ")", "\n", "phat1", "=", "self", ".", "_sigmoid", "(", "kappa", "*", "(", "b", "@", "self", ".", "_aocp_params", "[", ":", ",", "0", "]", ")", ")", "\n", "phat1", "=", "torch", ".", "clamp", "(", "phat1", ",", "0.001", ",", "0.999", ")", "\n", "p1", "=", "torch", ".", "clamp", "(", "p1prob", "[", "k", "]", ",", "0.001", ",", "0.999", ")", "\n", "\n", "# Calculate fraction of prior predictive violating the constraint.", "\n", "# This is KL divergence between two Bernoullis -- the desired p(Y=1) and the current p(Y=1).", "\n", "# To preserve symmetry, we add both KL(p||q) and KL(q||p).", "\n", "pvals", "+=", "p1", "*", "(", "torch", ".", "log", "(", "p1", ")", "-", "torch", ".", "log", "(", "phat1", ")", ")", "+", "(", "1", "-", "p1", ")", "*", "(", "torch", ".", "log", "(", "1", "-", "p1", ")", "-", "torch", ".", "log", "(", "1", "-", "phat1", ")", ")", "\n", "pvals", "+=", "phat1", "*", "(", "torch", ".", "log", "(", "phat1", ")", "-", "torch", ".", "log", "(", "p1", ")", ")", "+", "(", "1", "-", "phat1", ")", "*", "(", "torch", ".", "log", "(", "1", "-", "phat1", ")", "-", "torch", ".", "log", "(", "1", "-", "p1", ")", ")", "\n", "", "", "denom", "+=", "len", "(", "self", ".", "_cr_prob_xsamples", ")", "\n", "", "return", "pvals", "/", "denom", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.HMCMixin._compute_potential": [[29, 34], ["inference.HMCMixin.log_prior", "inference.HMCMixin.log_posterior"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.log_prior", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.log_posterior"], ["def", "_compute_potential", "(", "self", ",", "with_data", ")", ":", "\n", "\t\t", "\"\"\" Computes U(q). \"\"\"", "\n", "if", "with_data", ":", "\n", "\t\t\t", "return", "-", "1", "*", "self", ".", "log_posterior", "(", ")", "\n", "", "return", "-", "1", "*", "self", ".", "log_prior", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.HMCMixin._compute_kinetic": [[35, 38], ["None"], "methods", ["None"], ["", "def", "_compute_kinetic", "(", "self", ",", "p", ")", ":", "\n", "\t\t", "\"\"\" Computes K(p). \"\"\"", "\n", "return", "0.5", "*", "(", "p", "**", "2", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.HMCMixin.single": [[39, 79], ["torch.distributions.normal.Normal().sample", "inference.HMCMixin._compute_potential", "inference.HMCMixin._compute_kinetic", "inference.HMCMixin._compute_potential().backward", "range", "inference.HMCMixin._compute_potential().backward", "inference.HMCMixin._compute_potential", "inference.HMCMixin._compute_kinetic", "torch.Size", "sum", "logging.error", "numpy.random.uniform", "torch.exp().item", "torch.distributions.normal.Normal", "inference.HMCMixin._compute_potential", "inference.HMCMixin._compute_potential().backward", "inference.HMCMixin._compute_potential", "torch.isnan", "torch.exp", "inference.HMCMixin._compute_potential"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.HMCMixin._compute_potential", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.HMCMixin._compute_kinetic", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.HMCMixin._compute_potential", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.HMCMixin._compute_kinetic", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.HMCMixin._compute_potential", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.HMCMixin._compute_potential", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.HMCMixin._compute_potential"], ["", "def", "single", "(", "self", ",", "with_data", ")", ":", "\n", "\t\t", "\"\"\" Computes a single iteration of HMC iteration and collects another sample of q. \"\"\"", "\n", "\n", "epsilon", "=", "self", ".", "hmc_epsilon", "\n", "L", "=", "self", ".", "hmc_l", "\n", "\n", "current_p", "=", "Normal", "(", "0", ",", "1", ")", ".", "sample", "(", "torch", ".", "Size", "(", "[", "self", ".", "nweights", "]", ")", ")", "\n", "original_q", "=", "self", ".", "weights", ".", "data", "\n", "original_U", "=", "self", ".", "_compute_potential", "(", "with_data", ")", "\n", "original_K", "=", "self", ".", "_compute_kinetic", "(", "current_p", ")", "\n", "\n", "# Momentum half-step => position/momentum full-steps => momentum half-step => negate momentum", "\n", "self", ".", "weights", ".", "grad", "=", "None", "\n", "self", ".", "_compute_potential", "(", "with_data", ")", ".", "backward", "(", ")", "\n", "\n", "current_p", "-=", "(", "epsilon", "/", "2", ")", "*", "self", ".", "weights", ".", "grad", "\n", "for", "l", "in", "range", "(", "1", ",", "L", "+", "1", ")", ":", "\n", "\t\t\t", "self", ".", "weights", ".", "data", "+=", "epsilon", "*", "current_p", "\n", "if", "l", "<", "L", ":", "\n", "\t\t\t\t", "self", ".", "weights", ".", "grad", "=", "None", "\n", "self", ".", "_compute_potential", "(", "with_data", ")", ".", "backward", "(", ")", "\n", "current_p", "-=", "epsilon", "*", "self", ".", "weights", ".", "grad", "\n", "", "", "self", ".", "weights", ".", "grad", "=", "None", "\n", "self", ".", "_compute_potential", "(", "with_data", ")", ".", "backward", "(", ")", "\n", "current_p", "-=", "(", "epsilon", "/", "2", ")", "*", "self", ".", "weights", ".", "grad", "\n", "# current_p *= -1 # this step is computationally redundant", "\n", "if", "sum", "(", "torch", ".", "isnan", "(", "self", ".", "weights", ")", ")", ">", "0", ":", "\n", "\t\t\t", "logging", ".", "error", "(", "\"NaNs encountered in current set of weights.\"", ")", "\n", "raise", "Exception", "\n", "\n", "# Evaluate U(q) and K(p)", "\n", "", "current_U", "=", "self", ".", "_compute_potential", "(", "with_data", ")", "\n", "current_K", "=", "self", ".", "_compute_kinetic", "(", "current_p", ")", "\n", "\n", "# Metropolis-Hastings proposal", "\n", "if", "np", ".", "random", ".", "uniform", "(", ")", "<", "torch", ".", "exp", "(", "original_U", "-", "current_U", "+", "original_K", "-", "current_K", ")", ".", "item", "(", ")", ":", "\n", "\t\t\t", "self", ".", "accepts", "+=", "1", "\n", "", "else", ":", "\n", "\t\t\t", "self", ".", "rejects", "+=", "1", "\n", "self", ".", "weights", ".", "data", "=", "original_q", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.HMCMixin.infer": [[80, 125], ["logging.info", "time.time", "range", "logging.info", "range", "torch.stack", "torch.save", "inference.HMCMixin.all_bayes_samples.append", "logging.info", "len", "inference.HMCMixin.single", "inference.HMCMixin.single", "time.time", "logging.info", "logging.info", "logging.info", "torch.stack.append", "logging.info", "logging.info", "inference.HMCMixin.weights.data.clone", "int"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.single", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.single"], ["", "", "def", "infer", "(", "self", ",", "verbose", "=", "True", ",", "with_data", "=", "True", ")", ":", "\n", "\t\t", "\"\"\" Perform HMC and collects samples.\n\t\t\tIf `with_data`, sample from posterior, else, sample from prior. \n\t\t\tNote that unlike the other inference methods, HMC does not allow batched training data.  \n\t\t\"\"\"", "\n", "infer_id", "=", "len", "(", "self", ".", "all_bayes_samples", ")", "+", "1", "\n", "logging", ".", "info", "(", "f\"[{self.uid}] Posterior Sample #{infer_id}: Beginning HMC inference...\"", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Burn-in.", "\n", "# Print out whether first 10 samples are accepted/rejected to get a litmus test on hyperparameters.", "\n", "self", ".", "accepts", "=", "0", "\n", "self", ".", "rejects", "=", "0", "\n", "for", "i", "in", "range", "(", "1", ",", "self", ".", "hmc_nburnin", "+", "1", ")", ":", "\n", "\t\t\t", "self", ".", "single", "(", "with_data", ")", "\n", "if", "verbose", "and", "i", "<", "11", ":", "\n", "\t\t\t\t", "logging", ".", "info", "(", "f'  Iteration {i} (litmus): {self.accepts} accepts, {self.rejects} rejects.'", ")", "\n", "", "if", "verbose", "and", "i", "%", "500", "==", "0", ":", "\n", "\t\t\t\t", "logging", ".", "info", "(", "f'  Iteration {i}: Acceptance rate is {100 * (self.accepts / i):.2f}%.'", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "if", "self", ".", "hmc_nburnin", ":", "\n", "\t\t\t\t", "logging", ".", "info", "(", "f'  All {self.hmc_nburnin} burn-in steps completed. Acceptance rate is {100 * (self.accepts / self.hmc_nburnin):.2f}%.'", ")", "\n", "\n", "# Collect samples.", "\n", "", "", "logging", ".", "info", "(", "'  Collecting samples now...'", ")", "\n", "self", ".", "accepts", "=", "0", "\n", "self", ".", "rejects", "=", "0", "\n", "samples", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "self", ".", "infer_nsamples", "*", "self", ".", "hmc_ninterval", "+", "1", ")", ":", "\n", "\t\t\t", "self", ".", "single", "(", "with_data", ")", "\n", "if", "i", "%", "self", ".", "hmc_ninterval", "==", "0", ":", "\n", "\t\t\t\t", "samples", ".", "append", "(", "self", ".", "weights", ".", "data", ".", "clone", "(", ")", ")", "\n", "", "if", "verbose", "and", "i", "%", "(", "10", "*", "self", ".", "hmc_ninterval", ")", "==", "0", ":", "\n", "\t\t\t\t", "accept_perc", "=", "100", "*", "(", "self", ".", "accepts", "/", "i", ")", "\n", "logging", ".", "info", "(", "f'  {int(i / self.hmc_ninterval)} samples collected. Acceptance rate is {accept_perc:.2f}%.'", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "end_time", "=", "time", ".", "time", "(", ")", "\n", "if", "self", ".", "infer_nsamples", ":", "\n", "\t\t\t\t", "accept_perc", "=", "100", "*", "(", "self", ".", "accepts", "/", "(", "self", ".", "infer_nsamples", "*", "self", ".", "hmc_ninterval", ")", ")", "\n", "logging", ".", "info", "(", "f'  All {self.infer_nsamples} samples collected. Acceptance rate is {accept_perc:.2f}%. Time took: {(end_time - start_time):.0f} seconds.'", ")", "\n", "\n", "", "", "samples", "=", "torch", ".", "stack", "(", "samples", ")", "\n", "torch", ".", "save", "(", "samples", ",", "f\"history/{self.uid}_hmc{infer_id}.pt\"", ")", "\n", "self", ".", "all_bayes_samples", ".", "append", "(", "(", "samples", ",", "f\"hmc_{'ocbnn' if self.use_ocbnn else 'baseline'}\"", ")", ")", "\n", "logging", ".", "info", "(", "f'[{self.uid}] Posterior Sample #{infer_id}: HMC inference completed. Samples saved as `history/{self.uid}_hmc{infer_id}.pt`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.BBBMixin.sample_q": [[132, 141], ["torch.logsumexp", "torch.distributions.normal.Normal().log_prob", "torch.stack", "torch.randn", "torch.distributions.normal.Normal", "torch.zeros"], "methods", ["None"], ["def", "sample_q", "(", "self", ",", "k", ",", "q_params", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Sample a set of weights from current variational parameters. \"\"\"", "\n", "if", "q_params", "is", "None", ":", "\n", "\t\t\t", "q_params", "=", "self", ".", "q_params", "\n", "", "mean", ",", "log_std", "=", "self", ".", "q_params", "[", ":", ",", "0", "]", ",", "q_params", "[", ":", ",", "1", "]", "\n", "std", "=", "torch", ".", "logsumexp", "(", "torch", ".", "stack", "(", "(", "log_std", ",", "torch", ".", "zeros", "(", "self", ".", "nweights", ")", ")", ")", ",", "0", ")", "\n", "weights", "=", "mean", "+", "torch", ".", "randn", "(", "k", ",", "self", ".", "nweights", ")", "*", "std", "\n", "logq", "=", "Normal", "(", "mean", ",", "std", ")", ".", "log_prob", "(", "weights", ")", "\n", "return", "weights", ",", "logq", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.BBBMixin.compute_elbo": [[142, 154], ["inference.BBBMixin.sample_q", "range", "inference.BBBMixin.log_posterior", "logq[].sum", "inference.BBBMixin.log_prior", "logq[].sum"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.BBBMixin.sample_q", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.log_posterior", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.log_prior"], ["", "def", "compute_elbo", "(", "self", ",", "with_data", ",", "batch_indices", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Computes ELBO using samples from variational parameters. \"\"\"", "\n", "weights", ",", "logq", "=", "self", ".", "sample_q", "(", "self", ".", "bbb_esamples", ")", "\n", "elbo", "=", "0", "\n", "for", "j", "in", "range", "(", "self", ".", "bbb_esamples", ")", ":", "\n", "\t\t\t", "self", ".", "weights", "=", "weights", "[", "j", "]", "\n", "if", "with_data", ":", "\n", "\t\t\t\t", "elbo", "+=", "self", ".", "log_posterior", "(", "batch_indices", ")", "-", "logq", "[", "j", "]", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "elbo", "+=", "self", ".", "log_prior", "(", ")", "-", "logq", "[", "j", "]", ".", "sum", "(", ")", "\n", "", "", "elbo", "/=", "self", ".", "bbb_esamples", "\n", "return", "elbo", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.BBBMixin.infer": [[155, 201], ["logging.info", "time.time", "torch.autograd.Variable", "torch.optim.Adagrad", "range", "inference.BBBMixin.q_params.detach_", "torch.save", "inference.BBBMixin.sample_q", "inference.BBBMixin.all_bayes_samples.append", "torch.save", "logging.info", "logging.info", "len", "torch.randn", "torch.ones", "torch.cat", "torch.optim.Adagrad.zero_grad", "loss.backward", "torch.optim.Adagrad.step", "inference.BBBMixin.elbos.append", "time.time", "logging.info", "torch.arange", "inference.BBBMixin.compute_elbo", "inference.BBBMixin.compute_elbo", "inference.BBBMixin.item", "logging.info"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.BBBMixin.sample_q", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.BBBMixin.compute_elbo", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.BBBMixin.compute_elbo"], ["", "def", "infer", "(", "self", ",", "verbose", "=", "True", ",", "with_data", "=", "True", ")", ":", "\n", "\t\t", "\"\"\" Perform BBB and optimize variational parameters.\n\n\t\t\tBBB allows for batched inference, which is automatically set up by defining the config `nbatches`. \n\t\t\t\n\t\t\tBoth the final variational parameters, as well as samples from these parameters are saved.\n\t\t\tThe samples are loaded into `self.all_bayes_samples` for downstream prediction.  \n\n\t\t\tIf `with_data`, sample from posterior, else, sample from prior. \n\t\t\"\"\"", "\n", "infer_id", "=", "len", "(", "self", ".", "all_bayes_samples", ")", "+", "1", "\n", "logging", ".", "info", "(", "f\"[{self.uid}] Posterior Sample #{infer_id}: Beginning BBB inference...\"", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Initialize variational parameters.", "\n", "init_means", "=", "self", ".", "bbb_init_mean", "+", "torch", ".", "randn", "(", "self", ".", "nweights", ",", "1", ")", "\n", "init_log_stds", "=", "self", ".", "bbb_init_std", "*", "torch", ".", "ones", "(", "self", ".", "nweights", ",", "1", ")", "\n", "self", ".", "q_params", "=", "Variable", "(", "torch", ".", "cat", "(", "[", "init_means", ",", "init_log_stds", "]", ",", "dim", "=", "1", ")", ",", "requires_grad", "=", "True", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adagrad", "(", "[", "self", ".", "q_params", "]", ",", "lr", "=", "self", ".", "bbb_init_lr", ")", "\n", "\n", "# Optimization loop.", "\n", "self", ".", "elbos", "=", "[", "]", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "bbb_epochs", "+", "1", ")", ":", "\n", "\t\t\t", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "nbatches", ":", "\n", "\t\t\t\t", "batch_indices", "=", "torch", ".", "arange", "(", "epoch", "%", "self", ".", "nbatches", ",", "self", ".", "N_train", ",", "self", ".", "nbatches", ")", "\n", "elbo", "=", "self", ".", "compute_elbo", "(", "with_data", ",", "batch_indices", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "elbo", "=", "self", ".", "compute_elbo", "(", "with_data", ")", "\n", "", "loss", "=", "-", "1", "*", "elbo", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "self", ".", "elbos", ".", "append", "(", "elbo", ".", "item", "(", ")", ")", "\n", "if", "verbose", "and", "epoch", "%", "100", "==", "0", ":", "\n", "\t\t\t\t", "logging", ".", "info", "(", "f'  Epoch {epoch}: {self.elbos[-1]:.2f}'", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "end_time", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "f'  {self.bbb_epochs} epochs completed. Final ELBO is {self.elbos[-1]:.2f}. Time took: {(end_time - start_time):.0f} seconds.'", ")", "\n", "\n", "", "self", ".", "q_params", ".", "detach_", "(", ")", "\n", "torch", ".", "save", "(", "self", ".", "q_params", ",", "f\"history/{self.uid}_bbb{infer_id}_qparams.pt\"", ")", "\n", "samples", ",", "_", "=", "self", ".", "sample_q", "(", "self", ".", "infer_nsamples", ")", "\n", "self", ".", "all_bayes_samples", ".", "append", "(", "(", "samples", ",", "f\"bbb_{'ocbnn' if self.use_ocbnn else 'baseline'}\"", ")", ")", "\n", "torch", ".", "save", "(", "samples", ",", "f\"history/{self.uid}_bbb{infer_id}.pt\"", ")", "\n", "logging", ".", "info", "(", "f'[{self.uid}] Posterior Sample #{infer_id}: BBB inference completed.'", ")", "\n", "logging", ".", "info", "(", "f'[{self.uid}] Variational parameters saved as `history/{self.uid}_bbb{infer_id}_qparams.pt`. Samples saved as `history/{self.uid}_bbb{infer_id}.pt`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SVGDMixin._compute_rbf_h": [[208, 218], ["torch.nn.PairwiseDistance", "torch.zeros", "range", "fkernel.triu().flatten.triu().flatten.triu().flatten", "fkernel[].median", "torch.nn.PairwiseDistance.", "math.log", "fkernel.triu().flatten.triu().flatten.triu", "fkernel.triu().flatten.triu().flatten.nonzero"], "methods", ["None"], ["def", "_compute_rbf_h", "(", "self", ")", ":", "\n", "\t\t", "\"\"\" Compute h = (med ** 2) / log(n), where med is median of pairwise distances. \"\"\"", "\n", "pdist", "=", "torch", ".", "nn", ".", "PairwiseDistance", "(", ")", "\n", "fkernel", "=", "torch", ".", "zeros", "(", "self", ".", "infer_nsamples", ",", "self", ".", "infer_nsamples", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "infer_nsamples", ")", ":", "\n", "\t\t\t", "fkernel", "[", "i", "]", "=", "pdist", "(", "self", ".", "particles", "[", "i", "]", ",", "self", ".", "particles", ")", "\n", "\n", "", "fkernel", "=", "fkernel", ".", "triu", "(", "diagonal", "=", "1", ")", ".", "flatten", "(", ")", "\n", "med", "=", "fkernel", "[", "fkernel", ".", "nonzero", "(", ")", "]", ".", "median", "(", ")", "\n", "return", "(", "med", "**", "2", ")", "/", "math", ".", "log", "(", "self", ".", "infer_nsamples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SVGDMixin.kernel_rbf": [[219, 224], ["torch.norm", "torch.exp"], "methods", ["None"], ["", "def", "kernel_rbf", "(", "self", ",", "x1", ",", "x2", ",", "h", ")", ":", "\n", "\t\t", "\"\"\" Compute the RBF kernel: k(x, x') = exp(-1/h * l2-norm(x, x')). \"\"\"", "\n", "k", "=", "torch", ".", "norm", "(", "x1", "-", "x2", ")", "\n", "k", "=", "(", "k", "**", "2", ")", "/", "-", "h", "\n", "return", "torch", ".", "exp", "(", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SVGDMixin.single": [[225, 260], ["inference.SVGDMixin._compute_rbf_h", "torch.zeros", "torch.zeros", "range", "torch.zeros", "range", "torch.zeros.unsqueeze().repeat", "range", "update.mean.mean.mean", "torch.zeros", "range", "torch.autograd.Variable", "kernel[].unsqueeze", "torch.autograd.Variable", "inference.SVGDMixin.kernel_rbf", "inference.SVGDMixin.backward", "inference.SVGDMixin.log_posterior().backward", "inference.SVGDMixin.log_prior().backward", "torch.zeros.unsqueeze", "inference.SVGDMixin.log_posterior", "inference.SVGDMixin.log_prior"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SVGDMixin._compute_rbf_h", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SVGDMixin.kernel_rbf", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.log_posterior", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.log_prior"], ["", "def", "single", "(", "self", ",", "with_data", ",", "batch_indices", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Computes a single SVGD epoch and updates the particles. \"\"\"", "\n", "h", "=", "self", ".", "_compute_rbf_h", "(", ")", "\n", "kernel", "=", "torch", ".", "zeros", "(", "self", ".", "infer_nsamples", ",", "self", ".", "infer_nsamples", ")", "\n", "\n", "# Repulsive term", "\n", "gradk_matrix", "=", "torch", ".", "zeros", "(", "self", ".", "infer_nsamples", ",", "self", ".", "infer_nsamples", ",", "self", ".", "nweights", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "infer_nsamples", ")", ":", "\n", "\t\t\t", "grad_each_i", "=", "torch", ".", "zeros", "(", "self", ".", "infer_nsamples", ",", "self", ".", "nweights", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "infer_nsamples", ")", ":", "\n", "\t\t\t\t", "tempw", "=", "Variable", "(", "self", ".", "particles", "[", "j", "]", ",", "requires_grad", "=", "True", ")", "\n", "tempw", ".", "grad", "=", "None", "\n", "k", "=", "self", ".", "kernel_rbf", "(", "tempw", ",", "self", ".", "particles", "[", "i", "]", ",", "h", ")", "\n", "kernel", "[", "j", ",", "i", "]", "=", "k", "\n", "k", ".", "backward", "(", ")", "\n", "grad_each_i", "[", "j", "]", "=", "tempw", ".", "grad", "\n", "", "gradk_matrix", "[", "i", "]", "=", "grad_each_i", "\n", "\n", "# Smoothed gradient term", "\n", "", "logp_matrix", "=", "torch", ".", "zeros", "(", "self", ".", "infer_nsamples", ",", "self", ".", "nweights", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "infer_nsamples", ")", ":", "\n", "\t\t\t", "self", ".", "weights", "=", "Variable", "(", "self", ".", "particles", "[", "j", "]", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "weights", ".", "grad", "=", "None", "\n", "if", "with_data", ":", "\n", "\t\t\t\t", "self", ".", "log_posterior", "(", "batch_indices", ")", ".", "backward", "(", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "self", ".", "log_prior", "(", ")", ".", "backward", "(", ")", "\n", "", "logp_matrix", "[", "j", "]", "=", "self", ".", "weights", ".", "grad", "\n", "", "update", "=", "logp_matrix", ".", "unsqueeze", "(", "dim", "=", "0", ")", ".", "repeat", "(", "self", ".", "infer_nsamples", ",", "1", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "infer_nsamples", ")", ":", "\n", "\t\t\t", "update", "[", "i", "]", "*=", "kernel", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "\n", "", "update", "+=", "gradk_matrix", "\n", "update", "=", "update", ".", "mean", "(", "dim", "=", "1", ")", "\n", "return", "update", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SVGDMixin.infer": [[261, 293], ["logging.info", "time.time", "time.time", "torch.distributions.normal.Normal().sample", "torch.optim.Adagrad", "range", "inference.SVGDMixin.particles.detach_", "torch.save", "inference.SVGDMixin.all_bayes_samples.append", "logging.info", "len", "torch.Size", "torch.optim.Adagrad.zero_grad", "torch.optim.Adagrad.step", "time.time", "logging.info", "torch.distributions.normal.Normal", "torch.arange", "inference.SVGDMixin.single", "inference.SVGDMixin.single", "logging.info", "inference.SVGDMixin.particles.data.clone"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.single", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.single"], ["", "def", "infer", "(", "self", ",", "verbose", "=", "True", ",", "with_data", "=", "True", ")", ":", "\n", "\t\t", "\"\"\" Perform SVGD and collects samples (particles).\n\t\t\tIf `with_data`, sample from posterior, else, sample from prior.\n\t\t\tSVGD allows for batched inference, which is automatically set up by defining the config `nbatches`.   \n\t\t\"\"\"", "\n", "infer_id", "=", "len", "(", "self", ".", "all_bayes_samples", ")", "+", "1", "\n", "logging", ".", "info", "(", "f\"[{self.uid}] Posterior Sample #{infer_id}: Beginning SVGD inference...\"", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "particles", "=", "Normal", "(", "0", ",", "self", ".", "sigma_w", ")", ".", "sample", "(", "torch", ".", "Size", "(", "[", "self", ".", "infer_nsamples", ",", "self", ".", "nweights", "]", ")", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adagrad", "(", "[", "self", ".", "particles", "]", ",", "lr", "=", "self", ".", "svgd_init_lr", ")", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "svgd_epochs", "+", "1", ")", ":", "\n", "\t\t\t", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "nbatches", ":", "\n", "\t\t\t\t", "batch_indices", "=", "torch", ".", "arange", "(", "epoch", "%", "self", ".", "nbatches", ",", "self", ".", "N_train", ",", "self", ".", "nbatches", ")", "\n", "update", "=", "self", ".", "single", "(", "with_data", ",", "batch_indices", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "update", "=", "self", ".", "single", "(", "with_data", ")", "\n", "", "self", ".", "particles", ".", "grad", "=", "-", "update", "\n", "optimizer", ".", "step", "(", ")", "\n", "if", "verbose", "and", "epoch", "%", "10", "==", "0", ":", "\n", "\t\t\t\t", "logging", ".", "info", "(", "f'  Epoch {epoch} reached.'", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "end_time", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "info", "(", "f'  {self.svgd_epochs} epochs completed. Time took: {(end_time - start_time):.0f} seconds.'", ")", "\n", "\n", "# Convert to numpy for evaluation and plotting.", "\n", "", "self", ".", "particles", ".", "detach_", "(", ")", "\n", "torch", ".", "save", "(", "self", ".", "particles", ",", "f\"history/{self.uid}_svgd{infer_id}.pt\"", ")", "\n", "self", ".", "all_bayes_samples", ".", "append", "(", "(", "self", ".", "particles", ".", "data", ".", "clone", "(", ")", ",", "f\"svgd_{'ocbnn' if self.use_ocbnn else 'baseline'}\"", ")", ")", "\n", "logging", ".", "info", "(", "f'[{self.uid}] Posterior Sample #{infer_id}: SVGD inference completed. Samples saved as `history/{self.uid}_svgd{infer_id}.pt`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.get_stepsize": [[300, 303], ["None"], "methods", ["None"], ["def", "get_stepsize", "(", "self", ",", "t", ")", ":", "\n", "\t\t", "\"\"\" Computes stepsize: epsilon_t = a(b + t)^(-gamma). \"\"\"", "\n", "return", "self", ".", "sgld_epa", "*", "(", "(", "self", ".", "sgld_epb", "+", "t", ")", "**", "(", "-", "1", "*", "self", ".", "sgld_epgamma", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.single": [[304, 320], ["torch.zeros", "inference.SGLDMixin.log_prior().backward", "inference.SGLDMixin.log_likelihood().backward", "inference.SGLDMixin.log_prior", "inference.SGLDMixin.log_likelihood"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BayesianNeuralNetwork.log_prior", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.log_likelihood"], ["", "def", "single", "(", "self", ",", "with_data", ",", "batch_indices", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Runs a single iteration of SGLD. \"\"\"", "\n", "update", "=", "torch", ".", "zeros", "(", "self", ".", "nweights", ")", "\n", "\n", "# Prior term.", "\n", "self", ".", "weights", ".", "grad", "=", "None", "\n", "self", ".", "log_prior", "(", ")", ".", "backward", "(", ")", "\n", "update", "+=", "self", ".", "weights", ".", "grad", "\n", "\n", "# Batched likelihood term.", "\n", "if", "with_data", ":", "\n", "\t\t\t", "self", ".", "weights", ".", "grad", "=", "None", "\n", "self", ".", "log_likelihood", "(", "batch_indices", ")", ".", "backward", "(", ")", "\n", "update", "+=", "self", ".", "weights", ".", "grad", "\n", "\n", "", "return", "update", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.infer": [[321, 376], ["logging.info", "time.time", "range", "logging.info", "range", "torch.stack", "torch.save", "inference.SGLDMixin.all_bayes_samples.append", "logging.info", "len", "inference.SGLDMixin.get_stepsize", "torch.distributions.normal.Normal().sample", "inference.SGLDMixin.get_stepsize", "torch.distributions.normal.Normal().sample", "time.time", "torch.arange", "inference.SGLDMixin.single", "inference.SGLDMixin.single", "logging.info", "logging.info", "torch.arange", "inference.SGLDMixin.single", "inference.SGLDMixin.single", "torch.stack.append", "logging.info", "logging.info", "torch.distributions.normal.Normal", "torch.sum", "logging.error", "torch.distributions.normal.Normal", "inference.SGLDMixin.weights.data.clone", "torch.zeros", "torch.isnan", "torch.zeros", "torch.ones", "torch.ones", "int"], "methods", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.get_stepsize", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.get_stepsize", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.single", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.single", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.single", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.inference.SGLDMixin.single"], ["", "def", "infer", "(", "self", ",", "verbose", "=", "True", ",", "with_data", "=", "True", ")", ":", "\n", "\t\t", "\"\"\" Run SGLD and collect samples.\n\t\t\tIf `with_data`, sample from posterior, else, sample from prior.\n\t\t\tSGLD allows for batched inference, which is automatically set up by defining the config `nbatches`.  \n\t\t\"\"\"", "\n", "infer_id", "=", "len", "(", "self", ".", "all_bayes_samples", ")", "+", "1", "\n", "logging", ".", "info", "(", "f\"[{self.uid}] Posterior Sample #{infer_id}: Beginning SGLD inference...\"", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Burn-in stage.", "\n", "for", "t", "in", "range", "(", "1", ",", "self", ".", "sgld_nburnin", "+", "1", ")", ":", "\n", "\t\t\t", "epsilon", "=", "self", ".", "get_stepsize", "(", "t", ")", "\n", "if", "self", ".", "nbatches", ":", "\n", "\t\t\t\t", "batch_indices", "=", "torch", ".", "arange", "(", "t", "%", "self", ".", "nbatches", ",", "self", ".", "N_train", ",", "self", ".", "nbatches", ")", "\n", "update", "=", "self", ".", "single", "(", "with_data", ",", "batch_indices", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "update", "=", "self", ".", "single", "(", "with_data", ")", "\n", "", "update", "*=", "epsilon", "/", "2", "\n", "update", "+=", "Normal", "(", "torch", ".", "zeros", "(", "self", ".", "nweights", ")", ",", "(", "epsilon", "**", "0.5", ")", "*", "torch", ".", "ones", "(", "self", ".", "nweights", ")", ")", ".", "sample", "(", ")", "\n", "self", ".", "weights", ".", "data", "+=", "update", "\n", "if", "verbose", "and", "t", "%", "1000", "==", "0", ":", "\n", "\t\t\t\t", "if", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "self", ".", "weights", ")", ")", ">", "0", ":", "\n", "\t\t\t\t\t", "logging", ".", "error", "(", "f\"[{self.uid}] NaNs encountered in current set of weights.\"", ")", "\n", "raise", "Exception", "\n", "", "logging", ".", "info", "(", "f'  {t} iterations burnt-in.'", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "if", "self", ".", "sgld_nburnin", ":", "\n", "\t\t\t\t", "logging", ".", "info", "(", "f'  All {self.sgld_nburnin} burn-in steps completed.'", ")", "\n", "\n", "# Collecting SGLD samples.", "\n", "", "", "logging", ".", "info", "(", "'  Collecting samples now...'", ")", "\n", "samples", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "sgld_nburnin", "+", "1", ",", "self", ".", "sgld_nburnin", "+", "self", ".", "infer_nsamples", "*", "self", ".", "sgld_ninterval", "+", "1", ")", ":", "\n", "\t\t\t", "epsilon", "=", "self", ".", "get_stepsize", "(", "t", ")", "\n", "if", "self", ".", "nbatches", ":", "\n", "\t\t\t\t", "batch_indices", "=", "torch", ".", "arange", "(", "t", "%", "self", ".", "nbatches", ",", "self", ".", "N_train", ",", "self", ".", "nbatches", ")", "\n", "update", "=", "self", ".", "single", "(", "with_data", ",", "batch_indices", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "update", "=", "self", ".", "single", "(", "with_data", ")", "\n", "", "update", "*=", "epsilon", "/", "2", "\n", "update", "+=", "Normal", "(", "torch", ".", "zeros", "(", "self", ".", "nweights", ")", ",", "(", "epsilon", "**", "0.5", ")", "*", "torch", ".", "ones", "(", "self", ".", "nweights", ")", ")", ".", "sample", "(", ")", "\n", "self", ".", "weights", ".", "data", "+=", "update", "\n", "if", "(", "t", "-", "self", ".", "sgld_nburnin", ")", "%", "self", ".", "sgld_ninterval", "==", "0", ":", "\n", "\t\t\t\t", "samples", ".", "append", "(", "self", ".", "weights", ".", "data", ".", "clone", "(", ")", ")", "\n", "", "if", "verbose", "and", "(", "t", "-", "self", ".", "sgld_nburnin", ")", "%", "100", "==", "0", ":", "\n", "\t\t\t\t", "logging", ".", "info", "(", "f'  {int((t - self.sgld_nburnin) / self.sgld_ninterval)} samples collected.'", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "end_time", "=", "time", ".", "time", "(", ")", "\n", "if", "self", ".", "infer_nsamples", ":", "\n", "\t\t\t\t", "logging", ".", "info", "(", "f'  All {self.infer_nsamples} samples collected. Time took: {(end_time - start_time):.0f} seconds.'", ")", "\n", "\n", "", "", "samples", "=", "torch", ".", "stack", "(", "samples", ")", "\n", "torch", ".", "save", "(", "samples", ",", "f\"history/{self.uid}_sgld{infer_id}.pt\"", ")", "\n", "self", ".", "all_bayes_samples", ".", "append", "(", "(", "samples", ",", "f\"sgld_{'ocbnn' if self.use_ocbnn else 'baseline'}\"", ")", ")", "\n", "logging", ".", "info", "(", "f'[{self.uid}] Posterior Sample #{infer_id}: SGLD inference completed. Samples saved as `history/{self.uid}_sgld{infer_id}.pt`.'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_1dregressor": [[27, 79], ["matplotlib.figure", "matplotlib.gca().set_ylim", "matplotlib.gca().set_xlim", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.tight_layout", "re.sub().lower().replace", "matplotlib.savefig", "logging.info", "matplotlib.scatter", "bnn.predict().squeeze().t", "addons", "tuple", "matplotlib.gca", "matplotlib.gca", "bnn.X_train.data.numpy", "bnn.Y_train.data.numpy", "bnn.predict().squeeze().t.mean().squeeze", "numpy.percentile().squeeze", "numpy.percentile().squeeze", "numpy.percentile().squeeze", "numpy.percentile().squeeze", "matplotlib.fill_between", "matplotlib.fill_between", "matplotlib.plot", "re.sub().lower", "bnn.predict().squeeze", "domain.squeeze", "domain.squeeze", "domain.squeeze", "bnn.predict().squeeze().t.mean", "numpy.percentile", "numpy.percentile", "numpy.percentile", "numpy.percentile", "matplotlib.plot", "re.sub", "bnn.predict"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.predict"], ["def", "plot_1dregressor", "(", "bnn", ",", "plot_title", ",", "domain", ",", "ylims", ",", "plot_type", "=", "\"interval\"", ",", "with_data", "=", "True", ",", "\n", "plot_fontsize", "=", "18", ",", "plot_figsize", "=", "(", "8", ",", "6", ")", ",", "plot_dpi", "=", "400", ",", "addons", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Plot posterior/prior predictive for 1D regression tasks. \n\t\t\t\n\t\t\t`plot_type`: \"full\" for individual predictive functions, \"interval\" for credible intervals\n\t\t\"\"\"", "\n", "# Configurations.", "\n", "assert", "(", "bnn", ".", "Xdim", "==", "1", ")", "\n", "rcParams", "[", "'font.family'", "]", "=", "'serif'", "\n", "rcParams", "[", "'font.serif'", "]", "=", "[", "'Charter'", "]", "\n", "pp_fig", "=", "plt", ".", "figure", "(", "figsize", "=", "tuple", "(", "plot_figsize", ")", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_ylim", "(", "ylims", "[", "0", "]", ",", "ylims", "[", "1", "]", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_xlim", "(", "domain", "[", "0", "]", ",", "domain", "[", "-", "1", "]", ")", "\n", "plt", ".", "xticks", "(", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "yticks", "(", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "title", "(", "plot_title", ",", "fontsize", "=", "plot_fontsize", "+", "4", ")", "\n", "plt", ".", "xlabel", "(", "r'$\\mathcal{X}$'", ",", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "ylabel", "(", "r'$\\mathcal{Y}$'", ",", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "# Plot training data, if it exists.", "\n", "if", "with_data", ":", "\n", "\t\t\t", "plt", ".", "scatter", "(", "bnn", ".", "X_train", ".", "data", ".", "numpy", "(", ")", ",", "bnn", ".", "Y_train", ".", "data", ".", "numpy", "(", ")", ",", "facecolors", "=", "'w'", ",", "edgecolors", "=", "'k'", ",", "zorder", "=", "999", ")", "\n", "\n", "# For each inference run, plot results.", "\n", "", "for", "samples", ",", "name", "in", "bnn", ".", "all_bayes_samples", ":", "\n", "\t\t\t", "if", "\"ocbnn\"", "in", "name", ":", "\n", "\t\t\t\t", "cdict", "=", "COLORS", "[", "'blue'", "]", "\n", "", "else", ":", "\n", "\t\t\t\t", "cdict", "=", "COLORS", "[", "'gray'", "]", "\n", "", "results", "=", "bnn", ".", "predict", "(", "samples", ",", "domain", ")", ".", "squeeze", "(", ")", ".", "t", "(", ")", "\n", "if", "plot_type", "==", "\"interval\"", ":", "\n", "\t\t\t\t", "means", "=", "results", ".", "mean", "(", "dim", "=", "1", ")", ".", "squeeze", "(", ")", "\n", "lower2", "=", "np", ".", "percentile", "(", "results", ",", "2.275", ",", "axis", "=", "1", ")", ".", "squeeze", "(", ")", "\n", "upper2", "=", "np", ".", "percentile", "(", "results", ",", "97.725", ",", "axis", "=", "1", ")", ".", "squeeze", "(", ")", "\n", "lower1", "=", "np", ".", "percentile", "(", "results", ",", "15.865", ",", "axis", "=", "1", ")", ".", "squeeze", "(", ")", "\n", "upper1", "=", "np", ".", "percentile", "(", "results", ",", "84.135", ",", "axis", "=", "1", ")", ".", "squeeze", "(", ")", "\n", "plt", ".", "fill_between", "(", "domain", ".", "squeeze", "(", ")", ",", "lower1", ",", "upper1", ",", "facecolor", "=", "cdict", "[", "0", "]", ",", "alpha", "=", "cdict", "[", "1", "]", ")", "\n", "plt", ".", "fill_between", "(", "domain", ".", "squeeze", "(", ")", ",", "lower2", ",", "upper2", ",", "facecolor", "=", "cdict", "[", "0", "]", ",", "alpha", "=", "cdict", "[", "2", "]", ")", "\n", "plt", ".", "plot", "(", "domain", ".", "squeeze", "(", ")", ",", "means", ",", "color", "=", "cdict", "[", "0", "]", ",", "zorder", "=", "99", ")", "\n", "", "elif", "plot_type", "==", "\"full\"", ":", "\n", "\t\t\t\t", "for", "line", "in", "results", ".", "T", ":", "\n", "\t\t\t\t\t", "plt", ".", "plot", "(", "domain", ",", "line", ",", "color", "=", "cdict", "[", "0", "]", ",", "alpha", "=", "cdict", "[", "1", "]", ",", "linewidth", "=", "0.8", ")", "\n", "\n", "# Plot additional/custom structures.", "\n", "", "", "", "if", "addons", "is", "not", "None", ":", "\n", "\t\t\t", "addons", "(", ")", "\n", "\n", "# Save and close.", "\n", "", "plot_savename", "=", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "plot_title", ")", ".", "lower", "(", ")", ".", "replace", "(", "' '", ",", "'_'", ")", "\n", "plt", ".", "savefig", "(", "f'history/{bnn.uid}_plot_{plot_savename}.png'", ",", "dpi", "=", "plot_dpi", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}] {\"Posterior\" if with_data else \"Prior\"} predictive plot saved as `history/{bnn.uid}_plot_{plot_savename}.png`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_2d2classifier": [[82, 136], ["matplotlib.figure", "matplotlib.gca().set_ylim", "matplotlib.gca().set_xlim", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.tight_layout", "matplotlib.plot", "matplotlib.plot", "torch.stack().t", "bnn.predict().t", "numpy.apply_along_axis", "numpy.apply_along_axis", "re.sub().lower().replace", "matplotlib.savefig", "logging.info", "bnn.X_train.data.numpy", "bnn.Y_train.squeeze().data.numpy", "matplotlib.scatter", "addons", "tuple", "matplotlib.gca", "matplotlib.gca", "torch.stack", "bnn.predict", "numpy.bincount", "np.apply_along_axis.tolist", "enumerate", "re.sub().lower", "range", "matplotlib.colors.ListedColormap", "enumerate", "bnn.Y_train.squeeze", "x1_domain.repeat", "x2_domain.repeat_interleave", "len", "matplotlib.gca().contourf", "re.sub", "len", "len", "Xte[].reshape", "Xte[].reshape", "results_count[].reshape", "matplotlib.gca", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.predict"], ["", "def", "plot_2d2classifier", "(", "bnn", ",", "plot_title", ",", "x1_domain", ",", "x2_domain", ",", "plot_type", "=", "\"interval\"", ",", "with_data", "=", "True", ",", "\n", "plot_fontsize", "=", "18", ",", "plot_figsize", "=", "(", "8", ",", "6", ")", ",", "plot_dpi", "=", "400", ",", "addons", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Plot posterior/prior predictive for 2D classication tasks with 2 output classes (i.e. binary classification). \n\t\t\tNote that unlike regression, each plot can only show the results of ONE inference. By default, `bnn.all_bayes_samples[-1]` is taken.\n\n\t\t\t`plot_type`: \"full\" for individual predictive functions (grayscale shading), \"interval\" for credible intervals (contour lines)\n\t\t\"\"\"", "\n", "# Configurations.", "\n", "assert", "(", "bnn", ".", "Xdim", "==", "2", ")", "\n", "rcParams", "[", "'font.family'", "]", "=", "'serif'", "\n", "rcParams", "[", "'font.serif'", "]", "=", "[", "'Charter'", "]", "\n", "pp_fig", "=", "plt", ".", "figure", "(", "figsize", "=", "tuple", "(", "plot_figsize", ")", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_ylim", "(", "x2_domain", "[", "0", "]", ",", "x2_domain", "[", "-", "1", "]", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_xlim", "(", "x1_domain", "[", "0", "]", ",", "x1_domain", "[", "-", "1", "]", ")", "\n", "plt", ".", "xticks", "(", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "yticks", "(", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "title", "(", "plot_title", ",", "fontsize", "=", "plot_fontsize", "+", "4", ")", "\n", "plt", ".", "xlabel", "(", "r'$\\mathcal{X}_1$'", ",", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "ylabel", "(", "r'$\\mathcal{X}_2$'", ",", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "# Plot training data.", "\n", "Xtr", ",", "Ytr", "=", "bnn", ".", "X_train", ".", "data", ".", "numpy", "(", ")", ",", "bnn", ".", "Y_train", ".", "squeeze", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "plt", ".", "plot", "(", "Xtr", "[", "Ytr", "==", "1", "]", "[", ":", ",", "0", "]", ",", "Xtr", "[", "Ytr", "==", "1", "]", "[", ":", ",", "1", "]", ",", "color", "=", "COLORS", "[", "'sand'", "]", "[", "0", "]", ",", "\n", "marker", "=", "'o'", ",", "markeredgecolor", "=", "'k'", ",", "markeredgewidth", "=", "2.0", ",", "linewidth", "=", "0", ")", "\n", "plt", ".", "plot", "(", "Xtr", "[", "Ytr", "==", "0", "]", "[", ":", ",", "0", "]", ",", "Xtr", "[", "Ytr", "==", "0", "]", "[", ":", ",", "1", "]", ",", "color", "=", "COLORS", "[", "'ocean'", "]", "[", "0", "]", ",", "\n", "marker", "=", "'o'", ",", "markeredgecolor", "=", "'k'", ",", "markeredgewidth", "=", "2.0", ",", "linewidth", "=", "0", ")", "\n", "\n", "# Plot results of the MOST RECENT set of samples.", "\n", "samples", ",", "_", "=", "bnn", ".", "all_bayes_samples", "[", "-", "1", "]", "\n", "Xte", "=", "torch", ".", "stack", "(", "(", "x1_domain", ".", "repeat", "(", "len", "(", "x2_domain", ")", ")", ",", "x2_domain", ".", "repeat_interleave", "(", "len", "(", "x1_domain", ")", ")", ")", ")", ".", "t", "(", ")", "\n", "results", "=", "bnn", ".", "predict", "(", "samples", ",", "Xte", ")", ".", "t", "(", ")", "\n", "results_count", "=", "np", ".", "apply_along_axis", "(", "lambda", "v", ":", "np", ".", "bincount", "(", "v", ",", "minlength", "=", "2", ")", ",", "1", ",", "results", ")", "\n", "results_count", "=", "np", ".", "apply_along_axis", "(", "lambda", "v", ":", "v", "/", "results", ".", "shape", "[", "1", "]", ",", "1", ",", "results_count", ")", "\n", "colors", "=", "[", "(", "v", "[", "1", "]", ",", "v", "[", "1", "]", ",", "v", "[", "1", "]", ")", "for", "v", "in", "results_count", ".", "tolist", "(", ")", "]", "\n", "if", "plot_type", "==", "\"full\"", ":", "\n", "# grayscale shading: white --> positive (1) output class", "\n", "\t\t\t", "plt", ".", "scatter", "(", "Xte", "[", ":", ",", "0", "]", ",", "Xte", "[", ":", ",", "1", "]", ",", "marker", "=", "'o'", ",", "c", "=", "range", "(", "len", "(", "results", ")", ")", ",", "cmap", "=", "ListedColormap", "(", "colors", ")", ")", "\n", "", "elif", "plot_type", "==", "\"interval\"", ":", "\n", "# shading: orange for positive (1) and blue for negative (0)", "\n", "\t\t\t", "levels", "=", "[", "0.75", ",", "0.9", ",", "1.0", "]", "\n", "for", "idx", ",", "c", "in", "enumerate", "(", "[", "\"ocean\"", ",", "\"sand\"", "]", ")", ":", "\n", "\t\t\t\t", "for", "jdx", ",", "alpha", "in", "enumerate", "(", "[", "0.5", ",", "0.7", "]", ")", ":", "\n", "\t\t\t\t\t", "_", "=", "plt", ".", "gca", "(", ")", ".", "contourf", "(", "Xte", "[", ":", ",", "0", "]", ".", "reshape", "(", "len", "(", "x1_domain", ")", ",", "len", "(", "x2_domain", ")", ")", ",", "Xte", "[", ":", ",", "1", "]", ".", "reshape", "(", "len", "(", "x1_domain", ")", ",", "len", "(", "x2_domain", ")", ")", ",", "\n", "results_count", "[", ":", ",", "idx", "]", ".", "reshape", "(", "len", "(", "x1_domain", ")", ",", "len", "(", "x2_domain", ")", ")", ",", "levels", "=", "levels", "[", "jdx", ":", "jdx", "+", "2", "]", ",", "colors", "=", "COLORS", "[", "c", "]", "[", "0", "]", ",", "alpha", "=", "alpha", ")", "\n", "\n", "# Plot additional/custom structures.", "\n", "", "", "", "if", "addons", "is", "not", "None", ":", "\n", "\t\t\t", "addons", "(", ")", "\n", "\n", "# Save and close.", "\n", "", "plot_savename", "=", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "plot_title", ")", ".", "lower", "(", ")", ".", "replace", "(", "' '", ",", "'_'", ")", "\n", "plt", ".", "savefig", "(", "f'history/{bnn.uid}_plot_{plot_savename}.png'", ",", "dpi", "=", "plot_dpi", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}] {\"Posterior\" if with_data else \"Prior\"} predictive plot saved as `history/{bnn.uid}_plot_{plot_savename}.png`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.plot_2d3classifier": [[139, 190], ["matplotlib.figure", "matplotlib.gca().set_ylim", "matplotlib.gca().set_xlim", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.tight_layout", "range", "torch.stack().t", "bnn.predict().t", "numpy.apply_along_axis", "numpy.apply_along_axis", "re.sub().lower().replace", "matplotlib.savefig", "logging.info", "bnn.X_train.data.numpy", "bnn.Y_train.squeeze().data.numpy", "matplotlib.plot", "tuple", "matplotlib.scatter", "addons", "tuple", "matplotlib.gca", "matplotlib.gca", "torch.stack", "bnn.predict", "numpy.bincount", "np.apply_along_axis.tolist", "enumerate", "re.sub().lower", "numpy.bincount", "range", "matplotlib.colors.ListedColormap", "enumerate", "bnn.Y_train.squeeze", "x1_domain.repeat", "x2_domain.repeat_interleave", "len", "matplotlib.gca().contourf", "re.sub", "len", "len", "Xte[].reshape", "Xte[].reshape", "results_count[].reshape", "matplotlib.gca", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.predict"], ["", "def", "plot_2d3classifier", "(", "bnn", ",", "plot_title", ",", "x1_domain", ",", "x2_domain", ",", "plot_type", "=", "\"interval\"", ",", "with_data", "=", "True", ",", "\n", "plot_fontsize", "=", "18", ",", "plot_figsize", "=", "(", "8", ",", "6", ")", ",", "plot_dpi", "=", "400", ",", "addons", "=", "None", ")", ":", "\n", "\t\t", "\"\"\" Plot posterior/prior predictive for 2D classication tasks with 3 output classes. \n\t\t\tNote that unlike regression, each plot can only show the results of ONE inference. By default, `bnn.all_bayes_samples[-1]` is taken.\n\n\t\t\t`plot_type`: \"full\" for individual predictive functions (3-simplex RGB shading), \"interval\" for credible intervals (contour lines)\n\t\t\"\"\"", "\n", "# Configurations.", "\n", "assert", "(", "bnn", ".", "Xdim", "==", "2", ")", "\n", "rcParams", "[", "'font.family'", "]", "=", "'serif'", "\n", "rcParams", "[", "'font.serif'", "]", "=", "[", "'Charter'", "]", "\n", "pp_fig", "=", "plt", ".", "figure", "(", "figsize", "=", "tuple", "(", "plot_figsize", ")", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_ylim", "(", "x2_domain", "[", "0", "]", ",", "x2_domain", "[", "-", "1", "]", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_xlim", "(", "x1_domain", "[", "0", "]", ",", "x1_domain", "[", "-", "1", "]", ")", "\n", "plt", ".", "xticks", "(", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "yticks", "(", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "title", "(", "plot_title", ",", "fontsize", "=", "plot_fontsize", "+", "4", ")", "\n", "plt", ".", "xlabel", "(", "r'$\\mathcal{X}_1$'", ",", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "ylabel", "(", "r'$\\mathcal{X}_2$'", ",", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "# Plot training data.", "\n", "Xtr", ",", "Ytr", "=", "bnn", ".", "X_train", ".", "data", ".", "numpy", "(", ")", ",", "bnn", ".", "Y_train", ".", "squeeze", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "for", "oc", "in", "range", "(", "bnn", ".", "Ydim", ")", ":", "\n", "\t\t\t", "plt", ".", "plot", "(", "Xtr", "[", "Ytr", "==", "oc", "]", "[", ":", ",", "0", "]", ",", "Xtr", "[", "Ytr", "==", "oc", "]", "[", ":", ",", "1", "]", ",", "color", "=", "np", ".", "bincount", "(", "[", "oc", "]", ",", "minlength", "=", "3", ")", ",", "\n", "marker", "=", "'o'", ",", "markeredgecolor", "=", "'k'", ",", "markeredgewidth", "=", "2.0", ",", "linewidth", "=", "0", ")", "\n", "\n", "# Plot results of the MOST RECENT set of samples.", "\n", "", "samples", ",", "_", "=", "bnn", ".", "all_bayes_samples", "[", "-", "1", "]", "\n", "Xte", "=", "torch", ".", "stack", "(", "(", "x1_domain", ".", "repeat", "(", "len", "(", "x2_domain", ")", ")", ",", "x2_domain", ".", "repeat_interleave", "(", "len", "(", "x1_domain", ")", ")", ")", ")", ".", "t", "(", ")", "\n", "results", "=", "bnn", ".", "predict", "(", "samples", ",", "Xte", ")", ".", "t", "(", ")", "\n", "results_count", "=", "np", ".", "apply_along_axis", "(", "lambda", "v", ":", "np", ".", "bincount", "(", "v", ",", "minlength", "=", "3", ")", ",", "1", ",", "results", ")", "\n", "results_count", "=", "np", ".", "apply_along_axis", "(", "lambda", "v", ":", "v", "/", "results", ".", "shape", "[", "1", "]", ",", "1", ",", "results_count", ")", "\n", "colors", "=", "[", "tuple", "(", "v", ")", "for", "v", "in", "results_count", ".", "tolist", "(", ")", "]", "\n", "if", "plot_type", "==", "\"full\"", ":", "\n", "\t\t\t", "plt", ".", "scatter", "(", "Xte", "[", ":", ",", "0", "]", ",", "Xte", "[", ":", ",", "1", "]", ",", "marker", "=", "'o'", ",", "c", "=", "range", "(", "len", "(", "results", ")", ")", ",", "cmap", "=", "ListedColormap", "(", "colors", ")", ")", "\n", "", "elif", "plot_type", "==", "\"interval\"", ":", "\n", "\t\t\t", "levels", "=", "[", "0.75", ",", "0.9", ",", "1.0", "]", "\n", "for", "idx", ",", "c", "in", "enumerate", "(", "[", "\"red\"", ",", "\"green\"", ",", "\"blue\"", "]", ")", ":", "\n", "\t\t\t\t", "for", "jdx", ",", "alpha", "in", "enumerate", "(", "[", "0.5", ",", "0.7", "]", ")", ":", "\n", "\t\t\t\t\t", "_", "=", "plt", ".", "gca", "(", ")", ".", "contourf", "(", "Xte", "[", ":", ",", "0", "]", ".", "reshape", "(", "len", "(", "x1_domain", ")", ",", "len", "(", "x2_domain", ")", ")", ",", "Xte", "[", ":", ",", "1", "]", ".", "reshape", "(", "len", "(", "x1_domain", ")", ",", "len", "(", "x2_domain", ")", ")", ",", "\n", "results_count", "[", ":", ",", "idx", "]", ".", "reshape", "(", "len", "(", "x1_domain", ")", ",", "len", "(", "x2_domain", ")", ")", ",", "levels", "=", "levels", "[", "jdx", ":", "jdx", "+", "2", "]", ",", "colors", "=", "COLORS", "[", "c", "]", "[", "0", "]", ",", "alpha", "=", "alpha", ")", "\n", "\n", "# Plot additional/custom structures.", "\n", "", "", "", "if", "addons", "is", "not", "None", ":", "\n", "\t\t\t", "addons", "(", ")", "\n", "\n", "# Save and close.", "\n", "", "plot_savename", "=", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "plot_title", ")", ".", "lower", "(", ")", ".", "replace", "(", "' '", ",", "'_'", ")", "\n", "plt", ".", "savefig", "(", "f'history/{bnn.uid}_plot_{plot_savename}.png'", ",", "dpi", "=", "plot_dpi", ")", "\n", "logging", ".", "info", "(", "f'[{bnn.uid}] {\"Posterior\" if with_data else \"Prior\"} predictive plot saved as `history/{bnn.uid}_plot_{plot_savename}.png`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.generic_plot": [[193, 214], ["matplotlib.figure", "matplotlib.gca().set_ylim", "matplotlib.gca().set_xlim", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.tight_layout", "addons", "re.sub().lower().replace", "matplotlib.savefig", "logging.info", "tuple", "matplotlib.gca", "matplotlib.gca", "re.sub().lower", "re.sub"], "function", ["None"], ["", "def", "generic_plot", "(", "plot_title", ",", "xlims", ",", "ylims", ",", "xlabel", ",", "ylabel", ",", "addons", ",", "plot_fontsize", "=", "18", ",", "plot_figsize", "=", "(", "8", ",", "6", ")", ",", "plot_dpi", "=", "400", ")", ":", "\n", "\t", "\"\"\" Wrapper function for plot formatting. \"\"\"", "\n", "\n", "# Configurations.", "\n", "rcParams", "[", "'font.family'", "]", "=", "'serif'", "\n", "rcParams", "[", "'font.serif'", "]", "=", "[", "'Charter'", "]", "\n", "pp_fig", "=", "plt", ".", "figure", "(", "figsize", "=", "tuple", "(", "plot_figsize", ")", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_ylim", "(", "ylims", "[", "0", "]", ",", "ylims", "[", "-", "1", "]", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_xlim", "(", "xlims", "[", "0", "]", ",", "xlims", "[", "-", "1", "]", ")", "\n", "plt", ".", "xticks", "(", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "yticks", "(", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "title", "(", "plot_title", ",", "fontsize", "=", "plot_fontsize", "+", "4", ")", "\n", "plt", ".", "xlabel", "(", "xlabel", ",", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "ylabel", "(", "ylabel", ",", "fontsize", "=", "plot_fontsize", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "addons", "(", ")", "\n", "\n", "plot_savename", "=", "re", ".", "sub", "(", "r'[^\\w\\s]'", ",", "''", ",", "plot_title", ")", ".", "lower", "(", ")", ".", "replace", "(", "' '", ",", "'_'", ")", "\n", "plt", ".", "savefig", "(", "f'history/plot_{plot_savename}.png'", ",", "dpi", "=", "plot_dpi", ")", "\n", "logging", ".", "info", "(", "f'Plot saved as `history/plot_{plot_savename}.png`.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.utils.eval_accuracy_and_f1_score": [[217, 233], ["sklearn.metrics.accuracy_score", "sklearn.metrics.precision_recall_fscore_support", "bnn.predict().mean().argmax", "bnn.predict().mean", "bnn.predict().mean", "bnn.predict", "bnn.predict"], "function", ["home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.predict", "home.repos.pwc.inspect_result.dtak_ocbnn-public.bnn.base.BinaryClassifierMixin.predict"], ["", "def", "eval_accuracy_and_f1_score", "(", "bnn", ",", "is_binary", "=", "False", ",", "X_eval", "=", "None", ",", "Y_eval", "=", "None", ")", ":", "\n", "\t", "\"\"\" Evaluate accuracy and F1 score on the test set.\n\t\tBinary classification only, i.e. assume `bnn.predict()` returns a Boolean tensor. \n\t\tUses the most recent posterior sample: `bnn.all_bayes_samples[-1]`. \n\t\"\"\"", "\n", "if", "X_eval", "is", "None", ":", "\n", "\t\t", "X_eval", ",", "Y_eval", "=", "bnn", ".", "X_test", ",", "bnn", ".", "Y_test", "\n", "\n", "", "samples", ",", "_", "=", "bnn", ".", "all_bayes_samples", "[", "-", "1", "]", "\n", "if", "is_binary", ":", "\n", "\t\t", "preds", "=", "bnn", ".", "predict", "(", "samples", ",", "X_eval", ",", "return_probs", "=", "True", ")", ".", "mean", "(", "dim", "=", "0", ")", ">=", "0.5", "\n", "", "else", ":", "\n", "\t\t", "preds", "=", "bnn", ".", "predict", "(", "samples", ",", "X_eval", ",", "return_probs", "=", "True", ")", ".", "mean", "(", "dim", "=", "0", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "", "acc", "=", "accuracy_score", "(", "Y_eval", ",", "preds", ")", "\n", "_", ",", "_", ",", "f1", ",", "_", "=", "precision_recall_fscore_support", "(", "Y_eval", ",", "preds", ",", "average", "=", "'binary'", ")", "\n", "return", "acc", ",", "f1", "\n", "", ""]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy1": [[27, 38], ["torch.tensor().unsqueeze", "dataloader.toy1.f"], "function", ["None"], ["def", "toy1", "(", ")", ":", "\n", "\t", "\"\"\" 1D regression. \"\"\"", "\n", "def", "f", "(", "x", ")", ":", "\n", "\t\t", "return", "(", "-", "1", "*", "(", "x", "**", "4", ")", ")", "+", "(", "3", "*", "(", "x", "**", "2", ")", ")", "+", "1", "\n", "\n", "", "X_train", "=", "torch", ".", "tensor", "(", "[", "-", "2", ",", "-", "1.8", ",", "-", "1", ",", "1", ",", "1.8", ",", "2", "]", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "Y_train", "=", "f", "(", "X_train", ")", "\n", "\n", "X_train_min", "=", "[", "-", "3.0", "]", "\n", "X_train_max", "=", "[", "3.0", "]", "\n", "return", "{", "\"dataset_name\"", ":", "\"toy1\"", ",", "\"X_train\"", ":", "X_train", ",", "\"Y_train\"", ":", "Y_train", ",", "\"X_train_min\"", ":", "X_train_min", ",", "\"X_train_max\"", ":", "X_train_max", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy2": [[40, 72], ["torch.tensor", "torch.tensor().repeat", "torch.tensor", "range"], "function", ["None"], ["", "def", "toy2", "(", ")", ":", "\n", "\t", "\"\"\" 2D classification. 3 classes, with 8 data points for each class. Data was generated by a mixture of Gaussians. \"\"\"", "\n", "\n", "X_train", "=", "torch", ".", "tensor", "(", "[", "[", "-", "0.5568", ",", "-", "2.8603", "]", ",", "\n", "[", "-", "2.8323", ",", "0.9413", "]", ",", "\n", "[", "2.0402", ",", "2.6044", "]", ",", "\n", "[", "-", "0.3121", ",", "-", "3.2628", "]", ",", "\n", "[", "-", "3.2933", ",", "0.8421", "]", ",", "\n", "[", "2.2045", ",", "2.6692", "]", ",", "\n", "[", "-", "0.0165", ",", "-", "3.1644", "]", ",", "\n", "[", "-", "2.9325", ",", "0.8448", "]", ",", "\n", "[", "2.3423", ",", "2.8354", "]", ",", "\n", "[", "-", "0.2595", ",", "-", "2.9736", "]", ",", "\n", "[", "-", "2.9650", ",", "0.7760", "]", ",", "\n", "[", "2.2982", ",", "2.6264", "]", ",", "\n", "[", "-", "0.0605", ",", "-", "2.8752", "]", ",", "\n", "[", "-", "2.4977", ",", "1.2420", "]", ",", "\n", "[", "1.8175", ",", "3.1518", "]", ",", "\n", "[", "-", "0.2743", ",", "-", "3.0461", "]", ",", "\n", "[", "-", "2.7137", ",", "1.7121", "]", ",", "\n", "[", "1.9846", ",", "3.5413", "]", ",", "\n", "[", "0.3204", ",", "-", "2.8159", "]", ",", "\n", "[", "-", "2.6090", ",", "1.1718", "]", ",", "\n", "[", "2.0794", ",", "3.1475", "]", ",", "\n", "[", "0.1280", ",", "-", "2.9005", "]", ",", "\n", "[", "-", "2.9434", ",", "1.1424", "]", ",", "\n", "[", "1.9929", ",", "2.9455", "]", "]", ")", "\n", "Y_train", "=", "torch", ".", "tensor", "(", "range", "(", "3", ")", ")", ".", "repeat", "(", "8", ")", "\n", "\n", "X_train_min", "=", "[", "-", "3.0", ",", "-", "3.0", "]", "\n", "X_train_max", "=", "[", "3.0", ",", "3.0", "]", "\n", "return", "{", "\"dataset_name\"", ":", "\"toy2\"", ",", "\"X_train\"", ":", "X_train", ",", "\"Y_train\"", ":", "Y_train", ",", "\"X_train_min\"", ":", "X_train_min", ",", "\"X_train_max\"", ":", "X_train_max", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy3": [[74, 82], ["torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "toy3", "(", ")", ":", "\n", "\t", "\"\"\" 1D regression. \"\"\"", "\n", "X_train", "=", "torch", ".", "tensor", "(", "[", "-", "7", ",", "-", "5", ",", "2", ",", "2.5", "]", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "Y_train", "=", "torch", ".", "tensor", "(", "[", "-", "0.5", ",", "-", "1.0", ",", "1.0", ",", "0.7", "]", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "\n", "X_train_min", "=", "[", "-", "7.5", "]", "\n", "X_train_max", "=", "[", "3.0", "]", "\n", "return", "{", "\"dataset_name\"", ":", "\"toy3\"", ",", "\"X_train\"", ":", "X_train", ",", "\"Y_train\"", ":", "Y_train", ",", "\"X_train_min\"", ":", "X_train_min", ",", "\"X_train_max\"", ":", "X_train_max", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy4": [[84, 92], ["torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "toy4", "(", ")", ":", "\n", "\t", "\"\"\" 1D regression. \"\"\"", "\n", "X_train", "=", "torch", ".", "tensor", "(", "[", "-", "3.5", ",", "-", "2", ",", "2", ",", "3.5", "]", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "Y_train", "=", "torch", ".", "tensor", "(", "[", "-", "1", ",", "0.25", ",", "3.5", ",", "4.5", "]", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "\n", "X_train_min", "=", "[", "-", "4.0", "]", "\n", "X_train_max", "=", "[", "4.0", "]", "\n", "return", "{", "\"dataset_name\"", ":", "\"toy4\"", ",", "\"X_train\"", ":", "X_train", ",", "\"Y_train\"", ":", "Y_train", ",", "\"X_train_min\"", ":", "X_train_min", ",", "\"X_train_max\"", ":", "X_train_max", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy5": [[94, 102], ["torch.stack().t", "torch.tensor", "torch.stack", "torch.arange().repeat_interleave", "torch.arange().repeat", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "toy5", "(", ")", ":", "\n", "\t", "\"\"\" 2D binary classification. X_1 is a binary feature, and X_2 is continuous in [0, 1]. \"\"\"", "\n", "X_train", "=", "torch", ".", "stack", "(", "(", "torch", ".", "arange", "(", "2.0", ")", ".", "repeat_interleave", "(", "10", ")", ",", "torch", ".", "arange", "(", "0.1", ",", "1.1", ",", "0.1", ")", ".", "repeat", "(", "2", ")", ")", ")", ".", "t", "(", ")", "\n", "Y_train", "=", "torch", ".", "tensor", "(", "[", "0", "]", "*", "2", "+", "[", "1", "]", "*", "8", "+", "[", "0", "]", "*", "8", "+", "[", "1", "]", "*", "2", ")", "\n", "\n", "X_train_min", "=", "[", "0.0", ",", "0.0", "]", "\n", "X_train_max", "=", "[", "1.0", ",", "1.0", "]", "\n", "return", "{", "\"dataset_name\"", ":", "\"toy5\"", ",", "\"X_train\"", ":", "X_train", ",", "\"Y_train\"", ":", "Y_train", ",", "\"X_train_min\"", ":", "X_train_min", ",", "\"X_train_max\"", ":", "X_train_max", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.toy6": [[104, 116], ["torch.tensor().unsqueeze", "dataloader.toy1.f"], "function", ["None"], ["", "def", "toy6", "(", ")", ":", "\n", "\t", "\"\"\" 1D regression. Outputs are intentionally noisy. \"\"\"", "\n", "\n", "def", "f", "(", "x", ")", ":", "\n", "\t\t", "return", "5", "*", "np", ".", "cos", "(", "x", "/", "1.7", ")", "\n", "\n", "", "X_train", "=", "torch", ".", "tensor", "(", "[", "-", "2.7", ",", "-", "2.3", ",", "-", "2", ",", "2", ",", "2.3", ",", "2.7", "]", ")", ".", "unsqueeze", "(", "1", ")", "\n", "Y_train", "=", "f", "(", "X_train", ")", "+", "torch", ".", "tensor", "(", "[", "0.4", ",", "0.2", ",", "0.7", ",", "-", "2.5", ",", "0.6", ",", "2.1", "]", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "X_train_min", "=", "[", "-", "3.0", "]", "\n", "X_train_max", "=", "[", "3.0", "]", "\n", "return", "{", "\"dataset_name\"", ":", "\"toy6\"", ",", "\"X_train\"", ":", "X_train", ",", "\"Y_train\"", ":", "Y_train", ",", "\"X_train_min\"", ":", "X_train_min", ",", "\"X_train_max\"", ":", "X_train_max", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.compas_dataset": [[118, 153], ["pandas.read_csv", "numpy.loadtxt", "torch.tensor().float", "torch.tensor().long", "range", "range", "X_train_mean.append", "X_train_std.append", "X_train_min.append", "X_train_max.append", "torch.tensor", "torch.tensor", "X_train[].mean().item", "X_train[].std().item", "X_train[].min().item", "X_train[].max().item", "X_train[].mean", "X_train[].std", "X_train[].min", "X_train[].max"], "function", ["None"], ["", "def", "compas_dataset", "(", "csv_xfilename", ",", "csv_yfilename", ",", "with_race", "=", "True", ")", ":", "\n", "\t", "\"\"\" COMPAS dataset from 2016 ProPublica study:\n\t\t\tJeff Larson, Surya Mattu, Lauren Kirchner, and Julia Angwin. How We Analyzed the COMPAS\n\t\t\tRecidivism Algorithm. ProPublica, 2016.\n\t\t9D binary classification (8D without race as an explicit feature).\n\t\"\"\"", "\n", "X", "=", "pd", ".", "read_csv", "(", "csv_xfilename", ")", "\n", "Y", "=", "np", ".", "loadtxt", "(", "csv_yfilename", ")", "\n", "X", "=", "X", ".", "values", "\n", "\n", "X_train", "=", "torch", ".", "tensor", "(", "X", "[", ":", ",", "1", ":", "]", ")", ".", "float", "(", ")", "\n", "Y_train", "=", "torch", ".", "tensor", "(", "Y", ")", ".", "long", "(", ")", "\n", "X_train_race", "=", "X_train", "[", ":", ",", "-", "1", "]", "\n", "if", "not", "with_race", ":", "\n", "\t\t", "X_train", "=", "X_train", "[", ":", ",", ":", "-", "1", "]", "\n", "\n", "# Means and standard deviation for each feature.", "\n", "", "X_train_mean", ",", "X_train_std", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "X_train", ".", "shape", "[", "1", "]", ")", ":", "\n", "\t\t", "X_train_mean", ".", "append", "(", "X_train", "[", ":", ",", "i", "]", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "X_train_std", ".", "append", "(", "X_train", "[", ":", ",", "i", "]", ".", "std", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "# Standardization.", "\n", "", "for", "j", "in", "[", "0", ",", "2", ",", "3", "]", ":", "\n", "\t\t", "X_train", "[", ":", ",", "j", "]", "=", "(", "X_train", "[", ":", ",", "j", "]", "-", "X_train_mean", "[", "j", "]", ")", "/", "X_train_std", "[", "j", "]", "\n", "\n", "# Min/max.", "\n", "", "X_train_min", ",", "X_train_max", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "X_train", ".", "shape", "[", "1", "]", ")", ":", "\n", "\t\t", "X_train_min", ".", "append", "(", "X_train", "[", ":", ",", "i", "]", ".", "min", "(", ")", ".", "item", "(", ")", ")", "\n", "X_train_max", ".", "append", "(", "X_train", "[", ":", ",", "i", "]", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "", "return", "{", "\"dataset_name\"", ":", "\"compas\"", ",", "\"X_train\"", ":", "X_train", ",", "\"Y_train\"", ":", "Y_train", ",", "\n", "\"X_train_min\"", ":", "X_train_min", ",", "\"X_train_max\"", ":", "X_train_max", ",", "\"X_train_mean\"", ":", "X_train_mean", ",", "\n", "\"X_train_std\"", ":", "X_train_std", ",", "\"X_train_race\"", ":", "X_train_race", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dtak_ocbnn-public.data.dataloader.credit_dataset": [[155, 214], ["pandas.read_csv", "pd.read_csv.dropna", "sklearn.model_selection.train_test_split", "range", "sklearn.utils.resample", "numpy.concatenate", "numpy.random.shuffle", "torch.tensor().float", "torch.tensor().float", "torch.tensor().long", "torch.tensor().long", "torch.tensor().float.clone", "torch.tensor().long.clone", "range", "X_train_mean.append", "X_train_std.append", "X_train_min.append", "X_train_max.append", "data_train[].mean", "data_train[].std", "round", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "X_trainbl[].min().item", "X_trainbl[].max().item", "numpy.quantile", "numpy.quantile", "len", "X_trainbl[].min", "X_trainbl[].max"], "function", ["None"], ["", "def", "credit_dataset", "(", "csv_filename", ")", ":", "\n", "\t", "\"\"\" Give Me Some Credit dataset, taken from: http://www.kaggle.com/c/GiveMeSomeCredit/.\n\t\t10D binary classification.\n\t\"\"\"", "\n", "data", "=", "pd", ".", "read_csv", "(", "csv_filename", ")", "\n", "data", ".", "dropna", "(", "inplace", "=", "True", ")", "\n", "data", "=", "data", ".", "values", "[", ":", ",", "1", ":", "]", "\n", "\n", "# Filterig outliers.", "\n", "for", "i", "in", "[", "3", ",", "4", ",", "5", "]", ":", "\n", "\t\t", "data", "=", "data", "[", "(", "data", "[", ":", ",", "i", "]", "<=", "np", ".", "quantile", "(", "data", "[", ":", ",", "i", "]", ",", "0.95", ")", ")", "]", "\n", "", "for", "i", "in", "[", "1", ",", "7", ",", "8", ",", "9", ",", "10", "]", ":", "\n", "\t\t", "data", "=", "data", "[", "(", "data", "[", ":", ",", "i", "]", "<=", "np", ".", "quantile", "(", "data", "[", ":", ",", "i", "]", ",", "0.998", ")", ")", "]", "\n", "\n", "", "data_train", ",", "data_test", "=", "train_test_split", "(", "data", ",", "test_size", "=", "0.1", ",", "random_state", "=", "13", ")", "\n", "X_test", "=", "data_test", "[", ":", ",", "1", ":", "]", "\n", "Y_test", "=", "data_test", "[", ":", ",", "0", "]", "\n", "\n", "# Means and standard deviation for each feature.", "\n", "X_train_mean", ",", "X_train_std", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "11", ")", ":", "\n", "\t\t", "X_train_mean", ".", "append", "(", "data_train", "[", ":", ",", "i", "]", ".", "mean", "(", ")", ")", "\n", "X_train_std", ".", "append", "(", "data_train", "[", ":", ",", "i", "]", ".", "std", "(", ")", ")", "\n", "\n", "# Standardization.", "\n", "", "for", "j", "in", "[", "1", ",", "4", ",", "5", "]", ":", "\n", "\t\t", "X_test", "[", ":", ",", "j", "]", "=", "(", "X_test", "[", ":", ",", "j", "]", "-", "X_train_mean", "[", "j", "]", ")", "/", "X_train_std", "[", "j", "]", "\n", "data_train", "[", ":", ",", "j", "+", "1", "]", "=", "(", "data_train", "[", ":", ",", "j", "+", "1", "]", "-", "X_train_mean", "[", "j", "]", ")", "/", "X_train_std", "[", "j", "]", "\n", "\n", "# Upsampling minority class (Y = 1).", "\n", "", "majority", "=", "data_train", "[", "data_train", "[", ":", ",", "0", "]", "==", "0", "]", "\n", "minority", "=", "data_train", "[", "data_train", "[", ":", ",", "0", "]", "==", "1", "]", "\n", "minority_upsampled", "=", "resample", "(", "minority", ",", "replace", "=", "True", ",", "n_samples", "=", "round", "(", "len", "(", "majority", ")", "*", "0.5", ")", ",", "random_state", "=", "13", ")", "\n", "data_train", "=", "np", ".", "concatenate", "(", "(", "majority", ",", "minority_upsampled", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "data_train", ")", "\n", "X_train", "=", "data_train", "[", ":", ",", "1", ":", "]", "\n", "Y_train", "=", "data_train", "[", ":", ",", "0", "]", "\n", "\n", "# Conversion to tensors.", "\n", "X_train", "=", "torch", ".", "tensor", "(", "X_train", ")", ".", "float", "(", ")", "\n", "X_test", "=", "torch", ".", "tensor", "(", "X_test", ")", ".", "float", "(", ")", "\n", "Y_train", "=", "torch", ".", "tensor", "(", "Y_train", ")", ".", "long", "(", ")", "\n", "Y_test", "=", "torch", ".", "tensor", "(", "Y_test", ")", ".", "long", "(", ")", "\n", "\n", "# \"Blind dataset\" lacking individuals with age < 35", "\n", "X_trainbl", "=", "X_train", ".", "clone", "(", ")", "\n", "Y_trainbl", "=", "Y_train", ".", "clone", "(", ")", "\n", "Y_trainbl", "=", "Y_trainbl", "[", "(", "X_trainbl", "[", ":", ",", "1", "]", "*", "X_train_std", "[", "1", "]", "+", "X_train_mean", "[", "1", "]", ">=", "35", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "]", "\n", "X_trainbl", "=", "X_trainbl", "[", "(", "X_trainbl", "[", ":", ",", "1", "]", "*", "X_train_std", "[", "1", "]", "+", "X_train_mean", "[", "1", "]", ">=", "35", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", "dim", "=", "1", ")", "]", "\n", "\n", "# Min/max.", "\n", "X_train_min", ",", "X_train_max", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "\t\t", "X_train_min", ".", "append", "(", "X_trainbl", "[", ":", ",", "i", "]", ".", "min", "(", ")", ".", "item", "(", ")", ")", "\n", "X_train_max", ".", "append", "(", "X_trainbl", "[", ":", ",", "i", "]", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "", "return", "{", "\"dataset_name\"", ":", "\"give_me_some_credit\"", ",", "\"X_train\"", ":", "X_train", ",", "\"Y_train\"", ":", "Y_train", ",", "\n", "\"X_train_min\"", ":", "X_train_min", ",", "\"X_train_max\"", ":", "X_train_max", ",", "\"X_test\"", ":", "X_test", ",", "\"Y_test\"", ":", "Y_test", ",", "\n", "\"X_train_mean\"", ":", "X_train_mean", ",", "\"X_train_std\"", ":", "X_train_std", ",", "\"X_train_blind\"", ":", "X_trainbl", ",", "\"Y_train_blind\"", ":", "Y_trainbl", "}", "\n", "", ""]]}