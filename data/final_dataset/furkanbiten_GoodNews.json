{"home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloaderraw.DataLoaderRaw.__init__": [[20, 67], ["opt.get", "opt.get", "opt.get", "print", "print", "len", "print", "len", "len", "print", "json.load", "enumerate", "print", "os.walk", "open", "os.path.join", "dataloaderraw.DataLoaderRaw.files.append", "dataloaderraw.DataLoaderRaw.ids.append", "f.rfind", "os.path.join", "dataloaderraw.DataLoaderRaw.__init__.isImage"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "coco_json", "=", "opt", ".", "get", "(", "'coco_json'", ",", "''", ")", "\n", "self", ".", "folder_path", "=", "opt", ".", "get", "(", "'folder_path'", ",", "''", ")", "\n", "\n", "self", ".", "batch_size", "=", "opt", ".", "get", "(", "'batch_size'", ",", "1", ")", "\n", "self", ".", "seq_per_img", "=", "1", "\n", "\n", "# load the json file which contains additional information about the dataset", "\n", "print", "(", "'DataLoaderRaw loading images from folder: '", ",", "self", ".", "folder_path", ")", "\n", "\n", "self", ".", "files", "=", "[", "]", "\n", "self", ".", "ids", "=", "[", "]", "\n", "\n", "print", "(", "len", "(", "self", ".", "coco_json", ")", ")", "\n", "if", "len", "(", "self", ".", "coco_json", ")", ">", "0", ":", "\n", "            ", "print", "(", "'reading from '", "+", "opt", ".", "coco_json", ")", "\n", "# read in filenames from the coco-style json file", "\n", "self", ".", "coco_annotation", "=", "json", ".", "load", "(", "open", "(", "self", ".", "coco_json", ")", ")", "\n", "for", "k", ",", "v", "in", "enumerate", "(", "self", ".", "coco_annotation", "[", "'images'", "]", ")", ":", "\n", "                ", "fullpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "folder_path", ",", "v", "[", "'file_name'", "]", ")", "\n", "self", ".", "files", ".", "append", "(", "fullpath", ")", "\n", "self", ".", "ids", ".", "append", "(", "v", "[", "'id'", "]", ")", "\n", "", "", "else", ":", "\n", "# read in all the filenames from the folder", "\n", "            ", "print", "(", "'listing all images in directory '", "+", "self", ".", "folder_path", ")", "\n", "def", "isImage", "(", "f", ")", ":", "\n", "                ", "supportedExt", "=", "[", "'.jpg'", ",", "'.JPG'", ",", "'.jpeg'", ",", "'.JPEG'", ",", "'.png'", ",", "'.PNG'", ",", "'.ppm'", ",", "'.PPM'", "]", "\n", "for", "ext", "in", "supportedExt", ":", "\n", "                    ", "start_idx", "=", "f", ".", "rfind", "(", "ext", ")", "\n", "if", "start_idx", ">=", "0", "and", "start_idx", "+", "len", "(", "ext", ")", "==", "len", "(", "f", ")", ":", "\n", "                        ", "return", "True", "\n", "", "", "return", "False", "\n", "\n", "", "n", "=", "1", "\n", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "self", ".", "folder_path", ",", "topdown", "=", "False", ")", ":", "\n", "                ", "for", "file", "in", "files", ":", "\n", "                    ", "fullpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "folder_path", ",", "file", ")", "\n", "if", "isImage", "(", "fullpath", ")", ":", "\n", "                        ", "self", ".", "files", ".", "append", "(", "fullpath", ")", "\n", "self", ".", "ids", ".", "append", "(", "str", "(", "n", ")", ")", "# just order them sequentially", "\n", "n", "=", "n", "+", "1", "\n", "\n", "", "", "", "", "self", ".", "N", "=", "len", "(", "self", ".", "files", ")", "\n", "print", "(", "'DataLoaderRaw found '", ",", "self", ".", "N", ",", "' images'", ")", "\n", "\n", "self", ".", "iterator", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloaderraw.DataLoaderRaw.get_batch": [[68, 106], ["numpy.ndarray", "range", "scipy.misc.imread", "scipy.misc.imresize", "preprocess().numpy", "infos.append", "len", "numpy.concatenate", "preprocess", "torch.from_numpy", "numpy.concatenate.transpose().astype", "numpy.concatenate.transpose"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ",", "split", ",", "batch_size", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "batch_size", "or", "self", ".", "batch_size", "\n", "\n", "# pick an index of the datapoint to load next", "\n", "img_batch", "=", "np", ".", "ndarray", "(", "[", "batch_size", ",", "3", ",", "256", ",", "256", "]", ",", "dtype", "=", "'float32'", ")", "\n", "max_index", "=", "self", ".", "N", "\n", "wrapped", "=", "False", "\n", "infos", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "ri", "=", "self", ".", "iterator", "\n", "ri_next", "=", "ri", "+", "1", "\n", "if", "ri_next", ">=", "max_index", ":", "\n", "                ", "ri_next", "=", "0", "\n", "wrapped", "=", "True", "\n", "# wrap back around", "\n", "", "self", ".", "iterator", "=", "ri_next", "\n", "\n", "img", "=", "imread", "(", "self", ".", "files", "[", "ri", "]", ")", "\n", "img", "=", "imresize", "(", "img", ",", "(", "256", ",", "256", ")", ")", "\n", "\n", "if", "len", "(", "img", ".", "shape", ")", "==", "2", ":", "\n", "                ", "img", "=", "img", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", "\n", "img", "=", "np", ".", "concatenate", "(", "(", "img", ",", "img", ",", "img", ")", ",", "axis", "=", "2", ")", "\n", "\n", "", "img_batch", "[", "i", "]", "=", "preprocess", "(", "torch", ".", "from_numpy", "(", "img", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", ".", "astype", "(", "'float32'", ")", "/", "255.0", ")", ")", ".", "numpy", "(", ")", "\n", "\n", "info_struct", "=", "{", "}", "\n", "info_struct", "[", "'id'", "]", "=", "self", ".", "ids", "[", "ri", "]", "\n", "info_struct", "[", "'file_path'", "]", "=", "self", ".", "files", "[", "ri", "]", "\n", "infos", ".", "append", "(", "info_struct", ")", "\n", "\n", "", "data", "=", "{", "}", "\n", "data", "[", "'images'", "]", "=", "img_batch", "\n", "data", "[", "'bounds'", "]", "=", "{", "'it_pos_now'", ":", "self", ".", "iterator", ",", "'it_max'", ":", "self", ".", "N", ",", "'wrapped'", ":", "wrapped", "}", "\n", "data", "[", "'infos'", "]", "=", "infos", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloaderraw.DataLoaderRaw.reset_iterator": [[107, 109], ["None"], "methods", ["None"], ["", "def", "reset_iterator", "(", "self", ",", "split", ")", ":", "\n", "        ", "self", ".", "iterator", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloaderraw.DataLoaderRaw.get_vocab_size": [[110, 112], ["len"], "methods", ["None"], ["", "def", "get_vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ix_to_word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloaderraw.DataLoaderRaw.get_vocab": [[113, 115], ["None"], "methods", ["None"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "ix_to_word", "\n", "", "", ""]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.opts.parse_opt": [[5, 148], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "parse_opt", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# Data input settings", "\n", "parser", ".", "add_argument", "(", "'--input_json'", ",", "type", "=", "str", ",", "default", "=", "'data/data_news.json'", ",", "#data/cocotalk.json, data/data_europeana.json", "\n", "help", "=", "'path to the json file containing additional info and vocab'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_label_h5'", ",", "type", "=", "str", ",", "default", "=", "'./data/data_news_label.h5'", ",", "# data_europeana_label.h5", "\n", "help", "=", "'path to the h5file containing the preprocessed label'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_image_h5'", ",", "type", "=", "str", ",", "default", "=", "'/home/abiten/Desktop/Thesis/ImageCaptioning.pytorch-with_finetune/data/data_news_image.h5'", ",", "# data_europeana_image.h5", "\n", "help", "=", "'path to the h5file containing the preprocessed image'", ")", "\n", "parser", ".", "add_argument", "(", "'--cnn_model'", ",", "type", "=", "str", ",", "default", "=", "'resnet152'", ",", "\n", "help", "=", "'resnet'", ")", "\n", "parser", ".", "add_argument", "(", "'--cnn_weight'", ",", "type", "=", "str", ",", "default", "=", "'/home/abiten/.torch/models/resnet152-b121ed2d.pth'", ",", "\n", "help", "=", "'path to CNN tf model. Note this MUST be a resnet right now.'", ")", "\n", "parser", ".", "add_argument", "(", "'--start_from'", ",", "type", "=", "str", ",", "default", "=", "None", ",", "#'./save/news_compact_lda/show_attend_tell'", "\n", "help", "=", "\"\"\"continue training from saved model at this path. Path must contain files saved by previous training process: \n                        'infos.pkl'         : configuration;\n                        'checkpoint'        : paths to model file(s) (created by tf).\n                                              Note: this file contains absolute paths, be careful when moving files around;\n                        'model.ckpt-*'      : file(s) with model definition (created by tf)\n                    \"\"\"", ")", "\n", "\n", "# Model settings", "\n", "parser", ".", "add_argument", "(", "'--caption_model'", ",", "type", "=", "str", ",", "default", "=", "\"show_attend_tell\"", ",", "\n", "help", "=", "'show_tell, show_attend_tell, all_img, fc, att2in, att2in2, adaatt, adaattmo, topdown'", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_size'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "\n", "help", "=", "'size of the rnn in number of hidden nodes in each layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_layers'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'number of layers in the RNN'", ")", "\n", "parser", ".", "add_argument", "(", "'--rnn_type'", ",", "type", "=", "str", ",", "default", "=", "'lstm'", ",", "\n", "help", "=", "'rnn, gru, or lstm'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_encoding_size'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "\n", "help", "=", "'the encoding size of each token in the vocabulary, and the image.'", ")", "\n", "parser", ".", "add_argument", "(", "'--att_hid_size'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "\n", "help", "=", "'the hidden size of the attention MLP; only useful in show_attend_tell; 0 if not using hidden layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--fc_feat_size'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "\n", "help", "=", "'2048 for resnet, 4096 for vgg'", ")", "\n", "parser", ".", "add_argument", "(", "'--att_feat_size'", ",", "type", "=", "int", ",", "default", "=", "2048", ",", "\n", "help", "=", "'2048 for resnet, 512 for vgg'", ")", "\n", "parser", ".", "add_argument", "(", "'--sentence_embed'", ",", "type", "=", "str", ",", "default", "=", "'./data/articles_full_avg.h5'", ",", "#/media/abiten/SSD-DATA/breakingnews", "\n", "help", "=", "'it can be either LDA or SkipThought'", ")", "\n", "parser", ".", "add_argument", "(", "'--sentence_embed_att'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "\n", "help", "=", "'Use attention or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--sentence_embed_method'", ",", "type", "=", "str", ",", "default", "=", "'fc'", ",", "\n", "help", "=", "'choose which method to use, available options are fc_max, conv, conv_deep, fc, bnews'", ")", "\n", "parser", ".", "add_argument", "(", "'--sentence_length'", ",", "type", "=", "int", ",", "default", "=", "54", ",", "\n", "help", "=", "'hyperparameter to pad the values, this is used for both the sentence and word level'", ")", "\n", "parser", ".", "add_argument", "(", "'--sentence_embed_size'", ",", "type", "=", "int", ",", "default", "=", "300", ",", "\n", "help", "=", "'size for sentence embedding'", ")", "\n", "\n", "# Optimization: General", "\n", "parser", ".", "add_argument", "(", "'--max_epochs'", ",", "type", "=", "int", ",", "default", "=", "150", ",", "\n", "help", "=", "'number of epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "32", ",", "\n", "help", "=", "'minibatch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--grad_clip'", ",", "type", "=", "float", ",", "default", "=", "5.0", ",", "#5.,", "\n", "help", "=", "'clip gradients at this value'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_thread'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "\n", "help", "=", "'Number of threads to be used for retrieving the data'", ")", "\n", "parser", ".", "add_argument", "(", "'--drop_prob_lm'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "\n", "help", "=", "'strength of dropout in the Language Model RNN'", ")", "\n", "parser", ".", "add_argument", "(", "'--finetune_cnn_after'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'After what epoch do we start finetuning the CNN? (-1 = disable; never finetune, 0 = finetune from start)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seq_per_img'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'number of captions to sample for each image during training. Done for efficiency since CNN forward pass is expensive. E.g. coco has 5 sents/image'", ")", "\n", "parser", ".", "add_argument", "(", "'--beam_size'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'used when sample_max = 1, indicates number of beams in beam search. Usually 2 or 3 works well. More is not better. Set this to 1 for faster runtime but a bit worse performance.'", ")", "\n", "\n", "#Optimization: for the Language Model", "\n", "parser", ".", "add_argument", "(", "'--optim'", ",", "type", "=", "str", ",", "default", "=", "'adam'", ",", "\n", "help", "=", "'what update to use? rmsprop|sgd|sgdmom|adagrad|adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.002", ",", "\n", "help", "=", "'learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_start'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "\n", "help", "=", "'at what iteration to start decaying learning rate? (-1 = dont) (in epoch)'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_every'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "\n", "help", "=", "'every how many iterations thereafter to drop LR?(in epoch)'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate_decay_rate'", ",", "type", "=", "float", ",", "default", "=", "0.8", ",", "\n", "help", "=", "'every how many iterations thereafter to drop LR?(in epoch)'", ")", "\n", "parser", ".", "add_argument", "(", "'--optim_alpha'", ",", "type", "=", "float", ",", "default", "=", "0.8", ",", "\n", "help", "=", "'alpha for adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--optim_beta'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "'beta used for adam'", ")", "\n", "parser", ".", "add_argument", "(", "'--optim_epsilon'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ",", "\n", "help", "=", "'epsilon that goes into denominator for smoothing'", ")", "\n", "\n", "#Optimization: for the CNN", "\n", "parser", ".", "add_argument", "(", "'--cnn_optim'", ",", "type", "=", "str", ",", "default", "=", "'adam'", ",", "\n", "help", "=", "'optimization to use for CNN'", ")", "\n", "parser", ".", "add_argument", "(", "'--cnn_optim_alpha'", ",", "type", "=", "float", ",", "default", "=", "0.8", ",", "\n", "help", "=", "'alpha for momentum of CNN'", ")", "\n", "parser", ".", "add_argument", "(", "'--cnn_optim_beta'", ",", "type", "=", "float", ",", "default", "=", "0.999", ",", "\n", "help", "=", "'beta for momentum of CNN'", ")", "\n", "parser", ".", "add_argument", "(", "'--cnn_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "\n", "help", "=", "'learning rate for the CNN'", ")", "\n", "parser", ".", "add_argument", "(", "'--cnn_weight_decay'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "\n", "help", "=", "'L2 weight decay just for the CNN'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--scheduled_sampling_start'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "'at what iteration to start decay gt probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduled_sampling_increase_every'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'every how many iterations thereafter to gt probability'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduled_sampling_increase_prob'", ",", "type", "=", "float", ",", "default", "=", "0.05", ",", "\n", "help", "=", "'How much to update the prob'", ")", "\n", "parser", ".", "add_argument", "(", "'--scheduled_sampling_max_prob'", ",", "type", "=", "float", ",", "default", "=", "0.25", ",", "\n", "help", "=", "'Maximum scheduled sampling prob.'", ")", "\n", "\n", "# Evaluation/Checkpointing", "\n", "parser", ".", "add_argument", "(", "'--val_images_use'", ",", "type", "=", "int", ",", "default", "=", "5000", ",", "\n", "help", "=", "'how many images to use when periodically evaluating the validation loss? (-1 = all)'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_checkpoint_every'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "\n", "help", "=", "'how often to save a model checkpoint (in iterations)?'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint_path'", ",", "type", "=", "str", ",", "default", "=", "'save/'", ",", "\n", "help", "=", "'directory to store checkpointed models'", ")", "\n", "parser", ".", "add_argument", "(", "'--language_eval'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Evaluate language as well (1 = yes, 0 = no)? BLEU/CIDEr/METEOR/ROUGE_L? requires coco-caption code from Github.'", ")", "\n", "parser", ".", "add_argument", "(", "'--losses_log_every'", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "'How often do we snapshot losses, for inclusion in the progress dump? (0 = disable)'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_best_score'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Do we load previous best score when resuming training.'", ")", "\n", "\n", "# misc", "\n", "parser", ".", "add_argument", "(", "'--id'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'an id identifying this run/job. used in cross-val and appended when writing progress files'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_only'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "'if true then use 80k, else use 110k'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Check if args are valid", "\n", "assert", "args", ".", "rnn_size", ">", "0", ",", "\"rnn_size should be greater than 0\"", "\n", "assert", "args", ".", "num_layers", ">", "0", ",", "\"num_layers should be greater than 0\"", "\n", "assert", "args", ".", "input_encoding_size", ">", "0", ",", "\"input_encoding_size should be greater than 0\"", "\n", "assert", "args", ".", "batch_size", ">", "0", ",", "\"batch_size should be greater than 0\"", "\n", "assert", "args", ".", "drop_prob_lm", ">=", "0", "and", "args", ".", "drop_prob_lm", "<", "1", ",", "\"drop_prob_lm should be between 0 and 1\"", "\n", "assert", "args", ".", "seq_per_img", ">", "0", ",", "\"seq_per_img should be greater than 0\"", "\n", "assert", "args", ".", "beam_size", ">", "0", ",", "\"beam_size should be greater than 0\"", "\n", "assert", "args", ".", "save_checkpoint_every", ">", "0", ",", "\"save_checkpoint_every should be greater than 0\"", "\n", "assert", "args", ".", "losses_log_every", ">", "0", ",", "\"losses_log_every should be greater than 0\"", "\n", "assert", "args", ".", "language_eval", "==", "0", "or", "args", ".", "language_eval", "==", "1", ",", "\"language_eval should be 0 or 1\"", "\n", "assert", "args", ".", "load_best_score", "==", "0", "or", "args", ".", "load_best_score", "==", "1", ",", "\"language_eval should be 0 or 1\"", "\n", "assert", "args", ".", "train_only", "==", "0", "or", "args", ".", "train_only", "==", "1", ",", "\"language_eval should be 0 or 1\"", "\n", "\n", "return", "args", "", "", ""]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.train.add_summary_value": [[25, 28], ["tf.Summary", "writer.add_summary", "tf.Summary.Value"], "function", ["None"], ["", "def", "add_summary_value", "(", "writer", ",", "key", ",", "value", ",", "iteration", ")", ":", "\n", "    ", "summary", "=", "tf", ".", "Summary", "(", "value", "=", "[", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "key", ",", "simple_value", "=", "value", ")", "]", ")", "\n", "writer", ".", "add_summary", "(", "summary", ",", "iteration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.train.train": [[32, 278], ["np.random.seed", "warnings.filterwarnings", "misc.if_use_att", "dataloader.DataLoader", "np.random.seed", "cPickle.load.get", "cPickle.load.get", "cPickle.load.get", "cPickle.load.get", "cPickle.load.get", "cPickle.load.get", "cPickle.load.get", "misc.build_cnn", "utils.build_cnn.cuda", "models.setup", "models.setup.cuda", "models.setup.train", "misc.LanguageModelCriterion", "torch.Adam", "os.path.exists", "os.makedirs", "os.listdir", "tf.summary.FileWriter", "os.path.isfile", "cPickle.load.get", "models.setup.parameters", "torch.Adam", "vars().get", "os.path.isfile", "time.time", "dataloader.DataLoader.get_batch", "misc.prepro_images", "print", "time.time", "utils.build_cnn.permute", "torch.autograd.Variable.mean().mean", "torch.autograd.Variable.unsqueeze().expand().contiguous().view", "fc_feats.unsqueeze().expand().contiguous().view.unsqueeze().expand().contiguous().view", "models.setup.zero_grad", "optim.Adam.zero_grad", "crit.backward", "optim.Adam.step", "crit.item", "time.time", "print", "os.remove", "open", "six.moves.cPickle.load", "os.path.join", "os.path.join", "optim.Adam.load_state_dict", "os.path.isfile", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "optim.Adam.zero_grad", "torch.autograd.Variable", "models.setup.", "utils.LanguageModelCriterion.", "utils.LanguageModelCriterion.", "misc.clip_gradient", "optim.Adam.step", "eval_kwargs.update", "eval_utils.eval_split", "os.path.join", "open", "six.moves.cPickle.load", "vars", "torch.load", "torch.load", "torch.load", "os.path.join", "optim.Adam.load_state_dict", "misc.set_lr", "min", "utils.build_cnn.parameters", "utils.build_cnn.eval", "utils.build_cnn.parameters", "utils.build_cnn.train", "time.time", "utils.build_cnn.", "torch.autograd.Variable.mean", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.FloatTensor().cuda", "torch.autograd.Variable.unsqueeze().expand().contiguous", "fc_feats.unsqueeze().expand().contiguous().view.unsqueeze().expand().contiguous", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "models.setup.", "int", "train.add_summary_value", "train.add_summary_value", "train.add_summary_value", "tf_summary_writer.flush", "vars", "train.add_summary_value", "lang_stats.items", "tf_summary_writer.flush", "os.path.join", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "print", "os.path.join", "torch.save", "torch.save", "torch.save", "dataloader.DataLoader.get_vocab", "os.path.join", "module.parameters", "os.path.join", "torch.load", "torch.load", "torch.load", "utils.build_cnn._modules.values", "module.parameters", "torch.autograd.Variable", "int", "vars", "train.add_summary_value", "models.setup.state_dict", "utils.build_cnn.state_dict", "optim.Adam.state_dict", "os.path.join", "torch.save", "torch.save", "torch.save", "open", "six.moves.cPickle.dump", "open", "six.moves.cPickle.dump", "os.path.join", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "print", "vars", "vars", "utils.build_cnn._modules.values", "os.path.join", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.autograd.Variable.unsqueeze().expand", "torch.autograd.Variable.size", "fc_feats.unsqueeze().expand().contiguous().view.unsqueeze().expand", "fc_feats.unsqueeze().expand().contiguous().view.size", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "len", "optim.Adam.state_dict", "os.path.join", "os.path.join", "models.setup.state_dict", "utils.build_cnn.state_dict", "open", "six.moves.cPickle.dump", "torch.autograd.Variable.size", "fc_feats.unsqueeze().expand().contiguous().view.size", "np.array", "len", "vars", "os.path.join", "torch.autograd.Variable.unsqueeze", "fc_feats.unsqueeze().expand().contiguous().view.unsqueeze", "vars", "torch.autograd.Variable.size", "torch.autograd.Variable.size", "fc_feats.unsqueeze().expand().contiguous().view.size", "fc_feats.unsqueeze().expand().contiguous().view.size"], "function", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.if_use_att", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.build_cnn", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.__init__.setup", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.train.train", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.get_batch", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.prepro_images", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.clip_gradient", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.eval_utils.eval_split", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.set_lr", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.train.train", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.train.add_summary_value", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.train.add_summary_value", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.train.add_summary_value", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.train.add_summary_value", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.get_vocab", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.train.add_summary_value"], ["", "def", "train", "(", "opt", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "42", ")", "\n", "warnings", ".", "filterwarnings", "(", "'ignore'", ")", "\n", "\n", "opt", ".", "use_att", "=", "utils", ".", "if_use_att", "(", "opt", ".", "caption_model", ")", "\n", "loader", "=", "DataLoader", "(", "opt", ")", "\n", "opt", ".", "vocab_size", "=", "loader", ".", "vocab_size", "\n", "opt", ".", "seq_length", "=", "loader", ".", "seq_length", "\n", "# for debug purposes", "\n", "# a=get_batch_one(opt, [loader.split_ix, loader.shuffle, loader.iterators, loader.label_start_ix, loader.label_end_ix])", "\n", "# loader.get_batch('train')", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "opt", ".", "checkpoint_path", "+", "'tensorboard/'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "opt", ".", "checkpoint_path", "+", "'tensorboard/'", ")", "\n", "\n", "", "else", ":", "\n", "        ", "for", "path", "in", "os", ".", "listdir", "(", "opt", ".", "checkpoint_path", "+", "'tensorboard/'", ")", ":", "\n", "            ", "os", ".", "remove", "(", "opt", ".", "checkpoint_path", "+", "'tensorboard/'", "+", "path", ")", "\n", "", "", "tf_summary_writer", "=", "tf", "and", "tf", ".", "summary", ".", "FileWriter", "(", "opt", ".", "checkpoint_path", "+", "'tensorboard/'", ")", "\n", "np", ".", "random", ".", "seed", "(", "42", ")", "\n", "infos", "=", "{", "}", "\n", "histories", "=", "{", "}", "\n", "\n", "if", "opt", ".", "start_from", "is", "not", "None", ":", "\n", "# open old infos and check if models are compatible", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'infos_'", "+", "opt", ".", "id", "+", "'.pkl'", ")", ")", "as", "f", ":", "\n", "            ", "infos", "=", "cPickle", ".", "load", "(", "f", ")", "\n", "saved_model_opt", "=", "infos", "[", "'opt'", "]", "\n", "need_be_same", "=", "[", "\"caption_model\"", ",", "\"rnn_type\"", ",", "\"rnn_size\"", ",", "\"num_layers\"", "]", "\n", "for", "checkme", "in", "need_be_same", ":", "\n", "                ", "assert", "vars", "(", "saved_model_opt", ")", "[", "checkme", "]", "==", "vars", "(", "opt", ")", "[", "checkme", "]", ",", "\"Command line argument and saved model disagree on '%s' \"", "%", "checkme", "\n", "\n", "", "", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'histories_'", "+", "opt", ".", "id", "+", "'.pkl'", ")", ")", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'histories_'", "+", "opt", ".", "id", "+", "'.pkl'", ")", ")", "as", "f", ":", "\n", "                ", "histories", "=", "cPickle", ".", "load", "(", "f", ")", "\n", "\n", "", "", "", "iteration", "=", "infos", ".", "get", "(", "'iter'", ",", "0", ")", "\n", "# iteration = 26540", "\n", "epoch", "=", "infos", ".", "get", "(", "'epoch'", ",", "0", ")", "\n", "\n", "val_result_history", "=", "histories", ".", "get", "(", "'val_result_history'", ",", "{", "}", ")", "\n", "loss_history", "=", "histories", ".", "get", "(", "'loss_history'", ",", "{", "}", ")", "\n", "lr_history", "=", "histories", ".", "get", "(", "'lr_history'", ",", "{", "}", ")", "\n", "ss_prob_history", "=", "histories", ".", "get", "(", "'ss_prob_history'", ",", "{", "}", ")", "\n", "\n", "loader", ".", "iterators", "=", "infos", ".", "get", "(", "'iterators'", ",", "loader", ".", "iterators", ")", "\n", "if", "opt", ".", "load_best_score", "==", "1", ":", "\n", "        ", "best_val_score", "=", "infos", ".", "get", "(", "'best_val_score'", ",", "None", ")", "\n", "\n", "", "cnn_model", "=", "utils", ".", "build_cnn", "(", "opt", ")", "\n", "cnn_model", ".", "cuda", "(", ")", "\n", "model", "=", "models", ".", "setup", "(", "opt", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "\n", "update_lr_flag", "=", "True", "\n", "# Assure in training mode", "\n", "model", ".", "train", "(", ")", "\n", "\n", "crit", "=", "utils", ".", "LanguageModelCriterion", "(", ")", "\n", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "opt", ".", "learning_rate", ")", "\n", "if", "opt", ".", "finetune_cnn_after", "!=", "-", "1", ":", "\n", "# only finetune the layer2 to layer4", "\n", "        ", "cnn_optimizer", "=", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "module", ".", "parameters", "(", ")", "}", "for", "module", "in", "cnn_model", ".", "_modules", ".", "values", "(", ")", "[", "5", ":", "]", "]", ",", "lr", "=", "opt", ".", "cnn_learning_rate", ",", "weight_decay", "=", "opt", ".", "cnn_weight_decay", ")", "\n", "\n", "# Load the optimizer", "\n", "", "if", "vars", "(", "opt", ")", ".", "get", "(", "'start_from'", ",", "None", ")", "is", "not", "None", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'optimizer.pth'", ")", ")", ":", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'optimizer.pth'", ")", ")", ")", "\n", "", "if", "opt", ".", "finetune_cnn_after", "!=", "-", "1", "and", "epoch", ">=", "opt", ".", "finetune_cnn_after", ":", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'optimizer-cnn.pth'", ")", ")", ":", "\n", "                ", "cnn_optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'optimizer-cnn.pth'", ")", ")", ")", "\n", "", "", "", "while", "True", ":", "\n", "        ", "if", "update_lr_flag", ":", "\n", "# Assign the learning rate", "\n", "            ", "if", "epoch", ">", "opt", ".", "learning_rate_decay_start", "and", "opt", ".", "learning_rate_decay_start", ">=", "0", ":", "\n", "                ", "frac", "=", "(", "epoch", "-", "opt", ".", "learning_rate_decay_start", ")", "//", "opt", ".", "learning_rate_decay_every", "\n", "decay_factor", "=", "opt", ".", "learning_rate_decay_rate", "**", "frac", "\n", "opt", ".", "current_lr", "=", "opt", ".", "learning_rate", "*", "decay_factor", "\n", "utils", ".", "set_lr", "(", "optimizer", ",", "opt", ".", "current_lr", ")", "# set the decayed rate", "\n", "", "else", ":", "\n", "                ", "opt", ".", "current_lr", "=", "opt", ".", "learning_rate", "\n", "# Assign the scheduled sampling prob", "\n", "", "if", "epoch", ">", "opt", ".", "scheduled_sampling_start", "and", "opt", ".", "scheduled_sampling_start", ">=", "0", ":", "\n", "                ", "frac", "=", "(", "epoch", "-", "opt", ".", "scheduled_sampling_start", ")", "//", "opt", ".", "scheduled_sampling_increase_every", "\n", "opt", ".", "ss_prob", "=", "min", "(", "opt", ".", "scheduled_sampling_increase_prob", "*", "frac", ",", "opt", ".", "scheduled_sampling_max_prob", ")", "\n", "model", ".", "ss_prob", "=", "opt", ".", "ss_prob", "\n", "# Update the training stage of cnn", "\n", "", "if", "opt", ".", "finetune_cnn_after", "==", "-", "1", "or", "epoch", "<", "opt", ".", "finetune_cnn_after", ":", "\n", "                ", "for", "p", "in", "cnn_model", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "requires_grad", "=", "False", "\n", "", "cnn_model", ".", "eval", "(", ")", "\n", "", "else", ":", "\n", "                ", "for", "p", "in", "cnn_model", ".", "parameters", "(", ")", ":", "\n", "                    ", "p", ".", "requires_grad", "=", "True", "\n", "# Fix the first few layers:", "\n", "", "for", "module", "in", "cnn_model", ".", "_modules", ".", "values", "(", ")", "[", ":", "5", "]", ":", "\n", "                    ", "for", "p", "in", "module", ".", "parameters", "(", ")", ":", "\n", "                        ", "p", ".", "requires_grad", "=", "False", "\n", "", "", "cnn_model", ".", "train", "(", ")", "\n", "", "update_lr_flag", "=", "False", "\n", "# torch.cuda.synchronize()", "\n", "", "start", "=", "time", ".", "time", "(", ")", "\n", "# Load data from train split (0)", "\n", "# for validation training change the split to 'val'", "\n", "# data = loader.get_batch('val')", "\n", "data", "=", "loader", ".", "get_batch", "(", "'train'", ")", "\n", "\n", "data", "[", "'images'", "]", "=", "utils", ".", "prepro_images", "(", "data", "[", "'images'", "]", ",", "True", ")", "\n", "# torch.cuda.synchronize()", "\n", "print", "(", "'Read data:'", ",", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "\n", "# torch.cuda.synchronize()", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "tmp", "=", "[", "data", "[", "'images'", "]", ",", "data", "[", "'labels'", "]", ",", "data", "[", "'masks'", "]", "]", "\n", "tmp", "=", "[", "Variable", "(", "torch", ".", "from_numpy", "(", "_", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "for", "_", "in", "tmp", "]", "\n", "images", ",", "labels", ",", "masks", "=", "tmp", "\n", "\n", "att_feats", "=", "cnn_model", "(", "images", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "fc_feats", "=", "att_feats", ".", "mean", "(", "2", ")", ".", "mean", "(", "1", ")", "\n", "\n", "if", "not", "opt", ".", "use_att", ":", "\n", "            ", "att_feats", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "1", ",", "1", ",", "1", ",", "1", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "", "att_feats", "=", "att_feats", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "*", "(", "(", "att_feats", ".", "size", "(", "0", ")", ",", "opt", ".", "seq_per_img", ",", ")", "+", "\n", "att_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "(", "(", "att_feats", ".", "size", "(", "0", ")", "*", "opt", ".", "seq_per_img", ",", ")", "\n", "+", "att_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", "\n", "fc_feats", "=", "fc_feats", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "*", "(", "(", "fc_feats", ".", "size", "(", "0", ")", ",", "opt", ".", "seq_per_img", ",", ")", "+", "\n", "fc_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "(", "(", "fc_feats", ".", "size", "(", "0", ")", "*", "opt", ".", "seq_per_img", ",", ")", "+", "\n", "fc_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "opt", ".", "finetune_cnn_after", "!=", "-", "1", "and", "epoch", ">=", "opt", ".", "finetune_cnn_after", ":", "\n", "            ", "cnn_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "opt", ".", "sentence_embed", ":", "\n", "            ", "sen_embed", "=", "Variable", "(", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "data", "[", "'sen_embed'", "]", ")", ")", ".", "cuda", "(", ")", ")", "\n", "out", "=", "model", "(", "fc_feats", ",", "att_feats", ",", "labels", ",", "sen_embed", ")", "\n", "loss", "=", "crit", "(", "out", ",", "labels", "[", ":", ",", "1", ":", "]", ",", "masks", "[", ":", ",", "1", ":", "]", ")", "\n", "# loss += cov", "\n", "", "else", ":", "\n", "            ", "loss", "=", "crit", "(", "model", "(", "fc_feats", ",", "att_feats", ",", "labels", ")", ",", "labels", "[", ":", ",", "1", ":", "]", ",", "masks", "[", ":", ",", "1", ":", "]", ")", "\n", "# - 0.001 * crit(model(torch.zeros(fc_feats.size()).cuda(), torch.zeros(att_feats.size()).cuda(), labels), labels[:,1:], masks[:,1:])", "\n", "", "loss", ".", "backward", "(", ")", "\n", "# utils.clip_gradient(optimizer, opt.grad_clip)", "\n", "optimizer", ".", "step", "(", ")", "\n", "if", "opt", ".", "finetune_cnn_after", "!=", "-", "1", "and", "epoch", ">=", "opt", ".", "finetune_cnn_after", ":", "\n", "            ", "utils", ".", "clip_gradient", "(", "cnn_optimizer", ",", "opt", ".", "grad_clip", ")", "\n", "cnn_optimizer", ".", "step", "(", ")", "\n", "# train_loss = loss.data[0]", "\n", "", "train_loss", "=", "loss", ".", "item", "(", ")", "\n", "# torch.cuda.synchronize()", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Step [{}/{}], Epoch [{}/{}],  train_loss = {:.3f}, time/batch = {:.3f}\"", ".", "format", "(", "(", "iteration", "+", "1", ")", "%", "int", "(", "len", "(", "loader", ")", "/", "vars", "(", "opt", ")", "[", "'batch_size'", "]", ")", ",", "int", "(", "len", "(", "loader", ")", "/", "vars", "(", "opt", ")", "[", "'batch_size'", "]", ")", ",", "\n", "epoch", ",", "vars", "(", "opt", ")", "[", "'max_epochs'", "]", ",", "train_loss", ",", "end", "-", "start", ")", ")", "\n", "\n", "# Update the iteration and epoch", "\n", "iteration", "+=", "1", "\n", "if", "data", "[", "'bounds'", "]", "[", "'wrapped'", "]", ":", "\n", "            ", "epoch", "+=", "1", "\n", "update_lr_flag", "=", "True", "\n", "\n", "# Write the training loss summary", "\n", "", "if", "(", "iteration", "%", "opt", ".", "losses_log_every", "==", "0", ")", ":", "\n", "            ", "if", "tf", "is", "not", "None", ":", "\n", "                ", "add_summary_value", "(", "tf_summary_writer", ",", "'train_loss'", ",", "train_loss", ",", "iteration", ")", "\n", "add_summary_value", "(", "tf_summary_writer", ",", "'learning_rate'", ",", "opt", ".", "current_lr", ",", "iteration", ")", "\n", "add_summary_value", "(", "tf_summary_writer", ",", "'scheduled_sampling_prob'", ",", "model", ".", "ss_prob", ",", "iteration", ")", "\n", "tf_summary_writer", ".", "flush", "(", ")", "\n", "\n", "", "loss_history", "[", "iteration", "]", "=", "train_loss", "\n", "lr_history", "[", "iteration", "]", "=", "opt", ".", "current_lr", "\n", "ss_prob_history", "[", "iteration", "]", "=", "model", ".", "ss_prob", "\n", "\n", "# make evaluation on validation set, and save model", "\n", "", "if", "(", "iteration", "%", "opt", ".", "save_checkpoint_every", "==", "0", ")", ":", "\n", "# eval model", "\n", "            ", "eval_kwargs", "=", "{", "'split'", ":", "'val'", ",", "\n", "'dataset'", ":", "opt", ".", "input_json", "}", "\n", "eval_kwargs", ".", "update", "(", "vars", "(", "opt", ")", ")", "\n", "val_loss", ",", "predictions", ",", "lang_stats", "=", "eval_utils", ".", "eval_split", "(", "cnn_model", ",", "model", ",", "crit", ",", "loader", ",", "eval_kwargs", ")", "\n", "\n", "# Write validation result into summary", "\n", "if", "tf", "is", "not", "None", ":", "\n", "                ", "add_summary_value", "(", "tf_summary_writer", ",", "'validation loss'", ",", "val_loss", ",", "iteration", ")", "\n", "for", "k", ",", "v", "in", "lang_stats", ".", "items", "(", ")", ":", "\n", "                    ", "add_summary_value", "(", "tf_summary_writer", ",", "k", ",", "v", ",", "iteration", ")", "\n", "", "tf_summary_writer", ".", "flush", "(", ")", "\n", "", "val_result_history", "[", "iteration", "]", "=", "{", "'loss'", ":", "val_loss", ",", "'lang_stats'", ":", "lang_stats", ",", "'predictions'", ":", "predictions", "}", "\n", "\n", "# Save model if is improving on validation result", "\n", "if", "opt", ".", "language_eval", "==", "1", ":", "\n", "                ", "current_score", "=", "lang_stats", "[", "'CIDEr'", "]", "\n", "", "else", ":", "\n", "                ", "current_score", "=", "-", "val_loss", "\n", "\n", "", "best_flag", "=", "False", "\n", "if", "True", ":", "# if true", "\n", "                ", "if", "best_val_score", "is", "None", "or", "current_score", ">", "best_val_score", ":", "\n", "                    ", "best_val_score", "=", "current_score", "\n", "best_flag", "=", "True", "\n", "", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", "+", "opt", ".", "caption_model", ",", "'model.pth'", ")", "\n", "cnn_checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", "+", "opt", ".", "caption_model", ",", "'model-cnn.pth'", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "checkpoint_path", ")", "\n", "torch", ".", "save", "(", "cnn_model", ".", "state_dict", "(", ")", ",", "cnn_checkpoint_path", ")", "\n", "print", "(", "\"model saved to {}\"", ".", "format", "(", "checkpoint_path", ")", ")", "\n", "print", "(", "\"cnn model saved to {}\"", ".", "format", "(", "cnn_checkpoint_path", ")", ")", "\n", "optimizer_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", "+", "opt", ".", "caption_model", ",", "'optimizer.pth'", ")", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "optimizer_path", ")", "\n", "if", "opt", ".", "finetune_cnn_after", "!=", "-", "1", "and", "epoch", ">=", "opt", ".", "finetune_cnn_after", ":", "\n", "                    ", "cnn_optimizer_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", "+", "opt", ".", "caption_model", ",", "'optimizer-cnn.pth'", ")", "\n", "torch", ".", "save", "(", "cnn_optimizer", ".", "state_dict", "(", ")", ",", "cnn_optimizer_path", ")", "\n", "\n", "# Dump miscalleous informations", "\n", "", "infos", "[", "'iter'", "]", "=", "iteration", "\n", "infos", "[", "'epoch'", "]", "=", "epoch", "\n", "infos", "[", "'iterators'", "]", "=", "loader", ".", "iterators", "\n", "infos", "[", "'best_val_score'", "]", "=", "best_val_score", "\n", "infos", "[", "'opt'", "]", "=", "opt", "\n", "infos", "[", "'vocab'", "]", "=", "loader", ".", "get_vocab", "(", ")", "\n", "\n", "histories", "[", "'val_result_history'", "]", "=", "val_result_history", "\n", "histories", "[", "'loss_history'", "]", "=", "loss_history", "\n", "histories", "[", "'lr_history'", "]", "=", "lr_history", "\n", "histories", "[", "'ss_prob_history'", "]", "=", "ss_prob_history", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", "+", "opt", ".", "caption_model", ",", "'infos_'", "+", "opt", ".", "id", "+", "'.pkl'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                    ", "cPickle", ".", "dump", "(", "infos", ",", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", "+", "opt", ".", "caption_model", ",", "'histories_'", "+", "opt", ".", "id", "+", "'.pkl'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                    ", "cPickle", ".", "dump", "(", "histories", ",", "f", ")", "\n", "\n", "", "if", "best_flag", ":", "\n", "                    ", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", "+", "opt", ".", "caption_model", ",", "'model-best.pth'", ")", "\n", "cnn_checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", "+", "opt", ".", "caption_model", ",", "'model-cnn-best.pth'", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "checkpoint_path", ")", "\n", "torch", ".", "save", "(", "cnn_model", ".", "state_dict", "(", ")", ",", "cnn_checkpoint_path", ")", "\n", "print", "(", "\"model saved to {}\"", ".", "format", "(", "checkpoint_path", ")", ")", "\n", "print", "(", "\"cnn model saved to {}\"", ".", "format", "(", "cnn_checkpoint_path", ")", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "checkpoint_path", "+", "opt", ".", "caption_model", ",", "'infos_'", "+", "opt", ".", "id", "+", "'-best.pkl'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                        ", "cPickle", ".", "dump", "(", "infos", ",", "f", ")", "\n", "\n", "# Stop if reaching max epochs", "\n", "", "", "", "", "if", "epoch", ">=", "opt", ".", "max_epochs", "and", "opt", ".", "max_epochs", "!=", "-", "1", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.eval_utils.language_eval": [[25, 94], ["os.path.join", "COCO", "COCO.getImgIds", "print", "json.dump", "COCO.loadRes", "COCOEvalCap", "coco.loadRes.getImgIds", "COCOEvalCap.evaluate", "COCOEvalCap.eval.items", "sys.path.append", "eval_utils.evaluate", "print", "print", "print", "print", "print", "print", "format", "os.path.isdir", "os.mkdir", "open", "open", "json.dump", "open", "json.load", "open", "json.load", "enumerate", "hypo.keys", "len", "len"], "function", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.eval_utils.evaluate", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.eval_utils.evaluate"], ["def", "language_eval", "(", "dataset", ",", "preds", ",", "model_id", ",", "split", ")", ":", "\n", "    ", "import", "sys", "\n", "if", "'coco'", "in", "dataset", ":", "\n", "        ", "sys", ".", "path", ".", "append", "(", "\"coco-caption\"", ")", "\n", "annFile", "=", "'coco-caption/annotations/captions_val2014.json'", "\n", "", "else", ":", "\n", "# TODO: NYTIMES", "\n", "        ", "if", "split", "==", "'val'", ":", "\n", "            ", "annFile", "=", "'./data/val.json'", "\n", "with", "open", "(", "annFile", ",", "'rb'", ")", "as", "f", ":", "dataset", "=", "json", ".", "load", "(", "f", ")", "\n", "", "else", ":", "\n", "            ", "annFile", "=", "'./data/test.json'", "\n", "with", "open", "(", "annFile", ",", "'rb'", ")", "as", "f", ":", "dataset", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "# TODO: BREAKINGNEWS", "\n", "# with open(\"/home/abiten/Desktop/Thesis/newspaper/breakingnews/bnews_caps.json\", \"rb\") as f: dataset = json.load(f)", "\n", "\n", "", "id_to_ix", "=", "{", "v", "[", "'cocoid'", "]", ":", "ix", "for", "ix", ",", "v", "in", "enumerate", "(", "dataset", ")", "}", "\n", "hypo", "=", "{", "v", "[", "'image_id'", "]", ":", "[", "v", "[", "'caption'", "]", "]", "for", "v", "in", "preds", "}", "\n", "ref", "=", "{", "k", ":", "[", "i", "[", "'raw'", "]", "for", "i", "in", "dataset", "[", "id_to_ix", "[", "k", "]", "]", "[", "'sentences'", "]", "]", "for", "k", "in", "hypo", ".", "keys", "(", ")", "}", "\n", "final_scores", "=", "evaluate", "(", "ref", ",", "hypo", ")", "\n", "print", "(", "'Bleu_1:\\t'", ",", "final_scores", "[", "'Bleu_1'", "]", ")", "\n", "print", "(", "'Bleu_2:\\t'", ",", "final_scores", "[", "'Bleu_2'", "]", ")", "\n", "print", "(", "'Bleu_3:\\t'", ",", "final_scores", "[", "'Bleu_3'", "]", ")", "\n", "print", "(", "'Bleu_4:\\t'", ",", "final_scores", "[", "'Bleu_4'", "]", ")", "\n", "# print('METEOR:\\t', final_scores['METEOR'])", "\n", "print", "(", "'ROUGE_L:'", ",", "final_scores", "[", "'ROUGE_L'", "]", ")", "\n", "print", "(", "'CIDEr:\\t'", ",", "final_scores", "[", "'CIDEr'", "]", ")", "\n", "# print('Spice:\\t', final_scores['Spice'])", "\n", "return", "final_scores", "\n", "\n", "\n", "# sys.path.append(\"f30k-caption\")", "\n", "# annFile = 'f30k-caption/annotations/dataset_flickr30k.json'", "\n", "", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "from", "pycocoevalcap", ".", "eval", "import", "COCOEvalCap", "\n", "\n", "encoder", ".", "FLOAT_REPR", "=", "lambda", "o", ":", "format", "(", "o", ",", "'.3f'", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "'eval_results'", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "'eval_results'", ")", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "'eval_results/'", ",", "model_id", "+", "'_'", "+", "split", "+", "'.json'", ")", "\n", "\n", "coco", "=", "COCO", "(", "annFile", ")", "\n", "valids", "=", "coco", ".", "getImgIds", "(", ")", "\n", "\n", "# filter results to only those in MSCOCO validation set (will be about a third)", "\n", "preds_filt", "=", "[", "p", "for", "p", "in", "preds", "if", "p", "[", "'image_id'", "]", "in", "valids", "]", "\n", "print", "(", "'using %d/%d predictions'", "%", "(", "len", "(", "preds_filt", ")", ",", "len", "(", "preds", ")", ")", ")", "\n", "json", ".", "dump", "(", "preds_filt", ",", "open", "(", "cache_path", ",", "'w'", ")", ")", "# serialize to temporary json file. Sigh, COCO API...", "\n", "\n", "cocoRes", "=", "coco", ".", "loadRes", "(", "cache_path", ")", "\n", "cocoEval", "=", "COCOEvalCap", "(", "coco", ",", "cocoRes", ")", "\n", "cocoEval", ".", "params", "[", "'image_id'", "]", "=", "cocoRes", ".", "getImgIds", "(", ")", "\n", "cocoEval", ".", "evaluate", "(", ")", "\n", "\n", "# create output dictionary", "\n", "out", "=", "{", "}", "\n", "for", "metric", ",", "score", "in", "cocoEval", ".", "eval", ".", "items", "(", ")", ":", "\n", "        ", "out", "[", "metric", "]", "=", "score", "\n", "\n", "", "imgToEval", "=", "cocoEval", ".", "imgToEval", "\n", "for", "p", "in", "preds_filt", ":", "\n", "        ", "image_id", ",", "caption", "=", "p", "[", "'image_id'", "]", ",", "p", "[", "'caption'", "]", "\n", "imgToEval", "[", "image_id", "]", "[", "'caption'", "]", "=", "caption", "\n", "", "with", "open", "(", "cache_path", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "{", "'overall'", ":", "out", ",", "'imgToEval'", ":", "imgToEval", "}", ",", "outfile", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.eval_utils.evaluate": [[95, 113], ["scorer.compute_score", "pycocoevalcap.bleu.bleu.Bleu", "pycocoevalcap.rouge.rouge.Rouge", "pycocoevalcap.cider.cider.Cider", "type", "zip"], "function", ["None"], ["", "def", "evaluate", "(", "ref", ",", "hypo", ")", ":", "\n", "    ", "scorers", "=", "[", "\n", "(", "Bleu", "(", "4", ")", ",", "[", "\"Bleu_1\"", ",", "\"Bleu_2\"", ",", "\"Bleu_3\"", ",", "\"Bleu_4\"", "]", ")", ",", "\n", "# (Meteor(), \"METEOR\"),", "\n", "(", "Rouge", "(", ")", ",", "\"ROUGE_L\"", ")", ",", "\n", "(", "Cider", "(", ")", ",", "\"CIDEr\"", ")", "\n", "# (Spice(), \"Spice\")", "\n", "]", "\n", "final_scores", "=", "{", "}", "\n", "for", "scorer", ",", "method", "in", "scorers", ":", "\n", "        ", "score", ",", "scores", "=", "scorer", ".", "compute_score", "(", "ref", ",", "hypo", ")", "\n", "if", "type", "(", "score", ")", "==", "list", ":", "\n", "            ", "for", "m", ",", "s", "in", "zip", "(", "method", ",", "score", ")", ":", "\n", "                ", "final_scores", "[", "m", "]", "=", "s", "\n", "", "", "else", ":", "\n", "            ", "final_scores", "[", "method", "]", "=", "score", "\n", "\n", "", "", "return", "final_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.eval_utils.eval_split": [[114, 232], ["eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "eval_kwargs.get", "cnn_model.eval", "model.eval", "loader.reset_iterator", "model.train", "eval_kwargs.get", "loader.get_batch", "misc.prepro_images", "loader.get_batch.get", "misc.decode_sequence", "enumerate", "range", "eval_utils.language_eval", "loader.get_batch.get", "loader.get_batch.get", "torch.autograd.Variable().cuda", "torch.no_grad", "torch.no_grad", "cnn_model().permute", "att_feats.unsqueeze().expand().contiguous().view.mean().mean", "loader.get_batch.get", "att_feats.unsqueeze().expand().contiguous().view.unsqueeze().expand().contiguous().view", "fc_feats.unsqueeze().expand().contiguous().view.unsqueeze().expand().contiguous().view", "model.sample", "loader.get_vocab", "predictions.append", "min", "predictions.pop", "print", "numpy.zeros", "numpy.zeros", "model.sample", "numpy.array", "numpy.array", "model.sample", "len", "vis_attention[].tolist", "sen_attention[].tolist", "eval_kwargs.get", "eval_kwargs.get", "print", "os.system", "print", "torch.autograd.Variable", "cnn_model", "att_feats.unsqueeze().expand().contiguous().view.mean", "att_feats.unsqueeze().expand().contiguous().view.unsqueeze().expand().contiguous", "fc_feats.unsqueeze().expand().contiguous().view.unsqueeze().expand().contiguous", "torch.no_grad", "torch.no_grad", "numpy.array", "crit", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "sent.split", "torch.from_numpy", "torch.from_numpy", "model", "crit", "str", "att_feats.unsqueeze().expand().contiguous().view.unsqueeze().expand", "att_feats.unsqueeze().expand().contiguous().view.size", "fc_feats.unsqueeze().expand().contiguous().view.unsqueeze().expand", "fc_feats.unsqueeze().expand().contiguous().view.size", "torch.autograd.Variable().cuda", "model", "torch.autograd.Variable", "torch.autograd.Variable", "len", "att_feats.unsqueeze().expand().contiguous().view.size", "fc_feats.unsqueeze().expand().contiguous().view.size", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "os.path.join", "att_feats.unsqueeze().expand().contiguous().view.unsqueeze", "fc_feats.unsqueeze().expand().contiguous().view.unsqueeze", "torch.autograd.Variable", "torch.from_numpy", "torch.from_numpy", "att_feats.unsqueeze().expand().contiguous().view.size", "att_feats.unsqueeze().expand().contiguous().view.size", "fc_feats.unsqueeze().expand().contiguous().view.size", "fc_feats.unsqueeze().expand().contiguous().view.size"], "function", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.reset_iterator", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.train.train", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.get_batch", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.prepro_images", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.decode_sequence", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.eval_utils.language_eval", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.sample", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.get_vocab", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.sample", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.sample"], ["", "def", "eval_split", "(", "cnn_model", ",", "model", ",", "crit", ",", "loader", ",", "eval_kwargs", "=", "{", "}", ",", "return_attention", "=", "False", ")", ":", "\n", "    ", "verbose", "=", "eval_kwargs", ".", "get", "(", "'verbose'", ",", "True", ")", "\n", "num_images", "=", "eval_kwargs", ".", "get", "(", "'num_images'", ",", "eval_kwargs", ".", "get", "(", "'val_images_use'", ",", "-", "1", ")", ")", "\n", "split", "=", "eval_kwargs", ".", "get", "(", "'split'", ",", "'val'", ")", "\n", "lang_eval", "=", "eval_kwargs", ".", "get", "(", "'language_eval'", ",", "0", ")", "\n", "dataset", "=", "eval_kwargs", ".", "get", "(", "'dataset'", ",", "'news'", ")", "\n", "beam_size", "=", "eval_kwargs", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "\n", "# Make sure in the evaluation mode", "\n", "cnn_model", ".", "eval", "(", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "loader", ".", "reset_iterator", "(", "split", ")", "\n", "\n", "n", "=", "0", "\n", "loss", "=", "0", "\n", "loss_sum", "=", "0", "\n", "loss_evals", "=", "1e-8", "\n", "predictions", "=", "[", "]", "\n", "\n", "while", "True", ":", "\n", "        ", "data", "=", "loader", ".", "get_batch", "(", "split", ")", "\n", "data", "[", "'images'", "]", "=", "utils", ".", "prepro_images", "(", "data", "[", "'images'", "]", ",", "False", ")", "\n", "n", "=", "n", "+", "loader", ".", "batch_size", "\n", "\n", "#evaluate loss if we have the labels", "\n", "loss", "=", "0", "\n", "# vis_attention, sen_attention = [], []", "\n", "# Get the image features first", "\n", "tmp", "=", "[", "data", "[", "'images'", "]", ",", "data", ".", "get", "(", "'labels'", ",", "np", ".", "zeros", "(", "1", ")", ")", ",", "data", ".", "get", "(", "'masks'", ",", "np", ".", "zeros", "(", "1", ")", ")", "]", "\n", "tmp", "=", "[", "Variable", "(", "torch", ".", "from_numpy", "(", "_", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "for", "_", "in", "tmp", "]", "\n", "images", ",", "labels", ",", "masks", "=", "tmp", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "att_feats", "=", "cnn_model", "(", "images", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# .contiguous()", "\n", "# att_feats = _att_feats = cnn_model(images).permute(0, 2, 3, 1).contiguous()", "\n", "# fc_feats = _fc_feats = att_feats.mean(2).mean(1)", "\n", "fc_feats", "=", "att_feats", ".", "mean", "(", "2", ")", ".", "mean", "(", "1", ")", "\n", "", "sen_embed", "=", "data", ".", "get", "(", "'sen_embed'", ",", "None", ")", "\n", "\n", "# forward the model to get loss", "\n", "if", "data", ".", "get", "(", "'labels'", ",", "None", ")", "is", "not", "None", ":", "\n", "\n", "            ", "att_feats", "=", "att_feats", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "*", "(", "(", "att_feats", ".", "size", "(", "0", ")", ",", "loader", ".", "seq_per_img", ",", ")", "+", "att_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "(", "(", "att_feats", ".", "size", "(", "0", ")", "*", "loader", ".", "seq_per_img", ",", ")", "+", "att_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", "\n", "fc_feats", "=", "fc_feats", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "*", "(", "(", "fc_feats", ".", "size", "(", "0", ")", ",", "loader", ".", "seq_per_img", ",", ")", "+", "fc_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", ".", "view", "(", "*", "(", "(", "fc_feats", ".", "size", "(", "0", ")", "*", "loader", ".", "seq_per_img", ",", ")", "+", "fc_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", "\n", "if", "sen_embed", "is", "not", "None", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "sen_embed", "=", "np", ".", "array", "(", "sen_embed", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "loss", "=", "crit", "(", "model", "(", "fc_feats", ",", "att_feats", ",", "labels", ",", "Variable", "(", "torch", ".", "from_numpy", "(", "sen_embed", ")", ")", ".", "cuda", "(", ")", ")", ",", "\n", "labels", "[", ":", ",", "1", ":", "]", ",", "masks", "[", ":", ",", "1", ":", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", "=", "crit", "(", "model", "(", "fc_feats", ",", "att_feats", ",", "labels", ")", ",", "labels", "[", ":", ",", "1", ":", "]", ",", "masks", "[", ":", ",", "1", ":", "]", ")", ".", "data", "[", "0", "]", "\n", "", "loss_sum", "+=", "loss", "\n", "loss_evals", "=", "loss_evals", "+", "1", "\n", "\n", "# forward the model to also get generated samples for each image", "\n", "# Only leave one feature for each image, in case duplicate sample", "\n", "# fc_feats, att_feats = _fc_feats, _att_feats", "\n", "# forward the model to also get generated samples for each image", "\n", "", "if", "sen_embed", "is", "not", "None", ":", "\n", "            ", "if", "return_attention", ":", "\n", "                ", "seq", ",", "_", ",", "atts", "=", "model", ".", "sample", "(", "fc_feats", ",", "att_feats", ",", "eval_kwargs", ",", "Variable", "(", "torch", ".", "from_numpy", "(", "sen_embed", ")", ")", ".", "cuda", "(", ")", ",", "\n", "return_attention", ")", "\n", "vis_attention", "=", "np", ".", "array", "(", "[", "att", "[", "0", "]", "for", "att", "in", "atts", "]", ")", "\n", "sen_attention", "=", "np", ".", "array", "(", "[", "att", "[", "1", "]", "for", "att", "in", "atts", "]", ")", "\n", "", "else", ":", "\n", "                ", "seq", ",", "_", "=", "model", ".", "sample", "(", "fc_feats", ",", "att_feats", ",", "eval_kwargs", ",", "\n", "Variable", "(", "torch", ".", "from_numpy", "(", "sen_embed", ")", ")", ".", "cuda", "(", ")", ",", "\n", "return_attention", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "seq", ",", "_", "=", "model", ".", "sample", "(", "fc_feats", ",", "att_feats", ",", "eval_kwargs", ")", "\n", "#set_trace()", "\n", "", "sents", "=", "utils", ".", "decode_sequence", "(", "loader", ".", "get_vocab", "(", ")", ",", "seq", ")", "\n", "\n", "for", "k", ",", "sent", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "entry", "=", "{", "'image_id'", ":", "data", "[", "'infos'", "]", "[", "k", "]", "[", "'id'", "]", ",", "'caption'", ":", "sent", ",", "'image_path'", ":", "data", "[", "'infos'", "]", "[", "k", "]", "[", "'file_path'", "]", "}", "\n", "if", "return_attention", ":", "\n", "                ", "sen_length", "=", "len", "(", "sent", ".", "split", "(", ")", ")", "\n", "entry", "[", "'vis_att'", "]", "=", "vis_attention", "[", ":", "sen_length", ",", "k", ",", ":", "]", ".", "tolist", "(", ")", "\n", "entry", "[", "'sen_att'", "]", "=", "sen_attention", "[", ":", "sen_length", ",", "k", ",", ":", "]", ".", "tolist", "(", ")", "\n", "", "if", "eval_kwargs", ".", "get", "(", "'dump_path'", ",", "0", ")", "==", "1", ":", "\n", "                ", "entry", "[", "'file_name'", "]", "=", "data", "[", "'infos'", "]", "[", "k", "]", "[", "'file_path'", "]", "\n", "", "predictions", ".", "append", "(", "entry", ")", "\n", "if", "eval_kwargs", ".", "get", "(", "'dump_images'", ",", "0", ")", "==", "1", ":", "\n", "# dump the raw image to vis/ folder", "\n", "                ", "cmd", "=", "'cp \"'", "+", "os", ".", "path", ".", "join", "(", "eval_kwargs", "[", "'image_root'", "]", ",", "data", "[", "'infos'", "]", "[", "k", "]", "[", "'file_path'", "]", ")", "+", "'\" vis/imgs/img'", "+", "str", "(", "len", "(", "predictions", ")", ")", "+", "'.jpg'", "# bit gross", "\n", "print", "(", "cmd", ")", "\n", "os", ".", "system", "(", "cmd", ")", "\n", "\n", "", "if", "verbose", ":", "\n", "                ", "print", "(", "'image %s: %s'", "%", "(", "entry", "[", "'image_id'", "]", ",", "entry", "[", "'caption'", "]", ")", ")", "\n", "\n", "# if we wrapped around the split or used up val imgs budget then bail", "\n", "", "", "ix0", "=", "data", "[", "'bounds'", "]", "[", "'it_pos_now'", "]", "\n", "ix1", "=", "data", "[", "'bounds'", "]", "[", "'it_max'", "]", "\n", "if", "num_images", "!=", "-", "1", ":", "\n", "            ", "ix1", "=", "min", "(", "ix1", ",", "num_images", ")", "\n", "", "for", "i", "in", "range", "(", "n", "-", "ix1", ")", ":", "\n", "            ", "predictions", ".", "pop", "(", ")", "\n", "# break", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'evaluating validation preformance... %d/%d (%f)'", "%", "(", "ix0", "-", "1", ",", "ix1", ",", "loss", ")", ")", "\n", "\n", "", "if", "data", "[", "'bounds'", "]", "[", "'wrapped'", "]", ":", "\n", "            ", "break", "\n", "", "if", "num_images", ">=", "0", "and", "n", ">=", "num_images", ":", "\n", "            ", "break", "\n", "\n", "", "", "lang_stats", "=", "None", "\n", "if", "lang_eval", "==", "1", ":", "\n", "        ", "lang_stats", "=", "language_eval", "(", "dataset", ",", "predictions", ",", "eval_kwargs", "[", "'id'", "]", ",", "split", ")", "\n", "\n", "# if sen_embed is not None:", "\n", "#     atts = [{'file_path': d['file_path'], 'vis_att':vis_attention[i], 'sen_att':sen_attention[i]} for i, d in enumerate(data['infos'])]", "\n", "#     return loss_sum/loss_evals, predictions, lang_stats, atts", "\n", "# Switch back to training mode", "\n", "", "model", ".", "train", "(", ")", "\n", "return", "loss_sum", "/", "loss_evals", ",", "predictions", ",", "lang_stats", "\n", "", ""]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.__init__": [[58, 136], ["print", "json.load", "len", "print", "print", "tables.open_file", "tables.open_file", "print", "print", "numpy.array", "numpy.array", "range", "print", "print", "print", "open", "len", "len", "numpy.random.permutation", "numpy.arange", "numpy.arange", "h5py.File", "json.load", "[].split", "dataloader.DataLoader.split_ix[].append", "len", "len", "len", "numpy.arange", "len", "len", "open", "dataloader.DataLoader.split_ix[].append", "len", "dataloader.DataLoader.split_ix[].append", "i[].split", "dataloader.DataLoader.split_ix[].append", "dataloader.DataLoader.opt.sentence_embed.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "batch_size", "=", "self", ".", "opt", ".", "batch_size", "\n", "self", ".", "seq_per_img", "=", "self", ".", "opt", ".", "seq_per_img", "\n", "self", ".", "num_thread", "=", "1", "\n", "# load the json file which contains additional information about the dataset", "\n", "print", "(", "'DataLoader loading json file: '", ",", "opt", ".", "input_json", ")", "\n", "self", ".", "info", "=", "json", ".", "load", "(", "open", "(", "self", ".", "opt", ".", "input_json", ")", ")", "\n", "self", ".", "ix_to_word", "=", "self", ".", "info", "[", "'ix_to_word'", "]", "\n", "self", ".", "vocab_size", "=", "len", "(", "self", ".", "ix_to_word", ")", "\n", "print", "(", "'vocab size is '", ",", "self", ".", "vocab_size", ")", "\n", "\n", "\n", "# open the hdf5 file", "\n", "print", "(", "'DataLoader loading h5 file: '", ",", "opt", ".", "input_label_h5", ",", "opt", ".", "input_image_h5", ")", "\n", "# self.h5_label_file = h5py.File(self.opt.input_label_h5, mode='r')", "\n", "self", ".", "h5_label_file", "=", "tables", ".", "open_file", "(", "self", ".", "opt", ".", "input_label_h5", ",", "driver", "=", "\"H5FD_CORE\"", ")", "\n", "# self.h5_image_file = h5py.File(self.opt.input_image_h5, mode='r')", "\n", "self", ".", "h5_image_file", "=", "tables", ".", "open_file", "(", "self", ".", "opt", ".", "input_image_h5", ",", "mode", "=", "'r'", ")", "\n", "if", "'sentence_embed'", "in", "opt", ":", "\n", "            ", "if", "opt", ".", "sentence_embed", ":", "\n", "                ", "self", ".", "h5_sen_embed_file", "=", "h5py", ".", "File", "(", "self", ".", "opt", ".", "sentence_embed", ",", "mode", "=", "'r'", ")", "\n", "# self.h5_sen_embed_file = tables.open_file(self.opt.sentence_embed, mode='r')", "\n", "self", ".", "sen_embed_keys", "=", "json", ".", "load", "(", "open", "(", "self", ".", "opt", ".", "sentence_embed", ".", "split", "(", "'.h5'", ")", "[", "0", "]", "+", "'_keys.json'", ")", ")", "\n", "# self.sen_embed_file = da.from_array(self.h5_sen_embed_file['average'],", "\n", "#                     chunks=(self.h5_sen_embed_file['average'].shape[0], 300, ))", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "opt", ".", "sentence_embed", "=", "False", "\n", "\n", "# extract image size from dataset", "\n", "# images_size = self.h5_image_file['images'].shape", "\n", "", "images_size", "=", "self", ".", "h5_image_file", ".", "root", ".", "images", ".", "shape", "\n", "assert", "len", "(", "images_size", ")", "==", "4", ",", "'images should be a 4D tensor'", "\n", "assert", "images_size", "[", "2", "]", "==", "images_size", "[", "3", "]", ",", "'width and height must match'", "\n", "self", ".", "num_images", "=", "images_size", "[", "0", "]", "\n", "self", ".", "num_channels", "=", "images_size", "[", "1", "]", "\n", "self", ".", "max_image_size", "=", "images_size", "[", "2", "]", "\n", "print", "(", "'read %d images of size %dx%dx%d'", "%", "(", "self", ".", "num_images", ",", "\n", "self", ".", "num_channels", ",", "self", ".", "max_image_size", ",", "self", ".", "max_image_size", ")", ")", "\n", "\n", "# load in the sequence data", "\n", "# seq_size = self.h5_label_file['labels'].shape", "\n", "seq_size", "=", "self", ".", "h5_label_file", ".", "root", ".", "labels", ".", "shape", "\n", "self", ".", "seq_length", "=", "seq_size", "[", "1", "]", "\n", "print", "(", "'max sequence length in data is'", ",", "self", ".", "seq_length", ")", "\n", "# load the pointers in full to RAM (should be small enough)", "\n", "self", ".", "label_start_ix", "=", "np", ".", "array", "(", "self", ".", "h5_label_file", ".", "root", ".", "label_start_ix", ")", "\n", "# self.label_start_ix = np.array(self.h5_label_file['label_start_ix'])", "\n", "self", ".", "label_end_ix", "=", "np", ".", "array", "(", "self", ".", "h5_label_file", ".", "root", ".", "label_end_ix", ")", "\n", "# self.label_end_ix = np.array(self.h5_label_file['label_end_ix'])", "\n", "\n", "# separate out indexes for each of the provided splits", "\n", "self", ".", "split_ix", "=", "{", "'train'", ":", "[", "]", ",", "'val'", ":", "[", "]", ",", "'test'", ":", "[", "]", "}", "\n", "# TODO: for nytimes dataset", "\n", "self", ".", "id_to_keys", "=", "{", "i", "[", "'id'", "]", ":", "i", "[", "'file_path'", "]", ".", "split", "(", "'/'", ")", "[", "1", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", "for", "i", "in", "self", ".", "info", "[", "'images'", "]", "}", "\n", "# TODO: for breakinNews", "\n", "# self.id_to_keys = {i['id']: i['id'] for i in self.info['images']}", "\n", "\n", "\n", "for", "ix", "in", "range", "(", "len", "(", "self", ".", "info", "[", "'images'", "]", ")", ")", ":", "\n", "            ", "img", "=", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "\n", "if", "img", "[", "'split'", "]", "==", "'train'", ":", "\n", "                ", "self", ".", "split_ix", "[", "'train'", "]", ".", "append", "(", "ix", ")", "\n", "", "elif", "img", "[", "'split'", "]", "==", "'val'", ":", "\n", "                ", "self", ".", "split_ix", "[", "'val'", "]", ".", "append", "(", "ix", ")", "\n", "", "elif", "img", "[", "'split'", "]", "==", "'test'", ":", "\n", "                ", "self", ".", "split_ix", "[", "'test'", "]", ".", "append", "(", "ix", ")", "\n", "", "elif", "opt", ".", "train_only", "==", "0", ":", "# restval", "\n", "                ", "self", ".", "split_ix", "[", "'train'", "]", ".", "append", "(", "ix", ")", "\n", "\n", "", "", "print", "(", "'assigned %d images to split train'", "%", "len", "(", "self", ".", "split_ix", "[", "'train'", "]", ")", ")", "\n", "print", "(", "'assigned %d images to split val'", "%", "len", "(", "self", ".", "split_ix", "[", "'val'", "]", ")", ")", "\n", "print", "(", "'assigned %d images to split test'", "%", "len", "(", "self", ".", "split_ix", "[", "'test'", "]", ")", ")", "\n", "\n", "self", ".", "iterators", "=", "{", "'train'", ":", "0", ",", "'val'", ":", "0", ",", "'test'", ":", "0", "}", "\n", "self", ".", "shuffle", "=", "{", "'train'", ":", "np", ".", "random", ".", "permutation", "(", "np", ".", "arange", "(", "len", "(", "self", ".", "split_ix", "[", "'train'", "]", ")", ")", ")", ",", "\n", "'val'", ":", "np", ".", "arange", "(", "len", "(", "self", ".", "split_ix", "[", "'val'", "]", ")", ")", ",", "\n", "'test'", ":", "np", ".", "arange", "(", "len", "(", "self", ".", "split_ix", "[", "'test'", "]", ")", ")", "}", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.__len__": [[136, 138], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "split_ix", "[", "'train'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.get_vocab_size": [[139, 141], ["None"], "methods", ["None"], ["", "def", "get_vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.get_vocab": [[142, 144], ["None"], "methods", ["None"], ["", "def", "get_vocab", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "ix_to_word", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.get_seq_length": [[145, 147], ["None"], "methods", ["None"], ["", "def", "get_seq_length", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "seq_length", "\n", "", "def", "get_batch_one", "(", "self", ",", "split", ")", ":", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.get_batch_one": [[147, 224], ["numpy.ndarray", "numpy.zeros", "numpy.zeros", "len", "numpy.array", "preprocess().numpy", "infos.append", "numpy.array", "enumerate", "numpy.zeros", "numpy.random.shuffle", "numpy.zeros", "range", "random.randint", "dataloader.DataLoader.sen_embed_keys.index", "numpy.stack().transpose", "list", "len", "preprocess", "random.randint", "map", "torch.from_numpy", "numpy.stack", "len", "numpy.array.astype"], "methods", ["None"], ["", "def", "get_batch_one", "(", "self", ",", "split", ")", ":", "\n", "        ", "split_ix", "=", "self", ".", "split_ix", "[", "split", "]", "\n", "batch_size", "=", "1", "\n", "img_batch", "=", "np", ".", "ndarray", "(", "[", "batch_size", ",", "3", ",", "256", ",", "256", "]", ",", "dtype", "=", "'float32'", ")", "\n", "label_batch", "=", "np", ".", "zeros", "(", "[", "batch_size", "*", "self", ".", "seq_per_img", ",", "self", ".", "seq_length", "+", "2", "]", ",", "dtype", "=", "'int'", ")", "\n", "mask_batch", "=", "np", ".", "zeros", "(", "[", "batch_size", "*", "self", ".", "seq_per_img", ",", "self", ".", "seq_length", "+", "2", "]", ",", "dtype", "=", "'float32'", ")", "\n", "if", "self", ".", "opt", ".", "sentence_embed", ":", "\n", "            ", "sen_embed_batch", "=", "np", ".", "zeros", "(", "\n", "[", "batch_size", "*", "self", ".", "seq_per_img", ",", "self", ".", "opt", ".", "sentence_length", "+", "1", ",", "self", ".", "opt", ".", "sentence_embed_size", "]", ",", "\n", "dtype", "=", "'float32'", ")", "\n", "", "max_index", "=", "len", "(", "split_ix", ")", "\n", "infos", "=", "[", "]", "\n", "b_id", "=", "self", ".", "shuffle", "[", "split", "]", "[", "self", ".", "iterators", "[", "split", "]", ":", "self", ".", "iterators", "[", "split", "]", "+", "batch_size", "]", "[", "0", "]", "\n", "self", ".", "iterators", "[", "split", "]", "+=", "batch_size", "\n", "if", "self", ".", "iterators", "[", "split", "]", ">=", "max_index", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "shuffle", "[", "split", "]", ")", "\n", "self", ".", "iterators", "[", "split", "]", "=", "0", "\n", "\n", "", "i", "=", "0", "\n", "ix", "=", "split_ix", "[", "b_id", "]", "\n", "\n", "# fetch image", "\n", "# img = self.load_image(self.image_info[ix]['filename'])", "\n", "# img = np.array(self.h5_image_file['images'][ix, :, :, :])", "\n", "img", "=", "np", ".", "array", "(", "self", ".", "h5_image_file", ".", "root", ".", "images", "[", "ix", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "img_batch", "[", "i", "]", "=", "preprocess", "(", "torch", ".", "from_numpy", "(", "img", ".", "astype", "(", "'float32'", ")", "/", "255.0", ")", ")", ".", "numpy", "(", ")", "\n", "\n", "# fetch the sequence labels", "\n", "ix1", "=", "self", ".", "label_start_ix", "[", "ix", "]", "-", "1", "# label_start_ix starts from 1", "\n", "ix2", "=", "self", ".", "label_end_ix", "[", "ix", "]", "-", "1", "\n", "ncap", "=", "ix2", "-", "ix1", "+", "1", "# number of captions available for this image", "\n", "assert", "ncap", ">", "0", ",", "'an image does not have any label. this can be handled but right now isn\\'t'", "\n", "\n", "if", "ncap", "<", "self", ".", "seq_per_img", ":", "\n", "# we need to subsample (with replacement)", "\n", "            ", "seq", "=", "np", ".", "zeros", "(", "[", "self", ".", "seq_per_img", ",", "self", ".", "seq_length", "]", ",", "dtype", "=", "'int'", ")", "\n", "for", "q", "in", "range", "(", "self", ".", "seq_per_img", ")", ":", "\n", "                ", "ixl", "=", "random", ".", "randint", "(", "ix1", ",", "ix2", ")", "\n", "# seq[q, :] = self.h5_label_file['labels'][ixl, :self.seq_length]", "\n", "seq", "[", "q", ",", ":", "]", "=", "self", ".", "h5_label_file", ".", "root", ".", "labels", "[", "ixl", ",", ":", "self", ".", "seq_length", "]", "\n", "", "", "else", ":", "\n", "            ", "ixl", "=", "random", ".", "randint", "(", "ix1", ",", "ix2", "-", "self", ".", "seq_per_img", "+", "1", ")", "\n", "# seq = self.h5_label_file['labels'][ixl: ixl + self.seq_per_img, :self.seq_length]", "\n", "seq", "=", "self", ".", "h5_label_file", ".", "root", ".", "labels", "[", "ixl", ":", "ixl", "+", "self", ".", "seq_per_img", ",", ":", "self", ".", "seq_length", "]", "\n", "\n", "", "label_batch", "[", "i", "*", "self", ".", "seq_per_img", ":", "(", "i", "+", "1", ")", "*", "self", ".", "seq_per_img", ",", "1", ":", "self", ".", "seq_length", "+", "1", "]", "=", "seq", "\n", "\n", "# record associated info as well", "\n", "info_dict", "=", "{", "}", "\n", "info_dict", "[", "'id'", "]", "=", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'id'", "]", "\n", "info_dict", "[", "'file_path'", "]", "=", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'file_path'", "]", "\n", "# fetch sen_embed", "\n", "if", "self", ".", "opt", ".", "sentence_embed", ":", "\n", "# for q in range(self.seq_per_img):", "\n", "            ", "key", "=", "self", ".", "id_to_keys", "[", "info_dict", "[", "'id'", "]", "]", "\n", "sen_ix", "=", "self", ".", "sen_embed_keys", ".", "index", "(", "key", ")", "\n", "sen_embed", "=", "np", ".", "stack", "(", "self", ".", "h5_sen_embed_file", "[", "'average'", "]", "[", "sen_ix", ",", ":", "]", ")", ".", "transpose", "(", ")", "\n", "# sen_embed = np.stack(self.h5_sen_embed_file.root.average[sen_ix, :]).transpose()", "\n", "sen_embed_batch", "[", "i", ",", ":", "len", "(", "sen_embed", ")", ",", ":", "]", "=", "sen_embed", "\n", "", "infos", ".", "append", "(", "info_dict", ")", "\n", "\n", "# generate mask", "\n", "nonzeros", "=", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "x", ":", "(", "x", "!=", "0", ")", ".", "sum", "(", ")", "+", "2", ",", "label_batch", ")", ")", ")", "\n", "for", "ix", ",", "row", "in", "enumerate", "(", "mask_batch", ")", ":", "\n", "            ", "row", "[", ":", "nonzeros", "[", "ix", "]", "]", "=", "1", "\n", "\n", "", "data", "=", "{", "}", "\n", "if", "self", ".", "opt", ".", "sentence_embed", ":", "\n", "            ", "data", "[", "'sen_embed'", "]", "=", "sen_embed_batch", "\n", "\n", "", "data", "[", "'images'", "]", "=", "img_batch", "\n", "data", "[", "'labels'", "]", "=", "label_batch", "\n", "data", "[", "'masks'", "]", "=", "mask_batch", "\n", "data", "[", "'bounds'", "]", "=", "{", "'it_pos_now'", ":", "self", ".", "iterators", "[", "split", "]", ",", "'it_max'", ":", "len", "(", "split_ix", ")", "}", "\n", "data", "[", "'infos'", "]", "=", "infos", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.__call__": [[225, 227], ["dataloader.DataLoader.get_batch_one"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.get_batch_one"], ["", "def", "__call__", "(", "self", ",", "split", ")", ":", "\n", "        ", "return", "self", ".", "get_batch_one", "(", "split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.get_batch": [[229, 351], ["numpy.zeros", "numpy.zeros", "len", "[].tolist", "numpy.array", "enumerate", "numpy.array", "enumerate", "infos.append", "list", "len", "numpy.random.shuffle", "len", "[].tolist.extend", "dataloader.DataLoader.sen_embed_keys.index", "joblib.Parallel", "map", "numpy.array", "dataloader.get_img", "numpy.zeros", "range", "random.randint", "map", "len", "enumerate", "joblib.delayed", "vars().get", "vars().get", "numpy.pad", "random.randint", "numpy.pad", "zip", "vars", "vars", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.get_img"], ["", "def", "get_batch", "(", "self", ",", "split", ",", "batch_size", "=", "None", ")", ":", "\n", "        ", "split_ix", "=", "self", ".", "split_ix", "[", "split", "]", "\n", "batch_size", "=", "batch_size", "or", "self", ".", "batch_size", "\n", "\n", "# img_batch = np.ndarray([batch_size, 3, 256, 256], dtype='float32')", "\n", "label_batch", "=", "np", ".", "zeros", "(", "[", "batch_size", "*", "self", ".", "seq_per_img", ",", "self", ".", "seq_length", "+", "2", "]", ",", "dtype", "=", "'int'", ")", "\n", "mask_batch", "=", "np", ".", "zeros", "(", "[", "batch_size", "*", "self", ".", "seq_per_img", ",", "self", ".", "seq_length", "+", "2", "]", ",", "dtype", "=", "'float32'", ")", "\n", "# if self.opt.sentence_embed:", "\n", "#     sen_embed_batch = np.zeros(", "\n", "#         [batch_size * self.seq_per_img, self.opt.sentence_length + 1, self.opt.sentence_embed_size],", "\n", "#         dtype='float32')", "\n", "max_index", "=", "len", "(", "split_ix", ")", "\n", "wrapped", "=", "False", "\n", "infos", "=", "[", "]", "\n", "# temp_img_h5 = tables.open_file(self.opt.input_image_h5, mode='r')", "\n", "# Parallel(n_jobs=self.num_thread, verbose=0, backend=\"loky\")(map(delayed(self.get_batch_one),", "\n", "#                                                                           range(self.batch_size)))", "\n", "batch_ids", "=", "self", ".", "shuffle", "[", "split", "]", "[", "self", ".", "iterators", "[", "split", "]", ":", "self", ".", "iterators", "[", "split", "]", "+", "batch_size", "]", ".", "tolist", "(", ")", "\n", "self", ".", "iterators", "[", "split", "]", "+=", "batch_size", "\n", "if", "self", ".", "iterators", "[", "split", "]", ">=", "max_index", ":", "\n", "            ", "if", "split", "==", "'train'", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "shuffle", "[", "split", "]", ")", "\n", "", "self", ".", "iterators", "[", "split", "]", "=", "0", "\n", "wrapped", "=", "True", "\n", "if", "len", "(", "batch_ids", ")", "!=", "batch_size", ":", "\n", "                ", "leftover", "=", "batch_size", "-", "len", "(", "batch_ids", ")", "\n", "batch_ids", ".", "extend", "(", "self", ".", "shuffle", "[", "split", "]", "[", "self", ".", "iterators", "[", "split", "]", ":", "self", ".", "iterators", "[", "split", "]", "+", "leftover", "]", ")", "\n", "self", ".", "iterators", "[", "split", "]", "+=", "leftover", "\n", "\n", "#combine", "\n", "", "", "if", "self", ".", "opt", ".", "sentence_embed", ":", "\n", "            ", "keys", "=", "[", "self", ".", "id_to_keys", "[", "self", ".", "info", "[", "'images'", "]", "[", "i", "]", "[", "'id'", "]", "]", "for", "i", ",", "b_id", "in", "enumerate", "(", "batch_ids", ")", "]", "\n", "sen_ixs", "=", "[", "self", ".", "sen_embed_keys", ".", "index", "(", "key", ")", "for", "key", "in", "keys", "]", "\n", "\n", "combined", "=", "Parallel", "(", "n_jobs", "=", "self", ".", "num_thread", ",", "verbose", "=", "0", ",", "backend", "=", "\"loky\"", ")", "(", "\n", "map", "(", "delayed", "(", "combine", ")", ",", "[", "(", "self", ".", "opt", ".", "input_image_h5", ",", "split_ix", "[", "b_id", "]", ",", "self", ".", "opt", ".", "sentence_embed", ",", "s", "\n", ")", "for", "b_id", ",", "s", "in", "zip", "(", "batch_ids", ",", "sen_ixs", ")", "]", ")", ")", "\n", "img_batch", "=", "[", "c", "[", "0", "]", "for", "c", "in", "combined", "]", "\n", "sen", "=", "[", "c", "[", "1", "]", "for", "c", "in", "combined", "]", "\n", "if", "vars", "(", "self", ".", "opt", ")", ".", "get", "(", "'sentence_embed_method'", ",", "None", ")", "==", "'fc'", "or", "vars", "(", "self", ".", "opt", ")", ".", "get", "(", "'sentence_embed_method'", ",", "None", ")", "==", "'fc_max'", ":", "\n", "                ", "sen_embed_batch", "=", "[", "np", ".", "pad", "(", "a", ",", "(", "(", "0", ",", "self", ".", "opt", ".", "sentence_length", "+", "1", "-", "len", "(", "a", ")", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\n", "'constant'", ",", "constant_values", "=", "0", ")", "for", "a", "in", "sen", "]", "\n", "", "else", ":", "\n", "                ", "sen_embed_batch", "=", "[", "np", ".", "pad", "(", "a", ",", "(", "(", "0", ",", "self", ".", "opt", ".", "sentence_length", "-", "len", "(", "a", ")", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\n", "'constant'", ",", "constant_values", "=", "0", ")", "if", "len", "(", "a", ")", "<", "self", ".", "opt", ".", "sentence_length", "else", "a", "[", ":", "self", ".", "opt", ".", "sentence_length", "]", "for", "a", "in", "sen", "]", "\n", "sen_embed_batch", "=", "np", ".", "array", "(", "sen_embed_batch", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "", "else", ":", "\n", "# combined = Parallel(n_jobs=self.num_thread, verbose=0, backend=\"loky\")(", "\n", "#     map(delayed(get_img), [(self.opt.input_image_h5, split_ix[b_id]) for b_id in batch_ids]))", "\n", "            ", "img_batch", "=", "[", "get_img", "(", "(", "self", ".", "opt", ".", "input_image_h5", ",", "split_ix", "[", "b_id", "]", ")", ")", "for", "b_id", "in", "batch_ids", "]", "\n", "\n", "", "img_batch", "=", "np", ".", "array", "(", "img_batch", ")", "\n", "\n", "for", "i", ",", "b_id", "in", "enumerate", "(", "batch_ids", ")", ":", "\n", "# for i in range(batch_size):", "\n", "#     ri = self.iterators[split]", "\n", "#     ri_next = ri + 1", "\n", "#     if ri_next >= max_index:", "\n", "#         np.random.shuffle(self.shuffle[split])", "\n", "#         ri_next = 0", "\n", "#         wrapped = True", "\n", "#     self.iterators[split] = ri_next", "\n", "#     ix = split_ix[ri]", "\n", "            ", "ix", "=", "split_ix", "[", "b_id", "]", "\n", "\n", "# fetch image", "\n", "# img = self.load_image(self.image_info[ix]['filename'])", "\n", "# img = np.array(self.h5_image_file['images'][ix, :, :, :])", "\n", "# img = np.array(self.h5_image_file.root.images[ix, :, :, :])", "\n", "# img_batch[i] = preprocess(torch.from_numpy(img.astype('float32')/255.0)).numpy()", "\n", "\n", "# fetch the sequence labels", "\n", "ix1", "=", "self", ".", "label_start_ix", "[", "ix", "]", "-", "1", "#label_start_ix starts from 1", "\n", "ix2", "=", "self", ".", "label_end_ix", "[", "ix", "]", "-", "1", "\n", "ncap", "=", "ix2", "-", "ix1", "+", "1", "# number of captions available for this image", "\n", "assert", "ncap", ">", "0", ",", "'an image does not have any label. this can be handled but right now isn\\'t'", "\n", "\n", "if", "ncap", "<", "self", ".", "seq_per_img", ":", "\n", "# we need to subsample (with replacement)", "\n", "                ", "seq", "=", "np", ".", "zeros", "(", "[", "self", ".", "seq_per_img", ",", "self", ".", "seq_length", "]", ",", "dtype", "=", "'int'", ")", "\n", "for", "q", "in", "range", "(", "self", ".", "seq_per_img", ")", ":", "\n", "                    ", "ixl", "=", "random", ".", "randint", "(", "ix1", ",", "ix2", ")", "\n", "# seq[q, :] = self.h5_label_file['labels'][ixl, :self.seq_length]", "\n", "seq", "[", "q", ",", ":", "]", "=", "self", ".", "h5_label_file", ".", "root", ".", "labels", "[", "ixl", ",", ":", "self", ".", "seq_length", "]", "\n", "", "", "else", ":", "\n", "                ", "ixl", "=", "random", ".", "randint", "(", "ix1", ",", "ix2", "-", "self", ".", "seq_per_img", "+", "1", ")", "\n", "# seq = self.h5_label_file['labels'][ixl: ixl + self.seq_per_img, :self.seq_length]", "\n", "seq", "=", "self", ".", "h5_label_file", ".", "root", ".", "labels", "[", "ixl", ":", "ixl", "+", "self", ".", "seq_per_img", ",", ":", "self", ".", "seq_length", "]", "\n", "\n", "", "label_batch", "[", "i", "*", "self", ".", "seq_per_img", ":", "(", "i", "+", "1", ")", "*", "self", ".", "seq_per_img", ",", "1", ":", "self", ".", "seq_length", "+", "1", "]", "=", "seq", "\n", "\n", "# record associated info as well", "\n", "info_dict", "=", "{", "}", "\n", "info_dict", "[", "'id'", "]", "=", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'id'", "]", "\n", "info_dict", "[", "'file_path'", "]", "=", "self", ".", "info", "[", "'images'", "]", "[", "ix", "]", "[", "'file_path'", "]", "\n", "# fetch sen_embed", "\n", "# if self.opt.sentence_embed:", "\n", "#     # for q in range(self.seq_per_img):", "\n", "#     key = self.id_to_keys[info_dict['id']]", "\n", "#     sen_ix = self.sen_embed_keys.index(key)", "\n", "#     sen_embed = np.stack(self.h5_sen_embed_file['average'][sen_ix, :]).transpose()", "\n", "#     # sen_embed = np.stack(self.h5_sen_embed_file.root.average[sen_ix, :]).transpose()", "\n", "#     sen_embed_batch[i, :len(sen_embed), :] = sen_embed", "\n", "infos", ".", "append", "(", "info_dict", ")", "\n", "\n", "# generate mask", "\n", "", "nonzeros", "=", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "x", ":", "(", "x", "!=", "0", ")", ".", "sum", "(", ")", "+", "2", ",", "label_batch", ")", ")", ")", "\n", "for", "ix", ",", "row", "in", "enumerate", "(", "mask_batch", ")", ":", "\n", "            ", "row", "[", ":", "nonzeros", "[", "ix", "]", "]", "=", "1", "\n", "\n", "", "data", "=", "{", "}", "\n", "if", "self", ".", "opt", ".", "sentence_embed", ":", "\n", "            ", "data", "[", "'sen_embed'", "]", "=", "sen_embed_batch", "\n", "\n", "", "data", "[", "'images'", "]", "=", "img_batch", "\n", "data", "[", "'labels'", "]", "=", "label_batch", "\n", "data", "[", "'masks'", "]", "=", "mask_batch", "\n", "data", "[", "'bounds'", "]", "=", "{", "'it_pos_now'", ":", "self", ".", "iterators", "[", "split", "]", ",", "'it_max'", ":", "len", "(", "split_ix", ")", ",", "'wrapped'", ":", "wrapped", "}", "\n", "data", "[", "'infos'", "]", "=", "infos", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.reset_iterator": [[352, 354], ["None"], "methods", ["None"], ["", "def", "reset_iterator", "(", "self", ",", "split", ")", ":", "\n", "        ", "self", ".", "iterators", "[", "split", "]", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.func": [[30, 32], ["dataloader.DataLoader.get_batch_one"], "function", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.DataLoader.get_batch_one"], ["def", "func", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "DataLoader", ".", "get_batch_one", "(", "args", ",", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.get_img": [[33, 40], ["tables.open_file", "numpy.array", "preprocess().numpy", "tables.open_file.close", "preprocess", "torch.from_numpy", "np.array.astype"], "function", ["None"], ["", "def", "get_img", "(", "args", ")", ":", "\n", "    ", "h5_image_file", ",", "ix", "=", "args", "\n", "temp_h5", "=", "tables", ".", "open_file", "(", "h5_image_file", ",", "mode", "=", "'r'", ")", "\n", "img", "=", "np", ".", "array", "(", "temp_h5", ".", "root", ".", "images", "[", "ix", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "img_batch", "=", "preprocess", "(", "torch", ".", "from_numpy", "(", "img", ".", "astype", "(", "'float32'", ")", "/", "255.0", ")", ")", ".", "numpy", "(", ")", "\n", "temp_h5", ".", "close", "(", ")", "\n", "return", "img_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.get_sen_embed": [[41, 47], ["h5py.File", "numpy.stack().transpose", "h5py.File.close", "numpy.stack"], "function", ["None"], ["", "def", "get_sen_embed", "(", "args", ")", ":", "\n", "    ", "h5_sen_file", ",", "sen_ix", "=", "args", "\n", "temp_h5", "=", "h5py", ".", "File", "(", "h5_sen_file", ",", "mode", "=", "'r'", ")", "\n", "sen_embed", "=", "np", ".", "stack", "(", "temp_h5", "[", "'average'", "]", "[", "sen_ix", ",", ":", "]", ")", ".", "transpose", "(", ")", "\n", "temp_h5", ".", "close", "(", ")", "\n", "return", "sen_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.combine": [[48, 55], ["dataloader.get_img", "dataloader.get_sen_embed"], "function", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.get_img", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.None.dataloader.get_sen_embed"], ["", "def", "combine", "(", "args", ")", ":", "\n", "    ", "h5_image_file", ",", "ix", ",", "h5_sen_file", ",", "sen_ix", "=", "args", "\n", "arg1", "=", "h5_image_file", ",", "ix", "\n", "arg2", "=", "h5_sen_file", ",", "sen_ix", "\n", "img", "=", "get_img", "(", "arg1", ")", "\n", "sen", "=", "get_sen_embed", "(", "arg2", ")", "\n", "return", "img", ",", "sen", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_images.main": [[40, 71], ["json.load", "random.seed", "len", "h5py.File", "h5py.File.create_dataset", "enumerate", "h5py.File.close", "print", "open", "scipy.misc.imread", "np.concatenate.transpose", "os.path.join", "scipy.misc.imresize", "len", "numpy.concatenate", "print", "print"], "function", ["None"], ["def", "main", "(", "params", ")", ":", "\n", "\n", "  ", "imgs", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_json'", "]", ",", "'r'", ")", ")", "\n", "imgs", "=", "imgs", "[", "'images'", "]", "\n", "\n", "seed", "(", "123", ")", "# make reproducible", "\n", "\n", "# create output h5 file", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "f", "=", "h5py", ".", "File", "(", "params", "[", "'output_h5'", "]", "+", "'_image.h5'", ",", "\"w\"", ")", "\n", "dset", "=", "f", ".", "create_dataset", "(", "\"images\"", ",", "(", "N", ",", "3", ",", "256", ",", "256", ")", ",", "dtype", "=", "'uint8'", ")", "# space for resized images", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "# load the image", "\n", "    ", "I", "=", "imread", "(", "os", ".", "path", ".", "join", "(", "params", "[", "'images_root'", "]", ",", "img", "[", "'file_path'", "]", ")", ")", "\n", "try", ":", "\n", "        ", "Ir", "=", "imresize", "(", "I", ",", "(", "256", ",", "256", ")", ")", "\n", "", "except", ":", "\n", "        ", "print", "(", "'failed resizing image %s - see http://git.io/vBIE0'", "%", "(", "img", "[", "'filepath'", "]", ",", ")", ")", "\n", "raise", "\n", "# handle grayscale input images", "\n", "", "if", "len", "(", "Ir", ".", "shape", ")", "==", "2", ":", "\n", "      ", "Ir", "=", "Ir", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", "\n", "Ir", "=", "np", ".", "concatenate", "(", "(", "Ir", ",", "Ir", ",", "Ir", ")", ",", "axis", "=", "2", ")", "\n", "# and swap order of axes from (256,256,3) to (3,256,256)", "\n", "", "Ir", "=", "Ir", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "\n", "# write to h5", "\n", "dset", "[", "i", "]", "=", "Ir", "\n", "if", "i", "%", "1000", "==", "0", ":", "\n", "      ", "print", "(", "'processing %d/%d (%.2f%% done)'", "%", "(", "i", ",", "N", ",", "i", "*", "100.0", "/", "N", ")", ")", "\n", "", "", "f", ".", "close", "(", ")", "\n", "print", "(", "'wrote '", ",", "params", "[", "'output_h5'", "]", "+", "'_image.h5'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_labels_articles_captions.build_vocab": [[43, 94], ["sorted", "print", "print", "sum", "print", "sum", "print", "print", "print", "max", "print", "print", "sum", "range", "counts.values", "sent_lengths.keys", "sent_lengths.values", "print", "print", "vocab.append", "map", "counts.items", "counts.items", "len", "img[].append", "counts.items", "len", "len", "len", "sent_lengths.get", "counts.get", "len", "sent_lengths.get", "len", "counts.get", "sent_lengths.get"], "function", ["None"], ["def", "build_vocab", "(", "imgs", ",", "params", ")", ":", "\n", "  ", "count_thr", "=", "params", "[", "'word_count_threshold'", "]", "\n", "\n", "# count up the number of words", "\n", "counts", "=", "{", "}", "\n", "for", "img", "in", "imgs", ":", "\n", "    ", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "for", "w", "in", "sent", "[", "'tokens'", "]", ":", "\n", "        ", "counts", "[", "w", "]", "=", "counts", ".", "get", "(", "w", ",", "0", ")", "+", "1", "\n", "", "", "", "cw", "=", "sorted", "(", "[", "(", "count", ",", "w", ")", "for", "w", ",", "count", "in", "counts", ".", "items", "(", ")", "]", ",", "reverse", "=", "True", ")", "\n", "print", "(", "'top words and their counts:'", ")", "\n", "print", "(", "'\\n'", ".", "join", "(", "map", "(", "str", ",", "cw", "[", ":", "20", "]", ")", ")", ")", "\n", "\n", "# print some stats", "\n", "total_words", "=", "sum", "(", "counts", ".", "values", "(", ")", ")", "\n", "print", "(", "'total words:'", ",", "total_words", ")", "\n", "bad_words", "=", "[", "w", "for", "w", ",", "n", "in", "counts", ".", "items", "(", ")", "if", "n", "<=", "count_thr", "]", "\n", "vocab", "=", "[", "w", "for", "w", ",", "n", "in", "counts", ".", "items", "(", ")", "if", "n", ">", "count_thr", "]", "\n", "bad_count", "=", "sum", "(", "counts", "[", "w", "]", "for", "w", "in", "bad_words", ")", "\n", "print", "(", "'number of bad words: %d/%d = %.2f%%'", "%", "(", "len", "(", "bad_words", ")", ",", "len", "(", "counts", ")", ",", "len", "(", "bad_words", ")", "*", "100.0", "/", "len", "(", "counts", ")", ")", ")", "\n", "print", "(", "'number of words in vocab would be %d'", "%", "(", "len", "(", "vocab", ")", ",", ")", ")", "\n", "print", "(", "'number of UNKs: %d/%d = %.2f%%'", "%", "(", "bad_count", ",", "total_words", ",", "bad_count", "*", "100.0", "/", "total_words", ")", ")", "\n", "\n", "# lets look at the distribution of lengths as well", "\n", "sent_lengths", "=", "{", "}", "\n", "for", "img", "in", "imgs", ":", "\n", "    ", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "txt", "=", "sent", "[", "'tokens'", "]", "\n", "nw", "=", "len", "(", "txt", ")", "\n", "sent_lengths", "[", "nw", "]", "=", "sent_lengths", ".", "get", "(", "nw", ",", "0", ")", "+", "1", "\n", "", "", "max_len", "=", "max", "(", "sent_lengths", ".", "keys", "(", ")", ")", "\n", "print", "(", "'max length sentence in raw data: '", ",", "max_len", ")", "\n", "print", "(", "'sentence length distribution (count, number of words):'", ")", "\n", "sum_len", "=", "sum", "(", "sent_lengths", ".", "values", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "max_len", "+", "1", ")", ":", "\n", "    ", "print", "(", "'%2d: %10d   %f%%'", "%", "(", "i", ",", "sent_lengths", ".", "get", "(", "i", ",", "0", ")", ",", "sent_lengths", ".", "get", "(", "i", ",", "0", ")", "*", "100.0", "/", "sum_len", ")", ")", "\n", "\n", "# lets now produce the final annotations", "\n", "", "if", "bad_count", ">", "0", ":", "\n", "# additional special UNK token we will use below to map infrequent words to", "\n", "    ", "print", "(", "'inserting the special UNK token'", ")", "\n", "vocab", ".", "append", "(", "'UNK'", ")", "\n", "\n", "", "for", "img", "in", "imgs", ":", "\n", "    ", "img", "[", "'final_captions'", "]", "=", "[", "]", "\n", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "txt", "=", "sent", "[", "'tokens'", "]", "\n", "caption", "=", "[", "w", "if", "counts", ".", "get", "(", "w", ",", "0", ")", ">", "count_thr", "else", "'UNK'", "for", "w", "in", "txt", "]", "\n", "img", "[", "'final_captions'", "]", ".", "append", "(", "caption", ")", "\n", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_labels_articles_captions.encode_captions": [[95, 138], ["len", "sum", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.concatenate", "numpy.all", "print", "len", "numpy.zeros", "enumerate", "label_arrays.append", "len", "min", "enumerate", "len"], "function", ["None"], ["", "def", "encode_captions", "(", "imgs", ",", "params", ",", "wtoi", ")", ":", "\n", "  ", "\"\"\" \n  encode all captions into one large array, which will be 1-indexed.\n  also produces label_start_ix and label_end_ix which store 1-indexed \n  and inclusive (Lua-style) pointers to the first and last caption for\n  each image in the dataset.\n  \"\"\"", "\n", "\n", "max_length", "=", "params", "[", "'max_length'", "]", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "M", "=", "sum", "(", "len", "(", "img", "[", "'final_captions'", "]", ")", "for", "img", "in", "imgs", ")", "# total number of captions", "\n", "\n", "label_arrays", "=", "[", "]", "\n", "label_start_ix", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "# note: these will be one-indexed", "\n", "label_end_ix", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "\n", "label_length", "=", "np", ".", "zeros", "(", "M", ",", "dtype", "=", "'uint32'", ")", "\n", "caption_counter", "=", "0", "\n", "counter", "=", "1", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "    ", "n", "=", "len", "(", "img", "[", "'final_captions'", "]", ")", "\n", "assert", "n", ">", "0", ",", "'error: some image has no captions'", "\n", "\n", "Li", "=", "np", ".", "zeros", "(", "(", "n", ",", "max_length", ")", ",", "dtype", "=", "'uint32'", ")", "\n", "for", "j", ",", "s", "in", "enumerate", "(", "img", "[", "'final_captions'", "]", ")", ":", "\n", "      ", "label_length", "[", "caption_counter", "]", "=", "min", "(", "max_length", ",", "len", "(", "s", ")", ")", "# record the length of this sequence", "\n", "caption_counter", "+=", "1", "\n", "for", "k", ",", "w", "in", "enumerate", "(", "s", ")", ":", "\n", "        ", "if", "k", "<", "max_length", ":", "\n", "          ", "Li", "[", "j", ",", "k", "]", "=", "wtoi", "[", "w", "]", "\n", "\n", "# note: word indices are 1-indexed, and captions are padded with zeros", "\n", "", "", "", "label_arrays", ".", "append", "(", "Li", ")", "\n", "label_start_ix", "[", "i", "]", "=", "counter", "\n", "label_end_ix", "[", "i", "]", "=", "counter", "+", "n", "-", "1", "\n", "\n", "counter", "+=", "n", "\n", "\n", "", "L", "=", "np", ".", "concatenate", "(", "label_arrays", ",", "axis", "=", "0", ")", "# put all the labels together", "\n", "assert", "L", ".", "shape", "[", "0", "]", "==", "M", ",", "'lengths don\\'t match? that\\'s weird'", "\n", "assert", "np", ".", "all", "(", "label_length", ">", "0", ")", ",", "'error: some caption had no words?'", "\n", "\n", "print", "(", "'encoded captions to array of size '", ",", "L", ".", "shape", ")", "\n", "return", "L", ",", "label_start_ix", ",", "label_end_ix", ",", "label_length", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_labels_articles_captions.main": [[139, 178], ["json.load", "random.seed", "prepro_labels_articles_captions.build_vocab", "prepro_labels_articles_captions.encode_captions", "len", "h5py.File", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.close", "enumerate", "json.dump", "print", "open", "out[].append", "open", "enumerate", "enumerate", "os.path.join"], "function", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_labels.build_vocab", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_labels.encode_captions"], ["", "def", "main", "(", "params", ")", ":", "\n", "\n", "  ", "imgs", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_json'", "]", ",", "'r'", ")", ")", "\n", "imgs", "=", "imgs", "[", "'images'", "]", "\n", "\n", "seed", "(", "123", ")", "# make reproducible", "\n", "\n", "# create the vocab", "\n", "vocab", "=", "build_vocab", "(", "imgs", ",", "params", ")", "\n", "itow", "=", "{", "i", "+", "1", ":", "w", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "# a 1-indexed vocab translation table", "\n", "wtoi", "=", "{", "w", ":", "i", "+", "1", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "# inverse table", "\n", "\n", "# encode captions in large arrays, ready to ship to hdf5 file", "\n", "L", ",", "label_start_ix", ",", "label_end_ix", ",", "label_length", "=", "encode_captions", "(", "imgs", ",", "params", ",", "wtoi", ")", "\n", "\n", "# create output h5 file", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "f_lb", "=", "h5py", ".", "File", "(", "params", "[", "'output_h5'", "]", "+", "'_label.h5'", ",", "\"w\"", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"labels\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "L", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_start_ix\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_start_ix", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_end_ix\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_end_ix", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_length\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_length", ")", "\n", "f_lb", ".", "close", "(", ")", "\n", "\n", "# create output json file", "\n", "out", "=", "{", "}", "\n", "out", "[", "'ix_to_word'", "]", "=", "itow", "# encode the (1-indexed) vocab", "\n", "out", "[", "'images'", "]", "=", "[", "]", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "\n", "    ", "jimg", "=", "{", "}", "\n", "jimg", "[", "'split'", "]", "=", "img", "[", "'split'", "]", "\n", "if", "'filename'", "in", "img", ":", "jimg", "[", "'file_path'", "]", "=", "os", ".", "path", ".", "join", "(", "img", "[", "'filepath'", "]", ",", "img", "[", "'filename'", "]", ")", "# copy it over, might need", "\n", "if", "'cocoid'", "in", "img", ":", "jimg", "[", "'id'", "]", "=", "img", "[", "'cocoid'", "]", "# copy over & mantain an id, if present (e.g. coco ids, useful)", "\n", "\n", "out", "[", "'images'", "]", ".", "append", "(", "jimg", ")", "\n", "\n", "", "json", ".", "dump", "(", "out", ",", "open", "(", "params", "[", "'output_json'", "]", ",", "'w'", ")", ")", "\n", "print", "(", "'wrote '", ",", "params", "[", "'output_json'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_tbb.open_json": [[11, 14], ["open", "json.load"], "function", ["None"], ["def", "open_json", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_tbb.save_h5": [[15, 22], ["h5py.File", "h5py.special_dtype", "h5py.File.create_dataset", "tqdm.tqdm", "h5py.File.close", "enumerate", "numpy.dtype", "len"], "function", ["None"], ["", "", "def", "save_h5", "(", "file_save", ",", "data", ")", ":", "\n", "    ", "f_lb", "=", "h5py", ".", "File", "(", "file_save", ",", "\"w\"", ")", "\n", "dt", "=", "h5py", ".", "special_dtype", "(", "vlen", "=", "np", ".", "dtype", "(", "'float64'", ")", ")", "\n", "ds", "=", "f_lb", ".", "create_dataset", "(", "'average'", ",", "(", "len", "(", "data", ")", ",", "300", ",", ")", ",", "dtype", "=", "dt", ")", "\n", "for", "i", ",", "d", "in", "tqdm", ".", "tqdm", "(", "enumerate", "(", "data", ")", ")", ":", "\n", "        ", "ds", "[", "i", "]", "=", "d", "\n", "", "f_lb", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_labels.build_vocab": [[43, 94], ["sorted", "print", "print", "sum", "print", "sum", "print", "print", "print", "max", "print", "print", "sum", "range", "counts.values", "sent_lengths.keys", "sent_lengths.values", "print", "print", "vocab.append", "map", "counts.items", "counts.items", "len", "img[].append", "counts.items", "len", "len", "len", "sent_lengths.get", "counts.get", "len", "sent_lengths.get", "len", "counts.get", "sent_lengths.get"], "function", ["None"], ["def", "build_vocab", "(", "imgs", ",", "params", ")", ":", "\n", "  ", "count_thr", "=", "params", "[", "'word_count_threshold'", "]", "\n", "\n", "# count up the number of words", "\n", "counts", "=", "{", "}", "\n", "for", "img", "in", "imgs", ":", "\n", "    ", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "for", "w", "in", "sent", "[", "'tokens'", "]", ":", "\n", "        ", "counts", "[", "w", "]", "=", "counts", ".", "get", "(", "w", ",", "0", ")", "+", "1", "\n", "", "", "", "cw", "=", "sorted", "(", "[", "(", "count", ",", "w", ")", "for", "w", ",", "count", "in", "counts", ".", "items", "(", ")", "]", ",", "reverse", "=", "True", ")", "\n", "print", "(", "'top words and their counts:'", ")", "\n", "print", "(", "'\\n'", ".", "join", "(", "map", "(", "str", ",", "cw", "[", ":", "20", "]", ")", ")", ")", "\n", "\n", "# print some stats", "\n", "total_words", "=", "sum", "(", "counts", ".", "values", "(", ")", ")", "\n", "print", "(", "'total words:'", ",", "total_words", ")", "\n", "bad_words", "=", "[", "w", "for", "w", ",", "n", "in", "counts", ".", "items", "(", ")", "if", "n", "<=", "count_thr", "]", "\n", "vocab", "=", "[", "w", "for", "w", ",", "n", "in", "counts", ".", "items", "(", ")", "if", "n", ">", "count_thr", "]", "\n", "bad_count", "=", "sum", "(", "counts", "[", "w", "]", "for", "w", "in", "bad_words", ")", "\n", "print", "(", "'number of bad words: %d/%d = %.2f%%'", "%", "(", "len", "(", "bad_words", ")", ",", "len", "(", "counts", ")", ",", "len", "(", "bad_words", ")", "*", "100.0", "/", "len", "(", "counts", ")", ")", ")", "\n", "print", "(", "'number of words in vocab would be %d'", "%", "(", "len", "(", "vocab", ")", ",", ")", ")", "\n", "print", "(", "'number of UNKs: %d/%d = %.2f%%'", "%", "(", "bad_count", ",", "total_words", ",", "bad_count", "*", "100.0", "/", "total_words", ")", ")", "\n", "\n", "# lets look at the distribution of lengths as well", "\n", "sent_lengths", "=", "{", "}", "\n", "for", "img", "in", "imgs", ":", "\n", "    ", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "txt", "=", "sent", "[", "'tokens'", "]", "\n", "nw", "=", "len", "(", "txt", ")", "\n", "sent_lengths", "[", "nw", "]", "=", "sent_lengths", ".", "get", "(", "nw", ",", "0", ")", "+", "1", "\n", "", "", "max_len", "=", "max", "(", "sent_lengths", ".", "keys", "(", ")", ")", "\n", "print", "(", "'max length sentence in raw data: '", ",", "max_len", ")", "\n", "print", "(", "'sentence length distribution (count, number of words):'", ")", "\n", "sum_len", "=", "sum", "(", "sent_lengths", ".", "values", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "max_len", "+", "1", ")", ":", "\n", "    ", "print", "(", "'%2d: %10d   %f%%'", "%", "(", "i", ",", "sent_lengths", ".", "get", "(", "i", ",", "0", ")", ",", "sent_lengths", ".", "get", "(", "i", ",", "0", ")", "*", "100.0", "/", "sum_len", ")", ")", "\n", "\n", "# lets now produce the final annotations", "\n", "", "if", "bad_count", ">", "0", ":", "\n", "# additional special UNK token we will use below to map infrequent words to", "\n", "    ", "print", "(", "'inserting the special UNK token'", ")", "\n", "vocab", ".", "append", "(", "'UNK'", ")", "\n", "\n", "", "for", "img", "in", "imgs", ":", "\n", "    ", "img", "[", "'final_captions'", "]", "=", "[", "]", "\n", "for", "sent", "in", "img", "[", "'sentences'", "]", ":", "\n", "      ", "txt", "=", "sent", "[", "'tokens'", "]", "\n", "caption", "=", "[", "w", "if", "counts", ".", "get", "(", "w", ",", "0", ")", ">", "count_thr", "else", "'UNK'", "for", "w", "in", "txt", "]", "\n", "img", "[", "'final_captions'", "]", ".", "append", "(", "caption", ")", "\n", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_labels.encode_captions": [[95, 142], ["len", "sum", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.concatenate", "numpy.all", "print", "len", "numpy.zeros", "enumerate", "label_arrays.append", "len", "min", "enumerate", "len"], "function", ["None"], ["", "def", "encode_captions", "(", "imgs", ",", "params", ",", "wtoi", ")", ":", "\n", "  ", "\"\"\" \n  encode all captions into one large array, which will be 1-indexed.\n  also produces label_start_ix and label_end_ix which store 1-indexed \n  and inclusive (Lua-style) pointers to the first and last caption for\n  each image in the dataset.\n  \"\"\"", "\n", "\n", "max_length", "=", "params", "[", "'max_length'", "]", "\n", "# min_length = params['min_length']", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "M", "=", "sum", "(", "len", "(", "img", "[", "'final_captions'", "]", ")", "for", "img", "in", "imgs", ")", "# total number of captions", "\n", "\n", "label_arrays", "=", "[", "]", "\n", "label_start_ix", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "# note: these will be one-indexed", "\n", "label_end_ix", "=", "np", ".", "zeros", "(", "N", ",", "dtype", "=", "'uint32'", ")", "\n", "label_length", "=", "np", ".", "zeros", "(", "M", ",", "dtype", "=", "'uint32'", ")", "\n", "caption_counter", "=", "0", "\n", "counter", "=", "1", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "    ", "n", "=", "len", "(", "img", "[", "'final_captions'", "]", ")", "\n", "assert", "n", ">", "0", ",", "'error: some image has no captions'", "\n", "\n", "Li", "=", "np", ".", "zeros", "(", "(", "n", ",", "max_length", ")", ",", "dtype", "=", "'uint32'", ")", "\n", "for", "j", ",", "s", "in", "enumerate", "(", "img", "[", "'final_captions'", "]", ")", ":", "\n", "# if len(s) <= min_length:", "\n", "#   continue", "\n", "# else:", "\n", "      ", "label_length", "[", "caption_counter", "]", "=", "min", "(", "max_length", ",", "len", "(", "s", ")", ")", "# record the length of this sequence", "\n", "caption_counter", "+=", "1", "\n", "for", "k", ",", "w", "in", "enumerate", "(", "s", ")", ":", "\n", "        ", "if", "k", "<", "max_length", ":", "\n", "          ", "Li", "[", "j", ",", "k", "]", "=", "wtoi", "[", "w", "]", "\n", "\n", "# note: word indices are 1-indexed, and captions are padded with zeros", "\n", "", "", "", "label_arrays", ".", "append", "(", "Li", ")", "\n", "label_start_ix", "[", "i", "]", "=", "counter", "\n", "label_end_ix", "[", "i", "]", "=", "counter", "+", "n", "-", "1", "\n", "\n", "counter", "+=", "n", "\n", "\n", "", "L", "=", "np", ".", "concatenate", "(", "label_arrays", ",", "axis", "=", "0", ")", "# put all the labels together", "\n", "assert", "L", ".", "shape", "[", "0", "]", "==", "M", ",", "'lengths don\\'t match? that\\'s weird'", "\n", "assert", "np", ".", "all", "(", "label_length", ">", "0", ")", ",", "'error: some caption had no words?'", "\n", "\n", "print", "(", "'encoded captions to array of size '", ",", "L", ".", "shape", ")", "\n", "return", "L", ",", "label_start_ix", ",", "label_end_ix", ",", "label_length", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_labels.main": [[143, 182], ["json.load", "random.seed", "prepro_labels.build_vocab", "prepro_labels.encode_captions", "len", "h5py.File", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.create_dataset", "h5py.File.close", "enumerate", "json.dump", "print", "open", "out[].append", "open", "enumerate", "enumerate", "os.path.join"], "function", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_labels.build_vocab", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_labels.encode_captions"], ["", "def", "main", "(", "params", ")", ":", "\n", "\n", "  ", "imgs", "=", "json", ".", "load", "(", "open", "(", "params", "[", "'input_json'", "]", ",", "'r'", ")", ")", "\n", "# imgs = imgs['images']", "\n", "\n", "seed", "(", "123", ")", "# make reproducible", "\n", "\n", "# create the vocab", "\n", "vocab", "=", "build_vocab", "(", "imgs", ",", "params", ")", "\n", "itow", "=", "{", "i", "+", "1", ":", "w", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "# a 1-indexed vocab translation table", "\n", "wtoi", "=", "{", "w", ":", "i", "+", "1", "for", "i", ",", "w", "in", "enumerate", "(", "vocab", ")", "}", "# inverse table", "\n", "\n", "# encode captions in large arrays, ready to ship to hdf5 file", "\n", "L", ",", "label_start_ix", ",", "label_end_ix", ",", "label_length", "=", "encode_captions", "(", "imgs", ",", "params", ",", "wtoi", ")", "\n", "\n", "# create output h5 file", "\n", "N", "=", "len", "(", "imgs", ")", "\n", "f_lb", "=", "h5py", ".", "File", "(", "params", "[", "'output_h5'", "]", "+", "'_label.h5'", ",", "\"w\"", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"labels\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "L", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_start_ix\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_start_ix", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_end_ix\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_end_ix", ")", "\n", "f_lb", ".", "create_dataset", "(", "\"label_length\"", ",", "dtype", "=", "'uint32'", ",", "data", "=", "label_length", ")", "\n", "f_lb", ".", "close", "(", ")", "\n", "\n", "# create output json file", "\n", "out", "=", "{", "}", "\n", "out", "[", "'ix_to_word'", "]", "=", "itow", "# encode the (1-indexed) vocab", "\n", "out", "[", "'images'", "]", "=", "[", "]", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "imgs", ")", ":", "\n", "\n", "    ", "jimg", "=", "{", "}", "\n", "jimg", "[", "'split'", "]", "=", "img", "[", "'split'", "]", "\n", "if", "'filename'", "in", "img", ":", "jimg", "[", "'file_path'", "]", "=", "os", ".", "path", ".", "join", "(", "img", "[", "'filepath'", "]", ",", "img", "[", "'filename'", "]", ")", "# copy it over, might need", "\n", "if", "'cocoid'", "in", "img", ":", "jimg", "[", "'id'", "]", "=", "img", "[", "'cocoid'", "]", "# copy over & mantain an id, if present (e.g. coco ids, useful)", "\n", "\n", "out", "[", "'images'", "]", ".", "append", "(", "jimg", ")", "\n", "\n", "", "json", ".", "dump", "(", "out", ",", "open", "(", "params", "[", "'output_json'", "]", ",", "'w'", ")", ")", "\n", "print", "(", "'wrote '", ",", "params", "[", "'output_json'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_wavg.open_json": [[10, 13], ["open", "json.load"], "function", ["None"], ["def", "open_json", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_wavg.get_word_vector": [[14, 17], ["nlp", "unicode"], "function", ["None"], ["", "", "def", "get_word_vector", "(", "sen", ")", ":", "\n", "    ", "sen", "=", "nlp", "(", "unicode", "(", "sen", ")", ")", "\n", "return", "sen", ".", "doc", ".", "vector", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_wavg.save_h5": [[18, 25], ["h5py.File", "h5py.special_dtype", "h5py.File.create_dataset", "tqdm.tqdm", "h5py.File.close", "enumerate", "numpy.dtype", "len"], "function", ["None"], ["", "def", "save_h5", "(", "file_save", ",", "data", ")", ":", "\n", "    ", "f_lb", "=", "h5py", ".", "File", "(", "file_save", ",", "\"w\"", ")", "\n", "dt", "=", "h5py", ".", "special_dtype", "(", "vlen", "=", "np", ".", "dtype", "(", "'float64'", ")", ")", "\n", "ds", "=", "f_lb", ".", "create_dataset", "(", "'average'", ",", "(", "len", "(", "data", ")", ",", "300", ",", ")", ",", "dtype", "=", "dt", ")", "\n", "for", "i", ",", "d", "in", "tqdm", ".", "tqdm", "(", "enumerate", "(", "data", ")", ")", ":", "\n", "        ", "ds", "[", "i", "]", "=", "d", "\n", "", "f_lb", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_wavg.getLog": [[27, 30], ["math.log"], "function", ["None"], ["", "def", "getLog", "(", "frequency", ",", "a", "=", "10", "**", "-", "3", ")", ":", "\n", "#     return 1/math.log(1.1) if frequency==1 else 1/math.log(frequency)", "\n", "    ", "return", "a", "/", "(", "a", "+", "math", ".", "log", "(", "1", "+", "frequency", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_wavg.get_vector_avg_weighted_full": [[50, 65], ["nlp", "unicode", "numpy.average", "count_full.get", "prepro_articles_wavg.getLog", "vectors.append", "weights.append"], "function", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_wavg.getLog"], ["", "def", "get_vector_avg_weighted_full", "(", "sent", ")", ":", "\n", "    ", "sent", "=", "nlp", "(", "unicode", "(", "sent", ")", ")", "\n", "vectors", "=", "[", "]", "\n", "weights", "=", "[", "]", "\n", "for", "token", "in", "sent", ":", "\n", "        ", "if", "token", ".", "has_vector", ":", "\n", "            ", "frequency", "=", "count_full", ".", "get", "(", "token", ".", "text", ",", "10", ")", "\n", "weight", "=", "getLog", "(", "frequency", ")", "\n", "vectors", ".", "append", "(", "token", ".", "vector", ")", "\n", "weights", ".", "append", "(", "weight", ")", "\n", "", "", "try", ":", "\n", "        ", "doc_vector", "=", "np", ".", "average", "(", "vectors", ",", "weights", "=", "weights", ",", "axis", "=", "0", ")", "\n", "", "except", ":", "\n", "        ", "doc_vector", "=", "sent", ".", "doc", ".", "vector", "\n", "", "return", "doc_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_wavg.get_weighted_avg_data": [[67, 83], ["tqdm.tqdm", "article.items", "data.append", "keys.append", "len", "numpy.zeros", "enumerate", "numpy.zeros", "enumerate", "numpy.average", "get_vector_avg_weighted", "get_vector_avg_weighted", "len", "sents.lower", "sents.lower", "get_vector_avg_weighted", "sents.lower"], "function", ["None"], ["", "def", "get_weighted_avg_data", "(", "article", ",", "get_vector_avg_weighted", ")", ":", "\n", "    ", "data", ",", "keys", "=", "[", "]", ",", "[", "]", "\n", "for", "k", ",", "v", "in", "tqdm", ".", "tqdm", "(", "article", ".", "items", "(", ")", ")", ":", "\n", "        ", "if", "len", "(", "v", ")", "<", "sen_len", "+", "1", ":", "\n", "            ", "temp", "=", "np", ".", "zeros", "(", "[", "300", ",", "len", "(", "v", ")", "]", ")", "\n", "for", "i", ",", "sents", "in", "enumerate", "(", "v", ")", ":", "\n", "                ", "temp", "[", ":", ",", "i", "]", "=", "get_vector_avg_weighted", "(", "sents", ".", "lower", "(", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "temp", "=", "np", ".", "zeros", "(", "[", "300", ",", "sen_len", "+", "1", "]", ")", "\n", "for", "i", ",", "sents", "in", "enumerate", "(", "v", "[", ":", "sen_len", "]", ")", ":", "\n", "                ", "temp", "[", ":", ",", "i", "]", "=", "get_vector_avg_weighted", "(", "sents", ".", "lower", "(", ")", ")", "\n", "", "temp", "[", ":", ",", "sen_len", "]", "=", "np", ".", "average", "(", "[", "get_vector_avg_weighted", "(", "sents", ".", "lower", "(", ")", ")", "for", "sents", "in", "v", "[", "sen_len", ":", "]", "]", ")", "\n", "", "data", ".", "append", "(", "temp", ")", "\n", "keys", ".", "append", "(", "k", ")", "\n", "\n", "", "return", "keys", ",", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_avg.open_json": [[8, 11], ["open", "json.load"], "function", ["None"], ["def", "open_json", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_avg.get_word_vector": [[12, 15], ["nlp", "unicode"], "function", ["None"], ["", "", "def", "get_word_vector", "(", "sen", ")", ":", "\n", "    ", "sen", "=", "nlp", "(", "unicode", "(", "sen", ")", ")", "\n", "return", "sen", ".", "doc", ".", "vector", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_avg.save_h5": [[16, 23], ["h5py.File", "h5py.special_dtype", "h5py.File.create_dataset", "tqdm.tqdm", "h5py.File.close", "enumerate", "numpy.dtype", "len"], "function", ["None"], ["", "def", "save_h5", "(", "file_save", ",", "data", ")", ":", "\n", "    ", "f_lb", "=", "h5py", ".", "File", "(", "file_save", ",", "\"w\"", ")", "\n", "dt", "=", "h5py", ".", "special_dtype", "(", "vlen", "=", "np", ".", "dtype", "(", "'float64'", ")", ")", "\n", "ds", "=", "f_lb", ".", "create_dataset", "(", "'average'", ",", "(", "len", "(", "data", ")", ",", "300", ",", ")", ",", "dtype", "=", "dt", ")", "\n", "for", "i", ",", "d", "in", "tqdm", ".", "tqdm", "(", "enumerate", "(", "data", ")", ")", ":", "\n", "        ", "ds", "[", "i", "]", "=", "d", "\n", "", "f_lb", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_avg.create_rep": [[24, 41], ["tqdm.tqdm", "art.items", "data.append", "keys.append", "len", "numpy.zeros", "enumerate", "numpy.zeros", "enumerate", "numpy.average", "prepro_articles_avg.get_word_vector", "prepro_articles_avg.get_word_vector", "len", "sents.lower", "sents.lower", "prepro_articles_avg.get_word_vector", "sents.lower"], "function", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_avg.get_word_vector", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_avg.get_word_vector", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.scripts.prepro_articles_avg.get_word_vector"], ["", "def", "create_rep", "(", "art", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "keys", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "tqdm", ".", "tqdm", "(", "art", ".", "items", "(", ")", ")", ":", "\n", "        ", "v", "=", "v", "[", "'sentence'", "]", "\n", "if", "len", "(", "v", ")", "<", "sen_len", "+", "1", ":", "\n", "            ", "temp", "=", "np", ".", "zeros", "(", "[", "300", ",", "len", "(", "v", ")", "]", ")", "\n", "for", "i", ",", "sents", "in", "enumerate", "(", "v", ")", ":", "\n", "                ", "temp", "[", ":", ",", "i", "]", "=", "get_word_vector", "(", "sents", ".", "lower", "(", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "temp", "=", "np", ".", "zeros", "(", "[", "300", ",", "sen_len", "+", "1", "]", ")", "\n", "for", "i", ",", "sents", "in", "enumerate", "(", "v", "[", ":", "sen_len", "]", ")", ":", "\n", "                ", "temp", "[", ":", ",", "i", "]", "=", "get_word_vector", "(", "sents", ".", "lower", "(", ")", ")", "\n", "", "temp", "[", ":", ",", "sen_len", "]", "=", "np", ".", "average", "(", "[", "get_word_vector", "(", "sents", ".", "lower", "(", ")", ")", "for", "sents", "in", "v", "[", "sen_len", ":", "]", "]", ")", "\n", "", "data", ".", "append", "(", "temp", ")", "\n", "keys", ".", "append", "(", "k", ")", "\n", "", "return", "keys", ",", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AttModel.__init__": [[28, 60], ["CaptionModel.CaptionModel.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AttModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "opt", ".", "vocab_size", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "#self.rnn_type = opt.rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "seq_length", "=", "opt", ".", "seq_length", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "# self.sentence_embed_size = opt.sentence_embed_size", "\n", "\n", "self", ".", "ss_prob", "=", "0.0", "# Schedule sampling probability", "\n", "\n", "self", ".", "embed", "=", "nn", ".", "Sequential", "(", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "\n", "self", ".", "fc_embed", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "fc_feat_size", ",", "self", ".", "rnn_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "\n", "self", ".", "att_embed", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "att_feat_size", ",", "self", ".", "rnn_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "\n", "# if opt.sentence_embed:", "\n", "#     self.sentence_embed = nn.Sequential(nn.Linear(self.sentence_embed_size, self.rnn_size),", "\n", "#                             nn.ReLU(),", "\n", "#                             nn.Dropout(self.drop_prob_lm))", "\n", "\n", "self", ".", "logit", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", "+", "1", ")", "\n", "self", ".", "ctx2att", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AttModel.init_hidden": [[61, 65], ["next", "Variable", "Variable", "AttModel.AttModel.parameters", "weight.new().zero_", "weight.new().zero_", "weight.new", "weight.new"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "data", "\n", "return", "(", "Variable", "(", "weight", ".", "new", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ")", ",", "\n", "Variable", "(", "weight", ".", "new", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AttModel.forward": [[66, 108], ["AttModel.AttModel.size", "AttModel.AttModel.init_hidden", "AttModel.AttModel.fc_embed", "AttModel.AttModel.att_embed", "AttModel.AttModel.view", "AttModel.AttModel.ctx2att", "p_att_feats.view.view.view", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AttModel.AttModel.view.view", "AttModel.AttModel.view.view", "AttModel.AttModel.embed", "AttModel.AttModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "outputs.append", "seq.size", "AttModel.AttModel.data.new().uniform_", "seq[].clone", "AttModel.AttModel.logit", "_.unsqueeze", "sample_mask.sum", "seq[].clone", "sample_mask.nonzero().view", "seq[].data.clone", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "Variable.index_copy_", "Variable", "seq[].data.sum", "AttModel.AttModel.view.size", "AttModel.AttModel.view.size", "AttModel.AttModel.data.new", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "sample_mask.nonzero", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden"], ["", "def", "forward", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "seq", ")", ":", "\n", "        ", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "\n", "# embed fc and att feats", "\n", "fc_feats", "=", "self", ".", "fc_embed", "(", "fc_feats", ")", "\n", "_att_feats", "=", "self", ".", "att_embed", "(", "att_feats", ".", "view", "(", "-", "1", ",", "self", ".", "att_feat_size", ")", ")", "\n", "att_feats", "=", "_att_feats", ".", "view", "(", "*", "(", "att_feats", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "rnn_size", ",", ")", ")", ")", "\n", "\n", "# Project the attention feats first to reduce memory and computation comsumptions.", "\n", "p_att_feats", "=", "self", ".", "ctx2att", "(", "att_feats", ".", "view", "(", "-", "1", ",", "self", ".", "rnn_size", ")", ")", "\n", "p_att_feats", "=", "p_att_feats", ".", "view", "(", "*", "(", "att_feats", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "att_hid_size", ",", ")", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "seq", ".", "size", "(", "1", ")", "-", "1", ")", ":", "\n", "            ", "if", "self", ".", "training", "and", "i", ">=", "1", "and", "self", ".", "ss_prob", ">", "0.0", ":", "# otherwiste no need to sample", "\n", "                ", "sample_prob", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "uniform_", "(", "0", ",", "1", ")", "\n", "sample_mask", "=", "sample_prob", "<", "self", ".", "ss_prob", "\n", "if", "sample_mask", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                    ", "sample_ind", "=", "sample_mask", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "data", ".", "clone", "(", ")", "\n", "#prob_prev = torch.exp(outputs[-1].data.index_select(0, sample_ind)) # fetch prev distribution: shape Nx(M+1)", "\n", "#it.index_copy_(0, sample_ind, torch.multinomial(prob_prev, 1).view(-1))", "\n", "prob_prev", "=", "torch", ".", "exp", "(", "outputs", "[", "-", "1", "]", ".", "data", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "it", ".", "index_copy_", "(", "0", ",", "sample_ind", ",", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "view", "(", "-", "1", ")", ".", "index_select", "(", "0", ",", "sample_ind", ")", ")", "\n", "it", "=", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", "\n", "", "", "else", ":", "\n", "                ", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "clone", "(", ")", "\n", "# break if all the sequences end", "\n", "", "if", "i", ">=", "1", "and", "seq", "[", ":", ",", "i", "]", ".", "data", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ")", "\n", "output", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "outputs", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AttModel.get_logprobs_state": [[109, 117], ["AttModel.AttModel.embed", "AttModel.AttModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "AttModel.AttModel.logit"], "methods", ["None"], ["", "def", "get_logprobs_state", "(", "self", ",", "it", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "state", ")", ":", "\n", "# 'it' is Variable contraining a word index", "\n", "        ", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ")", "\n", "\n", "return", "logprobs", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AttModel.sample_beam": [[118, 156], ["opt.get", "AttModel.AttModel.size", "AttModel.AttModel.fc_embed", "AttModel.AttModel.att_embed", "AttModel.AttModel.view", "AttModel.AttModel.ctx2att", "p_att_feats.view.view.view", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "AttModel.AttModel.view.view", "AttModel.AttModel.view.view", "AttModel.AttModel.init_hidden", "fc_feats[].expand", "att_feats[].expand().contiguous", "p_att_feats[].expand().contiguous", "range", "AttModel.AttModel.beam_search", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "AttModel.AttModel.size", "AttModel.AttModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "att_feats[].expand", "p_att_feats[].expand", "AttModel.AttModel.data.new().long().zero_", "AttModel.AttModel.embed", "AttModel.AttModel.logit", "AttModel.AttModel.view.size", "AttModel.AttModel.view.size", "Variable", "AttModel.AttModel.data.new().long", "AttModel.AttModel.view.size", "p_att_feats.view.view.size", "AttModel.AttModel.data.new"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.CaptionModel.CaptionModel.beam_search"], ["", "def", "sample_beam", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "\n", "# embed fc and att feats", "\n", "fc_feats", "=", "self", ".", "fc_embed", "(", "fc_feats", ")", "\n", "_att_feats", "=", "self", ".", "att_embed", "(", "att_feats", ".", "view", "(", "-", "1", ",", "self", ".", "att_feat_size", ")", ")", "\n", "att_feats", "=", "_att_feats", ".", "view", "(", "*", "(", "att_feats", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "rnn_size", ",", ")", ")", ")", "\n", "\n", "# Project the attention feats first to reduce memory and computation comsumptions.", "\n", "p_att_feats", "=", "self", ".", "ctx2att", "(", "att_feats", ".", "view", "(", "-", "1", ",", "self", ".", "rnn_size", ")", ")", "\n", "p_att_feats", "=", "p_att_feats", ".", "view", "(", "*", "(", "att_feats", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "att_hid_size", ",", ")", ")", ")", "\n", "\n", "assert", "beam_size", "<=", "self", ".", "vocab_size", "+", "1", ",", "'lets assume this for now, otherwise this corner case causes a few headaches down the road. can be dealt with in future if needed'", "\n", "seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "seqLogprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", "\n", "# lets process every image independently for now, for simplicity", "\n", "\n", "self", ".", "done_beams", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "beam_size", ")", "\n", "tmp_fc_feats", "=", "fc_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "beam_size", ",", "fc_feats", ".", "size", "(", "1", ")", ")", "\n", "tmp_att_feats", "=", "att_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "*", "(", "(", "beam_size", ",", ")", "+", "att_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", "\n", "tmp_p_att_feats", "=", "p_att_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "*", "(", "(", "beam_size", ",", ")", "+", "p_att_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", "\n", "\n", "for", "t", "in", "range", "(", "1", ")", ":", "\n", "                ", "if", "t", "==", "0", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "beam_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "xt", "=", "self", ".", "embed", "(", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ")", "\n", "\n", "", "self", ".", "done_beams", "[", "k", "]", "=", "self", ".", "beam_search", "(", "state", ",", "logprobs", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "opt", "=", "opt", ")", "\n", "seq", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'seq'", "]", "# the first beam has highest cumulative score", "\n", "seqLogprobs", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'logps'", "]", "\n", "# return the samples and their log likelihoods", "\n", "", "return", "seq", ".", "transpose", "(", "0", ",", "1", ")", ",", "seqLogprobs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AttModel.sample": [[157, 213], ["opt.get", "opt.get", "opt.get", "AttModel.AttModel.size", "AttModel.AttModel.init_hidden", "AttModel.AttModel.fc_embed", "AttModel.AttModel.att_embed", "AttModel.AttModel.view", "AttModel.AttModel.ctx2att", "p_att_feats.view.view.view", "range", "AttModel.AttModel.sample_beam", "AttModel.AttModel.view.contiguous().view", "AttModel.AttModel.view.view", "AttModel.AttModel.embed", "AttModel.AttModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AttModel.AttModel.data.new().long().zero_", "Variable", "seq.append", "seqLogprobs.append", "AttModel.AttModel.logit", "AttModel.AttModel.view.contiguous", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "it.view().long.view().long.view().long", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.log_softmax.gather", "it.view().long.view().long.view().long", "unfinished.sum", "unfinished.type_as", "F.log_softmax.gather.view", "_.unsqueeze", "_.unsqueeze", "AttModel.AttModel.view.size", "AttModel.AttModel.view.size", "AttModel.AttModel.data.new().long", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "Variable", "it.view().long.view().long.view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "it.view().long.view().long.view", "AttModel.AttModel.data.new", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.sample_beam"], ["", "def", "sample", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "sample_max", "=", "opt", ".", "get", "(", "'sample_max'", ",", "1", ")", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "temperature", "=", "opt", ".", "get", "(", "'temperature'", ",", "1.0", ")", "\n", "if", "beam_size", ">", "1", ":", "\n", "            ", "return", "self", ".", "sample_beam", "(", "fc_feats", ",", "att_feats", ",", "opt", ")", "\n", "\n", "", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "# embed fc and att feats", "\n", "fc_feats", "=", "self", ".", "fc_embed", "(", "fc_feats", ")", "\n", "_att_feats", "=", "self", ".", "att_embed", "(", "att_feats", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "att_feat_size", ")", ")", "\n", "att_feats", "=", "_att_feats", ".", "view", "(", "*", "(", "att_feats", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "rnn_size", ",", ")", ")", ")", "\n", "\n", "# Project the attention feats first to reduce memory and computation comsumptions.", "\n", "p_att_feats", "=", "self", ".", "ctx2att", "(", "att_feats", ".", "view", "(", "-", "1", ",", "self", ".", "rnn_size", ")", ")", "\n", "p_att_feats", "=", "p_att_feats", ".", "view", "(", "*", "(", "att_feats", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "att_hid_size", ",", ")", ")", ")", "\n", "\n", "seq", "=", "[", "]", "\n", "seqLogprobs", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "seq_length", "+", "1", ")", ":", "\n", "            ", "if", "t", "==", "0", ":", "# input <bos>", "\n", "                ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "", "elif", "sample_max", ":", "\n", "                ", "sampleLogprobs", ",", "it", "=", "torch", ".", "max", "(", "logprobs", ".", "data", ",", "1", ")", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "temperature", "==", "1.0", ":", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "logprobs", ".", "data", ")", ".", "cpu", "(", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "", "else", ":", "\n", "# scale logprobs by temperature", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "logprobs", ".", "data", ",", "temperature", ")", ")", ".", "cpu", "(", ")", "\n", "", "it", "=", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "cuda", "(", ")", "\n", "sampleLogprobs", "=", "logprobs", ".", "gather", "(", "1", ",", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "# gather the logprobs at sampled positions", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "# and flatten indices for downstream processing", "\n", "\n", "", "xt", "=", "self", ".", "embed", "(", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n", "if", "t", ">=", "1", ":", "\n", "# stop when all finished", "\n", "                ", "if", "t", "==", "1", ":", "\n", "                    ", "unfinished", "=", "it", ">", "0", "\n", "", "else", ":", "\n", "                    ", "unfinished", "=", "unfinished", "*", "(", "it", ">", "0", ")", "\n", "", "if", "unfinished", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "", "it", "=", "it", "*", "unfinished", ".", "type_as", "(", "it", ")", "\n", "seq", ".", "append", "(", "it", ")", "#seq[t] the input of t+2 time step", "\n", "\n", "seqLogprobs", ".", "append", "(", "sampleLogprobs", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seq", "]", ",", "1", ")", ",", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seqLogprobs", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AdaAtt_lstm.__init__": [[215, 242], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "range", "range"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "use_maxout", "=", "True", ")", ":", "\n", "        ", "super", "(", "AdaAtt_lstm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "#self.rnn_type = opt.rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "self", ".", "use_maxout", "=", "use_maxout", "\n", "\n", "# Build a LSTM", "\n", "self", ".", "w2h", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "(", "4", "+", "(", "use_maxout", "==", "True", ")", ")", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "v2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "(", "4", "+", "(", "use_maxout", "==", "True", ")", ")", "*", "self", ".", "rnn_size", ")", "\n", "\n", "self", ".", "i2h", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "(", "4", "+", "(", "use_maxout", "==", "True", ")", ")", "*", "self", ".", "rnn_size", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", "-", "1", ")", "]", ")", "\n", "self", ".", "h2h", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "(", "4", "+", "(", "use_maxout", "==", "True", ")", ")", "*", "self", ".", "rnn_size", ")", "for", "_", "in", "range", "(", "self", ".", "num_layers", ")", "]", ")", "\n", "\n", "# Layers for getting the fake region", "\n", "if", "self", ".", "num_layers", "==", "1", ":", "\n", "            ", "self", ".", "r_w2h", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "self", ".", "rnn_size", ")", "\n", "self", ".", "r_v2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "r_i2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "", "self", ".", "r_h2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AdaAtt_lstm.forward": [[244, 301], ["range", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "all_input_sums.narrow", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.tanh", "torch.tanh", "torch.tanh", "cs.append", "hs.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.dropout", "torch.dropout", "torch.dropout", "torch.tanh", "torch.tanh", "torch.tanh", "all_input_sums.narrow", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "AttModel.AdaAtt_lstm.w2h", "AttModel.AdaAtt_lstm.v2h", "all_input_sums.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "AttModel.AdaAtt_lstm.r_i2h", "AttModel.AdaAtt_lstm.r_h2h", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "_.unsqueeze", "_.unsqueeze", "AttModel.AdaAtt_lstm.r_w2h", "AttModel.AdaAtt_lstm.r_v2h"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xt", ",", "img_fc", ",", "state", ")", ":", "\n", "\n", "        ", "hs", "=", "[", "]", "\n", "cs", "=", "[", "]", "\n", "for", "L", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "# c,h from previous timesteps", "\n", "            ", "prev_h", "=", "state", "[", "0", "]", "[", "L", "]", "\n", "prev_c", "=", "state", "[", "1", "]", "[", "L", "]", "\n", "# the input to this layer", "\n", "if", "L", "==", "0", ":", "\n", "                ", "x", "=", "xt", "\n", "i2h", "=", "self", ".", "w2h", "(", "x", ")", "+", "self", ".", "v2h", "(", "img_fc", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "hs", "[", "-", "1", "]", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "i2h", "=", "self", ".", "i2h", "[", "L", "-", "1", "]", "(", "x", ")", "\n", "\n", "", "all_input_sums", "=", "i2h", "+", "self", ".", "h2h", "[", "L", "]", "(", "prev_h", ")", "\n", "\n", "sigmoid_chunk", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "0", ",", "3", "*", "self", ".", "rnn_size", ")", "\n", "sigmoid_chunk", "=", "F", ".", "sigmoid", "(", "sigmoid_chunk", ")", "\n", "# decode the gates", "\n", "in_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", "\n", "forget_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "out_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", "*", "2", ",", "self", ".", "rnn_size", ")", "\n", "# decode the write inputs", "\n", "if", "not", "self", ".", "use_maxout", ":", "\n", "                ", "in_transform", "=", "F", ".", "tanh", "(", "all_input_sums", ".", "narrow", "(", "1", ",", "3", "*", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ")", "\n", "", "else", ":", "\n", "                ", "in_transform", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "3", "*", "self", ".", "rnn_size", ",", "2", "*", "self", ".", "rnn_size", ")", "\n", "in_transform", "=", "torch", ".", "max", "(", "in_transform", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", ",", "\n", "in_transform", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ")", "\n", "# perform the LSTM update", "\n", "", "next_c", "=", "forget_gate", "*", "prev_c", "+", "in_gate", "*", "in_transform", "\n", "# gated cells form the output", "\n", "tanh_nex_c", "=", "F", ".", "tanh", "(", "next_c", ")", "\n", "next_h", "=", "out_gate", "*", "tanh_nex_c", "\n", "if", "L", "==", "self", ".", "num_layers", "-", "1", ":", "\n", "                ", "if", "L", "==", "0", ":", "\n", "                    ", "i2h", "=", "self", ".", "r_w2h", "(", "x", ")", "+", "self", ".", "r_v2h", "(", "img_fc", ")", "\n", "", "else", ":", "\n", "                    ", "i2h", "=", "self", ".", "r_i2h", "(", "x", ")", "\n", "", "n5", "=", "i2h", "+", "self", ".", "r_h2h", "(", "prev_h", ")", "\n", "fake_region", "=", "F", ".", "sigmoid", "(", "n5", ")", "*", "tanh_nex_c", "\n", "\n", "", "cs", ".", "append", "(", "next_c", ")", "\n", "hs", ".", "append", "(", "next_h", ")", "\n", "\n", "# set up the decoder", "\n", "", "top_h", "=", "hs", "[", "-", "1", "]", "\n", "top_h", "=", "F", ".", "dropout", "(", "top_h", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "fake_region", "=", "F", ".", "dropout", "(", "fake_region", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "\n", "state", "=", "(", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "0", ")", "for", "_", "in", "hs", "]", ",", "0", ")", ",", "\n", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "0", ")", "for", "_", "in", "cs", "]", ",", "0", ")", ")", "\n", "return", "top_h", ",", "fake_region", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AdaAtt_attention.__init__": [[303, 327], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AdaAtt_attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "#self.rnn_type = opt.rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "# fake region embed", "\n", "self", ".", "fr_linear", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "input_encoding_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "\n", "self", ".", "fr_embed", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n", "# h out embed", "\n", "self", ".", "ho_linear", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "input_encoding_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "\n", "self", ".", "ho_embed", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n", "self", ".", "alpha_net", "=", "nn", ".", "Linear", "(", "self", ".", "att_hid_size", ",", "1", ")", "\n", "self", ".", "att2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AdaAtt_attention.forward": [[328, 361], ["conv_feat.view.view.view", "conv_feat_embed.view.view.view", "AttModel.AdaAtt_attention.fr_linear", "AttModel.AdaAtt_attention.fr_embed", "AttModel.AdaAtt_attention.ho_linear", "AttModel.AdaAtt_attention.ho_embed", "AttModel.AdaAtt_attention.unsqueeze().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tanh", "torch.tanh", "torch.tanh", "torch.dropout", "torch.dropout", "torch.dropout", "AttModel.AdaAtt_attention.alpha_net", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm.squeeze", "torch.bmm.squeeze", "torch.bmm.squeeze", "torch.tanh", "torch.tanh", "torch.tanh", "torch.dropout", "torch.dropout", "torch.dropout", "AttModel.AdaAtt_attention.size", "AttModel.AdaAtt_attention.size", "torch.dropout.view", "AttModel.AdaAtt_attention.view", "torch.softmax.unsqueeze", "AttModel.AdaAtt_attention.att2h", "conv_feat.view.view.numel", "conv_feat.view.view.size", "AttModel.AdaAtt_attention.unsqueeze", "AttModel.AdaAtt_attention.view", "AttModel.AdaAtt_attention.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h_out", ",", "fake_region", ",", "conv_feat", ",", "conv_feat_embed", ")", ":", "\n", "\n", "# View into three dimensions", "\n", "        ", "att_size", "=", "conv_feat", ".", "numel", "(", ")", "//", "conv_feat", ".", "size", "(", "0", ")", "//", "self", ".", "rnn_size", "\n", "conv_feat", "=", "conv_feat", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "rnn_size", ")", "\n", "conv_feat_embed", "=", "conv_feat_embed", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n", "# view neighbor from bach_size * neighbor_num x rnn_size to bach_size x rnn_size * neighbor_num", "\n", "fake_region", "=", "self", ".", "fr_linear", "(", "fake_region", ")", "\n", "fake_region_embed", "=", "self", ".", "fr_embed", "(", "fake_region", ")", "\n", "\n", "h_out_linear", "=", "self", ".", "ho_linear", "(", "h_out", ")", "\n", "h_out_embed", "=", "self", ".", "ho_embed", "(", "h_out_linear", ")", "\n", "\n", "txt_replicate", "=", "h_out_embed", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "h_out_embed", ".", "size", "(", "0", ")", ",", "att_size", "+", "1", ",", "h_out_embed", ".", "size", "(", "1", ")", ")", "\n", "\n", "img_all", "=", "torch", ".", "cat", "(", "[", "fake_region", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "input_encoding_size", ")", ",", "conv_feat", "]", ",", "1", ")", "\n", "img_all_embed", "=", "torch", ".", "cat", "(", "[", "fake_region_embed", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "input_encoding_size", ")", ",", "conv_feat_embed", "]", ",", "1", ")", "\n", "\n", "hA", "=", "F", ".", "tanh", "(", "img_all_embed", "+", "txt_replicate", ")", "\n", "hA", "=", "F", ".", "dropout", "(", "hA", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "\n", "hAflat", "=", "self", ".", "alpha_net", "(", "hA", ".", "view", "(", "-", "1", ",", "self", ".", "att_hid_size", ")", ")", "\n", "PI", "=", "F", ".", "softmax", "(", "hAflat", ".", "view", "(", "-", "1", ",", "att_size", "+", "1", ")", ")", "\n", "\n", "visAtt", "=", "torch", ".", "bmm", "(", "PI", ".", "unsqueeze", "(", "1", ")", ",", "img_all", ")", "\n", "visAttdim", "=", "visAtt", ".", "squeeze", "(", "1", ")", "\n", "\n", "atten_out", "=", "visAttdim", "+", "h_out_linear", "\n", "\n", "h", "=", "F", ".", "tanh", "(", "self", ".", "att2h", "(", "atten_out", ")", ")", "\n", "h", "=", "F", ".", "dropout", "(", "h", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AdaAttCore.__init__": [[363, 367], ["torch.Module.__init__", "AttModel.AdaAtt_lstm", "AttModel.AdaAtt_attention"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "use_maxout", "=", "False", ")", ":", "\n", "        ", "super", "(", "AdaAttCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lstm", "=", "AdaAtt_lstm", "(", "opt", ",", "use_maxout", ")", "\n", "self", ".", "attention", "=", "AdaAtt_attention", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AdaAttCore.forward": [[368, 372], ["AttModel.AdaAttCore.lstm", "AttModel.AdaAttCore.attention"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ")", ":", "\n", "        ", "h_out", ",", "p_out", ",", "state", "=", "self", ".", "lstm", "(", "xt", ",", "fc_feats", ",", "state", ")", "\n", "atten_out", "=", "self", ".", "attention", "(", "h_out", ",", "p_out", ",", "att_feats", ",", "p_att_feats", ")", "\n", "return", "atten_out", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.TopDownCore.__init__": [[374, 381], ["torch.Module.__init__", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "torch.LSTMCell", "AttModel.Attention"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "use_maxout", "=", "False", ")", ":", "\n", "        ", "super", "(", "TopDownCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "\n", "self", ".", "att_lstm", "=", "nn", ".", "LSTMCell", "(", "opt", ".", "input_encoding_size", "+", "opt", ".", "rnn_size", "*", "2", ",", "opt", ".", "rnn_size", ")", "# we, fc, h^2_t-1", "\n", "self", ".", "lang_lstm", "=", "nn", ".", "LSTMCell", "(", "opt", ".", "rnn_size", "*", "2", ",", "opt", ".", "rnn_size", ")", "# h^1_t, \\hat v", "\n", "self", ".", "attention", "=", "Attention", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.TopDownCore.forward": [[382, 399], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AttModel.TopDownCore.att_lstm", "AttModel.TopDownCore.attention", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "AttModel.TopDownCore.lang_lstm", "torch.dropout", "torch.dropout", "torch.dropout", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ")", ":", "\n", "        ", "prev_h", "=", "state", "[", "0", "]", "[", "-", "1", "]", "\n", "att_lstm_input", "=", "torch", ".", "cat", "(", "[", "prev_h", ",", "fc_feats", ",", "xt", "]", ",", "1", ")", "\n", "\n", "h_att", ",", "c_att", "=", "self", ".", "att_lstm", "(", "att_lstm_input", ",", "(", "state", "[", "0", "]", "[", "0", "]", ",", "state", "[", "1", "]", "[", "0", "]", ")", ")", "\n", "\n", "att", "=", "self", ".", "attention", "(", "h_att", ",", "att_feats", ",", "p_att_feats", ")", "\n", "\n", "lang_lstm_input", "=", "torch", ".", "cat", "(", "[", "att", ",", "h_att", "]", ",", "1", ")", "\n", "# lang_lstm_input = torch.cat([att, F.dropout(h_att, self.drop_prob_lm, self.training)], 1) ?????", "\n", "\n", "h_lang", ",", "c_lang", "=", "self", ".", "lang_lstm", "(", "lang_lstm_input", ",", "(", "state", "[", "0", "]", "[", "1", "]", ",", "state", "[", "1", "]", "[", "1", "]", ")", ")", "\n", "\n", "output", "=", "F", ".", "dropout", "(", "h_lang", ",", "self", ".", "drop_prob_lm", ",", "self", ".", "training", ")", "\n", "state", "=", "(", "torch", ".", "stack", "(", "[", "h_att", ",", "h_lang", "]", ")", ",", "torch", ".", "stack", "(", "[", "c_att", ",", "c_lang", "]", ")", ")", "\n", "\n", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.Attention.__init__": [[401, 408], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "self", ".", "h2att", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "alpha_net", "=", "nn", ".", "Linear", "(", "self", ".", "att_hid_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.Attention.forward": [[409, 427], ["p_att_feats.view", "AttModel.Attention.h2att", "att_h.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.tanh", "torch.tanh", "torch.tanh", "dot.view.view.view", "AttModel.Attention.alpha_net", "dot.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "att_feats.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "att_feats.numel", "att_feats.size", "att_h.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ",", "att_feats", ",", "p_att_feats", ")", ":", "\n", "# The p_att_feats here is already projected", "\n", "        ", "att_size", "=", "att_feats", ".", "numel", "(", ")", "//", "att_feats", ".", "size", "(", "0", ")", "//", "self", ".", "rnn_size", "\n", "att", "=", "p_att_feats", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n", "att_h", "=", "self", ".", "h2att", "(", "h", ")", "# batch * att_hid_size", "\n", "att_h", "=", "att_h", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "att", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "att", "+", "att_h", "# batch * att_size * att_hid_size", "\n", "dot", "=", "F", ".", "tanh", "(", "dot", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "dot", ".", "view", "(", "-", "1", ",", "self", ".", "att_hid_size", ")", "# (batch * att_size) * att_hid_size", "\n", "dot", "=", "self", ".", "alpha_net", "(", "dot", ")", "# (batch * att_size) * 1", "\n", "dot", "=", "dot", ".", "view", "(", "-", "1", ",", "att_size", ")", "# batch * att_size", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "dot", ")", "# batch * att_size", "\n", "att_feats_", "=", "att_feats", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "rnn_size", ")", "# batch * att_size * att_feat_size", "\n", "att_res", "=", "torch", ".", "bmm", "(", "weight", ".", "unsqueeze", "(", "1", ")", ",", "att_feats_", ")", ".", "squeeze", "(", "1", ")", "# batch * att_feat_size", "\n", "\n", "return", "att_res", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.Att2in2Core.__init__": [[430, 448], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "AttModel.Attention"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Att2in2Core", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "#self.rnn_type = opt.rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "#self.num_layers = opt.num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "# Build a LSTM", "\n", "self", ".", "a2c", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "2", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "i2h", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "h2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "\n", "\n", "self", ".", "attention", "=", "Attention", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.Att2in2Core.forward": [[449, 470], ["AttModel.Att2in2Core.attention", "all_input_sums.narrow", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "AttModel.Att2in2Core.dropout", "AttModel.Att2in2Core.i2h", "AttModel.Att2in2Core.h2h", "all_input_sums.narrow", "AttModel.Att2in2Core.a2c", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.tanh", "torch.tanh", "torch.tanh", "next_h.unsqueeze", "next_c.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ")", ":", "\n", "        ", "att_res", "=", "self", ".", "attention", "(", "state", "[", "0", "]", "[", "-", "1", "]", ",", "att_feats", ",", "p_att_feats", ")", "\n", "\n", "all_input_sums", "=", "self", ".", "i2h", "(", "xt", ")", "+", "self", ".", "h2h", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "\n", "sigmoid_chunk", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "0", ",", "3", "*", "self", ".", "rnn_size", ")", "\n", "sigmoid_chunk", "=", "F", ".", "sigmoid", "(", "sigmoid_chunk", ")", "\n", "in_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", "\n", "forget_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "out_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", "*", "2", ",", "self", ".", "rnn_size", ")", "\n", "\n", "in_transform", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "3", "*", "self", ".", "rnn_size", ",", "2", "*", "self", ".", "rnn_size", ")", "+", "self", ".", "a2c", "(", "att_res", ")", "\n", "in_transform", "=", "torch", ".", "max", "(", "in_transform", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", ",", "\n", "in_transform", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ")", "\n", "next_c", "=", "forget_gate", "*", "state", "[", "1", "]", "[", "-", "1", "]", "+", "in_gate", "*", "in_transform", "\n", "next_h", "=", "out_gate", "*", "F", ".", "tanh", "(", "next_c", ")", "\n", "\n", "output", "=", "self", ".", "dropout", "(", "next_h", ")", "\n", "state", "=", "(", "next_h", ".", "unsqueeze", "(", "0", ")", ",", "next_c", ".", "unsqueeze", "(", "0", ")", ")", "\n", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AdaAttModel.__init__": [[472, 475], ["AttModel.AttModel.__init__", "AttModel.AdaAttCore"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AdaAttModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "core", "=", "AdaAttCore", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.AdaAttMOModel.__init__": [[478, 481], ["AttModel.AttModel.__init__", "AttModel.AdaAttCore"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AdaAttMOModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "core", "=", "AdaAttCore", "(", "opt", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.Att2in2Model.__init__": [[483, 488], ["AttModel.AttModel.__init__", "AttModel.Att2in2Core", "delattr"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Att2in2Model", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "core", "=", "Att2in2Core", "(", "opt", ")", "\n", "delattr", "(", "self", ",", "'fc_embed'", ")", "\n", "self", ".", "fc_embed", "=", "lambda", "x", ":", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.TopDownModel.__init__": [[490, 494], ["AttModel.AttModel.__init__", "AttModel.TopDownCore"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "TopDownModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "num_layers", "=", "2", "\n", "self", ".", "core", "=", "TopDownCore", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.AttModel.SkipThought.__init__": [[496, 513], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "SkipThought", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "vocab_size", "=", "opt", ".", "vocab_size", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", ",", "self", ".", "rnn_size", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "LSTM", "(", "self", ".", "input_encoding_size", ",", "self", ".", "rnn_size", ",", "self", ".", "num_layers", ",", "\n", "dropout", "=", "self", ".", "drop_prob_lm", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "decoder_prev", "=", "nn", ".", "LSTM", "(", "self", ".", "input_encoding_size", ",", "self", ".", "rnn_size", ",", "self", ".", "num_layers", ",", "\n", "dropout", "=", "self", ".", "drop_prob_lm", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "decoder_after", "=", "nn", ".", "LSTM", "(", "self", ".", "input_encoding_size", ",", "self", ".", "rnn_size", ",", "self", ".", "num_layers", ",", "\n", "dropout", "=", "self", ".", "drop_prob_lm", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "fc_prev", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", ")", "\n", "self", ".", "fc_after", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.CaptionModel.CaptionModel.__init__": [[20, 22], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "CaptionModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.CaptionModel.CaptionModel.beam_search": [[23, 123], ["opt.get", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "min", "range", "sorted", "range", "logprobs.data.float", "CaptionModel.CaptionModel.beam_search.beam_step"], "methods", ["None"], ["", "def", "beam_search", "(", "self", ",", "state", ",", "logprobs", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# args are the miscelleous inputs to the core in addition to embedded word and state", "\n", "# kwargs only accept opt", "\n", "\n", "        ", "def", "beam_step", "(", "logprobsf", ",", "beam_size", ",", "t", ",", "beam_seq", ",", "beam_seq_logprobs", ",", "beam_logprobs_sum", ",", "state", ")", ":", "\n", "#INPUTS:", "\n", "#logprobsf: probabilities augmented after diversity", "\n", "#beam_size: obvious", "\n", "#t        : time instant", "\n", "#beam_seq : tensor contanining the beams", "\n", "#beam_seq_logprobs: tensor contanining the beam logprobs", "\n", "#beam_logprobs_sum: tensor contanining joint logprobs", "\n", "#OUPUTS:", "\n", "#beam_seq : tensor containing the word indices of the decoded captions", "\n", "#beam_seq_logprobs : log-probability of each decision made, same size as beam_seq", "\n", "#beam_logprobs_sum : joint log-probability of each beam", "\n", "\n", "            ", "ys", ",", "ix", "=", "torch", ".", "sort", "(", "logprobsf", ",", "1", ",", "True", ")", "\n", "candidates", "=", "[", "]", "\n", "cols", "=", "min", "(", "beam_size", ",", "ys", ".", "size", "(", "1", ")", ")", "\n", "rows", "=", "beam_size", "\n", "if", "t", "==", "0", ":", "\n", "                ", "rows", "=", "1", "\n", "", "for", "c", "in", "range", "(", "cols", ")", ":", "# for each column (word, essentially)", "\n", "                ", "for", "q", "in", "range", "(", "rows", ")", ":", "# for each beam expansion", "\n", "#compute logprob of expanding beam q with word in (sorted) position c", "\n", "                    ", "local_logprob", "=", "ys", "[", "q", ",", "c", "]", ".", "cpu", "(", ")", "\n", "candidate_logprob", "=", "beam_logprobs_sum", "[", "q", "]", "+", "local_logprob", "\n", "candidates", ".", "append", "(", "{", "'c'", ":", "ix", "[", "q", ",", "c", "]", ",", "'q'", ":", "q", ",", "'p'", ":", "candidate_logprob", ",", "'r'", ":", "local_logprob", "}", ")", "\n", "", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "'p'", "]", ")", "\n", "\n", "new_state", "=", "[", "_", ".", "clone", "(", ")", "for", "_", "in", "state", "]", "\n", "#beam_seq_prev, beam_seq_logprobs_prev", "\n", "if", "t", ">=", "1", ":", "\n", "#we''ll need these as reference when we fork beams around", "\n", "                ", "beam_seq_prev", "=", "beam_seq", "[", ":", "t", "]", ".", "clone", "(", ")", "\n", "beam_seq_logprobs_prev", "=", "beam_seq_logprobs", "[", ":", "t", "]", ".", "clone", "(", ")", "\n", "", "for", "vix", "in", "range", "(", "beam_size", ")", ":", "\n", "                ", "v", "=", "candidates", "[", "vix", "]", "\n", "#fork beam index q into index vix", "\n", "if", "t", ">=", "1", ":", "\n", "                    ", "beam_seq", "[", ":", "t", ",", "vix", "]", "=", "beam_seq_prev", "[", ":", ",", "v", "[", "'q'", "]", "]", "\n", "beam_seq_logprobs", "[", ":", "t", ",", "vix", "]", "=", "beam_seq_logprobs_prev", "[", ":", ",", "v", "[", "'q'", "]", "]", "\n", "#rearrange recurrent states", "\n", "", "for", "state_ix", "in", "range", "(", "len", "(", "new_state", ")", ")", ":", "\n", "#  copy over state in previous beam q to new beam at vix", "\n", "                    ", "new_state", "[", "state_ix", "]", "[", ":", ",", "vix", "]", "=", "state", "[", "state_ix", "]", "[", ":", ",", "v", "[", "'q'", "]", "]", "# dimension one is time step", "\n", "#append new end terminal at the end of this beam", "\n", "", "beam_seq", "[", "t", ",", "vix", "]", "=", "v", "[", "'c'", "]", "# c'th word is the continuation", "\n", "beam_seq_logprobs", "[", "t", ",", "vix", "]", "=", "v", "[", "'r'", "]", "# the raw logprob here", "\n", "beam_logprobs_sum", "[", "vix", "]", "=", "v", "[", "'p'", "]", "# the new (sum) logprob along this beam", "\n", "", "state", "=", "new_state", "\n", "return", "beam_seq", ",", "beam_seq_logprobs", ",", "beam_logprobs_sum", ",", "state", ",", "candidates", "\n", "\n", "# start beam search", "\n", "", "opt", "=", "kwargs", "[", "'opt'", "]", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "\n", "beam_seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "beam_size", ")", ".", "zero_", "(", ")", "\n", "beam_seq_logprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "beam_size", ")", ".", "zero_", "(", ")", "\n", "beam_logprobs_sum", "=", "torch", ".", "zeros", "(", "beam_size", ")", "# running sum of logprobs for each beam", "\n", "done_beams", "=", "[", "]", "\n", "\n", "for", "t", "in", "range", "(", "self", ".", "seq_length", ")", ":", "\n", "            ", "\"\"\"pem a beam merge. that is,\n            for every previous beam we now many new possibilities to branch out\n            we need to resort our beams to maintain the loop invariant of keeping\n            the top beam_size most likely sequences.\"\"\"", "\n", "logprobsf", "=", "logprobs", ".", "data", ".", "float", "(", ")", "# lets go to CPU for more efficiency in indexing operations", "\n", "\n", "beam_seq", ",", "beam_seq_logprobs", ",", "beam_logprobs_sum", ",", "state", ",", "candidates_divm", "=", "beam_step", "(", "logprobsf", ",", "\n", "beam_size", ",", "\n", "t", ",", "\n", "beam_seq", ",", "\n", "beam_seq_logprobs", ",", "\n", "beam_logprobs_sum", ",", "\n", "state", ")", "\n", "\n", "for", "vix", "in", "range", "(", "beam_size", ")", ":", "\n", "# if time's up... or if end token is reached then copy beams", "\n", "                ", "if", "beam_seq", "[", "t", ",", "vix", "]", "==", "0", "or", "t", "==", "self", ".", "seq_length", "-", "1", ":", "\n", "                    ", "final_beam", "=", "{", "\n", "'seq'", ":", "beam_seq", "[", ":", ",", "vix", "]", ".", "clone", "(", ")", ",", "\n", "'logps'", ":", "beam_seq_logprobs", "[", ":", ",", "vix", "]", ".", "clone", "(", ")", ",", "\n", "'p'", ":", "beam_logprobs_sum", "[", "vix", "]", "\n", "}", "\n", "done_beams", ".", "append", "(", "final_beam", ")", "\n", "# don't continue beams from finished sequences", "\n", "beam_logprobs_sum", "[", "vix", "]", "=", "-", "1000", "\n", "\n", "# encode as vectors", "\n", "", "", "it", "=", "beam_seq", "[", "t", "]", "\n", "logprobs", ",", "state", "=", "self", ".", "get_logprobs_state", "(", "Variable", "(", "it", ".", "cuda", "(", ")", ")", ",", "*", "(", "args", "+", "(", "state", ",", ")", ")", ")", "\n", "\n", "", "done_beams", "=", "sorted", "(", "done_beams", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "'p'", "]", ")", "[", ":", "beam_size", "]", "\n", "return", "done_beams", "\n", "", "", ""]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.Att2inModel.Att2inCore.__init__": [[21, 40], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Att2inCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "#self.rnn_type = opt.rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "#self.num_layers = opt.num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "# Build a LSTM", "\n", "self", ".", "a2c", "=", "nn", ".", "Linear", "(", "self", ".", "att_feat_size", ",", "2", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "i2h", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "h2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "\n", "\n", "self", ".", "h2att", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "alpha_net", "=", "nn", ".", "Linear", "(", "self", ".", "att_hid_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.Att2inModel.Att2inCore.forward": [[41, 76], ["p_att_feats.view", "Att2inModel.Att2inCore.h2att", "att_h.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.tanh", "torch.tanh", "torch.tanh", "dot.view.view.view", "Att2inModel.Att2inCore.alpha_net", "dot.view.view.view", "torch.softmax", "torch.softmax", "torch.softmax", "att_feats.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "all_input_sums.narrow", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "Att2inModel.Att2inCore.dropout", "Att2inModel.Att2inCore.i2h", "Att2inModel.Att2inCore.h2h", "all_input_sums.narrow", "Att2inModel.Att2inCore.a2c", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.max.narrow", "torch.tanh", "torch.tanh", "torch.tanh", "next_h.unsqueeze", "next_c.unsqueeze", "att_feats.numel", "att_feats.size", "att_h.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ")", ":", "\n", "# The p_att_feats here is already projected", "\n", "        ", "att_size", "=", "att_feats", ".", "numel", "(", ")", "//", "att_feats", ".", "size", "(", "0", ")", "//", "self", ".", "att_feat_size", "\n", "att", "=", "p_att_feats", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "att_hid_size", ")", "\n", "\n", "att_h", "=", "self", ".", "h2att", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "# batch * att_hid_size", "\n", "att_h", "=", "att_h", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "att", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "att", "+", "att_h", "# batch * att_size * att_hid_size", "\n", "dot", "=", "F", ".", "tanh", "(", "dot", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "dot", ".", "view", "(", "-", "1", ",", "self", ".", "att_hid_size", ")", "# (batch * att_size) * att_hid_size", "\n", "dot", "=", "self", ".", "alpha_net", "(", "dot", ")", "# (batch * att_size) * 1", "\n", "dot", "=", "dot", ".", "view", "(", "-", "1", ",", "att_size", ")", "# batch * att_size", "\n", "\n", "weight", "=", "F", ".", "softmax", "(", "dot", ")", "# batch * att_size", "\n", "att_feats_", "=", "att_feats", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "att_feat_size", ")", "# batch * att_size * att_feat_size", "\n", "att_res", "=", "torch", ".", "bmm", "(", "weight", ".", "unsqueeze", "(", "1", ")", ",", "att_feats_", ")", ".", "squeeze", "(", "1", ")", "# batch * att_feat_size", "\n", "\n", "all_input_sums", "=", "self", ".", "i2h", "(", "xt", ")", "+", "self", ".", "h2h", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "\n", "sigmoid_chunk", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "0", ",", "3", "*", "self", ".", "rnn_size", ")", "\n", "sigmoid_chunk", "=", "F", ".", "sigmoid", "(", "sigmoid_chunk", ")", "\n", "in_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", "\n", "forget_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "out_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", "*", "2", ",", "self", ".", "rnn_size", ")", "\n", "\n", "in_transform", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "3", "*", "self", ".", "rnn_size", ",", "2", "*", "self", ".", "rnn_size", ")", "+", "self", ".", "a2c", "(", "att_res", ")", "\n", "in_transform", "=", "torch", ".", "max", "(", "in_transform", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", ",", "\n", "in_transform", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ")", "\n", "next_c", "=", "forget_gate", "*", "state", "[", "1", "]", "[", "-", "1", "]", "+", "in_gate", "*", "in_transform", "\n", "next_h", "=", "out_gate", "*", "F", ".", "tanh", "(", "next_c", ")", "\n", "\n", "output", "=", "self", ".", "dropout", "(", "next_h", ")", "\n", "state", "=", "(", "next_h", ".", "unsqueeze", "(", "0", ")", ",", "next_c", ".", "unsqueeze", "(", "0", ")", ")", "\n", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.Att2inModel.Att2inModel.__init__": [[78, 99], ["CaptionModel.CaptionModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "Att2inModel.Att2inCore", "Att2inModel.Att2inModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Att2inModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "opt", ".", "vocab_size", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "#self.rnn_type = opt.rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "1", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "seq_length", "=", "opt", ".", "seq_length", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "self", ".", "ss_prob", "=", "0.0", "# Schedule sampling probability", "\n", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "logit", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", "+", "1", ")", "\n", "self", ".", "ctx2att", "=", "nn", ".", "Linear", "(", "self", ".", "att_feat_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "core", "=", "Att2inCore", "(", "opt", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.Att2inModel.Att2inModel.init_weights": [[100, 105], ["Att2inModel.Att2inModel.embed.weight.data.uniform_", "Att2inModel.Att2inModel.logit.bias.data.fill_", "Att2inModel.Att2inModel.logit.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "embed", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "logit", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "logit", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.Att2inModel.Att2inModel.init_hidden": [[106, 110], ["next", "Variable", "Variable", "Att2inModel.Att2inModel.parameters", "weight.new().zero_", "weight.new().zero_", "weight.new", "weight.new"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "data", "\n", "return", "(", "Variable", "(", "weight", ".", "new", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ")", ",", "\n", "Variable", "(", "weight", ".", "new", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.Att2inModel.Att2inModel.forward": [[111, 148], ["fc_feats.size", "Att2inModel.Att2inModel.init_hidden", "Att2inModel.Att2inModel.ctx2att", "p_att_feats.view.view.view", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "att_feats.view", "Att2inModel.Att2inModel.embed", "Att2inModel.Att2inModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "outputs.append", "seq.size", "fc_feats.data.new().uniform_", "seq[].clone", "Att2inModel.Att2inModel.logit", "_.unsqueeze", "sample_mask.sum", "seq[].clone", "sample_mask.nonzero().view", "seq[].data.clone", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "Variable.index_copy_", "Variable", "seq[].data.sum", "att_feats.size", "fc_feats.data.new", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "sample_mask.nonzero", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden"], ["", "def", "forward", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "seq", ")", ":", "\n", "        ", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "outputs", "=", "[", "]", "\n", "\n", "# Project the attention feats first to reduce memory and computation comsumptions.", "\n", "p_att_feats", "=", "self", ".", "ctx2att", "(", "att_feats", ".", "view", "(", "-", "1", ",", "self", ".", "att_feat_size", ")", ")", "\n", "p_att_feats", "=", "p_att_feats", ".", "view", "(", "*", "(", "att_feats", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "att_hid_size", ",", ")", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "seq", ".", "size", "(", "1", ")", "-", "1", ")", ":", "\n", "            ", "if", "self", ".", "training", "and", "i", ">=", "1", "and", "self", ".", "ss_prob", ">", "0.0", ":", "# otherwiste no need to sample", "\n", "                ", "sample_prob", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "uniform_", "(", "0", ",", "1", ")", "\n", "sample_mask", "=", "sample_prob", "<", "self", ".", "ss_prob", "\n", "if", "sample_mask", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                    ", "sample_ind", "=", "sample_mask", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "data", ".", "clone", "(", ")", "\n", "#prob_prev = torch.exp(outputs[-1].data.index_select(0, sample_ind)) # fetch prev distribution: shape Nx(M+1)", "\n", "#it.index_copy_(0, sample_ind, torch.multinomial(prob_prev, 1).view(-1))", "\n", "prob_prev", "=", "torch", ".", "exp", "(", "outputs", "[", "-", "1", "]", ".", "data", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "it", ".", "index_copy_", "(", "0", ",", "sample_ind", ",", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "view", "(", "-", "1", ")", ".", "index_select", "(", "0", ",", "sample_ind", ")", ")", "\n", "it", "=", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", "\n", "", "", "else", ":", "\n", "                ", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "clone", "(", ")", "\n", "# break if all the sequences end", "\n", "", "if", "i", ">=", "1", "and", "seq", "[", ":", ",", "i", "]", ".", "data", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ")", "\n", "output", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "outputs", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.Att2inModel.Att2inModel.get_logprobs_state": [[149, 157], ["Att2inModel.Att2inModel.embed", "Att2inModel.Att2inModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "Att2inModel.Att2inModel.logit"], "methods", ["None"], ["", "def", "get_logprobs_state", "(", "self", ",", "it", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "state", ")", ":", "\n", "# 'it' is Variable contraining a word index", "\n", "        ", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ")", "\n", "\n", "return", "logprobs", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.Att2inModel.Att2inModel.sample_beam": [[158, 191], ["opt.get", "fc_feats.size", "Att2inModel.Att2inModel.ctx2att", "p_att_feats.view.view.view", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "att_feats.view", "Att2inModel.Att2inModel.init_hidden", "fc_feats[].expand", "att_feats[].expand().contiguous", "p_att_feats[].expand().contiguous", "range", "Att2inModel.Att2inModel.beam_search", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "Att2inModel.Att2inModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "att_feats[].expand", "p_att_feats[].expand", "fc_feats.data.new().long().zero_", "Att2inModel.Att2inModel.embed", "Att2inModel.Att2inModel.logit", "att_feats.size", "Variable", "fc_feats.data.new().long", "att_feats.size", "p_att_feats.view.view.size", "fc_feats.data.new"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.CaptionModel.CaptionModel.beam_search"], ["", "def", "sample_beam", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "\n", "# Project the attention feats first to reduce memory and computation comsumptions.", "\n", "p_att_feats", "=", "self", ".", "ctx2att", "(", "att_feats", ".", "view", "(", "-", "1", ",", "self", ".", "att_feat_size", ")", ")", "\n", "p_att_feats", "=", "p_att_feats", ".", "view", "(", "*", "(", "att_feats", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "att_hid_size", ",", ")", ")", ")", "\n", "\n", "assert", "beam_size", "<=", "self", ".", "vocab_size", "+", "1", ",", "'lets assume this for now, otherwise this corner case causes a few headaches down the road. can be dealt with in future if needed'", "\n", "seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "seqLogprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", "\n", "# lets process every image independently for now, for simplicity", "\n", "\n", "self", ".", "done_beams", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "beam_size", ")", "\n", "tmp_fc_feats", "=", "fc_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "beam_size", ",", "self", ".", "fc_feat_size", ")", "\n", "tmp_att_feats", "=", "att_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "*", "(", "(", "beam_size", ",", ")", "+", "att_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", "\n", "tmp_p_att_feats", "=", "p_att_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "*", "(", "(", "beam_size", ",", ")", "+", "p_att_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", "\n", "\n", "for", "t", "in", "range", "(", "1", ")", ":", "\n", "                ", "if", "t", "==", "0", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "beam_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "xt", "=", "self", ".", "embed", "(", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ")", "\n", "\n", "", "self", ".", "done_beams", "[", "k", "]", "=", "self", ".", "beam_search", "(", "state", ",", "logprobs", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "tmp_p_att_feats", ",", "opt", "=", "opt", ")", "\n", "seq", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'seq'", "]", "# the first beam has highest cumulative score", "\n", "seqLogprobs", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'logps'", "]", "\n", "# return the samples and their log likelihoods", "\n", "", "return", "seq", ".", "transpose", "(", "0", ",", "1", ")", ",", "seqLogprobs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.Att2inModel.Att2inModel.sample": [[192, 243], ["opt.get", "opt.get", "opt.get", "fc_feats.size", "Att2inModel.Att2inModel.init_hidden", "Att2inModel.Att2inModel.ctx2att", "p_att_feats.view.view.view", "range", "Att2inModel.Att2inModel.sample_beam", "att_feats.view", "Att2inModel.Att2inModel.embed", "Att2inModel.Att2inModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fc_feats.data.new().long().zero_", "Variable", "seq.append", "seqLogprobs.append", "Att2inModel.Att2inModel.logit", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "it.view().long.view().long.view().long", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.log_softmax.gather", "it.view().long.view().long.view().long", "unfinished.sum", "unfinished.type_as", "F.log_softmax.gather.view", "_.unsqueeze", "_.unsqueeze", "att_feats.size", "fc_feats.data.new().long", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "Variable", "it.view().long.view().long.view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "it.view().long.view().long.view", "fc_feats.data.new", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.sample_beam"], ["", "def", "sample", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "sample_max", "=", "opt", ".", "get", "(", "'sample_max'", ",", "1", ")", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "temperature", "=", "opt", ".", "get", "(", "'temperature'", ",", "1.0", ")", "\n", "if", "beam_size", ">", "1", ":", "\n", "            ", "return", "self", ".", "sample_beam", "(", "fc_feats", ",", "att_feats", ",", "opt", ")", "\n", "\n", "", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "# Project the attention feats first to reduce memory and computation comsumptions.", "\n", "p_att_feats", "=", "self", ".", "ctx2att", "(", "att_feats", ".", "view", "(", "-", "1", ",", "self", ".", "att_feat_size", ")", ")", "\n", "p_att_feats", "=", "p_att_feats", ".", "view", "(", "*", "(", "att_feats", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "att_hid_size", ",", ")", ")", ")", "\n", "\n", "seq", "=", "[", "]", "\n", "seqLogprobs", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "seq_length", "+", "1", ")", ":", "\n", "            ", "if", "t", "==", "0", ":", "# input <bos>", "\n", "                ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "", "elif", "sample_max", ":", "\n", "                ", "sampleLogprobs", ",", "it", "=", "torch", ".", "max", "(", "logprobs", ".", "data", ",", "1", ")", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "temperature", "==", "1.0", ":", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "logprobs", ".", "data", ")", ".", "cpu", "(", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "", "else", ":", "\n", "# scale logprobs by temperature", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "logprobs", ".", "data", ",", "temperature", ")", ")", ".", "cpu", "(", ")", "\n", "", "it", "=", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "cuda", "(", ")", "\n", "sampleLogprobs", "=", "logprobs", ".", "gather", "(", "1", ",", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "# gather the logprobs at sampled positions", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "# and flatten indices for downstream processing", "\n", "\n", "", "xt", "=", "self", ".", "embed", "(", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n", "if", "t", ">=", "1", ":", "\n", "# stop when all finished", "\n", "                ", "if", "t", "==", "1", ":", "\n", "                    ", "unfinished", "=", "it", ">", "0", "\n", "", "else", ":", "\n", "                    ", "unfinished", "=", "unfinished", "*", "(", "it", ">", "0", ")", "\n", "", "if", "unfinished", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "", "it", "=", "it", "*", "unfinished", ".", "type_as", "(", "it", ")", "\n", "seq", ".", "append", "(", "it", ")", "#seq[t] the input of t+2 time step", "\n", "\n", "seqLogprobs", ".", "append", "(", "sampleLogprobs", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "p_att_feats", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seq", "]", ",", "1", ")", ",", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seqLogprobs", "]", ",", "1", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.ShowTellModel.ShowTellModel.__init__": [[14, 34], ["CaptionModel.CaptionModel.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "ShowTellModel.ShowTellModel.init_weights", "getattr", "ShowTellModel.ShowTellModel.rnn_type.upper"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "ShowTellModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "opt", ".", "vocab_size", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_type", "=", "opt", ".", "rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "seq_length", "=", "opt", ".", "seq_length", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "\n", "self", ".", "ss_prob", "=", "0.0", "# Schedule sampling probability", "\n", "\n", "self", ".", "img_embed", "=", "nn", ".", "Linear", "(", "self", ".", "fc_feat_size", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "core", "=", "getattr", "(", "nn", ",", "self", ".", "rnn_type", ".", "upper", "(", ")", ")", "(", "self", ".", "input_encoding_size", ",", "self", ".", "rnn_size", ",", "self", ".", "num_layers", ",", "bias", "=", "False", ",", "dropout", "=", "self", ".", "drop_prob_lm", ")", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "logit", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", "+", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.ShowTellModel.ShowTellModel.init_weights": [[35, 40], ["ShowTellModel.ShowTellModel.embed.weight.data.uniform_", "ShowTellModel.ShowTellModel.logit.bias.data.fill_", "ShowTellModel.ShowTellModel.logit.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "embed", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "logit", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "logit", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.ShowTellModel.ShowTellModel.init_hidden": [[41, 48], ["next", "Variable", "ShowTellModel.ShowTellModel.parameters", "Variable", "Variable", "weight.new().zero_", "weight.new().zero_", "weight.new().zero_", "weight.new", "weight.new", "weight.new"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "data", "\n", "if", "self", ".", "rnn_type", "==", "'lstm'", ":", "\n", "            ", "return", "(", "Variable", "(", "weight", ".", "new", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ")", ",", "\n", "Variable", "(", "weight", ".", "new", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "Variable", "(", "weight", ".", "new", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.ShowTellModel.ShowTellModel.forward": [[49, 83], ["fc_feats.size", "ShowTellModel.ShowTellModel.init_hidden", "range", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "seq.size", "ShowTellModel.ShowTellModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "outputs.append", "ShowTellModel.ShowTellModel.img_embed", "ShowTellModel.ShowTellModel.embed", "ShowTellModel.ShowTellModel.unsqueeze", "ShowTellModel.ShowTellModel.logit", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fc_feats.data.new().uniform_", "seq[].clone", "ShowTellModel.ShowTellModel.dropout", "sample_mask.sum", "seq[].clone", "sample_mask.nonzero().view", "seq[].data.clone", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "Variable.index_copy_", "Variable", "seq[].data.sum", "torch.log_softmax.squeeze", "_.unsqueeze", "fc_feats.data.new", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "sample_mask.nonzero", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden"], ["", "", "def", "forward", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "seq", ")", ":", "\n", "        ", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "outputs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "seq", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "xt", "=", "self", ".", "img_embed", "(", "fc_feats", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "training", "and", "i", ">=", "2", "and", "self", ".", "ss_prob", ">", "0.0", ":", "# otherwiste no need to sample", "\n", "                    ", "sample_prob", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "uniform_", "(", "0", ",", "1", ")", "\n", "sample_mask", "=", "sample_prob", "<", "self", ".", "ss_prob", "\n", "if", "sample_mask", ".", "sum", "(", ")", "==", "0", ":", "\n", "                        ", "it", "=", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                        ", "sample_ind", "=", "sample_mask", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "it", "=", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "data", ".", "clone", "(", ")", "\n", "#prob_prev = torch.exp(outputs[-1].data.index_select(0, sample_ind)) # fetch prev distribution: shape Nx(M+1)", "\n", "#it.index_copy_(0, sample_ind, torch.multinomial(prob_prev, 1).view(-1))", "\n", "prob_prev", "=", "torch", ".", "exp", "(", "outputs", "[", "-", "1", "]", ".", "data", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "it", ".", "index_copy_", "(", "0", ",", "sample_ind", ",", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "view", "(", "-", "1", ")", ".", "index_select", "(", "0", ",", "sample_ind", ")", ")", "\n", "it", "=", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", "\n", "", "", "else", ":", "\n", "                    ", "it", "=", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "clone", "(", ")", "\n", "# break if all the sequences end", "\n", "", "if", "i", ">=", "2", "and", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "data", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "output", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ".", "squeeze", "(", "0", ")", ")", ")", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "outputs", "[", "1", ":", "]", "]", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.ShowTellModel.ShowTellModel.get_logprobs_state": [[84, 92], ["ShowTellModel.ShowTellModel.embed", "ShowTellModel.ShowTellModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "ShowTellModel.ShowTellModel.unsqueeze", "ShowTellModel.ShowTellModel.logit", "ShowTellModel.ShowTellModel.dropout", "output.squeeze"], "methods", ["None"], ["", "def", "get_logprobs_state", "(", "self", ",", "it", ",", "state", ")", ":", "\n", "# 'it' is Variable contraining a word index", "\n", "        ", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ".", "squeeze", "(", "0", ")", ")", ")", ")", "\n", "\n", "return", "logprobs", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.ShowTellModel.ShowTellModel.sample_beam": [[93, 120], ["opt.get", "fc_feats.size", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "ShowTellModel.ShowTellModel.init_hidden", "range", "ShowTellModel.ShowTellModel.beam_search", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "ShowTellModel.ShowTellModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "ShowTellModel.ShowTellModel.img_embed().expand", "ShowTellModel.ShowTellModel.unsqueeze", "ShowTellModel.ShowTellModel.logit", "fc_feats.data.new().long().zero_", "ShowTellModel.ShowTellModel.embed", "ShowTellModel.ShowTellModel.dropout", "ShowTellModel.ShowTellModel.img_embed", "Variable", "output.squeeze", "fc_feats.data.new().long", "fc_feats.data.new"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.CaptionModel.CaptionModel.beam_search"], ["", "def", "sample_beam", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "\n", "assert", "beam_size", "<=", "self", ".", "vocab_size", "+", "1", ",", "'lets assume this for now, otherwise this corner case causes a few headaches down the road. can be dealt with in future if needed'", "\n", "seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "seqLogprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", "\n", "# lets process every image independently for now, for simplicity", "\n", "\n", "self", ".", "done_beams", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "beam_size", ")", "\n", "for", "t", "in", "range", "(", "2", ")", ":", "\n", "                ", "if", "t", "==", "0", ":", "\n", "                    ", "xt", "=", "self", ".", "img_embed", "(", "fc_feats", "[", "k", ":", "k", "+", "1", "]", ")", ".", "expand", "(", "beam_size", ",", "self", ".", "input_encoding_size", ")", "\n", "", "elif", "t", "==", "1", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "beam_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "xt", "=", "self", ".", "embed", "(", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ".", "squeeze", "(", "0", ")", ")", ")", ")", "\n", "\n", "", "self", ".", "done_beams", "[", "k", "]", "=", "self", ".", "beam_search", "(", "state", ",", "logprobs", ",", "opt", "=", "opt", ")", "\n", "seq", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'seq'", "]", "# the first beam has highest cumulative score", "\n", "seqLogprobs", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'logps'", "]", "\n", "# return the samples and their log likelihoods", "\n", "", "return", "seq", ".", "transpose", "(", "0", ",", "1", ")", ",", "seqLogprobs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.ShowTellModel.ShowTellModel.sample": [[121, 169], ["opt.get", "opt.get", "opt.get", "fc_feats.size", "ShowTellModel.ShowTellModel.init_hidden", "range", "ShowTellModel.ShowTellModel.sample_beam", "ShowTellModel.ShowTellModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "ShowTellModel.ShowTellModel.img_embed", "ShowTellModel.ShowTellModel.embed", "seq.append", "seqLogprobs.append", "ShowTellModel.ShowTellModel.unsqueeze", "ShowTellModel.ShowTellModel.logit", "fc_feats.data.new().long().zero_", "Variable", "unfinished.sum", "unfinished.type_as", "F.log_softmax.gather.view", "ShowTellModel.ShowTellModel.dropout", "_.unsqueeze", "_.unsqueeze", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "it.view().long.view().long.view().long", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.log_softmax.gather", "it.view().long.view().long.view().long", "output.squeeze", "fc_feats.data.new().long", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "Variable", "it.view().long.view().long.view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "it.view().long.view().long.view", "fc_feats.data.new", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.sample_beam"], ["", "def", "sample", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "sample_max", "=", "opt", ".", "get", "(", "'sample_max'", ",", "1", ")", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "temperature", "=", "opt", ".", "get", "(", "'temperature'", ",", "1.0", ")", "\n", "if", "beam_size", ">", "1", ":", "\n", "            ", "return", "self", ".", "sample_beam", "(", "fc_feats", ",", "att_feats", ",", "opt", ")", "\n", "\n", "", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "seq", "=", "[", "]", "\n", "seqLogprobs", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "seq_length", "+", "2", ")", ":", "\n", "            ", "if", "t", "==", "0", ":", "\n", "                ", "xt", "=", "self", ".", "img_embed", "(", "fc_feats", ")", "\n", "", "else", ":", "\n", "                ", "if", "t", "==", "1", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "", "elif", "sample_max", ":", "\n", "                    ", "sampleLogprobs", ",", "it", "=", "torch", ".", "max", "(", "logprobs", ".", "data", ",", "1", ")", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                    ", "if", "temperature", "==", "1.0", ":", "\n", "                        ", "prob_prev", "=", "torch", ".", "exp", "(", "logprobs", ".", "data", ")", ".", "cpu", "(", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "", "else", ":", "\n", "# scale logprobs by temperature", "\n", "                        ", "prob_prev", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "logprobs", ".", "data", ",", "temperature", ")", ")", ".", "cpu", "(", ")", "\n", "", "it", "=", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "cuda", "(", ")", "\n", "sampleLogprobs", "=", "logprobs", ".", "gather", "(", "1", ",", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "# gather the logprobs at sampled positions", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "# and flatten indices for downstream processing", "\n", "\n", "", "xt", "=", "self", ".", "embed", "(", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n", "", "if", "t", ">=", "2", ":", "\n", "# stop when all finished", "\n", "                ", "if", "t", "==", "2", ":", "\n", "                    ", "unfinished", "=", "it", ">", "0", "\n", "", "else", ":", "\n", "                    ", "unfinished", "=", "unfinished", "*", "(", "it", ">", "0", ")", "\n", "", "if", "unfinished", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "", "it", "=", "it", "*", "unfinished", ".", "type_as", "(", "it", ")", "\n", "seq", ".", "append", "(", "it", ")", "#seq[t] the input of t+2 time step", "\n", "seqLogprobs", ".", "append", "(", "sampleLogprobs", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ".", "squeeze", "(", "0", ")", ")", ")", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seq", "]", ",", "1", ")", ",", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seqLogprobs", "]", ",", "1", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.OldModel.__init__": [[21, 51], ["CaptionModel.CaptionModel.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "OldModel.OldModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "OldModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "opt", ".", "vocab_size", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_type", "=", "opt", ".", "rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "seq_length", "=", "opt", ".", "seq_length", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "if", "'sentence_embed_att'", "in", "opt", ":", "\n", "            ", "self", ".", "sentence_embed_att", "=", "opt", ".", "sentence_embed_att", "\n", "", "else", ":", "\n", "            ", "self", ".", "sentence_embed_att", "=", "False", "\n", "\n", "", "self", ".", "ss_prob", "=", "0.0", "# Schedule sampling probability", "\n", "# if opt.sentence_embed:", "\n", "#     self.sentence_embed_size = opt.sentence_embed_size", "\n", "#     # self.lda = nn.Linear(self.sentence_embed_size, self.rnn_size)", "\n", "#     self.lda = nn.Sequential(nn.Linear(self.sentence_embed_size, self.rnn_size),", "\n", "#                   nn.ReLU(),", "\n", "#                   nn.Dropout(self.drop_prob_lm))", "\n", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "self", ".", "fc_feat_size", ",", "self", ".", "num_layers", "*", "self", ".", "rnn_size", ")", "# feature to rnn_size", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "logit", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", "+", "1", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.OldModel.init_weights": [[52, 57], ["OldModel.OldModel.embed.weight.data.uniform_", "OldModel.OldModel.logit.bias.data.fill_", "OldModel.OldModel.logit.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "embed", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "logit", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "logit", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.OldModel.init_hidden": [[58, 64], ["OldModel.OldModel.linear().view().transpose", "OldModel.OldModel.linear().view", "OldModel.OldModel.linear"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "fc_feats", ")", ":", "\n", "        ", "image_map", "=", "self", ".", "linear", "(", "fc_feats", ")", ".", "view", "(", "-", "1", ",", "self", ".", "num_layers", ",", "self", ".", "rnn_size", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "rnn_type", "==", "'lstm'", ":", "\n", "            ", "return", "(", "image_map", ",", "image_map", ")", "\n", "", "else", ":", "\n", "            ", "return", "image_map", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.OldModel.forward": [[65, 107], ["fc_feats.size", "OldModel.OldModel.init_hidden", "range", "OldModel.OldModel.embed", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "outputs.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.Tensor().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "seq.size", "fc_feats.data.new().uniform_", "seq[].clone", "OldModel.OldModel.core", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "OldModel.OldModel.core", "OldModel.OldModel.logit", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sample_mask.sum", "seq[].clone", "sample_mask.nonzero().view", "seq[].data.clone", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "Variable.index_copy_", "Variable", "seq[].data.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "OldModel.OldModel.dropout", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "_.unsqueeze", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "fc_feats.data.new", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "_.unsqueeze", "sample_mask.nonzero", "atts[].squeeze", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden"], ["", "", "def", "forward", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "seq", ",", "sen_embed", "=", "None", ",", "return_attention", "=", "False", ")", ":", "\n", "        ", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "fc_feats", ")", "\n", "outputs", "=", "[", "]", "\n", "if", "return_attention", ":", "coverage", ",", "cov_loss", "=", "torch", ".", "Tensor", "(", "[", "]", ")", ".", "cuda", "(", ")", ",", "torch", ".", "zeros", "(", "batch_size", ")", ".", "cuda", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "seq", ".", "size", "(", "1", ")", "-", "1", ")", ":", "\n", "            ", "if", "self", ".", "training", "and", "i", ">=", "1", "and", "self", ".", "ss_prob", ">", "0.0", ":", "# otherwiste no need to sample", "\n", "                ", "sample_prob", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "uniform_", "(", "0", ",", "1", ")", "\n", "sample_mask", "=", "sample_prob", "<", "self", ".", "ss_prob", "\n", "if", "sample_mask", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                    ", "sample_ind", "=", "sample_mask", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "data", ".", "clone", "(", ")", "\n", "#prob_prev = torch.exp(outputs[-1].data.index_select(0, sample_ind)) # fetch prev distribution: shape Nx(M+1)", "\n", "#it.index_copy_(0, sample_ind, torch.multinomial(prob_prev, 1).view(-1))", "\n", "prob_prev", "=", "torch", ".", "exp", "(", "outputs", "[", "-", "1", "]", ".", "data", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "it", ".", "index_copy_", "(", "0", ",", "sample_ind", ",", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "view", "(", "-", "1", ")", ".", "index_select", "(", "0", ",", "sample_ind", ")", ")", "\n", "it", "=", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", "\n", "", "", "else", ":", "\n", "                ", "it", "=", "seq", "[", ":", ",", "i", "]", ".", "clone", "(", ")", "\n", "# break if all the sequences end", "\n", "", "if", "i", ">=", "1", "and", "seq", "[", ":", ",", "i", "]", ".", "data", ".", "sum", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "if", "return_attention", ":", "\n", "                ", "output", ",", "state", ",", "atts", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ",", "sen_embed", ",", "return_attention", ")", "\n", "atts", "=", "torch", ".", "from_numpy", "(", "atts", "[", "1", "]", ".", "squeeze", "(", "2", ")", ")", ".", "cuda", "(", ")", "\n", "if", "i", "!=", "0", ":", "\n", "                    ", "cov_loss", "+=", "torch", ".", "sum", "(", "torch", ".", "min", "(", "atts", ",", "coverage", ")", ",", "1", ")", "\n", "coverage", "+=", "atts", "\n", "", "else", ":", "\n", "                    ", "coverage", "=", "torch", ".", "cat", "(", "(", "coverage", ",", "atts", ")", ",", "0", ")", "\n", "", "", "else", ":", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ",", "sen_embed", ")", "\n", "output", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ")", ")", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "", "if", "return_attention", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "outputs", "]", ",", "1", ")", ",", "torch", ".", "sum", "(", "cov_loss", ")", "/", "batch_size", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "outputs", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.OldModel.get_logprobs_state": [[108, 116], ["OldModel.OldModel.embed", "OldModel.OldModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "OldModel.OldModel.logit", "OldModel.OldModel.dropout"], "methods", ["None"], ["", "", "def", "get_logprobs_state", "(", "self", ",", "it", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "state", ")", ":", "\n", "# 'it' is Variable contraining a word index", "\n", "        ", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ")", ")", ")", "\n", "\n", "return", "logprobs", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.OldModel.sample_beam": [[117, 157], ["opt.get", "fc_feats.size", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "fc_feats[].expand", "att_feats[].expand().contiguous", "OldModel.OldModel.init_hidden", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.FloatTensor().zero_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "OldModel.OldModel.beam_search", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "att_feats[].expand", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "fc_feats.data.new().long().zero_", "OldModel.OldModel.embed", "OldModel.OldModel.core", "OldModel.OldModel.logit", "Variable", "OldModel.OldModel.core", "OldModel.OldModel.core", "OldModel.OldModel.dropout", "fc_feats.data.new().long", "att_feats.size", "fc_feats.data.new"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.CaptionModel.CaptionModel.beam_search"], ["", "def", "sample_beam", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "opt", "=", "{", "}", ",", "sen_embed", "=", "None", ",", "return_attention", "=", "False", ")", ":", "\n", "        ", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "\n", "assert", "beam_size", "<=", "self", ".", "vocab_size", "+", "1", ",", "'lets assume this for now, otherwise this corner case causes a few headaches down the road. can be dealt with in future if needed'", "\n", "seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "seqLogprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", "\n", "# lets process every image independently for now, for simplicity", "\n", "\n", "self", ".", "done_beams", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "tmp_fc_feats", "=", "fc_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "beam_size", ",", "self", ".", "fc_feat_size", ")", "\n", "tmp_att_feats", "=", "att_feats", "[", "k", ":", "k", "+", "1", "]", ".", "expand", "(", "*", "(", "(", "beam_size", ",", ")", "+", "att_feats", ".", "size", "(", ")", "[", "1", ":", "]", ")", ")", ".", "contiguous", "(", ")", "\n", "\n", "state", "=", "self", ".", "init_hidden", "(", "tmp_fc_feats", ")", "\n", "\n", "beam_seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "beam_size", ")", ".", "zero_", "(", ")", "\n", "beam_seq_logprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "beam_size", ")", ".", "zero_", "(", ")", "\n", "beam_logprobs_sum", "=", "torch", ".", "zeros", "(", "beam_size", ")", "# running sum of logprobs for each beam", "\n", "done_beams", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "1", ")", ":", "\n", "                ", "if", "t", "==", "0", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "beam_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "xt", "=", "self", ".", "embed", "(", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n", "", "if", "sen_embed", "is", "not", "None", ":", "\n", "                    ", "if", "return_attention", ":", "\n", "                        ", "output", ",", "state", ",", "att", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ",", "sen_embed", ",", "return_attention", ")", "\n", "", "else", ":", "\n", "                        ", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ",", "sen_embed", ")", "\n", "", "", "else", ":", "\n", "                    ", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ")", "\n", "# output, state = self.core(xt, tmp_fc_feats, tmp_att_feats, state)", "\n", "", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ")", ")", ")", "\n", "\n", "", "self", ".", "done_beams", "[", "k", "]", "=", "self", ".", "beam_search", "(", "state", ",", "logprobs", ",", "tmp_fc_feats", ",", "tmp_att_feats", ",", "opt", "=", "opt", ")", "\n", "seq", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'seq'", "]", "# the first beam has highest cumulative score", "\n", "seqLogprobs", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'logps'", "]", "\n", "# return the samples and their log likelihoods", "\n", "", "return", "seq", ".", "transpose", "(", "0", ",", "1", ")", ",", "seqLogprobs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.OldModel.sample": [[158, 221], ["opt.get", "opt.get", "opt.get", "fc_feats.size", "OldModel.OldModel.init_hidden", "range", "OldModel.OldModel.sample_beam", "OldModel.OldModel.embed", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "fc_feats.data.new().long().zero_", "Variable", "seq.append", "seqLogprobs.append", "OldModel.OldModel.core", "OldModel.OldModel.logit", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "it.view().long.view().long.view().long", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.log_softmax.gather", "it.view().long.view().long.view().long", "unfinished.sum", "unfinished.type_as", "F.log_softmax.gather.view", "OldModel.OldModel.core", "atts.append", "OldModel.OldModel.core", "OldModel.OldModel.dropout", "fc_feats.data.new().long", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "Variable", "_.unsqueeze", "_.unsqueeze", "_.unsqueeze", "_.unsqueeze", "it.view().long.view().long.view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "it.view().long.view().long.view", "fc_feats.data.new", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.sample_beam"], ["", "def", "sample", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "opt", "=", "{", "}", ",", "sen_embed", "=", "None", ",", "return_attention", "=", "False", ")", ":", "\n", "        ", "sample_max", "=", "opt", ".", "get", "(", "'sample_max'", ",", "1", ")", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "temperature", "=", "opt", ".", "get", "(", "'temperature'", ",", "1.0", ")", "\n", "if", "beam_size", ">", "1", ":", "\n", "            ", "return", "self", ".", "sample_beam", "(", "fc_feats", ",", "att_feats", ",", "opt", ",", "sen_embed", ",", "return_attention", ")", "\n", "\n", "", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "fc_feats", ")", "\n", "\n", "if", "return_attention", ":", "atts", "=", "[", "]", "\n", "\n", "seq", "=", "[", "]", "\n", "seqLogprobs", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "seq_length", "+", "1", ")", ":", "\n", "            ", "if", "t", "==", "0", ":", "# input <bos>", "\n", "                ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "", "elif", "sample_max", ":", "\n", "                ", "sampleLogprobs", ",", "it", "=", "torch", ".", "max", "(", "logprobs", ".", "data", ",", "1", ")", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "temperature", "==", "1.0", ":", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "logprobs", ".", "data", ")", ".", "cpu", "(", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "", "else", ":", "\n", "# scale logprobs by temperature", "\n", "                    ", "prob_prev", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "logprobs", ".", "data", ",", "temperature", ")", ")", ".", "cpu", "(", ")", "\n", "", "it", "=", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "cuda", "(", ")", "\n", "sampleLogprobs", "=", "logprobs", ".", "gather", "(", "1", ",", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "# gather the logprobs at sampled positions", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "# and flatten indices for downstream processing", "\n", "\n", "", "xt", "=", "self", ".", "embed", "(", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n", "if", "t", ">=", "1", ":", "\n", "# stop when all finished", "\n", "                ", "if", "t", "==", "1", ":", "\n", "                    ", "unfinished", "=", "it", ">", "0", "\n", "", "else", ":", "\n", "                    ", "unfinished", "=", "unfinished", "*", "(", "it", ">", "0", ")", "\n", "", "if", "unfinished", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "", "it", "=", "it", "*", "unfinished", ".", "type_as", "(", "it", ")", "\n", "seq", ".", "append", "(", "it", ")", "#seq[t] the input of t+2 time step", "\n", "seqLogprobs", ".", "append", "(", "sampleLogprobs", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "if", "sen_embed", "is", "not", "None", ":", "\n", "# sen_embed = self.lda(lda)", "\n", "#     output, state = self.core(xt, fc_feats, att_feats, state, sen_embed)", "\n", "# elif self.sentence_embed_att:", "\n", "#     sen_embed = self.lda(lda)", "\n", "                ", "if", "return_attention", ":", "\n", "                    ", "output", ",", "state", ",", "att", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ",", "sen_embed", ",", "return_attention", ")", "\n", "atts", ".", "append", "(", "att", ")", "\n", "", "else", ":", "\n", "                    ", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ",", "sen_embed", ")", "\n", "", "", "else", ":", "\n", "                ", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ")", "\n", "# output, state = self.core(xt, fc_feats, att_feats, state)", "\n", "", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "self", ".", "dropout", "(", "output", ")", ")", ")", "\n", "\n", "", "if", "return_attention", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seq", "]", ",", "1", ")", ",", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seqLogprobs", "]", ",", "1", ")", ",", "atts", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seq", "]", ",", "1", ")", ",", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seqLogprobs", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.ShowAttendTellCore.__init__": [[224, 317], ["torch.Module.__init__", "vars().get", "vars().get", "vars().get", "vars().get", "vars().get", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "vars", "vars", "vars", "vars", "vars", "misc.LeakyReLUConv2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "getattr", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "OldModel.ShowAttendTellCore.rnn_type.upper", "getattr", "misc.LeakyReLUConv2d", "misc.INSResBlock", "misc.INSResBlock", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "OldModel.ShowAttendTellCore.rnn_type.upper", "getattr", "OldModel.ShowAttendTellCore.rnn_type.upper", "getattr", "getattr", "OldModel.ShowAttendTellCore.rnn_type.upper", "OldModel.ShowAttendTellCore.rnn_type.upper"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "ShowAttendTellCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_type", "=", "opt", ".", "rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "self", ".", "att_feat_size", "=", "opt", ".", "att_feat_size", "\n", "self", ".", "att_hid_size", "=", "opt", ".", "att_hid_size", "\n", "\n", "# sentence embedding parameters", "\n", "self", ".", "sentence_embed_method", "=", "vars", "(", "opt", ")", ".", "get", "(", "'sentence_embed_method'", ",", "''", ")", "\n", "self", ".", "sentence_embed_att", "=", "vars", "(", "opt", ")", ".", "get", "(", "'sentence_embed_att'", ",", "False", ")", "\n", "self", ".", "sentence_length", "=", "vars", "(", "opt", ")", ".", "get", "(", "'sentence_length'", ",", "None", ")", "\n", "self", ".", "sentence_embed_size", "=", "vars", "(", "opt", ")", ".", "get", "(", "'sentence_embed_size'", ",", "None", ")", "\n", "self", ".", "sentence_embed", "=", "vars", "(", "opt", ")", ".", "get", "(", "'sentence_embed'", ",", "False", ")", "\n", "\n", "if", "self", ".", "sentence_embed_method", "==", "'conv'", ":", "\n", "            ", "self", ".", "sen_conv_ch", "=", "32", "\n", "self", ".", "ctx2att_sen", "=", "[", "]", "\n", "self", ".", "ctx2att_sen", "+=", "[", "utils", ".", "LeakyReLUConv2d", "(", "1", ",", "self", ".", "sen_conv_ch", ",", "[", "self", ".", "sentence_embed_size", ",", "5", "]", ",", "1", ",", "[", "0", ",", "2", "]", ")", "]", "\n", "self", ".", "ctx2att_sen", "+=", "[", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "]", "\n", "self", ".", "ctx2att_sen", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "ctx2att_sen", ")", "\n", "self", ".", "h2att_sen", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "sentence_embed_size", ")", "\n", "self", ".", "ch_embed", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "sen_conv_ch", ",", "1", ")", ",", "\n", "# nn.ReLU(),", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "\n", "\n", "", "elif", "self", ".", "sentence_embed_method", "==", "'bnews'", ":", "\n", "            ", "self", ".", "sen_conv_ch", "=", "256", "\n", "self", ".", "ctx2att_sen", "=", "[", "]", "\n", "self", ".", "ctx2att_sen", "+=", "[", "nn", ".", "Conv2d", "(", "1", ",", "self", ".", "sen_conv_ch", ",", "[", "self", ".", "sentence_embed_size", ",", "5", "]", ",", "1", ",", "[", "0", ",", "0", "]", ")", "]", "\n", "self", ".", "ctx2att_sen", "+=", "[", "nn", ".", "MaxPool2d", "(", "(", "1", ",", "self", ".", "sentence_length", "-", "4", ")", ",", "1", ")", "]", "\n", "\n", "self", ".", "ctx2att_sen_lin", "=", "[", "]", "\n", "self", ".", "ctx2att_sen_lin", "+=", "[", "nn", ".", "Linear", "(", "self", ".", "sen_conv_ch", ",", "64", ")", "]", "\n", "self", ".", "ctx2att_sen_lin", "+=", "[", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "self", ".", "ctx2att_sen_lin", "+=", "[", "nn", ".", "Dropout", "(", "p", "=", "0.1", ")", "]", "\n", "\n", "self", ".", "ctx2att_sen", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "ctx2att_sen", ")", "\n", "self", ".", "ctx2att_sen_lin", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "ctx2att_sen_lin", ")", "\n", "\n", "", "elif", "self", ".", "sentence_embed_method", "==", "'conv_deep'", ":", "\n", "            ", "self", ".", "sen_conv_ch", "=", "128", "\n", "self", ".", "ctx2att_sen", "=", "[", "]", "\n", "self", ".", "ctx2att_sen", "+=", "[", "utils", ".", "LeakyReLUConv2d", "(", "1", ",", "self", ".", "sen_conv_ch", ",", "[", "self", ".", "sentence_embed_size", ",", "5", "]", ",", "1", ",", "[", "0", ",", "2", "]", ")", "]", "\n", "self", ".", "ctx2att_sen", "+=", "[", "utils", ".", "INSResBlock", "(", "self", ".", "sen_conv_ch", ",", "self", ".", "sen_conv_ch", ",", "[", "1", ",", "5", "]", ",", "1", ",", "[", "0", ",", "2", "]", ")", "]", "\n", "self", ".", "ctx2att_sen", "+=", "[", "utils", ".", "INSResBlock", "(", "self", ".", "sen_conv_ch", ",", "self", ".", "sen_conv_ch", ",", "[", "1", ",", "5", "]", ",", "1", ",", "[", "0", ",", "2", "]", ")", "]", "\n", "\n", "self", ".", "ctx2att_sen", "+=", "[", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "]", "\n", "self", ".", "ctx2att_sen", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "ctx2att_sen", ")", "\n", "self", ".", "h2att_sen", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "sentence_length", ")", "\n", "self", ".", "ch_embed", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "sen_conv_ch", ",", "1", ")", ",", "\n", "# nn.ReLU(),", "\n", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", ")", "\n", "\n", "", "elif", "self", ".", "sentence_embed_method", "==", "'fc'", "or", "self", ".", "sentence_embed_method", "==", "'fc_max'", ":", "\n", "            ", "self", ".", "sentence_att", "=", "nn", ".", "Linear", "(", "self", ".", "sentence_embed_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "h2att_sen", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "alpha_net_sen", "=", "nn", ".", "Linear", "(", "self", ".", "att_hid_size", ",", "1", ")", "\n", "\n", "\n", "\n", "", "if", "self", ".", "sentence_embed_att", "and", "(", "self", ".", "sentence_embed_method", "==", "'fc'", "or", "self", ".", "sentence_embed_method", "==", "'fc_max'", "\n", "or", "self", ".", "sentence_embed_method", "==", "'conv'", ")", ":", "\n", "            ", "self", ".", "rnn", "=", "getattr", "(", "nn", ",", "self", ".", "rnn_type", ".", "upper", "(", ")", ")", "(", "self", ".", "input_encoding_size", "+", "self", ".", "att_feat_size", "\n", "+", "self", ".", "sentence_embed_size", ",", "self", ".", "rnn_size", ",", "\n", "self", ".", "num_layers", ",", "bias", "=", "False", ",", "dropout", "=", "self", ".", "drop_prob_lm", ")", "\n", "", "elif", "self", ".", "sentence_embed_method", "==", "'bnews'", ":", "\n", "            ", "self", ".", "rnn", "=", "getattr", "(", "nn", ",", "self", ".", "rnn_type", ".", "upper", "(", ")", ")", "(", "\n", "self", ".", "input_encoding_size", "+", "self", ".", "att_feat_size", "+", "64", ",", "\n", "self", ".", "rnn_size", ",", "self", ".", "num_layers", ",", "bias", "=", "False", ",", "dropout", "=", "self", ".", "drop_prob_lm", ")", "\n", "\n", "", "elif", "self", ".", "sentence_embed_method", "==", "'conv_deep'", ":", "\n", "            ", "self", ".", "rnn", "=", "getattr", "(", "nn", ",", "self", ".", "rnn_type", ".", "upper", "(", ")", ")", "(", "self", ".", "input_encoding_size", "+", "self", ".", "att_feat_size", "\n", "+", "self", ".", "sen_conv_ch", ",", "self", ".", "rnn_size", ",", "\n", "self", ".", "num_layers", ",", "bias", "=", "False", ",", "dropout", "=", "self", ".", "drop_prob_lm", ")", "\n", "", "elif", "self", ".", "sentence_embed", "and", "not", "self", ".", "sentence_embed_att", ":", "\n", "            ", "self", ".", "rnn", "=", "getattr", "(", "nn", ",", "self", ".", "rnn_type", ".", "upper", "(", ")", ")", "(", "\n", "self", ".", "input_encoding_size", "+", "self", ".", "att_feat_size", "+", "self", ".", "att_hid_size", ",", "\n", "self", ".", "rnn_size", ",", "self", ".", "num_layers", ",", "bias", "=", "False", ",", "dropout", "=", "self", ".", "drop_prob_lm", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "rnn", "=", "getattr", "(", "nn", ",", "self", ".", "rnn_type", ".", "upper", "(", ")", ")", "(", "self", ".", "input_encoding_size", "+", "self", ".", "att_feat_size", ",", "\n", "self", ".", "rnn_size", ",", "self", ".", "num_layers", ",", "bias", "=", "False", ",", "\n", "dropout", "=", "self", ".", "drop_prob_lm", ")", "\n", "\n", "\n", "\n", "", "if", "self", ".", "att_hid_size", ">", "0", ":", "\n", "            ", "self", ".", "ctx2att", "=", "nn", ".", "Linear", "(", "self", ".", "att_feat_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "h2att", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "att_hid_size", ")", "\n", "self", ".", "alpha_net", "=", "nn", ".", "Linear", "(", "self", ".", "att_hid_size", ",", "1", ")", "\n", "# else:", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.ShowAttendTellCore.forward": [[321, 408], ["att_feats.contiguous().view", "OldModel.ShowAttendTellCore.ctx2att", "att.view.view.view", "OldModel.ShowAttendTellCore.h2att", "att_h.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh.view", "OldModel.ShowAttendTellCore.alpha_net", "torch.tanh.view", "torch.softmax", "torch.softmax", "torch.softmax", "att_feats.view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "OldModel.ShowAttendTellCore.ctx2att_sen", "OldModel.ShowAttendTellCore.ctx2att_sen_lin", "OldModel.ShowAttendTellCore.rnn", "att_feats.numel", "att_feats.size", "att_feats.contiguous", "sen_embed.view().float", "OldModel.ShowAttendTellCore.sentence_att", "OldModel.ShowAttendTellCore.view", "OldModel.ShowAttendTellCore.h2att_sen", "OldModel.ShowAttendTellCore.unsqueeze().expand_as", "torch.tanh", "torch.tanh", "torch.tanh", "OldModel.ShowAttendTellCore.alpha_net", "torch.softmax", "torch.softmax", "torch.softmax", "sen_embed.permute().unsqueeze", "OldModel.ShowAttendTellCore.squeeze().squeeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "OldModel.ShowAttendTellCore.rnn", "output.squeeze", "output.squeeze", "att_h.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "OldModel.ShowAttendTellCore.h2att_sen", "sen.permute().unsqueeze.permute().unsqueeze.permute().unsqueeze", "OldModel.ShowAttendTellCore.ctx2att_sen", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh.squeeze().permute", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "att_res_sen.squeeze.squeeze.squeeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "OldModel.ShowAttendTellCore.rnn", "OldModel.ShowAttendTellCore.rnn", "torch.softmax.data.cpu().numpy", "torch.softmax.data.cpu().numpy", "torch.softmax.unsqueeze", "sen_embed.view", "OldModel.ShowAttendTellCore.unsqueeze", "OldModel.ShowAttendTellCore.unsqueeze", "OldModel.ShowAttendTellCore.ch_embed().squeeze", "sen_embed.permute", "torch.softmax.unsqueeze", "OldModel.ShowAttendTellCore.h2att_sen", "OldModel.ShowAttendTellCore.ctx2att_sen", "torch.tanh", "torch.tanh", "torch.tanh", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "att_res_sen.squeeze.squeeze.squeeze", "sen_embed.permute", "OldModel.ShowAttendTellCore.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "sen.permute().unsqueeze.permute().unsqueeze.permute", "torch.tanh.squeeze", "sen_embed.permute().unsqueeze", "OldModel.ShowAttendTellCore.unsqueeze", "OldModel.ShowAttendTellCore.squeeze", "OldModel.ShowAttendTellCore.ch_embed", "torch.tanh.squeeze", "OldModel.ShowAttendTellCore.squeeze", "torch.softmax.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.softmax.data.cpu", "torch.softmax.data.cpu", "sen_embed.permute().float", "OldModel.ShowAttendTellCore.ch_embed", "att_sen_combined.permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.arange().long", "torch.softmax.argmax().squeeze", "sen_embed.permute", "att_res_sen.squeeze.squeeze.float", "sen_embed.permute", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.softmax.argmax", "sen_embed.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ",", "sen_embed", "=", "None", ",", "return_attention", "=", "False", ")", ":", "\n", "        ", "att_size", "=", "att_feats", ".", "numel", "(", ")", "//", "att_feats", ".", "size", "(", "0", ")", "//", "self", ".", "att_feat_size", "\n", "att", "=", "att_feats", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "att_feat_size", ")", "\n", "if", "self", ".", "att_hid_size", ">", "0", ":", "\n", "            ", "att", "=", "self", ".", "ctx2att", "(", "att", ")", "# (batch * att_size) * att_hid_size", "\n", "att", "=", "att", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "att_hid_size", ")", "# batch * att_size * att_hid_size", "\n", "att_h", "=", "self", ".", "h2att", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "# batch * att_hid_size", "\n", "att_h", "=", "att_h", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "att", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "att", "+", "att_h", "# batch * att_size * att_hid_size", "\n", "dot", "=", "F", ".", "tanh", "(", "dot", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "dot", ".", "view", "(", "-", "1", ",", "self", ".", "att_hid_size", ")", "# (batch * att_size) * att_hid_size", "\n", "dot", "=", "self", ".", "alpha_net", "(", "dot", ")", "# (batch * att_size) * 1", "\n", "dot", "=", "dot", ".", "view", "(", "-", "1", ",", "att_size", ")", "# batch * att_size", "\n", "weight", "=", "F", ".", "softmax", "(", "dot", ")", "\n", "att_feats_", "=", "att_feats", ".", "view", "(", "-", "1", ",", "att_size", ",", "self", ".", "att_feat_size", ")", "# batch * att_size * att_feat_size", "\n", "att_res", "=", "torch", ".", "bmm", "(", "weight", ".", "unsqueeze", "(", "1", ")", ",", "att_feats_", ")", ".", "squeeze", "(", "1", ")", "# batch * att_feat_size", "\n", "", "else", ":", "\n", "            ", "att_res", "=", "fc_feats", "\n", "# att = self.ctx2att(att)(att)                        # (batch * att_size) * 1", "\n", "# att = att.view(-1, att_size)                        # batch * att_size", "\n", "# att_h = self.h2att(state[0][-1])                    # batch * 1", "\n", "# att_h = att_h.expand_as(att)                        # batch * att_size", "\n", "# dot = att_h + att                                   # batch * att_size", "\n", "\n", "\n", "", "if", "self", ".", "sentence_embed_att", ":", "\n", "            ", "if", "self", ".", "sentence_embed_method", "==", "'fc'", "or", "self", ".", "sentence_embed_method", "==", "'fc_max'", ":", "\n", "                ", "att_size_sen", "=", "self", ".", "sentence_length", "+", "1", "\n", "att_sen", "=", "sen_embed", ".", "view", "(", "-", "1", ",", "self", ".", "sentence_embed_size", ")", ".", "float", "(", ")", "\n", "att_sen", "=", "self", ".", "sentence_att", "(", "att_sen", ")", "# (batch * att_size) * att_hid_size", "\n", "att_sen", "=", "att_sen", ".", "view", "(", "-", "1", ",", "att_size_sen", ",", "self", ".", "att_hid_size", ")", "# batch * att_size * att_hid_size", "\n", "att_h_sen", "=", "self", ".", "h2att_sen", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "# batch * att_hid_size", "\n", "att_h_sen", "=", "att_h_sen", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "att_sen", ")", "# batch * att_size * att_hid_size", "\n", "dot", "=", "att_sen", "+", "att_h_sen", "# batch * att_size * att_hid_size", "\n", "dot", "=", "F", ".", "tanh", "(", "dot", ")", "# batch * att_size * att_hid_size", "\n", "# dot = dot.view(-1, self.att_hid_size)  # (batch * att_size) * att_hid_size", "\n", "dot", "=", "self", ".", "alpha_net", "(", "dot", ")", "# (batch * att_size) * 1", "\n", "# dot = dot.view(-1, att_size)  # batch * att_size", "\n", "\n", "weight_sen", "=", "F", ".", "softmax", "(", "dot", ")", "\n", "# att_feats_sen = att_feats.view(-1, att_size_sen, self.sentence_embed_size)  # batch * att_size * att_feat_size", "\n", "if", "self", ".", "sentence_embed_method", "==", "'fc'", ":", "\n", "                    ", "att_res_sen", "=", "torch", ".", "bmm", "(", "sen_embed", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "float", "(", ")", ",", "weight_sen", ")", ".", "squeeze", "(", "2", ")", "# batch * att_feat_size", "\n", "", "elif", "self", ".", "sentence_embed_method", "==", "'fc_max'", ":", "\n", "# fancy indexing, we are taking the max of the attention values and choosing the sen_embed index accordingly.", "\n", "                    ", "att_res_sen", "=", "sen_embed", "[", "torch", ".", "arange", "(", "0", ",", "sen_embed", ".", "size", "(", ")", "[", "0", "]", ")", ".", "long", "(", ")", ",", "weight_sen", ".", "argmax", "(", "1", ")", ".", "squeeze", "(", "1", ")", ",", ":", "]", "\n", "\n", "", "", "elif", "self", ".", "sentence_embed_method", "==", "'conv'", ":", "\n", "                ", "att_h_sen", "=", "self", ".", "h2att_sen", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "\n", "sen", "=", "sen_embed", "+", "att_h_sen", ".", "unsqueeze", "(", "1", ")", "\n", "sen", "=", "sen", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "att_sen", "=", "self", ".", "ctx2att_sen", "(", "sen", ")", "\n", "dot", "=", "F", ".", "tanh", "(", "att_sen", ")", "\n", "dot", "=", "dot", ".", "squeeze", "(", "2", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "weight_sen", "=", "F", ".", "softmax", "(", "self", ".", "ch_embed", "(", "dot", ")", ".", "squeeze", "(", "2", ")", ")", "\n", "att_res_sen", "=", "torch", ".", "bmm", "(", "sen_embed", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ",", "weight_sen", ".", "unsqueeze", "(", "2", ")", ")", "\n", "att_res_sen", "=", "att_res_sen", ".", "squeeze", "(", "2", ")", "\n", "\n", "", "elif", "self", ".", "sentence_embed_method", "==", "'conv_deep'", ":", "\n", "                ", "att_h_sen", "=", "self", ".", "h2att_sen", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "\n", "# sen = sen_embed + att_h_sen.unsqueeze(1)", "\n", "# sen = sen.permute(0,2,1).unsqueeze(1)", "\n", "att_sen", "=", "self", ".", "ctx2att_sen", "(", "sen_embed", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "att_sen_combined", "=", "att_h_sen", ".", "unsqueeze", "(", "1", ")", "+", "att_sen", ".", "squeeze", "(", "2", ")", "\n", "dot", "=", "F", ".", "tanh", "(", "self", ".", "ch_embed", "(", "att_sen_combined", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ")", "\n", "# dot = dot.squeeze(2).permute(0, 2, 1)", "\n", "weight_sen", "=", "F", ".", "softmax", "(", "dot", ".", "squeeze", "(", "2", ")", ")", "\n", "att_res_sen", "=", "torch", ".", "bmm", "(", "att_sen", ".", "squeeze", "(", "2", ")", ",", "weight_sen", ".", "unsqueeze", "(", "2", ")", ")", "\n", "att_res_sen", "=", "att_res_sen", ".", "squeeze", "(", "2", ")", "\n", "", "", "if", "self", ".", "sentence_embed_method", "==", "'bnews'", ":", "\n", "            ", "intermediate", "=", "self", ".", "ctx2att_sen", "(", "sen_embed", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "final", "=", "self", ".", "ctx2att_sen_lin", "(", "intermediate", ".", "squeeze", "(", "2", ")", ".", "squeeze", "(", "2", ")", ")", "\n", "\n", "", "if", "self", ".", "sentence_embed_method", "==", "'bnews'", ":", "\n", "            ", "output", ",", "state", "=", "self", ".", "rnn", "(", "torch", ".", "cat", "(", "[", "xt", ",", "final", ",", "att_res", "]", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "", "elif", "self", ".", "sentence_embed_att", "and", "(", "self", ".", "sentence_embed_method", "==", "'conv'", "or", "self", ".", "sentence_embed_method", "==", "'fc'", "\n", "or", "self", ".", "sentence_embed_method", "==", "'fc_max'", ")", ":", "\n", "            ", "output", ",", "state", "=", "self", ".", "rnn", "(", "torch", ".", "cat", "(", "[", "xt", ",", "att_res", ",", "att_res_sen", ".", "float", "(", ")", "]", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "", "elif", "sen_embed", "is", "not", "None", ":", "\n", "            ", "output", ",", "state", "=", "self", ".", "rnn", "(", "torch", ".", "cat", "(", "[", "xt", ",", "sen_embed", ",", "att_res", "]", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "", "else", ":", "\n", "            ", "output", ",", "state", "=", "self", ".", "rnn", "(", "torch", ".", "cat", "(", "[", "xt", ",", "att_res", "]", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "\n", "", "if", "return_attention", ":", "\n", "            ", "return", "output", ".", "squeeze", "(", "0", ")", ",", "state", ",", "[", "weight", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "weight_sen", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "return", "output", ".", "squeeze", "(", "0", ")", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.AllImgCore.__init__": [[410, 421], ["torch.Module.__init__", "getattr", "OldModel.AllImgCore.rnn_type.upper"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AllImgCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_type", "=", "opt", ".", "rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "\n", "self", ".", "rnn", "=", "getattr", "(", "nn", ",", "self", ".", "rnn_type", ".", "upper", "(", ")", ")", "(", "self", ".", "input_encoding_size", "+", "self", ".", "fc_feat_size", ",", "\n", "self", ".", "rnn_size", ",", "self", ".", "num_layers", ",", "bias", "=", "False", ",", "dropout", "=", "self", ".", "drop_prob_lm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.AllImgCore.forward": [[422, 425], ["OldModel.AllImgCore.rnn", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "output.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xt", ",", "fc_feats", ",", "att_feats", ",", "state", ")", ":", "\n", "        ", "output", ",", "state", "=", "self", ".", "rnn", "(", "torch", ".", "cat", "(", "[", "xt", ",", "fc_feats", "]", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "return", "output", ".", "squeeze", "(", "0", ")", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.ShowAttendTellModel.__init__": [[427, 430], ["OldModel.OldModel.__init__", "OldModel.ShowAttendTellCore"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "ShowAttendTellModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "core", "=", "ShowAttendTellCore", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.OldModel.AllImgModel.__init__": [[432, 435], ["OldModel.OldModel.__init__", "OldModel.AllImgCore"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "AllImgModel", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "self", ".", "core", "=", "AllImgCore", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.LSTMCore.__init__": [[14, 24], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "LSTMCore", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "\n", "# Build a LSTM", "\n", "self", ".", "i2h", "=", "nn", ".", "Linear", "(", "self", ".", "input_encoding_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "h2h", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "5", "*", "self", ".", "rnn_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob_lm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.LSTMCore.forward": [[25, 45], ["all_input_sums.narrow", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.sigmoid.narrow", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "FCModel.LSTMCore.dropout", "FCModel.LSTMCore.i2h", "FCModel.LSTMCore.h2h", "all_input_sums.narrow", "all_input_sums.narrow", "torch.tanh", "torch.tanh", "torch.tanh", "FCModel.LSTMCore.unsqueeze", "next_c.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "xt", ",", "state", ")", ":", "\n", "\n", "        ", "all_input_sums", "=", "self", ".", "i2h", "(", "xt", ")", "+", "self", ".", "h2h", "(", "state", "[", "0", "]", "[", "-", "1", "]", ")", "\n", "sigmoid_chunk", "=", "all_input_sums", ".", "narrow", "(", "1", ",", "0", ",", "3", "*", "self", ".", "rnn_size", ")", "\n", "sigmoid_chunk", "=", "F", ".", "sigmoid", "(", "sigmoid_chunk", ")", "\n", "in_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "0", ",", "self", ".", "rnn_size", ")", "\n", "forget_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", "\n", "out_gate", "=", "sigmoid_chunk", ".", "narrow", "(", "1", ",", "self", ".", "rnn_size", "*", "2", ",", "self", ".", "rnn_size", ")", "\n", "\n", "in_transform", "=", "torch", ".", "max", "(", "all_input_sums", ".", "narrow", "(", "1", ",", "3", "*", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ",", "\n", "all_input_sums", ".", "narrow", "(", "1", ",", "4", "*", "self", ".", "rnn_size", ",", "self", ".", "rnn_size", ")", ")", "\n", "next_c", "=", "forget_gate", "*", "state", "[", "1", "]", "[", "-", "1", "]", "+", "in_gate", "*", "in_transform", "\n", "next_h", "=", "out_gate", "*", "F", ".", "tanh", "(", "next_c", ")", "\n", "\n", "next_h", "=", "self", ".", "dropout", "(", "next_h", ")", "\n", "\n", "output", "=", "next_h", "\n", "state", "=", "(", "next_h", ".", "unsqueeze", "(", "0", ")", ",", "next_c", ".", "unsqueeze", "(", "0", ")", ")", "\n", "return", "output", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.__init__": [[47, 66], ["CaptionModel.CaptionModel.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "FCModel.LSTMCore", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "FCModel.FCModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "FCModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "opt", ".", "vocab_size", "\n", "self", ".", "input_encoding_size", "=", "opt", ".", "input_encoding_size", "\n", "self", ".", "rnn_type", "=", "opt", ".", "rnn_type", "\n", "self", ".", "rnn_size", "=", "opt", ".", "rnn_size", "\n", "self", ".", "num_layers", "=", "opt", ".", "num_layers", "\n", "self", ".", "drop_prob_lm", "=", "opt", ".", "drop_prob_lm", "\n", "self", ".", "seq_length", "=", "opt", ".", "seq_length", "\n", "self", ".", "fc_feat_size", "=", "opt", ".", "fc_feat_size", "\n", "\n", "self", ".", "ss_prob", "=", "0.0", "# Schedule sampling probability", "\n", "\n", "self", ".", "img_embed", "=", "nn", ".", "Linear", "(", "self", ".", "fc_feat_size", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "core", "=", "LSTMCore", "(", "opt", ")", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "self", ".", "vocab_size", "+", "1", ",", "self", ".", "input_encoding_size", ")", "\n", "self", ".", "logit", "=", "nn", ".", "Linear", "(", "self", ".", "rnn_size", ",", "self", ".", "vocab_size", "+", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_weights": [[67, 72], ["FCModel.FCModel.embed.weight.data.uniform_", "FCModel.FCModel.logit.bias.data.fill_", "FCModel.FCModel.logit.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "embed", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "logit", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "self", ".", "logit", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden": [[73, 80], ["next", "Variable", "FCModel.FCModel.parameters", "Variable", "Variable", "weight.new().zero_", "weight.new().zero_", "weight.new().zero_", "weight.new", "weight.new", "weight.new"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "data", "\n", "if", "self", ".", "rnn_type", "==", "'lstm'", ":", "\n", "            ", "return", "(", "Variable", "(", "weight", ".", "new", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ")", ",", "\n", "Variable", "(", "weight", ".", "new", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "Variable", "(", "weight", ".", "new", "(", "self", ".", "num_layers", ",", "bsz", ",", "self", ".", "rnn_size", ")", ".", "zero_", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.forward": [[81, 115], ["fc_feats.size", "FCModel.FCModel.init_hidden", "range", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "seq.size", "FCModel.FCModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "outputs.append", "FCModel.FCModel.img_embed", "FCModel.FCModel.embed", "FCModel.FCModel.logit", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fc_feats.data.new().uniform_", "seq[].clone", "sample_mask.sum", "seq[].clone", "sample_mask.nonzero().view", "seq[].data.clone", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "Variable.index_copy_", "Variable", "seq[].data.sum", "_.unsqueeze", "fc_feats.data.new", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "torch.multinomial().view().index_select", "sample_mask.nonzero", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial().view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden"], ["", "", "def", "forward", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "seq", ")", ":", "\n", "        ", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "outputs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "seq", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "xt", "=", "self", ".", "img_embed", "(", "fc_feats", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "training", "and", "i", ">=", "2", "and", "self", ".", "ss_prob", ">", "0.0", ":", "# otherwiste no need to sample", "\n", "                    ", "sample_prob", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "uniform_", "(", "0", ",", "1", ")", "\n", "sample_mask", "=", "sample_prob", "<", "self", ".", "ss_prob", "\n", "if", "sample_mask", ".", "sum", "(", ")", "==", "0", ":", "\n", "                        ", "it", "=", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "                        ", "sample_ind", "=", "sample_mask", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "it", "=", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "data", ".", "clone", "(", ")", "\n", "#prob_prev = torch.exp(outputs[-1].data.index_select(0, sample_ind)) # fetch prev distribution: shape Nx(M+1)", "\n", "#it.index_copy_(0, sample_ind, torch.multinomial(prob_prev, 1).view(-1))", "\n", "prob_prev", "=", "torch", ".", "exp", "(", "outputs", "[", "-", "1", "]", ".", "data", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "it", ".", "index_copy_", "(", "0", ",", "sample_ind", ",", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "view", "(", "-", "1", ")", ".", "index_select", "(", "0", ",", "sample_ind", ")", ")", "\n", "it", "=", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", "\n", "", "", "else", ":", "\n", "                    ", "it", "=", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "clone", "(", ")", "\n", "# break if all the sequences end", "\n", "", "if", "i", ">=", "2", "and", "seq", "[", ":", ",", "i", "-", "1", "]", ".", "data", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "state", ")", "\n", "output", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "outputs", "[", "1", ":", "]", "]", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.get_logprobs_state": [[116, 124], ["FCModel.FCModel.embed", "FCModel.FCModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "FCModel.FCModel.logit"], "methods", ["None"], ["", "def", "get_logprobs_state", "(", "self", ",", "it", ",", "state", ")", ":", "\n", "# 'it' is Variable contraining a word index", "\n", "        ", "xt", "=", "self", ".", "embed", "(", "it", ")", "\n", "\n", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ")", "\n", "\n", "return", "logprobs", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.sample_beam": [[125, 152], ["opt.get", "fc_feats.size", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.LongTensor().zero_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "range", "FCModel.FCModel.init_hidden", "range", "FCModel.FCModel.beam_search", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.LongTensor().zero_.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.FloatTensor.transpose", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "FCModel.FCModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "FCModel.FCModel.img_embed().expand", "FCModel.FCModel.logit", "fc_feats.data.new().long().zero_", "FCModel.FCModel.embed", "FCModel.FCModel.img_embed", "Variable", "fc_feats.data.new().long", "fc_feats.data.new"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.CaptionModel.CaptionModel.beam_search"], ["", "def", "sample_beam", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "10", ")", "\n", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "\n", "assert", "beam_size", "<=", "self", ".", "vocab_size", "+", "1", ",", "'lets assume this for now, otherwise this corner case causes a few headaches down the road. can be dealt with in future if needed'", "\n", "seq", "=", "torch", ".", "LongTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", ".", "zero_", "(", ")", "\n", "seqLogprobs", "=", "torch", ".", "FloatTensor", "(", "self", ".", "seq_length", ",", "batch_size", ")", "\n", "# lets process every image independently for now, for simplicity", "\n", "\n", "self", ".", "done_beams", "=", "[", "[", "]", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "state", "=", "self", ".", "init_hidden", "(", "beam_size", ")", "\n", "for", "t", "in", "range", "(", "2", ")", ":", "\n", "                ", "if", "t", "==", "0", ":", "\n", "                    ", "xt", "=", "self", ".", "img_embed", "(", "fc_feats", "[", "k", ":", "k", "+", "1", "]", ")", ".", "expand", "(", "beam_size", ",", "self", ".", "input_encoding_size", ")", "\n", "", "elif", "t", "==", "1", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "beam_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "xt", "=", "self", ".", "embed", "(", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ")", "\n", "\n", "", "self", ".", "done_beams", "[", "k", "]", "=", "self", ".", "beam_search", "(", "state", ",", "logprobs", ",", "opt", "=", "opt", ")", "\n", "seq", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'seq'", "]", "# the first beam has highest cumulative score", "\n", "seqLogprobs", "[", ":", ",", "k", "]", "=", "self", ".", "done_beams", "[", "k", "]", "[", "0", "]", "[", "'logps'", "]", "\n", "# return the samples and their log likelihoods", "\n", "", "return", "seq", ".", "transpose", "(", "0", ",", "1", ")", ",", "seqLogprobs", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.sample": [[153, 201], ["opt.get", "opt.get", "opt.get", "fc_feats.size", "FCModel.FCModel.init_hidden", "range", "FCModel.FCModel.sample_beam", "FCModel.FCModel.core", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "FCModel.FCModel.img_embed", "FCModel.FCModel.embed", "seq.append", "seqLogprobs.append", "FCModel.FCModel.logit", "fc_feats.data.new().long().zero_", "Variable", "unfinished.sum", "unfinished.type_as", "F.log_softmax.gather.view", "_.unsqueeze", "_.unsqueeze", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "it.view().long.view().long.view().long", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.multinomial().cuda", "torch.log_softmax.gather", "it.view().long.view().long.view().long", "fc_feats.data.new().long", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "torch.exp().cpu", "Variable", "it.view().long.view().long.view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "it.view().long.view().long.view", "fc_feats.data.new", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.init_hidden", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.FCModel.FCModel.sample_beam"], ["", "def", "sample", "(", "self", ",", "fc_feats", ",", "att_feats", ",", "opt", "=", "{", "}", ")", ":", "\n", "        ", "sample_max", "=", "opt", ".", "get", "(", "'sample_max'", ",", "1", ")", "\n", "beam_size", "=", "opt", ".", "get", "(", "'beam_size'", ",", "1", ")", "\n", "temperature", "=", "opt", ".", "get", "(", "'temperature'", ",", "1.0", ")", "\n", "if", "beam_size", ">", "1", ":", "\n", "            ", "return", "self", ".", "sample_beam", "(", "fc_feats", ",", "att_feats", ",", "opt", ")", "\n", "\n", "", "batch_size", "=", "fc_feats", ".", "size", "(", "0", ")", "\n", "state", "=", "self", ".", "init_hidden", "(", "batch_size", ")", "\n", "seq", "=", "[", "]", "\n", "seqLogprobs", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "seq_length", "+", "2", ")", ":", "\n", "            ", "if", "t", "==", "0", ":", "\n", "                ", "xt", "=", "self", ".", "img_embed", "(", "fc_feats", ")", "\n", "", "else", ":", "\n", "                ", "if", "t", "==", "1", ":", "# input <bos>", "\n", "                    ", "it", "=", "fc_feats", ".", "data", ".", "new", "(", "batch_size", ")", ".", "long", "(", ")", ".", "zero_", "(", ")", "\n", "", "elif", "sample_max", ":", "\n", "                    ", "sampleLogprobs", ",", "it", "=", "torch", ".", "max", "(", "logprobs", ".", "data", ",", "1", ")", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                    ", "if", "temperature", "==", "1.0", ":", "\n", "                        ", "prob_prev", "=", "torch", ".", "exp", "(", "logprobs", ".", "data", ")", ".", "cpu", "(", ")", "# fetch prev distribution: shape Nx(M+1)", "\n", "", "else", ":", "\n", "# scale logprobs by temperature", "\n", "                        ", "prob_prev", "=", "torch", ".", "exp", "(", "torch", ".", "div", "(", "logprobs", ".", "data", ",", "temperature", ")", ")", ".", "cpu", "(", ")", "\n", "", "it", "=", "torch", ".", "multinomial", "(", "prob_prev", ",", "1", ")", ".", "cuda", "(", ")", "\n", "sampleLogprobs", "=", "logprobs", ".", "gather", "(", "1", ",", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "# gather the logprobs at sampled positions", "\n", "it", "=", "it", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "# and flatten indices for downstream processing", "\n", "\n", "", "xt", "=", "self", ".", "embed", "(", "Variable", "(", "it", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n", "", "if", "t", ">=", "2", ":", "\n", "# stop when all finished", "\n", "                ", "if", "t", "==", "2", ":", "\n", "                    ", "unfinished", "=", "it", ">", "0", "\n", "", "else", ":", "\n", "                    ", "unfinished", "=", "unfinished", "*", "(", "it", ">", "0", ")", "\n", "", "if", "unfinished", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "break", "\n", "", "it", "=", "it", "*", "unfinished", ".", "type_as", "(", "it", ")", "\n", "seq", ".", "append", "(", "it", ")", "#seq[t] the input of t+2 time step", "\n", "seqLogprobs", ".", "append", "(", "sampleLogprobs", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "", "output", ",", "state", "=", "self", ".", "core", "(", "xt", ",", "state", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "self", ".", "logit", "(", "output", ")", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seq", "]", ",", "1", ")", ",", "torch", ".", "cat", "(", "[", "_", ".", "unsqueeze", "(", "1", ")", "for", "_", "in", "seqLogprobs", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.models.__init__.setup": [[14, 52], ["ShowTellModel.ShowTellModel", "vars().get", "os.path.isdir", "os.path.isfile", "AttModel.TopDownModel.load_state_dict", "OldModel.ShowAttendTellModel", "os.path.join", "torch.load", "OldModel.AllImgModel", "vars", "os.path.join", "FCModel.FCModel", "Att2inModel.Att2inModel", "AttModel.Att2in2Model", "AttModel.AdaAttModel", "AttModel.AdaAttMOModel", "AttModel.TopDownModel", "Exception"], "function", ["None"], ["def", "setup", "(", "opt", ")", ":", "\n", "\n", "    ", "if", "opt", ".", "caption_model", "==", "'show_tell'", ":", "\n", "        ", "model", "=", "ShowTellModel", "(", "opt", ")", "\n", "", "elif", "opt", ".", "caption_model", "==", "'show_attend_tell'", ":", "\n", "        ", "model", "=", "ShowAttendTellModel", "(", "opt", ")", "\n", "# img is concatenated with word embedding at every time step as the input of lstm", "\n", "", "elif", "opt", ".", "caption_model", "==", "'all_img'", ":", "\n", "        ", "model", "=", "AllImgModel", "(", "opt", ")", "\n", "# FC model in self-critical", "\n", "", "elif", "opt", ".", "caption_model", "==", "'fc'", ":", "\n", "        ", "model", "=", "FCModel", "(", "opt", ")", "\n", "# Att2in model in self-critical", "\n", "", "elif", "opt", ".", "caption_model", "==", "'att2in'", ":", "\n", "        ", "model", "=", "Att2inModel", "(", "opt", ")", "\n", "# Att2in model with two-layer MLP img embedding and word embedding", "\n", "", "elif", "opt", ".", "caption_model", "==", "'att2in2'", ":", "\n", "        ", "model", "=", "Att2in2Model", "(", "opt", ")", "\n", "# Adaptive Attention model from Knowing when to look", "\n", "", "elif", "opt", ".", "caption_model", "==", "'adaatt'", ":", "\n", "        ", "model", "=", "AdaAttModel", "(", "opt", ")", "\n", "# Adaptive Attention with maxout lstm", "\n", "", "elif", "opt", ".", "caption_model", "==", "'adaattmo'", ":", "\n", "        ", "model", "=", "AdaAttMOModel", "(", "opt", ")", "\n", "# Top-down attention model", "\n", "", "elif", "opt", ".", "caption_model", "==", "'topdown'", ":", "\n", "        ", "model", "=", "TopDownModel", "(", "opt", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Caption model not supported: {}\"", ".", "format", "(", "opt", ".", "caption_model", ")", ")", "\n", "\n", "# check compatibility if training is continued from previously saved model", "\n", "", "if", "vars", "(", "opt", ")", ".", "get", "(", "'start_from'", ",", "None", ")", "is", "not", "None", ":", "\n", "# check if all necessary files exist ", "\n", "        ", "assert", "os", ".", "path", ".", "isdir", "(", "opt", ".", "start_from", ")", ",", "\" %s must be a a path\"", "%", "opt", ".", "start_from", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "\"infos_\"", "+", "opt", ".", "id", "+", "\".pkl\"", ")", ")", ",", "\"infos.pkl file does not exist in path %s\"", "%", "opt", ".", "start_from", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'model.pth'", ")", ")", ")", "\n", "\n", "", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.BasicBlock.__init__": [[28, 37], ["torch.Module.__init__", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.conv3x3", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.BasicBlock.forward": [[38, 55], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.Bottleneck.__init__": [[60, 72], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "# change", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "# change", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "4", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.Bottleneck.forward": [[73, 94], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.ResNet.__init__": [[97, 119], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ")", ":", "\n", "        ", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "0", ",", "ceil_mode", "=", "True", ")", "# change", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "7", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.ResNet._make_layer": [[120, 136], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.ResNet.forward": [[137, 153], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4", "resnet.ResNet.avgpool", "resnet.ResNet.view", "resnet.ResNet.fc", "resnet.ResNet.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.conv3x3": [[19, 23], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"3x3 convolution with padding\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.resnet18": [[155, 165], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "", "def", "resnet18", "(", "pretrained", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet18'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.resnet34": [[167, 177], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet34'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.resnet50": [[179, 189], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet50'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.resnet101": [[191, 201], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet101'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet.resnet152": [[203, 213], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet152'", "]", ")", ")", "\n", "", "return", "model", "", "", ""]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.LeakyReLUConv1d.__init__": [[23, 30], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "utils.LeakyReLUConv1d.model.apply", "torch.Conv1d", "torch.Conv1d", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["  ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_out", ",", "kernel_size", ",", "stride", ",", "padding", "=", "0", ")", ":", "\n", "    ", "super", "(", "LeakyReLUConv1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "model", "=", "[", "]", "\n", "model", "+=", "[", "nn", ".", "Conv1d", "(", "n_in", ",", "n_out", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "bias", "=", "True", ")", "]", "\n", "model", "+=", "[", "nn", ".", "LeakyReLU", "(", "inplace", "=", "True", ")", "]", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "self", ".", "model", ".", "apply", "(", "gaussian_weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.LeakyReLUConv1d.forward": [[31, 33], ["utils.LeakyReLUConv1d.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.LeakyReLUBNConv1d.__init__": [[35, 43], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "utils.LeakyReLUBNConv1d.model.apply", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["  ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_out", ",", "kernel_size", ",", "stride", ",", "padding", "=", "0", ")", ":", "\n", "    ", "super", "(", "LeakyReLUBNConv1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "model", "=", "[", "]", "\n", "model", "+=", "[", "nn", ".", "Conv1d", "(", "n_in", ",", "n_out", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "bias", "=", "False", ")", "]", "\n", "model", "+=", "[", "nn", ".", "BatchNorm1d", "(", "n_out", ")", "]", "\n", "model", "+=", "[", "nn", ".", "LeakyReLU", "(", "inplace", "=", "True", ")", "]", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "self", ".", "model", ".", "apply", "(", "gaussian_weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.LeakyReLUBNConv1d.forward": [[44, 46], ["utils.LeakyReLUBNConv1d.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.LeakyReLUBNConv2d.__init__": [[48, 56], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "utils.LeakyReLUBNConv2d.model.apply", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["  ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_out", ",", "kernel_size", ",", "stride", ",", "padding", "=", "0", ")", ":", "\n", "    ", "super", "(", "LeakyReLUBNConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "model", "=", "[", "]", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "n_in", ",", "n_out", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "bias", "=", "False", ")", "]", "\n", "model", "+=", "[", "nn", ".", "BatchNorm2d", "(", "n_out", ")", "]", "\n", "model", "+=", "[", "nn", ".", "LeakyReLU", "(", "inplace", "=", "True", ")", "]", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "self", ".", "model", ".", "apply", "(", "gaussian_weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.LeakyReLUBNConv2d.forward": [[57, 59], ["utils.LeakyReLUBNConv2d.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "model", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.LeakyReLUConv2d.__init__": [[61, 68], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "utils.LeakyReLUConv2d.model.apply", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["  ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_out", ",", "kernel_size", ",", "stride", ",", "padding", "=", "0", ")", ":", "\n", "    ", "super", "(", "LeakyReLUConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "model", "=", "[", "]", "\n", "model", "+=", "[", "nn", ".", "Conv2d", "(", "n_in", ",", "n_out", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "bias", "=", "True", ")", "]", "\n", "model", "+=", "[", "nn", ".", "LeakyReLU", "(", "inplace", "=", "True", ")", "]", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "self", ".", "model", ".", "apply", "(", "gaussian_weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.LeakyReLUConv2d.forward": [[69, 71], ["utils.LeakyReLUConv2d.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "model", "(", "x", ")", "\n", "##################################################################################", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.INSResBlock.conv1x1": [[75, 77], ["torch.Conv2d", "torch.Conv2d"], "methods", ["None"], ["  ", "def", "conv1x1", "(", "self", ",", "inplanes", ",", "out_planes", ",", "kernel", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", ":", "\n", "    ", "return", "nn", ".", "Conv2d", "(", "inplanes", ",", "out_planes", ",", "kernel_size", "=", "kernel", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.INSResBlock.__init__": [[78, 90], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "utils.INSResBlock.model.apply", "utils.INSResBlock.conv1x1", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.ReLU", "torch.ReLU", "utils.INSResBlock.conv1x1", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.INSResBlock.conv1x1", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.INSResBlock.conv1x1"], ["", "def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "kernel", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "dropout", "=", "0.0", ")", ":", "\n", "    ", "super", "(", "INSResBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "model", "=", "[", "]", "\n", "model", "+=", "[", "self", ".", "conv1x1", "(", "inplanes", ",", "planes", ",", "kernel", ",", "stride", ",", "padding", ")", "]", "\n", "model", "+=", "[", "nn", ".", "InstanceNorm2d", "(", "planes", ")", "]", "\n", "model", "+=", "[", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "]", "\n", "model", "+=", "[", "self", ".", "conv1x1", "(", "planes", ",", "planes", ",", "kernel", ",", "stride", ",", "padding", ")", "]", "\n", "model", "+=", "[", "nn", ".", "InstanceNorm2d", "(", "planes", ")", "]", "\n", "if", "dropout", ">", "0", ":", "\n", "      ", "model", "+=", "[", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "]", "\n", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "*", "model", ")", "\n", "self", ".", "model", ".", "apply", "(", "gaussian_weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.INSResBlock.forward": [[91, 96], ["utils.INSResBlock.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "    ", "residual", "=", "x", "\n", "out", "=", "self", ".", "model", "(", "x", ")", "\n", "out", "+=", "residual", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.LanguageModelCriterion.__init__": [[161, 163], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "opt", ")", ":", "\n", "        ", "super", "(", "LanguageModelCriterion", ",", "opt", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.LanguageModelCriterion.forward": [[164, 175], ["to_contiguous().view", "to_contiguous().view", "to_contiguous().view", "to_contiguous().view.size", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "utils.to_contiguous", "utils.to_contiguous", "utils.to_contiguous", "to_contiguous().view.gather", "to_contiguous().view.size", "to_contiguous().view.size"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.to_contiguous", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.to_contiguous", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.to_contiguous"], ["", "def", "forward", "(", "opt", ",", "input", ",", "target", ",", "mask", ",", "coverage", "=", "None", ")", ":", "\n", "# truncate to the same size", "\n", "        ", "target", "=", "target", "[", ":", ",", ":", "input", ".", "size", "(", "1", ")", "]", "\n", "mask", "=", "mask", "[", ":", ",", ":", "input", ".", "size", "(", "1", ")", "]", "\n", "input", "=", "to_contiguous", "(", "input", ")", ".", "view", "(", "-", "1", ",", "input", ".", "size", "(", "2", ")", ")", "\n", "target", "=", "to_contiguous", "(", "target", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "mask", "=", "to_contiguous", "(", "mask", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "output", "=", "-", "input", ".", "gather", "(", "1", ",", "target", ")", "*", "mask", "\n", "output", "=", "torch", ".", "sum", "(", "output", ")", "/", "torch", ".", "sum", "(", "mask", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.gaussian_weights_init": [[16, 21], ["m.weight.data.normal_", "classname.find", "classname.find"], "function", ["None"], ["def", "gaussian_weights_init", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", "and", "classname", ".", "find", "(", "'Conv'", ")", "==", "0", ":", "\n", "# print m.__class__.__name__", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.build_cnn": [[97, 113], ["torch.Sequential", "getattr", "nn.Sequential.load_state_dict", "vars().get", "nn.Sequential.load_state_dict", "vars().get", "vars().get", "torch.load", "torch.load", "torch.load", "torch.load", "vars", "os.path.join", "vars", "vars"], "function", ["None"], ["", "", "def", "build_cnn", "(", "opt", ")", ":", "\n", "    ", "net", "=", "getattr", "(", "resnet", ",", "opt", ".", "cnn_model", ")", "(", ")", "\n", "if", "vars", "(", "opt", ")", ".", "get", "(", "'start_from'", ",", "None", ")", "is", "None", "and", "vars", "(", "opt", ")", ".", "get", "(", "'cnn_weight'", ",", "''", ")", "!=", "''", ":", "\n", "        ", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "opt", ".", "cnn_weight", ")", ")", "\n", "", "net", "=", "nn", ".", "Sequential", "(", "net", ".", "conv1", ",", "\n", "net", ".", "bn1", ",", "\n", "net", ".", "relu", ",", "\n", "net", ".", "maxpool", ",", "\n", "net", ".", "layer1", ",", "\n", "net", ".", "layer2", ",", "\n", "net", ".", "layer3", ",", "\n", "net", ".", "layer4", ")", "\n", "if", "vars", "(", "opt", ")", ".", "get", "(", "'start_from'", ",", "None", ")", "is", "not", "None", ":", "\n", "        ", "net", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "start_from", ",", "'model-cnn.pth'", ")", ")", ")", "\n", "", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.prepro_images": [[114, 130], ["random.randint", "random.randint"], "function", ["None"], ["", "def", "prepro_images", "(", "imgs", ",", "data_augment", "=", "False", ")", ":", "\n", "# crop the image", "\n", "    ", "h", ",", "w", "=", "imgs", ".", "shape", "[", "2", "]", ",", "imgs", ".", "shape", "[", "3", "]", "\n", "cnn_input_size", "=", "224", "\n", "\n", "# cropping data augmentation, if needed", "\n", "if", "h", ">", "cnn_input_size", "or", "w", ">", "cnn_input_size", ":", "\n", "        ", "if", "data_augment", ":", "\n", "          ", "xoff", ",", "yoff", "=", "random", ".", "randint", "(", "0", ",", "w", "-", "cnn_input_size", ")", ",", "random", ".", "randint", "(", "0", ",", "h", "-", "cnn_input_size", ")", "\n", "", "else", ":", "\n", "# sample the center", "\n", "          ", "xoff", ",", "yoff", "=", "(", "w", "-", "cnn_input_size", ")", "//", "2", ",", "(", "h", "-", "cnn_input_size", ")", "//", "2", "\n", "# crop.", "\n", "", "", "imgs", "=", "imgs", "[", ":", ",", ":", ",", "yoff", ":", "yoff", "+", "cnn_input_size", ",", "xoff", ":", "xoff", "+", "cnn_input_size", "]", "\n", "\n", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.if_use_att": [[131, 136], ["None"], "function", ["None"], ["", "def", "if_use_att", "(", "caption_model", ")", ":", "\n", "# Decide if load attention feature according to caption model", "\n", "    ", "if", "caption_model", "in", "[", "'show_tell'", ",", "'all_img'", ",", "'fc'", "]", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.decode_sequence": [[138, 153], ["seq.size", "range", "range", "out.append", "seq[].cpu().numpy", "seq[].cpu", "str"], "function", ["None"], ["", "def", "decode_sequence", "(", "ix_to_word", ",", "seq", ")", ":", "\n", "    ", "N", ",", "D", "=", "seq", ".", "size", "(", ")", "\n", "out", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "        ", "txt", "=", "''", "\n", "for", "j", "in", "range", "(", "D", ")", ":", "\n", "            ", "ix", "=", "seq", "[", "i", ",", "j", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "ix", ">", "0", ":", "\n", "                ", "if", "j", ">=", "1", ":", "\n", "                    ", "txt", "=", "txt", "+", "' '", "\n", "", "txt", "=", "txt", "+", "ix_to_word", "[", "str", "(", "ix", ")", "]", "\n", "", "else", ":", "\n", "                ", "break", "\n", "", "", "out", ".", "append", "(", "txt", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.to_contiguous": [[154, 159], ["tensor.is_contiguous", "tensor.contiguous"], "function", ["None"], ["", "def", "to_contiguous", "(", "tensor", ")", ":", "\n", "    ", "if", "tensor", ".", "is_contiguous", "(", ")", ":", "\n", "        ", "return", "tensor", "\n", "", "else", ":", "\n", "        ", "return", "tensor", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.set_lr": [[176, 179], ["None"], "function", ["None"], ["", "", "def", "set_lr", "(", "optimizer", ",", "lr", ")", ":", "\n", "    ", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.utils.clip_gradient": [[180, 185], ["hasattr", "param.grad.data.clamp_"], "function", ["None"], ["", "", "def", "clip_gradient", "(", "optimizer", ",", "grad_clip", ")", ":", "\n", "    ", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "for", "param", "in", "group", "[", "'params'", "]", ":", "\n", "            ", "if", "hasattr", "(", "param", ",", "'grad'", ")", ":", "\n", "                ", "param", ".", "grad", ".", "data", ".", "clamp_", "(", "-", "grad_clip", ",", "grad_clip", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__": [[7, 10], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "resnet", ")", ":", "\n", "        ", "super", "(", "myResnet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "resnet", "=", "resnet", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.misc.resnet_utils.myResnet.forward": [[11, 28], ["img.unsqueeze", "resnet_utils.myResnet.resnet.conv1", "resnet_utils.myResnet.resnet.bn1", "resnet_utils.myResnet.resnet.relu", "resnet_utils.myResnet.resnet.maxpool", "resnet_utils.myResnet.resnet.layer1", "resnet_utils.myResnet.resnet.layer2", "resnet_utils.myResnet.resnet.layer3", "resnet_utils.myResnet.resnet.layer4", "resnet_utils.myResnet.mean().mean().squeeze", "torch.adaptive_avg_pool2d().squeeze().permute", "torch.adaptive_avg_pool2d().squeeze().permute", "torch.adaptive_avg_pool2d().squeeze().permute", "resnet_utils.myResnet.mean().mean", "torch.adaptive_avg_pool2d().squeeze", "torch.adaptive_avg_pool2d().squeeze", "torch.adaptive_avg_pool2d().squeeze", "resnet_utils.myResnet.mean", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "img", ",", "att_size", "=", "14", ")", ":", "\n", "        ", "x", "=", "img", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "x", "=", "self", ".", "resnet", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "resnet", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "resnet", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "resnet", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "resnet", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "resnet", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "resnet", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "resnet", ".", "layer4", "(", "x", ")", "\n", "\n", "fc", "=", "x", ".", "mean", "(", "3", ")", ".", "mean", "(", "2", ")", ".", "squeeze", "(", ")", "\n", "att", "=", "F", ".", "adaptive_avg_pool2d", "(", "x", ",", "[", "att_size", ",", "att_size", "]", ")", ".", "squeeze", "(", ")", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "\n", "return", "fc", ",", "att", "\n", "\n"]], "home.repos.pwc.inspect_result.furkanbiten_GoodNews.with_api.retrieve_all_urls.convert": [[6, 15], ["isinstance", "isinstance", "retrieve_all_urls.convert", "retrieve_all_urls.convert", "isinstance", "input.iteritems", "retrieve_all_urls.convert", "input.encode"], "function", ["home.repos.pwc.inspect_result.furkanbiten_GoodNews.with_api.retrieve_all_urls.convert", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.with_api.retrieve_all_urls.convert", "home.repos.pwc.inspect_result.furkanbiten_GoodNews.with_api.retrieve_all_urls.convert"], ["def", "convert", "(", "input", ")", ":", "\n", "    ", "if", "isinstance", "(", "input", ",", "dict", ")", ":", "\n", "        ", "return", "{", "convert", "(", "key", ")", ":", "convert", "(", "value", ")", "for", "key", ",", "value", "in", "input", ".", "iteritems", "(", ")", "}", "\n", "", "elif", "isinstance", "(", "input", ",", "list", ")", ":", "\n", "        ", "return", "[", "convert", "(", "element", ")", "for", "element", "in", "input", "]", "\n", "", "elif", "isinstance", "(", "input", ",", "unicode", ")", ":", "\n", "        ", "return", "input", ".", "encode", "(", "'utf-8'", ")", "\n", "", "else", ":", "\n", "        ", "return", "input", "\n", "\n"]]}