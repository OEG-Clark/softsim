{"home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.preprocess": [[72, 76], ["tensorflow.name_scope"], "function", ["None"], ["def", "preprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess\"", ")", ":", "\n", "# [0, 1] => [-1, 1]", "\n", "        ", "return", "image", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.deprocess": [[78, 82], ["tensorflow.name_scope"], "function", ["None"], ["", "", "def", "deprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess\"", ")", ":", "\n", "# [-1, 1] => [0, 1]", "\n", "        ", "return", "(", "image", "+", "1", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.preprocess_lab": [[84, 91], ["tensorflow.name_scope", "tensorflow.unstack"], "function", ["None"], ["", "", "def", "preprocess_lab", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess_lab\"", ")", ":", "\n", "        ", "L_chan", ",", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "lab", ",", "axis", "=", "2", ")", "\n", "# L_chan: black and white with input range [0, 100]", "\n", "# a_chan/b_chan: color channels with input range ~[-110, 110], not exact", "\n", "# [0, 100] => [-1, 1],  ~[-110, 110] => [-1, 1]", "\n", "return", "[", "L_chan", "/", "50", "-", "1", ",", "a_chan", "/", "110", ",", "b_chan", "/", "110", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.deprocess_lab": [[93, 97], ["tensorflow.name_scope", "tensorflow.stack"], "function", ["None"], ["", "", "def", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess_lab\"", ")", ":", "\n", "# this is axis=3 instead of axis=2 because we process individual images but deprocess batches", "\n", "        ", "return", "tf", ".", "stack", "(", "[", "(", "L_chan", "+", "1", ")", "/", "2", "*", "100", ",", "a_chan", "*", "110", ",", "b_chan", "*", "110", "]", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.augment": [[99, 106], ["tensorflow.unstack", "tensorflow.squeeze", "pix2pix_0orig_cv.deprocess_lab", "pix2pix_0orig_cv.lab_to_rgb"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess_lab", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lab_to_rgb"], ["", "", "def", "augment", "(", "image", ",", "brightness", ")", ":", "\n", "# (a, b) color channels, combine with L channel and convert to rgb", "\n", "    ", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "image", ",", "axis", "=", "3", ")", "\n", "L_chan", "=", "tf", ".", "squeeze", "(", "brightness", ",", "axis", "=", "3", ")", "\n", "lab", "=", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", "\n", "rgb", "=", "lab_to_rgb", "(", "lab", ")", "\n", "return", "rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.discrim_conv": [[108, 111], ["tensorflow.pad", "tensorflow.layers.conv2d", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "discrim_conv", "(", "batch_input", ",", "out_channels", ",", "stride", ")", ":", "\n", "    ", "padded_input", "=", "tf", ".", "pad", "(", "batch_input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"CONSTANT\"", ")", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "padded_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "stride", ",", "stride", ")", ",", "padding", "=", "\"valid\"", ",", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.gen_conv": [[113, 120], ["tensorflow.random_normal_initializer", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d"], "function", ["None"], ["", "def", "gen_conv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.gen_deconv": [[122, 131], ["tensorflow.random_normal_initializer", "tensorflow.image.resize_images", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d_transpose"], "function", ["None"], ["", "", "def", "gen_deconv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "_b", ",", "h", ",", "w", ",", "_c", "=", "batch_input", ".", "shape", "\n", "resized_input", "=", "tf", ".", "image", ".", "resize_images", "(", "batch_input", ",", "[", "h", "*", "2", ",", "w", "*", "2", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "resized_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d_transpose", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.lrelu": [[133, 143], ["tensorflow.name_scope", "tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["", "", "def", "lrelu", "(", "x", ",", "a", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lrelu\"", ")", ":", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: a*x/2 - a*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "        ", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.batchnorm": [[145, 147], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "", "def", "batchnorm", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.create_generator": [[148, 224], ["print", "print", "print", "len", "enumerate", "tensorflow.variable_scope", "pix2pix_0orig_cv.gen_conv", "layers.append", "print", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.nn.relu", "pix2pix_0orig_cv.gen_deconv", "tensorflow.tanh", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_0orig_cv.lrelu", "pix2pix_0orig_cv.gen_conv", "pix2pix_0orig_cv.batchnorm", "layers.append", "print", "tensorflow.variable_scope", "tensorflow.nn.relu", "pix2pix_0orig_cv.gen_deconv", "pix2pix_0orig_cv.batchnorm", "layers.append", "print", "tensorflow.concat", "tensorflow.nn.dropout", "len"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm"], ["", "def", "create_generator", "(", "generator_inputs", ",", "generator_outputs_channels", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "\n", "print", "(", "'encoder:'", ")", "\n", "print", "(", "generator_inputs", ".", "shape", ")", "\n", "\n", "# encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_1\"", ")", ":", "\n", "        ", "output", "=", "gen_conv", "(", "generator_inputs", ",", "a", ".", "ngf", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "a", ".", "ngf", "*", "2", ",", "# encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]", "\n", "a", ".", "ngf", "*", "4", ",", "# encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]", "\n", "]", "\n", "\n", "for", "out_channels", "in", "layer_specs", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]", "\n", "convolved", "=", "gen_conv", "(", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "\n", "", "", "print", "(", "'decoder:'", ")", "\n", "\n", "layer_specs", "=", "[", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.0", ")", ",", "# decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "4", ",", "0.0", ")", ",", "# decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]", "\n", "(", "a", ".", "ngf", "*", "2", ",", "0.0", ")", ",", "# decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]", "\n", "(", "a", ".", "ngf", ",", "0.0", ")", ",", "# decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]", "\n", "]", "\n", "\n", "\n", "num_encoder_layers", "=", "len", "(", "layers", ")", "\n", "for", "decoder_layer", ",", "(", "out_channels", ",", "dropout", ")", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "skip_layer", "=", "num_encoder_layers", "-", "decoder_layer", "-", "1", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder_%d\"", "%", "(", "skip_layer", "+", "1", ")", ")", ":", "\n", "            ", "if", "decoder_layer", "==", "0", ":", "\n", "# first decoder layer doesn't have skip connections", "\n", "# since it is directly connected to the skip_layer", "\n", "                ", "input", "=", "layers", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "skip_layer", "]", "]", ",", "axis", "=", "3", ")", "\n", "\n", "", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batchnorm", "(", "output", ")", "\n", "\n", "if", "dropout", ">", "0.0", ":", "\n", "                ", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "keep_prob", "=", "1", "-", "dropout", ")", "\n", "\n", "", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "# decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"decoder_1\"", ")", ":", "\n", "        ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "0", "]", "]", ",", "axis", "=", "3", ")", "\n", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "generator_outputs_channels", ")", "\n", "output", "=", "tf", ".", "tanh", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.create_model": [[228, 326], ["tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "print", "tensorflow.concat", "range", "tensorflow.variable_scope", "int", "pix2pix_0orig_cv.create_generator", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.variable_scope", "pix2pix_0orig_cv.discrim_conv", "pix2pix_0orig_cv.lrelu", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_0orig_cv.discrim_conv", "tensorflow.sigmoid", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_0orig_cv.create_model.create_discriminator"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_generator", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv"], ["", "def", "create_model", "(", "inputs", ",", "targets", ")", ":", "\n", "\n", "    ", "def", "create_discriminator", "(", "discrim_inputs", ",", "discrim_targets", ")", ":", "\n", "        ", "n_layers", "=", "3", "\n", "layers", "=", "[", "]", "\n", "print", "(", "'discriminator:'", ")", "\n", "\n", "# 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]", "\n", "input", "=", "tf", ".", "concat", "(", "[", "discrim_inputs", ",", "discrim_targets", "]", ",", "axis", "=", "3", ")", "\n", "\n", "# layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"layer_1\"", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "input", ",", "a", ".", "ndf", ",", "stride", "=", "2", ")", "\n", "rectified", "=", "lrelu", "(", "convolved", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]", "\n", "# layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]", "\n", "# layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]", "\n", "", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "                ", "out_channels", "=", "a", ".", "ndf", "*", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "stride", "=", "1", "if", "i", "==", "n_layers", "-", "1", "else", "2", "# last layer here has stride 1", "\n", "convolved", "=", "discrim_conv", "(", "layers", "[", "-", "1", "]", ",", "out_channels", ",", "stride", "=", "stride", ")", "\n", "normalized", "=", "batchnorm", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "\n", "# layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "rectified", ",", "out_channels", "=", "1", ",", "stride", "=", "1", ")", "\n", "output", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "        ", "out_channels", "=", "int", "(", "targets", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "outputs", "=", "create_generator", "(", "inputs", ",", "out_channels", ")", "\n", "\n", "# create two copies of discriminator, one for real pairs and one for fake pairs", "\n", "# they share the same underlying variables", "\n", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_real", "=", "create_discriminator", "(", "inputs", ",", "targets", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ",", "reuse", "=", "True", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_fake", "=", "create_discriminator", "(", "inputs", ",", "outputs", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_loss\"", ")", ":", "\n", "# minimizing -tf.log will try to get inputs to 1", "\n", "# predict_real => 1", "\n", "# predict_fake => 0", "\n", "        ", "discrim_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_loss\"", ")", ":", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "        ", "gen_loss_GAN", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_fake", "+", "EPS", ")", ")", "\n", "gen_loss_L1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "targets", "-", "outputs", ")", ")", "\n", "gen_loss", "=", "gen_loss_GAN", "*", "a", ".", "gan_weight", "+", "gen_loss_L1", "*", "a", ".", "l1_weight", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_train\"", ")", ":", "\n", "        ", "discrim_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"discriminator\"", ")", "]", "\n", "discrim_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "discrim_grads_and_vars", "=", "discrim_optim", ".", "compute_gradients", "(", "discrim_loss", ",", "var_list", "=", "discrim_tvars", ")", "\n", "discrim_train", "=", "discrim_optim", ".", "apply_gradients", "(", "discrim_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_train", "]", ")", ":", "\n", "            ", "gen_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"generator\"", ")", "]", "\n", "gen_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "gen_grads_and_vars", "=", "gen_optim", ".", "compute_gradients", "(", "gen_loss", ",", "var_list", "=", "gen_tvars", ")", "\n", "gen_train", "=", "gen_optim", ".", "apply_gradients", "(", "gen_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_loss", ",", "gen_loss_GAN", ",", "gen_loss_L1", "]", ")", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "return", "Model", "(", "\n", "predict_real", "=", "predict_real", ",", "\n", "predict_fake", "=", "predict_fake", ",", "\n", "discrim_loss", "=", "ema", ".", "average", "(", "discrim_loss", ")", ",", "\n", "discrim_grads_and_vars", "=", "discrim_grads_and_vars", ",", "\n", "gen_loss_GAN", "=", "ema", ".", "average", "(", "gen_loss_GAN", ")", ",", "\n", "gen_loss_L1", "=", "ema", ".", "average", "(", "gen_loss_L1", ")", ",", "\n", "gen_grads_and_vars", "=", "gen_grads_and_vars", ",", "\n", "outputs", "=", "outputs", ",", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_train", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.check_image": [[329, 342], ["tensorflow.assert_equal", "list", "tf.identity.set_shape", "tensorflow.control_dependencies", "tensorflow.identity", "ValueError", "tf.identity.get_shape", "tensorflow.shape", "tf.identity.get_shape"], "function", ["None"], ["", "def", "check_image", "(", "image", ")", ":", "\n", "    ", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "image", ")", "[", "-", "1", "]", ",", "3", ",", "message", "=", "\"image must have 3 color channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "        ", "image", "=", "tf", ".", "identity", "(", "image", ")", "\n", "\n", "", "if", "image", ".", "get_shape", "(", ")", ".", "ndims", "not", "in", "(", "3", ",", "4", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"image must be either 3 or 4 dimensions\"", ")", "\n", "\n", "# make the last dimension 3 so that you can unstack the colors", "\n", "", "shape", "=", "list", "(", "image", ".", "get_shape", "(", ")", ")", "\n", "shape", "[", "-", "1", "]", "=", "3", "\n", "image", ".", "set_shape", "(", "shape", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.rgb_to_lab": [[344, 383], ["tensorflow.name_scope", "pix2pix_0orig_cv.check_image", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.name_scope", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.matmul", "tensorflow.name_scope", "tensorflow.multiply", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.shape", "tensorflow.matmul", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.check_image"], ["", "def", "rgb_to_lab", "(", "srgb", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"rgb_to_lab\"", ")", ":", "\n", "        ", "srgb", "=", "check_image", "(", "srgb", ")", "\n", "srgb_pixels", "=", "tf", ".", "reshape", "(", "srgb", ",", "[", "-", "1", ",", "3", "]", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"srgb_to_xyz\"", ")", ":", "\n", "            ", "linear_mask", "=", "tf", ".", "cast", "(", "srgb_pixels", "<=", "0.04045", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "srgb_pixels", ">", "0.04045", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "rgb_pixels", "=", "(", "srgb_pixels", "/", "12.92", "*", "linear_mask", ")", "+", "(", "(", "(", "srgb_pixels", "+", "0.055", ")", "/", "1.055", ")", "**", "2.4", ")", "*", "exponential_mask", "\n", "rgb_to_xyz", "=", "tf", ".", "constant", "(", "[", "\n", "#    X        Y          Z", "\n", "[", "0.412453", ",", "0.212671", ",", "0.019334", "]", ",", "# R", "\n", "[", "0.357580", ",", "0.715160", ",", "0.119193", "]", ",", "# G", "\n", "[", "0.180423", ",", "0.072169", ",", "0.950227", "]", ",", "# B", "\n", "]", ")", "\n", "xyz_pixels", "=", "tf", ".", "matmul", "(", "rgb_pixels", ",", "rgb_to_xyz", ")", "\n", "\n", "# https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions", "\n", "", "with", "tf", ".", "name_scope", "(", "\"xyz_to_cielab\"", ")", ":", "\n", "# convert to fx = f(X/Xn), fy = f(Y/Yn), fz = f(Z/Zn)", "\n", "\n", "# normalize for D65 white point", "\n", "            ", "xyz_normalized_pixels", "=", "tf", ".", "multiply", "(", "xyz_pixels", ",", "[", "1", "/", "0.950456", ",", "1.0", ",", "1", "/", "1.088754", "]", ")", "\n", "\n", "epsilon", "=", "6", "/", "29", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "xyz_normalized_pixels", "<=", "(", "epsilon", "**", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "xyz_normalized_pixels", ">", "(", "epsilon", "**", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "fxfyfz_pixels", "=", "(", "xyz_normalized_pixels", "/", "(", "3", "*", "epsilon", "**", "2", ")", "+", "4", "/", "29", ")", "*", "linear_mask", "+", "(", "xyz_normalized_pixels", "**", "(", "1", "/", "3", ")", ")", "*", "exponential_mask", "\n", "\n", "# convert to lab", "\n", "fxfyfz_to_lab", "=", "tf", ".", "constant", "(", "[", "\n", "#  l       a       b", "\n", "[", "0.0", ",", "500.0", ",", "0.0", "]", ",", "# fx", "\n", "[", "116.0", ",", "-", "500.0", ",", "200.0", "]", ",", "# fy", "\n", "[", "0.0", ",", "0.0", ",", "-", "200.0", "]", ",", "# fz", "\n", "]", ")", "\n", "lab_pixels", "=", "tf", ".", "matmul", "(", "fxfyfz_pixels", ",", "fxfyfz_to_lab", ")", "+", "tf", ".", "constant", "(", "[", "-", "16.0", ",", "0.0", ",", "0.0", "]", ")", "\n", "\n", "", "return", "tf", ".", "reshape", "(", "lab_pixels", ",", "tf", ".", "shape", "(", "srgb", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.lab_to_rgb": [[385, 425], ["tensorflow.name_scope", "pix2pix_0orig_cv.check_image", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.name_scope", "tensorflow.constant", "tensorflow.matmul", "tensorflow.cast", "tensorflow.cast", "tensorflow.multiply", "tensorflow.name_scope", "tensorflow.constant", "tensorflow.matmul", "tensorflow.clip_by_value", "tensorflow.cast", "tensorflow.cast", "tensorflow.shape", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.check_image"], ["", "", "def", "lab_to_rgb", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lab_to_rgb\"", ")", ":", "\n", "        ", "lab", "=", "check_image", "(", "lab", ")", "\n", "lab_pixels", "=", "tf", ".", "reshape", "(", "lab", ",", "[", "-", "1", ",", "3", "]", ")", "\n", "\n", "# https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions", "\n", "with", "tf", ".", "name_scope", "(", "\"cielab_to_xyz\"", ")", ":", "\n", "# convert to fxfyfz", "\n", "            ", "lab_to_fxfyfz", "=", "tf", ".", "constant", "(", "[", "\n", "#   fx      fy        fz", "\n", "[", "1", "/", "116.0", ",", "1", "/", "116.0", ",", "1", "/", "116.0", "]", ",", "# l", "\n", "[", "1", "/", "500.0", ",", "0.0", ",", "0.0", "]", ",", "# a", "\n", "[", "0.0", ",", "0.0", ",", "-", "1", "/", "200.0", "]", ",", "# b", "\n", "]", ")", "\n", "fxfyfz_pixels", "=", "tf", ".", "matmul", "(", "lab_pixels", "+", "tf", ".", "constant", "(", "[", "16.0", ",", "0.0", ",", "0.0", "]", ")", ",", "lab_to_fxfyfz", ")", "\n", "\n", "# convert to xyz", "\n", "epsilon", "=", "6", "/", "29", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "fxfyfz_pixels", "<=", "epsilon", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "fxfyfz_pixels", ">", "epsilon", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "xyz_pixels", "=", "(", "3", "*", "epsilon", "**", "2", "*", "(", "fxfyfz_pixels", "-", "4", "/", "29", ")", ")", "*", "linear_mask", "+", "(", "fxfyfz_pixels", "**", "3", ")", "*", "exponential_mask", "\n", "\n", "# denormalize for D65 white point", "\n", "xyz_pixels", "=", "tf", ".", "multiply", "(", "xyz_pixels", ",", "[", "0.950456", ",", "1.0", ",", "1.088754", "]", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"xyz_to_srgb\"", ")", ":", "\n", "            ", "xyz_to_rgb", "=", "tf", ".", "constant", "(", "[", "\n", "#     r           g          b", "\n", "[", "3.2404542", ",", "-", "0.9692660", ",", "0.0556434", "]", ",", "# x", "\n", "[", "-", "1.5371385", ",", "1.8760108", ",", "-", "0.2040259", "]", ",", "# y", "\n", "[", "-", "0.4985314", ",", "0.0415560", ",", "1.0572252", "]", ",", "# z", "\n", "]", ")", "\n", "rgb_pixels", "=", "tf", ".", "matmul", "(", "xyz_pixels", ",", "xyz_to_rgb", ")", "\n", "# avoid a slightly negative number messing up the conversion", "\n", "rgb_pixels", "=", "tf", ".", "clip_by_value", "(", "rgb_pixels", ",", "0.0", ",", "1.0", ")", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "rgb_pixels", "<=", "0.0031308", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "rgb_pixels", ">", "0.0031308", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "srgb_pixels", "=", "(", "rgb_pixels", "*", "12.92", "*", "linear_mask", ")", "+", "(", "(", "rgb_pixels", "**", "(", "1", "/", "2.4", ")", "*", "1.055", ")", "-", "0.055", ")", "*", "exponential_mask", "\n", "\n", "", "return", "tf", ".", "reshape", "(", "srgb_pixels", ",", "tf", ".", "shape", "(", "lab", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.load_examples": [[427, 517], ["glob.glob", "all", "random.randint", "tensorflow.train.batch", "int", "Examples", "Exception", "os.path.join", "len", "glob.glob", "len", "Exception", "os.path.splitext", "sorted", "sorted", "tensorflow.name_scope", "tensorflow.train.string_input_producer", "tensorflow.WholeFileReader", "tf.WholeFileReader.read", "decode", "tensorflow.image.convert_image_dtype", "tensorflow.assert_equal", "tf.identity.set_shape", "tensorflow.image.resize_images", "tensorflow.cast", "tensorflow.name_scope", "pix2pix_0orig_cv.load_examples.transform"], "function", ["None"], ["", "", "def", "load_examples", "(", ")", ":", "\n", "    ", "if", "a", ".", "input_dir", "is", "None", "or", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "input_dir", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir does not exist\"", ")", "\n", "\n", "", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.jpg\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_jpeg", "\n", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.png\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_png", "\n", "\n", "", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir contains no image files\"", ")", "\n", "\n", "", "def", "get_name", "(", "path", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "\n", "return", "name", "\n", "\n", "# if the image names are numbers, sort by the value rather than asciibetically", "\n", "# having sorted inputs means that the outputs are sorted in test mode", "\n", "", "if", "all", "(", "get_name", "(", "path", ")", ".", "isdigit", "(", ")", "for", "path", "in", "input_paths", ")", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ",", "key", "=", "lambda", "path", ":", "int", "(", "get_name", "(", "path", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"load_images\"", ")", ":", "\n", "        ", "path_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "input_paths", ",", "shuffle", "=", "a", ".", "mode", "==", "\"train\"", ")", "\n", "reader", "=", "tf", ".", "WholeFileReader", "(", ")", "\n", "paths", ",", "contents", "=", "reader", ".", "read", "(", "path_queue", ")", "\n", "raw_input", "=", "decode", "(", "contents", ")", "\n", "raw_input", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "raw_input", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "raw_input", ")", "[", "2", "]", ",", "3", ",", "message", "=", "\"image does not have 3 channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "            ", "raw_input", "=", "tf", ".", "identity", "(", "raw_input", ")", "\n", "\n", "", "raw_input", ".", "set_shape", "(", "[", "None", ",", "None", ",", "3", "]", ")", "\n", "\n", "if", "a", ".", "lab_colorization", ":", "\n", "# load color and brightness from image, no B image exists here", "\n", "            ", "lab", "=", "rgb_to_lab", "(", "raw_input", ")", "\n", "L_chan", ",", "a_chan", ",", "b_chan", "=", "preprocess_lab", "(", "lab", ")", "\n", "a_images", "=", "tf", ".", "expand_dims", "(", "L_chan", ",", "axis", "=", "2", ")", "\n", "b_images", "=", "tf", ".", "stack", "(", "[", "a_chan", ",", "b_chan", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "# break apart image pair and move to range [-1, 1]", "\n", "            ", "width", "=", "tf", ".", "shape", "(", "raw_input", ")", "[", "1", "]", "# [height, width, channels]", "\n", "a_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", ":", "width", "//", "2", ",", ":", "]", ")", "\n", "b_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "width", "//", "2", ":", ",", ":", "]", ")", "\n", "\n", "", "", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "        ", "inputs", ",", "targets", "=", "[", "a_images", ",", "b_images", "]", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "        ", "inputs", ",", "targets", "=", "[", "b_images", ",", "a_images", "]", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "\n", "# synchronize seed for image operations so that we do the same operations to both", "\n", "# input and output images", "\n", "", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "def", "transform", "(", "image", ")", ":", "\n", "        ", "r", "=", "image", "\n", "if", "a", ".", "flip", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "r", ",", "seed", "=", "seed", ")", "\n", "\n", "# area produces a nice downscaling, but does nearest neighbor for upscaling", "\n", "# assume we're going to be doing downscaling here", "\n", "", "r", "=", "tf", ".", "image", ".", "resize_images", "(", "r", ",", "[", "a", ".", "scale_size", ",", "a", ".", "scale_size", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "AREA", ")", "\n", "\n", "offset", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "2", "]", ",", "0", ",", "a", ".", "scale_size", "-", "CROP_SIZE", "+", "1", ",", "seed", "=", "seed", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "if", "a", ".", "scale_size", ">", "CROP_SIZE", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "r", ",", "offset", "[", "0", "]", ",", "offset", "[", "1", "]", ",", "CROP_SIZE", ",", "CROP_SIZE", ")", "\n", "", "elif", "a", ".", "scale_size", "<", "CROP_SIZE", ":", "\n", "            ", "raise", "Exception", "(", "\"scale size cannot be less than crop size\"", ")", "\n", "", "return", "r", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"input_images\"", ")", ":", "\n", "        ", "input_images", "=", "transform", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"target_images\"", ")", ":", "\n", "        ", "target_images", "=", "transform", "(", "targets", ")", "\n", "\n", "", "paths_batch", ",", "inputs_batch", ",", "targets_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "paths", ",", "input_images", ",", "target_images", "]", ",", "batch_size", "=", "a", ".", "batch_size", ")", "\n", "steps_per_epoch", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "input_paths", ")", "/", "a", ".", "batch_size", ")", ")", "\n", "\n", "return", "Examples", "(", "\n", "paths", "=", "paths_batch", ",", "\n", "inputs", "=", "inputs_batch", ",", "\n", "targets", "=", "targets_batch", ",", "\n", "count", "=", "len", "(", "input_paths", ")", ",", "\n", "steps_per_epoch", "=", "steps_per_epoch", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.save_images": [[522, 542], ["os.path.join", "enumerate", "os.path.exists", "os.makedirs", "os.path.splitext", "filesets.append", "os.path.basename", "os.path.join", "in_path.decode", "open", "f.write"], "function", ["None"], ["", "def", "save_images", "(", "fetches", ",", "step", "=", "None", ")", ":", "\n", "    ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"images\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "filesets", "=", "[", "]", "\n", "for", "i", ",", "in_path", "in", "enumerate", "(", "fetches", "[", "\"paths\"", "]", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "in_path", ".", "decode", "(", "\"utf8\"", ")", ")", ")", "\n", "fileset", "=", "{", "\"name\"", ":", "name", ",", "\"step\"", ":", "step", "}", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs\"", ",", "\"targets\"", "]", ":", "\n", "            ", "filename", "=", "name", "+", "\"-\"", "+", "kind", "+", "\".png\"", "\n", "if", "step", "is", "not", "None", ":", "\n", "                ", "filename", "=", "\"%08d-%s\"", "%", "(", "step", ",", "filename", ")", "\n", "", "fileset", "[", "kind", "]", "=", "filename", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "filename", ")", "\n", "contents", "=", "fetches", "[", "kind", "]", "[", "i", "]", "\n", "with", "open", "(", "out_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "contents", ")", "\n", "", "", "filesets", ".", "append", "(", "fileset", ")", "\n", "", "return", "filesets", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.append_index": [[544, 567], ["os.path.join", "os.path.exists", "open", "open", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write"], "function", ["None"], ["", "def", "append_index", "(", "filesets", ",", "step", "=", "False", ")", ":", "\n", "    ", "index_path", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"index.html\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_path", ")", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"a\"", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"w\"", ")", "\n", "index", ".", "write", "(", "\"<html><body><table><tr>\"", ")", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<th>step</th>\"", ")", "\n", "", "index", ".", "write", "(", "\"<th>name</th><th>input</th><th>output</th><th>target</th></tr>\"", ")", "\n", "\n", "", "for", "fileset", "in", "filesets", ":", "\n", "        ", "index", ".", "write", "(", "\"<tr>\"", ")", "\n", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<td>%d</td>\"", "%", "fileset", "[", "\"step\"", "]", ")", "\n", "", "index", ".", "write", "(", "\"<td>%s</td>\"", "%", "fileset", "[", "\"name\"", "]", ")", "\n", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs\"", ",", "\"targets\"", "]", ":", "\n", "            ", "index", ".", "write", "(", "\"<td><img src='images/%s'></td>\"", "%", "fileset", "[", "kind", "]", ")", "\n", "\n", "", "index", ".", "write", "(", "\"</tr>\"", ")", "\n", "", "return", "index_path", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.main": [[569, 816], ["tensorflow.set_random_seed", "numpy.random.seed", "random.seed", "a._get_kwargs", "pix2pix_0orig_cv.load_examples", "print", "pix2pix_0orig_cv.create_model", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.train.Saver", "tensorflow.train.Supervisor", "random.randint", "os.path.exists", "os.makedirs", "print", "open", "f.write", "pix2pix_0orig_cv.deprocess", "pix2pix_0orig_cv.deprocess", "pix2pix_0orig_cv.deprocess", "tensorflow.image.convert_image_dtype", "tensorflow.name_scope", "pix2pix_0orig_cv.main.convert"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.load_examples", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_model", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "main", "(", ")", ":", "\n", "    ", "if", "a", ".", "seed", "is", "None", ":", "\n", "        ", "a", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "\n", "", "tf", ".", "set_random_seed", "(", "a", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "a", ".", "output_dir", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", "or", "a", ".", "mode", "==", "\"export\"", ":", "\n", "        ", "if", "a", ".", "checkpoint", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"checkpoint required for test mode\"", ")", "\n", "\n", "# load some options from the checkpoint", "\n", "", "options", "=", "{", "\"which_direction\"", ",", "\"ngf\"", ",", "\"ndf\"", ",", "\"lab_colorization\"", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "checkpoint", ",", "\"options.json\"", ")", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "val", "in", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "in", "options", ":", "\n", "                    ", "print", "(", "\"loaded\"", ",", "key", ",", "\"=\"", ",", "val", ")", "\n", "setattr", "(", "a", ",", "key", ",", "val", ")", "\n", "# disable these features in test mode", "\n", "", "", "", "a", ".", "scale_size", "=", "CROP_SIZE", "\n", "a", ".", "flip", "=", "False", "\n", "\n", "", "for", "k", ",", "v", "in", "a", ".", "_get_kwargs", "(", ")", ":", "\n", "        ", "print", "(", "k", ",", "\"=\"", ",", "v", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"options.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vars", "(", "a", ")", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n", "\n", "", "examples", "=", "load_examples", "(", ")", "\n", "print", "(", "\"examples count = %d\"", "%", "examples", ".", "count", ")", "\n", "\n", "# inputs and targets are [batch_size, height, width, channels]", "\n", "model", "=", "create_model", "(", "examples", ".", "inputs", ",", "examples", ".", "targets", ")", "\n", "\n", "# undo colorization splitting on images that we use for display/output", "\n", "if", "a", ".", "lab_colorization", ":", "\n", "        ", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "# inputs is brightness, this will be handled fine as a grayscale image", "\n", "# need to augment targets and outputs with brightness", "\n", "            ", "targets", "=", "augment", "(", "examples", ".", "targets", ",", "examples", ".", "inputs", ")", "\n", "outputs", "=", "augment", "(", "model", ".", "outputs", ",", "examples", ".", "inputs", ")", "\n", "# inputs can be deprocessed normally and handled as if they are single channel", "\n", "# grayscale images", "\n", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "# inputs will be color channels only, get brightness from targets", "\n", "            ", "inputs", "=", "augment", "(", "examples", ".", "inputs", ",", "examples", ".", "targets", ")", "\n", "targets", "=", "deprocess", "(", "examples", ".", "targets", ")", "\n", "outputs", "=", "deprocess", "(", "model", ".", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "", "", "else", ":", "\n", "        ", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "targets", "=", "deprocess", "(", "examples", ".", "targets", ")", "\n", "outputs", "=", "deprocess", "(", "model", ".", "outputs", ")", "\n", "\n", "", "def", "convert", "(", "image", ")", ":", "\n", "        ", "if", "a", ".", "aspect_ratio", "!=", "1.0", ":", "\n", "# upscale to correct aspect ratio", "\n", "            ", "size", "=", "[", "CROP_SIZE", ",", "int", "(", "round", "(", "CROP_SIZE", "*", "a", ".", "aspect_ratio", ")", ")", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "image", ",", "size", "=", "size", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "\n", "", "return", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "uint8", ",", "saturate", "=", "True", ")", "\n", "\n", "# reverse any processing on images so they can be written to disk or displayed to user", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_inputs\"", ")", ":", "\n", "        ", "converted_inputs", "=", "convert", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_targets\"", ")", ":", "\n", "        ", "converted_targets", "=", "convert", "(", "targets", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_outputs\"", ")", ":", "\n", "        ", "converted_outputs", "=", "convert", "(", "outputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"encode_images\"", ")", ":", "\n", "        ", "display_fetches", "=", "{", "\n", "\"paths\"", ":", "examples", ".", "paths", ",", "\n", "\"inputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_inputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"input_pngs\"", ")", ",", "\n", "\"targets\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_pngs\"", ")", ",", "\n", "\"outputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_pngs\"", ")", ",", "\n", "}", "\n", "\n", "# summaries", "\n", "", "with", "tf", ".", "name_scope", "(", "\"inputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"inputs\"", ",", "converted_inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"targets_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"targets\"", ",", "converted_targets", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"outputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"outputs\"", ",", "converted_outputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_real_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_real\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_real", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_fake_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_fake\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_fake", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss\"", ",", "model", ".", "discrim_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN\"", ",", "model", ".", "gen_loss_GAN", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_L1\"", ",", "model", ".", "gen_loss_L1", ")", "\n", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/values\"", ",", "var", ")", "\n", "\n", "", "for", "grad", ",", "var", "in", "model", ".", "discrim_grads_and_vars", "+", "model", ".", "gen_grads_and_vars", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/gradients\"", ",", "grad", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"parameter_count\"", ")", ":", "\n", "        ", "parameter_count", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "v", ")", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1", ")", "\n", "\n", "logdir", "=", "a", ".", "output_dir", "if", "(", "a", ".", "trace_freq", ">", "0", "or", "a", ".", "summary_freq", ">", "0", ")", "else", "None", "\n", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "logdir", "=", "logdir", ",", "save_summaries_secs", "=", "0", ",", "saver", "=", "None", ")", "\n", "with", "sv", ".", "managed_session", "(", ")", "as", "sess", ":", "\n", "        ", "print", "(", "\"parameter_count =\"", ",", "sess", ".", "run", "(", "parameter_count", ")", ")", "\n", "\n", "if", "a", ".", "checkpoint", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"#############################\"", ")", "\n", "print", "(", "\"loading model from checkpoint for continue training or test phase\"", ")", "\n", "print", "(", "\"#############################\"", ")", "\n", "try", ":", "\n", "                ", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"loading was unsuccessful-it will train from scratch\"", ")", "\n", "print", "(", "\"#############################\"", ")", "\n", "\n", "\n", "", "", "max_steps", "=", "2", "**", "32", "\n", "if", "a", ".", "max_epochs", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "examples", ".", "steps_per_epoch", "*", "a", ".", "max_epochs", "\n", "", "if", "a", ".", "max_steps", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "a", ".", "max_steps", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", ":", "\n", "# testing", "\n", "# at most, process the test data once", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "max_steps", "=", "min", "(", "examples", ".", "steps_per_epoch", ",", "max_steps", ")", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "results", "=", "sess", ".", "run", "(", "display_fetches", ")", "\n", "filesets", "=", "save_images", "(", "results", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "filesets", ")", ":", "\n", "                    ", "print", "(", "\"evaluated image\"", ",", "f", "[", "\"name\"", "]", ")", "\n", "", "index_path", "=", "append_index", "(", "filesets", ")", "\n", "", "print", "(", "\"wrote index at\"", ",", "index_path", ")", "\n", "print", "(", "\"rate\"", ",", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "max_steps", ")", "\n", "", "else", ":", "\n", "# training", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "discrim_loss_pre", "=", "10000", "\n", "gan_loss_pre", "=", "10000", "\n", "patience_counter", "=", "0", "\n", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "def", "should", "(", "freq", ")", ":", "\n", "                    ", "return", "freq", ">", "0", "and", "(", "(", "step", "+", "1", ")", "%", "freq", "==", "0", "or", "step", "==", "max_steps", "-", "1", ")", "\n", "\n", "", "options", "=", "None", "\n", "run_metadata", "=", "None", "\n", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "options", "=", "tf", ".", "RunOptions", "(", "trace_level", "=", "tf", ".", "RunOptions", ".", "FULL_TRACE", ")", "\n", "run_metadata", "=", "tf", ".", "RunMetadata", "(", ")", "\n", "\n", "", "fetches", "=", "{", "\n", "\"train\"", ":", "model", ".", "train", ",", "\n", "\"global_step\"", ":", "sv", ".", "global_step", ",", "\n", "}", "\n", "\n", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"discrim_loss\"", "]", "=", "model", ".", "discrim_loss", "\n", "fetches", "[", "\"gen_loss_GAN\"", "]", "=", "model", ".", "gen_loss_GAN", "\n", "fetches", "[", "\"gen_loss_L1\"", "]", "=", "model", ".", "gen_loss_L1", "\n", "\n", "", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"summary\"", "]", "=", "sv", ".", "summary_op", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"display\"", "]", "=", "display_fetches", "\n", "\n", "", "results", "=", "sess", ".", "run", "(", "fetches", ",", "options", "=", "options", ",", "run_metadata", "=", "run_metadata", ")", "\n", "\n", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording summary\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "results", "[", "\"summary\"", "]", ",", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving display images\"", ")", "\n", "filesets", "=", "save_images", "(", "results", "[", "\"display\"", "]", ",", "step", "=", "results", "[", "\"global_step\"", "]", ")", "\n", "append_index", "(", "filesets", ",", "step", "=", "True", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording trace\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_run_metadata", "(", "run_metadata", ",", "\"step_%d\"", "%", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "# global_step will have the correct step count if we resume from a checkpoint", "\n", "                    ", "train_epoch", "=", "math", ".", "ceil", "(", "results", "[", "\"global_step\"", "]", "/", "examples", ".", "steps_per_epoch", ")", "\n", "train_step", "=", "(", "results", "[", "\"global_step\"", "]", "-", "1", ")", "%", "examples", ".", "steps_per_epoch", "+", "1", "\n", "rate", "=", "(", "step", "+", "1", ")", "*", "a", ".", "batch_size", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "remaining", "=", "(", "max_steps", "-", "step", ")", "*", "a", ".", "batch_size", "/", "rate", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"discrim_loss\"", ",", "results", "[", "\"discrim_loss\"", "]", ")", "\n", "print", "(", "\"gen_loss_GAN\"", ",", "results", "[", "\"gen_loss_GAN\"", "]", ")", "\n", "print", "(", "\"gen_loss_L1\"", ",", "results", "[", "\"gen_loss_L1\"", "]", ")", "\n", "\n", "\n", "if", "discrim_loss_pre", ">=", "results", "[", "\"discrim_loss\"", "]", ":", "\n", "                        ", "if", "gan_loss_pre", "<=", "results", "[", "\"gen_loss_GAN\"", "]", ":", "\n", "                            ", "patience_counter", "=", "patience_counter", "+", "1", "\n", "\n", "\n", "\n", "", "", "discrim_loss_pre", "=", "results", "[", "\"discrim_loss\"", "]", "\n", "gan_loss_pre", "=", "results", "[", "\"gen_loss_GAN\"", "]", "\n", "\n", "if", "patience_counter", ">=", "float", "(", "a", ".", "patience_epochs", ")", ":", "\n", "                        ", "print", "(", "\"###################\"", ")", "\n", "print", "(", "\"early stop, disc is winning\"", ")", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "break", "\n", "\n", "\n", "", "if", "results", "[", "\"gen_loss_L1\"", "]", "<", "float", "(", "a", ".", "desired_l1_loss", ")", ":", "\n", "                        ", "print", "(", "\"###################\"", ")", "\n", "print", "(", "\"Reached desired error\"", ")", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "break", "\n", "\n", "", "", "if", "should", "(", "a", ".", "save_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "\n", "", "if", "sv", ".", "should_stop", "(", ")", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0orig_cv.CombineImages": [[821, 901], ["print", "os.mkdir", "skimage.io.imread", "skimage.io.imsave", "print", "shutil.rmtree", "os.mkdir", "filename.replace.replace", "len", "numpy.zeros", "skimage.io.imread", "numpy.zeros", "skimage.io.imread", "numpy.zeros", "print", "sys.exit", "len", "numpy.zeros", "len", "numpy.zeros", "str", "str"], "function", ["None"], ["", "", "", "", "", "def", "CombineImages", "(", "ImageListNames", ",", "task_No", ",", "input_dir_all", ")", ":", "\n", "    ", "print", "(", "'combining images ...'", ")", "\n", "\n", "try", ":", "\n", "        ", "os", ".", "mkdir", "(", "write_to_dir", ")", "\n", "", "except", ":", "\n", "        ", "print", "(", "'destination folder is already exist-It will be replaced'", ")", "\n", "shutil", ".", "rmtree", "(", "write_to_dir", ")", "\n", "os", ".", "mkdir", "(", "write_to_dir", ")", "\n", "\n", "\n", "", "for", "filename", "in", "ImageListNames", ":", "\n", "\n", "        ", "try", ":", "\n", "            ", "filename", "=", "filename", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "", "except", ":", "\n", "            ", "no", "=", "0", "\n", "\n", "", "Image", "=", "io", ".", "imread", "(", "a", ".", "input_dir_all", "+", "'/Inputs/'", "+", "filename", ")", "\n", "Size", "=", "Image", ".", "shape", "\n", "if", "len", "(", "Size", ")", "==", "2", ":", "\n", "            ", "Image_", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image", ".", "shape", "[", "0", "]", ",", "Image", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_", "[", ":", ",", ":", ",", "0", "]", "=", "Image", "\n", "Image_", "[", ":", ",", ":", ",", "1", "]", "=", "Image", "\n", "Image_", "[", ":", ",", ":", ",", "2", "]", "=", "Image", "\n", "Image", "=", "Image_", "\n", "\n", "", "if", "task_No", "==", "1", ":", "\n", "            ", "Image_t1", "=", "io", ".", "imread", "(", "a", ".", "input_dir_all", "+", "'/Targets_'", "+", "str", "(", "task_No", ")", "+", "'/'", "+", "filename", ")", "\n", "Size", "=", "Image_t1", ".", "shape", "\n", "if", "len", "(", "Size", ")", "==", "2", ":", "\n", "                ", "Image_", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image_t1", ".", "shape", "[", "0", "]", ",", "Image_t1", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_", "[", ":", ",", ":", ",", "0", "]", "=", "Image_t1", "\n", "Image_", "[", ":", ",", ":", ",", "1", "]", "=", "Image_t1", "\n", "Image_", "[", ":", ",", ":", ",", "2", "]", "=", "Image_t1", "\n", "Image_t1", "=", "Image_", "\n", "", "Image_combined", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image", ".", "shape", "[", "0", "]", ",", "2", "*", "Image", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_combined", "[", ":", ",", ":", "CROP_SIZE", ",", ":", "]", "=", "Image", "\n", "Image_combined", "[", ":", ",", "CROP_SIZE", ":", ",", ":", "]", "=", "Image_t1", "\n", "\n", "", "if", "task_No", "==", "2", ":", "\n", "            ", "Image_t2", "=", "io", ".", "imread", "(", "a", ".", "input_dir_all", "+", "'/Targets_'", "+", "str", "(", "task_No", ")", "+", "'/'", "+", "filename", ")", "\n", "Size", "=", "Image_t2", ".", "shape", "\n", "if", "len", "(", "Size", ")", "==", "2", ":", "\n", "                ", "Image_", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image_t2", ".", "shape", "[", "0", "]", ",", "Image_t2", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_", "[", ":", ",", ":", ",", "0", "]", "=", "Image_t2", "\n", "Image_", "[", ":", ",", ":", ",", "1", "]", "=", "Image_t2", "\n", "Image_", "[", ":", ",", ":", ",", "2", "]", "=", "Image_t2", "\n", "Image_t2", "=", "Image_", "\n", "", "Image_combined", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image", ".", "shape", "[", "0", "]", ",", "2", "*", "Image", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_combined", "[", ":", ",", ":", "CROP_SIZE", ",", ":", "]", "=", "Image", "\n", "Image_combined", "[", ":", ",", "CROP_SIZE", ":", ",", ":", "]", "=", "Image_t2", "\n", "\n", "", "if", "task_No", "==", "3", ":", "\n", "            ", "print", "(", "'3 is not acceptable for single task'", ")", "\n", "sys", ".", "exit", "(", "'3 is not acceptable for single task'", ")", "\n", "#            Image_t1=io.imread(a.input_dir_all+'Targets_1'+'/'+ filename)", "\n", "#            Image_t2=io.imread(a.input_dir_all+'Targets_2'+'/'+ filename)", "\n", "#            Size=Image_t1.shape", "\n", "#            if len(Size)==2:", "\n", "#                Image_=np.zeros(shape=[Image_t1.shape[0],Image_t1.shape[1],3], dtype='uint8')", "\n", "#                Image_[:,:,0]=Image_t1", "\n", "#                Image_[:,:,1]=Image_t1", "\n", "#                Image_[:,:,2]=Image_t1", "\n", "#                Image_t1=Image_", "\n", "#            Size=Image_t2.shape", "\n", "#            if len(Size)==2:", "\n", "#                Image_=np.zeros(shape=[Image_t2.shape[0],Image_t2.shape[1],3], dtype='uint8')", "\n", "#                Image_[:,:,0]=Image_t2", "\n", "#                Image_[:,:,1]=Image_t2", "\n", "#                Image_[:,:,2]=Image_t2", "\n", "#                Image_t2=Image_                                                 ", "\n", "#            Image_combined=np.zeros(shape=[Image.shape[0],3*Image.shape[1],3], dtype='uint8')", "\n", "#            Image_combined[:,:CROP_SIZE,:]=Image", "\n", "#            Image_combined[:,CROP_SIZE:2*CROP_SIZE,:]=Image_t1            ", "\n", "#            Image_combined[:,2*CROP_SIZE:,:]=Image_t2            ", "\n", "\n", "\n", "\n", "", "io", ".", "imsave", "(", "write_to_dir", "+", "filename", ",", "Image_combined", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.preprocess": [[77, 81], ["tensorflow.name_scope"], "function", ["None"], ["def", "preprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess\"", ")", ":", "\n", "# [0, 1] => [-1, 1]", "\n", "        ", "return", "image", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.deprocess": [[83, 87], ["tensorflow.name_scope"], "function", ["None"], ["", "", "def", "deprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess\"", ")", ":", "\n", "# [-1, 1] => [0, 1]", "\n", "        ", "return", "(", "image", "+", "1", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.preprocess_lab": [[89, 96], ["tensorflow.name_scope", "tensorflow.unstack"], "function", ["None"], ["", "", "def", "preprocess_lab", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess_lab\"", ")", ":", "\n", "        ", "L_chan", ",", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "lab", ",", "axis", "=", "2", ")", "\n", "# L_chan: black and white with input range [0, 100]", "\n", "# a_chan/b_chan: color channels with input range ~[-110, 110], not exact", "\n", "# [0, 100] => [-1, 1],  ~[-110, 110] => [-1, 1]", "\n", "return", "[", "L_chan", "/", "50", "-", "1", ",", "a_chan", "/", "110", ",", "b_chan", "/", "110", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.deprocess_lab": [[98, 102], ["tensorflow.name_scope", "tensorflow.stack"], "function", ["None"], ["", "", "def", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess_lab\"", ")", ":", "\n", "# this is axis=3 instead of axis=2 because we process individual images but deprocess batches", "\n", "        ", "return", "tf", ".", "stack", "(", "[", "(", "L_chan", "+", "1", ")", "/", "2", "*", "100", ",", "a_chan", "*", "110", ",", "b_chan", "*", "110", "]", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.augment": [[104, 111], ["tensorflow.unstack", "tensorflow.squeeze", "pix2pix_dG_cv.deprocess_lab", "pix2pix_dG_cv.lab_to_rgb"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess_lab", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lab_to_rgb"], ["", "", "def", "augment", "(", "image", ",", "brightness", ")", ":", "\n", "# (a, b) color channels, combine with L channel and convert to rgb", "\n", "    ", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "image", ",", "axis", "=", "3", ")", "\n", "L_chan", "=", "tf", ".", "squeeze", "(", "brightness", ",", "axis", "=", "3", ")", "\n", "lab", "=", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", "\n", "rgb", "=", "lab_to_rgb", "(", "lab", ")", "\n", "return", "rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.discrim_conv": [[113, 116], ["tensorflow.pad", "tensorflow.layers.conv2d", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "discrim_conv", "(", "batch_input", ",", "out_channels", ",", "stride", ")", ":", "\n", "    ", "padded_input", "=", "tf", ".", "pad", "(", "batch_input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"CONSTANT\"", ")", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "padded_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "stride", ",", "stride", ")", ",", "padding", "=", "\"valid\"", ",", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.gen_conv": [[118, 125], ["tensorflow.random_normal_initializer", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d"], "function", ["None"], ["", "def", "gen_conv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.gen_conv_dilate": [[127, 133], ["tensorflow.random_normal_initializer", "tensorflow.layers.conv2d", "tensorflow.layers.max_pooling2d"], "function", ["None"], ["", "", "def", "gen_conv_dilate", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "dilate_rate", "=", "2", "\n", "output", "=", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "dilation_rate", "=", "(", "dilate_rate", ",", "dilate_rate", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "return", "tf", ".", "layers", ".", "max_pooling2d", "(", "inputs", "=", "output", ",", "pool_size", "=", "[", "2", ",", "2", "]", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "'valid'", ",", "data_format", "=", "'channels_last'", ",", "name", "=", "None", ")", "\n", "#end  Moha ---------------------------------------", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.gen_deconv": [[136, 145], ["tensorflow.random_normal_initializer", "tensorflow.image.resize_images", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d_transpose"], "function", ["None"], ["", "def", "gen_deconv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "_b", ",", "h", ",", "w", ",", "_c", "=", "batch_input", ".", "shape", "\n", "resized_input", "=", "tf", ".", "image", ".", "resize_images", "(", "batch_input", ",", "[", "h", "*", "2", ",", "w", "*", "2", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "resized_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d_transpose", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.lrelu": [[147, 157], ["tensorflow.name_scope", "tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["", "", "def", "lrelu", "(", "x", ",", "a", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lrelu\"", ")", ":", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: a*x/2 - a*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "        ", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.batchnorm": [[159, 161], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "", "def", "batchnorm", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.create_generator": [[162, 246], ["print", "print", "len", "enumerate", "tensorflow.variable_scope", "pix2pix_dG_cv.gen_conv", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_dG_cv.lrelu", "pix2pix_dG_cv.gen_conv", "print", "pix2pix_dG_cv.batchnorm", "layers.append", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.nn.relu", "pix2pix_dG_cv.gen_deconv", "tensorflow.tanh", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_dG_cv.lrelu", "pix2pix_dG_cv.gen_conv_dilate", "print", "pix2pix_dG_cv.batchnorm", "layers.append", "tensorflow.variable_scope", "tensorflow.nn.relu", "pix2pix_dG_cv.gen_deconv", "print", "pix2pix_dG_cv.batchnorm", "layers.append", "tensorflow.concat", "tensorflow.nn.dropout", "len", "len"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv_dilate", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm"], ["", "def", "create_generator", "(", "generator_inputs", ",", "generator_outputs_channels", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "\n", "print", "(", "'encoder:'", ")", "\n", "# encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_1\"", ")", ":", "\n", "        ", "output", "=", "gen_conv", "(", "generator_inputs", ",", "a", ".", "ngf", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "a", ".", "ngf", "*", "2", ",", "# encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]", "\n", "a", ".", "ngf", "*", "4", ",", "# encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]", "\n", "]", "\n", "\n", "for", "out_channels", "in", "layer_specs", "[", ":", "6", "]", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]", "\n", "\n", "# orig: ---------------------------", "\n", "# convolved = gen_conv(rectified, out_channels)", "\n", "# Moha: ---------------------------", "\n", "convolved", "=", "gen_conv_dilate", "(", "rectified", ",", "out_channels", ")", "\n", "#convolved = gen_conv(rectified, out_channels)", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "# end Moha -----------------------------", "\n", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "convolved", "=", "gen_conv", "(", "rectified", ",", "layer_specs", "[", "6", "]", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.0", ")", ",", "# decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "4", ",", "0.0", ")", ",", "# decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]", "\n", "(", "a", ".", "ngf", "*", "2", ",", "0.0", ")", ",", "# decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]", "\n", "(", "a", ".", "ngf", ",", "0.0", ")", ",", "# decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]", "\n", "]", "\n", "\n", "print", "(", "'decoder:'", ")", "\n", "num_encoder_layers", "=", "len", "(", "layers", ")", "\n", "for", "decoder_layer", ",", "(", "out_channels", ",", "dropout", ")", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "skip_layer", "=", "num_encoder_layers", "-", "decoder_layer", "-", "1", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder_%d\"", "%", "(", "skip_layer", "+", "1", ")", ")", ":", "\n", "            ", "if", "decoder_layer", "==", "0", ":", "\n", "# first decoder layer doesn't have skip connections", "\n", "# since it is directly connected to the skip_layer", "\n", "                ", "input", "=", "layers", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "skip_layer", "]", "]", ",", "axis", "=", "3", ")", "\n", "\n", "", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "out_channels", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "output", "=", "batchnorm", "(", "output", ")", "\n", "\n", "if", "dropout", ">", "0.0", ":", "\n", "                ", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "keep_prob", "=", "1", "-", "dropout", ")", "\n", "\n", "", "layers", ".", "append", "(", "output", ")", "\n", "\n", "# decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"decoder_1\"", ")", ":", "\n", "        ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "0", "]", "]", ",", "axis", "=", "3", ")", "\n", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "generator_outputs_channels", ")", "\n", "output", "=", "tf", ".", "tanh", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.create_model": [[250, 347], ["tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "print", "tensorflow.concat", "range", "tensorflow.variable_scope", "int", "pix2pix_dG_cv.create_generator", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.variable_scope", "pix2pix_dG_cv.discrim_conv", "pix2pix_dG_cv.lrelu", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_dG_cv.discrim_conv", "tensorflow.sigmoid", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_dG_cv.create_model.create_discriminator"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_generator", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv"], ["", "def", "create_model", "(", "inputs", ",", "targets", ")", ":", "\n", "\n", "    ", "def", "create_discriminator", "(", "discrim_inputs", ",", "discrim_targets", ")", ":", "\n", "        ", "n_layers", "=", "3", "\n", "layers", "=", "[", "]", "\n", "print", "(", "'discriminator:'", ")", "\n", "\n", "# 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]", "\n", "input", "=", "tf", ".", "concat", "(", "[", "discrim_inputs", ",", "discrim_targets", "]", ",", "axis", "=", "3", ")", "\n", "\n", "# layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"layer_1\"", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "input", ",", "a", ".", "ndf", ",", "stride", "=", "2", ")", "\n", "rectified", "=", "lrelu", "(", "convolved", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]", "\n", "# layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]", "\n", "# layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]", "\n", "", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "                ", "out_channels", "=", "a", ".", "ndf", "*", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "stride", "=", "1", "if", "i", "==", "n_layers", "-", "1", "else", "2", "# last layer here has stride 1", "\n", "convolved", "=", "discrim_conv", "(", "layers", "[", "-", "1", "]", ",", "out_channels", ",", "stride", "=", "stride", ")", "\n", "normalized", "=", "batchnorm", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "rectified", ",", "out_channels", "=", "1", ",", "stride", "=", "1", ")", "\n", "output", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "        ", "out_channels", "=", "int", "(", "targets", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "outputs", "=", "create_generator", "(", "inputs", ",", "out_channels", ")", "\n", "\n", "# create two copies of discriminator, one for real pairs and one for fake pairs", "\n", "# they share the same underlying variables", "\n", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_real", "=", "create_discriminator", "(", "inputs", ",", "targets", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ",", "reuse", "=", "True", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_fake", "=", "create_discriminator", "(", "inputs", ",", "outputs", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_loss\"", ")", ":", "\n", "# minimizing -tf.log will try to get inputs to 1", "\n", "# predict_real => 1", "\n", "# predict_fake => 0", "\n", "        ", "discrim_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_loss\"", ")", ":", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "        ", "gen_loss_GAN", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_fake", "+", "EPS", ")", ")", "\n", "gen_loss_L1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "targets", "-", "outputs", ")", ")", "\n", "gen_loss", "=", "gen_loss_GAN", "*", "a", ".", "gan_weight", "+", "gen_loss_L1", "*", "a", ".", "l1_weight", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_train\"", ")", ":", "\n", "        ", "discrim_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"discriminator\"", ")", "]", "\n", "discrim_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "discrim_grads_and_vars", "=", "discrim_optim", ".", "compute_gradients", "(", "discrim_loss", ",", "var_list", "=", "discrim_tvars", ")", "\n", "discrim_train", "=", "discrim_optim", ".", "apply_gradients", "(", "discrim_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_train", "]", ")", ":", "\n", "            ", "gen_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"generator\"", ")", "]", "\n", "gen_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "gen_grads_and_vars", "=", "gen_optim", ".", "compute_gradients", "(", "gen_loss", ",", "var_list", "=", "gen_tvars", ")", "\n", "gen_train", "=", "gen_optim", ".", "apply_gradients", "(", "gen_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_loss", ",", "gen_loss_GAN", ",", "gen_loss_L1", "]", ")", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "return", "Model", "(", "\n", "predict_real", "=", "predict_real", ",", "\n", "predict_fake", "=", "predict_fake", ",", "\n", "discrim_loss", "=", "ema", ".", "average", "(", "discrim_loss", ")", ",", "\n", "discrim_grads_and_vars", "=", "discrim_grads_and_vars", ",", "\n", "gen_loss_GAN", "=", "ema", ".", "average", "(", "gen_loss_GAN", ")", ",", "\n", "gen_loss_L1", "=", "ema", ".", "average", "(", "gen_loss_L1", ")", ",", "\n", "gen_grads_and_vars", "=", "gen_grads_and_vars", ",", "\n", "outputs", "=", "outputs", ",", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_train", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.check_image": [[350, 363], ["tensorflow.assert_equal", "list", "tf.identity.set_shape", "tensorflow.control_dependencies", "tensorflow.identity", "ValueError", "tf.identity.get_shape", "tensorflow.shape", "tf.identity.get_shape"], "function", ["None"], ["", "def", "check_image", "(", "image", ")", ":", "\n", "    ", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "image", ")", "[", "-", "1", "]", ",", "3", ",", "message", "=", "\"image must have 3 color channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "        ", "image", "=", "tf", ".", "identity", "(", "image", ")", "\n", "\n", "", "if", "image", ".", "get_shape", "(", ")", ".", "ndims", "not", "in", "(", "3", ",", "4", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"image must be either 3 or 4 dimensions\"", ")", "\n", "\n", "# make the last dimension 3 so that you can unstack the colors", "\n", "", "shape", "=", "list", "(", "image", ".", "get_shape", "(", ")", ")", "\n", "shape", "[", "-", "1", "]", "=", "3", "\n", "image", ".", "set_shape", "(", "shape", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.rgb_to_lab": [[365, 404], ["tensorflow.name_scope", "pix2pix_dG_cv.check_image", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.name_scope", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.matmul", "tensorflow.name_scope", "tensorflow.multiply", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.shape", "tensorflow.matmul", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.check_image"], ["", "def", "rgb_to_lab", "(", "srgb", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"rgb_to_lab\"", ")", ":", "\n", "        ", "srgb", "=", "check_image", "(", "srgb", ")", "\n", "srgb_pixels", "=", "tf", ".", "reshape", "(", "srgb", ",", "[", "-", "1", ",", "3", "]", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"srgb_to_xyz\"", ")", ":", "\n", "            ", "linear_mask", "=", "tf", ".", "cast", "(", "srgb_pixels", "<=", "0.04045", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "srgb_pixels", ">", "0.04045", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "rgb_pixels", "=", "(", "srgb_pixels", "/", "12.92", "*", "linear_mask", ")", "+", "(", "(", "(", "srgb_pixels", "+", "0.055", ")", "/", "1.055", ")", "**", "2.4", ")", "*", "exponential_mask", "\n", "rgb_to_xyz", "=", "tf", ".", "constant", "(", "[", "\n", "#    X        Y          Z", "\n", "[", "0.412453", ",", "0.212671", ",", "0.019334", "]", ",", "# R", "\n", "[", "0.357580", ",", "0.715160", ",", "0.119193", "]", ",", "# G", "\n", "[", "0.180423", ",", "0.072169", ",", "0.950227", "]", ",", "# B", "\n", "]", ")", "\n", "xyz_pixels", "=", "tf", ".", "matmul", "(", "rgb_pixels", ",", "rgb_to_xyz", ")", "\n", "\n", "# https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions", "\n", "", "with", "tf", ".", "name_scope", "(", "\"xyz_to_cielab\"", ")", ":", "\n", "# convert to fx = f(X/Xn), fy = f(Y/Yn), fz = f(Z/Zn)", "\n", "\n", "# normalize for D65 white point", "\n", "            ", "xyz_normalized_pixels", "=", "tf", ".", "multiply", "(", "xyz_pixels", ",", "[", "1", "/", "0.950456", ",", "1.0", ",", "1", "/", "1.088754", "]", ")", "\n", "\n", "epsilon", "=", "6", "/", "29", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "xyz_normalized_pixels", "<=", "(", "epsilon", "**", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "xyz_normalized_pixels", ">", "(", "epsilon", "**", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "fxfyfz_pixels", "=", "(", "xyz_normalized_pixels", "/", "(", "3", "*", "epsilon", "**", "2", ")", "+", "4", "/", "29", ")", "*", "linear_mask", "+", "(", "xyz_normalized_pixels", "**", "(", "1", "/", "3", ")", ")", "*", "exponential_mask", "\n", "\n", "# convert to lab", "\n", "fxfyfz_to_lab", "=", "tf", ".", "constant", "(", "[", "\n", "#  l       a       b", "\n", "[", "0.0", ",", "500.0", ",", "0.0", "]", ",", "# fx", "\n", "[", "116.0", ",", "-", "500.0", ",", "200.0", "]", ",", "# fy", "\n", "[", "0.0", ",", "0.0", ",", "-", "200.0", "]", ",", "# fz", "\n", "]", ")", "\n", "lab_pixels", "=", "tf", ".", "matmul", "(", "fxfyfz_pixels", ",", "fxfyfz_to_lab", ")", "+", "tf", ".", "constant", "(", "[", "-", "16.0", ",", "0.0", ",", "0.0", "]", ")", "\n", "\n", "", "return", "tf", ".", "reshape", "(", "lab_pixels", ",", "tf", ".", "shape", "(", "srgb", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.lab_to_rgb": [[406, 446], ["tensorflow.name_scope", "pix2pix_dG_cv.check_image", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.name_scope", "tensorflow.constant", "tensorflow.matmul", "tensorflow.cast", "tensorflow.cast", "tensorflow.multiply", "tensorflow.name_scope", "tensorflow.constant", "tensorflow.matmul", "tensorflow.clip_by_value", "tensorflow.cast", "tensorflow.cast", "tensorflow.shape", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.check_image"], ["", "", "def", "lab_to_rgb", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lab_to_rgb\"", ")", ":", "\n", "        ", "lab", "=", "check_image", "(", "lab", ")", "\n", "lab_pixels", "=", "tf", ".", "reshape", "(", "lab", ",", "[", "-", "1", ",", "3", "]", ")", "\n", "\n", "# https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions", "\n", "with", "tf", ".", "name_scope", "(", "\"cielab_to_xyz\"", ")", ":", "\n", "# convert to fxfyfz", "\n", "            ", "lab_to_fxfyfz", "=", "tf", ".", "constant", "(", "[", "\n", "#   fx      fy        fz", "\n", "[", "1", "/", "116.0", ",", "1", "/", "116.0", ",", "1", "/", "116.0", "]", ",", "# l", "\n", "[", "1", "/", "500.0", ",", "0.0", ",", "0.0", "]", ",", "# a", "\n", "[", "0.0", ",", "0.0", ",", "-", "1", "/", "200.0", "]", ",", "# b", "\n", "]", ")", "\n", "fxfyfz_pixels", "=", "tf", ".", "matmul", "(", "lab_pixels", "+", "tf", ".", "constant", "(", "[", "16.0", ",", "0.0", ",", "0.0", "]", ")", ",", "lab_to_fxfyfz", ")", "\n", "\n", "# convert to xyz", "\n", "epsilon", "=", "6", "/", "29", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "fxfyfz_pixels", "<=", "epsilon", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "fxfyfz_pixels", ">", "epsilon", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "xyz_pixels", "=", "(", "3", "*", "epsilon", "**", "2", "*", "(", "fxfyfz_pixels", "-", "4", "/", "29", ")", ")", "*", "linear_mask", "+", "(", "fxfyfz_pixels", "**", "3", ")", "*", "exponential_mask", "\n", "\n", "# denormalize for D65 white point", "\n", "xyz_pixels", "=", "tf", ".", "multiply", "(", "xyz_pixels", ",", "[", "0.950456", ",", "1.0", ",", "1.088754", "]", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"xyz_to_srgb\"", ")", ":", "\n", "            ", "xyz_to_rgb", "=", "tf", ".", "constant", "(", "[", "\n", "#     r           g          b", "\n", "[", "3.2404542", ",", "-", "0.9692660", ",", "0.0556434", "]", ",", "# x", "\n", "[", "-", "1.5371385", ",", "1.8760108", ",", "-", "0.2040259", "]", ",", "# y", "\n", "[", "-", "0.4985314", ",", "0.0415560", ",", "1.0572252", "]", ",", "# z", "\n", "]", ")", "\n", "rgb_pixels", "=", "tf", ".", "matmul", "(", "xyz_pixels", ",", "xyz_to_rgb", ")", "\n", "# avoid a slightly negative number messing up the conversion", "\n", "rgb_pixels", "=", "tf", ".", "clip_by_value", "(", "rgb_pixels", ",", "0.0", ",", "1.0", ")", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "rgb_pixels", "<=", "0.0031308", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "rgb_pixels", ">", "0.0031308", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "srgb_pixels", "=", "(", "rgb_pixels", "*", "12.92", "*", "linear_mask", ")", "+", "(", "(", "rgb_pixels", "**", "(", "1", "/", "2.4", ")", "*", "1.055", ")", "-", "0.055", ")", "*", "exponential_mask", "\n", "\n", "", "return", "tf", ".", "reshape", "(", "srgb_pixels", ",", "tf", ".", "shape", "(", "lab", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.load_examples": [[448, 538], ["glob.glob", "all", "random.randint", "tensorflow.train.batch", "int", "Examples", "Exception", "os.path.join", "len", "glob.glob", "len", "Exception", "os.path.splitext", "sorted", "sorted", "tensorflow.name_scope", "tensorflow.train.string_input_producer", "tensorflow.WholeFileReader", "tf.WholeFileReader.read", "decode", "tensorflow.image.convert_image_dtype", "tensorflow.assert_equal", "tf.identity.set_shape", "tensorflow.image.resize_images", "tensorflow.cast", "tensorflow.name_scope", "pix2pix_dG_cv.load_examples.transform"], "function", ["None"], ["", "", "def", "load_examples", "(", ")", ":", "\n", "    ", "if", "a", ".", "input_dir", "is", "None", "or", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "input_dir", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir does not exist\"", ")", "\n", "\n", "", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.jpg\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_jpeg", "\n", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.png\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_png", "\n", "\n", "", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir contains no image files\"", ")", "\n", "\n", "", "def", "get_name", "(", "path", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "\n", "return", "name", "\n", "\n", "# if the image names are numbers, sort by the value rather than asciibetically", "\n", "# having sorted inputs means that the outputs are sorted in test mode", "\n", "", "if", "all", "(", "get_name", "(", "path", ")", ".", "isdigit", "(", ")", "for", "path", "in", "input_paths", ")", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ",", "key", "=", "lambda", "path", ":", "int", "(", "get_name", "(", "path", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"load_images\"", ")", ":", "\n", "        ", "path_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "input_paths", ",", "shuffle", "=", "a", ".", "mode", "==", "\"train\"", ")", "\n", "reader", "=", "tf", ".", "WholeFileReader", "(", ")", "\n", "paths", ",", "contents", "=", "reader", ".", "read", "(", "path_queue", ")", "\n", "raw_input", "=", "decode", "(", "contents", ")", "\n", "raw_input", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "raw_input", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "raw_input", ")", "[", "2", "]", ",", "3", ",", "message", "=", "\"image does not have 3 channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "            ", "raw_input", "=", "tf", ".", "identity", "(", "raw_input", ")", "\n", "\n", "", "raw_input", ".", "set_shape", "(", "[", "None", ",", "None", ",", "3", "]", ")", "\n", "\n", "if", "a", ".", "lab_colorization", ":", "\n", "# load color and brightness from image, no B image exists here", "\n", "            ", "lab", "=", "rgb_to_lab", "(", "raw_input", ")", "\n", "L_chan", ",", "a_chan", ",", "b_chan", "=", "preprocess_lab", "(", "lab", ")", "\n", "a_images", "=", "tf", ".", "expand_dims", "(", "L_chan", ",", "axis", "=", "2", ")", "\n", "b_images", "=", "tf", ".", "stack", "(", "[", "a_chan", ",", "b_chan", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "# break apart image pair and move to range [-1, 1]", "\n", "            ", "width", "=", "tf", ".", "shape", "(", "raw_input", ")", "[", "1", "]", "# [height, width, channels]", "\n", "a_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", ":", "width", "//", "2", ",", ":", "]", ")", "\n", "b_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "width", "//", "2", ":", ",", ":", "]", ")", "\n", "\n", "", "", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "        ", "inputs", ",", "targets", "=", "[", "a_images", ",", "b_images", "]", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "        ", "inputs", ",", "targets", "=", "[", "b_images", ",", "a_images", "]", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "\n", "# synchronize seed for image operations so that we do the same operations to both", "\n", "# input and output images", "\n", "", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "def", "transform", "(", "image", ")", ":", "\n", "        ", "r", "=", "image", "\n", "if", "a", ".", "flip", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "r", ",", "seed", "=", "seed", ")", "\n", "\n", "# area produces a nice downscaling, but does nearest neighbor for upscaling", "\n", "# assume we're going to be doing downscaling here", "\n", "", "r", "=", "tf", ".", "image", ".", "resize_images", "(", "r", ",", "[", "a", ".", "scale_size", ",", "a", ".", "scale_size", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "AREA", ")", "\n", "\n", "offset", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "2", "]", ",", "0", ",", "a", ".", "scale_size", "-", "CROP_SIZE", "+", "1", ",", "seed", "=", "seed", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "if", "a", ".", "scale_size", ">", "CROP_SIZE", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "r", ",", "offset", "[", "0", "]", ",", "offset", "[", "1", "]", ",", "CROP_SIZE", ",", "CROP_SIZE", ")", "\n", "", "elif", "a", ".", "scale_size", "<", "CROP_SIZE", ":", "\n", "            ", "raise", "Exception", "(", "\"scale size cannot be less than crop size\"", ")", "\n", "", "return", "r", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"input_images\"", ")", ":", "\n", "        ", "input_images", "=", "transform", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"target_images\"", ")", ":", "\n", "        ", "target_images", "=", "transform", "(", "targets", ")", "\n", "\n", "", "paths_batch", ",", "inputs_batch", ",", "targets_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "paths", ",", "input_images", ",", "target_images", "]", ",", "batch_size", "=", "a", ".", "batch_size", ")", "\n", "steps_per_epoch", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "input_paths", ")", "/", "a", ".", "batch_size", ")", ")", "\n", "\n", "return", "Examples", "(", "\n", "paths", "=", "paths_batch", ",", "\n", "inputs", "=", "inputs_batch", ",", "\n", "targets", "=", "targets_batch", ",", "\n", "count", "=", "len", "(", "input_paths", ")", ",", "\n", "steps_per_epoch", "=", "steps_per_epoch", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.save_images": [[543, 563], ["os.path.join", "enumerate", "os.path.exists", "os.makedirs", "os.path.splitext", "filesets.append", "os.path.basename", "os.path.join", "in_path.decode", "open", "f.write"], "function", ["None"], ["", "def", "save_images", "(", "fetches", ",", "step", "=", "None", ")", ":", "\n", "    ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"images\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "filesets", "=", "[", "]", "\n", "for", "i", ",", "in_path", "in", "enumerate", "(", "fetches", "[", "\"paths\"", "]", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "in_path", ".", "decode", "(", "\"utf8\"", ")", ")", ")", "\n", "fileset", "=", "{", "\"name\"", ":", "name", ",", "\"step\"", ":", "step", "}", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs\"", ",", "\"targets\"", "]", ":", "\n", "            ", "filename", "=", "name", "+", "\"-\"", "+", "kind", "+", "\".png\"", "\n", "if", "step", "is", "not", "None", ":", "\n", "                ", "filename", "=", "\"%08d-%s\"", "%", "(", "step", ",", "filename", ")", "\n", "", "fileset", "[", "kind", "]", "=", "filename", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "filename", ")", "\n", "contents", "=", "fetches", "[", "kind", "]", "[", "i", "]", "\n", "with", "open", "(", "out_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "contents", ")", "\n", "", "", "filesets", ".", "append", "(", "fileset", ")", "\n", "", "return", "filesets", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.append_index": [[565, 588], ["os.path.join", "os.path.exists", "open", "open", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write"], "function", ["None"], ["", "def", "append_index", "(", "filesets", ",", "step", "=", "False", ")", ":", "\n", "    ", "index_path", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"index.html\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_path", ")", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"a\"", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"w\"", ")", "\n", "index", ".", "write", "(", "\"<html><body><table><tr>\"", ")", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<th>step</th>\"", ")", "\n", "", "index", ".", "write", "(", "\"<th>name</th><th>input</th><th>output</th><th>target</th></tr>\"", ")", "\n", "\n", "", "for", "fileset", "in", "filesets", ":", "\n", "        ", "index", ".", "write", "(", "\"<tr>\"", ")", "\n", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<td>%d</td>\"", "%", "fileset", "[", "\"step\"", "]", ")", "\n", "", "index", ".", "write", "(", "\"<td>%s</td>\"", "%", "fileset", "[", "\"name\"", "]", ")", "\n", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs\"", ",", "\"targets\"", "]", ":", "\n", "            ", "index", ".", "write", "(", "\"<td><img src='images/%s'></td>\"", "%", "fileset", "[", "kind", "]", ")", "\n", "\n", "", "index", ".", "write", "(", "\"</tr>\"", ")", "\n", "", "return", "index_path", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.main": [[590, 892], ["tensorflow.set_random_seed", "numpy.random.seed", "random.seed", "a._get_kwargs", "pix2pix_dG_cv.load_examples", "print", "pix2pix_dG_cv.create_model", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.train.Saver", "tensorflow.train.Supervisor", "random.randint", "os.path.exists", "os.makedirs", "print", "open", "f.write", "tensorflow.placeholder", "tensorflow.decode_base64", "tensorflow.image.decode_png", "tensorflow.cond", "tensorflow.cond", "tensorflow.image.convert_image_dtype", "tf.image.convert_image_dtype.set_shape", "tensorflow.expand_dims", "tensorflow.convert_to_tensor", "tensorflow.placeholder", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.global_variables_initializer", "tensorflow.train.Saver", "tensorflow.train.Saver", "pix2pix_dG_cv.deprocess", "pix2pix_dG_cv.deprocess", "pix2pix_dG_cv.deprocess", "tensorflow.image.convert_image_dtype", "tensorflow.name_scope", "pix2pix_dG_cv.main.convert"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.load_examples", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_model", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "main", "(", ")", ":", "\n", "    ", "if", "a", ".", "seed", "is", "None", ":", "\n", "        ", "a", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "\n", "", "tf", ".", "set_random_seed", "(", "a", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "a", ".", "output_dir", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", "or", "a", ".", "mode", "==", "\"export\"", ":", "\n", "        ", "if", "a", ".", "checkpoint", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"checkpoint required for test mode\"", ")", "\n", "\n", "# load some options from the checkpoint", "\n", "", "options", "=", "{", "\"which_direction\"", ",", "\"ngf\"", ",", "\"ndf\"", ",", "\"lab_colorization\"", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "checkpoint", ",", "\"options.json\"", ")", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "val", "in", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "in", "options", ":", "\n", "                    ", "print", "(", "\"loaded\"", ",", "key", ",", "\"=\"", ",", "val", ")", "\n", "setattr", "(", "a", ",", "key", ",", "val", ")", "\n", "# disable these features in test mode", "\n", "", "", "", "a", ".", "scale_size", "=", "CROP_SIZE", "\n", "a", ".", "flip", "=", "False", "\n", "\n", "", "for", "k", ",", "v", "in", "a", ".", "_get_kwargs", "(", ")", ":", "\n", "        ", "print", "(", "k", ",", "\"=\"", ",", "v", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"options.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vars", "(", "a", ")", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"export\"", ":", "\n", "# export the generator to a meta graph that can be imported later for standalone generation", "\n", "        ", "if", "a", ".", "lab_colorization", ":", "\n", "            ", "raise", "Exception", "(", "\"export not supported for lab_colorization\"", ")", "\n", "\n", "", "input", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "input_data", "=", "tf", ".", "decode_base64", "(", "input", "[", "0", "]", ")", "\n", "input_image", "=", "tf", ".", "image", ".", "decode_png", "(", "input_data", ")", "\n", "\n", "# remove alpha channel if present", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "4", ")", ",", "lambda", ":", "input_image", "[", ":", ",", ":", ",", ":", "3", "]", ",", "lambda", ":", "input_image", ")", "\n", "# convert grayscale to RGB", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "1", ")", ",", "lambda", ":", "tf", ".", "image", ".", "grayscale_to_rgb", "(", "input_image", ")", ",", "lambda", ":", "input_image", ")", "\n", "\n", "input_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "input_image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "input_image", ".", "set_shape", "(", "[", "CROP_SIZE", ",", "CROP_SIZE", ",", "3", "]", ")", "\n", "batch_input", "=", "tf", ".", "expand_dims", "(", "input_image", ",", "axis", "=", "0", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "            ", "batch_output", "=", "deprocess", "(", "create_generator", "(", "preprocess", "(", "batch_input", ")", ",", "3", ")", ")", "\n", "\n", "", "output_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "batch_output", ",", "dtype", "=", "tf", ".", "uint8", ")", "[", "0", "]", "\n", "if", "a", ".", "output_filetype", "==", "\"png\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_png", "(", "output_image", ")", "\n", "", "elif", "a", ".", "output_filetype", "==", "\"jpeg\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_jpeg", "(", "output_image", ",", "quality", "=", "80", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid filetype\"", ")", "\n", "", "output", "=", "tf", ".", "convert_to_tensor", "(", "[", "tf", ".", "encode_base64", "(", "output_data", ")", "]", ")", "\n", "\n", "key", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "inputs", "=", "{", "\n", "\"key\"", ":", "key", ".", "name", ",", "\n", "\"input\"", ":", "input", ".", "name", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"inputs\"", ",", "json", ".", "dumps", "(", "inputs", ")", ")", "\n", "outputs", "=", "{", "\n", "\"key\"", ":", "tf", ".", "identity", "(", "key", ")", ".", "name", ",", "\n", "\"output\"", ":", "output", ".", "name", ",", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"outputs\"", ",", "json", ".", "dumps", "(", "outputs", ")", ")", "\n", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "restore_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "export_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "restore_saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "print", "(", "\"exporting model\"", ")", "\n", "export_saver", ".", "export_meta_graph", "(", "filename", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export.meta\"", ")", ")", "\n", "export_saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export\"", ")", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "", "return", "\n", "\n", "", "examples", "=", "load_examples", "(", ")", "\n", "print", "(", "\"examples count = %d\"", "%", "examples", ".", "count", ")", "\n", "\n", "# inputs and targets are [batch_size, height, width, channels]", "\n", "model", "=", "create_model", "(", "examples", ".", "inputs", ",", "examples", ".", "targets", ")", "\n", "\n", "# undo colorization splitting on images that we use for display/output", "\n", "if", "a", ".", "lab_colorization", ":", "\n", "        ", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "# inputs is brightness, this will be handled fine as a grayscale image", "\n", "# need to augment targets and outputs with brightness", "\n", "            ", "targets", "=", "augment", "(", "examples", ".", "targets", ",", "examples", ".", "inputs", ")", "\n", "outputs", "=", "augment", "(", "model", ".", "outputs", ",", "examples", ".", "inputs", ")", "\n", "# inputs can be deprocessed normally and handled as if they are single channel", "\n", "# grayscale images", "\n", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "# inputs will be color channels only, get brightness from targets", "\n", "            ", "inputs", "=", "augment", "(", "examples", ".", "inputs", ",", "examples", ".", "targets", ")", "\n", "targets", "=", "deprocess", "(", "examples", ".", "targets", ")", "\n", "outputs", "=", "deprocess", "(", "model", ".", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "", "", "else", ":", "\n", "        ", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "targets", "=", "deprocess", "(", "examples", ".", "targets", ")", "\n", "outputs", "=", "deprocess", "(", "model", ".", "outputs", ")", "\n", "\n", "", "def", "convert", "(", "image", ")", ":", "\n", "        ", "if", "a", ".", "aspect_ratio", "!=", "1.0", ":", "\n", "# upscale to correct aspect ratio", "\n", "            ", "size", "=", "[", "CROP_SIZE", ",", "int", "(", "round", "(", "CROP_SIZE", "*", "a", ".", "aspect_ratio", ")", ")", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "image", ",", "size", "=", "size", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "\n", "", "return", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "uint8", ",", "saturate", "=", "True", ")", "\n", "\n", "# reverse any processing on images so they can be written to disk or displayed to user", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_inputs\"", ")", ":", "\n", "        ", "converted_inputs", "=", "convert", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_targets\"", ")", ":", "\n", "        ", "converted_targets", "=", "convert", "(", "targets", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_outputs\"", ")", ":", "\n", "        ", "converted_outputs", "=", "convert", "(", "outputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"encode_images\"", ")", ":", "\n", "        ", "display_fetches", "=", "{", "\n", "\"paths\"", ":", "examples", ".", "paths", ",", "\n", "\"inputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_inputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"input_pngs\"", ")", ",", "\n", "\"targets\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_pngs\"", ")", ",", "\n", "\"outputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_pngs\"", ")", ",", "\n", "}", "\n", "\n", "# summaries", "\n", "", "with", "tf", ".", "name_scope", "(", "\"inputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"inputs\"", ",", "converted_inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"targets_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"targets\"", ",", "converted_targets", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"outputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"outputs\"", ",", "converted_outputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_real_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_real\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_real", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_fake_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_fake\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_fake", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss\"", ",", "model", ".", "discrim_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN\"", ",", "model", ".", "gen_loss_GAN", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_L1\"", ",", "model", ".", "gen_loss_L1", ")", "\n", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/values\"", ",", "var", ")", "\n", "\n", "", "for", "grad", ",", "var", "in", "model", ".", "discrim_grads_and_vars", "+", "model", ".", "gen_grads_and_vars", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/gradients\"", ",", "grad", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"parameter_count\"", ")", ":", "\n", "        ", "parameter_count", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "v", ")", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1", ")", "\n", "\n", "logdir", "=", "a", ".", "output_dir", "if", "(", "a", ".", "trace_freq", ">", "0", "or", "a", ".", "summary_freq", ">", "0", ")", "else", "None", "\n", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "logdir", "=", "logdir", ",", "save_summaries_secs", "=", "0", ",", "saver", "=", "None", ")", "\n", "with", "sv", ".", "managed_session", "(", ")", "as", "sess", ":", "\n", "        ", "print", "(", "\"parameter_count =\"", ",", "sess", ".", "run", "(", "parameter_count", ")", ")", "\n", "\n", "if", "a", ".", "checkpoint", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"#############################\"", ")", "\n", "print", "(", "\"loading model from checkpoint for continue training or testing phase ...\"", ")", "\n", "print", "(", "\"#############################\"", ")", "\n", "try", ":", "\n", "                ", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"loading was unsuccessful-it will be trained from scratch ...\"", ")", "\n", "print", "(", "\"#############################\"", ")", "\n", "\n", "", "", "max_steps", "=", "2", "**", "32", "\n", "if", "a", ".", "max_epochs", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "examples", ".", "steps_per_epoch", "*", "a", ".", "max_epochs", "\n", "", "if", "a", ".", "max_steps", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "a", ".", "max_steps", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", ":", "\n", "# testing", "\n", "# at most, process the test data once", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "max_steps", "=", "min", "(", "examples", ".", "steps_per_epoch", ",", "max_steps", ")", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "results", "=", "sess", ".", "run", "(", "display_fetches", ")", "\n", "filesets", "=", "save_images", "(", "results", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "filesets", ")", ":", "\n", "                    ", "print", "(", "\"evaluated image\"", ",", "f", "[", "\"name\"", "]", ")", "\n", "", "index_path", "=", "append_index", "(", "filesets", ")", "\n", "", "print", "(", "\"wrote index at\"", ",", "index_path", ")", "\n", "print", "(", "\"rate\"", ",", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "max_steps", ")", "\n", "", "else", ":", "\n", "# training", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "discrim_loss_pre", "=", "10000", "\n", "gan_loss_pre", "=", "10000", "\n", "patience_counter", "=", "0", "\n", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "def", "should", "(", "freq", ")", ":", "\n", "                    ", "return", "freq", ">", "0", "and", "(", "(", "step", "+", "1", ")", "%", "freq", "==", "0", "or", "step", "==", "max_steps", "-", "1", ")", "\n", "\n", "", "options", "=", "None", "\n", "run_metadata", "=", "None", "\n", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "options", "=", "tf", ".", "RunOptions", "(", "trace_level", "=", "tf", ".", "RunOptions", ".", "FULL_TRACE", ")", "\n", "run_metadata", "=", "tf", ".", "RunMetadata", "(", ")", "\n", "\n", "", "fetches", "=", "{", "\n", "\"train\"", ":", "model", ".", "train", ",", "\n", "\"global_step\"", ":", "sv", ".", "global_step", ",", "\n", "}", "\n", "\n", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"discrim_loss\"", "]", "=", "model", ".", "discrim_loss", "\n", "fetches", "[", "\"gen_loss_GAN\"", "]", "=", "model", ".", "gen_loss_GAN", "\n", "fetches", "[", "\"gen_loss_L1\"", "]", "=", "model", ".", "gen_loss_L1", "\n", "\n", "", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"summary\"", "]", "=", "sv", ".", "summary_op", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"display\"", "]", "=", "display_fetches", "\n", "\n", "", "results", "=", "sess", ".", "run", "(", "fetches", ",", "options", "=", "options", ",", "run_metadata", "=", "run_metadata", ")", "\n", "\n", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording summary\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "results", "[", "\"summary\"", "]", ",", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving display images\"", ")", "\n", "filesets", "=", "save_images", "(", "results", "[", "\"display\"", "]", ",", "step", "=", "results", "[", "\"global_step\"", "]", ")", "\n", "append_index", "(", "filesets", ",", "step", "=", "True", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording trace\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_run_metadata", "(", "run_metadata", ",", "\"step_%d\"", "%", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "# global_step will have the correct step count if we resume from a checkpoint", "\n", "                    ", "train_epoch", "=", "math", ".", "ceil", "(", "results", "[", "\"global_step\"", "]", "/", "examples", ".", "steps_per_epoch", ")", "\n", "train_step", "=", "(", "results", "[", "\"global_step\"", "]", "-", "1", ")", "%", "examples", ".", "steps_per_epoch", "+", "1", "\n", "rate", "=", "(", "step", "+", "1", ")", "*", "a", ".", "batch_size", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "remaining", "=", "(", "max_steps", "-", "step", ")", "*", "a", ".", "batch_size", "/", "rate", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"discrim_loss\"", ",", "results", "[", "\"discrim_loss\"", "]", ")", "\n", "print", "(", "\"gen_loss_GAN\"", ",", "results", "[", "\"gen_loss_GAN\"", "]", ")", "\n", "print", "(", "\"gen_loss_L1\"", ",", "results", "[", "\"gen_loss_L1\"", "]", ")", "\n", "\n", "\n", "if", "discrim_loss_pre", ">=", "results", "[", "\"discrim_loss\"", "]", ":", "\n", "                        ", "if", "gan_loss_pre", "<=", "results", "[", "\"gen_loss_GAN\"", "]", ":", "\n", "                            ", "patience_counter", "=", "patience_counter", "+", "1", "\n", "\n", "\n", "\n", "", "", "discrim_loss_pre", "=", "results", "[", "\"discrim_loss\"", "]", "\n", "gan_loss_pre", "=", "results", "[", "\"gen_loss_GAN\"", "]", "\n", "\n", "if", "patience_counter", ">=", "float", "(", "a", ".", "patience_epochs", ")", ":", "\n", "                        ", "print", "(", "\"###################\"", ")", "\n", "print", "(", "\"early stop, disc is winning\"", ")", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "break", "\n", "\n", "\n", "\n", "", "if", "results", "[", "\"gen_loss_L1\"", "]", "<", "float", "(", "a", ".", "desired_l1_loss", ")", ":", "\n", "                        ", "print", "(", "\"###################\"", ")", "\n", "print", "(", "\"Reached desired error\"", ")", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "break", "\n", "\n", "", "", "if", "should", "(", "a", ".", "save_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "\n", "", "if", "sv", ".", "should_stop", "(", ")", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_dG_cv.CombineImages": [[896, 975], ["print", "os.mkdir", "skimage.io.imread", "skimage.io.imsave", "print", "shutil.rmtree", "os.mkdir", "filename.replace.replace", "len", "numpy.zeros", "skimage.io.imread", "numpy.zeros", "skimage.io.imread", "numpy.zeros", "print", "sys.exit", "sys.exit", "len", "numpy.zeros", "len", "numpy.zeros", "str", "str"], "function", ["None"], ["", "", "", "", "", "def", "CombineImages", "(", "ImageListNames", ",", "task_No", ",", "input_dir_all", ")", ":", "\n", "    ", "print", "(", "'combining images ...'", ")", "\n", "try", ":", "\n", "        ", "os", ".", "mkdir", "(", "write_to_dir", ")", "\n", "", "except", ":", "\n", "        ", "print", "(", "'destination folder is already exist-it will be replaced'", ")", "\n", "shutil", ".", "rmtree", "(", "write_to_dir", ")", "\n", "os", ".", "mkdir", "(", "write_to_dir", ")", "\n", "\n", "\n", "", "for", "filename", "in", "ImageListNames", ":", "\n", "\n", "        ", "try", ":", "\n", "            ", "filename", "=", "filename", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "", "except", ":", "\n", "            ", "no", "=", "0", "\n", "\n", "", "Image", "=", "io", ".", "imread", "(", "a", ".", "input_dir_all", "+", "'/Inputs/'", "+", "filename", ")", "\n", "Size", "=", "Image", ".", "shape", "\n", "if", "len", "(", "Size", ")", "==", "2", ":", "\n", "            ", "Image_", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image", ".", "shape", "[", "0", "]", ",", "Image", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_", "[", ":", ",", ":", ",", "0", "]", "=", "Image", "\n", "Image_", "[", ":", ",", ":", ",", "1", "]", "=", "Image", "\n", "Image_", "[", ":", ",", ":", ",", "2", "]", "=", "Image", "\n", "Image", "=", "Image_", "\n", "\n", "", "if", "task_No", "==", "1", ":", "\n", "            ", "Image_t1", "=", "io", ".", "imread", "(", "a", ".", "input_dir_all", "+", "'/Targets_'", "+", "str", "(", "task_No", ")", "+", "'/'", "+", "filename", ")", "\n", "Size", "=", "Image_t1", ".", "shape", "\n", "if", "len", "(", "Size", ")", "==", "2", ":", "\n", "                ", "Image_", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image_t1", ".", "shape", "[", "0", "]", ",", "Image_t1", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_", "[", ":", ",", ":", ",", "0", "]", "=", "Image_t1", "\n", "Image_", "[", ":", ",", ":", ",", "1", "]", "=", "Image_t1", "\n", "Image_", "[", ":", ",", ":", ",", "2", "]", "=", "Image_t1", "\n", "Image_t1", "=", "Image_", "\n", "", "Image_combined", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image", ".", "shape", "[", "0", "]", ",", "2", "*", "Image", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_combined", "[", ":", ",", ":", "CROP_SIZE", ",", ":", "]", "=", "Image", "\n", "Image_combined", "[", ":", ",", "CROP_SIZE", ":", ",", ":", "]", "=", "Image_t1", "\n", "\n", "", "if", "task_No", "==", "2", ":", "\n", "            ", "Image_t2", "=", "io", ".", "imread", "(", "a", ".", "input_dir_all", "+", "'/Targets_'", "+", "str", "(", "task_No", ")", "+", "'/'", "+", "filename", ")", "\n", "Size", "=", "Image_t2", ".", "shape", "\n", "if", "len", "(", "Size", ")", "==", "2", ":", "\n", "                ", "Image_", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image_t2", ".", "shape", "[", "0", "]", ",", "Image_t2", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_", "[", ":", ",", ":", ",", "0", "]", "=", "Image_t2", "\n", "Image_", "[", ":", ",", ":", ",", "1", "]", "=", "Image_t2", "\n", "Image_", "[", ":", ",", ":", ",", "2", "]", "=", "Image_t2", "\n", "Image_t2", "=", "Image_", "\n", "", "Image_combined", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image", ".", "shape", "[", "0", "]", ",", "2", "*", "Image", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_combined", "[", ":", ",", ":", "CROP_SIZE", ",", ":", "]", "=", "Image", "\n", "Image_combined", "[", ":", ",", "CROP_SIZE", ":", ",", ":", "]", "=", "Image_t2", "\n", "\n", "", "if", "task_No", "==", "3", ":", "\n", "            ", "print", "(", "'3 is not acceptable for single task'", ")", "\n", "sys", ".", "exit", "(", "'3 is not acceptable for single task'", ")", "\n", "#            Image_t1=io.imread(a.input_dir_all+'Targets_1'+'/'+ filename)", "\n", "#            Image_t2=io.imread(a.input_dir_all+'Targets_2'+'/'+ filename)", "\n", "#            Size=Image_t1.shape", "\n", "#            if len(Size)==2:", "\n", "#                Image_=np.zeros(shape=[Image_t1.shape[0],Image_t1.shape[1],3], dtype='uint8')", "\n", "#                Image_[:,:,0]=Image_t1", "\n", "#                Image_[:,:,1]=Image_t1", "\n", "#                Image_[:,:,2]=Image_t1", "\n", "#                Image_t1=Image_", "\n", "#            Size=Image_t2.shape", "\n", "#            if len(Size)==2:", "\n", "#                Image_=np.zeros(shape=[Image_t2.shape[0],Image_t2.shape[1],3], dtype='uint8')", "\n", "#                Image_[:,:,0]=Image_t2", "\n", "#                Image_[:,:,1]=Image_t2", "\n", "#                Image_[:,:,2]=Image_t2", "\n", "#                Image_t2=Image_                                                 ", "\n", "#            Image_combined=np.zeros(shape=[Image.shape[0],3*Image.shape[1],3], dtype='uint8')", "\n", "#            Image_combined[:,:CROP_SIZE,:]=Image", "\n", "#            Image_combined[:,CROP_SIZE:2*CROP_SIZE,:]=Image_t1            ", "\n", "#            Image_combined[:,2*CROP_SIZE:,:]=Image_t2            ", "\n", "\n", "\n", "\n", "", "io", ".", "imsave", "(", "write_to_dir", "+", "filename", ",", "Image_combined", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_unet_p2pGenerator.callback_4_StopByLossValue.__init__": [[42, 47], ["tensorflow.keras.callbacks.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "monitor", "=", "'loss'", ",", "value", "=", "0.00001", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "super", "(", "Callback", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "monitor", "=", "monitor", "\n", "self", ".", "value", "=", "value", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_unet_p2pGenerator.callback_4_StopByLossValue.on_epoch_end": [[48, 53], ["logs.get", "print"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "current", "=", "logs", ".", "get", "(", "self", ".", "monitor", ")", "\n", "if", "current", "<", "self", ".", "value", ":", "\n", "            ", "print", "(", "\"Epoch %05d: reached desired error at epoch\"", "%", "epoch", ")", "\n", "self", ".", "model", ".", "stop_training", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_unet_p2pGenerator.custom_loss": [[55, 62], ["tensorflow.keras.losses.mean_absolute_error", "tensorflow.keras.losses.mean_absolute_error"], "function", ["None"], ["", "", "", "def", "custom_loss", "(", "y_true", ",", "y_pred", ")", ":", "\n", "\n", "\n", "#A = tensorflow.keras.losses.mean_squared_error(y_true, y_pred)", "\n", "    ", "B", "=", "tensorflow", ".", "keras", ".", "losses", ".", "mean_absolute_error", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "return", "(", "B", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_unet_p2pGenerator.lrelu": [[65, 75], ["tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["def", "lrelu", "(", "x", ")", ":", "#from pix2pix code", "\n", "    ", "a", "=", "0.2", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: a*x/2 - a*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_unet_p2pGenerator.lrelu_output_shape": [[76, 79], ["list", "tuple"], "function", ["None"], ["", "def", "lrelu_output_shape", "(", "input_shape", ")", ":", "\n", "    ", "shape", "=", "list", "(", "input_shape", ")", "\n", "return", "tuple", "(", "shape", ")", "\n", "", "layer_lrelu", "=", "Lambda", "(", "lrelu", ",", "output_shape", "=", "lrelu_output_shape", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_unet_p2pGenerator.PreProcess": [[82, 95], ["InputImages.astype.astype", "range", "numpy.max", "numpy.max"], "function", ["None"], ["def", "PreProcess", "(", "InputImages", ")", ":", "\n", "\n", "#output=np.zeros(InputImages.shape,dtype=np.float)", "\n", "    ", "InputImages", "=", "InputImages", ".", "astype", "(", "np", ".", "float", ")", "\n", "for", "i", "in", "range", "(", "InputImages", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "InputImages", "[", "i", ",", ":", ",", ":", ",", ":", "]", "=", "InputImages", "[", "i", ",", ":", ",", ":", ",", ":", "]", "/", "np", ".", "max", "(", "InputImages", "[", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "#            output[i,:,:,:] = (output[i,:,:,:]* 2)-1", "\n", "", "except", ":", "\n", "            ", "InputImages", "[", "i", ",", ":", ",", ":", "]", "=", "InputImages", "[", "i", ",", ":", ",", ":", "]", "/", "np", ".", "max", "(", "InputImages", "[", "i", ",", ":", ",", ":", "]", ")", "\n", "#            output[i,:,:] = (output[i,:,:]* 2) -1", "\n", "\n", "", "", "return", "InputImages", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_unet_p2pGenerator.CreateModel": [[145, 233], ["tensorflow.keras.layers.Input", "tensorflow.keras.layers.Input", "layer_lrelu", "layer_lrelu", "layer_lrelu", "layer_lrelu", "layer_lrelu", "layer_lrelu", "layer_lrelu", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.models.Model", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation"], "function", ["None"], ["def", "CreateModel", "(", ")", ":", "\n", "\n", "########### network    ", "\n", "    ", "kernelSize", "=", "(", "a", ".", "kernelsize", ",", "a", ".", "kernelsize", ")", "\n", "InputLayer", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "a", ".", "scale_size", ",", "a", ".", "scale_size", ",", "3", ")", ")", "\n", "e_1", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "InputLayer", ")", "\n", "\n", "e_2", "=", "layer_lrelu", "(", "e_1", ")", "\n", "e_2", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "2", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_2", ")", "\n", "e_2", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_2", ")", "\n", "\n", "e_3", "=", "layer_lrelu", "(", "e_2", ")", "\n", "e_3", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "4", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_3", ")", "\n", "e_3", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_3", ")", "\n", "\n", "e_4", "=", "layer_lrelu", "(", "e_3", ")", "\n", "e_4", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_4", ")", "\n", "e_4", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_4", ")", "\n", "\n", "e_5", "=", "layer_lrelu", "(", "e_4", ")", "\n", "e_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_5", ")", "\n", "e_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_5", ")", "\n", "\n", "e_6", "=", "layer_lrelu", "(", "e_5", ")", "\n", "e_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_6", ")", "\n", "e_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_6", ")", "\n", "\n", "e_7", "=", "layer_lrelu", "(", "e_6", ")", "\n", "e_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_7", ")", "\n", "e_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_7", ")", "\n", "\n", "e_8", "=", "layer_lrelu", "(", "e_7", ")", "\n", "e_8", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_8", ")", "\n", "e_8", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_8", ")", "\n", "\n", "\n", "\n", "\n", "d_8", "=", "e_8", "\n", "d_8", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_8", ")", "\n", "d_8", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_8", ")", "\n", "d_8", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_8", ")", "\n", "d_8", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "(", "d_8", ")", "\n", "\n", "d_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_8", ",", "e_7", "]", ",", "axis", "=", "3", ")", "\n", "d_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_7", ")", "\n", "d_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_7", ")", "\n", "d_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_7", ")", "\n", "d_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "(", "d_7", ")", "\n", "\n", "d_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_7", ",", "e_6", "]", ",", "axis", "=", "3", ")", "\n", "d_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_6", ")", "\n", "d_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_6", ")", "\n", "d_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_6", ")", "\n", "d_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "(", "d_6", ")", "\n", "\n", "d_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_6", ",", "e_5", "]", ",", "axis", "=", "3", ")", "\n", "d_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_5", ")", "\n", "d_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_5", ")", "\n", "d_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_5", ")", "\n", "d_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "(", "d_5", ")", "\n", "\n", "d_4", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_5", ",", "e_4", "]", ",", "axis", "=", "3", ")", "\n", "d_4", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_4", ")", "\n", "d_4", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", "*", "4", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_4", ")", "\n", "d_4", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_4", ")", "\n", "\n", "d_3", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_4", ",", "e_3", "]", ",", "axis", "=", "3", ")", "\n", "d_3", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_3", ")", "\n", "d_3", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", "*", "2", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_3", ")", "\n", "d_3", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_3", ")", "\n", "\n", "d_2", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_3", ",", "e_2", "]", ",", "axis", "=", "3", ")", "\n", "d_2", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_2", ")", "\n", "#        d_2=tensorflow.keras.layers.Conv2DTranspose(a.ngf, kernel_size=kernelSize, strides=(2, 2), dilation_rate=(1, 1), padding='same',)(d_2)", "\n", "d_2", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_2", ")", "\n", "d_2", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_2", ")", "\n", "\n", "\n", "d_1", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_2", ",", "e_1", "]", ",", "axis", "=", "3", ")", "\n", "d_1", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_1", ")", "\n", "d_1", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "3", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_1", ")", "\n", "OUT", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'tanh'", ",", "name", "=", "'last_layer_of_decoder'", ")", "(", "d_1", ")", "\n", "\n", "model_unet", "=", "Model", "(", "inputs", "=", "InputLayer", ",", "outputs", "=", "OUT", ")", "\n", "\n", "# model_unet.summary()", "\n", "return", "model_unet", "\n", "###########Train", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_unet_p2pGenerator.main": [[241, 335], ["print", "tensorflow.keras.models.load_model", "print", "CreateModel.predict", "range", "print", "Pr_unet_p2pGenerator.CreateModel", "print", "print", "CreateModel.summary", "tensorflow.set_random_seed", "numpy.random.seed", "random.seed", "Pr_unet_p2pGenerator.callback_4_StopByLossValue", "tensorflow.keras.callbacks.EarlyStopping", "tensorflow.keras.optimizers.Adam", "CreateModel.compile", "CreateModel.fit", "matplotlib.plot", "matplotlib.plot", "matplotlib.grid", "matplotlib.savefig", "matplotlib.close", "pickle.dump", "print", "print", "print", "print", "print", "print", "CreateModel.save", "len", "skimage.io.imsave", "skimage.io.imsave", "skimage.io.imsave", "int", "int", "open", "datetime.datetime.now", "filename_.replace.replace", "numpy.sum", "numpy.sum", "str", "tensorflow.keras.backend.count_params", "tensorflow.keras.backend.count_params", "str", "set", "set"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_Multi_unet_p2pGenerator.CreateModel", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.tfimage.save"], ["def", "main", "(", ")", ":", "\n", "\n", "\n", "    ", "if", "a", ".", "mode", "==", "'test'", ":", "\n", "\n", "        ", "checkpoint_model_file", "=", "a", ".", "checkpoint", "+", "'/Model'", "\n", "\n", "print", "(", "'loading model ...'", ")", "\n", "MODEL_unet", "=", "load_model", "(", "checkpoint_model_file", "+", "'_weights.h5'", ",", "custom_objects", "=", "{", "\n", "'custom_loss'", ":", "custom_loss", ",", "\n", "'layer_lrelu'", ":", "layer_lrelu", ",", "\n", "'lrelu'", ":", "lrelu", ",", "\n", "'lrelu_output_shape'", ":", "lrelu_output_shape", ",", "\n", "'tf'", ":", "tf", "}", ")", "\n", "\n", "print", "(", "'model is loaded '", ")", "\n", "\n", "Y_pred", "=", "MODEL_unet", ".", "predict", "(", "X_test", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "list_test", ")", ")", ":", "\n", "\n", "            ", "filename_", "=", "list_test", "[", "i", "]", "\n", "try", ":", "\n", "                ", "filename_", "=", "filename_", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "", "except", ":", "\n", "                ", "no", "=", "0", "\n", "\n", "", "io", ".", "imsave", "(", "a", ".", "output_dir", "+", "'/'", "+", "filename_", "[", ":", "-", "4", "]", "+", "'-outputs.png'", ",", "255", "*", "Y_pred", "[", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "io", ".", "imsave", "(", "a", ".", "output_dir", "+", "'/'", "+", "filename_", "[", ":", "-", "4", "]", "+", "'-inputs.png'", ",", "255", "*", "X_test", "[", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "io", ".", "imsave", "(", "a", ".", "output_dir", "+", "'/'", "+", "filename_", "[", ":", "-", "4", "]", "+", "'-targets.png'", ",", "255", "*", "Y_test", "[", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "\n", "\n", "\n", "\n", "", "", "if", "a", ".", "mode", "==", "'train'", ":", "\n", "\n", "\n", "#    plt.figure()", "\n", "#    plt.imshow(X_train[90,:,:,:])", "\n", "#    plt.figure()", "\n", "#    plt.imshow(Y_train_heatmap[90,:,:,4])", "\n", "\n", "\n", "        ", "print", "(", "'======== new training ...'", ")", "\n", "checkpoint_model_file", "=", "a", ".", "checkpoint", "+", "'/Model'", "\n", "MODEL_unet", "=", "CreateModel", "(", ")", "\n", "print", "(", "'trainable_count ='", ",", "int", "(", "np", ".", "sum", "(", "[", "K", ".", "count_params", "(", "p", ")", "for", "p", "in", "set", "(", "MODEL_unet", ".", "trainable_weights", ")", "]", ")", ")", ")", "\n", "print", "(", "'non_trainable_count ='", ",", "int", "(", "np", ".", "sum", "(", "[", "K", ".", "count_params", "(", "p", ")", "for", "p", "in", "set", "(", "MODEL_unet", ".", "non_trainable_weights", ")", "]", ")", ")", ")", "\n", "MODEL_unet", ".", "summary", "(", ")", "\n", "\n", "# fix random seed for reproducibility", "\n", "seed", "=", "a", ".", "seed", "\n", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "\n", "#### compile and train the model", "\n", "MyCallbacks_loss", "=", "callback_4_StopByLossValue", "(", "monitor", "=", "'loss'", ",", "value", "=", "a", ".", "desired_l1_loss", ",", "verbose", "=", "1", ")", "\n", "MyCallbacks_loss_val", "=", "tf", ".", "keras", ".", "callbacks", ".", "EarlyStopping", "(", "\n", "monitor", "=", "'val_loss'", ",", "min_delta", "=", "0", ",", "patience", "=", "a", ".", "patience_epochs", ",", "verbose", "=", "0", ",", "mode", "=", "'auto'", ",", "\n", "baseline", "=", "None", ",", "restore_best_weights", "=", "False", ")", "\n", "\n", "\n", "\n", "UsedOptimizer", "=", "optimizers", ".", "Adam", "(", "lr", "=", "a", ".", "lr", ",", "beta_1", "=", "a", ".", "beta1", ")", "\n", "MODEL_unet", ".", "compile", "(", "loss", "=", "custom_loss", ",", "optimizer", "=", "UsedOptimizer", ")", "\n", "History", "=", "MODEL_unet", ".", "fit", "(", "X_train", ",", "Y_train", ",", "\n", "batch_size", "=", "a", ".", "batch_size", ",", "shuffle", "=", "True", ",", "validation_split", "=", "0.05", ",", "\n", "epochs", "=", "a", ".", "max_epochs", ",", "\n", "verbose", "=", "1", ",", "callbacks", "=", "[", "MyCallbacks_loss", ",", "MyCallbacks_loss_val", "]", ")", "\n", "\n", "\n", "plt", ".", "plot", "(", "History", ".", "history", "[", "'loss'", "]", ")", "\n", "plt", ".", "plot", "(", "History", ".", "history", "[", "'val_loss'", "]", ")", "\n", "plt", ".", "grid", "(", ")", "\n", "plt", ".", "savefig", "(", "a", ".", "output_dir", "+", "'/History_'", "+", "str", "(", "a", ".", "lr", ")", "+", "'.png'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "\n", "Dict", "=", "{", "'History_loss_train'", ":", "History", ".", "history", "[", "'loss'", "]", ",", "\n", "'History_loss_val'", ":", "History", ".", "history", "[", "'val_loss'", "]", ",", "}", "\n", "pickle", ".", "dump", "(", "Dict", ",", "open", "(", "a", ".", "output_dir", "+", "'/History_'", "+", "str", "(", "a", ".", "lr", ")", "+", "'.pkl'", ",", "\"wb\"", ")", ")", "\n", "\n", "\n", "print", "(", "'===========training done================='", ")", "\n", "print", "(", "'============================'", ")", "\n", "print", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "\n", "print", "(", "'============================'", ")", "\n", "print", "(", "'============================'", ")", "\n", "\n", "\n", "print", "(", "'Saving model ...'", ")", "\n", "MODEL_unet", ".", "save", "(", "checkpoint_model_file", "+", "'_weights.h5'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_Multi_unet_p2pGenerator.callback_4_StopByLossValue.__init__": [[42, 47], ["tensorflow.keras.callbacks.Callback.__init__"], "methods", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.__init__"], ["    ", "def", "__init__", "(", "self", ",", "monitor", "=", "'loss'", ",", "value", "=", "0.00001", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "super", "(", "Callback", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "monitor", "=", "monitor", "\n", "self", ".", "value", "=", "value", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_Multi_unet_p2pGenerator.callback_4_StopByLossValue.on_epoch_end": [[48, 53], ["logs.get", "print"], "methods", ["None"], ["", "def", "on_epoch_end", "(", "self", ",", "epoch", ",", "logs", "=", "{", "}", ")", ":", "\n", "        ", "current", "=", "logs", ".", "get", "(", "self", ".", "monitor", ")", "\n", "if", "current", "<", "self", ".", "value", ":", "\n", "            ", "print", "(", "\"Epoch %05d: reached desired error at epoch\"", "%", "epoch", ")", "\n", "self", ".", "model", ".", "stop_training", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_Multi_unet_p2pGenerator.custom_loss": [[55, 62], ["tensorflow.keras.losses.mean_absolute_error", "tensorflow.keras.losses.mean_absolute_error"], "function", ["None"], ["", "", "", "def", "custom_loss", "(", "y_true", ",", "y_pred", ")", ":", "\n", "\n", "\n", "#A = tensorflow.keras.losses.mean_squared_error(y_true, y_pred)", "\n", "    ", "B", "=", "tensorflow", ".", "keras", ".", "losses", ".", "mean_absolute_error", "(", "y_true", ",", "y_pred", ")", "\n", "\n", "return", "(", "B", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_Multi_unet_p2pGenerator.lrelu": [[65, 75], ["tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["def", "lrelu", "(", "x", ")", ":", "#from pix2pix code", "\n", "    ", "a", "=", "0.2", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: a*x/2 - a*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_Multi_unet_p2pGenerator.lrelu_output_shape": [[76, 79], ["list", "tuple"], "function", ["None"], ["", "def", "lrelu_output_shape", "(", "input_shape", ")", ":", "\n", "    ", "shape", "=", "list", "(", "input_shape", ")", "\n", "return", "tuple", "(", "shape", ")", "\n", "", "layer_lrelu", "=", "Lambda", "(", "lrelu", ",", "output_shape", "=", "lrelu_output_shape", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_Multi_unet_p2pGenerator.PreProcess": [[82, 95], ["InputImages.astype.astype", "range", "numpy.max", "numpy.max"], "function", ["None"], ["def", "PreProcess", "(", "InputImages", ")", ":", "\n", "\n", "#output=np.zeros(InputImages.shape,dtype=np.float)", "\n", "    ", "InputImages", "=", "InputImages", ".", "astype", "(", "np", ".", "float", ")", "\n", "for", "i", "in", "range", "(", "InputImages", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "InputImages", "[", "i", ",", ":", ",", ":", ",", ":", "]", "=", "InputImages", "[", "i", ",", ":", ",", ":", ",", ":", "]", "/", "np", ".", "max", "(", "InputImages", "[", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "#            output[i,:,:,:] = (output[i,:,:,:]* 2)-1", "\n", "", "except", ":", "\n", "            ", "InputImages", "[", "i", ",", ":", ",", ":", "]", "=", "InputImages", "[", "i", ",", ":", ",", ":", "]", "/", "np", ".", "max", "(", "InputImages", "[", "i", ",", ":", ",", ":", "]", ")", "\n", "#            output[i,:,:] = (output[i,:,:]* 2) -1", "\n", "\n", "", "", "return", "InputImages", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_Multi_unet_p2pGenerator.CreateModel": [[142, 230], ["tensorflow.keras.layers.Input", "tensorflow.keras.layers.Input", "layer_lrelu", "layer_lrelu", "layer_lrelu", "layer_lrelu", "layer_lrelu", "layer_lrelu", "layer_lrelu", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.layers.concatenate", "tensorflow.keras.models.Model", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.Conv2D", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.BatchNormalization", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Conv2DTranspose", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.Activation"], "function", ["None"], ["def", "CreateModel", "(", ")", ":", "\n", "\n", "########### network    ", "\n", "    ", "kernelSize", "=", "(", "a", ".", "kernelsize", ",", "a", ".", "kernelsize", ")", "\n", "InputLayer", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Input", "(", "shape", "=", "(", "a", ".", "scale_size", ",", "a", ".", "scale_size", ",", "3", ")", ")", "\n", "e_1", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "InputLayer", ")", "\n", "\n", "e_2", "=", "layer_lrelu", "(", "e_1", ")", "\n", "e_2", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "2", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_2", ")", "\n", "e_2", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_2", ")", "\n", "\n", "e_3", "=", "layer_lrelu", "(", "e_2", ")", "\n", "e_3", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "4", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_3", ")", "\n", "e_3", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_3", ")", "\n", "\n", "e_4", "=", "layer_lrelu", "(", "e_3", ")", "\n", "e_4", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_4", ")", "\n", "e_4", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_4", ")", "\n", "\n", "e_5", "=", "layer_lrelu", "(", "e_4", ")", "\n", "e_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_5", ")", "\n", "e_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_5", ")", "\n", "\n", "e_6", "=", "layer_lrelu", "(", "e_5", ")", "\n", "e_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_6", ")", "\n", "e_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_6", ")", "\n", "\n", "e_7", "=", "layer_lrelu", "(", "e_6", ")", "\n", "e_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_7", ")", "\n", "e_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_7", ")", "\n", "\n", "e_8", "=", "layer_lrelu", "(", "e_7", ")", "\n", "e_8", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2D", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "e_8", ")", "\n", "e_8", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "e_8", ")", "\n", "\n", "\n", "\n", "\n", "d_8", "=", "e_8", "\n", "d_8", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_8", ")", "\n", "d_8", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_8", ")", "\n", "d_8", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_8", ")", "\n", "d_8", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "(", "d_8", ")", "\n", "\n", "d_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_8", ",", "e_7", "]", ",", "axis", "=", "3", ")", "\n", "d_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_7", ")", "\n", "d_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_7", ")", "\n", "d_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_7", ")", "\n", "d_7", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "(", "d_7", ")", "\n", "\n", "d_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_7", ",", "e_6", "]", ",", "axis", "=", "3", ")", "\n", "d_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_6", ")", "\n", "d_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_6", ")", "\n", "d_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_6", ")", "\n", "d_6", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "(", "d_6", ")", "\n", "\n", "d_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_6", ",", "e_5", "]", ",", "axis", "=", "3", ")", "\n", "d_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_5", ")", "\n", "d_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", "*", "8", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_5", ")", "\n", "d_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_5", ")", "\n", "d_5", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Dropout", "(", "0.5", ")", "(", "d_5", ")", "\n", "\n", "d_4", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_5", ",", "e_4", "]", ",", "axis", "=", "3", ")", "\n", "d_4", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_4", ")", "\n", "d_4", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", "*", "4", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_4", ")", "\n", "d_4", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_4", ")", "\n", "\n", "d_3", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_4", ",", "e_3", "]", ",", "axis", "=", "3", ")", "\n", "d_3", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_3", ")", "\n", "d_3", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", "*", "2", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_3", ")", "\n", "d_3", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_3", ")", "\n", "\n", "d_2", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_3", ",", "e_2", "]", ",", "axis", "=", "3", ")", "\n", "d_2", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_2", ")", "\n", "#        d_2=tensorflow.keras.layers.Conv2DTranspose(a.ngf, kernel_size=kernelSize, strides=(2, 2), dilation_rate=(1, 1), padding='same',)(d_2)", "\n", "d_2", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "a", ".", "ngf", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_2", ")", "\n", "d_2", "=", "tensorflow", ".", "keras", ".", "layers", ".", "BatchNormalization", "(", ")", "(", "d_2", ")", "\n", "\n", "\n", "d_1", "=", "tensorflow", ".", "keras", ".", "layers", ".", "concatenate", "(", "inputs", "=", "[", "d_2", ",", "e_1", "]", ",", "axis", "=", "3", ")", "\n", "d_1", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'relu'", ")", "(", "d_1", ")", "\n", "d_1", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Conv2DTranspose", "(", "6", ",", "kernel_size", "=", "kernelSize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "dilation_rate", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "'same'", ",", ")", "(", "d_1", ")", "\n", "OUT", "=", "tensorflow", ".", "keras", ".", "layers", ".", "Activation", "(", "'tanh'", ",", "name", "=", "'last_layer_of_decoder'", ")", "(", "d_1", ")", "\n", "\n", "model_unet", "=", "Model", "(", "inputs", "=", "InputLayer", ",", "outputs", "=", "OUT", ")", "\n", "\n", "# model_unet.summary()", "\n", "return", "model_unet", "\n", "###########Train", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_Multi_unet_p2pGenerator.main": [[238, 334], ["print", "tensorflow.keras.models.load_model", "print", "CreateModel.predict", "range", "print", "Pr_Multi_unet_p2pGenerator.CreateModel", "print", "print", "CreateModel.summary", "tensorflow.set_random_seed", "numpy.random.seed", "random.seed", "Pr_Multi_unet_p2pGenerator.callback_4_StopByLossValue", "tensorflow.keras.callbacks.EarlyStopping", "tensorflow.keras.optimizers.Adam", "CreateModel.compile", "CreateModel.fit", "matplotlib.plot", "matplotlib.plot", "matplotlib.grid", "matplotlib.savefig", "matplotlib.close", "pickle.dump", "print", "print", "print", "print", "print", "print", "CreateModel.save", "len", "skimage.io.imsave", "skimage.io.imsave", "skimage.io.imsave", "skimage.io.imsave", "skimage.io.imsave", "int", "int", "open", "datetime.datetime.now", "filename_.replace.replace", "numpy.sum", "numpy.sum", "str", "tensorflow.keras.backend.count_params", "tensorflow.keras.backend.count_params", "str", "set", "set"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.Pr_Multi_unet_p2pGenerator.CreateModel", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.tfimage.save"], ["def", "main", "(", ")", ":", "\n", "\n", "\n", "    ", "if", "a", ".", "mode", "==", "'test'", ":", "\n", "\n", "        ", "checkpoint_model_file", "=", "a", ".", "checkpoint", "+", "'/Model'", "\n", "\n", "print", "(", "'loading model ...'", ")", "\n", "MODEL_unet", "=", "load_model", "(", "checkpoint_model_file", "+", "'_weights.h5'", ",", "custom_objects", "=", "{", "\n", "'custom_loss'", ":", "custom_loss", ",", "\n", "'layer_lrelu'", ":", "layer_lrelu", ",", "\n", "'lrelu'", ":", "lrelu", ",", "\n", "'lrelu_output_shape'", ":", "lrelu_output_shape", ",", "\n", "'tf'", ":", "tf", "}", ")", "\n", "\n", "print", "(", "'model is loaded '", ")", "\n", "\n", "Y_pred", "=", "MODEL_unet", ".", "predict", "(", "X_test", ")", "\n", "Y_pred_1", "=", "Y_pred", "[", ":", ",", ":", ",", ":", ",", ":", "3", "]", "\n", "Y_pred_2", "=", "Y_pred", "[", ":", ",", ":", ",", ":", ",", "3", ":", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "list_test", ")", ")", ":", "\n", "\n", "            ", "filename_", "=", "list_test", "[", "i", "]", "\n", "try", ":", "\n", "                ", "filename_", "=", "filename_", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "", "except", ":", "\n", "                ", "no", "=", "0", "\n", "\n", "", "io", ".", "imsave", "(", "a", ".", "output_dir", "+", "'/'", "+", "filename_", "[", ":", "-", "4", "]", "+", "'-outputs_1.png'", ",", "255", "*", "Y_pred_1", "[", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "io", ".", "imsave", "(", "a", ".", "output_dir", "+", "'/'", "+", "filename_", "[", ":", "-", "4", "]", "+", "'-outputs_2.png'", ",", "255", "*", "Y_pred_2", "[", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "io", ".", "imsave", "(", "a", ".", "output_dir", "+", "'/'", "+", "filename_", "[", ":", "-", "4", "]", "+", "'-inputs.png'", ",", "255", "*", "X_test", "[", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "io", ".", "imsave", "(", "a", ".", "output_dir", "+", "'/'", "+", "filename_", "[", ":", "-", "4", "]", "+", "'-targets_1.png'", ",", "255", "*", "Y_test_1", "[", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "io", ".", "imsave", "(", "a", ".", "output_dir", "+", "'/'", "+", "filename_", "[", ":", "-", "4", "]", "+", "'-targets_2.png'", ",", "255", "*", "Y_test_2", "[", "i", ",", ":", ",", ":", ",", ":", "]", ")", "\n", "\n", "\n", "\n", "\n", "", "", "if", "a", ".", "mode", "==", "'train'", ":", "\n", "\n", "\n", "#    plt.figure()", "\n", "#    plt.imshow(X_train[90,:,:,:])", "\n", "#    plt.figure()", "\n", "#    plt.imshow(Y_train_heatmap[90,:,:,4])", "\n", "\n", "\n", "        ", "print", "(", "'======== new training ...'", ")", "\n", "checkpoint_model_file", "=", "a", ".", "checkpoint", "+", "'/Model'", "\n", "MODEL_unet", "=", "CreateModel", "(", ")", "\n", "print", "(", "'trainable_count ='", ",", "int", "(", "np", ".", "sum", "(", "[", "K", ".", "count_params", "(", "p", ")", "for", "p", "in", "set", "(", "MODEL_unet", ".", "trainable_weights", ")", "]", ")", ")", ")", "\n", "print", "(", "'non_trainable_count ='", ",", "int", "(", "np", ".", "sum", "(", "[", "K", ".", "count_params", "(", "p", ")", "for", "p", "in", "set", "(", "MODEL_unet", ".", "non_trainable_weights", ")", "]", ")", ")", ")", "\n", "MODEL_unet", ".", "summary", "(", ")", "\n", "\n", "# fix random seed for reproducibility", "\n", "seed", "=", "a", ".", "seed", "\n", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "\n", "#### compile and train the model", "\n", "MyCallbacks_loss", "=", "callback_4_StopByLossValue", "(", "monitor", "=", "'loss'", ",", "value", "=", "a", ".", "desired_l1_loss", ",", "verbose", "=", "1", ")", "\n", "MyCallbacks_loss_val", "=", "tf", ".", "keras", ".", "callbacks", ".", "EarlyStopping", "(", "\n", "monitor", "=", "'val_loss'", ",", "min_delta", "=", "0", ",", "patience", "=", "a", ".", "patience_epochs", ",", "verbose", "=", "0", ",", "mode", "=", "'auto'", ",", "\n", "baseline", "=", "None", ",", "restore_best_weights", "=", "False", ")", "\n", "\n", "UsedOptimizer", "=", "optimizers", ".", "Adam", "(", "lr", "=", "a", ".", "lr", ",", "beta_1", "=", "a", ".", "beta1", ")", "\n", "MODEL_unet", ".", "compile", "(", "loss", "=", "custom_loss", ",", "optimizer", "=", "UsedOptimizer", ")", "\n", "History", "=", "MODEL_unet", ".", "fit", "(", "X_train", ",", "Y_train", ",", "\n", "batch_size", "=", "a", ".", "batch_size", ",", "shuffle", "=", "True", ",", "validation_split", "=", "0.05", ",", "\n", "epochs", "=", "a", ".", "max_epochs", ",", "\n", "verbose", "=", "1", ",", "callbacks", "=", "[", "MyCallbacks_loss", ",", "MyCallbacks_loss_val", "]", ")", "\n", "\n", "\n", "plt", ".", "plot", "(", "History", ".", "history", "[", "'loss'", "]", ")", "\n", "plt", ".", "plot", "(", "History", ".", "history", "[", "'val_loss'", "]", ")", "\n", "plt", ".", "grid", "(", ")", "\n", "plt", ".", "savefig", "(", "a", ".", "output_dir", "+", "'/History_'", "+", "str", "(", "a", ".", "lr", ")", "+", "'.png'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "\n", "Dict", "=", "{", "'History_loss_train'", ":", "History", ".", "history", "[", "'loss'", "]", ",", "\n", "'History_loss_val'", ":", "History", ".", "history", "[", "'val_loss'", "]", ",", "}", "\n", "pickle", ".", "dump", "(", "Dict", ",", "open", "(", "a", ".", "output_dir", "+", "'/History_'", "+", "str", "(", "a", ".", "lr", ")", "+", "'.pkl'", ",", "\"wb\"", ")", ")", "\n", "\n", "\n", "print", "(", "'===========training done================='", ")", "\n", "print", "(", "'============================'", ")", "\n", "print", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "\n", "print", "(", "'============================'", ")", "\n", "print", "(", "'============================'", ")", "\n", "\n", "\n", "print", "(", "'Saving model ...'", ")", "\n", "MODEL_unet", ".", "save", "(", "checkpoint_model_file", "+", "'_weights.h5'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.preprocess": [[86, 90], ["tensorflow.name_scope"], "function", ["None"], ["def", "preprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess\"", ")", ":", "\n", "# [0, 1] => [-1, 1]", "\n", "        ", "return", "image", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.deprocess": [[92, 96], ["tensorflow.name_scope"], "function", ["None"], ["", "", "def", "deprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess\"", ")", ":", "\n", "# [-1, 1] => [0, 1]", "\n", "        ", "return", "(", "image", "+", "1", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.preprocess_lab": [[98, 105], ["tensorflow.name_scope", "tensorflow.unstack"], "function", ["None"], ["", "", "def", "preprocess_lab", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess_lab\"", ")", ":", "\n", "        ", "L_chan", ",", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "lab", ",", "axis", "=", "2", ")", "\n", "# L_chan: black and white with input range [0, 100]", "\n", "# a_chan/b_chan: color channels with input range ~[-110, 110], not exact", "\n", "# [0, 100] => [-1, 1],  ~[-110, 110] => [-1, 1]", "\n", "return", "[", "L_chan", "/", "50", "-", "1", ",", "a_chan", "/", "110", ",", "b_chan", "/", "110", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.deprocess_lab": [[107, 111], ["tensorflow.name_scope", "tensorflow.stack"], "function", ["None"], ["", "", "def", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess_lab\"", ")", ":", "\n", "# this is axis=3 instead of axis=2 because we process individual images but deprocess batches", "\n", "        ", "return", "tf", ".", "stack", "(", "[", "(", "L_chan", "+", "1", ")", "/", "2", "*", "100", ",", "a_chan", "*", "110", ",", "b_chan", "*", "110", "]", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.augment": [[113, 120], ["tensorflow.unstack", "tensorflow.squeeze", "pix2pix_MT_cv.deprocess_lab", "lab_to_rgb"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess_lab", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lab_to_rgb"], ["", "", "def", "augment", "(", "image", ",", "brightness", ")", ":", "\n", "# (a, b) color channels, combine with L channel and convert to rgb", "\n", "    ", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "image", ",", "axis", "=", "3", ")", "\n", "L_chan", "=", "tf", ".", "squeeze", "(", "brightness", ",", "axis", "=", "3", ")", "\n", "lab", "=", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", "\n", "rgb", "=", "lab_to_rgb", "(", "lab", ")", "\n", "return", "rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.discrim_conv": [[122, 125], ["tensorflow.pad", "tensorflow.layers.conv2d", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "discrim_conv", "(", "batch_input", ",", "out_channels", ",", "stride", ")", ":", "\n", "    ", "padded_input", "=", "tf", ".", "pad", "(", "batch_input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"CONSTANT\"", ")", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "padded_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "stride", ",", "stride", ")", ",", "padding", "=", "\"valid\"", ",", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.gen_conv": [[127, 134], ["tensorflow.random_normal_initializer", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d"], "function", ["None"], ["", "def", "gen_conv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.gen_deconv": [[136, 145], ["tensorflow.random_normal_initializer", "tensorflow.image.resize_images", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d_transpose"], "function", ["None"], ["", "", "def", "gen_deconv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "_b", ",", "h", ",", "w", ",", "_c", "=", "batch_input", ".", "shape", "\n", "resized_input", "=", "tf", ".", "image", ".", "resize_images", "(", "batch_input", ",", "[", "h", "*", "2", ",", "w", "*", "2", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "resized_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d_transpose", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.lrelu": [[147, 157], ["tensorflow.name_scope", "tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["", "", "def", "lrelu", "(", "x", ",", "a", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lrelu\"", ")", ":", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: a*x/2 - a*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "        ", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.batchnorm": [[159, 161], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "", "def", "batchnorm", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.dice_coe": [[163, 212], ["pix2pix_MT_cv.deprocess", "pix2pix_MT_cv.deprocess", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "Exception"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "dice_coe", "(", "output", ",", "target", ",", "loss_type", "=", "'jaccard'", ",", "axis", "=", "(", "1", ",", "2", ",", "3", ")", ",", "smooth", "=", "1e-5", ")", ":", "\n", "# Moha: based on code from tensorlayer", "\n", "    ", "\"\"\"Soft dice (Sorensen or Jaccard) coefficient for comparing the similarity\n    of two batch of data, usually be used for binary image segmentation\n    i.e. labels are binary. The coefficient between 0 to 1, 1 means totally match.\n    Parameters\n    -----------\n    output : Tensor\n        A distribution with shape: [batch_size, ....], (any dimensions).\n    target : Tensor\n        The target distribution, format the same with `output`.\n    loss_type : str\n        ``jaccard`` or ``sorensen``, default is ``jaccard``.\n    axis : tuple of int\n        All dimensions are reduced, default ``[1,2,3]``.\n    smooth : float\n        This small value will be added to the numerator and denominator.\n            - If both output and target are empty, it makes sure dice is 1.\n            - If either output or target are empty (all pixels are background), dice = ```smooth/(small_value + smooth)``, then if smooth is very small, dice close to 0 (even the image values lower than the threshold), so in this case, higher smooth can have a higher dice.\n    Examples\n    ---------\n    >>> outputs = tl.act.pixel_wise_softmax(network.outputs)\n    >>> dice_loss = 1 - tl.cost.dice_coe(outputs, y_)\n    \"\"\"", "\n", "\n", "output", "=", "deprocess", "(", "output", ")", "\n", "target", "=", "deprocess", "(", "target", ")", "\n", "\n", "output", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "output", ">", "0.5", ")", ")", "\n", "target", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "target", ">", "0.5", ")", ")", "\n", "\n", "inse", "=", "tf", ".", "reduce_sum", "(", "output", "*", "target", ",", "axis", "=", "axis", ")", "\n", "if", "loss_type", "==", "'jaccard'", ":", "\n", "        ", "l", "=", "tf", ".", "reduce_sum", "(", "output", "*", "output", ",", "axis", "=", "axis", ")", "\n", "r", "=", "tf", ".", "reduce_sum", "(", "target", "*", "target", ",", "axis", "=", "axis", ")", "\n", "", "elif", "loss_type", "==", "'sorensen'", ":", "\n", "        ", "l", "=", "tf", ".", "reduce_sum", "(", "output", ",", "axis", "=", "axis", ")", "\n", "r", "=", "tf", ".", "reduce_sum", "(", "target", ",", "axis", "=", "axis", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Unknow loss_type\"", ")", "\n", "# old axis=[0,1,2,3]", "\n", "# dice = 2 * (inse) / (l + r)", "\n", "# epsilon = 1e-5", "\n", "# dice = tf.clip_by_value(dice, 0, 1.0-epsilon) # if all empty, dice = 1", "\n", "# new haodong", "\n", "", "dice", "=", "(", "2.", "*", "inse", "+", "smooth", ")", "/", "(", "l", "+", "r", "+", "smooth", ")", "\n", "##", "\n", "dice", "=", "tf", ".", "reduce_mean", "(", "dice", ",", "name", "=", "'dice_coe'", ")", "\n", "return", "dice", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.tversky_loss": [[214, 252], ["pix2pix_MT_cv.deprocess", "pix2pix_MT_cv.deprocess", "tensorflow.contrib.layers.flatten", "tensorflow.contrib.layers.flatten", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.reduce_sum", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "tversky_loss", "(", "labels", ",", "predictions", ",", "alpha", "=", "0.3", ",", "beta", "=", "0.7", ",", "smooth", "=", "1e-10", ")", ":", "\n", "# Moha: based on code from: https://analysiscenter.github.io/radio/_modules/radio/models/tf/losses.html#tversky_loss", "\n", "    ", "\"\"\" Tversky loss function.\n\n    Parameters\n    ----------\n    labels : tf.Tensor\n        tensor containing target mask.\n    predictions : tf.Tensor\n        tensor containing predicted mask.\n    alpha : float\n        real value, weight of '0' class.\n    beta : float\n        real value, weight of '1' class.\n    smooth : float\n        small real value used for avoiding division by zero error.\n\n    Returns\n    -------\n    tf.Tensor\n        tensor containing tversky loss.\n    \"\"\"", "\n", "\n", "labels", "=", "deprocess", "(", "labels", ")", "\n", "predictions", "=", "deprocess", "(", "predictions", ")", "\n", "\n", "labels", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "labels", ")", "\n", "predictions", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "predictions", ")", "\n", "\n", "labels", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "labels", ">", "0.5", ")", ")", "\n", "predictions", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "predictions", ">", "0.5", ")", ")", "\n", "\n", "\n", "truepos", "=", "tf", ".", "reduce_sum", "(", "labels", "*", "predictions", ")", "\n", "fp_and_fn", "=", "(", "alpha", "*", "tf", ".", "reduce_sum", "(", "predictions", "*", "(", "1", "-", "labels", ")", ")", "\n", "+", "beta", "*", "tf", ".", "reduce_sum", "(", "(", "1", "-", "predictions", ")", "*", "labels", ")", ")", "\n", "\n", "return", "(", "truepos", "+", "smooth", ")", "/", "(", "truepos", "+", "smooth", "+", "fp_and_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.create_generator": [[255, 328], ["print", "print", "print", "len", "enumerate", "tensorflow.variable_scope", "pix2pix_MT_cv.gen_conv", "layers.append", "print", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.nn.relu", "pix2pix_MT_cv.gen_deconv", "tensorflow.tanh", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_MT_cv.lrelu", "pix2pix_MT_cv.gen_conv", "pix2pix_MT_cv.batchnorm", "layers.append", "print", "tensorflow.variable_scope", "tensorflow.nn.relu", "pix2pix_MT_cv.gen_deconv", "pix2pix_MT_cv.batchnorm", "layers.append", "print", "tensorflow.concat", "tensorflow.nn.dropout", "len"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm"], ["", "def", "create_generator", "(", "generator_inputs", ",", "generator_outputs_channels", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "\n", "print", "(", "'encoder:'", ")", "\n", "print", "(", "generator_inputs", ".", "shape", ")", "\n", "# encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_1\"", ")", ":", "\n", "        ", "output", "=", "gen_conv", "(", "generator_inputs", ",", "a", ".", "ngf", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "a", ".", "ngf", "*", "2", ",", "# encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]", "\n", "a", ".", "ngf", "*", "4", ",", "# encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]", "\n", "]", "\n", "\n", "for", "out_channels", "in", "layer_specs", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]", "\n", "convolved", "=", "gen_conv", "(", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "", "print", "(", "'decoder:'", ")", "\n", "layer_specs", "=", "[", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.0", ")", ",", "# decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "4", ",", "0.0", ")", ",", "# decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]", "\n", "(", "a", ".", "ngf", "*", "2", ",", "0.0", ")", ",", "# decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]", "\n", "(", "a", ".", "ngf", ",", "0.0", ")", ",", "# decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]", "\n", "]", "\n", "\n", "num_encoder_layers", "=", "len", "(", "layers", ")", "\n", "for", "decoder_layer", ",", "(", "out_channels", ",", "dropout", ")", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "skip_layer", "=", "num_encoder_layers", "-", "decoder_layer", "-", "1", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder_%d\"", "%", "(", "skip_layer", "+", "1", ")", ")", ":", "\n", "            ", "if", "decoder_layer", "==", "0", ":", "\n", "# first decoder layer doesn't have skip connections", "\n", "# since it is directly connected to the skip_layer", "\n", "                ", "input", "=", "layers", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "skip_layer", "]", "]", ",", "axis", "=", "3", ")", "\n", "\n", "", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batchnorm", "(", "output", ")", "\n", "\n", "if", "dropout", ">", "0.0", ":", "\n", "                ", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "keep_prob", "=", "1", "-", "dropout", ")", "\n", "\n", "", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "# decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"decoder_1\"", ")", ":", "\n", "        ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "0", "]", "]", ",", "axis", "=", "3", ")", "\n", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "generator_outputs_channels", ")", "\n", "output", "=", "tf", ".", "tanh", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.create_model_MT": [[333, 464], ["tensorflow.concat", "tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "print", "tensorflow.concat", "print", "range", "tensorflow.variable_scope", "int", "pix2pix_MT_cv.create_generator", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.abs", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.variable_scope", "pix2pix_MT_cv.discrim_conv", "pix2pix_MT_cv.lrelu", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_MT_cv.discrim_conv", "tensorflow.sigmoid", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_MT_cv.create_model_MT.create_discriminator"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_generator", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv"], ["", "def", "create_model_MT", "(", "inputs", ",", "targets_1", ",", "targets_2", ")", ":", "\n", "\n", "    ", "def", "create_discriminator", "(", "discrim_inputs", ",", "discrim_targets", ")", ":", "\n", "        ", "n_layers", "=", "3", "\n", "layers", "=", "[", "]", "\n", "print", "(", "'discriminator:'", ")", "\n", "\n", "# 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]", "\n", "input", "=", "tf", ".", "concat", "(", "[", "discrim_inputs", ",", "discrim_targets", "]", ",", "axis", "=", "3", ")", "\n", "print", "(", "input", ".", "shape", ")", "\n", "# layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"layer_1\"", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "input", ",", "a", ".", "ndf", ",", "stride", "=", "2", ")", "\n", "rectified", "=", "lrelu", "(", "convolved", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]", "\n", "# layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]", "\n", "# layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]", "\n", "", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "                ", "out_channels", "=", "a", ".", "ndf", "*", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "stride", "=", "1", "if", "i", "==", "n_layers", "-", "1", "else", "2", "# last layer here has stride 1", "\n", "convolved", "=", "discrim_conv", "(", "layers", "[", "-", "1", "]", ",", "out_channels", ",", "stride", "=", "stride", ")", "\n", "normalized", "=", "batchnorm", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "rectified", ",", "out_channels", "=", "1", ",", "stride", "=", "1", ")", "\n", "output", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n", "\n", "", "targets", "=", "tf", ".", "concat", "(", "[", "targets_1", ",", "targets_2", "]", ",", "axis", "=", "3", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "        ", "out_channels", "=", "int", "(", "targets", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "outputs", "=", "create_generator", "(", "inputs", ",", "out_channels", ")", "\n", "\n", "# create two copies of discriminator, one for real pairs and one for fake pairs", "\n", "# they share the same underlying variables", "\n", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_real", "=", "create_discriminator", "(", "inputs", ",", "targets", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ",", "reuse", "=", "True", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_fake", "=", "create_discriminator", "(", "inputs", ",", "outputs", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_loss\"", ")", ":", "\n", "# minimizing -tf.log will try to get inputs to 1", "\n", "# predict_real => 1 ", "\n", "# predict_fake => 0", "\n", "        ", "discrim_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "discrim_loss_real", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", ")", ")", "\n", "discrim_loss_fake", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_loss\"", ")", ":", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "        ", "gen_loss_GAN", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_fake", "+", "EPS", ")", ")", "\n", "gen_loss_L1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "targets", "-", "outputs", ")", ")", "\n", "gen_loss_dice", "=", "1", "-", "dice_coe", "(", "outputs", ",", "targets", ",", "loss_type", "=", "'sorensen'", ")", "\n", "gen_loss_jaccard", "=", "1", "-", "dice_coe", "(", "outputs", ",", "targets", ",", "loss_type", "=", "'jaccard'", ")", "\n", "\n", "gen_loss_Tversky", "=", "tf", ".", "abs", "(", "1", "-", "tversky_loss", "(", "targets", ",", "outputs", ")", ")", "\n", "gen_loss", "=", "gen_loss_GAN", "*", "a", ".", "gan_weight", "+", "gen_loss_L1", "*", "a", ".", "l1_weight", "\n", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_train\"", ")", ":", "\n", "        ", "discrim_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"discriminator\"", ")", "]", "\n", "discrim_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "discrim_grads_and_vars", "=", "discrim_optim", ".", "compute_gradients", "(", "discrim_loss", ",", "var_list", "=", "discrim_tvars", ")", "\n", "discrim_train", "=", "discrim_optim", ".", "apply_gradients", "(", "discrim_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_train", "]", ")", ":", "\n", "            ", "gen_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"generator\"", ")", "]", "\n", "gen_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "gen_grads_and_vars", "=", "gen_optim", ".", "compute_gradients", "(", "gen_loss", ",", "var_list", "=", "gen_tvars", ")", "\n", "gen_train", "=", "gen_optim", ".", "apply_gradients", "(", "gen_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "\n", "# orig: ----------------------", "\n", "#update_losses = ema.apply([discrim_loss, gen_loss_GAN, gen_loss_L1])", "\n", "# end orig", "\n", "# Moha: ----------------------", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_loss", ",", "gen_loss_GAN", ",", "gen_loss_L1", ",", "\n", "gen_loss", ",", "discrim_loss_real", ",", "discrim_loss_fake", ",", "gen_loss_jaccard", ",", "\n", "gen_loss_dice", ",", "gen_loss_Tversky", "]", ")", "\n", "\n", "outputs_1", "=", "outputs", "[", ":", ",", ":", ",", ":", ",", ":", "3", "]", "\n", "outputs_2", "=", "outputs", "[", ":", ",", ":", ",", ":", ",", "3", ":", "]", "\n", "# End Moha", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "\n", "return", "Model", "(", "\n", "predict_real", "=", "predict_real", ",", "\n", "predict_fake", "=", "predict_fake", ",", "\n", "\n", "discrim_loss", "=", "ema", ".", "average", "(", "discrim_loss", ")", ",", "\n", "discrim_grads_and_vars", "=", "discrim_grads_and_vars", ",", "\n", "\n", "gen_loss_GAN", "=", "ema", ".", "average", "(", "gen_loss_GAN", ")", ",", "\n", "gen_loss_L1", "=", "ema", ".", "average", "(", "gen_loss_L1", ")", ",", "\n", "gen_grads_and_vars", "=", "gen_grads_and_vars", ",", "\n", "\n", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_train", ")", ",", "\n", "# Noha: -----------------", "\n", "outputs_1", "=", "outputs_1", ",", "\n", "outputs_2", "=", "outputs_2", ",", "\n", "gen_loss", "=", "ema", ".", "average", "(", "gen_loss", ")", ",", "\n", "discrim_loss_fake", "=", "ema", ".", "average", "(", "discrim_loss_fake", ")", ",", "\n", "discrim_loss_real", "=", "ema", ".", "average", "(", "discrim_loss_real", ")", ",", "\n", "gen_loss_jaccard", "=", "ema", ".", "average", "(", "gen_loss_jaccard", ")", ",", "\n", "gen_loss_dice", "=", "ema", ".", "average", "(", "gen_loss_dice", ")", ",", "\n", "gen_loss_Tversky", "=", "ema", ".", "average", "(", "gen_loss_Tversky", ")", "\n", "# End Moha", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.check_image": [[557, 570], ["tensorflow.assert_equal", "list", "tf.identity.set_shape", "tensorflow.control_dependencies", "tensorflow.identity", "ValueError", "tf.identity.get_shape", "tensorflow.shape", "tf.identity.get_shape"], "function", ["None"], ["", "def", "check_image", "(", "image", ")", ":", "\n", "    ", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "image", ")", "[", "-", "1", "]", ",", "3", ",", "message", "=", "\"image must have 3 color channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "        ", "image", "=", "tf", ".", "identity", "(", "image", ")", "\n", "\n", "", "if", "image", ".", "get_shape", "(", ")", ".", "ndims", "not", "in", "(", "3", ",", "4", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"image must be either 3 or 4 dimensions\"", ")", "\n", "\n", "# make the last dimension 3 so that you can unstack the colors", "\n", "", "shape", "=", "list", "(", "image", ".", "get_shape", "(", ")", ")", "\n", "shape", "[", "-", "1", "]", "=", "3", "\n", "image", ".", "set_shape", "(", "shape", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.load_examples": [[571, 663], ["glob.glob", "all", "random.randint", "tensorflow.train.batch", "int", "Examples", "Exception", "os.path.join", "len", "glob.glob", "len", "Exception", "os.path.splitext", "sorted", "sorted", "tensorflow.name_scope", "tensorflow.train.string_input_producer", "tensorflow.WholeFileReader", "tf.WholeFileReader.read", "decode", "tensorflow.image.convert_image_dtype", "tensorflow.assert_equal", "tf.identity.set_shape", "pix2pix_MT_cv.preprocess", "pix2pix_MT_cv.preprocess", "pix2pix_MT_cv.preprocess", "tensorflow.image.resize_images", "tensorflow.cast", "tensorflow.name_scope", "pix2pix_MT_cv.load_examples.transform"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess"], ["", "def", "load_examples", "(", ")", ":", "\n", "    ", "if", "a", ".", "input_dir", "is", "None", "or", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "input_dir", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir does not exist\"", ")", "\n", "\n", "", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.jpg\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_jpeg", "\n", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.png\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_png", "\n", "\n", "", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir contains no image files\"", ")", "\n", "\n", "", "def", "get_name", "(", "path", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "\n", "return", "name", "\n", "\n", "# if the image names are numbers, sort by the value rather than asciibetically", "\n", "# having sorted inputs means that the outputs are sorted in test mode", "\n", "", "if", "all", "(", "get_name", "(", "path", ")", ".", "isdigit", "(", ")", "for", "path", "in", "input_paths", ")", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ",", "key", "=", "lambda", "path", ":", "int", "(", "get_name", "(", "path", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"load_images\"", ")", ":", "\n", "        ", "path_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "input_paths", ",", "shuffle", "=", "a", ".", "mode", "==", "\"train\"", ")", "\n", "reader", "=", "tf", ".", "WholeFileReader", "(", ")", "\n", "paths", ",", "contents", "=", "reader", ".", "read", "(", "path_queue", ")", "\n", "raw_input", "=", "decode", "(", "contents", ")", "\n", "raw_input", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "raw_input", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "raw_input", ")", "[", "2", "]", ",", "3", ",", "message", "=", "\"image does not have 3 channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "            ", "raw_input", "=", "tf", ".", "identity", "(", "raw_input", ")", "\n", "\n", "", "raw_input", ".", "set_shape", "(", "[", "None", ",", "None", ",", "3", "]", ")", "\n", "\n", "\n", "# break apart image pair and move to range [-1, 1]", "\n", "width", "=", "tf", ".", "shape", "(", "raw_input", ")", "[", "1", "]", "# [height, width, channels]", "\n", "a_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", ":", "width", "//", "3", ",", ":", "]", ")", "\n", "b_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "width", "//", "3", ":", "2", "*", "width", "//", "3", ",", ":", "]", ")", "\n", "c_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "2", "*", "width", "//", "3", ":", ",", ":", "]", ")", "\n", "\n", "\n", "\n", "", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "        ", "inputs", ",", "targets_1", ",", "targets_2", "=", "[", "a_images", ",", "b_images", ",", "c_images", "]", "\n", "#targets_2=c_images", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "#inputs, targets_1, targets_2 = [b_images, a_images]", "\n", "        ", "print", "(", "\"Error:::: just use AtoB direction\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "\n", "# synchronize seed for image operations so that we do the same operations to both", "\n", "# input and output images", "\n", "", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "def", "transform", "(", "image", ")", ":", "\n", "        ", "r", "=", "image", "\n", "if", "a", ".", "flip", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "r", ",", "seed", "=", "seed", ")", "\n", "\n", "# area produces a nice downscaling, but does nearest neighbor for upscaling", "\n", "# assume we're going to be doing downscaling here", "\n", "", "r", "=", "tf", ".", "image", ".", "resize_images", "(", "r", ",", "[", "a", ".", "scale_size", ",", "a", ".", "scale_size", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "AREA", ")", "\n", "\n", "offset", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "2", "]", ",", "0", ",", "a", ".", "scale_size", "-", "CROP_SIZE", "+", "1", ",", "seed", "=", "seed", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "if", "a", ".", "scale_size", ">", "CROP_SIZE", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "r", ",", "offset", "[", "0", "]", ",", "offset", "[", "1", "]", ",", "CROP_SIZE", ",", "CROP_SIZE", ")", "\n", "", "elif", "a", ".", "scale_size", "<", "CROP_SIZE", ":", "\n", "            ", "raise", "Exception", "(", "\"scale size cannot be less than crop size\"", ")", "\n", "", "return", "r", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"input_images\"", ")", ":", "\n", "        ", "input_images", "=", "transform", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"target_images\"", ")", ":", "\n", "        ", "target_1_images", "=", "transform", "(", "targets_1", ")", "\n", "target_2_images", "=", "transform", "(", "targets_2", ")", "\n", "#        target_images=tf.concat([target_1_images,target_2_images],axis=3)", "\n", "\n", "", "paths_batch", ",", "inputs_batch", ",", "targets_1_batch", ",", "targets_2_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "paths", ",", "input_images", ",", "target_1_images", ",", "target_2_images", "]", ",", "batch_size", "=", "a", ".", "batch_size", ")", "\n", "steps_per_epoch", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "input_paths", ")", "/", "a", ".", "batch_size", ")", ")", "\n", "\n", "return", "Examples", "(", "\n", "paths", "=", "paths_batch", ",", "\n", "inputs", "=", "inputs_batch", ",", "\n", "targets_1", "=", "targets_1_batch", ",", "\n", "targets_2", "=", "targets_2_batch", ",", "\n", "count", "=", "len", "(", "input_paths", ")", ",", "\n", "steps_per_epoch", "=", "steps_per_epoch", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.save_images": [[668, 688], ["os.path.join", "enumerate", "os.path.exists", "os.makedirs", "os.path.splitext", "filesets.append", "os.path.basename", "os.path.join", "in_path.decode", "open", "f.write"], "function", ["None"], ["", "def", "save_images", "(", "fetches", ",", "step", "=", "None", ")", ":", "\n", "    ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"images\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "filesets", "=", "[", "]", "\n", "for", "i", ",", "in_path", "in", "enumerate", "(", "fetches", "[", "\"paths\"", "]", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "in_path", ".", "decode", "(", "\"utf8\"", ")", ")", ")", "\n", "fileset", "=", "{", "\"name\"", ":", "name", ",", "\"step\"", ":", "step", "}", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs_1\"", ",", "\"targets_1\"", ",", "\"outputs_2\"", ",", "\"targets_2\"", "]", ":", "\n", "            ", "filename", "=", "name", "+", "\"-\"", "+", "kind", "+", "\".png\"", "\n", "if", "step", "is", "not", "None", ":", "\n", "                ", "filename", "=", "\"%08d-%s\"", "%", "(", "step", ",", "filename", ")", "\n", "", "fileset", "[", "kind", "]", "=", "filename", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "filename", ")", "\n", "contents", "=", "fetches", "[", "kind", "]", "[", "i", "]", "\n", "with", "open", "(", "out_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "contents", ")", "\n", "", "", "filesets", ".", "append", "(", "fileset", ")", "\n", "", "return", "filesets", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.append_index": [[690, 714], ["os.path.join", "os.path.exists", "open", "open", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write"], "function", ["None"], ["", "def", "append_index", "(", "filesets", ",", "step", "=", "False", ")", ":", "\n", "    ", "index_path", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"index.html\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_path", ")", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"a\"", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"w\"", ")", "\n", "index", ".", "write", "(", "\"<html><body><table><tr>\"", ")", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<th>step</th>\"", ")", "\n", "#table construction", "\n", "", "index", ".", "write", "(", "\"<th>name</th><th>input</th><th>output_1</th><th>target_1</th><th>output_2</th><th>target_2</th></tr>\"", ")", "\n", "\n", "", "for", "fileset", "in", "filesets", ":", "\n", "        ", "index", ".", "write", "(", "\"<tr>\"", ")", "\n", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<td>%d</td>\"", "%", "fileset", "[", "\"step\"", "]", ")", "\n", "", "index", ".", "write", "(", "\"<td>%s</td>\"", "%", "fileset", "[", "\"name\"", "]", ")", "\n", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs_1\"", ",", "\"targets_1\"", ",", "\"outputs_2\"", ",", "\"targets_2\"", "]", ":", "\n", "            ", "index", ".", "write", "(", "\"<td><img src='images/%s'></td>\"", "%", "fileset", "[", "kind", "]", ")", "\n", "\n", "", "index", ".", "write", "(", "\"</tr>\"", ")", "\n", "", "return", "index_path", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.main": [[716, 1043], ["tensorflow.set_random_seed", "numpy.random.seed", "random.seed", "a._get_kwargs", "pix2pix_MT_cv.load_examples", "print", "pix2pix_MT_cv.create_model_MT", "pix2pix_MT_cv.deprocess", "pix2pix_MT_cv.deprocess", "pix2pix_MT_cv.deprocess", "pix2pix_MT_cv.deprocess", "pix2pix_MT_cv.deprocess", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.train.Saver", "tensorflow.train.Supervisor", "random.randint", "os.path.exists", "os.makedirs", "print", "open", "f.write", "tensorflow.placeholder", "tensorflow.decode_base64", "tensorflow.image.decode_png", "tensorflow.cond", "tensorflow.cond", "tensorflow.image.convert_image_dtype", "tf.image.convert_image_dtype.set_shape", "tensorflow.expand_dims", "tensorflow.convert_to_tensor", "tensorflow.placeholder", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.global_variables_initializer", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.image.convert_image_dtype", "tensorflow.name_scope", "pix2pix_MT_cv.main.convert"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.load_examples", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.create_model_MT", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "main", "(", ")", ":", "\n", "    ", "if", "a", ".", "seed", "is", "None", ":", "\n", "        ", "a", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "\n", "", "tf", ".", "set_random_seed", "(", "a", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "a", ".", "output_dir", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", "or", "a", ".", "mode", "==", "\"export\"", ":", "\n", "        ", "if", "a", ".", "checkpoint", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"checkpoint required for test mode\"", ")", "\n", "\n", "# load some options from the checkpoint", "\n", "", "options", "=", "{", "\"which_direction\"", ",", "\"ngf\"", ",", "\"ndf\"", ",", "\"lab_colorization\"", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "checkpoint", ",", "\"options.json\"", ")", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "val", "in", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "in", "options", ":", "\n", "                    ", "print", "(", "\"loaded\"", ",", "key", ",", "\"=\"", ",", "val", ")", "\n", "setattr", "(", "a", ",", "key", ",", "val", ")", "\n", "# disable these features in test mode", "\n", "", "", "", "a", ".", "scale_size", "=", "CROP_SIZE", "\n", "a", ".", "flip", "=", "False", "\n", "\n", "", "for", "k", ",", "v", "in", "a", ".", "_get_kwargs", "(", ")", ":", "\n", "        ", "print", "(", "k", ",", "\"=\"", ",", "v", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"options.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vars", "(", "a", ")", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"export\"", ":", "\n", "# export the generator to a meta graph that can be imported later for standalone generation", "\n", "        ", "if", "a", ".", "lab_colorization", ":", "\n", "            ", "raise", "Exception", "(", "\"export not supported for lab_colorization\"", ")", "\n", "\n", "", "input", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "input_data", "=", "tf", ".", "decode_base64", "(", "input", "[", "0", "]", ")", "\n", "input_image", "=", "tf", ".", "image", ".", "decode_png", "(", "input_data", ")", "\n", "\n", "# remove alpha channel if present", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "4", ")", ",", "lambda", ":", "input_image", "[", ":", ",", ":", ",", ":", "3", "]", ",", "lambda", ":", "input_image", ")", "\n", "# convert grayscale to RGB", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "1", ")", ",", "lambda", ":", "tf", ".", "image", ".", "grayscale_to_rgb", "(", "input_image", ")", ",", "lambda", ":", "input_image", ")", "\n", "# Images that are represented using floating point values are expected to have values in the range [0,1)", "\n", "input_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "input_image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "input_image", ".", "set_shape", "(", "[", "CROP_SIZE", ",", "CROP_SIZE", ",", "3", "]", ")", "\n", "batch_input", "=", "tf", ".", "expand_dims", "(", "input_image", ",", "axis", "=", "0", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "            ", "batch_output", "=", "deprocess", "(", "create_generator", "(", "preprocess", "(", "batch_input", ")", ",", "3", ")", ")", "\n", "\n", "", "output_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "batch_output", ",", "dtype", "=", "tf", ".", "uint8", ")", "[", "0", "]", "\n", "if", "a", ".", "output_filetype", "==", "\"png\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_png", "(", "output_image", ")", "\n", "", "elif", "a", ".", "output_filetype", "==", "\"jpeg\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_jpeg", "(", "output_image", ",", "quality", "=", "80", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid filetype\"", ")", "\n", "", "output", "=", "tf", ".", "convert_to_tensor", "(", "[", "tf", ".", "encode_base64", "(", "output_data", ")", "]", ")", "\n", "\n", "key", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "inputs", "=", "{", "\n", "\"key\"", ":", "key", ".", "name", ",", "\n", "\"input\"", ":", "input", ".", "name", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"inputs\"", ",", "json", ".", "dumps", "(", "inputs", ")", ")", "\n", "outputs", "=", "{", "\n", "\"key\"", ":", "tf", ".", "identity", "(", "key", ")", ".", "name", ",", "\n", "\"output\"", ":", "output", ".", "name", ",", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"outputs\"", ",", "json", ".", "dumps", "(", "outputs", ")", ")", "\n", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "restore_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "export_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "restore_saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "print", "(", "\"exporting model\"", ")", "\n", "export_saver", ".", "export_meta_graph", "(", "filename", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export.meta\"", ")", ")", "\n", "export_saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export\"", ")", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "", "return", "\n", "\n", "", "examples", "=", "load_examples", "(", ")", "\n", "print", "(", "\"examples count = %d\"", "%", "examples", ".", "count", ")", "\n", "\n", "# inputs and targets are [batch_size, height, width, channels]", "\n", "model", "=", "create_model_MT", "(", "examples", ".", "inputs", ",", "examples", ".", "targets_1", ",", "examples", ".", "targets_2", ")", "\n", "\n", "\n", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "targets_1", "=", "deprocess", "(", "examples", ".", "targets_1", ")", "\n", "targets_2", "=", "deprocess", "(", "examples", ".", "targets_2", ")", "\n", "outputs_1", "=", "deprocess", "(", "model", ".", "outputs_1", ")", "\n", "outputs_2", "=", "deprocess", "(", "model", ".", "outputs_2", ")", "\n", "#print(outputs_2.shape)", "\n", "\n", "def", "convert", "(", "image", ")", ":", "\n", "        ", "if", "a", ".", "aspect_ratio", "!=", "1.0", ":", "\n", "# upscale to correct aspect ratio", "\n", "            ", "size", "=", "[", "CROP_SIZE", ",", "int", "(", "round", "(", "CROP_SIZE", "*", "a", ".", "aspect_ratio", ")", ")", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "image", ",", "size", "=", "size", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "\n", "", "return", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "uint8", ",", "saturate", "=", "True", ")", "\n", "\n", "# reverse any processing on images so they can be written to disk or displayed to user", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_inputs\"", ")", ":", "\n", "        ", "converted_inputs", "=", "convert", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_targets\"", ")", ":", "\n", "        ", "converted_targets_1", "=", "convert", "(", "targets_1", ")", "\n", "converted_targets_2", "=", "convert", "(", "targets_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_outputs\"", ")", ":", "\n", "        ", "converted_outputs_1", "=", "convert", "(", "outputs_1", ")", "\n", "converted_outputs_2", "=", "convert", "(", "outputs_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"encode_images\"", ")", ":", "\n", "        ", "display_fetches", "=", "{", "\n", "\"paths\"", ":", "examples", ".", "paths", ",", "\n", "\"inputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_inputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"input_pngs\"", ")", ",", "\n", "\"targets_1\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets_1", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_1_pngs\"", ")", ",", "\n", "\"targets_2\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets_2", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_2_pngs\"", ")", ",", "\n", "\"outputs_1\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs_1", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_1_pngs\"", ")", ",", "\n", "\"outputs_2\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs_2", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_2_pngs\"", ")", ",", "\n", "}", "\n", "\n", "# summaries", "\n", "", "with", "tf", ".", "name_scope", "(", "\"inputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"inputs\"", ",", "converted_inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"targets_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"targets_1\"", ",", "converted_targets_1", ")", "\n", "tf", ".", "summary", ".", "image", "(", "\"targets_2\"", ",", "converted_targets_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"outputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"outputs_1\"", ",", "converted_outputs_1", ")", "\n", "tf", ".", "summary", ".", "image", "(", "\"outputs_2\"", ",", "converted_outputs_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_real_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_real\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_real", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_fake_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_fake\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_fake", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss\"", ",", "model", ".", "discrim_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN\"", ",", "model", ".", "gen_loss_GAN", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_L1\"", ",", "model", ".", "gen_loss_L1", ")", "\n", "\n", "# Moha: --------------", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss_real\"", ",", "model", ".", "discrim_loss_real", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss_fake\"", ",", "model", ".", "discrim_loss_fake", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_total\"", ",", "model", ".", "gen_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_dice\"", ",", "model", ".", "gen_loss_dice", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_jaccard\"", ",", "model", ".", "gen_loss_jaccard", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_Tversky\"", ",", "model", ".", "gen_loss_Tversky", ")", "\n", "\n", "\n", "# End MOha", "\n", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/values\"", ",", "var", ")", "\n", "\n", "", "for", "grad", ",", "var", "in", "model", ".", "discrim_grads_and_vars", "+", "model", ".", "gen_grads_and_vars", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/gradients\"", ",", "grad", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"parameter_count\"", ")", ":", "\n", "        ", "parameter_count", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "v", ")", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1", ")", "\n", "\n", "logdir", "=", "a", ".", "output_dir", "if", "(", "a", ".", "trace_freq", ">", "0", "or", "a", ".", "summary_freq", ">", "0", ")", "else", "None", "\n", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "logdir", "=", "logdir", ",", "save_summaries_secs", "=", "0", ",", "saver", "=", "None", ")", "\n", "with", "sv", ".", "managed_session", "(", ")", "as", "sess", ":", "\n", "        ", "print", "(", "\"parameter_count =\"", ",", "sess", ".", "run", "(", "parameter_count", ")", ")", "\n", "\n", "if", "a", ".", "checkpoint", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"#############################\"", ")", "\n", "print", "(", "\"loading model from checkpoint for continue training or testing phase ..\"", ")", "\n", "print", "(", "\"#############################\"", ")", "\n", "try", ":", "\n", "                ", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"loading was unsuccessful-it will train from scrtach..\"", ")", "\n", "print", "(", "\"#############################\"", ")", "\n", "\n", "", "", "max_steps", "=", "2", "**", "32", "\n", "if", "a", ".", "max_epochs", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "examples", ".", "steps_per_epoch", "*", "a", ".", "max_epochs", "\n", "", "if", "a", ".", "max_steps", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "a", ".", "max_steps", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", ":", "\n", "# testing", "\n", "# at most, process the test data once", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "max_steps", "=", "min", "(", "examples", ".", "steps_per_epoch", ",", "max_steps", ")", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "results", "=", "sess", ".", "run", "(", "display_fetches", ")", "\n", "filesets", "=", "save_images", "(", "results", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "filesets", ")", ":", "\n", "                    ", "print", "(", "\"evaluated image\"", ",", "f", "[", "\"name\"", "]", ")", "\n", "", "index_path", "=", "append_index", "(", "filesets", ")", "\n", "", "print", "(", "\"wrote index at\"", ",", "index_path", ")", "\n", "print", "(", "\"rate\"", ",", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "max_steps", ")", "\n", "", "else", ":", "\n", "# training", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "discrim_loss_pre", "=", "10000", "\n", "gan_loss_pre", "=", "10000", "\n", "patience_counter", "=", "0", "\n", "\n", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "def", "should", "(", "freq", ")", ":", "\n", "                    ", "return", "freq", ">", "0", "and", "(", "(", "step", "+", "1", ")", "%", "freq", "==", "0", "or", "step", "==", "max_steps", "-", "1", ")", "\n", "\n", "", "options", "=", "None", "\n", "run_metadata", "=", "None", "\n", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "options", "=", "tf", ".", "RunOptions", "(", "trace_level", "=", "tf", ".", "RunOptions", ".", "FULL_TRACE", ")", "\n", "run_metadata", "=", "tf", ".", "RunMetadata", "(", ")", "\n", "\n", "", "fetches", "=", "{", "\n", "\"train\"", ":", "model", ".", "train", ",", "\n", "\"global_step\"", ":", "sv", ".", "global_step", ",", "\n", "}", "\n", "\n", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"discrim_loss\"", "]", "=", "model", ".", "discrim_loss", "\n", "fetches", "[", "\"gen_loss_GAN\"", "]", "=", "model", ".", "gen_loss_GAN", "\n", "fetches", "[", "\"gen_loss_L1\"", "]", "=", "model", ".", "gen_loss_L1", "\n", "# Moha: --------------------", "\n", "fetches", "[", "\"discrim_loss_real\"", "]", "=", "model", ".", "discrim_loss_real", "\n", "fetches", "[", "\"discrim_loss_fake\"", "]", "=", "model", ".", "discrim_loss_fake", "\n", "fetches", "[", "\"gen_loss_total\"", "]", "=", "model", ".", "gen_loss", "\n", "fetches", "[", "\"gen_loss_dice\"", "]", "=", "model", ".", "gen_loss_dice", "\n", "fetches", "[", "\"gen_loss_jaccard\"", "]", "=", "model", ".", "gen_loss_jaccard", "\n", "fetches", "[", "\"gen_loss_Tversky\"", "]", "=", "model", ".", "gen_loss_Tversky", "\n", "\n", "# End MOha", "\n", "\n", "\n", "\n", "", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"summary\"", "]", "=", "sv", ".", "summary_op", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"display\"", "]", "=", "display_fetches", "\n", "\n", "", "results", "=", "sess", ".", "run", "(", "fetches", ",", "options", "=", "options", ",", "run_metadata", "=", "run_metadata", ")", "\n", "\n", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording summary\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "results", "[", "\"summary\"", "]", ",", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving display images\"", ")", "\n", "filesets", "=", "save_images", "(", "results", "[", "\"display\"", "]", ",", "step", "=", "results", "[", "\"global_step\"", "]", ")", "\n", "append_index", "(", "filesets", ",", "step", "=", "True", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording trace\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_run_metadata", "(", "run_metadata", ",", "\"step_%d\"", "%", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "# global_step will have the correct step count if we resume from a checkpoint", "\n", "                    ", "train_epoch", "=", "math", ".", "ceil", "(", "results", "[", "\"global_step\"", "]", "/", "examples", ".", "steps_per_epoch", ")", "\n", "train_step", "=", "(", "results", "[", "\"global_step\"", "]", "-", "1", ")", "%", "examples", ".", "steps_per_epoch", "+", "1", "\n", "rate", "=", "(", "step", "+", "1", ")", "*", "a", ".", "batch_size", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "remaining", "=", "(", "max_steps", "-", "step", ")", "*", "a", ".", "batch_size", "/", "rate", "\n", "print", "(", "'***********************************************'", ")", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "\n", "print", "(", "\"gen_loss_GAN -----------\"", ",", "results", "[", "\"gen_loss_GAN\"", "]", ")", "\n", "print", "(", "\"gen_loss_L1 -----------\"", ",", "results", "[", "\"gen_loss_L1\"", "]", ")", "\n", "print", "(", "\"discrim_loss_total -----------\"", ",", "results", "[", "\"discrim_loss\"", "]", ")", "\n", "\n", "print", "(", "\"discrim_loss_real -----------\"", ",", "results", "[", "\"discrim_loss_real\"", "]", ")", "\n", "print", "(", "\"discrim_loss_fake -----------\"", ",", "results", "[", "\"discrim_loss_fake\"", "]", ")", "\n", "print", "(", "\"gen_loss_total -----------\"", ",", "results", "[", "\"gen_loss_total\"", "]", ")", "\n", "\n", "print", "(", "\"gen_loss_dice -----------\"", ",", "results", "[", "\"gen_loss_dice\"", "]", ")", "\n", "print", "(", "\"gen_loss_jaccard -----------\"", ",", "results", "[", "\"gen_loss_jaccard\"", "]", ")", "\n", "\n", "print", "(", "\"gen_loss_Tversky -----------\"", ",", "results", "[", "\"gen_loss_Tversky\"", "]", ")", "\n", "\n", "if", "discrim_loss_pre", ">=", "results", "[", "\"discrim_loss\"", "]", ":", "\n", "                        ", "if", "gan_loss_pre", "<=", "results", "[", "\"gen_loss_GAN\"", "]", ":", "\n", "                            ", "patience_counter", "=", "patience_counter", "+", "1", "\n", "\n", "\n", "\n", "", "", "discrim_loss_pre", "=", "results", "[", "\"discrim_loss\"", "]", "\n", "gan_loss_pre", "=", "results", "[", "\"gen_loss_GAN\"", "]", "\n", "\n", "if", "patience_counter", ">=", "float", "(", "a", ".", "patience_epochs", ")", ":", "\n", "                        ", "print", "(", "\"###################\"", ")", "\n", "print", "(", "\"early stop, disc is winning\"", ")", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "break", "\n", "\n", "\n", "", "if", "results", "[", "\"gen_loss_L1\"", "]", "<", "float", "(", "a", ".", "desired_l1_loss", ")", ":", "\n", "                        ", "print", "(", "\"###################\"", ")", "\n", "print", "(", "\"Reached desired error\"", ")", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "break", "\n", "\n", "", "", "if", "should", "(", "a", ".", "save_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "\n", "", "if", "sv", ".", "should_stop", "(", ")", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MT_cv.CombineImages": [[1045, 1129], ["print", "os.mkdir", "skimage.io.imread", "skimage.io.imsave", "print", "shutil.rmtree", "os.mkdir", "filename.replace.replace", "len", "numpy.zeros", "print", "sys.exit", "sys.exit", "print", "sys.exit", "sys.exit", "skimage.io.imread", "skimage.io.imread", "numpy.zeros", "len", "numpy.zeros", "len", "numpy.zeros"], "function", ["None"], ["", "", "", "", "", "def", "CombineImages", "(", "ImageListNames", ",", "task_No", ",", "input_dir_all", ")", ":", "\n", "    ", "print", "(", "'combining images ...'", ")", "\n", "try", ":", "\n", "        ", "os", ".", "mkdir", "(", "write_to_dir", ")", "\n", "", "except", ":", "\n", "        ", "print", "(", "'destination folder is already exist-it will be replaced'", ")", "\n", "shutil", ".", "rmtree", "(", "write_to_dir", ")", "\n", "os", ".", "mkdir", "(", "write_to_dir", ")", "\n", "\n", "\n", "", "for", "filename", "in", "ImageListNames", ":", "\n", "\n", "        ", "try", ":", "\n", "            ", "filename", "=", "filename", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "", "except", ":", "\n", "            ", "no", "=", "0", "\n", "\n", "", "Image", "=", "io", ".", "imread", "(", "a", ".", "input_dir_all", "+", "'/Inputs/'", "+", "filename", ")", "\n", "Size", "=", "Image", ".", "shape", "\n", "if", "len", "(", "Size", ")", "==", "2", ":", "\n", "            ", "Image_", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image", ".", "shape", "[", "0", "]", ",", "Image", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_", "[", ":", ",", ":", ",", "0", "]", "=", "Image", "\n", "Image_", "[", ":", ",", ":", ",", "1", "]", "=", "Image", "\n", "Image_", "[", ":", ",", ":", ",", "2", "]", "=", "Image", "\n", "Image", "=", "Image_", "\n", "\n", "", "if", "task_No", "==", "1", ":", "\n", "\n", "            ", "print", "(", "'1 is not acceptable for single task'", ")", "\n", "sys", ".", "exit", "(", "'1 is not acceptable for single task'", ")", "\n", "\n", "#            Image_t1=io.imread(a.input_dir_all+'/Targets_'+str(task_No) +'/'+ filename)", "\n", "#            Size=Image_t1.shape", "\n", "#            if len(Size)==2:", "\n", "#                Image_=np.zeros(shape=[Image_t1.shape[0],Image_t1.shape[1],3], dtype='uint8')", "\n", "#                Image_[:,:,0]=Image_t1", "\n", "#                Image_[:,:,1]=Image_t1", "\n", "#                Image_[:,:,2]=Image_t1", "\n", "#                Image_t1=Image_", "\n", "#            Image_combined=np.zeros(shape=[Image.shape[0],2*Image.shape[1],3], dtype='uint8')", "\n", "#            Image_combined[:,:CROP_SIZE,:]=Image", "\n", "#            Image_combined[:,CROP_SIZE:,:]=Image_t1", "\n", "\n", "", "if", "task_No", "==", "2", ":", "\n", "            ", "print", "(", "'2 is not acceptable for single task'", ")", "\n", "sys", ".", "exit", "(", "'2 is not acceptable for single task'", ")", "\n", "\n", "#            Image_t2=io.imread(a.input_dir_all+'/Targets_'+str(task_No) +'/'+ filename)", "\n", "#            Size=Image_t2.shape", "\n", "#            if len(Size)==2:", "\n", "#                Image_=np.zeros(shape=[Image_t2.shape[0],Image_t2.shape[1],3], dtype='uint8')", "\n", "#                Image_[:,:,0]=Image_t2", "\n", "#                Image_[:,:,1]=Image_t2", "\n", "#                Image_[:,:,2]=Image_t2", "\n", "#                Image_t2=Image_ ", "\n", "#            Image_combined=np.zeros(shape=[Image.shape[0],2*Image.shape[1],3], dtype='uint8')", "\n", "#            Image_combined[:,:CROP_SIZE,:]=Image", "\n", "#            Image_combined[:,CROP_SIZE:,:]=Image_t2", "\n", "\n", "", "if", "task_No", "==", "3", ":", "\n", "            ", "Image_t1", "=", "io", ".", "imread", "(", "a", ".", "input_dir_all", "+", "'/Targets_1'", "+", "'/'", "+", "filename", ")", "\n", "Image_t2", "=", "io", ".", "imread", "(", "a", ".", "input_dir_all", "+", "'/Targets_2'", "+", "'/'", "+", "filename", ")", "\n", "Size", "=", "Image_t1", ".", "shape", "\n", "if", "len", "(", "Size", ")", "==", "2", ":", "\n", "                ", "Image_", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image_t1", ".", "shape", "[", "0", "]", ",", "Image_t1", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_", "[", ":", ",", ":", ",", "0", "]", "=", "Image_t1", "\n", "Image_", "[", ":", ",", ":", ",", "1", "]", "=", "Image_t1", "\n", "Image_", "[", ":", ",", ":", ",", "2", "]", "=", "Image_t1", "\n", "Image_t1", "=", "Image_", "\n", "", "Size", "=", "Image_t2", ".", "shape", "\n", "if", "len", "(", "Size", ")", "==", "2", ":", "\n", "                ", "Image_", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image_t2", ".", "shape", "[", "0", "]", ",", "Image_t2", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_", "[", ":", ",", ":", ",", "0", "]", "=", "Image_t2", "\n", "Image_", "[", ":", ",", ":", ",", "1", "]", "=", "Image_t2", "\n", "Image_", "[", ":", ",", ":", ",", "2", "]", "=", "Image_t2", "\n", "Image_t2", "=", "Image_", "\n", "", "Image_combined", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image", ".", "shape", "[", "0", "]", ",", "3", "*", "Image", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_combined", "[", ":", ",", ":", "CROP_SIZE", ",", ":", "]", "=", "Image", "\n", "Image_combined", "[", ":", ",", "CROP_SIZE", ":", "2", "*", "CROP_SIZE", ",", ":", "]", "=", "Image_t1", "\n", "Image_combined", "[", ":", ",", "2", "*", "CROP_SIZE", ":", ",", ":", "]", "=", "Image_t2", "\n", "\n", "\n", "\n", "", "io", ".", "imsave", "(", "write_to_dir", "+", "filename", ",", "Image_combined", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.preprocess": [[85, 89], ["tensorflow.name_scope"], "function", ["None"], ["def", "preprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess\"", ")", ":", "\n", "# [0, 1] => [-1, 1]", "\n", "        ", "return", "image", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.deprocess": [[91, 95], ["tensorflow.name_scope"], "function", ["None"], ["", "", "def", "deprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess\"", ")", ":", "\n", "# [-1, 1] => [0, 1]", "\n", "        ", "return", "(", "image", "+", "1", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.preprocess_lab": [[97, 104], ["tensorflow.name_scope", "tensorflow.unstack"], "function", ["None"], ["", "", "def", "preprocess_lab", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess_lab\"", ")", ":", "\n", "        ", "L_chan", ",", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "lab", ",", "axis", "=", "2", ")", "\n", "# L_chan: black and white with input range [0, 100]", "\n", "# a_chan/b_chan: color channels with input range ~[-110, 110], not exact", "\n", "# [0, 100] => [-1, 1],  ~[-110, 110] => [-1, 1]", "\n", "return", "[", "L_chan", "/", "50", "-", "1", ",", "a_chan", "/", "110", ",", "b_chan", "/", "110", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.deprocess_lab": [[106, 110], ["tensorflow.name_scope", "tensorflow.stack"], "function", ["None"], ["", "", "def", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess_lab\"", ")", ":", "\n", "# this is axis=3 instead of axis=2 because we process individual images but deprocess batches", "\n", "        ", "return", "tf", ".", "stack", "(", "[", "(", "L_chan", "+", "1", ")", "/", "2", "*", "100", ",", "a_chan", "*", "110", ",", "b_chan", "*", "110", "]", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.augment": [[112, 119], ["tensorflow.unstack", "tensorflow.squeeze", "pix2pix_MTdG_cv.deprocess_lab", "lab_to_rgb"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess_lab", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lab_to_rgb"], ["", "", "def", "augment", "(", "image", ",", "brightness", ")", ":", "\n", "# (a, b) color channels, combine with L channel and convert to rgb", "\n", "    ", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "image", ",", "axis", "=", "3", ")", "\n", "L_chan", "=", "tf", ".", "squeeze", "(", "brightness", ",", "axis", "=", "3", ")", "\n", "lab", "=", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", "\n", "rgb", "=", "lab_to_rgb", "(", "lab", ")", "\n", "return", "rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.discrim_conv": [[121, 124], ["tensorflow.pad", "tensorflow.layers.conv2d", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "discrim_conv", "(", "batch_input", ",", "out_channels", ",", "stride", ")", ":", "\n", "    ", "padded_input", "=", "tf", ".", "pad", "(", "batch_input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"CONSTANT\"", ")", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "padded_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "stride", ",", "stride", ")", ",", "padding", "=", "\"valid\"", ",", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.gen_conv": [[126, 133], ["tensorflow.random_normal_initializer", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d"], "function", ["None"], ["", "def", "gen_conv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.gen_conv_dilate": [[135, 141], ["tensorflow.random_normal_initializer", "tensorflow.layers.conv2d", "tensorflow.layers.max_pooling2d"], "function", ["None"], ["", "", "def", "gen_conv_dilate", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "dilate_rate", "=", "2", "\n", "output", "=", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "dilation_rate", "=", "(", "dilate_rate", ",", "dilate_rate", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "return", "tf", ".", "layers", ".", "max_pooling2d", "(", "inputs", "=", "output", ",", "pool_size", "=", "[", "2", ",", "2", "]", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "'valid'", ",", "data_format", "=", "'channels_last'", ",", "name", "=", "None", ")", "\n", "#end  Moha ---------------------------------------", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.gen_deconv": [[145, 154], ["tensorflow.random_normal_initializer", "tensorflow.image.resize_images", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d_transpose"], "function", ["None"], ["", "def", "gen_deconv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "_b", ",", "h", ",", "w", ",", "_c", "=", "batch_input", ".", "shape", "\n", "resized_input", "=", "tf", ".", "image", ".", "resize_images", "(", "batch_input", ",", "[", "h", "*", "2", ",", "w", "*", "2", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "resized_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d_transpose", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "a", ".", "kernelsize", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.lrelu": [[156, 166], ["tensorflow.name_scope", "tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["", "", "def", "lrelu", "(", "x", ",", "a", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lrelu\"", ")", ":", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: a*x/2 - a*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "        ", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.batchnorm": [[168, 170], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "", "def", "batchnorm", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.dice_coe": [[171, 220], ["pix2pix_MTdG_cv.deprocess", "pix2pix_MTdG_cv.deprocess", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "Exception"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "dice_coe", "(", "output", ",", "target", ",", "loss_type", "=", "'jaccard'", ",", "axis", "=", "(", "1", ",", "2", ",", "3", ")", ",", "smooth", "=", "1e-5", ")", ":", "\n", "# Moha: based on code from tensorlayer", "\n", "    ", "\"\"\"Soft dice (Sorensen or Jaccard) coefficient for comparing the similarity\n    of two batch of data, usually be used for binary image segmentation\n    i.e. labels are binary. The coefficient between 0 to 1, 1 means totally match.\n    Parameters\n    -----------\n    output : Tensor\n        A distribution with shape: [batch_size, ....], (any dimensions).\n    target : Tensor\n        The target distribution, format the same with `output`.\n    loss_type : str\n        ``jaccard`` or ``sorensen``, default is ``jaccard``.\n    axis : tuple of int\n        All dimensions are reduced, default ``[1,2,3]``.\n    smooth : float\n        This small value will be added to the numerator and denominator.\n            - If both output and target are empty, it makes sure dice is 1.\n            - If either output or target are empty (all pixels are background), dice = ```smooth/(small_value + smooth)``, then if smooth is very small, dice close to 0 (even the image values lower than the threshold), so in this case, higher smooth can have a higher dice.\n    Examples\n    ---------\n    >>> outputs = tl.act.pixel_wise_softmax(network.outputs)\n    >>> dice_loss = 1 - tl.cost.dice_coe(outputs, y_)\n    \"\"\"", "\n", "\n", "output", "=", "deprocess", "(", "output", ")", "\n", "target", "=", "deprocess", "(", "target", ")", "\n", "\n", "output", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "output", ">", "0.5", ")", ")", "\n", "target", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "target", ">", "0.5", ")", ")", "\n", "\n", "inse", "=", "tf", ".", "reduce_sum", "(", "output", "*", "target", ",", "axis", "=", "axis", ")", "\n", "if", "loss_type", "==", "'jaccard'", ":", "\n", "        ", "l", "=", "tf", ".", "reduce_sum", "(", "output", "*", "output", ",", "axis", "=", "axis", ")", "\n", "r", "=", "tf", ".", "reduce_sum", "(", "target", "*", "target", ",", "axis", "=", "axis", ")", "\n", "", "elif", "loss_type", "==", "'sorensen'", ":", "\n", "        ", "l", "=", "tf", ".", "reduce_sum", "(", "output", ",", "axis", "=", "axis", ")", "\n", "r", "=", "tf", ".", "reduce_sum", "(", "target", ",", "axis", "=", "axis", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Unknow loss_type\"", ")", "\n", "# old axis=[0,1,2,3]", "\n", "# dice = 2 * (inse) / (l + r)", "\n", "# epsilon = 1e-5", "\n", "# dice = tf.clip_by_value(dice, 0, 1.0-epsilon) # if all empty, dice = 1", "\n", "# new haodong", "\n", "", "dice", "=", "(", "2.", "*", "inse", "+", "smooth", ")", "/", "(", "l", "+", "r", "+", "smooth", ")", "\n", "##", "\n", "dice", "=", "tf", ".", "reduce_mean", "(", "dice", ",", "name", "=", "'dice_coe'", ")", "\n", "return", "dice", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.tversky_loss": [[222, 260], ["pix2pix_MTdG_cv.deprocess", "pix2pix_MTdG_cv.deprocess", "tensorflow.contrib.layers.flatten", "tensorflow.contrib.layers.flatten", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.reduce_sum", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "tversky_loss", "(", "labels", ",", "predictions", ",", "alpha", "=", "0.3", ",", "beta", "=", "0.7", ",", "smooth", "=", "1e-10", ")", ":", "\n", "# Moha: based on code from: https://analysiscenter.github.io/radio/_modules/radio/models/tf/losses.html#tversky_loss", "\n", "    ", "\"\"\" Tversky loss function.\n\n    Parameters\n    ----------\n    labels : tf.Tensor\n        tensor containing target mask.\n    predictions : tf.Tensor\n        tensor containing predicted mask.\n    alpha : float\n        real value, weight of '0' class.\n    beta : float\n        real value, weight of '1' class.\n    smooth : float\n        small real value used for avoiding division by zero error.\n\n    Returns\n    -------\n    tf.Tensor\n        tensor containing tversky loss.\n    \"\"\"", "\n", "\n", "labels", "=", "deprocess", "(", "labels", ")", "\n", "predictions", "=", "deprocess", "(", "predictions", ")", "\n", "\n", "labels", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "labels", ")", "\n", "predictions", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "predictions", ")", "\n", "\n", "labels", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "labels", ">", "0.5", ")", ")", "\n", "predictions", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "predictions", ">", "0.5", ")", ")", "\n", "\n", "\n", "truepos", "=", "tf", ".", "reduce_sum", "(", "labels", "*", "predictions", ")", "\n", "fp_and_fn", "=", "(", "alpha", "*", "tf", ".", "reduce_sum", "(", "predictions", "*", "(", "1", "-", "labels", ")", ")", "\n", "+", "beta", "*", "tf", ".", "reduce_sum", "(", "(", "1", "-", "predictions", ")", "*", "labels", ")", ")", "\n", "\n", "return", "(", "truepos", "+", "smooth", ")", "/", "(", "truepos", "+", "smooth", "+", "fp_and_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.create_generator": [[261, 347], ["print", "print", "print", "len", "enumerate", "tensorflow.variable_scope", "pix2pix_MTdG_cv.gen_conv", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_MTdG_cv.lrelu", "pix2pix_MTdG_cv.gen_conv", "print", "pix2pix_MTdG_cv.batchnorm", "layers.append", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.nn.relu", "pix2pix_MTdG_cv.gen_deconv", "tensorflow.tanh", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_MTdG_cv.lrelu", "pix2pix_MTdG_cv.gen_conv_dilate", "print", "pix2pix_MTdG_cv.batchnorm", "layers.append", "tensorflow.variable_scope", "tensorflow.nn.relu", "pix2pix_MTdG_cv.gen_deconv", "pix2pix_MTdG_cv.batchnorm", "layers.append", "print", "tensorflow.concat", "tensorflow.nn.dropout", "len", "len"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv_dilate", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm"], ["", "def", "create_generator", "(", "generator_inputs", ",", "generator_outputs_channels", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "\n", "print", "(", "'encoder:'", ")", "\n", "print", "(", "generator_inputs", ".", "shape", ")", "\n", "# encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_1\"", ")", ":", "\n", "        ", "output", "=", "gen_conv", "(", "generator_inputs", ",", "a", ".", "ngf", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "a", ".", "ngf", "*", "2", ",", "# encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]", "\n", "a", ".", "ngf", "*", "4", ",", "# encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]", "\n", "]", "\n", "\n", "for", "out_channels", "in", "layer_specs", "[", ":", "6", "]", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]", "\n", "\n", "# orig: ---------------------------", "\n", "# convolved = gen_conv(rectified, out_channels)", "\n", "# Moha: ---------------------------", "\n", "convolved", "=", "gen_conv_dilate", "(", "rectified", ",", "out_channels", ")", "\n", "#convolved = gen_conv(rectified, out_channels)", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "# end Moha -----------------------------", "\n", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "convolved", "=", "gen_conv", "(", "rectified", ",", "layer_specs", "[", "6", "]", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "print", "(", "'decoder:'", ")", "\n", "layer_specs", "=", "[", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.0", ")", ",", "# decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "4", ",", "0.0", ")", ",", "# decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]", "\n", "(", "a", ".", "ngf", "*", "2", ",", "0.0", ")", ",", "# decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]", "\n", "(", "a", ".", "ngf", ",", "0.0", ")", ",", "# decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]", "\n", "]", "\n", "\n", "num_encoder_layers", "=", "len", "(", "layers", ")", "\n", "for", "decoder_layer", ",", "(", "out_channels", ",", "dropout", ")", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "skip_layer", "=", "num_encoder_layers", "-", "decoder_layer", "-", "1", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder_%d\"", "%", "(", "skip_layer", "+", "1", ")", ")", ":", "\n", "            ", "if", "decoder_layer", "==", "0", ":", "\n", "# first decoder layer doesn't have skip connections", "\n", "# since it is directly connected to the skip_layer", "\n", "                ", "input", "=", "layers", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "skip_layer", "]", "]", ",", "axis", "=", "3", ")", "\n", "\n", "", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batchnorm", "(", "output", ")", "\n", "\n", "if", "dropout", ">", "0.0", ":", "\n", "                ", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "keep_prob", "=", "1", "-", "dropout", ")", "\n", "\n", "", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "# decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"decoder_1\"", ")", ":", "\n", "        ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "0", "]", "]", ",", "axis", "=", "3", ")", "\n", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "generator_outputs_channels", ")", "\n", "output", "=", "tf", ".", "tanh", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.create_model_MT": [[350, 481], ["tensorflow.concat", "tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "print", "tensorflow.concat", "print", "range", "tensorflow.variable_scope", "int", "pix2pix_MTdG_cv.create_generator", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.abs", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.variable_scope", "pix2pix_MTdG_cv.discrim_conv", "pix2pix_MTdG_cv.lrelu", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_MTdG_cv.discrim_conv", "tensorflow.sigmoid", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_MTdG_cv.create_model_MT.create_discriminator"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_generator", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv"], ["", "def", "create_model_MT", "(", "inputs", ",", "targets_1", ",", "targets_2", ")", ":", "\n", "\n", "    ", "def", "create_discriminator", "(", "discrim_inputs", ",", "discrim_targets", ")", ":", "\n", "        ", "n_layers", "=", "3", "\n", "layers", "=", "[", "]", "\n", "print", "(", "'discriminator:'", ")", "\n", "\n", "# 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]", "\n", "input", "=", "tf", ".", "concat", "(", "[", "discrim_inputs", ",", "discrim_targets", "]", ",", "axis", "=", "3", ")", "\n", "print", "(", "input", ".", "shape", ")", "\n", "# layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"layer_1\"", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "input", ",", "a", ".", "ndf", ",", "stride", "=", "2", ")", "\n", "rectified", "=", "lrelu", "(", "convolved", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]", "\n", "# layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]", "\n", "# layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]", "\n", "", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "                ", "out_channels", "=", "a", ".", "ndf", "*", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "stride", "=", "1", "if", "i", "==", "n_layers", "-", "1", "else", "2", "# last layer here has stride 1", "\n", "convolved", "=", "discrim_conv", "(", "layers", "[", "-", "1", "]", ",", "out_channels", ",", "stride", "=", "stride", ")", "\n", "normalized", "=", "batchnorm", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "rectified", ",", "out_channels", "=", "1", ",", "stride", "=", "1", ")", "\n", "output", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n", "\n", "", "targets", "=", "tf", ".", "concat", "(", "[", "targets_1", ",", "targets_2", "]", ",", "axis", "=", "3", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "        ", "out_channels", "=", "int", "(", "targets", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "outputs", "=", "create_generator", "(", "inputs", ",", "out_channels", ")", "\n", "\n", "# create two copies of discriminator, one for real pairs and one for fake pairs", "\n", "# they share the same underlying variables", "\n", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_real", "=", "create_discriminator", "(", "inputs", ",", "targets", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ",", "reuse", "=", "True", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_fake", "=", "create_discriminator", "(", "inputs", ",", "outputs", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_loss\"", ")", ":", "\n", "# minimizing -tf.log will try to get inputs to 1", "\n", "# predict_real => 1 ", "\n", "# predict_fake => 0", "\n", "        ", "discrim_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "discrim_loss_real", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", ")", ")", "\n", "discrim_loss_fake", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_loss\"", ")", ":", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "        ", "gen_loss_GAN", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_fake", "+", "EPS", ")", ")", "\n", "gen_loss_L1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "targets", "-", "outputs", ")", ")", "\n", "gen_loss_dice", "=", "1", "-", "dice_coe", "(", "outputs", ",", "targets", ",", "loss_type", "=", "'sorensen'", ")", "\n", "gen_loss_jaccard", "=", "1", "-", "dice_coe", "(", "outputs", ",", "targets", ",", "loss_type", "=", "'jaccard'", ")", "\n", "\n", "gen_loss_Tversky", "=", "tf", ".", "abs", "(", "1", "-", "tversky_loss", "(", "targets", ",", "outputs", ")", ")", "\n", "gen_loss", "=", "gen_loss_GAN", "*", "a", ".", "gan_weight", "+", "gen_loss_L1", "*", "a", ".", "l1_weight", "\n", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_train\"", ")", ":", "\n", "        ", "discrim_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"discriminator\"", ")", "]", "\n", "discrim_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "discrim_grads_and_vars", "=", "discrim_optim", ".", "compute_gradients", "(", "discrim_loss", ",", "var_list", "=", "discrim_tvars", ")", "\n", "discrim_train", "=", "discrim_optim", ".", "apply_gradients", "(", "discrim_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_train", "]", ")", ":", "\n", "            ", "gen_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"generator\"", ")", "]", "\n", "gen_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "gen_grads_and_vars", "=", "gen_optim", ".", "compute_gradients", "(", "gen_loss", ",", "var_list", "=", "gen_tvars", ")", "\n", "gen_train", "=", "gen_optim", ".", "apply_gradients", "(", "gen_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "\n", "# orig: ----------------------", "\n", "#update_losses = ema.apply([discrim_loss, gen_loss_GAN, gen_loss_L1])", "\n", "# end orig", "\n", "# Moha: ----------------------", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_loss", ",", "gen_loss_GAN", ",", "gen_loss_L1", ",", "\n", "gen_loss", ",", "discrim_loss_real", ",", "discrim_loss_fake", ",", "gen_loss_jaccard", ",", "\n", "gen_loss_dice", ",", "gen_loss_Tversky", "]", ")", "\n", "\n", "outputs_1", "=", "outputs", "[", ":", ",", ":", ",", ":", ",", ":", "3", "]", "\n", "outputs_2", "=", "outputs", "[", ":", ",", ":", ",", ":", ",", "3", ":", "]", "\n", "# End Moha", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "\n", "return", "Model", "(", "\n", "predict_real", "=", "predict_real", ",", "\n", "predict_fake", "=", "predict_fake", ",", "\n", "\n", "discrim_loss", "=", "ema", ".", "average", "(", "discrim_loss", ")", ",", "\n", "discrim_grads_and_vars", "=", "discrim_grads_and_vars", ",", "\n", "\n", "gen_loss_GAN", "=", "ema", ".", "average", "(", "gen_loss_GAN", ")", ",", "\n", "gen_loss_L1", "=", "ema", ".", "average", "(", "gen_loss_L1", ")", ",", "\n", "gen_grads_and_vars", "=", "gen_grads_and_vars", ",", "\n", "\n", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_train", ")", ",", "\n", "# Noha: -----------------", "\n", "outputs_1", "=", "outputs_1", ",", "\n", "outputs_2", "=", "outputs_2", ",", "\n", "gen_loss", "=", "ema", ".", "average", "(", "gen_loss", ")", ",", "\n", "discrim_loss_fake", "=", "ema", ".", "average", "(", "discrim_loss_fake", ")", ",", "\n", "discrim_loss_real", "=", "ema", ".", "average", "(", "discrim_loss_real", ")", ",", "\n", "gen_loss_jaccard", "=", "ema", ".", "average", "(", "gen_loss_jaccard", ")", ",", "\n", "gen_loss_dice", "=", "ema", ".", "average", "(", "gen_loss_dice", ")", ",", "\n", "gen_loss_Tversky", "=", "ema", ".", "average", "(", "gen_loss_Tversky", ")", "\n", "# End Moha", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.check_image": [[574, 587], ["tensorflow.assert_equal", "list", "tf.identity.set_shape", "tensorflow.control_dependencies", "tensorflow.identity", "ValueError", "tf.identity.get_shape", "tensorflow.shape", "tf.identity.get_shape"], "function", ["None"], ["", "def", "check_image", "(", "image", ")", ":", "\n", "    ", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "image", ")", "[", "-", "1", "]", ",", "3", ",", "message", "=", "\"image must have 3 color channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "        ", "image", "=", "tf", ".", "identity", "(", "image", ")", "\n", "\n", "", "if", "image", ".", "get_shape", "(", ")", ".", "ndims", "not", "in", "(", "3", ",", "4", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"image must be either 3 or 4 dimensions\"", ")", "\n", "\n", "# make the last dimension 3 so that you can unstack the colors", "\n", "", "shape", "=", "list", "(", "image", ".", "get_shape", "(", ")", ")", "\n", "shape", "[", "-", "1", "]", "=", "3", "\n", "image", ".", "set_shape", "(", "shape", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.load_examples": [[588, 680], ["glob.glob", "all", "random.randint", "tensorflow.train.batch", "int", "Examples", "Exception", "os.path.join", "len", "glob.glob", "len", "Exception", "os.path.splitext", "sorted", "sorted", "tensorflow.name_scope", "tensorflow.train.string_input_producer", "tensorflow.WholeFileReader", "tf.WholeFileReader.read", "decode", "tensorflow.image.convert_image_dtype", "tensorflow.assert_equal", "tf.identity.set_shape", "pix2pix_MTdG_cv.preprocess", "pix2pix_MTdG_cv.preprocess", "pix2pix_MTdG_cv.preprocess", "tensorflow.image.resize_images", "tensorflow.cast", "tensorflow.name_scope", "pix2pix_MTdG_cv.load_examples.transform"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess"], ["", "def", "load_examples", "(", ")", ":", "\n", "    ", "if", "a", ".", "input_dir", "is", "None", "or", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "input_dir", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir does not exist\"", ")", "\n", "\n", "", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.jpg\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_jpeg", "\n", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.png\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_png", "\n", "\n", "", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir contains no image files\"", ")", "\n", "\n", "", "def", "get_name", "(", "path", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "\n", "return", "name", "\n", "\n", "# if the image names are numbers, sort by the value rather than asciibetically", "\n", "# having sorted inputs means that the outputs are sorted in test mode", "\n", "", "if", "all", "(", "get_name", "(", "path", ")", ".", "isdigit", "(", ")", "for", "path", "in", "input_paths", ")", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ",", "key", "=", "lambda", "path", ":", "int", "(", "get_name", "(", "path", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"load_images\"", ")", ":", "\n", "        ", "path_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "input_paths", ",", "shuffle", "=", "a", ".", "mode", "==", "\"train\"", ")", "\n", "reader", "=", "tf", ".", "WholeFileReader", "(", ")", "\n", "paths", ",", "contents", "=", "reader", ".", "read", "(", "path_queue", ")", "\n", "raw_input", "=", "decode", "(", "contents", ")", "\n", "raw_input", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "raw_input", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "raw_input", ")", "[", "2", "]", ",", "3", ",", "message", "=", "\"image does not have 3 channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "            ", "raw_input", "=", "tf", ".", "identity", "(", "raw_input", ")", "\n", "\n", "", "raw_input", ".", "set_shape", "(", "[", "None", ",", "None", ",", "3", "]", ")", "\n", "\n", "\n", "# break apart image pair and move to range [-1, 1]", "\n", "width", "=", "tf", ".", "shape", "(", "raw_input", ")", "[", "1", "]", "# [height, width, channels]", "\n", "a_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", ":", "width", "//", "3", ",", ":", "]", ")", "\n", "b_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "width", "//", "3", ":", "2", "*", "width", "//", "3", ",", ":", "]", ")", "\n", "c_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "2", "*", "width", "//", "3", ":", ",", ":", "]", ")", "\n", "\n", "\n", "\n", "", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "        ", "inputs", ",", "targets_1", ",", "targets_2", "=", "[", "a_images", ",", "b_images", ",", "c_images", "]", "\n", "#targets_2=c_images", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "#inputs, targets_1, targets_2 = [b_images, a_images]", "\n", "        ", "print", "(", "\"Error:::: just use AtoB direction\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "\n", "# synchronize seed for image operations so that we do the same operations to both", "\n", "# input and output images", "\n", "", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "def", "transform", "(", "image", ")", ":", "\n", "        ", "r", "=", "image", "\n", "if", "a", ".", "flip", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "r", ",", "seed", "=", "seed", ")", "\n", "\n", "# area produces a nice downscaling, but does nearest neighbor for upscaling", "\n", "# assume we're going to be doing downscaling here", "\n", "", "r", "=", "tf", ".", "image", ".", "resize_images", "(", "r", ",", "[", "a", ".", "scale_size", ",", "a", ".", "scale_size", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "AREA", ")", "\n", "\n", "offset", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "2", "]", ",", "0", ",", "a", ".", "scale_size", "-", "CROP_SIZE", "+", "1", ",", "seed", "=", "seed", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "if", "a", ".", "scale_size", ">", "CROP_SIZE", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "r", ",", "offset", "[", "0", "]", ",", "offset", "[", "1", "]", ",", "CROP_SIZE", ",", "CROP_SIZE", ")", "\n", "", "elif", "a", ".", "scale_size", "<", "CROP_SIZE", ":", "\n", "            ", "raise", "Exception", "(", "\"scale size cannot be less than crop size\"", ")", "\n", "", "return", "r", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"input_images\"", ")", ":", "\n", "        ", "input_images", "=", "transform", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"target_images\"", ")", ":", "\n", "        ", "target_1_images", "=", "transform", "(", "targets_1", ")", "\n", "target_2_images", "=", "transform", "(", "targets_2", ")", "\n", "#        target_images=tf.concat([target_1_images,target_2_images],axis=3)", "\n", "\n", "", "paths_batch", ",", "inputs_batch", ",", "targets_1_batch", ",", "targets_2_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "paths", ",", "input_images", ",", "target_1_images", ",", "target_2_images", "]", ",", "batch_size", "=", "a", ".", "batch_size", ")", "\n", "steps_per_epoch", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "input_paths", ")", "/", "a", ".", "batch_size", ")", ")", "\n", "\n", "return", "Examples", "(", "\n", "paths", "=", "paths_batch", ",", "\n", "inputs", "=", "inputs_batch", ",", "\n", "targets_1", "=", "targets_1_batch", ",", "\n", "targets_2", "=", "targets_2_batch", ",", "\n", "count", "=", "len", "(", "input_paths", ")", ",", "\n", "steps_per_epoch", "=", "steps_per_epoch", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.save_images": [[685, 705], ["os.path.join", "enumerate", "os.path.exists", "os.makedirs", "os.path.splitext", "filesets.append", "os.path.basename", "os.path.join", "in_path.decode", "open", "f.write"], "function", ["None"], ["", "def", "save_images", "(", "fetches", ",", "step", "=", "None", ")", ":", "\n", "    ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"images\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "filesets", "=", "[", "]", "\n", "for", "i", ",", "in_path", "in", "enumerate", "(", "fetches", "[", "\"paths\"", "]", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "in_path", ".", "decode", "(", "\"utf8\"", ")", ")", ")", "\n", "fileset", "=", "{", "\"name\"", ":", "name", ",", "\"step\"", ":", "step", "}", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs_1\"", ",", "\"targets_1\"", ",", "\"outputs_2\"", ",", "\"targets_2\"", "]", ":", "\n", "            ", "filename", "=", "name", "+", "\"-\"", "+", "kind", "+", "\".png\"", "\n", "if", "step", "is", "not", "None", ":", "\n", "                ", "filename", "=", "\"%08d-%s\"", "%", "(", "step", ",", "filename", ")", "\n", "", "fileset", "[", "kind", "]", "=", "filename", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "filename", ")", "\n", "contents", "=", "fetches", "[", "kind", "]", "[", "i", "]", "\n", "with", "open", "(", "out_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "contents", ")", "\n", "", "", "filesets", ".", "append", "(", "fileset", ")", "\n", "", "return", "filesets", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.append_index": [[707, 731], ["os.path.join", "os.path.exists", "open", "open", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write"], "function", ["None"], ["", "def", "append_index", "(", "filesets", ",", "step", "=", "False", ")", ":", "\n", "    ", "index_path", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"index.html\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_path", ")", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"a\"", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"w\"", ")", "\n", "index", ".", "write", "(", "\"<html><body><table><tr>\"", ")", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<th>step</th>\"", ")", "\n", "#table construction", "\n", "", "index", ".", "write", "(", "\"<th>name</th><th>input</th><th>output_1</th><th>target_1</th><th>output_2</th><th>target_2</th></tr>\"", ")", "\n", "\n", "", "for", "fileset", "in", "filesets", ":", "\n", "        ", "index", ".", "write", "(", "\"<tr>\"", ")", "\n", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<td>%d</td>\"", "%", "fileset", "[", "\"step\"", "]", ")", "\n", "", "index", ".", "write", "(", "\"<td>%s</td>\"", "%", "fileset", "[", "\"name\"", "]", ")", "\n", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs_1\"", ",", "\"targets_1\"", ",", "\"outputs_2\"", ",", "\"targets_2\"", "]", ":", "\n", "            ", "index", ".", "write", "(", "\"<td><img src='images/%s'></td>\"", "%", "fileset", "[", "kind", "]", ")", "\n", "\n", "", "index", ".", "write", "(", "\"</tr>\"", ")", "\n", "", "return", "index_path", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.main": [[733, 1060], ["tensorflow.set_random_seed", "numpy.random.seed", "random.seed", "a._get_kwargs", "pix2pix_MTdG_cv.load_examples", "print", "pix2pix_MTdG_cv.create_model_MT", "pix2pix_MTdG_cv.deprocess", "pix2pix_MTdG_cv.deprocess", "pix2pix_MTdG_cv.deprocess", "pix2pix_MTdG_cv.deprocess", "pix2pix_MTdG_cv.deprocess", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.train.Saver", "tensorflow.train.Supervisor", "random.randint", "os.path.exists", "os.makedirs", "print", "open", "f.write", "tensorflow.placeholder", "tensorflow.decode_base64", "tensorflow.image.decode_png", "tensorflow.cond", "tensorflow.cond", "tensorflow.image.convert_image_dtype", "tf.image.convert_image_dtype.set_shape", "tensorflow.expand_dims", "tensorflow.convert_to_tensor", "tensorflow.placeholder", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.global_variables_initializer", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.image.convert_image_dtype", "tensorflow.name_scope", "pix2pix_MTdG_cv.main.convert"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.load_examples", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.create_model_MT", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "main", "(", ")", ":", "\n", "    ", "if", "a", ".", "seed", "is", "None", ":", "\n", "        ", "a", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "\n", "", "tf", ".", "set_random_seed", "(", "a", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "a", ".", "output_dir", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", "or", "a", ".", "mode", "==", "\"export\"", ":", "\n", "        ", "if", "a", ".", "checkpoint", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"checkpoint required for test mode\"", ")", "\n", "\n", "# load some options from the checkpoint", "\n", "", "options", "=", "{", "\"which_direction\"", ",", "\"ngf\"", ",", "\"ndf\"", ",", "\"lab_colorization\"", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "checkpoint", ",", "\"options.json\"", ")", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "val", "in", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "in", "options", ":", "\n", "                    ", "print", "(", "\"loaded\"", ",", "key", ",", "\"=\"", ",", "val", ")", "\n", "setattr", "(", "a", ",", "key", ",", "val", ")", "\n", "# disable these features in test mode", "\n", "", "", "", "a", ".", "scale_size", "=", "CROP_SIZE", "\n", "a", ".", "flip", "=", "False", "\n", "\n", "", "for", "k", ",", "v", "in", "a", ".", "_get_kwargs", "(", ")", ":", "\n", "        ", "print", "(", "k", ",", "\"=\"", ",", "v", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"options.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vars", "(", "a", ")", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"export\"", ":", "\n", "# export the generator to a meta graph that can be imported later for standalone generation", "\n", "        ", "if", "a", ".", "lab_colorization", ":", "\n", "            ", "raise", "Exception", "(", "\"export not supported for lab_colorization\"", ")", "\n", "\n", "", "input", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "input_data", "=", "tf", ".", "decode_base64", "(", "input", "[", "0", "]", ")", "\n", "input_image", "=", "tf", ".", "image", ".", "decode_png", "(", "input_data", ")", "\n", "\n", "# remove alpha channel if present", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "4", ")", ",", "lambda", ":", "input_image", "[", ":", ",", ":", ",", ":", "3", "]", ",", "lambda", ":", "input_image", ")", "\n", "# convert grayscale to RGB", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "1", ")", ",", "lambda", ":", "tf", ".", "image", ".", "grayscale_to_rgb", "(", "input_image", ")", ",", "lambda", ":", "input_image", ")", "\n", "# Images that are represented using floating point values are expected to have values in the range [0,1)", "\n", "input_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "input_image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "input_image", ".", "set_shape", "(", "[", "CROP_SIZE", ",", "CROP_SIZE", ",", "3", "]", ")", "\n", "batch_input", "=", "tf", ".", "expand_dims", "(", "input_image", ",", "axis", "=", "0", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "            ", "batch_output", "=", "deprocess", "(", "create_generator", "(", "preprocess", "(", "batch_input", ")", ",", "3", ")", ")", "\n", "\n", "", "output_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "batch_output", ",", "dtype", "=", "tf", ".", "uint8", ")", "[", "0", "]", "\n", "if", "a", ".", "output_filetype", "==", "\"png\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_png", "(", "output_image", ")", "\n", "", "elif", "a", ".", "output_filetype", "==", "\"jpeg\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_jpeg", "(", "output_image", ",", "quality", "=", "80", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid filetype\"", ")", "\n", "", "output", "=", "tf", ".", "convert_to_tensor", "(", "[", "tf", ".", "encode_base64", "(", "output_data", ")", "]", ")", "\n", "\n", "key", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "inputs", "=", "{", "\n", "\"key\"", ":", "key", ".", "name", ",", "\n", "\"input\"", ":", "input", ".", "name", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"inputs\"", ",", "json", ".", "dumps", "(", "inputs", ")", ")", "\n", "outputs", "=", "{", "\n", "\"key\"", ":", "tf", ".", "identity", "(", "key", ")", ".", "name", ",", "\n", "\"output\"", ":", "output", ".", "name", ",", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"outputs\"", ",", "json", ".", "dumps", "(", "outputs", ")", ")", "\n", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "restore_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "export_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "restore_saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "print", "(", "\"exporting model\"", ")", "\n", "export_saver", ".", "export_meta_graph", "(", "filename", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export.meta\"", ")", ")", "\n", "export_saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export\"", ")", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "", "return", "\n", "\n", "", "examples", "=", "load_examples", "(", ")", "\n", "print", "(", "\"examples count = %d\"", "%", "examples", ".", "count", ")", "\n", "\n", "# inputs and targets are [batch_size, height, width, channels]", "\n", "model", "=", "create_model_MT", "(", "examples", ".", "inputs", ",", "examples", ".", "targets_1", ",", "examples", ".", "targets_2", ")", "\n", "\n", "\n", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "targets_1", "=", "deprocess", "(", "examples", ".", "targets_1", ")", "\n", "targets_2", "=", "deprocess", "(", "examples", ".", "targets_2", ")", "\n", "outputs_1", "=", "deprocess", "(", "model", ".", "outputs_1", ")", "\n", "outputs_2", "=", "deprocess", "(", "model", ".", "outputs_2", ")", "\n", "#print(outputs_2.shape)", "\n", "\n", "def", "convert", "(", "image", ")", ":", "\n", "        ", "if", "a", ".", "aspect_ratio", "!=", "1.0", ":", "\n", "# upscale to correct aspect ratio", "\n", "            ", "size", "=", "[", "CROP_SIZE", ",", "int", "(", "round", "(", "CROP_SIZE", "*", "a", ".", "aspect_ratio", ")", ")", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "image", ",", "size", "=", "size", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "\n", "", "return", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "uint8", ",", "saturate", "=", "True", ")", "\n", "\n", "# reverse any processing on images so they can be written to disk or displayed to user", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_inputs\"", ")", ":", "\n", "        ", "converted_inputs", "=", "convert", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_targets\"", ")", ":", "\n", "        ", "converted_targets_1", "=", "convert", "(", "targets_1", ")", "\n", "converted_targets_2", "=", "convert", "(", "targets_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_outputs\"", ")", ":", "\n", "        ", "converted_outputs_1", "=", "convert", "(", "outputs_1", ")", "\n", "converted_outputs_2", "=", "convert", "(", "outputs_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"encode_images\"", ")", ":", "\n", "        ", "display_fetches", "=", "{", "\n", "\"paths\"", ":", "examples", ".", "paths", ",", "\n", "\"inputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_inputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"input_pngs\"", ")", ",", "\n", "\"targets_1\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets_1", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_1_pngs\"", ")", ",", "\n", "\"targets_2\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets_2", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_2_pngs\"", ")", ",", "\n", "\"outputs_1\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs_1", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_1_pngs\"", ")", ",", "\n", "\"outputs_2\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs_2", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_2_pngs\"", ")", ",", "\n", "}", "\n", "\n", "# summaries", "\n", "", "with", "tf", ".", "name_scope", "(", "\"inputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"inputs\"", ",", "converted_inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"targets_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"targets_1\"", ",", "converted_targets_1", ")", "\n", "tf", ".", "summary", ".", "image", "(", "\"targets_2\"", ",", "converted_targets_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"outputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"outputs_1\"", ",", "converted_outputs_1", ")", "\n", "tf", ".", "summary", ".", "image", "(", "\"outputs_2\"", ",", "converted_outputs_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_real_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_real\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_real", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_fake_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_fake\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_fake", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss\"", ",", "model", ".", "discrim_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN\"", ",", "model", ".", "gen_loss_GAN", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_L1\"", ",", "model", ".", "gen_loss_L1", ")", "\n", "\n", "# Moha: --------------", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss_real\"", ",", "model", ".", "discrim_loss_real", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss_fake\"", ",", "model", ".", "discrim_loss_fake", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_total\"", ",", "model", ".", "gen_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_dice\"", ",", "model", ".", "gen_loss_dice", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_jaccard\"", ",", "model", ".", "gen_loss_jaccard", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_Tversky\"", ",", "model", ".", "gen_loss_Tversky", ")", "\n", "\n", "\n", "# End MOha", "\n", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/values\"", ",", "var", ")", "\n", "\n", "", "for", "grad", ",", "var", "in", "model", ".", "discrim_grads_and_vars", "+", "model", ".", "gen_grads_and_vars", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/gradients\"", ",", "grad", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"parameter_count\"", ")", ":", "\n", "        ", "parameter_count", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "v", ")", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1", ")", "\n", "\n", "logdir", "=", "a", ".", "output_dir", "if", "(", "a", ".", "trace_freq", ">", "0", "or", "a", ".", "summary_freq", ">", "0", ")", "else", "None", "\n", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "logdir", "=", "logdir", ",", "save_summaries_secs", "=", "0", ",", "saver", "=", "None", ")", "\n", "with", "sv", ".", "managed_session", "(", ")", "as", "sess", ":", "\n", "        ", "print", "(", "\"parameter_count =\"", ",", "sess", ".", "run", "(", "parameter_count", ")", ")", "\n", "\n", "if", "a", ".", "checkpoint", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"#############################\"", ")", "\n", "print", "(", "\"loading model from checkpoint for continue training or testing phase ...\"", ")", "\n", "print", "(", "\"#############################\"", ")", "\n", "try", ":", "\n", "                ", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"loading was unsuccessful-it will train from scratch ...\"", ")", "\n", "print", "(", "\"#############################\"", ")", "\n", "\n", "", "", "max_steps", "=", "2", "**", "32", "\n", "if", "a", ".", "max_epochs", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "examples", ".", "steps_per_epoch", "*", "a", ".", "max_epochs", "\n", "", "if", "a", ".", "max_steps", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "a", ".", "max_steps", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", ":", "\n", "# testing", "\n", "# at most, process the test data once", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "max_steps", "=", "min", "(", "examples", ".", "steps_per_epoch", ",", "max_steps", ")", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "results", "=", "sess", ".", "run", "(", "display_fetches", ")", "\n", "filesets", "=", "save_images", "(", "results", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "filesets", ")", ":", "\n", "                    ", "print", "(", "\"evaluated image\"", ",", "f", "[", "\"name\"", "]", ")", "\n", "", "index_path", "=", "append_index", "(", "filesets", ")", "\n", "", "print", "(", "\"wrote index at\"", ",", "index_path", ")", "\n", "print", "(", "\"rate\"", ",", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "max_steps", ")", "\n", "", "else", ":", "\n", "# training", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "discrim_loss_pre", "=", "10000", "\n", "gan_loss_pre", "=", "10000", "\n", "patience_counter", "=", "0", "\n", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "def", "should", "(", "freq", ")", ":", "\n", "                    ", "return", "freq", ">", "0", "and", "(", "(", "step", "+", "1", ")", "%", "freq", "==", "0", "or", "step", "==", "max_steps", "-", "1", ")", "\n", "\n", "", "options", "=", "None", "\n", "run_metadata", "=", "None", "\n", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "options", "=", "tf", ".", "RunOptions", "(", "trace_level", "=", "tf", ".", "RunOptions", ".", "FULL_TRACE", ")", "\n", "run_metadata", "=", "tf", ".", "RunMetadata", "(", ")", "\n", "\n", "", "fetches", "=", "{", "\n", "\"train\"", ":", "model", ".", "train", ",", "\n", "\"global_step\"", ":", "sv", ".", "global_step", ",", "\n", "}", "\n", "\n", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"discrim_loss\"", "]", "=", "model", ".", "discrim_loss", "\n", "fetches", "[", "\"gen_loss_GAN\"", "]", "=", "model", ".", "gen_loss_GAN", "\n", "fetches", "[", "\"gen_loss_L1\"", "]", "=", "model", ".", "gen_loss_L1", "\n", "# Moha: --------------------", "\n", "fetches", "[", "\"discrim_loss_real\"", "]", "=", "model", ".", "discrim_loss_real", "\n", "fetches", "[", "\"discrim_loss_fake\"", "]", "=", "model", ".", "discrim_loss_fake", "\n", "fetches", "[", "\"gen_loss_total\"", "]", "=", "model", ".", "gen_loss", "\n", "fetches", "[", "\"gen_loss_dice\"", "]", "=", "model", ".", "gen_loss_dice", "\n", "fetches", "[", "\"gen_loss_jaccard\"", "]", "=", "model", ".", "gen_loss_jaccard", "\n", "fetches", "[", "\"gen_loss_Tversky\"", "]", "=", "model", ".", "gen_loss_Tversky", "\n", "\n", "# End MOha", "\n", "\n", "\n", "\n", "", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"summary\"", "]", "=", "sv", ".", "summary_op", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"display\"", "]", "=", "display_fetches", "\n", "\n", "", "results", "=", "sess", ".", "run", "(", "fetches", ",", "options", "=", "options", ",", "run_metadata", "=", "run_metadata", ")", "\n", "\n", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording summary\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "results", "[", "\"summary\"", "]", ",", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving display images\"", ")", "\n", "filesets", "=", "save_images", "(", "results", "[", "\"display\"", "]", ",", "step", "=", "results", "[", "\"global_step\"", "]", ")", "\n", "append_index", "(", "filesets", ",", "step", "=", "True", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording trace\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_run_metadata", "(", "run_metadata", ",", "\"step_%d\"", "%", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "# global_step will have the correct step count if we resume from a checkpoint", "\n", "                    ", "train_epoch", "=", "math", ".", "ceil", "(", "results", "[", "\"global_step\"", "]", "/", "examples", ".", "steps_per_epoch", ")", "\n", "train_step", "=", "(", "results", "[", "\"global_step\"", "]", "-", "1", ")", "%", "examples", ".", "steps_per_epoch", "+", "1", "\n", "rate", "=", "(", "step", "+", "1", ")", "*", "a", ".", "batch_size", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "remaining", "=", "(", "max_steps", "-", "step", ")", "*", "a", ".", "batch_size", "/", "rate", "\n", "print", "(", "'***********************************************'", ")", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "\n", "print", "(", "\"gen_loss_GAN -----------\"", ",", "results", "[", "\"gen_loss_GAN\"", "]", ")", "\n", "print", "(", "\"gen_loss_L1 -----------\"", ",", "results", "[", "\"gen_loss_L1\"", "]", ")", "\n", "print", "(", "\"discrim_loss_total -----------\"", ",", "results", "[", "\"discrim_loss\"", "]", ")", "\n", "\n", "print", "(", "\"discrim_loss_real -----------\"", ",", "results", "[", "\"discrim_loss_real\"", "]", ")", "\n", "print", "(", "\"discrim_loss_fake -----------\"", ",", "results", "[", "\"discrim_loss_fake\"", "]", ")", "\n", "print", "(", "\"gen_loss_total -----------\"", ",", "results", "[", "\"gen_loss_total\"", "]", ")", "\n", "\n", "print", "(", "\"gen_loss_dice -----------\"", ",", "results", "[", "\"gen_loss_dice\"", "]", ")", "\n", "print", "(", "\"gen_loss_jaccard -----------\"", ",", "results", "[", "\"gen_loss_jaccard\"", "]", ")", "\n", "\n", "print", "(", "\"gen_loss_Tversky -----------\"", ",", "results", "[", "\"gen_loss_Tversky\"", "]", ")", "\n", "\n", "\n", "if", "discrim_loss_pre", ">=", "results", "[", "\"discrim_loss\"", "]", ":", "\n", "                        ", "if", "gan_loss_pre", "<=", "results", "[", "\"gen_loss_GAN\"", "]", ":", "\n", "                            ", "patience_counter", "=", "patience_counter", "+", "1", "\n", "\n", "\n", "\n", "", "", "discrim_loss_pre", "=", "results", "[", "\"discrim_loss\"", "]", "\n", "gan_loss_pre", "=", "results", "[", "\"gen_loss_GAN\"", "]", "\n", "\n", "if", "patience_counter", ">=", "float", "(", "a", ".", "patience_epochs", ")", ":", "\n", "                        ", "print", "(", "\"###################\"", ")", "\n", "print", "(", "\"early stop, disc is winning\"", ")", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "break", "\n", "\n", "\n", "", "if", "results", "[", "\"gen_loss_L1\"", "]", "<", "float", "(", "a", ".", "desired_l1_loss", ")", ":", "\n", "                        ", "print", "(", "\"###################\"", ")", "\n", "print", "(", "\"Reached desired error\"", ")", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "break", "\n", "\n", "", "", "if", "should", "(", "a", ".", "save_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "\n", "", "if", "sv", ".", "should_stop", "(", ")", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_MTdG_cv.CombineImages": [[1061, 1145], ["print", "os.mkdir", "skimage.io.imread", "skimage.io.imsave", "print", "shutil.rmtree", "os.mkdir", "filename.replace.replace", "len", "numpy.zeros", "print", "sys.exit", "sys.exit", "print", "sys.exit", "sys.exit", "skimage.io.imread", "skimage.io.imread", "numpy.zeros", "len", "numpy.zeros", "len", "numpy.zeros"], "function", ["None"], ["", "", "", "", "", "def", "CombineImages", "(", "ImageListNames", ",", "task_No", ",", "input_dir_all", ")", ":", "\n", "    ", "print", "(", "'combining images ...'", ")", "\n", "try", ":", "\n", "        ", "os", ".", "mkdir", "(", "write_to_dir", ")", "\n", "", "except", ":", "\n", "        ", "print", "(", "'destination folder is already exist-it will be replaced'", ")", "\n", "shutil", ".", "rmtree", "(", "write_to_dir", ")", "\n", "os", ".", "mkdir", "(", "write_to_dir", ")", "\n", "\n", "\n", "", "for", "filename", "in", "ImageListNames", ":", "\n", "\n", "        ", "try", ":", "\n", "            ", "filename", "=", "filename", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "", "except", ":", "\n", "            ", "no", "=", "0", "\n", "\n", "", "Image", "=", "io", ".", "imread", "(", "a", ".", "input_dir_all", "+", "'/Inputs/'", "+", "filename", ")", "\n", "Size", "=", "Image", ".", "shape", "\n", "if", "len", "(", "Size", ")", "==", "2", ":", "\n", "            ", "Image_", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image", ".", "shape", "[", "0", "]", ",", "Image", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_", "[", ":", ",", ":", ",", "0", "]", "=", "Image", "\n", "Image_", "[", ":", ",", ":", ",", "1", "]", "=", "Image", "\n", "Image_", "[", ":", ",", ":", ",", "2", "]", "=", "Image", "\n", "Image", "=", "Image_", "\n", "\n", "", "if", "task_No", "==", "1", ":", "\n", "\n", "            ", "print", "(", "'1 is not acceptable for single task'", ")", "\n", "sys", ".", "exit", "(", "'1 is not acceptable for single task'", ")", "\n", "\n", "#            Image_t1=io.imread(a.input_dir_all+'/Targets_'+str(task_No) +'/'+ filename)", "\n", "#            Size=Image_t1.shape", "\n", "#            if len(Size)==2:", "\n", "#                Image_=np.zeros(shape=[Image_t1.shape[0],Image_t1.shape[1],3], dtype='uint8')", "\n", "#                Image_[:,:,0]=Image_t1", "\n", "#                Image_[:,:,1]=Image_t1", "\n", "#                Image_[:,:,2]=Image_t1", "\n", "#                Image_t1=Image_", "\n", "#            Image_combined=np.zeros(shape=[Image.shape[0],2*Image.shape[1],3], dtype='uint8')", "\n", "#            Image_combined[:,:CROP_SIZE,:]=Image", "\n", "#            Image_combined[:,CROP_SIZE:,:]=Image_t1", "\n", "\n", "", "if", "task_No", "==", "2", ":", "\n", "            ", "print", "(", "'2 is not acceptable for single task'", ")", "\n", "sys", ".", "exit", "(", "'2 is not acceptable for single task'", ")", "\n", "\n", "#            Image_t2=io.imread(a.input_dir_all+'/Targets_'+str(task_No) +'/'+ filename)", "\n", "#            Size=Image_t2.shape", "\n", "#            if len(Size)==2:", "\n", "#                Image_=np.zeros(shape=[Image_t2.shape[0],Image_t2.shape[1],3], dtype='uint8')", "\n", "#                Image_[:,:,0]=Image_t2", "\n", "#                Image_[:,:,1]=Image_t2", "\n", "#                Image_[:,:,2]=Image_t2", "\n", "#                Image_t2=Image_ ", "\n", "#            Image_combined=np.zeros(shape=[Image.shape[0],2*Image.shape[1],3], dtype='uint8')", "\n", "#            Image_combined[:,:CROP_SIZE,:]=Image", "\n", "#            Image_combined[:,CROP_SIZE:,:]=Image_t2", "\n", "\n", "", "if", "task_No", "==", "3", ":", "\n", "            ", "Image_t1", "=", "io", ".", "imread", "(", "a", ".", "input_dir_all", "+", "'/Targets_1'", "+", "'/'", "+", "filename", ")", "\n", "Image_t2", "=", "io", ".", "imread", "(", "a", ".", "input_dir_all", "+", "'/Targets_2'", "+", "'/'", "+", "filename", ")", "\n", "Size", "=", "Image_t1", ".", "shape", "\n", "if", "len", "(", "Size", ")", "==", "2", ":", "\n", "                ", "Image_", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image_t1", ".", "shape", "[", "0", "]", ",", "Image_t1", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_", "[", ":", ",", ":", ",", "0", "]", "=", "Image_t1", "\n", "Image_", "[", ":", ",", ":", ",", "1", "]", "=", "Image_t1", "\n", "Image_", "[", ":", ",", ":", ",", "2", "]", "=", "Image_t1", "\n", "Image_t1", "=", "Image_", "\n", "", "Size", "=", "Image_t2", ".", "shape", "\n", "if", "len", "(", "Size", ")", "==", "2", ":", "\n", "                ", "Image_", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image_t2", ".", "shape", "[", "0", "]", ",", "Image_t2", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_", "[", ":", ",", ":", ",", "0", "]", "=", "Image_t2", "\n", "Image_", "[", ":", ",", ":", ",", "1", "]", "=", "Image_t2", "\n", "Image_", "[", ":", ",", ":", ",", "2", "]", "=", "Image_t2", "\n", "Image_t2", "=", "Image_", "\n", "", "Image_combined", "=", "np", ".", "zeros", "(", "shape", "=", "[", "Image", ".", "shape", "[", "0", "]", ",", "3", "*", "Image", ".", "shape", "[", "1", "]", ",", "3", "]", ",", "dtype", "=", "'uint8'", ")", "\n", "Image_combined", "[", ":", ",", ":", "CROP_SIZE", ",", ":", "]", "=", "Image", "\n", "Image_combined", "[", ":", ",", "CROP_SIZE", ":", "2", "*", "CROP_SIZE", ",", ":", "]", "=", "Image_t1", "\n", "Image_combined", "[", ":", ",", "2", "*", "CROP_SIZE", ":", ",", ":", "]", "=", "Image_t2", "\n", "\n", "\n", "\n", "", "io", ".", "imsave", "(", "write_to_dir", "+", "filename", ",", "Image_combined", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.preprocess": [[74, 78], ["tensorflow.name_scope"], "function", ["None"], ["def", "preprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess\"", ")", ":", "\n", "# [0, 1] => [-1, 1]", "\n", "        ", "return", "image", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.deprocess": [[80, 84], ["tensorflow.name_scope"], "function", ["None"], ["", "", "def", "deprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess\"", ")", ":", "\n", "# [-1, 1] => [0, 1]", "\n", "        ", "return", "(", "image", "+", "1", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.preprocess_lab": [[86, 93], ["tensorflow.name_scope", "tensorflow.unstack"], "function", ["None"], ["", "", "def", "preprocess_lab", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess_lab\"", ")", ":", "\n", "        ", "L_chan", ",", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "lab", ",", "axis", "=", "2", ")", "\n", "# L_chan: black and white with input range [0, 100]", "\n", "# a_chan/b_chan: color channels with input range ~[-110, 110], not exact", "\n", "# [0, 100] => [-1, 1],  ~[-110, 110] => [-1, 1]", "\n", "return", "[", "L_chan", "/", "50", "-", "1", ",", "a_chan", "/", "110", ",", "b_chan", "/", "110", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.deprocess_lab": [[95, 99], ["tensorflow.name_scope", "tensorflow.stack"], "function", ["None"], ["", "", "def", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess_lab\"", ")", ":", "\n", "# this is axis=3 instead of axis=2 because we process individual images but deprocess batches", "\n", "        ", "return", "tf", ".", "stack", "(", "[", "(", "L_chan", "+", "1", ")", "/", "2", "*", "100", ",", "a_chan", "*", "110", ",", "b_chan", "*", "110", "]", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.augment": [[101, 108], ["tensorflow.unstack", "tensorflow.squeeze", "pix2pix_3_MTdG.deprocess_lab", "lab_to_rgb"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess_lab", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lab_to_rgb"], ["", "", "def", "augment", "(", "image", ",", "brightness", ")", ":", "\n", "# (a, b) color channels, combine with L channel and convert to rgb", "\n", "    ", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "image", ",", "axis", "=", "3", ")", "\n", "L_chan", "=", "tf", ".", "squeeze", "(", "brightness", ",", "axis", "=", "3", ")", "\n", "lab", "=", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", "\n", "rgb", "=", "lab_to_rgb", "(", "lab", ")", "\n", "return", "rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.discrim_conv": [[110, 113], ["tensorflow.pad", "tensorflow.layers.conv2d", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "discrim_conv", "(", "batch_input", ",", "out_channels", ",", "stride", ")", ":", "\n", "    ", "padded_input", "=", "tf", ".", "pad", "(", "batch_input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"CONSTANT\"", ")", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "padded_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "stride", ",", "stride", ")", ",", "padding", "=", "\"valid\"", ",", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.gen_conv": [[115, 122], ["tensorflow.random_normal_initializer", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d"], "function", ["None"], ["", "def", "gen_conv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.gen_conv_dilate": [[124, 130], ["tensorflow.random_normal_initializer", "tensorflow.layers.conv2d", "tensorflow.layers.max_pooling2d"], "function", ["None"], ["", "", "def", "gen_conv_dilate", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "dilate_rate", "=", "2", "\n", "output", "=", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "dilation_rate", "=", "(", "dilate_rate", ",", "dilate_rate", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "return", "tf", ".", "layers", ".", "max_pooling2d", "(", "inputs", "=", "output", ",", "pool_size", "=", "[", "2", ",", "2", "]", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "'valid'", ",", "data_format", "=", "'channels_last'", ",", "name", "=", "None", ")", "\n", "#end  Moha ---------------------------------------", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.gen_deconv": [[134, 143], ["tensorflow.random_normal_initializer", "tensorflow.image.resize_images", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d_transpose"], "function", ["None"], ["", "def", "gen_deconv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "_b", ",", "h", ",", "w", ",", "_c", "=", "batch_input", ".", "shape", "\n", "resized_input", "=", "tf", ".", "image", ".", "resize_images", "(", "batch_input", ",", "[", "h", "*", "2", ",", "w", "*", "2", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "resized_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d_transpose", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.lrelu": [[145, 155], ["tensorflow.name_scope", "tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["", "", "def", "lrelu", "(", "x", ",", "a", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lrelu\"", ")", ":", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: a*x/2 - a*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "        ", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.batchnorm": [[157, 159], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "", "def", "batchnorm", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.dice_coe": [[160, 209], ["pix2pix_3_MTdG.deprocess", "pix2pix_3_MTdG.deprocess", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "Exception"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "dice_coe", "(", "output", ",", "target", ",", "loss_type", "=", "'jaccard'", ",", "axis", "=", "(", "1", ",", "2", ",", "3", ")", ",", "smooth", "=", "1e-5", ")", ":", "\n", "# Moha: based on code from tensorlayer", "\n", "    ", "\"\"\"Soft dice (Sorensen or Jaccard) coefficient for comparing the similarity\n    of two batch of data, usually be used for binary image segmentation\n    i.e. labels are binary. The coefficient between 0 to 1, 1 means totally match.\n    Parameters\n    -----------\n    output : Tensor\n        A distribution with shape: [batch_size, ....], (any dimensions).\n    target : Tensor\n        The target distribution, format the same with `output`.\n    loss_type : str\n        ``jaccard`` or ``sorensen``, default is ``jaccard``.\n    axis : tuple of int\n        All dimensions are reduced, default ``[1,2,3]``.\n    smooth : float\n        This small value will be added to the numerator and denominator.\n            - If both output and target are empty, it makes sure dice is 1.\n            - If either output or target are empty (all pixels are background), dice = ```smooth/(small_value + smooth)``, then if smooth is very small, dice close to 0 (even the image values lower than the threshold), so in this case, higher smooth can have a higher dice.\n    Examples\n    ---------\n    >>> outputs = tl.act.pixel_wise_softmax(network.outputs)\n    >>> dice_loss = 1 - tl.cost.dice_coe(outputs, y_)\n    \"\"\"", "\n", "\n", "output", "=", "deprocess", "(", "output", ")", "\n", "target", "=", "deprocess", "(", "target", ")", "\n", "\n", "output", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "output", ">", "0.5", ")", ")", "\n", "target", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "target", ">", "0.5", ")", ")", "\n", "\n", "inse", "=", "tf", ".", "reduce_sum", "(", "output", "*", "target", ",", "axis", "=", "axis", ")", "\n", "if", "loss_type", "==", "'jaccard'", ":", "\n", "        ", "l", "=", "tf", ".", "reduce_sum", "(", "output", "*", "output", ",", "axis", "=", "axis", ")", "\n", "r", "=", "tf", ".", "reduce_sum", "(", "target", "*", "target", ",", "axis", "=", "axis", ")", "\n", "", "elif", "loss_type", "==", "'sorensen'", ":", "\n", "        ", "l", "=", "tf", ".", "reduce_sum", "(", "output", ",", "axis", "=", "axis", ")", "\n", "r", "=", "tf", ".", "reduce_sum", "(", "target", ",", "axis", "=", "axis", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Unknow loss_type\"", ")", "\n", "# old axis=[0,1,2,3]", "\n", "# dice = 2 * (inse) / (l + r)", "\n", "# epsilon = 1e-5", "\n", "# dice = tf.clip_by_value(dice, 0, 1.0-epsilon) # if all empty, dice = 1", "\n", "# new haodong", "\n", "", "dice", "=", "(", "2.", "*", "inse", "+", "smooth", ")", "/", "(", "l", "+", "r", "+", "smooth", ")", "\n", "##", "\n", "dice", "=", "tf", ".", "reduce_mean", "(", "dice", ",", "name", "=", "'dice_coe'", ")", "\n", "return", "dice", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.tversky_loss": [[211, 249], ["pix2pix_3_MTdG.deprocess", "pix2pix_3_MTdG.deprocess", "tensorflow.contrib.layers.flatten", "tensorflow.contrib.layers.flatten", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.reduce_sum", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "tversky_loss", "(", "labels", ",", "predictions", ",", "alpha", "=", "0.3", ",", "beta", "=", "0.7", ",", "smooth", "=", "1e-10", ")", ":", "\n", "# Moha: based on code from: https://analysiscenter.github.io/radio/_modules/radio/models/tf/losses.html#tversky_loss", "\n", "    ", "\"\"\" Tversky loss function.\n\n    Parameters\n    ----------\n    labels : tf.Tensor\n        tensor containing target mask.\n    predictions : tf.Tensor\n        tensor containing predicted mask.\n    alpha : float\n        real value, weight of '0' class.\n    beta : float\n        real value, weight of '1' class.\n    smooth : float\n        small real value used for avoiding division by zero error.\n\n    Returns\n    -------\n    tf.Tensor\n        tensor containing tversky loss.\n    \"\"\"", "\n", "\n", "labels", "=", "deprocess", "(", "labels", ")", "\n", "predictions", "=", "deprocess", "(", "predictions", ")", "\n", "\n", "labels", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "labels", ")", "\n", "predictions", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "predictions", ")", "\n", "\n", "labels", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "labels", ">", "0.5", ")", ")", "\n", "predictions", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "predictions", ">", "0.5", ")", ")", "\n", "\n", "\n", "truepos", "=", "tf", ".", "reduce_sum", "(", "labels", "*", "predictions", ")", "\n", "fp_and_fn", "=", "(", "alpha", "*", "tf", ".", "reduce_sum", "(", "predictions", "*", "(", "1", "-", "labels", ")", ")", "\n", "+", "beta", "*", "tf", ".", "reduce_sum", "(", "(", "1", "-", "predictions", ")", "*", "labels", ")", ")", "\n", "\n", "return", "(", "truepos", "+", "smooth", ")", "/", "(", "truepos", "+", "smooth", "+", "fp_and_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.create_generator": [[250, 336], ["print", "print", "print", "len", "enumerate", "tensorflow.variable_scope", "pix2pix_3_MTdG.gen_conv", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_3_MTdG.lrelu", "pix2pix_3_MTdG.gen_conv", "print", "pix2pix_3_MTdG.batchnorm", "layers.append", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.nn.relu", "pix2pix_3_MTdG.gen_deconv", "tensorflow.tanh", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_3_MTdG.lrelu", "pix2pix_3_MTdG.gen_conv_dilate", "print", "pix2pix_3_MTdG.batchnorm", "layers.append", "tensorflow.variable_scope", "tensorflow.nn.relu", "pix2pix_3_MTdG.gen_deconv", "pix2pix_3_MTdG.batchnorm", "layers.append", "print", "tensorflow.concat", "tensorflow.nn.dropout", "len", "len"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv_dilate", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm"], ["", "def", "create_generator", "(", "generator_inputs", ",", "generator_outputs_channels", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "\n", "print", "(", "'encoder:'", ")", "\n", "print", "(", "generator_inputs", ".", "shape", ")", "\n", "# encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_1\"", ")", ":", "\n", "        ", "output", "=", "gen_conv", "(", "generator_inputs", ",", "a", ".", "ngf", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "a", ".", "ngf", "*", "2", ",", "# encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]", "\n", "a", ".", "ngf", "*", "4", ",", "# encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]", "\n", "]", "\n", "\n", "for", "out_channels", "in", "layer_specs", "[", ":", "6", "]", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]", "\n", "\n", "# orig: ---------------------------", "\n", "# convolved = gen_conv(rectified, out_channels)", "\n", "# Moha: ---------------------------", "\n", "convolved", "=", "gen_conv_dilate", "(", "rectified", ",", "out_channels", ")", "\n", "#convolved = gen_conv(rectified, out_channels)", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "# end Moha -----------------------------", "\n", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "convolved", "=", "gen_conv", "(", "rectified", ",", "layer_specs", "[", "6", "]", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "print", "(", "'decoder:'", ")", "\n", "layer_specs", "=", "[", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.0", ")", ",", "# decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "4", ",", "0.0", ")", ",", "# decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]", "\n", "(", "a", ".", "ngf", "*", "2", ",", "0.0", ")", ",", "# decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]", "\n", "(", "a", ".", "ngf", ",", "0.0", ")", ",", "# decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]", "\n", "]", "\n", "\n", "num_encoder_layers", "=", "len", "(", "layers", ")", "\n", "for", "decoder_layer", ",", "(", "out_channels", ",", "dropout", ")", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "skip_layer", "=", "num_encoder_layers", "-", "decoder_layer", "-", "1", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder_%d\"", "%", "(", "skip_layer", "+", "1", ")", ")", ":", "\n", "            ", "if", "decoder_layer", "==", "0", ":", "\n", "# first decoder layer doesn't have skip connections", "\n", "# since it is directly connected to the skip_layer", "\n", "                ", "input", "=", "layers", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "skip_layer", "]", "]", ",", "axis", "=", "3", ")", "\n", "\n", "", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batchnorm", "(", "output", ")", "\n", "\n", "if", "dropout", ">", "0.0", ":", "\n", "                ", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "keep_prob", "=", "1", "-", "dropout", ")", "\n", "\n", "", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "# decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"decoder_1\"", ")", ":", "\n", "        ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "0", "]", "]", ",", "axis", "=", "3", ")", "\n", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "generator_outputs_channels", ")", "\n", "output", "=", "tf", ".", "tanh", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.create_model_MT": [[339, 470], ["tensorflow.concat", "tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "print", "tensorflow.concat", "print", "range", "tensorflow.variable_scope", "int", "pix2pix_3_MTdG.create_generator", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.abs", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.variable_scope", "pix2pix_3_MTdG.discrim_conv", "pix2pix_3_MTdG.lrelu", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_3_MTdG.discrim_conv", "tensorflow.sigmoid", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_3_MTdG.create_model_MT.create_discriminator"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_generator", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv"], ["", "def", "create_model_MT", "(", "inputs", ",", "targets_1", ",", "targets_2", ")", ":", "\n", "\n", "    ", "def", "create_discriminator", "(", "discrim_inputs", ",", "discrim_targets", ")", ":", "\n", "        ", "n_layers", "=", "3", "\n", "layers", "=", "[", "]", "\n", "print", "(", "'discriminator:'", ")", "\n", "\n", "# 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]", "\n", "input", "=", "tf", ".", "concat", "(", "[", "discrim_inputs", ",", "discrim_targets", "]", ",", "axis", "=", "3", ")", "\n", "print", "(", "input", ".", "shape", ")", "\n", "# layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"layer_1\"", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "input", ",", "a", ".", "ndf", ",", "stride", "=", "2", ")", "\n", "rectified", "=", "lrelu", "(", "convolved", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]", "\n", "# layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]", "\n", "# layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]", "\n", "", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "                ", "out_channels", "=", "a", ".", "ndf", "*", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "stride", "=", "1", "if", "i", "==", "n_layers", "-", "1", "else", "2", "# last layer here has stride 1", "\n", "convolved", "=", "discrim_conv", "(", "layers", "[", "-", "1", "]", ",", "out_channels", ",", "stride", "=", "stride", ")", "\n", "normalized", "=", "batchnorm", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "rectified", ",", "out_channels", "=", "1", ",", "stride", "=", "1", ")", "\n", "output", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n", "\n", "", "targets", "=", "tf", ".", "concat", "(", "[", "targets_1", ",", "targets_2", "]", ",", "axis", "=", "3", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "        ", "out_channels", "=", "int", "(", "targets", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "outputs", "=", "create_generator", "(", "inputs", ",", "out_channels", ")", "\n", "\n", "# create two copies of discriminator, one for real pairs and one for fake pairs", "\n", "# they share the same underlying variables", "\n", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_real", "=", "create_discriminator", "(", "inputs", ",", "targets", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ",", "reuse", "=", "True", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_fake", "=", "create_discriminator", "(", "inputs", ",", "outputs", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_loss\"", ")", ":", "\n", "# minimizing -tf.log will try to get inputs to 1", "\n", "# predict_real => 1 ", "\n", "# predict_fake => 0", "\n", "        ", "discrim_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "discrim_loss_real", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", ")", ")", "\n", "discrim_loss_fake", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_loss\"", ")", ":", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "        ", "gen_loss_GAN", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_fake", "+", "EPS", ")", ")", "\n", "gen_loss_L1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "targets", "-", "outputs", ")", ")", "\n", "gen_loss_dice", "=", "1", "-", "dice_coe", "(", "outputs", ",", "targets", ",", "loss_type", "=", "'sorensen'", ")", "\n", "gen_loss_jaccard", "=", "1", "-", "dice_coe", "(", "outputs", ",", "targets", ",", "loss_type", "=", "'jaccard'", ")", "\n", "\n", "gen_loss_Tversky", "=", "tf", ".", "abs", "(", "1", "-", "tversky_loss", "(", "targets", ",", "outputs", ")", ")", "\n", "gen_loss", "=", "gen_loss_GAN", "*", "a", ".", "gan_weight", "+", "gen_loss_L1", "*", "a", ".", "l1_weight", "\n", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_train\"", ")", ":", "\n", "        ", "discrim_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"discriminator\"", ")", "]", "\n", "discrim_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "discrim_grads_and_vars", "=", "discrim_optim", ".", "compute_gradients", "(", "discrim_loss", ",", "var_list", "=", "discrim_tvars", ")", "\n", "discrim_train", "=", "discrim_optim", ".", "apply_gradients", "(", "discrim_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_train", "]", ")", ":", "\n", "            ", "gen_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"generator\"", ")", "]", "\n", "gen_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "gen_grads_and_vars", "=", "gen_optim", ".", "compute_gradients", "(", "gen_loss", ",", "var_list", "=", "gen_tvars", ")", "\n", "gen_train", "=", "gen_optim", ".", "apply_gradients", "(", "gen_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "\n", "# orig: ----------------------", "\n", "#update_losses = ema.apply([discrim_loss, gen_loss_GAN, gen_loss_L1])", "\n", "# end orig", "\n", "# Moha: ----------------------", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_loss", ",", "gen_loss_GAN", ",", "gen_loss_L1", ",", "\n", "gen_loss", ",", "discrim_loss_real", ",", "discrim_loss_fake", ",", "gen_loss_jaccard", ",", "\n", "gen_loss_dice", ",", "gen_loss_Tversky", "]", ")", "\n", "\n", "outputs_1", "=", "outputs", "[", ":", ",", ":", ",", ":", ",", ":", "3", "]", "\n", "outputs_2", "=", "outputs", "[", ":", ",", ":", ",", ":", ",", "3", ":", "]", "\n", "# End Moha", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "\n", "return", "Model", "(", "\n", "predict_real", "=", "predict_real", ",", "\n", "predict_fake", "=", "predict_fake", ",", "\n", "\n", "discrim_loss", "=", "ema", ".", "average", "(", "discrim_loss", ")", ",", "\n", "discrim_grads_and_vars", "=", "discrim_grads_and_vars", ",", "\n", "\n", "gen_loss_GAN", "=", "ema", ".", "average", "(", "gen_loss_GAN", ")", ",", "\n", "gen_loss_L1", "=", "ema", ".", "average", "(", "gen_loss_L1", ")", ",", "\n", "gen_grads_and_vars", "=", "gen_grads_and_vars", ",", "\n", "\n", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_train", ")", ",", "\n", "# Noha: -----------------", "\n", "outputs_1", "=", "outputs_1", ",", "\n", "outputs_2", "=", "outputs_2", ",", "\n", "gen_loss", "=", "ema", ".", "average", "(", "gen_loss", ")", ",", "\n", "discrim_loss_fake", "=", "ema", ".", "average", "(", "discrim_loss_fake", ")", ",", "\n", "discrim_loss_real", "=", "ema", ".", "average", "(", "discrim_loss_real", ")", ",", "\n", "gen_loss_jaccard", "=", "ema", ".", "average", "(", "gen_loss_jaccard", ")", ",", "\n", "gen_loss_dice", "=", "ema", ".", "average", "(", "gen_loss_dice", ")", ",", "\n", "gen_loss_Tversky", "=", "ema", ".", "average", "(", "gen_loss_Tversky", ")", "\n", "# End Moha", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.check_image": [[563, 576], ["tensorflow.assert_equal", "list", "tf.identity.set_shape", "tensorflow.control_dependencies", "tensorflow.identity", "ValueError", "tf.identity.get_shape", "tensorflow.shape", "tf.identity.get_shape"], "function", ["None"], ["", "def", "check_image", "(", "image", ")", ":", "\n", "    ", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "image", ")", "[", "-", "1", "]", ",", "3", ",", "message", "=", "\"image must have 3 color channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "        ", "image", "=", "tf", ".", "identity", "(", "image", ")", "\n", "\n", "", "if", "image", ".", "get_shape", "(", ")", ".", "ndims", "not", "in", "(", "3", ",", "4", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"image must be either 3 or 4 dimensions\"", ")", "\n", "\n", "# make the last dimension 3 so that you can unstack the colors", "\n", "", "shape", "=", "list", "(", "image", ".", "get_shape", "(", ")", ")", "\n", "shape", "[", "-", "1", "]", "=", "3", "\n", "image", ".", "set_shape", "(", "shape", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.load_examples": [[577, 669], ["glob.glob", "all", "random.randint", "tensorflow.train.batch", "int", "Examples", "Exception", "os.path.join", "len", "glob.glob", "len", "Exception", "os.path.splitext", "sorted", "sorted", "tensorflow.name_scope", "tensorflow.train.string_input_producer", "tensorflow.WholeFileReader", "tf.WholeFileReader.read", "decode", "tensorflow.image.convert_image_dtype", "tensorflow.assert_equal", "tf.identity.set_shape", "pix2pix_3_MTdG.preprocess", "pix2pix_3_MTdG.preprocess", "pix2pix_3_MTdG.preprocess", "tensorflow.image.resize_images", "tensorflow.cast", "tensorflow.name_scope", "pix2pix_3_MTdG.load_examples.transform"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess"], ["", "def", "load_examples", "(", ")", ":", "\n", "    ", "if", "a", ".", "input_dir", "is", "None", "or", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "input_dir", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir does not exist\"", ")", "\n", "\n", "", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.jpg\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_jpeg", "\n", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.png\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_png", "\n", "\n", "", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir contains no image files\"", ")", "\n", "\n", "", "def", "get_name", "(", "path", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "\n", "return", "name", "\n", "\n", "# if the image names are numbers, sort by the value rather than asciibetically", "\n", "# having sorted inputs means that the outputs are sorted in test mode", "\n", "", "if", "all", "(", "get_name", "(", "path", ")", ".", "isdigit", "(", ")", "for", "path", "in", "input_paths", ")", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ",", "key", "=", "lambda", "path", ":", "int", "(", "get_name", "(", "path", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"load_images\"", ")", ":", "\n", "        ", "path_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "input_paths", ",", "shuffle", "=", "a", ".", "mode", "==", "\"train\"", ")", "\n", "reader", "=", "tf", ".", "WholeFileReader", "(", ")", "\n", "paths", ",", "contents", "=", "reader", ".", "read", "(", "path_queue", ")", "\n", "raw_input", "=", "decode", "(", "contents", ")", "\n", "raw_input", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "raw_input", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "raw_input", ")", "[", "2", "]", ",", "3", ",", "message", "=", "\"image does not have 3 channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "            ", "raw_input", "=", "tf", ".", "identity", "(", "raw_input", ")", "\n", "\n", "", "raw_input", ".", "set_shape", "(", "[", "None", ",", "None", ",", "3", "]", ")", "\n", "\n", "\n", "# break apart image pair and move to range [-1, 1]", "\n", "width", "=", "tf", ".", "shape", "(", "raw_input", ")", "[", "1", "]", "# [height, width, channels]", "\n", "a_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", ":", "width", "//", "3", ",", ":", "]", ")", "\n", "b_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "width", "//", "3", ":", "2", "*", "width", "//", "3", ",", ":", "]", ")", "\n", "c_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "2", "*", "width", "//", "3", ":", ",", ":", "]", ")", "\n", "\n", "\n", "\n", "", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "        ", "inputs", ",", "targets_1", ",", "targets_2", "=", "[", "a_images", ",", "b_images", ",", "c_images", "]", "\n", "#targets_2=c_images", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "#inputs, targets_1, targets_2 = [b_images, a_images]", "\n", "        ", "print", "(", "\"Error:::: just use AtoB direction\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "\n", "# synchronize seed for image operations so that we do the same operations to both", "\n", "# input and output images", "\n", "", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "def", "transform", "(", "image", ")", ":", "\n", "        ", "r", "=", "image", "\n", "if", "a", ".", "flip", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "r", ",", "seed", "=", "seed", ")", "\n", "\n", "# area produces a nice downscaling, but does nearest neighbor for upscaling", "\n", "# assume we're going to be doing downscaling here", "\n", "", "r", "=", "tf", ".", "image", ".", "resize_images", "(", "r", ",", "[", "a", ".", "scale_size", ",", "a", ".", "scale_size", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "AREA", ")", "\n", "\n", "offset", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "2", "]", ",", "0", ",", "a", ".", "scale_size", "-", "CROP_SIZE", "+", "1", ",", "seed", "=", "seed", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "if", "a", ".", "scale_size", ">", "CROP_SIZE", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "r", ",", "offset", "[", "0", "]", ",", "offset", "[", "1", "]", ",", "CROP_SIZE", ",", "CROP_SIZE", ")", "\n", "", "elif", "a", ".", "scale_size", "<", "CROP_SIZE", ":", "\n", "            ", "raise", "Exception", "(", "\"scale size cannot be less than crop size\"", ")", "\n", "", "return", "r", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"input_images\"", ")", ":", "\n", "        ", "input_images", "=", "transform", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"target_images\"", ")", ":", "\n", "        ", "target_1_images", "=", "transform", "(", "targets_1", ")", "\n", "target_2_images", "=", "transform", "(", "targets_2", ")", "\n", "#        target_images=tf.concat([target_1_images,target_2_images],axis=3)", "\n", "\n", "", "paths_batch", ",", "inputs_batch", ",", "targets_1_batch", ",", "targets_2_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "paths", ",", "input_images", ",", "target_1_images", ",", "target_2_images", "]", ",", "batch_size", "=", "a", ".", "batch_size", ")", "\n", "steps_per_epoch", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "input_paths", ")", "/", "a", ".", "batch_size", ")", ")", "\n", "\n", "return", "Examples", "(", "\n", "paths", "=", "paths_batch", ",", "\n", "inputs", "=", "inputs_batch", ",", "\n", "targets_1", "=", "targets_1_batch", ",", "\n", "targets_2", "=", "targets_2_batch", ",", "\n", "count", "=", "len", "(", "input_paths", ")", ",", "\n", "steps_per_epoch", "=", "steps_per_epoch", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.save_images": [[674, 694], ["os.path.join", "enumerate", "os.path.exists", "os.makedirs", "os.path.splitext", "filesets.append", "os.path.basename", "os.path.join", "in_path.decode", "open", "f.write"], "function", ["None"], ["", "def", "save_images", "(", "fetches", ",", "step", "=", "None", ")", ":", "\n", "    ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"images\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "filesets", "=", "[", "]", "\n", "for", "i", ",", "in_path", "in", "enumerate", "(", "fetches", "[", "\"paths\"", "]", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "in_path", ".", "decode", "(", "\"utf8\"", ")", ")", ")", "\n", "fileset", "=", "{", "\"name\"", ":", "name", ",", "\"step\"", ":", "step", "}", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs_1\"", ",", "\"targets_1\"", ",", "\"outputs_2\"", ",", "\"targets_2\"", "]", ":", "\n", "            ", "filename", "=", "name", "+", "\"-\"", "+", "kind", "+", "\".png\"", "\n", "if", "step", "is", "not", "None", ":", "\n", "                ", "filename", "=", "\"%08d-%s\"", "%", "(", "step", ",", "filename", ")", "\n", "", "fileset", "[", "kind", "]", "=", "filename", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "filename", ")", "\n", "contents", "=", "fetches", "[", "kind", "]", "[", "i", "]", "\n", "with", "open", "(", "out_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "contents", ")", "\n", "", "", "filesets", ".", "append", "(", "fileset", ")", "\n", "", "return", "filesets", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.append_index": [[696, 720], ["os.path.join", "os.path.exists", "open", "open", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write"], "function", ["None"], ["", "def", "append_index", "(", "filesets", ",", "step", "=", "False", ")", ":", "\n", "    ", "index_path", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"index.html\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_path", ")", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"a\"", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"w\"", ")", "\n", "index", ".", "write", "(", "\"<html><body><table><tr>\"", ")", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<th>step</th>\"", ")", "\n", "#table construction", "\n", "", "index", ".", "write", "(", "\"<th>name</th><th>input</th><th>output_1</th><th>target_1</th><th>output_2</th><th>target_2</th></tr>\"", ")", "\n", "\n", "", "for", "fileset", "in", "filesets", ":", "\n", "        ", "index", ".", "write", "(", "\"<tr>\"", ")", "\n", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<td>%d</td>\"", "%", "fileset", "[", "\"step\"", "]", ")", "\n", "", "index", ".", "write", "(", "\"<td>%s</td>\"", "%", "fileset", "[", "\"name\"", "]", ")", "\n", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs_1\"", ",", "\"targets_1\"", ",", "\"outputs_2\"", ",", "\"targets_2\"", "]", ":", "\n", "            ", "index", ".", "write", "(", "\"<td><img src='images/%s'></td>\"", "%", "fileset", "[", "kind", "]", ")", "\n", "\n", "", "index", ".", "write", "(", "\"</tr>\"", ")", "\n", "", "return", "index_path", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_MTdG.main": [[722, 1015], ["tensorflow.set_random_seed", "numpy.random.seed", "random.seed", "a._get_kwargs", "pix2pix_3_MTdG.load_examples", "print", "pix2pix_3_MTdG.create_model_MT", "pix2pix_3_MTdG.deprocess", "pix2pix_3_MTdG.deprocess", "pix2pix_3_MTdG.deprocess", "pix2pix_3_MTdG.deprocess", "pix2pix_3_MTdG.deprocess", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.train.Saver", "tensorflow.train.Supervisor", "random.randint", "os.path.exists", "os.makedirs", "print", "open", "f.write", "tensorflow.placeholder", "tensorflow.decode_base64", "tensorflow.image.decode_png", "tensorflow.cond", "tensorflow.cond", "tensorflow.image.convert_image_dtype", "tf.image.convert_image_dtype.set_shape", "tensorflow.expand_dims", "tensorflow.convert_to_tensor", "tensorflow.placeholder", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.global_variables_initializer", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.image.convert_image_dtype", "tensorflow.name_scope", "pix2pix_3_MTdG.main.convert"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.load_examples", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.create_model_MT", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "main", "(", ")", ":", "\n", "    ", "if", "a", ".", "seed", "is", "None", ":", "\n", "        ", "a", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "\n", "", "tf", ".", "set_random_seed", "(", "a", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "a", ".", "output_dir", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", "or", "a", ".", "mode", "==", "\"export\"", ":", "\n", "        ", "if", "a", ".", "checkpoint", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"checkpoint required for test mode\"", ")", "\n", "\n", "# load some options from the checkpoint", "\n", "", "options", "=", "{", "\"which_direction\"", ",", "\"ngf\"", ",", "\"ndf\"", ",", "\"lab_colorization\"", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "checkpoint", ",", "\"options.json\"", ")", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "val", "in", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "in", "options", ":", "\n", "                    ", "print", "(", "\"loaded\"", ",", "key", ",", "\"=\"", ",", "val", ")", "\n", "setattr", "(", "a", ",", "key", ",", "val", ")", "\n", "# disable these features in test mode", "\n", "", "", "", "a", ".", "scale_size", "=", "CROP_SIZE", "\n", "a", ".", "flip", "=", "False", "\n", "\n", "", "for", "k", ",", "v", "in", "a", ".", "_get_kwargs", "(", ")", ":", "\n", "        ", "print", "(", "k", ",", "\"=\"", ",", "v", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"options.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vars", "(", "a", ")", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"export\"", ":", "\n", "# export the generator to a meta graph that can be imported later for standalone generation", "\n", "        ", "if", "a", ".", "lab_colorization", ":", "\n", "            ", "raise", "Exception", "(", "\"export not supported for lab_colorization\"", ")", "\n", "\n", "", "input", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "input_data", "=", "tf", ".", "decode_base64", "(", "input", "[", "0", "]", ")", "\n", "input_image", "=", "tf", ".", "image", ".", "decode_png", "(", "input_data", ")", "\n", "\n", "# remove alpha channel if present", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "4", ")", ",", "lambda", ":", "input_image", "[", ":", ",", ":", ",", ":", "3", "]", ",", "lambda", ":", "input_image", ")", "\n", "# convert grayscale to RGB", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "1", ")", ",", "lambda", ":", "tf", ".", "image", ".", "grayscale_to_rgb", "(", "input_image", ")", ",", "lambda", ":", "input_image", ")", "\n", "# Images that are represented using floating point values are expected to have values in the range [0,1)", "\n", "input_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "input_image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "input_image", ".", "set_shape", "(", "[", "CROP_SIZE", ",", "CROP_SIZE", ",", "3", "]", ")", "\n", "batch_input", "=", "tf", ".", "expand_dims", "(", "input_image", ",", "axis", "=", "0", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "            ", "batch_output", "=", "deprocess", "(", "create_generator", "(", "preprocess", "(", "batch_input", ")", ",", "3", ")", ")", "\n", "\n", "", "output_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "batch_output", ",", "dtype", "=", "tf", ".", "uint8", ")", "[", "0", "]", "\n", "if", "a", ".", "output_filetype", "==", "\"png\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_png", "(", "output_image", ")", "\n", "", "elif", "a", ".", "output_filetype", "==", "\"jpeg\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_jpeg", "(", "output_image", ",", "quality", "=", "80", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid filetype\"", ")", "\n", "", "output", "=", "tf", ".", "convert_to_tensor", "(", "[", "tf", ".", "encode_base64", "(", "output_data", ")", "]", ")", "\n", "\n", "key", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "inputs", "=", "{", "\n", "\"key\"", ":", "key", ".", "name", ",", "\n", "\"input\"", ":", "input", ".", "name", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"inputs\"", ",", "json", ".", "dumps", "(", "inputs", ")", ")", "\n", "outputs", "=", "{", "\n", "\"key\"", ":", "tf", ".", "identity", "(", "key", ")", ".", "name", ",", "\n", "\"output\"", ":", "output", ".", "name", ",", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"outputs\"", ",", "json", ".", "dumps", "(", "outputs", ")", ")", "\n", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "restore_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "export_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "restore_saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "print", "(", "\"exporting model\"", ")", "\n", "export_saver", ".", "export_meta_graph", "(", "filename", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export.meta\"", ")", ")", "\n", "export_saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export\"", ")", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "", "return", "\n", "\n", "", "examples", "=", "load_examples", "(", ")", "\n", "print", "(", "\"examples count = %d\"", "%", "examples", ".", "count", ")", "\n", "\n", "# inputs and targets are [batch_size, height, width, channels]", "\n", "model", "=", "create_model_MT", "(", "examples", ".", "inputs", ",", "examples", ".", "targets_1", ",", "examples", ".", "targets_2", ")", "\n", "\n", "\n", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "targets_1", "=", "deprocess", "(", "examples", ".", "targets_1", ")", "\n", "targets_2", "=", "deprocess", "(", "examples", ".", "targets_2", ")", "\n", "outputs_1", "=", "deprocess", "(", "model", ".", "outputs_1", ")", "\n", "outputs_2", "=", "deprocess", "(", "model", ".", "outputs_2", ")", "\n", "#print(outputs_2.shape)", "\n", "\n", "def", "convert", "(", "image", ")", ":", "\n", "        ", "if", "a", ".", "aspect_ratio", "!=", "1.0", ":", "\n", "# upscale to correct aspect ratio", "\n", "            ", "size", "=", "[", "CROP_SIZE", ",", "int", "(", "round", "(", "CROP_SIZE", "*", "a", ".", "aspect_ratio", ")", ")", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "image", ",", "size", "=", "size", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "\n", "", "return", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "uint8", ",", "saturate", "=", "True", ")", "\n", "\n", "# reverse any processing on images so they can be written to disk or displayed to user", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_inputs\"", ")", ":", "\n", "        ", "converted_inputs", "=", "convert", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_targets\"", ")", ":", "\n", "        ", "converted_targets_1", "=", "convert", "(", "targets_1", ")", "\n", "converted_targets_2", "=", "convert", "(", "targets_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_outputs\"", ")", ":", "\n", "        ", "converted_outputs_1", "=", "convert", "(", "outputs_1", ")", "\n", "converted_outputs_2", "=", "convert", "(", "outputs_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"encode_images\"", ")", ":", "\n", "        ", "display_fetches", "=", "{", "\n", "\"paths\"", ":", "examples", ".", "paths", ",", "\n", "\"inputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_inputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"input_pngs\"", ")", ",", "\n", "\"targets_1\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets_1", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_1_pngs\"", ")", ",", "\n", "\"targets_2\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets_2", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_2_pngs\"", ")", ",", "\n", "\"outputs_1\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs_1", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_1_pngs\"", ")", ",", "\n", "\"outputs_2\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs_2", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_2_pngs\"", ")", ",", "\n", "}", "\n", "\n", "# summaries", "\n", "", "with", "tf", ".", "name_scope", "(", "\"inputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"inputs\"", ",", "converted_inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"targets_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"targets_1\"", ",", "converted_targets_1", ")", "\n", "tf", ".", "summary", ".", "image", "(", "\"targets_2\"", ",", "converted_targets_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"outputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"outputs_1\"", ",", "converted_outputs_1", ")", "\n", "tf", ".", "summary", ".", "image", "(", "\"outputs_2\"", ",", "converted_outputs_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_real_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_real\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_real", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_fake_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_fake\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_fake", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss\"", ",", "model", ".", "discrim_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN\"", ",", "model", ".", "gen_loss_GAN", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_L1\"", ",", "model", ".", "gen_loss_L1", ")", "\n", "\n", "# Moha: --------------", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss_real\"", ",", "model", ".", "discrim_loss_real", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss_fake\"", ",", "model", ".", "discrim_loss_fake", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_total\"", ",", "model", ".", "gen_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_dice\"", ",", "model", ".", "gen_loss_dice", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_jaccard\"", ",", "model", ".", "gen_loss_jaccard", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_Tversky\"", ",", "model", ".", "gen_loss_Tversky", ")", "\n", "\n", "\n", "# End MOha", "\n", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/values\"", ",", "var", ")", "\n", "\n", "", "for", "grad", ",", "var", "in", "model", ".", "discrim_grads_and_vars", "+", "model", ".", "gen_grads_and_vars", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/gradients\"", ",", "grad", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"parameter_count\"", ")", ":", "\n", "        ", "parameter_count", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "v", ")", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1", ")", "\n", "\n", "logdir", "=", "a", ".", "output_dir", "if", "(", "a", ".", "trace_freq", ">", "0", "or", "a", ".", "summary_freq", ">", "0", ")", "else", "None", "\n", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "logdir", "=", "logdir", ",", "save_summaries_secs", "=", "0", ",", "saver", "=", "None", ")", "\n", "with", "sv", ".", "managed_session", "(", ")", "as", "sess", ":", "\n", "        ", "print", "(", "\"parameter_count =\"", ",", "sess", ".", "run", "(", "parameter_count", ")", ")", "\n", "\n", "if", "a", ".", "checkpoint", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"loading model was not successfull\"", ")", "\n", "\n", "", "", "max_steps", "=", "2", "**", "32", "\n", "if", "a", ".", "max_epochs", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "examples", ".", "steps_per_epoch", "*", "a", ".", "max_epochs", "\n", "", "if", "a", ".", "max_steps", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "a", ".", "max_steps", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", ":", "\n", "# testing", "\n", "# at most, process the test data once", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "max_steps", "=", "min", "(", "examples", ".", "steps_per_epoch", ",", "max_steps", ")", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "results", "=", "sess", ".", "run", "(", "display_fetches", ")", "\n", "filesets", "=", "save_images", "(", "results", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "filesets", ")", ":", "\n", "                    ", "print", "(", "\"evaluated image\"", ",", "f", "[", "\"name\"", "]", ")", "\n", "", "index_path", "=", "append_index", "(", "filesets", ")", "\n", "", "print", "(", "\"wrote index at\"", ",", "index_path", ")", "\n", "print", "(", "\"rate\"", ",", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "max_steps", ")", "\n", "", "else", ":", "\n", "# training", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "def", "should", "(", "freq", ")", ":", "\n", "                    ", "return", "freq", ">", "0", "and", "(", "(", "step", "+", "1", ")", "%", "freq", "==", "0", "or", "step", "==", "max_steps", "-", "1", ")", "\n", "\n", "", "options", "=", "None", "\n", "run_metadata", "=", "None", "\n", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "options", "=", "tf", ".", "RunOptions", "(", "trace_level", "=", "tf", ".", "RunOptions", ".", "FULL_TRACE", ")", "\n", "run_metadata", "=", "tf", ".", "RunMetadata", "(", ")", "\n", "\n", "", "fetches", "=", "{", "\n", "\"train\"", ":", "model", ".", "train", ",", "\n", "\"global_step\"", ":", "sv", ".", "global_step", ",", "\n", "}", "\n", "\n", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"discrim_loss\"", "]", "=", "model", ".", "discrim_loss", "\n", "fetches", "[", "\"gen_loss_GAN\"", "]", "=", "model", ".", "gen_loss_GAN", "\n", "fetches", "[", "\"gen_loss_L1\"", "]", "=", "model", ".", "gen_loss_L1", "\n", "# Moha: --------------------", "\n", "fetches", "[", "\"discrim_loss_real\"", "]", "=", "model", ".", "discrim_loss_real", "\n", "fetches", "[", "\"discrim_loss_fake\"", "]", "=", "model", ".", "discrim_loss_fake", "\n", "fetches", "[", "\"gen_loss_total\"", "]", "=", "model", ".", "gen_loss", "\n", "fetches", "[", "\"gen_loss_dice\"", "]", "=", "model", ".", "gen_loss_dice", "\n", "fetches", "[", "\"gen_loss_jaccard\"", "]", "=", "model", ".", "gen_loss_jaccard", "\n", "fetches", "[", "\"gen_loss_Tversky\"", "]", "=", "model", ".", "gen_loss_Tversky", "\n", "\n", "# End MOha", "\n", "\n", "\n", "\n", "", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"summary\"", "]", "=", "sv", ".", "summary_op", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"display\"", "]", "=", "display_fetches", "\n", "\n", "", "results", "=", "sess", ".", "run", "(", "fetches", ",", "options", "=", "options", ",", "run_metadata", "=", "run_metadata", ")", "\n", "\n", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording summary\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "results", "[", "\"summary\"", "]", ",", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving display images\"", ")", "\n", "filesets", "=", "save_images", "(", "results", "[", "\"display\"", "]", ",", "step", "=", "results", "[", "\"global_step\"", "]", ")", "\n", "append_index", "(", "filesets", ",", "step", "=", "True", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording trace\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_run_metadata", "(", "run_metadata", ",", "\"step_%d\"", "%", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "# global_step will have the correct step count if we resume from a checkpoint", "\n", "                    ", "train_epoch", "=", "math", ".", "ceil", "(", "results", "[", "\"global_step\"", "]", "/", "examples", ".", "steps_per_epoch", ")", "\n", "train_step", "=", "(", "results", "[", "\"global_step\"", "]", "-", "1", ")", "%", "examples", ".", "steps_per_epoch", "+", "1", "\n", "rate", "=", "(", "step", "+", "1", ")", "*", "a", ".", "batch_size", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "remaining", "=", "(", "max_steps", "-", "step", ")", "*", "a", ".", "batch_size", "/", "rate", "\n", "print", "(", "'***********************************************'", ")", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "\n", "print", "(", "\"gen_loss_GAN -----------\"", ",", "results", "[", "\"gen_loss_GAN\"", "]", ")", "\n", "print", "(", "\"gen_loss_L1 -----------\"", ",", "results", "[", "\"gen_loss_L1\"", "]", ")", "\n", "print", "(", "\"discrim_loss_total -----------\"", ",", "results", "[", "\"discrim_loss\"", "]", ")", "\n", "\n", "print", "(", "\"discrim_loss_real -----------\"", ",", "results", "[", "\"discrim_loss_real\"", "]", ")", "\n", "print", "(", "\"discrim_loss_fake -----------\"", ",", "results", "[", "\"discrim_loss_fake\"", "]", ")", "\n", "print", "(", "\"gen_loss_total -----------\"", ",", "results", "[", "\"gen_loss_total\"", "]", ")", "\n", "\n", "print", "(", "\"gen_loss_dice -----------\"", ",", "results", "[", "\"gen_loss_dice\"", "]", ")", "\n", "print", "(", "\"gen_loss_jaccard -----------\"", ",", "results", "[", "\"gen_loss_jaccard\"", "]", ")", "\n", "\n", "print", "(", "\"gen_loss_Tversky -----------\"", ",", "results", "[", "\"gen_loss_Tversky\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "save_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "\n", "", "if", "sv", ".", "should_stop", "(", ")", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.preprocess": [[74, 78], ["tensorflow.name_scope"], "function", ["None"], ["def", "preprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess\"", ")", ":", "\n", "# [0, 1] => [-1, 1]", "\n", "        ", "return", "image", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.deprocess": [[80, 84], ["tensorflow.name_scope"], "function", ["None"], ["", "", "def", "deprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess\"", ")", ":", "\n", "# [-1, 1] => [0, 1]", "\n", "        ", "return", "(", "image", "+", "1", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.preprocess_lab": [[86, 93], ["tensorflow.name_scope", "tensorflow.unstack"], "function", ["None"], ["", "", "def", "preprocess_lab", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess_lab\"", ")", ":", "\n", "        ", "L_chan", ",", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "lab", ",", "axis", "=", "2", ")", "\n", "# L_chan: black and white with input range [0, 100]", "\n", "# a_chan/b_chan: color channels with input range ~[-110, 110], not exact", "\n", "# [0, 100] => [-1, 1],  ~[-110, 110] => [-1, 1]", "\n", "return", "[", "L_chan", "/", "50", "-", "1", ",", "a_chan", "/", "110", ",", "b_chan", "/", "110", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.deprocess_lab": [[95, 99], ["tensorflow.name_scope", "tensorflow.stack"], "function", ["None"], ["", "", "def", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess_lab\"", ")", ":", "\n", "# this is axis=3 instead of axis=2 because we process individual images but deprocess batches", "\n", "        ", "return", "tf", ".", "stack", "(", "[", "(", "L_chan", "+", "1", ")", "/", "2", "*", "100", ",", "a_chan", "*", "110", ",", "b_chan", "*", "110", "]", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.augment": [[101, 108], ["tensorflow.unstack", "tensorflow.squeeze", "pix2pix_0_MT.deprocess_lab", "lab_to_rgb"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess_lab", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lab_to_rgb"], ["", "", "def", "augment", "(", "image", ",", "brightness", ")", ":", "\n", "# (a, b) color channels, combine with L channel and convert to rgb", "\n", "    ", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "image", ",", "axis", "=", "3", ")", "\n", "L_chan", "=", "tf", ".", "squeeze", "(", "brightness", ",", "axis", "=", "3", ")", "\n", "lab", "=", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", "\n", "rgb", "=", "lab_to_rgb", "(", "lab", ")", "\n", "return", "rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.discrim_conv": [[110, 113], ["tensorflow.pad", "tensorflow.layers.conv2d", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "discrim_conv", "(", "batch_input", ",", "out_channels", ",", "stride", ")", ":", "\n", "    ", "padded_input", "=", "tf", ".", "pad", "(", "batch_input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"CONSTANT\"", ")", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "padded_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "stride", ",", "stride", ")", ",", "padding", "=", "\"valid\"", ",", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.gen_conv": [[115, 122], ["tensorflow.random_normal_initializer", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d"], "function", ["None"], ["", "def", "gen_conv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.gen_deconv": [[124, 133], ["tensorflow.random_normal_initializer", "tensorflow.image.resize_images", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d_transpose"], "function", ["None"], ["", "", "def", "gen_deconv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "_b", ",", "h", ",", "w", ",", "_c", "=", "batch_input", ".", "shape", "\n", "resized_input", "=", "tf", ".", "image", ".", "resize_images", "(", "batch_input", ",", "[", "h", "*", "2", ",", "w", "*", "2", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "resized_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d_transpose", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.lrelu": [[135, 145], ["tensorflow.name_scope", "tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["", "", "def", "lrelu", "(", "x", ",", "a", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lrelu\"", ")", ":", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: a*x/2 - a*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "        ", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.batchnorm": [[147, 149], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "", "def", "batchnorm", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.dice_coe": [[151, 200], ["pix2pix_0_MT.deprocess", "pix2pix_0_MT.deprocess", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.reduce_sum", "tensorflow.reduce_mean", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "Exception"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "dice_coe", "(", "output", ",", "target", ",", "loss_type", "=", "'jaccard'", ",", "axis", "=", "(", "1", ",", "2", ",", "3", ")", ",", "smooth", "=", "1e-5", ")", ":", "\n", "# Moha: based on code from tensorlayer", "\n", "    ", "\"\"\"Soft dice (Sorensen or Jaccard) coefficient for comparing the similarity\n    of two batch of data, usually be used for binary image segmentation\n    i.e. labels are binary. The coefficient between 0 to 1, 1 means totally match.\n    Parameters\n    -----------\n    output : Tensor\n        A distribution with shape: [batch_size, ....], (any dimensions).\n    target : Tensor\n        The target distribution, format the same with `output`.\n    loss_type : str\n        ``jaccard`` or ``sorensen``, default is ``jaccard``.\n    axis : tuple of int\n        All dimensions are reduced, default ``[1,2,3]``.\n    smooth : float\n        This small value will be added to the numerator and denominator.\n            - If both output and target are empty, it makes sure dice is 1.\n            - If either output or target are empty (all pixels are background), dice = ```smooth/(small_value + smooth)``, then if smooth is very small, dice close to 0 (even the image values lower than the threshold), so in this case, higher smooth can have a higher dice.\n    Examples\n    ---------\n    >>> outputs = tl.act.pixel_wise_softmax(network.outputs)\n    >>> dice_loss = 1 - tl.cost.dice_coe(outputs, y_)\n    \"\"\"", "\n", "\n", "output", "=", "deprocess", "(", "output", ")", "\n", "target", "=", "deprocess", "(", "target", ")", "\n", "\n", "output", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "output", ">", "0.5", ")", ")", "\n", "target", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "target", ">", "0.5", ")", ")", "\n", "\n", "inse", "=", "tf", ".", "reduce_sum", "(", "output", "*", "target", ",", "axis", "=", "axis", ")", "\n", "if", "loss_type", "==", "'jaccard'", ":", "\n", "        ", "l", "=", "tf", ".", "reduce_sum", "(", "output", "*", "output", ",", "axis", "=", "axis", ")", "\n", "r", "=", "tf", ".", "reduce_sum", "(", "target", "*", "target", ",", "axis", "=", "axis", ")", "\n", "", "elif", "loss_type", "==", "'sorensen'", ":", "\n", "        ", "l", "=", "tf", ".", "reduce_sum", "(", "output", ",", "axis", "=", "axis", ")", "\n", "r", "=", "tf", ".", "reduce_sum", "(", "target", ",", "axis", "=", "axis", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Unknow loss_type\"", ")", "\n", "# old axis=[0,1,2,3]", "\n", "# dice = 2 * (inse) / (l + r)", "\n", "# epsilon = 1e-5", "\n", "# dice = tf.clip_by_value(dice, 0, 1.0-epsilon) # if all empty, dice = 1", "\n", "# new haodong", "\n", "", "dice", "=", "(", "2.", "*", "inse", "+", "smooth", ")", "/", "(", "l", "+", "r", "+", "smooth", ")", "\n", "##", "\n", "dice", "=", "tf", ".", "reduce_mean", "(", "dice", ",", "name", "=", "'dice_coe'", ")", "\n", "return", "dice", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.tversky_loss": [[202, 240], ["pix2pix_0_MT.deprocess", "pix2pix_0_MT.deprocess", "tensorflow.contrib.layers.flatten", "tensorflow.contrib.layers.flatten", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.reduce_sum", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "tversky_loss", "(", "labels", ",", "predictions", ",", "alpha", "=", "0.3", ",", "beta", "=", "0.7", ",", "smooth", "=", "1e-10", ")", ":", "\n", "# Moha: based on code from: https://analysiscenter.github.io/radio/_modules/radio/models/tf/losses.html#tversky_loss", "\n", "    ", "\"\"\" Tversky loss function.\n\n    Parameters\n    ----------\n    labels : tf.Tensor\n        tensor containing target mask.\n    predictions : tf.Tensor\n        tensor containing predicted mask.\n    alpha : float\n        real value, weight of '0' class.\n    beta : float\n        real value, weight of '1' class.\n    smooth : float\n        small real value used for avoiding division by zero error.\n\n    Returns\n    -------\n    tf.Tensor\n        tensor containing tversky loss.\n    \"\"\"", "\n", "\n", "labels", "=", "deprocess", "(", "labels", ")", "\n", "predictions", "=", "deprocess", "(", "predictions", ")", "\n", "\n", "labels", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "labels", ")", "\n", "predictions", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "predictions", ")", "\n", "\n", "labels", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "labels", ">", "0.5", ")", ")", "\n", "predictions", "=", "tf", ".", "to_float", "(", "tf", ".", "to_int32", "(", "predictions", ">", "0.5", ")", ")", "\n", "\n", "\n", "truepos", "=", "tf", ".", "reduce_sum", "(", "labels", "*", "predictions", ")", "\n", "fp_and_fn", "=", "(", "alpha", "*", "tf", ".", "reduce_sum", "(", "predictions", "*", "(", "1", "-", "labels", ")", ")", "\n", "+", "beta", "*", "tf", ".", "reduce_sum", "(", "(", "1", "-", "predictions", ")", "*", "labels", ")", ")", "\n", "\n", "return", "(", "truepos", "+", "smooth", ")", "/", "(", "truepos", "+", "smooth", "+", "fp_and_fn", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.create_generator": [[243, 316], ["print", "print", "print", "len", "enumerate", "tensorflow.variable_scope", "pix2pix_0_MT.gen_conv", "layers.append", "print", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.nn.relu", "pix2pix_0_MT.gen_deconv", "tensorflow.tanh", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_0_MT.lrelu", "pix2pix_0_MT.gen_conv", "pix2pix_0_MT.batchnorm", "layers.append", "print", "tensorflow.variable_scope", "tensorflow.nn.relu", "pix2pix_0_MT.gen_deconv", "pix2pix_0_MT.batchnorm", "layers.append", "print", "tensorflow.concat", "tensorflow.nn.dropout", "len"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm"], ["", "def", "create_generator", "(", "generator_inputs", ",", "generator_outputs_channels", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "\n", "print", "(", "'encoder:'", ")", "\n", "print", "(", "generator_inputs", ".", "shape", ")", "\n", "# encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_1\"", ")", ":", "\n", "        ", "output", "=", "gen_conv", "(", "generator_inputs", ",", "a", ".", "ngf", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "a", ".", "ngf", "*", "2", ",", "# encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]", "\n", "a", ".", "ngf", "*", "4", ",", "# encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]", "\n", "]", "\n", "\n", "for", "out_channels", "in", "layer_specs", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]", "\n", "convolved", "=", "gen_conv", "(", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "", "print", "(", "'decoder:'", ")", "\n", "layer_specs", "=", "[", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.0", ")", ",", "# decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "4", ",", "0.0", ")", ",", "# decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]", "\n", "(", "a", ".", "ngf", "*", "2", ",", "0.0", ")", ",", "# decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]", "\n", "(", "a", ".", "ngf", ",", "0.0", ")", ",", "# decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]", "\n", "]", "\n", "\n", "num_encoder_layers", "=", "len", "(", "layers", ")", "\n", "for", "decoder_layer", ",", "(", "out_channels", ",", "dropout", ")", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "skip_layer", "=", "num_encoder_layers", "-", "decoder_layer", "-", "1", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder_%d\"", "%", "(", "skip_layer", "+", "1", ")", ")", ":", "\n", "            ", "if", "decoder_layer", "==", "0", ":", "\n", "# first decoder layer doesn't have skip connections", "\n", "# since it is directly connected to the skip_layer", "\n", "                ", "input", "=", "layers", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "skip_layer", "]", "]", ",", "axis", "=", "3", ")", "\n", "\n", "", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batchnorm", "(", "output", ")", "\n", "\n", "if", "dropout", ">", "0.0", ":", "\n", "                ", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "keep_prob", "=", "1", "-", "dropout", ")", "\n", "\n", "", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "# decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"decoder_1\"", ")", ":", "\n", "        ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "0", "]", "]", ",", "axis", "=", "3", ")", "\n", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "generator_outputs_channels", ")", "\n", "output", "=", "tf", ".", "tanh", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.create_model_MT": [[321, 452], ["tensorflow.concat", "tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "print", "tensorflow.concat", "print", "range", "tensorflow.variable_scope", "int", "pix2pix_0_MT.create_generator", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.abs", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.variable_scope", "pix2pix_0_MT.discrim_conv", "pix2pix_0_MT.lrelu", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_0_MT.discrim_conv", "tensorflow.sigmoid", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_0_MT.create_model_MT.create_discriminator"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_generator", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv"], ["", "def", "create_model_MT", "(", "inputs", ",", "targets_1", ",", "targets_2", ")", ":", "\n", "\n", "    ", "def", "create_discriminator", "(", "discrim_inputs", ",", "discrim_targets", ")", ":", "\n", "        ", "n_layers", "=", "3", "\n", "layers", "=", "[", "]", "\n", "print", "(", "'discriminator:'", ")", "\n", "\n", "# 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]", "\n", "input", "=", "tf", ".", "concat", "(", "[", "discrim_inputs", ",", "discrim_targets", "]", ",", "axis", "=", "3", ")", "\n", "print", "(", "input", ".", "shape", ")", "\n", "# layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"layer_1\"", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "input", ",", "a", ".", "ndf", ",", "stride", "=", "2", ")", "\n", "rectified", "=", "lrelu", "(", "convolved", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]", "\n", "# layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]", "\n", "# layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]", "\n", "", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "                ", "out_channels", "=", "a", ".", "ndf", "*", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "stride", "=", "1", "if", "i", "==", "n_layers", "-", "1", "else", "2", "# last layer here has stride 1", "\n", "convolved", "=", "discrim_conv", "(", "layers", "[", "-", "1", "]", ",", "out_channels", ",", "stride", "=", "stride", ")", "\n", "normalized", "=", "batchnorm", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "rectified", ",", "out_channels", "=", "1", ",", "stride", "=", "1", ")", "\n", "output", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n", "\n", "", "targets", "=", "tf", ".", "concat", "(", "[", "targets_1", ",", "targets_2", "]", ",", "axis", "=", "3", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "        ", "out_channels", "=", "int", "(", "targets", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "outputs", "=", "create_generator", "(", "inputs", ",", "out_channels", ")", "\n", "\n", "# create two copies of discriminator, one for real pairs and one for fake pairs", "\n", "# they share the same underlying variables", "\n", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_real", "=", "create_discriminator", "(", "inputs", ",", "targets", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ",", "reuse", "=", "True", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_fake", "=", "create_discriminator", "(", "inputs", ",", "outputs", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_loss\"", ")", ":", "\n", "# minimizing -tf.log will try to get inputs to 1", "\n", "# predict_real => 1 ", "\n", "# predict_fake => 0", "\n", "        ", "discrim_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "discrim_loss_real", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", ")", ")", "\n", "discrim_loss_fake", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_loss\"", ")", ":", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "        ", "gen_loss_GAN", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_fake", "+", "EPS", ")", ")", "\n", "gen_loss_L1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "targets", "-", "outputs", ")", ")", "\n", "gen_loss_dice", "=", "1", "-", "dice_coe", "(", "outputs", ",", "targets", ",", "loss_type", "=", "'sorensen'", ")", "\n", "gen_loss_jaccard", "=", "1", "-", "dice_coe", "(", "outputs", ",", "targets", ",", "loss_type", "=", "'jaccard'", ")", "\n", "\n", "gen_loss_Tversky", "=", "tf", ".", "abs", "(", "1", "-", "tversky_loss", "(", "targets", ",", "outputs", ")", ")", "\n", "gen_loss", "=", "gen_loss_GAN", "*", "a", ".", "gan_weight", "+", "gen_loss_L1", "*", "a", ".", "l1_weight", "\n", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_train\"", ")", ":", "\n", "        ", "discrim_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"discriminator\"", ")", "]", "\n", "discrim_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "discrim_grads_and_vars", "=", "discrim_optim", ".", "compute_gradients", "(", "discrim_loss", ",", "var_list", "=", "discrim_tvars", ")", "\n", "discrim_train", "=", "discrim_optim", ".", "apply_gradients", "(", "discrim_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_train", "]", ")", ":", "\n", "            ", "gen_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"generator\"", ")", "]", "\n", "gen_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "gen_grads_and_vars", "=", "gen_optim", ".", "compute_gradients", "(", "gen_loss", ",", "var_list", "=", "gen_tvars", ")", "\n", "gen_train", "=", "gen_optim", ".", "apply_gradients", "(", "gen_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "\n", "# orig: ----------------------", "\n", "#update_losses = ema.apply([discrim_loss, gen_loss_GAN, gen_loss_L1])", "\n", "# end orig", "\n", "# Moha: ----------------------", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_loss", ",", "gen_loss_GAN", ",", "gen_loss_L1", ",", "\n", "gen_loss", ",", "discrim_loss_real", ",", "discrim_loss_fake", ",", "gen_loss_jaccard", ",", "\n", "gen_loss_dice", ",", "gen_loss_Tversky", "]", ")", "\n", "\n", "outputs_1", "=", "outputs", "[", ":", ",", ":", ",", ":", ",", ":", "3", "]", "\n", "outputs_2", "=", "outputs", "[", ":", ",", ":", ",", ":", ",", "3", ":", "]", "\n", "# End Moha", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "\n", "return", "Model", "(", "\n", "predict_real", "=", "predict_real", ",", "\n", "predict_fake", "=", "predict_fake", ",", "\n", "\n", "discrim_loss", "=", "ema", ".", "average", "(", "discrim_loss", ")", ",", "\n", "discrim_grads_and_vars", "=", "discrim_grads_and_vars", ",", "\n", "\n", "gen_loss_GAN", "=", "ema", ".", "average", "(", "gen_loss_GAN", ")", ",", "\n", "gen_loss_L1", "=", "ema", ".", "average", "(", "gen_loss_L1", ")", ",", "\n", "gen_grads_and_vars", "=", "gen_grads_and_vars", ",", "\n", "\n", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_train", ")", ",", "\n", "# Noha: -----------------", "\n", "outputs_1", "=", "outputs_1", ",", "\n", "outputs_2", "=", "outputs_2", ",", "\n", "gen_loss", "=", "ema", ".", "average", "(", "gen_loss", ")", ",", "\n", "discrim_loss_fake", "=", "ema", ".", "average", "(", "discrim_loss_fake", ")", ",", "\n", "discrim_loss_real", "=", "ema", ".", "average", "(", "discrim_loss_real", ")", ",", "\n", "gen_loss_jaccard", "=", "ema", ".", "average", "(", "gen_loss_jaccard", ")", ",", "\n", "gen_loss_dice", "=", "ema", ".", "average", "(", "gen_loss_dice", ")", ",", "\n", "gen_loss_Tversky", "=", "ema", ".", "average", "(", "gen_loss_Tversky", ")", "\n", "# End Moha", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.check_image": [[545, 558], ["tensorflow.assert_equal", "list", "tf.identity.set_shape", "tensorflow.control_dependencies", "tensorflow.identity", "ValueError", "tf.identity.get_shape", "tensorflow.shape", "tf.identity.get_shape"], "function", ["None"], ["", "def", "check_image", "(", "image", ")", ":", "\n", "    ", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "image", ")", "[", "-", "1", "]", ",", "3", ",", "message", "=", "\"image must have 3 color channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "        ", "image", "=", "tf", ".", "identity", "(", "image", ")", "\n", "\n", "", "if", "image", ".", "get_shape", "(", ")", ".", "ndims", "not", "in", "(", "3", ",", "4", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"image must be either 3 or 4 dimensions\"", ")", "\n", "\n", "# make the last dimension 3 so that you can unstack the colors", "\n", "", "shape", "=", "list", "(", "image", ".", "get_shape", "(", ")", ")", "\n", "shape", "[", "-", "1", "]", "=", "3", "\n", "image", ".", "set_shape", "(", "shape", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.load_examples": [[559, 651], ["glob.glob", "all", "random.randint", "tensorflow.train.batch", "int", "Examples", "Exception", "os.path.join", "len", "glob.glob", "len", "Exception", "os.path.splitext", "sorted", "sorted", "tensorflow.name_scope", "tensorflow.train.string_input_producer", "tensorflow.WholeFileReader", "tf.WholeFileReader.read", "decode", "tensorflow.image.convert_image_dtype", "tensorflow.assert_equal", "tf.identity.set_shape", "pix2pix_0_MT.preprocess", "pix2pix_0_MT.preprocess", "pix2pix_0_MT.preprocess", "tensorflow.image.resize_images", "tensorflow.cast", "tensorflow.name_scope", "pix2pix_0_MT.load_examples.transform"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess"], ["", "def", "load_examples", "(", ")", ":", "\n", "    ", "if", "a", ".", "input_dir", "is", "None", "or", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "input_dir", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir does not exist\"", ")", "\n", "\n", "", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.jpg\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_jpeg", "\n", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.png\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_png", "\n", "\n", "", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir contains no image files\"", ")", "\n", "\n", "", "def", "get_name", "(", "path", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "\n", "return", "name", "\n", "\n", "# if the image names are numbers, sort by the value rather than asciibetically", "\n", "# having sorted inputs means that the outputs are sorted in test mode", "\n", "", "if", "all", "(", "get_name", "(", "path", ")", ".", "isdigit", "(", ")", "for", "path", "in", "input_paths", ")", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ",", "key", "=", "lambda", "path", ":", "int", "(", "get_name", "(", "path", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"load_images\"", ")", ":", "\n", "        ", "path_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "input_paths", ",", "shuffle", "=", "a", ".", "mode", "==", "\"train\"", ")", "\n", "reader", "=", "tf", ".", "WholeFileReader", "(", ")", "\n", "paths", ",", "contents", "=", "reader", ".", "read", "(", "path_queue", ")", "\n", "raw_input", "=", "decode", "(", "contents", ")", "\n", "raw_input", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "raw_input", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "raw_input", ")", "[", "2", "]", ",", "3", ",", "message", "=", "\"image does not have 3 channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "            ", "raw_input", "=", "tf", ".", "identity", "(", "raw_input", ")", "\n", "\n", "", "raw_input", ".", "set_shape", "(", "[", "None", ",", "None", ",", "3", "]", ")", "\n", "\n", "\n", "# break apart image pair and move to range [-1, 1]", "\n", "width", "=", "tf", ".", "shape", "(", "raw_input", ")", "[", "1", "]", "# [height, width, channels]", "\n", "a_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", ":", "width", "//", "3", ",", ":", "]", ")", "\n", "b_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "width", "//", "3", ":", "2", "*", "width", "//", "3", ",", ":", "]", ")", "\n", "c_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "2", "*", "width", "//", "3", ":", ",", ":", "]", ")", "\n", "\n", "\n", "\n", "", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "        ", "inputs", ",", "targets_1", ",", "targets_2", "=", "[", "a_images", ",", "b_images", ",", "c_images", "]", "\n", "#targets_2=c_images", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "#inputs, targets_1, targets_2 = [b_images, a_images]", "\n", "        ", "print", "(", "\"Error:::: just use AtoB direction\"", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "\n", "# synchronize seed for image operations so that we do the same operations to both", "\n", "# input and output images", "\n", "", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "def", "transform", "(", "image", ")", ":", "\n", "        ", "r", "=", "image", "\n", "if", "a", ".", "flip", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "r", ",", "seed", "=", "seed", ")", "\n", "\n", "# area produces a nice downscaling, but does nearest neighbor for upscaling", "\n", "# assume we're going to be doing downscaling here", "\n", "", "r", "=", "tf", ".", "image", ".", "resize_images", "(", "r", ",", "[", "a", ".", "scale_size", ",", "a", ".", "scale_size", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "AREA", ")", "\n", "\n", "offset", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "2", "]", ",", "0", ",", "a", ".", "scale_size", "-", "CROP_SIZE", "+", "1", ",", "seed", "=", "seed", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "if", "a", ".", "scale_size", ">", "CROP_SIZE", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "r", ",", "offset", "[", "0", "]", ",", "offset", "[", "1", "]", ",", "CROP_SIZE", ",", "CROP_SIZE", ")", "\n", "", "elif", "a", ".", "scale_size", "<", "CROP_SIZE", ":", "\n", "            ", "raise", "Exception", "(", "\"scale size cannot be less than crop size\"", ")", "\n", "", "return", "r", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"input_images\"", ")", ":", "\n", "        ", "input_images", "=", "transform", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"target_images\"", ")", ":", "\n", "        ", "target_1_images", "=", "transform", "(", "targets_1", ")", "\n", "target_2_images", "=", "transform", "(", "targets_2", ")", "\n", "#        target_images=tf.concat([target_1_images,target_2_images],axis=3)", "\n", "\n", "", "paths_batch", ",", "inputs_batch", ",", "targets_1_batch", ",", "targets_2_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "paths", ",", "input_images", ",", "target_1_images", ",", "target_2_images", "]", ",", "batch_size", "=", "a", ".", "batch_size", ")", "\n", "steps_per_epoch", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "input_paths", ")", "/", "a", ".", "batch_size", ")", ")", "\n", "\n", "return", "Examples", "(", "\n", "paths", "=", "paths_batch", ",", "\n", "inputs", "=", "inputs_batch", ",", "\n", "targets_1", "=", "targets_1_batch", ",", "\n", "targets_2", "=", "targets_2_batch", ",", "\n", "count", "=", "len", "(", "input_paths", ")", ",", "\n", "steps_per_epoch", "=", "steps_per_epoch", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.save_images": [[656, 676], ["os.path.join", "enumerate", "os.path.exists", "os.makedirs", "os.path.splitext", "filesets.append", "os.path.basename", "os.path.join", "in_path.decode", "open", "f.write"], "function", ["None"], ["", "def", "save_images", "(", "fetches", ",", "step", "=", "None", ")", ":", "\n", "    ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"images\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "filesets", "=", "[", "]", "\n", "for", "i", ",", "in_path", "in", "enumerate", "(", "fetches", "[", "\"paths\"", "]", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "in_path", ".", "decode", "(", "\"utf8\"", ")", ")", ")", "\n", "fileset", "=", "{", "\"name\"", ":", "name", ",", "\"step\"", ":", "step", "}", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs_1\"", ",", "\"targets_1\"", ",", "\"outputs_2\"", ",", "\"targets_2\"", "]", ":", "\n", "            ", "filename", "=", "name", "+", "\"-\"", "+", "kind", "+", "\".png\"", "\n", "if", "step", "is", "not", "None", ":", "\n", "                ", "filename", "=", "\"%08d-%s\"", "%", "(", "step", ",", "filename", ")", "\n", "", "fileset", "[", "kind", "]", "=", "filename", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "filename", ")", "\n", "contents", "=", "fetches", "[", "kind", "]", "[", "i", "]", "\n", "with", "open", "(", "out_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "contents", ")", "\n", "", "", "filesets", ".", "append", "(", "fileset", ")", "\n", "", "return", "filesets", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.append_index": [[678, 702], ["os.path.join", "os.path.exists", "open", "open", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write"], "function", ["None"], ["", "def", "append_index", "(", "filesets", ",", "step", "=", "False", ")", ":", "\n", "    ", "index_path", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"index.html\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_path", ")", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"a\"", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"w\"", ")", "\n", "index", ".", "write", "(", "\"<html><body><table><tr>\"", ")", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<th>step</th>\"", ")", "\n", "#table construction", "\n", "", "index", ".", "write", "(", "\"<th>name</th><th>input</th><th>output_1</th><th>target_1</th><th>output_2</th><th>target_2</th></tr>\"", ")", "\n", "\n", "", "for", "fileset", "in", "filesets", ":", "\n", "        ", "index", ".", "write", "(", "\"<tr>\"", ")", "\n", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<td>%d</td>\"", "%", "fileset", "[", "\"step\"", "]", ")", "\n", "", "index", ".", "write", "(", "\"<td>%s</td>\"", "%", "fileset", "[", "\"name\"", "]", ")", "\n", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs_1\"", ",", "\"targets_1\"", ",", "\"outputs_2\"", ",", "\"targets_2\"", "]", ":", "\n", "            ", "index", ".", "write", "(", "\"<td><img src='images/%s'></td>\"", "%", "fileset", "[", "kind", "]", ")", "\n", "\n", "", "index", ".", "write", "(", "\"</tr>\"", ")", "\n", "", "return", "index_path", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.main": [[704, 997], ["tensorflow.set_random_seed", "numpy.random.seed", "random.seed", "a._get_kwargs", "pix2pix_0_MT.load_examples", "print", "pix2pix_0_MT.create_model_MT", "pix2pix_0_MT.deprocess", "pix2pix_0_MT.deprocess", "pix2pix_0_MT.deprocess", "pix2pix_0_MT.deprocess", "pix2pix_0_MT.deprocess", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.train.Saver", "tensorflow.train.Supervisor", "random.randint", "os.path.exists", "os.makedirs", "print", "open", "f.write", "tensorflow.placeholder", "tensorflow.decode_base64", "tensorflow.image.decode_png", "tensorflow.cond", "tensorflow.cond", "tensorflow.image.convert_image_dtype", "tf.image.convert_image_dtype.set_shape", "tensorflow.expand_dims", "tensorflow.convert_to_tensor", "tensorflow.placeholder", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.global_variables_initializer", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.image.convert_image_dtype", "tensorflow.name_scope", "pix2pix_0_MT.main.convert"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.load_examples", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0_MT.create_model_MT", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "main", "(", ")", ":", "\n", "    ", "if", "a", ".", "seed", "is", "None", ":", "\n", "        ", "a", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "\n", "", "tf", ".", "set_random_seed", "(", "a", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "a", ".", "output_dir", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", "or", "a", ".", "mode", "==", "\"export\"", ":", "\n", "        ", "if", "a", ".", "checkpoint", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"checkpoint required for test mode\"", ")", "\n", "\n", "# load some options from the checkpoint", "\n", "", "options", "=", "{", "\"which_direction\"", ",", "\"ngf\"", ",", "\"ndf\"", ",", "\"lab_colorization\"", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "checkpoint", ",", "\"options.json\"", ")", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "val", "in", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "in", "options", ":", "\n", "                    ", "print", "(", "\"loaded\"", ",", "key", ",", "\"=\"", ",", "val", ")", "\n", "setattr", "(", "a", ",", "key", ",", "val", ")", "\n", "# disable these features in test mode", "\n", "", "", "", "a", ".", "scale_size", "=", "CROP_SIZE", "\n", "a", ".", "flip", "=", "False", "\n", "\n", "", "for", "k", ",", "v", "in", "a", ".", "_get_kwargs", "(", ")", ":", "\n", "        ", "print", "(", "k", ",", "\"=\"", ",", "v", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"options.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vars", "(", "a", ")", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"export\"", ":", "\n", "# export the generator to a meta graph that can be imported later for standalone generation", "\n", "        ", "if", "a", ".", "lab_colorization", ":", "\n", "            ", "raise", "Exception", "(", "\"export not supported for lab_colorization\"", ")", "\n", "\n", "", "input", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "input_data", "=", "tf", ".", "decode_base64", "(", "input", "[", "0", "]", ")", "\n", "input_image", "=", "tf", ".", "image", ".", "decode_png", "(", "input_data", ")", "\n", "\n", "# remove alpha channel if present", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "4", ")", ",", "lambda", ":", "input_image", "[", ":", ",", ":", ",", ":", "3", "]", ",", "lambda", ":", "input_image", ")", "\n", "# convert grayscale to RGB", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "1", ")", ",", "lambda", ":", "tf", ".", "image", ".", "grayscale_to_rgb", "(", "input_image", ")", ",", "lambda", ":", "input_image", ")", "\n", "# Images that are represented using floating point values are expected to have values in the range [0,1)", "\n", "input_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "input_image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "input_image", ".", "set_shape", "(", "[", "CROP_SIZE", ",", "CROP_SIZE", ",", "3", "]", ")", "\n", "batch_input", "=", "tf", ".", "expand_dims", "(", "input_image", ",", "axis", "=", "0", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "            ", "batch_output", "=", "deprocess", "(", "create_generator", "(", "preprocess", "(", "batch_input", ")", ",", "3", ")", ")", "\n", "\n", "", "output_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "batch_output", ",", "dtype", "=", "tf", ".", "uint8", ")", "[", "0", "]", "\n", "if", "a", ".", "output_filetype", "==", "\"png\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_png", "(", "output_image", ")", "\n", "", "elif", "a", ".", "output_filetype", "==", "\"jpeg\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_jpeg", "(", "output_image", ",", "quality", "=", "80", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid filetype\"", ")", "\n", "", "output", "=", "tf", ".", "convert_to_tensor", "(", "[", "tf", ".", "encode_base64", "(", "output_data", ")", "]", ")", "\n", "\n", "key", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "inputs", "=", "{", "\n", "\"key\"", ":", "key", ".", "name", ",", "\n", "\"input\"", ":", "input", ".", "name", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"inputs\"", ",", "json", ".", "dumps", "(", "inputs", ")", ")", "\n", "outputs", "=", "{", "\n", "\"key\"", ":", "tf", ".", "identity", "(", "key", ")", ".", "name", ",", "\n", "\"output\"", ":", "output", ".", "name", ",", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"outputs\"", ",", "json", ".", "dumps", "(", "outputs", ")", ")", "\n", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "restore_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "export_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "restore_saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "print", "(", "\"exporting model\"", ")", "\n", "export_saver", ".", "export_meta_graph", "(", "filename", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export.meta\"", ")", ")", "\n", "export_saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export\"", ")", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "", "return", "\n", "\n", "", "examples", "=", "load_examples", "(", ")", "\n", "print", "(", "\"examples count = %d\"", "%", "examples", ".", "count", ")", "\n", "\n", "# inputs and targets are [batch_size, height, width, channels]", "\n", "model", "=", "create_model_MT", "(", "examples", ".", "inputs", ",", "examples", ".", "targets_1", ",", "examples", ".", "targets_2", ")", "\n", "\n", "\n", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "targets_1", "=", "deprocess", "(", "examples", ".", "targets_1", ")", "\n", "targets_2", "=", "deprocess", "(", "examples", ".", "targets_2", ")", "\n", "outputs_1", "=", "deprocess", "(", "model", ".", "outputs_1", ")", "\n", "outputs_2", "=", "deprocess", "(", "model", ".", "outputs_2", ")", "\n", "#print(outputs_2.shape)", "\n", "\n", "def", "convert", "(", "image", ")", ":", "\n", "        ", "if", "a", ".", "aspect_ratio", "!=", "1.0", ":", "\n", "# upscale to correct aspect ratio", "\n", "            ", "size", "=", "[", "CROP_SIZE", ",", "int", "(", "round", "(", "CROP_SIZE", "*", "a", ".", "aspect_ratio", ")", ")", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "image", ",", "size", "=", "size", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "\n", "", "return", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "uint8", ",", "saturate", "=", "True", ")", "\n", "\n", "# reverse any processing on images so they can be written to disk or displayed to user", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_inputs\"", ")", ":", "\n", "        ", "converted_inputs", "=", "convert", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_targets\"", ")", ":", "\n", "        ", "converted_targets_1", "=", "convert", "(", "targets_1", ")", "\n", "converted_targets_2", "=", "convert", "(", "targets_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_outputs\"", ")", ":", "\n", "        ", "converted_outputs_1", "=", "convert", "(", "outputs_1", ")", "\n", "converted_outputs_2", "=", "convert", "(", "outputs_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"encode_images\"", ")", ":", "\n", "        ", "display_fetches", "=", "{", "\n", "\"paths\"", ":", "examples", ".", "paths", ",", "\n", "\"inputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_inputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"input_pngs\"", ")", ",", "\n", "\"targets_1\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets_1", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_1_pngs\"", ")", ",", "\n", "\"targets_2\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets_2", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_2_pngs\"", ")", ",", "\n", "\"outputs_1\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs_1", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_1_pngs\"", ")", ",", "\n", "\"outputs_2\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs_2", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_2_pngs\"", ")", ",", "\n", "}", "\n", "\n", "# summaries", "\n", "", "with", "tf", ".", "name_scope", "(", "\"inputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"inputs\"", ",", "converted_inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"targets_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"targets_1\"", ",", "converted_targets_1", ")", "\n", "tf", ".", "summary", ".", "image", "(", "\"targets_2\"", ",", "converted_targets_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"outputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"outputs_1\"", ",", "converted_outputs_1", ")", "\n", "tf", ".", "summary", ".", "image", "(", "\"outputs_2\"", ",", "converted_outputs_2", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_real_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_real\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_real", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_fake_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_fake\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_fake", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss\"", ",", "model", ".", "discrim_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN\"", ",", "model", ".", "gen_loss_GAN", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_L1\"", ",", "model", ".", "gen_loss_L1", ")", "\n", "\n", "# Moha: --------------", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss_real\"", ",", "model", ".", "discrim_loss_real", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss_fake\"", ",", "model", ".", "discrim_loss_fake", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_total\"", ",", "model", ".", "gen_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_dice\"", ",", "model", ".", "gen_loss_dice", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_jaccard\"", ",", "model", ".", "gen_loss_jaccard", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN_Tversky\"", ",", "model", ".", "gen_loss_Tversky", ")", "\n", "\n", "\n", "# End MOha", "\n", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/values\"", ",", "var", ")", "\n", "\n", "", "for", "grad", ",", "var", "in", "model", ".", "discrim_grads_and_vars", "+", "model", ".", "gen_grads_and_vars", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/gradients\"", ",", "grad", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"parameter_count\"", ")", ":", "\n", "        ", "parameter_count", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "v", ")", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1", ")", "\n", "\n", "logdir", "=", "a", ".", "output_dir", "if", "(", "a", ".", "trace_freq", ">", "0", "or", "a", ".", "summary_freq", ">", "0", ")", "else", "None", "\n", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "logdir", "=", "logdir", ",", "save_summaries_secs", "=", "0", ",", "saver", "=", "None", ")", "\n", "with", "sv", ".", "managed_session", "(", ")", "as", "sess", ":", "\n", "        ", "print", "(", "\"parameter_count =\"", ",", "sess", ".", "run", "(", "parameter_count", ")", ")", "\n", "\n", "if", "a", ".", "checkpoint", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "\"loading model was not successfull\"", ")", "\n", "\n", "", "", "max_steps", "=", "2", "**", "32", "\n", "if", "a", ".", "max_epochs", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "examples", ".", "steps_per_epoch", "*", "a", ".", "max_epochs", "\n", "", "if", "a", ".", "max_steps", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "a", ".", "max_steps", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", ":", "\n", "# testing", "\n", "# at most, process the test data once", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "max_steps", "=", "min", "(", "examples", ".", "steps_per_epoch", ",", "max_steps", ")", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "results", "=", "sess", ".", "run", "(", "display_fetches", ")", "\n", "filesets", "=", "save_images", "(", "results", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "filesets", ")", ":", "\n", "                    ", "print", "(", "\"evaluated image\"", ",", "f", "[", "\"name\"", "]", ")", "\n", "", "index_path", "=", "append_index", "(", "filesets", ")", "\n", "", "print", "(", "\"wrote index at\"", ",", "index_path", ")", "\n", "print", "(", "\"rate\"", ",", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "max_steps", ")", "\n", "", "else", ":", "\n", "# training", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "def", "should", "(", "freq", ")", ":", "\n", "                    ", "return", "freq", ">", "0", "and", "(", "(", "step", "+", "1", ")", "%", "freq", "==", "0", "or", "step", "==", "max_steps", "-", "1", ")", "\n", "\n", "", "options", "=", "None", "\n", "run_metadata", "=", "None", "\n", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "options", "=", "tf", ".", "RunOptions", "(", "trace_level", "=", "tf", ".", "RunOptions", ".", "FULL_TRACE", ")", "\n", "run_metadata", "=", "tf", ".", "RunMetadata", "(", ")", "\n", "\n", "", "fetches", "=", "{", "\n", "\"train\"", ":", "model", ".", "train", ",", "\n", "\"global_step\"", ":", "sv", ".", "global_step", ",", "\n", "}", "\n", "\n", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"discrim_loss\"", "]", "=", "model", ".", "discrim_loss", "\n", "fetches", "[", "\"gen_loss_GAN\"", "]", "=", "model", ".", "gen_loss_GAN", "\n", "fetches", "[", "\"gen_loss_L1\"", "]", "=", "model", ".", "gen_loss_L1", "\n", "# Moha: --------------------", "\n", "fetches", "[", "\"discrim_loss_real\"", "]", "=", "model", ".", "discrim_loss_real", "\n", "fetches", "[", "\"discrim_loss_fake\"", "]", "=", "model", ".", "discrim_loss_fake", "\n", "fetches", "[", "\"gen_loss_total\"", "]", "=", "model", ".", "gen_loss", "\n", "fetches", "[", "\"gen_loss_dice\"", "]", "=", "model", ".", "gen_loss_dice", "\n", "fetches", "[", "\"gen_loss_jaccard\"", "]", "=", "model", ".", "gen_loss_jaccard", "\n", "fetches", "[", "\"gen_loss_Tversky\"", "]", "=", "model", ".", "gen_loss_Tversky", "\n", "\n", "# End MOha", "\n", "\n", "\n", "\n", "", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"summary\"", "]", "=", "sv", ".", "summary_op", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"display\"", "]", "=", "display_fetches", "\n", "\n", "", "results", "=", "sess", ".", "run", "(", "fetches", ",", "options", "=", "options", ",", "run_metadata", "=", "run_metadata", ")", "\n", "\n", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording summary\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "results", "[", "\"summary\"", "]", ",", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving display images\"", ")", "\n", "filesets", "=", "save_images", "(", "results", "[", "\"display\"", "]", ",", "step", "=", "results", "[", "\"global_step\"", "]", ")", "\n", "append_index", "(", "filesets", ",", "step", "=", "True", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording trace\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_run_metadata", "(", "run_metadata", ",", "\"step_%d\"", "%", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "# global_step will have the correct step count if we resume from a checkpoint", "\n", "                    ", "train_epoch", "=", "math", ".", "ceil", "(", "results", "[", "\"global_step\"", "]", "/", "examples", ".", "steps_per_epoch", ")", "\n", "train_step", "=", "(", "results", "[", "\"global_step\"", "]", "-", "1", ")", "%", "examples", ".", "steps_per_epoch", "+", "1", "\n", "rate", "=", "(", "step", "+", "1", ")", "*", "a", ".", "batch_size", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "remaining", "=", "(", "max_steps", "-", "step", ")", "*", "a", ".", "batch_size", "/", "rate", "\n", "print", "(", "'***********************************************'", ")", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "\n", "print", "(", "\"gen_loss_GAN -----------\"", ",", "results", "[", "\"gen_loss_GAN\"", "]", ")", "\n", "print", "(", "\"gen_loss_L1 -----------\"", ",", "results", "[", "\"gen_loss_L1\"", "]", ")", "\n", "print", "(", "\"discrim_loss_total -----------\"", ",", "results", "[", "\"discrim_loss\"", "]", ")", "\n", "\n", "print", "(", "\"discrim_loss_real -----------\"", ",", "results", "[", "\"discrim_loss_real\"", "]", ")", "\n", "print", "(", "\"discrim_loss_fake -----------\"", ",", "results", "[", "\"discrim_loss_fake\"", "]", ")", "\n", "print", "(", "\"gen_loss_total -----------\"", ",", "results", "[", "\"gen_loss_total\"", "]", ")", "\n", "\n", "print", "(", "\"gen_loss_dice -----------\"", ",", "results", "[", "\"gen_loss_dice\"", "]", ")", "\n", "print", "(", "\"gen_loss_jaccard -----------\"", ",", "results", "[", "\"gen_loss_jaccard\"", "]", ")", "\n", "\n", "print", "(", "\"gen_loss_Tversky -----------\"", ",", "results", "[", "\"gen_loss_Tversky\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "save_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "\n", "", "if", "sv", ".", "should_stop", "(", ")", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.preprocess": [[62, 66], ["tensorflow.name_scope"], "function", ["None"], ["def", "preprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess\"", ")", ":", "\n", "# [0, 1] => [-1, 1]", "\n", "        ", "return", "image", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.deprocess": [[68, 72], ["tensorflow.name_scope"], "function", ["None"], ["", "", "def", "deprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess\"", ")", ":", "\n", "# [-1, 1] => [0, 1]", "\n", "        ", "return", "(", "image", "+", "1", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.preprocess_lab": [[74, 81], ["tensorflow.name_scope", "tensorflow.unstack"], "function", ["None"], ["", "", "def", "preprocess_lab", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess_lab\"", ")", ":", "\n", "        ", "L_chan", ",", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "lab", ",", "axis", "=", "2", ")", "\n", "# L_chan: black and white with input range [0, 100]", "\n", "# a_chan/b_chan: color channels with input range ~[-110, 110], not exact", "\n", "# [0, 100] => [-1, 1],  ~[-110, 110] => [-1, 1]", "\n", "return", "[", "L_chan", "/", "50", "-", "1", ",", "a_chan", "/", "110", ",", "b_chan", "/", "110", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.deprocess_lab": [[83, 87], ["tensorflow.name_scope", "tensorflow.stack"], "function", ["None"], ["", "", "def", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess_lab\"", ")", ":", "\n", "# this is axis=3 instead of axis=2 because we process individual images but deprocess batches", "\n", "        ", "return", "tf", ".", "stack", "(", "[", "(", "L_chan", "+", "1", ")", "/", "2", "*", "100", ",", "a_chan", "*", "110", ",", "b_chan", "*", "110", "]", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.augment": [[89, 96], ["tensorflow.unstack", "tensorflow.squeeze", "pix2pix_0.deprocess_lab", "pix2pix_0.lab_to_rgb"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess_lab", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lab_to_rgb"], ["", "", "def", "augment", "(", "image", ",", "brightness", ")", ":", "\n", "# (a, b) color channels, combine with L channel and convert to rgb", "\n", "    ", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "image", ",", "axis", "=", "3", ")", "\n", "L_chan", "=", "tf", ".", "squeeze", "(", "brightness", ",", "axis", "=", "3", ")", "\n", "lab", "=", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", "\n", "rgb", "=", "lab_to_rgb", "(", "lab", ")", "\n", "return", "rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.discrim_conv": [[98, 101], ["tensorflow.pad", "tensorflow.layers.conv2d", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "discrim_conv", "(", "batch_input", ",", "out_channels", ",", "stride", ")", ":", "\n", "    ", "padded_input", "=", "tf", ".", "pad", "(", "batch_input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"CONSTANT\"", ")", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "padded_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "stride", ",", "stride", ")", ",", "padding", "=", "\"valid\"", ",", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.gen_conv": [[103, 110], ["tensorflow.random_normal_initializer", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d"], "function", ["None"], ["", "def", "gen_conv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.gen_deconv": [[112, 121], ["tensorflow.random_normal_initializer", "tensorflow.image.resize_images", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d_transpose"], "function", ["None"], ["", "", "def", "gen_deconv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "_b", ",", "h", ",", "w", ",", "_c", "=", "batch_input", ".", "shape", "\n", "resized_input", "=", "tf", ".", "image", ".", "resize_images", "(", "batch_input", ",", "[", "h", "*", "2", ",", "w", "*", "2", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "resized_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d_transpose", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.lrelu": [[123, 133], ["tensorflow.name_scope", "tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["", "", "def", "lrelu", "(", "x", ",", "a", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lrelu\"", ")", ":", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: a*x/2 - a*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "        ", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.batchnorm": [[135, 137], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "", "def", "batchnorm", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.create_generator": [[138, 214], ["print", "print", "print", "len", "enumerate", "tensorflow.variable_scope", "pix2pix_0.gen_conv", "layers.append", "print", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.nn.relu", "pix2pix_0.gen_deconv", "tensorflow.tanh", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_0.lrelu", "pix2pix_0.gen_conv", "pix2pix_0.batchnorm", "layers.append", "print", "tensorflow.variable_scope", "tensorflow.nn.relu", "pix2pix_0.gen_deconv", "pix2pix_0.batchnorm", "layers.append", "print", "tensorflow.concat", "tensorflow.nn.dropout", "len"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm"], ["", "def", "create_generator", "(", "generator_inputs", ",", "generator_outputs_channels", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "\n", "print", "(", "'encoder:'", ")", "\n", "print", "(", "generator_inputs", ".", "shape", ")", "\n", "\n", "# encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_1\"", ")", ":", "\n", "        ", "output", "=", "gen_conv", "(", "generator_inputs", ",", "a", ".", "ngf", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "a", ".", "ngf", "*", "2", ",", "# encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]", "\n", "a", ".", "ngf", "*", "4", ",", "# encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]", "\n", "]", "\n", "\n", "for", "out_channels", "in", "layer_specs", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]", "\n", "convolved", "=", "gen_conv", "(", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "\n", "", "", "print", "(", "'decoder:'", ")", "\n", "\n", "layer_specs", "=", "[", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.0", ")", ",", "# decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "4", ",", "0.0", ")", ",", "# decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]", "\n", "(", "a", ".", "ngf", "*", "2", ",", "0.0", ")", ",", "# decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]", "\n", "(", "a", ".", "ngf", ",", "0.0", ")", ",", "# decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]", "\n", "]", "\n", "\n", "\n", "num_encoder_layers", "=", "len", "(", "layers", ")", "\n", "for", "decoder_layer", ",", "(", "out_channels", ",", "dropout", ")", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "skip_layer", "=", "num_encoder_layers", "-", "decoder_layer", "-", "1", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder_%d\"", "%", "(", "skip_layer", "+", "1", ")", ")", ":", "\n", "            ", "if", "decoder_layer", "==", "0", ":", "\n", "# first decoder layer doesn't have skip connections", "\n", "# since it is directly connected to the skip_layer", "\n", "                ", "input", "=", "layers", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "skip_layer", "]", "]", ",", "axis", "=", "3", ")", "\n", "\n", "", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "out_channels", ")", "\n", "output", "=", "batchnorm", "(", "output", ")", "\n", "\n", "if", "dropout", ">", "0.0", ":", "\n", "                ", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "keep_prob", "=", "1", "-", "dropout", ")", "\n", "\n", "", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "# decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"decoder_1\"", ")", ":", "\n", "        ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "0", "]", "]", ",", "axis", "=", "3", ")", "\n", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "generator_outputs_channels", ")", "\n", "output", "=", "tf", ".", "tanh", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.create_model": [[218, 316], ["tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "print", "tensorflow.concat", "range", "tensorflow.variable_scope", "int", "pix2pix_0.create_generator", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.variable_scope", "pix2pix_0.discrim_conv", "pix2pix_0.lrelu", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_0.discrim_conv", "tensorflow.sigmoid", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_0.create_model.create_discriminator"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_generator", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv"], ["", "def", "create_model", "(", "inputs", ",", "targets", ")", ":", "\n", "\n", "    ", "def", "create_discriminator", "(", "discrim_inputs", ",", "discrim_targets", ")", ":", "\n", "        ", "n_layers", "=", "3", "\n", "layers", "=", "[", "]", "\n", "print", "(", "'discriminator:'", ")", "\n", "\n", "# 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]", "\n", "input", "=", "tf", ".", "concat", "(", "[", "discrim_inputs", ",", "discrim_targets", "]", ",", "axis", "=", "3", ")", "\n", "\n", "# layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"layer_1\"", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "input", ",", "a", ".", "ndf", ",", "stride", "=", "2", ")", "\n", "rectified", "=", "lrelu", "(", "convolved", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]", "\n", "# layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]", "\n", "# layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]", "\n", "", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "                ", "out_channels", "=", "a", ".", "ndf", "*", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "stride", "=", "1", "if", "i", "==", "n_layers", "-", "1", "else", "2", "# last layer here has stride 1", "\n", "convolved", "=", "discrim_conv", "(", "layers", "[", "-", "1", "]", ",", "out_channels", ",", "stride", "=", "stride", ")", "\n", "normalized", "=", "batchnorm", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "\n", "# layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "rectified", ",", "out_channels", "=", "1", ",", "stride", "=", "1", ")", "\n", "output", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "        ", "out_channels", "=", "int", "(", "targets", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "outputs", "=", "create_generator", "(", "inputs", ",", "out_channels", ")", "\n", "\n", "# create two copies of discriminator, one for real pairs and one for fake pairs", "\n", "# they share the same underlying variables", "\n", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_real", "=", "create_discriminator", "(", "inputs", ",", "targets", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ",", "reuse", "=", "True", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_fake", "=", "create_discriminator", "(", "inputs", ",", "outputs", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_loss\"", ")", ":", "\n", "# minimizing -tf.log will try to get inputs to 1", "\n", "# predict_real => 1", "\n", "# predict_fake => 0", "\n", "        ", "discrim_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_loss\"", ")", ":", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "        ", "gen_loss_GAN", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_fake", "+", "EPS", ")", ")", "\n", "gen_loss_L1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "targets", "-", "outputs", ")", ")", "\n", "gen_loss", "=", "gen_loss_GAN", "*", "a", ".", "gan_weight", "+", "gen_loss_L1", "*", "a", ".", "l1_weight", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_train\"", ")", ":", "\n", "        ", "discrim_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"discriminator\"", ")", "]", "\n", "discrim_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "discrim_grads_and_vars", "=", "discrim_optim", ".", "compute_gradients", "(", "discrim_loss", ",", "var_list", "=", "discrim_tvars", ")", "\n", "discrim_train", "=", "discrim_optim", ".", "apply_gradients", "(", "discrim_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_train", "]", ")", ":", "\n", "            ", "gen_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"generator\"", ")", "]", "\n", "gen_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "gen_grads_and_vars", "=", "gen_optim", ".", "compute_gradients", "(", "gen_loss", ",", "var_list", "=", "gen_tvars", ")", "\n", "gen_train", "=", "gen_optim", ".", "apply_gradients", "(", "gen_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_loss", ",", "gen_loss_GAN", ",", "gen_loss_L1", "]", ")", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "return", "Model", "(", "\n", "predict_real", "=", "predict_real", ",", "\n", "predict_fake", "=", "predict_fake", ",", "\n", "discrim_loss", "=", "ema", ".", "average", "(", "discrim_loss", ")", ",", "\n", "discrim_grads_and_vars", "=", "discrim_grads_and_vars", ",", "\n", "gen_loss_GAN", "=", "ema", ".", "average", "(", "gen_loss_GAN", ")", ",", "\n", "gen_loss_L1", "=", "ema", ".", "average", "(", "gen_loss_L1", ")", ",", "\n", "gen_grads_and_vars", "=", "gen_grads_and_vars", ",", "\n", "outputs", "=", "outputs", ",", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_train", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.check_image": [[319, 332], ["tensorflow.assert_equal", "list", "tf.identity.set_shape", "tensorflow.control_dependencies", "tensorflow.identity", "ValueError", "tf.identity.get_shape", "tensorflow.shape", "tf.identity.get_shape"], "function", ["None"], ["", "def", "check_image", "(", "image", ")", ":", "\n", "    ", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "image", ")", "[", "-", "1", "]", ",", "3", ",", "message", "=", "\"image must have 3 color channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "        ", "image", "=", "tf", ".", "identity", "(", "image", ")", "\n", "\n", "", "if", "image", ".", "get_shape", "(", ")", ".", "ndims", "not", "in", "(", "3", ",", "4", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"image must be either 3 or 4 dimensions\"", ")", "\n", "\n", "# make the last dimension 3 so that you can unstack the colors", "\n", "", "shape", "=", "list", "(", "image", ".", "get_shape", "(", ")", ")", "\n", "shape", "[", "-", "1", "]", "=", "3", "\n", "image", ".", "set_shape", "(", "shape", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.rgb_to_lab": [[334, 373], ["tensorflow.name_scope", "pix2pix_0.check_image", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.name_scope", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.matmul", "tensorflow.name_scope", "tensorflow.multiply", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.shape", "tensorflow.matmul", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.check_image"], ["", "def", "rgb_to_lab", "(", "srgb", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"rgb_to_lab\"", ")", ":", "\n", "        ", "srgb", "=", "check_image", "(", "srgb", ")", "\n", "srgb_pixels", "=", "tf", ".", "reshape", "(", "srgb", ",", "[", "-", "1", ",", "3", "]", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"srgb_to_xyz\"", ")", ":", "\n", "            ", "linear_mask", "=", "tf", ".", "cast", "(", "srgb_pixels", "<=", "0.04045", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "srgb_pixels", ">", "0.04045", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "rgb_pixels", "=", "(", "srgb_pixels", "/", "12.92", "*", "linear_mask", ")", "+", "(", "(", "(", "srgb_pixels", "+", "0.055", ")", "/", "1.055", ")", "**", "2.4", ")", "*", "exponential_mask", "\n", "rgb_to_xyz", "=", "tf", ".", "constant", "(", "[", "\n", "#    X        Y          Z", "\n", "[", "0.412453", ",", "0.212671", ",", "0.019334", "]", ",", "# R", "\n", "[", "0.357580", ",", "0.715160", ",", "0.119193", "]", ",", "# G", "\n", "[", "0.180423", ",", "0.072169", ",", "0.950227", "]", ",", "# B", "\n", "]", ")", "\n", "xyz_pixels", "=", "tf", ".", "matmul", "(", "rgb_pixels", ",", "rgb_to_xyz", ")", "\n", "\n", "# https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions", "\n", "", "with", "tf", ".", "name_scope", "(", "\"xyz_to_cielab\"", ")", ":", "\n", "# convert to fx = f(X/Xn), fy = f(Y/Yn), fz = f(Z/Zn)", "\n", "\n", "# normalize for D65 white point", "\n", "            ", "xyz_normalized_pixels", "=", "tf", ".", "multiply", "(", "xyz_pixels", ",", "[", "1", "/", "0.950456", ",", "1.0", ",", "1", "/", "1.088754", "]", ")", "\n", "\n", "epsilon", "=", "6", "/", "29", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "xyz_normalized_pixels", "<=", "(", "epsilon", "**", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "xyz_normalized_pixels", ">", "(", "epsilon", "**", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "fxfyfz_pixels", "=", "(", "xyz_normalized_pixels", "/", "(", "3", "*", "epsilon", "**", "2", ")", "+", "4", "/", "29", ")", "*", "linear_mask", "+", "(", "xyz_normalized_pixels", "**", "(", "1", "/", "3", ")", ")", "*", "exponential_mask", "\n", "\n", "# convert to lab", "\n", "fxfyfz_to_lab", "=", "tf", ".", "constant", "(", "[", "\n", "#  l       a       b", "\n", "[", "0.0", ",", "500.0", ",", "0.0", "]", ",", "# fx", "\n", "[", "116.0", ",", "-", "500.0", ",", "200.0", "]", ",", "# fy", "\n", "[", "0.0", ",", "0.0", ",", "-", "200.0", "]", ",", "# fz", "\n", "]", ")", "\n", "lab_pixels", "=", "tf", ".", "matmul", "(", "fxfyfz_pixels", ",", "fxfyfz_to_lab", ")", "+", "tf", ".", "constant", "(", "[", "-", "16.0", ",", "0.0", ",", "0.0", "]", ")", "\n", "\n", "", "return", "tf", ".", "reshape", "(", "lab_pixels", ",", "tf", ".", "shape", "(", "srgb", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.lab_to_rgb": [[375, 415], ["tensorflow.name_scope", "pix2pix_0.check_image", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.name_scope", "tensorflow.constant", "tensorflow.matmul", "tensorflow.cast", "tensorflow.cast", "tensorflow.multiply", "tensorflow.name_scope", "tensorflow.constant", "tensorflow.matmul", "tensorflow.clip_by_value", "tensorflow.cast", "tensorflow.cast", "tensorflow.shape", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.check_image"], ["", "", "def", "lab_to_rgb", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lab_to_rgb\"", ")", ":", "\n", "        ", "lab", "=", "check_image", "(", "lab", ")", "\n", "lab_pixels", "=", "tf", ".", "reshape", "(", "lab", ",", "[", "-", "1", ",", "3", "]", ")", "\n", "\n", "# https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions", "\n", "with", "tf", ".", "name_scope", "(", "\"cielab_to_xyz\"", ")", ":", "\n", "# convert to fxfyfz", "\n", "            ", "lab_to_fxfyfz", "=", "tf", ".", "constant", "(", "[", "\n", "#   fx      fy        fz", "\n", "[", "1", "/", "116.0", ",", "1", "/", "116.0", ",", "1", "/", "116.0", "]", ",", "# l", "\n", "[", "1", "/", "500.0", ",", "0.0", ",", "0.0", "]", ",", "# a", "\n", "[", "0.0", ",", "0.0", ",", "-", "1", "/", "200.0", "]", ",", "# b", "\n", "]", ")", "\n", "fxfyfz_pixels", "=", "tf", ".", "matmul", "(", "lab_pixels", "+", "tf", ".", "constant", "(", "[", "16.0", ",", "0.0", ",", "0.0", "]", ")", ",", "lab_to_fxfyfz", ")", "\n", "\n", "# convert to xyz", "\n", "epsilon", "=", "6", "/", "29", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "fxfyfz_pixels", "<=", "epsilon", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "fxfyfz_pixels", ">", "epsilon", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "xyz_pixels", "=", "(", "3", "*", "epsilon", "**", "2", "*", "(", "fxfyfz_pixels", "-", "4", "/", "29", ")", ")", "*", "linear_mask", "+", "(", "fxfyfz_pixels", "**", "3", ")", "*", "exponential_mask", "\n", "\n", "# denormalize for D65 white point", "\n", "xyz_pixels", "=", "tf", ".", "multiply", "(", "xyz_pixels", ",", "[", "0.950456", ",", "1.0", ",", "1.088754", "]", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"xyz_to_srgb\"", ")", ":", "\n", "            ", "xyz_to_rgb", "=", "tf", ".", "constant", "(", "[", "\n", "#     r           g          b", "\n", "[", "3.2404542", ",", "-", "0.9692660", ",", "0.0556434", "]", ",", "# x", "\n", "[", "-", "1.5371385", ",", "1.8760108", ",", "-", "0.2040259", "]", ",", "# y", "\n", "[", "-", "0.4985314", ",", "0.0415560", ",", "1.0572252", "]", ",", "# z", "\n", "]", ")", "\n", "rgb_pixels", "=", "tf", ".", "matmul", "(", "xyz_pixels", ",", "xyz_to_rgb", ")", "\n", "# avoid a slightly negative number messing up the conversion", "\n", "rgb_pixels", "=", "tf", ".", "clip_by_value", "(", "rgb_pixels", ",", "0.0", ",", "1.0", ")", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "rgb_pixels", "<=", "0.0031308", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "rgb_pixels", ">", "0.0031308", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "srgb_pixels", "=", "(", "rgb_pixels", "*", "12.92", "*", "linear_mask", ")", "+", "(", "(", "rgb_pixels", "**", "(", "1", "/", "2.4", ")", "*", "1.055", ")", "-", "0.055", ")", "*", "exponential_mask", "\n", "\n", "", "return", "tf", ".", "reshape", "(", "srgb_pixels", ",", "tf", ".", "shape", "(", "lab", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.load_examples": [[417, 507], ["glob.glob", "all", "random.randint", "tensorflow.train.batch", "int", "Examples", "Exception", "os.path.join", "len", "glob.glob", "len", "Exception", "os.path.splitext", "sorted", "sorted", "tensorflow.name_scope", "tensorflow.train.string_input_producer", "tensorflow.WholeFileReader", "tf.WholeFileReader.read", "decode", "tensorflow.image.convert_image_dtype", "tensorflow.assert_equal", "tf.identity.set_shape", "tensorflow.image.resize_images", "tensorflow.cast", "tensorflow.name_scope", "pix2pix_0.load_examples.transform"], "function", ["None"], ["", "", "def", "load_examples", "(", ")", ":", "\n", "    ", "if", "a", ".", "input_dir", "is", "None", "or", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "input_dir", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir does not exist\"", ")", "\n", "\n", "", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.jpg\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_jpeg", "\n", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.png\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_png", "\n", "\n", "", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir contains no image files\"", ")", "\n", "\n", "", "def", "get_name", "(", "path", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "\n", "return", "name", "\n", "\n", "# if the image names are numbers, sort by the value rather than asciibetically", "\n", "# having sorted inputs means that the outputs are sorted in test mode", "\n", "", "if", "all", "(", "get_name", "(", "path", ")", ".", "isdigit", "(", ")", "for", "path", "in", "input_paths", ")", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ",", "key", "=", "lambda", "path", ":", "int", "(", "get_name", "(", "path", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"load_images\"", ")", ":", "\n", "        ", "path_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "input_paths", ",", "shuffle", "=", "a", ".", "mode", "==", "\"train\"", ")", "\n", "reader", "=", "tf", ".", "WholeFileReader", "(", ")", "\n", "paths", ",", "contents", "=", "reader", ".", "read", "(", "path_queue", ")", "\n", "raw_input", "=", "decode", "(", "contents", ")", "\n", "raw_input", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "raw_input", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "raw_input", ")", "[", "2", "]", ",", "3", ",", "message", "=", "\"image does not have 3 channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "            ", "raw_input", "=", "tf", ".", "identity", "(", "raw_input", ")", "\n", "\n", "", "raw_input", ".", "set_shape", "(", "[", "None", ",", "None", ",", "3", "]", ")", "\n", "\n", "if", "a", ".", "lab_colorization", ":", "\n", "# load color and brightness from image, no B image exists here", "\n", "            ", "lab", "=", "rgb_to_lab", "(", "raw_input", ")", "\n", "L_chan", ",", "a_chan", ",", "b_chan", "=", "preprocess_lab", "(", "lab", ")", "\n", "a_images", "=", "tf", ".", "expand_dims", "(", "L_chan", ",", "axis", "=", "2", ")", "\n", "b_images", "=", "tf", ".", "stack", "(", "[", "a_chan", ",", "b_chan", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "# break apart image pair and move to range [-1, 1]", "\n", "            ", "width", "=", "tf", ".", "shape", "(", "raw_input", ")", "[", "1", "]", "# [height, width, channels]", "\n", "a_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", ":", "width", "//", "2", ",", ":", "]", ")", "\n", "b_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "width", "//", "2", ":", ",", ":", "]", ")", "\n", "\n", "", "", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "        ", "inputs", ",", "targets", "=", "[", "a_images", ",", "b_images", "]", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "        ", "inputs", ",", "targets", "=", "[", "b_images", ",", "a_images", "]", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "\n", "# synchronize seed for image operations so that we do the same operations to both", "\n", "# input and output images", "\n", "", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "def", "transform", "(", "image", ")", ":", "\n", "        ", "r", "=", "image", "\n", "if", "a", ".", "flip", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "r", ",", "seed", "=", "seed", ")", "\n", "\n", "# area produces a nice downscaling, but does nearest neighbor for upscaling", "\n", "# assume we're going to be doing downscaling here", "\n", "", "r", "=", "tf", ".", "image", ".", "resize_images", "(", "r", ",", "[", "a", ".", "scale_size", ",", "a", ".", "scale_size", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "AREA", ")", "\n", "\n", "offset", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "2", "]", ",", "0", ",", "a", ".", "scale_size", "-", "CROP_SIZE", "+", "1", ",", "seed", "=", "seed", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "if", "a", ".", "scale_size", ">", "CROP_SIZE", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "r", ",", "offset", "[", "0", "]", ",", "offset", "[", "1", "]", ",", "CROP_SIZE", ",", "CROP_SIZE", ")", "\n", "", "elif", "a", ".", "scale_size", "<", "CROP_SIZE", ":", "\n", "            ", "raise", "Exception", "(", "\"scale size cannot be less than crop size\"", ")", "\n", "", "return", "r", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"input_images\"", ")", ":", "\n", "        ", "input_images", "=", "transform", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"target_images\"", ")", ":", "\n", "        ", "target_images", "=", "transform", "(", "targets", ")", "\n", "\n", "", "paths_batch", ",", "inputs_batch", ",", "targets_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "paths", ",", "input_images", ",", "target_images", "]", ",", "batch_size", "=", "a", ".", "batch_size", ")", "\n", "steps_per_epoch", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "input_paths", ")", "/", "a", ".", "batch_size", ")", ")", "\n", "\n", "return", "Examples", "(", "\n", "paths", "=", "paths_batch", ",", "\n", "inputs", "=", "inputs_batch", ",", "\n", "targets", "=", "targets_batch", ",", "\n", "count", "=", "len", "(", "input_paths", ")", ",", "\n", "steps_per_epoch", "=", "steps_per_epoch", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.save_images": [[512, 532], ["os.path.join", "enumerate", "os.path.exists", "os.makedirs", "os.path.splitext", "filesets.append", "os.path.basename", "os.path.join", "in_path.decode", "open", "f.write"], "function", ["None"], ["", "def", "save_images", "(", "fetches", ",", "step", "=", "None", ")", ":", "\n", "    ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"images\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "filesets", "=", "[", "]", "\n", "for", "i", ",", "in_path", "in", "enumerate", "(", "fetches", "[", "\"paths\"", "]", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "in_path", ".", "decode", "(", "\"utf8\"", ")", ")", ")", "\n", "fileset", "=", "{", "\"name\"", ":", "name", ",", "\"step\"", ":", "step", "}", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs\"", ",", "\"targets\"", "]", ":", "\n", "            ", "filename", "=", "name", "+", "\"-\"", "+", "kind", "+", "\".png\"", "\n", "if", "step", "is", "not", "None", ":", "\n", "                ", "filename", "=", "\"%08d-%s\"", "%", "(", "step", ",", "filename", ")", "\n", "", "fileset", "[", "kind", "]", "=", "filename", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "filename", ")", "\n", "contents", "=", "fetches", "[", "kind", "]", "[", "i", "]", "\n", "with", "open", "(", "out_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "contents", ")", "\n", "", "", "filesets", ".", "append", "(", "fileset", ")", "\n", "", "return", "filesets", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.append_index": [[534, 557], ["os.path.join", "os.path.exists", "open", "open", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write"], "function", ["None"], ["", "def", "append_index", "(", "filesets", ",", "step", "=", "False", ")", ":", "\n", "    ", "index_path", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"index.html\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_path", ")", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"a\"", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"w\"", ")", "\n", "index", ".", "write", "(", "\"<html><body><table><tr>\"", ")", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<th>step</th>\"", ")", "\n", "", "index", ".", "write", "(", "\"<th>name</th><th>input</th><th>output</th><th>target</th></tr>\"", ")", "\n", "\n", "", "for", "fileset", "in", "filesets", ":", "\n", "        ", "index", ".", "write", "(", "\"<tr>\"", ")", "\n", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<td>%d</td>\"", "%", "fileset", "[", "\"step\"", "]", ")", "\n", "", "index", ".", "write", "(", "\"<td>%s</td>\"", "%", "fileset", "[", "\"name\"", "]", ")", "\n", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs\"", ",", "\"targets\"", "]", ":", "\n", "            ", "index", ".", "write", "(", "\"<td><img src='images/%s'></td>\"", "%", "fileset", "[", "kind", "]", ")", "\n", "\n", "", "index", ".", "write", "(", "\"</tr>\"", ")", "\n", "", "return", "index_path", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_0.main": [[559, 824], ["tensorflow.set_random_seed", "numpy.random.seed", "random.seed", "a._get_kwargs", "pix2pix_0.load_examples", "print", "pix2pix_0.create_model", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.train.Saver", "tensorflow.train.Supervisor", "random.randint", "os.path.exists", "os.makedirs", "print", "open", "f.write", "tensorflow.placeholder", "tensorflow.decode_base64", "tensorflow.image.decode_png", "tensorflow.cond", "tensorflow.cond", "tensorflow.image.convert_image_dtype", "tf.image.convert_image_dtype.set_shape", "tensorflow.expand_dims", "tensorflow.convert_to_tensor", "tensorflow.placeholder", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.global_variables_initializer", "tensorflow.train.Saver", "tensorflow.train.Saver", "pix2pix_0.deprocess", "pix2pix_0.deprocess", "pix2pix_0.deprocess", "tensorflow.image.convert_image_dtype", "tensorflow.name_scope", "pix2pix_0.main.convert"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.load_examples", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_model", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "main", "(", ")", ":", "\n", "    ", "if", "a", ".", "seed", "is", "None", ":", "\n", "        ", "a", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "\n", "", "tf", ".", "set_random_seed", "(", "a", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "a", ".", "output_dir", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", "or", "a", ".", "mode", "==", "\"export\"", ":", "\n", "        ", "if", "a", ".", "checkpoint", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"checkpoint required for test mode\"", ")", "\n", "\n", "# load some options from the checkpoint", "\n", "", "options", "=", "{", "\"which_direction\"", ",", "\"ngf\"", ",", "\"ndf\"", ",", "\"lab_colorization\"", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "checkpoint", ",", "\"options.json\"", ")", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "val", "in", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "in", "options", ":", "\n", "                    ", "print", "(", "\"loaded\"", ",", "key", ",", "\"=\"", ",", "val", ")", "\n", "setattr", "(", "a", ",", "key", ",", "val", ")", "\n", "# disable these features in test mode", "\n", "", "", "", "a", ".", "scale_size", "=", "CROP_SIZE", "\n", "a", ".", "flip", "=", "False", "\n", "\n", "", "for", "k", ",", "v", "in", "a", ".", "_get_kwargs", "(", ")", ":", "\n", "        ", "print", "(", "k", ",", "\"=\"", ",", "v", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"options.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vars", "(", "a", ")", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"export\"", ":", "\n", "# export the generator to a meta graph that can be imported later for standalone generation", "\n", "        ", "if", "a", ".", "lab_colorization", ":", "\n", "            ", "raise", "Exception", "(", "\"export not supported for lab_colorization\"", ")", "\n", "\n", "", "input", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "input_data", "=", "tf", ".", "decode_base64", "(", "input", "[", "0", "]", ")", "\n", "input_image", "=", "tf", ".", "image", ".", "decode_png", "(", "input_data", ")", "\n", "\n", "# remove alpha channel if present", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "4", ")", ",", "lambda", ":", "input_image", "[", ":", ",", ":", ",", ":", "3", "]", ",", "lambda", ":", "input_image", ")", "\n", "# convert grayscale to RGB", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "1", ")", ",", "lambda", ":", "tf", ".", "image", ".", "grayscale_to_rgb", "(", "input_image", ")", ",", "lambda", ":", "input_image", ")", "\n", "\n", "input_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "input_image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "input_image", ".", "set_shape", "(", "[", "CROP_SIZE", ",", "CROP_SIZE", ",", "3", "]", ")", "\n", "batch_input", "=", "tf", ".", "expand_dims", "(", "input_image", ",", "axis", "=", "0", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "            ", "batch_output", "=", "deprocess", "(", "create_generator", "(", "preprocess", "(", "batch_input", ")", ",", "3", ")", ")", "\n", "\n", "", "output_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "batch_output", ",", "dtype", "=", "tf", ".", "uint8", ")", "[", "0", "]", "\n", "if", "a", ".", "output_filetype", "==", "\"png\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_png", "(", "output_image", ")", "\n", "", "elif", "a", ".", "output_filetype", "==", "\"jpeg\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_jpeg", "(", "output_image", ",", "quality", "=", "80", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid filetype\"", ")", "\n", "", "output", "=", "tf", ".", "convert_to_tensor", "(", "[", "tf", ".", "encode_base64", "(", "output_data", ")", "]", ")", "\n", "\n", "key", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "inputs", "=", "{", "\n", "\"key\"", ":", "key", ".", "name", ",", "\n", "\"input\"", ":", "input", ".", "name", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"inputs\"", ",", "json", ".", "dumps", "(", "inputs", ")", ")", "\n", "outputs", "=", "{", "\n", "\"key\"", ":", "tf", ".", "identity", "(", "key", ")", ".", "name", ",", "\n", "\"output\"", ":", "output", ".", "name", ",", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"outputs\"", ",", "json", ".", "dumps", "(", "outputs", ")", ")", "\n", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "restore_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "export_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "restore_saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "print", "(", "\"exporting model\"", ")", "\n", "export_saver", ".", "export_meta_graph", "(", "filename", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export.meta\"", ")", ")", "\n", "export_saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export\"", ")", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "", "return", "\n", "\n", "", "examples", "=", "load_examples", "(", ")", "\n", "print", "(", "\"examples count = %d\"", "%", "examples", ".", "count", ")", "\n", "\n", "# inputs and targets are [batch_size, height, width, channels]", "\n", "model", "=", "create_model", "(", "examples", ".", "inputs", ",", "examples", ".", "targets", ")", "\n", "\n", "# undo colorization splitting on images that we use for display/output", "\n", "if", "a", ".", "lab_colorization", ":", "\n", "        ", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "# inputs is brightness, this will be handled fine as a grayscale image", "\n", "# need to augment targets and outputs with brightness", "\n", "            ", "targets", "=", "augment", "(", "examples", ".", "targets", ",", "examples", ".", "inputs", ")", "\n", "outputs", "=", "augment", "(", "model", ".", "outputs", ",", "examples", ".", "inputs", ")", "\n", "# inputs can be deprocessed normally and handled as if they are single channel", "\n", "# grayscale images", "\n", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "# inputs will be color channels only, get brightness from targets", "\n", "            ", "inputs", "=", "augment", "(", "examples", ".", "inputs", ",", "examples", ".", "targets", ")", "\n", "targets", "=", "deprocess", "(", "examples", ".", "targets", ")", "\n", "outputs", "=", "deprocess", "(", "model", ".", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "", "", "else", ":", "\n", "        ", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "targets", "=", "deprocess", "(", "examples", ".", "targets", ")", "\n", "outputs", "=", "deprocess", "(", "model", ".", "outputs", ")", "\n", "\n", "", "def", "convert", "(", "image", ")", ":", "\n", "        ", "if", "a", ".", "aspect_ratio", "!=", "1.0", ":", "\n", "# upscale to correct aspect ratio", "\n", "            ", "size", "=", "[", "CROP_SIZE", ",", "int", "(", "round", "(", "CROP_SIZE", "*", "a", ".", "aspect_ratio", ")", ")", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "image", ",", "size", "=", "size", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "\n", "", "return", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "uint8", ",", "saturate", "=", "True", ")", "\n", "\n", "# reverse any processing on images so they can be written to disk or displayed to user", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_inputs\"", ")", ":", "\n", "        ", "converted_inputs", "=", "convert", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_targets\"", ")", ":", "\n", "        ", "converted_targets", "=", "convert", "(", "targets", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_outputs\"", ")", ":", "\n", "        ", "converted_outputs", "=", "convert", "(", "outputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"encode_images\"", ")", ":", "\n", "        ", "display_fetches", "=", "{", "\n", "\"paths\"", ":", "examples", ".", "paths", ",", "\n", "\"inputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_inputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"input_pngs\"", ")", ",", "\n", "\"targets\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_pngs\"", ")", ",", "\n", "\"outputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_pngs\"", ")", ",", "\n", "}", "\n", "\n", "# summaries", "\n", "", "with", "tf", ".", "name_scope", "(", "\"inputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"inputs\"", ",", "converted_inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"targets_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"targets\"", ",", "converted_targets", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"outputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"outputs\"", ",", "converted_outputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_real_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_real\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_real", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_fake_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_fake\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_fake", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss\"", ",", "model", ".", "discrim_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN\"", ",", "model", ".", "gen_loss_GAN", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_L1\"", ",", "model", ".", "gen_loss_L1", ")", "\n", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/values\"", ",", "var", ")", "\n", "\n", "", "for", "grad", ",", "var", "in", "model", ".", "discrim_grads_and_vars", "+", "model", ".", "gen_grads_and_vars", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/gradients\"", ",", "grad", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"parameter_count\"", ")", ":", "\n", "        ", "parameter_count", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "v", ")", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1", ")", "\n", "\n", "logdir", "=", "a", ".", "output_dir", "if", "(", "a", ".", "trace_freq", ">", "0", "or", "a", ".", "summary_freq", ">", "0", ")", "else", "None", "\n", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "logdir", "=", "logdir", ",", "save_summaries_secs", "=", "0", ",", "saver", "=", "None", ")", "\n", "with", "sv", ".", "managed_session", "(", ")", "as", "sess", ":", "\n", "        ", "print", "(", "\"parameter_count =\"", ",", "sess", ".", "run", "(", "parameter_count", ")", ")", "\n", "\n", "if", "a", ".", "checkpoint", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "\n", "", "max_steps", "=", "2", "**", "32", "\n", "if", "a", ".", "max_epochs", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "examples", ".", "steps_per_epoch", "*", "a", ".", "max_epochs", "\n", "", "if", "a", ".", "max_steps", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "a", ".", "max_steps", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", ":", "\n", "# testing", "\n", "# at most, process the test data once", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "max_steps", "=", "min", "(", "examples", ".", "steps_per_epoch", ",", "max_steps", ")", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "results", "=", "sess", ".", "run", "(", "display_fetches", ")", "\n", "filesets", "=", "save_images", "(", "results", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "filesets", ")", ":", "\n", "                    ", "print", "(", "\"evaluated image\"", ",", "f", "[", "\"name\"", "]", ")", "\n", "", "index_path", "=", "append_index", "(", "filesets", ")", "\n", "", "print", "(", "\"wrote index at\"", ",", "index_path", ")", "\n", "print", "(", "\"rate\"", ",", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "max_steps", ")", "\n", "", "else", ":", "\n", "# training", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "def", "should", "(", "freq", ")", ":", "\n", "                    ", "return", "freq", ">", "0", "and", "(", "(", "step", "+", "1", ")", "%", "freq", "==", "0", "or", "step", "==", "max_steps", "-", "1", ")", "\n", "\n", "", "options", "=", "None", "\n", "run_metadata", "=", "None", "\n", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "options", "=", "tf", ".", "RunOptions", "(", "trace_level", "=", "tf", ".", "RunOptions", ".", "FULL_TRACE", ")", "\n", "run_metadata", "=", "tf", ".", "RunMetadata", "(", ")", "\n", "\n", "", "fetches", "=", "{", "\n", "\"train\"", ":", "model", ".", "train", ",", "\n", "\"global_step\"", ":", "sv", ".", "global_step", ",", "\n", "}", "\n", "\n", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"discrim_loss\"", "]", "=", "model", ".", "discrim_loss", "\n", "fetches", "[", "\"gen_loss_GAN\"", "]", "=", "model", ".", "gen_loss_GAN", "\n", "fetches", "[", "\"gen_loss_L1\"", "]", "=", "model", ".", "gen_loss_L1", "\n", "\n", "", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"summary\"", "]", "=", "sv", ".", "summary_op", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"display\"", "]", "=", "display_fetches", "\n", "\n", "", "results", "=", "sess", ".", "run", "(", "fetches", ",", "options", "=", "options", ",", "run_metadata", "=", "run_metadata", ")", "\n", "\n", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording summary\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "results", "[", "\"summary\"", "]", ",", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving display images\"", ")", "\n", "filesets", "=", "save_images", "(", "results", "[", "\"display\"", "]", ",", "step", "=", "results", "[", "\"global_step\"", "]", ")", "\n", "append_index", "(", "filesets", ",", "step", "=", "True", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording trace\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_run_metadata", "(", "run_metadata", ",", "\"step_%d\"", "%", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "# global_step will have the correct step count if we resume from a checkpoint", "\n", "                    ", "train_epoch", "=", "math", ".", "ceil", "(", "results", "[", "\"global_step\"", "]", "/", "examples", ".", "steps_per_epoch", ")", "\n", "train_step", "=", "(", "results", "[", "\"global_step\"", "]", "-", "1", ")", "%", "examples", ".", "steps_per_epoch", "+", "1", "\n", "rate", "=", "(", "step", "+", "1", ")", "*", "a", ".", "batch_size", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "remaining", "=", "(", "max_steps", "-", "step", ")", "*", "a", ".", "batch_size", "/", "rate", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"discrim_loss\"", ",", "results", "[", "\"discrim_loss\"", "]", ")", "\n", "print", "(", "\"gen_loss_GAN\"", ",", "results", "[", "\"gen_loss_GAN\"", "]", ")", "\n", "print", "(", "\"gen_loss_L1\"", ",", "results", "[", "\"gen_loss_L1\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "save_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "\n", "", "if", "sv", ".", "should_stop", "(", ")", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess": [[66, 70], ["tensorflow.name_scope"], "function", ["None"], ["def", "preprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess\"", ")", ":", "\n", "# [0, 1] => [-1, 1]", "\n", "        ", "return", "image", "*", "2", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess": [[72, 76], ["tensorflow.name_scope"], "function", ["None"], ["", "", "def", "deprocess", "(", "image", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess\"", ")", ":", "\n", "# [-1, 1] => [0, 1]", "\n", "        ", "return", "(", "image", "+", "1", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.preprocess_lab": [[78, 85], ["tensorflow.name_scope", "tensorflow.unstack"], "function", ["None"], ["", "", "def", "preprocess_lab", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"preprocess_lab\"", ")", ":", "\n", "        ", "L_chan", ",", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "lab", ",", "axis", "=", "2", ")", "\n", "# L_chan: black and white with input range [0, 100]", "\n", "# a_chan/b_chan: color channels with input range ~[-110, 110], not exact", "\n", "# [0, 100] => [-1, 1],  ~[-110, 110] => [-1, 1]", "\n", "return", "[", "L_chan", "/", "50", "-", "1", ",", "a_chan", "/", "110", ",", "b_chan", "/", "110", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess_lab": [[87, 91], ["tensorflow.name_scope", "tensorflow.stack"], "function", ["None"], ["", "", "def", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"deprocess_lab\"", ")", ":", "\n", "# this is axis=3 instead of axis=2 because we process individual images but deprocess batches", "\n", "        ", "return", "tf", ".", "stack", "(", "[", "(", "L_chan", "+", "1", ")", "/", "2", "*", "100", ",", "a_chan", "*", "110", ",", "b_chan", "*", "110", "]", ",", "axis", "=", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.augment": [[93, 100], ["tensorflow.unstack", "tensorflow.squeeze", "pix2pix_3_dG.deprocess_lab", "pix2pix_3_dG.lab_to_rgb"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess_lab", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lab_to_rgb"], ["", "", "def", "augment", "(", "image", ",", "brightness", ")", ":", "\n", "# (a, b) color channels, combine with L channel and convert to rgb", "\n", "    ", "a_chan", ",", "b_chan", "=", "tf", ".", "unstack", "(", "image", ",", "axis", "=", "3", ")", "\n", "L_chan", "=", "tf", ".", "squeeze", "(", "brightness", ",", "axis", "=", "3", ")", "\n", "lab", "=", "deprocess_lab", "(", "L_chan", ",", "a_chan", ",", "b_chan", ")", "\n", "rgb", "=", "lab_to_rgb", "(", "lab", ")", "\n", "return", "rgb", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv": [[102, 105], ["tensorflow.pad", "tensorflow.layers.conv2d", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "def", "discrim_conv", "(", "batch_input", ",", "out_channels", ",", "stride", ")", ":", "\n", "    ", "padded_input", "=", "tf", ".", "pad", "(", "batch_input", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "1", "]", ",", "[", "1", ",", "1", "]", ",", "[", "0", ",", "0", "]", "]", ",", "mode", "=", "\"CONSTANT\"", ")", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "padded_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "stride", ",", "stride", ")", ",", "padding", "=", "\"valid\"", ",", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv": [[107, 114], ["tensorflow.random_normal_initializer", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d"], "function", ["None"], ["", "def", "gen_conv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv_dilate": [[116, 122], ["tensorflow.random_normal_initializer", "tensorflow.layers.conv2d", "tensorflow.layers.max_pooling2d"], "function", ["None"], ["", "", "def", "gen_conv_dilate", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "dilate_rate", "=", "2", "\n", "output", "=", "tf", ".", "layers", ".", "conv2d", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "dilation_rate", "=", "(", "dilate_rate", ",", "dilate_rate", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "return", "tf", ".", "layers", ".", "max_pooling2d", "(", "inputs", "=", "output", ",", "pool_size", "=", "[", "2", ",", "2", "]", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "'valid'", ",", "data_format", "=", "'channels_last'", ",", "name", "=", "None", ")", "\n", "#end  Moha ---------------------------------------", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv": [[125, 134], ["tensorflow.random_normal_initializer", "tensorflow.image.resize_images", "tensorflow.layers.separable_conv2d", "tensorflow.layers.conv2d_transpose"], "function", ["None"], ["", "def", "gen_deconv", "(", "batch_input", ",", "out_channels", ")", ":", "\n", "# [batch, in_height, in_width, in_channels] => [batch, out_height, out_width, out_channels]", "\n", "    ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "0", ",", "0.02", ")", "\n", "if", "a", ".", "separable_conv", ":", "\n", "        ", "_b", ",", "h", ",", "w", ",", "_c", "=", "batch_input", ".", "shape", "\n", "resized_input", "=", "tf", ".", "image", ".", "resize_images", "(", "batch_input", ",", "[", "h", "*", "2", ",", "w", "*", "2", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "NEAREST_NEIGHBOR", ")", "\n", "return", "tf", ".", "layers", ".", "separable_conv2d", "(", "resized_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ",", "depthwise_initializer", "=", "initializer", ",", "pointwise_initializer", "=", "initializer", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "layers", ".", "conv2d_transpose", "(", "batch_input", ",", "out_channels", ",", "kernel_size", "=", "4", ",", "strides", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "\"same\"", ",", "kernel_initializer", "=", "initializer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu": [[136, 146], ["tensorflow.name_scope", "tensorflow.identity", "tensorflow.abs"], "function", ["None"], ["", "", "def", "lrelu", "(", "x", ",", "a", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lrelu\"", ")", ":", "\n", "# adding these together creates the leak part and linear part", "\n", "# then cancels them out by subtracting/adding an absolute value term", "\n", "# leak: a*x/2 - a*abs(x)/2", "\n", "# linear: x/2 + abs(x)/2", "\n", "\n", "# this block looks like it has 2 inputs on the graph unless we do this", "\n", "        ", "x", "=", "tf", ".", "identity", "(", "x", ")", "\n", "return", "(", "0.5", "*", "(", "1", "+", "a", ")", ")", "*", "x", "+", "(", "0.5", "*", "(", "1", "-", "a", ")", ")", "*", "tf", ".", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm": [[148, 150], ["tensorflow.layers.batch_normalization", "tensorflow.random_normal_initializer"], "function", ["None"], ["", "", "def", "batchnorm", "(", "inputs", ")", ":", "\n", "    ", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "inputs", ",", "axis", "=", "3", ",", "epsilon", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "training", "=", "True", ",", "gamma_initializer", "=", "tf", ".", "random_normal_initializer", "(", "1.0", ",", "0.02", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_generator": [[151, 235], ["print", "print", "len", "enumerate", "tensorflow.variable_scope", "pix2pix_3_dG.gen_conv", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_3_dG.lrelu", "pix2pix_3_dG.gen_conv", "print", "pix2pix_3_dG.batchnorm", "layers.append", "tensorflow.variable_scope", "tensorflow.concat", "tensorflow.nn.relu", "pix2pix_3_dG.gen_deconv", "tensorflow.tanh", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_3_dG.lrelu", "pix2pix_3_dG.gen_conv_dilate", "print", "pix2pix_3_dG.batchnorm", "layers.append", "tensorflow.variable_scope", "tensorflow.nn.relu", "pix2pix_3_dG.gen_deconv", "print", "pix2pix_3_dG.batchnorm", "layers.append", "tensorflow.concat", "tensorflow.nn.dropout", "len", "len"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_conv_dilate", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.gen_deconv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.batchnorm"], ["", "def", "create_generator", "(", "generator_inputs", ",", "generator_outputs_channels", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "\n", "print", "(", "'encoder:'", ")", "\n", "# encoder_1: [batch, 256, 256, in_channels] => [batch, 128, 128, ngf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder_1\"", ")", ":", "\n", "        ", "output", "=", "gen_conv", "(", "generator_inputs", ",", "a", ".", "ngf", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "a", ".", "ngf", "*", "2", ",", "# encoder_2: [batch, 128, 128, ngf] => [batch, 64, 64, ngf * 2]", "\n", "a", ".", "ngf", "*", "4", ",", "# encoder_3: [batch, 64, 64, ngf * 2] => [batch, 32, 32, ngf * 4]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_4: [batch, 32, 32, ngf * 4] => [batch, 16, 16, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_5: [batch, 16, 16, ngf * 8] => [batch, 8, 8, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_6: [batch, 8, 8, ngf * 8] => [batch, 4, 4, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_7: [batch, 4, 4, ngf * 8] => [batch, 2, 2, ngf * 8]", "\n", "a", ".", "ngf", "*", "8", ",", "# encoder_8: [batch, 2, 2, ngf * 8] => [batch, 1, 1, ngf * 8]", "\n", "]", "\n", "\n", "for", "out_channels", "in", "layer_specs", "[", ":", "6", "]", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height/2, in_width/2, out_channels]", "\n", "\n", "# orig: ---------------------------", "\n", "# convolved = gen_conv(rectified, out_channels)", "\n", "# Moha: ---------------------------", "\n", "convolved", "=", "gen_conv_dilate", "(", "rectified", ",", "out_channels", ")", "\n", "#convolved = gen_conv(rectified, out_channels)", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "# end Moha -----------------------------", "\n", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"encoder_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "rectified", "=", "lrelu", "(", "layers", "[", "-", "1", "]", ",", "0.2", ")", "\n", "convolved", "=", "gen_conv", "(", "rectified", ",", "layer_specs", "[", "6", "]", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "output", "=", "batchnorm", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "\n", "", "layer_specs", "=", "[", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_8: [batch, 1, 1, ngf * 8] => [batch, 2, 2, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_7: [batch, 2, 2, ngf * 8 * 2] => [batch, 4, 4, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.5", ")", ",", "# decoder_6: [batch, 4, 4, ngf * 8 * 2] => [batch, 8, 8, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "8", ",", "0.0", ")", ",", "# decoder_5: [batch, 8, 8, ngf * 8 * 2] => [batch, 16, 16, ngf * 8 * 2]", "\n", "(", "a", ".", "ngf", "*", "4", ",", "0.0", ")", ",", "# decoder_4: [batch, 16, 16, ngf * 8 * 2] => [batch, 32, 32, ngf * 4 * 2]", "\n", "(", "a", ".", "ngf", "*", "2", ",", "0.0", ")", ",", "# decoder_3: [batch, 32, 32, ngf * 4 * 2] => [batch, 64, 64, ngf * 2 * 2]", "\n", "(", "a", ".", "ngf", ",", "0.0", ")", ",", "# decoder_2: [batch, 64, 64, ngf * 2 * 2] => [batch, 128, 128, ngf * 2]", "\n", "]", "\n", "\n", "print", "(", "'decoder:'", ")", "\n", "num_encoder_layers", "=", "len", "(", "layers", ")", "\n", "for", "decoder_layer", ",", "(", "out_channels", ",", "dropout", ")", "in", "enumerate", "(", "layer_specs", ")", ":", "\n", "        ", "skip_layer", "=", "num_encoder_layers", "-", "decoder_layer", "-", "1", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder_%d\"", "%", "(", "skip_layer", "+", "1", ")", ")", ":", "\n", "            ", "if", "decoder_layer", "==", "0", ":", "\n", "# first decoder layer doesn't have skip connections", "\n", "# since it is directly connected to the skip_layer", "\n", "                ", "input", "=", "layers", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "skip_layer", "]", "]", ",", "axis", "=", "3", ")", "\n", "\n", "", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "# [batch, in_height, in_width, in_channels] => [batch, in_height*2, in_width*2, out_channels]", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "out_channels", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "output", "=", "batchnorm", "(", "output", ")", "\n", "\n", "if", "dropout", ">", "0.0", ":", "\n", "                ", "output", "=", "tf", ".", "nn", ".", "dropout", "(", "output", ",", "keep_prob", "=", "1", "-", "dropout", ")", "\n", "\n", "", "layers", ".", "append", "(", "output", ")", "\n", "\n", "# decoder_1: [batch, 128, 128, ngf * 2] => [batch, 256, 256, generator_outputs_channels]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"decoder_1\"", ")", ":", "\n", "        ", "input", "=", "tf", ".", "concat", "(", "[", "layers", "[", "-", "1", "]", ",", "layers", "[", "0", "]", "]", ",", "axis", "=", "3", ")", "\n", "rectified", "=", "tf", ".", "nn", ".", "relu", "(", "input", ")", "\n", "output", "=", "gen_deconv", "(", "rectified", ",", "generator_outputs_channels", ")", "\n", "output", "=", "tf", ".", "tanh", "(", "output", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_model": [[239, 336], ["tensorflow.train.ExponentialMovingAverage", "tf.train.ExponentialMovingAverage.apply", "tensorflow.train.get_or_create_global_step", "tensorflow.assign", "Model", "print", "tensorflow.concat", "range", "tensorflow.variable_scope", "int", "pix2pix_3_dG.create_generator", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.name_scope", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.compute_gradients", "tf.train.AdamOptimizer.apply_gradients", "tensorflow.name_scope", "tensorflow.variable_scope", "pix2pix_3_dG.discrim_conv", "pix2pix_3_dG.lrelu", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_3_dG.discrim_conv", "tensorflow.sigmoid", "layers.append", "print", "tensorflow.variable_scope", "pix2pix_3_dG.create_model.create_discriminator"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_generator", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lrelu", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.discrim_conv"], ["", "def", "create_model", "(", "inputs", ",", "targets", ")", ":", "\n", "\n", "    ", "def", "create_discriminator", "(", "discrim_inputs", ",", "discrim_targets", ")", ":", "\n", "        ", "n_layers", "=", "3", "\n", "layers", "=", "[", "]", "\n", "print", "(", "'discriminator:'", ")", "\n", "\n", "# 2x [batch, height, width, in_channels] => [batch, height, width, in_channels * 2]", "\n", "input", "=", "tf", ".", "concat", "(", "[", "discrim_inputs", ",", "discrim_targets", "]", ",", "axis", "=", "3", ")", "\n", "\n", "# layer_1: [batch, 256, 256, in_channels * 2] => [batch, 128, 128, ndf]", "\n", "with", "tf", ".", "variable_scope", "(", "\"layer_1\"", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "input", ",", "a", ".", "ndf", ",", "stride", "=", "2", ")", "\n", "rectified", "=", "lrelu", "(", "convolved", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_2: [batch, 128, 128, ndf] => [batch, 64, 64, ndf * 2]", "\n", "# layer_3: [batch, 64, 64, ndf * 2] => [batch, 32, 32, ndf * 4]", "\n", "# layer_4: [batch, 32, 32, ndf * 4] => [batch, 31, 31, ndf * 8]", "\n", "", "for", "i", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "                ", "out_channels", "=", "a", ".", "ndf", "*", "min", "(", "2", "**", "(", "i", "+", "1", ")", ",", "8", ")", "\n", "stride", "=", "1", "if", "i", "==", "n_layers", "-", "1", "else", "2", "# last layer here has stride 1", "\n", "convolved", "=", "discrim_conv", "(", "layers", "[", "-", "1", "]", ",", "out_channels", ",", "stride", "=", "stride", ")", "\n", "normalized", "=", "batchnorm", "(", "convolved", ")", "\n", "rectified", "=", "lrelu", "(", "normalized", ",", "0.2", ")", "\n", "layers", ".", "append", "(", "rectified", ")", "\n", "print", "(", "convolved", ".", "shape", ")", "\n", "\n", "# layer_5: [batch, 31, 31, ndf * 8] => [batch, 30, 30, 1]", "\n", "", "", "with", "tf", ".", "variable_scope", "(", "\"layer_%d\"", "%", "(", "len", "(", "layers", ")", "+", "1", ")", ")", ":", "\n", "            ", "convolved", "=", "discrim_conv", "(", "rectified", ",", "out_channels", "=", "1", ",", "stride", "=", "1", ")", "\n", "output", "=", "tf", ".", "sigmoid", "(", "convolved", ")", "\n", "layers", ".", "append", "(", "output", ")", "\n", "print", "(", "output", ".", "shape", ")", "\n", "\n", "", "return", "layers", "[", "-", "1", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "        ", "out_channels", "=", "int", "(", "targets", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "outputs", "=", "create_generator", "(", "inputs", ",", "out_channels", ")", "\n", "\n", "# create two copies of discriminator, one for real pairs and one for fake pairs", "\n", "# they share the same underlying variables", "\n", "", "with", "tf", ".", "name_scope", "(", "\"real_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_real", "=", "create_discriminator", "(", "inputs", ",", "targets", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"fake_discriminator\"", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"discriminator\"", ",", "reuse", "=", "True", ")", ":", "\n", "# 2x [batch, height, width, channels] => [batch, 30, 30, 1]", "\n", "            ", "predict_fake", "=", "create_discriminator", "(", "inputs", ",", "outputs", ")", "\n", "\n", "", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_loss\"", ")", ":", "\n", "# minimizing -tf.log will try to get inputs to 1", "\n", "# predict_real => 1", "\n", "# predict_fake => 0", "\n", "        ", "discrim_loss", "=", "tf", ".", "reduce_mean", "(", "-", "(", "tf", ".", "log", "(", "predict_real", "+", "EPS", ")", "+", "tf", ".", "log", "(", "1", "-", "predict_fake", "+", "EPS", ")", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_loss\"", ")", ":", "\n", "# predict_fake => 1", "\n", "# abs(targets - outputs) => 0", "\n", "        ", "gen_loss_GAN", "=", "tf", ".", "reduce_mean", "(", "-", "tf", ".", "log", "(", "predict_fake", "+", "EPS", ")", ")", "\n", "gen_loss_L1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "targets", "-", "outputs", ")", ")", "\n", "gen_loss", "=", "gen_loss_GAN", "*", "a", ".", "gan_weight", "+", "gen_loss_L1", "*", "a", ".", "l1_weight", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"discriminator_train\"", ")", ":", "\n", "        ", "discrim_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"discriminator\"", ")", "]", "\n", "discrim_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "discrim_grads_and_vars", "=", "discrim_optim", ".", "compute_gradients", "(", "discrim_loss", ",", "var_list", "=", "discrim_tvars", ")", "\n", "discrim_train", "=", "discrim_optim", ".", "apply_gradients", "(", "discrim_grads_and_vars", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"generator_train\"", ")", ":", "\n", "        ", "with", "tf", ".", "control_dependencies", "(", "[", "discrim_train", "]", ")", ":", "\n", "            ", "gen_tvars", "=", "[", "var", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", "if", "var", ".", "name", ".", "startswith", "(", "\"generator\"", ")", "]", "\n", "gen_optim", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "a", ".", "lr", ",", "a", ".", "beta1", ")", "\n", "gen_grads_and_vars", "=", "gen_optim", ".", "compute_gradients", "(", "gen_loss", ",", "var_list", "=", "gen_tvars", ")", "\n", "gen_train", "=", "gen_optim", ".", "apply_gradients", "(", "gen_grads_and_vars", ")", "\n", "\n", "", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "0.99", ")", "\n", "update_losses", "=", "ema", ".", "apply", "(", "[", "discrim_loss", ",", "gen_loss_GAN", ",", "gen_loss_L1", "]", ")", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "incr_global_step", "=", "tf", ".", "assign", "(", "global_step", ",", "global_step", "+", "1", ")", "\n", "\n", "return", "Model", "(", "\n", "predict_real", "=", "predict_real", ",", "\n", "predict_fake", "=", "predict_fake", ",", "\n", "discrim_loss", "=", "ema", ".", "average", "(", "discrim_loss", ")", ",", "\n", "discrim_grads_and_vars", "=", "discrim_grads_and_vars", ",", "\n", "gen_loss_GAN", "=", "ema", ".", "average", "(", "gen_loss_GAN", ")", ",", "\n", "gen_loss_L1", "=", "ema", ".", "average", "(", "gen_loss_L1", ")", ",", "\n", "gen_grads_and_vars", "=", "gen_grads_and_vars", ",", "\n", "outputs", "=", "outputs", ",", "\n", "train", "=", "tf", ".", "group", "(", "update_losses", ",", "incr_global_step", ",", "gen_train", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.check_image": [[339, 352], ["tensorflow.assert_equal", "list", "tf.identity.set_shape", "tensorflow.control_dependencies", "tensorflow.identity", "ValueError", "tf.identity.get_shape", "tensorflow.shape", "tf.identity.get_shape"], "function", ["None"], ["", "def", "check_image", "(", "image", ")", ":", "\n", "    ", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "image", ")", "[", "-", "1", "]", ",", "3", ",", "message", "=", "\"image must have 3 color channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "        ", "image", "=", "tf", ".", "identity", "(", "image", ")", "\n", "\n", "", "if", "image", ".", "get_shape", "(", ")", ".", "ndims", "not", "in", "(", "3", ",", "4", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"image must be either 3 or 4 dimensions\"", ")", "\n", "\n", "# make the last dimension 3 so that you can unstack the colors", "\n", "", "shape", "=", "list", "(", "image", ".", "get_shape", "(", ")", ")", "\n", "shape", "[", "-", "1", "]", "=", "3", "\n", "image", ".", "set_shape", "(", "shape", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.rgb_to_lab": [[354, 393], ["tensorflow.name_scope", "pix2pix_3_dG.check_image", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.name_scope", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.matmul", "tensorflow.name_scope", "tensorflow.multiply", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.shape", "tensorflow.matmul", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.check_image"], ["", "def", "rgb_to_lab", "(", "srgb", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"rgb_to_lab\"", ")", ":", "\n", "        ", "srgb", "=", "check_image", "(", "srgb", ")", "\n", "srgb_pixels", "=", "tf", ".", "reshape", "(", "srgb", ",", "[", "-", "1", ",", "3", "]", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "\"srgb_to_xyz\"", ")", ":", "\n", "            ", "linear_mask", "=", "tf", ".", "cast", "(", "srgb_pixels", "<=", "0.04045", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "srgb_pixels", ">", "0.04045", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "rgb_pixels", "=", "(", "srgb_pixels", "/", "12.92", "*", "linear_mask", ")", "+", "(", "(", "(", "srgb_pixels", "+", "0.055", ")", "/", "1.055", ")", "**", "2.4", ")", "*", "exponential_mask", "\n", "rgb_to_xyz", "=", "tf", ".", "constant", "(", "[", "\n", "#    X        Y          Z", "\n", "[", "0.412453", ",", "0.212671", ",", "0.019334", "]", ",", "# R", "\n", "[", "0.357580", ",", "0.715160", ",", "0.119193", "]", ",", "# G", "\n", "[", "0.180423", ",", "0.072169", ",", "0.950227", "]", ",", "# B", "\n", "]", ")", "\n", "xyz_pixels", "=", "tf", ".", "matmul", "(", "rgb_pixels", ",", "rgb_to_xyz", ")", "\n", "\n", "# https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions", "\n", "", "with", "tf", ".", "name_scope", "(", "\"xyz_to_cielab\"", ")", ":", "\n", "# convert to fx = f(X/Xn), fy = f(Y/Yn), fz = f(Z/Zn)", "\n", "\n", "# normalize for D65 white point", "\n", "            ", "xyz_normalized_pixels", "=", "tf", ".", "multiply", "(", "xyz_pixels", ",", "[", "1", "/", "0.950456", ",", "1.0", ",", "1", "/", "1.088754", "]", ")", "\n", "\n", "epsilon", "=", "6", "/", "29", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "xyz_normalized_pixels", "<=", "(", "epsilon", "**", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "xyz_normalized_pixels", ">", "(", "epsilon", "**", "3", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "fxfyfz_pixels", "=", "(", "xyz_normalized_pixels", "/", "(", "3", "*", "epsilon", "**", "2", ")", "+", "4", "/", "29", ")", "*", "linear_mask", "+", "(", "xyz_normalized_pixels", "**", "(", "1", "/", "3", ")", ")", "*", "exponential_mask", "\n", "\n", "# convert to lab", "\n", "fxfyfz_to_lab", "=", "tf", ".", "constant", "(", "[", "\n", "#  l       a       b", "\n", "[", "0.0", ",", "500.0", ",", "0.0", "]", ",", "# fx", "\n", "[", "116.0", ",", "-", "500.0", ",", "200.0", "]", ",", "# fy", "\n", "[", "0.0", ",", "0.0", ",", "-", "200.0", "]", ",", "# fz", "\n", "]", ")", "\n", "lab_pixels", "=", "tf", ".", "matmul", "(", "fxfyfz_pixels", ",", "fxfyfz_to_lab", ")", "+", "tf", ".", "constant", "(", "[", "-", "16.0", ",", "0.0", ",", "0.0", "]", ")", "\n", "\n", "", "return", "tf", ".", "reshape", "(", "lab_pixels", ",", "tf", ".", "shape", "(", "srgb", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.lab_to_rgb": [[395, 435], ["tensorflow.name_scope", "pix2pix_3_dG.check_image", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.name_scope", "tensorflow.constant", "tensorflow.matmul", "tensorflow.cast", "tensorflow.cast", "tensorflow.multiply", "tensorflow.name_scope", "tensorflow.constant", "tensorflow.matmul", "tensorflow.clip_by_value", "tensorflow.cast", "tensorflow.cast", "tensorflow.shape", "tensorflow.constant"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.check_image"], ["", "", "def", "lab_to_rgb", "(", "lab", ")", ":", "\n", "    ", "with", "tf", ".", "name_scope", "(", "\"lab_to_rgb\"", ")", ":", "\n", "        ", "lab", "=", "check_image", "(", "lab", ")", "\n", "lab_pixels", "=", "tf", ".", "reshape", "(", "lab", ",", "[", "-", "1", ",", "3", "]", ")", "\n", "\n", "# https://en.wikipedia.org/wiki/Lab_color_space#CIELAB-CIEXYZ_conversions", "\n", "with", "tf", ".", "name_scope", "(", "\"cielab_to_xyz\"", ")", ":", "\n", "# convert to fxfyfz", "\n", "            ", "lab_to_fxfyfz", "=", "tf", ".", "constant", "(", "[", "\n", "#   fx      fy        fz", "\n", "[", "1", "/", "116.0", ",", "1", "/", "116.0", ",", "1", "/", "116.0", "]", ",", "# l", "\n", "[", "1", "/", "500.0", ",", "0.0", ",", "0.0", "]", ",", "# a", "\n", "[", "0.0", ",", "0.0", ",", "-", "1", "/", "200.0", "]", ",", "# b", "\n", "]", ")", "\n", "fxfyfz_pixels", "=", "tf", ".", "matmul", "(", "lab_pixels", "+", "tf", ".", "constant", "(", "[", "16.0", ",", "0.0", ",", "0.0", "]", ")", ",", "lab_to_fxfyfz", ")", "\n", "\n", "# convert to xyz", "\n", "epsilon", "=", "6", "/", "29", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "fxfyfz_pixels", "<=", "epsilon", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "fxfyfz_pixels", ">", "epsilon", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "xyz_pixels", "=", "(", "3", "*", "epsilon", "**", "2", "*", "(", "fxfyfz_pixels", "-", "4", "/", "29", ")", ")", "*", "linear_mask", "+", "(", "fxfyfz_pixels", "**", "3", ")", "*", "exponential_mask", "\n", "\n", "# denormalize for D65 white point", "\n", "xyz_pixels", "=", "tf", ".", "multiply", "(", "xyz_pixels", ",", "[", "0.950456", ",", "1.0", ",", "1.088754", "]", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"xyz_to_srgb\"", ")", ":", "\n", "            ", "xyz_to_rgb", "=", "tf", ".", "constant", "(", "[", "\n", "#     r           g          b", "\n", "[", "3.2404542", ",", "-", "0.9692660", ",", "0.0556434", "]", ",", "# x", "\n", "[", "-", "1.5371385", ",", "1.8760108", ",", "-", "0.2040259", "]", ",", "# y", "\n", "[", "-", "0.4985314", ",", "0.0415560", ",", "1.0572252", "]", ",", "# z", "\n", "]", ")", "\n", "rgb_pixels", "=", "tf", ".", "matmul", "(", "xyz_pixels", ",", "xyz_to_rgb", ")", "\n", "# avoid a slightly negative number messing up the conversion", "\n", "rgb_pixels", "=", "tf", ".", "clip_by_value", "(", "rgb_pixels", ",", "0.0", ",", "1.0", ")", "\n", "linear_mask", "=", "tf", ".", "cast", "(", "rgb_pixels", "<=", "0.0031308", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "exponential_mask", "=", "tf", ".", "cast", "(", "rgb_pixels", ">", "0.0031308", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "srgb_pixels", "=", "(", "rgb_pixels", "*", "12.92", "*", "linear_mask", ")", "+", "(", "(", "rgb_pixels", "**", "(", "1", "/", "2.4", ")", "*", "1.055", ")", "-", "0.055", ")", "*", "exponential_mask", "\n", "\n", "", "return", "tf", ".", "reshape", "(", "srgb_pixels", ",", "tf", ".", "shape", "(", "lab", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.load_examples": [[437, 527], ["glob.glob", "all", "random.randint", "tensorflow.train.batch", "int", "Examples", "Exception", "os.path.join", "len", "glob.glob", "len", "Exception", "os.path.splitext", "sorted", "sorted", "tensorflow.name_scope", "tensorflow.train.string_input_producer", "tensorflow.WholeFileReader", "tf.WholeFileReader.read", "decode", "tensorflow.image.convert_image_dtype", "tensorflow.assert_equal", "tf.identity.set_shape", "tensorflow.image.resize_images", "tensorflow.cast", "tensorflow.name_scope", "pix2pix_3_dG.load_examples.transform"], "function", ["None"], ["", "", "def", "load_examples", "(", ")", ":", "\n", "    ", "if", "a", ".", "input_dir", "is", "None", "or", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "input_dir", ")", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir does not exist\"", ")", "\n", "\n", "", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.jpg\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_jpeg", "\n", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "input_paths", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "input_dir", ",", "\"*.png\"", ")", ")", "\n", "decode", "=", "tf", ".", "image", ".", "decode_png", "\n", "\n", "", "if", "len", "(", "input_paths", ")", "==", "0", ":", "\n", "        ", "raise", "Exception", "(", "\"input_dir contains no image files\"", ")", "\n", "\n", "", "def", "get_name", "(", "path", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "path", ")", ")", "\n", "return", "name", "\n", "\n", "# if the image names are numbers, sort by the value rather than asciibetically", "\n", "# having sorted inputs means that the outputs are sorted in test mode", "\n", "", "if", "all", "(", "get_name", "(", "path", ")", ".", "isdigit", "(", ")", "for", "path", "in", "input_paths", ")", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ",", "key", "=", "lambda", "path", ":", "int", "(", "get_name", "(", "path", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "input_paths", "=", "sorted", "(", "input_paths", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"load_images\"", ")", ":", "\n", "        ", "path_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "input_paths", ",", "shuffle", "=", "a", ".", "mode", "==", "\"train\"", ")", "\n", "reader", "=", "tf", ".", "WholeFileReader", "(", ")", "\n", "paths", ",", "contents", "=", "reader", ".", "read", "(", "path_queue", ")", "\n", "raw_input", "=", "decode", "(", "contents", ")", "\n", "raw_input", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "raw_input", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "assertion", "=", "tf", ".", "assert_equal", "(", "tf", ".", "shape", "(", "raw_input", ")", "[", "2", "]", ",", "3", ",", "message", "=", "\"image does not have 3 channels\"", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "assertion", "]", ")", ":", "\n", "            ", "raw_input", "=", "tf", ".", "identity", "(", "raw_input", ")", "\n", "\n", "", "raw_input", ".", "set_shape", "(", "[", "None", ",", "None", ",", "3", "]", ")", "\n", "\n", "if", "a", ".", "lab_colorization", ":", "\n", "# load color and brightness from image, no B image exists here", "\n", "            ", "lab", "=", "rgb_to_lab", "(", "raw_input", ")", "\n", "L_chan", ",", "a_chan", ",", "b_chan", "=", "preprocess_lab", "(", "lab", ")", "\n", "a_images", "=", "tf", ".", "expand_dims", "(", "L_chan", ",", "axis", "=", "2", ")", "\n", "b_images", "=", "tf", ".", "stack", "(", "[", "a_chan", ",", "b_chan", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "# break apart image pair and move to range [-1, 1]", "\n", "            ", "width", "=", "tf", ".", "shape", "(", "raw_input", ")", "[", "1", "]", "# [height, width, channels]", "\n", "a_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", ":", "width", "//", "2", ",", ":", "]", ")", "\n", "b_images", "=", "preprocess", "(", "raw_input", "[", ":", ",", "width", "//", "2", ":", ",", ":", "]", ")", "\n", "\n", "", "", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "        ", "inputs", ",", "targets", "=", "[", "a_images", ",", "b_images", "]", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "        ", "inputs", ",", "targets", "=", "[", "b_images", ",", "a_images", "]", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "\n", "# synchronize seed for image operations so that we do the same operations to both", "\n", "# input and output images", "\n", "", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "def", "transform", "(", "image", ")", ":", "\n", "        ", "r", "=", "image", "\n", "if", "a", ".", "flip", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "r", ",", "seed", "=", "seed", ")", "\n", "\n", "# area produces a nice downscaling, but does nearest neighbor for upscaling", "\n", "# assume we're going to be doing downscaling here", "\n", "", "r", "=", "tf", ".", "image", ".", "resize_images", "(", "r", ",", "[", "a", ".", "scale_size", ",", "a", ".", "scale_size", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "AREA", ")", "\n", "\n", "offset", "=", "tf", ".", "cast", "(", "tf", ".", "floor", "(", "tf", ".", "random_uniform", "(", "[", "2", "]", ",", "0", ",", "a", ".", "scale_size", "-", "CROP_SIZE", "+", "1", ",", "seed", "=", "seed", ")", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "if", "a", ".", "scale_size", ">", "CROP_SIZE", ":", "\n", "            ", "r", "=", "tf", ".", "image", ".", "crop_to_bounding_box", "(", "r", ",", "offset", "[", "0", "]", ",", "offset", "[", "1", "]", ",", "CROP_SIZE", ",", "CROP_SIZE", ")", "\n", "", "elif", "a", ".", "scale_size", "<", "CROP_SIZE", ":", "\n", "            ", "raise", "Exception", "(", "\"scale size cannot be less than crop size\"", ")", "\n", "", "return", "r", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"input_images\"", ")", ":", "\n", "        ", "input_images", "=", "transform", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"target_images\"", ")", ":", "\n", "        ", "target_images", "=", "transform", "(", "targets", ")", "\n", "\n", "", "paths_batch", ",", "inputs_batch", ",", "targets_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "paths", ",", "input_images", ",", "target_images", "]", ",", "batch_size", "=", "a", ".", "batch_size", ")", "\n", "steps_per_epoch", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "input_paths", ")", "/", "a", ".", "batch_size", ")", ")", "\n", "\n", "return", "Examples", "(", "\n", "paths", "=", "paths_batch", ",", "\n", "inputs", "=", "inputs_batch", ",", "\n", "targets", "=", "targets_batch", ",", "\n", "count", "=", "len", "(", "input_paths", ")", ",", "\n", "steps_per_epoch", "=", "steps_per_epoch", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.save_images": [[532, 552], ["os.path.join", "enumerate", "os.path.exists", "os.makedirs", "os.path.splitext", "filesets.append", "os.path.basename", "os.path.join", "in_path.decode", "open", "f.write"], "function", ["None"], ["", "def", "save_images", "(", "fetches", ",", "step", "=", "None", ")", ":", "\n", "    ", "image_dir", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"images\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "image_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "image_dir", ")", "\n", "\n", "", "filesets", "=", "[", "]", "\n", "for", "i", ",", "in_path", "in", "enumerate", "(", "fetches", "[", "\"paths\"", "]", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "in_path", ".", "decode", "(", "\"utf8\"", ")", ")", ")", "\n", "fileset", "=", "{", "\"name\"", ":", "name", ",", "\"step\"", ":", "step", "}", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs\"", ",", "\"targets\"", "]", ":", "\n", "            ", "filename", "=", "name", "+", "\"-\"", "+", "kind", "+", "\".png\"", "\n", "if", "step", "is", "not", "None", ":", "\n", "                ", "filename", "=", "\"%08d-%s\"", "%", "(", "step", ",", "filename", ")", "\n", "", "fileset", "[", "kind", "]", "=", "filename", "\n", "out_path", "=", "os", ".", "path", ".", "join", "(", "image_dir", ",", "filename", ")", "\n", "contents", "=", "fetches", "[", "kind", "]", "[", "i", "]", "\n", "with", "open", "(", "out_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "contents", ")", "\n", "", "", "filesets", ".", "append", "(", "fileset", ")", "\n", "", "return", "filesets", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.append_index": [[554, 577], ["os.path.join", "os.path.exists", "open", "open", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write", "open.write"], "function", ["None"], ["", "def", "append_index", "(", "filesets", ",", "step", "=", "False", ")", ":", "\n", "    ", "index_path", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"index.html\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "index_path", ")", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"a\"", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "open", "(", "index_path", ",", "\"w\"", ")", "\n", "index", ".", "write", "(", "\"<html><body><table><tr>\"", ")", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<th>step</th>\"", ")", "\n", "", "index", ".", "write", "(", "\"<th>name</th><th>input</th><th>output</th><th>target</th></tr>\"", ")", "\n", "\n", "", "for", "fileset", "in", "filesets", ":", "\n", "        ", "index", ".", "write", "(", "\"<tr>\"", ")", "\n", "\n", "if", "step", ":", "\n", "            ", "index", ".", "write", "(", "\"<td>%d</td>\"", "%", "fileset", "[", "\"step\"", "]", ")", "\n", "", "index", ".", "write", "(", "\"<td>%s</td>\"", "%", "fileset", "[", "\"name\"", "]", ")", "\n", "\n", "for", "kind", "in", "[", "\"inputs\"", ",", "\"outputs\"", ",", "\"targets\"", "]", ":", "\n", "            ", "index", ".", "write", "(", "\"<td><img src='images/%s'></td>\"", "%", "fileset", "[", "kind", "]", ")", "\n", "\n", "", "index", ".", "write", "(", "\"</tr>\"", ")", "\n", "", "return", "index_path", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.main": [[579, 844], ["tensorflow.set_random_seed", "numpy.random.seed", "random.seed", "a._get_kwargs", "pix2pix_3_dG.load_examples", "print", "pix2pix_3_dG.create_model", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.trainable_variables", "tensorflow.train.Saver", "tensorflow.train.Supervisor", "random.randint", "os.path.exists", "os.makedirs", "print", "open", "f.write", "tensorflow.placeholder", "tensorflow.decode_base64", "tensorflow.image.decode_png", "tensorflow.cond", "tensorflow.cond", "tensorflow.image.convert_image_dtype", "tf.image.convert_image_dtype.set_shape", "tensorflow.expand_dims", "tensorflow.convert_to_tensor", "tensorflow.placeholder", "tensorflow.add_to_collection", "tensorflow.add_to_collection", "tensorflow.global_variables_initializer", "tensorflow.train.Saver", "tensorflow.train.Saver", "pix2pix_3_dG.deprocess", "pix2pix_3_dG.deprocess", "pix2pix_3_dG.deprocess", "tensorflow.image.convert_image_dtype", "tensorflow.name_scope", "pix2pix_3_dG.main.convert"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.load_examples", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.create_model", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.Scripts.pix2pix_3_dG.deprocess"], ["", "def", "main", "(", ")", ":", "\n", "    ", "if", "a", ".", "seed", "is", "None", ":", "\n", "        ", "a", ".", "seed", "=", "random", ".", "randint", "(", "0", ",", "2", "**", "31", "-", "1", ")", "\n", "\n", "", "tf", ".", "set_random_seed", "(", "a", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "random", ".", "seed", "(", "a", ".", "seed", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "a", ".", "output_dir", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", "or", "a", ".", "mode", "==", "\"export\"", ":", "\n", "        ", "if", "a", ".", "checkpoint", "is", "None", ":", "\n", "            ", "raise", "Exception", "(", "\"checkpoint required for test mode\"", ")", "\n", "\n", "# load some options from the checkpoint", "\n", "", "options", "=", "{", "\"which_direction\"", ",", "\"ngf\"", ",", "\"ndf\"", ",", "\"lab_colorization\"", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "checkpoint", ",", "\"options.json\"", ")", ")", "as", "f", ":", "\n", "            ", "for", "key", ",", "val", "in", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "in", "options", ":", "\n", "                    ", "print", "(", "\"loaded\"", ",", "key", ",", "\"=\"", ",", "val", ")", "\n", "setattr", "(", "a", ",", "key", ",", "val", ")", "\n", "# disable these features in test mode", "\n", "", "", "", "a", ".", "scale_size", "=", "CROP_SIZE", "\n", "a", ".", "flip", "=", "False", "\n", "\n", "", "for", "k", ",", "v", "in", "a", ".", "_get_kwargs", "(", ")", ":", "\n", "        ", "print", "(", "k", ",", "\"=\"", ",", "v", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"options.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vars", "(", "a", ")", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", ")", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"export\"", ":", "\n", "# export the generator to a meta graph that can be imported later for standalone generation", "\n", "        ", "if", "a", ".", "lab_colorization", ":", "\n", "            ", "raise", "Exception", "(", "\"export not supported for lab_colorization\"", ")", "\n", "\n", "", "input", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "input_data", "=", "tf", ".", "decode_base64", "(", "input", "[", "0", "]", ")", "\n", "input_image", "=", "tf", ".", "image", ".", "decode_png", "(", "input_data", ")", "\n", "\n", "# remove alpha channel if present", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "4", ")", ",", "lambda", ":", "input_image", "[", ":", ",", ":", ",", ":", "3", "]", ",", "lambda", ":", "input_image", ")", "\n", "# convert grayscale to RGB", "\n", "input_image", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "tf", ".", "shape", "(", "input_image", ")", "[", "2", "]", ",", "1", ")", ",", "lambda", ":", "tf", ".", "image", ".", "grayscale_to_rgb", "(", "input_image", ")", ",", "lambda", ":", "input_image", ")", "\n", "\n", "input_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "input_image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "input_image", ".", "set_shape", "(", "[", "CROP_SIZE", ",", "CROP_SIZE", ",", "3", "]", ")", "\n", "batch_input", "=", "tf", ".", "expand_dims", "(", "input_image", ",", "axis", "=", "0", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"generator\"", ")", ":", "\n", "            ", "batch_output", "=", "deprocess", "(", "create_generator", "(", "preprocess", "(", "batch_input", ")", ",", "3", ")", ")", "\n", "\n", "", "output_image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "batch_output", ",", "dtype", "=", "tf", ".", "uint8", ")", "[", "0", "]", "\n", "if", "a", ".", "output_filetype", "==", "\"png\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_png", "(", "output_image", ")", "\n", "", "elif", "a", ".", "output_filetype", "==", "\"jpeg\"", ":", "\n", "            ", "output_data", "=", "tf", ".", "image", ".", "encode_jpeg", "(", "output_image", ",", "quality", "=", "80", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid filetype\"", ")", "\n", "", "output", "=", "tf", ".", "convert_to_tensor", "(", "[", "tf", ".", "encode_base64", "(", "output_data", ")", "]", ")", "\n", "\n", "key", "=", "tf", ".", "placeholder", "(", "tf", ".", "string", ",", "shape", "=", "[", "1", "]", ")", "\n", "inputs", "=", "{", "\n", "\"key\"", ":", "key", ".", "name", ",", "\n", "\"input\"", ":", "input", ".", "name", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"inputs\"", ",", "json", ".", "dumps", "(", "inputs", ")", ")", "\n", "outputs", "=", "{", "\n", "\"key\"", ":", "tf", ".", "identity", "(", "key", ")", ".", "name", ",", "\n", "\"output\"", ":", "output", ".", "name", ",", "\n", "}", "\n", "tf", ".", "add_to_collection", "(", "\"outputs\"", ",", "json", ".", "dumps", "(", "outputs", ")", ")", "\n", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "restore_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "export_saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "init_op", ")", "\n", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "restore_saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "print", "(", "\"exporting model\"", ")", "\n", "export_saver", ".", "export_meta_graph", "(", "filename", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export.meta\"", ")", ")", "\n", "export_saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"export\"", ")", ",", "write_meta_graph", "=", "False", ")", "\n", "\n", "", "return", "\n", "\n", "", "examples", "=", "load_examples", "(", ")", "\n", "print", "(", "\"examples count = %d\"", "%", "examples", ".", "count", ")", "\n", "\n", "# inputs and targets are [batch_size, height, width, channels]", "\n", "model", "=", "create_model", "(", "examples", ".", "inputs", ",", "examples", ".", "targets", ")", "\n", "\n", "# undo colorization splitting on images that we use for display/output", "\n", "if", "a", ".", "lab_colorization", ":", "\n", "        ", "if", "a", ".", "which_direction", "==", "\"AtoB\"", ":", "\n", "# inputs is brightness, this will be handled fine as a grayscale image", "\n", "# need to augment targets and outputs with brightness", "\n", "            ", "targets", "=", "augment", "(", "examples", ".", "targets", ",", "examples", ".", "inputs", ")", "\n", "outputs", "=", "augment", "(", "model", ".", "outputs", ",", "examples", ".", "inputs", ")", "\n", "# inputs can be deprocessed normally and handled as if they are single channel", "\n", "# grayscale images", "\n", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "", "elif", "a", ".", "which_direction", "==", "\"BtoA\"", ":", "\n", "# inputs will be color channels only, get brightness from targets", "\n", "            ", "inputs", "=", "augment", "(", "examples", ".", "inputs", ",", "examples", ".", "targets", ")", "\n", "targets", "=", "deprocess", "(", "examples", ".", "targets", ")", "\n", "outputs", "=", "deprocess", "(", "model", ".", "outputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"invalid direction\"", ")", "\n", "", "", "else", ":", "\n", "        ", "inputs", "=", "deprocess", "(", "examples", ".", "inputs", ")", "\n", "targets", "=", "deprocess", "(", "examples", ".", "targets", ")", "\n", "outputs", "=", "deprocess", "(", "model", ".", "outputs", ")", "\n", "\n", "", "def", "convert", "(", "image", ")", ":", "\n", "        ", "if", "a", ".", "aspect_ratio", "!=", "1.0", ":", "\n", "# upscale to correct aspect ratio", "\n", "            ", "size", "=", "[", "CROP_SIZE", ",", "int", "(", "round", "(", "CROP_SIZE", "*", "a", ".", "aspect_ratio", ")", ")", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize_images", "(", "image", ",", "size", "=", "size", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BICUBIC", ")", "\n", "\n", "", "return", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "uint8", ",", "saturate", "=", "True", ")", "\n", "\n", "# reverse any processing on images so they can be written to disk or displayed to user", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_inputs\"", ")", ":", "\n", "        ", "converted_inputs", "=", "convert", "(", "inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_targets\"", ")", ":", "\n", "        ", "converted_targets", "=", "convert", "(", "targets", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"convert_outputs\"", ")", ":", "\n", "        ", "converted_outputs", "=", "convert", "(", "outputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"encode_images\"", ")", ":", "\n", "        ", "display_fetches", "=", "{", "\n", "\"paths\"", ":", "examples", ".", "paths", ",", "\n", "\"inputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_inputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"input_pngs\"", ")", ",", "\n", "\"targets\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_targets", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"target_pngs\"", ")", ",", "\n", "\"outputs\"", ":", "tf", ".", "map_fn", "(", "tf", ".", "image", ".", "encode_png", ",", "converted_outputs", ",", "dtype", "=", "tf", ".", "string", ",", "name", "=", "\"output_pngs\"", ")", ",", "\n", "}", "\n", "\n", "# summaries", "\n", "", "with", "tf", ".", "name_scope", "(", "\"inputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"inputs\"", ",", "converted_inputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"targets_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"targets\"", ",", "converted_targets", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"outputs_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"outputs\"", ",", "converted_outputs", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_real_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_real\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_real", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"predict_fake_summary\"", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "image", "(", "\"predict_fake\"", ",", "tf", ".", "image", ".", "convert_image_dtype", "(", "model", ".", "predict_fake", ",", "dtype", "=", "tf", ".", "uint8", ")", ")", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "\"discriminator_loss\"", ",", "model", ".", "discrim_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_GAN\"", ",", "model", ".", "gen_loss_GAN", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "\"generator_loss_L1\"", ",", "model", ".", "gen_loss_L1", ")", "\n", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/values\"", ",", "var", ")", "\n", "\n", "", "for", "grad", ",", "var", "in", "model", ".", "discrim_grads_and_vars", "+", "model", ".", "gen_grads_and_vars", ":", "\n", "        ", "tf", ".", "summary", ".", "histogram", "(", "var", ".", "op", ".", "name", "+", "\"/gradients\"", ",", "grad", ")", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "\"parameter_count\"", ")", ":", "\n", "        ", "parameter_count", "=", "tf", ".", "reduce_sum", "(", "[", "tf", ".", "reduce_prod", "(", "tf", ".", "shape", "(", "v", ")", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "]", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "1", ")", "\n", "\n", "logdir", "=", "a", ".", "output_dir", "if", "(", "a", ".", "trace_freq", ">", "0", "or", "a", ".", "summary_freq", ">", "0", ")", "else", "None", "\n", "sv", "=", "tf", ".", "train", ".", "Supervisor", "(", "logdir", "=", "logdir", ",", "save_summaries_secs", "=", "0", ",", "saver", "=", "None", ")", "\n", "with", "sv", ".", "managed_session", "(", ")", "as", "sess", ":", "\n", "        ", "print", "(", "\"parameter_count =\"", ",", "sess", ".", "run", "(", "parameter_count", ")", ")", "\n", "\n", "if", "a", ".", "checkpoint", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"loading model from checkpoint\"", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "a", ".", "checkpoint", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "checkpoint", ")", "\n", "\n", "", "max_steps", "=", "2", "**", "32", "\n", "if", "a", ".", "max_epochs", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "examples", ".", "steps_per_epoch", "*", "a", ".", "max_epochs", "\n", "", "if", "a", ".", "max_steps", "is", "not", "None", ":", "\n", "            ", "max_steps", "=", "a", ".", "max_steps", "\n", "\n", "", "if", "a", ".", "mode", "==", "\"test\"", ":", "\n", "# testing", "\n", "# at most, process the test data once", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "max_steps", "=", "min", "(", "examples", ".", "steps_per_epoch", ",", "max_steps", ")", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "results", "=", "sess", ".", "run", "(", "display_fetches", ")", "\n", "filesets", "=", "save_images", "(", "results", ")", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "filesets", ")", ":", "\n", "                    ", "print", "(", "\"evaluated image\"", ",", "f", "[", "\"name\"", "]", ")", "\n", "", "index_path", "=", "append_index", "(", "filesets", ")", "\n", "", "print", "(", "\"wrote index at\"", ",", "index_path", ")", "\n", "print", "(", "\"rate\"", ",", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "max_steps", ")", "\n", "", "else", ":", "\n", "# training", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "step", "in", "range", "(", "max_steps", ")", ":", "\n", "                ", "def", "should", "(", "freq", ")", ":", "\n", "                    ", "return", "freq", ">", "0", "and", "(", "(", "step", "+", "1", ")", "%", "freq", "==", "0", "or", "step", "==", "max_steps", "-", "1", ")", "\n", "\n", "", "options", "=", "None", "\n", "run_metadata", "=", "None", "\n", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "options", "=", "tf", ".", "RunOptions", "(", "trace_level", "=", "tf", ".", "RunOptions", ".", "FULL_TRACE", ")", "\n", "run_metadata", "=", "tf", ".", "RunMetadata", "(", ")", "\n", "\n", "", "fetches", "=", "{", "\n", "\"train\"", ":", "model", ".", "train", ",", "\n", "\"global_step\"", ":", "sv", ".", "global_step", ",", "\n", "}", "\n", "\n", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"discrim_loss\"", "]", "=", "model", ".", "discrim_loss", "\n", "fetches", "[", "\"gen_loss_GAN\"", "]", "=", "model", ".", "gen_loss_GAN", "\n", "fetches", "[", "\"gen_loss_L1\"", "]", "=", "model", ".", "gen_loss_L1", "\n", "\n", "", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"summary\"", "]", "=", "sv", ".", "summary_op", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "fetches", "[", "\"display\"", "]", "=", "display_fetches", "\n", "\n", "", "results", "=", "sess", ".", "run", "(", "fetches", ",", "options", "=", "options", ",", "run_metadata", "=", "run_metadata", ")", "\n", "\n", "if", "should", "(", "a", ".", "summary_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording summary\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_summary", "(", "results", "[", "\"summary\"", "]", ",", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "display_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving display images\"", ")", "\n", "filesets", "=", "save_images", "(", "results", "[", "\"display\"", "]", ",", "step", "=", "results", "[", "\"global_step\"", "]", ")", "\n", "append_index", "(", "filesets", ",", "step", "=", "True", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "trace_freq", ")", ":", "\n", "                    ", "print", "(", "\"recording trace\"", ")", "\n", "sv", ".", "summary_writer", ".", "add_run_metadata", "(", "run_metadata", ",", "\"step_%d\"", "%", "results", "[", "\"global_step\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "progress_freq", ")", ":", "\n", "# global_step will have the correct step count if we resume from a checkpoint", "\n", "                    ", "train_epoch", "=", "math", ".", "ceil", "(", "results", "[", "\"global_step\"", "]", "/", "examples", ".", "steps_per_epoch", ")", "\n", "train_step", "=", "(", "results", "[", "\"global_step\"", "]", "-", "1", ")", "%", "examples", ".", "steps_per_epoch", "+", "1", "\n", "rate", "=", "(", "step", "+", "1", ")", "*", "a", ".", "batch_size", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", "\n", "remaining", "=", "(", "max_steps", "-", "step", ")", "*", "a", ".", "batch_size", "/", "rate", "\n", "print", "(", "\"progress  epoch %d  step %d  image/sec %0.1f  remaining %dm\"", "%", "(", "train_epoch", ",", "train_step", ",", "rate", ",", "remaining", "/", "60", ")", ")", "\n", "print", "(", "\"discrim_loss\"", ",", "results", "[", "\"discrim_loss\"", "]", ")", "\n", "print", "(", "\"gen_loss_GAN\"", ",", "results", "[", "\"gen_loss_GAN\"", "]", ")", "\n", "print", "(", "\"gen_loss_L1\"", ",", "results", "[", "\"gen_loss_L1\"", "]", ")", "\n", "\n", "", "if", "should", "(", "a", ".", "save_freq", ")", ":", "\n", "                    ", "print", "(", "\"saving model\"", ")", "\n", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "\"model\"", ")", ",", "global_step", "=", "sv", ".", "global_step", ")", "\n", "\n", "", "if", "sv", ".", "should_stop", "(", ")", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.server.serve.main": [[6, 16], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.chdir", "http.server.HTTPServer", "print", "http.server.HTTPServer.serve_forever"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--port\"", ",", "default", "=", "8000", ",", "type", "=", "int", ",", "help", "=", "\"port to listen on\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "os", ".", "chdir", "(", "'static'", ")", "\n", "server_address", "=", "(", "''", ",", "args", ".", "port", ")", "\n", "httpd", "=", "HTTPServer", "(", "server_address", ",", "SimpleHTTPRequestHandler", ")", "\n", "print", "(", "'serving at http://127.0.0.1:%d'", "%", "args", ".", "port", ")", "\n", "httpd", ".", "serve_forever", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.export-checkpoint.log_quantize": [[14, 23], ["numpy.max", "numpy.histogram", "numpy.abs", "numpy.log", "numpy.sign", "numpy.log", "numpy.sign", "numpy.abs", "numpy.abs"], "function", ["None"], ["def", "log_quantize", "(", "data", ",", "mu", ",", "bins", ")", ":", "\n", "# mu-law encoding", "\n", "    ", "scale", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "data", ")", ")", "\n", "norm_data", "=", "data", "/", "scale", "\n", "log_data", "=", "np", ".", "sign", "(", "data", ")", "*", "np", ".", "log", "(", "1", "+", "mu", "*", "np", ".", "abs", "(", "norm_data", ")", ")", "/", "np", ".", "log", "(", "1", "+", "mu", ")", "\n", "\n", "_counts", ",", "edges", "=", "np", ".", "histogram", "(", "log_data", ",", "bins", "=", "bins", ")", "\n", "log_points", "=", "(", "edges", "[", ":", "-", "1", "]", "+", "edges", "[", "1", ":", "]", ")", "/", "2", "\n", "return", "np", ".", "sign", "(", "log_points", ")", "*", "(", "1", "/", "mu", ")", "*", "(", "(", "1", "+", "mu", ")", "**", "np", ".", "abs", "(", "log_points", ")", "-", "1", ")", "*", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.export-checkpoint.main": [[25, 100], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.join", "zip", "numpy.hstack", "time.time", "log_quantize().astype", "print", "print", "numpy.zeros", "enumerate", "open", "Exception", "tempfile.TemporaryDirectory", "subprocess.check_call", "json.loads.keys", "sorted", "shapes.append", "numpy.abs", "numpy.argmin", "open", "export-checkpoint.main.write"], "function", ["None"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint\"", ",", "required", "=", "True", ",", "help", "=", "\"directory with checkpoint to resume training from or use for testing\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_file\"", ",", "required", "=", "True", ",", "help", "=", "\"where to write output\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "model_path", "=", "None", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint", ",", "\"checkpoint\"", ")", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "\"\"", ":", "\n", "                ", "continue", "\n", "", "key", ",", "_sep", ",", "val", "=", "line", ".", "partition", "(", "\": \"", ")", "\n", "val", "=", "val", "[", "1", ":", "-", "1", "]", "# remove quotes", "\n", "if", "key", "==", "\"model_checkpoint_path\"", ":", "\n", "                ", "model_path", "=", "val", "\n", "\n", "", "", "", "if", "model_path", "is", "None", ":", "\n", "        ", "raise", "Exception", "(", "\"failed to find model path\"", ")", "\n", "\n", "", "checkpoint_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint", ",", "model_path", ")", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmp_dir", ":", "\n", "        ", "cmd", "=", "[", "\"python\"", ",", "\"-u\"", ",", "os", ".", "path", ".", "join", "(", "SCRIPT_DIR", ",", "\"dump_checkpoints/dump_checkpoint_vars.py\"", ")", ",", "\"--model_type\"", ",", "\"tensorflow\"", ",", "\"--output_dir\"", ",", "tmp_dir", ",", "\"--checkpoint_file\"", ",", "checkpoint_file", "]", "\n", "sp", ".", "check_call", "(", "cmd", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "\"manifest.json\"", ")", ")", "as", "f", ":", "\n", "            ", "manifest", "=", "json", ".", "loads", "(", "f", ".", "read", "(", ")", ")", "\n", "\n", "", "names", "=", "[", "]", "\n", "for", "key", "in", "manifest", ".", "keys", "(", ")", ":", "\n", "            ", "if", "not", "key", ".", "startswith", "(", "\"generator\"", ")", "or", "\"Adam\"", "in", "key", "or", "\"_loss\"", "in", "key", "or", "\"_train\"", "in", "key", "or", "\"_moving_\"", "in", "key", ":", "\n", "                ", "continue", "\n", "", "names", ".", "append", "(", "key", ")", "\n", "", "names", "=", "sorted", "(", "names", ")", "\n", "\n", "arrays", "=", "[", "]", "\n", "for", "name", "in", "names", ":", "\n", "            ", "value", "=", "manifest", "[", "name", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "value", "[", "\"filename\"", "]", ")", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "arr", "=", "np", ".", "frombuffer", "(", "f", ".", "read", "(", ")", ",", "dtype", "=", "np", ".", "float32", ")", ".", "copy", "(", ")", ".", "reshape", "(", "value", "[", "\"shape\"", "]", ")", "\n", "arrays", ".", "append", "(", "arr", ")", "\n", "\n", "", "", "", "shapes", "=", "[", "]", "\n", "for", "name", ",", "arr", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "shapes", ".", "append", "(", "dict", "(", "\n", "name", "=", "name", ",", "\n", "shape", "=", "arr", ".", "shape", ",", "\n", ")", ")", "\n", "\n", "", "flat", "=", "np", ".", "hstack", "(", "[", "arr", ".", "reshape", "(", "-", "1", ")", "for", "arr", "in", "arrays", "]", ")", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "index", "=", "log_quantize", "(", "flat", ",", "mu", "=", "255", ",", "bins", "=", "256", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "print", "(", "\"index found in %0.2fs\"", "%", "(", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "\n", "print", "(", "\"quantizing\"", ")", "\n", "encoded", "=", "np", ".", "zeros", "(", "flat", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "elem_count", "=", "0", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "flat", ")", ":", "\n", "        ", "distances", "=", "np", ".", "abs", "(", "index", "-", "x", ")", "\n", "nearest", "=", "np", ".", "argmin", "(", "distances", ")", "\n", "encoded", "[", "i", "]", "=", "nearest", "\n", "elem_count", "+=", "1", "\n", "if", "elem_count", "%", "1000000", "==", "0", ":", "\n", "            ", "print", "(", "\"rate\"", ",", "int", "(", "elem_count", "/", "(", "time", ".", "time", "(", ")", "-", "start", ")", ")", ")", "\n", "\n", "", "", "with", "open", "(", "args", ".", "output_file", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "def", "write", "(", "name", ",", "buf", ")", ":", "\n", "            ", "print", "(", "\"%s bytes %d\"", "%", "(", "name", ",", "len", "(", "buf", ")", ")", ")", "\n", "f", ".", "write", "(", "struct", ".", "pack", "(", "\">L\"", ",", "len", "(", "buf", ")", ")", ")", "\n", "f", ".", "write", "(", "buf", ")", "\n", "\n", "", "write", "(", "\"shape\"", ",", "json", ".", "dumps", "(", "shapes", ")", ".", "encode", "(", "\"utf8\"", ")", ")", "\n", "write", "(", "\"index\"", ",", "index", ".", "tobytes", "(", ")", ")", "\n", "write", "(", "\"encoded\"", ",", "encoded", ".", "tobytes", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.resize": [[33, 58], ["tfimage.downscale", "max", "tfimage.pad", "min", "tfimage.crop", "tfimage.upscale"], "function", ["None"], ["def", "resize", "(", "src", ")", ":", "\n", "    ", "height", ",", "width", ",", "_", "=", "src", ".", "shape", "\n", "dst", "=", "src", "\n", "if", "height", "!=", "width", ":", "\n", "        ", "if", "a", ".", "pad", ":", "\n", "            ", "size", "=", "max", "(", "height", ",", "width", ")", "\n", "# pad to correct ratio", "\n", "oh", "=", "(", "size", "-", "height", ")", "//", "2", "\n", "ow", "=", "(", "size", "-", "width", ")", "//", "2", "\n", "dst", "=", "im", ".", "pad", "(", "image", "=", "dst", ",", "offset_height", "=", "oh", ",", "offset_width", "=", "ow", ",", "target_height", "=", "size", ",", "target_width", "=", "size", ")", "\n", "", "else", ":", "\n", "# crop to correct ratio", "\n", "            ", "size", "=", "min", "(", "height", ",", "width", ")", "\n", "oh", "=", "(", "height", "-", "size", ")", "//", "2", "\n", "ow", "=", "(", "width", "-", "size", ")", "//", "2", "\n", "dst", "=", "im", ".", "crop", "(", "image", "=", "dst", ",", "offset_height", "=", "oh", ",", "offset_width", "=", "ow", ",", "target_height", "=", "size", ",", "target_width", "=", "size", ")", "\n", "\n", "", "", "assert", "(", "dst", ".", "shape", "[", "0", "]", "==", "dst", ".", "shape", "[", "1", "]", ")", "\n", "\n", "size", ",", "_", ",", "_", "=", "dst", ".", "shape", "\n", "if", "size", ">", "a", ".", "size", ":", "\n", "        ", "dst", "=", "im", ".", "downscale", "(", "images", "=", "dst", ",", "size", "=", "[", "a", ".", "size", ",", "a", ".", "size", "]", ")", "\n", "", "elif", "size", "<", "a", ".", "size", ":", "\n", "        ", "dst", "=", "im", ".", "upscale", "(", "images", "=", "dst", ",", "size", "=", "[", "a", ".", "size", ",", "a", ".", "size", "]", ")", "\n", "", "return", "dst", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.blank": [[60, 72], ["int", "int", "numpy.ones", "Exception"], "function", ["None"], ["", "def", "blank", "(", "src", ")", ":", "\n", "    ", "height", ",", "width", ",", "_", "=", "src", ".", "shape", "\n", "if", "height", "!=", "width", ":", "\n", "        ", "raise", "Exception", "(", "\"non-square image\"", ")", "\n", "\n", "", "image_size", "=", "width", "\n", "size", "=", "int", "(", "image_size", "*", "0.3", ")", "\n", "offset", "=", "int", "(", "image_size", "/", "2", "-", "size", "/", "2", ")", "\n", "\n", "dst", "=", "src", "\n", "dst", "[", "offset", ":", "offset", "+", "size", ",", "offset", ":", "offset", "+", "size", ",", ":", "]", "=", "np", ".", "ones", "(", "[", "size", ",", "size", ",", "3", "]", ")", "\n", "return", "dst", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.combine": [[74, 108], ["os.path.splitext", "numpy.concatenate", "Exception", "os.path.basename", "os.path.join", "os.path.exists", "Exception", "Exception", "tfimage.grayscale_to_rgb", "tfimage.grayscale_to_rgb", "tfimage.load"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.tfimage.load"], ["", "def", "combine", "(", "src", ",", "src_path", ")", ":", "\n", "    ", "if", "a", ".", "b_dir", "is", "None", ":", "\n", "        ", "raise", "Exception", "(", "\"missing b_dir\"", ")", "\n", "\n", "# find corresponding file in b_dir, could have a different extension", "\n", "", "basename", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "src_path", ")", ")", "\n", "for", "ext", "in", "[", "\".png\"", ",", "\".jpg\"", "]", ":", "\n", "        ", "sibling_path", "=", "os", ".", "path", ".", "join", "(", "a", ".", "b_dir", ",", "basename", "+", "ext", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "sibling_path", ")", ":", "\n", "            ", "sibling", "=", "im", ".", "load", "(", "sibling_path", ")", "\n", "break", "\n", "", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"could not find sibling image for \"", "+", "src_path", ")", "\n", "\n", "# make sure that dimensions are correct", "\n", "", "height", ",", "width", ",", "_", "=", "src", ".", "shape", "\n", "if", "height", "!=", "sibling", ".", "shape", "[", "0", "]", "or", "width", "!=", "sibling", ".", "shape", "[", "1", "]", ":", "\n", "        ", "raise", "Exception", "(", "\"differing sizes\"", ")", "\n", "\n", "# convert both images to RGB if necessary", "\n", "", "if", "src", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "        ", "src", "=", "im", ".", "grayscale_to_rgb", "(", "images", "=", "src", ")", "\n", "\n", "", "if", "sibling", ".", "shape", "[", "2", "]", "==", "1", ":", "\n", "        ", "sibling", "=", "im", ".", "grayscale_to_rgb", "(", "images", "=", "sibling", ")", "\n", "\n", "# remove alpha channel", "\n", "", "if", "src", ".", "shape", "[", "2", "]", "==", "4", ":", "\n", "        ", "src", "=", "src", "[", ":", ",", ":", ",", ":", "3", "]", "\n", "\n", "", "if", "sibling", ".", "shape", "[", "2", "]", "==", "4", ":", "\n", "        ", "sibling", "=", "sibling", "[", ":", ",", ":", ",", ":", "3", "]", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "[", "src", ",", "sibling", "]", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.grayscale": [[110, 112], ["tfimage.grayscale_to_rgb", "tfimage.rgb_to_grayscale"], "function", ["None"], ["", "def", "grayscale", "(", "src", ")", ":", "\n", "    ", "return", "im", ".", "grayscale_to_rgb", "(", "images", "=", "im", ".", "rgb_to_grayscale", "(", "images", "=", "src", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.run_caffe": [[115, 130], ["caffe.Net.blobs[].reshape", "caffe.Net.forward", "caffe.Net"], "function", ["None"], ["def", "run_caffe", "(", "src", ")", ":", "\n", "# lazy load caffe and create net", "\n", "    ", "global", "net", "\n", "if", "net", "is", "None", ":", "\n", "# don't require caffe unless we are doing edge detection", "\n", "        ", "os", ".", "environ", "[", "\"GLOG_minloglevel\"", "]", "=", "\"2\"", "# disable logging from caffe", "\n", "import", "caffe", "\n", "# using this requires using the docker image or assembling a bunch of dependencies", "\n", "# and then changing these hardcoded paths", "\n", "net", "=", "caffe", ".", "Net", "(", "\"/opt/caffe/examples/hed/deploy.prototxt\"", ",", "\"/opt/caffe/hed_pretrained_bsds.caffemodel\"", ",", "caffe", ".", "TEST", ")", "\n", "\n", "", "net", ".", "blobs", "[", "\"data\"", "]", ".", "reshape", "(", "1", ",", "*", "src", ".", "shape", ")", "\n", "net", ".", "blobs", "[", "\"data\"", "]", ".", "data", "[", "...", "]", "=", "src", "\n", "net", ".", "forward", "(", ")", "\n", "return", "net", ".", "blobs", "[", "\"sigmoid-fuse\"", "]", ".", "data", "[", "0", "]", "[", "0", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.edges": [[132, 190], ["numpy.pad", "numpy.array", "src.transpose.transpose", "edge_pool.apply", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile", "scipy.io.savemat", "dict", "dict.items", "args.extend", "tfimage.load", "args.extend", "subprocess.check_output", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.tfimage.load"], ["", "def", "edges", "(", "src", ")", ":", "\n", "# based on https://github.com/phillipi/pix2pix/blob/master/scripts/edges/batch_hed.py", "\n", "# and https://github.com/phillipi/pix2pix/blob/master/scripts/edges/PostprocessHED.m", "\n", "    ", "import", "scipy", ".", "io", "\n", "src", "=", "src", "*", "255", "\n", "border", "=", "128", "# put a padding around images since edge detection seems to detect edge of image", "\n", "src", "=", "src", "[", ":", ",", ":", ",", ":", "3", "]", "# remove alpha channel if present", "\n", "src", "=", "np", ".", "pad", "(", "src", ",", "(", "(", "border", ",", "border", ")", ",", "(", "border", ",", "border", ")", ",", "(", "0", ",", "0", ")", ")", ",", "\"reflect\"", ")", "\n", "src", "=", "src", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "\n", "src", "-=", "np", ".", "array", "(", "(", "104.00698793", ",", "116.66876762", ",", "122.67891434", ")", ")", "\n", "src", "=", "src", ".", "transpose", "(", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "# [height, width, channels] => [batch, channel, height, width]", "\n", "fuse", "=", "edge_pool", ".", "apply", "(", "run_caffe", ",", "[", "src", "]", ")", "\n", "fuse", "=", "fuse", "[", "border", ":", "-", "border", ",", "border", ":", "-", "border", "]", "\n", "\n", "with", "tempfile", ".", "NamedTemporaryFile", "(", "suffix", "=", "\".png\"", ")", "as", "png_file", ",", "tempfile", ".", "NamedTemporaryFile", "(", "suffix", "=", "\".mat\"", ")", "as", "mat_file", ":", "\n", "        ", "scipy", ".", "io", ".", "savemat", "(", "mat_file", ".", "name", ",", "{", "\"input\"", ":", "fuse", "}", ")", "\n", "\n", "octave_code", "=", "r\"\"\"\nE = 1-load(input_path).input;\nE = imresize(E, [image_width,image_width]);\nE = 1 - E;\nE = single(E);\n[Ox, Oy] = gradient(convTri(E, 4), 1);\n[Oxx, ~] = gradient(Ox, 1);\n[Oxy, Oyy] = gradient(Oy, 1);\nO = mod(atan(Oyy .* sign(-Oxy) ./ (Oxx + 1e-5)), pi);\nE = edgesNmsMex(E, O, 1, 5, 1.01, 1);\nE = double(E >= max(eps, threshold));\nE = bwmorph(E, 'thin', inf);\nE = bwareaopen(E, small_edge);\nE = 1 - E;\nE = uint8(E * 255);\nimwrite(E, output_path);\n\"\"\"", "\n", "\n", "config", "=", "dict", "(", "\n", "input_path", "=", "\"'%s'\"", "%", "mat_file", ".", "name", ",", "\n", "output_path", "=", "\"'%s'\"", "%", "png_file", ".", "name", ",", "\n", "image_width", "=", "256", ",", "\n", "threshold", "=", "25.0", "/", "255.0", ",", "\n", "small_edge", "=", "5", ",", "\n", ")", "\n", "\n", "args", "=", "[", "\"octave\"", "]", "\n", "for", "k", ",", "v", "in", "config", ".", "items", "(", ")", ":", "\n", "            ", "args", ".", "extend", "(", "[", "\"--eval\"", ",", "\"%s=%s;\"", "%", "(", "k", ",", "v", ")", "]", ")", "\n", "\n", "", "args", ".", "extend", "(", "[", "\"--eval\"", ",", "octave_code", "]", ")", "\n", "try", ":", "\n", "            ", "subprocess", ".", "check_output", "(", "args", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", "as", "e", ":", "\n", "            ", "print", "(", "\"octave failed\"", ")", "\n", "print", "(", "\"returncode:\"", ",", "e", ".", "returncode", ")", "\n", "print", "(", "\"output:\"", ",", "e", ".", "output", ")", "\n", "raise", "\n", "", "return", "im", ".", "load", "(", "png_file", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.process": [[192, 209], ["tfimage.load", "tfimage.save", "process.grayscale", "process.resize", "process.blank", "process.combine", "process.edges", "Exception"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.tfimage.load", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.tfimage.save", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.grayscale", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.resize", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.blank", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.combine", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.edges"], ["", "", "def", "process", "(", "src_path", ",", "dst_path", ")", ":", "\n", "    ", "src", "=", "im", ".", "load", "(", "src_path", ")", "\n", "\n", "if", "a", ".", "operation", "==", "\"grayscale\"", ":", "\n", "        ", "dst", "=", "grayscale", "(", "src", ")", "\n", "", "elif", "a", ".", "operation", "==", "\"resize\"", ":", "\n", "        ", "dst", "=", "resize", "(", "src", ")", "\n", "", "elif", "a", ".", "operation", "==", "\"blank\"", ":", "\n", "        ", "dst", "=", "blank", "(", "src", ")", "\n", "", "elif", "a", ".", "operation", "==", "\"combine\"", ":", "\n", "        ", "dst", "=", "combine", "(", "src", ",", "src_path", ")", "\n", "", "elif", "a", ".", "operation", "==", "\"edges\"", ":", "\n", "        ", "dst", "=", "edges", "(", "src", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid operation\"", ")", "\n", "\n", "", "im", ".", "save", "(", "dst", ",", "dst_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.complete": [[216, 232], ["time.time", "print"], "function", ["None"], ["def", "complete", "(", ")", ":", "\n", "    ", "global", "num_complete", ",", "rate", ",", "last_complete", "\n", "\n", "with", "complete_lock", ":", "\n", "        ", "num_complete", "+=", "1", "\n", "now", "=", "time", ".", "time", "(", ")", "\n", "elapsed", "=", "now", "-", "start", "\n", "rate", "=", "num_complete", "/", "elapsed", "\n", "if", "rate", ">", "0", ":", "\n", "            ", "remaining", "=", "(", "total", "-", "num_complete", ")", "/", "rate", "\n", "", "else", ":", "\n", "            ", "remaining", "=", "0", "\n", "\n", "", "print", "(", "\"%d/%d complete  %0.2f images/sec  %dm%ds elapsed  %dm%ds remaining\"", "%", "(", "num_complete", ",", "total", ",", "rate", ",", "elapsed", "//", "60", ",", "elapsed", "%", "60", ",", "remaining", "//", "60", ",", "remaining", "%", "60", ")", ")", "\n", "\n", "last_complete", "=", "now", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.main": [[234, 305], ["tfimage.find", "print", "len", "print", "time.time", "os.path.exists", "os.makedirs", "os.path.splitext", "os.path.join", "os.path.exists", "multiprocessing.Pool", "tensorflow.train.input_producer", "tf.train.input_producer.dequeue", "tensorflow.local_variables_initializer", "os.path.basename", "src_paths.append", "dst_paths.append", "tensorflow.Session", "zip", "zip", "tensorflow.Session", "sess.run", "tensorflow.train.Coordinator", "tensorflow.train.start_queue_runners", "range", "process.process", "process.complete", "sess.as_default", "threading.Thread", "threading.Thread.start", "tf.train.start_queue_runners.append", "tf.train.Coordinator.join", "tf.train.Coordinator.should_stop", "process.process", "process.complete", "tf.train.Coordinator.request_stop", "tf.train.Coordinator.join", "sess.run", "tf.train.Coordinator.request_stop"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.tfimage.find", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.process", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.complete", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.process", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.process.complete"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "a", ".", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "a", ".", "output_dir", ")", "\n", "\n", "", "src_paths", "=", "[", "]", "\n", "dst_paths", "=", "[", "]", "\n", "\n", "skipped", "=", "0", "\n", "for", "src_path", "in", "im", ".", "find", "(", "a", ".", "input_dir", ")", ":", "\n", "        ", "name", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "src_path", ")", ")", "\n", "dst_path", "=", "os", ".", "path", ".", "join", "(", "a", ".", "output_dir", ",", "name", "+", "\".png\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "dst_path", ")", ":", "\n", "            ", "skipped", "+=", "1", "\n", "", "else", ":", "\n", "            ", "src_paths", ".", "append", "(", "src_path", ")", "\n", "dst_paths", ".", "append", "(", "dst_path", ")", "\n", "\n", "", "", "print", "(", "\"skipping %d files that already exist\"", "%", "skipped", ")", "\n", "\n", "global", "total", "\n", "total", "=", "len", "(", "src_paths", ")", "\n", "\n", "print", "(", "\"processing %d files\"", "%", "total", ")", "\n", "\n", "global", "start", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "a", ".", "operation", "==", "\"edges\"", ":", "\n", "# use a multiprocessing pool for this operation so it can use multiple CPUs", "\n", "# create the pool before we launch processing threads", "\n", "        ", "global", "edge_pool", "\n", "edge_pool", "=", "multiprocessing", ".", "Pool", "(", "a", ".", "workers", ")", "\n", "\n", "", "if", "a", ".", "workers", "==", "1", ":", "\n", "        ", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "for", "src_path", ",", "dst_path", "in", "zip", "(", "src_paths", ",", "dst_paths", ")", ":", "\n", "                ", "process", "(", "src_path", ",", "dst_path", ")", "\n", "complete", "(", ")", "\n", "", "", "", "else", ":", "\n", "        ", "queue", "=", "tf", ".", "train", ".", "input_producer", "(", "zip", "(", "src_paths", ",", "dst_paths", ")", ",", "shuffle", "=", "False", ",", "num_epochs", "=", "1", ")", "\n", "dequeue_op", "=", "queue", ".", "dequeue", "(", ")", "\n", "\n", "def", "worker", "(", "coord", ")", ":", "\n", "            ", "with", "sess", ".", "as_default", "(", ")", ":", "\n", "                ", "while", "not", "coord", ".", "should_stop", "(", ")", ":", "\n", "                    ", "try", ":", "\n", "                        ", "src_path", ",", "dst_path", "=", "sess", ".", "run", "(", "dequeue_op", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                        ", "coord", ".", "request_stop", "(", ")", "\n", "break", "\n", "\n", "", "process", "(", "src_path", ",", "dst_path", ")", "\n", "complete", "(", ")", "\n", "\n", "# init epoch counter for the queue", "\n", "", "", "", "local_init_op", "=", "tf", ".", "local_variables_initializer", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "local_init_op", ")", "\n", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "threads", "=", "tf", ".", "train", ".", "start_queue_runners", "(", "coord", "=", "coord", ")", "\n", "for", "i", "in", "range", "(", "a", ".", "workers", ")", ":", "\n", "                ", "t", "=", "threading", ".", "Thread", "(", "target", "=", "worker", ",", "args", "=", "(", "coord", ",", ")", ")", "\n", "t", ".", "start", "(", ")", "\n", "threads", ".", "append", "(", "t", ")", "\n", "\n", "", "try", ":", "\n", "                ", "coord", ".", "join", "(", "threads", ")", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "                ", "coord", ".", "request_stop", "(", ")", "\n", "coord", ".", "join", "(", "threads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.split.main": [[22, 47], ["random.seed", "glob.glob", "glob.glob.sort", "assignments.extend", "assignments.extend", "assignments.extend", "print", "zip", "os.path.join", "random.shuffle", "len", "len", "os.path.join", "print", "os.rename", "int", "int", "int", "os.path.join", "os.path.basename", "os.path.exists", "os.makedirs", "len", "len", "len", "len"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "random", ".", "seed", "(", "0", ")", "\n", "\n", "files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "a", ".", "dir", ",", "\"*.png\"", ")", ")", "\n", "files", ".", "sort", "(", ")", "\n", "\n", "assignments", "=", "[", "]", "\n", "assignments", ".", "extend", "(", "[", "\"train\"", "]", "*", "int", "(", "a", ".", "train_frac", "*", "len", "(", "files", ")", ")", ")", "\n", "assignments", ".", "extend", "(", "[", "\"test\"", "]", "*", "int", "(", "a", ".", "test_frac", "*", "len", "(", "files", ")", ")", ")", "\n", "assignments", ".", "extend", "(", "[", "\"val\"", "]", "*", "int", "(", "len", "(", "files", ")", "-", "len", "(", "assignments", ")", ")", ")", "\n", "\n", "if", "not", "a", ".", "sort", ":", "\n", "        ", "random", ".", "shuffle", "(", "assignments", ")", "\n", "\n", "", "for", "name", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", ":", "\n", "        ", "if", "name", "in", "assignments", ":", "\n", "            ", "d", "=", "os", ".", "path", ".", "join", "(", "a", ".", "dir", ",", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "d", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "d", ")", "\n", "\n", "", "", "", "print", "(", "len", "(", "files", ")", ",", "len", "(", "assignments", ")", ")", "\n", "for", "inpath", ",", "assignment", "in", "zip", "(", "files", ",", "assignments", ")", ":", "\n", "        ", "outpath", "=", "os", ".", "path", ".", "join", "(", "a", ".", "dir", ",", "assignment", ",", "os", ".", "path", ".", "basename", "(", "inpath", ")", ")", "\n", "print", "(", "inpath", ",", "\"->\"", ",", "outpath", ")", "\n", "os", ".", "rename", "(", "inpath", ",", "outpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.dockrun.which": [[11, 70], ["os.path.dirname", "os.environ.get.split", "set", "dockrun.which._access_check"], "function", ["None"], ["def", "which", "(", "cmd", ",", "mode", "=", "os", ".", "F_OK", "|", "os", ".", "X_OK", ",", "path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Given a command, mode, and a PATH string, return the path which\n    conforms to the given mode on the PATH, or None if there is no such\n    file.\n    `mode` defaults to os.F_OK | os.X_OK. `path` defaults to the result\n    of os.environ.get(\"PATH\"), or can be overridden with a custom search\n    path.\n    \"\"\"", "\n", "# Check that a given file can be accessed with the correct mode.", "\n", "# Additionally check that `file` is not a directory, as on Windows", "\n", "# directories pass the os.access check.", "\n", "def", "_access_check", "(", "fn", ",", "mode", ")", ":", "\n", "        ", "return", "(", "os", ".", "path", ".", "exists", "(", "fn", ")", "and", "os", ".", "access", "(", "fn", ",", "mode", ")", "\n", "and", "not", "os", ".", "path", ".", "isdir", "(", "fn", ")", ")", "\n", "\n", "# If we're given a path with a directory part, look it up directly rather", "\n", "# than referring to PATH directories. This includes checking relative to the", "\n", "# current directory, e.g. ./script", "\n", "", "if", "os", ".", "path", ".", "dirname", "(", "cmd", ")", ":", "\n", "        ", "if", "_access_check", "(", "cmd", ",", "mode", ")", ":", "\n", "            ", "return", "cmd", "\n", "", "return", "None", "\n", "\n", "", "if", "path", "is", "None", ":", "\n", "        ", "path", "=", "os", ".", "environ", ".", "get", "(", "\"PATH\"", ",", "os", ".", "defpath", ")", "\n", "", "if", "not", "path", ":", "\n", "        ", "return", "None", "\n", "", "path", "=", "path", ".", "split", "(", "os", ".", "pathsep", ")", "\n", "\n", "if", "sys", ".", "platform", "==", "\"win32\"", ":", "\n", "# The current directory takes precedence on Windows.", "\n", "        ", "if", "not", "os", ".", "curdir", "in", "path", ":", "\n", "            ", "path", ".", "insert", "(", "0", ",", "os", ".", "curdir", ")", "\n", "\n", "# PATHEXT is necessary to check on Windows.", "\n", "", "pathext", "=", "os", ".", "environ", ".", "get", "(", "\"PATHEXT\"", ",", "\"\"", ")", ".", "split", "(", "os", ".", "pathsep", ")", "\n", "# See if the given file matches any of the expected path extensions.", "\n", "# This will allow us to short circuit when given \"python.exe\".", "\n", "# If it does match, only test that one, otherwise we have to try", "\n", "# others.", "\n", "if", "any", "(", "cmd", ".", "lower", "(", ")", ".", "endswith", "(", "ext", ".", "lower", "(", ")", ")", "for", "ext", "in", "pathext", ")", ":", "\n", "            ", "files", "=", "[", "cmd", "]", "\n", "", "else", ":", "\n", "            ", "files", "=", "[", "cmd", "+", "ext", "for", "ext", "in", "pathext", "]", "\n", "", "", "else", ":", "\n", "# On other platforms you don't have things like PATHEXT to tell you", "\n", "# what file suffixes are executable, so just pass on cmd as-is.", "\n", "        ", "files", "=", "[", "cmd", "]", "\n", "\n", "", "seen", "=", "set", "(", ")", "\n", "for", "dir", "in", "path", ":", "\n", "        ", "normdir", "=", "os", ".", "path", ".", "normcase", "(", "dir", ")", "\n", "if", "not", "normdir", "in", "seen", ":", "\n", "            ", "seen", ".", "add", "(", "normdir", ")", "\n", "for", "thefile", "in", "files", ":", "\n", "                ", "name", "=", "os", ".", "path", ".", "join", "(", "dir", ",", "thefile", ")", "\n", "if", "_access_check", "(", "name", ",", "mode", ")", ":", "\n", "                    ", "return", "name", "\n", "", "", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.dockrun.main": [[72, 110], ["dockrun.which", "enumerate", "print", "os.execvp", "dockrun.which", "Exception", "docker_args.extend", "arg.startswith", "os.access", "os.getcwd", "shlex.quote"], "function", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.dockrun.which", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.dockrun.which"], ["", "def", "main", "(", ")", ":", "\n", "    ", "cmd", "=", "sys", ".", "argv", "[", "1", ":", "]", "\n", "\n", "# check if nvidia-docker or docker are on path", "\n", "docker_path", "=", "which", "(", "\"nvidia-docker\"", ")", "\n", "if", "docker_path", "is", "None", ":", "\n", "        ", "docker_path", "=", "which", "(", "\"docker\"", ")", "\n", "\n", "", "if", "docker_path", "is", "None", ":", "\n", "        ", "raise", "Exception", "(", "\"docker not found\"", ")", "\n", "\n", "", "docker_args", "=", "[", "\n", "\"--rm\"", ",", "\n", "\"--volume\"", ",", "\n", "\"/:/host\"", ",", "\n", "\"--workdir\"", ",", "\n", "\"/host\"", "+", "os", ".", "getcwd", "(", ")", ",", "\n", "\"--env\"", ",", "\n", "\"PYTHONUNBUFFERED=x\"", ",", "\n", "\"--env\"", ",", "\n", "\"CUDA_CACHE_PATH=/host/tmp/cuda-cache\"", ",", "\n", "]", "\n", "\n", "if", "\"CUDA_VISIBLE_DEVICES\"", "in", "os", ".", "environ", ":", "\n", "        ", "docker_args", ".", "extend", "(", "[", "\"--env\"", ",", "\"CUDA_VISIBLE_DEVICES=%s\"", "%", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "]", ")", "\n", "\n", "", "for", "i", ",", "arg", "in", "enumerate", "(", "cmd", ")", ":", "\n", "# change absolute paths", "\n", "        ", "if", "arg", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "            ", "cmd", "[", "i", "]", "=", "\"/host\"", "+", "arg", "\n", "\n", "", "", "args", "=", "[", "docker_path", ",", "\"run\"", "]", "+", "docker_args", "+", "[", "\"affinelayer/pix2pix-tensorflow:v3\"", "]", "+", "cmd", "\n", "\n", "if", "not", "os", ".", "access", "(", "\"/var/run/docker.sock\"", ",", "os", ".", "R_OK", ")", ":", "\n", "        ", "args", "=", "[", "\"sudo\"", "]", "+", "args", "\n", "\n", "", "print", "(", "\"running\"", ",", "\" \"", ".", "join", "(", "shlex", ".", "quote", "(", "a", ")", "for", "a", "in", "args", ")", ")", "\n", "os", ".", "execvp", "(", "args", "[", "0", "]", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.test.main": [[16, 61], ["time.time", "os.path.exists", "images.items", "print", "shutil.rmtree", "test.main.run"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "images", "=", "{", "\n", "\"affinelayer\"", ":", "\"affinelayer/pix2pix-tensorflow:v3\"", ",", "\n", "# \"py2-tensorflow\": \"tensorflow/tensorflow:1.4.1-gpu\",", "\n", "# \"py3-tensorflow\": \"tensorflow/tensorflow:1.4.1-gpu-py3\",", "\n", "}", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "OUTPUT_DIR", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "OUTPUT_DIR", ")", "\n", "\n", "", "for", "image_name", ",", "image", "in", "images", ".", "items", "(", ")", ":", "\n", "        ", "def", "run", "(", "cmd", ")", ":", "\n", "            ", "docker", "=", "\"docker\"", "\n", "if", "sys", ".", "platform", ".", "startswith", "(", "\"linux\"", ")", ":", "\n", "                ", "docker", "=", "\"nvidia-docker\"", "\n", "\n", "", "prefix", "=", "[", "docker", ",", "\"run\"", ",", "\"--rm\"", ",", "\"--volume\"", ",", "os", ".", "getcwd", "(", ")", "+", "\":/prj\"", ",", "\"--volume\"", ",", "INPUT_DIR", "+", "\":/input\"", ",", "\"--volume\"", ",", "os", ".", "path", ".", "join", "(", "OUTPUT_DIR", ",", "image_name", ")", "+", "\":/output\"", ",", "\"--workdir\"", ",", "\"/prj\"", ",", "\"--env\"", ",", "\"PYTHONUNBUFFERED=x\"", ",", "\"--volume\"", ",", "\"/tmp/cuda-cache:/cuda-cache\"", ",", "\"--env\"", ",", "\"CUDA_CACHE_PATH=/cuda-cache\"", ",", "image", "]", "\n", "args", "=", "prefix", "+", "shlex", ".", "split", "(", "cmd", ")", "\n", "print", "(", "\" \"", ".", "join", "(", "args", ")", ")", "\n", "subprocess", ".", "check_call", "(", "args", ")", "\n", "\n", "", "run", "(", "\"python tools/process.py --input_dir /input/pusheen/original --operation resize --output_dir /output/process_resize\"", ")", "\n", "if", "image_name", "==", "\"affinelayer\"", ":", "\n", "            ", "run", "(", "\"python tools/process.py --input_dir /output/process_resize --operation edges --output_dir /output/process_edges\"", ")", "\n", "\n", "", "for", "direction", "in", "[", "\"AtoB\"", ",", "\"BtoA\"", "]", ":", "\n", "            ", "for", "dataset", "in", "[", "\"facades\"", ",", "\"maps\"", "]", ":", "\n", "                ", "name", "=", "dataset", "+", "\"_\"", "+", "direction", "\n", "run", "(", "\"python pix2pix.py --mode train --input_dir /input/official/%s/train --output_dir /output/%s_train --display_freq 1 --max_steps 1 --which_direction %s --seed 0\"", "%", "(", "dataset", ",", "name", ",", "direction", ")", ")", "\n", "run", "(", "\"python pix2pix.py --mode test --input_dir /input/official/%s/val --output_dir /output/%s_test --display_freq 1 --max_steps 1 --checkpoint /output/%s_train --seed 0\"", "%", "(", "dataset", ",", "name", ",", "name", ")", ")", "\n", "\n", "", "dataset", "=", "\"color-lab\"", "\n", "name", "=", "dataset", "+", "\"_\"", "+", "direction", "\n", "run", "(", "\"python pix2pix.py --mode train --input_dir /input/%s/train --output_dir /output/%s_train --display_freq 1 --max_steps 1 --which_direction %s --lab_colorization --seed 0\"", "%", "(", "dataset", ",", "name", ",", "direction", ")", ")", "\n", "run", "(", "\"python pix2pix.py --mode test --input_dir /input/%s/val --output_dir /output/%s_test --display_freq 1 --max_steps 1 --checkpoint /output/%s_train --seed 0\"", "%", "(", "dataset", ",", "name", ",", "name", ")", ")", "\n", "\n", "# using pretrained model", "\n", "# for dataset, direction in [(\"facades\", \"BtoA\")]:", "\n", "#     name = dataset + \"_\" + direction", "\n", "#     run(\"python pix2pix.py --mode test --output_dir test/%s_pretrained_test --input_dir /input/official/%s/val --max_steps 100 --which_direction %s --seed 0 --checkpoint /input/pretrained/%s\" % (name, dataset, direction, name))", "\n", "#     run(\"python pix2pix.py --mode export --output_dir test/%s_pretrained_export --checkpoint /input/pretrained/%s\" % (name, name))", "\n", "\n", "", "", "print", "(", "\"elapsed\"", ",", "int", "(", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.tfimage.create_op": [[9, 20], ["func", "kwargs.items", "tensorflow.get_default_session().run", "tensorflow.get_default_session"], "function", ["None"], ["def", "create_op", "(", "func", ",", "**", "placeholders", ")", ":", "\n", "    ", "op", "=", "func", "(", "**", "placeholders", ")", "\n", "\n", "def", "f", "(", "**", "kwargs", ")", ":", "\n", "        ", "feed_dict", "=", "{", "}", "\n", "for", "argname", ",", "argvalue", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "placeholder", "=", "placeholders", "[", "argname", "]", "\n", "feed_dict", "[", "placeholder", "]", "=", "argvalue", "\n", "", "return", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "op", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.tfimage.load": [[97, 111], ["os.path.splitext", "to_float32", "open", "f.read", "path.lower", "decode_jpeg", "decode_png", "Exception"], "function", ["None"], ["def", "load", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "contents", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "_", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "path", ".", "lower", "(", ")", ")", "\n", "\n", "if", "ext", "==", "\".jpg\"", ":", "\n", "        ", "image", "=", "decode_jpeg", "(", "contents", "=", "contents", ")", "\n", "", "elif", "ext", "==", "\".png\"", ":", "\n", "        ", "image", "=", "decode_png", "(", "contents", "=", "contents", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid image suffix\"", ")", "\n", "\n", "", "return", "to_float32", "(", "image", "=", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.tfimage.find": [[113, 121], ["os.listdir", "result.sort", "os.path.splitext", "filename.lower", "result.append", "os.path.join"], "function", ["None"], ["", "def", "find", "(", "d", ")", ":", "\n", "    ", "result", "=", "[", "]", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "d", ")", ":", "\n", "        ", "_", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "filename", ".", "lower", "(", ")", ")", "\n", "if", "ext", "==", "\".jpg\"", "or", "ext", "==", "\".png\"", ":", "\n", "            ", "result", ".", "append", "(", "os", ".", "path", ".", "join", "(", "d", ",", "filename", ")", ")", "\n", "", "", "result", ".", "sort", "(", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.tfimage.save": [[123, 145], ["os.path.splitext", "to_uint8", "os.path.dirname", "os.path.exists", "path.lower", "encode_jpeg", "os.makedirs", "open", "f.write", "encode_png", "Exception", "os.path.exists", "os.remove", "Exception"], "function", ["None"], ["", "def", "save", "(", "image", ",", "path", ",", "replace", "=", "False", ")", ":", "\n", "    ", "_", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "path", ".", "lower", "(", ")", ")", "\n", "image", "=", "to_uint8", "(", "image", "=", "image", ")", "\n", "if", "ext", "==", "\".jpg\"", ":", "\n", "        ", "encoded", "=", "encode_jpeg", "(", "image", "=", "image", ")", "\n", "", "elif", "ext", "==", "\".png\"", ":", "\n", "        ", "encoded", "=", "encode_png", "(", "image", "=", "image", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"invalid image suffix\"", ")", "\n", "\n", "", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "path", ")", "\n", "if", "dirname", "!=", "\"\"", "and", "not", "os", ".", "path", ".", "exists", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "if", "replace", ":", "\n", "            ", "os", ".", "remove", "(", "path", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "\"file already exists at \"", "+", "path", ")", "\n", "\n", "", "", "with", "open", "(", "path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "encoded", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.pytorch_checkpoint_dumper.PytorchCheckpointDumper.__init__": [[50, 66], ["checkpoint_dumper.CheckpointDumper.__init__", "torch.load"], "methods", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.__init__", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.tools.tfimage.load"], ["def", "__init__", "(", "self", ",", "checkpoint_file", ",", "output_dir", ",", "remove_variables_regex", ")", ":", "\n", "    ", "\"\"\"Constructs object for Pytorch Checkpoint Dumper.\n\n    Parameters\n    ----------\n    checkpoint_file : str\n        Path to the model checkpoint\n    output_dir : str\n        Output directory path\n    remove_variables_regex : str\n        Regex expression for variables to be ignored\n    \"\"\"", "\n", "super", "(", "PytorchCheckpointDumper", ",", "self", ")", ".", "__init__", "(", "\n", "checkpoint_file", ",", "output_dir", ",", "remove_variables_regex", ")", "\n", "\n", "self", ".", "state_dictionary", "=", "torch", ".", "load", "(", "self", ".", "checkpoint_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.pytorch_checkpoint_dumper.PytorchCheckpointDumper.var_name_to_filename": [[67, 89], ["chars.append", "chars.append"], "methods", ["None"], ["", "def", "var_name_to_filename", "(", "self", ",", "var_name", ")", ":", "\n", "    ", "\"\"\"Converts variable names to standard file names.\n\n    Parameters\n    ----------\n    var_name : str\n        Variable name to be converted\n\n    Returns\n    -------\n    str\n        Standardized file name\n    \"\"\"", "\n", "chars", "=", "[", "]", "\n", "\n", "for", "c", "in", "var_name", ":", "\n", "      ", "if", "c", "in", "CheckpointDumper", ".", "FILENAME_CHARS", ":", "\n", "        ", "chars", ".", "append", "(", "c", ")", "\n", "", "elif", "c", "==", "'.'", ":", "\n", "        ", "chars", ".", "append", "(", "'_'", ")", "\n", "\n", "", "", "return", "''", ".", "join", "(", "chars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.pytorch_checkpoint_dumper.PytorchCheckpointDumper.build_and_dump_vars": [[90, 105], ["six.iteritems", "pytorch_checkpoint_dumper.PytorchCheckpointDumper.dump_manifest", "pytorch_checkpoint_dumper.PytorchCheckpointDumper.should_ignore", "pytorch_checkpoint_dumper.PytorchCheckpointDumper.var_name_to_filename", "list", "var_weights.cpu().numpy", "pytorch_checkpoint_dumper.PytorchCheckpointDumper.dump_weights", "print", "map", "list", "var_weights.cpu", "var_weights.size"], "methods", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.checkpoint_dumper.CheckpointDumper.dump_manifest", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.checkpoint_dumper.CheckpointDumper.should_ignore", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.var_name_to_filename", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.checkpoint_dumper.CheckpointDumper.dump_weights"], ["", "def", "build_and_dump_vars", "(", "self", ")", ":", "\n", "    ", "\"\"\"Builds and dumps variables and a manifest file.\n    \"\"\"", "\n", "for", "(", "var_name", ",", "var_weights", ")", "in", "iteritems", "(", "self", ".", "state_dictionary", ")", ":", "\n", "      ", "if", "(", "self", ".", "should_ignore", "(", "var_name", ")", ")", ":", "\n", "        ", "print", "(", "'Ignoring '", "+", "var_name", ")", "\n", "continue", "\n", "\n", "", "var_filename", "=", "self", ".", "var_name_to_filename", "(", "var_name", ")", "\n", "var_shape", "=", "list", "(", "map", "(", "int", ",", "list", "(", "var_weights", ".", "size", "(", ")", ")", ")", ")", "\n", "tensor", "=", "var_weights", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "self", ".", "dump_weights", "(", "var_name", ",", "var_filename", ",", "var_shape", ",", "tensor", ")", "\n", "\n", "", "self", ".", "dump_manifest", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.checkpoint_dumper.CheckpointDumper.__init__": [[53, 73], ["os.path.expanduser", "os.path.expanduser", "re.compile", "checkpoint_dumper.CheckpointDumper.make_dir"], "methods", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.checkpoint_dumper.CheckpointDumper.make_dir"], ["def", "__init__", "(", "self", ",", "checkpoint_file", ",", "output_dir", ",", "remove_variables_regex", ")", ":", "\n", "    ", "\"\"\"Constructs object for Checkpoint Dumper.\n\n    Parameters\n    ----------\n    checkpoint_file : str\n        Path to the model checkpoint\n    output_dir : str\n        Output directory path\n    remove_variables_regex : str\n        Regex expression for variables to be ignored\n    \"\"\"", "\n", "self", ".", "checkpoint_file", "=", "os", ".", "path", ".", "expanduser", "(", "checkpoint_file", ")", "\n", "self", ".", "output_dir", "=", "os", ".", "path", ".", "expanduser", "(", "output_dir", ")", "\n", "self", ".", "remove_variables_regex", "=", "remove_variables_regex", "\n", "\n", "self", ".", "manifest", "=", "{", "}", "\n", "self", ".", "remove_variables_regex_re", "=", "re", ".", "compile", "(", "self", ".", "remove_variables_regex", ")", "\n", "\n", "self", ".", "make_dir", "(", "self", ".", "output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.checkpoint_dumper.CheckpointDumper.make_dir": [[75, 86], ["os.path.exists", "os.makedirs"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "make_dir", "(", "directory", ")", ":", "\n", "    ", "\"\"\"Makes directory if not existing.\n    \n    Parameters\n    ----------\n    directory : str\n        Path to directory\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "      ", "os", ".", "makedirs", "(", "directory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.checkpoint_dumper.CheckpointDumper.should_ignore": [[88, 102], ["re.match"], "methods", ["None"], ["", "", "def", "should_ignore", "(", "self", ",", "name", ")", ":", "\n", "    ", "\"\"\"Checks whether name should be ignored or not.\n\n    Parameters\n    ----------\n    name : str\n        Name to be checked\n\n    Returns\n    -------\n    bool\n        Whether to ignore the name or not\n    \"\"\"", "\n", "return", "self", ".", "remove_variables_regex", "and", "re", ".", "match", "(", "self", ".", "remove_variables_regex_re", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.checkpoint_dumper.CheckpointDumper.dump_weights": [[104, 123], ["print", "open", "f.write", "os.path.join", "weights.tobytes"], "methods", ["None"], ["", "def", "dump_weights", "(", "self", ",", "variable_name", ",", "filename", ",", "shape", ",", "weights", ")", ":", "\n", "    ", "\"\"\"Creates a file with given name and dumps byte weights in it.\n\n    Parameters\n    ----------\n    variable_name : str\n        Name of given variable\n    filename : str\n        File name for given variable\n    shape : list\n        Shape of given variable\n    weights : ndarray\n        Weights for given variable\n    \"\"\"", "\n", "self", ".", "manifest", "[", "variable_name", "]", "=", "{", "'filename'", ":", "filename", ",", "'shape'", ":", "shape", "}", "\n", "\n", "print", "(", "'Writing variable '", "+", "variable_name", "+", "'...'", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "output_dir", ",", "filename", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "weights", ".", "tobytes", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.checkpoint_dumper.CheckpointDumper.dump_manifest": [[125, 139], ["os.path.join", "print", "open", "f.write", "json.dumps"], "methods", ["None"], ["", "", "def", "dump_manifest", "(", "self", ",", "filename", "=", "'manifest.json'", ")", ":", "\n", "    ", "\"\"\"Creates a manifest file with given name and dumps meta information\n    related to model.\n\n    Parameters\n    ----------\n    filename : str, optional\n        Manifest file name\n    \"\"\"", "\n", "manifest_fpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "output_dir", ",", "filename", ")", "\n", "\n", "print", "(", "'Writing manifest to '", "+", "manifest_fpath", ")", "\n", "with", "open", "(", "manifest_fpath", ",", "'w'", ")", "as", "f", ":", "\n", "      ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "manifest", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.dump_checkpoint_vars.get_checkpoint_dumper": [[25, 61], ["TensorflowCheckpointDumper", "PytorchCheckpointDumper", "Error"], "function", ["None"], ["def", "get_checkpoint_dumper", "(", "model_type", ",", "checkpoint_file", ",", "output_dir", ",", "remove_variables_regex", ")", ":", "\n", "  ", "\"\"\"Returns Checkpoint dumper instance for a given model type.\n\n  Parameters\n  ----------\n  model_type : str\n      Type of deeplearning framework\n  checkpoint_file : str\n      Path to checkpoint file\n  output_dir : str\n      Path to output directory\n  remove_variables_regex : str\n      Regex for variables to be ignored\n\n  Returns\n  -------\n  (TensorflowCheckpointDumper, PytorchCheckpointDumper)\n      Checkpoint Dumper Instance for corresponding model type\n\n  Raises\n  ------\n  Error\n      If particular model type is not supported\n  \"\"\"", "\n", "if", "model_type", "==", "'tensorflow'", ":", "\n", "    ", "from", "tensorflow_checkpoint_dumper", "import", "TensorflowCheckpointDumper", "\n", "\n", "return", "TensorflowCheckpointDumper", "(", "\n", "checkpoint_file", ",", "output_dir", ",", "remove_variables_regex", ")", "\n", "", "elif", "model_type", "==", "'pytorch'", ":", "\n", "    ", "from", "pytorch_checkpoint_dumper", "import", "PytorchCheckpointDumper", "\n", "\n", "return", "PytorchCheckpointDumper", "(", "\n", "checkpoint_file", ",", "output_dir", ",", "remove_variables_regex", ")", "\n", "", "else", ":", "\n", "    ", "raise", "Error", "(", "'Currently, \"%s\" models are not supported'", ".", "format", "(", "model_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.__init__": [[47, 63], ["checkpoint_dumper.CheckpointDumper.__init__", "tensorflow.train.NewCheckpointReader"], "methods", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.__init__"], ["def", "__init__", "(", "self", ",", "checkpoint_file", ",", "output_dir", ",", "remove_variables_regex", ")", ":", "\n", "    ", "\"\"\"Constructs object for Tensorflow Checkpoint Dumper.\n\n    Parameters\n    ----------\n    checkpoint_file : str\n        Path to the model checkpoint\n    output_dir : str\n        Output directory path\n    remove_variables_regex : str\n        Regex expression for variables to be ignored\n    \"\"\"", "\n", "super", "(", "TensorflowCheckpointDumper", ",", "self", ")", ".", "__init__", "(", "\n", "checkpoint_file", ",", "output_dir", ",", "remove_variables_regex", ")", "\n", "\n", "self", ".", "reader", "=", "tf", ".", "train", ".", "NewCheckpointReader", "(", "self", ".", "checkpoint_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.var_name_to_filename": [[64, 86], ["chars.append", "chars.append"], "methods", ["None"], ["", "def", "var_name_to_filename", "(", "self", ",", "var_name", ")", ":", "\n", "    ", "\"\"\"Converts variable names to standard file names.\n\n    Parameters\n    ----------\n    var_name : str\n        Variable name to be converted\n\n    Returns\n    -------\n    str\n        Standardized file name\n    \"\"\"", "\n", "chars", "=", "[", "]", "\n", "\n", "for", "c", "in", "var_name", ":", "\n", "      ", "if", "c", "in", "CheckpointDumper", ".", "FILENAME_CHARS", ":", "\n", "        ", "chars", ".", "append", "(", "c", ")", "\n", "", "elif", "c", "==", "'/'", ":", "\n", "        ", "chars", ".", "append", "(", "'_'", ")", "\n", "\n", "", "", "return", "''", ".", "join", "(", "chars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.build_and_dump_vars": [[87, 104], ["tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.reader.get_variable_to_shape_map", "six.iteritems", "tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.dump_manifest", "tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.var_name_to_filename", "tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.reader.get_tensor", "tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.dump_weights", "tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.should_ignore", "print"], "methods", ["home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.checkpoint_dumper.CheckpointDumper.dump_manifest", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.tensorflow_checkpoint_dumper.TensorflowCheckpointDumper.var_name_to_filename", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.checkpoint_dumper.CheckpointDumper.dump_weights", "home.repos.pwc.inspect_result.mohaEs_image-to-images-translation.dump_checkpoints.checkpoint_dumper.CheckpointDumper.should_ignore"], ["", "def", "build_and_dump_vars", "(", "self", ")", ":", "\n", "    ", "\"\"\"Builds and dumps variables and a manifest file.\n    \"\"\"", "\n", "var_to_shape_map", "=", "self", ".", "reader", ".", "get_variable_to_shape_map", "(", ")", "\n", "\n", "for", "(", "var_name", ",", "var_shape", ")", "in", "iteritems", "(", "var_to_shape_map", ")", ":", "\n", "      ", "if", "self", ".", "should_ignore", "(", "var_name", ")", "or", "var_name", "==", "'global_step'", ":", "\n", "        ", "print", "(", "'Ignoring '", "+", "var_name", ")", "\n", "continue", "\n", "\n", "", "var_filename", "=", "self", ".", "var_name_to_filename", "(", "var_name", ")", "\n", "self", ".", "manifest", "[", "var_name", "]", "=", "{", "'filename'", ":", "var_filename", ",", "'shape'", ":", "var_shape", "}", "\n", "\n", "tensor", "=", "self", ".", "reader", ".", "get_tensor", "(", "var_name", ")", "\n", "self", ".", "dump_weights", "(", "var_name", ",", "var_filename", ",", "var_shape", ",", "tensor", ")", "\n", "\n", "", "self", ".", "dump_manifest", "(", ")", "\n", "", "", ""]]}