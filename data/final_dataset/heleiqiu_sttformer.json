{"home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.AverageMeter.__init__": [[114, 116], ["main.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.AverageMeter.reset": [[117, 122], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "value", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.AverageMeter.update": [[123, 128], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "value", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "value", "=", "value", "\n", "self", ".", "sum", "+=", "value", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.__init__": [[133, 169], ["main.Processor.load_model", "main.Processor.load_data", "main.Processor.model.cuda", "os.path.exists", "os.makedirs", "os.path.join", "type", "os.path.isdir", "tensorboardX.SummaryWriter", "tensorboardX.SummaryWriter", "main.Processor.load_optimizer", "tensorboardX.SummaryWriter", "len", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "print", "input", "os.path.join", "os.path.join", "os.path.join", "shutil.rmtree", "print", "input", "print"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.load_model", "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.feeder_ntu.Feeder.load_data", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.load_optimizer"], ["def", "__init__", "(", "self", ",", "arg", ")", ":", "\n", "        ", "self", ".", "arg", "=", "arg", "\n", "self", ".", "global_step", "=", "0", "\n", "self", ".", "lr", "=", "self", ".", "arg", ".", "base_lr", "\n", "self", ".", "best_acc", "=", "0", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "arg", ".", "work_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "arg", ".", "work_dir", ")", "\n", "", "self", ".", "load_model", "(", ")", "\n", "self", ".", "load_data", "(", ")", "\n", "\n", "if", "arg", ".", "run_mode", "==", "'train'", ":", "\n", "            ", "result_visual", "=", "os", ".", "path", ".", "join", "(", "arg", ".", "work_dir", ",", "'runs'", ")", "\n", "if", "not", "arg", ".", "train_feeder_args", "[", "'debug'", "]", ":", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "result_visual", ")", ":", "\n", "                    ", "print", "(", "'log_dir: '", ",", "result_visual", ",", "'already exist'", ")", "\n", "answer", "=", "input", "(", "'delete it? y/n:'", ")", "\n", "if", "answer", "==", "'y'", ":", "\n", "                        ", "shutil", ".", "rmtree", "(", "result_visual", ")", "\n", "print", "(", "'Dir removed: '", ",", "result_visual", ")", "\n", "input", "(", "'Refresh the website of tensorboard by pressing any keys'", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "'Dir not removed: '", ",", "result_visual", ")", "\n", "", "", "self", ".", "train_writer", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "result_visual", ",", "'train'", ")", ",", "'train'", ")", "\n", "self", ".", "val_writer", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "result_visual", ",", "'val'", ")", ",", "'val'", ")", "\n", "\n", "self", ".", "load_optimizer", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "train_writer", "=", "self", ".", "val_writer", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "result_visual", ",", "'test'", ")", ",", "'test'", ")", "\n", "\n", "\n", "", "", "self", ".", "model", "=", "self", ".", "model", ".", "cuda", "(", "self", ".", "output_device", ")", "\n", "\n", "if", "type", "(", "self", ".", "arg", ".", "device", ")", "is", "list", ":", "\n", "            ", "if", "len", "(", "self", ".", "arg", ".", "device", ")", ">", "1", ":", "\n", "                ", "self", ".", "model", "=", "nn", ".", "DataParallel", "(", "self", ".", "model", ",", "device_ids", "=", "self", ".", "arg", ".", "device", ",", "output_device", "=", "self", ".", "output_device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.load_data": [[170, 189], ["main.import_class", "dict", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "main.Processor.print_log", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "import_class.", "import_class."], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.import_class", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log"], ["", "", "", "def", "load_data", "(", "self", ")", ":", "\n", "        ", "Feeder", "=", "import_class", "(", "self", ".", "arg", ".", "feeder", ")", "\n", "self", ".", "data_loader", "=", "dict", "(", ")", "\n", "if", "self", ".", "arg", ".", "run_mode", "==", "'train'", ":", "\n", "            ", "self", ".", "data_loader", "[", "'train'", "]", "=", "DataLoader", "(", "\n", "dataset", "=", "Feeder", "(", "**", "self", ".", "arg", ".", "train_feeder_args", ")", ",", "\n", "batch_size", "=", "self", ".", "arg", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "self", ".", "arg", ".", "num_worker", ",", "\n", "drop_last", "=", "True", ",", "\n", "worker_init_fn", "=", "init_seed", ")", "\n", "", "self", ".", "data_loader", "[", "'test'", "]", "=", "DataLoader", "(", "\n", "dataset", "=", "Feeder", "(", "**", "self", ".", "arg", ".", "test_feeder_args", ")", ",", "\n", "batch_size", "=", "self", ".", "arg", ".", "test_batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "arg", ".", "num_worker", ",", "\n", "drop_last", "=", "False", ",", "\n", "worker_init_fn", "=", "init_seed", ")", "\n", "self", ".", "print_log", "(", "'Data load finished'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.load_model": [[190, 230], ["main.import_class", "import_class.", "torch.CrossEntropyLoss().cuda", "torch.CrossEntropyLoss().cuda", "torch.CrossEntropyLoss().cuda", "main.Processor.print_log", "main.Processor.print_log", "collections.OrderedDict", "list", "type", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "pickle.load.keys", "main.Processor.model.load_state_dict", "open", "pickle.load", "main.Processor.model.state_dict", "list", "print", "main.Processor.update", "main.Processor.model.load_state_dict", "v.cuda", "pickle.load.items", "set().difference", "print", "k.split", "pickle.load.pop", "main.Processor.print_log", "main.Processor.print_log", "set", "set", "pickle.load.keys", "main.Processor.keys"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.import_class", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.AverageMeter.update", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log"], ["", "def", "load_model", "(", "self", ")", ":", "\n", "        ", "output_device", "=", "self", ".", "arg", ".", "device", "[", "0", "]", "if", "type", "(", "self", ".", "arg", ".", "device", ")", "is", "list", "else", "self", ".", "arg", ".", "device", "\n", "self", ".", "output_device", "=", "output_device", "\n", "Model", "=", "import_class", "(", "self", ".", "arg", ".", "model", ")", "\n", "# print(Model)", "\n", "self", ".", "model", "=", "Model", "(", "**", "self", ".", "arg", ".", "model_args", ")", "\n", "# print(self.model)", "\n", "self", ".", "loss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", "output_device", ")", "\n", "\n", "if", "self", ".", "arg", ".", "weights", ":", "\n", "# self.global_step = int(arg.weights[:-3].split('-')[-1])", "\n", "            ", "self", ".", "print_log", "(", "'Load weights from {}'", ".", "format", "(", "self", ".", "arg", ".", "weights", ")", ")", "\n", "if", "'.pkl'", "in", "self", ".", "arg", ".", "weights", ":", "\n", "                ", "with", "open", "(", "self", ".", "arg", ".", "weights", ",", "'r'", ")", "as", "f", ":", "\n", "                    ", "weights", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "                ", "weights", "=", "torch", ".", "load", "(", "self", ".", "arg", ".", "weights", ")", "\n", "\n", "", "weights", "=", "OrderedDict", "(", "[", "[", "k", ".", "split", "(", "'module.'", ")", "[", "-", "1", "]", ",", "v", ".", "cuda", "(", "output_device", ")", "]", "for", "k", ",", "v", "in", "weights", ".", "items", "(", ")", "]", ")", "\n", "\n", "keys", "=", "list", "(", "weights", ".", "keys", "(", ")", ")", "\n", "for", "w", "in", "self", ".", "arg", ".", "ignore_weights", ":", "\n", "                ", "for", "key", "in", "keys", ":", "\n", "                    ", "if", "w", "in", "key", ":", "\n", "                        ", "if", "weights", ".", "pop", "(", "key", ",", "None", ")", "is", "not", "None", ":", "\n", "                            ", "self", ".", "print_log", "(", "'Sucessfully Remove Weights: {}.'", ".", "format", "(", "key", ")", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "print_log", "(", "'Can Not Remove Weights: {}.'", ".", "format", "(", "key", ")", ")", "\n", "\n", "", "", "", "", "try", ":", "\n", "                ", "self", ".", "model", ".", "load_state_dict", "(", "weights", ")", "\n", "", "except", ":", "\n", "                ", "state", "=", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "diff", "=", "list", "(", "set", "(", "state", ".", "keys", "(", ")", ")", ".", "difference", "(", "set", "(", "weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "print", "(", "'Can not find these weights:'", ")", "\n", "for", "d", "in", "diff", ":", "\n", "                    ", "print", "(", "'  '", "+", "d", ")", "\n", "", "state", ".", "update", "(", "weights", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "state", ")", "\n", "", "", "self", ".", "print_log", "(", "'Model load finished: '", "+", "self", ".", "arg", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.load_optimizer": [[231, 247], ["main.Processor.print_log", "torch.SGD", "torch.SGD", "torch.SGD", "main.Processor.model.parameters", "torch.Adam", "torch.Adam", "torch.Adam", "ValueError", "main.Processor.model.parameters"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log"], ["", "def", "load_optimizer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "arg", ".", "optimizer", "==", "'SGD'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "SGD", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "arg", ".", "base_lr", ",", "\n", "momentum", "=", "0.9", ",", "\n", "nesterov", "=", "self", ".", "arg", ".", "nesterov", ",", "\n", "weight_decay", "=", "self", ".", "arg", ".", "weight_decay", ")", "\n", "", "elif", "self", ".", "arg", ".", "optimizer", "==", "'Adam'", ":", "\n", "            ", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "self", ".", "arg", ".", "base_lr", ",", "\n", "weight_decay", "=", "self", ".", "arg", ".", "weight_decay", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", ")", "\n", "", "self", ".", "print_log", "(", "'Optimizer load finished: '", "+", "self", ".", "arg", ".", "optimizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.adjust_learning_rate": [[248, 260], ["main.Processor.print_log", "ValueError", "numpy.sum", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log"], ["", "def", "adjust_learning_rate", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "print_log", "(", "'adjust learning rate, using warm up, epoch: {}'", ".", "format", "(", "self", ".", "arg", ".", "warm_up_epoch", ")", ")", "\n", "if", "self", ".", "arg", ".", "optimizer", "==", "'SGD'", "or", "self", ".", "arg", ".", "optimizer", "==", "'Adam'", ":", "\n", "            ", "if", "epoch", "<", "self", ".", "arg", ".", "warm_up_epoch", ":", "\n", "                ", "lr", "=", "self", ".", "arg", ".", "base_lr", "*", "(", "epoch", "+", "1", ")", "/", "self", ".", "arg", ".", "warm_up_epoch", "\n", "", "else", ":", "\n", "                ", "lr", "=", "self", ".", "arg", ".", "base_lr", "*", "(", "self", ".", "arg", ".", "lr_decay_rate", "**", "np", ".", "sum", "(", "epoch", ">=", "np", ".", "array", "(", "self", ".", "arg", ".", "step", ")", ")", ")", "\n", "", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "", "return", "lr", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log": [[261, 269], ["print", "time.strftime", "time.localtime", "open", "print", "time.time"], "methods", ["None"], ["", "", "def", "print_log", "(", "self", ",", "str", ",", "print_time", "=", "True", ")", ":", "\n", "        ", "if", "print_time", ":", "\n", "            ", "localtime", "=", "time", ".", "strftime", "(", "'%Y-%m-%d %H:%M'", ",", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "str", "=", "\"[ \"", "+", "localtime", "+", "' ] '", "+", "str", "\n", "", "print", "(", "str", ")", "\n", "if", "self", ".", "arg", ".", "print_log", ":", "\n", "            ", "with", "open", "(", "'{}/log.txt'", ".", "format", "(", "self", ".", "arg", ".", "work_dir", ")", ",", "'a'", ")", "as", "f", ":", "\n", "                ", "print", "(", "str", ",", "file", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.train": [[270, 313], ["main.AverageMeter", "main.AverageMeter", "main.AverageMeter", "main.Processor.model.train", "main.Processor.adjust_learning_rate", "main.Processor.train_writer.add_scalar", "enumerate", "main.Processor.print_log", "tqdm.tqdm.tqdm", "main.Processor.model", "main.Processor.loss", "main.Processor.optimizer.zero_grad", "main.Processor.backward", "main.Processor.optimizer.step", "main.accuracy", "main.AverageMeter.update", "main.AverageMeter.update", "main.AverageMeter.update", "main.Processor.train_writer.add_scalar", "main.Processor.train_writer.add_scalar", "main.Processor.train_writer.add_scalar", "main.Processor.model.state_dict", "collections.OrderedDict", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "data.float().cuda.float().cuda.float().cuda", "label.long().cuda.long().cuda.long().cuda", "prec1.item", "data.float().cuda.float().cuda.size", "prec5.item", "data.float().cuda.float().cuda.size", "main.Processor.item", "data.float().cuda.float().cuda.float", "label.long().cuda.long().cuda.long", "v.cpu", "main.Processor.items", "k.split", "main.Processor.arg.work_dir.split"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.train", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.adjust_learning_rate", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.accuracy", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.AverageMeter.update", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.AverageMeter.update", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.AverageMeter.update"], ["", "", "", "def", "train", "(", "self", ",", "epoch", ",", "save_model", "=", "False", ")", ":", "\n", "        ", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "adjust_learning_rate", "(", "epoch", ")", "\n", "\n", "self", ".", "train_writer", ".", "add_scalar", "(", "'epoch'", ",", "epoch", ",", "self", ".", "global_step", ")", "\n", "\n", "for", "batch", ",", "(", "data", ",", "label", ",", "sample", ")", "in", "enumerate", "(", "tqdm", "(", "self", ".", "data_loader", "[", "'train'", "]", ",", "desc", "=", "\"Training\"", ",", "ncols", "=", "100", ")", ")", ":", "\n", "            ", "self", ".", "global_step", "+=", "1", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "data", "=", "data", ".", "float", "(", ")", ".", "cuda", "(", "self", ".", "output_device", ")", "\n", "label", "=", "label", ".", "long", "(", ")", ".", "cuda", "(", "self", ".", "output_device", ")", "\n", "\n", "# forward", "\n", "", "output", "=", "self", ".", "model", "(", "data", ")", "\n", "loss", "=", "self", ".", "loss", "(", "output", ",", "label", ")", "\n", "# backward", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "prec1", ",", "prec5", "=", "accuracy", "(", "output", ".", "data", ",", "label", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "data", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "data", ".", "size", "(", "0", ")", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "self", ".", "train_writer", ".", "add_scalar", "(", "'top1'", ",", "top1", ".", "avg", ",", "self", ".", "global_step", ")", "\n", "self", ".", "train_writer", ".", "add_scalar", "(", "'loss'", ",", "losses", ".", "avg", ",", "self", ".", "global_step", ")", "\n", "\n", "# statistics", "\n", "self", ".", "lr", "=", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "self", ".", "train_writer", ".", "add_scalar", "(", "'lr'", ",", "self", ".", "lr", ",", "self", ".", "global_step", ")", "\n", "\n", "", "self", ".", "print_log", "(", "'training: epoch: {}, loss: {:.4f}, top1: {:.2f}%, lr: {:.6f}'", ".", "format", "(", "\n", "epoch", "+", "1", ",", "losses", ".", "avg", ",", "top1", ".", "avg", ",", "self", ".", "lr", ")", ")", "\n", "\n", "if", "epoch", "+", "1", "==", "self", ".", "arg", ".", "num_epoch", ":", "\n", "            ", "state_dict", "=", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "weights", "=", "OrderedDict", "(", "[", "[", "k", ".", "split", "(", "'module.'", ")", "[", "-", "1", "]", ",", "v", ".", "cpu", "(", ")", "]", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "]", ")", "\n", "torch", ".", "save", "(", "weights", ",", "self", ".", "arg", ".", "work_dir", "+", "'/'", "+", "self", ".", "arg", ".", "work_dir", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "+", "'.pt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.eval": [[314, 368], ["main.AverageMeter", "main.AverageMeter", "main.AverageMeter", "main.Processor.model.eval", "open", "open", "enumerate", "numpy.concatenate", "dict", "main.Processor.print_log", "tqdm.tqdm.tqdm", "label_list.append", "main.accuracy", "main.AverageMeter.update", "main.AverageMeter.update", "main.AverageMeter.update", "zip", "main.Processor.val_writer.add_scalar", "main.Processor.val_writer.add_scalar", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "data.float().cuda.float().cuda.float().cuda", "label.long().cuda.long().cuda.long().cuda", "main.Processor.model", "main.Processor.loss", "score_frag.append", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "pred_list.append", "prec1.item", "data.float().cuda.float().cuda.size", "prec5.item", "data.float().cuda.float().cuda.size", "main.Processor.item", "list", "list", "enumerate", "open", "pickle.dump", "main.Processor.data.cpu().numpy", "predict_label.data.cpu().numpy", "predict_label.cpu().numpy", "label.long().cuda.long().cuda.data.cpu().numpy", "data.float().cuda.float().cuda.float", "label.long().cuda.long().cuda.long", "open.write", "open.write", "main.Processor.data.cpu", "predict_label.data.cpu", "predict_label.cpu", "label.long().cuda.long().cuda.data.cpu", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.eval", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.accuracy", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.AverageMeter.update", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.AverageMeter.update", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.AverageMeter.update"], ["", "", "def", "eval", "(", "self", ",", "epoch", ",", "save_score", "=", "False", ",", "loader_name", "=", "[", "'test'", "]", ",", "wrong_file", "=", "None", ",", "result_file", "=", "None", ")", ":", "\n", "        ", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "\n", "if", "wrong_file", "is", "not", "None", ":", "\n", "            ", "f_w", "=", "open", "(", "wrong_file", ",", "'w'", ")", "\n", "", "if", "result_file", "is", "not", "None", ":", "\n", "            ", "f_r", "=", "open", "(", "result_file", ",", "'w'", ")", "\n", "", "self", ".", "model", ".", "eval", "(", ")", "\n", "for", "ln", "in", "loader_name", ":", "\n", "            ", "score_frag", "=", "[", "]", "\n", "label_list", "=", "[", "]", "\n", "pred_list", "=", "[", "]", "\n", "for", "batch", ",", "(", "data", ",", "label", ",", "sampie", ")", "in", "enumerate", "(", "tqdm", "(", "self", ".", "data_loader", "[", "ln", "]", ",", "desc", "=", "\"Evaluating\"", ",", "ncols", "=", "100", ")", ")", ":", "\n", "                ", "label_list", ".", "append", "(", "label", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "data", "=", "data", ".", "float", "(", ")", ".", "cuda", "(", "self", ".", "output_device", ")", "\n", "label", "=", "label", ".", "long", "(", ")", ".", "cuda", "(", "self", ".", "output_device", ")", "\n", "output", "=", "self", ".", "model", "(", "data", ")", "\n", "loss", "=", "self", ".", "loss", "(", "output", ",", "label", ")", "\n", "\n", "score_frag", ".", "append", "(", "output", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "_", ",", "predict_label", "=", "torch", ".", "max", "(", "output", ".", "data", ",", "1", ")", "\n", "pred_list", ".", "append", "(", "predict_label", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "prec1", ",", "prec5", "=", "accuracy", "(", "output", ".", "data", ",", "label", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "top1", ".", "update", "(", "prec1", ".", "item", "(", ")", ",", "data", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", ".", "item", "(", ")", ",", "data", ".", "size", "(", "0", ")", ")", "\n", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "if", "wrong_file", "is", "not", "None", "or", "result_file", "is", "not", "None", ":", "\n", "                    ", "predict", "=", "list", "(", "predict_label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "true", "=", "list", "(", "label", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "predict", ")", ":", "\n", "                        ", "if", "result_file", "is", "not", "None", ":", "\n", "                            ", "f_r", ".", "write", "(", "str", "(", "x", ")", "+", "','", "+", "str", "(", "true", "[", "i", "]", ")", "+", "'\\n'", ")", "\n", "", "if", "x", "!=", "true", "[", "i", "]", "and", "wrong_file", "is", "not", "None", ":", "\n", "                            ", "f_w", ".", "write", "(", "str", "(", "sampie", "[", "i", "]", ")", "+", "','", "+", "str", "(", "x", ")", "+", "','", "+", "str", "(", "true", "[", "i", "]", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "", "", "score", "=", "np", ".", "concatenate", "(", "score_frag", ")", "\n", "score_dict", "=", "dict", "(", "zip", "(", "self", ".", "data_loader", "[", "ln", "]", ".", "dataset", ".", "sample_name", ",", "score", ")", ")", "\n", "\n", "if", "self", ".", "arg", ".", "run_mode", "==", "'train'", ":", "\n", "                ", "self", ".", "val_writer", ".", "add_scalar", "(", "'loss'", ",", "top1", ".", "avg", ",", "self", ".", "global_step", ")", "\n", "self", ".", "val_writer", ".", "add_scalar", "(", "'acc'", ",", "losses", ".", "avg", ",", "self", ".", "global_step", ")", "\n", "\n", "", "self", ".", "best_acc", "=", "top1", ".", "avg", "if", "top1", ".", "avg", ">", "self", ".", "best_acc", "else", "self", ".", "best_acc", "\n", "\n", "self", ".", "print_log", "(", "'evaluating: loss: {:.4f}, top1: {:.2f}%, best_acc: {:.2f}%'", ".", "format", "(", "losses", ".", "avg", ",", "top1", ".", "avg", ",", "self", ".", "best_acc", ")", ")", "\n", "\n", "if", "save_score", ":", "\n", "                ", "with", "open", "(", "'{}/score.pkl'", ".", "format", "(", "self", ".", "arg", ".", "work_dir", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                    ", "pickle", ".", "dump", "(", "score_dict", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.start": [[369, 408], ["sorted", "main.Processor.print_log", "main.Processor.print_log", "range", "main.Processor.print_log", "vars().items", "main.Processor.print_log", "sum", "main.Processor.train", "main.Processor.print_log", "main.Processor.print_log", "main.Processor.eval", "main.Processor.print_log", "len", "main.Processor.eval", "ValueError", "vars", "p.numel", "main.Processor.start.count_parameters"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.train", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.eval", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.print_log", "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.Processor.eval"], ["", "", "", "", "def", "start", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "arg", ".", "run_mode", "==", "'train'", ":", "\n", "\n", "            ", "for", "argument", ",", "value", "in", "sorted", "(", "vars", "(", "self", ".", "arg", ")", ".", "items", "(", ")", ")", ":", "\n", "                ", "self", ".", "print_log", "(", "'{}: {}'", ".", "format", "(", "argument", ",", "value", ")", ")", "\n", "\n", "", "self", ".", "global_step", "=", "self", ".", "arg", ".", "start_epoch", "*", "len", "(", "self", ".", "data_loader", "[", "'train'", "]", ")", "/", "self", ".", "arg", ".", "batch_size", "\n", "\n", "def", "count_parameters", "(", "model", ")", ":", "\n", "                ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "", "self", ".", "print_log", "(", "f'# Parameters: {count_parameters(self.model)}'", ")", "\n", "\n", "self", ".", "print_log", "(", "'###***************start training***************###'", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "self", ".", "arg", ".", "start_epoch", ",", "self", ".", "arg", ".", "num_epoch", ")", ":", "\n", "\n", "                ", "save_model", "=", "(", "epoch", "+", "1", "==", "self", ".", "arg", ".", "num_epoch", ")", "\n", "self", ".", "train", "(", "epoch", ",", "save_model", "=", "save_model", ")", "\n", "\n", "if", "(", "(", "epoch", "+", "1", ")", "%", "self", ".", "arg", ".", "eval_interval", "==", "0", ")", ":", "\n", "                    ", "self", ".", "eval", "(", "epoch", ",", "save_score", "=", "self", ".", "arg", ".", "save_score", ",", "loader_name", "=", "[", "'test'", "]", ")", "\n", "", "", "self", ".", "print_log", "(", "'Done.\\n'", ")", "\n", "\n", "", "elif", "self", ".", "arg", ".", "run_mode", "==", "'test'", ":", "\n", "            ", "if", "not", "self", ".", "arg", ".", "test_feeder_args", "[", "'debug'", "]", ":", "\n", "                ", "weights_path", "=", "self", ".", "arg", ".", "work_dir", "+", "'.pt'", "\n", "wf", "=", "self", ".", "arg", ".", "work_dir", "+", "'/wrong.txt'", "\n", "rf", "=", "self", ".", "arg", ".", "work_dir", "+", "'/right.txt'", "\n", "", "else", ":", "\n", "                ", "wf", "=", "rf", "=", "None", "\n", "\n", "", "if", "self", ".", "arg", ".", "weights", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "'Please appoint --weights.'", ")", "\n", "", "self", ".", "arg", ".", "print_log", "=", "False", "\n", "self", ".", "print_log", "(", "'Model:   {}'", ".", "format", "(", "self", ".", "arg", ".", "model", ")", ")", "\n", "self", ".", "print_log", "(", "'Weights: {}'", ".", "format", "(", "self", ".", "arg", ".", "weights", ")", ")", "\n", "self", ".", "eval", "(", "epoch", "=", "0", ",", "save_score", "=", "self", ".", "arg", ".", "save_score", ",", "loader_name", "=", "[", "'test'", "]", ",", "wrong_file", "=", "wf", ",", "result_file", "=", "rf", ")", "\n", "self", ".", "print_log", "(", "'Done.\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.init_seed": [[24, 32], ["torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "numpy.random.seed", "random.seed"], "function", ["None"], ["def", "init_seed", "(", "seed", ")", ":", "\n", "    ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "1", ")", "\n", "torch", ".", "manual_seed", "(", "1", ")", "\n", "np", ".", "random", ".", "seed", "(", "1", ")", "\n", "random", ".", "seed", "(", "1", ")", "\n", "# torch.backends.cudnn.enabled = False", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.import_class": [[33, 39], ["name.split", "__import__", "getattr"], "function", ["None"], ["", "def", "import_class", "(", "name", ")", ":", "\n", "    ", "components", "=", "name", ".", "split", "(", "'.'", ")", "\n", "mod", "=", "__import__", "(", "components", "[", "0", "]", ")", "# import return model", "\n", "for", "comp", "in", "components", "[", "1", ":", "]", ":", "\n", "        ", "mod", "=", "getattr", "(", "mod", ",", "comp", ")", "\n", "", "return", "mod", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.str2bool": [[40, 47], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Unsupported value encountered.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.get_parser": [[49, 94], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "dict", "dict", "dict"], "function", ["None"], ["", "", "def", "get_parser", "(", ")", ":", "\n", "# parameter priority: command line > config > default", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Spatial Temporal Tuples Transformer'", ")", "\n", "parser", ".", "add_argument", "(", "'--work_dir'", ",", "default", "=", "'./work_dir/ntu60/temp'", ",", "help", "=", "'the work folder for storing results'", ")", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "default", "=", "'./config/ntu60_xsub_joint.yaml'", ",", "help", "=", "'path to the configuration file'", ")", "\n", "\n", "# processor", "\n", "parser", ".", "add_argument", "(", "'--run_mode'", ",", "default", "=", "'train'", ",", "help", "=", "'must be train or test'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_score'", ",", "type", "=", "str2bool", ",", "default", "=", "False", ",", "help", "=", "'if ture, the classification score will be stored'", ")", "\n", "\n", "# visulize and debug", "\n", "parser", ".", "add_argument", "(", "'--save_epoch'", ",", "type", "=", "int", ",", "default", "=", "80", ",", "help", "=", "'the start epoch to save model (#iteration)'", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_interval'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'the interval for evaluating models (#iteration)'", ")", "\n", "parser", ".", "add_argument", "(", "'--print_log'", ",", "type", "=", "str2bool", ",", "default", "=", "True", ",", "help", "=", "'print logging or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--show_topk'", ",", "type", "=", "int", ",", "default", "=", "[", "1", ",", "5", "]", ",", "nargs", "=", "'+'", ",", "help", "=", "'which Top K accuracy will be shown'", ")", "\n", "\n", "# feeder", "\n", "parser", ".", "add_argument", "(", "'--feeder'", ",", "default", "=", "'feeder.feeder'", ",", "help", "=", "'data loader will be used'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_worker'", ",", "type", "=", "int", ",", "default", "=", "8", ",", "help", "=", "'the number of worker for data loader'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_feeder_args'", ",", "default", "=", "dict", "(", ")", ",", "help", "=", "'the arguments of data loader for training'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_feeder_args'", ",", "default", "=", "dict", "(", ")", ",", "help", "=", "'the arguments of data loader for test'", ")", "\n", "\n", "# model", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "default", "=", "None", ",", "help", "=", "'the model will be used'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_args'", ",", "default", "=", "dict", "(", ")", ",", "help", "=", "'the arguments of model'", ")", "\n", "parser", ".", "add_argument", "(", "'--weights'", ",", "default", "=", "None", ",", "help", "=", "'the weights for model testing'", ")", "\n", "parser", ".", "add_argument", "(", "'--ignore_weights'", ",", "type", "=", "str", ",", "default", "=", "[", "]", ",", "nargs", "=", "'+'", ",", "help", "=", "'the name of weights which will be ignored in the initialization'", ")", "\n", "\n", "# optim", "\n", "parser", ".", "add_argument", "(", "'--base_lr'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'initial learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--step'", ",", "type", "=", "int", ",", "default", "=", "[", "60", ",", "80", "]", ",", "nargs", "=", "'+'", ",", "help", "=", "'the epoch where optimizer reduce the learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--cuda_visible_device'", ",", "default", "=", "'2,3'", ",", "help", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "type", "=", "int", ",", "default", "=", "[", "0", ",", "1", "]", ",", "nargs", "=", "'+'", ",", "help", "=", "'the indexes of GPUs for training or testing'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "default", "=", "'SGD'", ",", "help", "=", "'type of optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--nesterov'", ",", "type", "=", "str2bool", ",", "default", "=", "False", ",", "help", "=", "'use nesterov or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'training batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'test batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--start_epoch'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'start training from which epoch'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_epoch'", ",", "type", "=", "int", ",", "default", "=", "80", ",", "help", "=", "'stop training in which epoch'", ")", "\n", "parser", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "0.0005", ",", "help", "=", "'weight decay for optimizer'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay_rate'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'decay rate for learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--warm_up_epoch'", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.None.main.accuracy": [[96, 110], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].contiguous().view().float().sum", "res.append", "correct[].contiguous().view().float().sum.mul_", "target.view", "correct[].contiguous().view().float", "correct[].contiguous().view", "correct[].contiguous"], "function", ["None"], ["", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.model.pos_embed.Pos_Embed.__init__": [[7, 25], ["torch.Module.__init__", "range", "torch.from_numpy().unsqueeze().float", "torch.from_numpy().unsqueeze().float", "torch.from_numpy().unsqueeze().float", "torch.from_numpy().unsqueeze().float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.view().permute().unsqueeze.view().permute().unsqueeze.view().permute().unsqueeze", "pos_embed.Pos_Embed.register_buffer", "range", "pos_list.append", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.arange().float", "torch.arange().float", "torch.arange().float", "torch.arange().float", "pe.view().permute().unsqueeze.view().permute().unsqueeze.view().permute", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "math.log", "pe.view().permute().unsqueeze.view().permute().unsqueeze.view", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.feeder_ntu.Feeder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channels", ",", "num_frames", ",", "num_joints", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "pos_list", "=", "[", "]", "\n", "for", "tk", "in", "range", "(", "num_frames", ")", ":", "\n", "            ", "for", "st", "in", "range", "(", "num_joints", ")", ":", "\n", "                ", "pos_list", ".", "append", "(", "st", ")", "\n", "\n", "", "", "position", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "pos_list", ")", ")", ".", "unsqueeze", "(", "1", ")", ".", "float", "(", ")", "\n", "\n", "pe", "=", "torch", ".", "zeros", "(", "num_frames", "*", "num_joints", ",", "channels", ")", "\n", "\n", "div_term", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "0", ",", "channels", ",", "2", ")", ".", "float", "(", ")", "*", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "channels", ")", ")", "\n", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "view", "(", "num_frames", ",", "num_joints", ",", "channels", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.model.pos_embed.Pos_Embed.forward": [[26, 29], ["x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "# nctv", "\n", "        ", "x", "=", "self", ".", "pe", "[", ":", ",", ":", ",", ":", "x", ".", "size", "(", "2", ")", "]", "\n", "return", "x", "", "", "", ""]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.model.sta_block.STA_Block.__init__": [[6, 39], ["torch.Module.__init__", "int", "int", "torch.Conv2d", "torch.Conv2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Tanh", "torch.Tanh", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout", "torch.Dropout", "pos_embed.Pos_Embed", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.feeder_ntu.Feeder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "qkv_dim", ",", "\n", "num_frames", ",", "num_joints", ",", "num_heads", ",", "\n", "kernel_size", ",", "use_pes", "=", "True", ",", "att_drop", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "qkv_dim", "=", "qkv_dim", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "use_pes", "=", "use_pes", "\n", "pads", "=", "int", "(", "(", "kernel_size", "[", "1", "]", "-", "1", ")", "/", "2", ")", "\n", "padt", "=", "int", "(", "(", "kernel_size", "[", "0", "]", "-", "1", ")", "/", "2", ")", "\n", "\n", "# Spatio-Temporal Tuples Attention", "\n", "if", "self", ".", "use_pes", ":", "self", ".", "pes", "=", "Pos_Embed", "(", "in_channels", ",", "num_frames", ",", "num_joints", ")", "\n", "self", ".", "to_qkvs", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "2", "*", "num_heads", "*", "qkv_dim", ",", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "alphas", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ",", "num_heads", ",", "1", ",", "1", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "att0s", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ",", "num_heads", ",", "num_joints", ",", "num_joints", ")", "/", "num_joints", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "out_nets", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "in_channels", "*", "num_heads", ",", "out_channels", ",", "(", "1", ",", "kernel_size", "[", "1", "]", ")", ",", "padding", "=", "(", "0", ",", "pads", ")", ")", ",", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ")", "\n", "self", ".", "ff_net", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "out_channels", ",", "out_channels", ",", "1", ")", ",", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ")", "\n", "\n", "# Inter-Frame Feature Aggregation", "\n", "self", ".", "out_nett", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "out_channels", ",", "out_channels", ",", "(", "kernel_size", "[", "0", "]", ",", "1", ")", ",", "padding", "=", "(", "padt", ",", "0", ")", ")", ",", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ")", "\n", "\n", "if", "in_channels", "!=", "out_channels", ":", "\n", "            ", "self", ".", "ress", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "1", ")", ",", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ")", "\n", "self", ".", "rest", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "out_channels", ",", "out_channels", ",", "1", ")", ",", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ress", "=", "lambda", "x", ":", "x", "\n", "self", ".", "rest", "=", "lambda", "x", ":", "x", "\n", "\n", "", "self", ".", "tan", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "relu", "=", "nn", ".", "LeakyReLU", "(", "0.1", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "att_drop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.model.sta_block.STA_Block.forward": [[40, 58], ["x.size", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "sta_block.STA_Block.drop", "torch.einsum().contiguous().view", "torch.einsum().contiguous().view", "torch.einsum().contiguous().view", "torch.einsum().contiguous().view", "sta_block.STA_Block.ress", "sta_block.STA_Block.relu", "sta_block.STA_Block.relu", "sta_block.STA_Block.relu", "sta_block.STA_Block.to_qkvs().view", "sta_block.STA_Block.tan", "sta_block.STA_Block.att0s.repeat", "sta_block.STA_Block.pes", "torch.einsum().contiguous", "torch.einsum().contiguous", "torch.einsum().contiguous", "torch.einsum().contiguous", "sta_block.STA_Block.out_nets", "sta_block.STA_Block.ff_net", "sta_block.STA_Block.out_nett", "sta_block.STA_Block.rest", "sta_block.STA_Block.to_qkvs", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "N", ",", "C", ",", "T", ",", "V", "=", "x", ".", "size", "(", ")", "\n", "# Spatio-Temporal Tuples Attention", "\n", "xs", "=", "self", ".", "pes", "(", "x", ")", "+", "x", "if", "self", ".", "use_pes", "else", "x", "\n", "q", ",", "k", "=", "torch", ".", "chunk", "(", "self", ".", "to_qkvs", "(", "xs", ")", ".", "view", "(", "N", ",", "2", "*", "self", ".", "num_heads", ",", "self", ".", "qkv_dim", ",", "T", ",", "V", ")", ",", "2", ",", "dim", "=", "1", ")", "\n", "attention", "=", "self", ".", "tan", "(", "torch", ".", "einsum", "(", "'nhctu,nhctv->nhuv'", ",", "[", "q", ",", "k", "]", ")", "/", "(", "self", ".", "qkv_dim", "*", "T", ")", ")", "*", "self", ".", "alphas", "\n", "attention", "=", "attention", "+", "self", ".", "att0s", ".", "repeat", "(", "N", ",", "1", ",", "1", ",", "1", ")", "\n", "attention", "=", "self", ".", "drop", "(", "attention", ")", "\n", "xs", "=", "torch", ".", "einsum", "(", "'nctu,nhuv->nhctv'", ",", "[", "x", ",", "attention", "]", ")", ".", "contiguous", "(", ")", ".", "view", "(", "N", ",", "self", ".", "num_heads", "*", "self", ".", "in_channels", ",", "T", ",", "V", ")", "\n", "x_ress", "=", "self", ".", "ress", "(", "x", ")", "\n", "xs", "=", "self", ".", "relu", "(", "self", ".", "out_nets", "(", "xs", ")", "+", "x_ress", ")", "\n", "xs", "=", "self", ".", "relu", "(", "self", ".", "ff_net", "(", "xs", ")", "+", "x_ress", ")", "\n", "\n", "# Inter-Frame Feature Aggregation", "\n", "xt", "=", "self", ".", "relu", "(", "self", ".", "out_nett", "(", "xs", ")", "+", "self", ".", "rest", "(", "xs", ")", ")", "\n", "\n", "return", "xt", "", "", "", ""]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.model.sttformer.Model.__init__": [[19, 58], ["torch.Module.__init__", "torch.Sequential", "torch.ModuleList", "enumerate", "torch.Linear", "torch.Dropout", "torch.Dropout2d", "sttformer.Model.modules", "torch.Conv2d", "torch.BatchNorm2d", "torch.LeakyReLU", "sttformer.Model.blocks.append", "isinstance", "sta_block.STA_Block", "sttformer.conv_init", "isinstance", "sttformer.bn_init", "isinstance", "sttformer.fc_init"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.feeder_ntu.Feeder.__init__", "home.repos.pwc.inspect_result.heleiqiu_sttformer.model.sttformer.conv_init", "home.repos.pwc.inspect_result.heleiqiu_sttformer.model.sttformer.bn_init", "home.repos.pwc.inspect_result.heleiqiu_sttformer.model.sttformer.fc_init"], ["    ", "def", "__init__", "(", "self", ",", "len_parts", ",", "num_classes", ",", "num_joints", ",", "\n", "num_frames", ",", "num_heads", ",", "num_persons", ",", "num_channels", ",", "\n", "kernel_size", ",", "use_pes", "=", "True", ",", "config", "=", "None", ",", "\n", "att_drop", "=", "0", ",", "dropout", "=", "0", ",", "dropout2d", "=", "0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "len_parts", "=", "len_parts", "\n", "in_channels", "=", "config", "[", "0", "]", "[", "0", "]", "\n", "self", ".", "out_channels", "=", "config", "[", "-", "1", "]", "[", "1", "]", "\n", "\n", "num_frames", "=", "num_frames", "//", "len_parts", "\n", "num_joints", "=", "num_joints", "*", "len_parts", "\n", "\n", "self", ".", "input_map", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "num_channels", ",", "in_channels", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "in_channels", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.1", ")", ")", "\n", "\n", "self", ".", "blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "index", ",", "(", "in_channels", ",", "out_channels", ",", "qkv_dim", ")", "in", "enumerate", "(", "config", ")", ":", "\n", "            ", "self", ".", "blocks", ".", "append", "(", "STA_Block", "(", "in_channels", ",", "out_channels", ",", "qkv_dim", ",", "\n", "num_frames", "=", "num_frames", ",", "\n", "num_joints", "=", "num_joints", ",", "\n", "num_heads", "=", "num_heads", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "use_pes", "=", "use_pes", ",", "\n", "att_drop", "=", "att_drop", ")", ")", "\n", "\n", "", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "out_channels", ",", "num_classes", ")", "\n", "self", ".", "drop_out", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "drop_out2d", "=", "nn", ".", "Dropout2d", "(", "dropout2d", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "conv_init", "(", "m", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "bn_init", "(", "m", ",", "1", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "fc_init", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.model.sttformer.Model.forward": [[59, 79], ["block.permute().contiguous().view", "block.view", "sttformer.Model.input_map", "enumerate", "block.view", "block.permute().contiguous().view", "sttformer.Model.drop_out2d", "block.mean().mean", "sttformer.Model.drop_out", "sttformer.Model.fc", "block.size", "block.size", "block", "block.permute().contiguous", "block.permute().contiguous", "block.mean", "block.permute", "block.permute"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "N", ",", "C", ",", "T", ",", "V", ",", "M", "=", "x", ".", "shape", "\n", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "4", ",", "1", ",", "2", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "N", "*", "M", ",", "C", ",", "T", ",", "V", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", ",", "T", "//", "self", ".", "len_parts", ",", "V", "*", "self", ".", "len_parts", ")", "\n", "x", "=", "self", ".", "input_map", "(", "x", ")", "\n", "\n", "for", "i", ",", "block", "in", "enumerate", "(", "self", ".", "blocks", ")", ":", "\n", "            ", "x", "=", "block", "(", "x", ")", "\n", "\n", "# NM, C, T, V", "\n", "", "x", "=", "x", ".", "view", "(", "N", ",", "M", ",", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "N", ",", "-", "1", ",", "self", ".", "out_channels", ",", "1", ")", "\n", "x", "=", "self", ".", "drop_out2d", "(", "x", ")", "\n", "x", "=", "x", ".", "mean", "(", "3", ")", ".", "mean", "(", "1", ")", "\n", "\n", "x", "=", "self", ".", "drop_out", "(", "x", ")", "\n", "\n", "return", "self", ".", "fc", "(", "x", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.model.sttformer.conv_init": [[5, 7], ["torch.init.kaiming_normal_"], "function", ["None"], ["def", "conv_init", "(", "conv", ")", ":", "\n", "    ", "nn", ".", "init", ".", "kaiming_normal_", "(", "conv", ".", "weight", ",", "mode", "=", "'fan_out'", ")", "\n", "# nn.init.constant_(conv.bias, 0)", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.model.sttformer.bn_init": [[9, 12], ["torch.init.constant_", "torch.init.constant_"], "function", ["None"], ["", "def", "bn_init", "(", "bn", ",", "scale", ")", ":", "\n", "    ", "nn", ".", "init", ".", "constant_", "(", "bn", ".", "weight", ",", "scale", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "bn", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.model.sttformer.fc_init": [[13, 16], ["torch.init.xavier_normal_", "torch.init.constant_"], "function", ["None"], ["", "def", "fc_init", "(", "fc", ")", ":", "\n", "    ", "nn", ".", "init", ".", "xavier_normal_", "(", "fc", ".", "weight", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "fc", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.feeder_ntu.Feeder.__init__": [[7, 44], ["feeder_ntu.Feeder.load_data", "feeder_ntu.Feeder.get_mean_map"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.feeder_ntu.Feeder.load_data", "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.feeder_ntu.Feeder.get_mean_map"], ["    ", "def", "__init__", "(", "self", ",", "data_path", ",", "label_path", "=", "None", ",", "p_interval", "=", "1", ",", "split", "=", "'train'", ",", "random_choose", "=", "False", ",", "random_shift", "=", "False", ",", "\n", "random_move", "=", "False", ",", "random_rot", "=", "False", ",", "window_size", "=", "-", "1", ",", "normalization", "=", "False", ",", "debug", "=", "False", ",", "use_mmap", "=", "True", ",", "\n", "bone", "=", "False", ",", "vel", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        data_path:\n        label_path:\n        split: training set or test set\n        random_choose: If true, randomly choose a portion of the input sequence\n        random_shift: If true, randomly pad zeros at the begining or end of sequence\n        random_move:\n        random_rot: rotate skeleton around xyz axis\n        window_size: The length of the output sequence\n        normalization: If true, normalize input sequence\n        debug: If true, only use the first 100 samples\n        use_mmap: If true, use mmap mode to load data, which can save the running memory\n        bone: use bone modality or not\n        vel: use motion modality or not\n        only_label: only load label for ensemble score compute\n        \"\"\"", "\n", "\n", "self", ".", "debug", "=", "debug", "\n", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "label_path", "=", "label_path", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "random_choose", "=", "random_choose", "\n", "self", ".", "random_shift", "=", "random_shift", "\n", "self", ".", "random_move", "=", "random_move", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "normalization", "=", "normalization", "\n", "self", ".", "use_mmap", "=", "use_mmap", "\n", "self", ".", "p_interval", "=", "p_interval", "\n", "self", ".", "random_rot", "=", "random_rot", "\n", "self", ".", "bone", "=", "bone", "\n", "self", ".", "vel", "=", "vel", "\n", "self", ".", "load_data", "(", ")", "\n", "if", "normalization", ":", "\n", "            ", "self", ".", "get_mean_map", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.feeder_ntu.Feeder.load_data": [[45, 65], ["feeder_ntu.Feeder.data.reshape().transpose", "numpy.load", "numpy.load", "numpy.where", "NotImplementedError", "feeder_ntu.Feeder.data.reshape", "str", "range", "numpy.where", "len", "str", "range", "len"], "methods", ["None"], ["", "", "def", "load_data", "(", "self", ")", ":", "\n", "# data: N C V T M", "\n", "        ", "if", "self", ".", "use_mmap", ":", "\n", "            ", "npz_data", "=", "np", ".", "load", "(", "self", ".", "data_path", ",", "mmap_mode", "=", "'r'", ")", "\n", "", "else", ":", "\n", "            ", "npz_data", "=", "np", ".", "load", "(", "self", ".", "data_path", ")", "\n", "\n", "", "if", "self", ".", "split", "==", "'train'", ":", "\n", "            ", "self", ".", "data", "=", "npz_data", "[", "'x_train'", "]", "\n", "self", ".", "label", "=", "np", ".", "where", "(", "npz_data", "[", "'y_train'", "]", ">", "0", ")", "[", "1", "]", "\n", "self", ".", "sample_name", "=", "[", "'train_'", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "data", ")", ")", "]", "\n", "", "elif", "self", ".", "split", "==", "'test'", ":", "\n", "            ", "self", ".", "data", "=", "npz_data", "[", "'x_test'", "]", "\n", "self", ".", "label", "=", "np", ".", "where", "(", "npz_data", "[", "'y_test'", "]", ">", "0", ")", "[", "1", "]", "\n", "self", ".", "sample_name", "=", "[", "'test_'", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "len", "(", "self", ".", "data", ")", ")", "]", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "'data split only supports train/test'", ")", "\n", "\n", "", "N", ",", "T", ",", "_", "=", "self", ".", "data", ".", "shape", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "reshape", "(", "(", "N", ",", "T", ",", "2", ",", "25", ",", "3", ")", ")", ".", "transpose", "(", "0", ",", "4", ",", "1", ",", "3", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.feeder_ntu.Feeder.get_mean_map": [[67, 72], ["data.mean().mean().mean", "data.transpose().reshape().std().reshape", "data.mean().mean", "data.transpose().reshape().std", "data.mean", "data.transpose().reshape", "data.transpose"], "methods", ["None"], ["", "def", "get_mean_map", "(", "self", ")", ":", "\n", "        ", "data", "=", "self", ".", "data", "\n", "N", ",", "C", ",", "T", ",", "V", ",", "M", "=", "data", ".", "shape", "\n", "self", ".", "mean_map", "=", "data", ".", "mean", "(", "axis", "=", "2", ",", "keepdims", "=", "True", ")", ".", "mean", "(", "axis", "=", "4", ",", "keepdims", "=", "True", ")", ".", "mean", "(", "axis", "=", "0", ")", "\n", "self", ".", "std_map", "=", "data", ".", "transpose", "(", "(", "0", ",", "2", ",", "4", ",", "1", ",", "3", ")", ")", ".", "reshape", "(", "(", "N", "*", "T", "*", "M", ",", "C", "*", "V", ")", ")", ".", "std", "(", "axis", "=", "0", ")", ".", "reshape", "(", "(", "C", ",", "1", ",", "V", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.feeder_ntu.Feeder.__len__": [[73, 75], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.feeder_ntu.Feeder.__iter__": [[76, 78], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.feeder_ntu.Feeder.__getitem__": [[79, 102], ["numpy.array", "numpy.sum", "feeders.tools.valid_crop_resize", "feeders.tools.random_rot", "numpy.zeros_like", "feeders.tools.random_rot.sum().sum().sum", "feeders.tools.random_rot.sum().sum", "feeders.tools.random_rot.sum"], "methods", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.valid_crop_resize", "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.random_rot"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "data_numpy", "=", "self", ".", "data", "[", "index", "]", "\n", "label", "=", "self", ".", "label", "[", "index", "]", "\n", "data_numpy", "=", "np", ".", "array", "(", "data_numpy", ")", "\n", "valid_frame_num", "=", "np", ".", "sum", "(", "data_numpy", ".", "sum", "(", "0", ")", ".", "sum", "(", "-", "1", ")", ".", "sum", "(", "-", "1", ")", "!=", "0", ")", "\n", "# reshape Tx(MVC) to CTVM", "\n", "data_numpy", "=", "tools", ".", "valid_crop_resize", "(", "data_numpy", ",", "valid_frame_num", ",", "self", ".", "p_interval", ",", "self", ".", "window_size", ")", "\n", "if", "self", ".", "random_rot", ":", "\n", "            ", "data_numpy", "=", "tools", ".", "random_rot", "(", "data_numpy", ")", "\n", "", "if", "self", ".", "bone", ":", "\n", "            ", "ntu_pairs", "=", "(", "(", "1", ",", "2", ")", ",", "(", "2", ",", "21", ")", ",", "(", "3", ",", "21", ")", ",", "(", "4", ",", "3", ")", ",", "(", "5", ",", "21", ")", ",", "(", "6", ",", "5", ")", ",", "\n", "(", "7", ",", "6", ")", ",", "(", "8", ",", "7", ")", ",", "(", "9", ",", "21", ")", ",", "(", "10", ",", "9", ")", ",", "(", "11", ",", "10", ")", ",", "(", "12", ",", "11", ")", ",", "\n", "(", "13", ",", "1", ")", ",", "(", "14", ",", "13", ")", ",", "(", "15", ",", "14", ")", ",", "(", "16", ",", "15", ")", ",", "(", "17", ",", "1", ")", ",", "(", "18", ",", "17", ")", ",", "\n", "(", "19", ",", "18", ")", ",", "(", "20", ",", "19", ")", ",", "(", "22", ",", "23", ")", ",", "(", "21", ",", "21", ")", ",", "(", "23", ",", "8", ")", ",", "(", "24", ",", "25", ")", ",", "(", "25", ",", "12", ")", ")", "\n", "bone_data_numpy", "=", "np", ".", "zeros_like", "(", "data_numpy", ")", "\n", "for", "v1", ",", "v2", "in", "ntu_pairs", ":", "\n", "                ", "bone_data_numpy", "[", ":", ",", ":", ",", "v1", "-", "1", "]", "=", "data_numpy", "[", ":", ",", ":", ",", "v1", "-", "1", "]", "-", "data_numpy", "[", ":", ",", ":", ",", "v2", "-", "1", "]", "\n", "", "data_numpy", "=", "bone_data_numpy", "\n", "", "if", "self", ".", "vel", ":", "\n", "            ", "data_numpy", "[", ":", ",", ":", "-", "1", "]", "=", "data_numpy", "[", ":", ",", "1", ":", "]", "-", "data_numpy", "[", ":", ",", ":", "-", "1", "]", "\n", "data_numpy", "[", ":", ",", "-", "1", "]", "=", "0", "\n", "\n", "", "return", "data_numpy", ",", "label", ",", "index", "", "", "", ""]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.valid_crop_resize": [[9, 38], ["torch.tensor", "torch.tensor", "data.contiguous().view().permute().contiguous().numpy.permute().contiguous().view", "torch.interpolate().squeeze", "data.contiguous().view().permute().contiguous().numpy.contiguous().view().permute().contiguous().numpy", "len", "int", "numpy.minimum", "numpy.random.randint", "numpy.maximum", "print", "data.contiguous().view().permute().contiguous().numpy.permute().contiguous", "torch.interpolate", "data.contiguous().view().permute().contiguous().numpy.contiguous().view().permute().contiguous", "numpy.random.rand", "int", "numpy.floor", "data.contiguous().view().permute().contiguous().numpy.permute", "data.contiguous().view().permute().contiguous().numpy.contiguous().view().permute", "data.contiguous().view().permute().contiguous().numpy.contiguous().view", "data.contiguous().view().permute().contiguous().numpy.contiguous"], "function", ["None"], ["def", "valid_crop_resize", "(", "data_numpy", ",", "valid_frame_num", ",", "p_interval", ",", "window", ")", ":", "\n", "# input: C,T,V,M", "\n", "    ", "C", ",", "T", ",", "V", ",", "M", "=", "data_numpy", ".", "shape", "\n", "begin", "=", "0", "\n", "end", "=", "valid_frame_num", "\n", "valid_size", "=", "end", "-", "begin", "\n", "\n", "#crop", "\n", "if", "len", "(", "p_interval", ")", "==", "1", ":", "\n", "        ", "p", "=", "p_interval", "[", "0", "]", "\n", "bias", "=", "int", "(", "(", "1", "-", "p", ")", "*", "valid_size", "/", "2", ")", "\n", "data", "=", "data_numpy", "[", ":", ",", "begin", "+", "bias", ":", "end", "-", "bias", ",", ":", ",", ":", "]", "# center_crop", "\n", "cropped_length", "=", "data", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "p", "=", "np", ".", "random", ".", "rand", "(", "1", ")", "*", "(", "p_interval", "[", "1", "]", "-", "p_interval", "[", "0", "]", ")", "+", "p_interval", "[", "0", "]", "\n", "cropped_length", "=", "np", ".", "minimum", "(", "np", ".", "maximum", "(", "int", "(", "np", ".", "floor", "(", "valid_size", "*", "p", ")", ")", ",", "64", ")", ",", "valid_size", ")", "# constraint cropped_length lower bound as 64", "\n", "bias", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "valid_size", "-", "cropped_length", "+", "1", ")", "\n", "data", "=", "data_numpy", "[", ":", ",", "begin", "+", "bias", ":", "begin", "+", "bias", "+", "cropped_length", ",", ":", ",", ":", "]", "\n", "if", "data", ".", "shape", "[", "1", "]", "==", "0", ":", "\n", "            ", "print", "(", "cropped_length", ",", "bias", ",", "valid_size", ")", "\n", "\n", "# resize", "\n", "", "", "data", "=", "torch", ".", "tensor", "(", "data", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "data", "=", "data", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "C", "*", "V", "*", "M", ",", "cropped_length", ")", "\n", "data", "=", "data", "[", "None", ",", "None", ",", ":", ",", ":", "]", "\n", "data", "=", "F", ".", "interpolate", "(", "data", ",", "size", "=", "(", "C", "*", "V", "*", "M", ",", "window", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", ".", "squeeze", "(", ")", "# could perform both up sample and down sample", "\n", "data", "=", "data", ".", "contiguous", "(", ")", ".", "view", "(", "C", ",", "V", ",", "M", ",", "window", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.downsample": [[39, 43], ["numpy.random.randint"], "function", ["None"], ["", "def", "downsample", "(", "data_numpy", ",", "step", ",", "random_sample", "=", "True", ")", ":", "\n", "# input: C,T,V,M", "\n", "    ", "begin", "=", "np", ".", "random", ".", "randint", "(", "step", ")", "if", "random_sample", "else", "0", "\n", "return", "data_numpy", "[", ":", ",", "begin", ":", ":", "step", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.temporal_slice": [[45, 50], ["data_numpy.reshape().transpose().reshape", "data_numpy.reshape().transpose", "data_numpy.reshape"], "function", ["None"], ["", "def", "temporal_slice", "(", "data_numpy", ",", "step", ")", ":", "\n", "# input: C,T,V,M", "\n", "    ", "C", ",", "T", ",", "V", ",", "M", "=", "data_numpy", ".", "shape", "\n", "return", "data_numpy", ".", "reshape", "(", "C", ",", "T", "/", "step", ",", "step", ",", "V", ",", "M", ")", ".", "transpose", "(", "\n", "(", "0", ",", "1", ",", "3", ",", "2", ",", "4", ")", ")", ".", "reshape", "(", "C", ",", "T", "/", "step", ",", "V", ",", "step", "*", "M", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.mean_subtractor": [[52, 63], ["valid_frame.argmax", "len", "valid_frame[].argmax"], "function", ["None"], ["", "def", "mean_subtractor", "(", "data_numpy", ",", "mean", ")", ":", "\n", "# input: C,T,V,M", "\n", "# naive version", "\n", "    ", "if", "mean", "==", "0", ":", "\n", "        ", "return", "\n", "", "C", ",", "T", ",", "V", ",", "M", "=", "data_numpy", ".", "shape", "\n", "valid_frame", "=", "(", "data_numpy", "!=", "0", ")", ".", "sum", "(", "axis", "=", "3", ")", ".", "sum", "(", "axis", "=", "2", ")", ".", "sum", "(", "axis", "=", "0", ")", ">", "0", "\n", "begin", "=", "valid_frame", ".", "argmax", "(", ")", "\n", "end", "=", "len", "(", "valid_frame", ")", "-", "valid_frame", "[", ":", ":", "-", "1", "]", ".", "argmax", "(", ")", "\n", "data_numpy", "[", ":", ",", ":", "end", ",", ":", ",", ":", "]", "=", "data_numpy", "[", ":", ",", ":", "end", ",", ":", ",", ":", "]", "-", "mean", "\n", "return", "data_numpy", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.auto_pading": [[65, 74], ["numpy.zeros", "random.randint"], "function", ["None"], ["", "def", "auto_pading", "(", "data_numpy", ",", "size", ",", "random_pad", "=", "False", ")", ":", "\n", "    ", "C", ",", "T", ",", "V", ",", "M", "=", "data_numpy", ".", "shape", "\n", "if", "T", "<", "size", ":", "\n", "        ", "begin", "=", "random", ".", "randint", "(", "0", ",", "size", "-", "T", ")", "if", "random_pad", "else", "0", "\n", "data_numpy_paded", "=", "np", ".", "zeros", "(", "(", "C", ",", "size", ",", "V", ",", "M", ")", ")", "\n", "data_numpy_paded", "[", ":", ",", "begin", ":", "begin", "+", "T", ",", ":", ",", ":", "]", "=", "data_numpy", "\n", "return", "data_numpy_paded", "\n", "", "else", ":", "\n", "        ", "return", "data_numpy", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.random_choose": [[76, 89], ["random.randint", "tools.auto_pading"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.auto_pading"], ["", "", "def", "random_choose", "(", "data_numpy", ",", "size", ",", "auto_pad", "=", "True", ")", ":", "\n", "# input: C,T,V,M \u968f\u673a\u9009\u62e9\u5176\u4e2d\u4e00\u6bb5\uff0c\u4e0d\u662f\u5f88\u5408\u7406\u3002\u56e0\u4e3a\u67090", "\n", "    ", "C", ",", "T", ",", "V", ",", "M", "=", "data_numpy", ".", "shape", "\n", "if", "T", "==", "size", ":", "\n", "        ", "return", "data_numpy", "\n", "", "elif", "T", "<", "size", ":", "\n", "        ", "if", "auto_pad", ":", "\n", "            ", "return", "auto_pading", "(", "data_numpy", ",", "size", ",", "random_pad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "return", "data_numpy", "\n", "", "", "else", ":", "\n", "        ", "begin", "=", "random", ".", "randint", "(", "0", ",", "T", "-", "size", ")", "\n", "return", "data_numpy", "[", ":", ",", "begin", ":", "begin", "+", "size", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.random_move": [[90, 135], ["random.choice", "numpy.arange().round().astype", "numpy.append", "len", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "numpy.array", "range", "numpy.linspace", "numpy.linspace", "numpy.linspace", "numpy.dot", "np.dot.reshape", "numpy.arange().round", "xy.reshape", "numpy.linspace", "numpy.arange", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "function", ["None"], ["", "", "def", "random_move", "(", "data_numpy", ",", "\n", "angle_candidate", "=", "[", "-", "10.", ",", "-", "5.", ",", "0.", ",", "5.", ",", "10.", "]", ",", "\n", "scale_candidate", "=", "[", "0.9", ",", "1.0", ",", "1.1", "]", ",", "\n", "transform_candidate", "=", "[", "-", "0.2", ",", "-", "0.1", ",", "0.0", ",", "0.1", ",", "0.2", "]", ",", "\n", "move_time_candidate", "=", "[", "1", "]", ")", ":", "\n", "# input: C,T,V,M", "\n", "    ", "C", ",", "T", ",", "V", ",", "M", "=", "data_numpy", ".", "shape", "\n", "move_time", "=", "random", ".", "choice", "(", "move_time_candidate", ")", "\n", "node", "=", "np", ".", "arange", "(", "0", ",", "T", ",", "T", "*", "1.0", "/", "move_time", ")", ".", "round", "(", ")", ".", "astype", "(", "int", ")", "\n", "node", "=", "np", ".", "append", "(", "node", ",", "T", ")", "\n", "num_node", "=", "len", "(", "node", ")", "\n", "\n", "A", "=", "np", ".", "random", ".", "choice", "(", "angle_candidate", ",", "num_node", ")", "\n", "S", "=", "np", ".", "random", ".", "choice", "(", "scale_candidate", ",", "num_node", ")", "\n", "T_x", "=", "np", ".", "random", ".", "choice", "(", "transform_candidate", ",", "num_node", ")", "\n", "T_y", "=", "np", ".", "random", ".", "choice", "(", "transform_candidate", ",", "num_node", ")", "\n", "\n", "a", "=", "np", ".", "zeros", "(", "T", ")", "\n", "s", "=", "np", ".", "zeros", "(", "T", ")", "\n", "t_x", "=", "np", ".", "zeros", "(", "T", ")", "\n", "t_y", "=", "np", ".", "zeros", "(", "T", ")", "\n", "\n", "# linspace", "\n", "for", "i", "in", "range", "(", "num_node", "-", "1", ")", ":", "\n", "        ", "a", "[", "node", "[", "i", "]", ":", "node", "[", "i", "+", "1", "]", "]", "=", "np", ".", "linspace", "(", "\n", "A", "[", "i", "]", ",", "A", "[", "i", "+", "1", "]", ",", "node", "[", "i", "+", "1", "]", "-", "node", "[", "i", "]", ")", "*", "np", ".", "pi", "/", "180", "\n", "s", "[", "node", "[", "i", "]", ":", "node", "[", "i", "+", "1", "]", "]", "=", "np", ".", "linspace", "(", "S", "[", "i", "]", ",", "S", "[", "i", "+", "1", "]", ",", "\n", "node", "[", "i", "+", "1", "]", "-", "node", "[", "i", "]", ")", "\n", "t_x", "[", "node", "[", "i", "]", ":", "node", "[", "i", "+", "1", "]", "]", "=", "np", ".", "linspace", "(", "T_x", "[", "i", "]", ",", "T_x", "[", "i", "+", "1", "]", ",", "\n", "node", "[", "i", "+", "1", "]", "-", "node", "[", "i", "]", ")", "\n", "t_y", "[", "node", "[", "i", "]", ":", "node", "[", "i", "+", "1", "]", "]", "=", "np", ".", "linspace", "(", "T_y", "[", "i", "]", ",", "T_y", "[", "i", "+", "1", "]", ",", "\n", "node", "[", "i", "+", "1", "]", "-", "node", "[", "i", "]", ")", "\n", "\n", "", "theta", "=", "np", ".", "array", "(", "[", "[", "np", ".", "cos", "(", "a", ")", "*", "s", ",", "-", "np", ".", "sin", "(", "a", ")", "*", "s", "]", ",", "\n", "[", "np", ".", "sin", "(", "a", ")", "*", "s", ",", "np", ".", "cos", "(", "a", ")", "*", "s", "]", "]", ")", "\n", "\n", "# perform transformation", "\n", "for", "i_frame", "in", "range", "(", "T", ")", ":", "\n", "        ", "xy", "=", "data_numpy", "[", "0", ":", "2", ",", "i_frame", ",", ":", ",", ":", "]", "\n", "new_xy", "=", "np", ".", "dot", "(", "theta", "[", ":", ",", ":", ",", "i_frame", "]", ",", "xy", ".", "reshape", "(", "2", ",", "-", "1", ")", ")", "\n", "new_xy", "[", "0", "]", "+=", "t_x", "[", "i_frame", "]", "\n", "new_xy", "[", "1", "]", "+=", "t_y", "[", "i_frame", "]", "\n", "data_numpy", "[", "0", ":", "2", ",", "i_frame", ",", ":", ",", ":", "]", "=", "new_xy", ".", "reshape", "(", "2", ",", "V", ",", "M", ")", "\n", "\n", "", "return", "data_numpy", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.random_shift": [[137, 149], ["numpy.zeros", "valid_frame.argmax", "random.randint", "len", "valid_frame[].argmax"], "function", ["None"], ["", "def", "random_shift", "(", "data_numpy", ")", ":", "\n", "    ", "C", ",", "T", ",", "V", ",", "M", "=", "data_numpy", ".", "shape", "\n", "data_shift", "=", "np", ".", "zeros", "(", "data_numpy", ".", "shape", ")", "\n", "valid_frame", "=", "(", "data_numpy", "!=", "0", ")", ".", "sum", "(", "axis", "=", "3", ")", ".", "sum", "(", "axis", "=", "2", ")", ".", "sum", "(", "axis", "=", "0", ")", ">", "0", "\n", "begin", "=", "valid_frame", ".", "argmax", "(", ")", "\n", "end", "=", "len", "(", "valid_frame", ")", "-", "valid_frame", "[", ":", ":", "-", "1", "]", ".", "argmax", "(", ")", "\n", "\n", "size", "=", "end", "-", "begin", "\n", "bias", "=", "random", ".", "randint", "(", "0", ",", "T", "-", "size", ")", "\n", "data_shift", "[", ":", ",", "bias", ":", "bias", "+", "size", ",", ":", ",", ":", "]", "=", "data_numpy", "[", ":", ",", "begin", ":", "end", ",", ":", ",", ":", "]", "\n", "\n", "return", "data_shift", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools._rot": [[151, 176], ["torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat.matmul().matmul", "rz.matmul().matmul.cos", "rz.matmul().matmul.sin", "torch.cat.matmul"], "function", ["None"], ["", "def", "_rot", "(", "rot", ")", ":", "\n", "    ", "\"\"\"\n    rot: T,3\n    \"\"\"", "\n", "cos_r", ",", "sin_r", "=", "rot", ".", "cos", "(", ")", ",", "rot", ".", "sin", "(", ")", "# T,3", "\n", "zeros", "=", "torch", ".", "zeros", "(", "rot", ".", "shape", "[", "0", "]", ",", "1", ")", "# T,1", "\n", "ones", "=", "torch", ".", "ones", "(", "rot", ".", "shape", "[", "0", "]", ",", "1", ")", "# T,1", "\n", "\n", "r1", "=", "torch", ".", "stack", "(", "(", "ones", ",", "zeros", ",", "zeros", ")", ",", "dim", "=", "-", "1", ")", "# T,1,3", "\n", "rx2", "=", "torch", ".", "stack", "(", "(", "zeros", ",", "cos_r", "[", ":", ",", "0", ":", "1", "]", ",", "sin_r", "[", ":", ",", "0", ":", "1", "]", ")", ",", "dim", "=", "-", "1", ")", "# T,1,3", "\n", "rx3", "=", "torch", ".", "stack", "(", "(", "zeros", ",", "-", "sin_r", "[", ":", ",", "0", ":", "1", "]", ",", "cos_r", "[", ":", ",", "0", ":", "1", "]", ")", ",", "dim", "=", "-", "1", ")", "# T,1,3", "\n", "rx", "=", "torch", ".", "cat", "(", "(", "r1", ",", "rx2", ",", "rx3", ")", ",", "dim", "=", "1", ")", "# T,3,3", "\n", "\n", "ry1", "=", "torch", ".", "stack", "(", "(", "cos_r", "[", ":", ",", "1", ":", "2", "]", ",", "zeros", ",", "-", "sin_r", "[", ":", ",", "1", ":", "2", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "r2", "=", "torch", ".", "stack", "(", "(", "zeros", ",", "ones", ",", "zeros", ")", ",", "dim", "=", "-", "1", ")", "\n", "ry3", "=", "torch", ".", "stack", "(", "(", "sin_r", "[", ":", ",", "1", ":", "2", "]", ",", "zeros", ",", "cos_r", "[", ":", ",", "1", ":", "2", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "ry", "=", "torch", ".", "cat", "(", "(", "ry1", ",", "r2", ",", "ry3", ")", ",", "dim", "=", "1", ")", "\n", "\n", "rz1", "=", "torch", ".", "stack", "(", "(", "cos_r", "[", ":", ",", "2", ":", "3", "]", ",", "sin_r", "[", ":", ",", "2", ":", "3", "]", ",", "zeros", ")", ",", "dim", "=", "-", "1", ")", "\n", "r3", "=", "torch", ".", "stack", "(", "(", "zeros", ",", "zeros", ",", "ones", ")", ",", "dim", "=", "-", "1", ")", "\n", "rz2", "=", "torch", ".", "stack", "(", "(", "-", "sin_r", "[", ":", ",", "2", ":", "3", "]", ",", "cos_r", "[", ":", ",", "2", ":", "3", "]", ",", "zeros", ")", ",", "dim", "=", "-", "1", ")", "\n", "rz", "=", "torch", ".", "cat", "(", "(", "rz1", ",", "rz2", ",", "r3", ")", ",", "dim", "=", "1", ")", "\n", "\n", "rot", "=", "rz", ".", "matmul", "(", "ry", ")", ".", "matmul", "(", "rx", ")", "\n", "return", "rot", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.random_rot": [[178, 192], ["torch.from_numpy", "torch.from_numpy", "data_torch.view().permute().contiguous.permute().contiguous().view", "torch.zeros().uniform_", "torch.zeros().uniform_", "torch.stack", "torch.stack", "tools._rot", "torch.matmul", "torch.matmul", "data_torch.view().permute().contiguous.view().permute().contiguous", "data_torch.view().permute().contiguous.permute().contiguous", "torch.zeros", "torch.zeros", "data_torch.view().permute().contiguous.view().permute", "data_torch.view().permute().contiguous.permute", "data_torch.view().permute().contiguous.view"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools._rot"], ["", "def", "random_rot", "(", "data_numpy", ",", "theta", "=", "0.3", ")", ":", "\n", "    ", "\"\"\"\n    data_numpy: C,T,V,M\n    \"\"\"", "\n", "data_torch", "=", "torch", ".", "from_numpy", "(", "data_numpy", ")", "\n", "C", ",", "T", ",", "V", ",", "M", "=", "data_torch", ".", "shape", "\n", "data_torch", "=", "data_torch", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "T", ",", "C", ",", "V", "*", "M", ")", "# T,3,V*M", "\n", "rot", "=", "torch", ".", "zeros", "(", "3", ")", ".", "uniform_", "(", "-", "theta", ",", "theta", ")", "\n", "rot", "=", "torch", ".", "stack", "(", "[", "rot", ",", "]", "*", "T", ",", "dim", "=", "0", ")", "\n", "rot", "=", "_rot", "(", "rot", ")", "# T,3,3", "\n", "data_torch", "=", "torch", ".", "matmul", "(", "rot", ",", "data_torch", ")", "\n", "data_torch", "=", "data_torch", ".", "view", "(", "T", ",", "C", ",", "V", ",", "M", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "\n", "return", "data_torch", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.feeders.tools.openpose_match": [[193, 235], ["data_numpy[].sum", "data_numpy[].reshape", "data_numpy[].reshape", "range", "range", "numpy.all", "range", "numpy.zeros", "range", "data_numpy[].sum().sum", "numpy.zeros", "distance[].argmin", "range", "data_numpy[].transpose", "data_numpy[].sum"], "function", ["None"], ["", "def", "openpose_match", "(", "data_numpy", ")", ":", "\n", "    ", "C", ",", "T", ",", "V", ",", "M", "=", "data_numpy", ".", "shape", "\n", "assert", "(", "C", "==", "3", ")", "\n", "score", "=", "data_numpy", "[", "2", ",", ":", ",", ":", ",", ":", "]", ".", "sum", "(", "axis", "=", "1", ")", "\n", "# the rank of body confidence in each frame (shape: T-1, M)", "\n", "rank", "=", "(", "-", "score", "[", "0", ":", "T", "-", "1", "]", ")", ".", "argsort", "(", "axis", "=", "1", ")", ".", "reshape", "(", "T", "-", "1", ",", "M", ")", "\n", "\n", "# data of frame 1", "\n", "xy1", "=", "data_numpy", "[", "0", ":", "2", ",", "0", ":", "T", "-", "1", ",", ":", ",", ":", "]", ".", "reshape", "(", "2", ",", "T", "-", "1", ",", "V", ",", "M", ",", "1", ")", "\n", "# data of frame 2", "\n", "xy2", "=", "data_numpy", "[", "0", ":", "2", ",", "1", ":", "T", ",", ":", ",", ":", "]", ".", "reshape", "(", "2", ",", "T", "-", "1", ",", "V", ",", "1", ",", "M", ")", "\n", "# square of distance between frame 1&2 (shape: T-1, M, M)", "\n", "distance", "=", "(", "(", "xy2", "-", "xy1", ")", "**", "2", ")", ".", "sum", "(", "axis", "=", "2", ")", ".", "sum", "(", "axis", "=", "0", ")", "\n", "\n", "# match pose", "\n", "forward_map", "=", "np", ".", "zeros", "(", "(", "T", ",", "M", ")", ",", "dtype", "=", "int", ")", "-", "1", "\n", "forward_map", "[", "0", "]", "=", "range", "(", "M", ")", "\n", "for", "m", "in", "range", "(", "M", ")", ":", "\n", "        ", "choose", "=", "(", "rank", "==", "m", ")", "\n", "forward", "=", "distance", "[", "choose", "]", ".", "argmin", "(", "axis", "=", "1", ")", "\n", "for", "t", "in", "range", "(", "T", "-", "1", ")", ":", "\n", "            ", "distance", "[", "t", ",", ":", ",", "forward", "[", "t", "]", "]", "=", "np", ".", "inf", "\n", "", "forward_map", "[", "1", ":", "]", "[", "choose", "]", "=", "forward", "\n", "", "assert", "(", "np", ".", "all", "(", "forward_map", ">=", "0", ")", ")", "\n", "\n", "# string data", "\n", "for", "t", "in", "range", "(", "T", "-", "1", ")", ":", "\n", "        ", "forward_map", "[", "t", "+", "1", "]", "=", "forward_map", "[", "t", "+", "1", "]", "[", "forward_map", "[", "t", "]", "]", "\n", "\n", "# generate data", "\n", "", "new_data_numpy", "=", "np", ".", "zeros", "(", "data_numpy", ".", "shape", ")", "\n", "for", "t", "in", "range", "(", "T", ")", ":", "\n", "        ", "new_data_numpy", "[", ":", ",", "t", ",", ":", ",", ":", "]", "=", "data_numpy", "[", ":", ",", "t", ",", ":", ",", "forward_map", "[", "\n", "t", "]", "]", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "", "data_numpy", "=", "new_data_numpy", "\n", "\n", "# score sort", "\n", "trace_score", "=", "data_numpy", "[", "2", ",", ":", ",", ":", ",", ":", "]", ".", "sum", "(", "axis", "=", "1", ")", ".", "sum", "(", "axis", "=", "0", ")", "\n", "rank", "=", "(", "-", "trace_score", ")", ".", "argsort", "(", ")", "\n", "data_numpy", "=", "data_numpy", "[", ":", ",", ":", ",", ":", ",", "rank", "]", "\n", "\n", "return", "data_numpy", "\n", "", ""]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.get_raw_skes_data.get_raw_bodies_data": [[10, 94], ["os.join", "os.exists", "print", "int", "dict", "range", "len", "int", "open", "fr.readlines", "str_data[].strip", "int", "numpy.zeros", "numpy.zeros", "range", "numpy.array", "frames_drop_logger.info", "len", "dict.values", "str_data[].strip", "frames_drop.append", "int", "range", "numpy.sum", "str_data[].strip().split", "str_data[].strip", "str_data[].strip().split", "numpy.array", "numpy.array", "dict", "numpy.vstack", "numpy.vstack", "body_data[].append", "numpy.var", "str_data[].strip", "str_data[].strip"], "function", ["None"], ["def", "get_raw_bodies_data", "(", "skes_path", ",", "ske_name", ",", "frames_drop_skes", ",", "frames_drop_logger", ")", ":", "\n", "    ", "\"\"\"\n    Get raw bodies data from a skeleton sequence.\n\n    Each body's data is a dict that contains the following keys:\n      - joints: raw 3D joints positions. Shape: (num_frames x 25, 3)\n      - colors: raw 2D color locations. Shape: (num_frames, 25, 2)\n      - interval: a list which stores the frame indices of this body.\n      - motion: motion amount (only for the sequence with 2 or more bodyIDs).\n\n    Return:\n      a dict for a skeleton sequence with 3 key-value pairs:\n        - name: the skeleton filename.\n        - data: a dict which stores raw data of each body.\n        - num_frames: the number of valid frames.\n    \"\"\"", "\n", "if", "int", "(", "ske_name", "[", "1", ":", "4", "]", ")", ">=", "18", ":", "\n", "        ", "skes_path", "=", "'../nturgbd_raw/nturgb+d_skeletons120/'", "\n", "", "ske_file", "=", "osp", ".", "join", "(", "skes_path", ",", "ske_name", "+", "'.skeleton'", ")", "\n", "assert", "osp", ".", "exists", "(", "ske_file", ")", ",", "'Error: Skeleton file %s not found'", "%", "ske_file", "\n", "# Read all data from .skeleton file into a list (in string format)", "\n", "print", "(", "'Reading data from %s'", "%", "ske_file", "[", "-", "29", ":", "]", ")", "\n", "with", "open", "(", "ske_file", ",", "'r'", ")", "as", "fr", ":", "\n", "        ", "str_data", "=", "fr", ".", "readlines", "(", ")", "\n", "\n", "", "num_frames", "=", "int", "(", "str_data", "[", "0", "]", ".", "strip", "(", "'\\r\\n'", ")", ")", "\n", "frames_drop", "=", "[", "]", "\n", "bodies_data", "=", "dict", "(", ")", "\n", "valid_frames", "=", "-", "1", "# 0-based index", "\n", "current_line", "=", "1", "\n", "\n", "for", "f", "in", "range", "(", "num_frames", ")", ":", "\n", "        ", "num_bodies", "=", "int", "(", "str_data", "[", "current_line", "]", ".", "strip", "(", "'\\r\\n'", ")", ")", "\n", "current_line", "+=", "1", "\n", "\n", "if", "num_bodies", "==", "0", ":", "# no data in this frame, drop it", "\n", "            ", "frames_drop", ".", "append", "(", "f", ")", "# 0-based index", "\n", "continue", "\n", "\n", "", "valid_frames", "+=", "1", "\n", "joints", "=", "np", ".", "zeros", "(", "(", "num_bodies", ",", "25", ",", "3", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "colors", "=", "np", ".", "zeros", "(", "(", "num_bodies", ",", "25", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "b", "in", "range", "(", "num_bodies", ")", ":", "\n", "            ", "bodyID", "=", "str_data", "[", "current_line", "]", ".", "strip", "(", "'\\r\\n'", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "current_line", "+=", "1", "\n", "num_joints", "=", "int", "(", "str_data", "[", "current_line", "]", ".", "strip", "(", "'\\r\\n'", ")", ")", "# 25 joints", "\n", "current_line", "+=", "1", "\n", "\n", "for", "j", "in", "range", "(", "num_joints", ")", ":", "\n", "                ", "temp_str", "=", "str_data", "[", "current_line", "]", ".", "strip", "(", "'\\r\\n'", ")", ".", "split", "(", ")", "\n", "joints", "[", "b", ",", "j", ",", ":", "]", "=", "np", ".", "array", "(", "temp_str", "[", ":", "3", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "colors", "[", "b", ",", "j", ",", ":", "]", "=", "np", ".", "array", "(", "temp_str", "[", "5", ":", "7", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "current_line", "+=", "1", "\n", "\n", "", "if", "bodyID", "not", "in", "bodies_data", ":", "# Add a new body's data", "\n", "                ", "body_data", "=", "dict", "(", ")", "\n", "body_data", "[", "'joints'", "]", "=", "joints", "[", "b", "]", "# ndarray: (25, 3)", "\n", "body_data", "[", "'colors'", "]", "=", "colors", "[", "b", ",", "np", ".", "newaxis", "]", "# ndarray: (1, 25, 2)", "\n", "body_data", "[", "'interval'", "]", "=", "[", "valid_frames", "]", "# the index of the first frame", "\n", "", "else", ":", "# Update an already existed body's data", "\n", "                ", "body_data", "=", "bodies_data", "[", "bodyID", "]", "\n", "# Stack each body's data of each frame along the frame order", "\n", "body_data", "[", "'joints'", "]", "=", "np", ".", "vstack", "(", "(", "body_data", "[", "'joints'", "]", ",", "joints", "[", "b", "]", ")", ")", "\n", "body_data", "[", "'colors'", "]", "=", "np", ".", "vstack", "(", "(", "body_data", "[", "'colors'", "]", ",", "colors", "[", "b", ",", "np", ".", "newaxis", "]", ")", ")", "\n", "pre_frame_idx", "=", "body_data", "[", "'interval'", "]", "[", "-", "1", "]", "\n", "body_data", "[", "'interval'", "]", ".", "append", "(", "pre_frame_idx", "+", "1", ")", "# add a new frame index", "\n", "\n", "", "bodies_data", "[", "bodyID", "]", "=", "body_data", "# Update bodies_data", "\n", "\n", "", "", "num_frames_drop", "=", "len", "(", "frames_drop", ")", "\n", "assert", "num_frames_drop", "<", "num_frames", ",", "'Error: All frames data (%d) of %s is missing or lost'", "%", "(", "num_frames", ",", "ske_name", ")", "\n", "if", "num_frames_drop", ">", "0", ":", "\n", "        ", "frames_drop_skes", "[", "ske_name", "]", "=", "np", ".", "array", "(", "frames_drop", ",", "dtype", "=", "np", ".", "int", ")", "\n", "frames_drop_logger", ".", "info", "(", "'{}: {} frames missed: {}\\n'", ".", "format", "(", "ske_name", ",", "num_frames_drop", ",", "\n", "frames_drop", ")", ")", "\n", "\n", "# Calculate motion (only for the sequence with 2 or more bodyIDs)", "\n", "", "if", "len", "(", "bodies_data", ")", ">", "1", ":", "\n", "        ", "for", "body_data", "in", "bodies_data", ".", "values", "(", ")", ":", "\n", "            ", "body_data", "[", "'motion'", "]", "=", "np", ".", "sum", "(", "np", ".", "var", "(", "body_data", "[", "'joints'", "]", ",", "axis", "=", "0", ")", ")", "\n", "\n", "", "", "return", "{", "'name'", ":", "ske_name", ",", "'data'", ":", "bodies_data", ",", "'num_frames'", ":", "num_frames", "-", "num_frames_drop", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.get_raw_skes_data.get_raw_skes_data": [[96, 135], ["numpy.loadtxt", "print", "numpy.zeros", "enumerate", "numpy.savetxt", "print", "print", "get_raw_skes_data.get_raw_bodies_data", "raw_skes_data.append", "open", "pickle.dump", "os.join", "open", "pickle.dump", "print", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_skes_data.get_raw_bodies_data"], ["", "def", "get_raw_skes_data", "(", ")", ":", "\n", "# # save_path = './data'", "\n", "# # skes_path = '/data/pengfei/NTU/nturgb+d_skeletons/'", "\n", "# stat_path = osp.join(save_path, 'statistics')", "\n", "#", "\n", "# skes_name_file = osp.join(stat_path, 'skes_available_name.txt')", "\n", "# save_data_pkl = osp.join(save_path, 'raw_skes_data.pkl')", "\n", "# frames_drop_pkl = osp.join(save_path, 'frames_drop_skes.pkl')", "\n", "#", "\n", "# frames_drop_logger = logging.getLogger('frames_drop')", "\n", "# frames_drop_logger.setLevel(logging.INFO)", "\n", "# frames_drop_logger.addHandler(logging.FileHandler(osp.join(save_path, 'frames_drop.log')))", "\n", "# frames_drop_skes = dict()", "\n", "\n", "    ", "skes_name", "=", "np", ".", "loadtxt", "(", "skes_name_file", ",", "dtype", "=", "str", ")", "\n", "\n", "num_files", "=", "skes_name", ".", "size", "\n", "print", "(", "'Found %d available skeleton files.'", "%", "num_files", ")", "\n", "\n", "raw_skes_data", "=", "[", "]", "\n", "frames_cnt", "=", "np", ".", "zeros", "(", "num_files", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "for", "(", "idx", ",", "ske_name", ")", "in", "enumerate", "(", "skes_name", ")", ":", "\n", "        ", "bodies_data", "=", "get_raw_bodies_data", "(", "skes_path", ",", "ske_name", ",", "frames_drop_skes", ",", "frames_drop_logger", ")", "\n", "raw_skes_data", ".", "append", "(", "bodies_data", ")", "\n", "frames_cnt", "[", "idx", "]", "=", "bodies_data", "[", "'num_frames'", "]", "\n", "if", "(", "idx", "+", "1", ")", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "'Processed: %.2f%% (%d / %d)'", "%", "(", "100.0", "*", "(", "idx", "+", "1", ")", "/", "num_files", ",", "idx", "+", "1", ",", "num_files", ")", ")", "\n", "\n", "", "", "with", "open", "(", "save_data_pkl", ",", "'wb'", ")", "as", "fw", ":", "\n", "        ", "pickle", ".", "dump", "(", "raw_skes_data", ",", "fw", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "np", ".", "savetxt", "(", "osp", ".", "join", "(", "save_path", ",", "'raw_data'", ",", "'frames_cnt.txt'", ")", ",", "frames_cnt", ",", "fmt", "=", "'%d'", ")", "\n", "\n", "print", "(", "'Saved raw bodies data into %s'", "%", "save_data_pkl", ")", "\n", "print", "(", "'Total frames: %d'", "%", "np", ".", "sum", "(", "frames_cnt", ")", ")", "\n", "\n", "with", "open", "(", "frames_drop_pkl", ",", "'wb'", ")", "as", "fw", ":", "\n", "        ", "pickle", ".", "dump", "(", "frames_drop_skes", ",", "fw", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.get_raw_denoised_data.denoising_by_length": [[71, 90], ["str", "bodies_data.copy", "bodies_data.copy.items", "len", "noise_len_logger.info"], "function", ["None"], ["def", "denoising_by_length", "(", "ske_name", ",", "bodies_data", ")", ":", "\n", "    ", "\"\"\"\n    Denoising data based on the frame length for each bodyID.\n    Filter out the bodyID which length is less or equal than the predefined threshold.\n\n    \"\"\"", "\n", "noise_info", "=", "str", "(", ")", "\n", "new_bodies_data", "=", "bodies_data", ".", "copy", "(", ")", "\n", "for", "(", "bodyID", ",", "body_data", ")", "in", "new_bodies_data", ".", "items", "(", ")", ":", "\n", "        ", "length", "=", "len", "(", "body_data", "[", "'interval'", "]", ")", "\n", "if", "length", "<=", "noise_len_thres", ":", "\n", "            ", "noise_info", "+=", "'Filter out: %s, %d (length).\\n'", "%", "(", "bodyID", ",", "length", ")", "\n", "noise_len_logger", ".", "info", "(", "'{}\\t{}\\t{:.6f}\\t{:^6d}'", ".", "format", "(", "ske_name", ",", "bodyID", ",", "\n", "body_data", "[", "'motion'", "]", ",", "length", ")", ")", "\n", "del", "bodies_data", "[", "bodyID", "]", "\n", "", "", "if", "noise_info", "!=", "''", ":", "\n", "        ", "noise_info", "+=", "'\\n'", "\n", "\n", "", "return", "bodies_data", ",", "noise_info", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.get_raw_denoised_data.get_valid_frames_by_spread": [[92, 106], ["range", "valid_frames.append", "x.max", "x.min", "y.max", "y.min"], "function", ["None"], ["", "def", "get_valid_frames_by_spread", "(", "points", ")", ":", "\n", "    ", "\"\"\"\n    Find the valid (or reasonable) frames (index) based on the spread of X and Y.\n\n    points: joints or colors\n    \"\"\"", "\n", "num_frames", "=", "points", ".", "shape", "[", "0", "]", "\n", "valid_frames", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_frames", ")", ":", "\n", "        ", "x", "=", "points", "[", "i", ",", ":", ",", "0", "]", "\n", "y", "=", "points", "[", "i", ",", ":", ",", "1", "]", "\n", "if", "(", "x", ".", "max", "(", ")", "-", "x", ".", "min", "(", ")", ")", "<=", "noise_spr_thres1", "*", "(", "y", ".", "max", "(", ")", "-", "y", ".", "min", "(", ")", ")", ":", "# 0.8", "\n", "            ", "valid_frames", ".", "append", "(", "i", ")", "\n", "", "", "return", "valid_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.get_raw_denoised_data.denoising_by_spread": [[108, 147], ["str", "bodies_data.copy", "bodies_data.copy.items", "get_raw_denoised_data.get_valid_frames_by_spread", "len", "len", "body_data[].reshape", "len", "float", "noise_spr_logger.info", "min", "body_data[].reshape", "numpy.sum", "numpy.var", "joints.reshape"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_valid_frames_by_spread"], ["", "def", "denoising_by_spread", "(", "ske_name", ",", "bodies_data", ")", ":", "\n", "    ", "\"\"\"\n    Denoising data based on the spread of Y value and X value.\n    Filter out the bodyID which the ratio of noisy frames is higher than the predefined\n    threshold.\n\n    bodies_data: contains at least 2 bodyIDs\n    \"\"\"", "\n", "noise_info", "=", "str", "(", ")", "\n", "denoised_by_spr", "=", "False", "# mark if this sequence has been processed by spread.", "\n", "\n", "new_bodies_data", "=", "bodies_data", ".", "copy", "(", ")", "\n", "# for (bodyID, body_data) in bodies_data.items():", "\n", "for", "(", "bodyID", ",", "body_data", ")", "in", "new_bodies_data", ".", "items", "(", ")", ":", "\n", "        ", "if", "len", "(", "bodies_data", ")", "==", "1", ":", "\n", "            ", "break", "\n", "", "valid_frames", "=", "get_valid_frames_by_spread", "(", "body_data", "[", "'joints'", "]", ".", "reshape", "(", "-", "1", ",", "25", ",", "3", ")", ")", "\n", "num_frames", "=", "len", "(", "body_data", "[", "'interval'", "]", ")", "\n", "num_noise", "=", "num_frames", "-", "len", "(", "valid_frames", ")", "\n", "if", "num_noise", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "ratio", "=", "num_noise", "/", "float", "(", "num_frames", ")", "\n", "motion", "=", "body_data", "[", "'motion'", "]", "\n", "if", "ratio", ">=", "noise_spr_thres2", ":", "# 0.69754", "\n", "            ", "del", "bodies_data", "[", "bodyID", "]", "\n", "denoised_by_spr", "=", "True", "\n", "noise_info", "+=", "'Filter out: %s (spread rate >= %.2f).\\n'", "%", "(", "bodyID", ",", "noise_spr_thres2", ")", "\n", "noise_spr_logger", ".", "info", "(", "'%s\\t%s\\t%.6f\\t%.6f'", "%", "(", "ske_name", ",", "bodyID", ",", "motion", ",", "ratio", ")", ")", "\n", "", "else", ":", "# Update motion", "\n", "            ", "joints", "=", "body_data", "[", "'joints'", "]", ".", "reshape", "(", "-", "1", ",", "25", ",", "3", ")", "[", "valid_frames", "]", "\n", "body_data", "[", "'motion'", "]", "=", "min", "(", "motion", ",", "np", ".", "sum", "(", "np", ".", "var", "(", "joints", ".", "reshape", "(", "-", "1", ",", "3", ")", ",", "axis", "=", "0", ")", ")", ")", "\n", "noise_info", "+=", "'%s: motion %.6f -> %.6f\\n'", "%", "(", "bodyID", ",", "motion", ",", "body_data", "[", "'motion'", "]", ")", "\n", "# TODO: Consider removing noisy frames for each bodyID", "\n", "\n", "", "", "if", "noise_info", "!=", "''", ":", "\n", "        ", "noise_info", "+=", "'\\n'", "\n", "\n", "", "return", "bodies_data", ",", "noise_info", ",", "denoised_by_spr", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.get_raw_denoised_data.denoising_by_motion": [[149, 172], ["sorted", "str", "sorted.items", "noise_mot_logger.info", "denoised_bodies_data.append"], "function", ["None"], ["", "def", "denoising_by_motion", "(", "ske_name", ",", "bodies_data", ",", "bodies_motion", ")", ":", "\n", "    ", "\"\"\"\n    Filter out the bodyID which motion is out of the range of predefined interval\n\n    \"\"\"", "\n", "# Sort bodies based on the motion, return a list of tuples", "\n", "# bodies_motion = sorted(bodies_motion.items(), key=lambda x, y: cmp(x[1], y[1]), reverse=True)", "\n", "bodies_motion", "=", "sorted", "(", "bodies_motion", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "# Reserve the body data with the largest motion", "\n", "denoised_bodies_data", "=", "[", "(", "bodies_motion", "[", "0", "]", "[", "0", "]", ",", "bodies_data", "[", "bodies_motion", "[", "0", "]", "[", "0", "]", "]", ")", "]", "\n", "noise_info", "=", "str", "(", ")", "\n", "\n", "for", "(", "bodyID", ",", "motion", ")", "in", "bodies_motion", "[", "1", ":", "]", ":", "\n", "        ", "if", "(", "motion", "<", "noise_mot_thres_lo", ")", "or", "(", "motion", ">", "noise_mot_thres_hi", ")", ":", "\n", "            ", "noise_info", "+=", "'Filter out: %s, %.6f (motion).\\n'", "%", "(", "bodyID", ",", "motion", ")", "\n", "noise_mot_logger", ".", "info", "(", "'{}\\t{}\\t{:.6f}'", ".", "format", "(", "ske_name", ",", "bodyID", ",", "motion", ")", ")", "\n", "", "else", ":", "\n", "            ", "denoised_bodies_data", ".", "append", "(", "(", "bodyID", ",", "bodies_data", "[", "bodyID", "]", ")", ")", "\n", "", "", "if", "noise_info", "!=", "''", ":", "\n", "        ", "noise_info", "+=", "'\\n'", "\n", "\n", "", "return", "denoised_bodies_data", ",", "noise_info", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.get_raw_denoised_data.denoising_bodies_data": [[174, 207], ["get_raw_denoised_data.denoising_by_length", "get_raw_denoised_data.denoising_by_spread", "dict", "bodies_data.items", "sorted", "list", "len", "len", "sorted.items", "list.append", "bodies_data.items", "bodies_data.items"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.denoising_by_length", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.denoising_by_spread"], ["", "def", "denoising_bodies_data", "(", "bodies_data", ")", ":", "\n", "    ", "\"\"\"\n    Denoising data based on some heuristic methods, not necessarily correct for all samples.\n\n    Return:\n      denoised_bodies_data (list): tuple: (bodyID, body_data).\n    \"\"\"", "\n", "ske_name", "=", "bodies_data", "[", "'name'", "]", "\n", "bodies_data", "=", "bodies_data", "[", "'data'", "]", "\n", "\n", "# Step 1: Denoising based on frame length.", "\n", "bodies_data", ",", "noise_info_len", "=", "denoising_by_length", "(", "ske_name", ",", "bodies_data", ")", "\n", "\n", "if", "len", "(", "bodies_data", ")", "==", "1", ":", "# only has one bodyID left after step 1", "\n", "        ", "return", "bodies_data", ".", "items", "(", ")", ",", "noise_info_len", "\n", "\n", "# Step 2: Denoising based on spread.", "\n", "", "bodies_data", ",", "noise_info_spr", ",", "denoised_by_spr", "=", "denoising_by_spread", "(", "ske_name", ",", "bodies_data", ")", "\n", "\n", "if", "len", "(", "bodies_data", ")", "==", "1", ":", "\n", "        ", "return", "bodies_data", ".", "items", "(", ")", ",", "noise_info_len", "+", "noise_info_spr", "\n", "\n", "", "bodies_motion", "=", "dict", "(", ")", "# get body motion", "\n", "for", "(", "bodyID", ",", "body_data", ")", "in", "bodies_data", ".", "items", "(", ")", ":", "\n", "        ", "bodies_motion", "[", "bodyID", "]", "=", "body_data", "[", "'motion'", "]", "\n", "# Sort bodies based on the motion", "\n", "# bodies_motion = sorted(bodies_motion.items(), key=lambda x, y: cmp(x[1], y[1]), reverse=True)", "\n", "", "bodies_motion", "=", "sorted", "(", "bodies_motion", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "denoised_bodies_data", "=", "list", "(", ")", "\n", "for", "(", "bodyID", ",", "_", ")", "in", "bodies_motion", ":", "\n", "        ", "denoised_bodies_data", ".", "append", "(", "(", "bodyID", ",", "bodies_data", "[", "bodyID", "]", ")", ")", "\n", "\n", "", "return", "denoised_bodies_data", ",", "noise_info_len", "+", "noise_info_spr", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.get_raw_denoised_data.get_one_actor_points": [[223, 236], ["numpy.zeros", "body_data[].reshape", "numpy.ones"], "function", ["None"], ["", "def", "get_one_actor_points", "(", "body_data", ",", "num_frames", ")", ":", "\n", "    ", "\"\"\"\n    Get joints and colors for only one actor.\n    For joints, each frame contains 75 X-Y-Z coordinates.\n    For colors, each frame contains 25 x 2 (X, Y) coordinates.\n    \"\"\"", "\n", "joints", "=", "np", ".", "zeros", "(", "(", "num_frames", ",", "75", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "colors", "=", "np", ".", "ones", "(", "(", "num_frames", ",", "1", ",", "25", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "*", "np", ".", "nan", "\n", "start", ",", "end", "=", "body_data", "[", "'interval'", "]", "[", "0", "]", ",", "body_data", "[", "'interval'", "]", "[", "-", "1", "]", "\n", "joints", "[", "start", ":", "end", "+", "1", "]", "=", "body_data", "[", "'joints'", "]", ".", "reshape", "(", "-", "1", ",", "75", ")", "\n", "colors", "[", "start", ":", "end", "+", "1", ",", "0", "]", "=", "body_data", "[", "'colors'", "]", "\n", "\n", "return", "joints", ",", "colors", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.get_raw_denoised_data.remove_missing_frames": [[238, 279], ["len", "len", "len", "numpy.where", "numpy.where", "missing_skes_logger.info", "numpy.where", "numpy.where", "max", "missing_skes_logger1.info", "missing_skes_logger2.info", "joints.sum", "joints.sum", "joints[].sum", "joints[].sum"], "function", ["None"], ["", "def", "remove_missing_frames", "(", "ske_name", ",", "joints", ",", "colors", ")", ":", "\n", "    ", "\"\"\"\n    Cut off missing frames which all joints positions are 0s\n\n    For the sequence with 2 actors' data, also record the number of missing frames for\n    actor1 and actor2, respectively (for debug).\n    \"\"\"", "\n", "num_frames", "=", "joints", ".", "shape", "[", "0", "]", "\n", "num_bodies", "=", "colors", ".", "shape", "[", "1", "]", "# 1 or 2", "\n", "\n", "if", "num_bodies", "==", "2", ":", "# DEBUG", "\n", "        ", "missing_indices_1", "=", "np", ".", "where", "(", "joints", "[", ":", ",", ":", "75", "]", ".", "sum", "(", "axis", "=", "1", ")", "==", "0", ")", "[", "0", "]", "\n", "missing_indices_2", "=", "np", ".", "where", "(", "joints", "[", ":", ",", "75", ":", "]", ".", "sum", "(", "axis", "=", "1", ")", "==", "0", ")", "[", "0", "]", "\n", "cnt1", "=", "len", "(", "missing_indices_1", ")", "\n", "cnt2", "=", "len", "(", "missing_indices_2", ")", "\n", "\n", "start", "=", "1", "if", "0", "in", "missing_indices_1", "else", "0", "\n", "end", "=", "1", "if", "num_frames", "-", "1", "in", "missing_indices_1", "else", "0", "\n", "if", "max", "(", "cnt1", ",", "cnt2", ")", ">", "0", ":", "\n", "            ", "if", "cnt1", ">", "cnt2", ":", "\n", "                ", "info", "=", "'{}\\t{:^10d}\\t{:^6d}\\t{:^6d}\\t{:^5d}\\t{:^3d}'", ".", "format", "(", "ske_name", ",", "num_frames", ",", "\n", "cnt1", ",", "cnt2", ",", "start", ",", "end", ")", "\n", "missing_skes_logger1", ".", "info", "(", "info", ")", "\n", "", "else", ":", "\n", "                ", "info", "=", "'{}\\t{:^10d}\\t{:^6d}\\t{:^6d}'", ".", "format", "(", "ske_name", ",", "num_frames", ",", "cnt1", ",", "cnt2", ")", "\n", "missing_skes_logger2", ".", "info", "(", "info", ")", "\n", "\n", "# Find valid frame indices that the data is not missing or lost", "\n", "# For two-subjects action, this means both data of actor1 and actor2 is missing.", "\n", "", "", "", "valid_indices", "=", "np", ".", "where", "(", "joints", ".", "sum", "(", "axis", "=", "1", ")", "!=", "0", ")", "[", "0", "]", "# 0-based index", "\n", "missing_indices", "=", "np", ".", "where", "(", "joints", ".", "sum", "(", "axis", "=", "1", ")", "==", "0", ")", "[", "0", "]", "\n", "num_missing", "=", "len", "(", "missing_indices", ")", "\n", "\n", "if", "num_missing", ">", "0", ":", "# Update joints and colors", "\n", "        ", "joints", "=", "joints", "[", "valid_indices", "]", "\n", "colors", "[", "missing_indices", "]", "=", "np", ".", "nan", "\n", "global", "missing_count", "\n", "missing_count", "+=", "1", "\n", "missing_skes_logger", ".", "info", "(", "'{}\\t{:^10d}\\t{:^11d}'", ".", "format", "(", "ske_name", ",", "num_frames", ",", "num_missing", ")", ")", "\n", "\n", "", "return", "joints", ",", "colors", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.get_raw_denoised_data.get_bodies_info": [[281, 288], ["bodies_data.items", "str"], "function", ["None"], ["", "def", "get_bodies_info", "(", "bodies_data", ")", ":", "\n", "    ", "bodies_info", "=", "'{:^17}\\t{}\\t{:^8}\\n'", ".", "format", "(", "'bodyID'", ",", "'Interval'", ",", "'Motion'", ")", "\n", "for", "(", "bodyID", ",", "body_data", ")", "in", "bodies_data", ".", "items", "(", ")", ":", "\n", "        ", "start", ",", "end", "=", "body_data", "[", "'interval'", "]", "[", "0", "]", ",", "body_data", "[", "'interval'", "]", "[", "-", "1", "]", "\n", "bodies_info", "+=", "'{}\\t{:^8}\\t{:f}\\n'", ".", "format", "(", "bodyID", ",", "str", "(", "[", "start", ",", "end", "]", ")", ",", "body_data", "[", "'motion'", "]", ")", "\n", "\n", "", "return", "bodies_info", "+", "'\\n'", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.get_raw_denoised_data.get_two_actors_points": [[290, 365], ["int", "get_raw_denoised_data.get_bodies_info", "get_raw_denoised_data.denoising_bodies_data", "list", "len", "get_raw_denoised_data.get_one_actor_points", "numpy.zeros", "actor1[].reshape", "open", "fw.write", "fail_logger_2.info", "fail_logger_1.info", "numpy.ones", "len", "os.join", "str", "actor[].reshape", "min", "max", "min", "max", "str", "actor[].reshape", "min", "max", "min", "max", "str"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_bodies_info", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.denoising_bodies_data", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_one_actor_points"], ["", "def", "get_two_actors_points", "(", "bodies_data", ")", ":", "\n", "    ", "\"\"\"\n    Get the first and second actor's joints positions and colors locations.\n\n    # Arguments:\n        bodies_data (dict): 3 key-value pairs: 'name', 'data', 'num_frames'.\n        bodies_data['data'] is also a dict, while the key is bodyID, the value is\n        the corresponding body_data which is also a dict with 4 keys:\n          - joints: raw 3D joints positions. Shape: (num_frames x 25, 3)\n          - colors: raw 2D color locations. Shape: (num_frames, 25, 2)\n          - interval: a list which records the frame indices.\n          - motion: motion amount\n\n    # Return:\n        joints, colors.\n    \"\"\"", "\n", "ske_name", "=", "bodies_data", "[", "'name'", "]", "\n", "label", "=", "int", "(", "ske_name", "[", "-", "2", ":", "]", ")", "\n", "num_frames", "=", "bodies_data", "[", "'num_frames'", "]", "\n", "bodies_info", "=", "get_bodies_info", "(", "bodies_data", "[", "'data'", "]", ")", "\n", "\n", "bodies_data", ",", "noise_info", "=", "denoising_bodies_data", "(", "bodies_data", ")", "# Denoising data", "\n", "bodies_info", "+=", "noise_info", "\n", "\n", "bodies_data", "=", "list", "(", "bodies_data", ")", "\n", "if", "len", "(", "bodies_data", ")", "==", "1", ":", "# Only left one actor after denoising", "\n", "        ", "if", "label", ">=", "50", ":", "# DEBUG: Denoising failed for two-subjects action", "\n", "            ", "fail_logger_2", ".", "info", "(", "ske_name", ")", "\n", "\n", "", "bodyID", ",", "body_data", "=", "bodies_data", "[", "0", "]", "\n", "joints", ",", "colors", "=", "get_one_actor_points", "(", "body_data", ",", "num_frames", ")", "\n", "bodies_info", "+=", "'Main actor: %s'", "%", "bodyID", "\n", "", "else", ":", "\n", "        ", "if", "label", "<", "50", ":", "# DEBUG: Denoising failed for one-subject action", "\n", "            ", "fail_logger_1", ".", "info", "(", "ske_name", ")", "\n", "\n", "", "joints", "=", "np", ".", "zeros", "(", "(", "num_frames", ",", "150", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "colors", "=", "np", ".", "ones", "(", "(", "num_frames", ",", "2", ",", "25", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "*", "np", ".", "nan", "\n", "\n", "bodyID", ",", "actor1", "=", "bodies_data", "[", "0", "]", "# the 1st actor with largest motion", "\n", "start1", ",", "end1", "=", "actor1", "[", "'interval'", "]", "[", "0", "]", ",", "actor1", "[", "'interval'", "]", "[", "-", "1", "]", "\n", "joints", "[", "start1", ":", "end1", "+", "1", ",", ":", "75", "]", "=", "actor1", "[", "'joints'", "]", ".", "reshape", "(", "-", "1", ",", "75", ")", "\n", "colors", "[", "start1", ":", "end1", "+", "1", ",", "0", "]", "=", "actor1", "[", "'colors'", "]", "\n", "actor1_info", "=", "'{:^17}\\t{}\\t{:^8}\\n'", ".", "format", "(", "'Actor1'", ",", "'Interval'", ",", "'Motion'", ")", "+", "'{}\\t{:^8}\\t{:f}\\n'", ".", "format", "(", "bodyID", ",", "str", "(", "[", "start1", ",", "end1", "]", ")", ",", "actor1", "[", "'motion'", "]", ")", "\n", "del", "bodies_data", "[", "0", "]", "\n", "\n", "actor2_info", "=", "'{:^17}\\t{}\\t{:^8}\\n'", ".", "format", "(", "'Actor2'", ",", "'Interval'", ",", "'Motion'", ")", "\n", "start2", ",", "end2", "=", "[", "0", ",", "0", "]", "# initial interval for actor2 (virtual)", "\n", "\n", "while", "len", "(", "bodies_data", ")", ">", "0", ":", "\n", "            ", "bodyID", ",", "actor", "=", "bodies_data", "[", "0", "]", "\n", "start", ",", "end", "=", "actor", "[", "'interval'", "]", "[", "0", "]", ",", "actor", "[", "'interval'", "]", "[", "-", "1", "]", "\n", "if", "min", "(", "end1", ",", "end", ")", "-", "max", "(", "start1", ",", "start", ")", "<=", "0", ":", "# no overlap with actor1", "\n", "                ", "joints", "[", "start", ":", "end", "+", "1", ",", ":", "75", "]", "=", "actor", "[", "'joints'", "]", ".", "reshape", "(", "-", "1", ",", "75", ")", "\n", "colors", "[", "start", ":", "end", "+", "1", ",", "0", "]", "=", "actor", "[", "'colors'", "]", "\n", "actor1_info", "+=", "'{}\\t{:^8}\\t{:f}\\n'", ".", "format", "(", "bodyID", ",", "str", "(", "[", "start", ",", "end", "]", ")", ",", "actor", "[", "'motion'", "]", ")", "\n", "# Update the interval of actor1", "\n", "start1", "=", "min", "(", "start", ",", "start1", ")", "\n", "end1", "=", "max", "(", "end", ",", "end1", ")", "\n", "", "elif", "min", "(", "end2", ",", "end", ")", "-", "max", "(", "start2", ",", "start", ")", "<=", "0", ":", "# no overlap with actor2", "\n", "                ", "joints", "[", "start", ":", "end", "+", "1", ",", "75", ":", "]", "=", "actor", "[", "'joints'", "]", ".", "reshape", "(", "-", "1", ",", "75", ")", "\n", "colors", "[", "start", ":", "end", "+", "1", ",", "1", "]", "=", "actor", "[", "'colors'", "]", "\n", "actor2_info", "+=", "'{}\\t{:^8}\\t{:f}\\n'", ".", "format", "(", "bodyID", ",", "str", "(", "[", "start", ",", "end", "]", ")", ",", "actor", "[", "'motion'", "]", ")", "\n", "# Update the interval of actor2", "\n", "start2", "=", "min", "(", "start", ",", "start2", ")", "\n", "end2", "=", "max", "(", "end", ",", "end2", ")", "\n", "", "del", "bodies_data", "[", "0", "]", "\n", "\n", "", "bodies_info", "+=", "(", "'\\n'", "+", "actor1_info", "+", "'\\n'", "+", "actor2_info", ")", "\n", "\n", "", "with", "open", "(", "osp", ".", "join", "(", "actors_info_dir", ",", "ske_name", "+", "'.txt'", ")", ",", "'w'", ")", "as", "fw", ":", "\n", "        ", "fw", ".", "write", "(", "bodies_info", "+", "'\\n'", ")", "\n", "\n", "", "return", "joints", ",", "colors", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.get_raw_denoised_data.get_raw_denoised_data": [[367, 434], ["len", "print", "enumerate", "os.join", "os.join", "numpy.array", "numpy.savetxt", "print", "print", "open", "pickle.load", "print", "len", "raw_denoised_joints.append", "raw_denoised_colors.append", "np.array.append", "open", "pickle.dump", "open", "pickle.dump", "os.join", "get_raw_denoised_data.get_one_actor_points", "get_raw_denoised_data.get_two_actors_points", "get_raw_denoised_data.remove_missing_frames", "print", "numpy.sum", "list", "bodies_data[].values"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_one_actor_points", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_two_actors_points", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.remove_missing_frames"], ["", "def", "get_raw_denoised_data", "(", ")", ":", "\n", "    ", "\"\"\"\n    Get denoised data (joints positions and color locations) from raw skeleton sequences.\n\n    For each frame of a skeleton sequence, an actor's 3D positions of 25 joints represented\n    by an 2D array (shape: 25 x 3) is reshaped into a 75-dim vector by concatenating each\n    3-dim (x, y, z) coordinates along the row dimension in joint order. Each frame contains\n    two actor's joints positions constituting a 150-dim vector. If there is only one actor,\n    then the last 75 values are filled with zeros. Otherwise, select the main actor and the\n    second actor based on the motion amount. Each 150-dim vector as a row vector is put into\n    a 2D numpy array where the number of rows equals the number of valid frames. All such\n    2D arrays are put into a list and finally the list is serialized into a cPickle file.\n\n    For the skeleton sequence which contains two or more actors (mostly corresponds to the\n    last 11 classes), the filename and actors' information are recorded into log files.\n    For better understanding, also generate RGB+skeleton videos for visualization.\n    \"\"\"", "\n", "\n", "with", "open", "(", "raw_data_file", ",", "'rb'", ")", "as", "fr", ":", "# load raw skeletons data", "\n", "        ", "raw_skes_data", "=", "pickle", ".", "load", "(", "fr", ")", "\n", "\n", "", "num_skes", "=", "len", "(", "raw_skes_data", ")", "\n", "print", "(", "'Found %d available skeleton sequences.'", "%", "num_skes", ")", "\n", "\n", "raw_denoised_joints", "=", "[", "]", "\n", "raw_denoised_colors", "=", "[", "]", "\n", "frames_cnt", "=", "[", "]", "\n", "\n", "for", "(", "idx", ",", "bodies_data", ")", "in", "enumerate", "(", "raw_skes_data", ")", ":", "\n", "        ", "ske_name", "=", "bodies_data", "[", "'name'", "]", "\n", "print", "(", "'Processing %s'", "%", "ske_name", ")", "\n", "num_bodies", "=", "len", "(", "bodies_data", "[", "'data'", "]", ")", "\n", "\n", "if", "num_bodies", "==", "1", ":", "# only 1 actor", "\n", "            ", "num_frames", "=", "bodies_data", "[", "'num_frames'", "]", "\n", "body_data", "=", "list", "(", "bodies_data", "[", "'data'", "]", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "joints", ",", "colors", "=", "get_one_actor_points", "(", "body_data", ",", "num_frames", ")", "\n", "", "else", ":", "# more than 1 actor, select two main actors", "\n", "            ", "joints", ",", "colors", "=", "get_two_actors_points", "(", "bodies_data", ")", "\n", "# Remove missing frames", "\n", "joints", ",", "colors", "=", "remove_missing_frames", "(", "ske_name", ",", "joints", ",", "colors", ")", "\n", "num_frames", "=", "joints", ".", "shape", "[", "0", "]", "# Update", "\n", "# Visualize selected actors' skeletons on RGB videos.", "\n", "\n", "", "raw_denoised_joints", ".", "append", "(", "joints", ")", "\n", "raw_denoised_colors", ".", "append", "(", "colors", ")", "\n", "frames_cnt", ".", "append", "(", "num_frames", ")", "\n", "\n", "if", "(", "idx", "+", "1", ")", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "'Processed: %.2f%% (%d / %d), '", "%", "(", "100.0", "*", "(", "idx", "+", "1", ")", "/", "num_skes", ",", "idx", "+", "1", ",", "num_skes", ")", "+", "'Missing count: %d'", "%", "missing_count", ")", "\n", "\n", "", "", "raw_skes_joints_pkl", "=", "osp", ".", "join", "(", "save_path", ",", "'raw_denoised_joints.pkl'", ")", "\n", "with", "open", "(", "raw_skes_joints_pkl", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "raw_denoised_joints", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "raw_skes_colors_pkl", "=", "osp", ".", "join", "(", "save_path", ",", "'raw_denoised_colors.pkl'", ")", "\n", "with", "open", "(", "raw_skes_colors_pkl", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "raw_denoised_colors", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "frames_cnt", "=", "np", ".", "array", "(", "frames_cnt", ",", "dtype", "=", "np", ".", "int", ")", "\n", "np", ".", "savetxt", "(", "osp", ".", "join", "(", "save_path", ",", "'frames_cnt.txt'", ")", ",", "frames_cnt", ",", "fmt", "=", "'%d'", ")", "\n", "\n", "print", "(", "'Saved raw denoised positions of {} frames into {}'", ".", "format", "(", "np", ".", "sum", "(", "frames_cnt", ")", ",", "\n", "raw_skes_joints_pkl", ")", ")", "\n", "print", "(", "'Found %d files that have missing data'", "%", "missing_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.seq_transformation.remove_nan_frames": [[31, 43], ["range", "numpy.any", "valid_frames.append", "nan_logger.info", "numpy.isnan", "numpy.where", "numpy.isnan"], "function", ["None"], ["", "def", "remove_nan_frames", "(", "ske_name", ",", "ske_joints", ",", "nan_logger", ")", ":", "\n", "    ", "num_frames", "=", "ske_joints", ".", "shape", "[", "0", "]", "\n", "valid_frames", "=", "[", "]", "\n", "\n", "for", "f", "in", "range", "(", "num_frames", ")", ":", "\n", "        ", "if", "not", "np", ".", "any", "(", "np", ".", "isnan", "(", "ske_joints", "[", "f", "]", ")", ")", ":", "\n", "            ", "valid_frames", ".", "append", "(", "f", ")", "\n", "", "else", ":", "\n", "            ", "nan_indices", "=", "np", ".", "where", "(", "np", ".", "isnan", "(", "ske_joints", "[", "f", "]", ")", ")", "[", "0", "]", "\n", "nan_logger", ".", "info", "(", "'{}\\t{:^5}\\t{}'", ".", "format", "(", "ske_name", ",", "f", "+", "1", ",", "nan_indices", ")", ")", "\n", "\n", "", "", "return", "ske_joints", "[", "valid_frames", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.seq_transformation.seq_translation": [[44, 77], ["enumerate", "numpy.copy", "range", "len", "len", "numpy.any", "numpy.zeros", "numpy.zeros", "numpy.where", "numpy.where", "numpy.tile", "numpy.tile", "ske_joints[].sum", "ske_joints[].sum"], "function", ["None"], ["", "def", "seq_translation", "(", "skes_joints", ")", ":", "\n", "    ", "for", "idx", ",", "ske_joints", "in", "enumerate", "(", "skes_joints", ")", ":", "\n", "        ", "num_frames", "=", "ske_joints", ".", "shape", "[", "0", "]", "\n", "num_bodies", "=", "1", "if", "ske_joints", ".", "shape", "[", "1", "]", "==", "75", "else", "2", "\n", "if", "num_bodies", "==", "2", ":", "\n", "            ", "missing_frames_1", "=", "np", ".", "where", "(", "ske_joints", "[", ":", ",", ":", "75", "]", ".", "sum", "(", "axis", "=", "1", ")", "==", "0", ")", "[", "0", "]", "\n", "missing_frames_2", "=", "np", ".", "where", "(", "ske_joints", "[", ":", ",", "75", ":", "]", ".", "sum", "(", "axis", "=", "1", ")", "==", "0", ")", "[", "0", "]", "\n", "cnt1", "=", "len", "(", "missing_frames_1", ")", "\n", "cnt2", "=", "len", "(", "missing_frames_2", ")", "\n", "\n", "", "i", "=", "0", "# get the \"real\" first frame of actor1", "\n", "while", "i", "<", "num_frames", ":", "\n", "            ", "if", "np", ".", "any", "(", "ske_joints", "[", "i", ",", ":", "75", "]", "!=", "0", ")", ":", "\n", "                ", "break", "\n", "", "i", "+=", "1", "\n", "\n", "", "origin", "=", "np", ".", "copy", "(", "ske_joints", "[", "i", ",", "3", ":", "6", "]", ")", "# new origin: joint-2", "\n", "\n", "for", "f", "in", "range", "(", "num_frames", ")", ":", "\n", "            ", "if", "num_bodies", "==", "1", ":", "\n", "                ", "ske_joints", "[", "f", "]", "-=", "np", ".", "tile", "(", "origin", ",", "25", ")", "\n", "", "else", ":", "# for 2 actors", "\n", "                ", "ske_joints", "[", "f", "]", "-=", "np", ".", "tile", "(", "origin", ",", "50", ")", "\n", "\n", "", "", "if", "(", "num_bodies", "==", "2", ")", "and", "(", "cnt1", ">", "0", ")", ":", "\n", "            ", "ske_joints", "[", "missing_frames_1", ",", ":", "75", "]", "=", "np", ".", "zeros", "(", "(", "cnt1", ",", "75", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "if", "(", "num_bodies", "==", "2", ")", "and", "(", "cnt2", ">", "0", ")", ":", "\n", "            ", "ske_joints", "[", "missing_frames_2", ",", "75", ":", "]", "=", "np", ".", "zeros", "(", "(", "cnt2", ",", "75", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "skes_joints", "[", "idx", "]", "=", "ske_joints", "# Update", "\n", "\n", "", "return", "skes_joints", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.seq_transformation.frame_translation": [[79, 107], ["logging.getLogger", "logging.getLogger.setLevel", "logging.getLogger.addHandler", "logging.getLogger.info", "enumerate", "logging.FileHandler", "numpy.sqrt", "range", "seq_transformation.remove_nan_frames", "numpy.tile", "numpy.tile", "numpy.tile", "numpy.tile"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.remove_nan_frames"], ["", "def", "frame_translation", "(", "skes_joints", ",", "skes_name", ",", "frames_cnt", ")", ":", "\n", "    ", "nan_logger", "=", "logging", ".", "getLogger", "(", "'nan_skes'", ")", "\n", "nan_logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "nan_logger", ".", "addHandler", "(", "logging", ".", "FileHandler", "(", "\"./nan_frames.log\"", ")", ")", "\n", "nan_logger", ".", "info", "(", "'{}\\t{}\\t{}'", ".", "format", "(", "'Skeleton'", ",", "'Frame'", ",", "'Joints'", ")", ")", "\n", "\n", "for", "idx", ",", "ske_joints", "in", "enumerate", "(", "skes_joints", ")", ":", "\n", "        ", "num_frames", "=", "ske_joints", ".", "shape", "[", "0", "]", "\n", "# Calculate the distance between spine base (joint-1) and spine (joint-21)", "\n", "j1", "=", "ske_joints", "[", ":", ",", "0", ":", "3", "]", "\n", "j21", "=", "ske_joints", "[", ":", ",", "60", ":", "63", "]", "\n", "dist", "=", "np", ".", "sqrt", "(", "(", "(", "j1", "-", "j21", ")", "**", "2", ")", ".", "sum", "(", "axis", "=", "1", ")", ")", "\n", "\n", "for", "f", "in", "range", "(", "num_frames", ")", ":", "\n", "            ", "origin", "=", "ske_joints", "[", "f", ",", "3", ":", "6", "]", "# new origin: middle of the spine (joint-2)", "\n", "if", "(", "ske_joints", "[", "f", ",", "75", ":", "]", "==", "0", ")", ".", "all", "(", ")", ":", "\n", "                ", "ske_joints", "[", "f", ",", ":", "75", "]", "=", "(", "ske_joints", "[", "f", ",", ":", "75", "]", "-", "np", ".", "tile", "(", "origin", ",", "25", ")", ")", "/", "dist", "[", "f", "]", "+", "np", ".", "tile", "(", "origin", ",", "25", ")", "\n", "", "else", ":", "\n", "                ", "ske_joints", "[", "f", "]", "=", "(", "ske_joints", "[", "f", "]", "-", "np", ".", "tile", "(", "origin", ",", "50", ")", ")", "/", "dist", "[", "f", "]", "+", "np", ".", "tile", "(", "origin", ",", "50", ")", "\n", "\n", "", "", "ske_name", "=", "skes_name", "[", "idx", "]", "\n", "ske_joints", "=", "remove_nan_frames", "(", "ske_name", ",", "ske_joints", ",", "nan_logger", ")", "\n", "frames_cnt", "[", "idx", "]", "=", "num_frames", "# update valid number of frames", "\n", "skes_joints", "[", "idx", "]", "=", "ske_joints", "\n", "\n", "", "return", "skes_joints", ",", "frames_cnt", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.seq_transformation.align_frames": [[109, 128], ["len", "frames_cnt.max", "numpy.zeros", "enumerate", "numpy.hstack"], "function", ["None"], ["", "def", "align_frames", "(", "skes_joints", ",", "frames_cnt", ")", ":", "\n", "    ", "\"\"\"\n    Align all sequences with the same frame length.\n\n    \"\"\"", "\n", "num_skes", "=", "len", "(", "skes_joints", ")", "\n", "max_num_frames", "=", "frames_cnt", ".", "max", "(", ")", "# 300", "\n", "aligned_skes_joints", "=", "np", ".", "zeros", "(", "(", "num_skes", ",", "max_num_frames", ",", "150", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "idx", ",", "ske_joints", "in", "enumerate", "(", "skes_joints", ")", ":", "\n", "        ", "num_frames", "=", "ske_joints", ".", "shape", "[", "0", "]", "\n", "num_bodies", "=", "1", "if", "ske_joints", ".", "shape", "[", "1", "]", "==", "75", "else", "2", "\n", "if", "num_bodies", "==", "1", ":", "\n", "            ", "aligned_skes_joints", "[", "idx", ",", ":", "num_frames", "]", "=", "np", ".", "hstack", "(", "(", "ske_joints", ",", "ske_joints", ")", ")", "\n", "# aligned_skes_joints[idx, :num_frames] = np.hstack((ske_joints, np.zeros_like(ske_joints)))", "\n", "", "else", ":", "\n", "            ", "aligned_skes_joints", "[", "idx", ",", ":", "num_frames", "]", "=", "ske_joints", "\n", "\n", "", "", "return", "aligned_skes_joints", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.seq_transformation.one_hot_vector": [[130, 137], ["len", "numpy.zeros", "enumerate"], "function", ["None"], ["", "def", "one_hot_vector", "(", "labels", ")", ":", "\n", "    ", "num_skes", "=", "len", "(", "labels", ")", "\n", "labels_vector", "=", "np", ".", "zeros", "(", "(", "num_skes", ",", "120", ")", ")", "\n", "for", "idx", ",", "l", "in", "enumerate", "(", "labels", ")", ":", "\n", "        ", "labels_vector", "[", "idx", ",", "l", "]", "=", "1", "\n", "\n", "", "return", "labels_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.seq_transformation.split_train_val": [[139, 154], ["sklearn.model_selection.train_test_split", "numpy.random.seed", "numpy.random.shuffle", "int", "numpy.ceil", "len"], "function", ["None"], ["", "def", "split_train_val", "(", "train_indices", ",", "method", "=", "'sklearn'", ",", "ratio", "=", "0.05", ")", ":", "\n", "    ", "\"\"\"\n    Get validation set by splitting data randomly from training set with two methods.\n    In fact, I thought these two methods are equal as they got the same performance.\n\n    \"\"\"", "\n", "if", "method", "==", "'sklearn'", ":", "\n", "        ", "return", "train_test_split", "(", "train_indices", ",", "test_size", "=", "ratio", ",", "random_state", "=", "10000", ")", "\n", "", "else", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "10000", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "train_indices", ")", "\n", "val_num_skes", "=", "int", "(", "np", ".", "ceil", "(", "0.05", "*", "len", "(", "train_indices", ")", ")", ")", "\n", "val_indices", "=", "train_indices", "[", ":", "val_num_skes", "]", "\n", "train_indices", "=", "train_indices", "[", "val_num_skes", ":", "]", "\n", "return", "train_indices", ",", "val_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.seq_transformation.split_dataset": [[156, 173], ["seq_transformation.get_indices", "seq_transformation.one_hot_vector", "seq_transformation.one_hot_vector", "numpy.savez"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.get_indices", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.one_hot_vector", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.one_hot_vector"], ["", "", "def", "split_dataset", "(", "skes_joints", ",", "label", ",", "performer", ",", "setup", ",", "evaluation", ",", "save_path", ")", ":", "\n", "    ", "train_indices", ",", "test_indices", "=", "get_indices", "(", "performer", ",", "setup", ",", "evaluation", ")", "\n", "# m = 'sklearn'  # 'sklearn' or 'numpy'", "\n", "# Select validation set from training set", "\n", "# train_indices, val_indices = split_train_val(train_indices, m)", "\n", "\n", "# Save labels and num_frames for each sequence of each data set", "\n", "train_labels", "=", "label", "[", "train_indices", "]", "\n", "test_labels", "=", "label", "[", "test_indices", "]", "\n", "\n", "train_x", "=", "skes_joints", "[", "train_indices", "]", "\n", "train_y", "=", "one_hot_vector", "(", "train_labels", ")", "\n", "test_x", "=", "skes_joints", "[", "test_indices", "]", "\n", "test_y", "=", "one_hot_vector", "(", "test_labels", ")", "\n", "\n", "save_name", "=", "'NTU120_%s.npz'", "%", "evaluation", "\n", "np", ".", "savez", "(", "save_name", ",", "x_train", "=", "train_x", ",", "y_train", "=", "train_y", ",", "x_test", "=", "test_x", ",", "y_test", "=", "test_y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu120.seq_transformation.get_indices": [[192, 227], ["numpy.empty", "numpy.empty", "numpy.hstack().astype", "numpy.hstack().astype", "numpy.hstack().astype", "numpy.hstack().astype", "range", "numpy.where", "numpy.where", "range", "range", "numpy.where", "numpy.where", "numpy.hstack", "numpy.hstack", "numpy.hstack", "numpy.hstack"], "function", ["None"], ["", "def", "get_indices", "(", "performer", ",", "setup", ",", "evaluation", "=", "'XSub'", ")", ":", "\n", "    ", "test_indices", "=", "np", ".", "empty", "(", "0", ")", "\n", "train_indices", "=", "np", ".", "empty", "(", "0", ")", "\n", "\n", "if", "evaluation", "==", "'XSub'", ":", "# Cross Subject (Subject IDs)", "\n", "        ", "train_ids", "=", "[", "1", ",", "2", ",", "4", ",", "5", ",", "8", ",", "9", ",", "13", ",", "14", ",", "15", ",", "16", ",", "17", ",", "18", ",", "19", ",", "25", ",", "27", ",", "28", ",", "\n", "31", ",", "34", ",", "35", ",", "38", ",", "45", ",", "46", ",", "47", ",", "49", ",", "50", ",", "52", ",", "53", ",", "54", ",", "55", ",", "56", ",", "57", ",", "\n", "58", ",", "59", ",", "70", ",", "74", ",", "78", ",", "80", ",", "81", ",", "82", ",", "83", ",", "84", ",", "85", ",", "86", ",", "89", ",", "91", ",", "92", ",", "\n", "93", ",", "94", ",", "95", ",", "97", ",", "98", ",", "100", ",", "103", "]", "\n", "test_ids", "=", "[", "i", "for", "i", "in", "range", "(", "1", ",", "107", ")", "if", "i", "not", "in", "train_ids", "]", "\n", "\n", "# Get indices of test data", "\n", "for", "idx", "in", "test_ids", ":", "\n", "            ", "temp", "=", "np", ".", "where", "(", "performer", "==", "idx", ")", "[", "0", "]", "# 0-based index", "\n", "test_indices", "=", "np", ".", "hstack", "(", "(", "test_indices", ",", "temp", ")", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "# Get indices of training data", "\n", "", "for", "train_id", "in", "train_ids", ":", "\n", "            ", "temp", "=", "np", ".", "where", "(", "performer", "==", "train_id", ")", "[", "0", "]", "# 0-based index", "\n", "train_indices", "=", "np", ".", "hstack", "(", "(", "train_indices", ",", "temp", ")", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "", "", "else", ":", "# Cross Setup (Setup IDs)", "\n", "        ", "train_ids", "=", "[", "i", "for", "i", "in", "range", "(", "1", ",", "33", ")", "if", "i", "%", "2", "==", "0", "]", "# Even setup", "\n", "test_ids", "=", "[", "i", "for", "i", "in", "range", "(", "1", ",", "33", ")", "if", "i", "%", "2", "==", "1", "]", "# Odd setup", "\n", "\n", "# Get indices of test data", "\n", "for", "test_id", "in", "test_ids", ":", "\n", "            ", "temp", "=", "np", ".", "where", "(", "setup", "==", "test_id", ")", "[", "0", "]", "# 0-based index", "\n", "test_indices", "=", "np", ".", "hstack", "(", "(", "test_indices", ",", "temp", ")", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "# Get indices of training data", "\n", "", "for", "train_id", "in", "train_ids", ":", "\n", "            ", "temp", "=", "np", ".", "where", "(", "setup", "==", "train_id", ")", "[", "0", "]", "# 0-based index", "\n", "train_indices", "=", "np", ".", "hstack", "(", "(", "train_indices", ",", "temp", ")", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "", "", "return", "train_indices", ",", "test_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_skes_data.get_raw_bodies_data": [[10, 92], ["os.join", "os.exists", "print", "int", "dict", "range", "len", "open", "fr.readlines", "str_data[].strip", "int", "numpy.zeros", "numpy.zeros", "range", "numpy.array", "frames_drop_logger.info", "len", "dict.values", "str_data[].strip", "frames_drop.append", "int", "range", "numpy.sum", "str_data[].strip().split", "str_data[].strip", "str_data[].strip().split", "numpy.array", "numpy.array", "dict", "numpy.vstack", "numpy.vstack", "body_data[].append", "numpy.var", "str_data[].strip", "str_data[].strip"], "function", ["None"], ["def", "get_raw_bodies_data", "(", "skes_path", ",", "ske_name", ",", "frames_drop_skes", ",", "frames_drop_logger", ")", ":", "\n", "    ", "\"\"\"\n    Get raw bodies data from a skeleton sequence.\n\n    Each body's data is a dict that contains the following keys:\n      - joints: raw 3D joints positions. Shape: (num_frames x 25, 3)\n      - colors: raw 2D color locations. Shape: (num_frames, 25, 2)\n      - interval: a list which stores the frame indices of this body.\n      - motion: motion amount (only for the sequence with 2 or more bodyIDs).\n\n    Return:\n      a dict for a skeleton sequence with 3 key-value pairs:\n        - name: the skeleton filename.\n        - data: a dict which stores raw data of each body.\n        - num_frames: the number of valid frames.\n    \"\"\"", "\n", "if", "int", "(", "ske_name", "[", "1", ":", "4", "]", ")", ">=", "18", ":", "\n", "        ", "skes_path", "=", "'../nturgbd_raw/nturgb+d_skeletons120/'", "\n", "", "ske_file", "=", "osp", ".", "join", "(", "skes_path", ",", "ske_name", "+", "'.skeleton'", ")", "\n", "assert", "osp", ".", "exists", "(", "ske_file", ")", ",", "'Error: Skeleton file %s not found'", "%", "ske_file", "\n", "# Read all data from .skeleton file into a list (in string format)", "\n", "print", "(", "'Reading data from %s'", "%", "ske_file", "[", "-", "29", ":", "]", ")", "\n", "with", "open", "(", "ske_file", ",", "'r'", ")", "as", "fr", ":", "\n", "        ", "str_data", "=", "fr", ".", "readlines", "(", ")", "\n", "\n", "", "num_frames", "=", "int", "(", "str_data", "[", "0", "]", ".", "strip", "(", "'\\r\\n'", ")", ")", "\n", "frames_drop", "=", "[", "]", "\n", "bodies_data", "=", "dict", "(", ")", "\n", "valid_frames", "=", "-", "1", "# 0-based index", "\n", "current_line", "=", "1", "\n", "\n", "for", "f", "in", "range", "(", "num_frames", ")", ":", "\n", "        ", "num_bodies", "=", "int", "(", "str_data", "[", "current_line", "]", ".", "strip", "(", "'\\r\\n'", ")", ")", "\n", "current_line", "+=", "1", "\n", "\n", "if", "num_bodies", "==", "0", ":", "# no data in this frame, drop it", "\n", "            ", "frames_drop", ".", "append", "(", "f", ")", "# 0-based index", "\n", "continue", "\n", "\n", "", "valid_frames", "+=", "1", "\n", "joints", "=", "np", ".", "zeros", "(", "(", "num_bodies", ",", "25", ",", "3", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "colors", "=", "np", ".", "zeros", "(", "(", "num_bodies", ",", "25", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "b", "in", "range", "(", "num_bodies", ")", ":", "\n", "            ", "bodyID", "=", "str_data", "[", "current_line", "]", ".", "strip", "(", "'\\r\\n'", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "current_line", "+=", "1", "\n", "num_joints", "=", "int", "(", "str_data", "[", "current_line", "]", ".", "strip", "(", "'\\r\\n'", ")", ")", "# 25 joints", "\n", "current_line", "+=", "1", "\n", "\n", "for", "j", "in", "range", "(", "num_joints", ")", ":", "\n", "                ", "temp_str", "=", "str_data", "[", "current_line", "]", ".", "strip", "(", "'\\r\\n'", ")", ".", "split", "(", ")", "\n", "joints", "[", "b", ",", "j", ",", ":", "]", "=", "np", ".", "array", "(", "temp_str", "[", ":", "3", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "colors", "[", "b", ",", "j", ",", ":", "]", "=", "np", ".", "array", "(", "temp_str", "[", "5", ":", "7", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "current_line", "+=", "1", "\n", "\n", "", "if", "bodyID", "not", "in", "bodies_data", ":", "# Add a new body's data", "\n", "                ", "body_data", "=", "dict", "(", ")", "\n", "body_data", "[", "'joints'", "]", "=", "joints", "[", "b", "]", "# ndarray: (25, 3)", "\n", "body_data", "[", "'colors'", "]", "=", "colors", "[", "b", ",", "np", ".", "newaxis", "]", "# ndarray: (1, 25, 2)", "\n", "body_data", "[", "'interval'", "]", "=", "[", "valid_frames", "]", "# the index of the first frame", "\n", "", "else", ":", "# Update an already existed body's data", "\n", "                ", "body_data", "=", "bodies_data", "[", "bodyID", "]", "\n", "# Stack each body's data of each frame along the frame order", "\n", "body_data", "[", "'joints'", "]", "=", "np", ".", "vstack", "(", "(", "body_data", "[", "'joints'", "]", ",", "joints", "[", "b", "]", ")", ")", "\n", "body_data", "[", "'colors'", "]", "=", "np", ".", "vstack", "(", "(", "body_data", "[", "'colors'", "]", ",", "colors", "[", "b", ",", "np", ".", "newaxis", "]", ")", ")", "\n", "pre_frame_idx", "=", "body_data", "[", "'interval'", "]", "[", "-", "1", "]", "\n", "body_data", "[", "'interval'", "]", ".", "append", "(", "pre_frame_idx", "+", "1", ")", "# add a new frame index", "\n", "\n", "", "bodies_data", "[", "bodyID", "]", "=", "body_data", "# Update bodies_data", "\n", "\n", "", "", "num_frames_drop", "=", "len", "(", "frames_drop", ")", "\n", "assert", "num_frames_drop", "<", "num_frames", ",", "'Error: All frames data (%d) of %s is missing or lost'", "%", "(", "num_frames", ",", "ske_name", ")", "\n", "if", "num_frames_drop", ">", "0", ":", "\n", "        ", "frames_drop_skes", "[", "ske_name", "]", "=", "np", ".", "array", "(", "frames_drop", ",", "dtype", "=", "np", ".", "int", ")", "\n", "frames_drop_logger", ".", "info", "(", "'{}: {} frames missed: {}\\n'", ".", "format", "(", "ske_name", ",", "num_frames_drop", ",", "\n", "frames_drop", ")", ")", "\n", "\n", "# Calculate motion (only for the sequence with 2 or more bodyIDs)", "\n", "", "if", "len", "(", "bodies_data", ")", ">", "1", ":", "\n", "        ", "for", "body_data", "in", "bodies_data", ".", "values", "(", ")", ":", "\n", "            ", "body_data", "[", "'motion'", "]", "=", "np", ".", "sum", "(", "np", ".", "var", "(", "body_data", "[", "'joints'", "]", ",", "axis", "=", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_skes_data.get_raw_skes_data": [[94, 133], ["numpy.loadtxt", "print", "numpy.zeros", "enumerate", "numpy.savetxt", "print", "print", "get_raw_skes_data.get_raw_bodies_data", "raw_skes_data.append", "open", "pickle.dump", "os.join", "open", "pickle.dump", "print", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_skes_data.get_raw_bodies_data"], ["\n", "\n", "", "def", "get_raw_skes_data", "(", ")", ":", "\n", "# # save_path = './data'", "\n", "# # skes_path = '/data/pengfei/NTU/nturgb+d_skeletons/'", "\n", "# stat_path = osp.join(save_path, 'statistics')", "\n", "#", "\n", "# skes_name_file = osp.join(stat_path, 'skes_available_name.txt')", "\n", "# save_data_pkl = osp.join(save_path, 'raw_skes_data.pkl')", "\n", "# frames_drop_pkl = osp.join(save_path, 'frames_drop_skes.pkl')", "\n", "#", "\n", "# frames_drop_logger = logging.getLogger('frames_drop')", "\n", "# frames_drop_logger.setLevel(logging.INFO)", "\n", "# frames_drop_logger.addHandler(logging.FileHandler(osp.join(save_path, 'frames_drop.log')))", "\n", "# frames_drop_skes = dict()", "\n", "\n", "    ", "skes_name", "=", "np", ".", "loadtxt", "(", "skes_name_file", ",", "dtype", "=", "str", ")", "\n", "\n", "num_files", "=", "skes_name", ".", "size", "\n", "print", "(", "'Found %d available skeleton files.'", "%", "num_files", ")", "\n", "\n", "raw_skes_data", "=", "[", "]", "\n", "frames_cnt", "=", "np", ".", "zeros", "(", "num_files", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "for", "(", "idx", ",", "ske_name", ")", "in", "enumerate", "(", "skes_name", ")", ":", "\n", "        ", "bodies_data", "=", "get_raw_bodies_data", "(", "skes_path", ",", "ske_name", ",", "frames_drop_skes", ",", "frames_drop_logger", ")", "\n", "raw_skes_data", ".", "append", "(", "bodies_data", ")", "\n", "frames_cnt", "[", "idx", "]", "=", "bodies_data", "[", "'num_frames'", "]", "\n", "if", "(", "idx", "+", "1", ")", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "'Processed: %.2f%% (%d / %d)'", "%", "(", "100.0", "*", "(", "idx", "+", "1", ")", "/", "num_files", ",", "idx", "+", "1", ",", "num_files", ")", ")", "\n", "\n", "", "", "with", "open", "(", "save_data_pkl", ",", "'wb'", ")", "as", "fw", ":", "\n", "        ", "pickle", ".", "dump", "(", "raw_skes_data", ",", "fw", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "", "np", ".", "savetxt", "(", "osp", ".", "join", "(", "save_path", ",", "'raw_data'", ",", "'frames_cnt.txt'", ")", ",", "frames_cnt", ",", "fmt", "=", "'%d'", ")", "\n", "\n", "print", "(", "'Saved raw bodies data into %s'", "%", "save_data_pkl", ")", "\n", "print", "(", "'Total frames: %d'", "%", "np", ".", "sum", "(", "frames_cnt", ")", ")", "\n", "\n", "with", "open", "(", "frames_drop_pkl", ",", "'wb'", ")", "as", "fw", ":", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.denoising_by_length": [[71, 90], ["str", "bodies_data.copy", "bodies_data.copy.items", "len", "noise_len_logger.info"], "function", ["None"], ["def", "denoising_by_length", "(", "ske_name", ",", "bodies_data", ")", ":", "\n", "    ", "\"\"\"\n    Denoising data based on the frame length for each bodyID.\n    Filter out the bodyID which length is less or equal than the predefined threshold.\n\n    \"\"\"", "\n", "noise_info", "=", "str", "(", ")", "\n", "new_bodies_data", "=", "bodies_data", ".", "copy", "(", ")", "\n", "for", "(", "bodyID", ",", "body_data", ")", "in", "new_bodies_data", ".", "items", "(", ")", ":", "\n", "        ", "length", "=", "len", "(", "body_data", "[", "'interval'", "]", ")", "\n", "if", "length", "<=", "noise_len_thres", ":", "\n", "            ", "noise_info", "+=", "'Filter out: %s, %d (length).\\n'", "%", "(", "bodyID", ",", "length", ")", "\n", "noise_len_logger", ".", "info", "(", "'{}\\t{}\\t{:.6f}\\t{:^6d}'", ".", "format", "(", "ske_name", ",", "bodyID", ",", "\n", "body_data", "[", "'motion'", "]", ",", "length", ")", ")", "\n", "del", "bodies_data", "[", "bodyID", "]", "\n", "", "", "if", "noise_info", "!=", "''", ":", "\n", "        ", "noise_info", "+=", "'\\n'", "\n", "\n", "", "return", "bodies_data", ",", "noise_info", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_valid_frames_by_spread": [[92, 106], ["range", "valid_frames.append", "x.max", "x.min", "y.max", "y.min"], "function", ["None"], ["", "def", "get_valid_frames_by_spread", "(", "points", ")", ":", "\n", "    ", "\"\"\"\n    Find the valid (or reasonable) frames (index) based on the spread of X and Y.\n\n    points: joints or colors\n    \"\"\"", "\n", "num_frames", "=", "points", ".", "shape", "[", "0", "]", "\n", "valid_frames", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_frames", ")", ":", "\n", "        ", "x", "=", "points", "[", "i", ",", ":", ",", "0", "]", "\n", "y", "=", "points", "[", "i", ",", ":", ",", "1", "]", "\n", "if", "(", "x", ".", "max", "(", ")", "-", "x", ".", "min", "(", ")", ")", "<=", "noise_spr_thres1", "*", "(", "y", ".", "max", "(", ")", "-", "y", ".", "min", "(", ")", ")", ":", "# 0.8", "\n", "            ", "valid_frames", ".", "append", "(", "i", ")", "\n", "", "", "return", "valid_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.denoising_by_spread": [[108, 147], ["str", "bodies_data.copy", "bodies_data.copy.items", "get_raw_denoised_data.get_valid_frames_by_spread", "len", "len", "body_data[].reshape", "len", "float", "noise_spr_logger.info", "min", "body_data[].reshape", "numpy.sum", "numpy.var", "joints.reshape"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_valid_frames_by_spread"], ["", "def", "denoising_by_spread", "(", "ske_name", ",", "bodies_data", ")", ":", "\n", "    ", "\"\"\"\n    Denoising data based on the spread of Y value and X value.\n    Filter out the bodyID which the ratio of noisy frames is higher than the predefined\n    threshold.\n\n    bodies_data: contains at least 2 bodyIDs\n    \"\"\"", "\n", "noise_info", "=", "str", "(", ")", "\n", "denoised_by_spr", "=", "False", "# mark if this sequence has been processed by spread.", "\n", "\n", "new_bodies_data", "=", "bodies_data", ".", "copy", "(", ")", "\n", "# for (bodyID, body_data) in bodies_data.items():", "\n", "for", "(", "bodyID", ",", "body_data", ")", "in", "new_bodies_data", ".", "items", "(", ")", ":", "\n", "        ", "if", "len", "(", "bodies_data", ")", "==", "1", ":", "\n", "            ", "break", "\n", "", "valid_frames", "=", "get_valid_frames_by_spread", "(", "body_data", "[", "'joints'", "]", ".", "reshape", "(", "-", "1", ",", "25", ",", "3", ")", ")", "\n", "num_frames", "=", "len", "(", "body_data", "[", "'interval'", "]", ")", "\n", "num_noise", "=", "num_frames", "-", "len", "(", "valid_frames", ")", "\n", "if", "num_noise", "==", "0", ":", "\n", "            ", "continue", "\n", "\n", "", "ratio", "=", "num_noise", "/", "float", "(", "num_frames", ")", "\n", "motion", "=", "body_data", "[", "'motion'", "]", "\n", "if", "ratio", ">=", "noise_spr_thres2", ":", "# 0.69754", "\n", "            ", "del", "bodies_data", "[", "bodyID", "]", "\n", "denoised_by_spr", "=", "True", "\n", "noise_info", "+=", "'Filter out: %s (spread rate >= %.2f).\\n'", "%", "(", "bodyID", ",", "noise_spr_thres2", ")", "\n", "noise_spr_logger", ".", "info", "(", "'%s\\t%s\\t%.6f\\t%.6f'", "%", "(", "ske_name", ",", "bodyID", ",", "motion", ",", "ratio", ")", ")", "\n", "", "else", ":", "# Update motion", "\n", "            ", "joints", "=", "body_data", "[", "'joints'", "]", ".", "reshape", "(", "-", "1", ",", "25", ",", "3", ")", "[", "valid_frames", "]", "\n", "body_data", "[", "'motion'", "]", "=", "min", "(", "motion", ",", "np", ".", "sum", "(", "np", ".", "var", "(", "joints", ".", "reshape", "(", "-", "1", ",", "3", ")", ",", "axis", "=", "0", ")", ")", ")", "\n", "noise_info", "+=", "'%s: motion %.6f -> %.6f\\n'", "%", "(", "bodyID", ",", "motion", ",", "body_data", "[", "'motion'", "]", ")", "\n", "# TODO: Consider removing noisy frames for each bodyID", "\n", "\n", "", "", "if", "noise_info", "!=", "''", ":", "\n", "        ", "noise_info", "+=", "'\\n'", "\n", "\n", "", "return", "bodies_data", ",", "noise_info", ",", "denoised_by_spr", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.denoising_by_motion": [[149, 172], ["sorted", "str", "sorted.items", "noise_mot_logger.info", "denoised_bodies_data.append"], "function", ["None"], ["", "def", "denoising_by_motion", "(", "ske_name", ",", "bodies_data", ",", "bodies_motion", ")", ":", "\n", "    ", "\"\"\"\n    Filter out the bodyID which motion is out of the range of predefined interval\n\n    \"\"\"", "\n", "# Sort bodies based on the motion, return a list of tuples", "\n", "# bodies_motion = sorted(bodies_motion.items(), key=lambda x, y: cmp(x[1], y[1]), reverse=True)", "\n", "bodies_motion", "=", "sorted", "(", "bodies_motion", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "# Reserve the body data with the largest motion", "\n", "denoised_bodies_data", "=", "[", "(", "bodies_motion", "[", "0", "]", "[", "0", "]", ",", "bodies_data", "[", "bodies_motion", "[", "0", "]", "[", "0", "]", "]", ")", "]", "\n", "noise_info", "=", "str", "(", ")", "\n", "\n", "for", "(", "bodyID", ",", "motion", ")", "in", "bodies_motion", "[", "1", ":", "]", ":", "\n", "        ", "if", "(", "motion", "<", "noise_mot_thres_lo", ")", "or", "(", "motion", ">", "noise_mot_thres_hi", ")", ":", "\n", "            ", "noise_info", "+=", "'Filter out: %s, %.6f (motion).\\n'", "%", "(", "bodyID", ",", "motion", ")", "\n", "noise_mot_logger", ".", "info", "(", "'{}\\t{}\\t{:.6f}'", ".", "format", "(", "ske_name", ",", "bodyID", ",", "motion", ")", ")", "\n", "", "else", ":", "\n", "            ", "denoised_bodies_data", ".", "append", "(", "(", "bodyID", ",", "bodies_data", "[", "bodyID", "]", ")", ")", "\n", "", "", "if", "noise_info", "!=", "''", ":", "\n", "        ", "noise_info", "+=", "'\\n'", "\n", "\n", "", "return", "denoised_bodies_data", ",", "noise_info", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.denoising_bodies_data": [[174, 207], ["get_raw_denoised_data.denoising_by_length", "get_raw_denoised_data.denoising_by_spread", "dict", "bodies_data.items", "sorted", "list", "len", "len", "sorted.items", "list.append", "bodies_data.items", "bodies_data.items"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.denoising_by_length", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.denoising_by_spread"], ["", "def", "denoising_bodies_data", "(", "bodies_data", ")", ":", "\n", "    ", "\"\"\"\n    Denoising data based on some heuristic methods, not necessarily correct for all samples.\n\n    Return:\n      denoised_bodies_data (list): tuple: (bodyID, body_data).\n    \"\"\"", "\n", "ske_name", "=", "bodies_data", "[", "'name'", "]", "\n", "bodies_data", "=", "bodies_data", "[", "'data'", "]", "\n", "\n", "# Step 1: Denoising based on frame length.", "\n", "bodies_data", ",", "noise_info_len", "=", "denoising_by_length", "(", "ske_name", ",", "bodies_data", ")", "\n", "\n", "if", "len", "(", "bodies_data", ")", "==", "1", ":", "# only has one bodyID left after step 1", "\n", "        ", "return", "bodies_data", ".", "items", "(", ")", ",", "noise_info_len", "\n", "\n", "# Step 2: Denoising based on spread.", "\n", "", "bodies_data", ",", "noise_info_spr", ",", "denoised_by_spr", "=", "denoising_by_spread", "(", "ske_name", ",", "bodies_data", ")", "\n", "\n", "if", "len", "(", "bodies_data", ")", "==", "1", ":", "\n", "        ", "return", "bodies_data", ".", "items", "(", ")", ",", "noise_info_len", "+", "noise_info_spr", "\n", "\n", "", "bodies_motion", "=", "dict", "(", ")", "# get body motion", "\n", "for", "(", "bodyID", ",", "body_data", ")", "in", "bodies_data", ".", "items", "(", ")", ":", "\n", "        ", "bodies_motion", "[", "bodyID", "]", "=", "body_data", "[", "'motion'", "]", "\n", "# Sort bodies based on the motion", "\n", "# bodies_motion = sorted(bodies_motion.items(), key=lambda x, y: cmp(x[1], y[1]), reverse=True)", "\n", "", "bodies_motion", "=", "sorted", "(", "bodies_motion", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "denoised_bodies_data", "=", "list", "(", ")", "\n", "for", "(", "bodyID", ",", "_", ")", "in", "bodies_motion", ":", "\n", "        ", "denoised_bodies_data", ".", "append", "(", "(", "bodyID", ",", "bodies_data", "[", "bodyID", "]", ")", ")", "\n", "\n", "", "return", "denoised_bodies_data", ",", "noise_info_len", "+", "noise_info_spr", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_one_actor_points": [[223, 236], ["numpy.zeros", "body_data[].reshape", "numpy.ones"], "function", ["None"], ["", "def", "get_one_actor_points", "(", "body_data", ",", "num_frames", ")", ":", "\n", "    ", "\"\"\"\n    Get joints and colors for only one actor.\n    For joints, each frame contains 75 X-Y-Z coordinates.\n    For colors, each frame contains 25 x 2 (X, Y) coordinates.\n    \"\"\"", "\n", "joints", "=", "np", ".", "zeros", "(", "(", "num_frames", ",", "75", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "colors", "=", "np", ".", "ones", "(", "(", "num_frames", ",", "1", ",", "25", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "*", "np", ".", "nan", "\n", "start", ",", "end", "=", "body_data", "[", "'interval'", "]", "[", "0", "]", ",", "body_data", "[", "'interval'", "]", "[", "-", "1", "]", "\n", "joints", "[", "start", ":", "end", "+", "1", "]", "=", "body_data", "[", "'joints'", "]", ".", "reshape", "(", "-", "1", ",", "75", ")", "\n", "colors", "[", "start", ":", "end", "+", "1", ",", "0", "]", "=", "body_data", "[", "'colors'", "]", "\n", "\n", "return", "joints", ",", "colors", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.remove_missing_frames": [[238, 279], ["len", "len", "len", "numpy.where", "numpy.where", "missing_skes_logger.info", "numpy.where", "numpy.where", "max", "missing_skes_logger1.info", "missing_skes_logger2.info", "joints.sum", "joints.sum", "joints[].sum", "joints[].sum"], "function", ["None"], ["", "def", "remove_missing_frames", "(", "ske_name", ",", "joints", ",", "colors", ")", ":", "\n", "    ", "\"\"\"\n    Cut off missing frames which all joints positions are 0s\n\n    For the sequence with 2 actors' data, also record the number of missing frames for\n    actor1 and actor2, respectively (for debug).\n    \"\"\"", "\n", "num_frames", "=", "joints", ".", "shape", "[", "0", "]", "\n", "num_bodies", "=", "colors", ".", "shape", "[", "1", "]", "# 1 or 2", "\n", "\n", "if", "num_bodies", "==", "2", ":", "# DEBUG", "\n", "        ", "missing_indices_1", "=", "np", ".", "where", "(", "joints", "[", ":", ",", ":", "75", "]", ".", "sum", "(", "axis", "=", "1", ")", "==", "0", ")", "[", "0", "]", "\n", "missing_indices_2", "=", "np", ".", "where", "(", "joints", "[", ":", ",", "75", ":", "]", ".", "sum", "(", "axis", "=", "1", ")", "==", "0", ")", "[", "0", "]", "\n", "cnt1", "=", "len", "(", "missing_indices_1", ")", "\n", "cnt2", "=", "len", "(", "missing_indices_2", ")", "\n", "\n", "start", "=", "1", "if", "0", "in", "missing_indices_1", "else", "0", "\n", "end", "=", "1", "if", "num_frames", "-", "1", "in", "missing_indices_1", "else", "0", "\n", "if", "max", "(", "cnt1", ",", "cnt2", ")", ">", "0", ":", "\n", "            ", "if", "cnt1", ">", "cnt2", ":", "\n", "                ", "info", "=", "'{}\\t{:^10d}\\t{:^6d}\\t{:^6d}\\t{:^5d}\\t{:^3d}'", ".", "format", "(", "ske_name", ",", "num_frames", ",", "\n", "cnt1", ",", "cnt2", ",", "start", ",", "end", ")", "\n", "missing_skes_logger1", ".", "info", "(", "info", ")", "\n", "", "else", ":", "\n", "                ", "info", "=", "'{}\\t{:^10d}\\t{:^6d}\\t{:^6d}'", ".", "format", "(", "ske_name", ",", "num_frames", ",", "cnt1", ",", "cnt2", ")", "\n", "missing_skes_logger2", ".", "info", "(", "info", ")", "\n", "\n", "# Find valid frame indices that the data is not missing or lost", "\n", "# For two-subjects action, this means both data of actor1 and actor2 is missing.", "\n", "", "", "", "valid_indices", "=", "np", ".", "where", "(", "joints", ".", "sum", "(", "axis", "=", "1", ")", "!=", "0", ")", "[", "0", "]", "# 0-based index", "\n", "missing_indices", "=", "np", ".", "where", "(", "joints", ".", "sum", "(", "axis", "=", "1", ")", "==", "0", ")", "[", "0", "]", "\n", "num_missing", "=", "len", "(", "missing_indices", ")", "\n", "\n", "if", "num_missing", ">", "0", ":", "# Update joints and colors", "\n", "        ", "joints", "=", "joints", "[", "valid_indices", "]", "\n", "colors", "[", "missing_indices", "]", "=", "np", ".", "nan", "\n", "global", "missing_count", "\n", "missing_count", "+=", "1", "\n", "missing_skes_logger", ".", "info", "(", "'{}\\t{:^10d}\\t{:^11d}'", ".", "format", "(", "ske_name", ",", "num_frames", ",", "num_missing", ")", ")", "\n", "\n", "", "return", "joints", ",", "colors", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_bodies_info": [[281, 288], ["bodies_data.items", "str"], "function", ["None"], ["", "def", "get_bodies_info", "(", "bodies_data", ")", ":", "\n", "    ", "bodies_info", "=", "'{:^17}\\t{}\\t{:^8}\\n'", ".", "format", "(", "'bodyID'", ",", "'Interval'", ",", "'Motion'", ")", "\n", "for", "(", "bodyID", ",", "body_data", ")", "in", "bodies_data", ".", "items", "(", ")", ":", "\n", "        ", "start", ",", "end", "=", "body_data", "[", "'interval'", "]", "[", "0", "]", ",", "body_data", "[", "'interval'", "]", "[", "-", "1", "]", "\n", "bodies_info", "+=", "'{}\\t{:^8}\\t{:f}\\n'", ".", "format", "(", "bodyID", ",", "str", "(", "[", "start", ",", "end", "]", ")", ",", "body_data", "[", "'motion'", "]", ")", "\n", "\n", "", "return", "bodies_info", "+", "'\\n'", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_two_actors_points": [[290, 365], ["int", "get_raw_denoised_data.get_bodies_info", "get_raw_denoised_data.denoising_bodies_data", "list", "len", "get_raw_denoised_data.get_one_actor_points", "numpy.zeros", "actor1[].reshape", "open", "fw.write", "fail_logger_2.info", "fail_logger_1.info", "numpy.ones", "len", "os.join", "str", "actor[].reshape", "min", "max", "min", "max", "str", "actor[].reshape", "min", "max", "min", "max", "str"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_bodies_info", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.denoising_bodies_data", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_one_actor_points"], ["", "def", "get_two_actors_points", "(", "bodies_data", ")", ":", "\n", "    ", "\"\"\"\n    Get the first and second actor's joints positions and colors locations.\n\n    # Arguments:\n        bodies_data (dict): 3 key-value pairs: 'name', 'data', 'num_frames'.\n        bodies_data['data'] is also a dict, while the key is bodyID, the value is\n        the corresponding body_data which is also a dict with 4 keys:\n          - joints: raw 3D joints positions. Shape: (num_frames x 25, 3)\n          - colors: raw 2D color locations. Shape: (num_frames, 25, 2)\n          - interval: a list which records the frame indices.\n          - motion: motion amount\n\n    # Return:\n        joints, colors.\n    \"\"\"", "\n", "ske_name", "=", "bodies_data", "[", "'name'", "]", "\n", "label", "=", "int", "(", "ske_name", "[", "-", "2", ":", "]", ")", "\n", "num_frames", "=", "bodies_data", "[", "'num_frames'", "]", "\n", "bodies_info", "=", "get_bodies_info", "(", "bodies_data", "[", "'data'", "]", ")", "\n", "\n", "bodies_data", ",", "noise_info", "=", "denoising_bodies_data", "(", "bodies_data", ")", "# Denoising data", "\n", "bodies_info", "+=", "noise_info", "\n", "\n", "bodies_data", "=", "list", "(", "bodies_data", ")", "\n", "if", "len", "(", "bodies_data", ")", "==", "1", ":", "# Only left one actor after denoising", "\n", "        ", "if", "label", ">=", "50", ":", "# DEBUG: Denoising failed for two-subjects action", "\n", "            ", "fail_logger_2", ".", "info", "(", "ske_name", ")", "\n", "\n", "", "bodyID", ",", "body_data", "=", "bodies_data", "[", "0", "]", "\n", "joints", ",", "colors", "=", "get_one_actor_points", "(", "body_data", ",", "num_frames", ")", "\n", "bodies_info", "+=", "'Main actor: %s'", "%", "bodyID", "\n", "", "else", ":", "\n", "        ", "if", "label", "<", "50", ":", "# DEBUG: Denoising failed for one-subject action", "\n", "            ", "fail_logger_1", ".", "info", "(", "ske_name", ")", "\n", "\n", "", "joints", "=", "np", ".", "zeros", "(", "(", "num_frames", ",", "150", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "colors", "=", "np", ".", "ones", "(", "(", "num_frames", ",", "2", ",", "25", ",", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "*", "np", ".", "nan", "\n", "\n", "bodyID", ",", "actor1", "=", "bodies_data", "[", "0", "]", "# the 1st actor with largest motion", "\n", "start1", ",", "end1", "=", "actor1", "[", "'interval'", "]", "[", "0", "]", ",", "actor1", "[", "'interval'", "]", "[", "-", "1", "]", "\n", "joints", "[", "start1", ":", "end1", "+", "1", ",", ":", "75", "]", "=", "actor1", "[", "'joints'", "]", ".", "reshape", "(", "-", "1", ",", "75", ")", "\n", "colors", "[", "start1", ":", "end1", "+", "1", ",", "0", "]", "=", "actor1", "[", "'colors'", "]", "\n", "actor1_info", "=", "'{:^17}\\t{}\\t{:^8}\\n'", ".", "format", "(", "'Actor1'", ",", "'Interval'", ",", "'Motion'", ")", "+", "'{}\\t{:^8}\\t{:f}\\n'", ".", "format", "(", "bodyID", ",", "str", "(", "[", "start1", ",", "end1", "]", ")", ",", "actor1", "[", "'motion'", "]", ")", "\n", "del", "bodies_data", "[", "0", "]", "\n", "\n", "actor2_info", "=", "'{:^17}\\t{}\\t{:^8}\\n'", ".", "format", "(", "'Actor2'", ",", "'Interval'", ",", "'Motion'", ")", "\n", "start2", ",", "end2", "=", "[", "0", ",", "0", "]", "# initial interval for actor2 (virtual)", "\n", "\n", "while", "len", "(", "bodies_data", ")", ">", "0", ":", "\n", "            ", "bodyID", ",", "actor", "=", "bodies_data", "[", "0", "]", "\n", "start", ",", "end", "=", "actor", "[", "'interval'", "]", "[", "0", "]", ",", "actor", "[", "'interval'", "]", "[", "-", "1", "]", "\n", "if", "min", "(", "end1", ",", "end", ")", "-", "max", "(", "start1", ",", "start", ")", "<=", "0", ":", "# no overlap with actor1", "\n", "                ", "joints", "[", "start", ":", "end", "+", "1", ",", ":", "75", "]", "=", "actor", "[", "'joints'", "]", ".", "reshape", "(", "-", "1", ",", "75", ")", "\n", "colors", "[", "start", ":", "end", "+", "1", ",", "0", "]", "=", "actor", "[", "'colors'", "]", "\n", "actor1_info", "+=", "'{}\\t{:^8}\\t{:f}\\n'", ".", "format", "(", "bodyID", ",", "str", "(", "[", "start", ",", "end", "]", ")", ",", "actor", "[", "'motion'", "]", ")", "\n", "# Update the interval of actor1", "\n", "start1", "=", "min", "(", "start", ",", "start1", ")", "\n", "end1", "=", "max", "(", "end", ",", "end1", ")", "\n", "", "elif", "min", "(", "end2", ",", "end", ")", "-", "max", "(", "start2", ",", "start", ")", "<=", "0", ":", "# no overlap with actor2", "\n", "                ", "joints", "[", "start", ":", "end", "+", "1", ",", "75", ":", "]", "=", "actor", "[", "'joints'", "]", ".", "reshape", "(", "-", "1", ",", "75", ")", "\n", "colors", "[", "start", ":", "end", "+", "1", ",", "1", "]", "=", "actor", "[", "'colors'", "]", "\n", "actor2_info", "+=", "'{}\\t{:^8}\\t{:f}\\n'", ".", "format", "(", "bodyID", ",", "str", "(", "[", "start", ",", "end", "]", ")", ",", "actor", "[", "'motion'", "]", ")", "\n", "# Update the interval of actor2", "\n", "start2", "=", "min", "(", "start", ",", "start2", ")", "\n", "end2", "=", "max", "(", "end", ",", "end2", ")", "\n", "", "del", "bodies_data", "[", "0", "]", "\n", "\n", "", "bodies_info", "+=", "(", "'\\n'", "+", "actor1_info", "+", "'\\n'", "+", "actor2_info", ")", "\n", "\n", "", "with", "open", "(", "osp", ".", "join", "(", "actors_info_dir", ",", "ske_name", "+", "'.txt'", ")", ",", "'w'", ")", "as", "fw", ":", "\n", "        ", "fw", ".", "write", "(", "bodies_info", "+", "'\\n'", ")", "\n", "\n", "", "return", "joints", ",", "colors", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_raw_denoised_data": [[367, 434], ["len", "print", "enumerate", "os.join", "os.join", "numpy.array", "numpy.savetxt", "print", "print", "open", "pickle.load", "print", "len", "raw_denoised_joints.append", "raw_denoised_colors.append", "np.array.append", "open", "pickle.dump", "open", "pickle.dump", "os.join", "get_raw_denoised_data.get_one_actor_points", "get_raw_denoised_data.get_two_actors_points", "get_raw_denoised_data.remove_missing_frames", "print", "numpy.sum", "list", "bodies_data[].values"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_one_actor_points", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.get_two_actors_points", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.get_raw_denoised_data.remove_missing_frames"], ["", "def", "get_raw_denoised_data", "(", ")", ":", "\n", "    ", "\"\"\"\n    Get denoised data (joints positions and color locations) from raw skeleton sequences.\n\n    For each frame of a skeleton sequence, an actor's 3D positions of 25 joints represented\n    by an 2D array (shape: 25 x 3) is reshaped into a 75-dim vector by concatenating each\n    3-dim (x, y, z) coordinates along the row dimension in joint order. Each frame contains\n    two actor's joints positions constituting a 150-dim vector. If there is only one actor,\n    then the last 75 values are filled with zeros. Otherwise, select the main actor and the\n    second actor based on the motion amount. Each 150-dim vector as a row vector is put into\n    a 2D numpy array where the number of rows equals the number of valid frames. All such\n    2D arrays are put into a list and finally the list is serialized into a cPickle file.\n\n    For the skeleton sequence which contains two or more actors (mostly corresponds to the\n    last 11 classes), the filename and actors' information are recorded into log files.\n    For better understanding, also generate RGB+skeleton videos for visualization.\n    \"\"\"", "\n", "\n", "with", "open", "(", "raw_data_file", ",", "'rb'", ")", "as", "fr", ":", "# load raw skeletons data", "\n", "        ", "raw_skes_data", "=", "pickle", ".", "load", "(", "fr", ")", "\n", "\n", "", "num_skes", "=", "len", "(", "raw_skes_data", ")", "\n", "print", "(", "'Found %d available skeleton sequences.'", "%", "num_skes", ")", "\n", "\n", "raw_denoised_joints", "=", "[", "]", "\n", "raw_denoised_colors", "=", "[", "]", "\n", "frames_cnt", "=", "[", "]", "\n", "\n", "for", "(", "idx", ",", "bodies_data", ")", "in", "enumerate", "(", "raw_skes_data", ")", ":", "\n", "        ", "ske_name", "=", "bodies_data", "[", "'name'", "]", "\n", "print", "(", "'Processing %s'", "%", "ske_name", ")", "\n", "num_bodies", "=", "len", "(", "bodies_data", "[", "'data'", "]", ")", "\n", "\n", "if", "num_bodies", "==", "1", ":", "# only 1 actor", "\n", "            ", "num_frames", "=", "bodies_data", "[", "'num_frames'", "]", "\n", "body_data", "=", "list", "(", "bodies_data", "[", "'data'", "]", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "joints", ",", "colors", "=", "get_one_actor_points", "(", "body_data", ",", "num_frames", ")", "\n", "", "else", ":", "# more than 1 actor, select two main actors", "\n", "            ", "joints", ",", "colors", "=", "get_two_actors_points", "(", "bodies_data", ")", "\n", "# Remove missing frames", "\n", "joints", ",", "colors", "=", "remove_missing_frames", "(", "ske_name", ",", "joints", ",", "colors", ")", "\n", "num_frames", "=", "joints", ".", "shape", "[", "0", "]", "# Update", "\n", "# Visualize selected actors' skeletons on RGB videos.", "\n", "\n", "", "raw_denoised_joints", ".", "append", "(", "joints", ")", "\n", "raw_denoised_colors", ".", "append", "(", "colors", ")", "\n", "frames_cnt", ".", "append", "(", "num_frames", ")", "\n", "\n", "if", "(", "idx", "+", "1", ")", "%", "1000", "==", "0", ":", "\n", "            ", "print", "(", "'Processed: %.2f%% (%d / %d), '", "%", "(", "100.0", "*", "(", "idx", "+", "1", ")", "/", "num_skes", ",", "idx", "+", "1", ",", "num_skes", ")", "+", "'Missing count: %d'", "%", "missing_count", ")", "\n", "\n", "", "", "raw_skes_joints_pkl", "=", "osp", ".", "join", "(", "save_path", ",", "'raw_denoised_joints.pkl'", ")", "\n", "with", "open", "(", "raw_skes_joints_pkl", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "raw_denoised_joints", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "raw_skes_colors_pkl", "=", "osp", ".", "join", "(", "save_path", ",", "'raw_denoised_colors.pkl'", ")", "\n", "with", "open", "(", "raw_skes_colors_pkl", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "raw_denoised_colors", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n", "", "frames_cnt", "=", "np", ".", "array", "(", "frames_cnt", ",", "dtype", "=", "np", ".", "int", ")", "\n", "np", ".", "savetxt", "(", "osp", ".", "join", "(", "save_path", ",", "'frames_cnt.txt'", ")", ",", "frames_cnt", ",", "fmt", "=", "'%d'", ")", "\n", "\n", "print", "(", "'Saved raw denoised positions of {} frames into {}'", ".", "format", "(", "np", ".", "sum", "(", "frames_cnt", ")", ",", "\n", "raw_skes_joints_pkl", ")", ")", "\n", "print", "(", "'Found %d files that have missing data'", "%", "missing_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.remove_nan_frames": [[30, 42], ["range", "numpy.any", "valid_frames.append", "nan_logger.info", "numpy.isnan", "numpy.where", "numpy.isnan"], "function", ["None"], ["\n", "", "def", "remove_nan_frames", "(", "ske_name", ",", "ske_joints", ",", "nan_logger", ")", ":", "\n", "    ", "num_frames", "=", "ske_joints", ".", "shape", "[", "0", "]", "\n", "valid_frames", "=", "[", "]", "\n", "\n", "for", "f", "in", "range", "(", "num_frames", ")", ":", "\n", "        ", "if", "not", "np", ".", "any", "(", "np", ".", "isnan", "(", "ske_joints", "[", "f", "]", ")", ")", ":", "\n", "            ", "valid_frames", ".", "append", "(", "f", ")", "\n", "", "else", ":", "\n", "            ", "nan_indices", "=", "np", ".", "where", "(", "np", ".", "isnan", "(", "ske_joints", "[", "f", "]", ")", ")", "[", "0", "]", "\n", "nan_logger", ".", "info", "(", "'{}\\t{:^5}\\t{}'", ".", "format", "(", "ske_name", ",", "f", "+", "1", ",", "nan_indices", ")", ")", "\n", "\n", "", "", "return", "ske_joints", "[", "valid_frames", "]", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.seq_translation": [[43, 76], ["enumerate", "numpy.copy", "range", "len", "len", "numpy.any", "numpy.zeros", "numpy.zeros", "numpy.where", "numpy.where", "numpy.tile", "numpy.tile", "ske_joints[].sum", "ske_joints[].sum"], "function", ["None"], ["\n", "", "def", "seq_translation", "(", "skes_joints", ")", ":", "\n", "    ", "for", "idx", ",", "ske_joints", "in", "enumerate", "(", "skes_joints", ")", ":", "\n", "        ", "num_frames", "=", "ske_joints", ".", "shape", "[", "0", "]", "\n", "num_bodies", "=", "1", "if", "ske_joints", ".", "shape", "[", "1", "]", "==", "75", "else", "2", "\n", "if", "num_bodies", "==", "2", ":", "\n", "            ", "missing_frames_1", "=", "np", ".", "where", "(", "ske_joints", "[", ":", ",", ":", "75", "]", ".", "sum", "(", "axis", "=", "1", ")", "==", "0", ")", "[", "0", "]", "\n", "missing_frames_2", "=", "np", ".", "where", "(", "ske_joints", "[", ":", ",", "75", ":", "]", ".", "sum", "(", "axis", "=", "1", ")", "==", "0", ")", "[", "0", "]", "\n", "cnt1", "=", "len", "(", "missing_frames_1", ")", "\n", "cnt2", "=", "len", "(", "missing_frames_2", ")", "\n", "\n", "", "i", "=", "0", "# get the \"real\" first frame of actor1", "\n", "while", "i", "<", "num_frames", ":", "\n", "            ", "if", "np", ".", "any", "(", "ske_joints", "[", "i", ",", ":", "75", "]", "!=", "0", ")", ":", "\n", "                ", "break", "\n", "", "i", "+=", "1", "\n", "\n", "", "origin", "=", "np", ".", "copy", "(", "ske_joints", "[", "i", ",", "3", ":", "6", "]", ")", "# new origin: joint-2", "\n", "\n", "for", "f", "in", "range", "(", "num_frames", ")", ":", "\n", "            ", "if", "num_bodies", "==", "1", ":", "\n", "                ", "ske_joints", "[", "f", "]", "-=", "np", ".", "tile", "(", "origin", ",", "25", ")", "\n", "", "else", ":", "# for 2 actors", "\n", "                ", "ske_joints", "[", "f", "]", "-=", "np", ".", "tile", "(", "origin", ",", "50", ")", "\n", "\n", "", "", "if", "(", "num_bodies", "==", "2", ")", "and", "(", "cnt1", ">", "0", ")", ":", "\n", "            ", "ske_joints", "[", "missing_frames_1", ",", ":", "75", "]", "=", "np", ".", "zeros", "(", "(", "cnt1", ",", "75", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "if", "(", "num_bodies", "==", "2", ")", "and", "(", "cnt2", ">", "0", ")", ":", "\n", "            ", "ske_joints", "[", "missing_frames_2", ",", "75", ":", "]", "=", "np", ".", "zeros", "(", "(", "cnt2", ",", "75", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "skes_joints", "[", "idx", "]", "=", "ske_joints", "# Update", "\n", "\n", "", "return", "skes_joints", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.frame_translation": [[78, 104], ["logging.getLogger", "logging.getLogger.setLevel", "logging.getLogger.addHandler", "logging.getLogger.info", "enumerate", "logging.FileHandler", "numpy.sqrt", "range", "seq_transformation.remove_nan_frames", "numpy.tile", "numpy.tile", "numpy.tile", "numpy.tile"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.remove_nan_frames"], ["\n", "", "def", "frame_translation", "(", "skes_joints", ",", "skes_name", ",", "frames_cnt", ")", ":", "\n", "    ", "nan_logger", "=", "logging", ".", "getLogger", "(", "'nan_skes'", ")", "\n", "nan_logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "nan_logger", ".", "addHandler", "(", "logging", ".", "FileHandler", "(", "\"./nan_frames.log\"", ")", ")", "\n", "nan_logger", ".", "info", "(", "'{}\\t{}\\t{}'", ".", "format", "(", "'Skeleton'", ",", "'Frame'", ",", "'Joints'", ")", ")", "\n", "\n", "for", "idx", ",", "ske_joints", "in", "enumerate", "(", "skes_joints", ")", ":", "\n", "        ", "num_frames", "=", "ske_joints", ".", "shape", "[", "0", "]", "\n", "# Calculate the distance between spine base (joint-1) and spine (joint-21)", "\n", "j1", "=", "ske_joints", "[", ":", ",", "0", ":", "3", "]", "\n", "j21", "=", "ske_joints", "[", ":", ",", "60", ":", "63", "]", "\n", "dist", "=", "np", ".", "sqrt", "(", "(", "(", "j1", "-", "j21", ")", "**", "2", ")", ".", "sum", "(", "axis", "=", "1", ")", ")", "\n", "\n", "for", "f", "in", "range", "(", "num_frames", ")", ":", "\n", "            ", "origin", "=", "ske_joints", "[", "f", ",", "3", ":", "6", "]", "# new origin: middle of the spine (joint-2)", "\n", "if", "(", "ske_joints", "[", "f", ",", "75", ":", "]", "==", "0", ")", ".", "all", "(", ")", ":", "\n", "                ", "ske_joints", "[", "f", ",", ":", "75", "]", "=", "(", "ske_joints", "[", "f", ",", ":", "75", "]", "-", "np", ".", "tile", "(", "origin", ",", "25", ")", ")", "/", "dist", "[", "f", "]", "+", "np", ".", "tile", "(", "origin", ",", "25", ")", "\n", "", "else", ":", "\n", "                ", "ske_joints", "[", "f", "]", "=", "(", "ske_joints", "[", "f", "]", "-", "np", ".", "tile", "(", "origin", ",", "50", ")", ")", "/", "dist", "[", "f", "]", "+", "np", ".", "tile", "(", "origin", ",", "50", ")", "\n", "\n", "", "", "ske_name", "=", "skes_name", "[", "idx", "]", "\n", "ske_joints", "=", "remove_nan_frames", "(", "ske_name", ",", "ske_joints", ",", "nan_logger", ")", "\n", "frames_cnt", "[", "idx", "]", "=", "num_frames", "# update valid number of frames", "\n", "skes_joints", "[", "idx", "]", "=", "ske_joints", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.align_frames": [[106, 124], ["len", "frames_cnt.max", "numpy.zeros", "enumerate", "numpy.hstack", "numpy.zeros_like"], "function", ["None"], ["", "return", "skes_joints", ",", "frames_cnt", "\n", "\n", "\n", "", "def", "align_frames", "(", "skes_joints", ",", "frames_cnt", ")", ":", "\n", "    ", "\"\"\"\n    Align all sequences with the same frame length.\n\n    \"\"\"", "\n", "num_skes", "=", "len", "(", "skes_joints", ")", "\n", "max_num_frames", "=", "frames_cnt", ".", "max", "(", ")", "# 300", "\n", "aligned_skes_joints", "=", "np", ".", "zeros", "(", "(", "num_skes", ",", "max_num_frames", ",", "150", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "for", "idx", ",", "ske_joints", "in", "enumerate", "(", "skes_joints", ")", ":", "\n", "        ", "num_frames", "=", "ske_joints", ".", "shape", "[", "0", "]", "\n", "num_bodies", "=", "1", "if", "ske_joints", ".", "shape", "[", "1", "]", "==", "75", "else", "2", "\n", "if", "num_bodies", "==", "1", ":", "\n", "            ", "aligned_skes_joints", "[", "idx", ",", ":", "num_frames", "]", "=", "np", ".", "hstack", "(", "(", "ske_joints", ",", "ske_joints", ")", ")", "\n", "# aligned_skes_joints[idx, :num_frames] = np.hstack((ske_joints, np.zeros_like(ske_joints)))", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.one_hot_vector": [[126, 133], ["len", "numpy.zeros", "enumerate"], "function", ["None"], ["\n", "", "", "return", "aligned_skes_joints", "\n", "\n", "\n", "", "def", "one_hot_vector", "(", "labels", ")", ":", "\n", "    ", "num_skes", "=", "len", "(", "labels", ")", "\n", "labels_vector", "=", "np", ".", "zeros", "(", "(", "num_skes", ",", "120", ")", ")", "\n", "for", "idx", ",", "l", "in", "enumerate", "(", "labels", ")", ":", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.split_train_val": [[135, 150], ["sklearn.model_selection.train_test_split", "numpy.random.seed", "numpy.random.shuffle", "int", "numpy.ceil", "len"], "function", ["None"], ["\n", "", "return", "labels_vector", "\n", "\n", "\n", "", "def", "split_train_val", "(", "train_indices", ",", "method", "=", "'sklearn'", ",", "ratio", "=", "0.05", ")", ":", "\n", "    ", "\"\"\"\n    Get validation set by splitting data randomly from training set with two methods.\n    In fact, I thought these two methods are equal as they got the same performance.\n\n    \"\"\"", "\n", "if", "method", "==", "'sklearn'", ":", "\n", "        ", "return", "train_test_split", "(", "train_indices", ",", "test_size", "=", "ratio", ",", "random_state", "=", "10000", ")", "\n", "", "else", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "10000", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "train_indices", ")", "\n", "val_num_skes", "=", "int", "(", "np", ".", "ceil", "(", "0.05", "*", "len", "(", "train_indices", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.split_dataset": [[152, 167], ["seq_transformation.get_indices", "seq_transformation.one_hot_vector", "seq_transformation.one_hot_vector", "numpy.savez"], "function", ["home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.get_indices", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.one_hot_vector", "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.one_hot_vector"], ["train_indices", "=", "train_indices", "[", "val_num_skes", ":", "]", "\n", "return", "train_indices", ",", "val_indices", "\n", "\n", "\n", "", "", "def", "split_dataset", "(", "skes_joints", ",", "label", ",", "performer", ",", "setup", ",", "evaluation", ",", "save_path", ")", ":", "\n", "    ", "train_indices", ",", "test_indices", "=", "get_indices", "(", "performer", ",", "setup", ",", "evaluation", ")", "\n", "# m = 'sklearn'  # 'sklearn' or 'numpy'", "\n", "# Select validation set from training set", "\n", "# train_indices, val_indices = split_train_val(train_indices, m)", "\n", "\n", "# Save labels and num_frames for each sequence of each data set", "\n", "train_labels", "=", "label", "[", "train_indices", "]", "\n", "test_labels", "=", "label", "[", "test_indices", "]", "\n", "\n", "train_x", "=", "skes_joints", "[", "train_indices", "]", "\n", "train_y", "=", "one_hot_vector", "(", "train_labels", ")", "\n"]], "home.repos.pwc.inspect_result.heleiqiu_sttformer.ntu.seq_transformation.get_indices": [[168, 200], ["numpy.empty", "numpy.empty", "numpy.hstack().astype", "numpy.hstack().astype", "numpy.hstack().astype", "numpy.where", "numpy.hstack().astype", "numpy.where", "numpy.where", "numpy.hstack", "numpy.where", "numpy.hstack", "numpy.hstack", "numpy.hstack"], "function", ["None"], ["test_x", "=", "skes_joints", "[", "test_indices", "]", "\n", "test_y", "=", "one_hot_vector", "(", "test_labels", ")", "\n", "\n", "save_name", "=", "'NTU120_%s.npz'", "%", "evaluation", "\n", "np", ".", "savez", "(", "save_name", ",", "x_train", "=", "train_x", ",", "y_train", "=", "train_y", ",", "x_test", "=", "test_x", ",", "y_test", "=", "test_y", ")", "\n", "\n", "# # Save data into a .h5 file", "\n", "# h5file = h5py.File(osp.join(save_path, 'NTU_%s.h5' % (evaluation)), 'w')", "\n", "# # Training set", "\n", "# h5file.create_dataset('x', data=skes_joints[train_indices])", "\n", "# train_one_hot_labels = one_hot_vector(train_labels)", "\n", "# h5file.create_dataset('y', data=train_one_hot_labels)", "\n", "# # Validation set", "\n", "# h5file.create_dataset('valid_x', data=skes_joints[val_indices])", "\n", "# val_one_hot_labels = one_hot_vector(val_labels)", "\n", "# h5file.create_dataset('valid_y', data=val_one_hot_labels)", "\n", "# # Test set", "\n", "# h5file.create_dataset('test_x', data=skes_joints[test_indices])", "\n", "# test_one_hot_labels = one_hot_vector(test_labels)", "\n", "# h5file.create_dataset('test_y', data=test_one_hot_labels)", "\n", "\n", "# h5file.close()", "\n", "\n", "\n", "", "def", "get_indices", "(", "performer", ",", "setup", ",", "evaluation", "=", "'XSub'", ")", ":", "\n", "    ", "test_indices", "=", "np", ".", "empty", "(", "0", ")", "\n", "train_indices", "=", "np", ".", "empty", "(", "0", ")", "\n", "\n", "if", "evaluation", "==", "'XSub'", ":", "# Cross Subject (Subject IDs)", "\n", "        ", "train_ids", "=", "[", "1", ",", "2", ",", "4", ",", "5", ",", "8", ",", "9", ",", "13", ",", "14", ",", "15", ",", "16", ",", "17", ",", "18", ",", "19", ",", "25", ",", "27", ",", "28", ",", "\n", "31", ",", "34", ",", "35", ",", "38", ",", "45", ",", "46", ",", "47", ",", "49", ",", "50", ",", "52", ",", "53", ",", "54", ",", "55", ",", "56", ",", "57", ",", "\n", "58", ",", "59", ",", "70", ",", "74", ",", "78", ",", "80", ",", "81", ",", "82", ",", "83", ",", "84", ",", "85", ",", "86", ",", "89", ",", "91", ",", "92", ",", "\n", "93", ",", "94", ",", "95", ",", "97", ",", "98", ",", "100", ",", "103", "]", "\n"]]}