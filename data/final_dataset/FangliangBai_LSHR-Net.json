{"home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.conv_layer.__init__": [[190, 240], ["tf.variable_scope", "tf.nn.conv2d", "tf.add", "tf.summary.histogram", "tf.summary.histogram", "len", "tf.name_scope", "tf.get_variable", "tf.variable_scope", "tf.get_variable", "tf.cond", "ops.binarization", "tf.name_scope", "tf.get_variable", "tf.get_variable", "tf.get_variable", "tf.get_variable", "tf.glorot_uniform_initializer", "tf.constant_initializer", "ops.binarization", "tf.constant_initializer", "tf.constant_initializer", "tf.constant_initializer", "tf.constant_initializer"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.binarization", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.binarization"], ["    ", "def", "__init__", "(", "self", ",", "input_x", ",", "in_channel", ",", "out_channel", ",", "kernel_shape", ",", "padding", "=", "\"SAME\"", ",", "binary", "=", "False", ",", "stochastic", "=", "False", ",", "\n", "is_training", "=", "None", ",", "index", "=", "0", ")", ":", "\n", "# binary: whether to implement the Binary Connect", "\n", "# stochastic: whether implement stochastic weight if do Binary Connect", "\n", "\n", "        ", "assert", "len", "(", "input_x", ".", "shape", ")", "==", "4", "and", "input_x", ".", "shape", "[", "1", "]", "==", "input_x", ".", "shape", "[", "2", "]", "and", "input_x", ".", "shape", "[", "3", "]", "==", "in_channel", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'conv_layer_%d'", "%", "index", ")", ":", "\n", "            ", "with", "tf", ".", "name_scope", "(", "'conv_kernel'", ")", ":", "\n", "                ", "w_shape", "=", "[", "kernel_shape", ",", "kernel_shape", ",", "in_channel", ",", "out_channel", "]", "\n", "# the real value of weight", "\n", "weight", "=", "tf", ".", "get_variable", "(", "name", "=", "'conv_kernel_%d'", "%", "index", ",", "shape", "=", "w_shape", ",", "\n", "initializer", "=", "tf", ".", "glorot_uniform_initializer", "(", ")", ")", "\n", "self", ".", "weight", "=", "weight", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'conv_bias'", ")", ":", "\n", "                ", "b_shape", "=", "[", "out_channel", "]", "\n", "bias", "=", "tf", ".", "get_variable", "(", "name", "=", "'conv_bias_%d'", "%", "index", ",", "shape", "=", "b_shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.", ")", ")", "\n", "self", ".", "bias", "=", "bias", "\n", "\n", "# use real value weights to test in stochastic BinaryConnect", "\n", "", "if", "binary", "and", "stochastic", ":", "\n", "                ", "wb", "=", "tf", ".", "cond", "(", "is_training", ",", "lambda", ":", "binarization", "(", "weight", ",", "H", "=", "1", ",", "binary", "=", "binary", ",", "stochastic", "=", "stochastic", ")", ",", "\n", "lambda", ":", "weight", ")", "\n", "# otherwise, return binarization directly", "\n", "", "else", ":", "\n", "                ", "wb", "=", "binarization", "(", "weight", ",", "H", "=", "1", ",", "binary", "=", "binary", ",", "stochastic", "=", "stochastic", ")", "\n", "\n", "", "self", ".", "wb", "=", "wb", "\n", "\n", "cell_out", "=", "tf", ".", "nn", ".", "conv2d", "(", "input_x", ",", "self", ".", "wb", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "padding", ")", "\n", "\n", "cell_out", "=", "tf", ".", "add", "(", "cell_out", ",", "bias", ")", "\n", "\n", "self", ".", "cell_out", "=", "cell_out", "\n", "\n", "tf", ".", "summary", ".", "histogram", "(", "'conv_layer/{}/kernel'", ".", "format", "(", "index", ")", ",", "self", ".", "weight", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "'conv_layer/{}/bias'", ".", "format", "(", "index", ")", ",", "self", ".", "bias", ")", "\n", "\n", "# to store the moments for adam", "\n", "with", "tf", ".", "name_scope", "(", "'conv_moment'", ")", ":", "\n", "                ", "self", ".", "m_w", "=", "tf", ".", "get_variable", "(", "name", "=", "'conv_first_moment_w_%d'", "%", "index", ",", "shape", "=", "w_shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.", ")", ")", "\n", "self", ".", "v_w", "=", "tf", ".", "get_variable", "(", "name", "=", "'conv_second_moment_w_%d'", "%", "index", ",", "shape", "=", "w_shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.", ")", ")", "\n", "self", ".", "m_b", "=", "tf", ".", "get_variable", "(", "name", "=", "'conv_first_moment_b_%d'", "%", "index", ",", "shape", "=", "b_shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.", ")", ")", "\n", "self", ".", "v_b", "=", "tf", ".", "get_variable", "(", "name", "=", "'conv_second_moment_b_%d'", "%", "index", ",", "shape", "=", "b_shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.conv_layer.output": [[241, 243], ["None"], "methods", ["None"], ["", "", "", "def", "output", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cell_out", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.resnet_block": [[16, 26], ["tensorflow.conv2d", "tf.layers.batch_normalization", "tf.nn.relu", "tensorflow.conv2d", "tf.layers.batch_normalization", "tf.nn.relu", "tensorflow.conv2d", "tf.add"], "function", ["None"], ["def", "resnet_block", "(", "inputs", ",", "channels", "=", "64", ",", "kernel_size", "=", "3", ")", ":", "\n", "    ", "tmp", "=", "slim", ".", "conv2d", "(", "inputs", ",", "num_outputs", "=", "64", ",", "kernel_size", "=", "11", ",", "activation_fn", "=", "None", ")", "\n", "tmp", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "tmp", ")", "\n", "tmp", "=", "tf", ".", "nn", ".", "relu", "(", "tmp", ")", "\n", "tmp", "=", "slim", ".", "conv2d", "(", "tmp", ",", "num_outputs", "=", "32", ",", "kernel_size", "=", "1", ",", "activation_fn", "=", "None", ")", "\n", "tmp", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "tmp", ")", "\n", "tmp", "=", "tf", ".", "nn", ".", "relu", "(", "tmp", ")", "\n", "tmp", "=", "slim", ".", "conv2d", "(", "inputs", ",", "num_outputs", "=", "1", ",", "kernel_size", "=", "7", ",", "activation_fn", "=", "None", ")", "\n", "tmp", "=", "tf", ".", "add", "(", "inputs", ",", "tmp", ")", "\n", "return", "tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.upsample": [[28, 49], ["tensorflow.conv2d", "ops.PS", "ops.PS", "tensorflow.conv2d", "ops.PS", "range", "tensorflow.conv2d", "ops.PS"], "function", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.PS", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.PS", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.PS", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.PS"], ["", "def", "upsample", "(", "inputs", ",", "scale", "=", "2", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", ":", "\n", "    ", "assert", "scale", "in", "[", "2", ",", "3", ",", "4", "]", "\n", "if", "scale", "==", "2", ":", "\n", "        ", "ps_features", "=", "conf", ".", "img_channel", "*", "(", "scale", "**", "2", ")", "\n", "x", "=", "slim", ".", "conv2d", "(", "inputs", ",", "ps_features", ",", "[", "3", ",", "3", "]", ",", "activation_fn", "=", "activation", ")", "\n", "if", "conf", ".", "img_channel", "==", "1", ":", "\n", "            ", "x", "=", "PS", "(", "x", ",", "2", ",", "color", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "PS", "(", "x", ",", "2", ",", "color", "=", "True", ")", "\n", "", "", "elif", "scale", "==", "3", ":", "\n", "        ", "ps_features", "=", "3", "*", "(", "scale", "**", "2", ")", "\n", "inputs", "=", "slim", ".", "conv2d", "(", "inputs", ",", "ps_features", ",", "[", "3", ",", "3", "]", ",", "activation_fn", "=", "activation", ")", "\n", "# inputs = slim.conv2d_transpose(inputs,ps_features,9,stride=1,activation_fn=activation)", "\n", "inputs", "=", "PS", "(", "inputs", ",", "3", ",", "color", "=", "True", ")", "\n", "", "elif", "scale", "==", "4", ":", "\n", "        ", "ps_features", "=", "3", "*", "(", "2", "**", "2", ")", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "            ", "inputs", "=", "slim", ".", "conv2d", "(", "inputs", ",", "ps_features", ",", "[", "3", ",", "3", "]", ",", "activation_fn", "=", "activation", ")", "\n", "# inputs = slim.conv2d_transpose(inputs,ps_features,6,stride=1,activation_fn=activation)", "\n", "inputs", "=", "PS", "(", "inputs", ",", "2", ",", "color", "=", "True", ")", "\n", "", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.PS": [[51, 58], ["tf.split", "tf.concat", "ops._phase_shift", "ops._phase_shift"], "function", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops._phase_shift", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops._phase_shift"], ["", "def", "PS", "(", "X", ",", "r", ",", "color", "=", "False", ")", ":", "\n", "    ", "if", "color", ":", "\n", "        ", "Xc", "=", "tf", ".", "split", "(", "X", ",", "3", ",", "3", ")", "\n", "X", "=", "tf", ".", "concat", "(", "[", "_phase_shift", "(", "x", ",", "r", ")", "for", "x", "in", "Xc", "]", ",", "3", ")", "\n", "", "else", ":", "\n", "        ", "X", "=", "_phase_shift", "(", "X", ",", "r", ")", "\n", "", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops._phase_shift": [[60, 70], ["I.get_shape().as_list", "tf.reshape", "tf.transpose", "tf.split", "tf.concat", "tf.split", "tf.concat", "tf.reshape", "tf.shape", "I.get_shape", "tf.squeeze", "tf.squeeze"], "function", ["None"], ["", "def", "_phase_shift", "(", "I", ",", "r", ")", ":", "\n", "    ", "bsize", ",", "a", ",", "b", ",", "c", "=", "I", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "bsize", "=", "tf", ".", "shape", "(", "I", ")", "[", "0", "]", "# Handling Dimension(None) type for undefined batch dim", "\n", "X", "=", "tf", ".", "reshape", "(", "I", ",", "(", "bsize", ",", "a", ",", "b", ",", "r", ",", "r", ")", ")", "\n", "X", "=", "tf", ".", "transpose", "(", "X", ",", "(", "0", ",", "1", ",", "2", ",", "4", ",", "3", ")", ")", "# bsize, a, b, 1, 1", "\n", "X", "=", "tf", ".", "split", "(", "X", ",", "a", ",", "1", ")", "# a, [bsize, b, r, r]", "\n", "X", "=", "tf", ".", "concat", "(", "[", "tf", ".", "squeeze", "(", "x", ",", "axis", "=", "1", ")", "for", "x", "in", "X", "]", ",", "2", ")", "# bsize, b, a*r, r", "\n", "X", "=", "tf", ".", "split", "(", "X", ",", "b", ",", "1", ")", "# b, [bsize, a*r, r]", "\n", "X", "=", "tf", ".", "concat", "(", "[", "tf", ".", "squeeze", "(", "x", ",", "axis", "=", "1", ")", "for", "x", "in", "X", "]", ",", "2", ")", "# bsize, a*r, b*r", "\n", "return", "tf", ".", "reshape", "(", "X", ",", "(", "bsize", ",", "a", "*", "r", ",", "b", "*", "r", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.ResidualSingleLevel": [[72, 118], ["tf.variable_scope", "tensorlayer.layers.set_name_reuse", "range", "PReluLayer", "ops.get_bilinear_filter", "tf.nn.conv2d_transpose", "InputLayer", "Conv2dLayer", "ops.get_bilinear_filter", "tf.nn.conv2d_transpose", "InputLayer", "ElementwiseLayer", "ops.residual_unit", "ElementwiseLayer", "tf.constant_initializer", "tf.contrib.layers.variance_scaling_initializer"], "function", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.get_bilinear_filter", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.get_bilinear_filter", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.residual_unit"], ["", "def", "ResidualSingleLevel", "(", "net_image", ",", "net_feature", ",", "num_features", "=", "64", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "\"Model_level\"", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "tl", ".", "layers", ".", "set_name_reuse", "(", "reuse", ")", "\n", "\n", "net_tmp", "=", "net_feature", "\n", "# recursive block", "\n", "for", "i", "in", "range", "(", "6", ")", ":", "\n", "            ", "net_tmp", "=", "residual_unit", "(", "net_tmp", ",", "num_features", ",", "i", ")", "\n", "net_tmp", "=", "ElementwiseLayer", "(", "layers", "=", "[", "net_feature", ",", "net_tmp", "]", ",", "combine_fn", "=", "tf", ".", "add", ",", "name", "=", "'add_feature'", ")", "\n", "\n", "", "net_feature", "=", "net_tmp", "\n", "net_feature", "=", "PReluLayer", "(", "net_feature", ",", "name", "=", "'prelu_feature'", ",", "a_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.2", ")", ")", "\n", "# net_feature = Conv2dLayer(net_feature, shape=(3, 3, num_features, num_features*4), strides=(1, 1, 1, 1),", "\n", "#                           name='upconv_feature', W_init=tf.contrib.layers.xavier_initializer(), b_init=None)", "\n", "# net_feature = SubpixelConv2d(net_feature, scale=2, n_out_channel=num_features, name='subpixel_feature')", "\n", "\n", "# net_feature = DeConv2dLayer(net_feature, act=tf.identity, shape=(4, 4, 64, 64), strides=(1, 2, 2, 1),", "\n", "#                             output_shape=(conf.batch_size, conf.lr_size * 2, conf.lr_size * 2, 64), padding='SAME',", "\n", "#                             W_init=None, b_init=None, name='devcon1',", "\n", "#                             W_init_args=get_bilinear_filter([4, 4, 64, 64], 2))", "\n", "weights_f", "=", "get_bilinear_filter", "(", "[", "4", ",", "4", ",", "64", ",", "64", "]", ",", "2", ",", "name", "=", "'weights_f'", ")", "\n", "net_feature", "=", "tf", ".", "nn", ".", "conv2d_transpose", "(", "net_feature", ".", "outputs", ",", "weights_f", ",", "\n", "output_shape", "=", "[", "conf", ".", "batch_size", ",", "conf", ".", "lr_size", "*", "2", ",", "conf", ".", "lr_size", "*", "2", ",", "64", "]", ",", "\n", "strides", "=", "(", "1", ",", "2", ",", "2", ",", "1", ")", ",", "padding", "=", "'SAME'", ")", "\n", "net_feature", "=", "InputLayer", "(", "net_feature", ")", "\n", "\n", "# add image back", "\n", "gradient_level", "=", "Conv2dLayer", "(", "net_feature", ",", "shape", "=", "(", "3", ",", "3", ",", "num_features", ",", "conf", ".", "img_channel", ")", ",", "strides", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "act", "=", "leaky_relu", ",", "W_init", "=", "tf", ".", "contrib", ".", "layers", ".", "variance_scaling_initializer", "(", ")", ",", "\n", "b_init", "=", "None", ",", "name", "=", "'gradient_level'", ")", "\n", "\n", "# net_image = Conv2dLayer(net_image, shape=(3, 3, conf.img_channel, 4), strides=(1, 1, 1, 1),", "\n", "#                         name='upconv_image', W_init=tf.contrib.layers.xavier_initializer(), b_init=None)", "\n", "# net_image = SubpixelConv2d(net_image, scale=2, n_out_channel=1, name='subpixel_image')", "\n", "# net_image = DeConv2dLayer(net_image, act=tf.identity, shape=(4, 4, 1, 64), strides=(1, 2, 2, 1),", "\n", "#                           output_shape=(conf.batch_size, conf.lr_size * 2, conf.lr_size * 2, 1), padding='SAME',", "\n", "#                           W_init=None, b_init=None, name='devcon2',", "\n", "#                           W_init_args=get_bilinear_filter([4, 4, 64, 1], 2))", "\n", "weights_im", "=", "get_bilinear_filter", "(", "[", "4", ",", "4", ",", "1", ",", "1", "]", ",", "2", ",", "'weights_im'", ")", "\n", "net_image", "=", "tf", ".", "nn", ".", "conv2d_transpose", "(", "net_image", ".", "outputs", ",", "weights_im", ",", "\n", "output_shape", "=", "[", "conf", ".", "batch_size", ",", "conf", ".", "lr_size", "*", "2", ",", "conf", ".", "lr_size", "*", "2", ",", "1", "]", ",", "\n", "strides", "=", "(", "1", ",", "2", ",", "2", ",", "1", ")", ",", "padding", "=", "'SAME'", ")", "\n", "net_image", "=", "InputLayer", "(", "net_image", ")", "\n", "net_image", "=", "ElementwiseLayer", "(", "layers", "=", "[", "gradient_level", ",", "net_image", "]", ",", "combine_fn", "=", "tf", ".", "add", ",", "name", "=", "'add_image'", ")", "\n", "\n", "", "return", "net_image", ",", "net_feature", ",", "gradient_level", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.leaky_relu": [[120, 122], ["tf.maximum"], "function", ["None"], ["", "def", "leaky_relu", "(", "x", ",", "leaky_alpha", "=", "0.2", ")", ":", "\n", "    ", "return", "tf", ".", "maximum", "(", "x", ",", "leaky_alpha", "*", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.residual_unit": [[124, 140], ["PReluLayer", "Conv2dLayer", "PReluLayer", "Conv2dLayer", "tf.constant_initializer", "tf.contrib.layers.variance_scaling_initializer", "tf.constant_initializer", "tf.contrib.layers.variance_scaling_initializer"], "function", ["None"], ["", "def", "residual_unit", "(", "net_tmp", ",", "num_features", ",", "ind", ")", ":", "\n", "    ", "net_tmp", "=", "PReluLayer", "(", "net_tmp", ",", "\n", "name", "=", "'prelu_1_D%s'", "%", "ind", ",", "a_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.2", ")", ")", "\n", "net_tmp", "=", "Conv2dLayer", "(", "net_tmp", ",", "\n", "shape", "=", "(", "3", ",", "3", ",", "num_features", ",", "num_features", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "name", "=", "'conv_1_D%s'", "%", "ind", ",", "\n", "W_init", "=", "tf", ".", "contrib", ".", "layers", ".", "variance_scaling_initializer", "(", ")", ",", "b_init", "=", "None", ")", "\n", "net_tmp", "=", "PReluLayer", "(", "net_tmp", ",", "\n", "name", "=", "'prelu_2_D%s'", "%", "ind", ",", "a_init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "0.2", ")", ")", "\n", "net_tmp", "=", "Conv2dLayer", "(", "net_tmp", ",", "\n", "shape", "=", "(", "3", ",", "3", ",", "num_features", ",", "num_features", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "name", "=", "'conv_2_D%s'", "%", "ind", ",", "\n", "W_init", "=", "tf", ".", "contrib", ".", "layers", ".", "variance_scaling_initializer", "(", ")", ",", "b_init", "=", "None", ")", "\n", "return", "net_tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.get_bilinear_filter": [[142, 166], ["numpy.zeros", "range", "numpy.zeros", "range", "tf.constant_initializer", "tf.get_variable", "range", "abs", "abs"], "function", ["None"], ["", "def", "get_bilinear_filter", "(", "filter_shape", ",", "upscale_factor", ",", "name", ")", ":", "\n", "# filter_shape is [width, height, num_in_channels, num_out_channels]", "\n", "    ", "kernel_size", "=", "filter_shape", "[", "1", "]", "\n", "# Centre location of the filter for which value is calculated", "\n", "if", "kernel_size", "%", "2", "==", "1", ":", "\n", "        ", "centre_location", "=", "upscale_factor", "-", "1", "\n", "", "else", ":", "\n", "        ", "centre_location", "=", "upscale_factor", "-", "0.5", "\n", "\n", "", "bilinear", "=", "np", ".", "zeros", "(", "[", "filter_shape", "[", "0", "]", ",", "filter_shape", "[", "1", "]", "]", ")", "\n", "for", "x", "in", "range", "(", "filter_shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "y", "in", "range", "(", "filter_shape", "[", "1", "]", ")", ":", "\n", "# Interpolation Calculation", "\n", "            ", "value", "=", "(", "1", "-", "abs", "(", "(", "x", "-", "centre_location", ")", "/", "upscale_factor", ")", ")", "*", "(", "1", "-", "abs", "(", "(", "y", "-", "centre_location", ")", "/", "upscale_factor", ")", ")", "\n", "bilinear", "[", "x", ",", "y", "]", "=", "value", "\n", "", "", "weights", "=", "np", ".", "zeros", "(", "filter_shape", ")", "\n", "for", "i", "in", "range", "(", "filter_shape", "[", "2", "]", ")", ":", "\n", "        ", "weights", "[", ":", ",", ":", ",", "i", ",", "i", "]", "=", "bilinear", "\n", "", "init", "=", "tf", ".", "constant_initializer", "(", "value", "=", "weights", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "bilinear_weights", "=", "tf", ".", "get_variable", "(", "name", "=", "name", ",", "initializer", "=", "init", ",", "\n", "shape", "=", "weights", ".", "shape", ")", "\n", "return", "bilinear_weights", "\n", "# ============================ Binary-Neural-Network ============================", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.hard_sigmoid": [[169, 171], ["tf.contrib.keras.backend.clip"], "function", ["None"], ["", "def", "hard_sigmoid", "(", "x", ")", ":", "\n", "    ", "return", "tf", ".", "contrib", ".", "keras", ".", "backend", ".", "clip", "(", "(", "x", "+", "1.0", ")", "/", "2.0", ",", "0.0", ",", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.binarization": [[173, 187], ["ops.hard_sigmoid", "tf.contrib.keras.backend.random_binomial", "tf.round", "tf.shape"], "function", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.hard_sigmoid"], ["", "def", "binarization", "(", "W", ",", "H", "=", "1", ",", "binary", "=", "False", ",", "stochastic", "=", "False", ")", ":", "\n", "    ", "if", "not", "binary", ":", "\n", "        ", "Wb", "=", "W", "\n", "", "else", ":", "\n", "        ", "Wb", "=", "hard_sigmoid", "(", "W", "/", "H", ")", "\n", "if", "stochastic", ":", "\n", "# use hard sigmoid weight for possibility", "\n", "            ", "Wb", "=", "tf", ".", "contrib", ".", "keras", ".", "backend", ".", "random_binomial", "(", "tf", ".", "shape", "(", "Wb", ")", ",", "p", "=", "Wb", ")", "\n", "", "else", ":", "\n", "# round weight to 0 and 1", "\n", "            ", "Wb", "=", "tf", ".", "round", "(", "Wb", ")", "\n", "# change range from 0~1  to  -1~1", "\n", "", "Wb", "=", "Wb", "*", "2", "-", "1", "\n", "", "return", "Wb", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.quantize": [[247, 251], ["float", "G.gradient_override_map", "tf.round"], "function", ["None"], ["", "", "def", "quantize", "(", "x", ",", "k", ")", ":", "\n", "    ", "n", "=", "float", "(", "2", "**", "k", "-", "1", ")", "\n", "with", "G", ".", "gradient_override_map", "(", "{", "\"Round\"", ":", "\"Identity\"", "}", ")", ":", "\n", "        ", "return", "tf", ".", "round", "(", "x", "*", "n", ")", "/", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.fw": [[253, 262], ["tf.get_default_graph", "tf.tanh", "tf.get_default_graph.gradient_override_map", "tf.stop_gradient", "tf.reduce_mean", "tf.sign", "ops.quantize", "tf.abs", "tf.reduce_max", "tf.abs"], "function", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.quantize"], ["", "", "def", "fw", "(", "x", ")", ":", "\n", "    ", "G", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "\n", "with", "G", ".", "gradient_override_map", "(", "{", "\"Sign\"", ":", "\"Identity\"", "}", ")", ":", "\n", "        ", "E", "=", "tf", ".", "stop_gradient", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "x", ")", ")", ")", "\n", "return", "tf", ".", "sign", "(", "x", "/", "E", ")", "*", "E", "\n", "", "x", "=", "tf", ".", "tanh", "(", "x", ")", "\n", "x", "=", "x", "/", "tf", ".", "reduce_max", "(", "tf", ".", "abs", "(", "x", ")", ")", "*", "0.5", "+", "0.5", "\n", "return", "2", "*", "quantize", "(", "x", ",", "bitW", ")", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.remap_variables": [[264, 286], ["custom_getter_scope", "getter", "fn"], "function", ["None"], ["", "def", "remap_variables", "(", "fn", ")", ":", "\n", "    ", "\"\"\"\n    Use fn to map the output of any variable getter.\n\n    Args:\n        fn (tf.Variable -> tf.Tensor)\n\n    Returns:\n        a context where all the variables will be mapped by fn.\n\n    Example:\n        .. code-block:: python\n\n            with varreplace.remap_variables(lambda var: quantize(var)):\n                x = FullyConnected('fc', x, 1000)   # fc/{W,b} will be quantized\n    \"\"\"", "\n", "\n", "def", "custom_getter", "(", "getter", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "v", "=", "getter", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "fn", "(", "v", ")", "\n", "\n", "", "return", "custom_getter_scope", "(", "custom_getter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.custom_getter": [[288, 291], ["getter", "ops.fw"], "function", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.fw"], ["", "def", "custom_getter", "(", "getter", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "v", "=", "getter", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "fw", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.binarize": [[296, 306], ["tf.get_default_graph", "tensorflow.python.framework.ops.name_scope", "tf.get_default_graph.gradient_override_map", "tf.clip_by_value", "tf.ceil"], "function", ["None"], ["", "def", "binarize", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    Clip and binarize tensor using the straight through estimator (STE) for the gradient.\n    \"\"\"", "\n", "g", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "\n", "with", "ops", ".", "name_scope", "(", "\"Binarized\"", ")", "as", "name", ":", "\n", "        ", "with", "g", ".", "gradient_override_map", "(", "{", "\"Ceil\"", ":", "\"Identity\"", "}", ")", ":", "\n", "            ", "x", "=", "tf", ".", "clip_by_value", "(", "x", ",", "-", "0.8", ",", "0.8", ")", "\n", "return", "tf", ".", "ceil", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.bc_conv2d": [[308, 334], ["x.get_shape().as_list", "tf.variable_op_scope", "tf.get_variable", "ops.binarize", "tf.nn.conv2d", "visualize_tensor.put_kernels_on_grid", "tf.summary.image", "tf.summary.histogram", "tf.get_variable", "tf.nn.bias_add", "x.get_shape", "tf.contrib.layers.xavier_initializer_conv2d"], "function", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.binarize", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.visualize_tensor.put_kernels_on_grid"], ["", "", "", "def", "bc_conv2d", "(", "x", ",", "nOutputPlane", ",", "kW", ",", "kH", ",", "dW", "=", "1", ",", "dH", "=", "1", ",", "padding", "=", "'VALID'", ",", "bias", "=", "False", ",", "reuse", "=", "None", ",", "\n", "name", "=", "'BinarizedWeightOnlySpatialConvolution'", ",", "is_training", "=", "True", ")", ":", "\n", "    ", "nInputPlane", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "3", "]", "\n", "with", "tf", ".", "variable_op_scope", "(", "[", "x", "]", ",", "None", ",", "name", ",", "reuse", "=", "reuse", ")", ":", "\n", "# Random weights initialisation", "\n", "        ", "w", "=", "tf", ".", "get_variable", "(", "'weight'", ",", "[", "kH", ",", "kW", ",", "nInputPlane", ",", "nOutputPlane", "]", ",", "\n", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer_conv2d", "(", ")", ")", "\n", "# # Bernoulli weights initialisation", "\n", "# bernoulli = tf.distributions.Bernoulli(probs=0.5)", "\n", "# matrix = bernoulli.sample([1, nOutputPlane, kH, kW])", "\n", "# matrix = tf.cast(matrix, tf.float32)", "\n", "# matrix = tf.transpose(matrix, [2, 3, 0, 1])", "\n", "# w = tf.Variable(matrix, trainable=True, name='mask')", "\n", "\n", "bin_w", "=", "binarize", "(", "w", ")", "\n", "out", "=", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "bin_w", ",", "strides", "=", "[", "1", ",", "dH", ",", "dW", ",", "1", "]", ",", "padding", "=", "padding", ")", "\n", "\n", "# Visualise weights in TensorBoard", "\n", "grid", "=", "put_kernels_on_grid", "(", "bin_w", ")", "\n", "tf", ".", "summary", ".", "image", "(", "'linear_mapping/binary_kernels'", ",", "grid", ",", "max_outputs", "=", "3", ")", "\n", "tf", ".", "summary", ".", "histogram", "(", "\"linear_mapping/binary_kernels\"", ",", "bin_w", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "b", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "nOutputPlane", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", ")", "\n", "out", "=", "tf", ".", "nn", ".", "bias_add", "(", "out", ",", "b", ")", "\n", "", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.main.main": [[70, 77], ["solver.Solver", "solver.Solver.train", "solver.Solver.test"], "function", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.solver.Solver.train", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.solver.Solver.test"], ["def", "main", "(", "_", ")", ":", "\n", "    ", "solver", "=", "Solver", "(", ")", "\n", "\n", "if", "conf", ".", "train_only", ":", "\n", "        ", "solver", ".", "train", "(", ")", "\n", "", "elif", "conf", ".", "test_only", ":", "\n", "        ", "solver", ".", "test", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10.__init__": [[47, 83], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# Directory where you want to download and save the data-set.", "\n", "# Set this before you start calling any of the functions below.", "\n", "        ", "self", ".", "data_path", "=", "conf", ".", "cifar10_path", "\n", "\n", "# URL for the data-set on the internet.", "\n", "self", ".", "data_url", "=", "\"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"", "\n", "\n", "########################################################################", "\n", "# Various constants for the size of the images.", "\n", "# Use these constants in your own program.", "\n", "\n", "# Width and height of each image.", "\n", "self", ".", "img_size", "=", "32", "\n", "\n", "# Number of channels in each image, 3 channels: Red, Green, Blue.", "\n", "self", ".", "num_channels", "=", "3", "\n", "\n", "# Length of an image when flattened to a 1-dim array.", "\n", "self", ".", "img_size_flat", "=", "self", ".", "img_size", "*", "self", ".", "img_size", "*", "self", ".", "num_channels", "\n", "\n", "# Number of classes.", "\n", "self", ".", "num_classes", "=", "10", "\n", "\n", "########################################################################", "\n", "# Various constants used to allocate arrays of the correct size.", "\n", "\n", "# Number of files for the training-set.", "\n", "self", ".", "_num_files_train", "=", "5", "\n", "\n", "# Number of images for each batch-file in the training-set.", "\n", "self", ".", "_images_per_file", "=", "10000", "\n", "\n", "# Total number of images in the training-set.", "\n", "# This is used to pre-allocate arrays for efficiency.", "\n", "self", ".", "_num_images_train", "=", "self", ".", "_num_files_train", "*", "self", ".", "_images_per_file", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10.load_dataset": [[84, 121], ["data_reader_cifar10.Cifar10.load_training_data", "data_reader_cifar10.Cifar10.normalize_imgs_fn", "tensorflow.image.resize_images", "tensorflow.image.resize_images", "tensorflow.cast", "tensorflow.cast", "data_reader_cifar10.Cifar10.load_test_data", "data_reader_cifar10.Cifar10.normalize_imgs_fn", "tensorflow.image.resize_images", "tensorflow.image.resize_images", "tensorflow.cast", "tensorflow.cast", "sess.run", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10.load_training_data", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.normalize_imgs_fn", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10.load_test_data", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.normalize_imgs_fn"], ["", "def", "load_dataset", "(", "self", ",", "sess", ")", ":", "\n", "# Train", "\n", "        ", "hr_all_images", ",", "_", "=", "self", ".", "load_training_data", "(", ")", "\n", "hr_images", "=", "hr_all_images", "[", ":", "conf", ".", "num_train_images", "]", "\n", "del", "hr_all_images", "\n", "\n", "hr_images", "=", "self", ".", "normalize_imgs_fn", "(", "hr_images", ")", "\n", "hr_images", "=", "tf", ".", "image", ".", "resize_images", "(", "hr_images", ",", "[", "conf", ".", "hr_size", ",", "conf", ".", "hr_size", "]", ")", "\n", "lr_images", "=", "tf", ".", "image", ".", "resize_images", "(", "hr_images", ",", "[", "conf", ".", "lr_size", ",", "conf", ".", "lr_size", "]", ")", "\n", "hr_images", "=", "tf", ".", "cast", "(", "hr_images", ",", "tf", ".", "float32", ")", "\n", "lr_images", "=", "tf", ".", "cast", "(", "lr_images", ",", "tf", ".", "float32", ")", "\n", "if", "conf", ".", "img_channel", "==", "1", ":", "\n", "            ", "hr_images", "=", "hr_images", "[", ":", ",", ":", ",", ":", ",", "1", "]", "\n", "lr_images", "=", "lr_images", "[", ":", ",", ":", ",", ":", ",", "1", "]", "\n", "hr_images", "=", "tf", ".", "reshape", "(", "hr_images", ",", "shape", "=", "[", "conf", ".", "num_train_images", ",", "conf", ".", "hr_size", ",", "conf", ".", "hr_size", ",", "1", "]", ")", "\n", "lr_images", "=", "tf", ".", "reshape", "(", "lr_images", ",", "shape", "=", "[", "conf", ".", "num_train_images", ",", "conf", ".", "lr_size", ",", "conf", ".", "lr_size", ",", "1", "]", ")", "\n", "\n", "# Val", "\n", "", "val_hr_all_images", ",", "_", "=", "self", ".", "load_test_data", "(", ")", "\n", "val_hr_images", "=", "val_hr_all_images", "[", ":", "conf", ".", "num_val_images", "]", "\n", "del", "val_hr_all_images", "\n", "\n", "val_hr_images", "=", "self", ".", "normalize_imgs_fn", "(", "val_hr_images", ")", "\n", "val_hr_images", "=", "tf", ".", "image", ".", "resize_images", "(", "val_hr_images", ",", "[", "conf", ".", "hr_size", ",", "conf", ".", "hr_size", "]", ")", "\n", "val_lr_images", "=", "tf", ".", "image", ".", "resize_images", "(", "val_hr_images", ",", "[", "conf", ".", "lr_size", ",", "conf", ".", "lr_size", "]", ")", "\n", "val_hr_images", "=", "tf", ".", "cast", "(", "val_hr_images", ",", "tf", ".", "float32", ")", "\n", "val_lr_images", "=", "tf", ".", "cast", "(", "val_lr_images", ",", "tf", ".", "float32", ")", "\n", "if", "conf", ".", "img_channel", "==", "1", ":", "\n", "            ", "val_hr_images", "=", "val_hr_images", "[", ":", ",", ":", ",", ":", ",", "1", "]", "\n", "val_lr_images", "=", "val_lr_images", "[", ":", ",", ":", ",", ":", ",", "1", "]", "\n", "val_hr_images", "=", "tf", ".", "reshape", "(", "val_hr_images", ",", "shape", "=", "[", "conf", ".", "num_val_images", ",", "conf", ".", "hr_size", ",", "conf", ".", "hr_size", ",", "1", "]", ")", "\n", "val_lr_images", "=", "tf", ".", "reshape", "(", "val_lr_images", ",", "shape", "=", "[", "conf", ".", "num_val_images", ",", "conf", ".", "lr_size", ",", "conf", ".", "lr_size", ",", "1", "]", ")", "\n", "\n", "", "hr_images", ",", "lr_images", ",", "val_hr_images", ",", "val_lr_images", "=", "sess", ".", "run", "(", "\n", "[", "hr_images", ",", "lr_images", ",", "val_hr_images", ",", "val_lr_images", "]", ")", "\n", "\n", "return", "hr_images", ",", "lr_images", ",", "val_hr_images", ",", "val_lr_images", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10._get_file_path": [[125, 132], ["os.path.join"], "methods", ["None"], ["", "def", "_get_file_path", "(", "self", ",", "filename", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Return the full path of a data-file for the data-set.\n        If filename==\"\" then return the directory of the files.\n        \"\"\"", "\n", "\n", "return", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "\"cifar-10-batches-py/\"", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10._unpickle": [[133, 151], ["data_reader_cifar10.Cifar10._get_file_path", "print", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10._get_file_path"], ["", "def", "_unpickle", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\"\n        Unpickle the given file and return the data.\n        Note that the appropriate dir-name is prepended the filename.\n        \"\"\"", "\n", "\n", "# Create full path for the file.", "\n", "file_path", "=", "self", ".", "_get_file_path", "(", "filename", ")", "\n", "\n", "print", "(", "\"Loading data: \"", "+", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ",", "mode", "=", "'rb'", ")", "as", "file", ":", "\n", "# In Python 3.X it is important to set the encoding,", "\n", "# otherwise an exception is raised here.", "\n", "            ", "data", "=", "pickle", ".", "load", "(", "file", ")", "\n", "# data = pickle.load(file, encoding='bytes')", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10._convert_images": [[152, 169], ["numpy.array", "numpy.array.reshape", "images.transpose.transpose.transpose"], "methods", ["None"], ["", "def", "_convert_images", "(", "self", ",", "raw", ")", ":", "\n", "        ", "\"\"\"\n        Convert images from the CIFAR-10 format and\n        return a 4-dim array with shape: [image_number, height, width, channel]\n        where the pixels are floats between 0.0 and 1.0.\n        \"\"\"", "\n", "\n", "# Convert the raw images from the data-files to floating-points.", "\n", "raw_float", "=", "np", ".", "array", "(", "raw", ",", "dtype", "=", "float", ")", "\n", "\n", "# Reshape the array to 4-dimensions.", "\n", "images", "=", "raw_float", ".", "reshape", "(", "[", "-", "1", ",", "self", ".", "num_channels", ",", "self", ".", "img_size", ",", "self", ".", "img_size", "]", ")", "\n", "\n", "# Reorder the indices of the array.", "\n", "images", "=", "images", ".", "transpose", "(", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10._load_data": [[170, 190], ["data_reader_cifar10.Cifar10._unpickle", "numpy.array", "data_reader_cifar10.Cifar10._convert_images"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10._unpickle", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10._convert_images"], ["", "def", "_load_data", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\"\n        Load a pickled data-file from the CIFAR-10 data-set\n        and return the converted images (see above) and the class-number\n        for each image.\n        \"\"\"", "\n", "\n", "# Load the pickled data-file.", "\n", "data", "=", "self", ".", "_unpickle", "(", "filename", ")", "\n", "\n", "# Get the raw images.", "\n", "raw_images", "=", "data", "[", "b'data'", "]", "\n", "\n", "# Get the class-numbers for each image. Convert to numpy-array.", "\n", "cls", "=", "np", ".", "array", "(", "data", "[", "b'labels'", "]", ")", "\n", "\n", "# Convert the images.", "\n", "images", "=", "self", ".", "_convert_images", "(", "raw_images", ")", "\n", "\n", "return", "images", ",", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10.load_training_data": [[195, 230], ["numpy.zeros", "numpy.zeros", "range", "data_reader_cifar10.Cifar10._load_data", "len", "str"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10._load_data"], ["", "def", "load_training_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Load all the training-data for the CIFAR-10 data-set.\n        The data-set is split into 5 data-files which are merged here.\n        Returns the images, class-numbers and one-hot encoded class-labels.\n        \"\"\"", "\n", "\n", "# Pre-allocate the arrays for the images and class-numbers for efficiency.", "\n", "images", "=", "np", ".", "zeros", "(", "shape", "=", "[", "self", ".", "_num_images_train", ",", "self", ".", "img_size", ",", "self", ".", "img_size", ",", "self", ".", "num_channels", "]", ",", "dtype", "=", "float", ")", "\n", "cls", "=", "np", ".", "zeros", "(", "shape", "=", "[", "self", ".", "_num_images_train", "]", ",", "dtype", "=", "int", ")", "\n", "\n", "# Begin-index for the current batch.", "\n", "begin", "=", "0", "\n", "\n", "# For each data-file.", "\n", "for", "i", "in", "range", "(", "self", ".", "_num_files_train", ")", ":", "\n", "# Load the images and class-numbers from the data-file.", "\n", "            ", "images_batch", ",", "cls_batch", "=", "self", ".", "_load_data", "(", "filename", "=", "\"data_batch_\"", "+", "str", "(", "i", "+", "1", ")", ")", "\n", "\n", "# Number of images in this batch.", "\n", "num_images", "=", "len", "(", "images_batch", ")", "\n", "\n", "# End-index for the current batch.", "\n", "end", "=", "begin", "+", "num_images", "\n", "\n", "# Store the images into the array.", "\n", "images", "[", "begin", ":", "end", ",", ":", "]", "=", "images_batch", "\n", "\n", "# Store the class-numbers into the array.", "\n", "cls", "[", "begin", ":", "end", "]", "=", "cls_batch", "\n", "\n", "# The begin-index for the next batch is the current end-index.", "\n", "begin", "=", "end", "\n", "\n", "", "return", "images", ",", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10.load_test_data": [[231, 240], ["data_reader_cifar10.Cifar10._load_data"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10._load_data"], ["", "def", "load_test_data", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Load all the test-data for the CIFAR-10 data-set.\n        Returns the images, class-numbers and one-hot encoded class-labels.\n        \"\"\"", "\n", "\n", "images", ",", "cls", "=", "self", ".", "_load_data", "(", "filename", "=", "\"test_batch\"", ")", "\n", "\n", "return", "images", ",", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader_cifar10.Cifar10.normalize_imgs_fn": [[241, 245], ["None"], "methods", ["None"], ["", "def", "normalize_imgs_fn", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "*", "(", "2.", "/", "255.", ")", "-", "1.", "\n", "# x = x * (1./255.)", "\n", "return", "x", "\n", "########################################################################", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.solver.Solver.__init__": [[18, 26], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# Initialize  results saving path: model_dir, validate_dir, test_dir", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "conf", ".", "model_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "conf", ".", "model_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "conf", ".", "validate_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "conf", ".", "validate_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "conf", ".", "test_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "conf", ".", "test_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.solver.Solver.train": [[27, 167], ["tf.ConfigProto", "tf.Session", "print", "tf.get_variable", "tf.summary.merge_all", "tf.summary.FileWriter", "tf.train.exponential_decay", "tf.train.AdamOptimizer", "tf.get_collection", "tf.train.Saver", "tf.train.Saver", "tf.group", "tf.Session.run", "print", "tf.Session.close", "print", "tf.device", "tf.placeholder", "tf.placeholder", "net.Net", "tf.train.AdamOptimizer.minimize", "tf.train.Saver.restore", "tf.train.AdamOptimizer.minimize", "tf.train.AdamOptimizer.minimize", "tf.global_variables_initializer", "tf.local_variables_initializer", "str", "tf.placeholder", "tf.placeholder", "tf.data.Dataset.from_tensor_slices", "dataset.repeat().shuffle().batch.repeat().shuffle().batch.repeat().shuffle().batch", "dataset.repeat().shuffle().batch.repeat().shuffle().batch.make_initializable_iterator", "solver.Solver.iterator.get_next", "tf.placeholder", "tf.placeholder", "tf.data.Dataset.from_tensor_slices", "val_dataset.repeat().batch.repeat().batch.repeat().batch", "val_dataset.repeat().batch.repeat().batch.make_initializable_iterator", "solver.Solver.val_iterator.get_next", "tf.Session.run", "tf.Session.run", "tf.constant_initializer", "tf.get_collection", "tf.train.Saver", "tf.train.Saver.restore", "tf.get_collection", "tf.train.Saver", "tf.train.Saver.restore", "tf.get_collection", "tf.train.AdamOptimizer.minimize", "tf.Session.run", "print", "data_reader_cifar10.Cifar10", "data_reader_cifar10.Cifar10.load_dataset", "time.time", "tf.Session.run", "time.time", "tf.summary.FileWriter.add_summary", "print", "time.time", "tf.Session.run", "time.time", "print", "tf.Session.run", "solver.Solver.validate", "os.path.join", "tf.train.Saver.save", "data_reader.DataSet", "data_reader.DataSet.load_file_list", "data_reader.DataSet.load_dataset", "print", "dataset.repeat().shuffle().batch.repeat().shuffle().batch.repeat().shuffle", "val_dataset.repeat().batch.repeat().batch.repeat", "dataset.repeat().shuffle().batch.repeat().shuffle().batch.repeat"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.load_dataset", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.solver.Solver.validate", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.load_file_list", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.load_dataset"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "# Create Session", "\n", "        ", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "\n", "# Initialize gpu device name", "\n", "if", "conf", ".", "use_gpu", ":", "\n", "            ", "device_str", "=", "'/gpu:'", "+", "str", "(", "conf", ".", "device_id", ")", "\n", "", "else", ":", "\n", "            ", "device_str", "=", "'/cpu:0'", "\n", "\n", "", "with", "tf", ".", "device", "(", "device_str", ")", ":", "\n", "# Initialize data loader", "\n", "            ", "if", "conf", ".", "train_only", ":", "\n", "                ", "if", "conf", ".", "dataset", "==", "'cifar10'", ":", "\n", "                    ", "cifar10", "=", "Cifar10", "(", ")", "\n", "self", ".", "train_hr", ",", "self", ".", "train_lr", ",", "self", ".", "val_hr", ",", "self", ".", "val_lr", "=", "cifar10", ".", "load_dataset", "(", "sess", ")", "\n", "", "elif", "conf", ".", "dataset", "==", "'DIV2K'", "or", "'MNIST'", ":", "\n", "                    ", "div2k", "=", "DataSet", "(", ")", "\n", "self", ".", "train_hr_file_list", ",", "self", ".", "train_lr_file_list", ",", "self", ".", "valid_hr_file_list", ",", "self", ".", "valid_lr_file_list", "=", "div2k", ".", "load_file_list", "(", "\n", "conf", ".", "train_hr_list", ",", "conf", ".", "train_lr_list", ",", "conf", ".", "val_hr_list", ",", "conf", ".", "val_lr_list", ")", "\n", "self", ".", "train_hr", ",", "self", ".", "train_lr", ",", "self", ".", "val_hr", ",", "self", ".", "val_lr", "=", "div2k", ".", "load_dataset", "(", "self", ".", "train_hr_file_list", ",", "\n", "self", ".", "train_lr_file_list", ",", "\n", "self", ".", "valid_hr_file_list", ",", "\n", "self", ".", "valid_lr_file_list", ",", "\n", "sess", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "\"No dataset specified.\"", ")", "\n", "return", "\n", "\n", "# Train", "\n", "", "self", ".", "img_hr", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "self", ".", "img_lr", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "self", ".", "img_hr", ",", "self", ".", "img_lr", ")", ")", "\n", "dataset", "=", "dataset", ".", "repeat", "(", "conf", ".", "num_epoch", ")", ".", "shuffle", "(", "buffer_size", "=", "conf", ".", "shuffle_size", ")", ".", "batch", "(", "conf", ".", "batch_size", ")", "\n", "self", ".", "iterator", "=", "dataset", ".", "make_initializable_iterator", "(", ")", "\n", "self", ".", "next_batch", "=", "self", ".", "iterator", ".", "get_next", "(", ")", "\n", "\n", "# Val", "\n", "self", ".", "val_img_hr", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "self", ".", "val_img_lr", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "val_dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "self", ".", "val_img_hr", ",", "self", ".", "val_img_lr", ")", ")", "\n", "val_dataset", "=", "val_dataset", ".", "repeat", "(", ")", ".", "batch", "(", "conf", ".", "batch_size", ")", "\n", "self", ".", "val_iterator", "=", "val_dataset", ".", "make_initializable_iterator", "(", ")", "\n", "self", ".", "val_next_batch", "=", "self", ".", "val_iterator", ".", "get_next", "(", ")", "\n", "\n", "# Initialize data stream", "\n", "sess", ".", "run", "(", "self", ".", "iterator", ".", "initializer", ",", "feed_dict", "=", "{", "self", ".", "img_hr", ":", "self", ".", "train_hr", ",", "self", ".", "img_lr", ":", "self", ".", "train_lr", "}", ")", "\n", "sess", ".", "run", "(", "self", ".", "val_iterator", ".", "initializer", ",", "feed_dict", "=", "{", "self", ".", "val_img_hr", ":", "self", ".", "val_hr", ",", "self", ".", "val_img_lr", ":", "self", ".", "val_lr", "}", ")", "\n", "", "if", "conf", ".", "test_only", ":", "\n", "                ", "pass", "\n", "\n", "# Initialize network", "\n", "", "self", ".", "labels", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "conf", ".", "batch_size", ",", "conf", ".", "hr_size", ",", "conf", ".", "hr_size", ",", "conf", ".", "img_channel", "]", ")", "\n", "self", ".", "inputs", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "conf", ".", "batch_size", ",", "conf", ".", "lr_size", ",", "conf", ".", "lr_size", ",", "conf", ".", "img_channel", "]", ")", "\n", "self", ".", "net", "=", "Net", "(", "self", ".", "labels", ",", "self", ".", "inputs", ",", "mask_type", "=", "conf", ".", "mask_type", ",", "\n", "is_linear_only", "=", "conf", ".", "linear_mapping_only", ",", "scope", "=", "'sr_spc'", ")", "\n", "\n", "", "print", "(", "\"----- Done Initialization -----\"", ")", "\n", "\n", "self", ".", "global_step", "=", "tf", ".", "get_variable", "(", "'global_step'", ",", "[", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", ",", "trainable", "=", "False", ")", "\n", "\n", "summary_op", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "conf", ".", "model_dir", ",", "sess", ".", "graph", ")", "\n", "\n", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "conf", ".", "learning_rate", ",", "\n", "self", ".", "global_step", ",", "\n", "decay_steps", "=", "conf", ".", "decay_steps", ",", "\n", "decay_rate", "=", "conf", ".", "decay_rate", ",", "\n", "staircase", "=", "True", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", ")", "\n", "\n", "variables_list", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "'sr_spc'", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "variables_list", ")", "\n", "\n", "restorer", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "if", "conf", ".", "linear_mapping_only", ":", "\n", "            ", "if", "conf", ".", "restore_linear_part", ":", "\n", "                ", "linear_mapping_variables", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "\n", "scope", "=", "'sr_spc/linear_mapping'", ")", "\n", "linear_restorer", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "linear_mapping_variables", ")", "\n", "linear_restorer", ".", "restore", "(", "sess", ",", "conf", ".", "linear_model", ")", "\n", "", "train_op", "=", "optimizer", ".", "minimize", "(", "self", ".", "net", ".", "loss", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "", "elif", "conf", ".", "train_residual_only", ":", "\n", "            ", "linear_mapping_variables", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "'sr_spc/linear_mapping'", ")", "\n", "linear_restorer", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "linear_mapping_variables", ")", "\n", "linear_restorer", ".", "restore", "(", "sess", ",", "conf", ".", "linear_model", ")", "\n", "first_train_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "'sr_spc/residual_blocks'", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "self", ".", "net", ".", "loss", ",", "global_step", "=", "self", ".", "global_step", ",", "var_list", "=", "first_train_vars", ")", "\n", "", "if", "conf", ".", "restore_whole_model", ":", "\n", "            ", "restorer", ".", "restore", "(", "sess", ",", "conf", ".", "whole_model", ")", "\n", "train_op", "=", "optimizer", ".", "minimize", "(", "self", ".", "net", ".", "loss", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "", "else", ":", "\n", "            ", "train_op", "=", "optimizer", ".", "minimize", "(", "self", ".", "net", ".", "loss", ",", "global_step", "=", "self", ".", "global_step", ")", "\n", "\n", "", "init_op", "=", "tf", ".", "group", "(", "tf", ".", "global_variables_initializer", "(", ")", ",", "tf", ".", "local_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "init_op", ")", "\n", "\n", "# saver.restore(sess, conf.whole_model)", "\n", "\n", "print", "(", "\"----- Hyperparameter initialized. Begin training -----\"", ")", "\n", "\n", "# Start training", "\n", "iters", "=", "1", "\n", "try", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "hr_img", ",", "lr_img", "=", "sess", ".", "run", "(", "self", ".", "next_batch", ")", "\n", "# Calculate and optimize loss", "\n", "if", "iters", "%", "100", "==", "0", ":", "\n", "                    ", "t1", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "loss", ",", "summary_str", "=", "sess", ".", "run", "(", "[", "train_op", ",", "self", ".", "net", ".", "loss", ",", "summary_op", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "labels", ":", "hr_img", ",", "self", ".", "inputs", ":", "lr_img", "}", ")", "\n", "t2", "=", "time", ".", "time", "(", ")", "\n", "summary_writer", ".", "add_summary", "(", "summary_str", ",", "iters", ")", "\n", "print", "(", "'step %d, loss = %.2f (%.1f examples/sec; %.3f sec/batch)'", "%", "\n", "(", "iters", ",", "loss", ",", "conf", ".", "batch_size", "/", "(", "t2", "-", "t1", ")", ",", "(", "t2", "-", "t1", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "t1", "=", "time", ".", "time", "(", ")", "\n", "_", ",", "loss", "=", "sess", ".", "run", "(", "[", "train_op", ",", "self", ".", "net", ".", "loss", "]", ",", "feed_dict", "=", "{", "self", ".", "labels", ":", "hr_img", ",", "self", ".", "inputs", ":", "lr_img", "}", ")", "\n", "t2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'step %d, loss = %.2f (%.1f examples/sec; %.3f sec/batch)'", "%", "\n", "(", "iters", ",", "loss", ",", "conf", ".", "batch_size", "/", "(", "t2", "-", "t1", ")", ",", "(", "t2", "-", "t1", ")", ")", ")", "\n", "", "iters", "+=", "1", "\n", "\n", "# Run validation", "\n", "if", "iters", "%", "100", "==", "0", ":", "\n", "                    ", "val_hr_img", ",", "val_lr_img", "=", "sess", ".", "run", "(", "self", ".", "val_next_batch", ")", "\n", "self", ".", "validate", "(", "sess", ",", "val_hr_img", ",", "val_lr_img", ",", "summary_writer", ",", "iters", ")", "\n", "\n", "# Save module", "\n", "", "if", "iters", "%", "100", "==", "0", ":", "\n", "                    ", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "conf", ".", "model_dir", ",", "'model.ckpt'", ")", "\n", "saver", ".", "save", "(", "sess", ",", "checkpoint_path", ",", "global_step", "=", "iters", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "            ", "print", "(", "'Epoch limit reached'", ")", "\n", "\n", "# Close session", "\n", "", "sess", ".", "close", "(", ")", "\n", "print", "(", "'----- Done Training -----'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.solver.Solver.validate": [[168, 217], ["solver.Solver.net.compute_charbonnier_loss", "time.time", "sess.run", "time.time", "tf.Summary", "summary_writer.add_summary", "tl.vis.save_images", "tl.vis.save_images", "np.zeros", "range", "np.mean", "open", "csv.writer", "csv.writer.writerow", "open.close", "print", "tf.clip_by_value", "tf.clip_by_value", "tf.Summary.value.add", "tf.Summary.value.add", "skimage.measure.compare_psnr", "int", "int", "int", "int", "np.ceil", "np.ceil", "str", "np.ceil", "np.ceil", "str", "sqrt", "sqrt", "sqrt", "sqrt"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.Net.compute_charbonnier_loss"], ["", "def", "validate", "(", "self", ",", "sess", ",", "hr_img", ",", "lr_img", ",", "summary_writer", ",", "step", ")", ":", "\n", "        ", "if", "conf", ".", "linear_mapping_only", ":", "\n", "            ", "linear_mapping_logits", "=", "self", ".", "net", ".", "linear_mapping_logits", "\n", "img_output", "=", "tf", ".", "clip_by_value", "(", "linear_mapping_logits", ",", "-", "1.0", ",", "1.0", ")", "\n", "", "else", ":", "\n", "            ", "residual_reducing_logits", "=", "self", ".", "net", ".", "net_image1", ".", "outputs", "\n", "img_output", "=", "tf", ".", "clip_by_value", "(", "residual_reducing_logits", ",", "-", "1.0", ",", "1.0", ")", "\n", "\n", "# if conf.charbonnier_loss:", "\n", "#     loss = self.net.compute_charbonnier_loss(hr_img, img_output, is_mean=True)", "\n", "# else:", "\n", "#     loss = tf.reduce_mean(tf.nn.l2_loss(tf.losses.absolute_difference(hr_img, img_output)))", "\n", "# recon_loss = tf.reduce_mean(tf.reduce_sum(tf.square(img_output - hr_img), axis=1))", "\n", "\n", "", "recon_loss", "=", "self", ".", "net", ".", "compute_charbonnier_loss", "(", "hr_img", ",", "img_output", ",", "is_mean", "=", "True", ")", "\n", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "output", ",", "loss_val", "=", "sess", ".", "run", "(", "[", "img_output", ",", "recon_loss", "]", ",", "feed_dict", "=", "{", "self", ".", "labels", ":", "hr_img", ",", "self", ".", "inputs", ":", "lr_img", "}", ")", "\n", "t2", "=", "time", ".", "time", "(", ")", "\n", "\n", "process_time", "=", "conf", ".", "batch_size", "/", "(", "t2", "-", "t1", ")", "\n", "\n", "valid_summary", "=", "tf", ".", "Summary", "(", ")", "\n", "if", "conf", ".", "linear_mapping_only", ":", "\n", "            ", "valid_summary", ".", "value", ".", "add", "(", "tag", "=", "'linear_loss_val'", ",", "simple_value", "=", "loss_val", ")", "\n", "", "else", ":", "\n", "            ", "valid_summary", ".", "value", ".", "add", "(", "tag", "=", "'residual_loss_val'", ",", "simple_value", "=", "loss_val", ")", "\n", "", "summary_writer", ".", "add_summary", "(", "valid_summary", ",", "step", ")", "\n", "\n", "# Save validated images", "\n", "tl", ".", "vis", ".", "save_images", "(", "hr_img", ",", "[", "int", "(", "np", ".", "ceil", "(", "sqrt", "(", "conf", ".", "batch_size", ")", ")", ")", ",", "int", "(", "np", ".", "ceil", "(", "sqrt", "(", "conf", ".", "batch_size", ")", ")", ")", "]", ",", "\n", "conf", ".", "validate_dir", "+", "'/hr_'", "+", "str", "(", "step", ")", "+", "'.png'", ")", "\n", "tl", ".", "vis", ".", "save_images", "(", "output", ",", "[", "int", "(", "np", ".", "ceil", "(", "sqrt", "(", "conf", ".", "batch_size", ")", ")", ")", ",", "int", "(", "np", ".", "ceil", "(", "sqrt", "(", "conf", ".", "batch_size", ")", ")", ")", "]", ",", "\n", "conf", ".", "validate_dir", "+", "'/generate_'", "+", "str", "(", "step", ")", "+", "'.png'", ")", "\n", "\n", "# Measure PSNR", "\n", "img_psnr", "=", "np", ".", "zeros", "(", "12", ")", "\n", "for", "i", "in", "range", "(", "11", ")", ":", "\n", "            ", "img_psnr", "[", "i", "]", "=", "skimage", ".", "measure", ".", "compare_psnr", "(", "hr_img", "[", "i", "]", ",", "output", "[", "i", "]", ")", "\n", "\n", "", "img_psnr", "[", "-", "1", "]", "=", "np", ".", "mean", "(", "img_psnr", "[", ":", "11", "]", ")", "\n", "\n", "# Save processing time, PSNR", "\n", "write_file_obj", "=", "open", "(", "'metrics.csv'", ",", "'a'", ")", "\n", "writer", "=", "csv", ".", "writer", "(", "write_file_obj", ")", "\n", "writer", ".", "writerow", "(", "[", "step", ",", "loss_val", ",", "process_time", ",", "img_psnr", "]", ")", "\n", "write_file_obj", ".", "close", "(", ")", "\n", "\n", "print", "(", "'----- Done Validation -----'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.solver.Solver.test": [[218, 220], ["None"], "methods", ["None"], ["", "def", "test", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.Net.__init__": [[14, 20], ["tf.variable_scope", "net.Net.construct_net"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.Net.construct_net"], ["    ", "def", "__init__", "(", "self", ",", "hr_img", ",", "lr_img", ",", "mask_type", ",", "is_linear_only", ",", "scope", "=", "None", ")", ":", "\n", "# Initialize all parameters here", "\n", "        ", "self", ".", "hr_images", "=", "hr_img", "\n", "self", ".", "lr_images", "=", "lr_img", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", "as", "scope", ":", "\n", "            ", "self", ".", "construct_net", "(", "hr_img", ",", "lr_img", ",", "mask_type", ",", "is_linear_only", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.Net.linear_mapping_network": [[21, 201], ["tf.variable_scope", "tf.contrib.layers.conv2d", "slim.conv2d", "slim.maxout", "slim.conv2d_transpose", "slim.conv2d", "slim.maxout", "slim.conv2d", "slim.maxout", "slim.conv2d", "tf.summary.image", "tf.distributions.Bernoulli", "tf.distributions.Bernoulli.sample", "tf.cast", "tf.transpose", "tf.Variable", "tf.nn.conv2d", "slim.arg_scope", "slim.conv2d_transpose", "ops.bc_conv2d", "tf.contrib.layers.l1_regularizer", "tf.zeros_initializer", "tf.contrib.layers.l1_regularizer", "tf.zeros_initializer", "tf.contrib.layers.l1_regularizer", "tf.zeros_initializer", "tf.contrib.layers.l1_regularizer", "tf.zeros_initializer", "tf.get_variable", "tf.nn.conv2d", "tf.nn.dropout", "tf.multiply", "tf.constant_initializer", "slim.l2_regularizer", "tf.ones_initializer"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.bc_conv2d"], ["", "", "def", "linear_mapping_network", "(", "self", ",", "inputs", ",", "mask_type", ")", ":", "\n", "        ", "measurements", "=", "[", "]", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'linear_mapping'", ")", "as", "scope", ":", "\n", "# Sample", "\n", "            ", "if", "mask_type", "==", "'trained'", ":", "\n", "                ", "measurements", "=", "tf", ".", "contrib", ".", "layers", ".", "conv2d", "(", "inputs", ",", "\n", "num_outputs", "=", "conf", ".", "num_measure", ",", "\n", "kernel_size", "=", "conf", ".", "lr_size", ",", "\n", "padding", "=", "'VALID'", ",", "\n", "activation_fn", "=", "None", ",", "\n", "biases_initializer", "=", "None", ",", "\n", "scope", "=", "\"sampling\"", ")", "\n", "", "elif", "mask_type", "==", "'Bernoulli'", ":", "\n", "                ", "bernoulli", "=", "tf", ".", "distributions", ".", "Bernoulli", "(", "probs", "=", "0.5", ")", "\n", "matrix", "=", "bernoulli", ".", "sample", "(", "[", "conf", ".", "img_channel", ",", "\n", "conf", ".", "num_measure", ",", "\n", "16", ",", "\n", "16", "]", ")", "# [image_channel, num_mask, mask_height, mask_width]", "\n", "matrix", "=", "tf", ".", "cast", "(", "matrix", ",", "tf", ".", "float32", ")", "\n", "matrix", "=", "tf", ".", "transpose", "(", "matrix", ",", "[", "2", ",", "3", ",", "0", ",", "1", "]", ")", "\n", "mask", "=", "tf", ".", "Variable", "(", "matrix", ",", "trainable", "=", "False", ",", "name", "=", "'mask'", ")", "\n", "measurements", "=", "tf", ".", "nn", ".", "conv2d", "(", "inputs", ",", "mask", ",", "strides", "=", "[", "1", ",", "8", ",", "8", ",", "1", "]", ",", "padding", "=", "\"SAME\"", ")", "\n", "", "elif", "mask_type", "==", "'trained_binary'", ":", "\n", "                ", "measurements", "=", "bc_conv2d", "(", "inputs", ",", "nOutputPlane", "=", "conf", ".", "num_measure", ",", "\n", "kW", "=", "conf", ".", "lr_size", ",", "kH", "=", "conf", ".", "lr_size", ",", "\n", "dW", "=", "1", ",", "dH", "=", "1", ",", "padding", "=", "'VALID'", ",", "bias", "=", "True", ",", "\n", "reuse", "=", "None", ",", "is_training", "=", "False", ",", "name", "=", "'BinarizedWeightOnlySpatialConvolution'", ")", "\n", "", "elif", "mask_type", "==", "'dropout'", ":", "\n", "# Method 1_1", "\n", "# mask = tf.get_variable('mask', shape=[1, 1, conf.img_channel, conf.num_measure], dtype=tf.float32,", "\n", "#                        initializer=tf.ones_initializer(), trainable=False)", "\n", "# measurements = tf.nn.conv2d(inputs, mask, strides=[1, 1, 1, 1], padding=\"VALID\")", "\n", "# measurements = tf.nn.dropout(measurements, keep_prob=conf.dropout, noise_shape=[1, conf.hr_size, conf.hr_size, conf.num_measure])", "\n", "# measurements = tf.multiply(measurements, conf.dropout)", "\n", "\n", "# # Method 2", "\n", "# mask = tf.get_variable('mask', shape=[3, 3, conf.img_channel, conf.num_measure], dtype=tf.float32,", "\n", "#                        initializer=tf.ones_initializer(), trainable=False)", "\n", "# measurements = tf.nn.conv2d(inputs, mask, strides=[1, 1, 1, 1], padding=\"VALID\")", "\n", "# measurements = tf.nn.dropout(measurements, keep_prob=conf.dropout, noise_shape=[1, 14, 14, conf.num_measure])", "\n", "# measurements = tf.multiply(measurements, conf.dropout)", "\n", "\n", "# # Method 3", "\n", "# mask = tf.get_variable('mask', shape=[1, 1, conf.img_channel, conf.num_measure], dtype=tf.float32,", "\n", "#                        initializer=tf.ones_initializer(), trainable=False)", "\n", "# measurements = tf.nn.conv2d(inputs, mask, strides=[1, 1, 1, 1], padding=\"VALID\")", "\n", "# measurements = tf.nn.dropout(measurements, keep_prob=conf.dropout,", "\n", "#                              noise_shape=[1, conf.hr_size, conf.hr_size, conf.num_measure])", "\n", "# measurements = tf.multiply(measurements, conf.dropout)", "\n", "# measurements = tf.reduce_sum(measurements,axis=[1,2],keep_dims=True)", "\n", "\n", "# Method 1_2", "\n", "                ", "mask", "=", "tf", ".", "get_variable", "(", "'mask'", ",", "shape", "=", "[", "8", ",", "8", ",", "conf", ".", "img_channel", ",", "conf", ".", "num_measure", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ",", "trainable", "=", "False", ")", "\n", "measurements", "=", "tf", ".", "nn", ".", "conv2d", "(", "inputs", ",", "mask", ",", "strides", "=", "[", "1", ",", "8", ",", "8", ",", "1", "]", ",", "padding", "=", "\"VALID\"", ")", "\n", "measurements", "=", "tf", ".", "nn", ".", "dropout", "(", "measurements", ",", "keep_prob", "=", "conf", ".", "dropout", ",", "noise_shape", "=", "[", "1", ",", "8", ",", "8", ",", "conf", ".", "num_measure", "]", ")", "\n", "measurements", "=", "tf", ".", "multiply", "(", "measurements", ",", "conf", ".", "dropout", ")", "\n", "\n", "# Reconstruct", "\n", "", "if", "mask_type", "==", "'dropout'", ":", "\n", "# Method 1", "\n", "                ", "input0", "=", "slim", ".", "conv2d", "(", "measurements", ",", "\n", "num_outputs", "=", "256", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "weights_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l1_regularizer", "(", "scale", "=", "1e-3", ")", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "activation_fn", "=", "None", ")", "\n", "input0", "=", "slim", ".", "maxout", "(", "input0", ",", "256", ")", "\n", "input1", "=", "slim", ".", "conv2d_transpose", "(", "input0", ",", "\n", "num_outputs", "=", "256", ",", "\n", "kernel_size", "=", "[", "16", ",", "16", "]", ",", "\n", "stride", "=", "8", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "activation_fn", "=", "None", ")", "\n", "# input2 = slim.conv2d_transpose(input0,", "\n", "#                               num_outputs=256,", "\n", "#                               kernel_size=[8, 8],", "\n", "#                               stride=1,", "\n", "#                               padding='SAME',", "\n", "#                               activation_fn=None)", "\n", "# input3 = slim.conv2d_transpose(input0,", "\n", "#                                num_outputs=256,", "\n", "#                                kernel_size=[4, 4],", "\n", "#                                stride=1,", "\n", "#                                padding='SAME',", "\n", "#                                activation_fn=None)", "\n", "# input = tf.concat(values=[input1,input2,input3], axis=-1)", "\n", "# input = slim.maxout(input,128)", "\n", "input", "=", "slim", ".", "conv2d", "(", "input1", ",", "\n", "num_outputs", "=", "128", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "weights_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l1_regularizer", "(", "scale", "=", "1e-3", ")", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "activation_fn", "=", "None", ")", "\n", "input", "=", "slim", ".", "maxout", "(", "input", ",", "64", ")", "\n", "input", "=", "slim", ".", "conv2d", "(", "input", ",", "\n", "num_outputs", "=", "64", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "weights_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l1_regularizer", "(", "scale", "=", "1e-3", ")", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "activation_fn", "=", "None", ")", "\n", "input", "=", "slim", ".", "maxout", "(", "input", ",", "1", ")", "\n", "input", "=", "slim", ".", "conv2d", "(", "input", ",", "\n", "num_outputs", "=", "conf", ".", "img_channel", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "\n", "padding", "=", "'SAME'", ",", "\n", "weights_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l1_regularizer", "(", "scale", "=", "1e-3", ")", ",", "\n", "biases_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "activation_fn", "=", "None", ")", "# Set act_func to None because the pixel value is in range [-1, 1]", "\n", "linear_mapping_logits", "=", "input", "\n", "tf", ".", "summary", ".", "image", "(", "'linear_mapping/linear_outputs'", ",", "linear_mapping_logits", ",", "max_outputs", "=", "3", ")", "\n", "\n", "return", "linear_mapping_logits", "\n", "\n", "# # Method 2", "\n", "# with slim.arg_scope([slim.conv2d_transpose],", "\n", "#                     biases_initializer=tf.constant_initializer(0),", "\n", "#                     activation_fn=None,", "\n", "#                     weights_regularizer=slim.l2_regularizer(0.01)):", "\n", "#     input = slim.conv2d_transpose(measurements, 128, kernel_size=[3, 3], stride=1, padding='VALID')", "\n", "#     input = slim.conv2d(input, 64, 1, 1, 'SAME', activation_fn=None)", "\n", "#     input = slim.conv2d(input, 32, 5, 1, 'SAME', activation_fn=None)", "\n", "#     input = slim.conv2d(input, 1, 1, 1, 'SAME', activation_fn=None)", "\n", "#     linear_mapping_logits = input", "\n", "\n", "# # Method 3", "\n", "# with slim.arg_scope([slim.fully_connected],", "\n", "#                     biases_initializer=tf.constant_initializer(0),", "\n", "#                     activation_fn=None,", "\n", "#                     weights_regularizer=slim.l2_regularizer(0.01)):", "\n", "#     input = slim.fully_connected(measurements, 256)", "\n", "#     input = tf.contrib.layers.maxout(input,128)", "\n", "#     input = slim.fully_connected(input, 256)", "\n", "#     input = tf.contrib.layers.maxout(input, 128)", "\n", "#     input = slim.fully_connected(input, 256)", "\n", "#     input = tf.transpose(input, [0, 2, 3, 1])", "\n", "#     linear_mapping_logits = tf.reshape(input, [conf.batch_size, conf.hr_size, conf.hr_size, conf.img_channel])", "\n", "#     return linear_mapping_logits", "\n", "\n", "", "else", ":", "\n", "# input = slim.conv2d(measurements,", "\n", "#                     num_outputs=conf.hr_size * conf.hr_size * conf.img_channel,", "\n", "#                     kernel_size=1,", "\n", "#                     stride=1,", "\n", "#                     padding='SAME',", "\n", "#                     weights_regularizer=None,", "\n", "#                     biases_initializer=tf.zeros_initializer(),", "\n", "#                     activation_fn=None)", "\n", "# input = tf.transpose(input, [0, 2, 3, 1])", "\n", "# linear_mapping_logits = tf.reshape(input, [conf.batch_size, conf.hr_size, conf.hr_size, conf.img_channel])", "\n", "# return linear_mapping_logits", "\n", "\n", "# with slim.arg_scope([slim.fully_connected],", "\n", "#                     biases_initializer=tf.constant_initializer(0),", "\n", "#                     activation_fn=None,", "\n", "#                     weights_regularizer=slim.l2_regularizer(0.01)):", "\n", "#     input = slim.fully_connected(measurements, conf.hr_size*conf.hr_size)", "\n", "#     input = tf.contrib.layers.maxout(input,int(conf.hr_size*conf.hr_size/2))", "\n", "#     input = slim.fully_connected(input, conf.hr_size*conf.hr_size)", "\n", "#     input = tf.contrib.layers.maxout(input, int(conf.hr_size*conf.hr_size/2))", "\n", "#     input = slim.fully_connected(input, conf.hr_size*conf.hr_size)", "\n", "#     input = tf.transpose(input, [0, 2, 3, 1])", "\n", "#     linear_mapping_logits = tf.reshape(input, [conf.batch_size, conf.hr_size, conf.hr_size, conf.img_channel])", "\n", "#     return linear_mapping_logits", "\n", "\n", "                ", "with", "slim", ".", "arg_scope", "(", "[", "slim", ".", "conv2d_transpose", "]", ",", "\n", "biases_initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", ",", "\n", "activation_fn", "=", "None", ",", "\n", "weights_regularizer", "=", "slim", ".", "l2_regularizer", "(", "0.01", ")", ")", ":", "\n", "                    ", "input", "=", "slim", ".", "conv2d_transpose", "(", "measurements", ",", "1", ",", "kernel_size", "=", "[", "16", ",", "16", "]", ",", "stride", "=", "8", ",", "padding", "=", "'SAME'", ")", "\n", "linear_mapping_logits", "=", "input", "\n", "return", "linear_mapping_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.Net.residual_reducing_network": [[202, 220], ["tf.variable_scope", "InputLayer", "Conv2dLayer", "ops.ResidualSingleLevel", "ops.ResidualSingleLevel", "tf.contrib.layers.variance_scaling_initializer"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.ResidualSingleLevel", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.ResidualSingleLevel"], ["", "", "", "", "def", "residual_reducing_network", "(", "self", ",", "inputs", ",", "num_features", "=", "64", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'residual_blocks'", ")", "as", "scope", ":", "\n", "            ", "inputs_level", "=", "InputLayer", "(", "inputs", ",", "name", "=", "'input_level'", ")", "\n", "\n", "net_feature", "=", "Conv2dLayer", "(", "inputs_level", ",", "\n", "shape", "=", "(", "3", ",", "3", ",", "conf", ".", "img_channel", ",", "num_features", ")", ",", "\n", "strides", "=", "(", "1", ",", "1", ",", "1", ",", "1", ")", ",", "\n", "W_init", "=", "tf", ".", "contrib", ".", "layers", ".", "variance_scaling_initializer", "(", ")", ",", "\n", "b_init", "=", "None", ",", "\n", "name", "=", "'init_conv'", ")", "\n", "\n", "net_image", "=", "inputs_level", "\n", "\n", "# 2X for each level", "\n", "net_image1", ",", "net_feature1", ",", "net_gradient1", "=", "ResidualSingleLevel", "(", "net_image", ",", "net_feature", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "net_image2", ",", "net_feature2", ",", "net_gradient2", "=", "ResidualSingleLevel", "(", "net_image1", ",", "net_feature1", ",", "reuse", "=", "True", ")", "\n", "\n", "return", "net_image2", ",", "net_gradient2", ",", "net_image1", ",", "net_gradient1", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.Net.construct_net": [[221, 249], ["net.Net.linear_mapping_network", "net.Net.residual_reducing_network", "tf.image.resize_images", "tf.get_collection", "tf.summary.scalar", "tf.summary.scalar", "net.Net.compute_charbonnier_loss", "net.Net.compute_charbonnier_loss", "tf.summary.scalar", "tf.reduce_mean", "tf.reduce_mean", "net.Net.compute_charbonnier_loss", "tf.reduce_sum", "tf.reduce_mean", "tf.reduce_sum", "tf.nn.l2_loss", "tf.nn.l2_loss", "tf.nn.l2_loss", "tf.losses.absolute_difference", "tf.losses.absolute_difference", "tf.losses.absolute_difference"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.Net.linear_mapping_network", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.residual_reducing_network", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.Net.compute_charbonnier_loss", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.Net.compute_charbonnier_loss", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.Net.compute_charbonnier_loss"], ["", "", "def", "construct_net", "(", "self", ",", "hr_img", ",", "lr_img", ",", "mask_type", ",", "is_linear_only", ")", ":", "\n", "        ", "self", ".", "linear_mapping_logits", "=", "self", ".", "linear_mapping_network", "(", "lr_img", ",", "mask_type", ")", "\n", "\n", "self", ".", "net_image2", ",", "self", ".", "net_gradient2", ",", "self", ".", "net_image1", ",", "self", ".", "net_gradient1", "=", "self", ".", "residual_reducing_network", "(", "self", ".", "linear_mapping_logits", ")", "\n", "\n", "hr_img_down", "=", "tf", ".", "image", ".", "resize_images", "(", "hr_img", ",", "size", "=", "[", "conf", ".", "lr_size", "*", "2", ",", "conf", ".", "lr_size", "*", "2", "]", ")", "\n", "\n", "# collect the regularization loss", "\n", "reg_ws", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "REGULARIZATION_LOSSES", ",", "'linear_mapping'", ")", "\n", "\n", "if", "is_linear_only", ":", "\n", "            ", "if", "conf", ".", "charbonnier_loss", ":", "\n", "                ", "self", ".", "loss", "=", "self", ".", "compute_charbonnier_loss", "(", "hr_img", ",", "self", ".", "linear_mapping_logits", ",", "is_mean", "=", "True", ")", "+", "tf", ".", "reduce_sum", "(", "reg_ws", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "loss", "=", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "nn", ".", "l2_loss", "(", "tf", ".", "losses", ".", "absolute_difference", "(", "hr_img", ",", "self", ".", "linear_mapping_logits", ")", ")", ")", "+", "tf", ".", "reduce_sum", "(", "reg_ws", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "'linear_loss_train'", ",", "self", ".", "loss", ")", "\n", "", "else", ":", "\n", "            ", "if", "conf", ".", "charbonnier_loss", ":", "\n", "                ", "loss1", "=", "self", ".", "compute_charbonnier_loss", "(", "self", ".", "net_image1", ".", "outputs", ",", "hr_img_down", ",", "is_mean", "=", "True", ")", "\n", "loss2", "=", "self", ".", "compute_charbonnier_loss", "(", "self", ".", "net_image1", ".", "outputs", ",", "hr_img", ",", "is_mean", "=", "True", ")", "\n", "self", ".", "loss", "=", "loss2", "\n", "tf", ".", "summary", ".", "scalar", "(", "'residual_loss_train'", ",", "self", ".", "loss", ")", "\n", "", "else", ":", "\n", "                ", "loss1", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "l2_loss", "(", "tf", ".", "losses", ".", "absolute_difference", "(", "hr_img", ",", "self", ".", "net_image1", ")", ")", ")", "\n", "loss2", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "l2_loss", "(", "tf", ".", "losses", ".", "absolute_difference", "(", "hr_img", ",", "self", ".", "net_image2", ")", ")", ")", "\n", "self", ".", "loss", "=", "loss1", "+", "loss2", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "'residual_loss_train'", ",", "self", ".", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.Net.compute_charbonnier_loss": [[250, 257], ["tf.reduce_mean", "tf.reduce_mean", "tf.reduce_mean", "tf.reduce_sum", "tf.sqrt", "tf.sqrt", "tf.square", "tf.square", "tf.subtract", "tf.subtract"], "methods", ["None"], ["", "", "def", "compute_charbonnier_loss", "(", "self", ",", "tensor1", ",", "tensor2", ",", "is_mean", "=", "True", ")", ":", "\n", "        ", "epsilon", "=", "1e-3", "\n", "if", "is_mean", ":", "\n", "            ", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "sqrt", "(", "tf", ".", "square", "(", "tf", ".", "subtract", "(", "tensor1", ",", "tensor2", ")", ")", "+", "epsilon", ")", ",", "[", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "sqrt", "(", "tf", ".", "square", "(", "tf", ".", "subtract", "(", "tensor1", ",", "tensor2", ")", ")", "+", "epsilon", ")", ",", "[", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.net.residual_reducing_network": [[264, 281], ["tf.variable_scope", "slim.conv2d", "range", "slim.conv2d", "ops.upsample", "ops.resnet_block"], "function", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.upsample", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.ops.resnet_block"], ["def", "residual_reducing_network", "(", "self", ",", "inputs", ",", "res_num", "=", "1", ",", "num_features", "=", "64", ",", "scale", "=", "2", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "'residual_blocks'", ")", "as", "scope", ":", "\n", "        ", "conv_1", "=", "slim", ".", "conv2d", "(", "inputs", ",", "num_features", ",", "[", "3", ",", "3", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "res_num", ")", ":", "\n", "            ", "inputs", "=", "resnet_block", "(", "inputs", ",", "num_features", ")", "\n", "\n", "", "inputs", "=", "slim", ".", "conv2d", "(", "inputs", ",", "num_features", ",", "[", "3", ",", "3", "]", ")", "\n", "# Up-sample output of the convolution", "\n", "inputs", "=", "upsample", "(", "inputs", ",", "scale", ",", "activation", "=", "None", ")", "\n", "# net_image1, net_feature1, net_gradient1 = ResidualSingleLevel(inputs, conv_1, reuse=None)", "\n", "# inputs = slim.conv2d(inputs, 3, [3, 3])", "\n", "# One final convolution on the up-sampling output", "\n", "# inputs = inputs  # slim.conv2d(x,output_channels,[3,3])", "\n", "residual_reducing_logits", "=", "inputs", "\n", "\n", "return", "residual_reducing_logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.__init__": [[18, 24], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "train_hr_img", "=", "[", "]", "\n", "self", ".", "train_lr_img", "=", "[", "]", "\n", "self", ".", "val_hr_img", "=", "[", "]", "\n", "self", ".", "val_lr_img", "=", "[", "]", "\n", "self", ".", "test_lr_img", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.load_dataset": [[25, 150], ["numpy.ndarray", "range", "numpy.random.permutation", "numpy.ndarray", "range", "tensorflow.cast", "tensorflow.cast", "data_reader.DataSet.normalize_imgs_fn", "data_reader.DataSet.normalize_imgs_fn", "numpy.ndarray", "range", "numpy.random.permutation", "numpy.ndarray", "range", "tensorflow.cast", "tensorflow.cast", "data_reader.DataSet.normalize_imgs_fn", "data_reader.DataSet.normalize_imgs_fn", "sess.run", "print", "skimage.io.imread", "numpy.expand_dims", "print", "numpy.reshape", "PIL.Image.fromarray", "numpy.expand_dims.resize", "numpy.expand_dims", "skimage.io.imread", "numpy.expand_dims", "print", "numpy.reshape", "PIL.Image.fromarray", "numpy.expand_dims.resize", "numpy.expand_dims", "numpy.expand_dims.astype", "numpy.array", "numpy.expand_dims.astype", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.normalize_imgs_fn", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.normalize_imgs_fn", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.normalize_imgs_fn", "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.normalize_imgs_fn"], ["", "def", "load_dataset", "(", "self", ",", "hr_img_list", ",", "lr_img_list", ",", "val_hr_img_list", ",", "val_lr_img_list", ",", "sess", ",", "num_raw_train", "=", "11", ",", "num_raw_val", "=", "100", ",", "num_patch", "=", "1", ")", ":", "\n", "# Load train images", "\n", "\n", "        ", "hr_all_images", "=", "np", ".", "ndarray", "(", "[", "num_raw_train", "*", "num_patch", ",", "conf", ".", "im_size", ",", "conf", ".", "im_size", ",", "1", "]", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "# for i in range(num_raw_train):", "\n", "#     img = skimage.io.imread(hr_img_list[i], as_grey=True)", "\n", "#     patches = image.extract_patches_2d(img, [conf.im_size, conf.im_size], 50)  # The output patch shape is [50, 64, 64]", "\n", "#     patches = np.expand_dims(patches, axis=3)", "\n", "#     patches = img_as_ubyte(patches)", "\n", "#     hr_all_images[i * num_patch: i * num_patch + num_patch] = patches", "\n", "#     del img, patches", "\n", "#     print(i)", "\n", "\n", "for", "i", "in", "range", "(", "11", ")", ":", "\n", "            ", "img", "=", "skimage", ".", "io", ".", "imread", "(", "hr_img_list", "[", "i", "]", ",", "as_grey", "=", "True", ")", "\n", "img", "=", "np", ".", "expand_dims", "(", "img", ",", "axis", "=", "3", ")", "\n", "hr_all_images", "[", "i", "]", "=", "img", "\n", "del", "img", "\n", "print", "(", "i", ")", "\n", "\n", "", "idx_list", "=", "np", ".", "random", ".", "permutation", "(", "num_raw_train", "*", "num_patch", ")", "\n", "idx_list", "=", "idx_list", "[", ":", "conf", ".", "num_train_images", "]", "\n", "hr_images", "=", "hr_all_images", "[", "idx_list", "]", "\n", "del", "hr_all_images", ",", "idx_list", "\n", "\n", "# hr_images_tmp = np.ndarray([conf.num_train_images, conf.hr_size, conf.hr_size, 1], dtype=np.uint8)", "\n", "# for i in range(conf.num_train_images):", "\n", "#     image_pil = np.reshape(hr_images[i], [conf.im_size, conf.im_size])", "\n", "#     image_pil = Image.fromarray(image_pil.astype('uint8'))", "\n", "#     image_pil = image_pil.resize((conf.hr_size, conf.hr_size), Image.ANTIALIAS)", "\n", "#     image_pil = np.expand_dims(np.array(image_pil), axis=3)", "\n", "#     hr_images_tmp[i] = image_pil", "\n", "#", "\n", "# hr_images = hr_images_tmp", "\n", "# del hr_images_tmp", "\n", "\n", "lr_images", "=", "hr_images", "\n", "lr_images_tmp", "=", "np", ".", "ndarray", "(", "[", "conf", ".", "num_train_images", ",", "conf", ".", "lr_size", ",", "conf", ".", "lr_size", ",", "1", "]", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "for", "i", "in", "range", "(", "conf", ".", "num_train_images", ")", ":", "\n", "            ", "image_pil", "=", "np", ".", "reshape", "(", "lr_images", "[", "i", "]", ",", "[", "conf", ".", "hr_size", ",", "conf", ".", "hr_size", "]", ")", "\n", "image_pil", "=", "Image", ".", "fromarray", "(", "image_pil", ".", "astype", "(", "'uint8'", ")", ")", "\n", "image_pil", "=", "image_pil", ".", "resize", "(", "(", "conf", ".", "lr_size", ",", "conf", ".", "lr_size", ")", ",", "Image", ".", "ANTIALIAS", ")", "\n", "image_pil", "=", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "image_pil", ")", ",", "axis", "=", "3", ")", "\n", "lr_images_tmp", "[", "i", "]", "=", "image_pil", "\n", "\n", "", "lr_images", "=", "lr_images_tmp", "\n", "del", "lr_images_tmp", "\n", "\n", "hr_images", "=", "tf", ".", "cast", "(", "hr_images", ",", "tf", ".", "float32", ")", "\n", "lr_images", "=", "tf", ".", "cast", "(", "lr_images", ",", "tf", ".", "float32", ")", "\n", "hr_images", "=", "self", ".", "normalize_imgs_fn", "(", "hr_images", ")", "\n", "lr_images", "=", "self", ".", "normalize_imgs_fn", "(", "lr_images", ")", "\n", "\n", "# # This block is for loading the DIV2K validation data", "\n", "# # Load val hr images", "\n", "# val_hr_all_images = np.ndarray([num_raw_val * num_patch, conf.im_size, conf.im_size, 1], dtype=np.uint8)", "\n", "# for i in range(num_raw_val):", "\n", "#     img = skimage.io.imread(val_hr_img_list[i], as_grey=True)", "\n", "#     patches = image.extract_patches_2d(img, [conf.im_size, conf.im_size], 50)  # The output patch shape is [50, 64, 64]", "\n", "#     patches = np.expand_dims(patches, axis=3)", "\n", "#     patches = img_as_ubyte(patches)", "\n", "#     val_hr_all_images[i * num_patch: i * num_patch + num_patch] = patches", "\n", "#     del img, patches", "\n", "#     print(i)", "\n", "# idx_list = np.random.permutation(num_raw_val * num_patch)", "\n", "# idx_list = idx_list[:conf.num_val_images]", "\n", "# val_hr_images = val_hr_all_images[idx_list]", "\n", "# del val_hr_all_images, idx_list", "\n", "#", "\n", "# val_hr_images = tf.image.resize_images(val_hr_images, [conf.hr_size, conf.hr_size])", "\n", "# val_lr_images = tf.image.resize_images(val_hr_images, [conf.lr_size, conf.lr_size])", "\n", "# val_hr_images = tf.cast(val_hr_images, tf.float32)", "\n", "# val_lr_images = tf.cast(val_lr_images, tf.float32)", "\n", "# val_hr_images = self.normalize_imgs_fn(val_hr_images)", "\n", "# val_lr_images = self.normalize_imgs_fn(val_lr_images)", "\n", "\n", "# vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv", "\n", "# This block is for loading the 11 test image validation data", "\n", "# Load val hr images", "\n", "val_hr_all_images", "=", "np", ".", "ndarray", "(", "[", "conf", ".", "num_val_images", ",", "conf", ".", "im_size", ",", "conf", ".", "im_size", ",", "1", "]", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "for", "i", "in", "range", "(", "11", ")", ":", "\n", "            ", "img", "=", "skimage", ".", "io", ".", "imread", "(", "val_hr_img_list", "[", "i", "]", ",", "as_grey", "=", "True", ")", "\n", "img", "=", "np", ".", "expand_dims", "(", "img", ",", "axis", "=", "3", ")", "\n", "val_hr_all_images", "[", "i", "]", "=", "img", "\n", "del", "img", "\n", "print", "(", "i", ")", "\n", "", "idx_list", "=", "np", ".", "random", ".", "permutation", "(", "11", ")", "\n", "idx_list", "=", "idx_list", "[", ":", "conf", ".", "num_val_images", "]", "\n", "val_hr_images", "=", "val_hr_all_images", "[", "idx_list", "]", "\n", "del", "val_hr_all_images", ",", "idx_list", "\n", "\n", "# val_hr_images_tmp = np.ndarray([conf.num_val_images, conf.hr_size, conf.hr_size, 1], dtype=np.uint8)", "\n", "# for i in range(conf.num_val_images):", "\n", "#     image_pil = np.reshape(val_hr_images[i], [conf.im_size, conf.im_size])", "\n", "#     image_pil = Image.fromarray(image_pil.astype('uint8'))", "\n", "#     image_pil = image_pil.resize((conf.hr_size, conf.hr_size), Image.ANTIALIAS)", "\n", "#     image_pil = np.expand_dims(np.array(image_pil), axis=3)", "\n", "#     val_hr_images_tmp[i] = image_pil", "\n", "#", "\n", "# val_hr_images = val_hr_images_tmp", "\n", "# del val_hr_images_tmp", "\n", "\n", "val_lr_images", "=", "val_hr_images", "\n", "val_lr_images_tmp", "=", "np", ".", "ndarray", "(", "[", "conf", ".", "num_val_images", ",", "conf", ".", "lr_size", ",", "conf", ".", "lr_size", ",", "1", "]", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "for", "i", "in", "range", "(", "conf", ".", "num_val_images", ")", ":", "\n", "            ", "image_pil", "=", "np", ".", "reshape", "(", "val_lr_images", "[", "i", "]", ",", "[", "conf", ".", "hr_size", ",", "conf", ".", "hr_size", "]", ")", "\n", "image_pil", "=", "Image", ".", "fromarray", "(", "image_pil", ".", "astype", "(", "'uint8'", ")", ")", "\n", "image_pil", "=", "image_pil", ".", "resize", "(", "(", "conf", ".", "lr_size", ",", "conf", ".", "lr_size", ")", ",", "Image", ".", "ANTIALIAS", ")", "\n", "image_pil", "=", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "image_pil", ")", ",", "axis", "=", "3", ")", "\n", "val_lr_images_tmp", "[", "i", "]", "=", "image_pil", "\n", "\n", "", "val_lr_images", "=", "val_lr_images_tmp", "\n", "del", "val_lr_images_tmp", "\n", "\n", "val_hr_images", "=", "tf", ".", "cast", "(", "val_hr_images", ",", "tf", ".", "float32", ")", "\n", "val_lr_images", "=", "tf", ".", "cast", "(", "val_lr_images", ",", "tf", ".", "float32", ")", "\n", "val_hr_images", "=", "self", ".", "normalize_imgs_fn", "(", "val_hr_images", ")", "\n", "val_lr_images", "=", "self", ".", "normalize_imgs_fn", "(", "val_lr_images", ")", "\n", "# ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^", "\n", "\n", "hr_images", ",", "lr_images", ",", "val_hr_images", ",", "val_lr_images", "=", "sess", ".", "run", "(", "[", "hr_images", ",", "lr_images", ",", "val_hr_images", ",", "val_lr_images", "]", ")", "\n", "print", "(", "[", "hr_images", ".", "shape", ",", "lr_images", ".", "shape", ",", "val_hr_images", ".", "shape", ",", "val_lr_images", ".", "shape", "]", ")", "\n", "\n", "return", "hr_images", ",", "lr_images", ",", "val_hr_images", ",", "val_lr_images", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.normalize_imgs_fn": [[151, 155], ["None"], "methods", ["None"], ["", "def", "normalize_imgs_fn", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "*", "(", "2.", "/", "255.", ")", "-", "1.", "\n", "# x = x * (1./255.)", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.data_reader.DataSet.load_file_list": [[156, 175], ["train_hr_file_list.append", "train_lr_file_list.append", "valid_hr_file_list.append", "valid_lr_file_list.append", "sorted", "sorted", "sorted", "sorted", "os.listdir", "os.path.isfile", "os.listdir", "os.path.isfile", "os.listdir", "os.path.isfile", "os.listdir", "os.path.isfile", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "load_file_list", "(", "self", ",", "train_hr_file", ",", "train_lr_file", ",", "valid_hr_file", ",", "valid_lr_file", ")", ":", "\n", "        ", "train_hr_file_list", "=", "[", "]", "\n", "train_lr_file_list", "=", "[", "]", "\n", "valid_hr_file_list", "=", "[", "]", "\n", "valid_lr_file_list", "=", "[", "]", "\n", "\n", "for", "filename", "in", "[", "y", "for", "y", "in", "os", ".", "listdir", "(", "train_hr_file", ")", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "train_hr_file", ",", "y", ")", ")", "]", ":", "\n", "            ", "train_hr_file_list", ".", "append", "(", "\"%s%s\"", "%", "(", "train_hr_file", ",", "filename", ")", ")", "\n", "\n", "", "for", "filename", "in", "[", "y", "for", "y", "in", "os", ".", "listdir", "(", "train_lr_file", ")", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "train_lr_file", ",", "y", ")", ")", "]", ":", "\n", "            ", "train_lr_file_list", ".", "append", "(", "\"%s%s\"", "%", "(", "train_lr_file", ",", "filename", ")", ")", "\n", "\n", "", "for", "filename", "in", "[", "y", "for", "y", "in", "os", ".", "listdir", "(", "valid_hr_file", ")", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "valid_hr_file", ",", "y", ")", ")", "]", ":", "\n", "            ", "valid_hr_file_list", ".", "append", "(", "\"%s%s\"", "%", "(", "valid_hr_file", ",", "filename", ")", ")", "\n", "\n", "", "for", "filename", "in", "[", "y", "for", "y", "in", "os", ".", "listdir", "(", "valid_lr_file", ")", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "valid_lr_file", ",", "y", ")", ")", "]", ":", "\n", "            ", "valid_lr_file_list", ".", "append", "(", "\"%s%s\"", "%", "(", "valid_lr_file", ",", "filename", ")", ")", "\n", "\n", "", "return", "sorted", "(", "train_hr_file_list", ")", ",", "sorted", "(", "train_lr_file_list", ")", ",", "sorted", "(", "valid_hr_file_list", ")", ",", "sorted", "(", "valid_lr_file_list", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.visualize_tensor.put_kernels_on_grid": [[6, 58], ["visualize_tensor.put_kernels_on_grid.factorization"], "function", ["None"], ["def", "put_kernels_on_grid", "(", "kernel", ",", "pad", "=", "1", ")", ":", "\n", "    ", "'''Visualize conv. filters as an image (mostly for the 1st layer).\n    Arranges filters into a grid, with some paddings between adjacent filters.\n    Args:\n      kernel:            tensor of shape [Y, X, NumChannels, NumKernels]\n      pad:               number of black pixels around each filter (between them)\n    Return:\n      Tensor of shape [1, (Y+2*pad)*grid_Y, (X+2*pad)*grid_X, NumChannels].\n    '''", "\n", "\n", "# get shape of the grid. NumKernels == grid_Y * grid_X", "\n", "def", "factorization", "(", "n", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "int", "(", "sqrt", "(", "float", "(", "n", ")", ")", ")", ",", "0", ",", "-", "1", ")", ":", "\n", "            ", "if", "n", "%", "i", "==", "0", ":", "\n", "                ", "if", "i", "==", "1", ":", "print", "(", "'Who would enter a prime number of filters'", ")", "\n", "return", "(", "i", ",", "int", "(", "n", "/", "i", ")", ")", "\n", "\n", "", "", "", "(", "grid_Y", ",", "grid_X", ")", "=", "factorization", "(", "kernel", ".", "get_shape", "(", ")", "[", "3", "]", ".", "value", ")", "\n", "print", "(", "'grid: %d = (%d, %d)'", "%", "(", "kernel", ".", "get_shape", "(", ")", "[", "3", "]", ".", "value", ",", "grid_Y", ",", "grid_X", ")", ")", "\n", "\n", "x_min", "=", "tf", ".", "reduce_min", "(", "kernel", ")", "\n", "x_max", "=", "tf", ".", "reduce_max", "(", "kernel", ")", "\n", "kernel", "=", "(", "kernel", "-", "x_min", ")", "/", "(", "x_max", "-", "x_min", ")", "\n", "\n", "# pad X and Y", "\n", "x", "=", "tf", ".", "pad", "(", "kernel", ",", "tf", ".", "constant", "(", "[", "[", "pad", ",", "pad", "]", ",", "[", "pad", ",", "pad", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", ",", "mode", "=", "'CONSTANT'", ")", "\n", "\n", "# X and Y dimensions, w.r.t. padding", "\n", "Y", "=", "kernel", ".", "get_shape", "(", ")", "[", "0", "]", "+", "2", "*", "pad", "\n", "X", "=", "kernel", ".", "get_shape", "(", ")", "[", "1", "]", "+", "2", "*", "pad", "\n", "\n", "channels", "=", "kernel", ".", "get_shape", "(", ")", "[", "2", "]", "\n", "\n", "# put NumKernels to the 1st dimension", "\n", "x", "=", "tf", ".", "transpose", "(", "x", ",", "(", "3", ",", "0", ",", "1", ",", "2", ")", ")", "\n", "# organize grid on Y axis", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "tf", ".", "stack", "(", "[", "grid_X", ",", "Y", "*", "grid_Y", ",", "X", ",", "channels", "]", ")", ")", "\n", "\n", "# switch X and Y axes", "\n", "x", "=", "tf", ".", "transpose", "(", "x", ",", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "\n", "# organize grid on X axis", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "tf", ".", "stack", "(", "[", "1", ",", "X", "*", "grid_X", ",", "Y", "*", "grid_Y", ",", "channels", "]", ")", ")", "\n", "\n", "# back to normal order (not combining with the next step for clarity)", "\n", "x", "=", "tf", ".", "transpose", "(", "x", ",", "(", "2", ",", "1", ",", "3", ",", "0", ")", ")", "\n", "\n", "# to tf.image_summary order [batch_size, height, width, channels],", "\n", "#   where in this case batch_size == 1", "\n", "x", "=", "tf", ".", "transpose", "(", "x", ",", "(", "3", ",", "0", ",", "1", ",", "2", ")", ")", "\n", "\n", "# scaling to [0, 255] is not necessary for tensorboard", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.utils.save_samples": [[5, 20], ["np_imgs.astype.astype", "int", "numpy.zeros", "range", "skimage.io.imsave", "range"], "function", ["None"], ["def", "save_samples", "(", "np_imgs", ",", "img_path", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n      np_imgs: [N, H, W, 3] float32\n      img_path: str\n    \"\"\"", "\n", "np_imgs", "=", "np_imgs", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "N", ",", "H", ",", "W", ",", "_", "=", "np_imgs", ".", "shape", "\n", "num", "=", "int", "(", "N", "**", "0.5", ")", "\n", "merge_img", "=", "np", ".", "zeros", "(", "(", "num", "*", "H", ",", "num", "*", "W", ",", "3", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "for", "i", "in", "range", "(", "num", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "num", ")", ":", "\n", "            ", "merge_img", "[", "i", "*", "H", ":", "(", "i", "+", "1", ")", "*", "H", ",", "j", "*", "W", ":", "(", "j", "+", "1", ")", "*", "W", ",", ":", "]", "=", "np_imgs", "[", "i", "*", "num", "+", "j", ",", ":", ",", ":", ",", ":", "]", "\n", "\n", "", "", "imsave", "(", "img_path", ",", "merge_img", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.utils.logits_2_pixel_value": [[22, 35], ["utils.softmax", "numpy.arange", "numpy.sum", "numpy.floor"], "function", ["home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.utils.softmax"], ["", "def", "logits_2_pixel_value", "(", "logits", ",", "mu", "=", "1.1", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n      logits: [n, 256] float32\n      mu    : float32\n    Returns:\n      pixels: [n] float32\n    \"\"\"", "\n", "rebalance_logits", "=", "logits", "*", "mu", "\n", "probs", "=", "softmax", "(", "rebalance_logits", ")", "\n", "pixel_dict", "=", "np", ".", "arange", "(", "0", ",", "256", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "pixels", "=", "np", ".", "sum", "(", "probs", "*", "pixel_dict", ",", "axis", "=", "1", ")", "\n", "return", "np", ".", "floor", "(", "pixels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FangliangBai_LSHR-Net.Neurocomputing-LSHR_Net-code.utils.softmax": [[37, 41], ["numpy.exp", "numpy.expand_dims", "numpy.expand_dims", "np.exp.sum", "numpy.max"], "function", ["None"], ["", "def", "softmax", "(", "x", ")", ":", "\n", "    ", "\"\"\"Compute softmax values for each sets of scores in x.\"\"\"", "\n", "e_x", "=", "np", ".", "exp", "(", "x", "-", "np", ".", "expand_dims", "(", "np", ".", "max", "(", "x", ",", "axis", "=", "-", "1", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "return", "e_x", "/", "np", ".", "expand_dims", "(", "e_x", ".", "sum", "(", "axis", "=", "-", "1", ")", ",", "axis", "=", "-", "1", ")", "# only difference", "\n", "", ""]]}