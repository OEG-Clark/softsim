{"home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.models.Classifier.__init__": [[5, 21], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "layers.append", "layers.append", "layers.append", "layers.append", "range", "layers.append", "layers.append", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "layers.append", "layers.append", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_layers", ",", "n_inputs", ",", "n_hidden_units", ")", ":", "\n", "        ", "super", "(", "Classifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layers", "=", "[", "]", "\n", "\n", "if", "n_layers", "==", "1", ":", "# Logistic Regression", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "n_inputs", ",", "1", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "n_inputs", ",", "n_hidden_units", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "n_layers", "-", "2", ")", ":", "\n", "                ", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "n_hidden_units", ",", "n_hidden_units", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "n_hidden_units", ",", "1", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.models.Classifier.forward": [[22, 25], ["models.Classifier.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "layers", "(", "x", ")", "\n", "return", "x", "", "", "", ""]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader_multi.CustomDataset.__init__": [[68, 72], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "X", ",", "Y", ",", "Z", ")", ":", "\n", "        ", "self", ".", "X", "=", "X", "\n", "self", ".", "Y", "=", "Y", "\n", "self", ".", "Z", "=", "Z", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader_multi.CustomDataset.__len__": [[73, 75], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "Y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader_multi.CustomDataset.__getitem__": [[76, 79], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "x", ",", "y", ",", "z", "=", "self", ".", "X", "[", "index", "]", ",", "self", ".", "Y", "[", "index", "]", ",", "self", ".", "Z", "[", "index", "]", "\n", "return", "x", ",", "y", ",", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader_multi.FairnessDataset_multi.__init__": [[82, 93], ["torch.device", "numpy.random.seed", "dataloader_multi.FairnessDataset_multi.prepare_ndarray", "dataloader_multi.FairnessDataset_multi.get_adult_data", "ValueError"], "methods", ["home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.prepare_ndarray", "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.get_adult_data"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "device", "=", "device", "\n", "np", ".", "random", ".", "seed", "(", "12345678", ")", "\n", "\n", "if", "self", ".", "dataset", "==", "'AdultCensus'", ":", "\n", "            ", "self", ".", "get_adult_data", "(", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Your argument {} for dataset name is invalid.'", ".", "format", "(", "self", ".", "dataset", ")", ")", "\n", "", "self", ".", "prepare_ndarray", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader_multi.FairnessDataset_multi.get_adult_data": [[94, 126], ["dataloader_multi.adult", "X_train.drop.drop.drop", "X_train.drop.drop.drop", "X_test.drop.drop.drop", "X_test.drop.drop.drop", "pandas.get_dummies", "pandas.get_dummies", "pandas.get_dummies", "pandas.get_dummies", "sklearn.preprocessing.LabelEncoder", "sklearn.preprocessing.LabelEncoder.fit_transform", "pandas.Series", "sklearn.preprocessing.LabelEncoder.fit_transform", "pandas.Series"], "methods", ["home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.adult"], ["", "def", "get_adult_data", "(", "self", ")", ":", "\n", "        ", "X_train", ",", "Y_train", ",", "X_test", ",", "Y_test", "=", "adult", "(", "'./data/adult/'", ")", "\n", "\n", "self", ".", "Z1_train_", "=", "X_train", "[", "'Sex'", "]", "\n", "self", ".", "Z1_test_", "=", "X_test", "[", "'Sex'", "]", "\n", "self", ".", "Z2_train_", "=", "X_train", "[", "'Race'", "]", "==", "4", "\n", "self", ".", "Z2_test_", "=", "X_test", "[", "'Race'", "]", "==", "4", "\n", "self", ".", "Z_train_", "=", "self", ".", "Z1_train_", "*", "2", "+", "self", ".", "Z2_train_", "\n", "self", ".", "Z_test_", "=", "self", ".", "Z1_test_", "*", "2", "+", "self", ".", "Z2_test_", "\n", "\n", "X_train", "[", "'Race'", "]", "=", "X_train", "[", "'Race'", "]", "==", "4", "\n", "X_test", "[", "'Race'", "]", "=", "X_test", "[", "'Race'", "]", "==", "4", "\n", "\n", "self", ".", "XZ_train_", "=", "X_train", "\n", "self", ".", "XZ_test_", "=", "X_test", "\n", "X_train", "=", "X_train", ".", "drop", "(", "labels", "=", "[", "'Sex'", "]", ",", "axis", "=", "1", ")", "\n", "X_train", "=", "X_train", ".", "drop", "(", "labels", "=", "[", "'Race'", "]", ",", "axis", "=", "1", ")", "\n", "X_test", "=", "X_test", ".", "drop", "(", "labels", "=", "[", "'Sex'", "]", ",", "axis", "=", "1", ")", "\n", "X_test", "=", "X_test", ".", "drop", "(", "labels", "=", "[", "'Race'", "]", ",", "axis", "=", "1", ")", "\n", "\n", "self", ".", "X_train_", "=", "X_train", "\n", "self", ".", "X_test_", "=", "X_test", "\n", "self", ".", "XZ_train_", "=", "pd", ".", "get_dummies", "(", "self", ".", "XZ_train_", ")", "\n", "self", ".", "XZ_test_", "=", "pd", ".", "get_dummies", "(", "self", ".", "XZ_test_", ")", "\n", "self", ".", "X_train_", "=", "pd", ".", "get_dummies", "(", "self", ".", "X_train_", ")", "\n", "self", ".", "X_test_", "=", "pd", ".", "get_dummies", "(", "self", ".", "X_test_", ")", "\n", "\n", "le", "=", "LabelEncoder", "(", ")", "\n", "self", ".", "Y_train_", "=", "le", ".", "fit_transform", "(", "Y_train", ")", "\n", "self", ".", "Y_train_", "=", "pd", ".", "Series", "(", "self", ".", "Y_train_", ",", "name", "=", "'>50k'", ")", "\n", "self", ".", "Y_test_", "=", "le", ".", "fit_transform", "(", "Y_test", ")", "\n", "self", ".", "Y_test_", "=", "pd", ".", "Series", "(", "self", ".", "Y_test_", ",", "name", "=", "'>50k'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader_multi.FairnessDataset_multi.prepare_ndarray": [[128, 141], ["dataloader_multi.FairnessDataset_multi.X_train_.to_numpy", "dataloader_multi.FairnessDataset_multi.Y_train_.to_numpy", "dataloader_multi.FairnessDataset_multi.Z_train_.to_numpy", "dataloader_multi.FairnessDataset_multi.XZ_train_.to_numpy", "dataloader_multi.FairnessDataset_multi.X_test_.to_numpy", "dataloader_multi.FairnessDataset_multi.Y_test_.to_numpy", "dataloader_multi.FairnessDataset_multi.Z_test_.to_numpy", "dataloader_multi.FairnessDataset_multi.XZ_test_.to_numpy", "sorted", "list", "set"], "methods", ["None"], ["", "def", "prepare_ndarray", "(", "self", ")", ":", "\n", "        ", "self", ".", "normalized", "=", "False", "\n", "self", ".", "X_train", "=", "self", ".", "X_train_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "Y_train", "=", "self", ".", "Y_train_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "Z_train", "=", "self", ".", "Z_train_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "XZ_train", "=", "self", ".", "XZ_train_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "self", ".", "X_test", "=", "self", ".", "X_test_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "Y_test", "=", "self", ".", "Y_test_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "Z_test", "=", "self", ".", "Z_test_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "XZ_test", "=", "self", ".", "XZ_test_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "sensitive_attrs", "=", "sorted", "(", "list", "(", "set", "(", "self", ".", "Z_train", ")", ")", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader_multi.FairnessDataset_multi.normalize": [[142, 152], ["sklearn.preprocessing.StandardScaler", "sklearn.preprocessing.StandardScaler.fit_transform", "sklearn.preprocessing.StandardScaler.transform", "sklearn.preprocessing.StandardScaler", "sklearn.preprocessing.StandardScaler.fit_transform", "sklearn.preprocessing.StandardScaler.transform"], "methods", ["None"], ["", "def", "normalize", "(", "self", ")", ":", "\n", "        ", "self", ".", "normalized", "=", "True", "\n", "scaler_XZ", "=", "StandardScaler", "(", ")", "\n", "self", ".", "XZ_train", "=", "scaler_XZ", ".", "fit_transform", "(", "self", ".", "XZ_train", ")", "\n", "self", ".", "XZ_test", "=", "scaler_XZ", ".", "transform", "(", "self", ".", "XZ_test", ")", "\n", "\n", "scaler_X", "=", "StandardScaler", "(", ")", "\n", "self", ".", "X_train", "=", "scaler_X", ".", "fit_transform", "(", "self", ".", "X_train", ")", "\n", "self", ".", "X_test", "=", "scaler_X", ".", "transform", "(", "self", ".", "X_test", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader_multi.FairnessDataset_multi.get_dataset_in_ndarray": [[153, 156], ["None"], "methods", ["None"], ["", "def", "get_dataset_in_ndarray", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "X_train", ",", "self", ".", "Y_train", ",", "self", ".", "Z_train", ",", "self", ".", "XZ_train", ")", ",", "(", "self", ".", "X_test", ",", "self", ".", "Y_test", ",", "self", ".", "Z_test", ",", "self", ".", "XZ_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader_multi.FairnessDataset_multi.get_dataset_in_tensor": [[157, 164], ["dataloader_multi.arrays_to_tensor", "dataloader_multi.arrays_to_tensor"], "methods", ["home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.arrays_to_tensor", "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.arrays_to_tensor"], ["", "def", "get_dataset_in_tensor", "(", "self", ",", "validation", "=", "False", ",", "val_portion", "=", ".0", ")", ":", "\n", "        ", "X_train_", ",", "Y_train_", ",", "Z_train_", ",", "XZ_train_", "=", "arrays_to_tensor", "(", "\n", "self", ".", "X_train", ",", "self", ".", "Y_train", ",", "self", ".", "Z_train", ",", "self", ".", "XZ_train", ",", "self", ".", "device", ")", "\n", "X_test_", ",", "Y_test_", ",", "Z_test_", ",", "XZ_test_", "=", "arrays_to_tensor", "(", "\n", "self", ".", "X_test", ",", "self", ".", "Y_test", ",", "self", ".", "Z_test", ",", "self", ".", "XZ_test", ",", "self", ".", "device", ")", "\n", "return", "(", "X_train_", ",", "Y_train_", ",", "Z_train_", ",", "XZ_train_", ")", ",", "(", "X_test_", ",", "Y_test_", ",", "Z_test_", ",", "XZ_test_", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader_multi.arrays_to_tensor": [[14, 17], ["torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "function", ["None"], ["def", "arrays_to_tensor", "(", "X", ",", "Y", ",", "Z", ",", "XZ", ",", "device", ")", ":", "\n", "    ", "return", "torch", ".", "FloatTensor", "(", "X", ")", ".", "to", "(", "device", ")", ",", "torch", ".", "FloatTensor", "(", "Y", ")", ".", "to", "(", "device", ")", ",", "torch", ".", "FloatTensor", "(", "Z", ")", ".", "to", "(", "\n", "device", ")", ",", "torch", ".", "FloatTensor", "(", "XZ", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader_multi.adult": [[19, 65], ["pandas.read_csv", "pandas.read_csv", "pd.read_csv.drop", "pd.read_csv.drop", "list", "filter", "raw_train_data.drop.drop", "raw_test_data.drop.drop", "dict", "dict", "numpy.array", "numpy.array", "v.strip", "v.strip"], "function", ["None"], ["", "def", "adult", "(", "data_root", ",", "display", "=", "False", ")", ":", "\n", "    ", "\"\"\" Return the Adult census data in a nice package. \"\"\"", "\n", "dtypes", "=", "[", "\n", "(", "\"Age\"", ",", "\"float32\"", ")", ",", "(", "\"Workclass\"", ",", "\"category\"", ")", ",", "(", "\"fnlwgt\"", ",", "\"float32\"", ")", ",", "\n", "(", "\"Education\"", ",", "\"category\"", ")", ",", "(", "\"Education-Num\"", ",", "\"float32\"", ")", ",", "(", "\"Marital Status\"", ",", "\"category\"", ")", ",", "\n", "(", "\"Occupation\"", ",", "\"category\"", ")", ",", "(", "\"Relationship\"", ",", "\"category\"", ")", ",", "(", "\"Race\"", ",", "\"category\"", ")", ",", "\n", "(", "\"Sex\"", ",", "\"category\"", ")", ",", "(", "\"Capital Gain\"", ",", "\"float32\"", ")", ",", "(", "\"Capital Loss\"", ",", "\"float32\"", ")", ",", "\n", "(", "\"Hours per week\"", ",", "\"float32\"", ")", ",", "(", "\"Country\"", ",", "\"category\"", ")", ",", "(", "\"Target\"", ",", "\"category\"", ")", "\n", "]", "\n", "raw_train_data", "=", "pd", ".", "read_csv", "(", "\n", "data_root", "+", "'adult.data'", ",", "\n", "names", "=", "[", "d", "[", "0", "]", "for", "d", "in", "dtypes", "]", ",", "\n", "na_values", "=", "\"?\"", ",", "\n", "dtype", "=", "dict", "(", "dtypes", ")", "\n", ")", "\n", "raw_test_data", "=", "pd", ".", "read_csv", "(", "\n", "data_root", "+", "'adult.test'", ",", "\n", "skiprows", "=", "1", ",", "\n", "names", "=", "[", "d", "[", "0", "]", "for", "d", "in", "dtypes", "]", ",", "\n", "na_values", "=", "\"?\"", ",", "\n", "dtype", "=", "dict", "(", "dtypes", ")", "\n", ")", "\n", "train_data", "=", "raw_train_data", ".", "drop", "(", "[", "\"Education\"", "]", ",", "axis", "=", "1", ")", "# redundant with Education-Num", "\n", "test_data", "=", "raw_test_data", ".", "drop", "(", "[", "\"Education\"", "]", ",", "axis", "=", "1", ")", "# redundant with Education-Num", "\n", "filt_dtypes", "=", "list", "(", "filter", "(", "lambda", "x", ":", "not", "(", "x", "[", "0", "]", "in", "[", "\"Target\"", ",", "\"Education\"", "]", ")", ",", "dtypes", ")", ")", "\n", "train_data", "[", "\"Target\"", "]", "=", "train_data", "[", "\"Target\"", "]", "==", "\" >50K\"", "\n", "test_data", "[", "\"Target\"", "]", "=", "test_data", "[", "\"Target\"", "]", "==", "\" >50K.\"", "\n", "rcode", "=", "{", "\n", "\"Not-in-family\"", ":", "0", ",", "\n", "\"Unmarried\"", ":", "1", ",", "\n", "\"Other-relative\"", ":", "2", ",", "\n", "\"Own-child\"", ":", "3", ",", "\n", "\"Husband\"", ":", "4", ",", "\n", "\"Wife\"", ":", "5", "\n", "}", "\n", "for", "k", ",", "dtype", "in", "filt_dtypes", ":", "\n", "        ", "if", "dtype", "==", "\"category\"", ":", "\n", "            ", "if", "k", "==", "\"Relationship\"", ":", "\n", "                ", "train_data", "[", "k", "]", "=", "np", ".", "array", "(", "[", "rcode", "[", "v", ".", "strip", "(", ")", "]", "for", "v", "in", "train_data", "[", "k", "]", "]", ")", "\n", "test_data", "[", "k", "]", "=", "np", ".", "array", "(", "[", "rcode", "[", "v", ".", "strip", "(", ")", "]", "for", "v", "in", "test_data", "[", "k", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "train_data", "[", "k", "]", "=", "train_data", "[", "k", "]", ".", "cat", ".", "codes", "\n", "test_data", "[", "k", "]", "=", "test_data", "[", "k", "]", ".", "cat", ".", "codes", "\n", "\n", "", "", "", "return", "train_data", ".", "drop", "(", "[", "\"Target\"", ",", "\"fnlwgt\"", "]", ",", "axis", "=", "1", ")", ",", "train_data", "[", "\"Target\"", "]", ".", "values", ",", "test_data", ".", "drop", "(", "\n", "[", "\"Target\"", ",", "\"fnlwgt\"", "]", ",", "axis", "=", "1", ")", ",", "test_data", "[", "\"Target\"", "]", ".", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.algorithm_multi.FairBayes_multi": [[18, 103], ["dataset.get_dataset_in_tensor", "len", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "Y_val.detach().cpu().numpy", "Z_train.detach().cpu().numpy", "sorted", "Z_test.detach().cpu().numpy", "Y_test.detach().cpu().numpy", "Y_train[].detach().cpu().numpy", "Y_train[].detach().cpu().numpy", "dataloader.CustomDataset", "torch.utils.data.DataLoader", "torch.BCELoss", "range", "net.load_state_dict", "net().squeeze().detach().cpu().numpy", "net().squeeze().detach().cpu().numpy", "utils.threshold_DemPa_multi", "utils.measures_from_Yhat_DemPa_multi", "int", "int", "int", "list", "isinstance", "net.train", "enumerate", "Y_val.detach().cpu", "Z_train.detach().cpu", "set", "print", "sys.exit", "Z_test.detach().cpu", "Y_test.detach().cpu", "Y_train[].detach().cpu", "Y_train[].detach().cpu", "net", "nn.BCELoss.", "optimizer.zero_grad", "loss_function.backward", "optimizer.step", "costs.append", "torch.no_grad", "torch.no_grad", "net", "net().squeeze().detach().cpu", "net().squeeze().detach().cpu", "xz_batch.to", "y_batch.to", "z_batch.to", "net.squeeze", "loss_function.item", "print", "XZ_val.to", "net.state_dict", "net.state_dict", "Y_val.detach", "Z_train.detach", "Z_test.detach", "Y_test.detach", "Y_train[].detach", "Y_train[].detach", "len", "net().squeeze().detach", "net().squeeze().detach", "len", "loss_function.item", "net().squeeze", "net().squeeze", "net", "net"], "function", ["home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.get_dataset_in_tensor", "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.threshold_DemPa_multi", "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.measures_from_Yhat_DemPa_multi"], ["def", "FairBayes_multi", "(", "dataset", ",", "dataset_name", ",", "net", ",", "optimizer", ",", "device", ",", "n_epochs", "=", "200", ",", "\n", "batch_size", "=", "2048", ",", "seed", "=", "0", ")", ":", "\n", "# Retrieve train/test splitted pytorch tensors for index=split", "\n", "    ", "train_val_tensors", ",", "test_tensors", "=", "dataset", ".", "get_dataset_in_tensor", "(", ")", "\n", "X_train_val", ",", "Y_train_val", ",", "Z_train_val", ",", "XZ_train_val", "=", "train_val_tensors", "\n", "X_test", ",", "Y_test", ",", "Z_test", ",", "XZ_test", "=", "test_tensors", "\n", "\n", "# training data size and validation data size", "\n", "\n", "train_val_size", "=", "len", "(", "X_train_val", ")", "\n", "Y_train", ",", "Y_val", "=", "torch", ".", "split", "(", "Y_train_val", ",", "int", "(", "train_val_size", "*", "0.8", ")", ")", "\n", "Z_train", ",", "Z_val", "=", "torch", ".", "split", "(", "Z_train_val", ",", "int", "(", "train_val_size", "*", "0.8", ")", ")", "\n", "XZ_train", ",", "XZ_val", "=", "torch", ".", "split", "(", "XZ_train_val", ",", "int", "(", "train_val_size", "*", "0.8", ")", ")", "\n", "Y_val_np", "=", "Y_val", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# Retrieve train/test splitted numpy arrays for index=split", "\n", "Z_train_np", "=", "Z_train", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "Z_list", "=", "sorted", "(", "list", "(", "set", "(", "Z_train_np", ")", ")", ")", "\n", "for", "z", "in", "Z_list", ":", "\n", "        ", "if", "(", "Z_train_np", "==", "z", ")", ".", "sum", "(", ")", "==", "0", ":", "\n", "            ", "print", "(", "'At least one sensitive group has no data point'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "Z_test_np", "=", "Z_test", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "Y_test_np", "=", "Y_test", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "Y1_train_np", "=", "(", "Y_train", "[", "Z_train", "==", "1", "]", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "Y0_train_np", "=", "(", "Y_train", "[", "Z_train", "==", "0", "]", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "custom_dataset", "=", "CustomDataset", "(", "XZ_train", ",", "Y_train", ",", "Z_train", ")", "\n", "if", "batch_size", "==", "'full'", ":", "\n", "        ", "batch_size_", "=", "XZ_train", ".", "shape", "[", "0", "]", "\n", "", "elif", "isinstance", "(", "batch_size", ",", "int", ")", ":", "\n", "        ", "batch_size_", "=", "batch_size", "\n", "", "data_loader", "=", "DataLoader", "(", "custom_dataset", ",", "batch_size", "=", "batch_size_", ",", "shuffle", "=", "True", ")", "\n", "\n", "# An empty dataframe for logging experimental results", "\n", "\n", "loss_function", "=", "nn", ".", "BCELoss", "(", ")", "\n", "costs", "=", "[", "]", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "        ", "net", ".", "train", "(", ")", "\n", "for", "i", ",", "(", "xz_batch", ",", "y_batch", ",", "z_batch", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "xz_batch", ",", "y_batch", ",", "z_batch", "=", "xz_batch", ".", "to", "(", "device", ")", ",", "y_batch", ".", "to", "(", "device", ")", ",", "z_batch", ".", "to", "(", "device", ")", "\n", "Yhat", "=", "net", "(", "xz_batch", ")", "\n", "cost", "=", "0", "\n", "\n", "# prediction loss", "\n", "cost", "=", "loss_function", "(", "Yhat", ".", "squeeze", "(", ")", ",", "y_batch", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "cost", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "costs", ".", "append", "(", "cost", ".", "item", "(", ")", ")", "\n", "\n", "# Print the cost per 10 batches", "\n", "if", "(", "i", "+", "1", ")", "%", "10", "==", "0", "or", "(", "i", "+", "1", ")", "==", "len", "(", "data_loader", ")", ":", "\n", "                ", "print", "(", "'Epoch [{}/{}], Batch [{}/{}], Cost: {:.4f}'", ".", "format", "(", "epoch", "+", "1", ",", "n_epochs", ",", "\n", "i", "+", "1", ",", "len", "(", "data_loader", ")", ",", "\n", "cost", ".", "item", "(", ")", ")", ",", "end", "=", "'\\r'", ")", "\n", "\n", "########choose the model with best performance on validation set###########", "\n", "", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "output_val", "=", "net", "(", "XZ_val", ".", "to", "(", "device", ")", ")", "\n", "Yhat_val", "=", "(", "output_val", ">", "0.5", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "accuracy", "=", "(", "Yhat_val", "==", "Y_val_np", ")", ".", "mean", "(", ")", "\n", "\n", "if", "epoch", "==", "0", ":", "\n", "                ", "accuracy_max", "=", "accuracy", "\n", "bestnet_acc_stat_dict", "=", "net", ".", "state_dict", "(", ")", "\n", "\n", "", "if", "accuracy", ">", "accuracy_max", ":", "\n", "                ", "accuracy_max", "=", "accuracy", "\n", "bestnet_acc_stat_dict", "=", "net", ".", "state_dict", "(", ")", "\n", "\n", "#########Calculate thresholds for fair Bayes-optimal Classifier###########", "\n", "", "", "", "net", ".", "load_state_dict", "(", "bestnet_acc_stat_dict", ")", "\n", "\n", "eta_train", "=", "net", "(", "XZ_train", ")", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "eta_test", "=", "net", "(", "XZ_test", ")", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "t_star", "=", "threshold_DemPa_multi", "(", "eta_train", ",", "Z_train_np", ")", "\n", "\n", "df_test", "=", "measures_from_Yhat_DemPa_multi", "(", "eta_test", ",", "Z_test_np", ",", "Y_test_np", ",", "t_star", ")", "\n", "df_test", "[", "'seed'", "]", "=", "seed", "\n", "return", "df_test", "", "", ""]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.CustomDataset.__init__": [[91, 95], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "X", ",", "Y", ",", "Z", ")", ":", "\n", "        ", "self", ".", "X", "=", "X", "\n", "self", ".", "Y", "=", "Y", "\n", "self", ".", "Z", "=", "Z", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.CustomDataset.__len__": [[96, 98], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "Y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.CustomDataset.__getitem__": [[99, 102], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "x", ",", "y", ",", "z", "=", "self", ".", "X", "[", "index", "]", ",", "self", ".", "Y", "[", "index", "]", ",", "self", ".", "Z", "[", "index", "]", "\n", "return", "x", ",", "y", ",", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.__init__": [[105, 121], ["torch.device", "numpy.random.seed", "dataloader.FairnessDataset.prepare_ndarray", "dataloader.FairnessDataset.get_adult_data", "dataloader.FairnessDataset.get_compas_data", "dataloader.FairnessDataset.get_lawschool_data", "ValueError"], "methods", ["home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.prepare_ndarray", "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.get_adult_data", "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.get_compas_data", "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.get_lawschool_data"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ",", "device", "=", "torch", ".", "device", "(", "'cuda'", ")", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "device", "=", "device", "\n", "np", ".", "random", ".", "seed", "(", "12345678", ")", "\n", "\n", "if", "self", ".", "dataset", "==", "'AdultCensus'", ":", "\n", "            ", "self", ".", "get_adult_data", "(", ")", "\n", "", "elif", "self", ".", "dataset", "==", "'COMPAS'", ":", "\n", "            ", "self", ".", "get_compas_data", "(", ")", "\n", "\n", "", "elif", "self", ".", "dataset", "==", "'Lawschool'", ":", "\n", "            ", "self", ".", "get_lawschool_data", "(", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Your argument {} for dataset name is invalid.'", ".", "format", "(", "self", ".", "dataset", ")", ")", "\n", "", "self", ".", "prepare_ndarray", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.get_adult_data": [[122, 137], ["dataloader.adult", "X_train.drop", "pandas.get_dummies", "X_test.drop", "pandas.get_dummies", "sklearn.preprocessing.LabelEncoder", "sklearn.preprocessing.LabelEncoder.fit_transform", "pandas.Series", "sklearn.preprocessing.LabelEncoder.fit_transform", "pandas.Series"], "methods", ["home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.adult"], ["", "def", "get_adult_data", "(", "self", ")", ":", "\n", "        ", "X_train", ",", "Y_train", ",", "X_test", ",", "Y_test", "=", "adult", "(", "'./data/adult/'", ")", "\n", "\n", "self", ".", "Z_train_", "=", "X_train", "[", "'Sex'", "]", "\n", "self", ".", "Z_test_", "=", "X_test", "[", "'Sex'", "]", "\n", "self", ".", "X_train_", "=", "X_train", ".", "drop", "(", "labels", "=", "[", "'Sex'", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "X_train_", "=", "pd", ".", "get_dummies", "(", "self", ".", "X_train_", ")", "\n", "self", ".", "X_test_", "=", "X_test", ".", "drop", "(", "labels", "=", "[", "'Sex'", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "X_test_", "=", "pd", ".", "get_dummies", "(", "self", ".", "X_test_", ")", "\n", "\n", "le", "=", "LabelEncoder", "(", ")", "\n", "self", ".", "Y_train_", "=", "le", ".", "fit_transform", "(", "Y_train", ")", "\n", "self", ".", "Y_train_", "=", "pd", ".", "Series", "(", "self", ".", "Y_train_", ",", "name", "=", "'>50k'", ")", "\n", "self", ".", "Y_test_", "=", "le", ".", "fit_transform", "(", "Y_test", ")", "\n", "self", ".", "Y_test_", "=", "pd", ".", "Series", "(", "self", ".", "Y_test_", ",", "name", "=", "'>50k'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.get_compas_data": [[138, 152], ["dataset.get_X", "dataset.get_y", "dataset.get_sensitive_features"], "methods", ["None"], ["", "def", "get_compas_data", "(", "self", ")", ":", "\n", "        ", "dataset", "=", "datasets", "[", "'compas'", "]", "(", ")", "\n", "# dataset = compas_data_loader()", "\n", "X_train", ",", "X_test", "=", "dataset", ".", "get_X", "(", "format", "=", "pd", ".", "DataFrame", ")", "\n", "Y_train", ",", "Y_test", "=", "dataset", ".", "get_y", "(", "format", "=", "pd", ".", "Series", ")", "\n", "Z_train", ",", "Z_test", "=", "dataset", ".", "get_sensitive_features", "(", "'race'", ",", "format", "=", "pd", ".", "Series", ")", "\n", "\n", "self", ".", "X_train_", "=", "X_train", "\n", "self", ".", "Y_train_", "=", "Y_train", "\n", "self", ".", "Z_train_", "=", "(", "Z_train", "!=", "'African-American'", ")", ".", "astype", "(", "float", ")", "\n", "\n", "self", ".", "X_test_", "=", "X_test", "\n", "self", ".", "Y_test_", "=", "Y_test", "\n", "self", ".", "Z_test_", "=", "(", "Z_test", "!=", "'African-American'", ")", ".", "astype", "(", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.get_lawschool_data": [[154, 171], ["pandas.read_sas", "rawdata.sample().reset_index.sample().reset_index.drop", "rawdata.sample().reset_index.sample().reset_index.dropna", "rawdata.sample().reset_index.sample().reset_index.sample().reset_index", "rawdata.sample().reset_index.sample().reset_index.sample", "list", "list", "list", "list", "list", "range", "range", "list", "range", "range", "range", "range"], "methods", ["None"], ["", "def", "get_lawschool_data", "(", "self", ")", ":", "\n", "        ", "rawdata", "=", "pd", ".", "read_sas", "(", "'./data/lawschool/lawschs1_1.sas7bdat'", ")", "\n", "rawdata", "=", "rawdata", ".", "drop", "(", "[", "'college'", ",", "'Year'", ",", "'URM'", ",", "'enroll'", "]", ",", "axis", "=", "1", ")", "\n", "rawdata", "=", "rawdata", ".", "dropna", "(", "axis", "=", "0", ")", "\n", "rawdata", "=", "rawdata", ".", "sample", "(", "frac", "=", "1.0", ",", "random_state", "=", "12345678", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "X", "=", "rawdata", "[", "[", "'LSAT'", ",", "'GPA'", ",", "'Gender'", ",", "'resident'", "]", "]", "\n", "Y", "=", "rawdata", "[", "'admit'", "]", "\n", "Z", "=", "rawdata", "[", "'White'", "]", "\n", "\n", "self", ".", "X_train_", "=", "X", ".", "loc", "[", "list", "(", "range", "(", "77267", ")", ")", ",", ":", "]", "\n", "self", ".", "Y_train_", "=", "Y", ".", "loc", "[", "list", "(", "range", "(", "77267", ")", ")", "]", "\n", "self", ".", "Z_train_", "=", "Z", ".", "loc", "[", "list", "(", "range", "(", "77267", ")", ")", "]", "\n", "\n", "self", ".", "X_test_", "=", "X", ".", "loc", "[", "list", "(", "range", "(", "77267", ",", "96584", ")", ")", ",", ":", "]", "\n", "self", ".", "Y_test_", "=", "Y", ".", "loc", "[", "list", "(", "range", "(", "77267", ",", "96584", ")", ")", "]", "\n", "self", ".", "Z_test_", "=", "Z", ".", "loc", "[", "list", "(", "range", "(", "77267", ",", "96584", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.prepare_ndarray": [[174, 187], ["dataloader.FairnessDataset.X_train_.to_numpy", "dataloader.FairnessDataset.Y_train_.to_numpy", "dataloader.FairnessDataset.Z_train_.to_numpy", "numpy.concatenate", "dataloader.FairnessDataset.X_test_.to_numpy", "dataloader.FairnessDataset.Y_test_.to_numpy", "dataloader.FairnessDataset.Z_test_.to_numpy", "numpy.concatenate", "sorted", "list", "dataloader.FairnessDataset.Z_train.reshape", "dataloader.FairnessDataset.Z_test.reshape", "set"], "methods", ["None"], ["", "def", "prepare_ndarray", "(", "self", ")", ":", "\n", "        ", "self", ".", "normalized", "=", "False", "\n", "self", ".", "X_train", "=", "self", ".", "X_train_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "Y_train", "=", "self", ".", "Y_train_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "Z_train", "=", "self", ".", "Z_train_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "XZ_train", "=", "np", ".", "concatenate", "(", "[", "self", ".", "X_train", ",", "self", ".", "Z_train", ".", "reshape", "(", "-", "1", ",", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "self", ".", "X_test", "=", "self", ".", "X_test_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "Y_test", "=", "self", ".", "Y_test_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "Z_test", "=", "self", ".", "Z_test_", ".", "to_numpy", "(", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "XZ_test", "=", "np", ".", "concatenate", "(", "[", "self", ".", "X_test", ",", "self", ".", "Z_test", ".", "reshape", "(", "-", "1", ",", "1", ")", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "sensitive_attrs", "=", "sorted", "(", "list", "(", "set", "(", "self", ".", "Z_train", ")", ")", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.normalize": [[188, 198], ["sklearn.preprocessing.StandardScaler", "sklearn.preprocessing.StandardScaler.fit_transform", "sklearn.preprocessing.StandardScaler.transform", "sklearn.preprocessing.StandardScaler", "sklearn.preprocessing.StandardScaler.fit_transform", "sklearn.preprocessing.StandardScaler.transform"], "methods", ["None"], ["", "def", "normalize", "(", "self", ")", ":", "\n", "        ", "self", ".", "normalized", "=", "True", "\n", "scaler_XZ", "=", "StandardScaler", "(", ")", "\n", "self", ".", "XZ_train", "=", "scaler_XZ", ".", "fit_transform", "(", "self", ".", "XZ_train", ")", "\n", "self", ".", "XZ_test", "=", "scaler_XZ", ".", "transform", "(", "self", ".", "XZ_test", ")", "\n", "\n", "scaler_X", "=", "StandardScaler", "(", ")", "\n", "self", ".", "X_train", "=", "scaler_X", ".", "fit_transform", "(", "self", ".", "X_train", ")", "\n", "self", ".", "X_test", "=", "scaler_X", ".", "transform", "(", "self", ".", "X_test", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.get_dataset_in_ndarray": [[199, 202], ["None"], "methods", ["None"], ["", "def", "get_dataset_in_ndarray", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "X_train", ",", "self", ".", "Y_train", ",", "self", ".", "Z_train", ",", "self", ".", "XZ_train", ")", ",", "(", "self", ".", "X_test", ",", "self", ".", "Y_test", ",", "self", ".", "Z_test", ",", "self", ".", "XZ_test", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.get_dataset_in_tensor": [[203, 210], ["dataloader.arrays_to_tensor", "dataloader.arrays_to_tensor"], "methods", ["home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.arrays_to_tensor", "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.arrays_to_tensor"], ["", "def", "get_dataset_in_tensor", "(", "self", ",", "validation", "=", "False", ",", "val_portion", "=", ".0", ")", ":", "\n", "        ", "X_train_", ",", "Y_train_", ",", "Z_train_", ",", "XZ_train_", "=", "arrays_to_tensor", "(", "\n", "self", ".", "X_train", ",", "self", ".", "Y_train", ",", "self", ".", "Z_train", ",", "self", ".", "XZ_train", ",", "self", ".", "device", ")", "\n", "X_test_", ",", "Y_test_", ",", "Z_test_", ",", "XZ_test_", "=", "arrays_to_tensor", "(", "\n", "self", ".", "X_test", ",", "self", ".", "Y_test", ",", "self", ".", "Z_test", ",", "self", ".", "XZ_test", ",", "self", ".", "device", ")", "\n", "return", "(", "X_train_", ",", "Y_train_", ",", "Z_train_", ",", "XZ_train_", ")", ",", "(", "X_test_", ",", "Y_test_", ",", "Z_test_", ",", "XZ_test_", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.arrays_to_tensor": [[14, 16], ["torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "function", ["None"], ["def", "arrays_to_tensor", "(", "X", ",", "Y", ",", "Z", ",", "XZ", ",", "device", ")", ":", "\n", "    ", "return", "torch", ".", "FloatTensor", "(", "X", ")", ".", "to", "(", "device", ")", ",", "torch", ".", "FloatTensor", "(", "Y", ")", ".", "to", "(", "device", ")", ",", "torch", ".", "FloatTensor", "(", "Z", ")", ".", "to", "(", "device", ")", ",", "torch", ".", "FloatTensor", "(", "XZ", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.adult": [[17, 62], ["pandas.read_csv", "pandas.read_csv", "pd.read_csv.drop", "pd.read_csv.drop", "list", "filter", "raw_train_data.drop.drop", "raw_test_data.drop.drop", "dict", "dict", "numpy.array", "numpy.array", "v.strip", "v.strip"], "function", ["None"], ["", "def", "adult", "(", "data_root", ",", "display", "=", "False", ")", ":", "\n", "    ", "\"\"\" Return the Adult census data in a nice package. \"\"\"", "\n", "dtypes", "=", "[", "\n", "(", "\"Age\"", ",", "\"float32\"", ")", ",", "(", "\"Workclass\"", ",", "\"category\"", ")", ",", "(", "\"fnlwgt\"", ",", "\"float32\"", ")", ",", "\n", "(", "\"Education\"", ",", "\"category\"", ")", ",", "(", "\"Education-Num\"", ",", "\"float32\"", ")", ",", "(", "\"Marital Status\"", ",", "\"category\"", ")", ",", "\n", "(", "\"Occupation\"", ",", "\"category\"", ")", ",", "(", "\"Relationship\"", ",", "\"category\"", ")", ",", "(", "\"Race\"", ",", "\"category\"", ")", ",", "\n", "(", "\"Sex\"", ",", "\"category\"", ")", ",", "(", "\"Capital Gain\"", ",", "\"float32\"", ")", ",", "(", "\"Capital Loss\"", ",", "\"float32\"", ")", ",", "\n", "(", "\"Hours per week\"", ",", "\"float32\"", ")", ",", "(", "\"Country\"", ",", "\"category\"", ")", ",", "(", "\"Target\"", ",", "\"category\"", ")", "\n", "]", "\n", "raw_train_data", "=", "pd", ".", "read_csv", "(", "\n", "data_root", "+", "'adult.data'", ",", "\n", "names", "=", "[", "d", "[", "0", "]", "for", "d", "in", "dtypes", "]", ",", "\n", "na_values", "=", "\"?\"", ",", "\n", "dtype", "=", "dict", "(", "dtypes", ")", "\n", ")", "\n", "raw_test_data", "=", "pd", ".", "read_csv", "(", "\n", "data_root", "+", "'adult.test'", ",", "\n", "skiprows", "=", "1", ",", "\n", "names", "=", "[", "d", "[", "0", "]", "for", "d", "in", "dtypes", "]", ",", "\n", "na_values", "=", "\"?\"", ",", "\n", "dtype", "=", "dict", "(", "dtypes", ")", "\n", ")", "\n", "train_data", "=", "raw_train_data", ".", "drop", "(", "[", "\"Education\"", "]", ",", "axis", "=", "1", ")", "# redundant with Education-Num", "\n", "test_data", "=", "raw_test_data", ".", "drop", "(", "[", "\"Education\"", "]", ",", "axis", "=", "1", ")", "# redundant with Education-Num", "\n", "filt_dtypes", "=", "list", "(", "filter", "(", "lambda", "x", ":", "not", "(", "x", "[", "0", "]", "in", "[", "\"Target\"", ",", "\"Education\"", "]", ")", ",", "dtypes", ")", ")", "\n", "train_data", "[", "\"Target\"", "]", "=", "train_data", "[", "\"Target\"", "]", "==", "\" >50K\"", "\n", "test_data", "[", "\"Target\"", "]", "=", "test_data", "[", "\"Target\"", "]", "==", "\" >50K.\"", "\n", "rcode", "=", "{", "\n", "\"Not-in-family\"", ":", "0", ",", "\n", "\"Unmarried\"", ":", "1", ",", "\n", "\"Other-relative\"", ":", "2", ",", "\n", "\"Own-child\"", ":", "3", ",", "\n", "\"Husband\"", ":", "4", ",", "\n", "\"Wife\"", ":", "5", "\n", "}", "\n", "for", "k", ",", "dtype", "in", "filt_dtypes", ":", "\n", "        ", "if", "dtype", "==", "\"category\"", ":", "\n", "            ", "if", "k", "==", "\"Relationship\"", ":", "\n", "                ", "train_data", "[", "k", "]", "=", "np", ".", "array", "(", "[", "rcode", "[", "v", ".", "strip", "(", ")", "]", "for", "v", "in", "train_data", "[", "k", "]", "]", ")", "\n", "test_data", "[", "k", "]", "=", "np", ".", "array", "(", "[", "rcode", "[", "v", ".", "strip", "(", ")", "]", "for", "v", "in", "test_data", "[", "k", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "train_data", "[", "k", "]", "=", "train_data", "[", "k", "]", ".", "cat", ".", "codes", "\n", "test_data", "[", "k", "]", "=", "test_data", "[", "k", "]", ".", "cat", ".", "codes", "\n", "\n", "", "", "", "return", "train_data", ".", "drop", "(", "[", "\"Target\"", ",", "\"fnlwgt\"", "]", ",", "axis", "=", "1", ")", ",", "train_data", "[", "\"Target\"", "]", ".", "values", ",", "test_data", ".", "drop", "(", "[", "\"Target\"", ",", "\"fnlwgt\"", "]", ",", "axis", "=", "1", ")", ",", "test_data", "[", "\"Target\"", "]", ".", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.compas_data_loader": [[63, 88], ["pandas.read_csv", "pd.get_dummies.assign", "pandas.get_dummies"], "function", ["None"], ["", "def", "compas_data_loader", "(", ")", ":", "\n", "    ", "\"\"\" Downloads COMPAS data from the propublica GitHub repository.\n    :return: pandas.DataFrame with columns 'sex', 'age', 'juv_fel_count', 'juv_misd_count',\n       'juv_other_count', 'priors_count', 'two_year_recid', 'age_cat_25 - 45',\n       'age_cat_Greater than 45', 'age_cat_Less than 25', 'race_African-American',\n       'race_Caucasian', 'c_charge_degree_F', 'c_charge_degree_M'\n    \"\"\"", "\n", "data", "=", "pd", ".", "read_csv", "(", "\"./data/compas/compas-scores-two-years.csv\"", ")", "# noqa: E501", "\n", "# filter similar to", "\n", "# https://github.com/propublica/compas-analysis/blob/master/Compas%20Analysis.ipynb", "\n", "data", "=", "data", "[", "(", "data", "[", "'days_b_screening_arrest'", "]", "<=", "30", ")", "&", "\n", "(", "data", "[", "'days_b_screening_arrest'", "]", ">=", "-", "30", ")", "&", "\n", "(", "data", "[", "'is_recid'", "]", "!=", "-", "1", ")", "&", "\n", "(", "data", "[", "'c_charge_degree'", "]", "!=", "\"O\"", ")", "&", "\n", "(", "data", "[", "'score_text'", "]", "!=", "\"N/A\"", ")", "]", "\n", "# filter out all records except the ones with the most common two races", "\n", "data", "=", "data", "[", "(", "data", "[", "'race'", "]", "==", "'African-American'", ")", "|", "(", "data", "[", "'race'", "]", "==", "'Caucasian'", ")", "]", "\n", "# Select relevant columns for machine learning.", "\n", "# We explicitly leave in age_cat to allow linear classifiers to be non-linear in age", "\n", "data", "=", "data", "[", "[", "\"sex\"", ",", "\"age\"", ",", "\"age_cat\"", ",", "\"race\"", ",", "\"juv_fel_count\"", ",", "\"juv_misd_count\"", ",", "\n", "\"juv_other_count\"", ",", "\"priors_count\"", ",", "\"c_charge_degree\"", ",", "\"two_year_recid\"", "]", "]", "\n", "# map string representation of feature \"sex\" to 0 for Female and 1 for Male", "\n", "data", "=", "data", ".", "assign", "(", "sex", "=", "(", "data", "[", "\"sex\"", "]", "==", "\"Male\"", ")", "*", "1", ")", "\n", "data", "=", "pd", ".", "get_dummies", "(", "data", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.algorithm.FairBayes": [[18, 127], ["dataset.get_dataset_in_tensor", "len", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "Y_val.detach().cpu().numpy", "Z_train.detach().cpu().numpy", "Z_test.detach().cpu().numpy", "Y_test.detach().cpu().numpy", "Y_train[].detach().cpu().numpy", "Y_train[].detach().cpu().numpy", "dataloader.CustomDataset", "torch.utils.data.DataLoader", "torch.BCELoss", "range", "net.load_state_dict", "net().squeeze().detach().cpu().numpy", "net().squeeze().detach().cpu().numpy", "pandas.DataFrame", "int", "int", "int", "print", "sys.exit", "isinstance", "net.train", "enumerate", "df_test.append.append", "Y_val.detach().cpu", "Z_train.detach().cpu", "Z_train.detach().cpu().numpy.mean", "Z_train.detach().cpu().numpy.mean", "Z_test.detach().cpu", "Y_test.detach().cpu", "Y_train[].detach().cpu", "Y_train[].detach().cpu", "net", "nn.BCELoss.", "optimizer.zero_grad", "loss_function.backward", "optimizer.step", "costs.append", "torch.no_grad", "torch.no_grad", "net", "net().squeeze().detach().cpu", "net().squeeze().detach().cpu", "utils.threshold_DemPa", "utils.measures_from_Yhat_DemPa", "utils.threshold_EqqOp", "utils.measures_from_Yhat_EqqOp", "xz_batch.to", "y_batch.to", "z_batch.to", "net.squeeze", "loss_function.item", "print", "XZ_val.to", "net.state_dict", "net.state_dict", "Y_val.detach", "Z_train.detach", "Z_test.detach", "Y_test.detach", "Y_train[].detach", "Y_train[].detach", "len", "net().squeeze().detach", "net().squeeze().detach", "len", "loss_function.item", "net().squeeze", "net().squeeze", "net", "net"], "function", ["home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.dataloader.FairnessDataset.get_dataset_in_tensor", "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.threshold_DemPa", "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.measures_from_Yhat_DemPa", "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.threshold_EqqOp", "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.measures_from_Yhat_EqqOp"], ["def", "FairBayes", "(", "dataset", ",", "dataset_name", ",", "net", ",", "optimizer", ",", "fairness", ",", "delta_set", ",", "device", ",", "n_epochs", "=", "200", ",", "batch_size", "=", "2048", ",", "seed", "=", "0", ")", ":", "\n", "\n", "# Retrieve train/test splitted pytorch tensors for index=split", "\n", "    ", "train_val_tensors", ",", "test_tensors", "=", "dataset", ".", "get_dataset_in_tensor", "(", ")", "\n", "X_train_val", ",", "Y_train_val", ",", "Z_train_val", ",", "XZ_train_val", "=", "train_val_tensors", "\n", "X_test", ",", "Y_test", ",", "Z_test", ",", "XZ_test", "=", "test_tensors", "\n", "\n", "# training data size and validation data size", "\n", "\n", "train_val_size", "=", "len", "(", "X_train_val", ")", "\n", "Y_train", ",", "Y_val", "=", "torch", ".", "split", "(", "Y_train_val", ",", "int", "(", "train_val_size", "*", "0.8", ")", ")", "\n", "Z_train", ",", "Z_val", "=", "torch", ".", "split", "(", "Z_train_val", ",", "int", "(", "train_val_size", "*", "0.8", ")", ")", "\n", "XZ_train", ",", "XZ_val", "=", "torch", ".", "split", "(", "XZ_train_val", ",", "int", "(", "train_val_size", "*", "0.8", ")", ")", "\n", "Y_val_np", "=", "Y_val", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# Retrieve train/test splitted numpy arrays for index=split", "\n", "Z_train_np", "=", "Z_train", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "Z_train_np", ".", "mean", "(", ")", "==", "0", "or", "Z_train_np", ".", "mean", "(", ")", "==", "1", ":", "\n", "        ", "print", "(", "'At least one sensitive group has no data point'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "Z_test_np", "=", "Z_test", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "Y_test_np", "=", "Y_test", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "Y1_train_np", "=", "(", "Y_train", "[", "Z_train", "==", "1", "]", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "Y0_train_np", "=", "(", "Y_train", "[", "Z_train", "==", "0", "]", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "custom_dataset", "=", "CustomDataset", "(", "XZ_train", ",", "Y_train", ",", "Z_train", ")", "\n", "if", "batch_size", "==", "'full'", ":", "\n", "        ", "batch_size_", "=", "XZ_train", ".", "shape", "[", "0", "]", "\n", "", "elif", "isinstance", "(", "batch_size", ",", "int", ")", ":", "\n", "        ", "batch_size_", "=", "batch_size", "\n", "", "data_loader", "=", "DataLoader", "(", "custom_dataset", ",", "batch_size", "=", "batch_size_", ",", "shuffle", "=", "True", ")", "\n", "\n", "\n", "\n", "# An empty dataframe for logging experimental results", "\n", "\n", "loss_function", "=", "nn", ".", "BCELoss", "(", ")", "\n", "costs", "=", "[", "]", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "        ", "net", ".", "train", "(", ")", "\n", "for", "i", ",", "(", "xz_batch", ",", "y_batch", ",", "z_batch", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "xz_batch", ",", "y_batch", ",", "z_batch", "=", "xz_batch", ".", "to", "(", "device", ")", ",", "y_batch", ".", "to", "(", "device", ")", ",", "z_batch", ".", "to", "(", "device", ")", "\n", "Yhat", "=", "net", "(", "xz_batch", ")", "\n", "\n", "# prediction loss", "\n", "cost", "=", "loss_function", "(", "Yhat", ".", "squeeze", "(", ")", ",", "y_batch", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "cost", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "costs", ".", "append", "(", "cost", ".", "item", "(", ")", ")", "\n", "\n", "# Print the cost per 10 batches", "\n", "if", "(", "i", "+", "1", ")", "%", "10", "==", "0", "or", "(", "i", "+", "1", ")", "==", "len", "(", "data_loader", ")", ":", "\n", "                ", "print", "(", "'Epoch [{}/{}], Batch [{}/{}], Cost: {:.4f}'", ".", "format", "(", "epoch", "+", "1", ",", "n_epochs", ",", "\n", "i", "+", "1", ",", "len", "(", "data_loader", ")", ",", "\n", "cost", ".", "item", "(", ")", ")", ",", "end", "=", "'\\r'", ")", "\n", "\n", "\n", "########choose the model with best performance on validation set###########", "\n", "", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "\n", "            ", "output_val", "=", "net", "(", "XZ_val", ".", "to", "(", "device", ")", ")", "\n", "Yhat_val", "=", "(", "output_val", ">=", "0.5", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "accuracy", "=", "(", "Yhat_val", "==", "Y_val_np", ")", ".", "mean", "(", ")", "\n", "\n", "\n", "if", "epoch", "==", "0", ":", "\n", "                ", "accuracy_max", "=", "accuracy", "\n", "bestnet_acc_stat_dict", "=", "net", ".", "state_dict", "(", ")", "\n", "\n", "\n", "", "if", "accuracy", ">", "accuracy_max", ":", "\n", "                ", "accuracy_max", "=", "accuracy", "\n", "bestnet_acc_stat_dict", "=", "net", ".", "state_dict", "(", ")", "\n", "\n", "\n", "#########Calculate thresholds for fair Bayes-optimal Classifier###########", "\n", "", "", "", "net", ".", "load_state_dict", "(", "bestnet_acc_stat_dict", ")", "\n", "\n", "eta_train", "=", "net", "(", "XZ_train", ")", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "eta_1", "=", "eta_train", "[", "Z_train_np", "==", "1", "]", "\n", "eta_0", "=", "eta_train", "[", "Z_train_np", "==", "0", "]", "\n", "\n", "eta_test", "=", "net", "(", "XZ_test", ")", ".", "squeeze", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "eta1_test", "=", "eta_test", "[", "Z_test_np", "==", "1", "]", "\n", "eta0_test", "=", "eta_test", "[", "Z_test_np", "==", "0", "]", "\n", "Y1test_np", "=", "(", "Y_test_np", "[", "Z_test_np", "==", "1", "]", ")", "\n", "Y0test_np", "=", "(", "Y_test_np", "[", "Z_test_np", "==", "0", "]", ")", "\n", "\n", "df_test", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "for", "delta", "in", "delta_set", ":", "\n", "        ", "if", "fairness", "==", "'DemPa'", ":", "\n", "            ", "[", "t1_DDP", ",", "t0_DDP", "]", "=", "threshold_DemPa", "(", "eta_1", ",", "eta_0", ",", "delta", ")", "\n", "Yhat1", "=", "eta1_test", ">", "t1_DDP", "\n", "Yhat0", "=", "eta0_test", ">", "t0_DDP", "\n", "temp", "=", "measures_from_Yhat_DemPa", "(", "Yhat1", ",", "Yhat0", ",", "Y1test_np", ",", "Y0test_np", ")", "\n", "", "if", "fairness", "==", "'EqqOp'", ":", "\n", "            ", "[", "t1_DEO", ",", "t0_DEO", "]", "=", "threshold_EqqOp", "(", "eta_1", ",", "eta_0", ",", "Y1_train_np", ",", "Y0_train_np", ",", "delta", ")", "\n", "Yhat1", "=", "eta1_test", ">", "t1_DEO", "\n", "Yhat0", "=", "eta0_test", ">", "t0_DEO", "\n", "temp", "=", "measures_from_Yhat_EqqOp", "(", "Yhat1", ",", "Yhat0", ",", "Y1test_np", ",", "Y0test_np", ")", "\n", "", "temp", "[", "'delta'", "]", "=", "delta", "\n", "temp", "[", "'seed'", "]", "=", "seed", "\n", "\n", "df_test", "=", "df_test", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "df_test", "", "", ""]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.threshold_DemPa": [[14, 56], ["numpy.mean", "numpy.mean", "len", "abs", "len", "len", "min", "min", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean"], "function", ["None"], ["def", "threshold_DemPa", "(", "eta1", ",", "eta0", ",", "delta", "=", "0", ",", "pre_level", "=", "1e-5", ")", ":", "\n", "    ", "pa_hat", "=", "len", "(", "eta1", ")", "/", "(", "len", "(", "eta1", ")", "+", "len", "(", "eta0", ")", ")", "\n", "p1", "=", "np", ".", "mean", "(", "eta1", ">", "1", "/", "2", ")", "\n", "p0", "=", "np", ".", "mean", "(", "eta0", ">", "1", "/", "2", ")", "\n", "\n", "\n", "\n", "if", "abs", "(", "p1", "-", "p0", ")", "<=", "delta", ":", "\n", "        ", "tstar", "=", "0", "\n", "\n", "", "elif", "p1", "-", "p0", ">", "delta", ":", "\n", "        ", "tmin", "=", "0", "\n", "tmax", "=", "min", "(", "pa_hat", ",", "(", "1", "-", "pa_hat", ")", ")", "\n", "\n", "while", "tmax", "-", "tmin", ">", "pre_level", ":", "\n", "            ", "tmid", "=", "(", "tmin", "+", "tmax", ")", "/", "2", "\n", "t1", "=", "0.5", "+", "tmid", "/", "2", "/", "pa_hat", "\n", "t0", "=", "0.5", "-", "tmid", "/", "2", "/", "(", "1", "-", "pa_hat", ")", "\n", "DDP", "=", "np", ".", "mean", "(", "eta1", ">", "t1", ")", "-", "np", ".", "mean", "(", "eta0", ">", "t0", ")", "\n", "if", "DDP", ">", "delta", ":", "\n", "                ", "tmin", "=", "tmid", "\n", "", "else", ":", "\n", "                ", "tmax", "=", "tmid", "\n", "", "", "tstar", "=", "(", "tmin", "+", "tmax", ")", "/", "2", "\n", "\n", "", "else", ":", "\n", "        ", "tmin", "=", "-", "1", "*", "min", "(", "pa_hat", ",", "(", "1", "-", "pa_hat", ")", ")", "\n", "tmax", "=", "0", "\n", "while", "tmax", "-", "tmin", ">", "pre_level", ":", "\n", "            ", "tmid", "=", "(", "tmin", "+", "tmax", ")", "/", "2", "\n", "t1", "=", "0.5", "+", "tmid", "/", "2", "/", "pa_hat", "\n", "t0", "=", "0.5", "-", "tmid", "/", "2", "/", "(", "1", "-", "pa_hat", ")", "\n", "DDP", "=", "np", ".", "mean", "(", "eta1", ">", "t1", ")", "-", "np", ".", "mean", "(", "eta0", ">", "t0", ")", "\n", "if", "DDP", ">", "-", "delta", ":", "\n", "                ", "tmin", "=", "tmid", "\n", "", "else", ":", "\n", "                ", "tmax", "=", "tmid", "\n", "", "", "tstar", "=", "(", "tmin", "+", "tmax", ")", "/", "2", "\n", "\n", "", "t1star", "=", "0.5", "+", "tstar", "/", "2", "/", "pa_hat", "\n", "t0star", "=", "0.5", "-", "tstar", "/", "2", "/", "(", "1", "-", "pa_hat", ")", "\n", "return", "t1star", ",", "t0star", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.threshold_EqqOp": [[60, 106], ["numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "len", "abs", "len", "len", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean"], "function", ["None"], ["", "def", "threshold_EqqOp", "(", "eta1", ",", "eta0", ",", "Y1", ",", "Y0", ",", "delta", "=", "0", ",", "pre_level", "=", "1e-5", ")", ":", "\n", "    ", "pa_hat", "=", "len", "(", "eta1", ")", "/", "(", "len", "(", "eta1", ")", "+", "len", "(", "eta0", ")", ")", "\n", "py1_hat", "=", "np", ".", "mean", "(", "Y1", ")", "\n", "py0_hat", "=", "np", ".", "mean", "(", "Y0", ")", "\n", "\n", "p1", "=", "np", ".", "mean", "(", "eta1", "[", "Y1", "==", "1", "]", ">", "1", "/", "2", ")", "\n", "p0", "=", "np", ".", "mean", "(", "eta0", "[", "Y0", "==", "1", "]", ">", "1", "/", "2", ")", "\n", "\n", "\n", "\n", "if", "abs", "(", "p1", "-", "p0", ")", "<=", "delta", ":", "\n", "        ", "tstar", "=", "0", "\n", "\n", "", "elif", "p1", "-", "p0", ">", "delta", ":", "\n", "        ", "tmin", "=", "0", "\n", "tmax", "=", "pa_hat", "*", "py1_hat", "\n", "\n", "while", "tmax", "-", "tmin", ">", "pre_level", ":", "\n", "            ", "tmid", "=", "(", "tmin", "+", "tmax", ")", "/", "2", "\n", "t1", "=", "pa_hat", "*", "py1_hat", "/", "(", "2", "*", "pa_hat", "*", "py1_hat", "-", "tmid", ")", "\n", "t0", "=", "(", "1", "-", "pa_hat", ")", "*", "py0_hat", "/", "(", "2", "*", "(", "1", "-", "pa_hat", ")", "*", "py0_hat", "+", "tmid", ")", "\n", "DEO", "=", "np", ".", "mean", "(", "eta1", "[", "Y1", "==", "1", "]", ">", "t1", ")", "-", "np", ".", "mean", "(", "eta0", "[", "Y0", "==", "1", "]", ">", "t0", ")", "\n", "if", "DEO", ">", "delta", ":", "\n", "                ", "tmin", "=", "tmid", "\n", "", "else", ":", "\n", "                ", "tmax", "=", "tmid", "\n", "", "", "tstar", "=", "(", "tmin", "+", "tmax", ")", "/", "2", "\n", "\n", "", "else", ":", "\n", "        ", "tmin", "=", "-", "1", "*", "(", "1", "-", "pa_hat", ")", "*", "py0_hat", "\n", "tmax", "=", "0", "\n", "while", "tmax", "-", "tmin", ">", "pre_level", ":", "\n", "            ", "tmid", "=", "(", "tmin", "+", "tmax", ")", "/", "2", "\n", "t1", "=", "pa_hat", "*", "py1_hat", "/", "(", "2", "*", "pa_hat", "*", "py1_hat", "-", "tmid", ")", "\n", "t0", "=", "(", "1", "-", "pa_hat", ")", "*", "py0_hat", "/", "(", "2", "*", "(", "1", "-", "pa_hat", ")", "*", "py0_hat", "+", "tmid", ")", "\n", "DEO", "=", "np", ".", "mean", "(", "eta1", "[", "Y1", "==", "1", "]", ">", "t1", ")", "-", "np", ".", "mean", "(", "eta0", "[", "Y0", "==", "1", "]", ">", "t0", ")", "\n", "if", "DEO", ">", "-", "delta", ":", "\n", "                ", "tmin", "=", "tmid", "\n", "", "else", ":", "\n", "                ", "tmax", "=", "tmid", "\n", "", "", "tstar", "=", "(", "tmin", "+", "tmax", ")", "/", "2", "\n", "\n", "", "t1star", "=", "pa_hat", "*", "py1_hat", "/", "(", "2", "*", "pa_hat", "*", "py1_hat", "-", "tstar", ")", "\n", "t0star", "=", "(", "1", "-", "pa_hat", ")", "*", "py0_hat", "/", "(", "2", "*", "(", "1", "-", "pa_hat", ")", "*", "py0_hat", "+", "tstar", ")", "\n", "\n", "return", "t1star", ",", "t0star", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.balance_DDP": [[110, 121], ["numpy.mean", "numpy.mean"], "function", ["None"], ["", "def", "balance_DDP", "(", "eta_base", ",", "t_base", ",", "eta", ",", "tmin", ",", "tmax", ",", "pre_level", "=", "1e-5", ")", ":", "\n", "    ", "pbase", "=", "np", ".", "mean", "(", "eta_base", ">", "t_base", ")", "\n", "while", "tmax", "-", "tmin", ">", "pre_level", ":", "\n", "        ", "tmid", "=", "(", "tmin", "+", "tmax", ")", "/", "2", "\n", "pmid", "=", "np", ".", "mean", "(", "eta", ">", "tmid", ")", "\n", "if", "pmid", ">", "pbase", ":", "\n", "            ", "tmin", "=", "tmid", "\n", "", "else", ":", "\n", "            ", "tmax", "=", "tmid", "\n", "", "", "tstar", "=", "(", "tmin", "+", "tmax", ")", "/", "2", "\n", "return", "tstar", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.threshold_DemPa_multi": [[123, 152], ["sorted", "len", "numpy.max", "numpy.array", "list", "len", "len", "range", "numpy.array", "sum", "set", "numpy.max", "utils.balance_DDP", "np.array.append", "np.array.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.balance_DDP"], ["", "def", "threshold_DemPa_multi", "(", "eta", ",", "Z", ",", "pre_level", "=", "1e-5", ")", ":", "\n", "    ", "Z_list", "=", "sorted", "(", "list", "(", "set", "(", "Z", ")", ")", ")", "\n", "lenzlist", "=", "len", "(", "Z_list", ")", "\n", "eta_first", "=", "eta", "[", "Z", "==", "0", "]", "\n", "tmin1", "=", "0", "\n", "tmax1", "=", "np", ".", "max", "(", "eta_first", ")", "\n", "pa1", "=", "len", "(", "eta_first", ")", "/", "len", "(", "eta", ")", "\n", "while", "tmax1", "-", "tmin1", ">", "pre_level", ":", "\n", "        ", "tmid1", "=", "(", "tmin1", "+", "tmax1", ")", "/", "2", "\n", "tstar", "=", "[", "tmid1", "]", "\n", "s", "=", "[", "(", "tmid1", "-", "0.5", ")", "*", "pa1", "]", "\n", "for", "z", "in", "range", "(", "1", ",", "lenzlist", ")", ":", "\n", "            ", "eta_z", "=", "eta", "[", "Z", "==", "z", "]", "\n", "tzmin", "=", "0", "\n", "tzmax", "=", "np", ".", "max", "(", "eta_z", ")", "\n", "t_z", "=", "balance_DDP", "(", "eta_first", ",", "tmid1", ",", "eta_z", ",", "tzmin", ",", "tzmax", ")", "\n", "paz", "=", "len", "(", "eta_z", ")", "/", "len", "(", "eta", ")", "\n", "s_z", "=", "(", "t_z", "-", "0.5", ")", "*", "paz", "\n", "s", ".", "append", "(", "s_z", ")", "\n", "tstar", ".", "append", "(", "t_z", ")", "\n", "", "s", "=", "np", ".", "array", "(", "s", ")", "\n", "ssum", "=", "sum", "(", "s", ")", "\n", "\n", "if", "ssum", ">", "0", ":", "\n", "            ", "tmax1", "=", "tmid1", "\n", "", "else", ":", "\n", "            ", "tmin1", "=", "tmid1", "\n", "", "", "tstar", "=", "np", ".", "array", "(", "tstar", ")", "\n", "return", "tstar", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.measures_from_Yhat_DemPa": [[153, 168], ["isinstance", "isinstance", "isinstance", "isinstance", "abs", "pandas.DataFrame", "len", "len", "numpy.mean", "numpy.mean"], "function", ["None"], ["", "def", "measures_from_Yhat_DemPa", "(", "Y1hat", ",", "Y0hat", ",", "Y1", ",", "Y0", ")", ":", "\n", "    ", "assert", "isinstance", "(", "Y1hat", ",", "np", ".", "ndarray", ")", "\n", "assert", "isinstance", "(", "Y0hat", ",", "np", ".", "ndarray", ")", "\n", "assert", "isinstance", "(", "Y1", ",", "np", ".", "ndarray", ")", "\n", "assert", "isinstance", "(", "Y0", ",", "np", ".", "ndarray", ")", "\n", "\n", "datasize", "=", "len", "(", "Y1", ")", "+", "len", "(", "Y0", ")", "\n", "# Accuracy", "\n", "acc", "=", "(", "(", "Y1hat", "==", "Y1", ")", ".", "sum", "(", ")", "+", "(", "Y0hat", "==", "Y0", ")", ".", "sum", "(", ")", ")", "/", "datasize", "\n", "# DDP", "\n", "DDP", "=", "abs", "(", "np", ".", "mean", "(", "Y1hat", ")", "-", "np", ".", "mean", "(", "Y0hat", ")", ")", "\n", "\n", "data", "=", "[", "acc", ",", "DDP", "]", "\n", "columns", "=", "[", "'acc'", ",", "'DDP'", "]", "\n", "return", "pd", ".", "DataFrame", "(", "[", "data", "]", ",", "columns", "=", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.measures_from_Yhat_EqqOp": [[173, 188], ["isinstance", "isinstance", "isinstance", "isinstance", "abs", "pandas.DataFrame", "len", "len", "numpy.mean", "numpy.mean"], "function", ["None"], ["", "def", "measures_from_Yhat_EqqOp", "(", "Y1hat", ",", "Y0hat", ",", "Y1", ",", "Y0", ")", ":", "\n", "    ", "assert", "isinstance", "(", "Y1hat", ",", "np", ".", "ndarray", ")", "\n", "assert", "isinstance", "(", "Y0hat", ",", "np", ".", "ndarray", ")", "\n", "assert", "isinstance", "(", "Y1", ",", "np", ".", "ndarray", ")", "\n", "assert", "isinstance", "(", "Y0", ",", "np", ".", "ndarray", ")", "\n", "\n", "datasize", "=", "len", "(", "Y1", ")", "+", "len", "(", "Y0", ")", "\n", "# Accuracy", "\n", "acc", "=", "(", "(", "Y1hat", "==", "Y1", ")", ".", "sum", "(", ")", "+", "(", "Y0hat", "==", "Y0", ")", ".", "sum", "(", ")", ")", "/", "datasize", "\n", "# DEO", "\n", "DEO", "=", "abs", "(", "np", ".", "mean", "(", "Y1hat", "[", "Y1", "==", "1", "]", ")", "-", "np", ".", "mean", "(", "Y0hat", "[", "Y0", "==", "1", "]", ")", ")", "\n", "\n", "data", "=", "[", "acc", ",", "DEO", "]", "\n", "columns", "=", "[", "'acc'", ",", "'DEO'", "]", "\n", "return", "pd", ".", "DataFrame", "(", "[", "data", "]", ",", "columns", "=", "columns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xianlizeng_fairbayes.None.utils.measures_from_Yhat_DemPa_multi": [[195, 221], ["len", "sorted", "len", "range", "numpy.array", "numpy.sum", "pandas.DataFrame", "list", "Yz_hat.sum", "numpy.mean", "np.array.append", "numpy.abs", "set"], "function", ["None"], ["", "def", "measures_from_Yhat_DemPa_multi", "(", "eta", ",", "Z", ",", "Y", ",", "t", ")", ":", "\n", "    ", "datasize", "=", "len", "(", "Y", ")", "\n", "Z_list", "=", "sorted", "(", "list", "(", "set", "(", "Z", ")", ")", ")", "\n", "lenzlist", "=", "len", "(", "Z_list", ")", "\n", "accsum", "=", "0", "\n", "dppsum", "=", "0", "\n", "ddpset", "=", "[", "]", "\n", "for", "z", "in", "range", "(", "lenzlist", ")", ":", "\n", "        ", "Yz", "=", "Y", "[", "Z", "==", "z", "]", "\n", "Yz_hat", "=", "(", "eta", "[", "Z", "==", "z", "]", ">", "t", "[", "z", "]", ")", "\n", "accsum", "+=", "(", "Yz", "==", "Yz_hat", ")", ".", "sum", "(", ")", "\n", "dppsum", "+=", "Yz_hat", ".", "sum", "(", ")", "\n", "dppz", "=", "np", ".", "mean", "(", "Yz_hat", ")", "\n", "ddpset", ".", "append", "(", "dppz", ")", "\n", "# Accuracy", "\n", "", "acc", "=", "accsum", "/", "datasize", "\n", "\n", "# DDP", "\n", "ddp_mean", "=", "dppsum", "/", "datasize", "\n", "ddpset", "=", "np", ".", "array", "(", "ddpset", ")", "\n", "\n", "DDP", "=", "np", ".", "sum", "(", "np", ".", "abs", "(", "ddpset", "-", "ddp_mean", ")", ")", "\n", "\n", "data", "=", "[", "acc", ",", "DDP", "]", "\n", "columns", "=", "[", "'acc'", ",", "'DDP'", "]", "\n", "return", "pd", ".", "DataFrame", "(", "[", "data", "]", ",", "columns", "=", "columns", ")", "\n", "\n"]]}