{"home.repos.pwc.inspect_result.mpariente_AsSteroid.None.setup.read": [[14, 17], ["codecs.open", "fp.read", "os.path.join"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["def", "read", "(", "*", "parts", ")", ":", "\n", "    ", "with", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "here", ",", "*", "parts", ")", ",", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "return", "fp", ".", "read", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.None.setup.find_version": [[19, 25], ["setup.read", "re.search", "RuntimeError", "re.search.group"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "", "def", "find_version", "(", "*", "file_paths", ")", ":", "\n", "    ", "version_file", "=", "read", "(", "*", "file_paths", ")", "\n", "version_match", "=", "re", ".", "search", "(", "r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\"", ",", "version_file", ",", "re", ".", "M", ")", "\n", "if", "version_match", ":", "\n", "        ", "return", "version_match", ".", "group", "(", "1", ")", "\n", "", "raise", "RuntimeError", "(", "\"Unable to find version string.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.None.hubconf.demask": [[6, 31], ["asteroid.models.DeMask.from_pretrained", "asteroid.models.DeMask"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained"], ["def", "demask", "(", "name_url_or_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Load (pretrained) DeMask model\n\n    Args:\n        name_url_or_file (str): Model name (we'll find the URL),\n            model URL to download model, path to model file.\n            If None (default), DeMask is instantiated but no pretrained\n            weights are loaded.\n        **kwargs: Keyword arguments to pass to DeMask.\n\n    Returns:\n        DeMask instance (with ot without pretrained weights).\n\n    Examples:\n        >>> from torch import hub\n        >>> # Instantiate without pretrained weights\n        >>> model = hub.load('asteroid-team/asteroid', 'demask')\n        >>> # Use pretrained weights\n        >>> URL = \"popcornell/DeMask_Surgical_mask_speech_enhancement_v1\"\n        >>> model = hub.load('asteroid-team/asteroid', 'demask', URL)\n    \"\"\"", "\n", "# No pretrained weights", "\n", "if", "name_url_or_file", "is", "None", ":", "\n", "        ", "return", "models", ".", "DeMask", "(", "**", "kwargs", ")", "\n", "", "return", "models", ".", "DeMask", ".", "from_pretrained", "(", "name_url_or_file", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.None.hubconf.conv_tasnet": [[33, 58], ["asteroid.models.ConvTasNet.from_pretrained", "asteroid.models.ConvTasNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained"], ["", "def", "conv_tasnet", "(", "name_url_or_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Load (pretrained) ConvTasNet model\n\n    Args:\n        name_url_or_file (str): Model name (we'll find the URL),\n            model URL to download model, path to model file.\n            If None (default), ConvTasNet is instantiated but no pretrained\n            weights are loaded.\n        **kwargs: Keyword arguments to pass to ConvTasNet.\n\n    Returns:\n        ConvTasNet instance (with ot without pretrained weights).\n\n    Examples:\n        >>> from torch import hub\n        >>> # Instantiate without pretrained weights\n        >>> model = hub.load('asteroid-team/asteroid', 'conv_tasnet', n_src=2)\n        >>> # Use pretrained weights\n        >>> URL = \"TOCOME\"\n        >>> model = hub.load('asteroid-team/asteroid', 'conv_tasnet', URL)\n    \"\"\"", "\n", "# No pretrained weights", "\n", "if", "name_url_or_file", "is", "None", ":", "\n", "        ", "return", "models", ".", "ConvTasNet", "(", "**", "kwargs", ")", "\n", "", "return", "models", ".", "ConvTasNet", ".", "from_pretrained", "(", "name_url_or_file", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.None.hubconf.dprnn_tasnet": [[60, 85], ["asteroid.models.DPRNNTasNet.from_pretrained", "asteroid.models.DPRNNTasNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained"], ["", "def", "dprnn_tasnet", "(", "name_url_or_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Load (pretrained) DPRNNTasNet model\n\n    Args:\n        name_url_or_file (str): Model name (we'll find the URL),\n            model URL to download model, path to model file.\n            If None (default), DPRNNTasNet is instantiated but no pretrained\n            weights are loaded.\n        **kwargs: Keyword arguments to pass to DPRNNTasNet.\n\n    Returns:\n        DPRNNTasNet instance (with ot without pretrained weights).\n\n    Examples:\n        >>> from torch import hub\n        >>> # Instantiate without pretrained weights\n        >>> model = hub.load('asteroid-team/asteroid', 'dprnn_tasnet')\n        >>> # Use pretrained weights\n        >>> URL = \"TOCOME\"\n        >>> model = hub.load('asteroid-team/asteroid', 'dprnn_tasnet', URL)\n    \"\"\"", "\n", "# No pretrained weights", "\n", "if", "name_url_or_file", "is", "None", ":", "\n", "        ", "return", "models", ".", "DPRNNTasNet", "(", "**", "kwargs", ")", "\n", "", "return", "models", ".", "DPRNNTasNet", ".", "from_pretrained", "(", "name_url_or_file", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.None.hubconf.lstm_tasnet": [[87, 112], ["asteroid.models.LSTMTasNet.from_pretrained", "asteroid.models.LSTMTasNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained"], ["", "def", "lstm_tasnet", "(", "name_url_or_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Load (pretrained) LSTM TasNet model\n\n    Args:\n        name_url_or_file (str): Model name (we'll find the URL),\n            model URL to download model, path to model file.\n            If None (default), LSTMTasNet is instantiated but no pretrained\n            weights are loaded.\n        **kwargs: Keyword arguments to pass to LSTMTasNet.\n\n    Returns:\n        LSTMTasNet instance (with ot without pretrained weights).\n\n    Examples:\n        >>> from torch import hub\n        >>> # Instantiate without pretrained weights\n        >>> model = hub.load('asteroid-team/asteroid', 'lstm_tasnet')\n        >>> # Use pretrained weights\n        >>> URL = \"TOCOME\"\n        >>> model = hub.load('asteroid-team/asteroid', 'lstm_tasnet', URL)\n    \"\"\"", "\n", "# No pretrained weights", "\n", "if", "name_url_or_file", "is", "None", ":", "\n", "        ", "return", "models", ".", "LSTMTasNet", "(", "**", "kwargs", ")", "\n", "", "return", "models", ".", "LSTMTasNet", ".", "from_pretrained", "(", "name_url_or_file", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.None.hubconf.dpt_net": [[114, 139], ["asteroid.models.DPTNet.from_pretrained", "asteroid.models.DPTNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained"], ["", "def", "dpt_net", "(", "name_url_or_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Load (pretrained) DualPathTransformer (DPTNet) model\n\n    Args:\n        name_url_or_file (str): Model name (we'll find the URL),\n            model URL to download model, path to model file.\n            If None (default), DPTNet is instantiated but no pretrained\n            weights are loaded.\n        **kwargs: Keyword arguments to pass to DPTNet.\n\n    Returns:\n        DPTNet instance (with ot without pretrained weights).\n\n    Examples:\n        >>> from torch import hub\n        >>> # Instantiate without pretrained weights\n        >>> model = hub.load('asteroid-team/asteroid', 'dpt_net')\n        >>> # Use pretrained weights\n        >>> URL = \"TOCOME\"\n        >>> model = hub.load('asteroid-team/asteroid', 'dpt_net', URL)\n    \"\"\"", "\n", "# No pretrained weights", "\n", "if", "name_url_or_file", "is", "None", ":", "\n", "        ", "return", "models", ".", "DPTNet", "(", "**", "kwargs", ")", "\n", "", "return", "models", ".", "DPTNet", ".", "from_pretrained", "(", "name_url_or_file", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.None.hubconf.sudormrf_net": [[141, 166], ["asteroid.models.SuDORMRFNet.from_pretrained", "asteroid.models.SuDORMRFNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained"], ["", "def", "sudormrf_net", "(", "name_url_or_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Load (pretrained) SuDORMRF model.\n\n    Args:\n        name_url_or_file (str): Model name (we'll find the URL),\n            model URL to download model, path to model file.\n            If None (default), SuDORMRFNet is instantiated but no pretrained\n            weights are loaded.\n        **kwargs: Keyword arguments to pass to SuDORMRFNet.\n\n    Returns:\n        SuDORMRF instance (with ot without pretrained weights).\n\n    Examples:\n        >>> from torch import hub\n        >>> # Instantiate without pretrained weights\n        >>> model = hub.load('asteroid-team/asteroid', 'sudormrf_net')\n        >>> # Use pretrained weights\n        >>> URL = \"TOCOME\"\n        >>> model = hub.load('asteroid-team/asteroid', 'sudormrf_net', URL)\n    \"\"\"", "\n", "# No pretrained weights", "\n", "if", "name_url_or_file", "is", "None", ":", "\n", "        ", "return", "models", ".", "SuDORMRFNet", "(", "**", "kwargs", ")", "\n", "", "return", "models", ".", "SuDORMRFNet", ".", "from_pretrained", "(", "name_url_or_file", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.None.hubconf.sudormrf_improved_net": [[168, 193], ["asteroid.models.SuDORMRFImprovedNet.from_pretrained", "asteroid.models.SuDORMRFImprovedNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained"], ["", "def", "sudormrf_improved_net", "(", "name_url_or_file", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Load (pretrained) SuDORMRFImprovedNet improved model\n\n    Args:\n        name_url_or_file (str): Model name (we'll find the URL),\n            model URL to download model, path to model file.\n            If None (default), SuDORMRFImprovedNet is instantiated but no pretrained\n            weights are loaded.\n        **kwargs: Keyword arguments to pass to SuDORMRFImprovedNet.\n\n    Returns:\n        SuDORMRFImprovedNet instance (with ot without pretrained weights).\n\n    Examples:\n        >>> from torch import hub\n        >>> # Instantiate without pretrained weights\n        >>> model = hub.load('asteroid-team/asteroid', 'lstm_tasnet')\n        >>> # Use pretrained weights\n        >>> URL = \"TOCOME\"\n        >>> model = hub.load('asteroid-team/asteroid', 'lstm_tasnet', URL)\n    \"\"\"", "\n", "# No pretrained weights", "\n", "if", "name_url_or_file", "is", "None", ":", "\n", "        ", "return", "models", ".", "SuDORMRFImprovedNet", "(", "**", "kwargs", ")", "\n", "", "return", "models", ".", "SuDORMRFImprovedNet", ".", "from_pretrained", "(", "name_url_or_file", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.OnReIm.__init__": [[67, 71], ["torch.nn.Module.__init__", "module_cls", "module_cls"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "module_cls", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "re_module", "=", "module_cls", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "im_module", "=", "module_cls", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.OnReIm.forward": [[72, 74], ["complex_nn.torch_complex_from_reim", "complex_nn.OnReIm.re_module", "complex_nn.OnReIm.im_module"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_reim"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch_complex_from_reim", "(", "self", ".", "re_module", "(", "x", ".", "real", ")", ",", "self", ".", "im_module", "(", "x", ".", "imag", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.ComplexMultiplicationWrapper.__init__": [[90, 94], ["torch.nn.Module.__init__", "module_cls", "module_cls"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "module_cls", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "re_module", "=", "module_cls", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "im_module", "=", "module_cls", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.ComplexMultiplicationWrapper.forward": [[95, 99], ["complex_nn.torch_complex_from_reim", "complex_nn.ComplexMultiplicationWrapper.re_module", "complex_nn.ComplexMultiplicationWrapper.im_module", "complex_nn.ComplexMultiplicationWrapper.re_module", "complex_nn.ComplexMultiplicationWrapper.im_module"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_reim"], ["", "def", "forward", "(", "self", ",", "x", ":", "ComplexTensor", ")", "->", "ComplexTensor", ":", "\n", "        ", "return", "torch_complex_from_reim", "(", "\n", "self", ".", "re_module", "(", "x", ".", "real", ")", "-", "self", ".", "im_module", "(", "x", ".", "imag", ")", ",", "\n", "self", ".", "re_module", "(", "x", ".", "imag", ")", "+", "self", ".", "im_module", "(", "x", ".", "real", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.ComplexSingleRNN.__init__": [[125, 145], ["torch.nn.Module.__init__", "complex_nn.ComplexMultiplicationWrapper", "torch.nn.ModuleList", "range", "complex_nn.ComplexSingleRNN.rnns.append", "complex_nn.ComplexMultiplicationWrapper"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "rnn_type", ",", "input_size", ",", "hidden_size", ",", "n_layers", "=", "1", ",", "dropout", "=", "0", ",", "bidirectional", "=", "False", "\n", ")", ":", "\n", "        ", "assert", "not", "(", "dropout", "and", "n_layers", ">", "1", ")", ",", "\"Dropout is not yet supported for complex RNN\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "from", ".", "masknn", ".", "recurrent", "import", "SingleRNN", "# Avoid circual import", "\n", "\n", "kwargs", "=", "{", "\n", "\"rnn_type\"", ":", "rnn_type", ",", "\n", "\"hidden_size\"", ":", "hidden_size", ",", "\n", "\"n_layers\"", ":", "1", ",", "\n", "\"dropout\"", ":", "0", ",", "\n", "\"bidirectional\"", ":", "bidirectional", ",", "\n", "}", "\n", "first_rnn", "=", "ComplexMultiplicationWrapper", "(", "SingleRNN", ",", "input_size", "=", "input_size", ",", "**", "kwargs", ")", "\n", "self", ".", "rnns", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "first_rnn", "]", ")", "\n", "for", "_", "in", "range", "(", "n_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "rnns", ".", "append", "(", "\n", "ComplexMultiplicationWrapper", "(", "\n", "SingleRNN", ",", "input_size", "=", "first_rnn", ".", "re_module", ".", "output_size", ",", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.ComplexSingleRNN.output_size": [[148, 151], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "rnns", "[", "-", "1", "]", ".", "re_module", ".", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.ComplexSingleRNN.forward": [[152, 157], ["rnn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "ComplexTensor", ")", "->", "ComplexTensor", ":", "\n", "        ", "\"\"\"Input shape [batch, seq, feats]\"\"\"", "\n", "for", "rnn", "in", "self", ".", "rnns", ":", "\n", "            ", "x", "=", "rnn", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.BoundComplexMask.__init__": [[166, 169], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "bound_type", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bound_type", "=", "bound_type", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.BoundComplexMask.forward": [[170, 172], ["complex_nn.bound_complex_mask"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.bound_complex_mask"], ["", "def", "forward", "(", "self", ",", "mask", ":", "ComplexTensor", ")", ":", "\n", "        ", "return", "bound_complex_mask", "(", "mask", ",", "self", ".", "bound_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.is_torch_complex": [[24, 26], ["x.is_complex"], "function", ["None"], ["def", "is_torch_complex", "(", "x", ")", ":", "\n", "    ", "return", "x", ".", "is_complex", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_magphase": [[28, 31], ["torch.view_as_complex", "torch.stack", "torch.cos", "torch.sin"], "function", ["None"], ["", "def", "torch_complex_from_magphase", "(", "mag", ",", "phase", ")", ":", "\n", "    ", "return", "torch", ".", "view_as_complex", "(", "\n", "torch", ".", "stack", "(", "(", "mag", "*", "torch", ".", "cos", "(", "phase", ")", ",", "mag", "*", "torch", ".", "sin", "(", "phase", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_reim": [[34, 36], ["torch.view_as_complex", "torch.stack"], "function", ["None"], ["", "def", "torch_complex_from_reim", "(", "re", ",", "im", ")", ":", "\n", "    ", "return", "torch", ".", "view_as_complex", "(", "torch", ".", "stack", "(", "[", "re", ",", "im", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.on_reim": [[38, 57], ["functools.wraps", "complex_nn.torch_complex_from_reim", "f", "torch.sigmoid"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_reim", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.sigmoid"], ["", "def", "on_reim", "(", "f", ")", ":", "\n", "    ", "\"\"\"Make a complex-valued function callable from a real-valued one by applying it to\n    the real and imaginary components independently.\n\n    Return:\n        cf(x), complex version of `f`: A function that applies `f` to the real and\n        imaginary components of `x` and returns the result as PyTorch complex tensor.\n    \"\"\"", "\n", "\n", "@", "functools", ".", "wraps", "(", "f", ")", "\n", "def", "cf", "(", "x", ")", ":", "\n", "        ", "return", "torch_complex_from_reim", "(", "f", "(", "x", ".", "real", ")", ",", "f", "(", "x", ".", "imag", ")", ")", "\n", "\n", "# functools.wraps keeps the original name of `f`, which might be confusing,", "\n", "# since we are creating a new function that behaves differently.", "\n", "# Both __name__ and __qualname__ are used by printing code.", "\n", "", "cf", ".", "__name__", "==", "f\"{f.__name__} (complex)\"", "\n", "cf", ".", "__qualname__", "==", "f\"{f.__qualname__} (complex)\"", "\n", "return", "cf", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.bound_complex_mask": [[174, 202], ["complex_nn.on_reim", "asteroid_filterbanks.transforms.magphase", "complex_nn.torch_complex_from_magphase", "ValueError", "asteroid_filterbanks.transforms.from_torch_complex", "torch.tanh"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.on_reim", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_magphase", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.tanh"], ["", "", "def", "bound_complex_mask", "(", "mask", ":", "ComplexTensor", ",", "bound_type", "=", "\"tanh\"", ")", ":", "\n", "    ", "r\"\"\"Bound a complex mask, as proposed in [1], section 3.2.\n\n    Valid bound types, for a complex mask :math:`M = |M| \u22c5 e^{i \u03c6(M)}`:\n\n    - Unbounded (\"UBD\"): :math:`M_{\\mathrm{UBD}} = M`\n    - Sigmoid (\"BDSS\"): :math:`M_{\\mathrm{BDSS}} = \u03c3(|M|) e^{i \u03c3(\u03c6(M))}`\n    - Tanh (\"BDT\"): :math:`M_{\\mathrm{BDT}} = \\mathrm{tanh}(|M|) e^{i \u03c6(M)}`\n\n    Args:\n        bound_type (str or None): The type of bound to use, either of\n            \"tanh\"/\"bdt\" (default), \"sigmoid\"/\"bdss\" or None/\"bdt\".\n\n    References\n        [1] : \"Phase-aware Speech Enhancement with Deep Complex U-Net\",\n        Hyeong-Seok Choi et al. https://arxiv.org/abs/1903.03107\n    \"\"\"", "\n", "if", "bound_type", "in", "{", "\"BDSS\"", ",", "\"sigmoid\"", "}", ":", "\n", "        ", "return", "on_reim", "(", "torch", ".", "sigmoid", ")", "(", "mask", ")", "\n", "", "elif", "bound_type", "in", "{", "\"BDT\"", ",", "\"tanh\"", ",", "\"UBD\"", ",", "None", "}", ":", "\n", "        ", "mask_mag", ",", "mask_phase", "=", "transforms", ".", "magphase", "(", "transforms", ".", "from_torch_complex", "(", "mask", ")", ")", "\n", "if", "bound_type", "in", "{", "\"BDT\"", ",", "\"tanh\"", "}", ":", "\n", "            ", "mask_mag_bounded", "=", "torch", ".", "tanh", "(", "mask_mag", ")", "\n", "", "else", ":", "\n", "            ", "mask_mag_bounded", "=", "mask_mag", "\n", "", "return", "torch_complex_from_magphase", "(", "mask_mag_bounded", ",", "mask_phase", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Unknown mask bound {bound_type}\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.binarize.Binarize.__init__": [[21, 33], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "threshold", "=", "0.5", ",", "stability", "=", "0.1", ",", "sample_rate", "=", "8000", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            threshold (float): if x > threshold 0 else 1\n            stability (float): Minimum number of seconds of 0 (or 1) required to change from 1 (or 0) to 0 (or 1)\n            sample_rate (int): The sample rate of the wave form\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "threshold", "=", "threshold", "\n", "self", ".", "stability", "=", "stability", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.binarize.Binarize.forward": [[34, 40], ["transform_to_binary_sequence.squeeze().tolist", "binarize.count_same_pair", "binarize.transform_to_binary_sequence", "transform_to_binary_sequence.squeeze"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.binarize.count_same_pair", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.binarize.transform_to_binary_sequence"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "active", "=", "x", ">", "self", ".", "threshold", "\n", "active", "=", "active", ".", "squeeze", "(", "1", ")", ".", "tolist", "(", ")", "\n", "pairs", "=", "count_same_pair", "(", "active", ")", "\n", "active", "=", "transform_to_binary_sequence", "(", "pairs", ",", "self", ".", "stability", ",", "self", ".", "sample_rate", ")", "\n", "return", "active", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.binarize.count_same_pair": [[42, 62], ["result.append", "sum", "itertools.groupby"], "function", ["None"], ["", "", "def", "count_same_pair", "(", "nums", ")", ":", "\n", "    ", "\"\"\"Transform a list of 0 and 1 in a list of (value, num_consecutive_occurences).\n\n    Args:\n        nums (list): List of list containing the binary sequences.\n\n    Returns:\n        List of values and number consecutive occurences.\n\n    Example:\n        >>> nums = [[0,0,1,0]]\n        >>> result = count_same_pair(nums)\n        >>> print(result)\n        [[[0, 2], [1, 1], [0, 1]]]\n\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "num", "in", "nums", ":", "\n", "        ", "result", ".", "append", "(", "[", "[", "i", ",", "sum", "(", "1", "for", "_", "in", "group", ")", "]", "for", "i", ",", "group", "in", "groupby", "(", "num", ")", "]", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.binarize.transform_to_binary_sequence": [[64, 109], ["torch.vstack().unsqueeze", "binarize.check_silence_or_voice", "torch.vstack().unsqueeze.append", "len", "torch.hstack", "torch.vstack", "int", "binarize.resolve_instability", "active.append", "active.append", "torch.ones", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.binarize.check_silence_or_voice", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.binarize.resolve_instability"], ["", "def", "transform_to_binary_sequence", "(", "pairs", ",", "stability", ",", "sample_rate", ")", ":", "\n", "    ", "\"\"\"Transforms list of value and consecutive occurrences into a binary sequence with respect to stability\n\n    Args:\n        pairs (List): List of list of value and consecutive occurrences\n        stability (Float): Minimal number of seconds to change from 0 to 1 or 1 to 0.\n        sample_rate (int): The sample rate of the waveform.\n\n    Returns:\n        Torch.tensor : The binary sequences.\n    \"\"\"", "\n", "\n", "batch_active", "=", "[", "]", "\n", "for", "pair", "in", "pairs", ":", "\n", "        ", "active", "=", "[", "]", "\n", "# Check for fully silent or fully voice sequence", "\n", "active", ",", "check", "=", "check_silence_or_voice", "(", "active", ",", "pair", ")", "\n", "if", "check", ":", "\n", "            ", "return", "active", "\n", "# Counter for every set of (value, num_consecutive_occ)", "\n", "", "i", "=", "0", "\n", "# Do until every every sets as been used i.e until we have same sequence length as input length", "\n", "while", "i", "<", "len", "(", "pair", ")", ":", "\n", "            ", "value", ",", "num_consecutive_occurrences", "=", "pair", "[", "i", "]", "\n", "# Counter for active set of (value, num_consecutive_occ) i.e (1,num_consecutive_occ)", "\n", "actived", "=", "0", "\n", "# Counter for inactive set of (value, num_consecutive_occ) i.e (0,num_consecutive_occ)", "\n", "not_actived", "=", "0", "\n", "# num_consecutive_occ <  int(stability * sample_rate) need to resolve instability", "\n", "if", "num_consecutive_occurrences", "<", "int", "(", "stability", "*", "sample_rate", ")", ":", "\n", "# Resolve instability", "\n", "                ", "active", ",", "i", "=", "resolve_instability", "(", "\n", "i", ",", "pair", ",", "stability", ",", "sample_rate", ",", "actived", ",", "not_actived", ",", "active", "\n", ")", "\n", "# num_consecutive_occ >  int(stability * sample_rate) we can already choose", "\n", "", "else", ":", "\n", "                ", "if", "value", ":", "\n", "                    ", "active", ".", "append", "(", "torch", ".", "ones", "(", "pair", "[", "i", "]", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "active", ".", "append", "(", "torch", ".", "zeros", "(", "pair", "[", "i", "]", "[", "1", "]", ")", ")", "\n", "", "i", "+=", "1", "\n", "# Stack sequence to return a batch shaped tensor", "\n", "", "", "batch_active", ".", "append", "(", "torch", ".", "hstack", "(", "active", ")", ")", "\n", "", "batch_active", "=", "torch", ".", "vstack", "(", "batch_active", ")", ".", "unsqueeze", "(", "1", ")", "\n", "return", "batch_active", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.binarize.check_silence_or_voice": [[111, 128], ["len", "torch.ones", "torch.zeros"], "function", ["None"], ["", "def", "check_silence_or_voice", "(", "active", ",", "pair", ")", ":", "\n", "    ", "\"\"\"Check if sequence is fully silence or fully voice.\n\n    Args:\n        active (List) : List containing the binary sequence\n        pair: (List): list of value and consecutive occurrences\n\n    \"\"\"", "\n", "value", ",", "num_consecutive_occurrences", "=", "pair", "[", "0", "]", "\n", "check", "=", "False", "\n", "if", "len", "(", "pair", ")", "==", "1", ":", "\n", "        ", "check", "=", "True", "\n", "if", "value", ":", "\n", "            ", "active", "=", "torch", ".", "ones", "(", "num_consecutive_occurrences", ")", "\n", "", "else", ":", "\n", "            ", "active", "=", "torch", ".", "zeros", "(", "num_consecutive_occurrences", ")", "\n", "", "", "return", "active", ",", "check", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.binarize.resolve_instability": [[130, 176], ["len", "int", "int", "len", "active.append", "active.append", "active.append", "torch.ones", "torch.zeros", "int", "len", "torch.zeros", "active.append", "active.append", "torch.ones", "torch.zeros"], "function", ["None"], ["", "def", "resolve_instability", "(", "i", ",", "pair", ",", "stability", ",", "sample_rate", ",", "actived", ",", "not_actived", ",", "active", ")", ":", "\n", "    ", "\"\"\"Resolve stability issue in input list of value and num_consecutive_occ\n\n    Args:\n        i (int): The index of the considered pair of value and num_consecutive_occ.\n        pair (list) : Value and num_consecutive_occ.\n        stability (float): Minimal number of seconds to change from 0 to 1 or 1 to 0.\n        sample_rate (int): The sample rate of the waveform.\n        actived (int) : Number of occurrences of the value 1.\n        not_actived (int): Number of occurrences of the value 0.\n        active (list) : The binary sequence.\n\n    Returns:\n        active (list) : The binary sequence.\n         i (int): The index of the considered pair of value and num_consecutive_occ.\n    \"\"\"", "\n", "# Until we find stability count the number of samples active and inactive", "\n", "while", "i", "<", "len", "(", "pair", ")", "and", "pair", "[", "i", "]", "[", "1", "]", "<", "int", "(", "stability", "*", "sample_rate", ")", ":", "\n", "        ", "value", ",", "num_consecutive_occurrences", "=", "pair", "[", "i", "]", "\n", "if", "value", ":", "\n", "            ", "actived", "+=", "num_consecutive_occurrences", "\n", "i", "+=", "1", "\n", "", "else", ":", "\n", "            ", "not_actived", "+=", "num_consecutive_occurrences", "\n", "i", "+=", "1", "\n", "# If the length of unstable samples is smaller than the stability criteria and we are already in a state", "\n", "# then keep this state.", "\n", "", "", "if", "actived", "+", "not_actived", "<", "int", "(", "stability", "*", "sample_rate", ")", "and", "len", "(", "active", ")", ">", "0", ":", "\n", "# Last value", "\n", "        ", "if", "active", "[", "-", "1", "]", "[", "0", "]", "==", "1", ":", "\n", "            ", "active", ".", "append", "(", "torch", ".", "ones", "(", "actived", "+", "not_actived", ")", ")", "\n", "", "else", ":", "\n", "            ", "active", ".", "append", "(", "torch", ".", "zeros", "(", "actived", "+", "not_actived", ")", ")", "\n", "# If the length of unstable samples is smaller than the stability criteria and but we have no state yet", "\n", "# then consider it silent", "\n", "", "", "elif", "actived", "+", "not_actived", "<", "int", "(", "stability", "*", "sample_rate", ")", "and", "len", "(", "active", ")", "==", "0", ":", "\n", "        ", "active", ".", "append", "(", "torch", ".", "zeros", "(", "actived", "+", "not_actived", ")", ")", "\n", "# If the length of unstable samples is greater than the stability criteria then compare number of active", "\n", "# and inactive samples and choose.", "\n", "", "else", ":", "\n", "        ", "if", "actived", ">", "not_actived", ":", "\n", "            ", "active", ".", "append", "(", "torch", ".", "ones", "(", "actived", "+", "not_actived", ")", ")", "\n", "", "else", ":", "\n", "            ", "active", ".", "append", "(", "torch", ".", "zeros", "(", "actived", "+", "not_actived", ")", ")", "\n", "\n", "", "", "return", "active", ",", "i", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.MetricTracker.__init__": [[134, 152], ["tuple", "pandas.DataFrame"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "sample_rate", ",", "\n", "metrics_list", "=", "tuple", "(", "ALL_METRICS", ")", ",", "\n", "average", "=", "True", ",", "\n", "compute_permutation", "=", "False", ",", "\n", "ignore_metrics_errors", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "sample_rate", "=", "sample_rate", "\n", "# TODO: support WER in metrics_list when merged.", "\n", "self", ".", "metrics_list", "=", "metrics_list", "\n", "self", ".", "average", "=", "average", "\n", "self", ".", "compute_permutation", "=", "compute_permutation", "\n", "self", ".", "ignore_metrics_errors", "=", "ignore_metrics_errors", "\n", "\n", "self", ".", "series_list", "=", "[", "]", "\n", "self", ".", "_len_last_saved", "=", "0", "\n", "self", ".", "_all_metrics", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.MetricTracker.__call__": [[153, 180], ["metrics.get_metrics", "get_metrics.update", "metrics.MetricTracker.series_list.append", "pandas.Series"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics"], ["", "def", "__call__", "(", "\n", "self", ",", "*", ",", "mix", ":", "np", ".", "ndarray", ",", "clean", ":", "np", ".", "ndarray", ",", "estimate", ":", "np", ".", "ndarray", ",", "filename", "=", "None", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Compute metrics for mix/clean/estimate and log it to the class.\n\n        Args:\n            mix (np.array): mixture array.\n            clean (np.array): reference array.\n            estimate (np.array): estimate array.\n            sample_rate (int): sampling rate of the audio clips.\n            filename (str, optional): If computing a metric fails, print this\n                filename along with the exception/warning message for debugging purposes.\n            **kwargs: Any key, value pair to log in the utterance metric (filename, speaker ID, etc...)\n        \"\"\"", "\n", "utt_metrics", "=", "get_metrics", "(", "\n", "mix", ",", "\n", "clean", ",", "\n", "estimate", ",", "\n", "sample_rate", "=", "self", ".", "sample_rate", ",", "\n", "metrics_list", "=", "self", ".", "metrics_list", ",", "\n", "average", "=", "self", ".", "average", ",", "\n", "compute_permutation", "=", "self", ".", "compute_permutation", ",", "\n", "ignore_metrics_errors", "=", "self", ".", "ignore_metrics_errors", ",", "\n", "filename", "=", "filename", ",", "\n", ")", "\n", "utt_metrics", ".", "update", "(", "kwargs", ")", "\n", "self", ".", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.MetricTracker.as_df": [[181, 188], ["len", "pandas.DataFrame", "pandas.DataFrame", "len"], "methods", ["None"], ["", "def", "as_df", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return dataframe containing the results (cached).\"\"\"", "\n", "if", "self", ".", "_len_last_saved", "==", "len", "(", "self", ".", "series_list", ")", ":", "\n", "            ", "return", "self", ".", "_all_metrics", "\n", "", "self", ".", "_len_last_saved", "=", "len", "(", "self", ".", "series_list", ")", "\n", "self", ".", "_all_metrics", "=", "pd", ".", "DataFrame", "(", "self", ".", "series_list", ")", "\n", "return", "pd", ".", "DataFrame", "(", "self", ".", "series_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.MetricTracker.final_report": [[189, 203], ["metrics.MetricTracker.as_df", "metrics_df[].mean", "ldf.mean", "open", "json.dump", "dump_path.endswith"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.MetricTracker.as_df"], ["", "def", "final_report", "(", "self", ",", "dump_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"Return dict of average metrics. Dump to JSON if `dump_path` is not None.\"\"\"", "\n", "final_results", "=", "{", "}", "\n", "metrics_df", "=", "self", ".", "as_df", "(", ")", "\n", "for", "metric_name", "in", "self", ".", "metrics_list", ":", "\n", "            ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "metrics_df", "[", "metric_name", "]", "-", "metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "if", "dump_path", "is", "not", "None", ":", "\n", "            ", "dump_path", "=", "dump_path", "+", "\".json\"", "if", "not", "dump_path", ".", "endswith", "(", "\".json\"", ")", "else", "dump_path", "\n", "with", "open", "(", "dump_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "", "", "return", "final_results", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.MockWERTracker.__init__": [[206, 208], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.MockWERTracker.__call__": [[209, 211], ["dict"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.MockWERTracker.final_report_as_markdown": [[212, 214], ["None"], "methods", ["None"], ["", "def", "final_report_as_markdown", "(", "self", ")", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.__init__": [[226, 255], ["ModelDownloader", "Speech2Text", "int", "metrics.WERTracker._df_to_dict", "collections.Counter", "collections.Counter", "collections.Counter", "jiwer.Compose", "ModelDownloader.download_and_unpack", "jiwer.ToLowerCase", "jiwer.RemovePunctuation", "jiwer.RemoveMultipleSpaces", "jiwer.Strip", "jiwer.SentencesToListOfWords", "jiwer.RemoveEmptyStrings"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker._df_to_dict"], ["def", "__init__", "(", "self", ",", "model_name", ",", "trans_df", ",", "use_gpu", "=", "True", ")", ":", "\n", "\n", "        ", "from", "espnet2", ".", "bin", ".", "asr_inference", "import", "Speech2Text", "\n", "from", "espnet_model_zoo", ".", "downloader", "import", "ModelDownloader", "\n", "import", "jiwer", "\n", "\n", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "device", "=", "\"cuda\"", "if", "use_gpu", "else", "\"cpu\"", "\n", "d", "=", "ModelDownloader", "(", ")", "\n", "self", ".", "asr_model", "=", "Speech2Text", "(", "**", "d", ".", "download_and_unpack", "(", "model_name", ")", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "input_txt_list", "=", "[", "]", "\n", "self", ".", "clean_txt_list", "=", "[", "]", "\n", "self", ".", "output_txt_list", "=", "[", "]", "\n", "self", ".", "transcriptions", "=", "[", "]", "\n", "self", ".", "true_txt_list", "=", "[", "]", "\n", "self", ".", "sample_rate", "=", "int", "(", "d", ".", "data_frame", "[", "d", ".", "data_frame", "[", "\"name\"", "]", "==", "model_name", "]", "[", "\"fs\"", "]", ")", "\n", "self", ".", "trans_df", "=", "trans_df", "\n", "self", ".", "trans_dic", "=", "self", ".", "_df_to_dict", "(", "trans_df", ")", "\n", "self", ".", "mix_counter", "=", "Counter", "(", ")", "\n", "self", ".", "clean_counter", "=", "Counter", "(", ")", "\n", "self", ".", "est_counter", "=", "Counter", "(", ")", "\n", "self", ".", "transformation", "=", "jiwer", ".", "Compose", "(", "\n", "[", "\n", "jiwer", ".", "ToLowerCase", "(", ")", ",", "\n", "jiwer", ".", "RemovePunctuation", "(", ")", ",", "\n", "jiwer", ".", "RemoveMultipleSpaces", "(", ")", ",", "\n", "jiwer", ".", "Strip", "(", ")", ",", "\n", "jiwer", ".", "SentencesToListOfWords", "(", ")", ",", "\n", "jiwer", ".", "RemoveEmptyStrings", "(", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.__call__": [[258, 328], ["collections.Counter", "collections.Counter", "collections.Counter", "metrics.WERTracker.predict_hypothesis", "dict", "enumerate", "enumerate", "enumerate", "metrics.WERTracker.transcriptions.append", "dict", "metrics.WERTracker.resample", "metrics.WERTracker.true_txt_list.append", "collections.Counter", "metrics.WERTracker.input_txt_list.append", "zip", "metrics.WERTracker.predict_hypothesis", "collections.Counter", "metrics.WERTracker.clean_txt_list.append", "zip", "metrics.WERTracker.predict_hypothesis", "collections.Counter", "metrics.WERTracker.output_txt_list.append", "dict", "metrics.WERTracker.hsdi", "dict", "metrics.WERTracker.hsdi", "dict", "metrics.WERTracker.hsdi", "dict", "metrics.WERTracker.wer_from_hsdi", "metrics.WERTracker.wer_from_hsdi", "metrics.WERTracker.wer_from_hsdi", "dict", "dict", "dict"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.predict_hypothesis", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.resample", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.predict_hypothesis", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.predict_hypothesis", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.hsdi", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.hsdi", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.hsdi", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.wer_from_hsdi", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.wer_from_hsdi", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.wer_from_hsdi"], ["", "def", "__call__", "(", "\n", "self", ",", "\n", "*", ",", "\n", "mix", ":", "np", ".", "ndarray", ",", "\n", "clean", ":", "np", ".", "ndarray", ",", "\n", "estimate", ":", "np", ".", "ndarray", ",", "\n", "sample_rate", ":", "int", ",", "\n", "wav_id", ":", "List", "[", "str", "]", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Compute and store best hypothesis for the mixture and the estimates\"\"\"", "\n", "if", "sample_rate", "!=", "self", ".", "sample_rate", ":", "\n", "            ", "mix", ",", "clean", ",", "estimate", "=", "self", ".", "resample", "(", "\n", "mix", ",", "clean", ",", "estimate", ",", "fs_from", "=", "sample_rate", ",", "fs_to", "=", "self", ".", "sample_rate", "\n", ")", "\n", "", "local_mix_counter", "=", "Counter", "(", ")", "\n", "local_clean_counter", "=", "Counter", "(", ")", "\n", "local_est_counter", "=", "Counter", "(", ")", "\n", "# Count the mixture output for each speaker", "\n", "txt", "=", "self", ".", "predict_hypothesis", "(", "mix", ")", "\n", "\n", "# Dict to gather transcriptions and IDs", "\n", "trans_dict", "=", "dict", "(", "mixture_txt", "=", "{", "}", ",", "clean", "=", "{", "}", ",", "estimates", "=", "{", "}", ",", "truth", "=", "{", "}", ")", "\n", "# Get mixture transcription", "\n", "trans_dict", "[", "\"mixture_txt\"", "]", "=", "txt", "\n", "#  Get ground truth transcription and IDs", "\n", "for", "i", ",", "tmp_id", "in", "enumerate", "(", "wav_id", ")", ":", "\n", "            ", "trans_dict", "[", "\"truth\"", "]", "[", "f\"utt_id_{i}\"", "]", "=", "tmp_id", "\n", "trans_dict", "[", "\"truth\"", "]", "[", "f\"txt_{i}\"", "]", "=", "self", ".", "trans_dic", "[", "tmp_id", "]", "\n", "self", ".", "true_txt_list", ".", "append", "(", "dict", "(", "utt_id", "=", "tmp_id", ",", "text", "=", "self", ".", "trans_dic", "[", "tmp_id", "]", ")", ")", "\n", "# Mixture", "\n", "", "for", "tmp_id", "in", "wav_id", ":", "\n", "            ", "out_count", "=", "Counter", "(", "\n", "self", ".", "hsdi", "(", "\n", "truth", "=", "self", ".", "trans_dic", "[", "tmp_id", "]", ",", "hypothesis", "=", "txt", ",", "transformation", "=", "self", ".", "transformation", "\n", ")", "\n", ")", "\n", "self", ".", "mix_counter", "+=", "out_count", "\n", "local_mix_counter", "+=", "out_count", "\n", "self", ".", "input_txt_list", ".", "append", "(", "dict", "(", "utt_id", "=", "tmp_id", ",", "text", "=", "txt", ")", ")", "\n", "# Average WER for the clean pair", "\n", "", "for", "i", ",", "(", "wav", ",", "tmp_id", ")", "in", "enumerate", "(", "zip", "(", "clean", ",", "wav_id", ")", ")", ":", "\n", "            ", "txt", "=", "self", ".", "predict_hypothesis", "(", "wav", ")", "\n", "out_count", "=", "Counter", "(", "\n", "self", ".", "hsdi", "(", "\n", "truth", "=", "self", ".", "trans_dic", "[", "tmp_id", "]", ",", "hypothesis", "=", "txt", ",", "transformation", "=", "self", ".", "transformation", "\n", ")", "\n", ")", "\n", "self", ".", "clean_counter", "+=", "out_count", "\n", "local_clean_counter", "+=", "out_count", "\n", "self", ".", "clean_txt_list", ".", "append", "(", "dict", "(", "utt_id", "=", "tmp_id", ",", "text", "=", "txt", ")", ")", "\n", "trans_dict", "[", "\"clean\"", "]", "[", "f\"utt_id_{i}\"", "]", "=", "tmp_id", "\n", "trans_dict", "[", "\"clean\"", "]", "[", "f\"txt_{i}\"", "]", "=", "txt", "\n", "# Average WER for the estimate pair", "\n", "", "for", "i", ",", "(", "est", ",", "tmp_id", ")", "in", "enumerate", "(", "zip", "(", "estimate", ",", "wav_id", ")", ")", ":", "\n", "            ", "txt", "=", "self", ".", "predict_hypothesis", "(", "est", ")", "\n", "out_count", "=", "Counter", "(", "\n", "self", ".", "hsdi", "(", "\n", "truth", "=", "self", ".", "trans_dic", "[", "tmp_id", "]", ",", "hypothesis", "=", "txt", ",", "transformation", "=", "self", ".", "transformation", "\n", ")", "\n", ")", "\n", "self", ".", "est_counter", "+=", "out_count", "\n", "local_est_counter", "+=", "out_count", "\n", "self", ".", "output_txt_list", ".", "append", "(", "dict", "(", "utt_id", "=", "tmp_id", ",", "text", "=", "txt", ")", ")", "\n", "trans_dict", "[", "\"estimates\"", "]", "[", "f\"utt_id_{i}\"", "]", "=", "tmp_id", "\n", "trans_dict", "[", "\"estimates\"", "]", "[", "f\"txt_{i}\"", "]", "=", "txt", "\n", "", "self", ".", "transcriptions", ".", "append", "(", "trans_dict", ")", "\n", "return", "dict", "(", "\n", "input_wer", "=", "self", ".", "wer_from_hsdi", "(", "**", "dict", "(", "local_mix_counter", ")", ")", ",", "\n", "clean_wer", "=", "self", ".", "wer_from_hsdi", "(", "**", "dict", "(", "local_clean_counter", ")", ")", ",", "\n", "wer", "=", "self", ".", "wer_from_hsdi", "(", "**", "dict", "(", "local_est_counter", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.wer_from_hsdi": [[330, 334], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "wer_from_hsdi", "(", "hits", "=", "0", ",", "substitutions", "=", "0", ",", "deletions", "=", "0", ",", "insertions", "=", "0", ")", ":", "\n", "        ", "wer", "=", "(", "substitutions", "+", "deletions", "+", "insertions", ")", "/", "(", "hits", "+", "substitutions", "+", "deletions", ")", "\n", "return", "wer", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.hsdi": [[335, 347], ["compute_measures().items", "compute_measures"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "hsdi", "(", "truth", ",", "hypothesis", ",", "transformation", ")", ":", "\n", "        ", "from", "jiwer", "import", "compute_measures", "\n", "\n", "keep", "=", "[", "\"hits\"", ",", "\"substitutions\"", ",", "\"deletions\"", ",", "\"insertions\"", "]", "\n", "out", "=", "compute_measures", "(", "\n", "truth", "=", "truth", ",", "\n", "hypothesis", "=", "hypothesis", ",", "\n", "truth_transform", "=", "transformation", ",", "\n", "hypothesis_transform", "=", "transformation", ",", "\n", ")", ".", "items", "(", ")", "\n", "return", "{", "k", ":", "v", "for", "k", ",", "v", "in", "out", "if", "k", "in", "keep", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.predict_hypothesis": [[348, 353], ["torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "metrics.WERTracker.asr_model", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "def", "predict_hypothesis", "(", "self", ",", "wav", ")", ":", "\n", "        ", "wav", "=", "torch", ".", "from_numpy", "(", "wav", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "nbests", "=", "self", ".", "asr_model", "(", "wav", ")", "\n", "text", ",", "*", "_", "=", "nbests", "[", "0", "]", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.resample": [[354, 359], ["_resample"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.separate._resample"], ["", "@", "staticmethod", "\n", "def", "resample", "(", "*", "wavs", ":", "np", ".", "ndarray", ",", "fs_from", "=", "None", ",", "fs_to", "=", "None", ")", ":", "\n", "        ", "from", "resampy", "import", "resample", "as", "_resample", "\n", "\n", "return", "[", "_resample", "(", "w", ",", "sr_orig", "=", "fs_from", ",", "sr_new", "=", "fs_to", ")", "for", "w", "in", "wavs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker._df_to_dict": [[360, 363], ["zip", "df[].to_list", "df[].to_list"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_df_to_dict", "(", "df", ")", ":", "\n", "        ", "return", "{", "k", ":", "v", "for", "k", ",", "v", "in", "zip", "(", "df", "[", "\"utt_id\"", "]", ".", "to_list", "(", ")", ",", "df", "[", "\"text\"", "]", ".", "to_list", "(", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.final_df": [[364, 396], ["sum", "sum", "sum", "metrics.WERTracker.wer_from_hsdi", "metrics.WERTracker.wer_from_hsdi", "metrics.WERTracker.wer_from_hsdi", "pandas.DataFrame", "dict", "dict", "dict", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.wer_from_hsdi", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.wer_from_hsdi", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.wer_from_hsdi"], ["", "def", "final_df", "(", "self", ")", ":", "\n", "        ", "\"\"\"Generate a MarkDown table, as done by ESPNet.\"\"\"", "\n", "mix_n_word", "=", "sum", "(", "self", ".", "mix_counter", "[", "k", "]", "for", "k", "in", "[", "\"hits\"", ",", "\"substitutions\"", ",", "\"deletions\"", "]", ")", "\n", "clean_n_word", "=", "sum", "(", "self", ".", "clean_counter", "[", "k", "]", "for", "k", "in", "[", "\"hits\"", ",", "\"substitutions\"", ",", "\"deletions\"", "]", ")", "\n", "est_n_word", "=", "sum", "(", "self", ".", "est_counter", "[", "k", "]", "for", "k", "in", "[", "\"hits\"", ",", "\"substitutions\"", ",", "\"deletions\"", "]", ")", "\n", "mix_wer", "=", "self", ".", "wer_from_hsdi", "(", "**", "dict", "(", "self", ".", "mix_counter", ")", ")", "\n", "clean_wer", "=", "self", ".", "wer_from_hsdi", "(", "**", "dict", "(", "self", ".", "clean_counter", ")", ")", "\n", "est_wer", "=", "self", ".", "wer_from_hsdi", "(", "**", "dict", "(", "self", ".", "est_counter", ")", ")", "\n", "\n", "mix_hsdi", "=", "[", "\n", "self", ".", "mix_counter", "[", "k", "]", "for", "k", "in", "[", "\"hits\"", ",", "\"substitutions\"", ",", "\"deletions\"", ",", "\"insertions\"", "]", "\n", "]", "\n", "clean_hsdi", "=", "[", "\n", "self", ".", "clean_counter", "[", "k", "]", "for", "k", "in", "[", "\"hits\"", ",", "\"substitutions\"", ",", "\"deletions\"", ",", "\"insertions\"", "]", "\n", "]", "\n", "est_hsdi", "=", "[", "\n", "self", ".", "est_counter", "[", "k", "]", "for", "k", "in", "[", "\"hits\"", ",", "\"substitutions\"", ",", "\"deletions\"", ",", "\"insertions\"", "]", "\n", "]", "\n", "#                   Snt               Wrd         HSDI       Err     S.Err", "\n", "for_mix", "=", "[", "len", "(", "self", ".", "mix_counter", ")", ",", "mix_n_word", "]", "+", "mix_hsdi", "+", "[", "mix_wer", ",", "\"-\"", "]", "\n", "for_clean", "=", "[", "len", "(", "self", ".", "clean_counter", ")", ",", "clean_n_word", "]", "+", "clean_hsdi", "+", "[", "clean_wer", ",", "\"-\"", "]", "\n", "for_est", "=", "[", "len", "(", "self", ".", "est_counter", ")", ",", "est_n_word", "]", "+", "est_hsdi", "+", "[", "est_wer", ",", "\"-\"", "]", "\n", "\n", "table", "=", "[", "\n", "[", "\"test_clean / mixture\"", "]", "+", "for_mix", ",", "\n", "[", "\"test_clean / clean\"", "]", "+", "for_clean", ",", "\n", "[", "\"test_clean / separated\"", "]", "+", "for_est", ",", "\n", "]", "\n", "df", "=", "pd", ".", "DataFrame", "(", "\n", "table", ",", "columns", "=", "[", "\"dataset\"", ",", "\"Snt\"", ",", "\"Wrd\"", ",", "\"Corr\"", ",", "\"Sub\"", ",", "\"Del\"", ",", "\"Ins\"", ",", "\"Err\"", ",", "\"S.Err\"", "]", "\n", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.final_report_as_markdown": [[397, 399], ["metrics.WERTracker.final_df().to_markdown", "metrics.WERTracker.final_df"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.final_df"], ["", "def", "final_report_as_markdown", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "final_df", "(", ")", ".", "to_markdown", "(", "index", "=", "False", ",", "tablefmt", "=", "\"github\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.F1Tracker.__init__": [[404, 407], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "epsilon", "=", "1e-7", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.F1Tracker.forward": [[408, 424], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "f1.clamp.clamp.clamp", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "torch.logical_and", "float", "float", "float", "float", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_not", "torch.logical_xor", "torch.logical_xor", "torch.logical_xor", "torch.logical_xor", "torch.logical_xor", "torch.logical_xor", "torch.logical_xor", "torch.logical_xor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "y_pred", ",", "y_true", ")", ":", "\n", "        ", "tp", "=", "torch", ".", "sum", "(", "torch", ".", "logical_and", "(", "y_pred", ",", "y_true", ")", ")", "\n", "tn", "=", "torch", ".", "sum", "(", "torch", ".", "logical_and", "(", "torch", ".", "logical_not", "(", "y_pred", ")", ",", "torch", ".", "logical_not", "(", "y_true", ")", ")", ")", "\n", "fp", "=", "torch", ".", "sum", "(", "torch", ".", "logical_and", "(", "torch", ".", "logical_xor", "(", "y_pred", ",", "y_true", ")", ",", "y_pred", ")", ")", "\n", "fn", "=", "torch", ".", "sum", "(", "torch", ".", "logical_and", "(", "torch", ".", "logical_xor", "(", "y_pred", ",", "y_true", ")", ",", "y_true", ")", ")", "\n", "accuracy", "=", "(", "tp", "+", "tn", ")", "/", "(", "tp", "+", "tn", "+", "fp", "+", "fn", ")", "\n", "precision", "=", "tp", "/", "(", "tp", "+", "fp", "+", "self", ".", "epsilon", ")", "\n", "recall", "=", "tp", "/", "(", "tp", "+", "fn", "+", "self", ".", "epsilon", ")", "\n", "\n", "f1", "=", "2", "*", "(", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", "+", "self", ".", "epsilon", ")", "\n", "f1", "=", "f1", ".", "clamp", "(", "min", "=", "self", ".", "epsilon", ",", "max", "=", "1", "-", "self", ".", "epsilon", ")", "\n", "return", "{", "\n", "\"accuracy\"", ":", "float", "(", "accuracy", ")", ",", "\n", "\"precision\"", ":", "float", "(", "precision", ")", ",", "\n", "\"recall\"", ":", "float", "(", "recall", ")", ",", "\n", "\"f1_score\"", ":", "float", "(", "f1", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics": [[17, 118], ["isinstance", "pb_bss_eval.InputMetrics", "pb_bss_eval.OutputMetrics", "utils.average_arrays_in_dic", "warnings.warn", "traceback.print_stack", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.average_arrays_in_dic"], ["def", "get_metrics", "(", "\n", "mix", ",", "\n", "clean", ",", "\n", "estimate", ",", "\n", "sample_rate", "=", "16000", ",", "\n", "metrics_list", "=", "\"all\"", ",", "\n", "average", "=", "True", ",", "\n", "compute_permutation", "=", "False", ",", "\n", "ignore_metrics_errors", "=", "False", ",", "\n", "filename", "=", "None", ",", "\n", ")", ":", "\n", "    ", "r\"\"\"Get speech separation/enhancement metrics from mix/clean/estimate.\n\n    Args:\n        mix (np.array): mixture array.\n        clean (np.array): reference array.\n        estimate (np.array): estimate array.\n        sample_rate (int): sampling rate of the audio clips.\n        metrics_list (Union[List[str], str): List of metrics to compute.\n            Defaults to 'all' (['si_sdr', 'sdr', 'sir', 'sar', 'stoi', 'pesq']).\n        average (bool): Return dict([float]) if True, else dict([array]).\n        compute_permutation (bool): Whether to compute the permutation on\n            estimate sources for the output metrics (default False)\n        ignore_metrics_errors (bool): Whether to ignore errors that occur in\n            computing the metrics. A warning will be printed instead.\n        filename (str, optional): If computing a metric fails, print this\n            filename along with the exception/warning message for debugging purposes.\n\n    Shape:\n        - mix: :math:`(D, N)` or `(N, )`.\n        - clean: :math:`(K\\_source, N)` or `(N, )`.\n        - estimate: :math:`(K\\_target, N)` or `(N, )`.\n\n    Returns:\n        dict: Dictionary with all requested metrics, with `'input_'` prefix\n        for metrics at the input (mixture against clean), no prefix at the\n        output (estimate against clean). Output format depends on average.\n\n    Examples\n        >>> import numpy as np\n        >>> import pprint\n        >>> from asteroid.metrics import get_metrics\n        >>> mix = np.random.randn(1, 16000)\n        >>> clean = np.random.randn(2, 16000)\n        >>> est = np.random.randn(2, 16000)\n        >>> metrics_dict = get_metrics(mix, clean, est, sample_rate=8000,\n        ...                            metrics_list='all')\n        >>> pprint.pprint(metrics_dict)\n        {'input_pesq': 1.924380898475647,\n         'input_sar': -11.67667585294225,\n         'input_sdr': -14.88667106190552,\n         'input_si_sdr': -52.43849784881705,\n         'input_sir': -0.10419427290163795,\n         'input_stoi': 0.015112115177091223,\n         'pesq': 1.7713886499404907,\n         'sar': -11.610963379923195,\n         'sdr': -14.527246041125844,\n         'si_sdr': -46.26557128489802,\n         'sir': 0.4799929272243427,\n         'stoi': 0.022023073540350643}\n\n    \"\"\"", "\n", "if", "metrics_list", "==", "\"all\"", ":", "\n", "        ", "metrics_list", "=", "ALL_METRICS", "\n", "", "if", "isinstance", "(", "metrics_list", ",", "str", ")", ":", "\n", "        ", "metrics_list", "=", "[", "metrics_list", "]", "\n", "# For each utterance, we get a dictionary with the input and output metrics", "\n", "", "input_metrics", "=", "InputMetrics", "(", "\n", "observation", "=", "mix", ",", "speech_source", "=", "clean", ",", "enable_si_sdr", "=", "True", ",", "sample_rate", "=", "sample_rate", "\n", ")", "\n", "output_metrics", "=", "OutputMetrics", "(", "\n", "speech_prediction", "=", "estimate", ",", "\n", "speech_source", "=", "clean", ",", "\n", "enable_si_sdr", "=", "True", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "compute_permutation", "=", "compute_permutation", ",", "\n", ")", "\n", "utt_metrics", "=", "{", "}", "\n", "for", "src", ",", "prefix", "in", "[", "(", "input_metrics", ",", "\"input_\"", ")", ",", "(", "output_metrics", ",", "\"\"", ")", "]", ":", "\n", "        ", "for", "metric", "in", "metrics_list", ":", "\n", "# key: eg. \"input_pesq\" or \"pesq\"", "\n", "            ", "key", "=", "prefix", "+", "metric", "\n", "try", ":", "\n", "                ", "utt_metrics", "[", "key", "]", "=", "src", "[", "metric", "]", "\n", "", "except", "Exception", "as", "err", ":", "\n", "                ", "if", "ignore_metrics_errors", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\n", "f\"Error computing {key} for {filename or '<unknown file>'},\"", "\n", "f\" ignoring. Error was: {err}\"", ",", "\n", "RuntimeWarning", ",", "\n", ")", "\n", "traceback", ".", "print_stack", "(", ")", "\n", "utt_metrics", "[", "key", "]", "=", "None", "\n", "", "else", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "f\"Error computing {key} for {filename or '<unknown file>'}\"", "\n", ")", "from", "err", "\n", "", "", "", "", "if", "average", ":", "\n", "        ", "return", "average_arrays_in_dic", "(", "utt_metrics", ")", "\n", "", "else", ":", "\n", "        ", "return", "utt_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.separate.Separatable.forward_wav": [[25, 38], ["None"], "methods", ["None"], ["def", "forward_wav", "(", "self", ",", "wav", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Args:\n            wav (torch.Tensor): waveform tensor.\n                Shape: 1D, 2D or 3D tensor, time last.\n            **kwargs: Keyword arguments from `separate`.\n\n        Returns:\n            torch.Tensor: the estimated sources.\n                Shape: [batch, n_src, time] or [n_src, time] if the input `wav`\n                did not have a batch dim.\n        \"\"\"", "\n", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.separate.Separatable.sample_rate": [[39, 43], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "sample_rate", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"Operating sample rate of the model (float).\"\"\"", "\n", "...", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.separate.separate": [[45, 88], ["isinstance", "separate.file_separate", "isinstance", "separate.numpy_separate", "isinstance", "separate.torch_separate", "ValueError", "type"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.file_separate", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.numpy_separate", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.torch_separate"], ["", "", "def", "separate", "(", "\n", "model", ":", "Separatable", ",", "wav", ",", "output_dir", "=", "None", ",", "force_overwrite", "=", "False", ",", "resample", "=", "False", ",", "**", "kwargs", "\n", ")", ":", "\n", "    ", "\"\"\"Infer separated sources from input waveforms.\n    Also supports filenames.\n\n    Args:\n        model (Separatable, for example asteroid.models.BaseModel): Model to use.\n        wav (Union[torch.Tensor, numpy.ndarray, str]): waveform array/tensor.\n            Shape: 1D, 2D or 3D tensor, time last.\n        output_dir (str): path to save all the wav files. If None,\n            estimated sources will be saved next to the original ones.\n        force_overwrite (bool): whether to overwrite existing files\n            (when separating from file).\n        resample (bool): Whether to resample input files with wrong sample rate\n            (when separating from file).\n        **kwargs: keyword arguments to be passed to `forward_wav`.\n\n    Returns:\n        Union[torch.Tensor, numpy.ndarray, None], the estimated sources.\n            (batch, n_src, time) or (n_src, time) w/o batch dim.\n\n    .. note::\n        `separate` calls `model.forward_wav` which calls `forward` by default.\n        For models whose `forward` doesn't have waveform tensors as input/ouput,\n        overwrite their `forward_wav` method to separate from waveform to waveform.\n    \"\"\"", "\n", "if", "isinstance", "(", "wav", ",", "str", ")", ":", "\n", "        ", "file_separate", "(", "\n", "model", ",", "\n", "wav", ",", "\n", "output_dir", "=", "output_dir", ",", "\n", "force_overwrite", "=", "force_overwrite", ",", "\n", "resample", "=", "resample", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "", "elif", "isinstance", "(", "wav", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "return", "numpy_separate", "(", "model", ",", "wav", ",", "**", "kwargs", ")", "\n", "", "elif", "isinstance", "(", "wav", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "torch_separate", "(", "model", ",", "wav", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Only support filenames, numpy arrays and torch tensors, received {type(wav)}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.separate.torch_separate": [[91, 113], ["torch.no_grad", "utils.get_device", "utils.get_device", "wav.to.to", "getattr", "getattr.", "out_wavs.to.to", "RuntimeError", "wav.to.abs().sum", "out_wavs.to.abs().sum", "wav.to.abs", "out_wavs.to.abs"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.get_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.get_device"], ["", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "torch_separate", "(", "model", ":", "Separatable", ",", "wav", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Core logic of `separate`.\"\"\"", "\n", "if", "model", ".", "in_channels", "is", "not", "None", "and", "wav", ".", "shape", "[", "-", "2", "]", "!=", "model", ".", "in_channels", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "f\"Model supports {model.in_channels}-channel inputs but found audio with {wav.shape[-2]} channels.\"", "\n", "f\"Please match the number of channels.\"", "\n", ")", "\n", "# Handle device placement", "\n", "", "input_device", "=", "get_device", "(", "wav", ",", "default", "=", "\"cpu\"", ")", "\n", "model_device", "=", "get_device", "(", "model", ",", "default", "=", "\"cpu\"", ")", "\n", "wav", "=", "wav", ".", "to", "(", "model_device", ")", "\n", "# Forward", "\n", "separate_func", "=", "getattr", "(", "model", ",", "\"forward_wav\"", ",", "model", ")", "\n", "out_wavs", "=", "separate_func", "(", "wav", ",", "**", "kwargs", ")", "\n", "\n", "# FIXME: for now this is the best we can do.", "\n", "out_wavs", "*=", "wav", ".", "abs", "(", ")", ".", "sum", "(", ")", "/", "(", "out_wavs", ".", "abs", "(", ")", ".", "sum", "(", ")", ")", "\n", "\n", "# Back to input device (and numpy if necessary)", "\n", "out_wavs", "=", "out_wavs", ".", "to", "(", "input_device", ")", "\n", "return", "out_wavs", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.separate.numpy_separate": [[115, 121], ["torch.from_numpy", "separate.torch_separate", "out_wavs.data.numpy.data.numpy"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.torch_separate"], ["", "def", "numpy_separate", "(", "model", ":", "Separatable", ",", "wav", ":", "np", ".", "ndarray", ",", "**", "kwargs", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"Numpy interface to `separate`.\"\"\"", "\n", "wav", "=", "torch", ".", "from_numpy", "(", "wav", ")", "\n", "out_wavs", "=", "torch_separate", "(", "model", ",", "wav", ",", "**", "kwargs", ")", "\n", "out_wavs", "=", "out_wavs", ".", "data", ".", "numpy", "(", ")", "\n", "return", "out_wavs", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.separate.file_separate": [[123, 180], ["os.path.splitext", "save_name_template.format", "separate._load_audio", "separate.numpy_separate", "enumerate", "hasattr", "TypeError", "os.path.join", "os.path.isfile", "warnings.warn", "warnings.warn", "separate._resample", "soundfile.write", "os.path.basename", "separate._resample", "RuntimeError", "save_name_template.format", "int", "int", "type"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dampvsep_dataset.DAMPVSEPSinglesDataset._load_audio", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.numpy_separate", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.separate._resample", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.separate._resample"], ["", "def", "file_separate", "(", "\n", "model", ":", "Separatable", ",", "\n", "filename", ":", "str", ",", "\n", "output_dir", "=", "None", ",", "\n", "force_overwrite", "=", "False", ",", "\n", "resample", "=", "False", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"Filename interface to `separate`.\"\"\"", "\n", "\n", "if", "not", "hasattr", "(", "model", ",", "\"sample_rate\"", ")", ":", "\n", "        ", "raise", "TypeError", "(", "\n", "f\"This function requires your model ({type(model).__name__}) to have a \"", "\n", "\"'sample_rate' attribute. See `BaseModel.sample_rate` for details.\"", "\n", ")", "\n", "\n", "# Estimates will be saved as filename_est1.wav etc...", "\n", "", "base", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "filename", ")", "\n", "if", "output_dir", "is", "not", "None", ":", "\n", "        ", "base", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "os", ".", "path", ".", "basename", "(", "base", ")", ")", "\n", "", "save_name_template", "=", "base", "+", "\"_est{}.wav\"", "\n", "\n", "# Bail out early if an estimate file already exists and we shall not overwrite.", "\n", "est1_filename", "=", "save_name_template", ".", "format", "(", "1", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "est1_filename", ")", "and", "not", "force_overwrite", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "f\"File {est1_filename} already exists, pass `force_overwrite=True` to overwrite it\"", ",", "\n", "UserWarning", ",", "\n", ")", "\n", "return", "\n", "\n", "# SoundFile wav shape: [time, n_chan]", "\n", "", "wav", ",", "fs", "=", "_load_audio", "(", "filename", ")", "\n", "if", "wav", ".", "shape", "[", "-", "1", "]", ">", "1", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "f\"Received multichannel signal with {wav.shape[-1]} signals, \"", "\n", "f\"using the first channel only.\"", "\n", ")", "\n", "# FIXME: support only single-channel files for now.", "\n", "", "if", "resample", ":", "\n", "        ", "wav", "=", "_resample", "(", "wav", "[", ":", ",", "0", "]", ",", "orig_sr", "=", "fs", ",", "target_sr", "=", "int", "(", "model", ".", "sample_rate", ")", ")", "[", ":", ",", "None", "]", "\n", "", "elif", "fs", "!=", "model", ".", "sample_rate", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "f\"Received a signal with a sampling rate of {fs}Hz for a model \"", "\n", "f\"of {model.sample_rate}Hz. You can pass `resample=True` to resample automatically.\"", "\n", ")", "\n", "# Pass wav as [batch, n_chan, time]; here: [1, chan, time]", "\n", "", "wav", "=", "wav", ".", "T", "[", "None", "]", "\n", "(", "est_srcs", ",", ")", "=", "numpy_separate", "(", "model", ",", "wav", ",", "**", "kwargs", ")", "\n", "# Resample to original sr", "\n", "est_srcs", "=", "[", "\n", "_resample", "(", "est_src", ",", "orig_sr", "=", "int", "(", "model", ".", "sample_rate", ")", ",", "target_sr", "=", "fs", ")", "for", "est_src", "in", "est_srcs", "\n", "]", "\n", "\n", "# Save wav files to filename_est1.wav etc...", "\n", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_srcs", ",", "1", ")", ":", "\n", "        ", "sf", ".", "write", "(", "save_name_template", ".", "format", "(", "src_idx", ")", ",", "est_src", ",", "fs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.separate._resample": [[182, 196], ["ResampleFrac.numpy", "ResampleFrac", "ResampleFrac.", "torch.from_numpy"], "function", ["None"], ["", "", "def", "_resample", "(", "wav", ",", "orig_sr", ",", "target_sr", ",", "_resamplers", "=", "{", "}", ")", ":", "\n", "    ", "from", "julius", "import", "ResampleFrac", "\n", "\n", "if", "orig_sr", "==", "target_sr", ":", "\n", "        ", "return", "wav", "\n", "\n", "# Cache ResampleFrac instance to speed up resampling if we're repeatedly", "\n", "# resampling between the same two sample rates.", "\n", "", "try", ":", "\n", "        ", "resampler", "=", "_resamplers", "[", "(", "orig_sr", ",", "target_sr", ")", "]", "\n", "", "except", "KeyError", ":", "\n", "        ", "resampler", "=", "_resamplers", "[", "(", "orig_sr", ",", "target_sr", ")", "]", "=", "ResampleFrac", "(", "orig_sr", ",", "target_sr", ")", "\n", "\n", "", "return", "resampler", "(", "torch", ".", "from_numpy", "(", "wav", ")", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.separate._load_audio": [[198, 219], ["soundfile.read", "librosa.load", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "_load_audio", "(", "filename", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "sf", ".", "read", "(", "filename", ",", "dtype", "=", "\"float32\"", ",", "always_2d", "=", "True", ")", "\n", "", "except", "Exception", "as", "sf_err", ":", "\n", "# If soundfile fails to load the file, try with librosa next, which uses", "\n", "# the 'audioread' library to support a wide range of audio formats.", "\n", "# We try with soundfile first because librosa takes a long time to import.", "\n", "        ", "try", ":", "\n", "            ", "import", "librosa", "\n", "", "except", "ModuleNotFoundError", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "f\"Could not load file {filename!r} with soundfile. \"", "\n", "\"Install 'librosa' to be able to load more file types.\"", "\n", ")", "from", "sf_err", "\n", "\n", "", "wav", ",", "sr", "=", "librosa", ".", "load", "(", "filename", ",", "dtype", "=", "\"float32\"", ",", "sr", "=", "None", ")", "\n", "# Always return wav of shape [time, n_chan]", "\n", "if", "wav", ".", "ndim", "==", "1", ":", "\n", "            ", "return", "wav", "[", ":", ",", "None", "]", ",", "sr", "\n", "", "else", ":", "\n", "            ", "return", "wav", ".", "T", ",", "sr", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.__init__.show_available_models": [[10, 14], ["print", "list", "MODELS_URLS_HASHTABLE.keys"], "function", ["None"], ["def", "show_available_models", "(", ")", ":", "\n", "    ", "from", ".", "utils", ".", "hub_utils", "import", "MODELS_URLS_HASHTABLE", "\n", "\n", "print", "(", "\" \\n\"", ".", "join", "(", "list", "(", "MODELS_URLS_HASHTABLE", ".", "keys", "(", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.__init__.available_models": [[16, 20], ["None"], "function", ["None"], ["", "def", "available_models", "(", ")", ":", "\n", "    ", "from", ".", "utils", ".", "hub_utils", "import", "MODELS_URLS_HASHTABLE", "\n", "\n", "return", "MODELS_URLS_HASHTABLE", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.cached_download": [[33, 88], ["os.path.isfile", "filename_or_url.startswith", "filename_or_url.startswith", "hub_utils.url_to_filename", "os.path.join", "os.path.join", "os.makedirs", "print", "hub_utils.get_cache_dir", "os.path.isfile", "torch.hub.download_url_to_file", "huggingface_hub.hf_hub_url", "huggingface_hub.cached_download", "len", "filename_or_url.split", "filename_or_url.split", "hub_utils.get_cache_dir"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.url_to_filename", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.get_cache_dir", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.cached_download", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.get_cache_dir"], ["def", "cached_download", "(", "filename_or_url", ")", ":", "\n", "    ", "\"\"\"Download from URL and cache the result in ASTEROID_CACHE.\n\n    Args:\n        filename_or_url (str): Name of a model as named on the Zenodo Community\n            page (ex: ``\"mpariente/ConvTasNet_WHAM!_sepclean\"``), or model id from\n            the Hugging Face model hub (ex: ``\"julien-c/DPRNNTasNet-ks16_WHAM_sepclean\"``),\n            or a URL to a model file (ex: ``\"https://zenodo.org/.../model.pth\"``), or a filename\n            that exists locally (ex: ``\"local/tmp_model.pth\"``)\n\n    Returns:\n        str, normalized path to the downloaded (or not) model\n    \"\"\"", "\n", "from", ".", ".", "import", "__version__", "as", "asteroid_version", "# Avoid circular imports", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "filename_or_url", ")", ":", "\n", "        ", "return", "filename_or_url", "\n", "\n", "", "if", "filename_or_url", ".", "startswith", "(", "huggingface_hub", ".", "HUGGINGFACE_CO_URL_HOME", ")", ":", "\n", "        ", "filename_or_url", "=", "filename_or_url", "[", "len", "(", "huggingface_hub", ".", "HUGGINGFACE_CO_URL_HOME", ")", ":", "]", "\n", "\n", "", "if", "filename_or_url", ".", "startswith", "(", "(", "\"http://\"", ",", "\"https://\"", ")", ")", ":", "\n", "        ", "url", "=", "filename_or_url", "\n", "", "elif", "filename_or_url", "in", "MODELS_URLS_HASHTABLE", ":", "\n", "        ", "url", "=", "MODELS_URLS_HASHTABLE", "[", "filename_or_url", "]", "\n", "", "else", ":", "\n", "# Finally, let's try to find it on Hugging Face model hub", "\n", "# e.g. julien-c/DPRNNTasNet-ks16_WHAM_sepclean is a valid model id", "\n", "# and  julien-c/DPRNNTasNet-ks16_WHAM_sepclean@main supports specifying a commit/branch/tag.", "\n", "        ", "if", "\"@\"", "in", "filename_or_url", ":", "\n", "            ", "model_id", "=", "filename_or_url", ".", "split", "(", "\"@\"", ")", "[", "0", "]", "\n", "revision", "=", "filename_or_url", ".", "split", "(", "\"@\"", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "model_id", "=", "filename_or_url", "\n", "revision", "=", "None", "\n", "", "url", "=", "huggingface_hub", ".", "hf_hub_url", "(", "\n", "model_id", ",", "filename", "=", "huggingface_hub", ".", "PYTORCH_WEIGHTS_NAME", ",", "revision", "=", "revision", "\n", ")", "\n", "return", "huggingface_hub", ".", "cached_download", "(", "\n", "url", ",", "\n", "cache_dir", "=", "get_cache_dir", "(", ")", ",", "\n", "library_name", "=", "\"asteroid\"", ",", "\n", "library_version", "=", "asteroid_version", ",", "\n", ")", "\n", "", "cached_filename", "=", "url_to_filename", "(", "url", ")", "\n", "cached_dir", "=", "os", ".", "path", ".", "join", "(", "get_cache_dir", "(", ")", ",", "cached_filename", ")", "\n", "cached_path", "=", "os", ".", "path", ".", "join", "(", "cached_dir", ",", "\"model.pth\"", ")", "\n", "\n", "os", ".", "makedirs", "(", "cached_dir", ",", "exist_ok", "=", "True", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "cached_path", ")", ":", "\n", "        ", "hub", ".", "download_url_to_file", "(", "url", ",", "cached_path", ")", "\n", "return", "cached_path", "\n", "# It was already downloaded", "\n", "", "print", "(", "f\"Using cached model `{filename_or_url}`\"", ")", "\n", "return", "cached_path", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.url_to_filename": [[90, 96], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TasNet.model.TasNet.encode"], ["", "def", "url_to_filename", "(", "url", ")", ":", "\n", "    ", "\"\"\"Consistently convert ``url`` into a filename.\"\"\"", "\n", "_bytes", "=", "url", ".", "encode", "(", "\"utf-8\"", ")", "\n", "_hash", "=", "sha256", "(", "_bytes", ")", "\n", "filename", "=", "_hash", ".", "hexdigest", "(", ")", "\n", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.get_cache_dir": [[98, 101], ["os.makedirs"], "function", ["None"], ["", "def", "get_cache_dir", "(", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "CACHE_DIR", ",", "exist_ok", "=", "True", ")", "\n", "return", "CACHE_DIR", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.model_list": [[103, 115], ["functools.lru_cache", "requests.get", "requests.get.raise_for_status", "requests.get.json"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "@", "lru_cache", "(", ")", "\n", "def", "model_list", "(", "\n", "endpoint", "=", "huggingface_hub", ".", "HUGGINGFACE_CO_URL_HOME", ",", "name_only", "=", "False", "\n", ")", "->", "Union", "[", "str", ",", "List", "[", "Dict", "]", "]", ":", "\n", "    ", "\"\"\"Get the public list of all the models on huggingface with an 'asteroid' tag.\"\"\"", "\n", "path", "=", "\"{}api/models?full=true&filter=asteroid\"", ".", "format", "(", "endpoint", ")", "\n", "r", "=", "requests", ".", "get", "(", "path", ")", "\n", "r", ".", "raise_for_status", "(", ")", "\n", "all_models", "=", "r", ".", "json", "(", ")", "\n", "if", "name_only", ":", "\n", "        ", "return", "[", "x", "[", "\"modelId\"", "]", "for", "x", "in", "all_models", "]", "\n", "", "return", "all_models", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.mark_deprecated": [[18, 40], ["functools.wraps", "warnings.warn", "func"], "function", ["None"], ["", "def", "mark_deprecated", "(", "message", ",", "version", "=", "None", ")", ":", "\n", "    ", "\"\"\"Decorator to add deprecation message.\n\n    Args:\n        message: Migration steps to be given to users.\n    \"\"\"", "\n", "\n", "def", "decorator", "(", "func", ")", ":", "\n", "        ", "@", "wraps", "(", "func", ")", "\n", "def", "wrapped", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "from_what", "=", "\"a future release\"", "if", "version", "is", "None", "else", "f\"asteroid v{version}\"", "\n", "warn_message", "=", "(", "\n", "f\"{func.__module__}.{func.__name__} has been deprecated \"", "\n", "f\"and will be removed from {from_what}. \"", "\n", "f\"{message}\"", "\n", ")", "\n", "warnings", ".", "warn", "(", "warn_message", ",", "VisibleDeprecationWarning", ",", "stacklevel", "=", "2", ")", "\n", "return", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "wrapped", "\n", "\n", "", "return", "decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.is_overridden": [[42, 88], ["getattr", "hasattr", "getattr", "deprecation_utils.is_overridden.get_mro"], "function", ["None"], ["", "def", "is_overridden", "(", "method_name", ",", "obj", ",", "parent", "=", "None", ")", "->", "bool", ":", "\n", "    ", "\"\"\"Check if `method_name` from parent is overridden in `obj`.\n\n    Args:\n        method_name (str): Name of the method.\n        obj: Instance or class that potentially overrode the method.\n        parent: parent class with which to compare. If None, traverse the MRO\n            for the first parent that has the method.\n\n    Raises RuntimeError if `parent` is not a parent class and if `parent`\n    doesn't have the method. Or, if `parent` was None, that none of the\n    potential parents had the method.\n    \"\"\"", "\n", "\n", "def", "get_mro", "(", "cls", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "inspect", ".", "getmro", "(", "cls", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "return", "inspect", ".", "getmro", "(", "cls", ".", "__class__", ")", "\n", "\n", "", "", "def", "first_parent_with_method", "(", "fn", ",", "mro_list", ")", ":", "\n", "        ", "for", "cls", "in", "mro_list", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "if", "hasattr", "(", "cls", ",", "fn", ")", ":", "\n", "                ", "return", "cls", "\n", "", "", "return", "None", "\n", "\n", "", "if", "not", "hasattr", "(", "obj", ",", "method_name", ")", ":", "\n", "        ", "return", "False", "\n", "\n", "", "try", ":", "\n", "        ", "instance_attr", "=", "getattr", "(", "obj", ",", "method_name", ")", "\n", "", "except", "AttributeError", ":", "\n", "        ", "return", "False", "\n", "return", "False", "\n", "\n", "", "mro", "=", "get_mro", "(", "obj", ")", "[", "1", ":", "]", "# All parent classes in order, self excluded", "\n", "parent", "=", "parent", "if", "parent", "is", "not", "None", "else", "first_parent_with_method", "(", "method_name", ",", "mro", ")", "\n", "\n", "if", "parent", "not", "in", "mro", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"`{obj}` has no parent that defined method {method_name}`.\"", ")", "\n", "\n", "", "if", "not", "hasattr", "(", "parent", ",", "method_name", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"Parent `{parent}` does have method `{method_name}`\"", ")", "\n", "\n", "", "super_attr", "=", "getattr", "(", "parent", ",", "method_name", ")", "\n", "return", "instance_attr", ".", "__code__", "is", "not", "super_attr", ".", "__code__", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.test_utils.DummyDataset.__init__": [[6, 9], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "inp_dim", "=", "10", "\n", "self", ".", "out_dim", "=", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.test_utils.DummyDataset.__len__": [[10, 12], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "20", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.test_utils.DummyDataset.__getitem__": [[13, 15], ["torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "torch", ".", "randn", "(", "1", ",", "self", ".", "inp_dim", ")", ",", "torch", ".", "randn", "(", "1", ",", "self", ".", "out_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.test_utils.DummyWaveformDataset.__init__": [[18, 24], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "total", "=", "12", ",", "n_src", "=", "3", ",", "len_wave", "=", "16000", ")", ":", "\n", "        ", "self", ".", "inp_len_wave", "=", "len_wave", "\n", "self", ".", "out_len_wave", "=", "len_wave", "\n", "self", ".", "total", "=", "total", "\n", "self", ".", "inp_n_sig", "=", "1", "\n", "self", ".", "out_n_sig", "=", "n_src", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.test_utils.DummyWaveformDataset.__len__": [[25, 27], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.test_utils.DummyWaveformDataset.__getitem__": [[28, 32], ["torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "mixed", "=", "torch", ".", "randn", "(", "self", ".", "inp_n_sig", ",", "self", ".", "inp_len_wave", ")", "\n", "srcs", "=", "torch", ".", "randn", "(", "self", ".", "out_n_sig", ",", "self", ".", "out_len_wave", ")", "\n", "return", "mixed", ",", "srcs", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.test_utils.torch_version_tuple": [[34, 37], ["torch.__version__.split", "tuple", "tuple", "map", "version.split"], "function", ["None"], ["", "", "def", "torch_version_tuple", "(", ")", ":", "\n", "    ", "version", ",", "*", "suffix", "=", "torch", ".", "__version__", ".", "split", "(", "\"+\"", ")", "\n", "return", "tuple", "(", "map", "(", "int", ",", "version", ".", "split", "(", "\".\"", ")", ")", ")", "+", "tuple", "(", "suffix", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.prepare_parser_from_dict": [[4, 36], ["dic.keys", "isinstance", "type", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument_group", "dic[].keys", "parser_utils.str2bool", "parser_utils.prepare_parser_from_dict.standardized_entry_type"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.str2bool"], ["def", "prepare_parser_from_dict", "(", "dic", ",", "parser", "=", "None", ")", ":", "\n", "    ", "\"\"\"Prepare an argparser from a dictionary.\n\n    Args:\n        dic (dict): Two-level config dictionary with unique bottom-level keys.\n        parser (argparse.ArgumentParser, optional): If a parser already\n            exists, add the keys from the dictionary on the top of it.\n\n    Returns:\n        argparse.ArgumentParser:\n            Parser instance with groups corresponding to the first level keys\n            and arguments corresponding to the second level keys with default\n            values given by the values.\n    \"\"\"", "\n", "\n", "def", "standardized_entry_type", "(", "value", ")", ":", "\n", "        ", "\"\"\"If the default value is None, replace NoneType by str_int_float.\n        If the default value is boolean, look for boolean strings.\"\"\"", "\n", "if", "value", "is", "None", ":", "\n", "            ", "return", "str_int_float", "\n", "", "if", "isinstance", "(", "str2bool", "(", "value", ")", ",", "bool", ")", ":", "\n", "            ", "return", "str2bool_arg", "\n", "", "return", "type", "(", "value", ")", "\n", "\n", "", "if", "parser", "is", "None", ":", "\n", "        ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "", "for", "k", "in", "dic", ".", "keys", "(", ")", ":", "\n", "        ", "group", "=", "parser", ".", "add_argument_group", "(", "k", ")", "\n", "for", "kk", "in", "dic", "[", "k", "]", ".", "keys", "(", ")", ":", "\n", "            ", "entry_type", "=", "standardized_entry_type", "(", "dic", "[", "k", "]", "[", "kk", "]", ")", "\n", "group", ".", "add_argument", "(", "\"--\"", "+", "kk", ",", "default", "=", "dic", "[", "k", "]", "[", "kk", "]", ",", "type", "=", "entry_type", ")", "\n", "", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.str_int_float": [[38, 53], ["parser_utils.isint", "parser_utils.isfloat", "int", "float", "isinstance"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.isint", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.isfloat"], ["", "def", "str_int_float", "(", "value", ")", ":", "\n", "    ", "\"\"\"Type to convert strings to int, float (in this order) if possible.\n\n    Args:\n        value (str): Value to convert.\n\n    Returns:\n        int, float, str: Converted value.\n    \"\"\"", "\n", "if", "isint", "(", "value", ")", ":", "\n", "        ", "return", "int", "(", "value", ")", "\n", "", "if", "isfloat", "(", "value", ")", ":", "\n", "        ", "return", "float", "(", "value", ")", "\n", "", "elif", "isinstance", "(", "value", ",", "str", ")", ":", "\n", "        ", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.str2bool": [[55, 65], ["isinstance", "value.lower", "value.lower"], "function", ["None"], ["", "", "def", "str2bool", "(", "value", ")", ":", "\n", "    ", "\"\"\"Type to convert strings to Boolean (returns input if not boolean)\"\"\"", "\n", "if", "not", "isinstance", "(", "value", ",", "str", ")", ":", "\n", "        ", "return", "value", "\n", "", "if", "value", ".", "lower", "(", ")", "in", "(", "\"yes\"", ",", "\"true\"", ",", "\"y\"", ",", "\"1\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "value", ".", "lower", "(", ")", "in", "(", "\"no\"", ",", "\"false\"", ",", "\"n\"", ",", "\"0\"", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.str2bool_arg": [[67, 73], ["parser_utils.str2bool", "isinstance", "argparse.ArgumentTypeError"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.str2bool"], ["", "", "def", "str2bool_arg", "(", "value", ")", ":", "\n", "    ", "\"\"\"Argparse type to convert strings to Boolean\"\"\"", "\n", "value", "=", "str2bool", "(", "value", ")", "\n", "if", "isinstance", "(", "value", ",", "bool", ")", ":", "\n", "        ", "return", "value", "\n", "", "raise", "argparse", ".", "ArgumentTypeError", "(", "\"Boolean value expected.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.isfloat": [[75, 90], ["float"], "function", ["None"], ["", "def", "isfloat", "(", "value", ")", ":", "\n", "    ", "\"\"\"Computes whether `value` can be cast to a float.\n\n    Args:\n        value (str): Value to check.\n\n    Returns:\n        bool: Whether `value` can be cast to a float.\n\n    \"\"\"", "\n", "try", ":", "\n", "        ", "float", "(", "value", ")", "\n", "return", "True", "\n", "", "except", "ValueError", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.isint": [[92, 107], ["int"], "function", ["None"], ["", "", "def", "isint", "(", "value", ")", ":", "\n", "    ", "\"\"\"Computes whether `value` can be cast to an int\n\n    Args:\n        value (str): Value to check.\n\n    Returns:\n        bool: Whether `value` can be cast to an int.\n\n    \"\"\"", "\n", "try", ":", "\n", "        ", "int", "(", "value", ")", "\n", "return", "True", "\n", "", "except", "ValueError", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.parse_args_as_dict": [[109, 140], ["parser.parse_args", "getattr"], "function", ["None"], ["", "", "def", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "False", ",", "args", "=", "None", ")", ":", "\n", "    ", "\"\"\"Get a dict of dicts out of process `parser.parse_args()`\n\n    Top-level keys corresponding to groups and bottom-level keys corresponding\n    to arguments. Under `'main_args'`, the arguments which don't belong to a\n    argparse group (i.e main arguments defined before parsing from a dict) can\n    be found.\n\n    Args:\n        parser (argparse.ArgumentParser): ArgumentParser instance containing\n            groups. Output of `prepare_parser_from_dict`.\n        return_plain_args (bool): Whether to return the output or\n            `parser.parse_args()`.\n        args (list): List of arguments as read from the command line.\n            Used for unit testing.\n\n    Returns:\n        dict:\n            Dictionary of dictionaries containing the arguments. Optionally the\n            direct output `parser.parse_args()`.\n    \"\"\"", "\n", "args", "=", "parser", ".", "parse_args", "(", "args", "=", "args", ")", "\n", "args_dic", "=", "{", "}", "\n", "for", "group", "in", "parser", ".", "_action_groups", ":", "\n", "        ", "group_dict", "=", "{", "a", ".", "dest", ":", "getattr", "(", "args", ",", "a", ".", "dest", ",", "None", ")", "for", "a", "in", "group", ".", "_group_actions", "}", "\n", "args_dic", "[", "group", ".", "title", "]", "=", "group_dict", "\n", "", "args_dic", "[", "\"main_args\"", "]", "=", "args_dic", "[", "\"optional arguments\"", "]", "\n", "del", "args_dic", "[", "\"optional arguments\"", "]", "\n", "if", "return_plain_args", ":", "\n", "        ", "return", "args_dic", ",", "args", "\n", "", "return", "args_dic", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.has_arg": [[6, 24], ["inspect.signature", "inspect.signature.parameters.get"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "has_arg", "(", "fn", ",", "name", ")", ":", "\n", "    ", "\"\"\"Checks if a callable accepts a given keyword argument.\n\n    Args:\n        fn (callable): Callable to inspect.\n        name (str): Check if ``fn`` can be called with ``name`` as a keyword\n            argument.\n\n    Returns:\n        bool: whether ``fn`` accepts a ``name`` keyword argument.\n    \"\"\"", "\n", "signature", "=", "inspect", ".", "signature", "(", "fn", ")", "\n", "parameter", "=", "signature", ".", "parameters", ".", "get", "(", "name", ")", "\n", "if", "parameter", "is", "None", ":", "\n", "        ", "return", "False", "\n", "", "return", "parameter", ".", "kind", "in", "(", "\n", "inspect", ".", "Parameter", ".", "POSITIONAL_OR_KEYWORD", ",", "\n", "inspect", ".", "Parameter", ".", "KEYWORD_ONLY", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.flatten_dict": [[27, 48], ["d.items", "dict", "isinstance", "items.extend", "items.append", "flatten_dict().items", "generic_utils.flatten_dict"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.flatten_dict"], ["", "def", "flatten_dict", "(", "d", ",", "parent_key", "=", "\"\"", ",", "sep", "=", "\"_\"", ")", ":", "\n", "    ", "\"\"\"Flattens a dictionary into a single-level dictionary while preserving\n    parent keys. Taken from\n    `SO <https://stackoverflow.com/questions/6027558/flatten-nested-dictionaries-compressing-keys>`_\n\n    Args:\n        d (MutableMapping): Dictionary to be flattened.\n        parent_key (str): String to use as a prefix to all subsequent keys.\n        sep (str): String to use as a separator between two key levels.\n\n    Returns:\n        dict: Single-level dictionary, flattened.\n    \"\"\"", "\n", "items", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "        ", "new_key", "=", "parent_key", "+", "sep", "+", "k", "if", "parent_key", "else", "k", "\n", "if", "isinstance", "(", "v", ",", "MutableMapping", ")", ":", "\n", "            ", "items", ".", "extend", "(", "flatten_dict", "(", "v", ",", "new_key", ",", "sep", "=", "sep", ")", ".", "items", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "items", ".", "append", "(", "(", "new_key", ",", "v", ")", ")", "\n", "", "", "return", "dict", "(", "items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.average_arrays_in_dic": [[50, 66], ["dict", "dict.items", "isinstance", "float", "v.mean"], "function", ["None"], ["", "def", "average_arrays_in_dic", "(", "dic", ")", ":", "\n", "    ", "\"\"\"Take average of numpy arrays in a dictionary.\n\n    Args:\n        dic (dict): Input dictionary to take average from\n\n    Returns:\n        dict: New dictionary with array averaged.\n\n    \"\"\"", "\n", "# Copy dic first", "\n", "dic", "=", "dict", "(", "dic", ")", "\n", "for", "k", ",", "v", "in", "dic", ".", "items", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "v", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "dic", "[", "k", "]", "=", "float", "(", "v", ".", "mean", "(", ")", ")", "\n", "", "", "return", "dic", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.get_wav_random_start_stop": [[68, 83], ["numpy.random.randint", "min", "max"], "function", ["None"], ["", "def", "get_wav_random_start_stop", "(", "signal_len", ",", "desired_len", "=", "4", "*", "8000", ")", ":", "\n", "    ", "\"\"\"Get indexes for a chunk of signal of a given length.\n\n    Args:\n        signal_len (int): length of the signal to trim.\n        desired_len (int): the length of [start:stop]\n\n    Returns:\n        tuple: random start integer, stop integer.\n    \"\"\"", "\n", "if", "desired_len", "is", "None", ":", "\n", "        ", "return", "0", ",", "signal_len", "\n", "", "rand_start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "max", "(", "1", ",", "signal_len", "-", "desired_len", ")", ")", "\n", "stop", "=", "min", "(", "signal_len", ",", "rand_start", "+", "desired_len", ")", "\n", "return", "rand_start", ",", "stop", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.unet_decoder_args": [[85, 109], ["reversed", "tuple", "decoder_args.append"], "function", ["None"], ["", "def", "unet_decoder_args", "(", "encoders", ",", "*", ",", "skip_connections", ")", ":", "\n", "    ", "\"\"\"Get list of decoder arguments for upsampling (right) side of a symmetric u-net,\n    given the arguments used to construct the encoder.\n\n    Args:\n        encoders (tuple of length `N` of tuples of (in_chan, out_chan, kernel_size, stride, padding)):\n            List of arguments used to construct the encoders\n        skip_connections (bool): Whether to include skip connections in the\n            calculation of decoder input channels.\n\n    Return:\n        tuple of length `N` of tuples of (in_chan, out_chan, kernel_size, stride, padding):\n            Arguments to be used to construct decoders\n    \"\"\"", "\n", "decoder_args", "=", "[", "]", "\n", "for", "enc_in_chan", ",", "enc_out_chan", ",", "enc_kernel_size", ",", "enc_stride", ",", "enc_padding", "in", "reversed", "(", "encoders", ")", ":", "\n", "        ", "if", "skip_connections", "and", "decoder_args", ":", "\n", "            ", "skip_in_chan", "=", "enc_out_chan", "\n", "", "else", ":", "\n", "            ", "skip_in_chan", "=", "0", "\n", "", "decoder_args", ".", "append", "(", "\n", "(", "enc_out_chan", "+", "skip_in_chan", ",", "enc_in_chan", ",", "enc_kernel_size", ",", "enc_stride", ",", "enc_padding", ")", "\n", ")", "\n", "", "return", "tuple", "(", "decoder_args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.to_cuda": [[8, 31], ["isinstance", "isinstance", "isinstance", "TypeError", "tensors.cuda", "tensors.keys", "torch_utils.to_cuda", "torch_utils.to_cuda", "type"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.to_cuda", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.to_cuda"], ["def", "to_cuda", "(", "tensors", ")", ":", "# pragma: no cover", "\n", "    ", "\"\"\"Transfer tensor, dict or list of tensors to GPU.\n\n    Args:\n        tensors (:class:`torch.Tensor`, list or dict): May be a single, a\n            list or a dictionary of tensors.\n\n    Returns:\n        :class:`torch.Tensor`:\n        Same as input but transferred to cuda. Goes through lists and dicts\n        and transfers the torch.Tensor to cuda. Leaves the rest untouched.\n    \"\"\"", "\n", "if", "isinstance", "(", "tensors", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "tensors", ".", "cuda", "(", ")", "\n", "", "if", "isinstance", "(", "tensors", ",", "list", ")", ":", "\n", "        ", "return", "[", "to_cuda", "(", "tens", ")", "for", "tens", "in", "tensors", "]", "\n", "", "if", "isinstance", "(", "tensors", ",", "dict", ")", ":", "\n", "        ", "for", "key", "in", "tensors", ".", "keys", "(", ")", ":", "\n", "            ", "tensors", "[", "key", "]", "=", "to_cuda", "(", "tensors", "[", "key", "]", ")", "\n", "", "return", "tensors", "\n", "", "raise", "TypeError", "(", "\n", "\"tensors must be a tensor or a list or dict of tensors. \"", "\n", "\" Got tensors of type {}\"", ".", "format", "(", "type", "(", "tensors", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device": [[34, 58], ["isinstance", "tensors.to", "isinstance", "isinstance", "torch_utils.tensors_to_device", "tensors.keys", "torch_utils.tensors_to_device"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device"], ["", "def", "tensors_to_device", "(", "tensors", ",", "device", ")", ":", "\n", "    ", "\"\"\"Transfer tensor, dict or list of tensors to device.\n\n    Args:\n        tensors (:class:`torch.Tensor`): May be a single, a list or a\n            dictionary of tensors.\n        device (:class: `torch.device`): the device where to place the tensors.\n\n    Returns:\n        Union [:class:`torch.Tensor`, list, tuple, dict]:\n            Same as input but transferred to device.\n            Goes through lists and dicts and transfers the torch.Tensor to\n            device. Leaves the rest untouched.\n    \"\"\"", "\n", "if", "isinstance", "(", "tensors", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "tensors", ".", "to", "(", "device", ")", "\n", "", "elif", "isinstance", "(", "tensors", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "return", "[", "tensors_to_device", "(", "tens", ",", "device", ")", "for", "tens", "in", "tensors", "]", "\n", "", "elif", "isinstance", "(", "tensors", ",", "dict", ")", ":", "\n", "        ", "for", "key", "in", "tensors", ".", "keys", "(", ")", ":", "\n", "            ", "tensors", "[", "key", "]", "=", "tensors_to_device", "(", "tensors", "[", "key", "]", ",", "device", ")", "\n", "", "return", "tensors", "\n", "", "else", ":", "\n", "        ", "return", "tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.get_device": [[60, 83], ["hasattr", "hasattr", "next", "TypeError", "torch.device", "tensor_or_module.parameters", "type"], "function", ["None"], ["", "", "def", "get_device", "(", "tensor_or_module", ",", "default", "=", "None", ")", ":", "\n", "    ", "\"\"\"Get the device of a tensor or a module.\n\n    Args:\n        tensor_or_module (Union[torch.Tensor, torch.nn.Module]):\n            The object to get the device from. Can be a ``torch.Tensor``,\n            a ``torch.nn.Module``, or anything else that has a ``device`` attribute\n            or a ``parameters() -> Iterator[torch.Tensor]`` method.\n        default (Optional[Union[str, torch.device]]): If the device can not be\n            determined, return this device instead. If ``None`` (the default),\n            raise a ``TypeError`` instead.\n\n    Returns:\n        torch.device: The device that ``tensor_or_module`` is on.\n    \"\"\"", "\n", "if", "hasattr", "(", "tensor_or_module", ",", "\"device\"", ")", ":", "\n", "        ", "return", "tensor_or_module", ".", "device", "\n", "", "elif", "hasattr", "(", "tensor_or_module", ",", "\"parameters\"", ")", ":", "\n", "        ", "return", "next", "(", "tensor_or_module", ".", "parameters", "(", ")", ")", ".", "device", "\n", "", "elif", "default", "is", "None", ":", "\n", "        ", "raise", "TypeError", "(", "f\"Don't know how to get device of {type(tensor_or_module)} object\"", ")", "\n", "", "else", ":", "\n", "        ", "return", "torch", ".", "device", "(", "default", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.is_tracing": [[85, 92], ["torch._C._is_tracing"], "function", ["None"], ["", "", "def", "is_tracing", "(", ")", ":", "\n", "# Taken for pytorch for compat in 1.6.0", "\n", "    ", "\"\"\"\n    Returns ``True`` in tracing (if a function is called during the tracing of\n    code with ``torch.jit.trace``) and ``False`` otherwise.\n    \"\"\"", "\n", "return", "torch", ".", "_C", ".", "_is_tracing", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.script_if_tracing": [[94, 126], ["functools.wraps", "torch.jit.script", "torch.jit.script.", "torch_utils.is_tracing", "fn"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.is_tracing"], ["", "def", "script_if_tracing", "(", "fn", ")", ":", "\n", "# Taken for pytorch for compat in 1.6.0", "\n", "    ", "\"\"\"\n    Compiles ``fn`` when it is first called during tracing. ``torch.jit.script``\n    has a non-negligible start up time when it is first called due to\n    lazy-initializations of many compiler builtins. Therefore you should not use\n    it in library code. However, you may want to have parts of your library work\n    in tracing even if they use control flow. In these cases, you should use\n    ``@torch.jit.script_if_tracing`` to substitute for\n    ``torch.jit.script``.\n\n    Arguments:\n        fn: A function to compile.\n\n    Returns:\n        If called during tracing, a :class:`ScriptFunction` created by `\n        `torch.jit.script`` is returned. Otherwise, the original function ``fn`` is returned.\n    \"\"\"", "\n", "\n", "@", "functools", ".", "wraps", "(", "fn", ")", "\n", "def", "wrapper", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "is_tracing", "(", ")", ":", "\n", "# Not tracing, don't do anything", "\n", "            ", "return", "fn", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "compiled_fn", "=", "torch", ".", "jit", ".", "script", "(", "wrapper", ".", "__original_fn", ")", "# type: ignore", "\n", "return", "compiled_fn", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "wrapper", ".", "__original_fn", "=", "fn", "# type: ignore", "\n", "wrapper", ".", "__script_if_tracing_wrapper", "=", "True", "# type: ignore", "\n", "\n", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.pad_x_to_y": [[128, 145], ["torch.nn.functional.pad"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad"], ["", "@", "script_if_tracing", "\n", "def", "pad_x_to_y", "(", "x", ":", "torch", ".", "Tensor", ",", "y", ":", "torch", ".", "Tensor", ",", "axis", ":", "int", "=", "-", "1", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Right-pad or right-trim first argument to have same size as second argument\n\n    Args:\n        x (torch.Tensor): Tensor to be padded.\n        y (torch.Tensor): Tensor to pad `x` to.\n        axis (int): Axis to pad on.\n\n    Returns:\n        torch.Tensor, `x` padded to match `y`'s shape.\n    \"\"\"", "\n", "if", "axis", "!=", "-", "1", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "inp_len", "=", "y", ".", "shape", "[", "axis", "]", "\n", "output_len", "=", "x", ".", "shape", "[", "axis", "]", "\n", "return", "nn", ".", "functional", ".", "pad", "(", "x", ",", "[", "0", ",", "inp_len", "-", "output_len", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.load_state_dict_in": [[147, 182], ["model.load_state_dict", "collections.OrderedDict", "state_dict.items", "model.load_state_dict", "k.find"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict"], ["", "def", "load_state_dict_in", "(", "state_dict", ",", "model", ")", ":", "\n", "    ", "\"\"\"Strictly loads state_dict in model, or the next submodel.\n        Useful to load standalone model after training it with System.\n\n    Args:\n        state_dict (OrderedDict): the state_dict to load.\n        model (torch.nn.Module): the model to load it into\n\n    Returns:\n        torch.nn.Module: model with loaded weights.\n\n    .. note:: Keys in a state_dict look like ``object1.object2.layer_name.weight.etc``\n        We first try to load the model in the classic way.\n        If this fail we removes the first left part of the key to obtain\n        ``object2.layer_name.weight.etc``.\n        Blindly loading with ``strictly=False`` should be done with some logging\n        of the missing keys in the state_dict and the model.\n\n    \"\"\"", "\n", "try", ":", "\n", "# This can fail if the model was included into a bigger nn.Module", "\n", "# object. For example, into System.", "\n", "        ", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "True", ")", "\n", "", "except", "RuntimeError", ":", "\n", "# keys look like object1.object2.layer_name.weight.etc", "\n", "# The following will remove the first left part of the key to obtain", "\n", "# object2.layer_name.weight.etc.", "\n", "# Blindly loading with strictly=False should be done with some", "\n", "# new_state_dict of the missing keys in the state_dict and the model.", "\n", "        ", "new_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "new_k", "=", "k", "[", "k", ".", "find", "(", "\".\"", ")", "+", "1", ":", "]", "\n", "new_state_dict", "[", "new_k", "]", "=", "v", "\n", "", "model", ".", "load_state_dict", "(", "new_state_dict", ",", "strict", "=", "True", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.are_models_equal": [[184, 198], ["zip", "model1.parameters", "model2.parameters", "p1.data.ne().sum", "p1.data.ne"], "function", ["None"], ["", "def", "are_models_equal", "(", "model1", ",", "model2", ")", ":", "\n", "    ", "\"\"\"Check for weights equality between models.\n\n    Args:\n        model1 (nn.Module): model instance to be compared.\n        model2 (nn.Module): second model instance to be compared.\n\n    Returns:\n        bool: Whether all model weights are equal.\n    \"\"\"", "\n", "for", "p1", ",", "p2", "in", "zip", "(", "model1", ".", "parameters", "(", ")", ",", "model2", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "if", "p1", ".", "data", ".", "ne", "(", "p2", ".", "data", ")", ".", "sum", "(", ")", ">", "0", ":", "\n", "            ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.jitable_shape": [[200, 215], ["torch.tensor"], "function", ["None"], ["", "@", "script_if_tracing", "\n", "def", "jitable_shape", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"Gets shape of ``tensor`` as ``torch.Tensor`` type for jit compiler\n\n    .. note::\n        Returning ``tensor.shape`` of ``tensor.size()`` directly is not torchscript\n        compatible as return type would not be supported.\n\n    Args:\n        tensor (torch.Tensor): Tensor\n\n    Returns:\n        torch.Tensor: Shape of ``tensor``\n    \"\"\"", "\n", "return", "torch", ".", "tensor", "(", "tensor", ".", "shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils_test.test_download": [[14, 21], ["asteroid.utils.hub_utils.cached_download", "os.path.isfile", "asteroid.utils.hub_utils.cached_download"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.cached_download", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.cached_download"], ["def", "test_download", "(", ")", ":", "\n", "# We download", "\n", "    ", "path1", "=", "hub_utils", ".", "cached_download", "(", "\"mpariente/ConvTasNet_WHAM!_sepclean\"", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "path1", ")", "\n", "# We use cache", "\n", "path2", "=", "hub_utils", ".", "cached_download", "(", "\"mpariente/ConvTasNet_WHAM!_sepclean\"", ")", "\n", "assert", "path1", "==", "path2", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils_test.test_hf_download": [[23, 40], ["pytest.mark.parametrize", "asteroid.utils.hub_utils.cached_download", "os.path.isfile", "asteroid.utils.hub_utils.cached_download", "asteroid.utils.hub_utils.cached_download"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.cached_download", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.cached_download", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.cached_download"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"model_id\"", ",", "\n", "[", "HF_EXAMPLE_MODEL_IDENTIFER", ",", "HF_EXAMPLE_MODEL_IDENTIFER_URL", "]", ",", "\n", ")", "\n", "def", "test_hf_download", "(", "model_id", ")", ":", "\n", "# We download", "\n", "    ", "path1", "=", "hub_utils", ".", "cached_download", "(", "model_id", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "path1", ")", "\n", "# We use cache", "\n", "path2", "=", "hub_utils", ".", "cached_download", "(", "model_id", ")", "\n", "assert", "path1", "==", "path2", "\n", "# However if specifying a particular commit,", "\n", "# file will be different.", "\n", "path3", "=", "hub_utils", ".", "cached_download", "(", "\n", "f\"{HF_EXAMPLE_MODEL_IDENTIFER}@{REVISION_ID_ONE_SPECIFIC_COMMIT}\"", "\n", ")", "\n", "assert", "path3", "!=", "path1", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils_test.test_model_list": [[42, 45], ["asteroid.utils.hub_utils.model_list", "asteroid.utils.hub_utils.model_list"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.model_list", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.model_list"], ["", "def", "test_model_list", "(", ")", ":", "\n", "    ", "hub_utils", ".", "model_list", "(", ")", "\n", "hub_utils", ".", "model_list", "(", "name_only", "=", "True", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils_test.test_warning": [[6, 9], ["pytest.warns", "warnings.warn"], "function", ["None"], ["def", "test_warning", "(", ")", ":", "\n", "    ", "with", "pytest", ".", "warns", "(", "dp", ".", "VisibleDeprecationWarning", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"Expected warning.\"", ",", "dp", ".", "VisibleDeprecationWarning", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils_test.test_deprecated": [[11, 41], ["Foo", "Foo.new_func", "asteroid.utils.deprecation_utils.mark_deprecated", "asteroid.utils.deprecation_utils.mark_deprecated", "asteroid.utils.deprecation_utils.mark_deprecated", "pytest.warns", "Foo.old_func", "len", "pytest.warns", "Foo.no_version_old_func", "Foo.no_message_old_func"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.mark_deprecated", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.mark_deprecated", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.mark_deprecated"], ["", "", "def", "test_deprecated", "(", ")", ":", "\n", "    ", "class", "Foo", ":", "\n", "        ", "def", "new_func", "(", "self", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "@", "dp", ".", "mark_deprecated", "(", "\"Please use `new_func`\"", ",", "\"0.5.0\"", ")", "\n", "def", "old_func", "(", "self", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "@", "dp", ".", "mark_deprecated", "(", "\"Please use `new_func`\"", ")", "\n", "def", "no_version_old_func", "(", "self", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "@", "dp", ".", "mark_deprecated", "(", "message", "=", "\"\"", ")", "\n", "def", "no_message_old_func", "(", "self", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "", "foo", "=", "Foo", "(", ")", "\n", "foo", ".", "new_func", "(", ")", "\n", "\n", "with", "pytest", ".", "warns", "(", "dp", ".", "VisibleDeprecationWarning", ")", "as", "record", ":", "\n", "        ", "foo", ".", "old_func", "(", ")", "\n", "# check that only one warning was raised", "\n", "", "assert", "len", "(", "record", ")", "==", "1", "\n", "# check that the message matches", "\n", "assert", "\"0.5.0\"", "in", "record", "[", "0", "]", ".", "message", ".", "args", "[", "0", "]", "\n", "\n", "with", "pytest", ".", "warns", "(", "dp", ".", "VisibleDeprecationWarning", ")", ":", "\n", "        ", "foo", ".", "no_version_old_func", "(", ")", "\n", "foo", ".", "no_message_old_func", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils_test.test_is_overidden": [[43, 83], ["asteroid.utils.deprecation_utils.is_overridden", "asteroid.utils.deprecation_utils.is_overridden", "Bar", "asteroid.utils.deprecation_utils.is_overridden", "asteroid.utils.deprecation_utils.is_overridden", "Hey", "asteroid.utils.deprecation_utils.is_overridden", "asteroid.utils.deprecation_utils.is_overridden", "asteroid.utils.deprecation_utils.is_overridden", "pytest.raises", "asteroid.utils.deprecation_utils.is_overridden", "pytest.raises", "asteroid.utils.deprecation_utils.is_overridden", "pytest.raises", "asteroid.utils.deprecation_utils.is_overridden"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.is_overridden", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.is_overridden", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.is_overridden", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.is_overridden", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.is_overridden", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.is_overridden", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.is_overridden", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.is_overridden", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.is_overridden", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.deprecation_utils.is_overridden"], ["", "", "def", "test_is_overidden", "(", ")", ":", "\n", "    ", "class", "Foo", ":", "\n", "        ", "def", "some_func", "(", "self", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "", "class", "Bar", "(", "Foo", ")", ":", "\n", "        ", "def", "some_func", "(", "self", ")", ":", "\n", "            ", "something_changed", "=", "None", "\n", "return", "None", "\n", "\n", "", "", "class", "Ho", "(", "Bar", ")", ":", "\n", "        ", "pass", "\n", "\n", "# On class", "\n", "", "assert", "dp", ".", "is_overridden", "(", "\"some_func\"", ",", "Bar", ",", "parent", "=", "Foo", ")", "\n", "assert", "dp", ".", "is_overridden", "(", "\"some_func\"", ",", "Bar", ")", "\n", "# On instance", "\n", "bar", "=", "Bar", "(", ")", "\n", "assert", "dp", ".", "is_overridden", "(", "\"some_func\"", ",", "bar", ",", "parent", "=", "Foo", ")", "\n", "assert", "dp", ".", "is_overridden", "(", "\"some_func\"", ",", "bar", ")", "\n", "\n", "class", "Hey", "(", "Foo", ")", ":", "\n", "        ", "def", "some_other_func", "(", "self", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "# On class", "\n", "", "", "assert", "not", "dp", ".", "is_overridden", "(", "\"some_func\"", ",", "Hey", ",", "parent", "=", "Foo", ")", "\n", "# On instance", "\n", "hey", "=", "Hey", "(", ")", "\n", "assert", "not", "dp", ".", "is_overridden", "(", "\"some_func\"", ",", "hey", ",", "parent", "=", "Foo", ")", "\n", "assert", "not", "dp", ".", "is_overridden", "(", "\"some_func\"", ",", "hey", ",", "parent", "=", "Foo", ")", "\n", "\n", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "        ", "dp", ".", "is_overridden", "(", "\"some_func\"", ",", "hey", ",", "parent", "=", "Bar", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "        ", "dp", ".", "is_overridden", "(", "\"some_other_func\"", ",", "hey", ",", "parent", "=", "Foo", ")", "\n", "\n", "", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "        ", "dp", ".", "is_overridden", "(", "\"some_other_func\"", ",", "hey", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils_test.test_pad": [[7, 12], ["torch.randn", "torch.randn", "asteroid.torch_utils.pad_x_to_y"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.pad_x_to_y"], ["def", "test_pad", "(", ")", ":", "\n", "    ", "x", "=", "torch", ".", "randn", "(", "10", ",", "1", ",", "16000", ")", "\n", "y", "=", "torch", ".", "randn", "(", "10", ",", "1", ",", "16234", ")", "\n", "padded_x", "=", "torch_utils", ".", "pad_x_to_y", "(", "x", ",", "y", ")", "\n", "assert", "padded_x", ".", "shape", "==", "y", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils_test.test_pad_fail": [[14, 19], ["torch.randn", "torch.randn", "pytest.raises", "asteroid.torch_utils.pad_x_to_y"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.pad_x_to_y"], ["", "def", "test_pad_fail", "(", ")", ":", "\n", "    ", "x", "=", "torch", ".", "randn", "(", "10", ",", "16000", ",", "1", ")", "\n", "y", "=", "torch", ".", "randn", "(", "10", ",", "16234", ",", "1", ")", "\n", "with", "pytest", ".", "raises", "(", "NotImplementedError", ")", ":", "\n", "        ", "torch_utils", ".", "pad_x_to_y", "(", "x", ",", "y", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils_test.test_model_equal": [[21, 26], ["torch.nn.Sequential", "asteroid.torch_utils.are_models_equal", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "asteroid.torch_utils.are_models_equal"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.are_models_equal", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.are_models_equal"], ["", "", "def", "test_model_equal", "(", ")", ":", "\n", "    ", "model", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "10", ",", "10", ")", ")", "\n", "assert", "torch_utils", ".", "are_models_equal", "(", "model", ",", "model", ")", "\n", "model_2", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "10", ",", "10", ")", ")", "\n", "assert", "not", "torch_utils", ".", "are_models_equal", "(", "model", ",", "model_2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils_test.test_loader_module": [[28, 34], ["torch.nn.Sequential", "nn.Sequential.state_dict", "torch.nn.Sequential", "asteroid.torch_utils.load_state_dict_in", "asteroid.torch_utils.are_models_equal", "torch.nn.Linear", "torch.nn.Linear"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.load_state_dict_in", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.are_models_equal"], ["", "def", "test_loader_module", "(", ")", ":", "\n", "    ", "model", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "10", ",", "10", ")", ")", "\n", "state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "model_2", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "10", ",", "10", ")", ")", "\n", "model_2", "=", "torch_utils", ".", "load_state_dict_in", "(", "state_dict", ",", "model_2", ")", "\n", "assert", "torch_utils", ".", "are_models_equal", "(", "model", ",", "model_2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils_test.test_loader_submodule": [[36, 58], ["SuperModule", "SuperModule.state_dict", "torch.nn.Sequential", "torch_utils.load_state_dict_in.load_state_dict", "asteroid.torch_utils.load_state_dict_in", "asteroid.torch_utils.are_models_equal", "torch.nn.Sequential", "torch.nn.Linear", "pytest.raises", "torch_utils.load_state_dict_in.load_state_dict", "asteroid.torch_utils.are_models_equal", "super().__init__", "torch.nn.Linear"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.load_state_dict_in", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.are_models_equal", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.are_models_equal", "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["", "def", "test_loader_submodule", "(", ")", ":", "\n", "    ", "class", "SuperModule", "(", "nn", ".", "Module", ")", ":", "\n", "        ", "\"\"\"nn.Module subclass that holds a model under self.whoever\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "sub_model", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "whoever", "=", "sub_model", "\n", "\n", "", "", "model", "=", "SuperModule", "(", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "10", ",", "10", ")", ")", ")", "\n", "# Keys in state_dict will be whoever.0.weight, whoever.0.bias", "\n", "state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "# We want to load it in model_2 (has keys 0.weight, 0.bias)", "\n", "model_2", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "10", ",", "10", ")", ")", "\n", "# Keys are not the same, torch raises an error for that.", "\n", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "        ", "model_2", ".", "load_state_dict", "(", "state_dict", ")", "\n", "# We can try loose model loading (assert it doesn't work)", "\n", "", "model_2", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "False", ")", "\n", "assert", "not", "torch_utils", ".", "are_models_equal", "(", "model", ",", "model_2", ")", "\n", "# Apply our workaround torch_utils.load_state_dict_in and assert True.", "\n", "model_2", "=", "torch_utils", ".", "load_state_dict_in", "(", "state_dict", ",", "model_2", ")", "\n", "assert", "torch_utils", ".", "are_models_equal", "(", "model", ",", "model_2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils_test.test_jitable_shape": [[60, 72], ["pytest.mark.parametrize", "asteroid.torch_utils.jitable_shape", "torch.equal", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.jitable_shape"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"data, expected\"", ",", "\n", "(", "\n", "(", "torch", ".", "tensor", "(", "[", "1", "]", ")", ",", "torch", ".", "tensor", "(", "[", "1", "]", ")", ")", ",", "\n", "(", "torch", ".", "tensor", "(", "[", "1", ",", "2", "]", ")", ",", "torch", ".", "tensor", "(", "[", "2", "]", ")", ")", ",", "\n", "(", "torch", ".", "tensor", "(", "[", "[", "1", "]", ",", "[", "2", "]", "]", ")", ",", "torch", ".", "tensor", "(", "[", "2", ",", "1", "]", ")", ")", ",", "\n", "(", "torch", ".", "tensor", "(", "[", "[", "2", ",", "5", ",", "5", "]", ",", "[", "3", ",", "8", ",", "-", "2", "]", "]", ")", ",", "torch", ".", "tensor", "(", "[", "2", ",", "3", "]", ")", ")", ",", "\n", ")", ",", "\n", ")", "\n", "def", "test_jitable_shape", "(", "data", ",", "expected", ")", ":", "\n", "    ", "output", "=", "torch_utils", ".", "jitable_shape", "(", "data", ")", "\n", "assert", "torch", ".", "equal", "(", "output", ",", "expected", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils_test.test_get_device": [[74, 91], ["asteroid.torch_utils.get_device", "asteroid.torch_utils.get_device", "pytest.raises", "asteroid.torch_utils.get_device", "FakeTensor", "FakeModule", "UnknownObject", "FakeTensor"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.get_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.get_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.get_device"], ["", "def", "test_get_device", "(", ")", ":", "\n", "# We have only CPU in CI so can't test with real devices.", "\n", "\n", "    ", "class", "FakeTensor", ":", "\n", "        ", "device", "=", "\"dev1\"", "\n", "\n", "", "class", "FakeModule", ":", "\n", "        ", "def", "parameters", "(", "self", ")", ":", "\n", "            ", "yield", "FakeTensor", "(", ")", "\n", "\n", "", "", "class", "UnknownObject", ":", "\n", "        ", "pass", "\n", "\n", "", "assert", "torch_utils", ".", "get_device", "(", "FakeTensor", "(", ")", ")", "==", "\"dev1\"", "\n", "assert", "torch_utils", ".", "get_device", "(", "FakeModule", "(", ")", ")", "==", "\"dev1\"", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "        ", "torch_utils", ".", "get_device", "(", "UnknownObject", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.utils_test.parser": [[13, 23], ["pytest.fixture", "dict", "argparse.ArgumentParser", "asteroid.utils.prepare_parser_from_dict.add_argument", "asteroid.utils.prepare_parser_from_dict", "dict", "dict"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.prepare_parser_from_dict"], ["@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "parser", "(", ")", ":", "\n", "# Create dictionary as from .yml file", "\n", "    ", "def_conf", "=", "dict", "(", "top1", "=", "dict", "(", "key1", "=", "2", ")", ",", "top2", "=", "dict", "(", "key2", "=", "None", ",", "key3", "=", "True", ")", ")", "\n", "# Create empty parser and add top level keys", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--main_key\"", ",", "default", "=", "\"\"", ")", "\n", "# Populate parser from def_conf", "\n", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.utils_test.test_namespace_dic": [[25, 30], ["asteroid.utils.parse_args_as_dict"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.parse_args_as_dict"], ["", "def", "test_namespace_dic", "(", "parser", ")", ":", "\n", "    ", "fake_args", "=", "[", "\"--key2\"", ",", "\"hey\"", ",", "\"--key3\"", ",", "\"0\"", "]", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ",", "args", "=", "fake_args", ")", "\n", "assert", "arg_dic", "[", "\"main_args\"", "]", "[", "\"main_key\"", "]", "==", "plain_args", ".", "main_key", "\n", "assert", "arg_dic", "[", "\"top2\"", "]", "[", "\"key3\"", "]", "==", "plain_args", ".", "key3", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.utils_test.test_none_default": [[32, 39], ["pytest.mark.parametrize", "asteroid.utils.parse_args_as_dict", "str", "type", "type"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.parse_args_as_dict"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"inp\"", ",", "[", "\"one_string\"", ",", "3", ",", "3.14", "]", ")", "\n", "def", "test_none_default", "(", "parser", ",", "inp", ")", ":", "\n", "# If the default is None, convert the input string into an int, a float", "\n", "# or string.", "\n", "    ", "fake_args", "=", "[", "\"--key2\"", ",", "str", "(", "inp", ")", "]", "# Note : inp is converted to string", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ",", "args", "=", "fake_args", ")", "\n", "assert", "type", "(", "plain_args", ".", "key2", ")", "==", "type", "(", "inp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.utils_test.test_boolean": [[41, 49], ["asteroid.utils.parse_args_as_dict", "asteroid.utils.parse_args_as_dict"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.parse_args_as_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.parser_utils.parse_args_as_dict"], ["", "def", "test_boolean", "(", "parser", ")", ":", "\n", "    ", "fake_args", "=", "[", "\"--key3\"", ",", "\"y\"", "]", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ",", "args", "=", "fake_args", ")", "\n", "assert", "plain_args", ".", "key3", "is", "True", "\n", "\n", "fake_args", "=", "[", "\"--key3\"", ",", "\"n\"", "]", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ",", "args", "=", "fake_args", ")", "\n", "assert", "plain_args", ".", "key3", "is", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.utils_test.test_transfer": [[51, 72], ["pytest.mark.parametrize", "isinstance", "isinstance", "isinstance", "torch.testing.assert_allclose", "torch.randn", "dict", "dict", "asteroid.utils.tensors_to_device", "list", "list", "dict", "dict", "torch.randn", "torch.randn", "dict", "torch.randn", "asteroid.utils.tensors_to_device", "asteroid.utils.tensors_to_device", "torch.randn", "torch.randn", "torch.randn", "dict", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"tensors\"", ",", "\n", "[", "\n", "torch", ".", "randn", "(", "10", ",", "10", ")", ",", "# tensor", "\n", "dict", "(", "tensor_a", "=", "torch", ".", "randn", "(", "10", ",", "10", ")", ",", "tensor_b", "=", "torch", ".", "randn", "(", "12", ",", "12", ")", ")", ",", "# dict", "\n", "[", "torch", ".", "randn", "(", "10", ",", "10", ")", ",", "torch", ".", "randn", "(", "12", ",", "12", ")", "]", ",", "# list", "\n", "dict", "(", "\n", "tensor_a", "=", "torch", ".", "randn", "(", "10", ",", "10", ")", ",", "\n", "tensor_list", "=", "[", "torch", ".", "randn", "(", "12", ",", "12", ")", ",", "torch", ".", "randn", "(", "14", ",", "14", ")", "]", ",", "\n", "tensor_dict", "=", "dict", "(", "u", "=", "torch", ".", "randn", "(", "8", ",", "10", ")", ",", "v", "=", "torch", ".", "randn", "(", "10", ",", "8", ")", ")", ",", "\n", ")", ",", "\n", "[", "dict", "(", "u", "=", "torch", ".", "randn", "(", "8", ",", "10", ")", ",", "v", "=", "torch", ".", "randn", "(", "10", ",", "8", ")", ")", ",", "torch", ".", "randn", "(", "10", ",", "10", ")", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_transfer", "(", "tensors", ")", ":", "\n", "    ", "if", "isinstance", "(", "tensors", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "assert_allclose", "(", "utils", ".", "tensors_to_device", "(", "tensors", ",", "\"cpu\"", ")", ",", "tensors", ")", "\n", "", "if", "isinstance", "(", "tensors", ",", "list", ")", ":", "\n", "        ", "assert", "list", "(", "utils", ".", "tensors_to_device", "(", "tensors", ",", "\"cpu\"", ")", ")", "==", "list", "(", "tensors", ")", "\n", "", "if", "isinstance", "(", "tensors", ",", "dict", ")", ":", "\n", "        ", "assert", "dict", "(", "utils", ".", "tensors_to_device", "(", "tensors", ",", "\"cpu\"", ")", ")", "==", "dict", "(", "tensors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.utils_test.test_flatten_dict": [[74, 84], ["dict", "asteroid.utils.flatten_dict", "utils.flatten_dict.items", "dict", "isinstance", "dict"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.flatten_dict"], ["", "", "def", "test_flatten_dict", "(", ")", ":", "\n", "    ", "to_test", "=", "dict", "(", "\n", "top1", "=", "[", "1", ",", "2", "]", ",", "\n", "top2", "=", "dict", "(", "\n", "sub1", "=", "\"hey\"", ",", "sub2", "=", "dict", "(", "subsub1", "=", "True", ",", "subsub2", "=", "[", "\"This\"", ",", "\"is\"", ",", "\"a\"", ",", "\"list\"", "]", ")", ",", "sub3", "=", "False", "\n", ")", ",", "\n", ")", "\n", "flat_dic", "=", "utils", ".", "flatten_dict", "(", "to_test", ")", "\n", "for", "k", ",", "v", "in", "flat_dic", ".", "items", "(", ")", ":", "\n", "        ", "assert", "not", "isinstance", "(", "v", ",", "MutableMapping", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.utils_test.test_average_array_in_dic": [[86, 92], ["dict", "asteroid.utils.average_arrays_in_dic", "dict", "numpy.array"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.average_arrays_in_dic"], ["", "", "def", "test_average_array_in_dic", "(", ")", ":", "\n", "    ", "d", "=", "dict", "(", "a", "=", "\"hey\"", ",", "b", "=", "np", ".", "array", "(", "[", "1.0", ",", "3.0", "]", ")", ",", "c", "=", "2", ")", "\n", "av_d", "=", "utils", ".", "average_arrays_in_dic", "(", "d", ")", "\n", "d_should_be", "=", "dict", "(", "a", "=", "\"hey\"", ",", "b", "=", "2.0", ",", "c", "=", "2", ")", "\n", "# We need the arrays to be averaged", "\n", "assert", "av_d", "==", "d_should_be", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.utils_test.test_get_start_stop": [[94, 104], ["pytest.mark.parametrize", "numpy.random.randn", "asteroid.utils.get_wav_random_start_stop", "itertools.product", "len", "max", "min"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.get_wav_random_start_stop"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"sig_len,desired\"", ",", "itertools", ".", "product", "(", "[", "50", ",", "100", ",", "150", "]", ",", "[", "50", ",", "100", ",", "150", "]", ")", ")", "\n", "def", "test_get_start_stop", "(", "sig_len", ",", "desired", ")", ":", "\n", "    ", "sig", "=", "np", ".", "random", ".", "randn", "(", "sig_len", ")", "\n", "start", ",", "stop", "=", "utils", ".", "get_wav_random_start_stop", "(", "len", "(", "sig", ")", ",", "desired_len", "=", "desired", ")", "\n", "# Start must be chosen so that len(sig[start:]) is at least `desired`", "\n", "# (or if `desired < sig_len`, then exactly `sig_len`).", "\n", "assert", "start", "<", "max", "(", "1", ",", "sig_len", "-", "desired", ")", "\n", "# Stop must be chosen so that `start + stop == desired`", "\n", "# (or if `desired < sig_len`, then exactly `sig_len`).", "\n", "assert", "stop", "==", "start", "+", "min", "(", "sig_len", ",", "desired", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.utils_test.test_unet_decoder_args": [[106, 122], ["numpy.random.randint", "asteroid.utils.unet_decoder_args", "asteroid.utils.unet_decoder_args"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.unet_decoder_args", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.unet_decoder_args"], ["", "def", "test_unet_decoder_args", "(", ")", ":", "\n", "    ", "a", ",", "b", ",", "c", ",", "d", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "100", ",", "size", "=", "4", ")", "\n", "encoders", "=", "(", "\n", "(", "a", ",", "b", ",", "\"ks1\"", ",", "\"st1\"", ",", "\"pad1\"", ")", ",", "\n", "(", "b", ",", "c", ",", "\"ks2\"", ",", "\"st2\"", ",", "\"pad2\"", ")", ",", "\n", "(", "c", ",", "d", ",", "\"ks3\"", ",", "\"st3\"", ",", "\"pad3\"", ")", ",", "\n", ")", "\n", "assert", "utils", ".", "unet_decoder_args", "(", "encoders", ",", "skip_connections", "=", "False", ")", "==", "(", "\n", "(", "1", "*", "d", ",", "c", ",", "\"ks3\"", ",", "\"st3\"", ",", "\"pad3\"", ")", ",", "\n", "(", "1", "*", "c", ",", "b", ",", "\"ks2\"", ",", "\"st2\"", ",", "\"pad2\"", ")", ",", "\n", "(", "1", "*", "b", ",", "a", ",", "\"ks1\"", ",", "\"st1\"", ",", "\"pad1\"", ")", ",", "\n", ")", "\n", "assert", "utils", ".", "unet_decoder_args", "(", "encoders", ",", "skip_connections", "=", "True", ")", "==", "(", "\n", "(", "1", "*", "d", ",", "c", ",", "\"ks3\"", ",", "\"st3\"", ",", "\"pad3\"", ")", ",", "\n", "(", "2", "*", "c", ",", "b", ",", "\"ks2\"", ",", "\"st2\"", ",", "\"pad2\"", ")", ",", "\n", "(", "2", "*", "b", ",", "a", ",", "\"ks1\"", ",", "\"st1\"", ",", "\"pad1\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.print_versions": [[9, 13], ["asteroid_versions().items", "print", "asteroid_versions.asteroid_versions"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.asteroid_versions"], ["def", "print_versions", "(", ")", ":", "\n", "    ", "\"\"\"CLI function to get info about the Asteroid and dependency versions.\"\"\"", "\n", "for", "k", ",", "v", "in", "asteroid_versions", "(", ")", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "f\"{k:20s}{v}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.asteroid_versions": [[15, 20], ["asteroid_versions.asteroid_version", "asteroid_versions.pytorch_version", "asteroid_versions.pytorch_lightning_version"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.asteroid_version", "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.pytorch_version", "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.pytorch_lightning_version"], ["", "", "def", "asteroid_versions", "(", ")", ":", "\n", "    ", "return", "{", "\n", "\"Asteroid\"", ":", "asteroid_version", "(", ")", ",", "\n", "\"PyTorch\"", ":", "pytorch_version", "(", ")", ",", "\n", "\"PyTorch-Lightning\"", ":", "pytorch_lightning_version", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.pytorch_version": [[23, 25], ["None"], "function", ["None"], ["", "def", "pytorch_version", "(", ")", ":", "\n", "    ", "return", "torch", ".", "__version__", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.pytorch_lightning_version": [[27, 29], ["None"], "function", ["None"], ["", "def", "pytorch_lightning_version", "(", ")", ":", "\n", "    ", "return", "pl", ".", "__version__", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.asteroid_version": [[31, 37], ["asteroid_root.joinpath().exists", "asteroid_root.joinpath", "pathlib.Path", "asteroid_versions.get_git_version"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.get_git_version"], ["", "def", "asteroid_version", "(", ")", ":", "\n", "    ", "asteroid_root", "=", "pathlib", ".", "Path", "(", "__file__", ")", ".", "parent", ".", "parent", ".", "parent", "\n", "if", "asteroid_root", ".", "joinpath", "(", "\".git\"", ")", ".", "exists", "(", ")", ":", "\n", "        ", "return", "f\"{asteroid.__version__}, Git checkout {get_git_version(asteroid_root)}\"", "\n", "", "else", ":", "\n", "        ", "return", "asteroid", ".", "__version__", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.get_git_version": [[39, 56], ["subprocess.check_output().strip().decode", "asteroid_versions.get_git_version._git"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.AVSpeechDataset.decode"], ["", "", "def", "get_git_version", "(", "root", ")", ":", "\n", "    ", "def", "_git", "(", "*", "cmd", ")", ":", "\n", "        ", "return", "subprocess", ".", "check_output", "(", "[", "\"git\"", ",", "*", "cmd", "]", ",", "cwd", "=", "root", ")", ".", "strip", "(", ")", ".", "decode", "(", "\"ascii\"", ",", "\"ignore\"", ")", "\n", "\n", "", "try", ":", "\n", "        ", "commit", "=", "_git", "(", "\"rev-parse\"", ",", "\"HEAD\"", ")", "\n", "branch", "=", "_git", "(", "\"rev-parse\"", ",", "\"--symbolic-full-name\"", ",", "\"--abbrev-ref\"", ",", "\"HEAD\"", ")", "\n", "dirty", "=", "_git", "(", "\"status\"", ",", "\"--porcelain\"", ")", "\n", "", "except", "Exception", "as", "err", ":", "\n", "        ", "print", "(", "f\"Failed to get Git checkout info: {err}\"", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "\"\"", "\n", "", "s", "=", "commit", "[", ":", "12", "]", "\n", "if", "branch", ":", "\n", "        ", "s", "+=", "f\" ({branch})\"", "\n", "", "if", "dirty", ":", "\n", "        ", "s", "+=", "f\", dirty tree\"", "\n", "", "return", "s", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_cli.validate_window_length": [[24, 33], ["int", "argparse.ArgumentTypeError", "argparse.ArgumentTypeError"], "function", ["None"], ["def", "validate_window_length", "(", "n", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "n", "=", "int", "(", "n", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "\"Must be integer\"", ")", "\n", "", "if", "n", "<", "10", ":", "\n", "# Note: This doesn't allow for hop < 10.", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "\"Must be given in samples, not seconds\"", ")", "\n", "", "return", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_cli.upload": [[35, 87], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "dict", "os.path.join", "os.path.exists", "asteroid.models.publisher.upload_publishable", "vars", "yaml.safe_load", "yaml.safe_load.items", "os.path.exists", "print", "print", "open", "argparse.ArgumentParser.get_default"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.upload_publishable"], ["", "def", "upload", "(", ")", ":", "\n", "    ", "\"\"\"CLI function to upload pretrained models.\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"publish_dir\"", ",", "type", "=", "str", ",", "help", "=", "\"Path to the publish dir.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--uploader\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"Name of the uploader. Ex: `Manuel Pariente`\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--affiliation\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"Affiliation of the uploader. Ex `INRIA` \"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--git_username\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"Username in GitHub\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--token\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"Access token for Zenodo (or sandbox)\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--force_publish\"", ",", "\n", "default", "=", "False", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to  without asking confirmation\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use_sandbox\"", ",", "default", "=", "False", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to use Zenodo sandbox.\"", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args_as_dict", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load uploader info if present", "\n", "info_file", "=", "os", ".", "path", ".", "join", "(", "asteroid", ".", "project_root", ",", "\"uploader_info.yml\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "info_file", ")", ":", "\n", "        ", "uploader_info", "=", "yaml", ".", "safe_load", "(", "open", "(", "info_file", ",", "\"r\"", ")", ")", "\n", "# Replace fields that where not specified (CLI dominates)", "\n", "for", "k", ",", "v", "in", "uploader_info", ".", "items", "(", ")", ":", "\n", "            ", "if", "args_as_dict", "[", "k", "]", "==", "parser", ".", "get_default", "(", "k", ")", ":", "\n", "                ", "args_as_dict", "[", "k", "]", "=", "v", "\n", "\n", "", "", "", "upload_publishable", "(", "**", "args_as_dict", ")", "\n", "# Suggest creating uploader_infos.yml", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "info_file", ")", ":", "\n", "        ", "example", "=", "\"\"\"\n        ```asteroid/uploader_infos.yml\n        uploader: Manuel Pariente\n        affiliation: Universite Lorraine, CNRS, Inria, LORIA, France\n        git_username: mpariente\n        token: XXX\n        ```\n        \"\"\"", "\n", "print", "(", "\n", "\"You can create a `uploader_infos.yml` file in `Asteroid` root\"", "\n", "f\"to stop passing your name, affiliation etc. to the CLI. \"", "\n", "f\"Here is an example {example}\"", "\n", ")", "\n", "print", "(", "\n", "\"Thanks a lot for sharing your model! Don't forget to create\"", "\n", "\"a model card in the repo! \"", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_cli.infer": [[91, 179], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "asteroid.models.base_models.BaseModel.from_pretrained", "asteroid.dsp.LambdaOverlapAdd.to", "asteroid_cli._process_files_as_list", "asteroid.dsp.LambdaOverlapAdd", "asteroid.separate.separate", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_cli._process_files_as_list", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate"], ["", "", "def", "infer", "(", "argv", "=", "None", ")", ":", "\n", "    ", "\"\"\"CLI function to run pretrained model inference on wav files.\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"url_or_path\"", ",", "type", "=", "str", ",", "help", "=", "\"Path to the pretrained model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--files\"", ",", "\n", "default", "=", "None", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to the wav files to separate. Also supports list of filenames, \"", "\n", "\"directory names and globs.\"", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-f\"", ",", "\n", "\"--force-overwrite\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to overwrite output wav files.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-r\"", ",", "\n", "\"--resample\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to resample wrong sample rate input files.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-w\"", ",", "\n", "\"--ola-window\"", ",", "\n", "type", "=", "validate_window_length", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Overlap-add window to use. If not set (default), overlap-add is not used.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ola-hop\"", ",", "\n", "type", "=", "validate_window_length", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Overlap-add hop length in samples. Defaults to ola-window // 2. Only used if --ola-window is set.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ola-window-type\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"hanning\"", ",", "\n", "help", "=", "\"Type of overlap-add window to use. Only used if --ola-window is set.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ola-no-reorder\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Disable automatic reordering of overlap-add chunk. See asteroid.dsp.LambdaOverlapAdd for details. \"", "\n", "\"Only used if --ola-window is set.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-o\"", ",", "\"--output-dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "help", "=", "\"Output directory to save files.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"-d\"", ",", "\n", "\"--device\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Device to run the model on, eg. 'cuda:0'.\"", "\n", "\"Defaults to 'cuda' if CUDA is available, else 'cpu'.\"", ",", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "argv", ")", "\n", "\n", "if", "args", ".", "device", "is", "None", ":", "\n", "        ", "device", "=", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", "\n", "", "else", ":", "\n", "        ", "device", "=", "args", ".", "device", "\n", "\n", "", "model", "=", "BaseModel", ".", "from_pretrained", "(", "pretrained_model_conf_or_path", "=", "args", ".", "url_or_path", ")", "\n", "if", "args", ".", "ola_window", "is", "not", "None", ":", "\n", "        ", "model", "=", "LambdaOverlapAdd", "(", "\n", "model", ",", "\n", "n_src", "=", "None", ",", "\n", "window_size", "=", "args", ".", "ola_window", ",", "\n", "hop_size", "=", "args", ".", "ola_hop", ",", "\n", "window", "=", "args", ".", "ola_window_type", ",", "\n", "reorder_chunks", "=", "not", "args", ".", "ola_no_reorder", ",", "\n", ")", "\n", "", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "\n", "file_list", "=", "_process_files_as_list", "(", "args", ".", "files", ")", "\n", "for", "f", "in", "file_list", ":", "\n", "        ", "separate", "(", "\n", "model", ",", "\n", "f", ",", "\n", "force_overwrite", "=", "args", ".", "force_overwrite", ",", "\n", "output_dir", "=", "args", ".", "output_dir", ",", "\n", "resample", "=", "args", ".", "resample", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_cli.register_sample_rate": [[182, 198], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "asteroid_cli.register_sample_rate._register_sample_rate"], "function", ["None"], ["", "", "def", "register_sample_rate", "(", ")", ":", "\n", "    ", "\"\"\"CLI to register sample rate to an Asteroid model saved without `sample_rate`,  before 0.4.0.\"\"\"", "\n", "\n", "def", "_register_sample_rate", "(", "filename", ",", "sample_rate", ")", ":", "\n", "        ", "import", "torch", "\n", "\n", "conf", "=", "torch", ".", "load", "(", "filename", ",", "map_location", "=", "\"cpu\"", ")", "\n", "conf", "[", "\"model_args\"", "]", "[", "\"sample_rate\"", "]", "=", "sample_rate", "\n", "torch", ".", "save", "(", "conf", ",", "filename", ")", "\n", "\n", "", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"filename\"", ",", "type", "=", "str", ",", "help", "=", "\"Model file to edit.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"sample_rate\"", ",", "type", "=", "float", ",", "help", "=", "\"Sampling rate to add to the model.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "_register_sample_rate", "(", "filename", "=", "args", ".", "filename", ",", "sample_rate", "=", "args", ".", "sample_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_cli._process_files_as_list": [[200, 216], ["os.path.isfile", "all_files.append", "os.path.isdir", "all_files.extend", "glob.glob", "all_files.extend", "asteroid_cli.glob_dir", "warnings.warn"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_cli.glob_dir"], ["", "def", "_process_files_as_list", "(", "files_str", ":", "List", "[", "str", "]", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "\"\"\"Support filename, folder name, and globs. Returns list of filenames.\"\"\"", "\n", "all_files", "=", "[", "]", "\n", "for", "f", "in", "files_str", ":", "\n", "# Existing file", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "f", ")", ":", "\n", "            ", "all_files", ".", "append", "(", "f", ")", "\n", "# Glob folder and append.", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "f", ")", ":", "\n", "            ", "all_files", ".", "extend", "(", "glob_dir", "(", "f", ")", ")", "\n", "", "else", ":", "\n", "            ", "local_list", "=", "glob", ".", "glob", "(", "f", ")", "\n", "if", "not", "local_list", ":", "\n", "                ", "warnings", ".", "warn", "(", "f\"Could find any file that matched {f}\"", ",", "UserWarning", ")", "\n", "", "all_files", ".", "extend", "(", "local_list", ")", "\n", "", "", "return", "all_files", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_cli.glob_dir": [[218, 225], ["list", "itertools.chain", "glob.glob", "os.path.join"], "function", ["None"], ["", "def", "glob_dir", "(", "d", ")", ":", "\n", "    ", "\"\"\"Return all filenames in directory that match the supported extensions.\"\"\"", "\n", "return", "list", "(", "\n", "itertools", ".", "chain", "(", "\n", "*", "[", "\n", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "d", ",", "\"**/*\"", "+", "ext", ")", ",", "recursive", "=", "True", ")", "\n", "for", "ext", "in", "SUPPORTED_EXTENSIONS", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.conv_tasnet.ConvTasNet.__init__": [[49, 110], ["asteroid_filterbanks.make_enc_dec", "masknn.TDConvNet", "base_models.BaseEncoderMaskerDecoder.__init__", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "n_src", ",", "\n", "out_chan", "=", "None", ",", "\n", "n_blocks", "=", "8", ",", "\n", "n_repeats", "=", "3", ",", "\n", "bn_chan", "=", "128", ",", "\n", "hid_chan", "=", "512", ",", "\n", "skip_chan", "=", "128", ",", "\n", "conv_kernel_size", "=", "3", ",", "\n", "norm_type", "=", "\"gLN\"", ",", "\n", "mask_act", "=", "\"sigmoid\"", ",", "\n", "in_chan", "=", "None", ",", "\n", "causal", "=", "False", ",", "\n", "fb_name", "=", "\"free\"", ",", "\n", "kernel_size", "=", "16", ",", "\n", "n_filters", "=", "512", ",", "\n", "stride", "=", "8", ",", "\n", "encoder_activation", "=", "None", ",", "\n", "sample_rate", "=", "8000", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", ":", "\n", "        ", "encoder", ",", "decoder", "=", "make_enc_dec", "(", "\n", "fb_name", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "n_filters", "=", "n_filters", ",", "\n", "stride", "=", "stride", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", "\n", "n_feats", "=", "encoder", ".", "n_feats_out", "\n", "if", "in_chan", "is", "not", "None", ":", "\n", "            ", "assert", "in_chan", "==", "n_feats", ",", "(", "\n", "\"Number of filterbank output channels\"", "\n", "\" and number of input channels should \"", "\n", "\"be the same. Received \"", "\n", "f\"{n_feats} and {in_chan}\"", "\n", ")", "\n", "", "if", "causal", "and", "norm_type", "not", "in", "[", "\"cgLN\"", ",", "\"cLN\"", "]", ":", "\n", "            ", "norm_type", "=", "\"cLN\"", "\n", "warnings", ".", "warn", "(", "\n", "\"In causal configuration cumulative layer normalization (cgLN)\"", "\n", "\"or channel-wise layer normalization (chanLN)  \"", "\n", "f\"must be used. Changing {norm_type} to cLN\"", "\n", ")", "\n", "# Update in_chan", "\n", "", "masker", "=", "TDConvNet", "(", "\n", "n_feats", ",", "\n", "n_src", ",", "\n", "out_chan", "=", "out_chan", ",", "\n", "n_blocks", "=", "n_blocks", ",", "\n", "n_repeats", "=", "n_repeats", ",", "\n", "bn_chan", "=", "bn_chan", ",", "\n", "hid_chan", "=", "hid_chan", ",", "\n", "skip_chan", "=", "skip_chan", ",", "\n", "conv_kernel_size", "=", "conv_kernel_size", ",", "\n", "norm_type", "=", "norm_type", ",", "\n", "mask_act", "=", "mask_act", ",", "\n", "causal", "=", "causal", ",", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "masker", ",", "decoder", ",", "encoder_activation", "=", "encoder_activation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.conv_tasnet.VADNet.forward_decoder": [[113, 115], ["torch.nn.functional.sigmoid", "conv_tasnet.VADNet.decoder"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.sigmoid"], ["    ", "def", "forward_decoder", "(", "self", ",", "masked_tf_rep", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "return", "torch", ".", "nn", ".", "functional", ".", "sigmoid", "(", "self", ".", "decoder", "(", "masked_tf_rep", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable": [[20, 61], ["isinstance", "os.makedirs", "torch.save", "print", "model_dict.keys", "model_dict.keys", "model_dict.keys", "model_dict.keys", "isinstance", "os.path.exists", "os.path.join", "PLEASE_PUBLISH.format", "os.path.join", "next", "next.replace", "open", "os.path.join"], "function", ["None"], ["def", "save_publishable", "(", "publish_dir", ",", "model_dict", ",", "metrics", "=", "None", ",", "train_conf", "=", "None", ",", "recipe", "=", "None", ")", ":", "\n", "    ", "\"\"\"Save models to prepare for publication / model sharing.\n\n    Args:\n        publish_dir (str): Path to the publishing directory.\n            Usually under exp/exp_name/publish_dir\n        model_dict (dict): dict at least with keys `model_args`,\n            `state_dict`,`dataset` or `licenses`\n        metrics (dict): dict with evaluation metrics.\n        train_conf (dict): Training configuration dict (from conf.yml).\n        recipe (str): Name of the recipe.\n\n    Returns:\n        dict, same as `model_dict` with added fields.\n\n    Raises:\n        AssertionError when either `model_args`, `state_dict`,`dataset` or\n            `licenses` are not present is `model_dict.keys()`\n    \"\"\"", "\n", "assert", "\"model_args\"", "in", "model_dict", ".", "keys", "(", ")", ",", "\"`model_args` not found in model dict.\"", "\n", "assert", "\"state_dict\"", "in", "model_dict", ".", "keys", "(", ")", ",", "\"`state_dict` not found in model dict.\"", "\n", "assert", "\"dataset\"", "in", "model_dict", ".", "keys", "(", ")", ",", "\"`dataset` not found in model dict.\"", "\n", "assert", "\"licenses\"", "in", "model_dict", ".", "keys", "(", ")", ",", "\"`licenses` not found in model dict.\"", "\n", "assert", "isinstance", "(", "metrics", ",", "dict", ")", ",", "\"Cannot upload a model without metrics.\"", "\n", "# Additional infos.", "\n", "if", "recipe", "is", "not", "None", ":", "\n", "        ", "assert", "isinstance", "(", "recipe", ",", "str", ")", ",", "\"`recipe` should be a string.\"", "\n", "recipe_name", "=", "recipe", "\n", "", "else", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "publish_dir", ",", "\"recipe_name.txt\"", ")", ")", ":", "\n", "            ", "recipe_name", "=", "next", "(", "open", "(", "os", ".", "path", ".", "join", "(", "publish_dir", ",", "\"recipe_name.txt\"", ")", ")", ")", "\n", "recipe_name", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", "# remove next line", "\n", "", "else", ":", "\n", "            ", "recipe_name", "=", "\"Unknown\"", "\n", "", "", "model_dict", "[", "\"infos\"", "]", "[", "\"recipe_name\"", "]", "=", "recipe_name", "\n", "model_dict", "[", "\"infos\"", "]", "[", "\"training_config\"", "]", "=", "train_conf", "\n", "model_dict", "[", "\"infos\"", "]", "[", "\"final_metrics\"", "]", "=", "metrics", "\n", "os", ".", "makedirs", "(", "publish_dir", ",", "exist_ok", "=", "True", ")", "\n", "torch", ".", "save", "(", "model_dict", ",", "os", ".", "path", ".", "join", "(", "publish_dir", ",", "\"model.pth\"", ")", ")", "\n", "print", "(", "PLEASE_PUBLISH", ".", "format", "(", "publish_dir", ")", ")", "\n", "return", "model_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.upload_publishable": [[63, 151], ["os.path.join", "os.path.join", "torch.load", "publisher._populate_publishable", "torch.save", "publisher.zenodo_upload", "os.path.join", "zen.get_deposition", "print", "pprint.pprint", "input", "ValueError", "os.getenv", "str", "zen.publish_deposition", "pprint.pprint", "print", "zen.get_deposition.json", "publisher.upload_publishable.get_answer"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher._populate_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.zenodo_upload", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.get_deposition", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.publish_deposition"], ["", "def", "upload_publishable", "(", "\n", "publish_dir", ",", "\n", "uploader", "=", "None", ",", "\n", "affiliation", "=", "None", ",", "\n", "git_username", "=", "None", ",", "\n", "token", "=", "None", ",", "\n", "force_publish", "=", "False", ",", "\n", "use_sandbox", "=", "False", ",", "\n", "unit_test", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Entry point to upload publishable model.\n\n    Args:\n        publish_dir (str): Path to the publishing directory.\n            Usually under exp/exp_name/publish_dir\n        uploader (str): Full name of the uploader (Ex: Manuel Pariente)\n        affiliation (str, optional): Affiliation (no accent).\n        git_username (str, optional): GitHub username.\n        token (str): Access token generated to upload depositions.\n        force_publish (bool): Whether to directly publish without\n            asking confirmation before. Defaults to False.\n        use_sandbox (bool): Whether to use Zenodo's sandbox instead of\n            the official Zenodo.\n        unit_test (bool): If True, we do not ask user input and do not publish.\n\n    \"\"\"", "\n", "\n", "def", "get_answer", "(", ")", ":", "\n", "        ", "out", "=", "input", "(", "\"\\n\\nDo you want to publish it now (irreversible)? y/n\"", "\"(Recommended: n).\\n\"", ")", "\n", "if", "out", "not", "in", "[", "\"y\"", ",", "\"n\"", "]", ":", "\n", "            ", "print", "(", "f\"\\nExpected one of [`y`, `n`], received {out}, please retry.\"", ")", "\n", "return", "get_answer", "(", ")", "\n", "", "return", "out", "\n", "\n", "", "if", "uploader", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Need uploader name\"", ")", "\n", "\n", "# Make publishable model and save it", "\n", "", "model_path", "=", "os", ".", "path", ".", "join", "(", "publish_dir", ",", "\"model.pth\"", ")", "\n", "publish_model_path", "=", "os", ".", "path", ".", "join", "(", "publish_dir", ",", "\"published_model.pth\"", ")", "\n", "model", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "model", "=", "_populate_publishable", "(", "\n", "model", ",", "\n", "uploader", "=", "uploader", ",", "\n", "affiliation", "=", "affiliation", ",", "\n", "git_username", "=", "git_username", ",", "\n", ")", "\n", "torch", ".", "save", "(", "model", ",", "publish_model_path", ")", "\n", "\n", "# Get Zenodo access token", "\n", "if", "token", "is", "None", ":", "\n", "        ", "token", "=", "os", ".", "getenv", "(", "\"ACCESS_TOKEN\"", ")", "\n", "if", "token", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Need an access token to Zenodo to upload the model. Either \"", "\n", "\"set ACCESS_TOKEN environment variable or pass it directly \"", "\n", "\"(`asteroid-upload --token ...`).\"", "\n", "\"If you do not have a access token, first create a Zenodo \"", "\n", "\"account (https://zenodo.org/signup/), create a token \"", "\n", "\"https://zenodo.org/account/settings/applications/tokens/new/\"", "\n", "\"and you are all set to help us! =)\"", "\n", ")", "\n", "\n", "# Do the actual upload", "\n", "", "", "zen", ",", "dep_id", "=", "zenodo_upload", "(", "\n", "model", ",", "token", ",", "model_path", "=", "publish_model_path", ",", "use_sandbox", "=", "use_sandbox", "\n", ")", "\n", "address", "=", "os", ".", "path", ".", "join", "(", "zen", ".", "zenodo_address", ",", "\"deposit\"", ",", "str", "(", "dep_id", ")", ")", "\n", "if", "force_publish", ":", "\n", "        ", "r_publish", "=", "zen", ".", "publish_deposition", "(", "dep_id", ")", "\n", "pprint", "(", "r_publish", ".", "json", "(", ")", ")", "\n", "print", "(", "\"You can also visit it at {}\"", ".", "format", "(", "address", ")", ")", "\n", "return", "r_publish", "\n", "# Give choice", "\n", "", "current", "=", "zen", ".", "get_deposition", "(", "dep_id", ")", "\n", "print", "(", "f\"\\n\\n This is the current state of the deposition \"", "f\"(see here {address}): \"", ")", "\n", "pprint", "(", "current", ".", "json", "(", ")", ")", "\n", "# Patch to run unit test", "\n", "if", "unit_test", ":", "\n", "        ", "return", "zen", ",", "current", "\n", "", "else", ":", "\n", "        ", "inp", "=", "get_answer", "(", ")", "\n", "# Get user input", "\n", "", "if", "inp", "==", "\"y\"", ":", "\n", "        ", "_", "=", "zen", ".", "publish_deposition", "(", "dep_id", ")", "\n", "print", "(", "\"Visit it at {}\"", ".", "format", "(", "address", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "f\"Did not finalize the upload, please visit {address} to finalize \"", "f\"it.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher._populate_publishable": [[153, 184], ["publisher.make_license_notice", "publisher.get_username", "model[].replace"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.make_license_notice", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.get_username"], ["", "", "def", "_populate_publishable", "(", "model", ",", "uploader", "=", "None", ",", "affiliation", "=", "None", ",", "git_username", "=", "None", ")", ":", "\n", "    ", "\"\"\"Populate infos in publishable model.\n\n    Args:\n        model (dict): Model to publish, with `infos` key, at least.\n        uploader (str): Full name of the uploader (Ex: Manuel Pariente)\n        affiliation (str, optional): Affiliation (no accent).\n        git_username (str, optional): GitHub username.\n\n    Returns:\n        dict (model), same as input `model`\n\n    .. note:: If a `git_username` is not specified, we look for it somehow, or take\n        the laptop username.\n    \"\"\"", "\n", "# Get username somehow", "\n", "if", "git_username", "is", "None", ":", "\n", "        ", "git_username", "=", "get_username", "(", ")", "\n", "\n", "# Example: mpariente/ConvTasNet_WHAM_sepclean", "\n", "", "model_name", "=", "\"_\"", ".", "join", "(", "[", "model", "[", "\"model_name\"", "]", ",", "model", "[", "\"dataset\"", "]", ",", "model", "[", "\"task\"", "]", ".", "replace", "(", "\"_\"", ",", "\"\"", ")", "]", ")", "\n", "upload_name", "=", "git_username", "+", "\"/\"", "+", "model_name", "\n", "# Write License Notice", "\n", "license_note", "=", "make_license_notice", "(", "model_name", ",", "model", "[", "\"licenses\"", "]", ",", "uploader", "=", "uploader", ")", "\n", "# Add infos", "\n", "model", "[", "\"infos\"", "]", "[", "\"uploader\"", "]", "=", "uploader", "\n", "model", "[", "\"infos\"", "]", "[", "\"git_username\"", "]", "=", "git_username", "\n", "model", "[", "\"infos\"", "]", "[", "\"affiliation\"", "]", "=", "affiliation", "if", "affiliation", "else", "\"Unknown\"", "\n", "model", "[", "\"infos\"", "]", "[", "\"upload_name\"", "]", "=", "upload_name", "\n", "model", "[", "\"infos\"", "]", "[", "\"license_note\"", "]", "=", "license_note", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.get_username": [[186, 195], ["subprocess.check_output", "getpass.getuser.decode", "getpass.getuser"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.AVSpeechDataset.decode"], ["", "def", "get_username", "(", ")", ":", "\n", "    ", "\"\"\"Get git of FS username for upload.\"\"\"", "\n", "username", "=", "subprocess", ".", "check_output", "(", "[", "\"git\"", ",", "\"config\"", ",", "\"user.name\"", "]", ")", "\n", "username", "=", "username", ".", "decode", "(", "\"utf-8\"", ")", "[", ":", "-", "1", "]", "\n", "if", "not", "username", ":", "# Empty string", "\n", "        ", "import", "getpass", "\n", "\n", "username", "=", "getpass", ".", "getuser", "(", ")", "\n", "", "return", "username", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.make_license_notice": [[197, 226], ["HREF.format", "ValueError", "HREF.format", "HREF.format", "HREF.format"], "function", ["None"], ["", "def", "make_license_notice", "(", "model_name", ",", "licenses", ",", "uploader", "=", "None", ")", ":", "\n", "    ", "\"\"\"Make license notice based on license dicts.\n\n    Args:\n        model_name (str): Name of the model.\n        licenses (List[dict]): List of dict with\n            keys (`title`, `title_link`, `author`, `author_link`,\n                  `licence`, `licence_link`).\n        uploader (str): Name of the uploader such as \"Manuel Pariente\".\n\n    Returns:\n        str, the license note describing the model, it's attribution,\n            the original licenses, what we license it under and the licensor.\n    \"\"\"", "\n", "if", "uploader", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Cannot share model without uploader.\"", ")", "\n", "", "note", "=", "'This work \"{}\" is a derivative '", ".", "format", "(", "model_name", ")", "\n", "for", "l_dict", "in", "licenses", ":", "\n", "# Clickable links in HTML.", "\n", "        ", "title", "=", "HREF", ".", "format", "(", "l_dict", "[", "\"title_link\"", "]", ",", "l_dict", "[", "\"title\"", "]", ")", "\n", "author", "=", "HREF", ".", "format", "(", "l_dict", "[", "\"author_link\"", "]", ",", "l_dict", "[", "\"author\"", "]", ")", "\n", "license_h", "=", "HREF", ".", "format", "(", "l_dict", "[", "\"license_link\"", "]", ",", "l_dict", "[", "\"license\"", "]", ")", "\n", "comm", "=", "\" (Research only)\"", "if", "l_dict", "[", "\"non_commercial\"", "]", "else", "\"\"", "\n", "note", "+=", "f\"of {title} by {author}, used under {license_h}{comm}\"", "\n", "note", "+=", "\"; \"", "\n", "", "note", "=", "note", "[", ":", "-", "2", "]", "+", "\". \"", "# Remove the last ;", "\n", "cc_sa", "=", "HREF", ".", "format", "(", "CC_SA_LINK", ",", "CC_SA", ")", "\n", "note", "+=", "f'\"{model_name}\" is licensed under {cc_sa} by {uploader}.'", "\n", "return", "note", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.zenodo_upload": [[228, 264], ["Zenodo", "publisher.make_metadata_from_model", "Zenodo.create_new_deposition", "Zenodo.upload_new_file_to_deposition", "torch.save", "print", "RuntimeError", "zen.create_new_deposition.json", "os.remove", "zen.create_new_deposition.json"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.make_metadata_from_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.create_new_deposition", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.upload_new_file_to_deposition"], ["", "def", "zenodo_upload", "(", "model", ",", "token", ",", "model_path", "=", "None", ",", "use_sandbox", "=", "False", ")", ":", "\n", "    ", "\"\"\"Create deposit and upload metadata + model\n\n    Args:\n        model (dict):\n        token (str): Access token.\n        model_path (str): Saved model path.\n        use_sandbox (bool): Whether to use Zenodo's sandbox instead of\n            the official Zenodo.\n\n    Returns:\n        Zenodo (Zenodo instance with access token)\n        int (deposit ID)\n\n    .. note::If `model_path` is not specified, save the model in tmp.pth and\n        remove it after upload.\n    \"\"\"", "\n", "model_path_was_none", "=", "False", "\n", "if", "model_path", "is", "None", ":", "\n", "        ", "model_path_was_none", "=", "True", "\n", "model_path", "=", "\"tmp.pth\"", "\n", "torch", ".", "save", "(", "model", ",", "model_path", ")", "\n", "\n", "", "from", ".", "zenodo", "import", "Zenodo", "\n", "\n", "zen", "=", "Zenodo", "(", "token", ",", "use_sandbox", "=", "use_sandbox", ")", "\n", "metadata", "=", "make_metadata_from_model", "(", "model", ")", "\n", "r", "=", "zen", ".", "create_new_deposition", "(", "metadata", "=", "metadata", ")", "\n", "if", "r", ".", "status_code", "!=", "200", ":", "\n", "        ", "print", "(", "r", ".", "json", "(", ")", ")", "\n", "raise", "RuntimeError", "(", "\"Could not create the deposition, check the \"", "\"provided token.\"", ")", "\n", "", "dep_id", "=", "r", ".", "json", "(", ")", "[", "\"id\"", "]", "\n", "_", "=", "zen", ".", "upload_new_file_to_deposition", "(", "dep_id", ",", "model_path", ",", "name", "=", "\"model.pth\"", ")", "\n", "if", "model_path_was_none", ":", "\n", "        ", "os", ".", "remove", "(", "model_path", ")", "\n", "", "return", "zen", ",", "dep_id", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.make_metadata_from_model": [[266, 326], ["tmp.format", "tmp.format", "publisher.two_level_dict_html", "publisher.display_one_level_dict", "publisher.display_one_level_dict", "infos[].items", "k.lower"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.two_level_dict_html", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.display_one_level_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.display_one_level_dict"], ["", "def", "make_metadata_from_model", "(", "model", ")", ":", "\n", "    ", "\"\"\"Create Zenodo deposit metadata for a given publishable model.\n\n    Args:\n        model (dict): Dictionary with all infos needed to publish.\n            More info to come.\n\n    Returns:\n        dict, the metadata to create the Zenodo deposit with.\n\n    .. note:: We remove the PESQ from the final results as a license is needed to\n        use it.\n    \"\"\"", "\n", "infos", "=", "model", "[", "\"infos\"", "]", "\n", "# Description section", "\n", "description", "=", "\"<p><strong>Description: </strong></p>\"", "\n", "tmp", "=", "\"This model was trained by {} using the {} recipe in {}. \"", "\n", "description", "+=", "tmp", ".", "format", "(", "infos", "[", "\"uploader\"", "]", ",", "infos", "[", "\"recipe_name\"", "]", ",", "ASTEROID_REF", ")", "\n", "tmp", "=", "\"</a>It was trained on the <code>{}</code> task of the {} dataset.</p>\"", "\n", "description", "+=", "tmp", ".", "format", "(", "model", "[", "\"task\"", "]", ",", "model", "[", "\"dataset\"", "]", ")", "\n", "\n", "# Training config section", "\n", "description", "+=", "\"<p>&nbsp;</p>\"", "\n", "description", "+=", "\"<p><strong>Training config:</strong></p>\"", "\n", "description", "+=", "two_level_dict_html", "(", "infos", "[", "\"training_config\"", "]", ")", "\n", "\n", "# Results section", "\n", "description", "+=", "\"<p>&nbsp;</p>\"", "\n", "description", "+=", "\"<p><strong>Results:</strong></p>\"", "\n", "display_result", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "infos", "[", "\"final_metrics\"", "]", ".", "items", "(", ")", "if", "\"pesq\"", "not", "in", "k", ".", "lower", "(", ")", "}", "\n", "description", "+=", "display_one_level_dict", "(", "display_result", ")", "\n", "\n", "# Software section", "\n", "description", "+=", "\"<p>&nbsp;</p>\"", "\n", "description", "+=", "\"<p><strong>Versions:</strong></p>\"", "\n", "description", "+=", "display_one_level_dict", "(", "infos", "[", "\"software_versions\"", "]", ")", "\n", "\n", "# License section", "\n", "description", "+=", "\"<p>&nbsp;</p>\"", "\n", "description", "+=", "\"<p><strong>License notice:</strong></p>\"", "\n", "description", "+=", "infos", "[", "\"license_note\"", "]", "\n", "\n", "# Putting it together.", "\n", "metadata", "=", "{", "\n", "\"title\"", ":", "infos", "[", "\"upload_name\"", "]", ",", "\n", "\"upload_type\"", ":", "\"software\"", ",", "\n", "\"description\"", ":", "description", ",", "\n", "\"creators\"", ":", "[", "{", "\"name\"", ":", "infos", "[", "\"uploader\"", "]", ",", "\"affiliation\"", ":", "infos", "[", "\"affiliation\"", "]", "}", "]", ",", "\n", "\"communities\"", ":", "[", "{", "\"identifier\"", ":", "\"zenodo\"", "}", ",", "{", "\"identifier\"", ":", "\"asteroid-models\"", "}", "]", ",", "\n", "\"keywords\"", ":", "[", "\n", "\"Asteroid\"", ",", "\n", "\"audio source separation\"", ",", "\n", "model", "[", "\"dataset\"", "]", ",", "\n", "model", "[", "\"task\"", "]", ",", "\n", "model", "[", "\"model_name\"", "]", ",", "\n", "\"pretrained model\"", ",", "\n", "]", ",", "\n", "\"license\"", ":", "\"CC-BY-SA-3.0\"", ",", "\n", "}", "\n", "return", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.two_level_dict_html": [[328, 348], ["dic.keys", "dic[].keys", "str"], "function", ["None"], ["", "def", "two_level_dict_html", "(", "dic", ")", ":", "\n", "    ", "\"\"\"Two-level dict to HTML.\n\n    Args:\n        dic (dict): two-level dict\n\n    Returns:\n        str for HTML-encoded two level dic\n    \"\"\"", "\n", "html", "=", "\"<ul>\"", "\n", "for", "k", "in", "dic", ".", "keys", "(", ")", ":", "\n", "# Open field", "\n", "        ", "html", "+=", "f\"<li>{k}: <ul>\"", "\n", "for", "k2", "in", "dic", "[", "k", "]", ".", "keys", "(", ")", ":", "\n", "            ", "val", "=", "str", "(", "dic", "[", "k", "]", "[", "k2", "]", ")", "\n", "html", "+=", "f\"<li>{k2}: {val}</li>\"", "\n", "# Close field", "\n", "", "html", "+=", "\"</il></ul>\"", "\n", "", "html", "+=", "\"</ul>\"", "\n", "return", "html", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.display_one_level_dict": [[350, 366], ["dic.keys", "str"], "function", ["None"], ["", "def", "display_one_level_dict", "(", "dic", ")", ":", "\n", "    ", "\"\"\"Single level dict to HTML\n\n    Args:\n        dic (dict):\n\n    Returns:\n        str for HTML-encoded single level dic\n    \"\"\"", "\n", "html", "=", "\"<ul>\"", "\n", "for", "k", "in", "dic", ".", "keys", "(", ")", ":", "\n", "# Open field", "\n", "        ", "val", "=", "str", "(", "dic", "[", "k", "]", ")", "\n", "html", "+=", "f\"<li>{k}: {val} </li>\"", "\n", "", "html", "+=", "\"</ul>\"", "\n", "return", "html", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.fasnet.FasNetTAC.__init__": [[46, 125], ["base_models.BaseModel.__init__", "int", "int", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "int", "masknn.norms.get", "torch.nn.ModuleList", "torch.nn.ModuleList", "fasnet.FasNetTAC.DPRNN_TAC.append", "torch.nn.PReLU", "torch.nn.PReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.ModuleList.append", "masknn.recurrent.DPRNNBlock", "masknn.tac.TAC"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "__init__", "(", "\n", "self", ",", "\n", "n_src", ",", "\n", "enc_dim", "=", "64", ",", "\n", "feature_dim", "=", "64", ",", "\n", "hidden_dim", "=", "128", ",", "\n", "n_layers", "=", "4", ",", "\n", "window_ms", "=", "4", ",", "\n", "stride", "=", "None", ",", "\n", "context_ms", "=", "16", ",", "\n", "sample_rate", "=", "16000", ",", "\n", "tac_hidden_dim", "=", "384", ",", "\n", "norm_type", "=", "\"gLN\"", ",", "\n", "chunk_size", "=", "50", ",", "\n", "hop_size", "=", "25", ",", "\n", "bidirectional", "=", "True", ",", "\n", "rnn_type", "=", "\"LSTM\"", ",", "\n", "dropout", "=", "0.0", ",", "\n", "use_tac", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "sample_rate", "=", "sample_rate", ",", "in_channels", "=", "None", ")", "\n", "\n", "self", ".", "enc_dim", "=", "enc_dim", "\n", "self", ".", "feature_dim", "=", "feature_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "n_src", "=", "n_src", "\n", "assert", "window_ms", "%", "2", "==", "0", ",", "\"Window length should be even\"", "\n", "# Parameters", "\n", "self", ".", "window_ms", "=", "window_ms", "\n", "self", ".", "context_ms", "=", "context_ms", "\n", "self", ".", "window", "=", "int", "(", "self", ".", "sample_rate", "*", "window_ms", "/", "1000", ")", "\n", "self", ".", "context", "=", "int", "(", "self", ".", "sample_rate", "*", "context_ms", "/", "1000", ")", "\n", "if", "not", "stride", ":", "\n", "            ", "self", ".", "stride", "=", "self", ".", "window", "//", "2", "\n", "", "else", ":", "\n", "            ", "self", ".", "stride", "=", "int", "(", "self", ".", "sample_rate", "*", "stride", "/", "1000", ")", "\n", "", "self", ".", "filter_dim", "=", "self", ".", "context", "*", "2", "+", "1", "\n", "self", ".", "output_dim", "=", "self", ".", "context", "*", "2", "+", "1", "\n", "self", ".", "tac_hidden_dim", "=", "tac_hidden_dim", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "self", ".", "chunk_size", "=", "chunk_size", "\n", "self", ".", "hop_size", "=", "hop_size", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "use_tac", "=", "use_tac", "\n", "\n", "# waveform encoder", "\n", "self", ".", "encoder", "=", "nn", ".", "Conv1d", "(", "1", ",", "self", ".", "enc_dim", ",", "self", ".", "context", "*", "2", "+", "self", ".", "window", ",", "bias", "=", "False", ")", "\n", "self", ".", "enc_LN", "=", "norms", ".", "get", "(", "norm_type", ")", "(", "self", ".", "enc_dim", ")", "\n", "\n", "# DPRNN here + TAC at each layer", "\n", "self", ".", "bottleneck", "=", "nn", ".", "Conv1d", "(", "self", ".", "filter_dim", "+", "self", ".", "enc_dim", ",", "self", ".", "feature_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "DPRNN_TAC", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "tmp", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "DPRNNBlock", "(", "\n", "self", ".", "feature_dim", ",", "\n", "self", ".", "hidden_dim", ",", "\n", "norm_type", ",", "\n", "bidirectional", ",", "\n", "rnn_type", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "]", "\n", ")", "\n", "if", "self", ".", "use_tac", ":", "\n", "                ", "tmp", ".", "append", "(", "TAC", "(", "self", ".", "feature_dim", ",", "tac_hidden_dim", ",", "norm_type", "=", "norm_type", ")", ")", "\n", "", "self", ".", "DPRNN_TAC", ".", "append", "(", "tmp", ")", "\n", "\n", "# DPRNN output layers", "\n", "", "self", ".", "conv_2D", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "PReLU", "(", ")", ",", "nn", ".", "Conv2d", "(", "self", ".", "feature_dim", ",", "self", ".", "n_src", "*", "self", ".", "feature_dim", ",", "1", ")", "\n", ")", "\n", "self", ".", "tanh", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv1d", "(", "self", ".", "feature_dim", ",", "self", ".", "output_dim", ",", "1", ")", ",", "nn", ".", "Tanh", "(", ")", ")", "\n", "self", ".", "gate", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv1d", "(", "self", ".", "feature_dim", ",", "self", ".", "output_dim", ",", "1", ")", ",", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.fasnet.FasNetTAC.windowing_with_context": [[126, 141], ["torch.unfold", "torch.unfold", "unfolded.reshape.reshape.size", "unfolded.reshape.reshape.reshape", "x.unsqueeze", "unfolded[].transpose", "unfolded.reshape.reshape.transpose"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.unfold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.unfold"], ["", "@", "staticmethod", "\n", "def", "windowing_with_context", "(", "x", ",", "window", ",", "context", ")", ":", "\n", "        ", "batch_size", ",", "nmic", ",", "nsample", "=", "x", ".", "shape", "\n", "unfolded", "=", "F", ".", "unfold", "(", "\n", "x", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "kernel_size", "=", "(", "window", "+", "2", "*", "context", ",", "1", ")", ",", "\n", "padding", "=", "(", "context", "+", "window", ",", "0", ")", ",", "\n", "stride", "=", "(", "window", "//", "2", ",", "1", ")", ",", "\n", ")", "\n", "\n", "n_chunks", "=", "unfolded", ".", "size", "(", "-", "1", ")", "\n", "unfolded", "=", "unfolded", ".", "reshape", "(", "batch_size", ",", "nmic", ",", "window", "+", "2", "*", "context", ",", "n_chunks", ")", "\n", "return", "(", "\n", "unfolded", "[", ":", ",", ":", ",", "context", ":", "context", "+", "window", "]", ".", "transpose", "(", "2", ",", "-", "1", ")", ",", "\n", "unfolded", ".", "transpose", "(", "2", ",", "-", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.fasnet.FasNetTAC.forward": [[143, 265], ["x.size", "fasnet.FasNetTAC.windowing_with_context", "all_mic_context.unsqueeze().repeat.unsqueeze().repeat.size", "fasnet.FasNetTAC.encoder().reshape().transpose().contiguous", "fasnet.FasNetTAC.enc_LN().reshape", "all_seg[].reshape().unsqueeze", "all_mic_context.unsqueeze().repeat.unsqueeze().repeat.transpose().reshape", "dsp.spatial.xcorr", "all_cos_sim.reshape().permute().contiguous.reshape().permute().contiguous.reshape().permute().contiguous", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fasnet.FasNetTAC.bottleneck", "torch.unfold", "torch.unfold", "tac().reshape.size", "tac().reshape.reshape", "range", "fasnet.FasNetTAC.conv_2D().reshape", "torch.fold", "torch.fold", "folded.view.view.view", "all_mic_context.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "torch.conv1d", "torch.conv1d", "torch.fold.view", "torch.fold", "torch.fold", "torch.fold.reshape", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "fasnet.FasNetTAC.reshape", "fasnet.FasNetTAC.unsqueeze", "dprnn", "folded.view.view.squeeze", "fasnet.FasNetTAC.tanh", "fasnet.FasNetTAC.gate", "all_mic_context.unsqueeze().repeat.unsqueeze().repeat.view", "folded.view.view.transpose().contiguous().view", "torch.fold.reshape().transpose", "torch.LongTensor.max", "torch.LongTensor.max", "torch.cat.mean", "torch.cat.mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "fasnet.FasNetTAC.encoder().reshape().transpose", "fasnet.FasNetTAC.enc_LN", "all_seg[].reshape", "all_mic_context.unsqueeze().repeat.unsqueeze().repeat.transpose", "all_cos_sim.reshape().permute().contiguous.reshape().permute().contiguous.reshape().permute", "tac().reshape.size", "tac().reshape.reshape", "tac().reshape", "fasnet.FasNetTAC.conv_2D", "all_mic_context.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "bf_signal[].mean().unsqueeze", "folded.view.view.transpose().contiguous", "torch.fold.reshape", "range", "fasnet.FasNetTAC.encoder().reshape", "all_cos_sim.reshape().permute().contiguous.reshape().permute().contiguous.reshape", "tac", "bf_signal[].mean", "folded.view.view.transpose", "fasnet.FasNetTAC.encoder", "all_mic_context.unsqueeze().repeat.unsqueeze().repeat.reshape"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.fasnet.FasNetTAC.windowing_with_context", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.spatial.xcorr", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.unfold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.unfold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.fold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.fold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.fold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.fold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.tanh"], ["", "def", "forward", "(", "self", ",", "x", ",", "valid_mics", "=", "None", ")", ":", "\n", "        ", "r\"\"\"\n        Args:\n            x: (:class:`torch.Tensor`): multi-channel input signal. Shape: :math:`(batch, mic\\_channels, samples)`.\n            valid_mics: (:class:`torch.LongTensor`): tensor containing effective number of microphones on each batch.\n                Batches can be composed of examples coming from arrays with a different\n                number of microphones and thus the ``mic_channels`` dimension is padded.\n                E.g. torch.tensor([4, 3]) means first example has 4 channels and the second 3.\n                Shape: :math`(batch)`.\n\n        Returns:\n            bf_signal (:class:`torch.Tensor`): beamformed signal with shape :math:`(batch, n\\_src, samples)`.\n        \"\"\"", "\n", "if", "valid_mics", "is", "None", ":", "\n", "            ", "valid_mics", "=", "torch", ".", "LongTensor", "(", "[", "x", ".", "shape", "[", "1", "]", "]", "*", "x", ".", "shape", "[", "0", "]", ")", "\n", "", "n_samples", "=", "x", ".", "size", "(", "-", "1", ")", "# Original number of samples of multichannel audio", "\n", "all_seg", ",", "all_mic_context", "=", "self", ".", "windowing_with_context", "(", "x", ",", "self", ".", "window", ",", "self", ".", "context", ")", "\n", "batch_size", ",", "n_mics", ",", "seq_length", ",", "feats", "=", "all_mic_context", ".", "size", "(", ")", "\n", "# All_seg contains only the central window, all_mic_context contains also the right and left context", "\n", "\n", "# Encoder applies a filter on each all_mic_context feats", "\n", "enc_output", "=", "(", "\n", "self", ".", "encoder", "(", "all_mic_context", ".", "reshape", "(", "batch_size", "*", "n_mics", "*", "seq_length", ",", "1", ",", "feats", ")", ")", "\n", ".", "reshape", "(", "batch_size", "*", "n_mics", ",", "seq_length", ",", "self", ".", "enc_dim", ")", "\n", ".", "transpose", "(", "1", ",", "2", ")", "\n", ".", "contiguous", "(", ")", "\n", ")", "# B*n_mics, seq_len, enc_dim", "\n", "enc_output", "=", "self", ".", "enc_LN", "(", "enc_output", ")", ".", "reshape", "(", "\n", "batch_size", ",", "n_mics", ",", "self", ".", "enc_dim", ",", "seq_length", "\n", ")", "# apply norm", "\n", "\n", "# For each context window cosine similarity is computed. The first channel is chosen as a reference", "\n", "ref_seg", "=", "all_seg", "[", ":", ",", "0", "]", ".", "reshape", "(", "batch_size", "*", "seq_length", ",", "self", ".", "window", ")", ".", "unsqueeze", "(", "1", ")", "\n", "all_context", "=", "all_mic_context", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "\n", "batch_size", "*", "seq_length", ",", "n_mics", ",", "self", ".", "context", "*", "2", "+", "self", ".", "window", "\n", ")", "\n", "\n", "all_cos_sim", "=", "xcorr", "(", "all_context", ",", "ref_seg", ")", "\n", "all_cos_sim", "=", "(", "\n", "all_cos_sim", ".", "reshape", "(", "batch_size", ",", "seq_length", ",", "n_mics", ",", "self", ".", "context", "*", "2", "+", "1", ")", "\n", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", ".", "contiguous", "(", ")", "\n", ")", "\n", "# B, nmic, 2*context + 1, seq_len", "\n", "\n", "# Encoder features and cosine similarity features are concatenated", "\n", "input_feature", "=", "torch", ".", "cat", "(", "[", "enc_output", ",", "all_cos_sim", "]", ",", "2", ")", "\n", "# Apply bottleneck to reduce parameters and feed to DPRNN", "\n", "input_feature", "=", "self", ".", "bottleneck", "(", "input_feature", ".", "reshape", "(", "batch_size", "*", "n_mics", ",", "-", "1", ",", "seq_length", ")", ")", "\n", "# We unfold the features for dual path processing", "\n", "unfolded", "=", "F", ".", "unfold", "(", "\n", "input_feature", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "kernel_size", "=", "(", "self", ".", "chunk_size", ",", "1", ")", ",", "\n", "padding", "=", "(", "self", ".", "chunk_size", ",", "0", ")", ",", "\n", "stride", "=", "(", "self", ".", "hop_size", ",", "1", ")", ",", "\n", ")", "\n", "n_chunks", "=", "unfolded", ".", "size", "(", "-", "1", ")", "\n", "unfolded", "=", "unfolded", ".", "reshape", "(", "\n", "batch_size", "*", "n_mics", ",", "self", ".", "feature_dim", ",", "self", ".", "chunk_size", ",", "n_chunks", "\n", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "# At each layer we apply DPRNN to process each mic independently and then TAC for inter-mic processing.", "\n", "            ", "dprnn", "=", "self", ".", "DPRNN_TAC", "[", "i", "]", "[", "0", "]", "\n", "unfolded", "=", "dprnn", "(", "unfolded", ")", "\n", "if", "self", ".", "use_tac", ":", "\n", "                ", "b", ",", "ch", ",", "chunk_size", ",", "n_chunks", "=", "unfolded", ".", "size", "(", ")", "\n", "tac", "=", "self", ".", "DPRNN_TAC", "[", "i", "]", "[", "1", "]", "\n", "unfolded", "=", "unfolded", ".", "reshape", "(", "-", "1", ",", "n_mics", ",", "ch", ",", "chunk_size", ",", "n_chunks", ")", "\n", "unfolded", "=", "tac", "(", "unfolded", ",", "valid_mics", ")", ".", "reshape", "(", "\n", "batch_size", "*", "n_mics", ",", "self", ".", "feature_dim", ",", "self", ".", "chunk_size", ",", "n_chunks", "\n", ")", "\n", "# Output, 2D conv to get different feats for each source", "\n", "", "", "unfolded", "=", "self", ".", "conv_2D", "(", "unfolded", ")", ".", "reshape", "(", "\n", "batch_size", "*", "n_mics", "*", "self", ".", "n_src", ",", "self", ".", "feature_dim", "*", "self", ".", "chunk_size", ",", "n_chunks", "\n", ")", "\n", "# Dual path processing is done we fold back", "\n", "folded", "=", "F", ".", "fold", "(", "\n", "unfolded", ",", "\n", "(", "seq_length", ",", "1", ")", ",", "\n", "kernel_size", "=", "(", "self", ".", "chunk_size", ",", "1", ")", ",", "\n", "padding", "=", "(", "self", ".", "chunk_size", ",", "0", ")", ",", "\n", "stride", "=", "(", "self", ".", "hop_size", ",", "1", ")", ",", "\n", ")", "\n", "# Dividing to assure perfect reconstruction", "\n", "folded", "=", "folded", ".", "squeeze", "(", "-", "1", ")", "/", "(", "self", ".", "chunk_size", "/", "self", ".", "hop_size", ")", "\n", "# apply gating to output and scaling to -1 and 1", "\n", "folded", "=", "self", ".", "tanh", "(", "folded", ")", "*", "self", ".", "gate", "(", "folded", ")", "\n", "folded", "=", "folded", ".", "view", "(", "batch_size", ",", "n_mics", ",", "self", ".", "n_src", ",", "-", "1", ",", "seq_length", ")", "\n", "\n", "# Beamforming", "\n", "# Convolving with all mic context --> Filter and Sum", "\n", "all_mic_context", "=", "all_mic_context", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_src", ",", "1", ",", "1", ")", "\n", "all_bf_output", "=", "F", ".", "conv1d", "(", "\n", "all_mic_context", ".", "view", "(", "1", ",", "-", "1", ",", "self", ".", "context", "*", "2", "+", "self", ".", "window", ")", ",", "\n", "folded", ".", "transpose", "(", "3", ",", "-", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "filter_dim", ")", ",", "\n", "groups", "=", "batch_size", "*", "n_mics", "*", "self", ".", "n_src", "*", "seq_length", ",", "\n", ")", "\n", "all_bf_output", "=", "all_bf_output", ".", "view", "(", "batch_size", ",", "n_mics", ",", "self", ".", "n_src", ",", "seq_length", ",", "self", ".", "window", ")", "\n", "\n", "# Fold back to obtain signal", "\n", "all_bf_output", "=", "F", ".", "fold", "(", "\n", "all_bf_output", ".", "reshape", "(", "\n", "batch_size", "*", "n_mics", "*", "self", ".", "n_src", ",", "seq_length", ",", "self", ".", "window", "\n", ")", ".", "transpose", "(", "1", ",", "-", "1", ")", ",", "\n", "(", "n_samples", ",", "1", ")", ",", "\n", "kernel_size", "=", "(", "self", ".", "window", ",", "1", ")", ",", "\n", "padding", "=", "(", "self", ".", "window", ",", "0", ")", ",", "\n", "stride", "=", "(", "self", ".", "window", "//", "2", ",", "1", ")", ",", "\n", ")", "\n", "bf_signal", "=", "all_bf_output", ".", "reshape", "(", "batch_size", ",", "n_mics", ",", "self", ".", "n_src", ",", "n_samples", ")", "\n", "\n", "# We sum over mics after filtering (filters will realign the signals --> delay and sum)", "\n", "if", "valid_mics", ".", "max", "(", ")", "==", "0", ":", "\n", "            ", "bf_signal", "=", "bf_signal", ".", "mean", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "bf_signal", "=", "[", "\n", "bf_signal", "[", "b", ",", ":", "valid_mics", "[", "b", "]", "]", ".", "mean", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "for", "b", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "bf_signal", "=", "torch", ".", "cat", "(", "bf_signal", ",", "0", ")", "\n", "\n", "", "return", "bf_signal", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.fasnet.FasNetTAC.get_model_args": [[266, 287], ["None"], "methods", ["None"], ["", "def", "get_model_args", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "\"n_src\"", ":", "self", ".", "n_src", ",", "\n", "\"enc_dim\"", ":", "self", ".", "enc_dim", ",", "\n", "\"feature_dim\"", ":", "self", ".", "feature_dim", ",", "\n", "\"hidden_dim\"", ":", "self", ".", "hidden_dim", ",", "\n", "\"n_layers\"", ":", "self", ".", "n_layers", ",", "\n", "\"window_ms\"", ":", "self", ".", "window_ms", ",", "\n", "\"stride\"", ":", "self", ".", "stride", ",", "\n", "\"context_ms\"", ":", "self", ".", "context_ms", ",", "\n", "\"sample_rate\"", ":", "self", ".", "sample_rate", ",", "\n", "\"tac_hidden_dim\"", ":", "self", ".", "tac_hidden_dim", ",", "\n", "\"norm_type\"", ":", "self", ".", "norm_type", ",", "\n", "\"chunk_size\"", ":", "self", ".", "chunk_size", ",", "\n", "\"hop_size\"", ":", "self", ".", "hop_size", ",", "\n", "\"bidirectional\"", ":", "self", ".", "bidirectional", ",", "\n", "\"rnn_type\"", ":", "self", ".", "rnn_type", ",", "\n", "\"dropout\"", ":", "self", ".", "dropout", ",", "\n", "\"use_tac\"", ":", "self", ".", "use_tac", ",", "\n", "}", "\n", "return", "config", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.__init__": [[40, 44], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "sample_rate", ":", "float", ",", "in_channels", ":", "Optional", "[", "int", "]", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "__sample_rate", "=", "sample_rate", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.forward": [[45, 47], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.sample_rate": [[53, 61], ["warnings.warn"], "methods", ["None"], ["", "@", "sample_rate", ".", "setter", "\n", "def", "sample_rate", "(", "self", ",", "new_sample_rate", ":", "float", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"Other sub-components of the model might have a `sample_rate` \"", "\n", "\"attribute, be sure to modify them for consistency.\"", ",", "\n", "UserWarning", ",", "\n", ")", "\n", "self", ".", "__sample_rate", "=", "new_sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.separate": [[62, 65], ["separate.separate"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate"], ["", "def", "separate", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Convenience for :func:`~asteroid.separate.separate`.\"\"\"", "\n", "return", "separate", ".", "separate", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.torch_separate": [[66, 69], ["separate.torch_separate"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.torch_separate"], ["", "def", "torch_separate", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Convenience for :func:`~asteroid.separate.torch_separate`.\"\"\"", "\n", "return", "separate", ".", "torch_separate", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.numpy_separate": [[70, 73], ["separate.numpy_separate"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.numpy_separate"], ["", "def", "numpy_separate", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Convenience for :func:`~asteroid.separate.numpy_separate`.\"\"\"", "\n", "return", "separate", ".", "numpy_separate", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.file_separate": [[74, 77], ["separate.file_separate"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.file_separate"], ["", "def", "file_separate", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Convenience for :func:`~asteroid.separate.file_separate`.\"\"\"", "\n", "return", "separate", ".", "file_separate", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.forward_wav": [[78, 90], ["base_models.BaseModel."], "methods", ["None"], ["", "def", "forward_wav", "(", "self", ",", "wav", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Separation method for waveforms.\n\n        In case the network's `forward` doesn't have waveforms as input/output,\n        overwrite this method to separate from waveform to waveform.\n        Should return a single torch.Tensor, the separated waveforms.\n\n        Args:\n            wav (torch.Tensor): waveform array/tensor.\n                Shape: 1D, 2D or 3D tensor, time last.\n        \"\"\"", "\n", "return", "self", "(", "wav", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained": [[91, 149], ["isinstance", "conf[].update", "cls.load_state_dict", "utils.hub_utils.cached_download", "torch.load", "torch.load.keys", "ValueError", "torch.load.keys", "ValueError", "torch.load.keys", "ValueError", "isinstance", "utils.hub_utils.SR_HASHTABLE.get", "get", "get.", "cls", "torch.load.keys", "torch.load.keys", "torch.load.keys"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.hub_utils.cached_download", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_conf_or_path", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Instantiate separation model from a model config (file or dict).\n\n        Args:\n            pretrained_model_conf_or_path (Union[dict, str]): model conf as\n                returned by `serialize`, or path to it. Need to contain\n                `model_args` and `state_dict` keys.\n            *args: Positional arguments to be passed to the model.\n            **kwargs: Keyword arguments to be passed to the model.\n                They overwrite the ones in the model package.\n\n        Returns:\n            nn.Module corresponding to the pretrained model conf/URL.\n\n        Raises:\n            ValueError if the input config file doesn't contain the keys\n                `model_name`, `model_args` or `state_dict`.\n        \"\"\"", "\n", "from", ".", "import", "get", "# Avoid circular imports", "\n", "\n", "if", "isinstance", "(", "pretrained_model_conf_or_path", ",", "str", ")", ":", "\n", "            ", "cached_model", "=", "cached_download", "(", "pretrained_model_conf_or_path", ")", "\n", "conf", "=", "torch", ".", "load", "(", "cached_model", ",", "map_location", "=", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "conf", "=", "pretrained_model_conf_or_path", "\n", "\n", "", "if", "\"model_name\"", "not", "in", "conf", ".", "keys", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Expected config dictionary to have field \"", "\n", "\"model_name`. Found only: {}\"", ".", "format", "(", "conf", ".", "keys", "(", ")", ")", "\n", ")", "\n", "", "if", "\"state_dict\"", "not", "in", "conf", ".", "keys", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Expected config dictionary to have field \"", "\n", "\"state_dict`. Found only: {}\"", ".", "format", "(", "conf", ".", "keys", "(", ")", ")", "\n", ")", "\n", "", "if", "\"model_args\"", "not", "in", "conf", ".", "keys", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Expected config dictionary to have field \"", "\n", "\"model_args`. Found only: {}\"", ".", "format", "(", "conf", ".", "keys", "(", ")", ")", "\n", ")", "\n", "", "conf", "[", "\"model_args\"", "]", ".", "update", "(", "kwargs", ")", "# kwargs overwrite config.", "\n", "if", "\"sample_rate\"", "not", "in", "conf", "[", "\"model_args\"", "]", "and", "isinstance", "(", "\n", "pretrained_model_conf_or_path", ",", "str", "\n", ")", ":", "\n", "            ", "conf", "[", "\"model_args\"", "]", "[", "\"sample_rate\"", "]", "=", "SR_HASHTABLE", ".", "get", "(", "\n", "pretrained_model_conf_or_path", ",", "None", "\n", ")", "\n", "# Attempt to find the model and instantiate it.", "\n", "", "try", ":", "\n", "            ", "model_class", "=", "get", "(", "conf", "[", "\"model_name\"", "]", ")", "\n", "", "except", "ValueError", ":", "# Couldn't get the model, maybe custom.", "\n", "            ", "model", "=", "cls", "(", "*", "args", ",", "**", "conf", "[", "\"model_args\"", "]", ")", "# Child class.", "\n", "", "else", ":", "\n", "            ", "model", "=", "model_class", "(", "*", "args", ",", "**", "conf", "[", "\"model_args\"", "]", ")", "\n", "", "model", ".", "load_state_dict", "(", "conf", "[", "\"state_dict\"", "]", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize": [[150, 174], ["dict", "dict", "dict", "base_models.BaseModel.get_state_dict", "base_models.BaseModel.get_model_args"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.get_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dcunet.BaseDCUNet.get_model_args"], ["", "def", "serialize", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serialize model and output dictionary.\n\n        Returns:\n            dict, serialized model with keys `model_args` and `state_dict`.\n        \"\"\"", "\n", "import", "pytorch_lightning", "as", "pl", "# Not used in torch.hub", "\n", "\n", "from", ".", ".", "import", "__version__", "as", "asteroid_version", "# Avoid circular imports", "\n", "\n", "model_conf", "=", "dict", "(", "\n", "model_name", "=", "self", ".", "__class__", ".", "__name__", ",", "\n", "state_dict", "=", "self", ".", "get_state_dict", "(", ")", ",", "\n", "model_args", "=", "self", ".", "get_model_args", "(", ")", ",", "\n", ")", "\n", "# Additional infos", "\n", "infos", "=", "dict", "(", ")", "\n", "infos", "[", "\"software_versions\"", "]", "=", "dict", "(", "\n", "torch_version", "=", "torch", ".", "__version__", ",", "\n", "pytorch_lightning_version", "=", "pl", ".", "__version__", ",", "\n", "asteroid_version", "=", "asteroid_version", ",", "\n", ")", "\n", "model_conf", "[", "\"infos\"", "]", "=", "infos", "\n", "return", "model_conf", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.get_state_dict": [[175, 178], ["base_models.BaseModel.state_dict"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.state_dict"], ["", "def", "get_state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"In case the state dict needs to be modified before sharing the model.\"\"\"", "\n", "return", "self", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.get_model_args": [[179, 182], ["None"], "methods", ["None"], ["", "def", "get_model_args", "(", "self", ")", ":", "\n", "        ", "\"\"\"Should return args to re-instantiate the class.\"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseEncoderMaskerDecoder.__init__": [[195, 202], ["base_models.BaseModel.__init__", "masknn.activations.get", "getattr"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "__init__", "(", "self", ",", "encoder", ",", "masker", ",", "decoder", ",", "encoder_activation", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "sample_rate", "=", "getattr", "(", "encoder", ",", "\"sample_rate\"", ",", "None", ")", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "masker", "=", "masker", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "encoder_activation", "=", "encoder_activation", "\n", "self", ".", "enc_activation", "=", "activations", ".", "get", "(", "encoder_activation", "or", "\"linear\"", ")", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseEncoderMaskerDecoder.forward": [[203, 225], ["utils.torch_utils.jitable_shape", "base_models._unsqueeze_to_3d", "base_models.BaseEncoderMaskerDecoder.forward_encoder", "base_models.BaseEncoderMaskerDecoder.forward_masker", "base_models.BaseEncoderMaskerDecoder.apply_masks", "base_models.BaseEncoderMaskerDecoder.forward_decoder", "utils.torch_utils.pad_x_to_y", "base_models._shape_reconstructed"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.jitable_shape", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models._unsqueeze_to_3d", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dccrnet.DCCRNet.forward_encoder", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask.DeMask.forward_masker", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dccrnet.DCCRNet.apply_masks", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseEncoderMaskerDecoder.forward_decoder", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.pad_x_to_y", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models._shape_reconstructed"], ["", "def", "forward", "(", "self", ",", "wav", ")", ":", "\n", "        ", "\"\"\"Enc/Mask/Dec model forward\n\n        Args:\n            wav (torch.Tensor): waveform tensor. 1D, 2D or 3D tensor, time last.\n\n        Returns:\n            torch.Tensor, of shape (batch, n_src, time) or (n_src, time).\n        \"\"\"", "\n", "# Remember shape to shape reconstruction, cast to Tensor for torchscript", "\n", "shape", "=", "jitable_shape", "(", "wav", ")", "\n", "# Reshape to (batch, n_mix, time)", "\n", "wav", "=", "_unsqueeze_to_3d", "(", "wav", ")", "\n", "\n", "# Real forward", "\n", "tf_rep", "=", "self", ".", "forward_encoder", "(", "wav", ")", "\n", "est_masks", "=", "self", ".", "forward_masker", "(", "tf_rep", ")", "\n", "masked_tf_rep", "=", "self", ".", "apply_masks", "(", "tf_rep", ",", "est_masks", ")", "\n", "decoded", "=", "self", ".", "forward_decoder", "(", "masked_tf_rep", ")", "\n", "\n", "reconstructed", "=", "pad_x_to_y", "(", "decoded", ",", "wav", ")", "\n", "return", "_shape_reconstructed", "(", "reconstructed", ",", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseEncoderMaskerDecoder.forward_encoder": [[226, 237], ["base_models.BaseEncoderMaskerDecoder.encoder", "base_models.BaseEncoderMaskerDecoder.enc_activation"], "methods", ["None"], ["", "def", "forward_encoder", "(", "self", ",", "wav", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes time-frequency representation of `wav`.\n\n        Args:\n            wav (torch.Tensor): waveform tensor in 3D shape, time last.\n\n        Returns:\n            torch.Tensor, of shape (batch, feat, seq).\n        \"\"\"", "\n", "tf_rep", "=", "self", ".", "encoder", "(", "wav", ")", "\n", "return", "self", ".", "enc_activation", "(", "tf_rep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseEncoderMaskerDecoder.forward_masker": [[238, 249], ["base_models.BaseEncoderMaskerDecoder.masker"], "methods", ["None"], ["", "def", "forward_masker", "(", "self", ",", "tf_rep", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Estimates masks from time-frequency representation.\n\n        Args:\n            tf_rep (torch.Tensor): Time-frequency representation in (batch,\n                feat, seq).\n\n        Returns:\n            torch.Tensor: Estimated masks\n        \"\"\"", "\n", "return", "self", ".", "masker", "(", "tf_rep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseEncoderMaskerDecoder.apply_masks": [[250, 262], ["tf_rep.unsqueeze"], "methods", ["None"], ["", "def", "apply_masks", "(", "self", ",", "tf_rep", ":", "torch", ".", "Tensor", ",", "est_masks", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Applies masks to time-frequency representation.\n\n        Args:\n            tf_rep (torch.Tensor): Time-frequency representation in (batch,\n                feat, seq) shape.\n            est_masks (torch.Tensor): Estimated masks.\n\n        Returns:\n            torch.Tensor: Masked time-frequency representations.\n        \"\"\"", "\n", "return", "est_masks", "*", "tf_rep", ".", "unsqueeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseEncoderMaskerDecoder.forward_decoder": [[263, 273], ["base_models.BaseEncoderMaskerDecoder.decoder"], "methods", ["None"], ["", "def", "forward_decoder", "(", "self", ",", "masked_tf_rep", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Reconstructs time-domain waveforms from masked representations.\n\n        Args:\n            masked_tf_rep (torch.Tensor): Masked time-frequency representation.\n\n        Returns:\n            torch.Tensor: Time-domain waveforms.\n        \"\"\"", "\n", "return", "self", ".", "decoder", "(", "masked_tf_rep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseEncoderMaskerDecoder.get_model_args": [[274, 290], ["base_models.BaseEncoderMaskerDecoder.encoder.filterbank.get_config", "base_models.BaseEncoderMaskerDecoder.masker.get_config", "all", "AssertionError"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.SuDORMRFImproved.get_config", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.SuDORMRFImproved.get_config"], ["", "def", "get_model_args", "(", "self", ")", ":", "\n", "        ", "\"\"\"Arguments needed to re-instantiate the model.\"\"\"", "\n", "fb_config", "=", "self", ".", "encoder", ".", "filterbank", ".", "get_config", "(", ")", "\n", "masknet_config", "=", "self", ".", "masker", ".", "get_config", "(", ")", "\n", "# Assert both dict are disjoint", "\n", "if", "not", "all", "(", "k", "not", "in", "fb_config", "for", "k", "in", "masknet_config", ")", ":", "\n", "            ", "raise", "AssertionError", "(", "\n", "\"Filterbank and Mask network config share common keys. Merging them is not safe.\"", "\n", ")", "\n", "# Merge all args under model_args.", "\n", "", "model_args", "=", "{", "\n", "**", "fb_config", ",", "\n", "**", "masknet_config", ",", "\n", "\"encoder_activation\"", ":", "self", ".", "encoder_activation", ",", "\n", "}", "\n", "return", "model_args", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models._unsqueeze_to_3d": [[12, 21], ["x.reshape", "x.unsqueeze"], "function", ["None"], ["@", "script_if_tracing", "\n", "def", "_unsqueeze_to_3d", "(", "x", ")", ":", "\n", "    ", "\"\"\"Normalize shape of `x` to [batch, n_chan, time].\"\"\"", "\n", "if", "x", ".", "ndim", "==", "1", ":", "\n", "        ", "return", "x", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "", "elif", "x", ".", "ndim", "==", "2", ":", "\n", "        ", "return", "x", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models._shape_reconstructed": [[292, 307], ["len", "reconstructed.squeeze"], "function", ["None"], ["", "", "@", "script_if_tracing", "\n", "def", "_shape_reconstructed", "(", "reconstructed", ",", "size", ")", ":", "\n", "    ", "\"\"\"Reshape `reconstructed` to have same size as `size`\n\n    Args:\n        reconstructed (torch.Tensor): Reconstructed waveform\n        size (torch.Tensor): Size of desired waveform\n\n    Returns:\n        torch.Tensor: Reshaped waveform\n\n    \"\"\"", "\n", "if", "len", "(", "size", ")", "==", "1", ":", "\n", "        ", "return", "reconstructed", ".", "squeeze", "(", "0", ")", "\n", "", "return", "reconstructed", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dptnet.DPTNet.__init__": [[52, 106], ["asteroid_filterbanks.make_enc_dec", "masknn.DPTransformer", "base_models.BaseEncoderMaskerDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "n_src", ",", "\n", "n_heads", "=", "4", ",", "\n", "ff_hid", "=", "256", ",", "\n", "chunk_size", "=", "100", ",", "\n", "hop_size", "=", "None", ",", "\n", "n_repeats", "=", "6", ",", "\n", "norm_type", "=", "\"gLN\"", ",", "\n", "ff_activation", "=", "\"relu\"", ",", "\n", "encoder_activation", "=", "\"relu\"", ",", "\n", "mask_act", "=", "\"relu\"", ",", "\n", "bidirectional", "=", "True", ",", "\n", "dropout", "=", "0", ",", "\n", "in_chan", "=", "None", ",", "\n", "fb_name", "=", "\"free\"", ",", "\n", "kernel_size", "=", "16", ",", "\n", "n_filters", "=", "64", ",", "\n", "stride", "=", "8", ",", "\n", "sample_rate", "=", "8000", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", ":", "\n", "        ", "encoder", ",", "decoder", "=", "make_enc_dec", "(", "\n", "fb_name", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "n_filters", "=", "n_filters", ",", "\n", "stride", "=", "stride", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", "\n", "n_feats", "=", "encoder", ".", "n_feats_out", "\n", "if", "in_chan", "is", "not", "None", ":", "\n", "            ", "assert", "in_chan", "==", "n_feats", ",", "(", "\n", "\"Number of filterbank output channels\"", "\n", "\" and number of input channels should \"", "\n", "\"be the same. Received \"", "\n", "f\"{n_feats} and {in_chan}\"", "\n", ")", "\n", "# Update in_chan", "\n", "", "masker", "=", "DPTransformer", "(", "\n", "n_feats", ",", "\n", "n_src", ",", "\n", "n_heads", "=", "n_heads", ",", "\n", "ff_hid", "=", "ff_hid", ",", "\n", "ff_activation", "=", "ff_activation", ",", "\n", "chunk_size", "=", "chunk_size", ",", "\n", "hop_size", "=", "hop_size", ",", "\n", "n_repeats", "=", "n_repeats", ",", "\n", "norm_type", "=", "norm_type", ",", "\n", "mask_act", "=", "mask_act", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "masker", ",", "decoder", ",", "encoder_activation", "=", "encoder_activation", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.__init__": [[22, 41], ["os.getenv", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "api_key", "=", "None", ",", "use_sandbox", "=", "True", ")", ":", "\n", "        ", "if", "api_key", "is", "None", ":", "\n", "            ", "api_key", "=", "os", ".", "getenv", "(", "\"ACCESS_TOKEN\"", ",", "None", ")", "\n", "", "if", "api_key", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Need to set `api_key` somehow. Either through the class\"", "\n", "\"arguments or by setting ACCESS_TOKEN env variable in bash.\"", "\n", ")", "\n", "", "self", ".", "use_sandbox", "=", "use_sandbox", "\n", "if", "use_sandbox", "is", "True", ":", "\n", "            ", "self", ".", "zenodo_address", "=", "\"https://sandbox.zenodo.org\"", "\n", "", "else", ":", "\n", "            ", "self", ".", "zenodo_address", "=", "\"https://zenodo.org\"", "\n", "\n", "", "self", ".", "api_key", "=", "api_key", "\n", "self", ".", "auth_header", "=", "{", "\"Authorization\"", ":", "f\"Bearer {self.api_key}\"", "}", "\n", "self", ".", "headers", "=", "{", "\n", "\"Content-Type\"", ":", "\"application/json\"", ",", "\n", "\"Authorization\"", ":", "f\"Bearer {self.api_key}\"", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.create_new_deposition": [[43, 63], ["requests.post", "print", "isinstance", "zenodo.Zenodo.change_metadata_in_deposition", "print", "requests.post.json", "type"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.change_metadata_in_deposition"], ["", "def", "create_new_deposition", "(", "self", ",", "metadata", "=", "None", ")", ":", "\n", "        ", "\"\"\"Creates a new deposition.\n\n        Args:\n            metadata (dict, optional): Metadata dict to upload on the new\n                deposition.\n        \"\"\"", "\n", "r", "=", "requests", ".", "post", "(", "\n", "f\"{self.zenodo_address}/api/deposit/depositions\"", ",", "json", "=", "{", "}", ",", "headers", "=", "self", ".", "headers", "\n", ")", "\n", "\n", "if", "r", ".", "status_code", "!=", "201", ":", "\n", "            ", "print", "(", "\"Creation failed (status code: {})\"", ".", "format", "(", "r", ".", "status_code", ")", ")", "\n", "return", "r", "\n", "\n", "", "if", "metadata", "is", "not", "None", "and", "isinstance", "(", "metadata", ",", "dict", ")", ":", "\n", "            ", "return", "self", ".", "change_metadata_in_deposition", "(", "r", ".", "json", "(", ")", "[", "\"id\"", "]", ",", "metadata", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"Could not interpret metadata type ({type(metadata)}), \"", "\"expected dict\"", ")", "\n", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.change_metadata_in_deposition": [[64, 88], ["requests.put", "json.dumps"], "methods", ["None"], ["", "def", "change_metadata_in_deposition", "(", "self", ",", "dep_id", ",", "metadata", ")", ":", "\n", "        ", "\"\"\"Set or replace metadata in given deposition\n\n        Args:\n            dep_id (int): deposition id. You cna get it with\n                `r = create_new_deposition(); dep_id = r.json()['id']`\n            metadata (dict): Metadata dict.\n\n        Examples\n            >>> metadata = {\n            ...     'title': 'My first upload',\n            ...     'upload_type': 'poster',\n            ...     'description': 'This is my first upload',\n            ...     'creators': [{'name': 'Doe, John',\n            ...                   'affiliation': 'Zenodo'}]\n            ... }\n        \"\"\"", "\n", "data", "=", "{", "\"metadata\"", ":", "metadata", "}", "\n", "r", "=", "requests", ".", "put", "(", "\n", "f\"{self.zenodo_address}/api/deposit/depositions/{dep_id}\"", ",", "\n", "data", "=", "json", ".", "dumps", "(", "data", ")", ",", "\n", "headers", "=", "self", ".", "headers", ",", "\n", ")", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.upload_new_file_to_deposition": [[89, 127], ["isinstance", "print", "requests.post", "print", "isinstance", "os.path.isfile", "ValueError", "open", "os.path.basename", "io.BytesIO", "os.path.expanduser", "bytes"], "methods", ["None"], ["", "def", "upload_new_file_to_deposition", "(", "self", ",", "dep_id", ",", "file", ",", "name", "=", "None", ")", ":", "\n", "        ", "\"\"\"Upload one file to existing deposition.\n\n        Args:\n            dep_id (int): deposition id. You cna get it with\n                `r = create_new_deposition(); dep_id = r.json()['id']`\n            file (str or io.BufferedReader): path to a file, or already opened\n                file (path prefered).\n            name (str, optional): name given to the uploaded file.\n                Defaults to the path.\n\n        (More: https://developers.zenodo.org/#deposition-files)\n        \"\"\"", "\n", "if", "isinstance", "(", "file", ",", "BufferedReader", ")", ":", "\n", "            ", "files", "=", "{", "\"file\"", ":", "file", "}", "\n", "filename", "=", "name", "if", "name", "else", "\"Unknown\"", "\n", "", "elif", "isinstance", "(", "file", ",", "str", ")", ":", "\n", "            ", "if", "os", ".", "path", ".", "isfile", "(", "file", ")", ":", "\n", "# This is a file, read it", "\n", "                ", "files", "=", "{", "\"file\"", ":", "open", "(", "os", ".", "path", ".", "expanduser", "(", "file", ")", ",", "\"rb\"", ")", "}", "\n", "filename", "=", "name", "if", "name", "else", "os", ".", "path", ".", "basename", "(", "file", ")", "\n", "", "else", ":", "\n", "# This is a string, convert to BytesIO", "\n", "                ", "files", "=", "{", "\"file\"", ":", "BytesIO", "(", "bytes", "(", "file", ",", "\"utf-8\"", ")", ")", "}", "\n", "filename", "=", "name", "if", "name", "else", "\"Unknown\"", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown file format , expected str or Bytes \"", ")", "\n", "", "data", "=", "{", "\"name\"", ":", "filename", "}", "\n", "print", "(", "\"Submitting Data: {} and Files: {}\"", ".", "format", "(", "data", ",", "files", ")", ")", "\n", "\n", "r", "=", "requests", ".", "post", "(", "\n", "f\"{self.zenodo_address}/api/deposit/depositions/{dep_id}/files\"", ",", "\n", "headers", "=", "self", ".", "auth_header", ",", "\n", "data", "=", "data", ",", "\n", "files", "=", "files", ",", "\n", ")", "\n", "print", "(", "\"Zenodo received : {}\"", ".", "format", "(", "r", ".", "content", ")", ")", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.publish_deposition": [[128, 140], ["requests.post"], "methods", ["None"], ["", "def", "publish_deposition", "(", "self", ",", "dep_id", ")", ":", "# pragma: no cover (Cannot publish)", "\n", "        ", "\"\"\"Publish given deposition (Cannot be deleted)!\n\n        Args:\n            dep_id (int): deposition id. You cna get it with\n                `r = create_new_deposition(); dep_id = r.json()['id']`\n        \"\"\"", "\n", "r", "=", "requests", ".", "post", "(", "\n", "f\"{self.zenodo_address}/api/deposit/depositions/{dep_id}/actions/publish\"", ",", "\n", "headers", "=", "self", ".", "headers", ",", "\n", ")", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.get_deposition": [[141, 153], ["print", "print", "requests.get", "print", "requests.get"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "def", "get_deposition", "(", "self", ",", "dep_id", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"Get deposition by deposition id. Get all dep_id is -1 (default).\"\"\"", "\n", "if", "dep_id", ">", "-", "1", ":", "\n", "            ", "print", "(", "f\"Get deposition {dep_id} from Zenodo\"", ")", "\n", "r", "=", "requests", ".", "get", "(", "\n", "f\"{self.zenodo_address}/api/deposit/depositions/{dep_id}\"", ",", "headers", "=", "self", ".", "headers", "\n", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Get all depositions from Zenodo\"", ")", "\n", "r", "=", "requests", ".", "get", "(", "f\"{self.zenodo_address}/api/deposit/depositions\"", ",", "headers", "=", "self", ".", "headers", ")", "\n", "", "print", "(", "\"Get Depositions: Status Code: {}\"", ".", "format", "(", "r", ".", "status_code", ")", ")", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.remove_deposition": [[154, 161], ["print", "requests.delete"], "methods", ["None"], ["", "def", "remove_deposition", "(", "self", ",", "dep_id", ")", ":", "\n", "        ", "\"\"\"Remove deposition with deposition id `dep_id`\"\"\"", "\n", "print", "(", "f\"Delete deposition number {dep_id}\"", ")", "\n", "r", "=", "requests", ".", "delete", "(", "\n", "f\"{self.zenodo_address}/api/deposit/depositions/{dep_id}\"", ",", "headers", "=", "self", ".", "auth_header", "\n", ")", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.remove_all_depositions": [[162, 167], ["zenodo.Zenodo.get_deposition", "zenodo.Zenodo.json", "zenodo.Zenodo.remove_deposition"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.get_deposition", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.remove_deposition"], ["", "def", "remove_all_depositions", "(", "self", ")", ":", "\n", "        ", "\"\"\"Removes all unpublished deposition (not records).\"\"\"", "\n", "all_depositions", "=", "self", ".", "get_deposition", "(", ")", "\n", "for", "dep", "in", "all_depositions", ".", "json", "(", ")", ":", "\n", "            ", "self", ".", "remove_deposition", "(", "dep", "[", "\"id\"", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx.XUMX.__init__": [[49, 145], ["base_models.BaseModel.__init__", "x_umx._STFT", "x_umx._Spectrogram", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "torch.ParameterDict", "torch.ParameterDict", "torch.ParameterDict", "x_umx._ISTFT", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "x_umx._InstrumentBackboneEnc", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "x_umx._InstrumentBackboneDec", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros.clone", "torch.zeros.clone", "torch.zeros.clone", "torch.ones.clone", "torch.ones.clone", "torch.ones.clone", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.ones().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "sources", ",", "\n", "window_length", "=", "4096", ",", "\n", "in_chan", "=", "4096", ",", "\n", "n_hop", "=", "1024", ",", "\n", "hidden_size", "=", "512", ",", "\n", "nb_channels", "=", "2", ",", "\n", "sample_rate", "=", "44100", ",", "\n", "nb_layers", "=", "3", ",", "\n", "input_mean", "=", "None", ",", "\n", "input_scale", "=", "None", ",", "\n", "max_bin", "=", "None", ",", "\n", "bidirectional", "=", "True", ",", "\n", "spec_power", "=", "1", ",", "\n", "return_time_signals", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "sample_rate", ")", "\n", "\n", "self", ".", "window_length", "=", "window_length", "\n", "self", ".", "in_chan", "=", "in_chan", "\n", "self", ".", "n_hop", "=", "n_hop", "\n", "self", ".", "sources", "=", "sources", "\n", "self", ".", "_return_time_signals", "=", "return_time_signals", "\n", "self", ".", "nb_channels", "=", "nb_channels", "\n", "self", ".", "nb_layers", "=", "nb_layers", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "nb_output_bins", "=", "in_chan", "//", "2", "+", "1", "\n", "if", "max_bin", ":", "\n", "            ", "self", ".", "max_bin", "=", "max_bin", "\n", "", "else", ":", "\n", "            ", "self", ".", "max_bin", "=", "self", ".", "nb_output_bins", "\n", "", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "spec_power", "=", "spec_power", "\n", "\n", "if", "input_mean", "is", "not", "None", ":", "\n", "            ", "input_mean", "=", "torch", ".", "from_numpy", "(", "-", "input_mean", "[", ":", "self", ".", "max_bin", "]", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_mean", "=", "torch", ".", "zeros", "(", "self", ".", "max_bin", ")", "\n", "\n", "", "if", "input_scale", "is", "not", "None", ":", "\n", "            ", "input_scale", "=", "torch", ".", "from_numpy", "(", "1.0", "/", "input_scale", "[", ":", "self", ".", "max_bin", "]", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_scale", "=", "torch", ".", "ones", "(", "self", ".", "max_bin", ")", "\n", "\n", "# Define spectral encoder", "\n", "", "stft", "=", "_STFT", "(", "window_length", "=", "window_length", ",", "n_fft", "=", "in_chan", ",", "n_hop", "=", "n_hop", ",", "center", "=", "True", ")", "\n", "spec", "=", "_Spectrogram", "(", "spec_power", "=", "spec_power", ",", "mono", "=", "(", "nb_channels", "==", "1", ")", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Sequential", "(", "stft", ",", "spec", ")", "# Return: Spec, Angle", "\n", "\n", "# Define DNN Core", "\n", "lstm_hidden_size", "=", "hidden_size", "//", "2", "if", "bidirectional", "else", "hidden_size", "\n", "src_enc", "=", "{", "}", "\n", "src_lstm", "=", "{", "}", "\n", "src_dec", "=", "{", "}", "\n", "mean_scale", "=", "{", "}", "\n", "for", "src", "in", "sources", ":", "\n", "# Define Enc.", "\n", "            ", "src_enc", "[", "src", "]", "=", "_InstrumentBackboneEnc", "(", "\n", "nb_bins", "=", "self", ".", "max_bin", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "nb_channels", "=", "nb_channels", ",", "\n", ")", "\n", "\n", "# Define Recurrent Lyaers.", "\n", "src_lstm", "[", "src", "]", "=", "LSTM", "(", "\n", "input_size", "=", "hidden_size", ",", "\n", "hidden_size", "=", "lstm_hidden_size", ",", "\n", "num_layers", "=", "nb_layers", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "batch_first", "=", "False", ",", "\n", "dropout", "=", "0.4", ",", "\n", ")", "\n", "\n", "# Define Dec.", "\n", "src_dec", "[", "src", "]", "=", "_InstrumentBackboneDec", "(", "\n", "nb_output_bins", "=", "self", ".", "nb_output_bins", ",", "\n", "hidden_size", "=", "hidden_size", ",", "\n", "nb_channels", "=", "nb_channels", ",", "\n", ")", "\n", "\n", "mean_scale", "[", "\"input_mean_{}\"", ".", "format", "(", "src", ")", "]", "=", "Parameter", "(", "input_mean", ".", "clone", "(", ")", ")", "\n", "mean_scale", "[", "\"input_scale_{}\"", ".", "format", "(", "src", ")", "]", "=", "Parameter", "(", "input_scale", ".", "clone", "(", ")", ")", "\n", "mean_scale", "[", "\"output_mean_{}\"", ".", "format", "(", "src", ")", "]", "=", "Parameter", "(", "\n", "torch", ".", "ones", "(", "self", ".", "nb_output_bins", ")", ".", "float", "(", ")", "\n", ")", "\n", "mean_scale", "[", "\"output_scale_{}\"", ".", "format", "(", "src", ")", "]", "=", "Parameter", "(", "\n", "torch", ".", "ones", "(", "self", ".", "nb_output_bins", ")", ".", "float", "(", ")", "\n", ")", "\n", "", "self", ".", "layer_enc", "=", "nn", ".", "ModuleDict", "(", "src_enc", ")", "\n", "self", ".", "layer_lstm", "=", "nn", ".", "ModuleDict", "(", "src_lstm", ")", "\n", "self", ".", "layer_dec", "=", "nn", ".", "ModuleDict", "(", "src_dec", ")", "\n", "self", ".", "mean_scale", "=", "nn", ".", "ParameterDict", "(", "mean_scale", ")", "\n", "\n", "# Define spectral decoder", "\n", "self", ".", "decoder", "=", "_ISTFT", "(", "window", "=", "stft", ".", "window", ",", "n_fft", "=", "in_chan", ",", "hop_length", "=", "n_hop", ",", "center", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx.XUMX.forward": [[146, 174], ["x_umx.XUMX.encoder", "x_umx.XUMX.forward_masker", "x_umx.XUMX.apply_masks", "mixture.clone", "x_umx.XUMX.permute", "x_umx.XUMX.decoder"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask.DeMask.forward_masker", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dccrnet.DCCRNet.apply_masks"], ["", "def", "forward", "(", "self", ",", "wav", ")", ":", "\n", "        ", "\"\"\"Model forward\n\n        Args:\n            wav (torch.Tensor): waveform tensor. 1D, 2D or 3D tensor, time last.\n\n        Returns:\n            masked_mixture (torch.Tensor): estimated spectrograms masked by\n                X-UMX's output of shape $(sources, frames, batch_size, channels, bins)$\n            time_signals (torch.Tensor): estimated time signals of shape $(sources, batch_size, channels, time_length)$ if `return_time_signals` is `True`\n        \"\"\"", "\n", "# Transform", "\n", "mixture", ",", "ang", "=", "self", ".", "encoder", "(", "wav", ")", "\n", "\n", "# Estimate masks", "\n", "est_masks", "=", "self", ".", "forward_masker", "(", "mixture", ".", "clone", "(", ")", ")", "\n", "\n", "# Apply masks to mixture", "\n", "masked_mixture", "=", "self", ".", "apply_masks", "(", "mixture", ",", "est_masks", ")", "\n", "\n", "# Inverse Transform", "\n", "if", "self", ".", "_return_time_signals", ":", "\n", "            ", "spec", "=", "masked_mixture", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "4", ",", "1", ")", "\n", "time_signals", "=", "self", ".", "decoder", "(", "spec", ",", "ang", ")", "\n", "", "else", ":", "\n", "            ", "time_signals", "=", "None", "\n", "\n", "", "return", "masked_mixture", ",", "time_signals", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx.XUMX.forward_masker": [[175, 212], ["range", "enumerate", "enumerate", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "len", "inputs.append", "sum", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mask_list.append", "x.clone", "torch.relu", "torch.relu", "torch.relu"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu"], ["", "def", "forward_masker", "(", "self", ",", "input_spec", ")", ":", "\n", "        ", "shapes", "=", "input_spec", ".", "data", ".", "shape", "\n", "\n", "# crop", "\n", "x", "=", "input_spec", "[", "...", ",", ":", "self", ".", "max_bin", "]", "\n", "\n", "# clone for the number of sources", "\n", "inputs", "=", "[", "x", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "sources", ")", ")", ":", "\n", "            ", "inputs", ".", "append", "(", "x", ".", "clone", "(", ")", ")", "\n", "\n", "# shift and scale input to mean=0 std=1 (across all bins)", "\n", "# and encode to (nb_frames*nb_samples, hidden_size)", "\n", "", "for", "i", ",", "src", "in", "enumerate", "(", "self", ".", "sources", ")", ":", "\n", "            ", "inputs", "[", "i", "]", "+=", "self", ".", "mean_scale", "[", "\"input_mean_{}\"", ".", "format", "(", "src", ")", "]", "\n", "inputs", "[", "i", "]", "*=", "self", ".", "mean_scale", "[", "\"input_scale_{}\"", ".", "format", "(", "src", ")", "]", "\n", "inputs", "[", "i", "]", "=", "self", ".", "layer_enc", "[", "src", "]", "(", "inputs", "[", "i", "]", ",", "shapes", ")", "\n", "\n", "# 1st Bridging operation and apply 3-layers of stacked LSTM", "\n", "", "cross_1", "=", "sum", "(", "inputs", ")", "/", "len", "(", "self", ".", "sources", ")", "\n", "cross_2", "=", "0.0", "\n", "for", "i", ",", "src", "in", "enumerate", "(", "self", ".", "sources", ")", ":", "\n", "            ", "tmp_lstm_out", "=", "self", ".", "layer_lstm", "[", "src", "]", "(", "cross_1", ")", "\n", "# lstm skip connection", "\n", "cross_2", "+=", "torch", ".", "cat", "(", "[", "inputs", "[", "i", "]", ",", "tmp_lstm_out", "[", "0", "]", "]", ",", "-", "1", ")", "\n", "\n", "# 2nd Bridging operation", "\n", "", "cross_2", "/=", "len", "(", "self", ".", "sources", ")", "\n", "mask_list", "=", "[", "]", "\n", "for", "src", "in", "self", ".", "sources", ":", "\n", "            ", "x_tmp", "=", "self", ".", "layer_dec", "[", "src", "]", "(", "cross_2", ",", "shapes", ")", "\n", "x_tmp", "*=", "self", ".", "mean_scale", "[", "\"output_scale_{}\"", ".", "format", "(", "src", ")", "]", "\n", "x_tmp", "+=", "self", ".", "mean_scale", "[", "\"output_mean_{}\"", ".", "format", "(", "src", ")", "]", "\n", "mask_list", ".", "append", "(", "F", ".", "relu", "(", "x_tmp", ")", ")", "\n", "", "est_masks", "=", "torch", ".", "stack", "(", "mask_list", ",", "dim", "=", "0", ")", "\n", "\n", "return", "est_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx.XUMX.apply_masks": [[213, 216], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "range", "len"], "methods", ["None"], ["", "def", "apply_masks", "(", "self", ",", "mixture", ",", "est_masks", ")", ":", "\n", "        ", "masked_tf_rep", "=", "torch", ".", "stack", "(", "[", "mixture", "*", "est_masks", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "self", ".", "sources", ")", ")", "]", ")", "\n", "return", "masked_tf_rep", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx.XUMX.get_model_args": [[217, 245], ["None"], "methods", ["None"], ["", "def", "get_model_args", "(", "self", ")", ":", "\n", "        ", "\"\"\"Arguments needed to re-instantiate the model.\"\"\"", "\n", "fb_config", "=", "{", "\n", "\"window_length\"", ":", "self", ".", "window_length", ",", "\n", "\"in_chan\"", ":", "self", ".", "in_chan", ",", "\n", "\"n_hop\"", ":", "self", ".", "n_hop", ",", "\n", "\"sample_rate\"", ":", "self", ".", "sample_rate", ",", "\n", "}", "\n", "\n", "net_config", "=", "{", "\n", "\"sources\"", ":", "self", ".", "sources", ",", "\n", "\"hidden_size\"", ":", "self", ".", "hidden_size", ",", "\n", "\"nb_channels\"", ":", "self", ".", "nb_channels", ",", "\n", "\"input_mean\"", ":", "None", ",", "\n", "\"input_scale\"", ":", "None", ",", "\n", "\"max_bin\"", ":", "self", ".", "max_bin", ",", "\n", "\"nb_layers\"", ":", "self", ".", "nb_layers", ",", "\n", "\"bidirectional\"", ":", "self", ".", "bidirectional", ",", "\n", "\"spec_power\"", ":", "self", ".", "spec_power", ",", "\n", "\"return_time_signals\"", ":", "False", ",", "\n", "}", "\n", "\n", "# Merge all args under model_args.", "\n", "model_args", "=", "{", "\n", "**", "fb_config", ",", "\n", "**", "net_config", ",", "\n", "}", "\n", "return", "model_args", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx._InstrumentBackboneEnc.__init__": [[258, 271], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nb_bins", ",", "\n", "hidden_size", "=", "512", ",", "\n", "nb_channels", "=", "2", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "max_bin", "=", "nb_bins", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "enc", "=", "nn", ".", "Sequential", "(", "\n", "Linear", "(", "self", ".", "max_bin", "*", "nb_channels", ",", "hidden_size", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm1d", "(", "hidden_size", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx._InstrumentBackboneEnc.forward": [[273, 281], ["x_umx._InstrumentBackboneEnc.enc", "torch.tanh.reshape", "torch.tanh.reshape", "torch.tanh.reshape", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh.reshape", "torch.tanh.reshape", "torch.tanh.reshape"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.tanh", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.tanh", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.tanh", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.tanh", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.tanh", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.tanh", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.tanh", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.tanh", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.tanh"], ["", "def", "forward", "(", "self", ",", "x", ",", "shapes", ")", ":", "\n", "        ", "nb_frames", ",", "nb_samples", ",", "nb_channels", ",", "_", "=", "shapes", "\n", "x", "=", "self", ".", "enc", "(", "x", ".", "reshape", "(", "-", "1", ",", "nb_channels", "*", "self", ".", "max_bin", ")", ")", "\n", "x", "=", "x", ".", "reshape", "(", "nb_frames", ",", "nb_samples", ",", "self", ".", "hidden_size", ")", "\n", "\n", "# squash range to [-1, 1]", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx._InstrumentBackboneDec.__init__": [[294, 310], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nb_output_bins", ",", "\n", "hidden_size", "=", "512", ",", "\n", "nb_channels", "=", "2", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nb_output_bins", "=", "nb_output_bins", "\n", "self", ".", "dec", "=", "nn", ".", "Sequential", "(", "\n", "Linear", "(", "in_features", "=", "hidden_size", "*", "2", ",", "out_features", "=", "hidden_size", ",", "bias", "=", "False", ")", ",", "\n", "BatchNorm1d", "(", "hidden_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "Linear", "(", "\n", "in_features", "=", "hidden_size", ",", "out_features", "=", "self", ".", "nb_output_bins", "*", "nb_channels", ",", "bias", "=", "False", "\n", ")", ",", "\n", "BatchNorm1d", "(", "self", ".", "nb_output_bins", "*", "nb_channels", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx._InstrumentBackboneDec.forward": [[312, 317], ["x_umx._InstrumentBackboneDec.dec", "x.reshape.reshape.reshape", "x.reshape.reshape.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "shapes", ")", ":", "\n", "        ", "nb_frames", ",", "nb_samples", ",", "nb_channels", ",", "_", "=", "shapes", "\n", "x", "=", "self", ".", "dec", "(", "x", ".", "reshape", "(", "-", "1", ",", "x", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "x", "=", "x", ".", "reshape", "(", "nb_frames", ",", "nb_samples", ",", "nb_channels", ",", "self", ".", "nb_output_bins", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx._STFT.__init__": [[320, 326], ["torch.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window", "torch.hann_window"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "window_length", ",", "n_fft", "=", "4096", ",", "n_hop", "=", "1024", ",", "center", "=", "True", ")", ":", "\n", "        ", "super", "(", "_STFT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "window", "=", "Parameter", "(", "torch", ".", "hann_window", "(", "window_length", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "n_fft", "=", "n_fft", "\n", "self", ".", "n_hop", "=", "n_hop", "\n", "self", ".", "center", "=", "center", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx._STFT.forward": [[327, 354], ["x.reshape.reshape.size", "x.reshape.reshape.reshape", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "torch.stft", "stft_f.contiguous().view.contiguous().view.contiguous().view", "stft_f.contiguous().view.contiguous().view.contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Input: (nb_samples, nb_channels, nb_timesteps)\n        Output:(nb_samples, nb_channels, nb_bins, nb_frames, 2)\n        \"\"\"", "\n", "\n", "nb_samples", ",", "nb_channels", ",", "nb_timesteps", "=", "x", ".", "size", "(", ")", "\n", "\n", "# merge nb_samples and nb_channels for multichannel stft", "\n", "x", "=", "x", ".", "reshape", "(", "nb_samples", "*", "nb_channels", ",", "-", "1", ")", "\n", "\n", "# compute stft with parameters as close as possible scipy settings", "\n", "stft_f", "=", "torch", ".", "stft", "(", "\n", "x", ",", "\n", "n_fft", "=", "self", ".", "n_fft", ",", "\n", "hop_length", "=", "self", ".", "n_hop", ",", "\n", "window", "=", "self", ".", "window", ",", "\n", "center", "=", "self", ".", "center", ",", "\n", "normalized", "=", "False", ",", "\n", "onesided", "=", "True", ",", "\n", "pad_mode", "=", "\"reflect\"", ",", "\n", "return_complex", "=", "False", ",", "\n", ")", "\n", "\n", "# reshape back to channel dimension", "\n", "stft_f", "=", "stft_f", ".", "contiguous", "(", ")", ".", "view", "(", "nb_samples", ",", "nb_channels", ",", "self", ".", "n_fft", "//", "2", "+", "1", ",", "-", "1", ",", "2", ")", "\n", "return", "stft_f", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx._Spectrogram.__init__": [[357, 361], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "spec_power", "=", "1", ",", "mono", "=", "True", ")", ":", "\n", "        ", "super", "(", "_Spectrogram", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "spec_power", "=", "spec_power", "\n", "self", ".", "mono", "=", "mono", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx._Spectrogram.forward": [[362, 385], ["torch.mean.detach().clone", "torch.mean.detach().clone", "torch.mean.detach().clone", "torch.atan2", "torch.atan2", "torch.atan2", "torch.atan2", "torch.atan2", "torch.atan2", "torch.atan2", "torch.atan2", "torch.atan2", "torch.mean.transpose", "torch.mean.transpose", "torch.mean.transpose", "torch.mean.pow().sum().pow", "torch.mean.pow().sum().pow", "torch.mean.pow().sum().pow", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.permute", "torch.mean.permute", "torch.mean.permute", "torch.mean.detach", "torch.mean.detach", "torch.mean.detach", "torch.mean.pow().sum", "torch.mean.pow().sum", "torch.mean.pow().sum", "torch.mean.pow", "torch.mean.pow", "torch.mean.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "stft_f", ")", ":", "\n", "        ", "\"\"\"\n        Input: complex STFT\n            (nb_samples, nb_channels, nb_bins, nb_frames, 2)\n        Output: Power/Mag Spectrogram and the corresponding phase\n            (nb_frames, nb_samples, nb_channels, nb_bins)\n        \"\"\"", "\n", "\n", "phase", "=", "stft_f", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "phase", "=", "torch", ".", "atan2", "(", "phase", "[", "Ellipsis", ",", "1", "]", ",", "phase", "[", "Ellipsis", ",", "0", "]", ")", "\n", "\n", "stft_f", "=", "stft_f", ".", "transpose", "(", "2", ",", "3", ")", "\n", "\n", "# take the magnitude", "\n", "stft_f", "=", "stft_f", ".", "pow", "(", "2", ")", ".", "sum", "(", "-", "1", ")", ".", "pow", "(", "self", ".", "spec_power", "/", "2.0", ")", "\n", "\n", "# downmix in the mag domain", "\n", "if", "self", ".", "mono", ":", "\n", "            ", "stft_f", "=", "torch", ".", "mean", "(", "stft_f", ",", "1", ",", "keepdim", "=", "True", ")", "\n", "phase", "=", "torch", ".", "mean", "(", "phase", ",", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# permute output for LSTM convenience", "\n", "", "return", "[", "stft_f", ".", "permute", "(", "2", ",", "0", ",", "1", ",", "3", ")", ",", "phase", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx._ISTFT.__init__": [[388, 394], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "window", ",", "n_fft", "=", "4096", ",", "hop_length", "=", "1024", ",", "center", "=", "True", ")", ":", "\n", "        ", "super", "(", "_ISTFT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "window", "=", "window", "\n", "self", ".", "n_fft", "=", "n_fft", "\n", "self", ".", "hop_length", "=", "hop_length", "\n", "self", ".", "center", "=", "center", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.x_umx._ISTFT.forward": [[395, 407], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.view.view.view", "torch.istft", "torch.istft", "torch.istft", "torch.istft", "torch.istft", "torch.istft", "torch.istft", "torch.istft", "torch.istft", "wav.view.view.view", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft"], ["", "def", "forward", "(", "self", ",", "spec", ",", "ang", ")", ":", "\n", "        ", "sources", ",", "bsize", ",", "channels", ",", "fbins", ",", "frames", "=", "spec", ".", "shape", "\n", "x_r", "=", "spec", "*", "torch", ".", "cos", "(", "ang", ")", "\n", "x_i", "=", "spec", "*", "torch", ".", "sin", "(", "ang", ")", "\n", "x", "=", "torch", ".", "stack", "(", "[", "x_r", ",", "x_i", "]", ",", "dim", "=", "-", "1", ")", "\n", "x", "=", "x", ".", "view", "(", "sources", "*", "bsize", "*", "channels", ",", "fbins", ",", "frames", ",", "2", ")", "\n", "wav", "=", "torch", ".", "istft", "(", "\n", "x", ",", "n_fft", "=", "self", ".", "n_fft", ",", "hop_length", "=", "self", ".", "hop_length", ",", "window", "=", "self", ".", "window", ",", "center", "=", "self", ".", "center", "\n", ")", "\n", "wav", "=", "wav", ".", "view", "(", "sources", ",", "bsize", ",", "channels", ",", "wav", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "return", "wav", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask.DeMask.__init__": [[39, 84], ["asteroid_filterbanks.make_enc_dec", "demask.DeMask._get_n_feats_input", "demask.DeMask._get_n_feats_output", "demask.build_demask_masker", "base_models.BaseEncoderMaskerDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask.DeMask._get_n_feats_input", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask.DeMask._get_n_feats_output", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask.build_demask_masker", "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_type", "=", "\"mag\"", ",", "\n", "output_type", "=", "\"mag\"", ",", "\n", "hidden_dims", "=", "(", "1024", ",", ")", ",", "\n", "dropout", "=", "0.0", ",", "\n", "activation", "=", "\"relu\"", ",", "\n", "mask_act", "=", "\"relu\"", ",", "\n", "norm_type", "=", "\"gLN\"", ",", "\n", "fb_name", "=", "\"stft\"", ",", "\n", "n_filters", "=", "512", ",", "\n", "stride", "=", "256", ",", "\n", "kernel_size", "=", "512", ",", "\n", "sample_rate", "=", "16000", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", ":", "\n", "        ", "encoder", ",", "decoder", "=", "make_enc_dec", "(", "\n", "fb_name", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "n_filters", "=", "n_filters", ",", "\n", "stride", "=", "stride", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", "\n", "\n", "n_masker_in", "=", "self", ".", "_get_n_feats_input", "(", "input_type", ",", "encoder", ".", "n_feats_out", ")", "\n", "n_masker_out", "=", "self", ".", "_get_n_feats_output", "(", "output_type", ",", "encoder", ".", "n_feats_out", ")", "\n", "masker", "=", "build_demask_masker", "(", "\n", "n_masker_in", ",", "\n", "n_masker_out", ",", "\n", "norm_type", "=", "norm_type", ",", "\n", "activation", "=", "activation", ",", "\n", "hidden_dims", "=", "hidden_dims", ",", "\n", "dropout", "=", "dropout", ",", "\n", "mask_act", "=", "mask_act", ",", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "masker", ",", "decoder", ")", "\n", "\n", "self", ".", "input_type", "=", "input_type", "\n", "self", ".", "output_type", "=", "output_type", "\n", "self", ".", "hidden_dims", "=", "hidden_dims", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "mask_act", "=", "mask_act", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask.DeMask._get_n_feats_input": [[85, 96], ["NotImplementedError"], "methods", ["None"], ["", "def", "_get_n_feats_input", "(", "self", ",", "input_type", ",", "encoder_n_out", ")", ":", "\n", "        ", "if", "input_type", "==", "\"reim\"", ":", "\n", "            ", "return", "encoder_n_out", "\n", "\n", "", "if", "input_type", "not", "in", "{", "\"mag\"", ",", "\"cat\"", "}", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Input type should be either mag, reim or cat\"", ")", "\n", "\n", "", "n_feats_input", "=", "encoder_n_out", "//", "2", "\n", "if", "input_type", "==", "\"cat\"", ":", "\n", "            ", "n_feats_input", "+=", "encoder_n_out", "\n", "", "return", "n_feats_input", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask.DeMask._get_n_feats_output": [[97, 103], ["NotImplementedError"], "methods", ["None"], ["", "def", "_get_n_feats_output", "(", "self", ",", "output_type", ",", "encoder_n_out", ")", ":", "\n", "        ", "if", "output_type", "==", "\"mag\"", ":", "\n", "            ", "return", "encoder_n_out", "//", "2", "\n", "", "if", "output_type", "==", "\"reim\"", ":", "\n", "            ", "return", "encoder_n_out", "\n", "", "raise", "NotImplementedError", "(", "\"Output type should be either mag or reim\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask.DeMask.forward_masker": [[104, 123], ["demask.DeMask.masker", "asteroid_filterbanks.transforms.mag", "est_masks.repeat.repeat.repeat", "asteroid_filterbanks.transforms.magreim"], "methods", ["None"], ["", "def", "forward_masker", "(", "self", ",", "tf_rep", ")", ":", "\n", "        ", "\"\"\"Estimates masks based on time-frequency representations.\n\n        Args:\n            tf_rep (torch.Tensor): Time-frequency representation in\n                (batch, freq, seq).\n\n        Returns:\n            torch.Tensor: Estimated masks in (batch, freq, seq).\n        \"\"\"", "\n", "masker_input", "=", "tf_rep", "\n", "if", "self", ".", "input_type", "==", "\"mag\"", ":", "\n", "            ", "masker_input", "=", "mag", "(", "masker_input", ")", "\n", "", "elif", "self", ".", "input_type", "==", "\"cat\"", ":", "\n", "            ", "masker_input", "=", "magreim", "(", "masker_input", ")", "\n", "", "est_masks", "=", "self", ".", "masker", "(", "masker_input", ")", "\n", "if", "self", ".", "output_type", "==", "\"mag\"", ":", "\n", "            ", "est_masks", "=", "est_masks", ".", "repeat", "(", "1", ",", "2", ",", "1", ")", "\n", "", "return", "est_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask.DeMask.apply_masks": [[124, 138], ["tf_rep.unsqueeze.unsqueeze.unsqueeze"], "methods", ["None"], ["", "def", "apply_masks", "(", "self", ",", "tf_rep", ",", "est_masks", ")", ":", "\n", "        ", "\"\"\"Applies masks to time-frequency representations.\n\n        Args:\n            tf_rep (torch.Tensor): Time-frequency representations in\n                (batch, freq, seq).\n            est_masks (torch.Tensor): Estimated masks in (batch, freq, seq).\n\n        Returns:\n            torch.Tensor: Masked time-frequency representations.\n        \"\"\"", "\n", "if", "self", ".", "output_type", "==", "\"reim\"", ":", "\n", "            ", "tf_rep", "=", "tf_rep", ".", "unsqueeze", "(", "1", ")", "\n", "", "return", "est_masks", "*", "tf_rep", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask.DeMask.get_model_args": [[139, 152], ["model_args.update", "demask.DeMask.encoder.filterbank.get_config"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.SuDORMRFImproved.get_config"], ["", "def", "get_model_args", "(", "self", ")", ":", "\n", "        ", "\"\"\"Arguments needed to re-instantiate the model.\"\"\"", "\n", "model_args", "=", "{", "\n", "\"input_type\"", ":", "self", ".", "input_type", ",", "\n", "\"output_type\"", ":", "self", ".", "output_type", ",", "\n", "\"hidden_dims\"", ":", "self", ".", "hidden_dims", ",", "\n", "\"dropout\"", ":", "self", ".", "dropout", ",", "\n", "\"activation\"", ":", "self", ".", "activation", ",", "\n", "\"mask_act\"", ":", "self", ".", "mask_act", ",", "\n", "\"norm_type\"", ":", "self", ".", "norm_type", ",", "\n", "}", "\n", "model_args", ".", "update", "(", "self", ".", "encoder", ".", "filterbank", ".", "get_config", "(", ")", ")", "\n", "return", "model_args", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask.build_demask_masker": [[154, 180], ["masknn.norms.get", "net.extend", "torch.nn.Sequential", "norms.get.", "masknn.activations.get", "net.extend", "torch.nn.Conv1d", "torch.nn.Conv1d", "norms.get.", "torch.nn.Dropout", "masknn.activations.get"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "", "def", "build_demask_masker", "(", "\n", "n_in", ",", "\n", "n_out", ",", "\n", "activation", "=", "\"relu\"", ",", "\n", "dropout", "=", "0.0", ",", "\n", "hidden_dims", "=", "(", "1024", ",", ")", ",", "\n", "mask_act", "=", "\"relu\"", ",", "\n", "norm_type", "=", "\"gLN\"", ",", "\n", ")", ":", "\n", "    ", "make_layer_norm", "=", "norms", ".", "get", "(", "norm_type", ")", "\n", "net", "=", "[", "make_layer_norm", "(", "n_in", ")", "]", "\n", "layer_activation", "=", "activations", ".", "get", "(", "activation", ")", "(", ")", "\n", "in_chan", "=", "n_in", "\n", "for", "hidden_dim", "in", "hidden_dims", ":", "\n", "        ", "net", ".", "extend", "(", "\n", "[", "\n", "nn", ".", "Conv1d", "(", "in_chan", ",", "hidden_dim", ",", "1", ")", ",", "\n", "make_layer_norm", "(", "hidden_dim", ")", ",", "\n", "layer_activation", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "]", "\n", ")", "\n", "in_chan", "=", "hidden_dim", "\n", "\n", "", "net", ".", "extend", "(", "[", "nn", ".", "Conv1d", "(", "in_chan", ",", "n_out", ",", "1", ")", ",", "activations", ".", "get", "(", "mask_act", ")", "(", ")", "]", ")", "\n", "return", "nn", ".", "Sequential", "(", "*", "net", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dprnn_tasnet.DPRNNTasNet.__init__": [[52, 112], ["asteroid_filterbanks.make_enc_dec", "masknn.DPRNN", "base_models.BaseEncoderMaskerDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "n_src", ",", "\n", "out_chan", "=", "None", ",", "\n", "bn_chan", "=", "128", ",", "\n", "hid_size", "=", "128", ",", "\n", "chunk_size", "=", "100", ",", "\n", "hop_size", "=", "None", ",", "\n", "n_repeats", "=", "6", ",", "\n", "norm_type", "=", "\"gLN\"", ",", "\n", "mask_act", "=", "\"sigmoid\"", ",", "\n", "bidirectional", "=", "True", ",", "\n", "rnn_type", "=", "\"LSTM\"", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout", "=", "0", ",", "\n", "in_chan", "=", "None", ",", "\n", "fb_name", "=", "\"free\"", ",", "\n", "kernel_size", "=", "16", ",", "\n", "n_filters", "=", "64", ",", "\n", "stride", "=", "8", ",", "\n", "encoder_activation", "=", "None", ",", "\n", "sample_rate", "=", "8000", ",", "\n", "use_mulcat", "=", "False", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", ":", "\n", "        ", "encoder", ",", "decoder", "=", "make_enc_dec", "(", "\n", "fb_name", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "n_filters", "=", "n_filters", ",", "\n", "stride", "=", "stride", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", "\n", "n_feats", "=", "encoder", ".", "n_feats_out", "\n", "if", "in_chan", "is", "not", "None", ":", "\n", "            ", "assert", "in_chan", "==", "n_feats", ",", "(", "\n", "\"Number of filterbank output channels\"", "\n", "\" and number of input channels should \"", "\n", "\"be the same. Received \"", "\n", "f\"{n_feats} and {in_chan}\"", "\n", ")", "\n", "# Update in_chan", "\n", "", "masker", "=", "DPRNN", "(", "\n", "n_feats", ",", "\n", "n_src", ",", "\n", "out_chan", "=", "out_chan", ",", "\n", "bn_chan", "=", "bn_chan", ",", "\n", "hid_size", "=", "hid_size", ",", "\n", "chunk_size", "=", "chunk_size", ",", "\n", "hop_size", "=", "hop_size", ",", "\n", "n_repeats", "=", "n_repeats", ",", "\n", "norm_type", "=", "norm_type", ",", "\n", "mask_act", "=", "mask_act", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "rnn_type", "=", "rnn_type", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "use_mulcat", "=", "use_mulcat", ",", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "masker", ",", "decoder", ",", "encoder_activation", "=", "encoder_activation", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.lstm_tasnet.LSTMTasNet.__init__": [[44, 96], ["asteroid_filterbanks.make_enc_dec", "lstm_tasnet._GatedEncoder", "masknn.LSTMMasker", "base_models.BaseEncoderMaskerDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "n_src", ",", "\n", "out_chan", "=", "None", ",", "\n", "rnn_type", "=", "\"lstm\"", ",", "\n", "n_layers", "=", "4", ",", "\n", "hid_size", "=", "512", ",", "\n", "dropout", "=", "0.3", ",", "\n", "mask_act", "=", "\"sigmoid\"", ",", "\n", "bidirectional", "=", "True", ",", "\n", "in_chan", "=", "None", ",", "\n", "fb_name", "=", "\"free\"", ",", "\n", "n_filters", "=", "64", ",", "\n", "kernel_size", "=", "16", ",", "\n", "stride", "=", "8", ",", "\n", "encoder_activation", "=", "None", ",", "\n", "sample_rate", "=", "8000", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", ":", "\n", "        ", "encoder", ",", "decoder", "=", "make_enc_dec", "(", "\n", "fb_name", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "n_filters", "=", "n_filters", ",", "\n", "stride", "=", "stride", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", "\n", "n_feats", "=", "encoder", ".", "n_feats_out", "\n", "if", "in_chan", "is", "not", "None", ":", "\n", "            ", "assert", "in_chan", "==", "n_feats", ",", "(", "\n", "\"Number of filterbank output channels\"", "\n", "\" and number of input channels should \"", "\n", "\"be the same. Received \"", "\n", "f\"{n_feats} and {in_chan}\"", "\n", ")", "\n", "\n", "# Real gated encoder", "\n", "", "encoder", "=", "_GatedEncoder", "(", "encoder", ")", "\n", "\n", "# Masker", "\n", "masker", "=", "LSTMMasker", "(", "\n", "n_feats", ",", "\n", "n_src", ",", "\n", "out_chan", "=", "out_chan", ",", "\n", "hid_size", "=", "hid_size", ",", "\n", "mask_act", "=", "mask_act", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "rnn_type", "=", "rnn_type", ",", "\n", "n_layers", "=", "n_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "masker", ",", "decoder", ",", "encoder_activation", "=", "encoder_activation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.lstm_tasnet._GatedEncoder.__init__": [[99, 107], ["torch.nn.Module.__init__", "getattr", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# For config", "\n", "self", ".", "filterbank", "=", "encoder", ".", "filterbank", "\n", "self", ".", "sample_rate", "=", "getattr", "(", "encoder", ".", "filterbank", ",", "\"sample_rate\"", ",", "None", ")", "\n", "# Gated encoder.", "\n", "self", ".", "encoder_relu", "=", "encoder", "\n", "self", ".", "encoder_sig", "=", "deepcopy", "(", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.lstm_tasnet._GatedEncoder.forward": [[108, 112], ["torch.relu", "torch.sigmoid", "lstm_tasnet._GatedEncoder.encoder_relu", "lstm_tasnet._GatedEncoder.encoder_sig"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.sigmoid"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "relu_out", "=", "torch", ".", "relu", "(", "self", ".", "encoder_relu", "(", "x", ")", ")", "\n", "sig_out", "=", "torch", ".", "sigmoid", "(", "self", ".", "encoder_sig", "(", "x", ")", ")", "\n", "return", "sig_out", "*", "relu_out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.__init__.register_model": [[34, 47], ["globals().update", "ValueError", "globals().keys", "custom_model.__name__.lower", "globals().keys", "globals", "globals", "globals"], "function", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.__init__.get": [[49, 65], ["isinstance", "ValueError", "to_get.get", "k.lower", "identifier.lower", "ValueError", "globals().items", "str", "globals", "str"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dcunet.BaseDCUNet.__init__": [[21, 45], ["asteroid_filterbanks.make_enc_dec", "dcunet.BaseDCUNet.masknet_class.default_architecture", "base_models.BaseEncoderMaskerDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.base.BaseDCUMaskNet.default_architecture", "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "architecture", ",", "\n", "stft_n_filters", "=", "1024", ",", "\n", "stft_kernel_size", "=", "1024", ",", "\n", "stft_stride", "=", "256", ",", "\n", "sample_rate", "=", "16000.0", ",", "\n", "**", "masknet_kwargs", ",", "\n", ")", ":", "\n", "        ", "self", ".", "architecture", "=", "architecture", "\n", "self", ".", "stft_n_filters", "=", "stft_n_filters", "\n", "self", ".", "stft_kernel_size", "=", "stft_kernel_size", "\n", "self", ".", "stft_stride", "=", "stft_stride", "\n", "self", ".", "masknet_kwargs", "=", "masknet_kwargs", "\n", "\n", "encoder", ",", "decoder", "=", "make_enc_dec", "(", "\n", "\"stft\"", ",", "\n", "n_filters", "=", "stft_n_filters", ",", "\n", "kernel_size", "=", "stft_kernel_size", ",", "\n", "stride", "=", "stft_stride", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", ")", "\n", "masker", "=", "self", ".", "masknet_class", ".", "default_architecture", "(", "architecture", ",", "**", "masknet_kwargs", ")", "\n", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "masker", ",", "decoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dcunet.BaseDCUNet.forward_encoder": [[46, 49], ["dcunet.BaseDCUNet.encoder", "asteroid_filterbanks.transforms.to_torch_complex"], "methods", ["None"], ["", "def", "forward_encoder", "(", "self", ",", "wav", ")", ":", "\n", "        ", "tf_rep", "=", "self", ".", "encoder", "(", "wav", ")", "\n", "return", "to_torch_complex", "(", "tf_rep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dcunet.BaseDCUNet.apply_masks": [[50, 53], ["asteroid_filterbanks.transforms.from_torch_complex", "tf_rep.unsqueeze"], "methods", ["None"], ["", "def", "apply_masks", "(", "self", ",", "tf_rep", ",", "est_masks", ")", ":", "\n", "        ", "masked_tf_rep", "=", "est_masks", "*", "tf_rep", ".", "unsqueeze", "(", "1", ")", "\n", "return", "from_torch_complex", "(", "masked_tf_rep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dcunet.BaseDCUNet.get_model_args": [[54, 65], ["None"], "methods", ["None"], ["", "def", "get_model_args", "(", "self", ")", ":", "\n", "        ", "\"\"\"Arguments needed to re-instantiate the model.\"\"\"", "\n", "model_args", "=", "{", "\n", "\"architecture\"", ":", "self", ".", "architecture", ",", "\n", "\"stft_n_filters\"", ":", "self", ".", "stft_n_filters", ",", "\n", "\"stft_kernel_size\"", ":", "self", ".", "stft_kernel_size", ",", "\n", "\"stft_stride\"", ":", "self", ".", "stft_stride", ",", "\n", "\"sample_rate\"", ":", "self", ".", "sample_rate", ",", "\n", "**", "self", ".", "masknet_kwargs", ",", "\n", "}", "\n", "return", "model_args", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dccrnet.DCCRNet.__init__": [[24, 34], ["masknet_kwargs.setdefault", "dcunet.BaseDCUNet.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "*", "args", ",", "stft_n_filters", "=", "512", ",", "stft_kernel_size", "=", "400", ",", "stft_stride", "=", "100", ",", "**", "masknet_kwargs", "\n", ")", ":", "\n", "        ", "masknet_kwargs", ".", "setdefault", "(", "\"n_freqs\"", ",", "stft_n_filters", "//", "2", ")", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "*", "args", ",", "\n", "stft_n_filters", "=", "stft_n_filters", ",", "\n", "stft_kernel_size", "=", "stft_kernel_size", ",", "\n", "stft_stride", "=", "stft_stride", ",", "\n", "**", "masknet_kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dccrnet.DCCRNet.forward_encoder": [[36, 40], ["dccrnet.DCCRNet.encoder", "asteroid_filterbanks.transforms.to_torch_complex"], "methods", ["None"], ["", "def", "forward_encoder", "(", "self", ",", "wav", ")", ":", "\n", "        ", "tf_rep", "=", "self", ".", "encoder", "(", "wav", ")", "\n", "# Remove Nyquist frequency bin", "\n", "return", "to_torch_complex", "(", "tf_rep", ")", "[", "...", ",", ":", "-", "1", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dccrnet.DCCRNet.apply_masks": [[41, 45], ["asteroid_filterbanks.transforms.from_torch_complex", "tf_rep.unsqueeze", "torch.nn.functional.pad"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad"], ["", "def", "apply_masks", "(", "self", ",", "tf_rep", ",", "est_masks", ")", ":", "\n", "        ", "masked_tf_rep", "=", "est_masks", "*", "tf_rep", ".", "unsqueeze", "(", "1", ")", "\n", "# Pad Nyquist frequency bin", "\n", "return", "from_torch_complex", "(", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "masked_tf_rep", ",", "[", "0", ",", "0", ",", "0", ",", "1", "]", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.SuDORMRFNet.__init__": [[38, 84], ["asteroid_filterbanks.make_enc_dec", "sudormrf._Padder", "masknn.SuDORMRF", "base_models.BaseEncoderMaskerDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "n_src", ",", "\n", "bn_chan", "=", "128", ",", "\n", "num_blocks", "=", "16", ",", "\n", "upsampling_depth", "=", "4", ",", "\n", "mask_act", "=", "\"softmax\"", ",", "\n", "in_chan", "=", "None", ",", "\n", "fb_name", "=", "\"free\"", ",", "\n", "kernel_size", "=", "21", ",", "\n", "n_filters", "=", "512", ",", "\n", "stride", "=", "None", ",", "\n", "sample_rate", "=", "8000", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", ":", "\n", "# Need the encoder to determine the number of input channels", "\n", "        ", "stride", "=", "kernel_size", "//", "2", "if", "not", "stride", "else", "stride", "\n", "enc", ",", "dec", "=", "make_enc_dec", "(", "\n", "fb_name", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "n_filters", "=", "n_filters", ",", "\n", "stride", "=", "kernel_size", "//", "2", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "padding", "=", "kernel_size", "//", "2", ",", "\n", "output_padding", "=", "(", "kernel_size", "//", "2", ")", "-", "1", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", "\n", "n_feats", "=", "enc", ".", "n_feats_out", "\n", "enc", "=", "_Padder", "(", "enc", ",", "upsampling_depth", "=", "upsampling_depth", ",", "kernel_size", "=", "kernel_size", ")", "\n", "\n", "if", "in_chan", "is", "not", "None", ":", "\n", "            ", "assert", "in_chan", "==", "n_feats", ",", "(", "\n", "\"Number of filterbank output channels\"", "\n", "\" and number of input channels should \"", "\n", "\"be the same. Received \"", "\n", "f\"{n_feats} and {in_chan}\"", "\n", ")", "\n", "", "masker", "=", "SuDORMRF", "(", "\n", "n_feats", ",", "\n", "n_src", ",", "\n", "bn_chan", "=", "bn_chan", ",", "\n", "num_blocks", "=", "num_blocks", ",", "\n", "upsampling_depth", "=", "upsampling_depth", ",", "\n", "mask_act", "=", "mask_act", ",", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "enc", ",", "masker", ",", "dec", ",", "encoder_activation", "=", "\"relu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.SuDORMRFImprovedNet.__init__": [[112, 159], ["asteroid_filterbanks.make_enc_dec", "sudormrf._Padder", "masknn.SuDORMRFImproved", "base_models.BaseEncoderMaskerDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "n_src", ",", "\n", "bn_chan", "=", "128", ",", "\n", "num_blocks", "=", "16", ",", "\n", "upsampling_depth", "=", "4", ",", "\n", "mask_act", "=", "\"relu\"", ",", "\n", "in_chan", "=", "None", ",", "\n", "fb_name", "=", "\"free\"", ",", "\n", "kernel_size", "=", "21", ",", "\n", "n_filters", "=", "512", ",", "\n", "stride", "=", "None", ",", "\n", "sample_rate", "=", "8000", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", ":", "\n", "        ", "stride", "=", "kernel_size", "//", "2", "if", "not", "stride", "else", "stride", "\n", "# Need the encoder to determine the number of input channels", "\n", "enc", ",", "dec", "=", "make_enc_dec", "(", "\n", "fb_name", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "n_filters", "=", "n_filters", ",", "\n", "stride", "=", "stride", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "padding", "=", "kernel_size", "//", "2", ",", "\n", "output_padding", "=", "(", "kernel_size", "//", "2", ")", "-", "1", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", "\n", "n_feats", "=", "enc", ".", "n_feats_out", "\n", "enc", "=", "_Padder", "(", "enc", ",", "upsampling_depth", "=", "upsampling_depth", ",", "kernel_size", "=", "kernel_size", ")", "\n", "\n", "if", "in_chan", "is", "not", "None", ":", "\n", "            ", "assert", "in_chan", "==", "n_feats", ",", "(", "\n", "\"Number of filterbank output channels\"", "\n", "\" and number of input channels should \"", "\n", "\"be the same. Received \"", "\n", "f\"{n_feats} and {in_chan}\"", "\n", ")", "\n", "\n", "", "masker", "=", "SuDORMRFImproved", "(", "\n", "n_feats", ",", "\n", "n_src", ",", "\n", "bn_chan", "=", "bn_chan", ",", "\n", "num_blocks", "=", "num_blocks", ",", "\n", "upsampling_depth", "=", "upsampling_depth", ",", "\n", "mask_act", "=", "mask_act", ",", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "enc", ",", "masker", ",", "dec", ",", "encoder_activation", "=", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf._Padder.__init__": [[162, 176], ["torch.nn.Module.__init__", "getattr", "abs", "math.gcd"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "encoder", ",", "upsampling_depth", "=", "4", ",", "kernel_size", "=", "21", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "upsampling_depth", "=", "upsampling_depth", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "\n", "# Appropriate padding is needed for arbitrary lengths", "\n", "self", ".", "lcm", "=", "abs", "(", "self", ".", "kernel_size", "//", "2", "*", "2", "**", "self", ".", "upsampling_depth", ")", "//", "math", ".", "gcd", "(", "\n", "self", ".", "kernel_size", "//", "2", ",", "2", "**", "self", ".", "upsampling_depth", "\n", ")", "\n", "\n", "# For serialize", "\n", "self", ".", "filterbank", "=", "self", ".", "encoder", ".", "filterbank", "\n", "self", ".", "sample_rate", "=", "getattr", "(", "self", ".", "encoder", ".", "filterbank", ",", "\"sample_rate\"", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf._Padder.forward": [[177, 180], ["sudormrf.pad", "sudormrf._Padder.encoder"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "pad", "(", "x", ",", "self", ".", "lcm", ")", "\n", "return", "self", ".", "encoder", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad": [[182, 193], ["int", "torch.zeros", "torch.cat", "list"], "function", ["None"], ["", "", "@", "script_if_tracing", "\n", "def", "pad", "(", "x", ",", "lcm", ":", "int", ")", ":", "\n", "    ", "values_to_pad", "=", "int", "(", "x", ".", "shape", "[", "-", "1", "]", ")", "%", "lcm", "\n", "if", "values_to_pad", ":", "\n", "        ", "appropriate_shape", "=", "x", ".", "shape", "\n", "padding", "=", "torch", ".", "zeros", "(", "\n", "list", "(", "appropriate_shape", "[", ":", "-", "1", "]", ")", "+", "[", "lcm", "-", "values_to_pad", "]", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", "\n", ")", "\n", "padded_x", "=", "torch", ".", "cat", "(", "[", "x", ",", "padding", "]", ",", "dim", "=", "-", "1", ")", "\n", "return", "padded_x", "\n", "", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publish_test.populate_wham_dir": [[10, 17], ["os.makedirs", "os.path.join", "open", "json.dump", "os.path.join", "dict"], "function", ["None"], ["def", "populate_wham_dir", "(", "path", ")", ":", "\n", "    ", "wham_files", "=", "[", "\"s1\"", ",", "\"s2\"", ",", "\"noise\"", ",", "\"mix_single\"", ",", "\"mix_clean\"", ",", "\"mix_both\"", "]", "\n", "os", ".", "makedirs", "(", "path", ",", "exist_ok", "=", "True", ")", "\n", "for", "source", "in", "wham_files", ":", "\n", "        ", "json_file", "=", "os", ".", "path", ".", "join", "(", "path", ",", "source", "+", "\".json\"", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "json_file", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "dict", "(", ")", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publish_test.test_upload": [[19, 57], ["pytest.mark.skipif", "os.makedirs", "publish_test.populate_wham_dir", "asteroid.data.wham_dataset.WhamDataset", "asteroid.models.ConvTasNet", "asteroid.models.ConvTasNet.serialize", "model.serialize.update", "asteroid.models.save_publishable", "os.getenv", "asteroid.data.wham_dataset.WhamDataset.get_infos", "asteroid.models.upload_publishable", "zen.remove_deposition", "shutil.rmtree", "os.getenv", "current.json", "current.json"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publish_test.populate_wham_dir", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.upload_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.zenodo.Zenodo.remove_deposition"], ["", "", "", "@", "pytest", ".", "mark", ".", "skipif", "(", "os", ".", "getenv", "(", "\"ACCESS_TOKEN\"", ",", "None", ")", "is", "None", ",", "reason", "=", "\"Require private key\"", ")", "\n", "def", "test_upload", "(", ")", ":", "\n", "# Make dirs", "\n", "    ", "os", ".", "makedirs", "(", "\"tmp/publish_dir\"", ",", "exist_ok", "=", "True", ")", "\n", "populate_wham_dir", "(", "\"tmp/wham\"", ")", "\n", "\n", "# Dataset and NN", "\n", "train_set", "=", "WhamDataset", "(", "\"tmp/wham\"", ",", "task", "=", "\"sep_clean\"", ")", "\n", "model", "=", "ConvTasNet", "(", "\n", "n_src", "=", "2", ",", "n_repeats", "=", "2", ",", "n_blocks", "=", "2", ",", "bn_chan", "=", "16", ",", "hid_chan", "=", "4", ",", "skip_chan", "=", "8", ",", "n_filters", "=", "32", "\n", ")", "\n", "\n", "# Save publishable", "\n", "model_conf", "=", "model", ".", "serialize", "(", ")", "\n", "model_conf", ".", "update", "(", "train_set", ".", "get_infos", "(", ")", ")", "\n", "save_publishable", "(", "\"tmp/publish_dir\"", ",", "model_conf", ",", "metrics", "=", "{", "}", ",", "train_conf", "=", "{", "}", ")", "\n", "\n", "# Upload", "\n", "token", "=", "os", ".", "getenv", "(", "\"ACCESS_TOKEN\"", ")", "\n", "if", "token", ":", "# ACESS_TOKEN is not available on forks.", "\n", "        ", "zen", ",", "current", "=", "upload_publishable", "(", "\n", "\"tmp/publish_dir\"", ",", "\n", "uploader", "=", "\"Manuel Pariente\"", ",", "\n", "affiliation", "=", "\"INRIA\"", ",", "\n", "use_sandbox", "=", "True", ",", "\n", "unit_test", "=", "True", ",", "# Remove this argument and monkeypatch `input()`", "\n", "git_username", "=", "\"mpariente\"", ",", "\n", ")", "\n", "\n", "# Assert metadata is correct", "\n", "meta", "=", "current", ".", "json", "(", ")", "[", "\"metadata\"", "]", "\n", "assert", "meta", "[", "\"creators\"", "]", "[", "0", "]", "[", "\"name\"", "]", "==", "\"Manuel Pariente\"", "\n", "assert", "meta", "[", "\"creators\"", "]", "[", "0", "]", "[", "\"affiliation\"", "]", "==", "\"INRIA\"", "\n", "assert", "\"asteroid-models\"", "in", "[", "d", "[", "\"identifier\"", "]", "for", "d", "in", "meta", "[", "\"communities\"", "]", "]", "\n", "\n", "# Clean up", "\n", "zen", ".", "remove_deposition", "(", "current", ".", "json", "(", ")", "[", "\"id\"", "]", ")", "\n", "shutil", ".", "rmtree", "(", "\"tmp/wham\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_set_sample_rate_raises_warning": [[30, 34], ["asteroid.models.base_models.BaseModel", "pytest.warns"], "function", ["None"], ["def", "test_set_sample_rate_raises_warning", "(", ")", ":", "\n", "    ", "model", "=", "BaseModel", "(", "sample_rate", "=", "8000.0", ")", "\n", "with", "pytest", ".", "warns", "(", "UserWarning", ")", ":", "\n", "        ", "model", ".", "sample_rate", "=", "16000.0", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_no_sample_rate_raises": [[36, 39], ["pytest.raises", "asteroid.models.base_models.BaseModel"], "function", ["None"], ["", "", "def", "test_no_sample_rate_raises", "(", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "        ", "BaseModel", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_multichannel_model_loading": [[41, 57], ["MCModel", "MCModel.serialize", "MCModel.from_pretrained", "super().__init__"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["", "", "def", "test_multichannel_model_loading", "(", ")", ":", "\n", "    ", "class", "MCModel", "(", "BaseModel", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ",", "sample_rate", "=", "8000.0", ",", "in_channels", "=", "2", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", "sample_rate", "=", "sample_rate", ",", "in_channels", "=", "in_channels", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "x", "\n", "\n", "", "def", "get_model_args", "(", "self", ")", ":", "\n", "            ", "return", "{", "\"sample_rate\"", ":", "self", ".", "sample_rate", ",", "\"in_channels\"", ":", "self", ".", "in_channels", "}", "\n", "\n", "", "", "model", "=", "MCModel", "(", ")", "\n", "model_conf", "=", "model", ".", "serialize", "(", ")", "\n", "\n", "new_model", "=", "MCModel", ".", "from_pretrained", "(", "model_conf", ")", "\n", "assert", "model", ".", "in_channels", "==", "new_model", ".", "in_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_convtasnet_sep": [[59, 91], ["asteroid.models.ConvTasNet", "torch.rand", "asteroid.models.ConvTasNet.separate", "isinstance", "numpy.random.randn().astype", "asteroid.models.ConvTasNet.separate", "isinstance", "soundfile.write", "asteroid.models.ConvTasNet.separate", "soundfile.write", "asteroid.models.ConvTasNet.separate", "pytest.warns", "asteroid.models.ConvTasNet.separate", "pytest.raises", "asteroid.models.ConvTasNet.separate", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate"], ["", "def", "test_convtasnet_sep", "(", ")", ":", "\n", "    ", "nnet", "=", "ConvTasNet", "(", "\n", "n_src", "=", "2", ",", "\n", "n_repeats", "=", "2", ",", "\n", "n_blocks", "=", "3", ",", "\n", "bn_chan", "=", "16", ",", "\n", "hid_chan", "=", "4", ",", "\n", "skip_chan", "=", "8", ",", "\n", "n_filters", "=", "32", ",", "\n", ")", "\n", "# Test torch input", "\n", "wav", "=", "torch", ".", "rand", "(", "1", ",", "800", ")", "\n", "out", "=", "nnet", ".", "separate", "(", "wav", ")", "\n", "assert", "isinstance", "(", "out", ",", "torch", ".", "Tensor", ")", "\n", "# Test numpy input", "\n", "wav", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "800", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "out", "=", "nnet", ".", "separate", "(", "wav", ")", "\n", "assert", "isinstance", "(", "out", ",", "np", ".", "ndarray", ")", "\n", "# Test str input", "\n", "sf", ".", "write", "(", "\"tmp.wav\"", ",", "wav", "[", "0", "]", ",", "8000", ")", "\n", "nnet", ".", "separate", "(", "\"tmp.wav\"", ")", "\n", "# Warning when overwriting", "\n", "with", "pytest", ".", "warns", "(", "UserWarning", ")", ":", "\n", "        ", "nnet", ".", "separate", "(", "\"tmp.wav\"", ")", "\n", "\n", "# Test with bad samplerate", "\n", "", "sf", ".", "write", "(", "\"tmp.wav\"", ",", "wav", "[", "0", "]", ",", "16000", ")", "\n", "# Raises", "\n", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "        ", "nnet", ".", "separate", "(", "\"tmp.wav\"", ",", "force_overwrite", "=", "True", ")", "\n", "# Resamples", "\n", "", "nnet", ".", "separate", "(", "\"tmp.wav\"", ",", "force_overwrite", "=", "True", ",", "resample", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_save_and_load_convtasnet": [[93, 107], ["pytest.mark.parametrize", "pytest.mark.parametrize", "models_test._default_test_model", "asteroid.models.ConvTasNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"fb\"", ",", "[", "\"free\"", ",", "\"stft\"", ",", "\"analytic_free\"", ",", "\"param_sinc\"", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"sample_rate\"", ",", "[", "8000.0", ",", "16000.0", "]", ")", "\n", "def", "test_save_and_load_convtasnet", "(", "fb", ",", "sample_rate", ")", ":", "\n", "    ", "_default_test_model", "(", "\n", "ConvTasNet", "(", "\n", "n_src", "=", "2", ",", "\n", "n_repeats", "=", "2", ",", "\n", "n_blocks", "=", "2", ",", "\n", "bn_chan", "=", "16", ",", "\n", "hid_chan", "=", "4", ",", "\n", "skip_chan", "=", "8", ",", "\n", "n_filters", "=", "32", ",", "\n", "fb_name", "=", "fb", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_dprnntasnet_sep": [[111, 130], ["pytest.mark.parametrize", "asteroid.models.DPRNNTasNet", "torch.rand", "asteroid.models.DPRNNTasNet.separate", "isinstance", "numpy.random.randn().astype", "asteroid.models.DPRNNTasNet.separate", "isinstance", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"use_mulcat\"", ",", "[", "True", ",", "False", "]", ")", "\n", "def", "test_dprnntasnet_sep", "(", "use_mulcat", ")", ":", "\n", "    ", "nnet", "=", "DPRNNTasNet", "(", "\n", "n_src", "=", "2", ",", "\n", "n_repeats", "=", "2", ",", "\n", "bn_chan", "=", "16", ",", "\n", "hid_size", "=", "4", ",", "\n", "chunk_size", "=", "20", ",", "\n", "n_filters", "=", "32", ",", "\n", "use_mulcat", "=", "use_mulcat", ",", "\n", ")", "\n", "# Test torch input", "\n", "wav", "=", "torch", ".", "rand", "(", "1", ",", "800", ")", "\n", "out", "=", "nnet", ".", "separate", "(", "wav", ")", "\n", "assert", "isinstance", "(", "out", ",", "torch", ".", "Tensor", ")", "\n", "# Test numpy input", "\n", "wav", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "800", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "out", "=", "nnet", ".", "separate", "(", "wav", ")", "\n", "assert", "isinstance", "(", "out", ",", "np", ".", "ndarray", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_dprnntasnet_sep_from_hf": [[132, 135], ["asteroid.models.DPRNNTasNet.from_pretrained", "isinstance"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained"], ["", "def", "test_dprnntasnet_sep_from_hf", "(", ")", ":", "\n", "    ", "model", "=", "DPRNNTasNet", ".", "from_pretrained", "(", "HF_EXAMPLE_MODEL_IDENTIFER", ")", "\n", "assert", "isinstance", "(", "model", ",", "DPRNNTasNet", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_save_and_load_dprnn": [[137, 152], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "models_test._default_test_model", "asteroid.models.DPRNNTasNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"fb\"", ",", "[", "\"free\"", ",", "\"stft\"", ",", "\"analytic_free\"", ",", "\"param_sinc\"", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"sample_rate\"", ",", "[", "8000.0", ",", "16000.0", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"use_mulcat\"", ",", "[", "True", ",", "False", "]", ")", "\n", "def", "test_save_and_load_dprnn", "(", "fb", ",", "sample_rate", ",", "use_mulcat", ")", ":", "\n", "    ", "_default_test_model", "(", "\n", "DPRNNTasNet", "(", "\n", "n_src", "=", "2", ",", "\n", "n_repeats", "=", "2", ",", "\n", "bn_chan", "=", "16", ",", "\n", "hid_size", "=", "4", ",", "\n", "chunk_size", "=", "20", ",", "\n", "n_filters", "=", "32", ",", "\n", "fb_name", "=", "fb", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", "use_mulcat", "=", "use_mulcat", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_save_and_load_tasnet": [[156, 168], ["pytest.mark.parametrize", "pytest.mark.parametrize", "models_test._default_test_model", "asteroid.models.LSTMTasNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"fb\"", ",", "[", "\"free\"", ",", "\"stft\"", ",", "\"analytic_free\"", ",", "\"param_sinc\"", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"sample_rate\"", ",", "[", "8000.0", ",", "16000.0", "]", ")", "\n", "def", "test_save_and_load_tasnet", "(", "fb", ",", "sample_rate", ")", ":", "\n", "    ", "_default_test_model", "(", "\n", "LSTMTasNet", "(", "\n", "n_src", "=", "2", ",", "\n", "hid_size", "=", "4", ",", "\n", "n_layers", "=", "1", ",", "\n", "n_filters", "=", "32", ",", "\n", "dropout", "=", "0.0", ",", "\n", "fb_name", "=", "fb", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_sudormrf": [[172, 183], ["pytest.mark.parametrize", "models_test._default_test_model", "asteroid.models.SuDORMRFNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"sample_rate\"", ",", "[", "8000.0", ",", "16000.0", "]", ")", "\n", "def", "test_sudormrf", "(", "sample_rate", ")", ":", "\n", "    ", "_default_test_model", "(", "\n", "SuDORMRFNet", "(", "\n", "2", ",", "\n", "bn_chan", "=", "10", ",", "\n", "num_blocks", "=", "4", ",", "\n", "upsampling_depth", "=", "2", ",", "\n", "kernel_size", "=", "21", ",", "\n", "n_filters", "=", "12", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_sudormrf_imp": [[187, 198], ["pytest.mark.parametrize", "models_test._default_test_model", "asteroid.models.SuDORMRFImprovedNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"sample_rate\"", ",", "[", "8000.0", ",", "16000.0", "]", ")", "\n", "def", "test_sudormrf_imp", "(", "sample_rate", ")", ":", "\n", "    ", "_default_test_model", "(", "\n", "SuDORMRFImprovedNet", "(", "\n", "2", ",", "\n", "bn_chan", "=", "10", ",", "\n", "num_blocks", "=", "4", ",", "\n", "upsampling_depth", "=", "2", ",", "\n", "kernel_size", "=", "21", ",", "\n", "n_filters", "=", "12", ",", "\n", "sample_rate", "=", "sample_rate", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_dptnet": [[202, 207], ["pytest.mark.filterwarnings", "pytest.mark.parametrize", "pytest.mark.parametrize", "models_test._default_test_model", "asteroid.models.DPTNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model"], ["", "@", "pytest", ".", "mark", ".", "filterwarnings", "(", "\"ignore: DPTransformer input dim\"", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"fb\"", ",", "[", "\"free\"", ",", "\"stft\"", ",", "\"analytic_free\"", ",", "\"param_sinc\"", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"sample_rate\"", ",", "[", "8000.0", ",", "16000.0", "]", ")", "\n", "def", "test_dptnet", "(", "fb", ",", "sample_rate", ")", ":", "\n", "    ", "_default_test_model", "(", "DPTNet", "(", "2", ",", "ff_hid", "=", "10", ",", "chunk_size", "=", "4", ",", "n_repeats", "=", "2", ",", "sample_rate", "=", "sample_rate", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_fasnet": [[209, 214], ["pytest.mark.parametrize", "models_test._default_test_model", "asteroid.models.fasnet.FasNetTAC", "torch.randn"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"use_tac\"", ",", "[", "True", ",", "False", "]", ")", "\n", "def", "test_fasnet", "(", "use_tac", ")", ":", "\n", "    ", "_default_test_model", "(", "\n", "FasNetTAC", "(", "n_src", "=", "2", ",", "feature_dim", "=", "8", ",", "hidden_dim", "=", "10", ",", "n_layers", "=", "2", ",", "use_tac", "=", "use_tac", ")", ",", "\n", "test_input", "=", "torch", ".", "randn", "(", "3", ",", "2", ",", "8372", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_dcunet": [[217, 239], ["asteroid_filterbanks.make_enc_dec", "models_test._default_test_model", "models_test._default_test_model", "models_test._default_test_model", "models_test._default_test_model", "models_test._default_test_model", "asteroid.models.DCUNet().masker", "asteroid.models.DCUNet().masker", "asteroid.models.DCUNet().masker", "asteroid.models.DCUNet", "asteroid.models.DCUNet", "asteroid.models.DCUNet", "asteroid.models.DCUNet", "asteroid.models.DCUNet", "torch.zeros", "pytest.raises", "asteroid.models.DCUNet().masker", "torch.zeros", "torch.zeros", "pytest.raises", "asteroid.models.DCUNet().masker", "istft", "asteroid.models.DCUNet", "torch.zeros", "asteroid.models.DCUNet", "asteroid.models.DCUNet", "torch.zeros", "torch.zeros", "asteroid.models.DCUNet", "asteroid.models.DCUNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft"], ["", "def", "test_dcunet", "(", ")", ":", "\n", "    ", "n_fft", "=", "1024", "\n", "_", ",", "istft", "=", "make_enc_dec", "(", "\n", "\"stft\"", ",", "n_filters", "=", "n_fft", ",", "kernel_size", "=", "1024", ",", "stride", "=", "256", ",", "sample_rate", "=", "16000", "\n", ")", "\n", "input_samples", "=", "istft", "(", "torch", ".", "zeros", "(", "(", "n_fft", "+", "2", ",", "17", ")", ")", ")", ".", "shape", "[", "0", "]", "\n", "_default_test_model", "(", "DCUNet", "(", "\"DCUNet-10\"", ")", ",", "input_samples", "=", "input_samples", ")", "\n", "_default_test_model", "(", "DCUNet", "(", "\"DCUNet-16\"", ")", ",", "input_samples", "=", "input_samples", ")", "\n", "_default_test_model", "(", "DCUNet", "(", "\"DCUNet-20\"", ")", ",", "input_samples", "=", "input_samples", ")", "\n", "_default_test_model", "(", "DCUNet", "(", "\"Large-DCUNet-20\"", ")", ",", "input_samples", "=", "input_samples", ")", "\n", "_default_test_model", "(", "DCUNet", "(", "\"DCUNet-10\"", ",", "n_src", "=", "2", ")", ",", "input_samples", "=", "input_samples", ")", "\n", "\n", "# DCUMaskNet should fail with wrong freqency dimensions", "\n", "DCUNet", "(", "\"mini\"", ")", ".", "masker", "(", "torch", ".", "zeros", "(", "(", "1", ",", "9", ",", "17", ")", ",", "dtype", "=", "torch", ".", "complex64", ")", ")", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "        ", "DCUNet", "(", "\"mini\"", ")", ".", "masker", "(", "torch", ".", "zeros", "(", "(", "1", ",", "42", ",", "17", ")", ",", "dtype", "=", "torch", ".", "complex64", ")", ")", "\n", "\n", "# DCUMaskNet should fail with wrong time dimensions if fix_length_mode is not used", "\n", "", "DCUNet", "(", "\"mini\"", ",", "fix_length_mode", "=", "\"pad\"", ")", ".", "masker", "(", "torch", ".", "zeros", "(", "(", "1", ",", "9", ",", "17", ")", ",", "dtype", "=", "torch", ".", "complex64", ")", ")", "\n", "DCUNet", "(", "\"mini\"", ",", "fix_length_mode", "=", "\"trim\"", ")", ".", "masker", "(", "torch", ".", "zeros", "(", "(", "1", ",", "9", ",", "17", ")", ",", "dtype", "=", "torch", ".", "complex64", ")", ")", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "        ", "DCUNet", "(", "\"mini\"", ")", ".", "masker", "(", "torch", ".", "zeros", "(", "(", "1", ",", "9", ",", "16", ")", ",", "dtype", "=", "torch", ".", "complex64", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_dccrnet": [[241, 252], ["asteroid_filterbanks.make_enc_dec", "models_test._default_test_model", "models_test._default_test_model", "asteroid.models.DCCRNet().masker", "asteroid.models.DCCRNet", "asteroid.models.DCCRNet", "torch.zeros", "pytest.raises", "asteroid.models.DCCRNet().masker", "istft", "asteroid.models.DCCRNet", "torch.zeros", "torch.zeros", "asteroid.models.DCCRNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft"], ["", "", "def", "test_dccrnet", "(", ")", ":", "\n", "    ", "n_fft", "=", "512", "\n", "_", ",", "istft", "=", "make_enc_dec", "(", "\"stft\"", ",", "n_filters", "=", "n_fft", ",", "kernel_size", "=", "400", ",", "stride", "=", "100", ",", "sample_rate", "=", "16000", ")", "\n", "input_samples", "=", "istft", "(", "torch", ".", "zeros", "(", "(", "n_fft", "+", "2", ",", "16", ")", ")", ")", ".", "shape", "[", "0", "]", "\n", "_default_test_model", "(", "DCCRNet", "(", "\"DCCRN-CL\"", ")", ",", "input_samples", "=", "input_samples", ")", "\n", "_default_test_model", "(", "DCCRNet", "(", "\"DCCRN-CL\"", ",", "n_src", "=", "2", ")", ",", "input_samples", "=", "input_samples", ")", "\n", "\n", "# DCCRMaskNet should fail with wrong input dimensions", "\n", "DCCRNet", "(", "\"mini\"", ")", ".", "masker", "(", "torch", ".", "zeros", "(", "(", "1", ",", "256", ",", "3", ")", ",", "dtype", "=", "torch", ".", "complex64", ")", ")", "\n", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "        ", "DCCRNet", "(", "\"mini\"", ")", ".", "masker", "(", "torch", ".", "zeros", "(", "(", "1", ",", "42", ",", "3", ")", ",", "dtype", "=", "torch", ".", "complex64", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test._default_test_model": [[254, 268], ["model.serialize", "model.__class__.from_pretrained", "torch.testing.assert_allclose", "model_conf[].pop", "model.__class__.from_pretrained", "model.__class__.from_pretrained", "torch.randn", "model", "model.__class__.from_pretrained."], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained"], ["", "", "def", "_default_test_model", "(", "model", ",", "input_samples", "=", "801", ",", "test_input", "=", "None", ")", ":", "\n", "    ", "if", "test_input", "is", "None", ":", "\n", "        ", "test_input", "=", "torch", ".", "randn", "(", "1", ",", "input_samples", ")", "\n", "\n", "", "model_conf", "=", "model", ".", "serialize", "(", ")", "\n", "reconstructed_model", "=", "model", ".", "__class__", ".", "from_pretrained", "(", "model_conf", ")", "\n", "assert_allclose", "(", "model", "(", "test_input", ")", ",", "reconstructed_model", "(", "test_input", ")", ")", "\n", "\n", "# Load with and without SR", "\n", "sr", "=", "model_conf", "[", "\"model_args\"", "]", ".", "pop", "(", "\"sample_rate\"", ")", "\n", "reconstructed_model_nosr", "=", "model", ".", "__class__", ".", "from_pretrained", "(", "model_conf", ")", "\n", "reconstructed_model", "=", "model", ".", "__class__", ".", "from_pretrained", "(", "model_conf", ",", "sample_rate", "=", "sr", ")", "\n", "\n", "assert", "reconstructed_model", ".", "sample_rate", "==", "model", ".", "sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_get": [[270, 276], ["pytest.mark.parametrize", "asteroid.models.get"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"model\"", ",", "[", "LSTMTasNet", ",", "ConvTasNet", ",", "DPRNNTasNet", ",", "DPTNet", ",", "SuDORMRFImprovedNet", ",", "SuDORMRFNet", "]", "\n", ")", "\n", "def", "test_get", "(", "model", ")", ":", "\n", "    ", "retrieved", "=", "models", ".", "get", "(", "model", ".", "__name__", ")", "\n", "assert", "retrieved", "==", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_get_errors": [[278, 283], ["pytest.mark.parametrize", "pytest.raises", "asteroid.models.get", "object"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"wrong\"", ",", "[", "\"wrong_string\"", ",", "12", ",", "object", "(", ")", "]", ")", "\n", "def", "test_get_errors", "(", "wrong", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# Should raise for anything not a Optimizer instance + unknown string", "\n", "        ", "models", ".", "get", "(", "wrong", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_register": [[285, 296], ["asteroid.models.register_model", "asteroid.models.get", "pytest.raises", "asteroid.models.register_model", "super().__init__"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.__init__.register_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.__init__.register_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["", "", "def", "test_register", "(", ")", ":", "\n", "    ", "class", "Custom", "(", "BaseModel", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "", "", "models", ".", "register_model", "(", "Custom", ")", "\n", "cls", "=", "models", ".", "get", "(", "\"Custom\"", ")", "\n", "assert", "cls", "==", "Custom", "\n", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "models", ".", "register_model", "(", "models", ".", "DPRNNTasNet", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_show": [[298, 300], ["asteroid.show_available_models"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.__init__.show_available_models"], ["", "", "def", "test_show", "(", ")", ":", "\n", "    ", "asteroid", ".", "show_available_models", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_available_models": [[302, 304], ["asteroid.available_models"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.__init__.available_models"], ["", "def", "test_available_models", "(", ")", ":", "\n", "    ", "all_models", "=", "asteroid", ".", "available_models", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_demask": [[306, 314], ["pytest.mark.parametrize", "asteroid.models.DeMask", "torch.randn", "asteroid.models.DeMask.serialize", "asteroid.models.DeMask.from_pretrained", "torch.testing.assert_allclose", "asteroid.models.DeMask.", "DeMask.from_pretrained."], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"fb\"", ",", "[", "\"free\"", ",", "\"stft\"", ",", "\"analytic_free\"", ",", "\"param_sinc\"", "]", ")", "\n", "def", "test_demask", "(", "fb", ")", ":", "\n", "    ", "model", "=", "DeMask", "(", "fb_name", "=", "fb", ")", "\n", "test_input", "=", "torch", ".", "randn", "(", "1", ",", "801", ")", "\n", "\n", "model_conf", "=", "model", ".", "serialize", "(", ")", "\n", "reconstructed_model", "=", "DeMask", ".", "from_pretrained", "(", "model_conf", ")", "\n", "assert_allclose", "(", "model", "(", "test_input", ")", ",", "reconstructed_model", "(", "test_input", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.models_test.test_separate": [[316, 330], ["asteroid.models.ConvTasNet", "torch.rand", "asteroid.dsp.LambdaOverlapAdd", "asteroid.separate.separate"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate"], ["", "def", "test_separate", "(", ")", ":", "\n", "    ", "nnet", "=", "ConvTasNet", "(", "\n", "n_src", "=", "2", ",", "\n", "n_repeats", "=", "2", ",", "\n", "n_blocks", "=", "3", ",", "\n", "bn_chan", "=", "16", ",", "\n", "hid_chan", "=", "4", ",", "\n", "skip_chan", "=", "8", ",", "\n", "n_filters", "=", "32", ",", "\n", ")", "\n", "# Test torch input", "\n", "wav", "=", "torch", ".", "rand", "(", "1", ",", "1", ",", "8000", ")", "\n", "model", "=", "LambdaOverlapAdd", "(", "nnet", ",", "None", ",", "window_size", "=", "1000", ")", "\n", "out", "=", "separate", "(", "model", ",", "wav", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask_test.test_forward": [[80, 106], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "asteroid.models.DeMask", "demask.eval.eval", "torch.no_grad", "demask.eval.", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "function", ["None"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"input_type\"", ",", "(", "\"mag\"", ",", "\"cat\"", ",", "\"reim\"", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"fb_name\"", ",", "(", "\"stft\"", ",", "\"free\"", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"output_type\"", ",", "(", "\"mag\"", ",", "\"reim\"", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"data\"", ",", "\n", "(", "\n", "(", "torch", ".", "rand", "(", "130", ",", "requires_grad", "=", "False", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "1", ",", "100", ",", "requires_grad", "=", "False", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "3", ",", "50", ",", "requires_grad", "=", "False", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "1", ",", "1", ",", "50", ",", "requires_grad", "=", "False", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "2", ",", "1", ",", "50", ",", "requires_grad", "=", "False", ")", "-", "0.5", ")", "*", "2", ",", "\n", ")", ",", "\n", ")", "\n", "def", "test_forward", "(", "input_type", ",", "output_type", ",", "fb_name", ",", "data", ")", ":", "\n", "    ", "demask", "=", "DeMask", "(", "\n", "input_type", "=", "input_type", ",", "\n", "output_type", "=", "output_type", ",", "\n", "fb_name", "=", "fb_name", ",", "\n", "hidden_dims", "=", "(", "16", ",", ")", ",", "\n", "kernel_size", "=", "8", ",", "\n", "n_filters", "=", "8", ",", "\n", "stride", "=", "4", ",", "\n", ")", "\n", "demask", "=", "demask", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "demask", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask_test.test_sample_rate": [[108, 111], ["asteroid.models.DeMask"], "function", ["None"], ["", "", "def", "test_sample_rate", "(", ")", ":", "\n", "    ", "demask", "=", "DeMask", "(", "hidden_dims", "=", "(", "16", ",", ")", ",", "kernel_size", "=", "8", ",", "n_filters", "=", "8", ",", "stride", "=", "4", ",", "sample_rate", "=", "9704", ")", "\n", "assert", "demask", ".", "sample_rate", "==", "9704", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.demask_test.test_get_model_args": [[113, 130], ["asteroid.models.DeMask", "asteroid.models.DeMask.get_model_args"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dcunet.BaseDCUNet.get_model_args"], ["", "def", "test_get_model_args", "(", ")", ":", "\n", "    ", "demask", "=", "DeMask", "(", ")", "\n", "expected", "=", "{", "\n", "\"activation\"", ":", "\"relu\"", ",", "\n", "\"dropout\"", ":", "0", ",", "\n", "\"fb_name\"", ":", "\"STFTFB\"", ",", "\n", "\"hidden_dims\"", ":", "(", "1024", ",", ")", ",", "\n", "\"input_type\"", ":", "\"mag\"", ",", "\n", "\"kernel_size\"", ":", "512", ",", "\n", "\"mask_act\"", ":", "\"relu\"", ",", "\n", "\"n_filters\"", ":", "512", ",", "\n", "\"norm_type\"", ":", "\"gLN\"", ",", "\n", "\"output_type\"", ":", "\"mag\"", ",", "\n", "\"sample_rate\"", ":", "16000", ",", "\n", "\"stride\"", ":", "256", ",", "\n", "}", "\n", "assert", "demask", ".", "get_model_args", "(", ")", "==", "expected", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.fasnet_test.test_fasnet": [[7, 28], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.rand", "torch.tensor", "asteroid.models.fasnet.FasNetTAC", "asteroid.models.fasnet.FasNetTAC.", "range"], "function", ["None"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"samples\"", ",", "[", "8372", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_mics\"", ",", "[", "1", ",", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"use_tac\"", ",", "[", "True", ",", "False", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"enc_dim\"", ",", "[", "4", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"feature_dim\"", ",", "[", "8", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"window\"", ",", "[", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"context\"", ",", "[", "3", "]", ")", "\n", "def", "test_fasnet", "(", "batch_size", ",", "n_mics", ",", "samples", ",", "n_src", ",", "use_tac", ",", "enc_dim", ",", "feature_dim", ",", "window", ",", "context", ")", ":", "\n", "    ", "mixture", "=", "torch", ".", "rand", "(", "(", "batch_size", ",", "n_mics", ",", "samples", ")", ")", "\n", "valid_mics", "=", "torch", ".", "tensor", "(", "[", "n_mics", "for", "x", "in", "range", "(", "batch_size", ")", "]", ")", "\n", "fasnet", "=", "FasNetTAC", "(", "\n", "n_src", ",", "\n", "use_tac", "=", "use_tac", ",", "\n", "enc_dim", "=", "enc_dim", ",", "\n", "feature_dim", "=", "feature_dim", ",", "\n", "window_ms", "=", "window", ",", "\n", "context_ms", "=", "context", ",", "\n", ")", "\n", "fasnet", "(", "mixture", ",", "valid_mics", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.xumx_test.test_forward": [[14, 46], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "asteroid.models.XUMX", "x_umx.eval.eval", "torch.no_grad", "x_umx.eval.", "torch.rand", "torch.rand"], "function", ["None"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"nb_channels\"", ",", "(", "1", ",", "2", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"sources\"", ",", "sources", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"bidirectional\"", ",", "(", "True", ",", "False", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"spec_power\"", ",", "(", "1", ",", "2", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"return_time_signals\"", ",", "(", "True", ",", "False", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"data\"", ",", "\n", "(", "\n", "torch", ".", "rand", "(", "3", ",", "2", ",", "44100", ",", "requires_grad", "=", "False", ")", ",", "\n", "torch", ".", "rand", "(", "1", ",", "2", ",", "2", "*", "44100", ",", "requires_grad", "=", "False", ")", ",", "\n", ")", ",", "\n", ")", "\n", "def", "test_forward", "(", "nb_channels", ",", "sources", ",", "bidirectional", ",", "spec_power", ",", "return_time_signals", ",", "data", ")", ":", "\n", "    ", "x_umx", "=", "XUMX", "(", "\n", "window_length", "=", "4096", ",", "\n", "input_mean", "=", "None", ",", "\n", "input_scale", "=", "None", ",", "\n", "nb_channels", "=", "nb_channels", ",", "\n", "hidden_size", "=", "128", ",", "\n", "nb_layers", "=", "2", ",", "\n", "in_chan", "=", "4096", ",", "\n", "n_hop", "=", "1024", ",", "\n", "sources", "=", "sources", ",", "\n", "max_bin", "=", "1000", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "sample_rate", "=", "44100", ",", "\n", "spec_power", "=", "spec_power", ",", "\n", "return_time_signals", "=", "return_time_signals", ",", "\n", ")", "\n", "x_umx", "=", "x_umx", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "x_umx", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.xumx_test.test_get_model_args": [[48, 68], ["asteroid.models.XUMX", "asteroid.models.XUMX.get_model_args"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.dcunet.BaseDCUNet.get_model_args"], ["", "", "def", "test_get_model_args", "(", ")", ":", "\n", "    ", "sources_tmp", "=", "[", "\"vocals\"", "]", "\n", "x_umx", "=", "XUMX", "(", "sources", "=", "sources_tmp", ",", "window_length", "=", "4096", ")", "\n", "expected", "=", "{", "\n", "\"window_length\"", ":", "4096", ",", "\n", "\"in_chan\"", ":", "4096", ",", "\n", "\"n_hop\"", ":", "1024", ",", "\n", "\"sample_rate\"", ":", "44100", ",", "\n", "\"sources\"", ":", "sources_tmp", ",", "\n", "\"hidden_size\"", ":", "512", ",", "\n", "\"nb_channels\"", ":", "2", ",", "\n", "\"input_mean\"", ":", "None", ",", "\n", "\"input_scale\"", ":", "None", ",", "\n", "\"max_bin\"", ":", "4096", "//", "2", "+", "1", ",", "\n", "\"nb_layers\"", ":", "3", ",", "\n", "\"bidirectional\"", ":", "True", ",", "\n", "\"spec_power\"", ":", "1", ",", "\n", "\"return_time_signals\"", ":", "False", ",", "\n", "}", "\n", "assert", "x_umx", ".", "get_model_args", "(", ")", "==", "expected", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.xumx_test.test_model_loading": [[70, 85], ["asteroid.models.XUMX", "model.eval.serialize", "asteroid.models.XUMX.from_pretrained", "torch.rand", "model.eval.eval", "new_model.eval.eval", "torch.allclose", "torch.no_grad", "model.eval.", "new_model.eval."], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained"], ["", "def", "test_model_loading", "(", ")", ":", "\n", "    ", "sources_tmp", "=", "[", "\"bass\"", ",", "\"drums\"", ",", "\"vocals\"", ",", "\"other\"", "]", "\n", "model", "=", "XUMX", "(", "sources", "=", "sources_tmp", ")", "\n", "\n", "model_conf", "=", "model", ".", "serialize", "(", ")", "\n", "\n", "new_model", "=", "XUMX", ".", "from_pretrained", "(", "model_conf", ")", "\n", "\n", "random_input", "=", "torch", ".", "rand", "(", "3", ",", "2", ",", "44100", ",", "requires_grad", "=", "False", ")", "\n", "model", "=", "model", ".", "eval", "(", ")", "\n", "new_model", "=", "new_model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "output1", "=", "model", "(", "random_input", ")", "\n", "output2", "=", "new_model", "(", "random_input", ")", "\n", "", "assert", "torch", ".", "allclose", "(", "output1", "[", "0", "]", ",", "output2", "[", "0", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.__init__": [[17, 20], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "optimizer", ")", ":", "\n", "        ", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "step_num", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.zero_grad": [[21, 23], ["schedulers.BaseScheduler.optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler._get_lr": [[24, 26], ["None"], "methods", ["None"], ["", "def", "_get_lr", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler._set_lr": [[27, 30], ["None"], "methods", ["None"], ["", "def", "_set_lr", "(", "self", ",", "lr", ")", ":", "\n", "        ", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "\"lr\"", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.step": [[31, 36], ["schedulers.BaseScheduler._get_lr", "schedulers.BaseScheduler._set_lr"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.DPTNetScheduler._get_lr", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler._set_lr"], ["", "", "def", "step", "(", "self", ",", "metrics", "=", "None", ",", "epoch", "=", "None", ")", ":", "\n", "        ", "\"\"\"Update step-wise learning rate before optimizer.step.\"\"\"", "\n", "self", ".", "step_num", "+=", "1", "\n", "lr", "=", "self", ".", "_get_lr", "(", ")", "\n", "self", ".", "_set_lr", "(", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict": [[37, 39], ["schedulers.BaseScheduler.__dict__.update"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "__dict__", ".", "update", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.state_dict": [[40, 42], ["schedulers.BaseScheduler.__dict__.items"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "key", ":", "value", "for", "key", ",", "value", "in", "self", ".", "__dict__", ".", "items", "(", ")", "if", "key", "!=", "\"optimizer\"", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.as_tensor": [[43, 51], ["range", "torch.tensor", "lr_list.append", "schedulers.BaseScheduler._get_lr"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.DPTNetScheduler._get_lr"], ["", "def", "as_tensor", "(", "self", ",", "start", "=", "0", ",", "stop", "=", "100_000", ")", ":", "\n", "        ", "\"\"\"Returns the scheduler values from start to stop.\"\"\"", "\n", "lr_list", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "start", ",", "stop", ")", ":", "\n", "            ", "self", ".", "step_num", "+=", "1", "\n", "lr_list", ".", "append", "(", "self", ".", "_get_lr", "(", ")", ")", "\n", "", "self", ".", "step_num", "=", "0", "\n", "return", "torch", ".", "tensor", "(", "lr_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.plot": [[52, 59], ["schedulers.BaseScheduler.as_tensor", "plt.plot", "plt.show", "schedulers.BaseScheduler.numpy"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.as_tensor", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.plot"], ["", "def", "plot", "(", "self", ",", "start", "=", "0", ",", "stop", "=", "100_000", ")", ":", "# noqa", "\n", "        ", "\"\"\"Plot the scheduler values from start to stop.\"\"\"", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "\n", "all_lr", "=", "self", ".", "as_tensor", "(", "start", "=", "start", ",", "stop", "=", "stop", ")", "\n", "plt", ".", "plot", "(", "all_lr", ".", "numpy", "(", ")", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.NoamScheduler.__init__": [[83, 88], ["schedulers.BaseScheduler.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "d_model", ",", "warmup_steps", ",", "scale", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "optimizer", ")", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.NoamScheduler._get_lr": [[89, 96], ["min"], "methods", ["None"], ["", "def", "_get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "(", "\n", "self", ".", "scale", "\n", "*", "self", ".", "d_model", "**", "(", "-", "0.5", ")", "\n", "*", "min", "(", "self", ".", "step_num", "**", "(", "-", "0.5", ")", ",", "self", ".", "step_num", "*", "self", ".", "warmup_steps", "**", "(", "-", "1.5", ")", ")", "\n", ")", "\n", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.DPTNetScheduler.__init__": [[119, 137], ["schedulers.BaseScheduler.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ",", "\n", "steps_per_epoch", ",", "\n", "d_model", ",", "\n", "warmup_steps", "=", "4000", ",", "\n", "noam_scale", "=", "1.0", ",", "\n", "exp_max", "=", "0.0004", ",", "\n", "exp_base", "=", "0.98", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "optimizer", ")", "\n", "self", ".", "noam_scale", "=", "noam_scale", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "exp_max", "=", "exp_max", "\n", "self", ".", "exp_base", "=", "exp_base", "\n", "self", ".", "steps_per_epoch", "=", "steps_per_epoch", "\n", "self", ".", "epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.DPTNetScheduler._get_lr": [[138, 153], ["min"], "methods", ["None"], ["", "def", "_get_lr", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "step_num", "%", "self", ".", "steps_per_epoch", "==", "0", ":", "\n", "            ", "self", ".", "epoch", "+=", "1", "\n", "\n", "", "if", "self", ".", "step_num", ">", "self", ".", "warmup_steps", ":", "\n", "# exp decaying", "\n", "            ", "lr", "=", "self", ".", "exp_max", "*", "(", "self", ".", "exp_base", "**", "(", "(", "self", ".", "epoch", "-", "1", ")", "//", "2", ")", ")", "\n", "", "else", ":", "\n", "# noam", "\n", "            ", "lr", "=", "(", "\n", "self", ".", "noam_scale", "\n", "*", "self", ".", "d_model", "**", "(", "-", "0.5", ")", "\n", "*", "min", "(", "self", ".", "step_num", "**", "(", "-", "0.5", ")", ",", "self", ".", "step_num", "*", "self", ".", "warmup_steps", "**", "(", "-", "1.5", ")", ")", "\n", ")", "\n", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.SinkPITBetaScheduler.__init__": [[180, 182], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cooling_schedule", "=", "sinkpit_default_beta_schedule", ")", ":", "\n", "        ", "self", ".", "cooling_schedule", "=", "cooling_schedule", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.SinkPITBetaScheduler.on_epoch_start": [[183, 190], ["isinstance", "schedulers.SinkPITBetaScheduler.cooling_schedule"], "methods", ["None"], ["", "def", "on_epoch_start", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "assert", "isinstance", "(", "pl_module", ".", "loss_func", ",", "SinkPITLossWrapper", ")", "\n", "assert", "trainer", ".", "current_epoch", "==", "pl_module", ".", "current_epoch", "# same", "\n", "epoch", "=", "pl_module", ".", "current_epoch", "\n", "# step = pl_module.global_step", "\n", "beta", "=", "self", ".", "cooling_schedule", "(", "epoch", ")", "\n", "pl_module", ".", "loss_func", ".", "beta", "=", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.sinkpit_default_beta_schedule": [[155, 157], ["min"], "function", ["None"], ["", "", "def", "sinkpit_default_beta_schedule", "(", "epoch", ")", ":", "\n", "    ", "return", "min", "(", "[", "1.02", "**", "epoch", ",", "10", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.__init__": [[46, 66], ["pytorch_lightning.LightningModule.__init__", "system.System.save_hyperparameters", "system.System.config_to_hparams"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.config_to_hparams"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "optimizer", ",", "\n", "loss_func", ",", "\n", "train_loader", ",", "\n", "val_loader", "=", "None", ",", "\n", "scheduler", "=", "None", ",", "\n", "config", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "loss_func", "=", "loss_func", "\n", "self", ".", "train_loader", "=", "train_loader", "\n", "self", ".", "val_loader", "=", "val_loader", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "config", "=", "{", "}", "if", "config", "is", "None", "else", "config", "\n", "# Save lightning's AttributeDict under self.hparams", "\n", "self", ".", "save_hyperparameters", "(", "self", ".", "config_to_hparams", "(", "self", ".", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.forward": [[67, 74], ["system.System.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Applies forward pass of the model.\n\n        Returns:\n            :class:`torch.Tensor`\n        \"\"\"", "\n", "return", "self", ".", "model", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.common_step": [[75, 104], ["system.System.", "system.System.loss_func"], "methods", ["None"], ["", "def", "common_step", "(", "self", ",", "batch", ",", "batch_nb", ",", "train", "=", "True", ")", ":", "\n", "        ", "\"\"\"Common forward step between training and validation.\n\n        The function of this method is to unpack the data given by the loader,\n        forward the batch through the model and compute the loss.\n        Pytorch-lightning handles all the rest.\n\n        Args:\n            batch: the object returned by the loader (a list of torch.Tensor\n                in most cases) but can be something else.\n            batch_nb (int): The number of the batch in the epoch.\n            train (bool): Whether in training mode. Needed only if the training\n                and validation steps are fundamentally different, otherwise,\n                pytorch-lightning handles the usual differences.\n\n        Returns:\n            :class:`torch.Tensor` : The loss value on this batch.\n\n        .. note::\n            This is typically the method to overwrite when subclassing\n            ``System``. If the training and validation steps are somehow\n            different (except for ``loss.backward()`` and ``optimzer.step()``),\n            the argument ``train`` can be used to switch behavior.\n            Otherwise, ``training_step`` and ``validation_step`` can be overwriten.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "batch", "\n", "est_targets", "=", "self", "(", "inputs", ")", "\n", "loss", "=", "self", ".", "loss_func", "(", "est_targets", ",", "targets", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.training_step": [[105, 121], ["system.System.common_step", "system.System.log"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.common_step"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "\"\"\"Pass data through the model and compute the loss.\n\n        Backprop is **not** performed (meaning PL will do it for you).\n\n        Args:\n            batch: the object returned by the loader (a list of torch.Tensor\n                in most cases) but can be something else.\n            batch_nb (int): The number of the batch in the epoch.\n\n        Returns:\n            torch.Tensor, the value of the loss.\n        \"\"\"", "\n", "loss", "=", "self", ".", "common_step", "(", "batch", ",", "batch_nb", ",", "train", "=", "True", ")", "\n", "self", ".", "log", "(", "\"loss\"", ",", "loss", ",", "logger", "=", "True", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.validation_step": [[122, 132], ["system.System.common_step", "system.System.log"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.common_step"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "\"\"\"Need to overwrite PL validation_step to do validation.\n\n        Args:\n            batch: the object returned by the loader (a list of torch.Tensor\n                in most cases) but can be something else.\n            batch_nb (int): The number of the batch in the epoch.\n        \"\"\"", "\n", "loss", "=", "self", ".", "common_step", "(", "batch", ",", "batch_nb", ",", "train", "=", "False", ")", "\n", "self", ".", "log", "(", "\"val_loss\"", ",", "loss", ",", "on_epoch", "=", "True", ",", "prog_bar", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.on_validation_epoch_end": [[133, 138], ["system.System.trainer.callback_metrics.get", "system.System.trainer.logger.log_metrics"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "def", "on_validation_epoch_end", "(", "self", ")", ":", "\n", "        ", "\"\"\"Log hp_metric to tensorboard for hparams selection.\"\"\"", "\n", "hp_metric", "=", "self", ".", "trainer", ".", "callback_metrics", ".", "get", "(", "\"val_loss\"", ",", "None", ")", "\n", "if", "hp_metric", "is", "not", "None", ":", "\n", "            ", "self", ".", "trainer", ".", "logger", ".", "log_metrics", "(", "{", "\"hp_metric\"", ":", "hp_metric", "}", ",", "step", "=", "self", ".", "trainer", ".", "global_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.configure_optimizers": [[139, 165], ["isinstance", "isinstance", "isinstance", "epoch_schedulers.append", "sched.setdefault", "sched.setdefault", "epoch_schedulers.append"], "methods", ["None"], ["", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize optimizers, batch-wise and epoch-wise schedulers.\"\"\"", "\n", "if", "self", ".", "scheduler", "is", "None", ":", "\n", "            ", "return", "self", ".", "optimizer", "\n", "\n", "", "if", "not", "isinstance", "(", "self", ".", "scheduler", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "self", ".", "scheduler", "=", "[", "self", ".", "scheduler", "]", "# support multiple schedulers", "\n", "\n", "", "epoch_schedulers", "=", "[", "]", "\n", "for", "sched", "in", "self", ".", "scheduler", ":", "\n", "            ", "if", "not", "isinstance", "(", "sched", ",", "dict", ")", ":", "\n", "                ", "if", "isinstance", "(", "sched", ",", "ReduceLROnPlateau", ")", ":", "\n", "                    ", "sched", "=", "{", "\"scheduler\"", ":", "sched", ",", "\"monitor\"", ":", "self", ".", "default_monitor", "}", "\n", "", "epoch_schedulers", ".", "append", "(", "sched", ")", "\n", "", "else", ":", "\n", "                ", "sched", ".", "setdefault", "(", "\"monitor\"", ",", "self", ".", "default_monitor", ")", "\n", "sched", ".", "setdefault", "(", "\"frequency\"", ",", "1", ")", "\n", "# Backward compat", "\n", "if", "sched", "[", "\"interval\"", "]", "==", "\"batch\"", ":", "\n", "                    ", "sched", "[", "\"interval\"", "]", "=", "\"step\"", "\n", "", "assert", "sched", "[", "\"interval\"", "]", "in", "[", "\n", "\"epoch\"", ",", "\n", "\"step\"", ",", "\n", "]", ",", "\"Scheduler interval should be either step or epoch\"", "\n", "epoch_schedulers", ".", "append", "(", "sched", ")", "\n", "", "", "return", "[", "self", ".", "optimizer", "]", ",", "epoch_schedulers", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.lr_scheduler_step": [[166, 171], ["scheduler.step", "scheduler.step"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.step", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.step"], ["", "def", "lr_scheduler_step", "(", "self", ",", "scheduler", ",", "optimizer_idx", ",", "metric", ")", ":", "\n", "        ", "if", "metric", "is", "None", ":", "\n", "            ", "scheduler", ".", "step", "(", ")", "\n", "", "else", ":", "\n", "            ", "scheduler", ".", "step", "(", "metric", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.train_dataloader": [[172, 175], ["None"], "methods", ["None"], ["", "", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"Training dataloader\"\"\"", "\n", "return", "self", ".", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.val_dataloader": [[176, 179], ["None"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"Validation dataloader\"\"\"", "\n", "return", "self", ".", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.on_save_checkpoint": [[180, 184], ["None"], "methods", ["None"], ["", "def", "on_save_checkpoint", "(", "self", ",", "checkpoint", ")", ":", "\n", "        ", "\"\"\"Overwrite if you want to save more things in the checkpoint.\"\"\"", "\n", "checkpoint", "[", "\"training_config\"", "]", "=", "self", ".", "config", "\n", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.config_to_hparams": [[185, 204], ["utils.flatten_dict", "utils.flatten_dict.items", "str", "isinstance", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.flatten_dict"], ["", "@", "staticmethod", "\n", "def", "config_to_hparams", "(", "dic", ")", ":", "\n", "        ", "\"\"\"Sanitizes the config dict to be handled correctly by torch\n        SummaryWriter. It flatten the config dict, converts ``None`` to\n        ``\"None\"`` and any list and tuple into torch.Tensors.\n\n        Args:\n            dic (dict): Dictionary to be transformed.\n\n        Returns:\n            dict: Transformed dictionary.\n        \"\"\"", "\n", "dic", "=", "flatten_dict", "(", "dic", ")", "\n", "for", "k", ",", "v", "in", "dic", ".", "items", "(", ")", ":", "\n", "            ", "if", "v", "is", "None", ":", "\n", "                ", "dic", "[", "k", "]", "=", "str", "(", "v", ")", "\n", "", "elif", "isinstance", "(", "v", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "dic", "[", "k", "]", "=", "torch", ".", "tensor", "(", "v", ")", "\n", "", "", "return", "dic", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer": [[51, 69], ["optimizers.get"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "make_optimizer", "(", "params", ",", "optimizer", "=", "\"adam\"", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n\n    Args:\n        params (iterable): Output of `nn.Module.parameters()`.\n        optimizer (str or :class:`torch.optim.Optimizer`): Identifier understood\n            by :func:`~.get`.\n        **kwargs (dict): keyword arguments for the optimizer.\n\n    Returns:\n        torch.optim.Optimizer\n    Examples\n        >>> from torch import nn\n        >>> model = nn.Sequential(nn.Linear(10, 10))\n        >>> optimizer = make_optimizer(model.parameters(), optimizer='sgd',\n        >>>                            lr=1e-3)\n    \"\"\"", "\n", "return", "get", "(", "optimizer", ")", "(", "params", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.register_optimizer": [[71, 81], ["globals().update", "ValueError", "globals().keys", "custom_opt.__name__.lower", "globals().keys", "globals", "globals", "globals"], "function", ["None"], ["", "def", "register_optimizer", "(", "custom_opt", ")", ":", "\n", "    ", "\"\"\"Register a custom opt, gettable with `optimzers.get`.\n\n    Args:\n        custom_opt: Custom optimizer to register.\n\n    \"\"\"", "\n", "if", "custom_opt", ".", "__name__", "in", "globals", "(", ")", ".", "keys", "(", ")", "or", "custom_opt", ".", "__name__", ".", "lower", "(", ")", "in", "globals", "(", ")", ".", "keys", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Activation {custom_opt.__name__} already exists. Choose another name.\"", ")", "\n", "", "globals", "(", ")", ".", "update", "(", "{", "custom_opt", ".", "__name__", ":", "custom_opt", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.get": [[83, 102], ["isinstance", "ValueError", "isinstance", "to_get.get", "k.lower", "identifier.lower", "ValueError", "str", "globals().items", "globals", "str"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "def", "get", "(", "identifier", ")", ":", "\n", "    ", "\"\"\"Returns an optimizer function from a string. Returns its input if it\n    is callable (already a :class:`torch.optim.Optimizer` for example).\n\n    Args:\n        identifier (str or Callable): the optimizer identifier.\n\n    Returns:\n        :class:`torch.optim.Optimizer` or None\n    \"\"\"", "\n", "if", "isinstance", "(", "identifier", ",", "Optimizer", ")", ":", "\n", "        ", "return", "identifier", "\n", "", "elif", "isinstance", "(", "identifier", ",", "str", ")", ":", "\n", "        ", "to_get", "=", "{", "k", ".", "lower", "(", ")", ":", "v", "for", "k", ",", "v", "in", "globals", "(", ")", ".", "items", "(", ")", "}", "\n", "cls", "=", "to_get", ".", "get", "(", "identifier", ".", "lower", "(", ")", ")", "\n", "if", "cls", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Could not interpret optimizer : {str(identifier)}\"", ")", "\n", "", "return", "cls", "\n", "", "raise", "ValueError", "(", "f\"Could not interpret optimizer : {str(identifier)}\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers_test.optim_mapping": [[7, 15], ["None"], "function", ["None"], ["def", "optim_mapping", "(", ")", ":", "\n", "    ", "mapping_list", "=", "[", "\n", "(", "optim", ".", "Adam", ",", "\"adam\"", ")", ",", "\n", "(", "optim", ".", "SGD", ",", "\"sgd\"", ")", ",", "\n", "(", "optim", ".", "RMSprop", ",", "\"rmsprop\"", ")", ",", "\n", "(", "Ranger", ",", "\"ranger\"", ")", ",", "\n", "]", "\n", "return", "mapping_list", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers_test.test_all_get": [[20, 50], ["pytest.mark.parametrize", "asteroid.engine.optimizers.get", "global_model.parameters"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"opt\"", ",", "\n", "[", "\n", "\"Adam\"", ",", "\n", "\"RMSprop\"", ",", "\n", "\"SGD\"", ",", "\n", "\"Adadelta\"", ",", "\n", "\"Adagrad\"", ",", "\n", "\"Adamax\"", ",", "\n", "\"AdamW\"", ",", "\n", "\"ASGD\"", ",", "\n", "\"AccSGD\"", ",", "\n", "\"AdaBound\"", ",", "\n", "\"AdaMod\"", ",", "\n", "\"DiffGrad\"", ",", "\n", "\"Lamb\"", ",", "\n", "\"NovoGrad\"", ",", "\n", "\"PID\"", ",", "\n", "\"QHAdam\"", ",", "\n", "\"QHM\"", ",", "\n", "\"RAdam\"", ",", "\n", "\"SGDW\"", ",", "\n", "\"Yogi\"", ",", "\n", "\"Ranger\"", ",", "\n", "\"RangerQH\"", ",", "\n", "\"RangerVA\"", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_all_get", "(", "opt", ")", ":", "\n", "    ", "optimizers", ".", "get", "(", "opt", ")", "(", "global_model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers_test.test_get_str_returns_instance": [[52, 58], ["pytest.mark.parametrize", "optimizers_test.optim_mapping", "global_model.parameters", "asteroid.engine.optimizers.get", "global_model.parameters", "type", "type"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers_test.optim_mapping", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"opt_tuple\"", ",", "optim_mapping", "(", ")", ")", "\n", "def", "test_get_str_returns_instance", "(", "opt_tuple", ")", ":", "\n", "    ", "torch_optim", "=", "opt_tuple", "[", "0", "]", "(", "global_model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "asteroid_optim", "=", "optimizers", ".", "get", "(", "opt_tuple", "[", "1", "]", ")", "(", "global_model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "assert", "type", "(", "torch_optim", ")", "==", "type", "(", "asteroid_optim", ")", "\n", "assert", "torch_optim", ".", "param_groups", "==", "asteroid_optim", ".", "param_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers_test.test_get_instance_returns_instance": [[60, 65], ["pytest.mark.parametrize", "opt", "asteroid.engine.optimizers.get", "global_model.parameters"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"opt\"", ",", "[", "optim", ".", "Adam", ",", "optim", ".", "SGD", ",", "optim", ".", "Adadelta", "]", ")", "\n", "def", "test_get_instance_returns_instance", "(", "opt", ")", ":", "\n", "    ", "torch_optim", "=", "opt", "(", "global_model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "asteroid_optim", "=", "optimizers", ".", "get", "(", "torch_optim", ")", "\n", "assert", "torch_optim", "==", "asteroid_optim", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers_test.test_get_errors": [[67, 72], ["pytest.mark.parametrize", "pytest.raises", "asteroid.engine.optimizers.get", "object"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"wrong\"", ",", "[", "\"wrong_string\"", ",", "12", ",", "object", "(", ")", "]", ")", "\n", "def", "test_get_errors", "(", "wrong", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# Should raise for anything not a Optimizer instance + unknown string", "\n", "        ", "optimizers", ".", "get", "(", "wrong", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers_test.test_make_optimizer": [[74, 76], ["asteroid.engine.optimizers.make_optimizer", "global_model.parameters"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer"], ["", "", "def", "test_make_optimizer", "(", ")", ":", "\n", "    ", "optimizers", ".", "make_optimizer", "(", "global_model", ".", "parameters", "(", ")", ",", "\"adam\"", ",", "lr", "=", "1e-3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers_test.test_register": [[78, 89], ["asteroid.engine.optimizers.register_optimizer", "asteroid.engine.optimizers.get", "pytest.raises", "asteroid.engine.optimizers.register_optimizer", "super().__init__"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.register_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.register_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["", "def", "test_register", "(", ")", ":", "\n", "    ", "class", "Custom", "(", "optim", ".", "Optimizer", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "", "", "optimizers", ".", "register_optimizer", "(", "Custom", ")", "\n", "cls", "=", "optimizers", ".", "get", "(", "\"Custom\"", ")", "\n", "assert", "cls", "==", "Custom", "\n", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "optimizers", ".", "register_optimizer", "(", "optimizers", ".", "Adam", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.scheduler_test.common_setup": [[11, 18], ["torch.nn.Sequential", "torch.optim.Adam", "asteroid.utils.test_utils.DummyDataset", "torch.utils.data.DataLoader", "pytorch_lightning.Trainer", "torch.nn.Linear", "torch.nn.ReLU", "nn.Sequential.parameters"], "function", ["None"], ["def", "common_setup", "(", ")", ":", "\n", "    ", "model", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "10", ",", "10", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "dataset", "=", "DummyDataset", "(", ")", "\n", "loader", "=", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "2", ",", "num_workers", "=", "4", ")", "\n", "trainer", "=", "Trainer", "(", "max_epochs", "=", "1", ",", "fast_dev_run", "=", "True", ")", "\n", "return", "model", ",", "optimizer", ",", "loader", ",", "trainer", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.scheduler_test.test_state_dict": [[20, 30], ["scheduler_test.common_setup", "asteroid.engine.schedulers.NoamScheduler", "asteroid.engine.schedulers.NoamScheduler.state_dict", "asteroid.engine.schedulers.NoamScheduler.load_state_dict", "asteroid.engine.schedulers.NoamScheduler.state_dict", "asteroid.engine.schedulers.NoamScheduler.zero_grad"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.scheduler_test.common_setup", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.zero_grad"], ["", "def", "test_state_dict", "(", ")", ":", "\n", "    ", "\"\"\"Load and serialize scheduler.\"\"\"", "\n", "model", ",", "optimizer", ",", "loader", ",", "trainer", "=", "common_setup", "(", ")", "\n", "sched", "=", "NoamScheduler", "(", "optimizer", ",", "d_model", "=", "10", ",", "warmup_steps", "=", "100", ")", "\n", "state_dict", "=", "sched", ".", "state_dict", "(", ")", "\n", "sched", ".", "load_state_dict", "(", "state_dict", ")", "\n", "state_dict_c", "=", "sched", ".", "state_dict", "(", ")", "\n", "assert", "state_dict", "==", "state_dict_c", "\n", "# Test zero_grad", "\n", "sched", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.scheduler_test.test_noam_scheduler": [[32, 50], ["scheduler_test.common_setup", "asteroid.engine.system.System", "trainer.fit", "scheduler[].as_tensor", "asteroid.engine.schedulers.NoamScheduler", "torch.nn.MSELoss"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.scheduler_test.common_setup", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.as_tensor"], ["", "def", "test_noam_scheduler", "(", ")", ":", "\n", "    ", "model", ",", "optimizer", ",", "loader", ",", "trainer", "=", "common_setup", "(", ")", "\n", "scheduler", "=", "{", "\n", "\"scheduler\"", ":", "NoamScheduler", "(", "optimizer", ",", "d_model", "=", "10", ",", "warmup_steps", "=", "100", ")", ",", "\n", "\"interval\"", ":", "\"step\"", ",", "\n", "}", "\n", "\n", "system", "=", "System", "(", "\n", "model", ",", "\n", "optimizer", ",", "\n", "loss_func", "=", "nn", ".", "MSELoss", "(", ")", ",", "\n", "train_loader", "=", "loader", ",", "\n", "val_loader", "=", "loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "# Test `as_tensor` for `plot`", "\n", "scheduler", "[", "\"scheduler\"", "]", ".", "as_tensor", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.scheduler_test.test_dptnet_scheduler": [[52, 71], ["scheduler_test.common_setup", "asteroid.engine.system.System", "trainer.fit", "scheduler[].as_tensor", "asteroid.engine.schedulers.DPTNetScheduler", "torch.nn.MSELoss"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.scheduler_test.common_setup", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.as_tensor"], ["", "def", "test_dptnet_scheduler", "(", ")", ":", "\n", "    ", "model", ",", "optimizer", ",", "loader", ",", "trainer", "=", "common_setup", "(", ")", "\n", "\n", "scheduler", "=", "{", "\n", "\"scheduler\"", ":", "DPTNetScheduler", "(", "optimizer", ",", "d_model", "=", "10", ",", "steps_per_epoch", "=", "6", ",", "warmup_steps", "=", "4", ")", ",", "\n", "\"interval\"", ":", "\"step\"", ",", "\n", "}", "\n", "\n", "system", "=", "System", "(", "\n", "model", ",", "\n", "optimizer", ",", "\n", "loss_func", "=", "nn", ".", "MSELoss", "(", ")", ",", "\n", "train_loader", "=", "loader", ",", "\n", "val_loader", "=", "loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "# Test `as_tensor` for `plot`", "\n", "scheduler", "[", "\"scheduler\"", "]", ".", "as_tensor", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system_test.test_system": [[9, 27], ["torch.nn.Sequential", "torch.optim.Adam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "asteroid.utils.test_utils.DummyDataset", "torch.utils.data.DataLoader", "asteroid.engine.system.System", "pytorch_lightning.Trainer", "pytorch_lightning.Trainer.fit", "torch.nn.Linear", "torch.nn.ReLU", "nn.Sequential.parameters", "torch.nn.MSELoss"], "function", ["None"], ["def", "test_system", "(", ")", ":", "\n", "    ", "model", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "10", ",", "10", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "optimizer", ")", "\n", "dataset", "=", "DummyDataset", "(", ")", "\n", "loader", "=", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "2", ",", "num_workers", "=", "4", ")", "\n", "system", "=", "System", "(", "\n", "model", ",", "\n", "optimizer", ",", "\n", "loss_func", "=", "nn", ".", "MSELoss", "(", ")", ",", "\n", "train_loader", "=", "loader", ",", "\n", "val_loader", "=", "loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", ")", "\n", "trainer", "=", "Trainer", "(", "\n", "max_epochs", "=", "1", ",", "fast_dev_run", "=", "True", ",", "accelerator", "=", "\"cpu\"", ",", "strategy", "=", "\"ddp\"", ",", "devices", "=", "\"auto\"", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system_test.test_system_no_scheduler": [[29, 47], ["torch.nn.Sequential", "torch.optim.Adam", "asteroid.utils.test_utils.DummyDataset", "torch.utils.data.DataLoader", "asteroid.engine.system.System", "pytorch_lightning.Trainer", "pytorch_lightning.Trainer.fit", "torch.nn.Linear", "torch.nn.ReLU", "nn.Sequential.parameters", "torch.nn.MSELoss"], "function", ["None"], ["", "def", "test_system_no_scheduler", "(", ")", ":", "\n", "    ", "model", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "10", ",", "10", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "scheduler", "=", "None", "\n", "dataset", "=", "DummyDataset", "(", ")", "\n", "loader", "=", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "2", ",", "num_workers", "=", "4", ")", "\n", "system", "=", "System", "(", "\n", "model", ",", "\n", "optimizer", ",", "\n", "loss_func", "=", "nn", ".", "MSELoss", "(", ")", ",", "\n", "train_loader", "=", "loader", ",", "\n", "val_loader", "=", "loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", ")", "\n", "trainer", "=", "Trainer", "(", "\n", "max_epochs", "=", "1", ",", "fast_dev_run", "=", "True", ",", "accelerator", "=", "\"cpu\"", ",", "strategy", "=", "\"ddp\"", ",", "devices", "=", "\"auto\"", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system_test.test_config_to_hparams": [[49, 52], ["asteroid.engine.system.System.config_to_hparams"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.system.System.config_to_hparams"], ["", "def", "test_config_to_hparams", "(", ")", ":", "\n", "    ", "conf", "=", "{", "\"data\"", ":", "{", "\"a\"", ":", "1", ",", "\"b\"", ":", "2", "}", ",", "\"nnet\"", ":", "{", "\"c\"", ":", "3", "}", ",", "\"optim\"", ":", "{", "\"d\"", ":", "None", ",", "\"e\"", ":", "[", "1", ",", "2", ",", "3", "]", "}", "}", "\n", "System", ".", "config_to_hparams", "(", "conf", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.musdb18_dataset.MUSDB18Dataset.__init__": [[94, 125], ["pathlib.Path().expanduser", "list", "musdb18_dataset.MUSDB18Dataset.get_tracks", "RuntimeError", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dampvsep_dataset.DAMPVSEPSinglesDataset.get_tracks"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", ",", "\n", "sources", "=", "[", "\"vocals\"", ",", "\"bass\"", ",", "\"drums\"", ",", "\"other\"", "]", ",", "\n", "targets", "=", "None", ",", "\n", "suffix", "=", "\".wav\"", ",", "\n", "split", "=", "\"train\"", ",", "\n", "subset", "=", "None", ",", "\n", "segment", "=", "None", ",", "\n", "samples_per_track", "=", "1", ",", "\n", "random_segments", "=", "False", ",", "\n", "random_track_mix", "=", "False", ",", "\n", "source_augmentations", "=", "lambda", "audio", ":", "audio", ",", "\n", "sample_rate", "=", "44100", ",", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "root", "=", "Path", "(", "root", ")", ".", "expanduser", "(", ")", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "segment", "=", "segment", "\n", "self", ".", "random_track_mix", "=", "random_track_mix", "\n", "self", ".", "random_segments", "=", "random_segments", "\n", "self", ".", "source_augmentations", "=", "source_augmentations", "\n", "self", ".", "sources", "=", "sources", "\n", "self", ".", "targets", "=", "targets", "\n", "self", ".", "suffix", "=", "suffix", "\n", "self", ".", "subset", "=", "subset", "\n", "self", ".", "samples_per_track", "=", "samples_per_track", "\n", "self", ".", "tracks", "=", "list", "(", "self", ".", "get_tracks", "(", ")", ")", "\n", "if", "not", "self", ".", "tracks", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"No tracks found.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.musdb18_dataset.MUSDB18Dataset.__getitem__": [[126, 176], ["torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "torch.stack().sum", "random.uniform", "int", "soundfile.read", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "musdb18_dataset.MUSDB18Dataset.source_augmentations", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "random.choice", "pathlib.Path().with_suffix", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "range", "random.uniform", "int", "list", "len", "pathlib.Path", "torch.stack.values", "torch.stack.values", "torch.stack.items", "torch.stack.items"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# assemble the mixture of target and interferers", "\n", "        ", "audio_sources", "=", "{", "}", "\n", "\n", "# get track_id", "\n", "track_id", "=", "index", "//", "self", ".", "samples_per_track", "\n", "if", "self", ".", "random_segments", ":", "\n", "            ", "start", "=", "random", ".", "uniform", "(", "0", ",", "self", ".", "tracks", "[", "track_id", "]", "[", "\"min_duration\"", "]", "-", "self", ".", "segment", ")", "\n", "", "else", ":", "\n", "            ", "start", "=", "0", "\n", "\n", "# load sources", "\n", "", "for", "source", "in", "self", ".", "sources", ":", "\n", "# optionally select a random track for each source", "\n", "            ", "if", "self", ".", "random_track_mix", ":", "\n", "# load a different track", "\n", "                ", "track_id", "=", "random", ".", "choice", "(", "range", "(", "len", "(", "self", ".", "tracks", ")", ")", ")", "\n", "if", "self", ".", "random_segments", ":", "\n", "                    ", "start", "=", "random", ".", "uniform", "(", "0", ",", "self", ".", "tracks", "[", "track_id", "]", "[", "\"min_duration\"", "]", "-", "self", ".", "segment", ")", "\n", "\n", "# loads the full track duration", "\n", "", "", "start_sample", "=", "int", "(", "start", "*", "self", ".", "sample_rate", ")", "\n", "# check if dur is none", "\n", "if", "self", ".", "segment", ":", "\n", "# stop in soundfile is calc in samples, not seconds", "\n", "                ", "stop_sample", "=", "start_sample", "+", "int", "(", "self", ".", "segment", "*", "self", ".", "sample_rate", ")", "\n", "", "else", ":", "\n", "# set to None for reading complete file", "\n", "                ", "stop_sample", "=", "None", "\n", "\n", "# load actual audio", "\n", "", "audio", ",", "_", "=", "sf", ".", "read", "(", "\n", "Path", "(", "self", ".", "tracks", "[", "track_id", "]", "[", "\"path\"", "]", "/", "source", ")", ".", "with_suffix", "(", "self", ".", "suffix", ")", ",", "\n", "always_2d", "=", "True", ",", "\n", "start", "=", "start_sample", ",", "\n", "stop", "=", "stop_sample", ",", "\n", ")", "\n", "# convert to torch tensor", "\n", "audio", "=", "torch", ".", "tensor", "(", "audio", ".", "T", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "# apply source-wise augmentations", "\n", "audio", "=", "self", ".", "source_augmentations", "(", "audio", ")", "\n", "audio_sources", "[", "source", "]", "=", "audio", "\n", "\n", "# apply linear mix over source index=0", "\n", "", "audio_mix", "=", "torch", ".", "stack", "(", "list", "(", "audio_sources", ".", "values", "(", ")", ")", ")", ".", "sum", "(", "0", ")", "\n", "if", "self", ".", "targets", ":", "\n", "            ", "audio_sources", "=", "torch", ".", "stack", "(", "\n", "[", "wav", "for", "src", ",", "wav", "in", "audio_sources", ".", "items", "(", ")", "if", "src", "in", "self", ".", "targets", "]", ",", "dim", "=", "0", "\n", ")", "\n", "", "return", "audio_mix", ",", "audio_sources", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.musdb18_dataset.MUSDB18Dataset.__len__": [[177, 179], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "tracks", ")", "*", "self", ".", "samples_per_track", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.musdb18_dataset.MUSDB18Dataset.get_tracks": [[180, 207], ["pathlib.Path", "tqdm.tqdm", "pathlib.Path.iterdir", "track_path.is_dir", "list", "all", "print", "map", "all", "print", "min", "sp.exists"], "methods", ["None"], ["", "def", "get_tracks", "(", "self", ")", ":", "\n", "        ", "\"\"\"Loads input and output tracks\"\"\"", "\n", "p", "=", "Path", "(", "self", ".", "root", ",", "self", ".", "split", ")", "\n", "for", "track_path", "in", "tqdm", ".", "tqdm", "(", "p", ".", "iterdir", "(", ")", ")", ":", "\n", "            ", "if", "track_path", ".", "is_dir", "(", ")", ":", "\n", "                ", "if", "self", ".", "subset", "and", "track_path", ".", "stem", "not", "in", "self", ".", "subset", ":", "\n", "# skip this track", "\n", "                    ", "continue", "\n", "\n", "", "source_paths", "=", "[", "track_path", "/", "(", "s", "+", "self", ".", "suffix", ")", "for", "s", "in", "self", ".", "sources", "]", "\n", "if", "not", "all", "(", "sp", ".", "exists", "(", ")", "for", "sp", "in", "source_paths", ")", ":", "\n", "                    ", "print", "(", "\"Exclude track due to non-existing source\"", ",", "track_path", ")", "\n", "continue", "\n", "\n", "# get metadata", "\n", "", "infos", "=", "list", "(", "map", "(", "sf", ".", "info", ",", "source_paths", ")", ")", "\n", "if", "not", "all", "(", "i", ".", "samplerate", "==", "self", ".", "sample_rate", "for", "i", "in", "infos", ")", ":", "\n", "                    ", "print", "(", "\"Exclude track due to different sample rate \"", ",", "track_path", ")", "\n", "continue", "\n", "\n", "", "if", "self", ".", "segment", "is", "not", "None", ":", "\n", "# get minimum duration of track", "\n", "                    ", "min_duration", "=", "min", "(", "i", ".", "duration", "for", "i", "in", "infos", ")", "\n", "if", "min_duration", ">", "self", ".", "segment", ":", "\n", "                        ", "yield", "(", "{", "\"path\"", ":", "track_path", ",", "\"min_duration\"", ":", "min_duration", "}", ")", "\n", "", "", "else", ":", "\n", "                    ", "yield", "(", "{", "\"path\"", ":", "track_path", ",", "\"min_duration\"", ":", "None", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.musdb18_dataset.MUSDB18Dataset.get_infos": [[208, 219], ["dict"], "methods", ["None"], ["", "", "", "", "def", "get_infos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get dataset infos (for publishing models).\n\n        Returns:\n            dict, dataset infos with keys `dataset`, `task` and `licences`.\n        \"\"\"", "\n", "infos", "=", "dict", "(", ")", "\n", "infos", "[", "\"dataset\"", "]", "=", "self", ".", "dataset_name", "\n", "infos", "[", "\"task\"", "]", "=", "\"enhancement\"", "\n", "infos", "[", "\"licenses\"", "]", "=", "[", "musdb_license", "]", "\n", "return", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.sms_wsj_dataset.SmsWsjDataset.__init__": [[69, 131], ["torch.utils.data.Dataset.__init__", "JsonDatabase", "JsonDatabase.get_dataset", "SMS_TARGETS.keys", "ValueError", "int", "dataset.filter.filter.filter", "warnings.warn", "SMS_TARGETS.keys"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "json_path", ",", "\n", "target", ",", "\n", "dset", ",", "\n", "sample_rate", "=", "8000", ",", "\n", "single_channel", "=", "True", ",", "\n", "segment", "=", "4.0", ",", "\n", "nondefault_nsrc", "=", "None", ",", "\n", "normalize_audio", "=", "False", ",", "\n", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "sms_wsj", "# noqa", "\n", "", "except", "ModuleNotFoundError", ":", "\n", "            ", "import", "warnings", "\n", "\n", "warnings", ".", "warn", "(", "\n", "\"Some of the functionality relies on the sms_wsj package \"", "\n", "\"downloadable from https://github.com/fgnt/sms_wsj .\"", "\n", "\"The user is encouraged to install the package\"", "\n", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "target", "not", "in", "SMS_TARGETS", ".", "keys", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Unexpected task {}, expected one of \"", "\"{}\"", ".", "format", "(", "target", ",", "SMS_TARGETS", ".", "keys", "(", ")", ")", "\n", ")", "\n", "\n", "# Task setting", "\n", "", "self", ".", "json_path", "=", "json_path", "\n", "self", ".", "target", "=", "target", "\n", "self", ".", "target_dict", "=", "SMS_TARGETS", "[", "target", "]", "\n", "self", ".", "single_channel", "=", "single_channel", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "normalize_audio", "=", "normalize_audio", "\n", "self", ".", "seg_len", "=", "None", "if", "segment", "is", "None", "else", "int", "(", "segment", "*", "sample_rate", ")", "\n", "if", "not", "nondefault_nsrc", ":", "\n", "            ", "self", ".", "n_src", "=", "self", ".", "target_dict", "[", "\"default_nsrc\"", "]", "\n", "", "else", ":", "\n", "            ", "assert", "nondefault_nsrc", ">=", "self", ".", "target_dict", "[", "\"default_nsrc\"", "]", "\n", "self", ".", "n_src", "=", "nondefault_nsrc", "\n", "", "self", ".", "like_test", "=", "self", ".", "seg_len", "is", "None", "\n", "self", ".", "dset", "=", "dset", "\n", "self", ".", "EPS", "=", "1e-8", "\n", "\n", "# Load json files", "\n", "\n", "from", "lazy_dataset", ".", "database", "import", "JsonDatabase", "\n", "\n", "db", "=", "JsonDatabase", "(", "json_path", ")", "\n", "dataset", "=", "db", ".", "get_dataset", "(", "dset", ")", "\n", "# Filter out short utterances only when segment is specified", "\n", "if", "not", "self", ".", "like_test", ":", "\n", "\n", "            ", "def", "filter_short_examples", "(", "example", ")", ":", "\n", "                ", "num_samples", "=", "example", "[", "\"num_samples\"", "]", "[", "\"observation\"", "]", "\n", "if", "num_samples", "<", "self", ".", "seg_len", ":", "\n", "                    ", "return", "False", "\n", "", "else", ":", "\n", "                    ", "return", "True", "\n", "\n", "", "", "dataset", "=", "dataset", ".", "filter", "(", "filter_short_examples", ",", "lazy", "=", "False", ")", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.sms_wsj_dataset.SmsWsjDataset.__add__": [[132, 146], ["sms_wsj_dataset.SmsWsjDataset.dataset.concatenate", "ValueError", "min", "print"], "methods", ["None"], ["", "def", "__add__", "(", "self", ",", "sms_wsj", ")", ":", "\n", "        ", "if", "self", ".", "n_src", "!=", "sms_wsj", ".", "n_src", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Only datasets having the same number of sources\"", "\n", "\"can be added together. Received \"", "\n", "\"{} and {}\"", ".", "format", "(", "self", ".", "n_src", ",", "sms_wsj", ".", "n_src", ")", "\n", ")", "\n", "", "if", "self", ".", "seg_len", "!=", "sms_wsj", ".", "seg_len", ":", "\n", "            ", "self", ".", "seg_len", "=", "min", "(", "self", ".", "seg_len", ",", "sms_wsj", ".", "seg_len", ")", "\n", "print", "(", "\n", "\"Segment length mismatched between the two Dataset\"", "\n", "\"passed one the smallest to the sum.\"", "\n", ")", "\n", "", "self", ".", "dataset", "=", "self", ".", "dataset", ".", "concatenate", "(", "sms_wsj", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.sms_wsj_dataset.SmsWsjDataset.__len__": [[147, 149], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.sms_wsj_dataset.SmsWsjDataset.__getitem__": [[150, 223], ["soundfile.read", "torch.as_tensor", "range", "torch.from_numpy", "torch.from_numpy", "numpy.random.randint", "source_arrays.append", "numpy.stack", "wham_dataset.normalize_tensor_wav.std", "wham_dataset.normalize_tensor_wav", "wham_dataset.normalize_tensor_wav", "numpy.random.randint", "extract_piece", "soundfile.read", "zip", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.as_tensor", "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wham_dataset.normalize_tensor_wav", "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wham_dataset.normalize_tensor_wav", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Gets a mixture/sources pair.\n        Returns:\n            mixture, vstack([source_arrays])\n        \"\"\"", "\n", "# Random start", "\n", "example", "=", "self", ".", "dataset", "[", "idx", "]", "\n", "in_signal", "=", "self", ".", "target_dict", "[", "\"mixture\"", "]", "\n", "target", "=", "self", ".", "target_dict", "[", "\"target\"", "]", "\n", "audio_path", "=", "example", "[", "\"audio_path\"", "]", "\n", "num_samples", "=", "example", "[", "\"num_samples\"", "]", "[", "\"observation\"", "]", "\n", "if", "num_samples", "==", "self", ".", "seg_len", "or", "self", ".", "like_test", ":", "\n", "            ", "rand_start", "=", "0", "\n", "", "else", ":", "\n", "            ", "rand_start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "num_samples", "-", "self", ".", "seg_len", ")", "\n", "", "if", "self", ".", "like_test", ":", "\n", "            ", "stop", "=", "None", "\n", "", "else", ":", "\n", "            ", "stop", "=", "rand_start", "+", "self", ".", "seg_len", "\n", "# Load mixture", "\n", "", "x", ",", "_", "=", "sf", ".", "read", "(", "audio_path", "[", "in_signal", "]", ",", "start", "=", "rand_start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ")", "\n", "x", "=", "x", ".", "T", "\n", "\n", "num_channels", "=", "self", ".", "target_dict", "[", "\"infos\"", "]", "[", "\"num_channels\"", "]", "\n", "if", "self", ".", "single_channel", ":", "\n", "            ", "if", "self", ".", "like_test", ":", "\n", "                ", "ref_channel", "=", "0", "\n", "", "else", ":", "\n", "                ", "ref_channel", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "num_channels", ")", "\n", "", "x", "=", "x", "[", "ref_channel", "]", "\n", "", "seg_len", "=", "torch", ".", "as_tensor", "(", "[", "x", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "# Load sources", "\n", "source_arrays", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "self", ".", "n_src", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "s", "=", "0", "\n", "for", "t", "in", "target", ":", "\n", "                    ", "if", "t", "==", "\"speech_source\"", ":", "\n", "                        ", "start", "=", "0", "\n", "stop_", "=", "None", "\n", "", "else", ":", "\n", "                        ", "start", "=", "rand_start", "\n", "stop_", "=", "stop", "\n", "", "s_", ",", "_", "=", "sf", ".", "read", "(", "audio_path", "[", "t", "]", "[", "idx", "]", ",", "start", "=", "start", ",", "stop", "=", "stop_", ",", "dtype", "=", "\"float32\"", ")", "\n", "s", "+=", "s_", ".", "T", "\n", "", "", "except", "IndexError", ":", "\n", "                ", "if", "self", ".", "single_channel", ":", "\n", "                    ", "s", "=", "np", ".", "zeros", "(", "(", "seg_len", ",", ")", ")", "\n", "", "else", ":", "\n", "                    ", "s", "=", "np", ".", "zeros", "(", "(", "num_channels", ",", "seg_len", ")", ")", "\n", "", "", "source_arrays", ".", "append", "(", "s", ")", "\n", "\n", "", "if", "target", "[", "0", "]", "==", "\"speech_source\"", ":", "\n", "            ", "from", "sms_wsj", ".", "database", ".", "utils", "import", "extract_piece", "\n", "\n", "offset", "=", "example", "[", "\"offset\"", "]", "\n", "source_arrays", "=", "[", "\n", "extract_piece", "(", "s", ",", "offset_", ",", "num_samples", ")", "for", "s", ",", "offset_", "in", "zip", "(", "source_arrays", ",", "offset", ")", "\n", "]", "\n", "source_arrays", "=", "[", "s", "[", "rand_start", ":", "stop", "]", "for", "s", "in", "source_arrays", "]", "\n", "\n", "", "sources", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "source_arrays", ",", "axis", "=", "0", ")", ")", "\n", "assert", "sources", ".", "shape", "[", "-", "1", "]", "==", "seg_len", "[", "0", "]", ",", "(", "sources", ".", "shape", ",", "seg_len", ")", "\n", "if", "self", ".", "single_channel", "and", "not", "target", "[", "0", "]", "==", "\"source\"", ":", "\n", "            ", "sources", "=", "sources", "[", ":", ",", "ref_channel", "]", "\n", "\n", "", "mixture", "=", "torch", ".", "from_numpy", "(", "x", ")", "\n", "\n", "if", "self", ".", "normalize_audio", ":", "\n", "            ", "m_std", "=", "mixture", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "mixture", "=", "normalize_tensor_wav", "(", "mixture", ",", "eps", "=", "self", ".", "EPS", ",", "std", "=", "m_std", ")", "\n", "sources", "=", "normalize_tensor_wav", "(", "sources", ",", "eps", "=", "self", ".", "EPS", ",", "std", "=", "m_std", ")", "\n", "", "return", "mixture", ",", "sources", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.sms_wsj_dataset.SmsWsjDataset.get_infos": [[224, 236], ["dict"], "methods", ["None"], ["", "def", "get_infos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get dataset infos (for publishing models).\n\n        Returns:\n            dict, dataset infos with keys `dataset`, `task` and `target`.\n        \"\"\"", "\n", "infos", "=", "dict", "(", ")", "\n", "infos", "[", "\"dataset\"", "]", "=", "self", ".", "dataset_name", "\n", "infos", "[", "\"task_dataset\"", "]", "=", "self", ".", "dset", "\n", "infos", "[", "\"target\"", "]", "=", "self", ".", "target", "\n", "infos", "[", "\"licenses\"", "]", "=", "[", "wsj0_license", ",", "wsj1_license", ",", "sms_wsj_license", "]", "\n", "return", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.whamr_dataset.WhamRDataset.__init__": [[81, 132], ["torch.utils.data.Dataset.__init__", "os.path.join", "len", "print", "WHAMR_TASKS.keys", "ValueError", "int", "os.path.join", "open", "json.load", "range", "len", "sources_infos.append", "open", "sources_infos.append", "WHAMR_TASKS.keys", "json.load", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "json_dir", ",", "task", ",", "sample_rate", "=", "8000", ",", "segment", "=", "4.0", ",", "nondefault_nsrc", "=", "None", ")", ":", "\n", "        ", "super", "(", "WhamRDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "task", "not", "in", "WHAMR_TASKS", ".", "keys", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Unexpected task {}, expected one of \"", "\"{}\"", ".", "format", "(", "task", ",", "WHAMR_TASKS", ".", "keys", "(", ")", ")", "\n", ")", "\n", "# Task setting", "\n", "", "self", ".", "json_dir", "=", "json_dir", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "task_dict", "=", "WHAMR_TASKS", "[", "task", "]", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "seg_len", "=", "None", "if", "segment", "is", "None", "else", "int", "(", "segment", "*", "sample_rate", ")", "\n", "if", "not", "nondefault_nsrc", ":", "\n", "            ", "self", ".", "n_src", "=", "self", ".", "task_dict", "[", "\"default_nsrc\"", "]", "\n", "", "else", ":", "\n", "            ", "assert", "nondefault_nsrc", ">=", "self", ".", "task_dict", "[", "\"default_nsrc\"", "]", "\n", "self", ".", "n_src", "=", "nondefault_nsrc", "\n", "", "self", ".", "like_test", "=", "self", ".", "seg_len", "is", "None", "\n", "# Load json files", "\n", "mix_json", "=", "os", ".", "path", ".", "join", "(", "json_dir", ",", "self", ".", "task_dict", "[", "\"mixture\"", "]", "+", "\".json\"", ")", "\n", "sources_json", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "json_dir", ",", "source", "+", "\".json\"", ")", "for", "source", "in", "self", ".", "task_dict", "[", "\"sources\"", "]", "\n", "]", "\n", "with", "open", "(", "mix_json", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "mix_infos", "=", "json", ".", "load", "(", "f", ")", "\n", "", "sources_infos", "=", "[", "]", "\n", "for", "src_json", "in", "sources_json", ":", "\n", "            ", "with", "open", "(", "src_json", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "sources_infos", ".", "append", "(", "json", ".", "load", "(", "f", ")", ")", "\n", "# Filter out short utterances only when segment is specified", "\n", "", "", "orig_len", "=", "len", "(", "mix_infos", ")", "\n", "drop_utt", ",", "drop_len", "=", "0", ",", "0", "\n", "if", "not", "self", ".", "like_test", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "mix_infos", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "# Go backward", "\n", "                ", "if", "mix_infos", "[", "i", "]", "[", "1", "]", "<", "self", ".", "seg_len", ":", "\n", "                    ", "drop_utt", "+=", "1", "\n", "drop_len", "+=", "mix_infos", "[", "i", "]", "[", "1", "]", "\n", "del", "mix_infos", "[", "i", "]", "\n", "for", "src_inf", "in", "sources_infos", ":", "\n", "                        ", "del", "src_inf", "[", "i", "]", "\n", "\n", "", "", "", "", "print", "(", "\n", "\"Drop {} utts({:.2f} h) from {} (shorter than {} samples)\"", ".", "format", "(", "\n", "drop_utt", ",", "drop_len", "/", "sample_rate", "/", "36000", ",", "orig_len", ",", "self", ".", "seg_len", "\n", ")", "\n", ")", "\n", "self", ".", "mix", "=", "mix_infos", "\n", "# Handle the case n_src > default_nsrc", "\n", "while", "len", "(", "sources_infos", ")", "<", "self", ".", "n_src", ":", "\n", "            ", "sources_infos", ".", "append", "(", "[", "None", "for", "_", "in", "range", "(", "len", "(", "self", ".", "mix", ")", ")", "]", ")", "\n", "", "self", ".", "sources", "=", "sources_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.whamr_dataset.WhamRDataset.__add__": [[133, 148], ["ValueError", "min", "print", "zip"], "methods", ["None"], ["", "def", "__add__", "(", "self", ",", "wham", ")", ":", "\n", "        ", "if", "self", ".", "n_src", "!=", "wham", ".", "n_src", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Only datasets having the same number of sources\"", "\n", "\"can be added together. Received \"", "\n", "\"{} and {}\"", ".", "format", "(", "self", ".", "n_src", ",", "wham", ".", "n_src", ")", "\n", ")", "\n", "", "if", "self", ".", "seg_len", "!=", "wham", ".", "seg_len", ":", "\n", "            ", "self", ".", "seg_len", "=", "min", "(", "self", ".", "seg_len", ",", "wham", ".", "seg_len", ")", "\n", "print", "(", "\n", "\"Segment length mismatched between the two Dataset\"", "\n", "\"passed one the smallest to the sum.\"", "\n", ")", "\n", "", "self", ".", "mix", "=", "self", ".", "mix", "+", "wham", ".", "mix", "\n", "self", ".", "sources", "=", "[", "a", "+", "b", "for", "a", ",", "b", "in", "zip", "(", "self", ".", "sources", ",", "wham", ".", "sources", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.whamr_dataset.WhamRDataset.__len__": [[149, 151], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "mix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.whamr_dataset.WhamRDataset.__getitem__": [[152, 180], ["soundfile.read", "torch.as_tensor", "torch.from_numpy", "numpy.random.randint", "source_arrays.append", "numpy.vstack", "torch.from_numpy", "len", "numpy.zeros", "soundfile.read"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.as_tensor", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Gets a mixture/sources pair.\n        Returns:\n            mixture, vstack([source_arrays])\n        \"\"\"", "\n", "# Random start", "\n", "if", "self", ".", "mix", "[", "idx", "]", "[", "1", "]", "==", "self", ".", "seg_len", "or", "self", ".", "like_test", ":", "\n", "            ", "rand_start", "=", "0", "\n", "", "else", ":", "\n", "            ", "rand_start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "mix", "[", "idx", "]", "[", "1", "]", "-", "self", ".", "seg_len", ")", "\n", "", "if", "self", ".", "like_test", ":", "\n", "            ", "stop", "=", "None", "\n", "", "else", ":", "\n", "            ", "stop", "=", "rand_start", "+", "self", ".", "seg_len", "\n", "# Load mixture", "\n", "", "x", ",", "_", "=", "sf", ".", "read", "(", "self", ".", "mix", "[", "idx", "]", "[", "0", "]", ",", "start", "=", "rand_start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ")", "\n", "seg_len", "=", "torch", ".", "as_tensor", "(", "[", "len", "(", "x", ")", "]", ")", "\n", "# Load sources", "\n", "source_arrays", "=", "[", "]", "\n", "for", "src", "in", "self", ".", "sources", ":", "\n", "            ", "if", "src", "[", "idx", "]", "is", "None", ":", "\n", "# Target is filled with zeros if n_src > default_nsrc", "\n", "                ", "s", "=", "np", ".", "zeros", "(", "(", "seg_len", ",", ")", ")", "\n", "", "else", ":", "\n", "                ", "s", ",", "_", "=", "sf", ".", "read", "(", "src", "[", "idx", "]", "[", "0", "]", ",", "start", "=", "rand_start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ")", "\n", "", "source_arrays", ".", "append", "(", "s", ")", "\n", "", "sources", "=", "torch", ".", "from_numpy", "(", "np", ".", "vstack", "(", "source_arrays", ")", ")", "\n", "return", "torch", ".", "from_numpy", "(", "x", ")", ",", "sources", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.whamr_dataset.WhamRDataset.get_infos": [[181, 196], ["dict"], "methods", ["None"], ["", "def", "get_infos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get dataset infos (for publishing models).\n\n        Returns:\n            dict, dataset infos with keys `dataset`, `task` and `licences`.\n        \"\"\"", "\n", "infos", "=", "dict", "(", ")", "\n", "infos", "[", "\"dataset\"", "]", "=", "self", ".", "dataset_name", "\n", "infos", "[", "\"task\"", "]", "=", "self", ".", "task", "\n", "if", "self", ".", "task", "==", "\"sep_clean\"", ":", "\n", "            ", "data_license", "=", "[", "wsj0_license", "]", "\n", "", "else", ":", "\n", "            ", "data_license", "=", "[", "wsj0_license", ",", "wham_noise_license", "]", "\n", "", "infos", "[", "\"licenses\"", "]", "=", "data_license", "\n", "return", "infos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.kinect_wsj.KinectWsjMixDataset.__init__": [[50, 61], ["wsj0_mix.Wsj0mixDataset.__init__", "range", "len", "path.split", "noises.append", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "json_dir", ",", "n_src", "=", "2", ",", "sample_rate", "=", "16000", ",", "segment", "=", "4.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "json_dir", ",", "n_src", "=", "n_src", ",", "sample_rate", "=", "sample_rate", ",", "segment", "=", "segment", ")", "\n", "noises", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "mix", ")", ")", ":", "\n", "            ", "path", "=", "self", ".", "mix", "[", "i", "]", "[", "0", "]", "\n", "# Warning: linux specific", "\n", "path_splits", "=", "path", ".", "split", "(", "\"/\"", ")", "\n", "path_splits", "[", "-", "2", "]", "=", "\"noise\"", "\n", "noise_path", "=", "\"/\"", "+", "os", ".", "path", ".", "join", "(", "*", "path_splits", ")", "\n", "noises", ".", "append", "(", "[", "noise_path", ",", "self", ".", "mix", "[", "i", "]", "[", "1", "]", "]", ")", "\n", "", "self", ".", "noises", "=", "noises", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.kinect_wsj.KinectWsjMixDataset.__getitem__": [[62, 98], ["soundfile.read", "soundfile.read", "torch.from_numpy", "numpy.random.randint", "source_arrays.append", "numpy.stack", "torch.from_numpy", "torch.from_numpy", "numpy.zeros_like", "soundfile.read"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Gets a mixture/sources pair.\n        Returns:\n            mixture, stack([source_arrays]), noise\n            mixture is of dimension [samples, channels]\n            sources are of dimension [n_src, samples, channels]\n        \"\"\"", "\n", "# Random start", "\n", "if", "self", ".", "mix", "[", "idx", "]", "[", "1", "]", "==", "self", ".", "seg_len", "or", "self", ".", "like_test", ":", "\n", "            ", "rand_start", "=", "0", "\n", "", "else", ":", "\n", "            ", "rand_start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "mix", "[", "idx", "]", "[", "1", "]", "-", "self", ".", "seg_len", ")", "\n", "", "if", "self", ".", "like_test", ":", "\n", "            ", "stop", "=", "None", "\n", "", "else", ":", "\n", "            ", "stop", "=", "rand_start", "+", "self", ".", "seg_len", "\n", "# Load mixture", "\n", "", "x", ",", "_", "=", "sf", ".", "read", "(", "\n", "self", ".", "mix", "[", "idx", "]", "[", "0", "]", ",", "start", "=", "rand_start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ",", "always_2d", "=", "True", "\n", ")", "\n", "noise", ",", "_", "=", "sf", ".", "read", "(", "\n", "self", ".", "noises", "[", "idx", "]", "[", "0", "]", ",", "start", "=", "rand_start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ",", "always_2d", "=", "True", "\n", ")", "\n", "# Load sources", "\n", "source_arrays", "=", "[", "]", "\n", "for", "src", "in", "self", ".", "sources", ":", "\n", "            ", "if", "src", "[", "idx", "]", "is", "None", ":", "\n", "# Target is filled with zeros if n_src > default_nsrc", "\n", "                ", "s", "=", "np", ".", "zeros_like", "(", "x", ")", "\n", "", "else", ":", "\n", "                ", "s", ",", "_", "=", "sf", ".", "read", "(", "\n", "src", "[", "idx", "]", "[", "0", "]", ",", "start", "=", "rand_start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ",", "always_2d", "=", "True", "\n", ")", "\n", "", "source_arrays", ".", "append", "(", "s", ")", "\n", "", "sources", "=", "torch", ".", "from_numpy", "(", "np", ".", "stack", "(", "source_arrays", ")", ")", "\n", "return", "torch", ".", "from_numpy", "(", "x", ")", ",", "sources", ",", "torch", ".", "from_numpy", "(", "noise", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.kinect_wsj.KinectWsjMixDataset.get_infos": [[99, 108], ["super().get_infos", "infos[].append"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], ["", "def", "get_infos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get dataset infos (for publishing models).\n\n        Returns:\n            dict, dataset infos with keys `dataset`, `task` and `licences`.\n        \"\"\"", "\n", "infos", "=", "super", "(", ")", ".", "get_infos", "(", ")", "\n", "infos", "[", "\"licenses\"", "]", ".", "append", "(", "chime5_license", ")", "\n", "return", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.kinect_wsj.make_dataloaders": [[9, 31], ["kinect_wsj.KinectWsjMixDataset", "kinect_wsj.KinectWsjMixDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["None"], ["def", "make_dataloaders", "(", "\n", "train_dir", ",", "\n", "valid_dir", ",", "\n", "n_src", "=", "2", ",", "\n", "sample_rate", "=", "16000", ",", "\n", "segment", "=", "4.0", ",", "\n", "batch_size", "=", "4", ",", "\n", "num_workers", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "    ", "num_workers", "=", "num_workers", "if", "num_workers", "else", "batch_size", "\n", "train_set", "=", "KinectWsjMixDataset", "(", "\n", "train_dir", ",", "n_src", "=", "n_src", ",", "sample_rate", "=", "sample_rate", ",", "segment", "=", "segment", "\n", ")", "\n", "val_set", "=", "KinectWsjMixDataset", "(", "valid_dir", ",", "n_src", "=", "n_src", ",", "sample_rate", "=", "sample_rate", ",", "segment", "=", "segment", ")", "\n", "train_loader", "=", "data", ".", "DataLoader", "(", "\n", "train_set", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ",", "num_workers", "=", "num_workers", ",", "drop_last", "=", "True", "\n", ")", "\n", "val_loader", "=", "data", ".", "DataLoader", "(", "\n", "val_set", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ",", "num_workers", "=", "num_workers", ",", "drop_last", "=", "True", "\n", ")", "\n", "return", "train_loader", ",", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.vad_dataset.LibriVADDataset.__init__": [[15, 22], ["open", "json.load"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "md_file_path", ",", "sample_rate", "=", "8000", ",", "segment", "=", "3", ")", ":", "\n", "\n", "        ", "self", ".", "md_filepath", "=", "md_file_path", "\n", "with", "open", "(", "self", ".", "md_filepath", ")", "as", "json_file", ":", "\n", "            ", "self", ".", "md", "=", "json", ".", "load", "(", "json_file", ")", "\n", "", "self", ".", "segment", "=", "segment", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.vad_dataset.LibriVADDataset.__len__": [[23, 25], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "md", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.vad_dataset.LibriVADDataset.__getitem__": [[26, 44], ["len", "soundfile.read", "torch.from_numpy", "from_vad_to_label().unsqueeze", "random.randint", "soundfile.read", "int", "vad_dataset.from_vad_to_label", "int"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.vad_dataset.from_vad_to_label"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "# Get the row in dataframe", "\n", "        ", "row", "=", "self", ".", "md", "[", "idx", "]", "\n", "# Get mixture path", "\n", "self", ".", "source_path", "=", "row", "[", "f\"mixture_path\"", "]", "\n", "length", "=", "len", "(", "sf", ".", "read", "(", "self", ".", "source_path", ")", "[", "0", "]", ")", "\n", "if", "self", ".", "segment", "is", "not", "None", ":", "\n", "            ", "start", "=", "random", ".", "randint", "(", "0", ",", "length", "-", "int", "(", "self", ".", "segment", "*", "self", ".", "sample_rate", ")", ")", "\n", "stop", "=", "start", "+", "int", "(", "self", ".", "segment", "*", "self", ".", "sample_rate", ")", "\n", "", "else", ":", "\n", "            ", "start", "=", "0", "\n", "stop", "=", "None", "\n", "\n", "", "s", ",", "sr", "=", "sf", ".", "read", "(", "self", ".", "source_path", ",", "start", "=", "start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ")", "\n", "# Convert sources to tensor", "\n", "source", "=", "torch", ".", "from_numpy", "(", "s", ")", "\n", "label", "=", "from_vad_to_label", "(", "length", ",", "row", "[", "\"VAD\"", "]", ",", "start", ",", "stop", ")", ".", "unsqueeze", "(", "0", ")", "\n", "return", "source", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.vad_dataset.from_vad_to_label": [[46, 51], ["torch.zeros", "zip"], "function", ["None"], ["", "", "def", "from_vad_to_label", "(", "length", ",", "vad", ",", "begin", ",", "end", ")", ":", "\n", "    ", "label", "=", "torch", ".", "zeros", "(", "length", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "for", "start", ",", "stop", "in", "zip", "(", "vad", "[", "\"start\"", "]", ",", "vad", "[", "\"stop\"", "]", ")", ":", "\n", "        ", "label", "[", "...", ",", "start", ":", "stop", "]", "=", "1", "\n", "", "return", "label", "[", "...", ",", "begin", ":", "end", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dampvsep_dataset.DAMPVSEPSinglesDataset.__init__": [[60, 100], ["pathlib.Path().expanduser", "dampvsep_dataset.DAMPVSEPSinglesDataset.get_tracks", "Exception", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dampvsep_dataset.DAMPVSEPSinglesDataset.get_tracks"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root_path", ",", "\n", "task", ",", "\n", "split", "=", "\"train_singles\"", ",", "\n", "ex_per_track", "=", "1", ",", "\n", "random_segments", "=", "False", ",", "\n", "sample_rate", "=", "16000", ",", "\n", "segment", "=", "None", ",", "\n", "norm", "=", "None", ",", "\n", "source_augmentations", "=", "None", ",", "\n", "mixture", "=", "\"original\"", ",", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "sample_rate", "=", "sample_rate", "\n", "\n", "self", ".", "root_path", "=", "Path", "(", "root_path", ")", ".", "expanduser", "(", ")", "\n", "# Task detail parameters", "\n", "assert", "task", "in", "[", "\"enh_vocal\"", ",", "\"separation\"", "]", ",", "\"Task should be one of 'enh_vocal','separation'\"", "\n", "assert", "mixture", "in", "[", "\"remix\"", ",", "\"original\"", "]", ",", "\"Mixture should be one of 'remix', 'original'\"", "\n", "\n", "self", ".", "task", "=", "task", "\n", "if", "task", "==", "\"enh_vocal\"", ":", "\n", "            ", "self", ".", "target", "=", "[", "\"vocal\"", "]", "\n", "", "elif", "task", "==", "\"separation\"", ":", "\n", "            ", "self", ".", "target", "=", "[", "\"vocal\"", ",", "\"background\"", "]", "\n", "\n", "", "self", ".", "split", "=", "split", "\n", "self", ".", "tracks", "=", "self", ".", "get_tracks", "(", ")", "\n", "self", ".", "perf_key", "=", "[", "*", "self", ".", "tracks", "]", "# list of performances keys", "\n", "\n", "self", ".", "ex_per_track", "=", "ex_per_track", "\n", "self", ".", "random_segments", "=", "random_segments", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "segment", "=", "segment", "\n", "self", ".", "norm", "=", "norm", "\n", "self", ".", "source_augmentations", "=", "source_augmentations", "\n", "self", ".", "mixture", "=", "mixture", "\n", "if", "self", ".", "mixture", "==", "\"original\"", "and", "self", ".", "split", "==", "\"train_english\"", ":", "\n", "            ", "raise", "Exception", "(", "\"The 'train_english' train can only accept 'remix' mixture.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dampvsep_dataset.DAMPVSEPSinglesDataset.__len__": [[101, 103], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "tracks", ")", "*", "self", ".", "ex_per_track", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dampvsep_dataset.DAMPVSEPSinglesDataset._load_audio": [[104, 129], ["warnings.filterwarnings", "librosa.load"], "methods", ["None"], ["", "def", "_load_audio", "(", "self", ",", "path", ",", "start", "=", "0.0", ",", "duration", "=", "None", ",", "scaler", "=", "None", ",", "mean", "=", "0.0", ",", "std", "=", "1.0", ")", ":", "\n", "        ", "import", "librosa", "\n", "\n", "# ignore warning related with", "\n", "# https://github.com/librosa/librosa/issues/1015", "\n", "# Soundfile can read OGG (vocal) but not M4A (background and mixture)", "\n", "import", "warnings", "\n", "\n", "warnings", ".", "filterwarnings", "(", "\"ignore\"", ",", "category", "=", "UserWarning", ")", "\n", "\n", "x", ",", "_", "=", "librosa", ".", "load", "(", "\n", "path", ",", "\n", "sr", "=", "self", ".", "sample_rate", ",", "\n", "mono", "=", "True", ",", "\n", "offset", "=", "start", ",", "\n", "duration", "=", "duration", ",", "\n", "dtype", "=", "\"float32\"", ",", "\n", "res_type", "=", "\"polyphase\"", ",", "\n", ")", "\n", "if", "scaler", ":", "\n", "            ", "x", "*=", "scaler", "\n", "", "x", "-=", "mean", "\n", "x", "/=", "std", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dampvsep_dataset.DAMPVSEPSinglesDataset.__getitem__": [[130, 192], ["torch.stack", "math.floor", "random.uniform", "float", "dampvsep_dataset.DAMPVSEPSinglesDataset._load_audio", "torch.from_numpy", "torch.stack.sum", "dampvsep_dataset.DAMPVSEPSinglesDataset._load_audio", "float", "float", "float", "dampvsep_dataset.DAMPVSEPSinglesDataset.source_augmentations", "float", "float", "float", "float", "torch.stack.items", "float", "float"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dampvsep_dataset.DAMPVSEPSinglesDataset._load_audio", "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dampvsep_dataset.DAMPVSEPSinglesDataset._load_audio"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "import", "math", "\n", "\n", "audio_sources", "=", "{", "}", "\n", "track_id", "=", "index", "//", "self", ".", "ex_per_track", "\n", "perf", "=", "self", ".", "perf_key", "[", "track_id", "]", "\n", "\n", "self", ".", "mixture_path", "=", "perf", "\n", "\n", "# Set start time of segment", "\n", "start", "=", "0.0", "\n", "duration", "=", "math", ".", "floor", "(", "float", "(", "self", ".", "tracks", "[", "perf", "]", "[", "\"duration\"", "]", ")", "*", "100", ")", "/", "100", "\n", "if", "self", ".", "random_segments", ":", "\n", "            ", "start", "=", "random", ".", "uniform", "(", "0.0", ",", "float", "(", "self", ".", "tracks", "[", "perf", "]", "[", "\"duration\"", "]", ")", "-", "self", ".", "segment", ")", "\n", "duration", "=", "float", "(", "self", ".", "segment", ")", "\n", "\n", "", "mix_mean", "=", "0.0", "\n", "mix_std", "=", "1.0", "\n", "if", "self", ".", "norm", "==", "\"song_level\"", ":", "\n", "            ", "if", "self", ".", "mixture", "==", "\"original\"", ":", "\n", "                ", "mix_mean", "=", "float", "(", "self", ".", "tracks", "[", "perf", "]", "[", "\"original_mix_mean\"", "]", ")", "\n", "mix_std", "=", "float", "(", "self", ".", "tracks", "[", "perf", "]", "[", "\"original_mix_std\"", "]", ")", "\n", "", "elif", "self", ".", "mixture", "==", "\"remix\"", ":", "\n", "                ", "mix_mean", "=", "float", "(", "self", ".", "tracks", "[", "perf", "]", "[", "\"mean\"", "]", ")", "\n", "mix_std", "=", "float", "(", "self", ".", "tracks", "[", "perf", "]", "[", "\"std\"", "]", ")", "\n", "\n", "", "", "for", "source", "in", "[", "\"vocal\"", ",", "\"background\"", "]", ":", "\n", "            ", "scaler", "=", "None", "\n", "if", "source", "==", "\"vocal\"", ":", "\n", "                ", "scaler", "=", "float", "(", "self", ".", "tracks", "[", "perf", "]", "[", "\"scaler\"", "]", ")", "\n", "\n", "", "x", "=", "self", ".", "_load_audio", "(", "\n", "self", ".", "root_path", "/", "self", ".", "tracks", "[", "perf", "]", "[", "source", "]", ",", "\n", "start", "=", "start", "+", "float", "(", "self", ".", "tracks", "[", "perf", "]", "[", "f\"{source}_start\"", "]", ")", ",", "\n", "duration", "=", "duration", ",", "\n", "scaler", "=", "scaler", ",", "\n", "mean", "=", "mix_mean", ",", "\n", "std", "=", "mix_std", ",", "\n", ")", "\n", "if", "self", ".", "source_augmentations", ":", "\n", "                ", "x", "=", "self", ".", "source_augmentations", "(", "x", ",", "self", ".", "sample_rate", ")", "\n", "", "x", "=", "torch", ".", "from_numpy", "(", "x", ".", "T", ")", "\n", "\n", "audio_sources", "[", "source", "]", "=", "x", "\n", "\n", "# Prepare targets and mixture", "\n", "", "audio_sources", "=", "torch", ".", "stack", "(", "\n", "[", "wav", "for", "src", ",", "wav", "in", "audio_sources", ".", "items", "(", ")", "if", "src", "in", "self", ".", "target", "]", ",", "dim", "=", "0", "\n", ")", "\n", "\n", "if", "self", ".", "mixture", "==", "\"remix\"", ":", "\n", "            ", "audio_mix", "=", "audio_sources", ".", "sum", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "audio_mix", "=", "self", ".", "_load_audio", "(", "\n", "self", ".", "root_path", "/", "self", ".", "tracks", "[", "perf", "]", "[", "\"original_mix\"", "]", ",", "\n", "start", "=", "start", "+", "float", "(", "self", ".", "tracks", "[", "perf", "]", "[", "\"background_start\"", "]", ")", ",", "\n", "duration", "=", "duration", ",", "\n", "mean", "=", "mix_mean", ",", "\n", "std", "=", "mix_std", ",", "\n", ")", "\n", "\n", "", "return", "audio_mix", ",", "audio_sources", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dampvsep_dataset.DAMPVSEPSinglesDataset.get_track_name": [[193, 196], ["None"], "methods", ["None"], ["", "def", "get_track_name", "(", "self", ",", "idx", ")", ":", "\n", "        ", "track_id", "=", "idx", "//", "self", ".", "ex_per_track", "\n", "return", "self", ".", "perf_key", "[", "track_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dampvsep_dataset.DAMPVSEPSinglesDataset.get_tracks": [[197, 207], ["pathlib.Path", "pathlib.Path.exists", "json.load", "RuntimeError", "open"], "methods", ["None"], ["", "def", "get_tracks", "(", "self", ")", ":", "\n", "        ", "\"\"\"Loads metadata with tracks info.\n        Raises error if metadata doesn't exist.\n        \"\"\"", "\n", "metadata_path", "=", "Path", "(", "f\"metadata/{self.split}_sr{self.sample_rate}.json\"", ")", "\n", "if", "metadata_path", ".", "exists", "(", ")", ":", "\n", "            ", "tracks", "=", "json", ".", "load", "(", "open", "(", "metadata_path", ",", "\"r\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "f\"Metadata file for {self.split} not found\"", ")", "\n", "", "return", "tracks", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dampvsep_dataset.DAMPVSEPSinglesDataset.get_infos": [[208, 219], ["dict"], "methods", ["None"], ["", "def", "get_infos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get dataset infos (for publishing models).\n\n        Returns:\n            dict, dataset infos with keys `dataset`, `task` and `licences`.\n        \"\"\"", "\n", "infos", "=", "dict", "(", ")", "\n", "infos", "[", "\"dataset\"", "]", "=", "self", ".", "dataset_name", "\n", "infos", "[", "\"task\"", "]", "=", "self", ".", "task", "\n", "infos", "[", "\"licenses\"", "]", "=", "[", "dampvsep_license", "]", "\n", "return", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wham_dataset.WhamDataset.__init__": [[65, 126], ["torch.utils.data.Dataset.__init__", "os.path.join", "len", "print", "WHAM_TASKS.keys", "ValueError", "int", "os.path.join", "open", "json.load", "range", "len", "sources_infos.append", "open", "sources_infos.append", "WHAM_TASKS.keys", "json.load", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "json_dir", ",", "\n", "task", ",", "\n", "sample_rate", "=", "8000", ",", "\n", "segment", "=", "4.0", ",", "\n", "nondefault_nsrc", "=", "None", ",", "\n", "normalize_audio", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "WhamDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "task", "not", "in", "WHAM_TASKS", ".", "keys", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Unexpected task {}, expected one of \"", "\"{}\"", ".", "format", "(", "task", ",", "WHAM_TASKS", ".", "keys", "(", ")", ")", "\n", ")", "\n", "# Task setting", "\n", "", "self", ".", "json_dir", "=", "json_dir", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "task_dict", "=", "WHAM_TASKS", "[", "task", "]", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "normalize_audio", "=", "normalize_audio", "\n", "self", ".", "seg_len", "=", "None", "if", "segment", "is", "None", "else", "int", "(", "segment", "*", "sample_rate", ")", "\n", "self", ".", "EPS", "=", "1e-8", "\n", "if", "not", "nondefault_nsrc", ":", "\n", "            ", "self", ".", "n_src", "=", "self", ".", "task_dict", "[", "\"default_nsrc\"", "]", "\n", "", "else", ":", "\n", "            ", "assert", "nondefault_nsrc", ">=", "self", ".", "task_dict", "[", "\"default_nsrc\"", "]", "\n", "self", ".", "n_src", "=", "nondefault_nsrc", "\n", "", "self", ".", "like_test", "=", "self", ".", "seg_len", "is", "None", "\n", "# Load json files", "\n", "mix_json", "=", "os", ".", "path", ".", "join", "(", "json_dir", ",", "self", ".", "task_dict", "[", "\"mixture\"", "]", "+", "\".json\"", ")", "\n", "sources_json", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "json_dir", ",", "source", "+", "\".json\"", ")", "for", "source", "in", "self", ".", "task_dict", "[", "\"sources\"", "]", "\n", "]", "\n", "with", "open", "(", "mix_json", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "mix_infos", "=", "json", ".", "load", "(", "f", ")", "\n", "", "sources_infos", "=", "[", "]", "\n", "for", "src_json", "in", "sources_json", ":", "\n", "            ", "with", "open", "(", "src_json", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "sources_infos", ".", "append", "(", "json", ".", "load", "(", "f", ")", ")", "\n", "# Filter out short utterances only when segment is specified", "\n", "", "", "orig_len", "=", "len", "(", "mix_infos", ")", "\n", "drop_utt", ",", "drop_len", "=", "0", ",", "0", "\n", "if", "not", "self", ".", "like_test", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "mix_infos", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "# Go backward", "\n", "                ", "if", "mix_infos", "[", "i", "]", "[", "1", "]", "<", "self", ".", "seg_len", ":", "\n", "                    ", "drop_utt", "+=", "1", "\n", "drop_len", "+=", "mix_infos", "[", "i", "]", "[", "1", "]", "\n", "del", "mix_infos", "[", "i", "]", "\n", "for", "src_inf", "in", "sources_infos", ":", "\n", "                        ", "del", "src_inf", "[", "i", "]", "\n", "\n", "", "", "", "", "print", "(", "\n", "\"Drop {} utts({:.2f} h) from {} (shorter than {} samples)\"", ".", "format", "(", "\n", "drop_utt", ",", "drop_len", "/", "sample_rate", "/", "36000", ",", "orig_len", ",", "self", ".", "seg_len", "\n", ")", "\n", ")", "\n", "self", ".", "mix", "=", "mix_infos", "\n", "# Handle the case n_src > default_nsrc", "\n", "while", "len", "(", "sources_infos", ")", "<", "self", ".", "n_src", ":", "\n", "            ", "sources_infos", ".", "append", "(", "[", "None", "for", "_", "in", "range", "(", "len", "(", "self", ".", "mix", ")", ")", "]", ")", "\n", "", "self", ".", "sources", "=", "sources_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wham_dataset.WhamDataset.__add__": [[127, 142], ["ValueError", "min", "print", "zip"], "methods", ["None"], ["", "def", "__add__", "(", "self", ",", "wham", ")", ":", "\n", "        ", "if", "self", ".", "n_src", "!=", "wham", ".", "n_src", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Only datasets having the same number of sources\"", "\n", "\"can be added together. Received \"", "\n", "\"{} and {}\"", ".", "format", "(", "self", ".", "n_src", ",", "wham", ".", "n_src", ")", "\n", ")", "\n", "", "if", "self", ".", "seg_len", "!=", "wham", ".", "seg_len", ":", "\n", "            ", "self", ".", "seg_len", "=", "min", "(", "self", ".", "seg_len", ",", "wham", ".", "seg_len", ")", "\n", "print", "(", "\n", "\"Segment length mismatched between the two Dataset\"", "\n", "\"passed one the smallest to the sum.\"", "\n", ")", "\n", "", "self", ".", "mix", "=", "self", ".", "mix", "+", "wham", ".", "mix", "\n", "self", ".", "sources", "=", "[", "a", "+", "b", "for", "a", ",", "b", "in", "zip", "(", "self", ".", "sources", ",", "wham", ".", "sources", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wham_dataset.WhamDataset.__len__": [[143, 145], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "mix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wham_dataset.WhamDataset.__getitem__": [[146, 180], ["soundfile.read", "torch.as_tensor", "torch.from_numpy", "torch.from_numpy", "numpy.random.randint", "source_arrays.append", "numpy.vstack", "normalize_tensor_wav.std", "wham_dataset.normalize_tensor_wav", "wham_dataset.normalize_tensor_wav", "len", "numpy.zeros", "soundfile.read"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.as_tensor", "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wham_dataset.normalize_tensor_wav", "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wham_dataset.normalize_tensor_wav", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Gets a mixture/sources pair.\n        Returns:\n            mixture, vstack([source_arrays])\n        \"\"\"", "\n", "# Random start", "\n", "if", "self", ".", "mix", "[", "idx", "]", "[", "1", "]", "==", "self", ".", "seg_len", "or", "self", ".", "like_test", ":", "\n", "            ", "rand_start", "=", "0", "\n", "", "else", ":", "\n", "            ", "rand_start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "mix", "[", "idx", "]", "[", "1", "]", "-", "self", ".", "seg_len", ")", "\n", "", "if", "self", ".", "like_test", ":", "\n", "            ", "stop", "=", "None", "\n", "", "else", ":", "\n", "            ", "stop", "=", "rand_start", "+", "self", ".", "seg_len", "\n", "# Load mixture", "\n", "", "x", ",", "_", "=", "sf", ".", "read", "(", "self", ".", "mix", "[", "idx", "]", "[", "0", "]", ",", "start", "=", "rand_start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ")", "\n", "seg_len", "=", "torch", ".", "as_tensor", "(", "[", "len", "(", "x", ")", "]", ")", "\n", "# Load sources", "\n", "source_arrays", "=", "[", "]", "\n", "for", "src", "in", "self", ".", "sources", ":", "\n", "            ", "if", "src", "[", "idx", "]", "is", "None", ":", "\n", "# Target is filled with zeros if n_src > default_nsrc", "\n", "                ", "s", "=", "np", ".", "zeros", "(", "(", "seg_len", ",", ")", ")", "\n", "", "else", ":", "\n", "                ", "s", ",", "_", "=", "sf", ".", "read", "(", "src", "[", "idx", "]", "[", "0", "]", ",", "start", "=", "rand_start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ")", "\n", "", "source_arrays", ".", "append", "(", "s", ")", "\n", "", "sources", "=", "torch", ".", "from_numpy", "(", "np", ".", "vstack", "(", "source_arrays", ")", ")", "\n", "mixture", "=", "torch", ".", "from_numpy", "(", "x", ")", "\n", "\n", "if", "self", ".", "normalize_audio", ":", "\n", "            ", "m_std", "=", "mixture", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "mixture", "=", "normalize_tensor_wav", "(", "mixture", ",", "eps", "=", "self", ".", "EPS", ",", "std", "=", "m_std", ")", "\n", "sources", "=", "normalize_tensor_wav", "(", "sources", ",", "eps", "=", "self", ".", "EPS", ",", "std", "=", "m_std", ")", "\n", "", "return", "mixture", ",", "sources", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wham_dataset.WhamDataset.get_infos": [[181, 196], ["dict"], "methods", ["None"], ["", "def", "get_infos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get dataset infos (for publishing models).\n\n        Returns:\n            dict, dataset infos with keys `dataset`, `task` and `licences`.\n        \"\"\"", "\n", "infos", "=", "dict", "(", ")", "\n", "infos", "[", "\"dataset\"", "]", "=", "self", ".", "dataset_name", "\n", "infos", "[", "\"task\"", "]", "=", "self", ".", "task", "\n", "if", "self", ".", "task", "==", "\"sep_clean\"", ":", "\n", "            ", "data_license", "=", "[", "wsj0_license", "]", "\n", "", "else", ":", "\n", "            ", "data_license", "=", "[", "wsj0_license", ",", "wham_noise_license", "]", "\n", "", "infos", "[", "\"licenses\"", "]", "=", "data_license", "\n", "return", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wham_dataset.normalize_tensor_wav": [[28, 33], ["wav_tensor.mean", "wav_tensor.std"], "function", ["None"], ["def", "normalize_tensor_wav", "(", "wav_tensor", ",", "eps", "=", "1e-8", ",", "std", "=", "None", ")", ":", "\n", "    ", "mean", "=", "wav_tensor", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "std", "is", "None", ":", "\n", "        ", "std", "=", "wav_tensor", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "", "return", "(", "wav_tensor", "-", "mean", ")", "/", "(", "std", "+", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dns_dataset.DNSDataset.__init__": [[21, 29], ["torch.utils.data.Dataset.__init__", "list", "open", "json.load", "dns_dataset.DNSDataset.mix_infos.keys", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "json_dir", ")", ":", "\n", "\n", "        ", "super", "(", "DNSDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "json_dir", "=", "json_dir", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "json_dir", ",", "\"file_infos.json\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "self", ".", "mix_infos", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "wav_ids", "=", "list", "(", "self", ".", "mix_infos", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dns_dataset.DNSDataset.__len__": [[30, 32], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "wav_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dns_dataset.DNSDataset.__getitem__": [[33, 46], ["torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "soundfile.read", "soundfile.read", "soundfile.read"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Gets a mixture/sources pair.\n        Returns:\n            mixture, vstack([source_arrays])\n        \"\"\"", "\n", "utt_info", "=", "self", ".", "mix_infos", "[", "self", ".", "wav_ids", "[", "idx", "]", "]", "\n", "# Load mixture", "\n", "x", "=", "torch", ".", "from_numpy", "(", "sf", ".", "read", "(", "utt_info", "[", "\"mix\"", "]", ",", "dtype", "=", "\"float32\"", ")", "[", "0", "]", ")", "\n", "# Load clean", "\n", "speech", "=", "torch", ".", "from_numpy", "(", "sf", ".", "read", "(", "utt_info", "[", "\"clean\"", "]", ",", "dtype", "=", "\"float32\"", ")", "[", "0", "]", ")", "\n", "# Load noise", "\n", "noise", "=", "torch", ".", "from_numpy", "(", "sf", ".", "read", "(", "utt_info", "[", "\"noise\"", "]", ",", "dtype", "=", "\"float32\"", ")", "[", "0", "]", ")", "\n", "return", "x", ",", "speech", ",", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.dns_dataset.DNSDataset.get_infos": [[47, 58], ["dict"], "methods", ["None"], ["", "def", "get_infos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get dataset infos (for publishing models).\n\n        Returns:\n            dict, dataset infos with keys `dataset`, `task` and `licences`.\n        \"\"\"", "\n", "infos", "=", "dict", "(", ")", "\n", "infos", "[", "\"dataset\"", "]", "=", "self", ".", "dataset_name", "\n", "infos", "[", "\"task\"", "]", "=", "\"enhancement\"", "\n", "infos", "[", "\"licenses\"", "]", "=", "[", "dns_license", "]", "\n", "return", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.fuss_dataset.FUSSDataset.__init__": [[24, 46], ["torch.utils.data.Dataset.__init__", "pandas.read_csv", "fuss_dataset.FUSSDataset.mix_df.fillna", "range"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "file_list_path", ",", "return_bg", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# Arguments", "\n", "self", ".", "return_bg", "=", "return_bg", "\n", "# Constants", "\n", "self", ".", "max_n_fg", "=", "3", "\n", "self", ".", "n_src", "=", "self", ".", "max_n_fg", "# Same variable as in WHAM", "\n", "self", ".", "sample_rate", "=", "16000", "\n", "self", ".", "num_samples", "=", "self", ".", "sample_rate", "*", "10", "\n", "\n", "# Load the file list as a dataframe", "\n", "# FUSS has a maximum of 3 foregrounds, make column names", "\n", "self", ".", "fg_names", "=", "[", "f\"fg{i}\"", "for", "i", "in", "range", "(", "self", ".", "max_n_fg", ")", "]", "\n", "names", "=", "[", "\"mix\"", ",", "\"bg\"", "]", "+", "self", ".", "fg_names", "\n", "# Lines with less labels will have nan, replace with empty string", "\n", "self", ".", "mix_df", "=", "pd", ".", "read_csv", "(", "file_list_path", ",", "sep", "=", "\"\\t\"", ",", "names", "=", "names", ")", "\n", "# Number of foregrounds (fg) vary from 0 to 3", "\n", "# This can easily be used to remove mixtures with less than x fg", "\n", "# remove_less_than = 1", "\n", "# self.mix_df.dropna(threshold=remove_less_than, inplace=True)", "\n", "# self.mix_df.reset_index(inplace=True)", "\n", "self", ".", "mix_df", ".", "fillna", "(", "value", "=", "\"\"", ",", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.fuss_dataset.FUSSDataset.__len__": [[47, 49], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "mix_df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.fuss_dataset.FUSSDataset.__getitem__": [[50, 66], ["torch.from_numpy", "soundfile.read", "numpy.vstack", "torch.from_numpy", "torch.from_numpy.append", "torch.from_numpy.append", "soundfile.read", "torch.from_numpy", "torch.from_numpy", "numpy.zeros_like", "soundfile.read"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "# Each line has absolute to miture, background and foregrounds", "\n", "        ", "line", "=", "self", ".", "mix_df", ".", "iloc", "[", "idx", "]", "\n", "mix", "=", "sf", ".", "read", "(", "line", "[", "\"mix\"", "]", ",", "dtype", "=", "\"float32\"", ")", "[", "0", "]", "\n", "sources", "=", "[", "]", "\n", "for", "fg_path", "in", "[", "line", "[", "fg_n", "]", "for", "fg_n", "in", "self", ".", "fg_names", "]", ":", "\n", "            ", "if", "fg_path", ":", "\n", "                ", "sources", ".", "append", "(", "sf", ".", "read", "(", "fg_path", ",", "dtype", "=", "\"float32\"", ")", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                ", "sources", ".", "append", "(", "np", ".", "zeros_like", "(", "mix", ")", ")", "\n", "", "", "sources", "=", "torch", ".", "from_numpy", "(", "np", ".", "vstack", "(", "sources", ")", ")", "\n", "\n", "if", "self", ".", "return_bg", ":", "\n", "            ", "bg", "=", "sf", ".", "read", "(", "line", "[", "\"bg\"", "]", ",", "dtype", "=", "\"float32\"", ")", "[", "0", "]", "\n", "return", "torch", ".", "from_numpy", "(", "mix", ")", ",", "sources", ",", "torch", ".", "from_numpy", "(", "bg", ")", "\n", "", "return", "torch", ".", "from_numpy", "(", "mix", ")", ",", "sources", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.fuss_dataset.FUSSDataset.get_infos": [[67, 78], ["dict"], "methods", ["None"], ["", "def", "get_infos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get dataset infos (for publishing models).\n\n        Returns:\n            dict, dataset infos with keys `dataset`, `task` and `licences`.\n        \"\"\"", "\n", "infos", "=", "dict", "(", ")", "\n", "infos", "[", "\"dataset\"", "]", "=", "self", ".", "dataset_name", "\n", "infos", "[", "\"task\"", "]", "=", "\"sep_noisy\"", "\n", "infos", "[", "\"licenses\"", "]", "=", "[", "fuss_license", "]", "\n", "return", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.librimix_dataset.LibriMix.__init__": [[41, 79], ["pandas.read_csv", "os.path.join", "len", "int", "print", "os.path.join", "pandas.read_csv", "os.path.join", "os.path.join", "os.listdir", "os.path.join", "os.listdir", "os.listdir", "len", "os.listdir", "os.listdir"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "csv_dir", ",", "task", "=", "\"sep_clean\"", ",", "sample_rate", "=", "16000", ",", "n_src", "=", "2", ",", "segment", "=", "3", ",", "return_id", "=", "False", "\n", ")", ":", "\n", "        ", "self", ".", "csv_dir", "=", "csv_dir", "\n", "self", ".", "task", "=", "task", "\n", "self", ".", "return_id", "=", "return_id", "\n", "# Get the csv corresponding to the task", "\n", "if", "task", "==", "\"enh_single\"", ":", "\n", "            ", "md_file", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "csv_dir", ")", "if", "\"single\"", "in", "f", "]", "[", "0", "]", "\n", "self", ".", "csv_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "csv_dir", ",", "md_file", ")", "\n", "", "elif", "task", "==", "\"enh_both\"", ":", "\n", "            ", "md_file", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "csv_dir", ")", "if", "\"both\"", "in", "f", "]", "[", "0", "]", "\n", "self", ".", "csv_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "csv_dir", ",", "md_file", ")", "\n", "md_clean_file", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "csv_dir", ")", "if", "\"clean\"", "in", "f", "]", "[", "0", "]", "\n", "self", ".", "df_clean", "=", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "csv_dir", ",", "md_clean_file", ")", ")", "\n", "", "elif", "task", "==", "\"sep_clean\"", ":", "\n", "            ", "md_file", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "csv_dir", ")", "if", "\"clean\"", "in", "f", "]", "[", "0", "]", "\n", "self", ".", "csv_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "csv_dir", ",", "md_file", ")", "\n", "", "elif", "task", "==", "\"sep_noisy\"", ":", "\n", "            ", "md_file", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "csv_dir", ")", "if", "\"both\"", "in", "f", "]", "[", "0", "]", "\n", "self", ".", "csv_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "csv_dir", ",", "md_file", ")", "\n", "", "self", ".", "segment", "=", "segment", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "# Open csv file", "\n", "self", ".", "df", "=", "pd", ".", "read_csv", "(", "self", ".", "csv_path", ")", "\n", "# Get rid of the utterances too short", "\n", "if", "self", ".", "segment", "is", "not", "None", ":", "\n", "            ", "max_len", "=", "len", "(", "self", ".", "df", ")", "\n", "self", ".", "seg_len", "=", "int", "(", "self", ".", "segment", "*", "self", ".", "sample_rate", ")", "\n", "# Ignore the file shorter than the desired_length", "\n", "self", ".", "df", "=", "self", ".", "df", "[", "self", ".", "df", "[", "\"length\"", "]", ">=", "self", ".", "seg_len", "]", "\n", "print", "(", "\n", "f\"Drop {max_len - len(self.df)} utterances from {max_len} \"", "\n", "f\"(shorter than {segment} seconds)\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "seg_len", "=", "None", "\n", "", "self", ".", "n_src", "=", "n_src", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.librimix_dataset.LibriMix.__len__": [[80, 82], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.librimix_dataset.LibriMix.__getitem__": [[83, 122], ["soundfile.read", "torch.from_numpy", "numpy.vstack", "torch.from_numpy", "[].split", "random.randint", "soundfile.read", "sources_list.append", "range", "soundfile.read", "sources_list.append", "[].split", "mixture_path.split"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "# Get the row in dataframe", "\n", "        ", "row", "=", "self", ".", "df", ".", "iloc", "[", "idx", "]", "\n", "# Get mixture path", "\n", "mixture_path", "=", "row", "[", "\"mixture_path\"", "]", "\n", "self", ".", "mixture_path", "=", "mixture_path", "\n", "sources_list", "=", "[", "]", "\n", "# If there is a seg start point is set randomly", "\n", "if", "self", ".", "seg_len", "is", "not", "None", ":", "\n", "            ", "start", "=", "random", ".", "randint", "(", "0", ",", "row", "[", "\"length\"", "]", "-", "self", ".", "seg_len", ")", "\n", "stop", "=", "start", "+", "self", ".", "seg_len", "\n", "", "else", ":", "\n", "            ", "start", "=", "0", "\n", "stop", "=", "None", "\n", "# If task is enh_both then the source is the clean mixture", "\n", "", "if", "\"enh_both\"", "in", "self", ".", "task", ":", "\n", "            ", "mix_clean_path", "=", "self", ".", "df_clean", ".", "iloc", "[", "idx", "]", "[", "\"mixture_path\"", "]", "\n", "s", ",", "_", "=", "sf", ".", "read", "(", "mix_clean_path", ",", "dtype", "=", "\"float32\"", ",", "start", "=", "start", ",", "stop", "=", "stop", ")", "\n", "sources_list", ".", "append", "(", "s", ")", "\n", "\n", "", "else", ":", "\n", "# Read sources", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "n_src", ")", ":", "\n", "                ", "source_path", "=", "row", "[", "f\"source_{i + 1}_path\"", "]", "\n", "s", ",", "_", "=", "sf", ".", "read", "(", "source_path", ",", "dtype", "=", "\"float32\"", ",", "start", "=", "start", ",", "stop", "=", "stop", ")", "\n", "sources_list", ".", "append", "(", "s", ")", "\n", "# Read the mixture", "\n", "", "", "mixture", ",", "_", "=", "sf", ".", "read", "(", "mixture_path", ",", "dtype", "=", "\"float32\"", ",", "start", "=", "start", ",", "stop", "=", "stop", ")", "\n", "# Convert to torch tensor", "\n", "mixture", "=", "torch", ".", "from_numpy", "(", "mixture", ")", "\n", "# Stack sources", "\n", "sources", "=", "np", ".", "vstack", "(", "sources_list", ")", "\n", "# Convert sources to tensor", "\n", "sources", "=", "torch", ".", "from_numpy", "(", "sources", ")", "\n", "if", "not", "self", ".", "return_id", ":", "\n", "            ", "return", "mixture", ",", "sources", "\n", "# 5400-34479-0005_4973-24515-0007.wav", "\n", "", "id1", ",", "id2", "=", "mixture_path", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", ".", "split", "(", "\"_\"", ")", "\n", "return", "mixture", ",", "sources", ",", "[", "id1", ",", "id2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.librimix_dataset.LibriMix.loaders_from_mini": [[123, 149], ["cls.mini_from_download", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.librimix_dataset.LibriMix.mini_from_download"], ["", "@", "classmethod", "\n", "def", "loaders_from_mini", "(", "cls", ",", "batch_size", "=", "4", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Downloads MiniLibriMix and returns train and validation DataLoader.\n\n        Args:\n            batch_size (int): Batch size of the Dataloader. Only DataLoader param.\n                To have more control on Dataloader, call `mini_from_download` and\n                instantiate the DatalLoader.\n            **kwargs: keyword arguments to pass the `LibriMix`, see `__init__`.\n                The kwargs will be fed to both the training set and validation\n                set.\n\n        Returns:\n            train_loader, val_loader: training and validation DataLoader out of\n            `LibriMix` Dataset.\n\n        Examples\n            >>> from asteroid.data import LibriMix\n            >>> train_loader, val_loader = LibriMix.loaders_from_mini(\n            >>>     task='sep_clean', batch_size=4\n            >>> )\n        \"\"\"", "\n", "train_set", ",", "val_set", "=", "cls", ".", "mini_from_download", "(", "**", "kwargs", ")", "\n", "train_loader", "=", "DataLoader", "(", "train_set", ",", "batch_size", "=", "batch_size", ",", "drop_last", "=", "True", ")", "\n", "val_loader", "=", "DataLoader", "(", "val_set", ",", "batch_size", "=", "batch_size", ",", "drop_last", "=", "True", ")", "\n", "return", "train_loader", ",", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.librimix_dataset.LibriMix.mini_from_download": [[150, 184], ["cls.mini_download", "cls", "cls", "kwargs.get", "kwargs.get", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.librimix_dataset.LibriMix.mini_download", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "@", "classmethod", "\n", "def", "mini_from_download", "(", "cls", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Downloads MiniLibriMix and returns train and validation Dataset.\n        If you want to instantiate the Dataset by yourself, call\n        `mini_download` that returns the path to the path to the metadata files.\n\n        Args:\n            **kwargs: keyword arguments to pass the `LibriMix`, see `__init__`.\n                The kwargs will be fed to both the training set and validation\n                set\n\n        Returns:\n            train_set, val_set: training and validation instances of\n            `LibriMix` (data.Dataset).\n\n        Examples\n            >>> from asteroid.data import LibriMix\n            >>> train_set, val_set = LibriMix.mini_from_download(task='sep_clean')\n        \"\"\"", "\n", "# kwargs checks", "\n", "assert", "\"csv_dir\"", "not", "in", "kwargs", ",", "\"Cannot specify csv_dir when downloading.\"", "\n", "assert", "kwargs", ".", "get", "(", "\"task\"", ",", "\"sep_clean\"", ")", "in", "[", "\n", "\"sep_clean\"", ",", "\n", "\"sep_noisy\"", ",", "\n", "]", ",", "\"Only clean and noisy separation are supported in MiniLibriMix.\"", "\n", "assert", "(", "\n", "kwargs", ".", "get", "(", "\"sample_rate\"", ",", "8000", ")", "==", "8000", "\n", ")", ",", "\"Only 8kHz sample rate is supported in MiniLibriMix.\"", "\n", "# Download LibriMix in current directory", "\n", "meta_path", "=", "cls", ".", "mini_download", "(", ")", "\n", "# Create dataset instances", "\n", "train_set", "=", "cls", "(", "os", ".", "path", ".", "join", "(", "meta_path", ",", "\"train\"", ")", ",", "sample_rate", "=", "8000", ",", "**", "kwargs", ")", "\n", "val_set", "=", "cls", "(", "os", ".", "path", ".", "join", "(", "meta_path", ",", "\"val\"", ")", ",", "sample_rate", "=", "8000", ",", "**", "kwargs", ")", "\n", "return", "train_set", ",", "val_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.librimix_dataset.LibriMix.mini_download": [[185, 214], ["os.makedirs", "all", "os.path.isfile", "torch.hub.download_url_to_file", "os.makedirs", "os.path.isdir", "zipfile.ZipFile", "zip_ref.extractall", "shutil.copyfile", "os.listdir", "os.path.isfile"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "mini_download", "(", ")", ":", "\n", "        ", "\"\"\"Downloads MiniLibriMix from Zenodo in current directory\n\n        Returns:\n            The path to the metadata directory.\n        \"\"\"", "\n", "mini_dir", "=", "\"./MiniLibriMix/\"", "\n", "os", ".", "makedirs", "(", "mini_dir", ",", "exist_ok", "=", "True", ")", "\n", "# Download zip (or cached)", "\n", "zip_path", "=", "mini_dir", "+", "\"MiniLibriMix.zip\"", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "zip_path", ")", ":", "\n", "            ", "hub", ".", "download_url_to_file", "(", "MINI_URL", ",", "zip_path", ")", "\n", "# Unzip zip", "\n", "", "cond", "=", "all", "(", "[", "os", ".", "path", ".", "isdir", "(", "\"MiniLibriMix/\"", "+", "f", ")", "for", "f", "in", "[", "\"train\"", ",", "\"val\"", ",", "\"metadata\"", "]", "]", ")", "\n", "if", "not", "cond", ":", "\n", "            ", "with", "zipfile", ".", "ZipFile", "(", "zip_path", ",", "\"r\"", ")", "as", "zip_ref", ":", "\n", "                ", "zip_ref", ".", "extractall", "(", "\"./\"", ")", "# Will unzip in MiniLibriMix", "\n", "# Reorder metadata", "\n", "", "", "src", "=", "\"MiniLibriMix/metadata/\"", "\n", "for", "mode", "in", "[", "\"train\"", ",", "\"val\"", "]", ":", "\n", "            ", "dst", "=", "f\"MiniLibriMix/metadata/{mode}/\"", "\n", "os", ".", "makedirs", "(", "dst", ",", "exist_ok", "=", "True", ")", "\n", "[", "\n", "shutil", ".", "copyfile", "(", "src", "+", "f", ",", "dst", "+", "f", ")", "\n", "for", "f", "in", "os", ".", "listdir", "(", "src", ")", "\n", "if", "mode", "in", "f", "and", "os", ".", "path", ".", "isfile", "(", "src", "+", "f", ")", "\n", "]", "\n", "", "return", "\"./MiniLibriMix/metadata\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.librimix_dataset.LibriMix.get_infos": [[215, 230], ["dict", "librimix_dataset.LibriMix._dataset_name"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.librimix_dataset.LibriMix._dataset_name"], ["", "def", "get_infos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get dataset infos (for publishing models).\n\n        Returns:\n            dict, dataset infos with keys `dataset`, `task` and `licences`.\n        \"\"\"", "\n", "infos", "=", "dict", "(", ")", "\n", "infos", "[", "\"dataset\"", "]", "=", "self", ".", "_dataset_name", "(", ")", "\n", "infos", "[", "\"task\"", "]", "=", "self", ".", "task", "\n", "if", "self", ".", "task", "==", "\"sep_clean\"", ":", "\n", "            ", "data_license", "=", "[", "librispeech_license", "]", "\n", "", "else", ":", "\n", "            ", "data_license", "=", "[", "librispeech_license", ",", "wham_noise_license", "]", "\n", "", "infos", "[", "\"licenses\"", "]", "=", "data_license", "\n", "return", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.librimix_dataset.LibriMix._dataset_name": [[231, 234], ["None"], "methods", ["None"], ["", "def", "_dataset_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"Differentiate between 2 and 3 sources.\"\"\"", "\n", "return", "f\"Libri{self.n_src}Mix\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.Signal.__init__": [[49, 80], ["isinstance", "isinstance", "isinstance", "avspeech_dataset.Signal._load", "avspeech_dataset.Signal._check_video_embed", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.Signal._load", "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.Signal._check_video_embed"], ["def", "__init__", "(", "\n", "self", ",", "\n", "video_path", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "audio_path", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "embed_dir", ":", "Union", "[", "str", ",", "Path", "]", ",", "\n", "sr", "=", "16_000", ",", "\n", "video_start_length", "=", "0", ",", "\n", "fps", "=", "25", ",", "\n", "signal_len", "=", "3", ",", "\n", ")", ":", "\n", "        ", "if", "isinstance", "(", "video_path", ",", "str", ")", ":", "\n", "            ", "video_path", "=", "Path", "(", "video_path", ")", "\n", "", "if", "isinstance", "(", "audio_path", ",", "str", ")", ":", "\n", "            ", "audio_path", "=", "Path", "(", "audio_path", ")", "\n", "", "if", "isinstance", "(", "embed_dir", ",", "str", ")", ":", "\n", "            ", "embed_dir", "=", "Path", "(", "embed_dir", ")", "\n", "\n", "", "self", ".", "video_path", "=", "video_path", "\n", "self", ".", "audio_path", "=", "audio_path", "\n", "self", ".", "video_start_length", "=", "video_start_length", "\n", "\n", "self", ".", "embed_path", "=", "None", "\n", "self", ".", "embed", "=", "None", "\n", "self", ".", "embed_dir", "=", "embed_dir", "\n", "\n", "self", ".", "fps", "=", "fps", "\n", "self", ".", "signal_len", "=", "signal_len", "\n", "self", ".", "sr", "=", "sr", "\n", "\n", "self", ".", "_load", "(", "sr", "=", "sr", ")", "\n", "self", ".", "_check_video_embed", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.Signal._load": [[81, 86], ["librosa.load", "cv2.VideoCapture", "avspeech_dataset.Signal.audio_path.as_posix", "avspeech_dataset.Signal.video_path.as_posix"], "methods", ["None"], ["", "def", "_load", "(", "self", ",", "sr", ":", "int", ")", ":", "\n", "        ", "import", "cv2", "# Fix sphinx import", "\n", "\n", "self", ".", "audio", ",", "_", "=", "librosa", ".", "load", "(", "self", ".", "audio_path", ".", "as_posix", "(", ")", ",", "sr", "=", "sr", ")", "\n", "self", ".", "video", "=", "cv2", ".", "VideoCapture", "(", "self", ".", "video_path", ".", "as_posix", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.Signal._check_video_embed": [[87, 104], ["pathlib.Path", "avspeech_dataset.Signal.embed_path.is_file", "pathlib.Path.is_dir", "pathlib.Path", "numpy.load", "ValueError", "avspeech_dataset.Signal.embed_path.as_posix"], "methods", ["None"], ["", "def", "_check_video_embed", "(", "self", ",", "embed_ext", "=", "\".npy\"", ")", ":", "\n", "# convert mp4 location to embedding...", "\n", "        ", "video_name_stem", "=", "self", ".", "video_path", ".", "stem", "\n", "\n", "embed_dir", "=", "self", ".", "embed_dir", "\n", "if", "not", "embed_dir", ".", "is_dir", "(", ")", ":", "\n", "# check embed_dir=\"../../dir\" or embed_dir=\"dir\"", "\n", "            ", "embed_dir", "=", "Path", "(", "*", "embed_dir", ".", "parts", "[", "2", ":", "]", ")", "\n", "\n", "", "self", ".", "embed_path", "=", "Path", "(", "\n", "embed_dir", ",", "f\"{video_name_stem}_part{self.video_start_length}{embed_ext}\"", "\n", ")", "\n", "if", "self", ".", "embed_path", ".", "is_file", "(", ")", ":", "\n", "            ", "self", ".", "embed", "=", "np", ".", "load", "(", "self", ".", "embed_path", ".", "as_posix", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Embeddings not found in {self.embed_dir} for {self.video_path} \"", "\n", "f\"for part: {self.video_start_length}\"", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.Signal.get_embed": [[107, 109], ["None"], "methods", ["None"], ["", "", "def", "get_embed", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.Signal.get_audio": [[110, 112], ["None"], "methods", ["None"], ["", "def", "get_audio", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.AVSpeechDataset.__init__": [[129, 139], ["isinstance", "isinstance", "pandas.read_csv", "asteroid_filterbanks.Encoder", "pathlib.Path", "pathlib.Path", "pathlib.Path.as_posix", "asteroid_filterbanks.STFTFB"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_df_path", ":", "Union", "[", "str", ",", "Path", "]", ",", "embed_dir", ":", "Union", "[", "str", ",", "Path", "]", ",", "n_src", "=", "2", ")", ":", "\n", "        ", "if", "isinstance", "(", "input_df_path", ",", "str", ")", ":", "\n", "            ", "input_df_path", "=", "Path", "(", "input_df_path", ")", "\n", "", "if", "isinstance", "(", "embed_dir", ",", "str", ")", ":", "\n", "            ", "embed_dir", "=", "Path", "(", "embed_dir", ")", "\n", "\n", "", "self", ".", "n_src", "=", "n_src", "\n", "self", ".", "embed_dir", "=", "embed_dir", "\n", "self", ".", "input_df", "=", "pd", ".", "read_csv", "(", "input_df_path", ".", "as_posix", "(", ")", ")", "\n", "self", ".", "stft_encoder", "=", "Encoder", "(", "STFTFB", "(", "n_filters", "=", "512", ",", "kernel_size", "=", "400", ",", "stride", "=", "160", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.AVSpeechDataset.encode": [[140, 152], ["torch.from_numpy().float", "asteroid_filterbanks.Encoder", "asteroid_filterbanks.Encoder.squeeze", "torch.sign", "asteroid_filterbanks.STFTFB", "torch.from_numpy", "torch.abs", "asteroid_filterbanks.Encoder."], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "encode", "(", "x", ":", "np", ".", "ndarray", ",", "p", "=", "0.3", ",", "stft_encoder", "=", "None", ",", "EPS", "=", "1e-8", ")", ":", "\n", "        ", "if", "stft_encoder", "is", "None", ":", "\n", "            ", "stft_encoder", "=", "Encoder", "(", "STFTFB", "(", "n_filters", "=", "512", ",", "kernel_size", "=", "400", ",", "stride", "=", "160", ")", ")", "\n", "\n", "", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "float", "(", ")", "\n", "\n", "# time domain to time-frequency representation", "\n", "tf_rep", "=", "stft_encoder", "(", "x", ")", ".", "squeeze", "(", "0", ")", "+", "EPS", "\n", "# power law on complex numbers", "\n", "tf_rep", "=", "(", "torch", ".", "abs", "(", "tf_rep", ")", "**", "p", ")", "*", "torch", ".", "sign", "(", "tf_rep", ")", "\n", "return", "tf_rep", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.AVSpeechDataset.decode": [[153, 169], ["torch.from_numpy().float", "asteroid_filterbanks.Decoder.", "len", "asteroid_filterbanks.Decoder", "torch.sign", "torch.nn.functional.pad", "asteroid_filterbanks.STFTFB", "torch.from_numpy", "torch.abs"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad"], ["", "@", "staticmethod", "\n", "def", "decode", "(", "tf_rep", ":", "np", ".", "ndarray", ",", "p", "=", "0.3", ",", "stft_decoder", "=", "None", ",", "final_len", "=", "48000", ")", ":", "\n", "        ", "if", "stft_decoder", "is", "None", ":", "\n", "            ", "stft_decoder", "=", "Decoder", "(", "STFTFB", "(", "n_filters", "=", "512", ",", "kernel_size", "=", "400", ",", "stride", "=", "160", ")", ")", "\n", "\n", "", "tf_rep", "=", "torch", ".", "from_numpy", "(", "tf_rep", ")", ".", "float", "(", ")", "\n", "\n", "# power law on complex numbers", "\n", "tf_rep", "=", "(", "torch", ".", "abs", "(", "tf_rep", ")", "**", "(", "1", "/", "p", ")", ")", "*", "torch", ".", "sign", "(", "tf_rep", ")", "\n", "# time domain to time-frequency representation", "\n", "x", "=", "stft_decoder", "(", "tf_rep", ")", "\n", "\n", "length", "=", "len", "(", "x", ")", "\n", "if", "length", "!=", "final_len", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "[", "0", ",", "final_len", "-", "length", "]", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.AVSpeechDataset.__len__": [[170, 172], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "input_df", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.AVSpeechDataset.__getitem__": [[173, 215], ["range", "librosa.load", "avspeech_dataset.AVSpeechDataset.encode", "range", "torch.stack", "re.search", "avspeech_dataset.Signal", "all_signals.append", "avspeech_dataset.AVSpeechDataset.encode", "torch.stack.append", "torch.from_numpy", "video_tensors.append", "int", "all_signals[].get_audio", "all_signals[].get_embed", "re.search.group"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TasNet.model.TasNet.encode", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TasNet.model.TasNet.encode", "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.Signal.get_audio", "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.Signal.get_embed"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "row", "=", "self", ".", "input_df", ".", "iloc", "[", "idx", ",", ":", "]", "\n", "all_signals", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_src", ")", ":", "\n", "# get audio, video path from combination dataframe", "\n", "            ", "video_path", "=", "row", ".", "loc", "[", "f\"video_{i+1}\"", "]", "\n", "audio_path", "=", "row", ".", "loc", "[", "f\"audio_{i+1}\"", "]", "\n", "\n", "# video length is 3-10 seconds, hence, part index can take values 0-2", "\n", "re_match", "=", "re", ".", "search", "(", "r\"_part\\d\"", ",", "audio_path", ")", "\n", "video_length_idx", "=", "0", "\n", "if", "re_match", ":", "\n", "                ", "video_length_idx", "=", "int", "(", "re_match", ".", "group", "(", "0", ")", "[", "-", "1", "]", ")", "\n", "\n", "", "signal", "=", "Signal", "(", "\n", "video_path", ",", "\n", "audio_path", ",", "\n", "self", ".", "embed_dir", ",", "\n", "video_start_length", "=", "video_length_idx", ",", "\n", ")", "\n", "all_signals", ".", "append", "(", "signal", ")", "\n", "\n", "# input audio signal is the last column.", "\n", "", "mixed_signal", ",", "_", "=", "librosa", ".", "load", "(", "row", ".", "loc", "[", "\"mixed_audio\"", "]", ",", "sr", "=", "16_000", ")", "\n", "mixed_signal_tensor", "=", "self", ".", "encode", "(", "mixed_signal", ",", "stft_encoder", "=", "self", ".", "stft_encoder", ")", "\n", "\n", "audio_tensors", "=", "[", "]", "\n", "video_tensors", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_src", ")", ":", "\n", "# audio to spectrogram", "\n", "            ", "spectrogram", "=", "self", ".", "encode", "(", "all_signals", "[", "i", "]", ".", "get_audio", "(", ")", ",", "stft_encoder", "=", "self", ".", "stft_encoder", ")", "\n", "audio_tensors", ".", "append", "(", "spectrogram", ")", "\n", "\n", "# get embed", "\n", "embeddings", "=", "torch", ".", "from_numpy", "(", "all_signals", "[", "i", "]", ".", "get_embed", "(", ")", ")", "\n", "video_tensors", ".", "append", "(", "embeddings", ")", "\n", "\n", "", "audio_tensors", "=", "torch", ".", "stack", "(", "audio_tensors", ")", "\n", "\n", "return", "audio_tensors", ",", "video_tensors", ",", "mixed_signal_tensor", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.get_frames": [[13, 32], ["int", "int", "int", "numpy.empty", "video.release", "video.get", "video.get", "video.get", "numpy.dtype", "video.read", "cv2.cvtColor"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["def", "get_frames", "(", "video", ")", ":", "\n", "    ", "import", "cv2", "# Fix sphinx import", "\n", "\n", "frame_count", "=", "int", "(", "video", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "frame_width", "=", "int", "(", "video", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "frame_height", "=", "int", "(", "video", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "\n", "buffer_video", "=", "np", ".", "empty", "(", "(", "frame_count", ",", "frame_height", ",", "frame_width", ",", "3", ")", ",", "np", ".", "dtype", "(", "\"uint8\"", ")", ")", "\n", "\n", "frame", "=", "0", "\n", "ret", "=", "True", "\n", "\n", "while", "frame", "<", "frame_count", "and", "ret", ":", "\n", "        ", "ret", ",", "f", "=", "video", ".", "read", "(", ")", "\n", "buffer_video", "[", "frame", "]", "=", "cv2", ".", "cvtColor", "(", "f", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "\n", "frame", "+=", "1", "\n", "", "video", ".", "release", "(", ")", "\n", "return", "buffer_video", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wsj0_mix.Wsj0mixDataset.__init__": [[48, 89], ["torch.utils.data.Dataset.__init__", "os.path.join", "len", "print", "int", "os.path.join", "open", "json.load", "range", "open", "sources_infos.append", "json.load", "len", "range"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "json_dir", ",", "n_src", "=", "2", ",", "sample_rate", "=", "8000", ",", "segment", "=", "4.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# Task setting", "\n", "self", ".", "json_dir", "=", "json_dir", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "if", "segment", "is", "None", ":", "\n", "            ", "self", ".", "seg_len", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "seg_len", "=", "int", "(", "segment", "*", "sample_rate", ")", "\n", "", "self", ".", "n_src", "=", "n_src", "\n", "self", ".", "like_test", "=", "self", ".", "seg_len", "is", "None", "\n", "# Load json files", "\n", "mix_json", "=", "os", ".", "path", ".", "join", "(", "json_dir", ",", "\"mix.json\"", ")", "\n", "sources_json", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "json_dir", ",", "source", "+", "\".json\"", ")", "for", "source", "in", "[", "f\"s{n+1}\"", "for", "n", "in", "range", "(", "n_src", ")", "]", "\n", "]", "\n", "with", "open", "(", "mix_json", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "mix_infos", "=", "json", ".", "load", "(", "f", ")", "\n", "", "sources_infos", "=", "[", "]", "\n", "for", "src_json", "in", "sources_json", ":", "\n", "            ", "with", "open", "(", "src_json", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "sources_infos", ".", "append", "(", "json", ".", "load", "(", "f", ")", ")", "\n", "# Filter out short utterances only when segment is specified", "\n", "", "", "orig_len", "=", "len", "(", "mix_infos", ")", "\n", "drop_utt", ",", "drop_len", "=", "0", ",", "0", "\n", "if", "not", "self", ".", "like_test", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "mix_infos", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "# Go backward", "\n", "                ", "if", "mix_infos", "[", "i", "]", "[", "1", "]", "<", "self", ".", "seg_len", ":", "\n", "                    ", "drop_utt", "+=", "1", "\n", "drop_len", "+=", "mix_infos", "[", "i", "]", "[", "1", "]", "\n", "del", "mix_infos", "[", "i", "]", "\n", "for", "src_inf", "in", "sources_infos", ":", "\n", "                        ", "del", "src_inf", "[", "i", "]", "\n", "\n", "", "", "", "", "print", "(", "\n", "\"Drop {} utts({:.2f} h) from {} (shorter than {} samples)\"", ".", "format", "(", "\n", "drop_utt", ",", "drop_len", "/", "sample_rate", "/", "36000", ",", "orig_len", ",", "self", ".", "seg_len", "\n", ")", "\n", ")", "\n", "self", ".", "mix", "=", "mix_infos", "\n", "self", ".", "sources", "=", "sources_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wsj0_mix.Wsj0mixDataset.__len__": [[90, 92], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "mix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wsj0_mix.Wsj0mixDataset.__getitem__": [[93, 121], ["soundfile.read", "torch.as_tensor", "torch.from_numpy", "numpy.random.randint", "source_arrays.append", "numpy.vstack", "torch.from_numpy", "len", "numpy.zeros", "soundfile.read"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.as_tensor", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Gets a mixture/sources pair.\n        Returns:\n            mixture, vstack([source_arrays])\n        \"\"\"", "\n", "# Random start", "\n", "if", "self", ".", "mix", "[", "idx", "]", "[", "1", "]", "==", "self", ".", "seg_len", "or", "self", ".", "like_test", ":", "\n", "            ", "rand_start", "=", "0", "\n", "", "else", ":", "\n", "            ", "rand_start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "mix", "[", "idx", "]", "[", "1", "]", "-", "self", ".", "seg_len", ")", "\n", "", "if", "self", ".", "like_test", ":", "\n", "            ", "stop", "=", "None", "\n", "", "else", ":", "\n", "            ", "stop", "=", "rand_start", "+", "self", ".", "seg_len", "\n", "# Load mixture", "\n", "", "x", ",", "_", "=", "sf", ".", "read", "(", "self", ".", "mix", "[", "idx", "]", "[", "0", "]", ",", "start", "=", "rand_start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ")", "\n", "seg_len", "=", "torch", ".", "as_tensor", "(", "[", "len", "(", "x", ")", "]", ")", "\n", "# Load sources", "\n", "source_arrays", "=", "[", "]", "\n", "for", "src", "in", "self", ".", "sources", ":", "\n", "            ", "if", "src", "[", "idx", "]", "is", "None", ":", "\n", "# Target is filled with zeros if n_src > default_nsrc", "\n", "                ", "s", "=", "np", ".", "zeros", "(", "(", "seg_len", ",", ")", ")", "\n", "", "else", ":", "\n", "                ", "s", ",", "_", "=", "sf", ".", "read", "(", "src", "[", "idx", "]", "[", "0", "]", ",", "start", "=", "rand_start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ")", "\n", "", "source_arrays", ".", "append", "(", "s", ")", "\n", "", "sources", "=", "torch", ".", "from_numpy", "(", "np", ".", "vstack", "(", "source_arrays", ")", ")", "\n", "return", "torch", ".", "from_numpy", "(", "x", ")", ",", "sources", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wsj0_mix.Wsj0mixDataset.get_infos": [[122, 133], ["dict"], "methods", ["None"], ["", "def", "get_infos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get dataset infos (for publishing models).\n\n        Returns:\n            dict, dataset infos with keys `dataset`, `task` and `licences`.\n        \"\"\"", "\n", "infos", "=", "dict", "(", ")", "\n", "infos", "[", "\"dataset\"", "]", "=", "self", ".", "dataset_name", "\n", "infos", "[", "\"task\"", "]", "=", "\"sep_clean\"", "\n", "infos", "[", "\"licenses\"", "]", "=", "[", "wsj0_license", "]", "\n", "return", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wsj0_mix.make_dataloaders": [[9, 29], ["wsj0_mix.Wsj0mixDataset", "wsj0_mix.Wsj0mixDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["None"], ["def", "make_dataloaders", "(", "\n", "train_dir", ",", "\n", "valid_dir", ",", "\n", "n_src", "=", "2", ",", "\n", "sample_rate", "=", "8000", ",", "\n", "segment", "=", "4.0", ",", "\n", "batch_size", "=", "4", ",", "\n", "num_workers", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "    ", "num_workers", "=", "num_workers", "if", "num_workers", "else", "batch_size", "\n", "train_set", "=", "Wsj0mixDataset", "(", "train_dir", ",", "n_src", "=", "n_src", ",", "sample_rate", "=", "sample_rate", ",", "segment", "=", "segment", ")", "\n", "val_set", "=", "Wsj0mixDataset", "(", "valid_dir", ",", "n_src", "=", "n_src", ",", "sample_rate", "=", "sample_rate", ",", "segment", "=", "segment", ")", "\n", "train_loader", "=", "data", ".", "DataLoader", "(", "\n", "train_set", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ",", "num_workers", "=", "num_workers", ",", "drop_last", "=", "True", "\n", ")", "\n", "val_loader", "=", "data", ".", "DataLoader", "(", "\n", "val_set", ",", "shuffle", "=", "True", ",", "batch_size", "=", "batch_size", ",", "num_workers", "=", "num_workers", ",", "drop_last", "=", "True", "\n", ")", "\n", "return", "train_loader", ",", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.utils.online_mixing_collate": [[5, 24], ["torch.utils.data._utils.collate.default_collate", "torch.sum", "range", "torch.stack", "torch.stack.sum", "new_src.append", "torch.sqrt", "torch.randperm"], "function", ["None"], ["def", "online_mixing_collate", "(", "batch", ")", ":", "\n", "    ", "\"\"\"Mix target sources to create new mixtures.\n    Output of the default collate function is expected to return two objects:\n    inputs and targets.\n    \"\"\"", "\n", "# Inputs (batch, time) / targets (batch, n_src, time)", "\n", "inputs", ",", "targets", "=", "default_collate", "(", "batch", ")", "\n", "batch", ",", "n_src", ",", "_", "=", "targets", ".", "shape", "\n", "\n", "energies", "=", "torch", ".", "sum", "(", "targets", "**", "2", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "new_src", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "targets", ".", "shape", "[", "1", "]", ")", ":", "\n", "        ", "new_s", "=", "targets", "[", "torch", ".", "randperm", "(", "batch", ")", ",", "i", ",", ":", "]", "\n", "new_s", "=", "new_s", "*", "torch", ".", "sqrt", "(", "energies", "[", ":", ",", "i", "]", "/", "(", "new_s", "**", "2", ")", ".", "sum", "(", "-", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "new_src", ".", "append", "(", "new_s", ")", "\n", "\n", "", "targets", "=", "torch", ".", "stack", "(", "new_src", ",", "dim", "=", "1", ")", "\n", "inputs", "=", "targets", ".", "sum", "(", "1", ")", "\n", "return", "inputs", ",", "targets", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.SCM.forward": [[8, 11], ["beamforming.compute_scm"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.compute_scm"], ["    ", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", "=", "None", ",", "normalize", ":", "bool", "=", "True", ")", ":", "\n", "        ", "\"\"\"See :func:`compute_scm`.\"\"\"", "\n", "return", "compute_scm", "(", "x", ",", "mask", "=", "mask", ",", "normalize", "=", "normalize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.Beamformer.apply_beamforming_vector": [[16, 25], ["torch.einsum", "bf_vector.conj"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "apply_beamforming_vector", "(", "bf_vector", ":", "torch", ".", "Tensor", ",", "mix", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Apply the beamforming vector to the mixture. Output (batch, freqs, frames).\n\n        Args:\n            bf_vector: shape (batch, mics, freqs)\n            mix: shape (batch, mics, freqs, frames).\n        \"\"\"", "\n", "return", "torch", ".", "einsum", "(", "\"...mf,...mft->...ft\"", ",", "bf_vector", ".", "conj", "(", ")", ",", "mix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.Beamformer.get_reference_mic_vects": [[26, 72], ["ref_mic_vects.to().to", "isinstance", "beamforming.get_optimal_reference_mic", "isinstance", "torch.nn.functional.one_hot", "torch.LongTensor().to", "isinstance", "ref_mic_vects.to", "ValueError", "torch.LongTensor", "type"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.get_optimal_reference_mic"], ["", "@", "staticmethod", "\n", "def", "get_reference_mic_vects", "(", "\n", "ref_mic", ",", "\n", "bf_mat", ":", "torch", ".", "Tensor", ",", "\n", "target_scm", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "noise_scm", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Return the reference channel indices over the batch.\n\n        Args:\n            ref_mic (Optional[Union[int, torch.Tensor]]): The reference channel.\n                If torch.Tensor (ndim>1), return it, it is the reference mic vector,\n                If torch.LongTensor of size `batch`, select independent reference mic of the batch.\n                If int, select the corresponding reference mic,\n                If None, the optimal reference mics are computed with :func:`get_optimal_reference_mic`,\n                If None, and either SCM is None, `ref_mic` is set to `0`,\n            bf_mat: beamforming matrix of shape (batch, freq, mics, mics).\n            target_scm (torch.ComplexTensor): (batch, freqs, mics, mics).\n            noise_scm (torch.ComplexTensor): (batch, freqs, mics, mics).\n\n        Returns:\n            torch.LongTensor of size ``batch`` to select with the reference channel indices.\n        \"\"\"", "\n", "# If ref_mic already has the expected shape.", "\n", "if", "isinstance", "(", "ref_mic", ",", "torch", ".", "Tensor", ")", "and", "ref_mic", ".", "ndim", ">", "1", ":", "\n", "            ", "return", "ref_mic", "\n", "\n", "", "if", "(", "target_scm", "is", "None", "or", "noise_scm", "is", "None", ")", "and", "ref_mic", "is", "None", ":", "\n", "            ", "ref_mic", "=", "0", "\n", "", "if", "ref_mic", "is", "None", ":", "\n", "            ", "batch_mic_idx", "=", "get_optimal_reference_mic", "(", "\n", "bf_mat", "=", "bf_mat", ",", "target_scm", "=", "target_scm", ",", "noise_scm", "=", "noise_scm", "\n", ")", "\n", "", "elif", "isinstance", "(", "ref_mic", ",", "int", ")", ":", "\n", "            ", "batch_mic_idx", "=", "torch", ".", "LongTensor", "(", "[", "ref_mic", "]", "*", "bf_mat", ".", "shape", "[", "0", "]", ")", ".", "to", "(", "bf_mat", ".", "device", ")", "\n", "", "elif", "isinstance", "(", "ref_mic", ",", "torch", ".", "Tensor", ")", ":", "# Must be 1D", "\n", "            ", "batch_mic_idx", "=", "ref_mic", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Unsupported reference microphone format. Support None, int and 1D \"", "\n", "f\"torch.LongTensor and torch.Tensor, received {type(ref_mic)}.\"", "\n", ")", "\n", "# Output (batch, 1, n_mics, 1)", "\n", "# import ipdb; ipdb.set_trace()", "\n", "", "ref_mic_vects", "=", "F", ".", "one_hot", "(", "batch_mic_idx", ",", "num_classes", "=", "bf_mat", ".", "shape", "[", "-", "1", "]", ")", "[", ":", ",", "None", ",", ":", ",", "None", "]", "\n", "return", "ref_mic_vects", ".", "to", "(", "bf_mat", ".", "dtype", ")", ".", "to", "(", "bf_mat", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.RTFMVDRBeamformer.forward": [[75, 100], ["torch.symeig", "beamforming.RTFMVDRBeamformer.from_rtf_vect", "target_scm.permute", "rtf_vect.transpose"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.RTFMVDRBeamformer.from_rtf_vect"], ["    ", "def", "forward", "(", "\n", "self", ",", "\n", "mix", ":", "torch", ".", "Tensor", ",", "\n", "target_scm", ":", "torch", ".", "Tensor", ",", "\n", "noise_scm", ":", "torch", ".", "Tensor", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"Compute and apply MVDR beamformer from the speech and noise SCM matrices.\n\n        :math:`\\mathbf{w} =  \\displaystyle \\frac{\\Sigma_{nn}^{-1} \\mathbf{a}}{\n        \\mathbf{a}^H \\Sigma_{nn}^{-1} \\mathbf{a}}` where :math:`\\mathbf{a}` is the\n        ATF estimated from the target SCM.\n\n        Args:\n            mix (torch.ComplexTensor): shape (batch, mics, freqs, frames)\n            target_scm (torch.ComplexTensor): (batch, mics, mics, freqs)\n            noise_scm (torch.ComplexTensor): (batch, mics, mics, freqs)\n\n        Returns:\n            Filtered mixture. torch.ComplexTensor (batch, freqs, frames)\n        \"\"\"", "\n", "# TODO: Implement several RTF estimation strategies, and choose one here, or expose all.", "\n", "# Get relative transfer function (1st PCA of \u03a3ss)", "\n", "e_val", ",", "e_vec", "=", "torch", ".", "symeig", "(", "target_scm", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "eigenvectors", "=", "True", ")", "\n", "rtf_vect", "=", "e_vec", "[", "...", ",", "-", "1", "]", "# bfm", "\n", "return", "self", ".", "from_rtf_vect", "(", "mix", "=", "mix", ",", "rtf_vec", "=", "rtf_vect", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ",", "noise_scm", "=", "noise_scm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.RTFMVDRBeamformer.from_rtf_vect": [[101, 126], ["noise_scm.permute", "rtf_vec.transpose().unsqueeze", "beamforming.stable_solve", "torch.matmul", "beamforming.RTFMVDRBeamformer.apply_beamforming_vector", "rtf_vec.transpose().unsqueeze.conj().transpose", "rtf_vec.transpose", "rtf_vec.transpose().unsqueeze.conj"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.stable_solve", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.Beamformer.apply_beamforming_vector"], ["", "def", "from_rtf_vect", "(", "\n", "self", ",", "\n", "mix", ":", "torch", ".", "Tensor", ",", "\n", "rtf_vec", ":", "torch", ".", "Tensor", ",", "\n", "noise_scm", ":", "torch", ".", "Tensor", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Compute and apply MVDR beamformer from the ATF vector and noise SCM matrix.\n\n        Args:\n            mix (torch.ComplexTensor): shape (batch, mics, freqs, frames)\n            rtf_vec (torch.ComplexTensor): (batch, mics, freqs)\n            noise_scm (torch.ComplexTensor): (batch, mics, mics, freqs)\n\n        Returns:\n            Filtered mixture. torch.ComplexTensor (batch, freqs, frames)\n        \"\"\"", "\n", "noise_scm_t", "=", "noise_scm", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "# -> bfmm", "\n", "rtf_vec_t", "=", "rtf_vec", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ".", "unsqueeze", "(", "-", "1", ")", "# -> bfm1", "\n", "\n", "numerator", "=", "stable_solve", "(", "rtf_vec_t", ",", "noise_scm_t", ")", "# -> bfm1", "\n", "\n", "denominator", "=", "torch", ".", "matmul", "(", "rtf_vec_t", ".", "conj", "(", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ",", "numerator", ")", "# -> bf11", "\n", "bf_vect", "=", "(", "numerator", "/", "denominator", ")", ".", "squeeze", "(", "-", "1", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "# -> bfm1  -> bmf", "\n", "output", "=", "self", ".", "apply_beamforming_vector", "(", "bf_vect", ",", "mix", "=", "mix", ")", "# -> bft", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.SoudenMVDRBeamformer.forward": [[129, 173], ["noise_scm.permute.permute.permute", "target_scm.permute.permute.permute", "beamforming.stable_solve", "beamforming.SoudenMVDRBeamformer.get_reference_mic_vects", "torch.matmul", "bf_vect.squeeze().transpose.squeeze().transpose.squeeze().transpose", "beamforming.SoudenMVDRBeamformer.apply_beamforming_vector", "bf_vect.squeeze().transpose.squeeze().transpose.squeeze", "beamforming.batch_trace"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.stable_solve", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.Beamformer.get_reference_mic_vects", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.Beamformer.apply_beamforming_vector", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.batch_trace"], ["    ", "def", "forward", "(", "\n", "self", ",", "\n", "mix", ":", "torch", ".", "Tensor", ",", "\n", "target_scm", ":", "torch", ".", "Tensor", ",", "\n", "noise_scm", ":", "torch", ".", "Tensor", ",", "\n", "ref_mic", ":", "Union", "[", "torch", ".", "Tensor", ",", "torch", ".", "LongTensor", ",", "int", "]", "=", "0", ",", "\n", "eps", "=", "1e-8", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"Compute and apply MVDR beamformer from the speech and noise SCM matrices.\n        This class uses Souden's formulation [1].\n\n        :math:`\\mathbf{w} =  \\displaystyle \\frac{\\Sigma_{nn}^{-1} \\Sigma_{ss}}{\n        Tr\\left( \\Sigma_{nn}^{-1} \\Sigma_{ss} \\right) }\\mathbf{u}` where :math:`\\mathbf{a}`\n        is the steering vector.\n\n\n        Args:\n            mix (torch.ComplexTensor): shape (batch, mics, freqs, frames)\n            target_scm (torch.ComplexTensor): (batch, mics, mics, freqs)\n            noise_scm (torch.ComplexTensor): (batch, mics, mics, freqs)\n            ref_mic (int): reference microphone.\n            eps: numerical stabilizer.\n\n        Returns:\n            Filtered mixture. torch.ComplexTensor (batch, freqs, frames)\n\n        References\n            [1] Souden, M., Benesty, J., & Affes, S. (2009). On optimal frequency-domain multichannel\n            linear filtering for noise reduction. IEEE Transactions on audio, speech, and language processing, 18(2), 260-276.\n        \"\"\"", "\n", "noise_scm", "=", "noise_scm", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "# -> bfmm", "\n", "target_scm", "=", "target_scm", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "# -> bfmm", "\n", "\n", "numerator", "=", "stable_solve", "(", "target_scm", ",", "noise_scm", ")", "\n", "bf_mat", "=", "numerator", "/", "(", "batch_trace", "(", "numerator", ")", "[", "...", ",", "None", ",", "None", "]", "+", "eps", ")", "# bfmm", "\n", "\n", "# allow for a-posteriori SNR selection", "\n", "batch_mic_vects", "=", "self", ".", "get_reference_mic_vects", "(", "\n", "ref_mic", ",", "bf_mat", ",", "target_scm", "=", "target_scm", ",", "noise_scm", "=", "noise_scm", "\n", ")", "\n", "bf_vect", "=", "torch", ".", "matmul", "(", "bf_mat", ",", "batch_mic_vects", ")", "# -> bfmm  -> bfm1", "\n", "bf_vect", "=", "bf_vect", ".", "squeeze", "(", "-", "1", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "# bfm1 -> bmf", "\n", "output", "=", "self", ".", "apply_beamforming_vector", "(", "bf_vect", ",", "mix", "=", "mix", ")", "# -> bft", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.SDWMWFBeamformer.__init__": [[176, 179], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "mu", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mu", "=", "mu", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.SDWMWFBeamformer.forward": [[180, 215], ["noise_scm.permute", "target_scm.permute", "beamforming.stable_solve", "beamforming.SDWMWFBeamformer.get_reference_mic_vects", "torch.matmul", "bf_vect.squeeze().transpose.squeeze().transpose.squeeze().transpose", "beamforming.SDWMWFBeamformer.apply_beamforming_vector", "bf_vect.squeeze().transpose.squeeze().transpose.squeeze"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.stable_solve", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.Beamformer.get_reference_mic_vects", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.Beamformer.apply_beamforming_vector"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "mix", ":", "torch", ".", "Tensor", ",", "\n", "target_scm", ":", "torch", ".", "Tensor", ",", "\n", "noise_scm", ":", "torch", ".", "Tensor", ",", "\n", "ref_mic", ":", "Union", "[", "torch", ".", "Tensor", ",", "torch", ".", "LongTensor", ",", "int", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"Compute and apply SDW-MWF beamformer.\n\n        :math:`\\mathbf{w} =  \\displaystyle (\\Sigma_{ss} + \\mu \\Sigma_{nn})^{-1} \\Sigma_{ss}`.\n\n        Args:\n            mix (torch.ComplexTensor): shape (batch, mics, freqs, frames)\n            target_scm (torch.ComplexTensor): (batch, mics, mics, freqs)\n            noise_scm (torch.ComplexTensor): (batch, mics, mics, freqs)\n            ref_mic (int): reference microphone.\n\n        Returns:\n            Filtered mixture. torch.ComplexTensor (batch, freqs, frames)\n        \"\"\"", "\n", "noise_scm_t", "=", "noise_scm", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "# -> bfmm", "\n", "target_scm_t", "=", "target_scm", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "# -> bfmm", "\n", "\n", "# import ipdb; ipdb.set_trace()", "\n", "\n", "denominator", "=", "target_scm_t", "+", "self", ".", "mu", "*", "noise_scm_t", "\n", "bf_mat", "=", "stable_solve", "(", "target_scm_t", ",", "denominator", ")", "\n", "# Reference mic selection and application", "\n", "batch_mic_vects", "=", "self", ".", "get_reference_mic_vects", "(", "\n", "ref_mic", ",", "bf_mat", ",", "target_scm", "=", "target_scm_t", ",", "noise_scm", "=", "noise_scm_t", "\n", ")", "# b1m1", "\n", "bf_vect", "=", "torch", ".", "matmul", "(", "bf_mat", ",", "batch_mic_vects", ")", "# -> bfmm  -> bfm1", "\n", "bf_vect", "=", "bf_vect", ".", "squeeze", "(", "-", "1", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "# bfm1 -> bmf", "\n", "output", "=", "self", ".", "apply_beamforming_vector", "(", "bf_vect", ",", "mix", "=", "mix", ")", "# -> bft", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.GEVBeamformer.forward": [[218, 236], ["beamforming.GEVBeamformer.compute_beamforming_vector", "beamforming.GEVBeamformer.apply_beamforming_vector"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.GEVDBeamformer.compute_beamforming_vector", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.Beamformer.apply_beamforming_vector"], ["    ", "def", "forward", "(", "self", ",", "mix", ":", "torch", ".", "Tensor", ",", "target_scm", ":", "torch", ".", "Tensor", ",", "noise_scm", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "r\"\"\"Compute and apply the GEV beamformer.\n\n        :math:`\\mathbf{w} =  \\displaystyle MaxEig\\{ \\Sigma_{nn}^{-1}\\Sigma_{ss} \\}`, where\n        MaxEig extracts the eigenvector corresponding to the maximum eigenvalue\n        (using the GEV decomposition).\n\n        Args:\n            mix: shape (batch, mics, freqs, frames)\n            target_scm: (batch, mics, mics, freqs)\n            noise_scm: (batch, mics, mics, freqs)\n\n        Returns:\n            Filtered mixture. torch.ComplexTensor (batch, freqs, frames)\n        \"\"\"", "\n", "bf_vect", "=", "self", ".", "compute_beamforming_vector", "(", "target_scm", ",", "noise_scm", ")", "\n", "output", "=", "self", ".", "apply_beamforming_vector", "(", "bf_vect", ",", "mix", "=", "mix", ")", "# -> bft", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.GEVBeamformer.compute_beamforming_vector": [[237, 249], ["noise_scm.permute", "beamforming.condition_scm", "beamforming.generalized_eigenvalue_decomposition", "torch.norm", "bf_vect.squeeze().transpose.squeeze().transpose.squeeze().transpose", "target_scm.permute", "bf_vect.squeeze().transpose.squeeze().transpose.squeeze"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.condition_scm", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.generalized_eigenvalue_decomposition"], ["", "@", "staticmethod", "\n", "def", "compute_beamforming_vector", "(", "target_scm", ":", "torch", ".", "Tensor", ",", "noise_scm", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "noise_scm_t", "=", "noise_scm", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "noise_scm_t", "=", "condition_scm", "(", "noise_scm_t", ",", "1e-6", ")", "\n", "e_val", ",", "e_vec", "=", "generalized_eigenvalue_decomposition", "(", "\n", "target_scm", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "noise_scm_t", "\n", ")", "\n", "bf_vect", "=", "e_vec", "[", "...", ",", "-", "1", "]", "\n", "# Normalize", "\n", "bf_vect", "/=", "torch", ".", "norm", "(", "bf_vect", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "bf_vect", "=", "bf_vect", ".", "squeeze", "(", "-", "1", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "# -> bft", "\n", "return", "bf_vect", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.GEVDBeamformer.__init__": [[270, 273], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mu", ":", "float", "=", "1.0", ",", "rank", ":", "int", "=", "1", ")", ":", "\n", "        ", "self", ".", "mu", "=", "mu", "\n", "self", ".", "rank", "=", "rank", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.GEVDBeamformer.compute_beamforming_vector": [[274, 313], ["beamforming._generalized_eigenvalue_decomposition", "torch.clamp", "torch.diag_embed", "torch.flip", "bf_vect[].permute", "target_scm.permute", "noise_scm.permute", "torch.finfo", "torch.flip", "torch.linalg.inv", "torch.eye().expand_as", "torch.diag_embed.to", "ev_plus_mu.to", "torch.eye"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._generalized_eigenvalue_decomposition"], ["", "def", "compute_beamforming_vector", "(", "self", ",", "target_scm", ":", "torch", ".", "Tensor", ",", "noise_scm", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Compute beamforming vectors for GEVD beamFormer.\n\n        Args:\n            target_scm (torch.ComplexTensor): shape (batch, mics, mics, freqs)\n            noise_scm (torch.ComplexTensor): shape (batch, mics, mics, freqs)\n\n        Returns:\n            torch.ComplexTensor: shape (batch, mics, freqs)\n\n        \"\"\"", "\n", "#  GEV decomposition of noise_scm^(-1) * target_scm", "\n", "e_values", ",", "e_vectors", "=", "_generalized_eigenvalue_decomposition", "(", "\n", "target_scm", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "# bmmf -> bfmm", "\n", "noise_scm", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ",", "# bmmf -> bfmm", "\n", ")", "\n", "\n", "#  Prevent negative and infinite eigenvalues", "\n", "eps", "=", "torch", ".", "finfo", "(", "e_values", ".", "dtype", ")", ".", "eps", "\n", "e_values", "=", "torch", ".", "clamp", "(", "e_values", ",", "min", "=", "eps", ",", "max", "=", "1e6", ")", "\n", "\n", "#  Sort eigen values and vectors in descending-order", "\n", "e_values", "=", "torch", ".", "diag_embed", "(", "torch", ".", "flip", "(", "e_values", ",", "[", "-", "1", "]", ")", ")", "\n", "e_vectors", "=", "torch", ".", "flip", "(", "e_vectors", ",", "[", "-", "1", "]", ")", "\n", "\n", "#  Force zero values for all GEV but the highest", "\n", "if", "self", ".", "rank", ":", "\n", "            ", "e_values", "[", "...", ",", "self", ".", "rank", ":", ",", ":", "]", "=", "0.0", "\n", "\n", "#  Compute bf vectors as SDW MWF filter  in eigen space", "\n", "", "complex_type", "=", "e_vectors", ".", "dtype", "\n", "ev_plus_mu", "=", "e_values", "+", "self", ".", "mu", "*", "torch", ".", "eye", "(", "e_values", ".", "shape", "[", "-", "1", "]", ")", ".", "expand_as", "(", "e_values", ")", "\n", "bf_vect", "=", "(", "\n", "e_vectors", "\n", "@", "e_values", ".", "to", "(", "complex_type", ")", "\n", "@", "torch", ".", "linalg", ".", "inv", "(", "e_vectors", "@", "ev_plus_mu", ".", "to", "(", "complex_type", ")", ")", "\n", ")", "\n", "\n", "return", "bf_vect", "[", "...", ",", "0", "]", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# bfmm -> bfm -> bmf", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.GEVDBeamformer.forward": [[314, 332], ["beamforming.GEVDBeamformer.compute_beamforming_vector", "beamforming.GEVDBeamformer.apply_beamforming_vector"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.GEVDBeamformer.compute_beamforming_vector", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.Beamformer.apply_beamforming_vector"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "mix", ":", "torch", ".", "Tensor", ",", "\n", "target_scm", ":", "torch", ".", "Tensor", ",", "\n", "noise_scm", ":", "torch", ".", "Tensor", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Compute and apply the GEVD beamformer.\n\n        Args:\n            mix (torch.ComplexTensor): shape (batch, mics, freqs, frames)\n            target_scm (torch.ComplexTensor): (batch, mics, mics, freqs)\n            noise_scm (torch.ComplexTensor): (batch, mics, mics, freqs)\n\n        Returns:\n            Filtered mixture. torch.ComplexTensor (batch, freqs, frames)\n        \"\"\"", "\n", "bf_vect", "=", "self", ".", "compute_beamforming_vector", "(", "target_scm", ",", "noise_scm", ")", "\n", "return", "self", ".", "apply_beamforming_vector", "(", "bf_vect", ",", "mix", "=", "mix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.compute_scm": [[334, 356], ["torch.einsum", "torch.ones", "x.conj", "torch.ones.sum().transpose", "torch.ones.sum"], "function", ["None"], ["", "", "def", "compute_scm", "(", "x", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", "=", "None", ",", "normalize", ":", "bool", "=", "True", ")", ":", "\n", "    ", "\"\"\"Compute the spatial covariance matrix from a STFT signal x.\n\n    Args:\n        x (torch.ComplexTensor): shape  [batch, mics, freqs, frames]\n        mask (torch.Tensor): [batch, 1, freqs, frames] or [batch, 1, freqs, frames]. Optional\n        normalize (bool): Whether to normalize with the mask mean per bin.\n\n    Returns:\n        torch.ComplexTensor, the SCM with shape (batch, mics, mics, freqs)\n    \"\"\"", "\n", "batch", ",", "mics", ",", "freqs", ",", "frames", "=", "x", ".", "shape", "\n", "if", "mask", "is", "None", ":", "\n", "        ", "mask", "=", "torch", ".", "ones", "(", "batch", ",", "1", ",", "freqs", ",", "frames", ")", "\n", "", "if", "mask", ".", "ndim", "==", "3", ":", "\n", "        ", "mask", "=", "mask", "[", ":", ",", "None", "]", "\n", "\n", "# torch.matmul((mask * x).transpose(1, 2), x.conj().permute(0, 2, 3, 1))", "\n", "", "scm", "=", "torch", ".", "einsum", "(", "\"bmft,bnft->bmnf\"", ",", "mask", "*", "x", ",", "x", ".", "conj", "(", ")", ")", "\n", "if", "normalize", ":", "\n", "        ", "scm", "/=", "mask", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "", "return", "scm", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.get_optimal_reference_mic": [[358, 387], ["torch.clamp", "torch.all", "torch.argmax", "torch.isfinite", "torch.einsum", "torch.einsum", "bf_mat.conj", "bf_mat.conj"], "function", ["None"], ["", "def", "get_optimal_reference_mic", "(", "\n", "bf_mat", ":", "torch", ".", "Tensor", ",", "\n", "target_scm", ":", "torch", ".", "Tensor", ",", "\n", "noise_scm", ":", "torch", ".", "Tensor", ",", "\n", "eps", ":", "float", "=", "1e-6", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Compute the optimal reference mic given the a posteriori SNR, see [1].\n\n    Args:\n        bf_mat: (batch, freq, mics, mics)\n        target_scm (torch.ComplexTensor): (batch, freqs, mics, mics)\n        noise_scm (torch.ComplexTensor): (batch, freqs, mics, mics)\n        eps: value to clip the denominator.\n\n    Returns:\n        torch.\n\n    References\n        Erdogan et al. 2016: \"Improved MVDR beamforming using single-channel maskprediction networks\"\n            https://www.merl.com/publications/docs/TR2016-072.pdf\n    \"\"\"", "\n", "den", "=", "torch", ".", "clamp", "(", "\n", "torch", ".", "einsum", "(", "\"...flm,...fln,...fnm->...m\"", ",", "bf_mat", ".", "conj", "(", ")", ",", "noise_scm", ",", "bf_mat", ")", ".", "real", ",", "min", "=", "eps", "\n", ")", "\n", "snr_post", "=", "(", "\n", "torch", ".", "einsum", "(", "\"...flm,...fln,...fnm->...m\"", ",", "bf_mat", ".", "conj", "(", ")", ",", "target_scm", ",", "bf_mat", ")", ".", "real", "/", "den", "\n", ")", "\n", "assert", "torch", ".", "all", "(", "torch", ".", "isfinite", "(", "snr_post", ")", ")", ",", "snr_post", "\n", "return", "torch", ".", "argmax", "(", "snr_post", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.condition_scm": [[389, 400], ["torch.eye", "beamforming.batch_trace"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.batch_trace"], ["", "def", "condition_scm", "(", "x", ",", "eps", "=", "1e-6", ",", "dim1", "=", "-", "2", ",", "dim2", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\"Condition input SCM with (x + eps tr(x) I) / (1 + eps) along `dim1` and `dim2`.\n\n    See https://stt.msu.edu/users/mauryaas/Ashwini_JPEN.pdf (2.3).\n    \"\"\"", "\n", "# Assume 4d with ...mm", "\n", "if", "dim1", "!=", "-", "2", "or", "dim2", "!=", "-", "1", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "scale", "=", "eps", "*", "batch_trace", "(", "x", ",", "dim1", "=", "dim1", ",", "dim2", "=", "dim2", ")", "[", "...", ",", "None", ",", "None", "]", "/", "x", ".", "shape", "[", "dim1", "]", "\n", "scaled_eye", "=", "torch", ".", "eye", "(", "x", ".", "shape", "[", "dim1", "]", ",", "device", "=", "x", ".", "device", ")", "[", "None", ",", "None", "]", "*", "scale", "\n", "return", "(", "x", "+", "scaled_eye", ")", "/", "(", "1", "+", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.batch_trace": [[402, 405], ["torch.diagonal().sum", "torch.diagonal"], "function", ["None"], ["", "def", "batch_trace", "(", "x", ",", "dim1", "=", "-", "2", ",", "dim2", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\"Compute the trace along `dim1` and `dim2` for a any matrix `ndim>=2`.\"\"\"", "\n", "return", "torch", ".", "diagonal", "(", "x", ",", "dim1", "=", "dim1", ",", "dim2", "=", "dim2", ")", ".", "sum", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.stable_solve": [[407, 415], ["beamforming._common_dtype", "_stable_solve().to", "beamforming._precision_mapping", "beamforming._stable_solve", "b.to", "a.to"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._common_dtype", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._precision_mapping", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._stable_solve"], ["", "def", "stable_solve", "(", "b", ",", "a", ")", ":", "\n", "    ", "\"\"\"Return torch.solve if `a` is non-singular, else regularize `a` and return torch.solve.\"\"\"", "\n", "# Only run it in double", "\n", "input_dtype", "=", "_common_dtype", "(", "b", ",", "a", ")", "\n", "solve_dtype", "=", "input_dtype", "\n", "if", "input_dtype", "not", "in", "[", "torch", ".", "float64", ",", "torch", ".", "complex128", "]", ":", "\n", "        ", "solve_dtype", "=", "_precision_mapping", "(", ")", "[", "input_dtype", "]", "\n", "", "return", "_stable_solve", "(", "b", ".", "to", "(", "solve_dtype", ")", ",", "a", ".", "to", "(", "solve_dtype", ")", ")", ".", "to", "(", "input_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._stable_solve": [[417, 423], ["torch.linalg.solve", "beamforming.condition_scm", "torch.linalg.solve"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.condition_scm"], ["", "def", "_stable_solve", "(", "b", ",", "a", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "return", "torch", ".", "linalg", ".", "solve", "(", "a", ",", "b", ")", "\n", "", "except", "RuntimeError", ":", "\n", "        ", "a", "=", "condition_scm", "(", "a", ",", "eps", ")", "\n", "return", "torch", ".", "linalg", ".", "solve", "(", "a", ",", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.stable_cholesky": [[425, 441], ["_stable_cholesky().to", "beamforming._precision_mapping", "beamforming._stable_cholesky", "input.to"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._precision_mapping", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._stable_cholesky"], ["", "", "def", "stable_cholesky", "(", "input", ",", "upper", "=", "False", ",", "out", "=", "None", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"Compute the Cholesky decomposition of ``input``.\n    If ``input`` is only p.s.d, add a small jitter to the diagonal.\n\n    Args:\n        input (Tensor): The tensor to compute the Cholesky decomposition of\n        upper (bool, optional): See torch.cholesky\n        out (Tensor, optional): See torch.cholesky\n        eps (int): small jitter added to the diagonal if PD.\n    \"\"\"", "\n", "# Only run it in double", "\n", "input_dtype", "=", "input", ".", "dtype", "\n", "solve_dtype", "=", "input_dtype", "\n", "if", "input_dtype", "not", "in", "[", "torch", ".", "float64", ",", "torch", ".", "complex128", "]", ":", "\n", "        ", "solve_dtype", "=", "_precision_mapping", "(", ")", "[", "input_dtype", "]", "\n", "", "return", "_stable_cholesky", "(", "input", ".", "to", "(", "solve_dtype", ")", ",", "upper", "=", "upper", ",", "out", "=", "out", ",", "eps", "=", "eps", ")", ".", "to", "(", "input_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._stable_cholesky": [[443, 453], ["torch.linalg.cholesky", "beamforming.condition_scm", "torch.linalg.cholesky", "torch.linalg.cholesky", "torch.linalg.cholesky"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.condition_scm"], ["", "def", "_stable_cholesky", "(", "input", ",", "upper", "=", "False", ",", "out", "=", "None", ",", "eps", "=", "1e-6", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "if", "upper", ":", "\n", "            ", "return", "torch", ".", "linalg", ".", "cholesky", "(", "input", ",", "out", "=", "out", ")", ".", "mH", "\n", "", "return", "torch", ".", "linalg", ".", "cholesky", "(", "input", ",", "out", "=", "out", ")", "\n", "", "except", "RuntimeError", ":", "\n", "        ", "input", "=", "condition_scm", "(", "input", ",", "eps", ")", "\n", "if", "upper", ":", "\n", "            ", "return", "torch", ".", "linalg", ".", "cholesky", "(", "input", ",", "out", "=", "out", ")", ".", "mH", "\n", "", "return", "torch", ".", "linalg", ".", "cholesky", "(", "input", ",", "out", "=", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.generalized_eigenvalue_decomposition": [[455, 466], ["beamforming._common_dtype", "beamforming._generalized_eigenvalue_decomposition", "a.to", "b.to", "e_vec.to", "beamforming._precision_mapping", "e_val.to"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._common_dtype", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._generalized_eigenvalue_decomposition", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._precision_mapping"], ["", "", "def", "generalized_eigenvalue_decomposition", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\"Solves the generalized eigenvalue decomposition through Cholesky decomposition.\n    Returns eigen values and eigen vectors (ascending order).\n    \"\"\"", "\n", "# Only run it in double", "\n", "input_dtype", "=", "_common_dtype", "(", "a", ",", "b", ")", "\n", "solve_dtype", "=", "input_dtype", "\n", "if", "input_dtype", "not", "in", "[", "torch", ".", "float64", ",", "torch", ".", "complex128", "]", ":", "\n", "        ", "solve_dtype", "=", "_precision_mapping", "(", ")", "[", "input_dtype", "]", "\n", "", "e_val", ",", "e_vec", "=", "_generalized_eigenvalue_decomposition", "(", "a", ".", "to", "(", "solve_dtype", ")", ",", "b", ".", "to", "(", "solve_dtype", ")", ")", "\n", "return", "e_val", ".", "to", "(", "input_dtype", ")", ".", "real", ",", "e_vec", ".", "to", "(", "input_dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._generalized_eigenvalue_decomposition": [[468, 478], ["beamforming.stable_cholesky", "torch.inverse", "torch.symeig", "torch.matmul", "torch.inverse.conj().transpose", "torch.inverse.conj().transpose", "torch.inverse.conj", "torch.inverse.conj"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.stable_cholesky"], ["", "def", "_generalized_eigenvalue_decomposition", "(", "a", ",", "b", ")", ":", "\n", "    ", "cholesky", "=", "stable_cholesky", "(", "b", ")", "\n", "inv_cholesky", "=", "torch", ".", "inverse", "(", "cholesky", ")", "\n", "# Compute C matrix L\u207b1 A L^-T", "\n", "cmat", "=", "inv_cholesky", "@", "a", "@", "inv_cholesky", ".", "conj", "(", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "# Performing the eigenvalue decomposition", "\n", "e_val", ",", "e_vec", "=", "torch", ".", "symeig", "(", "cmat", ",", "eigenvectors", "=", "True", ")", "\n", "# Collecting the eigenvectors", "\n", "e_vec", "=", "torch", ".", "matmul", "(", "inv_cholesky", ".", "conj", "(", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ",", "e_vec", ")", "\n", "return", "e_val", ",", "e_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._common_dtype": [[480, 485], ["len", "RuntimeError", "set"], "function", ["None"], ["", "def", "_common_dtype", "(", "*", "args", ")", ":", "\n", "    ", "all_dtypes", "=", "[", "a", ".", "dtype", "for", "a", "in", "args", "]", "\n", "if", "len", "(", "set", "(", "all_dtypes", ")", ")", ">", "1", ":", "\n", "        ", "raise", "RuntimeError", "(", "f\"Expected inputs from the same dtype. Received {all_dtypes}.\"", ")", "\n", "", "return", "all_dtypes", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.force_float_linalg": [[490, 493], ["None"], "function", ["None"], ["def", "force_float_linalg", "(", ")", ":", "\n", "    ", "global", "USE_DOUBLE", "\n", "USE_DOUBLE", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.force_double_linalg": [[495, 498], ["None"], "function", ["None"], ["", "def", "force_double_linalg", "(", ")", ":", "\n", "    ", "global", "USE_DOUBLE", "\n", "USE_DOUBLE", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming._precision_mapping": [[500, 519], ["hasattr"], "function", ["None"], ["", "def", "_precision_mapping", "(", ")", ":", "\n", "    ", "has_complex32", "=", "hasattr", "(", "torch", ",", "\"complex32\"", ")", "\n", "if", "USE_DOUBLE", ":", "\n", "        ", "precision_map", "=", "{", "\n", "torch", ".", "float16", ":", "torch", ".", "float64", ",", "\n", "torch", ".", "float32", ":", "torch", ".", "float64", ",", "\n", "torch", ".", "complex64", ":", "torch", ".", "complex128", ",", "\n", "}", "\n", "if", "has_complex32", ":", "\n", "            ", "precision_map", "[", "torch", ".", "complex32", "]", "=", "torch", ".", "complex128", "\n", "", "", "else", ":", "\n", "        ", "precision_map", "=", "{", "\n", "torch", ".", "float16", ":", "torch", ".", "float16", ",", "\n", "torch", ".", "float32", ":", "torch", ".", "float32", ",", "\n", "torch", ".", "complex64", ":", "torch", ".", "complex64", ",", "\n", "}", "\n", "if", "has_complex32", ":", "\n", "            ", "precision_map", "[", "torch", ".", "complex32", "]", "=", "torch", ".", "complex32", "\n", "", "", "return", "precision_map", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.spatial.xcorr": [[5, 58], ["inp.expand().contiguous.permute().contiguous", "ref.expand().contiguous.permute().contiguous", "inp.expand().contiguous.size", "inp.expand().contiguous.size", "torch.conv1d", "F.conv1d.view().permute().contiguous", "inp.expand().contiguous.size", "ref.expand().contiguous.size", "inp.expand().contiguous.size", "ref.expand().contiguous.size", "ref.expand().contiguous.size", "inp.expand().contiguous.size", "inp.expand().contiguous.expand().contiguous", "ref.expand().contiguous.size", "inp.expand().contiguous.view", "ref.expand().contiguous.view", "torch.conv1d", "inp.expand().contiguous.permute", "ref.expand().contiguous.permute", "ref.expand().contiguous.size", "inp.expand().contiguous.size", "ref.expand().contiguous.expand().contiguous", "inp.expand().contiguous.size", "ref.expand().contiguous.size", "inp.expand().contiguous.view().pow", "torch.ones().type", "torch.ones().type", "F.conv1d.sqrt", "ref.expand().contiguous.norm().view", "F.conv1d.view().permute", "inp.expand().contiguous.expand", "inp.expand().contiguous.type", "ref.expand().contiguous.size", "inp.expand().contiguous.size", "inp.expand().contiguous.size", "ref.expand().contiguous.expand", "inp.expand().contiguous.view", "torch.ones", "torch.ones", "ref.expand().contiguous.norm", "F.conv1d.view", "inp.expand().contiguous.size", "ref.expand().contiguous.size", "ref.expand().contiguous.size", "inp.expand().contiguous.size", "ref.expand().contiguous.size", "inp.expand().contiguous.size", "inp.expand().contiguous.size"], "function", ["None"], ["def", "xcorr", "(", "inp", ",", "ref", ",", "normalized", "=", "True", ",", "eps", "=", "1e-8", ")", ":", "\n", "    ", "r\"\"\"Multi-channel cross correlation.\n\n    The two signals can have different lengths but the input signal should be shorter than the reference signal.\n\n    .. note:: The cross correlation is computed between each pair of microphone channels and not\n        between all possible pairs e.g. if both input and ref have shape ``(1, 2, 100)``\n        the output will be ``(1, 2, 1)`` the first element is the xcorr between\n        the first mic channel of input and the first mic channel of ref.\n        If either input and ref have only one channel e.g. input: (1, 3, 100) and ref: ``(1, 1, 100)``\n        then output will be ``(1, 3, 1)`` as ref will be broadcasted to have same shape as input.\n\n    Args:\n        inp (:class:`torch.Tensor`): multi-channel input signal. Shape: :math:`(batch, mic\\_channels, seq\\_len)`.\n        ref (:class:`torch.Tensor`): multi-channel reference signal. Shape: :math:`(batch, mic\\_channels, seq\\_len)`.\n        normalized (bool, optional): whether to normalize the cross-correlation with the l2 norm of input signals.\n        eps (float, optional): machine epsilon used for numerical stabilization when normalization is used.\n\n    Returns:\n        out (:class:`torch.Tensor`): cross correlation between the two multi-channel signals.\n            Shape: :math:`(batch, mic\\_channels, seq\\_len\\_ref - seq\\_len\\_input + 1)`.\n\n    \"\"\"", "\n", "# inp: batch, nmics2, seq_len2 || ref: batch, nmics1, seq_len1", "\n", "assert", "inp", ".", "size", "(", "0", ")", "==", "ref", ".", "size", "(", "0", ")", ",", "\"ref and inp signals should have same batch size.\"", "\n", "assert", "inp", ".", "size", "(", "2", ")", ">=", "ref", ".", "size", "(", "2", ")", ",", "\"Input signal should be shorter than the ref signal.\"", "\n", "\n", "inp", "=", "inp", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "ref", "=", "ref", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "bsz", "=", "inp", ".", "size", "(", "1", ")", "\n", "inp_mics", "=", "inp", ".", "size", "(", "0", ")", "\n", "\n", "if", "ref", ".", "size", "(", "0", ")", ">", "inp", ".", "size", "(", "0", ")", ":", "\n", "        ", "inp", "=", "inp", ".", "expand", "(", "ref", ".", "size", "(", "0", ")", ",", "inp", ".", "size", "(", "1", ")", ",", "inp", ".", "size", "(", "2", ")", ")", ".", "contiguous", "(", ")", "# nmic2, L, seg1", "\n", "inp_mics", "=", "ref", ".", "size", "(", "0", ")", "\n", "", "elif", "ref", ".", "size", "(", "0", ")", "<", "inp", ".", "size", "(", "0", ")", ":", "\n", "        ", "ref", "=", "ref", ".", "expand", "(", "inp", ".", "size", "(", "0", ")", ",", "ref", ".", "size", "(", "1", ")", ",", "ref", ".", "size", "(", "2", ")", ")", ".", "contiguous", "(", ")", "# nmic1, L, seg2", "\n", "# cosine similarity", "\n", "", "out", "=", "F", ".", "conv1d", "(", "\n", "inp", ".", "view", "(", "1", ",", "-", "1", ",", "inp", ".", "size", "(", "2", ")", ")", ",", "ref", ".", "view", "(", "-", "1", ",", "1", ",", "ref", ".", "size", "(", "2", ")", ")", ",", "groups", "=", "inp_mics", "*", "bsz", "\n", ")", "# 1, inp_mics*L, seg1-seg2+1", "\n", "\n", "# L2 norms", "\n", "if", "normalized", ":", "\n", "        ", "inp_norm", "=", "F", ".", "conv1d", "(", "\n", "inp", ".", "view", "(", "1", ",", "-", "1", ",", "inp", ".", "size", "(", "2", ")", ")", ".", "pow", "(", "2", ")", ",", "\n", "torch", ".", "ones", "(", "inp", ".", "size", "(", "0", ")", "*", "inp", ".", "size", "(", "1", ")", ",", "1", ",", "ref", ".", "size", "(", "2", ")", ")", ".", "type", "(", "inp", ".", "type", "(", ")", ")", ",", "\n", "groups", "=", "inp_mics", "*", "bsz", ",", "\n", ")", "# 1, inp_mics*L, seg1-seg2+1", "\n", "inp_norm", "=", "inp_norm", ".", "sqrt", "(", ")", "+", "eps", "\n", "ref_norm", "=", "ref", ".", "norm", "(", "2", ",", "dim", "=", "2", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", "+", "eps", "# 1, inp_mics*L, 1", "\n", "out", "=", "out", "/", "(", "inp_norm", "*", "ref_norm", ")", "\n", "", "return", "out", ".", "view", "(", "inp_mics", ",", "bsz", ",", "-", "1", ")", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.LambdaOverlapAdd.__init__": [[52, 83], ["super().__init__", "getattr", "overlap_add.LambdaOverlapAdd.register_buffer", "get_window().astype", "torch.from_numpy", "get_window"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nnet", ",", "\n", "n_src", ",", "\n", "window_size", ",", "\n", "hop_size", "=", "None", ",", "\n", "window", "=", "\"hanning\"", ",", "\n", "reorder_chunks", "=", "True", ",", "\n", "enable_grad", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "window_size", "%", "2", "==", "0", ",", "\"Window size must be even\"", "\n", "\n", "self", ".", "nnet", "=", "nnet", "\n", "self", ".", "window_size", "=", "window_size", "\n", "self", ".", "hop_size", "=", "hop_size", "if", "hop_size", "is", "not", "None", "else", "window_size", "//", "2", "\n", "self", ".", "n_src", "=", "n_src", "\n", "self", ".", "in_channels", "=", "getattr", "(", "nnet", ",", "\"in_channels\"", ",", "None", ")", "\n", "\n", "if", "window", ":", "\n", "            ", "from", "scipy", ".", "signal", "import", "get_window", "# for torch.hub", "\n", "\n", "window", "=", "get_window", "(", "window", ",", "self", ".", "window_size", ")", ".", "astype", "(", "\"float32\"", ")", "\n", "window", "=", "torch", ".", "from_numpy", "(", "window", ")", "\n", "self", ".", "use_window", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "use_window", "=", "False", "\n", "\n", "", "self", ".", "register_buffer", "(", "\"window\"", ",", "window", ")", "\n", "self", ".", "reorder_chunks", "=", "reorder_chunks", "\n", "self", ".", "enable_grad", "=", "enable_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.LambdaOverlapAdd.ola_forward": [[84, 132], ["x.size", "torch.nn.functional.unfold", "range", "torch.stack().reshape", "torch.nn.functional.fold.permute", "torch.nn.functional.fold", "torch.nn.functional.fold.squeeze().reshape", "x.unsqueeze", "overlap_add.LambdaOverlapAdd.nnet", "_reorder_sources.reshape", "torch.nn.functional.fold.append", "overlap_add._reorder_sources", "torch.stack", "torch.nn.functional.fold.squeeze"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.unfold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.fold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add._reorder_sources"], ["", "def", "ola_forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Heart of the class: segment signal, apply func, combine with OLA.\"\"\"", "\n", "\n", "assert", "x", ".", "ndim", "==", "3", "\n", "\n", "batch", ",", "channels", ",", "n_frames", "=", "x", ".", "size", "(", ")", "\n", "# Overlap and add:", "\n", "# [batch, chans, n_frames] -> [batch, chans, win_size, n_chunks]", "\n", "unfolded", "=", "torch", ".", "nn", ".", "functional", ".", "unfold", "(", "\n", "x", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "kernel_size", "=", "(", "self", ".", "window_size", ",", "1", ")", ",", "\n", "padding", "=", "(", "self", ".", "window_size", ",", "0", ")", ",", "\n", "stride", "=", "(", "self", ".", "hop_size", ",", "1", ")", ",", "\n", ")", "\n", "\n", "out", "=", "[", "]", "\n", "n_chunks", "=", "unfolded", ".", "shape", "[", "-", "1", "]", "\n", "for", "frame_idx", "in", "range", "(", "n_chunks", ")", ":", "# for loop to spare memory", "\n", "            ", "frame", "=", "self", ".", "nnet", "(", "unfolded", "[", "...", ",", "frame_idx", "]", ")", "\n", "# user must handle multichannel by reshaping to batch", "\n", "if", "frame_idx", "==", "0", ":", "\n", "                ", "assert", "frame", ".", "ndim", "==", "3", ",", "\"nnet should return (batch, n_src, time)\"", "\n", "if", "self", ".", "n_src", "is", "not", "None", ":", "\n", "                    ", "assert", "frame", ".", "shape", "[", "1", "]", "==", "self", ".", "n_src", ",", "\"nnet should return (batch, n_src, time)\"", "\n", "", "n_src", "=", "frame", ".", "shape", "[", "1", "]", "\n", "", "frame", "=", "frame", ".", "reshape", "(", "batch", "*", "n_src", ",", "-", "1", ")", "\n", "\n", "if", "frame_idx", "!=", "0", "and", "self", ".", "reorder_chunks", ":", "\n", "# we determine best perm based on xcorr with previous sources", "\n", "                ", "frame", "=", "_reorder_sources", "(", "frame", ",", "out", "[", "-", "1", "]", ",", "n_src", ",", "self", ".", "window_size", ",", "self", ".", "hop_size", ")", "\n", "\n", "", "if", "self", ".", "use_window", ":", "\n", "                ", "frame", "=", "frame", "*", "self", ".", "window", "\n", "", "else", ":", "\n", "                ", "frame", "=", "frame", "/", "(", "self", ".", "window_size", "/", "self", ".", "hop_size", ")", "\n", "", "out", ".", "append", "(", "frame", ")", "\n", "\n", "", "out", "=", "torch", ".", "stack", "(", "out", ")", ".", "reshape", "(", "n_chunks", ",", "batch", "*", "n_src", ",", "self", ".", "window_size", ")", "\n", "out", "=", "out", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "\n", "out", "=", "torch", ".", "nn", ".", "functional", ".", "fold", "(", "\n", "out", ",", "\n", "(", "n_frames", ",", "1", ")", ",", "\n", "kernel_size", "=", "(", "self", ".", "window_size", ",", "1", ")", ",", "\n", "padding", "=", "(", "self", ".", "window_size", ",", "0", ")", ",", "\n", "stride", "=", "(", "self", ".", "hop_size", ",", "1", ")", ",", "\n", ")", "\n", "return", "out", ".", "squeeze", "(", "-", "1", ")", ".", "reshape", "(", "batch", ",", "n_src", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.LambdaOverlapAdd.forward": [[133, 146], ["torch.autograd.set_grad_enabled", "overlap_add.LambdaOverlapAdd.ola_forward"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.LambdaOverlapAdd.ola_forward"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward module: segment signal, apply func, combine with OLA.\n\n        Args:\n            x (:class:`torch.Tensor`): waveform signal of shape (batch, 1, time).\n\n        Returns:\n            :class:`torch.Tensor`: The output of the lambda OLA.\n        \"\"\"", "\n", "# Here we can do the reshaping", "\n", "with", "torch", ".", "autograd", ".", "set_grad_enabled", "(", "self", ".", "enable_grad", ")", ":", "\n", "            ", "olad", "=", "self", ".", "ola_forward", "(", "x", ")", "\n", "return", "olad", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.LambdaOverlapAdd.sample_rate": [[149, 152], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "sample_rate", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "nnet", ".", "sample_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.LambdaOverlapAdd._separate": [[153, 155], ["overlap_add.LambdaOverlapAdd.forward"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.Model.forward"], ["", "def", "_separate", "(", "self", ",", "wav", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "forward", "(", "wav", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.__init__": [[216, 221], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "chunk_size", ",", "hop_size", ")", ":", "\n", "        ", "super", "(", "DualPathProcessing", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "chunk_size", "=", "chunk_size", "\n", "self", ".", "hop_size", "=", "hop_size", "\n", "self", ".", "n_orig_frames", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.unfold": [[222, 248], ["x.size", "torch.nn.functional.unfold", "torch.nn.functional.unfold.reshape", "x.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.unfold"], ["", "def", "unfold", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"\n        Unfold the feature tensor from $(batch, channels, time)$ to\n        $(batch, channels, chunksize, nchunks)$.\n\n        Args:\n            x (:class:`torch.Tensor`): feature tensor of shape $(batch, channels, time)$.\n\n        Returns:\n            :class:`torch.Tensor`: spliced feature tensor of shape\n            $(batch, channels, chunksize, nchunks)$.\n\n        \"\"\"", "\n", "# x is (batch, chan, frames)", "\n", "batch", ",", "chan", ",", "frames", "=", "x", ".", "size", "(", ")", "\n", "assert", "x", ".", "ndim", "==", "3", "\n", "self", ".", "n_orig_frames", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "unfolded", "=", "torch", ".", "nn", ".", "functional", ".", "unfold", "(", "\n", "x", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "kernel_size", "=", "(", "self", ".", "chunk_size", ",", "1", ")", ",", "\n", "padding", "=", "(", "self", ".", "chunk_size", ",", "0", ")", ",", "\n", "stride", "=", "(", "self", ".", "hop_size", ",", "1", ")", ",", "\n", ")", "\n", "\n", "return", "unfolded", ".", "reshape", "(", "\n", "batch", ",", "chan", ",", "self", ".", "chunk_size", ",", "-", "1", "\n", ")", "# (batch, chan, chunk_size, n_chunks)", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.fold": [[250, 285], ["torch.nn.functional.fold.size", "torch.nn.functional.fold.reshape", "torch.nn.functional.fold", "torch.nn.functional.fold.reshape", "float"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.fold"], ["", "def", "fold", "(", "self", ",", "x", ",", "output_size", "=", "None", ")", ":", "\n", "        ", "r\"\"\"\n        Folds back the spliced feature tensor.\n        Input shape $(batch, channels, chunksize, nchunks)$ to original shape\n        $(batch, channels, time)$ using overlap-add.\n\n        Args:\n            x (:class:`torch.Tensor`): spliced feature tensor of shape\n                $(batch, channels, chunksize, nchunks)$.\n            output_size (int, optional): sequence length of original feature tensor.\n                If None, the original length cached by the previous call of\n                :meth:`unfold` will be used.\n\n        Returns:\n            :class:`torch.Tensor`:  feature tensor of shape $(batch, channels, time)$.\n\n        .. note:: `fold` caches the original length of the input.\n\n        \"\"\"", "\n", "output_size", "=", "output_size", "if", "output_size", "is", "not", "None", "else", "self", ".", "n_orig_frames", "\n", "# x is (batch, chan, chunk_size, n_chunks)", "\n", "batch", ",", "chan", ",", "chunk_size", ",", "n_chunks", "=", "x", ".", "size", "(", ")", "\n", "to_unfold", "=", "x", ".", "reshape", "(", "batch", ",", "chan", "*", "self", ".", "chunk_size", ",", "n_chunks", ")", "\n", "x", "=", "torch", ".", "nn", ".", "functional", ".", "fold", "(", "\n", "to_unfold", ",", "\n", "(", "output_size", ",", "1", ")", ",", "\n", "kernel_size", "=", "(", "self", ".", "chunk_size", ",", "1", ")", ",", "\n", "padding", "=", "(", "self", ".", "chunk_size", ",", "0", ")", ",", "\n", "stride", "=", "(", "self", ".", "hop_size", ",", "1", ")", ",", "\n", ")", "\n", "\n", "# force float div for torch jit", "\n", "x", "/=", "float", "(", "self", ".", "chunk_size", ")", "/", "self", ".", "hop_size", "\n", "\n", "return", "x", ".", "reshape", "(", "batch", ",", "chan", ",", "self", ".", "n_orig_frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.intra_process": [[286, 311], ["x.reshape().transpose().transpose.reshape().transpose().transpose.size", "x.reshape().transpose().transpose.reshape().transpose().transpose.transpose().reshape().transpose", "module", "x.reshape().transpose().transpose.reshape().transpose().transpose.reshape().transpose().transpose", "x.reshape().transpose().transpose.reshape().transpose().transpose.transpose().reshape", "x.reshape().transpose().transpose.reshape().transpose().transpose.reshape().transpose", "x.reshape().transpose().transpose.reshape().transpose().transpose.transpose", "x.reshape().transpose().transpose.reshape().transpose().transpose.reshape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "intra_process", "(", "x", ",", "module", ")", ":", "\n", "        ", "r\"\"\"Performs intra-chunk processing.\n\n        Args:\n            x (:class:`torch.Tensor`): spliced feature tensor of shape\n                (batch, channels, chunk_size, n_chunks).\n            module (:class:`torch.nn.Module`): module one wish to apply to each chunk\n                of the spliced feature tensor.\n\n        Returns:\n            :class:`torch.Tensor`: processed spliced feature tensor of shape\n            $(batch, channels, chunksize, nchunks)$.\n\n        .. note:: the module should have the channel first convention and accept\n            a 3D tensor of shape $(batch, channels, time)$.\n        \"\"\"", "\n", "\n", "# x is (batch, channels, chunk_size, n_chunks)", "\n", "batch", ",", "channels", ",", "chunk_size", ",", "n_chunks", "=", "x", ".", "size", "(", ")", "\n", "# we reshape to batch*chunk_size, channels, n_chunks", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "-", "1", ")", ".", "reshape", "(", "batch", "*", "n_chunks", ",", "chunk_size", ",", "channels", ")", ".", "transpose", "(", "1", ",", "-", "1", ")", "\n", "x", "=", "module", "(", "x", ")", "\n", "x", "=", "x", ".", "reshape", "(", "batch", ",", "n_chunks", ",", "channels", ",", "chunk_size", ")", ".", "transpose", "(", "1", ",", "-", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.inter_process": [[312, 336], ["x.reshape().transpose.reshape().transpose.size", "x.reshape().transpose.reshape().transpose.transpose().reshape", "module", "x.reshape().transpose.reshape().transpose.reshape().transpose", "x.reshape().transpose.reshape().transpose.transpose", "x.reshape().transpose.reshape().transpose.reshape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "inter_process", "(", "x", ",", "module", ")", ":", "\n", "        ", "r\"\"\"Performs inter-chunk processing.\n\n        Args:\n            x (:class:`torch.Tensor`): spliced feature tensor of shape\n                $(batch, channels, chunksize, nchunks)$.\n            module (:class:`torch.nn.Module`): module one wish to apply between\n                each chunk of the spliced feature tensor.\n\n\n        Returns:\n            x (:class:`torch.Tensor`): processed spliced feature tensor of shape\n            $(batch, channels, chunksize, nchunks)$.\n\n        .. note:: the module should have the channel first convention and accept\n            a 3D tensor of shape $(batch, channels, time)$.\n        \"\"\"", "\n", "\n", "batch", ",", "channels", ",", "chunk_size", ",", "n_chunks", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "batch", "*", "chunk_size", ",", "channels", ",", "n_chunks", ")", "\n", "x", "=", "module", "(", "x", ")", "\n", "x", "=", "x", ".", "reshape", "(", "batch", ",", "chunk_size", ",", "channels", ",", "n_chunks", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add._reorder_sources": [[157, 200], ["pit.size", "pit.reshape", "previous.reshape.reshape", "losses.pit_wrapper.PITReorder", "losses.pit_wrapper.PITReorder.", "pit.reshape", "x.mean", "y.mean", "torch.sum", "x.unsqueeze", "y.unsqueeze"], "function", ["None"], ["", "", "def", "_reorder_sources", "(", "\n", "current", ":", "torch", ".", "FloatTensor", ",", "\n", "previous", ":", "torch", ".", "FloatTensor", ",", "\n", "n_src", ":", "int", ",", "\n", "window_size", ":", "int", ",", "\n", "hop_size", ":", "int", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n     Reorder sources in current chunk to maximize correlation with previous chunk.\n     Used for Continuous Source Separation. Standard dsp correlation is used\n     for reordering.\n\n\n    Args:\n        current (:class:`torch.Tensor`): current chunk, tensor\n                                        of shape (batch, n_src, window_size)\n        previous (:class:`torch.Tensor`): previous chunk, tensor\n                                        of shape (batch, n_src, window_size)\n        n_src (:class:`int`): number of sources.\n        window_size (:class:`int`): window_size, equal to last dimension of\n                                    both current and previous.\n        hop_size (:class:`int`): hop_size between current and previous tensors.\n\n    \"\"\"", "\n", "batch", ",", "frames", "=", "current", ".", "size", "(", ")", "\n", "current", "=", "current", ".", "reshape", "(", "-", "1", ",", "n_src", ",", "frames", ")", "\n", "previous", "=", "previous", ".", "reshape", "(", "-", "1", ",", "n_src", ",", "frames", ")", "\n", "\n", "overlap_f", "=", "window_size", "-", "hop_size", "\n", "\n", "def", "reorder_func", "(", "x", ",", "y", ")", ":", "\n", "        ", "x", "=", "x", "[", "...", ",", ":", "overlap_f", "]", "\n", "y", "=", "y", "[", "...", ",", "-", "overlap_f", ":", "]", "\n", "# Mean normalization", "\n", "x", "=", "x", "-", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "y", "=", "y", "-", "y", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "# Negative mean Correlation", "\n", "return", "-", "torch", ".", "sum", "(", "x", ".", "unsqueeze", "(", "1", ")", "*", "y", ".", "unsqueeze", "(", "2", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# We maximize correlation-like between previous and current.", "\n", "", "pit", "=", "PITReorder", "(", "reorder_func", ")", "\n", "current", "=", "pit", "(", "current", ",", "previous", ")", "\n", "return", "current", ".", "reshape", "(", "batch", ",", "frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.normalization.normalize_estimates": [[4, 14], ["numpy.max", "numpy.stack", "numpy.abs", "numpy.max", "numpy.abs"], "function", ["None"], ["def", "normalize_estimates", "(", "est_np", ",", "mix_np", ")", ":", "\n", "    ", "\"\"\"Normalizes estimates according to the mixture maximum amplitude\n\n    Args:\n        est_np (np.array): Estimates with shape (n_src, time).\n        mix_np (np.array): One mixture with shape (time, ).\n\n    \"\"\"", "\n", "mix_max", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "mix_np", ")", ")", "\n", "return", "np", ".", "stack", "(", "[", "est", "*", "mix_max", "/", "np", ".", "max", "(", "np", ".", "abs", "(", "est", ")", ")", "for", "est", "in", "est_np", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.vad.ebased_vad": [[5, 32], ["torch.log10", "list", "torch.max", "log_mag.view"], "function", ["None"], ["@", "script_if_tracing", "\n", "def", "ebased_vad", "(", "mag_spec", ",", "th_db", ":", "int", "=", "40", ")", ":", "\n", "    ", "\"\"\"Compute energy-based VAD from a magnitude spectrogram (or equivalent).\n\n    Args:\n        mag_spec (torch.Tensor): the spectrogram to perform VAD on.\n            Expected shape (batch, *, freq, time).\n            The VAD mask will be computed independently for all the leading\n            dimensions until the last two. Independent of the ordering of the\n            last two dimensions.\n        th_db (int): The threshold in dB from which a TF-bin is considered\n            silent.\n\n    Returns:\n        :class:`torch.BoolTensor`, the VAD mask.\n\n\n    Examples\n        >>> import torch\n        >>> mag_spec = torch.abs(torch.randn(10, 2, 65, 16))\n        >>> batch_src_mask = ebased_vad(mag_spec)\n    \"\"\"", "\n", "log_mag", "=", "20", "*", "torch", ".", "log10", "(", "mag_spec", ")", "\n", "# Compute VAD for each utterance in a batch independently.", "\n", "to_view", "=", "list", "(", "mag_spec", ".", "shape", "[", ":", "-", "2", "]", ")", "+", "[", "1", ",", "-", "1", "]", "\n", "max_log_mag", "=", "torch", ".", "max", "(", "log_mag", ".", "view", "(", "to_view", ")", ",", "-", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", "\n", "return", "log_mag", ">", "(", "max_log_mag", "-", "th_db", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.deltas.compute_delta": [[4, 28], ["feats.new_zeros", "compute_delta().transpose", "deltas.compute_delta", "feats.transpose"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.deltas.compute_delta"], ["def", "compute_delta", "(", "feats", ":", "torch", ".", "Tensor", ",", "dim", ":", "int", "=", "-", "1", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Compute delta coefficients of a tensor.\n\n    Args:\n        feats: Input features to compute deltas with.\n        dim: feature dimension in the feats tensor.\n\n    Returns:\n        Tensor: Tensor of deltas.\n\n    Examples\n        >>> import torch\n        >>> phase = torch.randn(2, 257, 100)\n        >>> # Compute instantaneous frequency\n        >>> inst_freq = compute_delta(phase, dim=-1)\n        >>> # Or group delay\n        >>> group_delay = compute_delta(phase, dim=-2)\n    \"\"\"", "\n", "if", "dim", "!=", "-", "1", ":", "\n", "        ", "return", "compute_delta", "(", "feats", ".", "transpose", "(", "-", "1", ",", "dim", ")", ",", "dim", "=", "-", "1", ")", ".", "transpose", "(", "-", "1", ",", "dim", ")", "\n", "# First frame has nothing. Then each frame is the diff with the previous one.", "\n", "", "delta", "=", "feats", ".", "new_zeros", "(", "feats", ".", "shape", ")", "\n", "delta", "[", "...", ",", "1", ":", "]", "=", "feats", "[", "...", ",", "1", ":", "]", "-", "feats", "[", "...", ",", ":", "-", "1", "]", "\n", "return", "delta", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.deltas.concat_deltas": [[30, 54], ["range", "torch.cat", "all_feats.append", "deltas.compute_delta"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.deltas.compute_delta"], ["", "def", "concat_deltas", "(", "feats", ":", "torch", ".", "Tensor", ",", "order", ":", "int", "=", "1", ",", "dim", ":", "int", "=", "-", "1", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Concatenate delta coefficients of a tensor to itself.\n\n    Args:\n        feats: Input features to compute deltas with.\n        order: Order of the delta e.g with order==2, compute delta of delta\n            as well.\n        dim: feature dimension in the feats tensor.\n\n    Returns:\n        Tensor: Concatenation of the features, the deltas and subsequent deltas.\n\n    Examples\n        >>> import torch\n        >>> phase = torch.randn(2, 257, 100)\n        >>> # Compute second order instantaneous frequency\n        >>> phase_and_inst_freq = concat_deltas(phase, order=2, dim=-1)\n        >>> # Or group delay\n        >>> phase_and_group_delay = concat_deltas(phase, order=2, dim=-2)\n    \"\"\"", "\n", "all_feats", "=", "[", "feats", "]", "\n", "for", "_", "in", "range", "(", "order", ")", ":", "\n", "        ", "all_feats", ".", "append", "(", "compute_delta", "(", "all_feats", "[", "-", "1", "]", ",", "dim", "=", "dim", ")", ")", "\n", "", "return", "torch", ".", "cat", "(", "all_feats", ",", "dim", "=", "dim", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.consistency.mixture_consistency": [[5, 73], ["torch.arange().tolist", "all_dims.pop", "all_dims.pop", "torch.mean", "torch.sum", "RuntimeError", "torch.arange", "est_sources.sum", "est_sources.sum"], "function", ["None"], ["def", "mixture_consistency", "(", "\n", "mixture", ":", "torch", ".", "Tensor", ",", "\n", "est_sources", ":", "torch", ".", "Tensor", ",", "\n", "src_weights", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "dim", ":", "int", "=", "1", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"Applies mixture consistency to a tensor of estimated sources.\n\n    Args:\n        mixture (torch.Tensor): Mixture waveform or TF representation.\n        est_sources (torch.Tensor): Estimated sources waveforms or TF representations.\n        src_weights (torch.Tensor): Consistency weight for each source.\n            Shape needs to be broadcastable to `est_source`.\n            We make sure that the weights sum up to 1 along dim `dim`.\n            If `src_weights` is None, compute them based on relative power.\n        dim (int): Axis which contains the sources in `est_sources`.\n\n    Returns\n        torch.Tensor with same shape as `est_sources`, after applying mixture\n        consistency.\n\n    Examples\n        >>> # Works on waveforms\n        >>> mix = torch.randn(10, 16000)\n        >>> est_sources = torch.randn(10, 2, 16000)\n        >>> new_est_sources = mixture_consistency(mix, est_sources, dim=1)\n        >>> # Also works on spectrograms\n        >>> mix = torch.randn(10, 514, 400)\n        >>> est_sources = torch.randn(10, 2, 514, 400)\n        >>> new_est_sources = mixture_consistency(mix, est_sources, dim=1)\n\n    .. note::\n        This method can be used only in 'complete' separation tasks, otherwise\n        the residual error will contain unwanted sources. For example, this\n        won't work with the task `\"sep_noisy\"` from WHAM.\n\n    References\n        Scott Wisdom et al. \"Differentiable consistency constraints for improved\n        deep speech enhancement\", ICASSP 2019.\n    \"\"\"", "\n", "# If the source weights are not specified, the weights are the relative", "\n", "# power of each source to the sum. w_i = P_i / (P_all), P for power.", "\n", "if", "src_weights", "is", "None", ":", "\n", "        ", "all_dims", ":", "List", "[", "int", "]", "=", "torch", ".", "arange", "(", "est_sources", ".", "ndim", ")", ".", "tolist", "(", ")", "\n", "all_dims", ".", "pop", "(", "dim", ")", "# Remove source axis", "\n", "all_dims", ".", "pop", "(", "0", ")", "# Remove batch axis", "\n", "src_weights", "=", "torch", ".", "mean", "(", "est_sources", "**", "2", ",", "dim", "=", "all_dims", ",", "keepdim", "=", "True", ")", "\n", "# Make sure that the weights sum up to 1", "\n", "", "norm_weights", "=", "torch", ".", "sum", "(", "src_weights", ",", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "+", "1e-8", "\n", "src_weights", "=", "src_weights", "/", "norm_weights", "\n", "\n", "# Compute residual mix - sum(est_sources)", "\n", "if", "mixture", ".", "ndim", "==", "est_sources", ".", "ndim", "-", "1", ":", "\n", "# mixture (batch, *), est_sources (batch, n_src, *)", "\n", "        ", "residual", "=", "(", "mixture", "-", "est_sources", ".", "sum", "(", "dim", "=", "dim", ")", ")", ".", "unsqueeze", "(", "dim", ")", "\n", "", "elif", "mixture", ".", "ndim", "==", "est_sources", ".", "ndim", ":", "\n", "# mixture (batch, 1, *), est_sources (batch, n_src, *)", "\n", "        ", "residual", "=", "mixture", "-", "est_sources", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "n", ",", "m", "=", "est_sources", ".", "ndim", ",", "mixture", ".", "ndim", "\n", "raise", "RuntimeError", "(", "\n", "f\"The size of the mixture tensor should match the \"", "\n", "f\"size of the est_sources tensor. Expected mixture\"", "\n", "f\"tensor to have {n} or {n-1} dimension, found {m}.\"", "\n", ")", "\n", "# Compute remove", "\n", "", "new_sources", "=", "est_sources", "+", "src_weights", "*", "residual", "\n", "return", "new_sources", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.vad_test.test_ebased_vad": [[5, 13], ["torch.abs", "asteroid.dsp.vad.ebased_vad", "isinstance", "asteroid.dsp.vad.ebased_vad", "torch.randn"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.vad.ebased_vad", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.vad.ebased_vad"], ["def", "test_ebased_vad", "(", ")", ":", "\n", "    ", "mag_spec", "=", "torch", ".", "abs", "(", "torch", ".", "randn", "(", "10", ",", "2", ",", "65", ",", "16", ")", ")", "# Need positive inputs", "\n", "batch_src_mask", "=", "ebased_vad", "(", "mag_spec", ")", "\n", "\n", "assert", "isinstance", "(", "batch_src_mask", ",", "torch", ".", "BoolTensor", ")", "\n", "batch_1_mask", "=", "ebased_vad", "(", "mag_spec", "[", ":", ",", "0", "]", ")", "\n", "# Assert independence of VAD output", "\n", "assert", "(", "batch_src_mask", "[", ":", ",", "0", "]", "==", "batch_1_mask", ")", ".", "all", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.deltas_tests.test_delta": [[7, 12], ["pytest.mark.parametrize", "torch.randn", "asteroid.dsp.deltas.compute_delta"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.deltas.compute_delta"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"dim\"", ",", "[", "1", ",", "2", ",", "-", "1", ",", "-", "2", "]", ")", "\n", "def", "test_delta", "(", "dim", ")", ":", "\n", "    ", "phase", "=", "torch", ".", "randn", "(", "2", ",", "257", ",", "100", ")", "\n", "delta_phase", "=", "compute_delta", "(", "phase", ",", "dim", "=", "dim", ")", "\n", "assert", "phase", ".", "shape", "==", "delta_phase", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.deltas_tests.test_concat_deltas": [[14, 23], ["pytest.mark.parametrize", "pytest.mark.parametrize", "torch.randn", "asteroid.dsp.deltas.concat_deltas", "list", "list"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.deltas.concat_deltas"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"dim\"", ",", "[", "1", ",", "2", ",", "-", "1", ",", "-", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"order\"", ",", "[", "1", ",", "2", "]", ")", "\n", "def", "test_concat_deltas", "(", "dim", ",", "order", ")", ":", "\n", "    ", "phase_shape", "=", "[", "2", ",", "257", ",", "100", "]", "\n", "phase", "=", "torch", ".", "randn", "(", "*", "phase_shape", ")", "\n", "cat_deltas", "=", "concat_deltas", "(", "phase", ",", "order", "=", "order", ",", "dim", "=", "dim", ")", "\n", "out_shape", "=", "list", "(", "phase_shape", ")", "\n", "out_shape", "[", "dim", "]", "=", "phase_shape", "[", "dim", "]", "*", "(", "1", "+", "order", ")", "\n", "assert", "out_shape", "==", "list", "(", "cat_deltas", ".", "shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add_test.test_overlap_add": [[8, 20], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.randn().reshape", "asteroid.dsp.overlap_add.LambdaOverlapAdd", "asteroid.dsp.overlap_add.LambdaOverlapAdd.", "torch.testing.assert_allclose", "x.unsqueeze().repeat", "torch.randn().reshape.repeat", "torch.randn", "x.unsqueeze"], "function", ["None"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"length\"", ",", "[", "1390", ",", "8372", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "1", ",", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"window\"", ",", "[", "\"hanning\"", ",", "None", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"window_size\"", ",", "[", "128", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"hop_size\"", ",", "[", "64", "]", ")", "\n", "def", "test_overlap_add", "(", "length", ",", "batch_size", ",", "n_src", ",", "window", ",", "window_size", ",", "hop_size", ")", ":", "\n", "    ", "mix", "=", "torch", ".", "randn", "(", "(", "batch_size", ",", "length", ")", ")", ".", "reshape", "(", "batch_size", ",", "1", ",", "-", "1", ")", "\n", "nnet", "=", "lambda", "x", ":", "x", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "n_src", ",", "1", ")", "\n", "oladd", "=", "LambdaOverlapAdd", "(", "nnet", ",", "n_src", ",", "window_size", ",", "hop_size", ",", "window", ")", "\n", "oladded", "=", "oladd", "(", "mix", ")", "\n", "assert_allclose", "(", "mix", ".", "repeat", "(", "1", ",", "n_src", ",", "1", ")", ",", "oladded", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.spatial_test.test_xcorr": [[7, 25], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.rand", "torch.rand", "asteroid.dsp.spatial.xcorr", "range", "range", "numpy.correlate", "numpy.testing.assert_array_almost_equal", "target[].numpy", "ref[].numpy", "result[].numpy", "len"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.spatial.xcorr"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"seq_len_input\"", ",", "[", "1390", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"seq_len_ref\"", ",", "[", "1390", ",", "1290", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_mics_input\"", ",", "[", "1", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_mics_ref\"", ",", "[", "1", ",", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"normalized\"", ",", "[", "False", ",", "True", "]", ")", "\n", "def", "test_xcorr", "(", "seq_len_input", ",", "seq_len_ref", ",", "batch_size", ",", "n_mics_input", ",", "n_mics_ref", ",", "normalized", ")", ":", "\n", "    ", "target", "=", "torch", ".", "rand", "(", "(", "batch_size", ",", "n_mics_input", ",", "seq_len_input", ")", ")", "\n", "ref", "=", "torch", ".", "rand", "(", "(", "batch_size", ",", "n_mics_ref", ",", "seq_len_ref", ")", ")", "\n", "result", "=", "xcorr", "(", "target", ",", "ref", ",", "normalized", ")", "\n", "assert", "result", ".", "shape", "[", "-", "1", "]", "==", "(", "seq_len_input", "-", "seq_len_ref", ")", "+", "1", "\n", "\n", "if", "normalized", "==", "False", ":", "\n", "        ", "for", "b", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "for", "m", "in", "range", "(", "n_mics_input", ")", ":", "\n", "                ", "npy_result", "=", "np", ".", "correlate", "(", "target", "[", "b", ",", "m", "]", ".", "numpy", "(", ")", ",", "ref", "[", "b", ",", "m", "]", ".", "numpy", "(", ")", ")", "\n", "np", ".", "testing", ".", "assert_array_almost_equal", "(", "\n", "result", "[", "b", ",", "m", ",", ":", "len", "(", "npy_result", ")", "]", ".", "numpy", "(", ")", ",", "npy_result", ",", "decimal", "=", "2", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.consistency_test.test_consistency_noweight": [[8, 17], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.randn", "torch.randn", "asteroid.dsp.consistency.mixture_consistency", "torch.testing.assert_allclose", "asteroid.dsp.consistency.mixture_consistency.sum"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.consistency.mixture_consistency"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"mix_shape\"", ",", "[", "[", "2", ",", "1600", "]", ",", "[", "2", ",", "130", ",", "10", "]", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"dim\"", ",", "[", "1", ",", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "def", "test_consistency_noweight", "(", "mix_shape", ",", "dim", ",", "n_src", ")", ":", "\n", "    ", "mix", "=", "torch", ".", "randn", "(", "mix_shape", ")", "\n", "est_shape", "=", "mix_shape", "[", ":", "dim", "]", "+", "[", "n_src", "]", "+", "mix_shape", "[", "dim", ":", "]", "\n", "est_sources", "=", "torch", ".", "randn", "(", "est_shape", ")", "\n", "consistent_est_sources", "=", "mixture_consistency", "(", "mix", ",", "est_sources", ",", "dim", "=", "dim", ")", "\n", "assert_allclose", "(", "mix", ",", "consistent_est_sources", ".", "sum", "(", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.consistency_test.test_consistency_withweight": [[19, 34], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.randn", "torch.randn", "torch.softmax", "asteroid.dsp.consistency.mixture_consistency", "torch.testing.assert_allclose", "torch.randn", "asteroid.dsp.consistency.mixture_consistency.sum", "range", "len"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.consistency.mixture_consistency"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"mix_shape\"", ",", "[", "[", "2", ",", "1600", "]", ",", "[", "2", ",", "130", ",", "10", "]", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"dim\"", ",", "[", "1", ",", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "def", "test_consistency_withweight", "(", "mix_shape", ",", "dim", ",", "n_src", ")", ":", "\n", "    ", "mix", "=", "torch", ".", "randn", "(", "mix_shape", ")", "\n", "est_shape", "=", "mix_shape", "[", ":", "dim", "]", "+", "[", "n_src", "]", "+", "mix_shape", "[", "dim", ":", "]", "\n", "est_sources", "=", "torch", ".", "randn", "(", "est_shape", ")", "\n", "# Create source weights : should have the same number of dims as", "\n", "# est_sources with ones out of batch and n_src dims.", "\n", "ones", "=", "[", "1", "for", "_", "in", "range", "(", "len", "(", "mix_shape", ")", "-", "1", ")", "]", "\n", "src_weights_shape", "=", "mix_shape", "[", ":", "1", "]", "+", "ones", "[", ":", "dim", "-", "1", "]", "+", "[", "n_src", "]", "+", "ones", "[", "dim", "-", "1", ":", "]", "\n", "src_weights", "=", "torch", ".", "softmax", "(", "torch", ".", "randn", "(", "src_weights_shape", ")", ",", "dim", "=", "dim", ")", "\n", "# Apply mixture consitency", "\n", "consistent_est_sources", "=", "mixture_consistency", "(", "mix", ",", "est_sources", ",", "src_weights", "=", "src_weights", ",", "dim", "=", "dim", ")", "\n", "assert_allclose", "(", "mix", ",", "consistent_est_sources", ".", "sum", "(", "dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.consistency_test.test_consistency_raise": [[36, 41], ["torch.randn", "torch.randn", "pytest.raises", "asteroid.dsp.consistency.mixture_consistency"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.consistency.mixture_consistency"], ["", "def", "test_consistency_raise", "(", ")", ":", "\n", "    ", "mix", "=", "torch", ".", "randn", "(", "10", ",", "1", ",", "1", ",", "160", ")", "\n", "est", "=", "torch", ".", "randn", "(", "10", ",", "2", ",", "160", ")", "\n", "with", "pytest", ".", "raises", "(", "RuntimeError", ")", ":", "\n", "        ", "mixture_consistency", "(", "mix", ",", "est", ",", "dim", "=", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test._default_beamformer_test": [[24, 42], ["pytest.mark.skipif", "asteroid.dsp.beamforming.SCM", "torch.randn", "torch.randn", "stft", "stft", "stft", "asteroid.dsp.beamforming.SCM.", "asteroid.dsp.beamforming.SCM.", "beamformer.forward", "istft"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.Model.forward", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft"], ["@", "pytest", ".", "mark", ".", "skipif", "(", "not", "torch_has_complex_support", ",", "\"No complex support \"", ")", "\n", "def", "_default_beamformer_test", "(", "beamformer", ":", "Beamformer", ",", "batch_size", "=", "2", ",", "n_mics", "=", "4", ",", "**", "forward_kwargs", ")", ":", "\n", "    ", "scm", "=", "SCM", "(", ")", "\n", "\n", "speech", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_mics", ",", "16000", "*", "6", ")", "\n", "noise", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_mics", ",", "16000", "*", "6", ")", "\n", "mix", "=", "speech", "+", "noise", "\n", "# GeV Beamforming", "\n", "mix_stft", "=", "stft", "(", "mix", ")", "\n", "speech_stft", "=", "stft", "(", "speech", ")", "\n", "noise_stft", "=", "stft", "(", "noise", ")", "\n", "sigma_ss", "=", "scm", "(", "speech_stft", ")", "\n", "sigma_nn", "=", "scm", "(", "noise_stft", ")", "\n", "\n", "Ys_gev", "=", "beamformer", ".", "forward", "(", "\n", "mix", "=", "mix_stft", ",", "target_scm", "=", "sigma_ss", ",", "noise_scm", "=", "sigma_nn", ",", "**", "forward_kwargs", "\n", ")", "\n", "ys_gev", "=", "istft", "(", "Ys_gev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test.test_gev": [[44, 49], ["pytest.mark.skipif", "pytest.mark.parametrize", "pytest.mark.parametrize", "beamforming_test._default_beamformer_test", "asteroid.dsp.beamforming.GEVBeamformer"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test._default_beamformer_test"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "not", "torch_has_complex_support", ",", "reason", "=", "\"No complex support \"", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_mics\"", ",", "[", "2", ",", "3", ",", "4", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", "]", ")", "\n", "def", "test_gev", "(", "n_mics", ",", "batch_size", ")", ":", "\n", "    ", "_default_beamformer_test", "(", "GEVBeamformer", "(", ")", ",", "n_mics", "=", "n_mics", ",", "batch_size", "=", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test.test_mvdr": [[51, 57], ["pytest.mark.skipif", "pytest.mark.parametrize", "pytest.mark.parametrize", "beamforming_test._default_beamformer_test", "beamforming_test._default_beamformer_test", "asteroid.dsp.beamforming.RTFMVDRBeamformer", "asteroid.dsp.beamforming.SoudenMVDRBeamformer"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test._default_beamformer_test", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test._default_beamformer_test"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "not", "torch_has_complex_support", ",", "reason", "=", "\"No complex support \"", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_mics\"", ",", "[", "2", ",", "3", ",", "4", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", "]", ")", "\n", "def", "test_mvdr", "(", "n_mics", ",", "batch_size", ")", ":", "\n", "    ", "_default_beamformer_test", "(", "RTFMVDRBeamformer", "(", ")", ",", "n_mics", "=", "n_mics", ",", "batch_size", "=", "batch_size", ")", "\n", "_default_beamformer_test", "(", "SoudenMVDRBeamformer", "(", ")", ",", "n_mics", "=", "n_mics", ",", "batch_size", "=", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test.test_mwf": [[59, 65], ["pytest.mark.skipif", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "beamforming_test._default_beamformer_test", "asteroid.dsp.beamforming.SDWMWFBeamformer"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test._default_beamformer_test"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "not", "torch_has_complex_support", ",", "reason", "=", "\"No complex support \"", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_mics\"", ",", "[", "2", ",", "3", ",", "4", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"mu\"", ",", "[", "1.0", ",", "2.0", ",", "0", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", "]", ")", "\n", "def", "test_mwf", "(", "n_mics", ",", "mu", ",", "batch_size", ")", ":", "\n", "    ", "_default_beamformer_test", "(", "SDWMWFBeamformer", "(", "mu", "=", "mu", ")", ",", "n_mics", "=", "n_mics", ",", "batch_size", "=", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test.test_mwf_indices": [[67, 84], ["pytest.mark.skipif", "pytest.mark.parametrize", "pytest.mark.parametrize", "beamforming_test._default_beamformer_test", "beamforming_test._default_beamformer_test", "beamforming_test._default_beamformer_test", "beamforming_test._default_beamformer_test", "asteroid.dsp.beamforming.SDWMWFBeamformer", "asteroid.dsp.beamforming.SDWMWFBeamformer", "asteroid.dsp.beamforming.SDWMWFBeamformer", "asteroid.dsp.beamforming.SDWMWFBeamformer", "torch.randint", "torch.randn"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test._default_beamformer_test", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test._default_beamformer_test", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test._default_beamformer_test", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test._default_beamformer_test"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "not", "torch_has_complex_support", ",", "reason", "=", "\"No complex support \"", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_mics\"", ",", "[", "2", ",", "3", ",", "4", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", "]", ")", "\n", "def", "test_mwf_indices", "(", "n_mics", ",", "batch_size", ")", ":", "\n", "    ", "_default_beamformer_test", "(", "SDWMWFBeamformer", "(", ")", ",", "n_mics", "=", "n_mics", ",", "batch_size", "=", "batch_size", ",", "ref_mic", "=", "0", ")", "\n", "_default_beamformer_test", "(", "SDWMWFBeamformer", "(", ")", ",", "n_mics", "=", "n_mics", ",", "batch_size", "=", "batch_size", ",", "ref_mic", "=", "None", ")", "\n", "_default_beamformer_test", "(", "\n", "SDWMWFBeamformer", "(", ")", ",", "\n", "n_mics", "=", "n_mics", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "ref_mic", "=", "torch", ".", "randint", "(", "0", ",", "n_mics", ",", "size", "=", "(", "batch_size", ",", ")", ")", ",", "\n", ")", "\n", "_default_beamformer_test", "(", "\n", "SDWMWFBeamformer", "(", ")", ",", "\n", "n_mics", "=", "n_mics", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "ref_mic", "=", "torch", ".", "randn", "(", "batch_size", ",", "1", ",", "n_mics", ",", "1", ",", "dtype", "=", "torch", ".", "complex64", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test.test_gevd": [[87, 94], ["pytest.mark.skipif", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "beamforming_test._default_beamformer_test", "asteroid.dsp.beamforming.GEVDBeamformer"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test._default_beamformer_test"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "not", "torch_has_complex_support", ",", "reason", "=", "\"No complex support \"", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_mics\"", ",", "[", "2", ",", "3", ",", "4", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"mu\"", ",", "[", "2.0", ",", "1.0", ",", "0.5", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"rank\"", ",", "[", "1", ",", "2", ",", "None", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", "]", ")", "\n", "def", "test_gevd", "(", "n_mics", ",", "mu", ",", "rank", ",", "batch_size", ")", ":", "\n", "    ", "_default_beamformer_test", "(", "GEVDBeamformer", "(", "mu", "=", "mu", ",", "rank", "=", "rank", ")", ",", "n_mics", "=", "n_mics", ",", "batch_size", "=", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming_test.test_stable_cholesky": [[96, 100], ["torch.randn", "torch.mm", "asteroid.dsp.beamforming.stable_cholesky", "torch.mm.t"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.beamforming.stable_cholesky"], ["", "def", "test_stable_cholesky", "(", ")", ":", "\n", "    ", "a", "=", "torch", ".", "randn", "(", "3", ",", "3", ")", "\n", "a", "=", "torch", ".", "mm", "(", "a", ",", "a", ".", "t", "(", ")", ")", "# make symmetric positive-definite", "\n", "stable_cholesky", "(", "a", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.normalization_test.test_normalization": [[5, 13], ["asteroid.dsp.normalization.normalize_estimates", "numpy.max", "numpy.min", "numpy.random.rand", "numpy.random.rand"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.normalization.normalize_estimates"], ["def", "test_normalization", "(", ")", ":", "\n", "\n", "    ", "mix", "=", "(", "np", ".", "random", ".", "rand", "(", "1600", ")", "-", "0.5", ")", "*", "2", "# random [-1,1[", "\n", "est", "=", "(", "np", ".", "random", ".", "rand", "(", "2", ",", "1600", ")", "-", "0.5", ")", "*", "10", "\n", "est_normalized", "=", "normalize_estimates", "(", "est", ",", "mix", ")", "\n", "\n", "assert", "np", ".", "max", "(", "est_normalized", ")", "<", "1", "\n", "assert", "np", ".", "min", "(", "est_normalized", ")", ">=", "-", "1", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.soft_f1.F1_loss.__init__": [[8, 11], ["torch.nn.modules.loss._Loss.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "eps", "=", "1e-10", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.soft_f1.F1_loss.forward": [[12, 22], ["f1.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "estimates", ",", "targets", ")", ":", "\n", "        ", "tp", "=", "(", "targets", "*", "estimates", ")", ".", "sum", "(", ")", "\n", "fp", "=", "(", "(", "1", "-", "targets", ")", "*", "estimates", ")", ".", "sum", "(", ")", "\n", "fn", "=", "(", "targets", "*", "(", "1", "-", "estimates", ")", ")", ".", "sum", "(", ")", "\n", "\n", "precision", "=", "tp", "/", "(", "tp", "+", "fp", "+", "self", ".", "eps", ")", "\n", "recall", "=", "tp", "/", "(", "tp", "+", "fn", "+", "self", ".", "eps", ")", "\n", "\n", "f1", "=", "2", "*", "(", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", "+", "self", ".", "eps", ")", "\n", "return", "1", "-", "f1", ".", "mean", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sdr.PairwiseNegSDR.__init__": [[37, 44], ["torch.nn.modules.loss._Loss.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "sdr_type", ",", "zero_mean", "=", "True", ",", "take_log", "=", "True", ",", "EPS", "=", "1e-8", ")", ":", "\n", "        ", "super", "(", "PairwiseNegSDR", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "sdr_type", "in", "[", "\"snr\"", ",", "\"sisdr\"", ",", "\"sdsdr\"", "]", "\n", "self", ".", "sdr_type", "=", "sdr_type", "\n", "self", ".", "zero_mean", "=", "zero_mean", "\n", "self", ".", "take_log", "=", "take_log", "\n", "self", ".", "EPS", "=", "EPS", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sdr.PairwiseNegSDR.forward": [[45, 82], ["torch.unsqueeze", "torch.unsqueeze", "TypeError", "targets.size", "est_targets.size", "torch.mean", "torch.mean", "torch.sum", "torch.unsqueeze.repeat", "torch.sum", "targets.size", "est_targets.size", "torch.sum", "torch.sum", "torch.log10", "targets.size", "est_targets.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "est_targets", ",", "targets", ")", ":", "\n", "        ", "if", "targets", ".", "size", "(", ")", "!=", "est_targets", ".", "size", "(", ")", "or", "targets", ".", "ndim", "!=", "3", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f\"Inputs must be of shape [batch, n_src, time], got {targets.size()} and {est_targets.size()} instead\"", "\n", ")", "\n", "", "assert", "targets", ".", "size", "(", ")", "==", "est_targets", ".", "size", "(", ")", "\n", "# Step 1. Zero-mean norm", "\n", "if", "self", ".", "zero_mean", ":", "\n", "            ", "mean_source", "=", "torch", ".", "mean", "(", "targets", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "mean_estimate", "=", "torch", ".", "mean", "(", "est_targets", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "targets", "=", "targets", "-", "mean_source", "\n", "est_targets", "=", "est_targets", "-", "mean_estimate", "\n", "# Step 2. Pair-wise SI-SDR. (Reshape to use broadcast)", "\n", "", "s_target", "=", "torch", ".", "unsqueeze", "(", "targets", ",", "dim", "=", "1", ")", "\n", "s_estimate", "=", "torch", ".", "unsqueeze", "(", "est_targets", ",", "dim", "=", "2", ")", "\n", "\n", "if", "self", ".", "sdr_type", "in", "[", "\"sisdr\"", ",", "\"sdsdr\"", "]", ":", "\n", "# [batch, n_src, n_src, 1]", "\n", "            ", "pair_wise_dot", "=", "torch", ".", "sum", "(", "s_estimate", "*", "s_target", ",", "dim", "=", "3", ",", "keepdim", "=", "True", ")", "\n", "# [batch, 1, n_src, 1]", "\n", "s_target_energy", "=", "torch", ".", "sum", "(", "s_target", "**", "2", ",", "dim", "=", "3", ",", "keepdim", "=", "True", ")", "+", "self", ".", "EPS", "\n", "# [batch, n_src, n_src, time]", "\n", "pair_wise_proj", "=", "pair_wise_dot", "*", "s_target", "/", "s_target_energy", "\n", "", "else", ":", "\n", "# [batch, n_src, n_src, time]", "\n", "            ", "pair_wise_proj", "=", "s_target", ".", "repeat", "(", "1", ",", "s_target", ".", "shape", "[", "2", "]", ",", "1", ",", "1", ")", "\n", "", "if", "self", ".", "sdr_type", "in", "[", "\"sdsdr\"", ",", "\"snr\"", "]", ":", "\n", "            ", "e_noise", "=", "s_estimate", "-", "s_target", "\n", "", "else", ":", "\n", "            ", "e_noise", "=", "s_estimate", "-", "pair_wise_proj", "\n", "# [batch, n_src, n_src]", "\n", "", "pair_wise_sdr", "=", "torch", ".", "sum", "(", "pair_wise_proj", "**", "2", ",", "dim", "=", "3", ")", "/", "(", "\n", "torch", ".", "sum", "(", "e_noise", "**", "2", ",", "dim", "=", "3", ")", "+", "self", ".", "EPS", "\n", ")", "\n", "if", "self", ".", "take_log", ":", "\n", "            ", "pair_wise_sdr", "=", "10", "*", "torch", ".", "log10", "(", "pair_wise_sdr", "+", "self", ".", "EPS", ")", "\n", "", "return", "-", "pair_wise_sdr", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sdr.SingleSrcNegSDR.__init__": [[122, 131], ["torch.nn.modules.loss._Loss.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "sdr_type", ",", "zero_mean", "=", "True", ",", "take_log", "=", "True", ",", "reduction", "=", "\"none\"", ",", "EPS", "=", "1e-8", ")", ":", "\n", "        ", "assert", "reduction", "!=", "\"sum\"", ",", "NotImplementedError", "\n", "super", "(", ")", ".", "__init__", "(", "reduction", "=", "reduction", ")", "\n", "\n", "assert", "sdr_type", "in", "[", "\"snr\"", ",", "\"sisdr\"", ",", "\"sdsdr\"", "]", "\n", "self", ".", "sdr_type", "=", "sdr_type", "\n", "self", ".", "zero_mean", "=", "zero_mean", "\n", "self", ".", "take_log", "=", "take_log", "\n", "self", ".", "EPS", "=", "1e-8", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sdr.SingleSrcNegSDR.forward": [[132, 164], ["TypeError", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "losses.mean", "target.size", "est_target.size", "torch.sum", "torch.sum", "torch.log10", "target.size", "est_target.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "est_target", ",", "target", ")", ":", "\n", "        ", "if", "target", ".", "size", "(", ")", "!=", "est_target", ".", "size", "(", ")", "or", "target", ".", "ndim", "!=", "2", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f\"Inputs must be of shape [batch, time], got {target.size()} and {est_target.size()} instead\"", "\n", ")", "\n", "# Step 1. Zero-mean norm", "\n", "", "if", "self", ".", "zero_mean", ":", "\n", "            ", "mean_source", "=", "torch", ".", "mean", "(", "target", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "mean_estimate", "=", "torch", ".", "mean", "(", "est_target", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "target", "=", "target", "-", "mean_source", "\n", "est_target", "=", "est_target", "-", "mean_estimate", "\n", "# Step 2. Pair-wise SI-SDR.", "\n", "", "if", "self", ".", "sdr_type", "in", "[", "\"sisdr\"", ",", "\"sdsdr\"", "]", ":", "\n", "# [batch, 1]", "\n", "            ", "dot", "=", "torch", ".", "sum", "(", "est_target", "*", "target", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "# [batch, 1]", "\n", "s_target_energy", "=", "torch", ".", "sum", "(", "target", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "self", ".", "EPS", "\n", "# [batch, time]", "\n", "scaled_target", "=", "dot", "*", "target", "/", "s_target_energy", "\n", "", "else", ":", "\n", "# [batch, time]", "\n", "            ", "scaled_target", "=", "target", "\n", "", "if", "self", ".", "sdr_type", "in", "[", "\"sdsdr\"", ",", "\"snr\"", "]", ":", "\n", "            ", "e_noise", "=", "est_target", "-", "target", "\n", "", "else", ":", "\n", "            ", "e_noise", "=", "est_target", "-", "scaled_target", "\n", "# [batch]", "\n", "", "losses", "=", "torch", ".", "sum", "(", "scaled_target", "**", "2", ",", "dim", "=", "1", ")", "/", "(", "torch", ".", "sum", "(", "e_noise", "**", "2", ",", "dim", "=", "1", ")", "+", "self", ".", "EPS", ")", "\n", "if", "self", ".", "take_log", ":", "\n", "            ", "losses", "=", "10", "*", "torch", ".", "log10", "(", "losses", "+", "self", ".", "EPS", ")", "\n", "", "losses", "=", "losses", ".", "mean", "(", ")", "if", "self", ".", "reduction", "==", "\"mean\"", "else", "losses", "\n", "return", "-", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sdr.MultiSrcNegSDR.__init__": [[201, 209], ["torch.nn.modules.loss._Loss.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "sdr_type", ",", "zero_mean", "=", "True", ",", "take_log", "=", "True", ",", "EPS", "=", "1e-8", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "sdr_type", "in", "[", "\"snr\"", ",", "\"sisdr\"", ",", "\"sdsdr\"", "]", "\n", "self", ".", "sdr_type", "=", "sdr_type", "\n", "self", ".", "zero_mean", "=", "zero_mean", "\n", "self", ".", "take_log", "=", "take_log", "\n", "self", ".", "EPS", "=", "1e-8", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sdr.MultiSrcNegSDR.forward": [[210, 242], ["TypeError", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.mean", "targets.size", "est_targets.size", "torch.sum", "torch.sum", "torch.log10", "targets.size", "est_targets.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "est_targets", ",", "targets", ")", ":", "\n", "        ", "if", "targets", ".", "size", "(", ")", "!=", "est_targets", ".", "size", "(", ")", "or", "targets", ".", "ndim", "!=", "3", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f\"Inputs must be of shape [batch, n_src, time], got {targets.size()} and {est_targets.size()} instead\"", "\n", ")", "\n", "", "if", "self", ".", "zero_mean", ":", "\n", "            ", "mean_source", "=", "torch", ".", "mean", "(", "targets", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "mean_estimate", "=", "torch", ".", "mean", "(", "est_targets", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "targets", "=", "targets", "-", "mean_source", "\n", "est_targets", "=", "est_targets", "-", "mean_estimate", "\n", "# Step 2. Pair-wise SI-SDR.", "\n", "", "if", "self", ".", "sdr_type", "in", "[", "\"sisdr\"", ",", "\"sdsdr\"", "]", ":", "\n", "# [batch, n_src]", "\n", "            ", "pair_wise_dot", "=", "torch", ".", "sum", "(", "est_targets", "*", "targets", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "# [batch, n_src]", "\n", "s_target_energy", "=", "torch", ".", "sum", "(", "targets", "**", "2", ",", "dim", "=", "2", ",", "keepdim", "=", "True", ")", "+", "self", ".", "EPS", "\n", "# [batch, n_src, time]", "\n", "scaled_targets", "=", "pair_wise_dot", "*", "targets", "/", "s_target_energy", "\n", "", "else", ":", "\n", "# [batch, n_src, time]", "\n", "            ", "scaled_targets", "=", "targets", "\n", "", "if", "self", ".", "sdr_type", "in", "[", "\"sdsdr\"", ",", "\"snr\"", "]", ":", "\n", "            ", "e_noise", "=", "est_targets", "-", "targets", "\n", "", "else", ":", "\n", "            ", "e_noise", "=", "est_targets", "-", "scaled_targets", "\n", "# [batch, n_src]", "\n", "", "pair_wise_sdr", "=", "torch", ".", "sum", "(", "scaled_targets", "**", "2", ",", "dim", "=", "2", ")", "/", "(", "\n", "torch", ".", "sum", "(", "e_noise", "**", "2", ",", "dim", "=", "2", ")", "+", "self", ".", "EPS", "\n", ")", "\n", "if", "self", ".", "take_log", ":", "\n", "            ", "pair_wise_sdr", "=", "10", "*", "torch", ".", "log10", "(", "pair_wise_sdr", "+", "self", ".", "EPS", ")", "\n", "", "return", "-", "torch", ".", "mean", "(", "pair_wise_sdr", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.__init__": [[64, 72], ["torch.nn.Module.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "loss_func", ",", "pit_from", "=", "\"pw_mtx\"", ",", "perm_reduce", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_func", "=", "loss_func", "\n", "self", ".", "pit_from", "=", "pit_from", "\n", "self", ".", "perm_reduce", "=", "perm_reduce", "\n", "if", "self", ".", "pit_from", "not", "in", "[", "\"pw_mtx\"", ",", "\"pw_pt\"", ",", "\"perm_avg\"", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Unsupported loss function type for now. Expected\"", "\n", "\"one of [`pw_mtx`, `pw_pt`, `perm_avg`]\"", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.forward": [[75, 133], ["pit_wrapper.PITLossWrapper.find_best_perm", "torch.mean", "pit_wrapper.PITLossWrapper.reorder_source", "pit_wrapper.PITLossWrapper.loss_func", "dict", "pit_wrapper.PITLossWrapper.get_pw_losses", "pit_wrapper.PITLossWrapper.best_perm_from_perm_avg_loss", "torch.mean", "pit_wrapper.PITLossWrapper.reorder_source"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.find_best_perm", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.reorder_source", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.get_pw_losses", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.best_perm_from_perm_avg_loss", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.reorder_source"], ["", "", "def", "forward", "(", "self", ",", "est_targets", ",", "targets", ",", "return_est", "=", "False", ",", "reduce_kwargs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Find the best permutation and return the loss.\n\n        Args:\n            est_targets: torch.Tensor. Expected shape $(batch, nsrc, ...)$.\n                The batch of target estimates.\n            targets: torch.Tensor. Expected shape $(batch, nsrc, ...)$.\n                The batch of training targets\n            return_est: Boolean. Whether to return the reordered targets\n                estimates (To compute metrics or to save example).\n            reduce_kwargs (dict or None): kwargs that will be passed to the\n                pairwise losses reduce function (`perm_reduce`).\n            **kwargs: additional keyword argument that will be passed to the\n                loss function.\n\n        Returns:\n            - Best permutation loss for each batch sample, average over\n              the batch.\n            - The reordered targets estimates if ``return_est`` is True.\n              :class:`torch.Tensor` of shape $(batch, nsrc, ...)$.\n        \"\"\"", "\n", "n_src", "=", "targets", ".", "shape", "[", "1", "]", "\n", "assert", "n_src", "<", "10", ",", "f\"Expected source axis along dim 1, found {n_src}\"", "\n", "if", "self", ".", "pit_from", "==", "\"pw_mtx\"", ":", "\n", "# Loss function already returns pairwise losses", "\n", "            ", "pw_losses", "=", "self", ".", "loss_func", "(", "est_targets", ",", "targets", ",", "**", "kwargs", ")", "\n", "", "elif", "self", ".", "pit_from", "==", "\"pw_pt\"", ":", "\n", "# Compute pairwise losses with a for loop.", "\n", "            ", "pw_losses", "=", "self", ".", "get_pw_losses", "(", "self", ".", "loss_func", ",", "est_targets", ",", "targets", ",", "**", "kwargs", ")", "\n", "", "elif", "self", ".", "pit_from", "==", "\"perm_avg\"", ":", "\n", "# Cannot get pairwise losses from this type of loss.", "\n", "# Find best permutation directly.", "\n", "            ", "min_loss", ",", "batch_indices", "=", "self", ".", "best_perm_from_perm_avg_loss", "(", "\n", "self", ".", "loss_func", ",", "est_targets", ",", "targets", ",", "**", "kwargs", "\n", ")", "\n", "# Take the mean over the batch", "\n", "mean_loss", "=", "torch", ".", "mean", "(", "min_loss", ")", "\n", "if", "not", "return_est", ":", "\n", "                ", "return", "mean_loss", "\n", "", "reordered", "=", "self", ".", "reorder_source", "(", "est_targets", ",", "batch_indices", ")", "\n", "return", "mean_loss", ",", "reordered", "\n", "", "else", ":", "\n", "            ", "return", "\n", "\n", "", "assert", "pw_losses", ".", "ndim", "==", "3", ",", "(", "\n", "\"Something went wrong with the loss \"", "\"function, please read the docs.\"", "\n", ")", "\n", "assert", "pw_losses", ".", "shape", "[", "0", "]", "==", "targets", ".", "shape", "[", "0", "]", ",", "\"PIT loss needs same batch dim as input\"", "\n", "\n", "reduce_kwargs", "=", "reduce_kwargs", "if", "reduce_kwargs", "is", "not", "None", "else", "dict", "(", ")", "\n", "min_loss", ",", "batch_indices", "=", "self", ".", "find_best_perm", "(", "\n", "pw_losses", ",", "perm_reduce", "=", "self", ".", "perm_reduce", ",", "**", "reduce_kwargs", "\n", ")", "\n", "mean_loss", "=", "torch", ".", "mean", "(", "min_loss", ")", "\n", "if", "not", "return_est", ":", "\n", "            ", "return", "mean_loss", "\n", "", "reordered", "=", "self", ".", "reorder_source", "(", "est_targets", ",", "batch_indices", ")", "\n", "return", "mean_loss", ",", "reordered", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.get_pw_losses": [[134, 163], ["targets.new_empty", "enumerate", "est_targets.transpose", "enumerate", "targets.transpose", "loss_func"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_pw_losses", "(", "loss_func", ",", "est_targets", ",", "targets", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Get pair-wise losses between the training targets and its estimate\n        for a given loss function.\n\n        Args:\n            loss_func: function with signature (est_targets, targets, **kwargs)\n                The loss function to get pair-wise losses from.\n            est_targets: torch.Tensor. Expected shape $(batch, nsrc, ...)$.\n                The batch of target estimates.\n            targets: torch.Tensor. Expected shape $(batch, nsrc, ...)$.\n                The batch of training targets.\n            **kwargs: additional keyword argument that will be passed to the\n                loss function.\n\n        Returns:\n            torch.Tensor or size $(batch, nsrc, nsrc)$, losses computed for\n            all permutations of the targets and est_targets.\n\n        This function can be called on a loss function which returns a tensor\n        of size :math:`(batch)`. There are more efficient ways to compute pair-wise\n        losses using broadcasting.\n        \"\"\"", "\n", "batch_size", ",", "n_src", ",", "*", "_", "=", "targets", ".", "shape", "\n", "pair_wise_losses", "=", "targets", ".", "new_empty", "(", "batch_size", ",", "n_src", ",", "n_src", ")", "\n", "for", "est_idx", ",", "est_src", "in", "enumerate", "(", "est_targets", ".", "transpose", "(", "0", ",", "1", ")", ")", ":", "\n", "            ", "for", "target_idx", ",", "target_src", "in", "enumerate", "(", "targets", ".", "transpose", "(", "0", ",", "1", ")", ")", ":", "\n", "                ", "pair_wise_losses", "[", ":", ",", "est_idx", ",", "target_idx", "]", "=", "loss_func", "(", "est_src", ",", "target_src", ",", "**", "kwargs", ")", "\n", "", "", "return", "pair_wise_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.best_perm_from_perm_avg_loss": [[164, 195], ["torch.tensor", "torch.stack", "torch.min", "torch.stack", "list", "itertools.permutations", "loss_func", "range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "best_perm_from_perm_avg_loss", "(", "loss_func", ",", "est_targets", ",", "targets", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Find best permutation from loss function with source axis.\n\n        Args:\n            loss_func: function with signature $(est_targets, targets, **kwargs)$\n                The loss function batch losses from.\n            est_targets: torch.Tensor. Expected shape $(batch, nsrc, *)$.\n                The batch of target estimates.\n            targets: torch.Tensor. Expected shape $(batch, nsrc, *)$.\n                The batch of training targets.\n            **kwargs: additional keyword argument that will be passed to the\n                loss function.\n\n        Returns:\n            - :class:`torch.Tensor`:\n                The loss corresponding to the best permutation of size $(batch,)$.\n\n            - :class:`torch.Tensor`:\n                The indices of the best permutations.\n        \"\"\"", "\n", "n_src", "=", "targets", ".", "shape", "[", "1", "]", "\n", "perms", "=", "torch", ".", "tensor", "(", "list", "(", "permutations", "(", "range", "(", "n_src", ")", ")", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "loss_set", "=", "torch", ".", "stack", "(", "\n", "[", "loss_func", "(", "est_targets", "[", ":", ",", "perm", "]", ",", "targets", ",", "**", "kwargs", ")", "for", "perm", "in", "perms", "]", ",", "dim", "=", "1", "\n", ")", "\n", "# Indexes and values of min losses for each batch element", "\n", "min_loss", ",", "min_loss_idx", "=", "torch", ".", "min", "(", "loss_set", ",", "dim", "=", "1", ")", "\n", "# Permutation indices for each batch.", "\n", "batch_indices", "=", "torch", ".", "stack", "(", "[", "perms", "[", "m", "]", "for", "m", "in", "min_loss_idx", "]", ",", "dim", "=", "0", ")", "\n", "return", "min_loss", ",", "batch_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.find_best_perm": [[196, 228], ["pit_wrapper.PITLossWrapper.find_best_perm_factorial", "pit_wrapper.PITLossWrapper.find_best_perm_hungarian"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.find_best_perm_factorial", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.find_best_perm_hungarian"], ["", "@", "staticmethod", "\n", "def", "find_best_perm", "(", "pair_wise_losses", ",", "perm_reduce", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Find the best permutation, given the pair-wise losses.\n\n        Dispatch between factorial method if number of sources is small (<3)\n        and hungarian method for more sources. If ``perm_reduce`` is not None,\n        the factorial method is always used.\n\n        Args:\n            pair_wise_losses (:class:`torch.Tensor`):\n                Tensor of shape :math:`(batch, n\\_src, n\\_src)`. Pairwise losses.\n            perm_reduce (Callable): torch function to reduce permutation losses.\n                Defaults to None (equivalent to mean). Signature of the func\n                (pwl_set, **kwargs) : :math:`(B, n\\_src!, n\\_src) -> (B, n\\_src!)`\n            **kwargs: additional keyword argument that will be passed to the\n                permutation reduce function.\n\n        Returns:\n            - :class:`torch.Tensor`:\n              The loss corresponding to the best permutation of size $(batch,)$.\n\n            - :class:`torch.Tensor`:\n              The indices of the best permutations.\n        \"\"\"", "\n", "n_src", "=", "pair_wise_losses", ".", "shape", "[", "-", "1", "]", "\n", "if", "perm_reduce", "is", "not", "None", "or", "n_src", "<=", "3", ":", "\n", "            ", "min_loss", ",", "batch_indices", "=", "PITLossWrapper", ".", "find_best_perm_factorial", "(", "\n", "pair_wise_losses", ",", "perm_reduce", "=", "perm_reduce", ",", "**", "kwargs", "\n", ")", "\n", "", "else", ":", "\n", "            ", "min_loss", ",", "batch_indices", "=", "PITLossWrapper", ".", "find_best_perm_hungarian", "(", "pair_wise_losses", ")", "\n", "", "return", "min_loss", ",", "batch_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.reorder_source": [[229, 245], ["torch.stack", "torch.index_select", "zip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "reorder_source", "(", "source", ",", "batch_indices", ")", ":", "\n", "        ", "r\"\"\"Reorder sources according to the best permutation.\n\n        Args:\n            source (torch.Tensor): Tensor of shape :math:`(batch, n_src, time)`\n            batch_indices (torch.Tensor): Tensor of shape :math:`(batch, n_src)`.\n                Contains optimal permutation indices for each batch.\n\n        Returns:\n            :class:`torch.Tensor`: Reordered sources.\n        \"\"\"", "\n", "reordered_sources", "=", "torch", ".", "stack", "(", "\n", "[", "torch", ".", "index_select", "(", "s", ",", "0", ",", "b", ")", "for", "s", ",", "b", "in", "zip", "(", "source", ",", "batch_indices", ")", "]", "\n", ")", "\n", "return", "reordered_sources", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.find_best_perm_factorial": [[246, 296], ["pair_wise_losses.transpose", "pair_wise_losses.transpose.new_tensor", "torch.unsqueeze", "torch.min", "torch.stack", "list", "pair_wise_losses.transpose.new_zeros().scatter_", "torch.einsum", "perm_reduce", "itertools.permutations", "range", "pair_wise_losses.transpose.new_zeros", "torch.arange", "torch.unsqueeze.squeeze", "pair_wise_losses.transpose.new_tensor.size"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "find_best_perm_factorial", "(", "pair_wise_losses", ",", "perm_reduce", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Find the best permutation given the pair-wise losses by looping\n        through all the permutations.\n\n        Args:\n            pair_wise_losses (:class:`torch.Tensor`):\n                Tensor of shape :math:`(batch, n_src, n_src)`. Pairwise losses.\n            perm_reduce (Callable): torch function to reduce permutation losses.\n                Defaults to None (equivalent to mean). Signature of the func\n                (pwl_set, **kwargs) : :math:`(B, n\\_src!, n\\_src) -> (B, n\\_src!)`\n            **kwargs: additional keyword argument that will be passed to the\n                permutation reduce function.\n\n        Returns:\n            - :class:`torch.Tensor`:\n              The loss corresponding to the best permutation of size $(batch,)$.\n\n            - :class:`torch.Tensor`:\n              The indices of the best permutations.\n\n        MIT Copyright (c) 2018 Kaituo XU.\n        See `Original code\n        <https://github.com/kaituoxu/Conv-TasNet/blob/master>`__ and `License\n        <https://github.com/kaituoxu/Conv-TasNet/blob/master/LICENSE>`__.\n        \"\"\"", "\n", "n_src", "=", "pair_wise_losses", ".", "shape", "[", "-", "1", "]", "\n", "# After transposition, dim 1 corresp. to sources and dim 2 to estimates", "\n", "pwl", "=", "pair_wise_losses", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "perms", "=", "pwl", ".", "new_tensor", "(", "list", "(", "permutations", "(", "range", "(", "n_src", ")", ")", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "# Column permutation indices", "\n", "idx", "=", "torch", ".", "unsqueeze", "(", "perms", ",", "2", ")", "\n", "# Loss mean of each permutation", "\n", "if", "perm_reduce", "is", "None", ":", "\n", "# one-hot, [n_src!, n_src, n_src]", "\n", "            ", "perms_one_hot", "=", "pwl", ".", "new_zeros", "(", "(", "*", "perms", ".", "size", "(", ")", ",", "n_src", ")", ")", ".", "scatter_", "(", "2", ",", "idx", ",", "1", ")", "\n", "loss_set", "=", "torch", ".", "einsum", "(", "\"bij,pij->bp\"", ",", "[", "pwl", ",", "perms_one_hot", "]", ")", "\n", "loss_set", "/=", "n_src", "\n", "", "else", ":", "\n", "# batch = pwl.shape[0]; n_perm = idx.shape[0]", "\n", "# [batch, n_src!, n_src] : Pairwise losses for each permutation.", "\n", "            ", "pwl_set", "=", "pwl", "[", ":", ",", "torch", ".", "arange", "(", "n_src", ")", ",", "idx", ".", "squeeze", "(", "-", "1", ")", "]", "\n", "# Apply reduce [batch, n_src!, n_src] --> [batch, n_src!]", "\n", "loss_set", "=", "perm_reduce", "(", "pwl_set", ",", "**", "kwargs", ")", "\n", "# Indexes and values of min losses for each batch element", "\n", "", "min_loss", ",", "min_loss_idx", "=", "torch", ".", "min", "(", "loss_set", ",", "dim", "=", "1", ")", "\n", "\n", "# Permutation indices for each batch.", "\n", "batch_indices", "=", "torch", ".", "stack", "(", "[", "perms", "[", "m", "]", "for", "m", "in", "min_loss_idx", "]", ",", "dim", "=", "0", ")", "\n", "return", "min_loss", ",", "batch_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.find_best_perm_hungarian": [[297, 319], ["pair_wise_losses.transpose", "pair_wise_losses.transpose.detach().cpu", "torch.tensor().to", "torch.gather().mean", "pair_wise_losses.transpose.detach", "torch.tensor", "torch.gather", "scipy.optimize.linear_sum_assignment"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "find_best_perm_hungarian", "(", "pair_wise_losses", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Find the best permutation given the pair-wise losses, using the Hungarian algorithm.\n\n        Returns:\n            - :class:`torch.Tensor`:\n              The loss corresponding to the best permutation of size (batch,).\n\n            - :class:`torch.Tensor`:\n              The indices of the best permutations.\n        \"\"\"", "\n", "# After transposition, dim 1 corresp. to sources and dim 2 to estimates", "\n", "pwl", "=", "pair_wise_losses", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "# Just bring the numbers to cpu(), not the graph", "\n", "pwl_copy", "=", "pwl", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "# Loop over batch + row indices are always ordered for square matrices.", "\n", "batch_indices", "=", "torch", ".", "tensor", "(", "[", "linear_sum_assignment", "(", "pwl", ")", "[", "1", "]", "for", "pwl", "in", "pwl_copy", "]", ")", ".", "to", "(", "\n", "pwl", ".", "device", "\n", ")", "\n", "min_loss", "=", "torch", ".", "gather", "(", "pwl", ",", "2", ",", "batch_indices", "[", "...", ",", "None", "]", ")", ".", "mean", "(", "[", "-", "1", ",", "-", "2", "]", ")", "\n", "return", "min_loss", ",", "batch_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITReorder.forward": [[325, 334], ["pit_wrapper.PITLossWrapper.forward"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.Model.forward"], ["def", "forward", "(", "self", ",", "est_targets", ",", "targets", ",", "reduce_kwargs", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "_", ",", "reordered", "=", "super", "(", ")", ".", "forward", "(", "\n", "est_targets", "=", "est_targets", ",", "\n", "targets", "=", "targets", ",", "\n", "return_est", "=", "True", ",", "\n", "reduce_kwargs", "=", "reduce_kwargs", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "return", "reordered", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.cluster.deep_clustering_loss": [[4, 62], ["len", "binary_mask.view.float", "binary_mask.view.to", "torch.zeros", "torch.zeros.scatter_", "torch.einsum", "torch.einsum", "torch.einsum", "tgt_index.unique", "torch.ones", "len", "binary_mask.view.view", "tgt_index.view", "cluster.batch_matrix_norm", "cluster.batch_matrix_norm", "torch.sum", "cluster.batch_matrix_norm"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.cluster.batch_matrix_norm", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.cluster.batch_matrix_norm", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.cluster.batch_matrix_norm"], ["def", "deep_clustering_loss", "(", "embedding", ",", "tgt_index", ",", "binary_mask", "=", "None", ")", ":", "\n", "    ", "r\"\"\"Compute the deep clustering loss defined in [1].\n\n    Args:\n        embedding (torch.Tensor): Estimated embeddings.\n            Expected shape  :math:`(batch, frequency * frame, embedding\\_dim)`.\n        tgt_index (torch.Tensor): Dominating source index in each TF bin.\n            Expected shape: :math:`(batch, frequency, frame)`.\n        binary_mask (torch.Tensor): VAD in TF plane. Bool or Float.\n            See asteroid.dsp.vad.ebased_vad.\n\n    Returns:\n         `torch.Tensor`. Deep clustering loss for every batch sample.\n\n    Examples\n        >>> import torch\n        >>> from asteroid.losses.cluster import deep_clustering_loss\n        >>> spk_cnt = 3\n        >>> embedding = torch.randn(10, 5*400, 20)\n        >>> targets = torch.LongTensor(10, 400, 5).random_(0, spk_cnt)\n        >>> loss = deep_clustering_loss(embedding, targets)\n\n    Reference\n        [1] Zhong-Qiu Wang, Jonathan Le Roux, John R. Hershey\n        \"ALTERNATIVE OBJECTIVE FUNCTIONS FOR DEEP CLUSTERING\"\n\n    .. note::\n        Be careful in viewing the embedding tensors. The target indices\n        ``tgt_index`` are of shape :math:`(batch, freq, frames)`. Even if the embedding\n        is of shape :math:`(batch, freq * frames, emb)`, the underlying view should be\n        :math:`(batch, freq, frames, emb)` and not :math:`(batch, frames, freq, emb)`.\n    \"\"\"", "\n", "spk_cnt", "=", "len", "(", "tgt_index", ".", "unique", "(", ")", ")", "\n", "\n", "batch", ",", "bins", ",", "frames", "=", "tgt_index", ".", "shape", "\n", "if", "binary_mask", "is", "None", ":", "\n", "        ", "binary_mask", "=", "torch", ".", "ones", "(", "batch", ",", "bins", "*", "frames", ",", "1", ")", "\n", "", "binary_mask", "=", "binary_mask", ".", "float", "(", ")", "\n", "if", "len", "(", "binary_mask", ".", "shape", ")", "==", "3", ":", "\n", "        ", "binary_mask", "=", "binary_mask", ".", "view", "(", "batch", ",", "bins", "*", "frames", ",", "1", ")", "\n", "# If boolean mask, make it float.", "\n", "", "binary_mask", "=", "binary_mask", ".", "to", "(", "tgt_index", ".", "device", ")", "\n", "\n", "# Fill in one-hot vector for each TF bin", "\n", "tgt_embedding", "=", "torch", ".", "zeros", "(", "batch", ",", "bins", "*", "frames", ",", "spk_cnt", ",", "device", "=", "tgt_index", ".", "device", ")", "\n", "tgt_embedding", ".", "scatter_", "(", "2", ",", "tgt_index", ".", "view", "(", "batch", ",", "bins", "*", "frames", ",", "1", ")", ",", "1", ")", "\n", "\n", "# Compute VAD-weighted DC loss", "\n", "tgt_embedding", "=", "tgt_embedding", "*", "binary_mask", "\n", "embedding", "=", "embedding", "*", "binary_mask", "\n", "est_proj", "=", "torch", ".", "einsum", "(", "\"ijk,ijl->ikl\"", ",", "embedding", ",", "embedding", ")", "\n", "true_proj", "=", "torch", ".", "einsum", "(", "\"ijk,ijl->ikl\"", ",", "tgt_embedding", ",", "tgt_embedding", ")", "\n", "true_est_proj", "=", "torch", ".", "einsum", "(", "\"ijk,ijl->ikl\"", ",", "embedding", ",", "tgt_embedding", ")", "\n", "# Equation (1) in [1]", "\n", "cost", "=", "batch_matrix_norm", "(", "est_proj", ")", "+", "batch_matrix_norm", "(", "true_proj", ")", "\n", "cost", "=", "cost", "-", "2", "*", "batch_matrix_norm", "(", "true_est_proj", ")", "\n", "# Divide by number of active bins, for each element in batch", "\n", "return", "cost", "/", "torch", ".", "sum", "(", "binary_mask", ",", "dim", "=", "[", "1", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.cluster.batch_matrix_norm": [[64, 76], ["list", "range", "torch.norm"], "function", ["None"], ["", "def", "batch_matrix_norm", "(", "matrix", ",", "norm_order", "=", "2", ")", ":", "\n", "    ", "\"\"\"Normalize a matrix according to `norm_order`\n\n    Args:\n        matrix (torch.Tensor): Expected shape [batch, *]\n        norm_order (int): Norm order.\n\n    Returns:\n        torch.Tensor, normed matrix of shape [batch]\n    \"\"\"", "\n", "keep_batch", "=", "list", "(", "range", "(", "1", ",", "matrix", ".", "ndim", ")", ")", "\n", "return", "torch", ".", "norm", "(", "matrix", ",", "p", "=", "norm_order", ",", "dim", "=", "keep_batch", ")", "**", "norm_order", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper.SinkPITLossWrapper.__init__": [[55, 61], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "loss_func", ",", "n_iter", "=", "200", ",", "hungarian_validation", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_func", "=", "loss_func", "\n", "self", ".", "_beta", "=", "10", "\n", "self", ".", "n_iter", "=", "n_iter", "\n", "self", ".", "hungarian_validation", "=", "hungarian_validation", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper.SinkPITLossWrapper.beta": [[66, 70], ["None"], "methods", ["None"], ["", "@", "beta", ".", "setter", "\n", "def", "beta", "(", "self", ",", "beta", ")", ":", "\n", "        ", "assert", "beta", ">", "0", "\n", "self", ".", "_beta", "=", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper.SinkPITLossWrapper.forward": [[71, 120], ["sinkpit_wrapper.SinkPITLossWrapper.loss_func", "PITLossWrapper.find_best_perm", "torch.mean", "PITLossWrapper.reorder_source", "sinkpit_wrapper.SinkPITLossWrapper.best_softperm_sinkhorn", "torch.mean", "PITLossWrapper.find_best_perm", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.find_best_perm", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.reorder_source", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper.SinkPITLossWrapper.best_softperm_sinkhorn", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.find_best_perm"], ["", "def", "forward", "(", "self", ",", "est_targets", ",", "targets", ",", "return_est", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Evaluate the loss using Sinkhorn's algorithm.\n\n        Args:\n            est_targets: torch.Tensor. Expected shape :math:`(batch, nsrc, ...)`.\n                The batch of target estimates.\n            targets: torch.Tensor. Expected shape :math:`(batch, nsrc, ...)`.\n                The batch of training targets\n            return_est: Boolean. Whether to return the reordered targets\n                estimates (To compute metrics or to save example).\n            **kwargs: additional keyword argument that will be passed to the\n                loss function.\n\n        Returns:\n            - Best permutation loss for each batch sample, average over\n                the batch. torch.Tensor(loss_value)\n            - The reordered targets estimates if return_est is True.\n                torch.Tensor of shape :math:`(batch, nsrc, ...)`.\n        \"\"\"", "\n", "n_src", "=", "targets", ".", "shape", "[", "1", "]", "\n", "assert", "n_src", "<", "100", ",", "f\"Expected source axis along dim 1, found {n_src}\"", "\n", "\n", "# Evaluate the loss using Sinkhorn's iterative algorithm", "\n", "pw_losses", "=", "self", ".", "loss_func", "(", "est_targets", ",", "targets", ",", "**", "kwargs", ")", "\n", "\n", "assert", "pw_losses", ".", "ndim", "==", "3", ",", "(", "\n", "\"Something went wrong with the loss \"", "\"function, please read the docs.\"", "\n", ")", "\n", "assert", "pw_losses", ".", "shape", "[", "0", "]", "==", "targets", ".", "shape", "[", "0", "]", ",", "\"PIT loss needs same batch dim as input\"", "\n", "\n", "if", "not", "return_est", ":", "\n", "            ", "if", "self", ".", "training", "or", "not", "self", ".", "hungarian_validation", ":", "\n", "# Train or sinkhorn validation", "\n", "                ", "min_loss", ",", "soft_perm", "=", "self", ".", "best_softperm_sinkhorn", "(", "\n", "pw_losses", ",", "self", ".", "_beta", ",", "self", ".", "n_iter", "\n", ")", "\n", "mean_loss", "=", "torch", ".", "mean", "(", "min_loss", ")", "\n", "return", "mean_loss", "\n", "", "else", ":", "\n", "# Reorder the output by using the Hungarian algorithm below", "\n", "                ", "min_loss", ",", "batch_indices", "=", "PITLossWrapper", ".", "find_best_perm", "(", "pw_losses", ")", "\n", "mean_loss", "=", "torch", ".", "mean", "(", "min_loss", ")", "\n", "return", "mean_loss", "\n", "", "", "else", ":", "\n", "# Test -> reorder the output by using the Hungarian algorithm below", "\n", "            ", "min_loss", ",", "batch_indices", "=", "PITLossWrapper", ".", "find_best_perm", "(", "pw_losses", ")", "\n", "mean_loss", "=", "torch", ".", "mean", "(", "min_loss", ")", "\n", "reordered", "=", "PITLossWrapper", ".", "reorder_source", "(", "est_targets", ",", "batch_indices", ")", "\n", "return", "mean_loss", ",", "reordered", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper.SinkPITLossWrapper.best_softperm_sinkhorn": [[121, 149], ["pair_wise_losses.transpose", "range", "torch.einsum", "torch.exp", "torch.exp", "torch.logsumexp", "torch.logsumexp"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "best_softperm_sinkhorn", "(", "pair_wise_losses", ",", "beta", "=", "10", ",", "n_iter", "=", "200", ")", ":", "\n", "        ", "r\"\"\"Compute an approximate PIT loss using Sinkhorn's algorithm.\n        See http://arxiv.org/abs/2010.11871\n\n        Args:\n            pair_wise_losses (:class:`torch.Tensor`):\n                Tensor of shape :math:`(batch, n_src, n_src)`. Pairwise losses.\n            beta (float) : Inverse temperature parameter. (default = 10)\n            n_iter (int) : Number of iteration. Even number. (default = 200)\n\n        Returns:\n            - :class:`torch.Tensor`:\n              The loss corresponding to the best permutation of size (batch,).\n\n            - :class:`torch.Tensor`:\n              A soft permutation matrix.\n        \"\"\"", "\n", "C", "=", "pair_wise_losses", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "n_src", "=", "C", ".", "shape", "[", "-", "1", "]", "\n", "# initial values", "\n", "Z", "=", "-", "beta", "*", "C", "\n", "for", "it", "in", "range", "(", "n_iter", "//", "2", ")", ":", "\n", "            ", "Z", "=", "Z", "-", "torch", ".", "logsumexp", "(", "Z", ",", "axis", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "Z", "=", "Z", "-", "torch", ".", "logsumexp", "(", "Z", ",", "axis", "=", "2", ",", "keepdim", "=", "True", ")", "\n", "", "min_loss", "=", "torch", ".", "einsum", "(", "\"bij,bij->b\"", ",", "C", "+", "Z", "/", "beta", ",", "torch", ".", "exp", "(", "Z", ")", ")", "\n", "min_loss", "=", "min_loss", "/", "n_src", "\n", "return", "min_loss", ",", "torch", ".", "exp", "(", "Z", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.stoi.NegSTOILoss.__init__": [[63, 65], ["_NegSTOILoss.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.__init__": [[60, 102], ["torch.Module.__init__", "pmsqe.SingleSrcPMSQE.get_correction_factor", "pmsqe.SingleSrcPMSQE.populate_constants", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "ValueError", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.get_correction_factor", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.populate_constants"], ["def", "__init__", "(", "\n", "self", ",", "\n", "window_name", "=", "\"sqrt_hann\"", ",", "\n", "window_weight", "=", "1.0", ",", "\n", "bark_eq", "=", "True", ",", "\n", "gain_eq", "=", "True", ",", "\n", "sample_rate", "=", "16000", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "window_name", "=", "window_name", "\n", "self", ".", "window_weight", "=", "window_weight", "\n", "self", ".", "bark_eq", "=", "bark_eq", "\n", "self", ".", "gain_eq", "=", "gain_eq", "\n", "\n", "if", "sample_rate", "not", "in", "[", "16000", ",", "8000", "]", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unsupported sample rate {}\"", ".", "format", "(", "sample_rate", ")", ")", "\n", "", "self", ".", "sample_rate", "=", "sample_rate", "\n", "if", "sample_rate", "==", "16000", ":", "\n", "            ", "self", ".", "Sp", "=", "6.910853e-006", "\n", "self", ".", "Sl", "=", "1.866055e-001", "\n", "self", ".", "nbins", "=", "512", "\n", "self", ".", "nbark", "=", "49", "\n", "", "else", ":", "\n", "            ", "self", ".", "Sp", "=", "2.764344e-5", "\n", "self", ".", "Sl", "=", "1.866055e-1", "\n", "self", ".", "nbins", "=", "256", "\n", "self", ".", "nbark", "=", "42", "\n", "# As described in [1] and used in the TF implementation.", "\n", "", "self", ".", "alpha", "=", "0.1", "\n", "self", ".", "beta", "=", "0.309", "*", "self", ".", "alpha", "\n", "\n", "pow_correc_factor", "=", "self", ".", "get_correction_factor", "(", "window_name", ")", "\n", "self", ".", "pow_correc_factor", "=", "pow_correc_factor", "*", "self", ".", "window_weight", "\n", "# Initialize to None and populate as a function of sample rate.", "\n", "self", ".", "abs_thresh_power", "=", "None", "\n", "self", ".", "modified_zwicker_power", "=", "None", "\n", "self", ".", "width_of_band_bark", "=", "None", "\n", "self", ".", "bark_matrix", "=", "None", "\n", "self", ".", "mask_sll", "=", "None", "\n", "self", ".", "populate_constants", "(", "self", ".", "sample_rate", ")", "\n", "self", ".", "sqrt_total_width", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "self", ".", "width_of_band_bark", ")", ")", "\n", "self", ".", "EPS", "=", "1e-8", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.forward": [[103, 172], ["pmsqe.SingleSrcPMSQE.magnitude_at_sll", "pmsqe.SingleSrcPMSQE.magnitude_at_sll", "pmsqe.SingleSrcPMSQE.bark_computation", "pmsqe.SingleSrcPMSQE.bark_computation", "pmsqe.SingleSrcPMSQE.compute_distortion_tensors", "pmsqe.SingleSrcPMSQE.compute_audible_power", "pmsqe.SingleSrcPMSQE.per_frame_distortion", "est_targets.transpose.transpose.shape.index", "est_targets.transpose.transpose.transpose", "targets.transpose.transpose.transpose", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "pmsqe.SingleSrcPMSQE.bark_freq_equalization", "pmsqe.SingleSrcPMSQE.bark_gain_equalization", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.ones.sum", "torch.ones.sum", "ValueError", "torch.ones.transpose", "torch.ones.transpose"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.magnitude_at_sll", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.magnitude_at_sll", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.bark_computation", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.bark_computation", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.compute_distortion_tensors", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.compute_audible_power", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.per_frame_distortion", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.bark_freq_equalization", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.bark_gain_equalization"], ["", "def", "forward", "(", "self", ",", "est_targets", ",", "targets", ",", "pad_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args\n            est_targets (torch.Tensor): Dimensions (B, T, F).\n                Padded degraded power spectrum in time-frequency domain.\n            targets (torch.Tensor): Dimensions (B, T, F).\n                Zero-Padded reference power spectrum in time-frequency domain.\n            pad_mask (torch.Tensor, optional):  Dimensions (B, T, 1). Mask\n                to indicate the padding frames. Defaults to all ones.\n\n        Dimensions\n            B: Number of sequences in the batch.\n            T: Number of time frames.\n            F: Number of frequency bins.\n\n        Returns\n            torch.tensor of shape (B, ), wD + 0.309 * wDA\n\n        ..note:: Dimensions (B, F, T) are also supported by SingleSrcPMSQE but are\n            less efficient because input tensors are transposed (not inplace).\n\n        \"\"\"", "\n", "assert", "est_targets", ".", "shape", "==", "targets", ".", "shape", "\n", "# Need transpose? Find it out", "\n", "try", ":", "\n", "            ", "freq_idx", "=", "est_targets", ".", "shape", ".", "index", "(", "self", ".", "nbins", "//", "2", "+", "1", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Could not find dimension with {} elements in \"", "\n", "\"input tensors, verify your inputs\"", "\n", "\"\"", ".", "format", "(", "self", ".", "nbins", "//", "2", "+", "1", ")", "\n", ")", "\n", "", "if", "freq_idx", "==", "1", ":", "\n", "            ", "est_targets", "=", "est_targets", ".", "transpose", "(", "1", ",", "2", ")", "\n", "targets", "=", "targets", ".", "transpose", "(", "1", ",", "2", ")", "\n", "", "if", "pad_mask", "is", "not", "None", ":", "\n", "# Transpose the pad mask as well if needed.", "\n", "            ", "pad_mask", "=", "pad_mask", ".", "transpose", "(", "1", ",", "2", ")", "if", "freq_idx", "==", "1", "else", "pad_mask", "\n", "", "else", ":", "\n", "# Suppose no padding if no pad_mask is provided.", "\n", "            ", "pad_mask", "=", "torch", ".", "ones", "(", "\n", "est_targets", ".", "shape", "[", "0", "]", ",", "est_targets", ".", "shape", "[", "1", "]", ",", "1", ",", "device", "=", "est_targets", ".", "device", "\n", ")", "\n", "# SLL equalization", "\n", "", "ref_spectra", "=", "self", ".", "magnitude_at_sll", "(", "targets", ",", "pad_mask", ")", "\n", "deg_spectra", "=", "self", ".", "magnitude_at_sll", "(", "est_targets", ",", "pad_mask", ")", "\n", "\n", "# Bark spectra computation", "\n", "ref_bark_spectra", "=", "self", ".", "bark_computation", "(", "ref_spectra", ")", "\n", "deg_bark_spectra", "=", "self", ".", "bark_computation", "(", "deg_spectra", ")", "\n", "\n", "# (Optional) frequency and gain equalization", "\n", "if", "self", ".", "bark_eq", ":", "\n", "            ", "deg_bark_spectra", "=", "self", ".", "bark_freq_equalization", "(", "ref_bark_spectra", ",", "deg_bark_spectra", ")", "\n", "\n", "", "if", "self", ".", "gain_eq", ":", "\n", "            ", "deg_bark_spectra", "=", "self", ".", "bark_gain_equalization", "(", "ref_bark_spectra", ",", "deg_bark_spectra", ")", "\n", "\n", "# Distortion matrix computation", "\n", "", "sym_d", ",", "asym_d", "=", "self", ".", "compute_distortion_tensors", "(", "ref_bark_spectra", ",", "deg_bark_spectra", ")", "\n", "\n", "# Per-frame distortion", "\n", "audible_power_ref", "=", "self", ".", "compute_audible_power", "(", "ref_bark_spectra", ",", "1.0", ")", "\n", "wd_frame", ",", "wda_frame", "=", "self", ".", "per_frame_distortion", "(", "sym_d", ",", "asym_d", ",", "audible_power_ref", ")", "\n", "# Mean distortions over frames : keep batch dims", "\n", "dims", "=", "[", "-", "1", ",", "-", "2", "]", "\n", "pmsqe_frame", "=", "(", "self", ".", "alpha", "*", "wd_frame", "+", "self", ".", "beta", "*", "wda_frame", ")", "*", "pad_mask", "\n", "pmsqe", "=", "torch", ".", "sum", "(", "pmsqe_frame", ",", "dim", "=", "dims", ")", "/", "pad_mask", ".", "sum", "(", "dims", ")", "\n", "return", "pmsqe", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.magnitude_at_sll": [[173, 184], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "magnitude_at_sll", "(", "self", ",", "spectra", ",", "pad_mask", ")", ":", "\n", "# Apply padding and SLL masking", "\n", "        ", "masked_spectra", "=", "spectra", "*", "pad_mask", "*", "self", ".", "mask_sll", "\n", "# Compute mean over frequency", "\n", "freq_mean_masked_spectra", "=", "torch", ".", "mean", "(", "masked_spectra", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "# Compute mean over time (taking into account padding)", "\n", "sum_spectra", "=", "torch", ".", "sum", "(", "freq_mean_masked_spectra", ",", "dim", "=", "-", "2", ",", "keepdim", "=", "True", ")", "\n", "seq_len", "=", "torch", ".", "sum", "(", "pad_mask", ",", "dim", "=", "-", "2", ",", "keepdim", "=", "True", ")", "\n", "mean_pow", "=", "sum_spectra", "/", "seq_len", "\n", "# Compute final SLL spectra", "\n", "return", "10000000.0", "*", "spectra", "/", "mean_pow", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.bark_computation": [[185, 187], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["None"], ["", "def", "bark_computation", "(", "self", ",", "spectra", ")", ":", "\n", "        ", "return", "self", ".", "Sp", "*", "torch", ".", "matmul", "(", "spectra", ",", "self", ".", "bark_matrix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.compute_audible_power": [[188, 197], ["torch.where", "torch.where", "torch.where", "torch.where", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "compute_audible_power", "(", "self", ",", "bark_spectra", ",", "factor", "=", "1.0", ")", ":", "\n", "# Apply absolute hearing threshold to each band", "\n", "        ", "thr_bark", "=", "torch", ".", "where", "(", "\n", "bark_spectra", ">", "self", ".", "abs_thresh_power", "*", "factor", ",", "\n", "bark_spectra", ",", "\n", "torch", ".", "zeros_like", "(", "bark_spectra", ")", ",", "\n", ")", "\n", "# Sum band power over frequency", "\n", "return", "torch", ".", "sum", "(", "thr_bark", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.bark_gain_equalization": [[198, 209], ["pmsqe.SingleSrcPMSQE.compute_audible_power", "pmsqe.SingleSrcPMSQE.compute_audible_power", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.compute_audible_power", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.compute_audible_power"], ["", "def", "bark_gain_equalization", "(", "self", ",", "ref_bark_spectra", ",", "deg_bark_spectra", ")", ":", "\n", "# Compute audible power", "\n", "        ", "audible_power_ref", "=", "self", ".", "compute_audible_power", "(", "ref_bark_spectra", ",", "1.0", ")", "\n", "audible_power_deg", "=", "self", ".", "compute_audible_power", "(", "deg_bark_spectra", ",", "1.0", ")", "\n", "# Compute gain factor", "\n", "gain", "=", "(", "audible_power_ref", "+", "5.0e3", ")", "/", "(", "audible_power_deg", "+", "5.0e3", ")", "\n", "# Limit the range of the gain factor", "\n", "limited_gain", "=", "torch", ".", "min", "(", "gain", ",", "5.0", "*", "torch", ".", "ones_like", "(", "gain", ")", ")", "\n", "limited_gain", "=", "torch", ".", "max", "(", "limited_gain", ",", "3.0e-4", "*", "torch", ".", "ones_like", "(", "limited_gain", ")", ")", "\n", "# Apply gain correction on degraded", "\n", "return", "limited_gain", "*", "deg_bark_spectra", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.bark_freq_equalization": [[210, 240], ["pmsqe.SingleSrcPMSQE.compute_audible_power", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.min", "torch.min", "torch.min", "torch.min", "torch.max", "torch.max", "torch.max", "torch.max", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.compute_audible_power"], ["", "def", "bark_freq_equalization", "(", "self", ",", "ref_bark_spectra", ",", "deg_bark_spectra", ")", ":", "\n", "        ", "\"\"\"This version is applied in the degraded directly.\"\"\"", "\n", "# Identification of speech active frames", "\n", "audible_power_x100", "=", "self", ".", "compute_audible_power", "(", "ref_bark_spectra", ",", "100.0", ")", "\n", "not_silent", "=", "audible_power_x100", ">=", "1.0e7", "\n", "# Threshold for active bark bins", "\n", "cond_thr", "=", "ref_bark_spectra", ">=", "self", ".", "abs_thresh_power", "*", "100.0", "\n", "ref_thresholded", "=", "torch", ".", "where", "(", "\n", "cond_thr", ",", "ref_bark_spectra", ",", "torch", ".", "zeros_like", "(", "ref_bark_spectra", ")", "\n", ")", "\n", "deg_thresholded", "=", "torch", ".", "where", "(", "\n", "cond_thr", ",", "deg_bark_spectra", ",", "torch", ".", "zeros_like", "(", "deg_bark_spectra", ")", "\n", ")", "\n", "# Total power per bark bin (ppb)", "\n", "avg_ppb_ref", "=", "torch", ".", "sum", "(", "\n", "torch", ".", "where", "(", "not_silent", ",", "ref_thresholded", ",", "torch", ".", "zeros_like", "(", "ref_thresholded", ")", ")", ",", "\n", "dim", "=", "-", "2", ",", "\n", "keepdim", "=", "True", ",", "\n", ")", "\n", "avg_ppb_deg", "=", "torch", ".", "sum", "(", "\n", "torch", ".", "where", "(", "not_silent", ",", "deg_thresholded", ",", "torch", ".", "zeros_like", "(", "deg_thresholded", ")", ")", ",", "\n", "dim", "=", "-", "2", ",", "\n", "keepdim", "=", "True", ",", "\n", ")", "\n", "# Compute equalizer", "\n", "equalizer", "=", "(", "avg_ppb_ref", "+", "1000.0", ")", "/", "(", "avg_ppb_deg", "+", "1000.0", ")", "\n", "equalizer", "=", "torch", ".", "min", "(", "equalizer", ",", "100.0", "*", "torch", ".", "ones_like", "(", "equalizer", ")", ")", "\n", "equalizer", "=", "torch", ".", "max", "(", "equalizer", ",", "0.01", "*", "torch", ".", "ones_like", "(", "equalizer", ")", ")", "\n", "# Apply frequency correction on degraded", "\n", "return", "equalizer", "*", "deg_bark_spectra", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.loudness_computation": [[241, 251], ["torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.where", "torch.where", "torch.where", "torch.where", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "loudness_computation", "(", "self", ",", "bark_spectra", ")", ":", "\n", "# Bark spectra transformed to a sone loudness scale using Zwicker's law", "\n", "        ", "aterm", "=", "torch", ".", "pow", "(", "self", ".", "abs_thresh_power", "/", "0.5", ",", "self", ".", "modified_zwicker_power", ")", "\n", "bterm", "=", "(", "\n", "torch", ".", "pow", "(", "0.5", "+", "0.5", "*", "bark_spectra", "/", "self", ".", "abs_thresh_power", ",", "self", ".", "modified_zwicker_power", ")", "\n", "-", "1.0", "\n", ")", "\n", "loudness_dens", "=", "self", ".", "Sl", "*", "aterm", "*", "bterm", "\n", "cond", "=", "bark_spectra", "<", "self", ".", "abs_thresh_power", "\n", "return", "torch", ".", "where", "(", "cond", ",", "torch", ".", "zeros_like", "(", "loudness_dens", ")", ",", "loudness_dens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.compute_distortion_tensors": [[252, 271], ["pmsqe.SingleSrcPMSQE.loudness_computation", "pmsqe.SingleSrcPMSQE.loudness_computation", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.max", "torch.max", "torch.max", "torch.max", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.where", "torch.where", "torch.where", "torch.where", "torch.min", "torch.min", "torch.min", "torch.min", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.min", "torch.min", "torch.min", "torch.min", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.loudness_computation", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.loudness_computation"], ["", "def", "compute_distortion_tensors", "(", "self", ",", "ref_bark_spec", ",", "deg_bark_spec", ")", ":", "\n", "# After bark spectra are compensated, transform to sone loudness", "\n", "        ", "original_loudness", "=", "self", ".", "loudness_computation", "(", "ref_bark_spec", ")", "\n", "distorted_loudness", "=", "self", ".", "loudness_computation", "(", "deg_bark_spec", ")", "\n", "# Loudness difference", "\n", "r", "=", "torch", ".", "abs", "(", "distorted_loudness", "-", "original_loudness", ")", "\n", "# Masking effect computation", "\n", "m", "=", "0.25", "*", "torch", ".", "min", "(", "original_loudness", ",", "distorted_loudness", ")", "\n", "# Center clipping using masking effect", "\n", "sym_d", "=", "torch", ".", "max", "(", "r", "-", "m", ",", "torch", ".", "ones_like", "(", "r", ")", "*", "self", ".", "EPS", ")", "\n", "# Asymmetry factor computation", "\n", "asym", "=", "torch", ".", "pow", "(", "(", "deg_bark_spec", "+", "50.0", ")", "/", "(", "ref_bark_spec", "+", "50.0", ")", ",", "1.2", ")", "\n", "cond", "=", "asym", "<", "3.0", "*", "torch", ".", "ones_like", "(", "asym", ")", "\n", "asym_factor", "=", "torch", ".", "where", "(", "\n", "cond", ",", "torch", ".", "zeros_like", "(", "asym", ")", ",", "torch", ".", "min", "(", "asym", ",", "12.0", "*", "torch", ".", "ones_like", "(", "asym", ")", ")", "\n", ")", "\n", "# Asymmetric Disturbance matrix computation", "\n", "asym_d", "=", "asym_factor", "*", "sym_d", "\n", "return", "sym_d", ",", "asym_d", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.per_frame_distortion": [[272, 291], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like"], "methods", ["None"], ["", "def", "per_frame_distortion", "(", "self", ",", "sym_d", ",", "asym_d", ",", "total_power_ref", ")", ":", "\n", "# Computation of the norms over bark bands for each frame", "\n", "# 2 and 1 for sym_d and asym_d, respectively", "\n", "        ", "d_frame", "=", "torch", ".", "sum", "(", "\n", "torch", ".", "pow", "(", "sym_d", "*", "self", ".", "width_of_band_bark", ",", "2.0", ")", "+", "self", ".", "EPS", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", "\n", ")", "\n", "# a = torch.pow(sym_d * self.width_of_band_bark, 2.0)", "\n", "# b = sym_d", "\n", "# print(a.min(),a.max(),b.min(),b.max(), d_frame.min(), d_frame.max())", "\n", "# print(self.width_of_band_bark.requires_grad)", "\n", "# print(d_frame.requires_grad)", "\n", "d_frame", "=", "torch", ".", "sqrt", "(", "d_frame", ")", "*", "self", ".", "sqrt_total_width", "\n", "da_frame", "=", "torch", ".", "sum", "(", "asym_d", "*", "self", ".", "width_of_band_bark", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "# Weighting by the audible power raised to 0.04", "\n", "weights", "=", "torch", ".", "pow", "(", "(", "total_power_ref", "+", "1e5", ")", "/", "1e7", ",", "0.04", ")", "\n", "# Bounded computation of the per frame distortion metric", "\n", "wd_frame", "=", "torch", ".", "min", "(", "d_frame", "/", "weights", ",", "45.0", "*", "torch", ".", "ones_like", "(", "d_frame", ")", ")", "\n", "wda_frame", "=", "torch", ".", "min", "(", "da_frame", "/", "weights", ",", "45.0", "*", "torch", ".", "ones_like", "(", "da_frame", ")", ")", "\n", "return", "wd_frame", ",", "wda_frame", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.get_correction_factor": [[292, 307], ["ValueError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_correction_factor", "(", "window_name", ")", ":", "\n", "        ", "\"\"\"Returns the power correction factor depending on the window.\"\"\"", "\n", "if", "window_name", "==", "\"rect\"", ":", "\n", "            ", "return", "1.0", "\n", "", "elif", "window_name", "==", "\"hann\"", ":", "\n", "            ", "return", "2.666666666666754", "\n", "", "elif", "window_name", "==", "\"sqrt_hann\"", ":", "\n", "            ", "return", "2.0", "\n", "", "elif", "window_name", "==", "\"hamming\"", ":", "\n", "            ", "return", "2.51635879188799", "\n", "", "elif", "window_name", "==", "\"flatTop\"", ":", "\n", "            ", "return", "5.70713295690759", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unexpected window type {}\"", ".", "format", "(", "window_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.populate_constants": [[308, 321], ["numpy.zeros", "torch.Parameter", "torch.Parameter", "pmsqe.SingleSrcPMSQE.register_8k_constants", "torch.tensor", "torch.tensor", "pmsqe.SingleSrcPMSQE.register_16k_constants"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.register_8k_constants", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.register_16k_constants"], ["", "", "def", "populate_constants", "(", "self", ",", "sample_rate", ")", ":", "\n", "        ", "if", "sample_rate", "==", "8000", ":", "\n", "            ", "self", ".", "register_8k_constants", "(", ")", "\n", "", "elif", "sample_rate", "==", "16000", ":", "\n", "            ", "self", ".", "register_16k_constants", "(", ")", "\n", "# Mask SSL", "\n", "", "mask_sll", "=", "np", ".", "zeros", "(", "shape", "=", "[", "self", ".", "nbins", "//", "2", "+", "1", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "mask_sll", "[", "11", "]", "=", "0.5", "*", "25.0", "/", "31.25", "\n", "mask_sll", "[", "12", ":", "104", "]", "=", "1.0", "\n", "mask_sll", "[", "104", "]", "=", "0.5", "\n", "correction", "=", "self", ".", "pow_correc_factor", "*", "(", "self", ".", "nbins", "+", "2.0", ")", "/", "self", ".", "nbins", "**", "2", "\n", "mask_sll", "=", "mask_sll", "*", "correction", "\n", "self", ".", "mask_sll", "=", "nn", ".", "Parameter", "(", "tensor", "(", "mask_sll", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.register_16k_constants": [[322, 487], ["torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "pathlib.Path().parent.absolute", "os.path.join", "[].astype", "torch.Parameter", "torch.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "pathlib.Path", "pmsqe.SingleSrcPMSQE.load_mat"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.load_mat"], ["", "def", "register_16k_constants", "(", "self", ")", ":", "\n", "# Absolute threshold power", "\n", "        ", "abs_thresh_power", "=", "[", "\n", "51286152.00", ",", "\n", "2454709.500", ",", "\n", "70794.593750", ",", "\n", "4897.788574", ",", "\n", "1174.897705", ",", "\n", "389.045166", ",", "\n", "104.712860", ",", "\n", "45.708820", ",", "\n", "17.782795", ",", "\n", "9.772372", ",", "\n", "4.897789", ",", "\n", "3.090296", ",", "\n", "1.905461", ",", "\n", "1.258925", ",", "\n", "0.977237", ",", "\n", "0.724436", ",", "\n", "0.562341", ",", "\n", "0.457088", ",", "\n", "0.389045", ",", "\n", "0.331131", ",", "\n", "0.295121", ",", "\n", "0.269153", ",", "\n", "0.257040", ",", "\n", "0.251189", ",", "\n", "0.251189", ",", "\n", "0.251189", ",", "\n", "0.251189", ",", "\n", "0.263027", ",", "\n", "0.288403", ",", "\n", "0.309030", ",", "\n", "0.338844", ",", "\n", "0.371535", ",", "\n", "0.398107", ",", "\n", "0.436516", ",", "\n", "0.467735", ",", "\n", "0.489779", ",", "\n", "0.501187", ",", "\n", "0.501187", ",", "\n", "0.512861", ",", "\n", "0.524807", ",", "\n", "0.524807", ",", "\n", "0.524807", ",", "\n", "0.512861", ",", "\n", "0.478630", ",", "\n", "0.426580", ",", "\n", "0.371535", ",", "\n", "0.363078", ",", "\n", "0.416869", ",", "\n", "0.537032", ",", "\n", "]", "\n", "self", ".", "abs_thresh_power", "=", "nn", ".", "Parameter", "(", "tensor", "(", "abs_thresh_power", ")", ",", "requires_grad", "=", "False", ")", "\n", "# Modified zwicker power", "\n", "modif_zwicker_power", "=", "[", "\n", "0.25520097857560436", ",", "\n", "0.25520097857560436", ",", "\n", "0.25520097857560436", ",", "\n", "0.25520097857560436", ",", "\n", "0.25168783742879913", ",", "\n", "0.24806665731869609", ",", "\n", "0.244767379124259", ",", "\n", "0.24173800119368227", ",", "\n", "0.23893798876066405", ",", "\n", "0.23633516221479894", ",", "\n", "0.23390360348392067", ",", "\n", "0.23162209128929445", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "]", "\n", "self", ".", "modified_zwicker_power", "=", "nn", ".", "Parameter", "(", "tensor", "(", "modif_zwicker_power", ")", ",", "requires_grad", "=", "False", ")", "\n", "# Width of band bark", "\n", "width_of_band_bark", "=", "[", "\n", "0.157344", ",", "\n", "0.317994", ",", "\n", "0.322441", ",", "\n", "0.326934", ",", "\n", "0.331474", ",", "\n", "0.336061", ",", "\n", "0.340697", ",", "\n", "0.345381", ",", "\n", "0.350114", ",", "\n", "0.354897", ",", "\n", "0.359729", ",", "\n", "0.364611", ",", "\n", "0.369544", ",", "\n", "0.374529", ",", "\n", "0.379565", ",", "\n", "0.384653", ",", "\n", "0.389794", ",", "\n", "0.394989", ",", "\n", "0.400236", ",", "\n", "0.405538", ",", "\n", "0.410894", ",", "\n", "0.416306", ",", "\n", "0.421773", ",", "\n", "0.427297", ",", "\n", "0.432877", ",", "\n", "0.438514", ",", "\n", "0.444209", ",", "\n", "0.449962", ",", "\n", "0.455774", ",", "\n", "0.461645", ",", "\n", "0.467577", ",", "\n", "0.473569", ",", "\n", "0.479621", ",", "\n", "0.485736", ",", "\n", "0.491912", ",", "\n", "0.498151", ",", "\n", "0.504454", ",", "\n", "0.510819", ",", "\n", "0.517250", ",", "\n", "0.523745", ",", "\n", "0.530308", ",", "\n", "0.536934", ",", "\n", "0.543629", ",", "\n", "0.550390", ",", "\n", "0.557220", ",", "\n", "0.564119", ",", "\n", "0.571085", ",", "\n", "0.578125", ",", "\n", "0.585232", ",", "\n", "]", "\n", "self", ".", "width_of_band_bark", "=", "nn", ".", "Parameter", "(", "tensor", "(", "width_of_band_bark", ")", ",", "requires_grad", "=", "False", ")", "\n", "# Bark matrix", "\n", "local_path", "=", "pathlib", ".", "Path", "(", "__file__", ")", ".", "parent", ".", "absolute", "(", ")", "\n", "bark_path", "=", "os", ".", "path", ".", "join", "(", "local_path", ",", "\"bark_matrix_16k.mat\"", ")", "\n", "bark_matrix", "=", "self", ".", "load_mat", "(", "bark_path", ")", "[", "\"Bark_matrix_16k\"", "]", ".", "astype", "(", "\"float32\"", ")", "\n", "self", ".", "bark_matrix", "=", "nn", ".", "Parameter", "(", "tensor", "(", "bark_matrix", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.register_8k_constants": [[488, 632], ["torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "pathlib.Path().parent.absolute", "os.path.join", "[].astype", "torch.Parameter", "torch.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "pathlib.Path", "pmsqe.SingleSrcPMSQE.load_mat"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.load_mat"], ["", "def", "register_8k_constants", "(", "self", ")", ":", "\n", "# Absolute threshold power", "\n", "        ", "abs_thresh_power", "=", "[", "\n", "51286152", ",", "\n", "2454709.500", ",", "\n", "70794.593750", ",", "\n", "4897.788574", ",", "\n", "1174.897705", ",", "\n", "389.045166", ",", "\n", "104.712860", ",", "\n", "45.708820", ",", "\n", "17.782795", ",", "\n", "9.772372", ",", "\n", "4.897789", ",", "\n", "3.090296", ",", "\n", "1.905461", ",", "\n", "1.258925", ",", "\n", "0.977237", ",", "\n", "0.724436", ",", "\n", "0.562341", ",", "\n", "0.457088", ",", "\n", "0.389045", ",", "\n", "0.331131", ",", "\n", "0.295121", ",", "\n", "0.269153", ",", "\n", "0.257040", ",", "\n", "0.251189", ",", "\n", "0.251189", ",", "\n", "0.251189", ",", "\n", "0.251189", ",", "\n", "0.263027", ",", "\n", "0.288403", ",", "\n", "0.309030", ",", "\n", "0.338844", ",", "\n", "0.371535", ",", "\n", "0.398107", ",", "\n", "0.436516", ",", "\n", "0.467735", ",", "\n", "0.489779", ",", "\n", "0.501187", ",", "\n", "0.501187", ",", "\n", "0.512861", ",", "\n", "0.524807", ",", "\n", "0.524807", ",", "\n", "0.524807", ",", "\n", "]", "\n", "self", ".", "abs_thresh_power", "=", "nn", ".", "Parameter", "(", "tensor", "(", "abs_thresh_power", ")", ",", "requires_grad", "=", "False", ")", "\n", "# Modified zwicker power", "\n", "modif_zwicker_power", "=", "[", "\n", "0.25520097857560436", ",", "\n", "0.25520097857560436", ",", "\n", "0.25520097857560436", ",", "\n", "0.25520097857560436", ",", "\n", "0.25168783742879913", ",", "\n", "0.24806665731869609", ",", "\n", "0.244767379124259", ",", "\n", "0.24173800119368227", ",", "\n", "0.23893798876066405", ",", "\n", "0.23633516221479894", ",", "\n", "0.23390360348392067", ",", "\n", "0.23162209128929445", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "0.23", ",", "\n", "]", "\n", "self", ".", "modified_zwicker_power", "=", "nn", ".", "Parameter", "(", "tensor", "(", "modif_zwicker_power", ")", ",", "requires_grad", "=", "False", ")", "\n", "# Width of band bark", "\n", "width_of_band_bark", "=", "[", "\n", "0.157344", ",", "\n", "0.317994", ",", "\n", "0.322441", ",", "\n", "0.326934", ",", "\n", "0.331474", ",", "\n", "0.336061", ",", "\n", "0.340697", ",", "\n", "0.345381", ",", "\n", "0.350114", ",", "\n", "0.354897", ",", "\n", "0.359729", ",", "\n", "0.364611", ",", "\n", "0.369544", ",", "\n", "0.374529", ",", "\n", "0.379565", ",", "\n", "0.384653", ",", "\n", "0.389794", ",", "\n", "0.394989", ",", "\n", "0.400236", ",", "\n", "0.405538", ",", "\n", "0.410894", ",", "\n", "0.416306", ",", "\n", "0.421773", ",", "\n", "0.427297", ",", "\n", "0.432877", ",", "\n", "0.438514", ",", "\n", "0.444209", ",", "\n", "0.449962", ",", "\n", "0.455774", ",", "\n", "0.461645", ",", "\n", "0.467577", ",", "\n", "0.473569", ",", "\n", "0.479621", ",", "\n", "0.485736", ",", "\n", "0.491912", ",", "\n", "0.498151", ",", "\n", "0.504454", ",", "\n", "0.510819", ",", "\n", "0.517250", ",", "\n", "0.523745", ",", "\n", "0.530308", ",", "\n", "0.536934", ",", "\n", "]", "\n", "self", ".", "width_of_band_bark", "=", "nn", ".", "Parameter", "(", "tensor", "(", "width_of_band_bark", ")", ",", "requires_grad", "=", "False", ")", "\n", "# Bark matrix", "\n", "local_path", "=", "pathlib", ".", "Path", "(", "__file__", ")", ".", "parent", ".", "absolute", "(", ")", "\n", "bark_path", "=", "os", ".", "path", ".", "join", "(", "local_path", ",", "\"bark_matrix_8k.mat\"", ")", "\n", "bark_matrix", "=", "self", ".", "load_mat", "(", "bark_path", ")", "[", "\"Bark_matrix_8k\"", "]", ".", "astype", "(", "\"float32\"", ")", "\n", "self", ".", "bark_matrix", "=", "nn", ".", "Parameter", "(", "tensor", "(", "bark_matrix", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pmsqe.SingleSrcPMSQE.load_mat": [[633, 637], ["loadmat"], "methods", ["None"], ["", "def", "load_mat", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "from", "scipy", ".", "io", "import", "loadmat", "\n", "\n", "return", "loadmat", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mse.PairwiseMSE.forward": [[23, 34], ["targets.unsqueeze.unsqueeze.unsqueeze", "est_targets.unsqueeze.unsqueeze.unsqueeze", "list", "pw_loss.mean", "TypeError", "range", "targets.unsqueeze.unsqueeze.size", "est_targets.unsqueeze.unsqueeze.size", "targets.unsqueeze.unsqueeze.size", "est_targets.unsqueeze.unsqueeze.size"], "methods", ["None"], ["def", "forward", "(", "self", ",", "est_targets", ",", "targets", ")", ":", "\n", "        ", "if", "targets", ".", "size", "(", ")", "!=", "est_targets", ".", "size", "(", ")", "or", "targets", ".", "ndim", "<", "3", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f\"Inputs must be of shape [batch, n_src, *], got {targets.size()} and {est_targets.size()} instead\"", "\n", ")", "\n", "", "targets", "=", "targets", ".", "unsqueeze", "(", "1", ")", "\n", "est_targets", "=", "est_targets", ".", "unsqueeze", "(", "2", ")", "\n", "pw_loss", "=", "(", "targets", "-", "est_targets", ")", "**", "2", "\n", "# Need to return [batch, nsrc, nsrc]", "\n", "mean_over", "=", "list", "(", "range", "(", "3", ",", "pw_loss", ".", "ndim", ")", ")", "\n", "return", "pw_loss", ".", "mean", "(", "dim", "=", "mean_over", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mse.SingleSrcMSE.forward": [[57, 65], ["list", "loss.mean", "TypeError", "range", "targets.size", "est_targets.size", "targets.size", "est_targets.size"], "methods", ["None"], ["def", "forward", "(", "self", ",", "est_targets", ",", "targets", ")", ":", "\n", "        ", "if", "targets", ".", "size", "(", ")", "!=", "est_targets", ".", "size", "(", ")", "or", "targets", ".", "ndim", "<", "2", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f\"Inputs must be of shape [batch, *], got {targets.size()} and {est_targets.size()} instead\"", "\n", ")", "\n", "", "loss", "=", "(", "targets", "-", "est_targets", ")", "**", "2", "\n", "mean_over", "=", "list", "(", "range", "(", "1", ",", "loss", ".", "ndim", ")", ")", "\n", "return", "loss", ".", "mean", "(", "dim", "=", "mean_over", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.multi_scale_spectral.SingleSrcMultiScaleSpectral.__init__": [[48, 66], ["torch.nn.modules.loss._Loss.__init__", "torch.ModuleList", "torch.ModuleList", "asteroid_filterbanks.Encoder", "asteroid_filterbanks.STFTFB", "range", "len"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "n_filters", "=", "None", ",", "windows_size", "=", "None", ",", "hops_size", "=", "None", ",", "alpha", "=", "1.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "windows_size", "is", "None", ":", "\n", "            ", "windows_size", "=", "[", "2048", ",", "1024", ",", "512", ",", "256", ",", "128", ",", "64", ",", "32", "]", "\n", "", "if", "n_filters", "is", "None", ":", "\n", "            ", "n_filters", "=", "[", "2048", ",", "1024", ",", "512", ",", "256", ",", "128", ",", "64", ",", "32", "]", "\n", "", "if", "hops_size", "is", "None", ":", "\n", "            ", "hops_size", "=", "[", "1024", ",", "512", ",", "256", ",", "128", ",", "64", ",", "32", ",", "16", "]", "\n", "\n", "", "self", ".", "windows_size", "=", "windows_size", "\n", "self", ".", "n_filters", "=", "n_filters", "\n", "self", ".", "hops_size", "=", "hops_size", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n", "self", ".", "encoders", "=", "nn", ".", "ModuleList", "(", "\n", "Encoder", "(", "STFTFB", "(", "n_filters", "[", "i", "]", ",", "windows_size", "[", "i", "]", ",", "hops_size", "[", "i", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "n_filters", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.multi_scale_spectral.SingleSrcMultiScaleSpectral.forward": [[68, 77], ["est_target.unsqueeze.unsqueeze.unsqueeze", "target.unsqueeze.unsqueeze.unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "multi_scale_spectral.SingleSrcMultiScaleSpectral.compute_spectral_loss"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.multi_scale_spectral.SingleSrcMultiScaleSpectral.compute_spectral_loss"], ["", "def", "forward", "(", "self", ",", "est_target", ",", "target", ")", ":", "\n", "        ", "batch_size", "=", "est_target", ".", "shape", "[", "0", "]", "\n", "est_target", "=", "est_target", ".", "unsqueeze", "(", "1", ")", "\n", "target", "=", "target", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "loss", "=", "torch", ".", "zeros", "(", "batch_size", ",", "device", "=", "est_target", ".", "device", ")", "\n", "for", "encoder", "in", "self", ".", "encoders", ":", "\n", "            ", "loss", "+=", "self", ".", "compute_spectral_loss", "(", "encoder", ",", "est_target", ",", "target", ")", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.multi_scale_spectral.SingleSrcMultiScaleSpectral.compute_spectral_loss": [[78, 85], ["asteroid_filterbanks.transforms.mag().view", "asteroid_filterbanks.transforms.mag().view", "multi_scale_spectral.SingleSrcMultiScaleSpectral.norm1", "multi_scale_spectral.SingleSrcMultiScaleSpectral.norm1", "asteroid_filterbanks.transforms.mag", "asteroid_filterbanks.transforms.mag", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "encoder", "encoder"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.multi_scale_spectral.SingleSrcMultiScaleSpectral.norm1", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.multi_scale_spectral.SingleSrcMultiScaleSpectral.norm1"], ["", "def", "compute_spectral_loss", "(", "self", ",", "encoder", ",", "est_target", ",", "target", ",", "EPS", "=", "1e-8", ")", ":", "\n", "        ", "batch_size", "=", "est_target", ".", "shape", "[", "0", "]", "\n", "spect_est_target", "=", "mag", "(", "encoder", "(", "est_target", ")", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "spect_target", "=", "mag", "(", "encoder", "(", "target", ")", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "linear_loss", "=", "self", ".", "norm1", "(", "spect_est_target", "-", "spect_target", ")", "\n", "log_loss", "=", "self", ".", "norm1", "(", "torch", ".", "log", "(", "spect_est_target", "+", "EPS", ")", "-", "torch", ".", "log", "(", "spect_target", "+", "EPS", ")", ")", "\n", "return", "linear_loss", "+", "self", ".", "alpha", "*", "log_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.multi_scale_spectral.SingleSrcMultiScaleSpectral.norm1": [[86, 89], ["torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "norm1", "(", "a", ")", ":", "\n", "        ", "return", "torch", ".", "norm", "(", "a", ",", "p", "=", "1", ",", "dim", "=", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.__init__": [[41, 46], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "loss_func", ",", "generalized", "=", "True", ",", "reduction", "=", "\"mean\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_func", "=", "loss_func", "\n", "self", ".", "generalized", "=", "generalized", "\n", "self", ".", "reduction", "=", "reduction", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.forward": [[47, 87], ["mixit_wrapper.MixITLossWrapper.reorder_source", "mixit_wrapper.MixITLossWrapper.best_part_mixit", "mixit_wrapper.MixITLossWrapper.best_part_mixit_generalized", "min_loss.mean"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.reorder_source", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.best_part_mixit", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.best_part_mixit_generalized"], ["", "def", "forward", "(", "self", ",", "est_targets", ",", "targets", ",", "return_est", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Find the best partition and return the loss.\n\n        Args:\n            est_targets: torch.Tensor. Expected shape :math:`(batch, nsrc, *)`.\n                The batch of target estimates.\n            targets: torch.Tensor. Expected shape :math:`(batch, nmix, ...)`.\n                The batch of training targets\n            return_est: Boolean. Whether to return the estimated mixtures\n                estimates (To compute metrics or to save example).\n            **kwargs: additional keyword argument that will be passed to the\n                loss function.\n\n        Returns:\n            - Best partition loss for each batch sample, average over\n              the batch. torch.Tensor(loss_value)\n            - The estimated mixtures (estimated sources summed according to the partition)\n              if return_est is True. torch.Tensor of shape :math:`(batch, nmix, ...)`.\n        \"\"\"", "\n", "# Check input dimensions", "\n", "assert", "est_targets", ".", "shape", "[", "0", "]", "==", "targets", ".", "shape", "[", "0", "]", "\n", "assert", "est_targets", ".", "shape", "[", "2", "]", "==", "targets", ".", "shape", "[", "2", "]", "\n", "\n", "if", "not", "self", ".", "generalized", ":", "\n", "            ", "min_loss", ",", "min_loss_idx", ",", "parts", "=", "self", ".", "best_part_mixit", "(", "\n", "self", ".", "loss_func", ",", "est_targets", ",", "targets", ",", "**", "kwargs", "\n", ")", "\n", "", "else", ":", "\n", "            ", "min_loss", ",", "min_loss_idx", ",", "parts", "=", "self", ".", "best_part_mixit_generalized", "(", "\n", "self", ".", "loss_func", ",", "est_targets", ",", "targets", ",", "**", "kwargs", "\n", ")", "\n", "\n", "# Apply any reductions over the batch axis", "\n", "", "returned_loss", "=", "min_loss", ".", "mean", "(", ")", "if", "self", ".", "reduction", "==", "\"mean\"", "else", "min_loss", "\n", "if", "not", "return_est", ":", "\n", "            ", "return", "returned_loss", "\n", "\n", "# Order and sum on the best partition to get the estimated mixtures", "\n", "", "reordered", "=", "self", ".", "reorder_source", "(", "est_targets", ",", "targets", ",", "min_loss_idx", ",", "parts", ")", "\n", "return", "returned_loss", ",", "reordered", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.best_part_mixit": [[88, 143], ["list", "mixit_wrapper.MixITLossWrapper.loss_set_from_parts", "torch.min", "ValueError", "mixit_wrapper.MixITLossWrapper.best_part_mixit.parts_mixit"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.loss_set_from_parts"], ["", "@", "staticmethod", "\n", "def", "best_part_mixit", "(", "loss_func", ",", "est_targets", ",", "targets", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Find best partition of the estimated sources that gives the minimum\n        loss for the MixIT training paradigm in [1]. Valid for any number of\n        mixtures as soon as they contain the same number of sources.\n\n        Args:\n            loss_func: function with signature ``(est_targets, targets, **kwargs)``\n                The loss function to get batch losses from.\n            est_targets: torch.Tensor. Expected shape :math:`(batch, nsrc, ...)`.\n                The batch of target estimates.\n            targets: torch.Tensor. Expected shape :math:`(batch, nmix, ...)`.\n                The batch of training targets (mixtures).\n            **kwargs: additional keyword argument that will be passed to the\n                loss function.\n\n        Returns:\n            - :class:`torch.Tensor`:\n              The loss corresponding to the best permutation of size (batch,).\n\n            - :class:`torch.LongTensor`:\n              The indices of the best partition.\n\n            - :class:`list`:\n              list of the possible partitions of the sources.\n\n        \"\"\"", "\n", "nmix", "=", "targets", ".", "shape", "[", "1", "]", "\n", "nsrc", "=", "est_targets", ".", "shape", "[", "1", "]", "\n", "if", "nsrc", "%", "nmix", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"The mixtures are assumed to contain the same number of sources\"", ")", "\n", "", "nsrcmix", "=", "nsrc", "//", "nmix", "\n", "\n", "# Generate all unique partitions of size k from a list lst of", "\n", "# length n, where l = n // k is the number of parts. The total", "\n", "# number of such partitions is: NPK(n,k) = n! / ((k!)^l * l!)", "\n", "# Algorithm recursively distributes items over parts", "\n", "def", "parts_mixit", "(", "lst", ",", "k", ",", "l", ")", ":", "\n", "            ", "if", "l", "==", "0", ":", "\n", "                ", "yield", "[", "]", "\n", "", "else", ":", "\n", "                ", "for", "c", "in", "combinations", "(", "lst", ",", "k", ")", ":", "\n", "                    ", "rest", "=", "[", "x", "for", "x", "in", "lst", "if", "x", "not", "in", "c", "]", "\n", "for", "r", "in", "parts_mixit", "(", "rest", ",", "k", ",", "l", "-", "1", ")", ":", "\n", "                        ", "yield", "[", "list", "(", "c", ")", ",", "*", "r", "]", "\n", "\n", "# Generate all the possible partitions", "\n", "", "", "", "", "parts", "=", "list", "(", "parts_mixit", "(", "range", "(", "nsrc", ")", ",", "nsrcmix", ",", "nmix", ")", ")", "\n", "# Compute the loss corresponding to each partition", "\n", "loss_set", "=", "MixITLossWrapper", ".", "loss_set_from_parts", "(", "\n", "loss_func", ",", "est_targets", "=", "est_targets", ",", "targets", "=", "targets", ",", "parts", "=", "parts", ",", "**", "kwargs", "\n", ")", "\n", "# Indexes and values of min losses for each batch element", "\n", "min_loss", ",", "min_loss_indexes", "=", "torch", ".", "min", "(", "loss_set", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "min_loss", ",", "min_loss_indexes", ",", "parts", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.best_part_mixit_generalized": [[144, 195], ["mixit_wrapper.MixITLossWrapper.best_part_mixit_generalized.parts_mixit_gen"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "best_part_mixit_generalized", "(", "loss_func", ",", "est_targets", ",", "targets", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Find best partition of the estimated sources that gives the minimum\n        loss for the MixIT training paradigm in [1]. Valid only for two mixtures,\n        but those mixtures do not necessarly have to contain the same number of\n        sources e.g the case where one mixture is silent is allowed..\n\n        Args:\n            loss_func: function with signature ``(est_targets, targets, **kwargs)``\n                The loss function to get batch losses from.\n            est_targets: torch.Tensor. Expected shape :math:`(batch, nsrc, ...)`.\n                The batch of target estimates.\n            targets: torch.Tensor. Expected shape :math:`(batch, nmix, ...)`.\n                The batch of training targets (mixtures).\n            **kwargs: additional keyword argument that will be passed to the\n                loss function.\n\n        Returns:\n            - :class:`torch.Tensor`:\n              The loss corresponding to the best permutation of size (batch,).\n\n            - :class:`torch.LongTensor`:\n              The indexes of the best permutations.\n\n            - :class:`list`:\n              list of the possible partitions of the sources.\n        \"\"\"", "\n", "nmix", "=", "targets", ".", "shape", "[", "1", "]", "# number of mixtures", "\n", "nsrc", "=", "est_targets", ".", "shape", "[", "1", "]", "# number of estimated sources", "\n", "if", "nmix", "!=", "2", ":", "\n", "            ", "raise", "ValueError", "(", "\"Works only with two mixtures\"", ")", "\n", "\n", "# Generate all unique partitions of any size from a list lst of", "\n", "# length n. Algorithm recursively distributes items over parts", "\n", "", "def", "parts_mixit_gen", "(", "lst", ")", ":", "\n", "            ", "partitions", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "len", "(", "lst", ")", "+", "1", ")", ":", "\n", "                ", "for", "c", "in", "combinations", "(", "lst", ",", "k", ")", ":", "\n", "                    ", "rest", "=", "[", "x", "for", "x", "in", "lst", "if", "x", "not", "in", "c", "]", "\n", "partitions", ".", "append", "(", "[", "list", "(", "c", ")", ",", "rest", "]", ")", "\n", "", "", "return", "partitions", "\n", "\n", "# Generate all the possible partitions", "\n", "", "parts", "=", "parts_mixit_gen", "(", "range", "(", "nsrc", ")", ")", "\n", "# Compute the loss corresponding to each partition", "\n", "loss_set", "=", "MixITLossWrapper", ".", "loss_set_from_parts", "(", "\n", "loss_func", ",", "est_targets", "=", "est_targets", ",", "targets", "=", "targets", ",", "parts", "=", "parts", ",", "**", "kwargs", "\n", ")", "\n", "# Indexes and values of min losses for each batch element", "\n", "min_loss", ",", "min_loss_indexes", "=", "torch", ".", "min", "(", "loss_set", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "min_loss", ",", "min_loss_indexes", ",", "parts", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.loss_set_from_parts": [[196, 210], ["torch.cat", "torch.stack", "loss_func", "torch.cat.append", "ValueError", "est_targets[].sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "loss_set_from_parts", "(", "loss_func", ",", "est_targets", ",", "targets", ",", "parts", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Common loop between both best_part_mixit\"\"\"", "\n", "loss_set", "=", "[", "]", "\n", "for", "partition", "in", "parts", ":", "\n", "# sum the sources according to the given partition", "\n", "            ", "est_mixes", "=", "torch", ".", "stack", "(", "[", "est_targets", "[", ":", ",", "idx", ",", ":", "]", ".", "sum", "(", "1", ")", "for", "idx", "in", "partition", "]", ",", "dim", "=", "1", ")", "\n", "# get loss for the given partition", "\n", "loss_partition", "=", "loss_func", "(", "est_mixes", ",", "targets", ",", "**", "kwargs", ")", "\n", "if", "loss_partition", ".", "ndim", "!=", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\"Loss function return value should be of size (batch,).\"", ")", "\n", "", "loss_set", ".", "append", "(", "loss_partition", "[", ":", ",", "None", "]", ")", "\n", "", "loss_set", "=", "torch", ".", "cat", "(", "loss_set", ",", "dim", "=", "1", ")", "\n", "return", "loss_set", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.reorder_source": [[211, 237], ["torch.zeros_like", "enumerate", "torch.stack", "[].sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "reorder_source", "(", "est_targets", ",", "targets", ",", "min_loss_idx", ",", "parts", ")", ":", "\n", "        ", "\"\"\"Reorder sources according to the best partition.\n\n        Args:\n            est_targets: torch.Tensor. Expected shape :math:`(batch, nsrc, ...)`.\n                The batch of target estimates.\n            targets: torch.Tensor. Expected shape :math:`(batch, nmix, ...)`.\n                The batch of training targets.\n            min_loss_idx: torch.LongTensor. The indexes of the best permutations.\n            parts: list of the possible partitions of the sources.\n\n        Returns:\n            :class:`torch.Tensor`: Reordered sources of shape :math:`(batch, nmix, time)`.\n\n        \"\"\"", "\n", "# For each batch there is a different min_loss_idx", "\n", "ordered", "=", "torch", ".", "zeros_like", "(", "targets", ")", "\n", "for", "b", ",", "idx", "in", "enumerate", "(", "min_loss_idx", ")", ":", "\n", "            ", "right_partition", "=", "parts", "[", "idx", "]", "\n", "# Sum the estimated sources to get the estimated mixtures", "\n", "ordered", "[", "b", ",", ":", ",", ":", "]", "=", "torch", ".", "stack", "(", "\n", "[", "est_targets", "[", "b", ",", "idx", ",", ":", "]", "[", "None", ",", ":", ",", ":", "]", ".", "sum", "(", "1", ")", "for", "idx", "in", "right_partition", "]", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "", "return", "ordered", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.loss_functions_test.assert_loss_checks_shape": [[14, 46], ["loss_functions_test.assert_loss_checks_shape._test"], "function", ["None"], ["def", "assert_loss_checks_shape", "(", "loss_func", ",", "shape", ",", "arbitrary_last_dim", "=", "False", ",", "no_batch_ok", "=", "False", ")", ":", "\n", "    ", "\"\"\"Test that `loss_func` raises a TypeError if you are passing anything that isn't of the expected shape.\n\n    Args:\n        loss_func (callable): The loss to check, signature: `loss_func(x, y) -> Any`\n        shape (tuple): Shape that the loss is expected to accept (without batch dimension).\n        arbitrary_last_dim (bool, optional): Whether the last dimension may be replaced by any number of dimensions.\n        no_batch_ok (bool, optional): Whether having no batch dimension is acceptable.\n    \"\"\"", "\n", "\n", "def", "_test", "(", "shape", ")", ":", "\n", "        ", "loss_func", "(", "torch", ".", "randn", "(", "shape", ")", ",", "torch", ".", "randn", "(", "shape", ")", ")", "\n", "\n", "", "batch_size", "=", "5", "\n", "\n", "# Check that given shape works.", "\n", "_test", "(", "(", "batch_size", ",", "*", "shape", ")", ")", "\n", "\n", "if", "not", "no_batch_ok", ":", "\n", "# Should fail without batch dim.", "\n", "        ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "            ", "_test", "(", "shape", ")", "\n", "\n", "", "", "if", "arbitrary_last_dim", ":", "\n", "# Last dim can be arbitrary", "\n", "        ", "_test", "(", "(", "batch_size", ",", "*", "shape", ",", "4", ")", ")", "\n", "_test", "(", "(", "batch_size", ",", "*", "shape", ",", "4", ",", "5", ")", ")", "\n", "", "else", ":", "\n", "# Random unsqueezes should fail.", "\n", "        ", "for", "dim", "in", "range", "(", "len", "(", "shape", ")", ")", ":", "\n", "            ", "with", "pytest", ".", "raises", "(", "TypeError", ")", ":", "\n", "                ", "_test", "(", "(", "batch_size", ",", "*", "shape", "[", ":", "dim", "]", ",", "1", ",", "*", "shape", "[", "dim", ":", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.loss_functions_test.test_sisdr_and_mse": [[57, 82], ["pytest.mark.parametrize", "pytest.mark.parametrize", "torch.randn", "torch.randn", "asteroid.losses.PITLossWrapper", "asteroid.losses.PITLossWrapper", "asteroid.losses.PITLossWrapper", "torch.testing.assert_allclose", "torch.testing.assert_allclose", "torch.testing.assert_allclose", "torch.testing.assert_allclose", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper."], "function", ["None"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "2", ",", "3", ",", "4", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"loss\"", ",", "loss_properties", ")", "\n", "def", "test_sisdr_and_mse", "(", "n_src", ",", "loss", ")", ":", "\n", "# Unpack the triplet", "\n", "    ", "pairwise", ",", "singlesrc", ",", "multisrc", ",", "_", "=", "loss", "\n", "# Fake targets and estimates", "\n", "targets", "=", "torch", ".", "randn", "(", "2", ",", "n_src", ",", "10000", ")", "\n", "est_targets", "=", "torch", ".", "randn", "(", "2", ",", "n_src", ",", "10000", ")", "\n", "# Create the 3 PIT wrappers", "\n", "pw_wrapper", "=", "PITLossWrapper", "(", "pairwise", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "wo_src_wrapper", "=", "PITLossWrapper", "(", "singlesrc", ",", "pit_from", "=", "\"pw_pt\"", ")", "\n", "w_src_wrapper", "=", "PITLossWrapper", "(", "multisrc", ",", "pit_from", "=", "\"perm_avg\"", ")", "\n", "\n", "# Circular tests on value", "\n", "assert_allclose", "(", "pw_wrapper", "(", "est_targets", ",", "targets", ")", ",", "wo_src_wrapper", "(", "est_targets", ",", "targets", ")", ")", "\n", "assert_allclose", "(", "wo_src_wrapper", "(", "est_targets", ",", "targets", ")", ",", "w_src_wrapper", "(", "est_targets", ",", "targets", ")", ")", "\n", "\n", "# Circular tests on returned estimates", "\n", "assert_allclose", "(", "\n", "pw_wrapper", "(", "est_targets", ",", "targets", ",", "return_est", "=", "True", ")", "[", "1", "]", ",", "\n", "wo_src_wrapper", "(", "est_targets", ",", "targets", ",", "return_est", "=", "True", ")", "[", "1", "]", ",", "\n", ")", "\n", "assert_allclose", "(", "\n", "wo_src_wrapper", "(", "est_targets", ",", "targets", ",", "return_est", "=", "True", ")", "[", "1", "]", ",", "\n", "w_src_wrapper", "(", "est_targets", ",", "targets", ",", "return_est", "=", "True", ")", "[", "1", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.loss_functions_test.test_sisdr_and_mse_shape_checks": [[85, 94], ["pytest.mark.parametrize", "loss_functions_test.assert_loss_checks_shape", "loss_functions_test.assert_loss_checks_shape", "loss_functions_test.assert_loss_checks_shape"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.loss_functions_test.assert_loss_checks_shape", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.loss_functions_test.assert_loss_checks_shape", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.loss_functions_test.assert_loss_checks_shape"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"loss\"", ",", "loss_properties", ")", "\n", "def", "test_sisdr_and_mse_shape_checks", "(", "loss", ")", ":", "\n", "    ", "pairwise", ",", "singlesrc", ",", "multisrc", ",", "arbitrary_last_dim", "=", "loss", "\n", "assert_loss_checks_shape", "(", "pairwise", ",", "(", "3", ",", "1000", ")", ",", "arbitrary_last_dim", ")", "\n", "assert_loss_checks_shape", "(", "singlesrc", ",", "(", "1000", ",", ")", ",", "arbitrary_last_dim", ")", "\n", "# Special case for multisrc_mse that shares the same code with", "\n", "# singlesrc_mse and thus accepts 1-dim tensors.", "\n", "no_batch_ok", "=", "multisrc", "==", "mse", ".", "multisrc_mse", "\n", "assert_loss_checks_shape", "(", "multisrc", ",", "(", "3", ",", "1000", ")", ",", "arbitrary_last_dim", ",", "no_batch_ok", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.loss_functions_test.test_dc": [[96, 102], ["pytest.mark.parametrize", "torch.randn", "torch.zeros().random_().long", "asteroid.losses.deep_clustering_loss", "torch.zeros().random_", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.cluster.deep_clustering_loss"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"spk_cnt\"", ",", "[", "2", ",", "3", ",", "4", "]", ")", "\n", "def", "test_dc", "(", "spk_cnt", ")", ":", "\n", "    ", "embedding", "=", "torch", ".", "randn", "(", "10", ",", "5", "*", "400", ",", "20", ")", "\n", "targets", "=", "torch", ".", "zeros", "(", "10", ",", "400", ",", "5", ")", ".", "random_", "(", "0", ",", "spk_cnt", ")", ".", "long", "(", ")", "\n", "loss", "=", "deep_clustering_loss", "(", "embedding", ",", "targets", ")", "\n", "assert", "loss", ".", "shape", "[", "0", "]", "==", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.loss_functions_test.test_multi_scale_spectral_PIT": [[104, 119], ["pytest.mark.parametrize", "torch.randn", "torch.randn", "asteroid.losses.multi_scale_spectral.SingleSrcMultiScaleSpectral", "asteroid.losses.PITLossWrapper", "asteroid.losses.PITLossWrapper."], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "2", ",", "3", "]", ")", "\n", "def", "test_multi_scale_spectral_PIT", "(", "n_src", ")", ":", "\n", "# Test in with reduced number of STFT scales.", "\n", "    ", "filt_list", "=", "[", "512", ",", "256", ",", "32", "]", "\n", "# Fake targets and estimates", "\n", "targets", "=", "torch", ".", "randn", "(", "2", ",", "n_src", ",", "8000", ")", "\n", "est_targets", "=", "torch", ".", "randn", "(", "2", ",", "n_src", ",", "8000", ")", "\n", "# Create PITLossWrapper in 'pw_pt' mode", "\n", "pt_loss", "=", "SingleSrcMultiScaleSpectral", "(", "\n", "windows_size", "=", "filt_list", ",", "n_filters", "=", "filt_list", ",", "hops_size", "=", "filt_list", "\n", ")", "\n", "\n", "loss_func", "=", "PITLossWrapper", "(", "pt_loss", ",", "pit_from", "=", "\"pw_pt\"", ")", "\n", "# Compute the loss", "\n", "loss_func", "(", "targets", ",", "est_targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.loss_functions_test.test_multi_scale_spectral_shape": [[121, 135], ["pytest.mark.parametrize", "torch.randn", "torch.randn", "asteroid.losses.multi_scale_spectral.SingleSrcMultiScaleSpectral", "asteroid.losses.multi_scale_spectral.SingleSrcMultiScaleSpectral."], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", "]", ")", "\n", "def", "test_multi_scale_spectral_shape", "(", "batch_size", ")", ":", "\n", "# Test in with reduced number of STFT scales.", "\n", "    ", "filt_list", "=", "[", "512", ",", "256", ",", "32", "]", "\n", "# Fake targets and estimates", "\n", "targets", "=", "torch", ".", "randn", "(", "batch_size", ",", "8000", ")", "\n", "est_targets", "=", "torch", ".", "randn", "(", "batch_size", ",", "8000", ")", "\n", "# Create PITLossWrapper in 'pw_pt' mode", "\n", "loss_func", "=", "SingleSrcMultiScaleSpectral", "(", "\n", "windows_size", "=", "filt_list", ",", "n_filters", "=", "filt_list", ",", "hops_size", "=", "filt_list", "\n", ")", "\n", "# Compute the loss", "\n", "loss", "=", "loss_func", "(", "targets", ",", "est_targets", ")", "\n", "assert", "loss", ".", "shape", "[", "0", "]", "==", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.loss_functions_test.test_pmsqe": [[137, 155], ["pytest.mark.parametrize", "asteroid_filterbanks.transforms.mag", "asteroid_filterbanks.transforms.mag", "asteroid.losses.SingleSrcPMSQE", "asteroid.losses.SingleSrcPMSQE.", "asteroid.losses.SingleSrcPMSQE.", "torch.testing.assert_allclose", "asteroid_filterbanks.Encoder", "asteroid_filterbanks.Encoder", "torch.randn", "torch.randn", "asteroid_filterbanks.Encoder.", "asteroid_filterbanks.Encoder.", "transforms.mag.transpose", "transforms.mag.transpose", "asteroid_filterbanks.STFTFB", "asteroid_filterbanks.STFTFB"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"sample_rate\"", ",", "[", "8000", ",", "16000", "]", ")", "\n", "def", "test_pmsqe", "(", "sample_rate", ")", ":", "\n", "# Define supported STFT", "\n", "    ", "if", "sample_rate", "==", "16000", ":", "\n", "        ", "stft", "=", "Encoder", "(", "STFTFB", "(", "kernel_size", "=", "512", ",", "n_filters", "=", "512", ",", "stride", "=", "256", ")", ")", "\n", "", "else", ":", "\n", "        ", "stft", "=", "Encoder", "(", "STFTFB", "(", "kernel_size", "=", "256", ",", "n_filters", "=", "256", ",", "stride", "=", "128", ")", ")", "\n", "# Usage by itself", "\n", "", "ref", ",", "est", "=", "torch", ".", "randn", "(", "2", ",", "1", ",", "16000", ")", ",", "torch", ".", "randn", "(", "2", ",", "1", ",", "16000", ")", "\n", "ref_spec", "=", "transforms", ".", "mag", "(", "stft", "(", "ref", ")", ")", "\n", "est_spec", "=", "transforms", ".", "mag", "(", "stft", "(", "est", ")", ")", "\n", "loss_func", "=", "SingleSrcPMSQE", "(", "sample_rate", "=", "sample_rate", ")", "\n", "loss_value", "=", "loss_func", "(", "est_spec", ",", "ref_spec", ")", "\n", "# Assert output has shape (batch,)", "\n", "assert", "loss_value", ".", "shape", "[", "0", "]", "==", "ref", ".", "shape", "[", "0", "]", "\n", "# Assert support for transposed inputs.", "\n", "tr_loss_value", "=", "loss_func", "(", "est_spec", ".", "transpose", "(", "1", ",", "2", ")", ",", "ref_spec", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "assert_allclose", "(", "loss_value", ",", "tr_loss_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.loss_functions_test.test_pmsqe_pit": [[157, 172], ["pytest.mark.parametrize", "pytest.mark.parametrize", "asteroid_filterbanks.transforms.mag", "asteroid_filterbanks.transforms.mag", "asteroid.losses.PITLossWrapper", "asteroid.losses.PITLossWrapper.", "asteroid_filterbanks.Encoder", "asteroid_filterbanks.Encoder", "torch.randn", "torch.randn", "asteroid_filterbanks.Encoder.", "asteroid_filterbanks.Encoder.", "asteroid.losses.SingleSrcPMSQE", "asteroid_filterbanks.STFTFB", "asteroid_filterbanks.STFTFB"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "2", ",", "3", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"sample_rate\"", ",", "[", "8000", ",", "16000", "]", ")", "\n", "def", "test_pmsqe_pit", "(", "n_src", ",", "sample_rate", ")", ":", "\n", "# Define supported STFT", "\n", "    ", "if", "sample_rate", "==", "16000", ":", "\n", "        ", "stft", "=", "Encoder", "(", "STFTFB", "(", "kernel_size", "=", "512", ",", "n_filters", "=", "512", ",", "stride", "=", "256", ")", ")", "\n", "", "else", ":", "\n", "        ", "stft", "=", "Encoder", "(", "STFTFB", "(", "kernel_size", "=", "256", ",", "n_filters", "=", "256", ",", "stride", "=", "128", ")", ")", "\n", "# Usage by itself", "\n", "", "ref", ",", "est", "=", "torch", ".", "randn", "(", "2", ",", "n_src", ",", "16000", ")", ",", "torch", ".", "randn", "(", "2", ",", "n_src", ",", "16000", ")", "\n", "ref_spec", "=", "transforms", ".", "mag", "(", "stft", "(", "ref", ")", ")", "\n", "est_spec", "=", "transforms", ".", "mag", "(", "stft", "(", "est", ")", ")", "\n", "loss_func", "=", "PITLossWrapper", "(", "SingleSrcPMSQE", "(", "sample_rate", "=", "sample_rate", ")", ",", "pit_from", "=", "\"pw_pt\"", ")", "\n", "# Assert forward ok.", "\n", "loss_func", "(", "est_spec", ",", "ref_spec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.loss_functions_test.test_negstoi_pit": [[174, 188], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "asteroid.losses.SingleSrcNegSTOI", "asteroid.losses.PITLossWrapper", "torch.randn", "torch.randn", "warnings.catch_warnings", "warnings.simplefilter", "asteroid.losses.PITLossWrapper."], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "2", ",", "3", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"sample_rate\"", ",", "[", "8000", ",", "16000", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"use_vad\"", ",", "[", "True", ",", "False", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"extended\"", ",", "[", "True", ",", "False", "]", ")", "\n", "def", "test_negstoi_pit", "(", "n_src", ",", "sample_rate", ",", "use_vad", ",", "extended", ")", ":", "\n", "    ", "ref", ",", "est", "=", "torch", ".", "randn", "(", "2", ",", "n_src", ",", "8000", ")", ",", "torch", ".", "randn", "(", "2", ",", "n_src", ",", "8000", ")", "\n", "singlesrc_negstoi", "=", "SingleSrcNegSTOI", "(", "\n", "sample_rate", "=", "sample_rate", ",", "use_vad", "=", "use_vad", ",", "extended", "=", "extended", "\n", ")", "\n", "loss_func", "=", "PITLossWrapper", "(", "singlesrc_negstoi", ",", "pit_from", "=", "\"pw_pt\"", ")", "\n", "# Assert forward ok.", "\n", "with", "warnings", ".", "catch_warnings", "(", ")", ":", "\n", "        ", "warnings", ".", "simplefilter", "(", "\"ignore\"", ")", "\n", "loss_func", "(", "est", ",", "ref", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper_test.bad_loss_func_ndim0": [[9, 11], ["torch.randn().mean", "torch.randn"], "function", ["None"], ["def", "bad_loss_func_ndim0", "(", "y_pred", ",", "y_true", ")", ":", "\n", "    ", "return", "torch", ".", "randn", "(", "1", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper_test.bad_loss_func_ndim1": [[13, 15], ["torch.randn"], "function", ["None"], ["", "def", "bad_loss_func_ndim1", "(", "y_pred", ",", "y_true", ")", ":", "\n", "    ", "return", "torch", ".", "randn", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper_test.good_batch_loss_func": [[17, 20], ["torch.randn"], "function", ["None"], ["", "def", "good_batch_loss_func", "(", "y_pred", ",", "y_true", ")", ":", "\n", "    ", "batch", ",", "*", "_", "=", "y_true", ".", "shape", "\n", "return", "torch", ".", "randn", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper_test.good_pairwise_loss_func": [[22, 25], ["torch.randn"], "function", ["None"], ["", "def", "good_pairwise_loss_func", "(", "y_pred", ",", "y_true", ")", ":", "\n", "    ", "batch", ",", "n_src", ",", "*", "_", "=", "y_true", ".", "shape", "\n", "return", "torch", ".", "randn", "(", "batch", ",", "n_src", ",", "n_src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper_test.test_wrapper": [[27, 54], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.randn", "torch.randn", "asteroid.losses.PITLossWrapper", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper", "pytest.raises", "asteroid.losses.PITLossWrapper."], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", ",", "8", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "2", ",", "3", ",", "4", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"time\"", ",", "[", "16000", ",", "1221", "]", ")", "\n", "def", "test_wrapper", "(", "batch_size", ",", "n_src", ",", "time", ")", ":", "\n", "    ", "targets", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_src", ",", "time", ")", "\n", "est_targets", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_src", ",", "time", ")", "\n", "for", "bad_loss_func", "in", "[", "bad_loss_func_ndim0", ",", "bad_loss_func_ndim1", "]", ":", "\n", "        ", "loss", "=", "PITLossWrapper", "(", "bad_loss_func", ")", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "            ", "loss", "(", "est_targets", ",", "targets", ")", "\n", "# wo_src loss function / With and without return estimates", "\n", "", "", "loss", "=", "PITLossWrapper", "(", "good_batch_loss_func", ",", "pit_from", "=", "\"pw_pt\"", ")", "\n", "loss", "(", "est_targets", ",", "targets", ")", "\n", "loss_value", ",", "reordered_est", "=", "loss", "(", "est_targets", ",", "targets", ",", "return_est", "=", "True", ")", "\n", "assert", "reordered_est", ".", "shape", "==", "est_targets", ".", "shape", "\n", "\n", "# pairwise loss function / With and without return estimates", "\n", "loss", "=", "PITLossWrapper", "(", "good_pairwise_loss_func", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "loss", "(", "est_targets", ",", "targets", ")", "\n", "loss_value", ",", "reordered_est", "=", "loss", "(", "est_targets", ",", "targets", ",", "return_est", "=", "True", ")", "\n", "assert", "reordered_est", ".", "shape", "==", "est_targets", ".", "shape", "\n", "\n", "# w_src loss function / With and without return estimates", "\n", "loss", "=", "PITLossWrapper", "(", "good_batch_loss_func", ",", "pit_from", "=", "\"perm_avg\"", ")", "\n", "loss", "(", "est_targets", ",", "targets", ")", "\n", "loss_value", ",", "reordered_est", "=", "loss", "(", "est_targets", ",", "targets", ",", "return_est", "=", "True", ")", "\n", "assert", "reordered_est", ".", "shape", "==", "est_targets", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper_test.test_permutation": [[56, 75], ["pytest.mark.parametrize", "len", "torch.Tensor", "torch.ones", "asteroid.losses.PITLossWrapper", "asteroid.losses.PITLossWrapper.", "torch.testing.assert_allclose", "torch.arange().unsqueeze", "torch.Tensor.unsqueeze", "loss_value.item", "list", "list", "list", "itertools.permutations", "torch.arange", "itertools.permutations", "itertools.permutations"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"perm\"", ",", "\n", "list", "(", "itertools", ".", "permutations", "(", "[", "0", ",", "1", ",", "2", "]", ")", ")", "\n", "+", "list", "(", "itertools", ".", "permutations", "(", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", ")", "\n", "+", "list", "(", "itertools", ".", "permutations", "(", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ")", ")", ",", "\n", ")", "\n", "def", "test_permutation", "(", "perm", ")", ":", "\n", "    ", "\"\"\"Construct fake target/estimates pair. Check the value and reordering.\"\"\"", "\n", "n_src", "=", "len", "(", "perm", ")", "\n", "perm_tensor", "=", "torch", ".", "Tensor", "(", "perm", ")", "\n", "source_base", "=", "torch", ".", "ones", "(", "1", ",", "n_src", ",", "10", ")", "\n", "sources", "=", "torch", ".", "arange", "(", "n_src", ")", ".", "unsqueeze", "(", "-", "1", ")", "*", "source_base", "\n", "est_sources", "=", "perm_tensor", ".", "unsqueeze", "(", "-", "1", ")", "*", "source_base", "\n", "\n", "loss_func", "=", "PITLossWrapper", "(", "pairwise_mse", ")", "\n", "loss_value", ",", "reordered", "=", "loss_func", "(", "est_sources", ",", "sources", ",", "return_est", "=", "True", ")", "\n", "\n", "assert", "loss_value", ".", "item", "(", ")", "==", "0", "\n", "assert_allclose", "(", "sources", ",", "reordered", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper_test.test_permreduce": [[77, 100], ["torch.randn", "torch.randn", "asteroid.losses.PITLossWrapper", "asteroid.losses.PITLossWrapper", "asteroid.losses.PITLossWrapper", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper.", "asteroid.losses.PITLossWrapper.", "torch.testing.assert_allclose", "torch.testing.assert_allclose", "partial", "torch.mean"], "function", ["None"], ["", "def", "test_permreduce", "(", ")", ":", "\n", "    ", "from", "functools", "import", "partial", "\n", "\n", "n_src", "=", "3", "\n", "sources", "=", "torch", ".", "randn", "(", "10", ",", "n_src", ",", "8000", ")", "\n", "est_sources", "=", "torch", ".", "randn", "(", "10", ",", "n_src", ",", "8000", ")", "\n", "wo_reduce", "=", "PITLossWrapper", "(", "pairwise_mse", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "w_mean_reduce", "=", "PITLossWrapper", "(", "\n", "pairwise_mse", ",", "\n", "pit_from", "=", "\"pw_mtx\"", ",", "\n", "# perm_reduce=partial(torch.mean, dim=-1))", "\n", "perm_reduce", "=", "lambda", "x", ":", "torch", ".", "mean", "(", "x", ",", "dim", "=", "-", "1", ")", ",", "\n", ")", "\n", "w_sum_reduce", "=", "PITLossWrapper", "(", "\n", "pairwise_mse", ",", "pit_from", "=", "\"pw_mtx\"", ",", "perm_reduce", "=", "partial", "(", "torch", ".", "sum", ",", "dim", "=", "-", "1", ")", "\n", ")", "\n", "\n", "wo", "=", "wo_reduce", "(", "est_sources", ",", "sources", ")", "\n", "w_mean", "=", "w_mean_reduce", "(", "est_sources", ",", "sources", ")", "\n", "w_sum", "=", "w_sum_reduce", "(", "est_sources", ",", "sources", ")", "\n", "\n", "assert_allclose", "(", "wo", ",", "w_mean", ")", "\n", "assert_allclose", "(", "wo", ",", "w_sum", "/", "n_src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper_test.test_permreduce_args": [[102, 117], ["torch.randn", "torch.randn", "asteroid.losses.PITLossWrapper", "torch.softmax", "asteroid.losses.PITLossWrapper.", "torch.mean", "torch.randn", "torch.mean", "class_weights.unsqueeze.unsqueeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax"], ["", "def", "test_permreduce_args", "(", ")", ":", "\n", "    ", "def", "reduce_func", "(", "perm_losses", ",", "class_weights", "=", "None", ")", ":", "\n", "# perm_losses is (batch , n_perms, n_src) for now", "\n", "        ", "if", "class_weights", "is", "None", ":", "\n", "            ", "return", "torch", ".", "mean", "(", "perm_losses", ",", "dim", "=", "-", "1", ")", "\n", "", "if", "class_weights", ".", "ndim", "==", "2", ":", "\n", "            ", "class_weights", "=", "class_weights", ".", "unsqueeze", "(", "1", ")", "\n", "", "return", "torch", ".", "mean", "(", "perm_losses", "*", "class_weights", ",", "-", "1", ")", "\n", "\n", "", "n_src", "=", "3", "\n", "sources", "=", "torch", ".", "randn", "(", "10", ",", "n_src", ",", "8000", ")", "\n", "est_sources", "=", "torch", ".", "randn", "(", "10", ",", "n_src", ",", "8000", ")", "\n", "loss_func", "=", "PITLossWrapper", "(", "pairwise_mse", ",", "pit_from", "=", "\"pw_mtx\"", ",", "perm_reduce", "=", "reduce_func", ")", "\n", "weights", "=", "torch", ".", "softmax", "(", "torch", ".", "randn", "(", "10", ",", "n_src", ")", ",", "dim", "=", "-", "1", ")", "\n", "loss_func", "(", "est_sources", ",", "sources", ",", "reduce_kwargs", "=", "{", "\"class_weights\"", ":", "weights", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper_test.test_best_perm_match": [[119, 128], ["pytest.mark.parametrize", "torch.randn", "asteroid.losses.PITLossWrapper.find_best_perm_factorial", "asteroid.losses.PITLossWrapper.find_best_perm_hungarian", "torch.testing.assert_allclose", "torch.testing.assert_allclose"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.find_best_perm_factorial", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.find_best_perm_hungarian"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "2", ",", "4", ",", "5", ",", "6", ",", "8", "]", ")", "\n", "def", "test_best_perm_match", "(", "n_src", ")", ":", "\n", "    ", "pwl", "=", "torch", ".", "randn", "(", "2", ",", "n_src", ",", "n_src", ")", "\n", "\n", "min_loss", ",", "min_idx", "=", "PITLossWrapper", ".", "find_best_perm_factorial", "(", "pwl", ")", "\n", "min_loss_hun", ",", "min_idx_hun", "=", "PITLossWrapper", ".", "find_best_perm_hungarian", "(", "pwl", ")", "\n", "\n", "assert_allclose", "(", "min_loss", ",", "min_loss_hun", ")", "\n", "assert_allclose", "(", "min_idx", ",", "min_idx_hun", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper_test.test_raises_wrong_pit_from": [[130, 133], ["pytest.raises", "asteroid.losses.PITLossWrapper"], "function", ["None"], ["", "def", "test_raises_wrong_pit_from", "(", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "PITLossWrapper", "(", "lambda", "x", ":", "x", ",", "pit_from", "=", "\"unknown_mode\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper_test._TestCallback.__init__": [[97, 101], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "function", ",", "total", ",", "batch_size", ")", ":", "\n", "        ", "self", ".", "f", "=", "function", "\n", "self", ".", "epoch", "=", "0", "\n", "self", ".", "n_batch", "=", "total", "//", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper_test._TestCallback.on_batch_end": [[102, 106], ["None"], "methods", ["None"], ["", "def", "on_batch_end", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "step", "=", "trainer", ".", "global_step", "\n", "assert", "self", ".", "epoch", "*", "self", ".", "n_batch", "<=", "step", "\n", "assert", "step", "<=", "(", "self", ".", "epoch", "+", "1", ")", "*", "self", ".", "n_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper_test._TestCallback.on_train_epoch_end": [[107, 112], ["sinkpit_wrapper_test._TestCallback.f"], "methods", ["None"], ["", "def", "on_train_epoch_end", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "epoch", "=", "trainer", ".", "current_epoch", "\n", "assert", "epoch", "==", "self", ".", "epoch", "\n", "assert", "pl_module", ".", "loss_func", ".", "beta", "==", "self", ".", "f", "(", "epoch", ")", "\n", "self", ".", "epoch", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper_test.bad_loss_func_ndim0": [[22, 24], ["torch.randn().mean", "torch.randn"], "function", ["None"], ["def", "bad_loss_func_ndim0", "(", "y_pred", ",", "y_true", ")", ":", "\n", "    ", "return", "torch", ".", "randn", "(", "1", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper_test.bad_loss_func_ndim1": [[26, 28], ["torch.randn"], "function", ["None"], ["", "def", "bad_loss_func_ndim1", "(", "y_pred", ",", "y_true", ")", ":", "\n", "    ", "return", "torch", ".", "randn", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper_test.good_batch_loss_func": [[30, 33], ["torch.randn"], "function", ["None"], ["", "def", "good_batch_loss_func", "(", "y_pred", ",", "y_true", ")", ":", "\n", "    ", "batch", ",", "*", "_", "=", "y_true", ".", "shape", "\n", "return", "torch", ".", "randn", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper_test.good_pairwise_loss_func": [[35, 38], ["torch.randn"], "function", ["None"], ["", "def", "good_pairwise_loss_func", "(", "y_pred", ",", "y_true", ")", ":", "\n", "    ", "batch", ",", "n_src", ",", "*", "_", "=", "y_true", ".", "shape", "\n", "return", "torch", ".", "randn", "(", "batch", ",", "n_src", ",", "n_src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper_test.test_wrapper": [[40, 55], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.randn", "torch.randn", "asteroid.losses.SinkPITLossWrapper", "asteroid.losses.SinkPITLossWrapper.", "asteroid.losses.SinkPITLossWrapper.", "asteroid.losses.SinkPITLossWrapper", "pytest.raises", "asteroid.losses.SinkPITLossWrapper."], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", ",", "8", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "2", ",", "5", ",", "10", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"time\"", ",", "[", "16000", ",", "1221", "]", ")", "\n", "def", "test_wrapper", "(", "batch_size", ",", "n_src", ",", "time", ")", ":", "\n", "    ", "targets", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_src", ",", "time", ")", "\n", "est_targets", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_src", ",", "time", ")", "\n", "for", "bad_loss_func", "in", "[", "bad_loss_func_ndim0", ",", "bad_loss_func_ndim1", "]", ":", "\n", "        ", "loss", "=", "SinkPITLossWrapper", "(", "bad_loss_func", ")", "\n", "with", "pytest", ".", "raises", "(", "AssertionError", ")", ":", "\n", "            ", "loss", "(", "est_targets", ",", "targets", ")", "\n", "\n", "", "", "loss", "=", "SinkPITLossWrapper", "(", "good_pairwise_loss_func", ")", "\n", "loss", "(", "est_targets", ",", "targets", ")", "\n", "loss_value", ",", "reordered_est", "=", "loss", "(", "est_targets", ",", "targets", ",", "return_est", "=", "True", ")", "\n", "assert", "reordered_est", ".", "shape", "==", "est_targets", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper_test.test_proximity_sinkhorn_hungarian": [[57, 94], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "asteroid.losses.SinkPITLossWrapper", "asteroid.losses.PITLossWrapper", "asteroid.losses.SinkPITLossWrapper.", "asteroid.losses.PITLossWrapper.", "torch.testing.assert_allclose", "torch.randn", "torch.randn", "torch.randperm"], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "2", ",", "3", ",", "4", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"beta,n_iter\"", ",", "[", "(", "100.0", ",", "2000", ")", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"function_triplet\"", ",", "\n", "[", "\n", "[", "sdr", ".", "pairwise_neg_sisdr", ",", "sdr", ".", "singlesrc_neg_sisdr", ",", "sdr", ".", "multisrc_neg_sisdr", "]", ",", "\n", "[", "sdr", ".", "pairwise_neg_sdsdr", ",", "sdr", ".", "singlesrc_neg_sdsdr", ",", "sdr", ".", "multisrc_neg_sdsdr", "]", ",", "\n", "[", "sdr", ".", "pairwise_neg_snr", ",", "sdr", ".", "singlesrc_neg_snr", ",", "sdr", ".", "multisrc_neg_snr", "]", ",", "\n", "[", "pairwise_mse", ",", "singlesrc_mse", ",", "multisrc_mse", "]", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_proximity_sinkhorn_hungarian", "(", "batch_size", ",", "n_src", ",", "beta", ",", "n_iter", ",", "function_triplet", ")", ":", "\n", "    ", "time", "=", "16000", "\n", "noise_level", "=", "0.1", "\n", "pairwise", ",", "nosrc", ",", "nonpit", "=", "function_triplet", "\n", "\n", "# random data", "\n", "targets", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_src", ",", "time", ")", "*", "10", "# ground truth", "\n", "noise", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_src", ",", "time", ")", "*", "noise_level", "\n", "est_targets", "=", "(", "\n", "targets", "[", ":", ",", "torch", ".", "randperm", "(", "n_src", ")", ",", ":", "]", "+", "noise", "\n", ")", "# reorder channels, and add small noise", "\n", "\n", "# initialize wrappers", "\n", "loss_sinkhorn", "=", "SinkPITLossWrapper", "(", "pairwise", ",", "n_iter", "=", "n_iter", ")", "\n", "loss_hungarian", "=", "PITLossWrapper", "(", "pairwise", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "\n", "# compute loss by sinkhorn", "\n", "loss_sinkhorn", ".", "beta", "=", "beta", "\n", "mean_loss_sinkhorn", "=", "loss_sinkhorn", "(", "est_targets", ",", "targets", ",", "return_est", "=", "False", ")", "\n", "\n", "# compute loss by hungarian", "\n", "mean_loss_hungarian", "=", "loss_hungarian", "(", "est_targets", ",", "targets", ",", "return_est", "=", "False", ")", "\n", "\n", "# compare", "\n", "assert_allclose", "(", "mean_loss_sinkhorn", ",", "mean_loss_hungarian", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.sinkpit_wrapper_test.test_sinkpit_beta_scheduler": [[114, 152], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.nn.Sequential", "torch.optim.Adam", "asteroid.utils.test_utils.DummyWaveformDataset", "torch.utils.data.DataLoader", "asteroid.engine.system.System", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.nn.Conv1d", "torch.nn.ReLU", "nn.Sequential.parameters", "asteroid.losses.SinkPITLossWrapper", "asteroid.engine.schedulers.SinkPITBetaScheduler", "sinkpit_wrapper_test._TestCallback", "len"], "function", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "2", ",", "10", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"len_wave\"", ",", "[", "100", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"beta_schedule\"", ",", "\n", "[", "\n", "sinkpit_default_beta_schedule", ",", "# default", "\n", "lambda", "epoch", ":", "123.0", "if", "epoch", "<", "3", "else", "456.0", ",", "# test if lambda function works", "\n", "]", ",", "\n", ")", "\n", "def", "test_sinkpit_beta_scheduler", "(", "batch_size", ",", "n_src", ",", "len_wave", ",", "beta_schedule", ")", ":", "\n", "    ", "model", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv1d", "(", "1", ",", "n_src", ",", "1", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "dataset", "=", "DummyWaveformDataset", "(", "total", "=", "2", "*", "batch_size", ",", "n_src", "=", "n_src", ",", "len_wave", "=", "len_wave", ")", "\n", "loader", "=", "data", ".", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "batch_size", ",", "num_workers", "=", "0", "\n", ")", "# num_workers=0 means doing everything in the main process without calling subprocesses", "\n", "\n", "system", "=", "System", "(", "\n", "model", ",", "\n", "optimizer", ",", "\n", "loss_func", "=", "SinkPITLossWrapper", "(", "sdr", ".", "pairwise_neg_sisdr", ",", "n_iter", "=", "5", ")", ",", "\n", "train_loader", "=", "loader", ",", "\n", "val_loader", "=", "loader", ",", "\n", ")", "\n", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "10", ",", "\n", "fast_dev_run", "=", "False", ",", "\n", "callbacks", "=", "[", "\n", "SinkPITBetaScheduler", "(", "beta_schedule", ")", ",", "\n", "_TestCallback", "(", "\n", "beta_schedule", ",", "len", "(", "dataset", ")", ",", "batch_size", "\n", ")", ",", "# test if beta are the same at epoch_start and epoch_end.", "\n", "]", ",", "\n", ")", "\n", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper_test.good_batch_loss_func": [[8, 11], ["torch.randn"], "function", ["None"], ["def", "good_batch_loss_func", "(", "y_pred", ",", "y_true", ")", ":", "\n", "    ", "batch", ",", "*", "_", "=", "y_true", ".", "shape", "\n", "return", "torch", ".", "randn", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper_test.test_mixitwrapper_as_pit_wrapper": [[13, 25], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.randn", "torch.randn", "asteroid.losses.MixITLossWrapper", "asteroid.losses.MixITLossWrapper.", "asteroid.losses.MixITLossWrapper."], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", ",", "8", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "2", ",", "3", ",", "4", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"time\"", ",", "[", "16000", "]", ")", "\n", "def", "test_mixitwrapper_as_pit_wrapper", "(", "batch_size", ",", "n_src", ",", "time", ")", ":", "\n", "    ", "targets", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_src", ",", "time", ")", "\n", "est_targets", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_src", ",", "time", ")", "\n", "\n", "# mix_it base case: targets == mixtures / With and without return estimates", "\n", "loss", "=", "MixITLossWrapper", "(", "good_batch_loss_func", ",", "generalized", "=", "False", ")", "\n", "loss", "(", "est_targets", ",", "targets", ")", "\n", "loss_value", ",", "reordered_est", "=", "loss", "(", "est_targets", ",", "targets", ",", "return_est", "=", "True", ")", "\n", "assert", "reordered_est", ".", "shape", "==", "est_targets", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper_test.test_mixit_wrapper": [[27, 41], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.randn", "torch.randn", "asteroid.losses.MixITLossWrapper", "asteroid.losses.MixITLossWrapper.", "asteroid.losses.MixITLossWrapper."], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", ",", "4", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"factor\"", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_mix\"", ",", "[", "2", ",", "3", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"time\"", ",", "[", "16000", "]", ")", "\n", "def", "test_mixit_wrapper", "(", "batch_size", ",", "factor", ",", "n_mix", ",", "time", ")", ":", "\n", "    ", "mixtures", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_mix", ",", "time", ")", "\n", "n_src", "=", "n_mix", "*", "factor", "\n", "est_targets", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_src", ",", "time", ")", "\n", "\n", "# mix_it / With and without return estimates", "\n", "loss", "=", "MixITLossWrapper", "(", "good_batch_loss_func", ",", "generalized", "=", "False", ")", "\n", "loss", "(", "est_targets", ",", "mixtures", ")", "\n", "loss_value", ",", "reordered_mix", "=", "loss", "(", "est_targets", ",", "mixtures", ",", "return_est", "=", "True", ")", "\n", "assert", "reordered_mix", ".", "shape", "==", "mixtures", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper_test.test_mixit_gen_wrapper": [[43, 56], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.randn", "torch.randn", "asteroid.losses.MixITLossWrapper", "asteroid.losses.MixITLossWrapper.", "asteroid.losses.MixITLossWrapper."], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "2", ",", "8", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_src\"", ",", "[", "2", ",", "3", ",", "4", ",", "5", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_mix\"", ",", "[", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"time\"", ",", "[", "16000", "]", ")", "\n", "def", "test_mixit_gen_wrapper", "(", "batch_size", ",", "n_src", ",", "n_mix", ",", "time", ")", ":", "\n", "    ", "mixtures", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_mix", ",", "time", ")", "\n", "est_targets", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_src", ",", "time", ")", "\n", "\n", "# mix_it_gen / With and without return estimates. Works only with two mixtures", "\n", "loss", "=", "MixITLossWrapper", "(", "good_batch_loss_func", ")", "\n", "loss", "(", "est_targets", ",", "mixtures", ")", "\n", "loss_value", ",", "reordered_est", "=", "loss", "(", "est_targets", ",", "mixtures", ",", "return_est", "=", "True", ")", "\n", "assert", "reordered_est", ".", "shape", "==", "mixtures", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper_test.test_mixitwrapper_checks_loss_shape": [[58, 76], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "torch.randn", "torch.randn", "asteroid.losses.MixITLossWrapper", "asteroid.losses.MixITLossWrapper.", "asteroid.losses.MixITLossWrapper", "pytest.raises", "asteroid.losses.MixITLossWrapper."], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"batch_size\"", ",", "[", "1", ",", "8", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"factor\"", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_mix\"", ",", "[", "2", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"time\"", ",", "[", "16000", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"generalized\"", ",", "[", "True", ",", "False", "]", ")", "\n", "def", "test_mixitwrapper_checks_loss_shape", "(", "batch_size", ",", "factor", ",", "n_mix", ",", "time", ",", "generalized", ")", ":", "\n", "    ", "mixtures", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_mix", ",", "time", ")", "\n", "n_src", "=", "n_mix", "*", "factor", "\n", "est_targets", "=", "torch", ".", "randn", "(", "batch_size", ",", "n_src", ",", "time", ")", "\n", "\n", "# correct usage", "\n", "loss", "=", "MixITLossWrapper", "(", "multisrc_neg_sisdr", ",", "generalized", "=", "generalized", ")", "\n", "loss", "(", "est_targets", ",", "mixtures", ")", "\n", "\n", "# incorrect usage", "\n", "loss", "=", "MixITLossWrapper", "(", "pairwise_neg_sisdr", ",", "generalized", "=", "generalized", ")", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "loss", "(", "est_targets", ",", "mixtures", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.base.BaseUNet.__init__": [[23, 37], ["super().__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "len", "torch.nn.Identity", "len"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "encoders", ",", "\n", "decoders", ",", "\n", "*", ",", "\n", "output_layer", "=", "None", ",", "\n", ")", ":", "\n", "        ", "assert", "len", "(", "encoders", ")", "==", "len", "(", "decoders", ")", "+", "1", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoders", "=", "torch", ".", "nn", ".", "ModuleList", "(", "encoders", ")", "\n", "self", ".", "decoders", "=", "torch", ".", "nn", ".", "ModuleList", "(", "decoders", ")", "\n", "self", ".", "output_layer", "=", "output_layer", "or", "torch", ".", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.base.BaseUNet.forward": [[38, 47], ["enumerate", "enumerate", "base.BaseUNet.output_layer", "enc", "enc_outs.append", "zip", "dec", "torch.cat", "reversed"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "enc_outs", "=", "[", "]", "\n", "for", "idx", ",", "enc", "in", "enumerate", "(", "self", ".", "encoders", ")", ":", "\n", "            ", "x", "=", "enc", "(", "x", ")", "\n", "enc_outs", ".", "append", "(", "x", ")", "\n", "", "for", "idx", ",", "(", "enc_out", ",", "dec", ")", "in", "enumerate", "(", "zip", "(", "reversed", "(", "enc_outs", "[", ":", "-", "1", "]", ")", ",", "self", ".", "decoders", ")", ")", ":", "\n", "            ", "x", "=", "dec", "(", "x", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "enc_out", "]", ",", "dim", "=", "1", ")", "\n", "", "return", "self", ".", "output_layer", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.base.BaseDCUMaskNet.default_architecture": [[70, 85], ["cls"], "methods", ["None"], ["@", "classmethod", "\n", "def", "default_architecture", "(", "cls", ",", "architecture", ":", "str", ",", "n_src", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Create a masknet instance from a predefined, named architecture.\n\n        Args:\n            architecture (str): Name of predefined architecture. Valid values\n                are dependent on the concrete subclass of ``BaseDCUMaskNet``.\n            n_src (int, optional): Number of sources\n            kwargs (optional): Passed to ``__init__``.\n        \"\"\"", "\n", "encoders", ",", "decoders", "=", "cls", ".", "_architectures", "[", "architecture", "]", "\n", "# Fix n_src in last decoder", "\n", "in_chan", ",", "_ignored_out_chan", ",", "*", "rest", "=", "decoders", "[", "-", "1", "]", "\n", "decoders", "=", "(", "*", "decoders", "[", ":", "-", "1", "]", ",", "(", "in_chan", ",", "n_src", ",", "*", "rest", ")", ")", "\n", "return", "cls", "(", "encoders", ",", "decoders", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.base.BaseDCUMaskNet.__init__": [[86, 96], ["base.BaseUNet.__init__", "base._none_sequential", "complex_nn.BoundComplexMask"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.base._none_sequential"], ["", "def", "__init__", "(", "self", ",", "encoders", ",", "decoders", ",", "output_layer", "=", "None", ",", "mask_bound", "=", "\"tanh\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "mask_bound", "=", "mask_bound", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "encoders", "=", "encoders", ",", "\n", "decoders", "=", "decoders", ",", "\n", "output_layer", "=", "_none_sequential", "(", "\n", "output_layer", ",", "\n", "complex_nn", ".", "BoundComplexMask", "(", "mask_bound", ")", ",", "\n", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.base.BaseDCUMaskNet.forward": [[98, 103], ["base.BaseDCUMaskNet.fix_input_dims", "base.BaseUNet.forward", "base.BaseDCUMaskNet.fix_output_dims", "base.BaseDCUMaskNet.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.DCUMaskNet.fix_input_dims", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.Model.forward", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.DCUMaskNet.fix_output_dims"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "fixed_x", "=", "self", ".", "fix_input_dims", "(", "x", ")", "\n", "out", "=", "super", "(", ")", ".", "forward", "(", "fixed_x", ".", "unsqueeze", "(", "1", ")", ")", "\n", "out", "=", "self", ".", "fix_output_dims", "(", "out", ",", "x", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.base.BaseDCUMaskNet.fix_input_dims": [[104, 107], ["None"], "methods", ["None"], ["", "def", "fix_input_dims", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Overwrite this in subclasses to implement input dimension checks.\"\"\"", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.base.BaseDCUMaskNet.fix_output_dims": [[108, 112], ["None"], "methods", ["None"], ["", "def", "fix_output_dims", "(", "self", ",", "y", ",", "x", ")", ":", "\n", "        ", "\"\"\"Overwrite this in subclasses to implement output dimension checks.\n        y is the output and x was the input (passed to use the shape).\"\"\"", "\n", "return", "y", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.base._none_sequential": [[7, 9], ["torch.nn.Sequential"], "function", ["None"], ["def", "_none_sequential", "(", "*", "args", ")", ":", "\n", "    ", "return", "torch", ".", "nn", ".", "Sequential", "(", "*", "[", "x", "for", "x", "in", "args", "if", "x", "is", "not", "None", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.SingleRNN.__init__": [[32, 51], ["torch.nn.Module.__init__", "rnn_type.upper.upper.upper", "rnn_type.upper.upper.upper", "getattr", "bool"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "rnn_type", ",", "input_size", ",", "hidden_size", ",", "n_layers", "=", "1", ",", "dropout", "=", "0", ",", "bidirectional", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", "SingleRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "rnn_type", ".", "upper", "(", ")", "in", "[", "\"RNN\"", ",", "\"LSTM\"", ",", "\"GRU\"", "]", "\n", "rnn_type", "=", "rnn_type", ".", "upper", "(", ")", "\n", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "rnn", "=", "getattr", "(", "nn", ",", "rnn_type", ")", "(", "\n", "input_size", ",", "\n", "hidden_size", ",", "\n", "num_layers", "=", "n_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bool", "(", "bidirectional", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.SingleRNN.output_size": [[53, 56], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "hidden_size", "*", "(", "2", "if", "self", ".", "bidirectional", "else", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.SingleRNN.forward": [[57, 63], ["recurrent.SingleRNN.rnn.flatten_parameters", "recurrent.SingleRNN.rnn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "\"\"\"Input shape [batch, seq, feats]\"\"\"", "\n", "self", ".", "rnn", ".", "flatten_parameters", "(", ")", "# Enables faster multi-GPU training.", "\n", "output", "=", "inp", "\n", "rnn_output", ",", "_", "=", "self", ".", "rnn", "(", "output", ")", "\n", "return", "rnn_output", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.MulCatRNN.__init__": [[84, 111], ["torch.nn.Module.__init__", "rnn_type.upper.upper.upper", "rnn_type.upper.upper.upper", "getattr", "getattr", "bool", "bool"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "rnn_type", ",", "input_size", ",", "hidden_size", ",", "n_layers", "=", "1", ",", "dropout", "=", "0", ",", "bidirectional", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", "MulCatRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "rnn_type", ".", "upper", "(", ")", "in", "[", "\"RNN\"", ",", "\"LSTM\"", ",", "\"GRU\"", "]", "\n", "rnn_type", "=", "rnn_type", ".", "upper", "(", ")", "\n", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "rnn1", "=", "getattr", "(", "nn", ",", "rnn_type", ")", "(", "\n", "input_size", ",", "\n", "hidden_size", ",", "\n", "num_layers", "=", "n_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bool", "(", "bidirectional", ")", ",", "\n", ")", "\n", "self", ".", "rnn2", "=", "getattr", "(", "nn", ",", "rnn_type", ")", "(", "\n", "input_size", ",", "\n", "hidden_size", ",", "\n", "num_layers", "=", "n_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "batch_first", "=", "True", ",", "\n", "bidirectional", "=", "bool", "(", "bidirectional", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.MulCatRNN.output_size": [[113, 116], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "hidden_size", "*", "(", "2", "if", "self", ".", "bidirectional", "else", "1", ")", "+", "self", ".", "input_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.MulCatRNN.forward": [[117, 124], ["recurrent.MulCatRNN.rnn1.flatten_parameters", "recurrent.MulCatRNN.rnn2.flatten_parameters", "recurrent.MulCatRNN.rnn1", "recurrent.MulCatRNN.rnn2", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "\"\"\"Input shape [batch, seq, feats]\"\"\"", "\n", "self", ".", "rnn1", ".", "flatten_parameters", "(", ")", "# Enables faster multi-GPU training.", "\n", "self", ".", "rnn2", ".", "flatten_parameters", "(", ")", "# Enables faster multi-GPU training.", "\n", "rnn_output1", ",", "_", "=", "self", ".", "rnn1", "(", "inp", ")", "\n", "rnn_output2", ",", "_", "=", "self", ".", "rnn2", "(", "inp", ")", "\n", "return", "torch", ".", "cat", "(", "(", "rnn_output1", "*", "rnn_output2", ",", "inp", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.StackedResidualRNN.__init__": [[142, 159], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "range", "torch.nn.Dropout", "recurrent.StackedResidualRNN.layers.append", "recurrent.SingleRNN"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "n_units", ",", "n_layers", "=", "4", ",", "dropout", "=", "0.0", ",", "bidirectional", "=", "False", ")", ":", "\n", "        ", "super", "(", "StackedResidualRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "n_units", "=", "n_units", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "assert", "bidirectional", "is", "False", ",", "\"Bidirectional not supported yet\"", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "n_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "SingleRNN", "(", "\n", "rnn_type", ",", "input_size", "=", "n_units", ",", "hidden_size", "=", "n_units", ",", "bidirectional", "=", "bidirectional", "\n", ")", "\n", ")", "\n", "", "self", ".", "dropout_layer", "=", "nn", ".", "Dropout", "(", "self", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.StackedResidualRNN.forward": [[160, 169], ["rnn", "recurrent.StackedResidualRNN.dropout_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Builtin residual connections + dropout applied before residual.\n        Input shape : [batch, time_axis, feat_axis]\n        \"\"\"", "\n", "for", "rnn", "in", "self", ".", "layers", ":", "\n", "            ", "rnn_out", "=", "rnn", "(", "x", ")", "\n", "dropped_out", "=", "self", ".", "dropout_layer", "(", "rnn_out", ")", "\n", "x", "=", "x", "+", "dropped_out", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.StackedResidualBiRNN.__init__": [[188, 215], ["torch.nn.Module.__init__", "recurrent.SingleRNN", "torch.nn.ModuleList", "range", "torch.nn.Dropout", "recurrent.StackedResidualBiRNN.layers.append", "recurrent.SingleRNN"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "rnn_type", ",", "n_units", ",", "n_layers", "=", "4", ",", "dropout", "=", "0.0", ",", "bidirectional", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "n_units", "=", "n_units", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "assert", "bidirectional", "is", "True", ",", "\"Only bidirectional not supported yet\"", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "\n", "# The first layer has as many units as input size", "\n", "self", ".", "first_layer", "=", "SingleRNN", "(", "\n", "rnn_type", ",", "input_size", "=", "n_units", ",", "hidden_size", "=", "n_units", ",", "bidirectional", "=", "bidirectional", "\n", ")", "\n", "# As the first layer outputs 2*n_units, the following layers need", "\n", "# 2*n_units as input size", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "n_layers", "-", "1", ")", ":", "\n", "            ", "input_size", "=", "2", "*", "n_units", "\n", "self", ".", "layers", ".", "append", "(", "\n", "SingleRNN", "(", "\n", "rnn_type", ",", "\n", "input_size", "=", "input_size", ",", "\n", "hidden_size", "=", "n_units", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", ")", "\n", ")", "\n", "", "self", ".", "dropout_layer", "=", "nn", ".", "Dropout", "(", "self", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.StackedResidualBiRNN.forward": [[216, 230], ["recurrent.StackedResidualBiRNN.first_layer", "recurrent.StackedResidualBiRNN.dropout_layer", "torch.cat", "rnn", "recurrent.StackedResidualBiRNN.dropout_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Builtin residual connections + dropout applied before residual.\n        Input shape : [batch, time_axis, feat_axis]\n        \"\"\"", "\n", "# First layer", "\n", "rnn_out", "=", "self", ".", "first_layer", "(", "x", ")", "\n", "dropped_out", "=", "self", ".", "dropout_layer", "(", "rnn_out", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "x", "]", ",", "dim", "=", "-", "1", ")", "+", "dropped_out", "\n", "# Rest of the layers", "\n", "for", "rnn", "in", "self", ".", "layers", ":", "\n", "            ", "rnn_out", "=", "rnn", "(", "x", ")", "\n", "dropped_out", "=", "self", ".", "dropout_layer", "(", "rnn_out", ")", "\n", "x", "=", "x", "+", "dropped_out", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.DPRNNBlock.__init__": [[253, 306], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "recurrent.MulCatRNN", "recurrent.MulCatRNN", "recurrent.SingleRNN", "recurrent.SingleRNN", "norms.get", "norms.get"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_chan", ",", "\n", "hid_size", ",", "\n", "norm_type", "=", "\"gLN\"", ",", "\n", "bidirectional", "=", "True", ",", "\n", "rnn_type", "=", "\"LSTM\"", ",", "\n", "use_mulcat", "=", "False", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", "DPRNNBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "use_mulcat", ":", "\n", "# IntraRNN block and linear projection layer (always bi-directional)", "\n", "            ", "self", ".", "intra_RNN", "=", "MulCatRNN", "(", "\n", "rnn_type", ",", "\n", "in_chan", ",", "\n", "hid_size", ",", "\n", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", "\n", "# InterRNN block and linear projection layer (uni or bi-directional)", "\n", "self", ".", "inter_RNN", "=", "MulCatRNN", "(", "\n", "rnn_type", ",", "\n", "in_chan", ",", "\n", "hid_size", ",", "\n", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "intra_RNN", "=", "SingleRNN", "(", "\n", "rnn_type", ",", "\n", "in_chan", ",", "\n", "hid_size", ",", "\n", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", "\n", "self", ".", "inter_RNN", "=", "SingleRNN", "(", "\n", "rnn_type", ",", "\n", "in_chan", ",", "\n", "hid_size", ",", "\n", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", ")", "\n", "", "self", ".", "intra_linear", "=", "nn", ".", "Linear", "(", "self", ".", "intra_RNN", ".", "output_size", ",", "in_chan", ")", "\n", "self", ".", "intra_norm", "=", "norms", ".", "get", "(", "norm_type", ")", "(", "in_chan", ")", "\n", "\n", "self", ".", "inter_linear", "=", "nn", ".", "Linear", "(", "self", ".", "inter_RNN", ".", "output_size", ",", "in_chan", ")", "\n", "self", ".", "inter_norm", "=", "norms", ".", "get", "(", "norm_type", ")", "(", "in_chan", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.DPRNNBlock.forward": [[307, 325], ["recurrent.DPRNNBlock.size", "recurrent.DPRNNBlock.transpose().reshape", "recurrent.DPRNNBlock.intra_RNN", "recurrent.DPRNNBlock.intra_linear", "recurrent.DPRNNBlock.reshape().transpose", "recurrent.DPRNNBlock.intra_norm", "output.transpose().transpose().reshape", "recurrent.DPRNNBlock.inter_RNN", "recurrent.DPRNNBlock.inter_linear", "recurrent.DPRNNBlock.reshape().transpose().transpose().contiguous", "recurrent.DPRNNBlock.inter_norm", "recurrent.DPRNNBlock.transpose", "recurrent.DPRNNBlock.reshape", "output.transpose().transpose", "recurrent.DPRNNBlock.reshape().transpose().transpose", "output.transpose", "recurrent.DPRNNBlock.reshape().transpose", "recurrent.DPRNNBlock.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Input shape : [batch, feats, chunk_size, num_chunks]\"\"\"", "\n", "B", ",", "N", ",", "K", ",", "L", "=", "x", ".", "size", "(", ")", "\n", "output", "=", "x", "# for skip connection", "\n", "# Intra-chunk processing", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "-", "1", ")", ".", "reshape", "(", "B", "*", "L", ",", "K", ",", "N", ")", "\n", "x", "=", "self", ".", "intra_RNN", "(", "x", ")", "\n", "x", "=", "self", ".", "intra_linear", "(", "x", ")", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "L", ",", "K", ",", "N", ")", ".", "transpose", "(", "1", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "intra_norm", "(", "x", ")", "\n", "output", "=", "output", "+", "x", "\n", "# Inter-chunk processing", "\n", "x", "=", "output", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "2", ",", "-", "1", ")", ".", "reshape", "(", "B", "*", "K", ",", "L", ",", "N", ")", "\n", "x", "=", "self", ".", "inter_RNN", "(", "x", ")", "\n", "x", "=", "self", ".", "inter_linear", "(", "x", ")", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "K", ",", "L", ",", "N", ")", ".", "transpose", "(", "1", ",", "-", "1", ")", ".", "transpose", "(", "2", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "x", "=", "self", ".", "inter_norm", "(", "x", ")", "\n", "return", "output", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.DPRNN.__init__": [[363, 435], ["torch.nn.Module.__init__", "torch.nn.Conv1d", "torch.nn.Sequential", "range", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv1d", "activations.get", "utils.has_arg", "norms.get", "torch.nn.PReLU", "torch.nn.Conv1d", "torch.nn.Tanh", "torch.nn.Conv1d", "torch.nn.Sigmoid", "activations.get.", "activations.get.", "recurrent.DPRNNBlock"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.has_arg", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_chan", ",", "\n", "n_src", ",", "\n", "out_chan", "=", "None", ",", "\n", "bn_chan", "=", "128", ",", "\n", "hid_size", "=", "128", ",", "\n", "chunk_size", "=", "100", ",", "\n", "hop_size", "=", "None", ",", "\n", "n_repeats", "=", "6", ",", "\n", "norm_type", "=", "\"gLN\"", ",", "\n", "mask_act", "=", "\"relu\"", ",", "\n", "bidirectional", "=", "True", ",", "\n", "rnn_type", "=", "\"LSTM\"", ",", "\n", "use_mulcat", "=", "False", ",", "\n", "num_layers", "=", "1", ",", "\n", "dropout", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", "DPRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_chan", "=", "in_chan", "\n", "out_chan", "=", "out_chan", "if", "out_chan", "is", "not", "None", "else", "in_chan", "\n", "self", ".", "out_chan", "=", "out_chan", "\n", "self", ".", "bn_chan", "=", "bn_chan", "\n", "self", ".", "hid_size", "=", "hid_size", "\n", "self", ".", "chunk_size", "=", "chunk_size", "\n", "hop_size", "=", "hop_size", "if", "hop_size", "is", "not", "None", "else", "chunk_size", "//", "2", "\n", "self", ".", "hop_size", "=", "hop_size", "\n", "self", ".", "n_repeats", "=", "n_repeats", "\n", "self", ".", "n_src", "=", "n_src", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "self", ".", "mask_act", "=", "mask_act", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "use_mulcat", "=", "use_mulcat", "\n", "\n", "layer_norm", "=", "norms", ".", "get", "(", "norm_type", ")", "(", "in_chan", ")", "\n", "bottleneck_conv", "=", "nn", ".", "Conv1d", "(", "in_chan", ",", "bn_chan", ",", "1", ")", "\n", "self", ".", "bottleneck", "=", "nn", ".", "Sequential", "(", "layer_norm", ",", "bottleneck_conv", ")", "\n", "\n", "# Succession of DPRNNBlocks.", "\n", "net", "=", "[", "]", "\n", "for", "x", "in", "range", "(", "self", ".", "n_repeats", ")", ":", "\n", "            ", "net", "+=", "[", "\n", "DPRNNBlock", "(", "\n", "bn_chan", ",", "\n", "hid_size", ",", "\n", "norm_type", "=", "norm_type", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "rnn_type", "=", "rnn_type", ",", "\n", "use_mulcat", "=", "use_mulcat", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", "\n", "]", "\n", "", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "net", ")", "\n", "# Masking in 3D space", "\n", "net_out_conv", "=", "nn", ".", "Conv2d", "(", "bn_chan", ",", "n_src", "*", "bn_chan", ",", "1", ")", "\n", "self", ".", "first_out", "=", "nn", ".", "Sequential", "(", "nn", ".", "PReLU", "(", ")", ",", "net_out_conv", ")", "\n", "# Gating and masking in 2D space (after fold)", "\n", "self", ".", "net_out", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv1d", "(", "bn_chan", ",", "bn_chan", ",", "1", ")", ",", "nn", ".", "Tanh", "(", ")", ")", "\n", "self", ".", "net_gate", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv1d", "(", "bn_chan", ",", "bn_chan", ",", "1", ")", ",", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "self", ".", "mask_net", "=", "nn", ".", "Conv1d", "(", "bn_chan", ",", "out_chan", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n", "# Get activation function.", "\n", "mask_nl_class", "=", "activations", ".", "get", "(", "mask_act", ")", "\n", "# For softmax, feed the source dimension.", "\n", "if", "has_arg", "(", "mask_nl_class", ",", "\"dim\"", ")", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.DPRNN.forward": [[436, 478], ["mixture_w.size", "recurrent.DPRNN.bottleneck", "torch.nn.functional.unfold", "output.reshape.reshape.reshape", "recurrent.DPRNN.net", "recurrent.DPRNN.first_out", "output.reshape.reshape.reshape", "torch.nn.functional.fold", "output.reshape.reshape.reshape", "recurrent.DPRNN.mask_net", "recurrent.DPRNN.output_act", "est_mask.view.view.view", "output.reshape.reshape.unsqueeze", "output.reshape.reshape.reshape", "recurrent.DPRNN.net_out", "recurrent.DPRNN.net_gate"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.unfold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.fold"], ["", "", "def", "forward", "(", "self", ",", "mixture_w", ")", ":", "\n", "        ", "r\"\"\"Forward.\n\n        Args:\n            mixture_w (:class:`torch.Tensor`): Tensor of shape $(batch, nfilters, nframes)$\n\n        Returns:\n            :class:`torch.Tensor`: estimated mask of shape $(batch, nsrc, nfilters, nframes)$\n        \"\"\"", "\n", "batch", ",", "n_filters", ",", "n_frames", "=", "mixture_w", ".", "size", "(", ")", "\n", "output", "=", "self", ".", "bottleneck", "(", "mixture_w", ")", "# [batch, bn_chan, n_frames]", "\n", "output", "=", "unfold", "(", "\n", "output", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "kernel_size", "=", "(", "self", ".", "chunk_size", ",", "1", ")", ",", "\n", "padding", "=", "(", "self", ".", "chunk_size", ",", "0", ")", ",", "\n", "stride", "=", "(", "self", ".", "hop_size", ",", "1", ")", ",", "\n", ")", "\n", "n_chunks", "=", "output", ".", "shape", "[", "-", "1", "]", "\n", "output", "=", "output", ".", "reshape", "(", "batch", ",", "self", ".", "bn_chan", ",", "self", ".", "chunk_size", ",", "n_chunks", ")", "\n", "# Apply stacked DPRNN Blocks sequentially", "\n", "output", "=", "self", ".", "net", "(", "output", ")", "\n", "# Map to sources with kind of 2D masks", "\n", "output", "=", "self", ".", "first_out", "(", "output", ")", "\n", "output", "=", "output", ".", "reshape", "(", "batch", "*", "self", ".", "n_src", ",", "self", ".", "bn_chan", ",", "self", ".", "chunk_size", ",", "n_chunks", ")", "\n", "# Overlap and add:", "\n", "# [batch, out_chan, chunk_size, n_chunks] -> [batch, out_chan, n_frames]", "\n", "to_unfold", "=", "self", ".", "bn_chan", "*", "self", ".", "chunk_size", "\n", "output", "=", "fold", "(", "\n", "output", ".", "reshape", "(", "batch", "*", "self", ".", "n_src", ",", "to_unfold", ",", "n_chunks", ")", ",", "\n", "(", "n_frames", ",", "1", ")", ",", "\n", "kernel_size", "=", "(", "self", ".", "chunk_size", ",", "1", ")", ",", "\n", "padding", "=", "(", "self", ".", "chunk_size", ",", "0", ")", ",", "\n", "stride", "=", "(", "self", ".", "hop_size", ",", "1", ")", ",", "\n", ")", "\n", "# Apply gating", "\n", "output", "=", "output", ".", "reshape", "(", "batch", "*", "self", ".", "n_src", ",", "self", ".", "bn_chan", ",", "-", "1", ")", "\n", "output", "=", "self", ".", "net_out", "(", "output", ")", "*", "self", ".", "net_gate", "(", "output", ")", "\n", "# Compute mask", "\n", "score", "=", "self", ".", "mask_net", "(", "output", ")", "\n", "est_mask", "=", "self", ".", "output_act", "(", "score", ")", "\n", "est_mask", "=", "est_mask", ".", "view", "(", "batch", ",", "self", ".", "n_src", ",", "self", ".", "out_chan", ",", "n_frames", ")", "\n", "return", "est_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.DPRNN.get_config": [[479, 498], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "\"in_chan\"", ":", "self", ".", "in_chan", ",", "\n", "\"out_chan\"", ":", "self", ".", "out_chan", ",", "\n", "\"bn_chan\"", ":", "self", ".", "bn_chan", ",", "\n", "\"hid_size\"", ":", "self", ".", "hid_size", ",", "\n", "\"chunk_size\"", ":", "self", ".", "chunk_size", ",", "\n", "\"hop_size\"", ":", "self", ".", "hop_size", ",", "\n", "\"n_repeats\"", ":", "self", ".", "n_repeats", ",", "\n", "\"n_src\"", ":", "self", ".", "n_src", ",", "\n", "\"norm_type\"", ":", "self", ".", "norm_type", ",", "\n", "\"mask_act\"", ":", "self", ".", "mask_act", ",", "\n", "\"bidirectional\"", ":", "self", ".", "bidirectional", ",", "\n", "\"rnn_type\"", ":", "self", ".", "rnn_type", ",", "\n", "\"num_layers\"", ":", "self", ".", "num_layers", ",", "\n", "\"dropout\"", ":", "self", ".", "dropout", ",", "\n", "\"use_mulcat\"", ":", "self", ".", "use_mulcat", ",", "\n", "}", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.LSTMMasker.__init__": [[521, 570], ["torch.nn.Module.__init__", "activations.get", "utils.has_arg", "torch.nn.Sequential", "activations.get.", "activations.get.", "norms.GlobLN", "norms.CumLN", "recurrent.SingleRNN", "torch.nn.Linear", "int"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.has_arg"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_chan", ",", "\n", "n_src", ",", "\n", "out_chan", "=", "None", ",", "\n", "rnn_type", "=", "\"lstm\"", ",", "\n", "n_layers", "=", "4", ",", "\n", "hid_size", "=", "512", ",", "\n", "dropout", "=", "0.3", ",", "\n", "mask_act", "=", "\"sigmoid\"", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_chan", "=", "in_chan", "\n", "self", ".", "n_src", "=", "n_src", "\n", "out_chan", "=", "out_chan", "if", "out_chan", "is", "not", "None", "else", "in_chan", "\n", "self", ".", "out_chan", "=", "out_chan", "\n", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "hid_size", "=", "hid_size", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "mask_act", "=", "mask_act", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "\n", "# Get activation function.", "\n", "mask_nl_class", "=", "activations", ".", "get", "(", "mask_act", ")", "\n", "# For softmax, feed the source dimension.", "\n", "if", "has_arg", "(", "mask_nl_class", ",", "\"dim\"", ")", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", ")", "\n", "\n", "# Create TasNet masker", "\n", "", "out_size", "=", "hid_size", "*", "(", "int", "(", "bidirectional", ")", "+", "1", ")", "\n", "if", "bidirectional", ":", "\n", "            ", "self", ".", "bn_layer", "=", "GlobLN", "(", "in_chan", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bn_layer", "=", "CumLN", "(", "in_chan", ")", "\n", "", "self", ".", "masker", "=", "nn", ".", "Sequential", "(", "\n", "SingleRNN", "(", "\n", "\"lstm\"", ",", "\n", "in_chan", ",", "\n", "hidden_size", "=", "hid_size", ",", "\n", "n_layers", "=", "n_layers", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", "dropout", "=", "dropout", ",", "\n", ")", ",", "\n", "nn", ".", "Linear", "(", "out_size", ",", "self", ".", "n_src", "*", "out_chan", ")", ",", "\n", "self", ".", "output_act", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.LSTMMasker.forward": [[572, 578], ["recurrent.LSTMMasker.bn_layer", "recurrent.LSTMMasker.masker().transpose", "est_masks.view.view.view", "recurrent.LSTMMasker.masker", "recurrent.LSTMMasker.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "to_sep", "=", "self", ".", "bn_layer", "(", "x", ")", "\n", "est_masks", "=", "self", ".", "masker", "(", "to_sep", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "est_masks", "=", "est_masks", ".", "view", "(", "batch_size", ",", "self", ".", "n_src", ",", "self", ".", "out_chan", ",", "-", "1", ")", "\n", "return", "est_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.LSTMMasker.get_config": [[579, 592], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "\"in_chan\"", ":", "self", ".", "in_chan", ",", "\n", "\"n_src\"", ":", "self", ".", "n_src", ",", "\n", "\"out_chan\"", ":", "self", ".", "out_chan", ",", "\n", "\"rnn_type\"", ":", "self", ".", "rnn_type", ",", "\n", "\"n_layers\"", ":", "self", ".", "n_layers", ",", "\n", "\"hid_size\"", ":", "self", ".", "hid_size", ",", "\n", "\"dropout\"", ":", "self", ".", "dropout", ",", "\n", "\"mask_act\"", ":", "self", ".", "mask_act", ",", "\n", "\"bidirectional\"", ":", "self", ".", "bidirectional", ",", "\n", "}", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.DCCRMaskNetRNN.__init__": [[614, 626], ["torch.nn.Module.__init__", "complex_nn.ComplexSingleRNN", "complex_nn.ComplexMultiplicationWrapper", "norms.get_complex"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get_complex"], ["def", "__init__", "(", "\n", "self", ",", "in_size", ",", "hid_size", "=", "128", ",", "rnn_type", "=", "\"LSTM\"", ",", "n_layers", "=", "2", ",", "norm_type", "=", "None", ",", "**", "rnn_kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "rnn", "=", "complex_nn", ".", "ComplexSingleRNN", "(", "\n", "rnn_type", ",", "in_size", ",", "hid_size", ",", "n_layers", "=", "n_layers", ",", "**", "rnn_kwargs", "\n", ")", "\n", "self", ".", "linear", "=", "complex_nn", ".", "ComplexMultiplicationWrapper", "(", "\n", "nn", ".", "Linear", ",", "self", ".", "rnn", ".", "output_size", ",", "in_size", "\n", ")", "\n", "self", ".", "norm", "=", "norms", ".", "get_complex", "(", "norm_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.DCCRMaskNetRNN.forward": [[627, 638], ["recurrent.DCCRMaskNetRNN.permute", "recurrent.DCCRMaskNetRNN.linear().reshape", "recurrent.DCCRMaskNetRNN.permute", "recurrent.DCCRMaskNetRNN.norm", "range", "recurrent.DCCRMaskNetRNN.linear", "range", "recurrent.DCCRMaskNetRNN.rnn", "recurrent.DCCRMaskNetRNN.reshape"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.linear"], ["", "def", "forward", "(", "self", ",", "x", ":", "complex_nn", ".", "ComplexTensor", ")", ":", "\n", "        ", "\"\"\"Input shape: [batch, ..., time]\"\"\"", "\n", "# Permute to [batch, time, ...]", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "x", ".", "ndim", "-", "1", ",", "*", "range", "(", "1", ",", "x", ".", "ndim", "-", "1", ")", ")", "\n", "# RNN + Linear expect [batch, time, rest]", "\n", "x", "=", "self", ".", "linear", "(", "self", ".", "rnn", "(", "x", ".", "reshape", "(", "*", "x", ".", "shape", "[", ":", "2", "]", ",", "-", "1", ")", ")", ")", ".", "reshape", "(", "*", "x", ".", "shape", ")", "\n", "# Permute back to [batch, ..., time]", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "*", "range", "(", "2", ",", "x", ".", "ndim", ")", ",", "1", ")", "\n", "if", "self", ".", "norm", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "norm", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.DCCRMaskNet.__init__": [[665, 687], ["numpy.prod", "base.BaseDCUMaskNet.__init__", "int", "numpy.ceil", "complex_nn.ComplexConvTranspose2d", "recurrent.DCCRMaskNetRNN", "torch.nn.Identity", "numpy.prod", "DCUNetComplexEncoderBlock", "DCUNetComplexDecoderBlock"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "encoders", ",", "decoders", ",", "n_freqs", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "encoders_stride_product", "=", "np", ".", "prod", "(", "\n", "[", "enc_stride", "for", "_", ",", "_", ",", "_", ",", "enc_stride", ",", "_", "in", "encoders", "]", ",", "axis", "=", "0", "\n", ")", "\n", "\n", "freq_prod", ",", "_", "=", "self", ".", "encoders_stride_product", "\n", "last_encoder_out_shape", "=", "(", "encoders", "[", "-", "1", "]", "[", "1", "]", ",", "int", "(", "np", ".", "ceil", "(", "n_freqs", "/", "freq_prod", ")", ")", ")", "\n", "\n", "# Avoid circual import", "\n", "from", ".", "convolutional", "import", "DCUNetComplexDecoderBlock", ",", "DCUNetComplexEncoderBlock", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "encoders", "=", "[", "\n", "*", "(", "DCUNetComplexEncoderBlock", "(", "*", "args", ",", "activation", "=", "\"prelu\"", ")", "for", "args", "in", "encoders", ")", ",", "\n", "DCCRMaskNetRNN", "(", "np", ".", "prod", "(", "last_encoder_out_shape", ")", ")", ",", "\n", "]", ",", "\n", "decoders", "=", "[", "\n", "torch", ".", "nn", ".", "Identity", "(", ")", ",", "\n", "*", "(", "DCUNetComplexDecoderBlock", "(", "*", "args", ",", "activation", "=", "\"prelu\"", ")", "for", "args", "in", "decoders", "[", ":", "-", "1", "]", ")", ",", "\n", "]", ",", "\n", "output_layer", "=", "complex_nn", ".", "ComplexConvTranspose2d", "(", "*", "decoders", "[", "-", "1", "]", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent.DCCRMaskNet.fix_input_dims": [[689, 699], ["TypeError"], "methods", ["None"], ["", "def", "fix_input_dims", "(", "self", ",", "x", ")", ":", "\n", "# TODO: We can probably lift the shape requirements once Keras-style \"same\"", "\n", "# padding for convolutions has landed: https://github.com/pytorch/pytorch/pull/42190", "\n", "        ", "freq_prod", ",", "_", "=", "self", ".", "encoders_stride_product", "\n", "if", "x", ".", "shape", "[", "1", "]", "%", "freq_prod", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f\"Input shape must be [batch, freq, time] with freq divisible by {freq_prod}, \"", "\n", "f\"got {x.shape} instead\"", "\n", ")", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms._LayerNorm.__init__": [[35, 40], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "channel_size", ")", ":", "\n", "        ", "super", "(", "_LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channel_size", "=", "channel_size", "\n", "self", ".", "gamma", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "channel_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "self", ".", "beta", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "channel_size", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms._LayerNorm.apply_gain_and_bias": [[41, 44], ["normed_x.transpose"], "methods", ["None"], ["", "def", "apply_gain_and_bias", "(", "self", ",", "normed_x", ")", ":", "\n", "        ", "\"\"\"Assumes input of size `[batch, chanel, *]`.\"\"\"", "\n", "return", "(", "self", ".", "gamma", "*", "normed_x", ".", "transpose", "(", "1", ",", "-", "1", ")", "+", "self", ".", "beta", ")", ".", "transpose", "(", "1", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.GlobLN.forward": [[49, 62], ["norms._glob_norm", "norms.GlobLN.apply_gain_and_bias"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms._glob_norm", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms._LayerNorm.apply_gain_and_bias"], ["def", "forward", "(", "self", ",", "x", ",", "EPS", ":", "float", "=", "1e-8", ")", ":", "\n", "        ", "\"\"\"Applies forward pass.\n\n        Works for any input size > 2D.\n\n        Args:\n            x (:class:`torch.Tensor`): Shape `[batch, chan, *]`\n\n        Returns:\n            :class:`torch.Tensor`: gLN_x `[batch, chan, *]`\n        \"\"\"", "\n", "value", "=", "_glob_norm", "(", "x", ",", "eps", "=", "EPS", ")", "\n", "return", "self", ".", "apply_gain_and_bias", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.ChanLN.forward": [[67, 81], ["torch.mean", "torch.var", "norms.ChanLN.apply_gain_and_bias"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms._LayerNorm.apply_gain_and_bias"], ["def", "forward", "(", "self", ",", "x", ",", "EPS", ":", "float", "=", "1e-8", ")", ":", "\n", "        ", "\"\"\"Applies forward pass.\n\n        Works for any input size > 2D.\n\n        Args:\n            x (:class:`torch.Tensor`): `[batch, chan, *]`\n\n        Returns:\n            :class:`torch.Tensor`: chanLN_x `[batch, chan, *]`\n        \"\"\"", "\n", "mean", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "var", "=", "torch", ".", "var", "(", "x", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ",", "unbiased", "=", "False", ")", "\n", "return", "self", ".", "apply_gain_and_bias", "(", "(", "x", "-", "mean", ")", "/", "(", "var", "+", "EPS", ")", ".", "sqrt", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.CumLN.forward": [[86, 103], ["x.size", "torch.cumsum", "torch.cumsum", "torch.arange().view", "norms.CumLN.apply_gain_and_bias", "x.sum", "x.pow().sum", "cum_mean.pow", "torch.arange", "x.pow"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms._LayerNorm.apply_gain_and_bias"], ["def", "forward", "(", "self", ",", "x", ",", "EPS", ":", "float", "=", "1e-8", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            x (:class:`torch.Tensor`): Shape `[batch, channels, length]`\n        Returns:\n             :class:`torch.Tensor`: cumLN_x `[batch, channels, length]`\n        \"\"\"", "\n", "batch", ",", "chan", ",", "spec_len", "=", "x", ".", "size", "(", ")", "\n", "cum_sum", "=", "torch", ".", "cumsum", "(", "x", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ",", "dim", "=", "-", "1", ")", "\n", "cum_pow_sum", "=", "torch", ".", "cumsum", "(", "x", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", ",", "dim", "=", "-", "1", ")", "\n", "cnt", "=", "torch", ".", "arange", "(", "\n", "start", "=", "chan", ",", "end", "=", "chan", "*", "(", "spec_len", "+", "1", ")", ",", "step", "=", "chan", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", "\n", ")", ".", "view", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "cum_mean", "=", "cum_sum", "/", "cnt", "\n", "cum_var", "=", "cum_pow_sum", "-", "cum_mean", ".", "pow", "(", "2", ")", "\n", "return", "self", ".", "apply_gain_and_bias", "(", "(", "x", "-", "cum_mean", ")", "/", "(", "cum_var", "+", "EPS", ")", ".", "sqrt", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.FeatsGlobLN.forward": [[109, 122], ["norms._feat_glob_norm", "norms.FeatsGlobLN.apply_gain_and_bias"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms._feat_glob_norm", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms._LayerNorm.apply_gain_and_bias"], ["def", "forward", "(", "self", ",", "x", ",", "EPS", ":", "float", "=", "1e-8", ")", ":", "\n", "        ", "\"\"\"Applies forward pass.\n\n        Works for any input size > 2D.\n\n        Args:\n            x (:class:`torch.Tensor`): `[batch, chan, time]`\n\n        Returns:\n            :class:`torch.Tensor`: chanLN_x `[batch, chan, time]`\n        \"\"\"", "\n", "value", "=", "_feat_glob_norm", "(", "x", ",", "eps", "=", "EPS", ")", "\n", "return", "self", ".", "apply_gain_and_bias", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.BatchNorm._check_input_dim": [[127, 130], ["ValueError", "input.dim", "input.dim", "input.dim"], "methods", ["None"], ["def", "_check_input_dim", "(", "self", ",", "input", ")", ":", "\n", "        ", "if", "input", ".", "dim", "(", ")", "<", "2", "or", "input", ".", "dim", "(", ")", ">", "4", ":", "\n", "            ", "raise", "ValueError", "(", "\"expected 4D or 3D input (got {}D input)\"", ".", "format", "(", "input", ".", "dim", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.z_norm": [[13, 18], ["x.mean", "torch.var", "torch.sqrt"], "function", ["None"], ["def", "z_norm", "(", "x", ",", "dims", ":", "List", "[", "int", "]", ",", "eps", ":", "float", "=", "1e-8", ")", ":", "\n", "    ", "mean", "=", "x", ".", "mean", "(", "dim", "=", "dims", ",", "keepdim", "=", "True", ")", "\n", "var2", "=", "torch", ".", "var", "(", "x", ",", "dim", "=", "dims", ",", "keepdim", "=", "True", ",", "unbiased", "=", "False", ")", "\n", "value", "=", "(", "x", "-", "mean", ")", "/", "torch", ".", "sqrt", "(", "(", "var2", "+", "eps", ")", ")", "\n", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms._glob_norm": [[20, 24], ["torch.arange().tolist", "norms.z_norm", "torch.arange", "len"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.z_norm"], ["", "@", "script_if_tracing", "\n", "def", "_glob_norm", "(", "x", ",", "eps", ":", "float", "=", "1e-8", ")", ":", "\n", "    ", "dims", ":", "List", "[", "int", "]", "=", "torch", ".", "arange", "(", "1", ",", "len", "(", "x", ".", "shape", ")", ")", ".", "tolist", "(", ")", "\n", "return", "z_norm", "(", "x", ",", "dims", ",", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms._feat_glob_norm": [[26, 30], ["torch.arange().tolist", "norms.z_norm", "torch.arange", "len"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.z_norm"], ["", "@", "script_if_tracing", "\n", "def", "_feat_glob_norm", "(", "x", ",", "eps", ":", "float", "=", "1e-8", ")", ":", "\n", "    ", "dims", ":", "List", "[", "int", "]", "=", "torch", ".", "arange", "(", "2", ",", "len", "(", "x", ".", "shape", ")", ")", ".", "tolist", "(", ")", "\n", "return", "z_norm", "(", "x", ",", "dims", ",", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.register_norm": [[140, 150], ["globals().update", "ValueError", "globals().keys", "custom_norm.__name__.lower", "globals().keys", "globals", "globals", "globals"], "function", ["None"], ["def", "register_norm", "(", "custom_norm", ")", ":", "\n", "    ", "\"\"\"Register a custom norm, gettable with `norms.get`.\n\n    Args:\n        custom_norm: Custom norm to register.\n\n    \"\"\"", "\n", "if", "custom_norm", ".", "__name__", "in", "globals", "(", ")", ".", "keys", "(", ")", "or", "custom_norm", ".", "__name__", ".", "lower", "(", ")", "in", "globals", "(", ")", ".", "keys", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Norm {custom_norm.__name__} already exists. Choose another name.\"", ")", "\n", "", "globals", "(", ")", ".", "update", "(", "{", "custom_norm", ".", "__name__", ":", "custom_norm", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.get": [[152, 173], ["callable", "isinstance", "globals().get", "ValueError", "ValueError", "globals", "str", "str"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "def", "get", "(", "identifier", ")", ":", "\n", "    ", "\"\"\"Returns a norm class from a string. Returns its input if it\n    is callable (already a :class:`._LayerNorm` for example).\n\n    Args:\n        identifier (str or Callable or None): the norm identifier.\n\n    Returns:\n        :class:`._LayerNorm` or None\n    \"\"\"", "\n", "if", "identifier", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "elif", "callable", "(", "identifier", ")", ":", "\n", "        ", "return", "identifier", "\n", "", "elif", "isinstance", "(", "identifier", ",", "str", ")", ":", "\n", "        ", "cls", "=", "globals", "(", ")", ".", "get", "(", "identifier", ")", "\n", "if", "cls", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Could not interpret normalization identifier: \"", "+", "str", "(", "identifier", ")", ")", "\n", "", "return", "cls", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Could not interpret normalization identifier: \"", "+", "str", "(", "identifier", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.get_complex": [[175, 182], ["norms.get", "functools.partial"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "", "def", "get_complex", "(", "identifier", ")", ":", "\n", "    ", "\"\"\"Like `.get` but returns a complex norm created with `asteroid.complex_nn.OnReIm`.\"\"\"", "\n", "norm", "=", "get", "(", "identifier", ")", "\n", "if", "norm", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "partial", "(", "complex_nn", ".", "OnReIm", ",", "norm", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.attention.ImprovedTransformedLayer.__init__": [[34, 54], ["torch.Module.__init__", "torch.nn.modules.activation.MultiheadAttention", "torch.nn.modules.activation.MultiheadAttention", "torch.Dropout", "torch.Dropout", "torch.LSTM", "torch.LSTM", "torch.Linear", "torch.Linear", "activations.get", "norms.get", "norms.get"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed_dim", ",", "\n", "n_heads", ",", "\n", "dim_ff", ",", "\n", "dropout", "=", "0.0", ",", "\n", "activation", "=", "\"relu\"", ",", "\n", "bidirectional", "=", "True", ",", "\n", "norm", "=", "\"gLN\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", "ImprovedTransformedLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "mha", "=", "MultiheadAttention", "(", "embed_dim", ",", "n_heads", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "recurrent", "=", "nn", ".", "LSTM", "(", "embed_dim", ",", "dim_ff", ",", "bidirectional", "=", "bidirectional", ",", "batch_first", "=", "True", ")", "\n", "ff_inner_dim", "=", "2", "*", "dim_ff", "if", "bidirectional", "else", "dim_ff", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "ff_inner_dim", ",", "embed_dim", ")", "\n", "self", ".", "activation", "=", "activations", ".", "get", "(", "activation", ")", "(", ")", "\n", "self", ".", "norm_mha", "=", "norms", ".", "get", "(", "norm", ")", "(", "embed_dim", ")", "\n", "self", ".", "norm_ff", "=", "norms", ".", "get", "(", "norm", ")", "(", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.attention.ImprovedTransformedLayer.forward": [[55, 68], ["attention.ImprovedTransformedLayer.permute", "attention.ImprovedTransformedLayer.norm_mha", "attention.ImprovedTransformedLayer.linear", "attention.ImprovedTransformedLayer.norm_ff", "attention.ImprovedTransformedLayer.mha", "attention.ImprovedTransformedLayer.dropout", "attention.ImprovedTransformedLayer.dropout", "attention.ImprovedTransformedLayer.dropout", "attention.ImprovedTransformedLayer.permute", "attention.ImprovedTransformedLayer.activation", "attention.ImprovedTransformedLayer.transpose", "attention.ImprovedTransformedLayer.recurrent", "attention.ImprovedTransformedLayer.transpose"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.linear"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "tomha", "=", "x", ".", "permute", "(", "2", ",", "0", ",", "1", ")", "\n", "# x is batch, channels, seq_len", "\n", "# mha is seq_len, batch, channels", "\n", "# self-attention is applied", "\n", "out", "=", "self", ".", "mha", "(", "tomha", ",", "tomha", ",", "tomha", ")", "[", "0", "]", "\n", "x", "=", "self", ".", "dropout", "(", "out", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ")", "+", "x", "\n", "x", "=", "self", ".", "norm_mha", "(", "x", ")", "\n", "\n", "# lstm is applied", "\n", "out", "=", "self", ".", "linear", "(", "self", ".", "dropout", "(", "self", ".", "activation", "(", "self", ".", "recurrent", "(", "x", ".", "transpose", "(", "1", ",", "-", "1", ")", ")", "[", "0", "]", ")", ")", ")", "\n", "x", "=", "self", ".", "dropout", "(", "out", ".", "transpose", "(", "1", ",", "-", "1", ")", ")", "+", "x", "\n", "return", "self", ".", "norm_ff", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.attention.DPTransformer.__init__": [[97, 182], ["torch.Module.__init__", "dsp.overlap_add.DualPathProcessing", "torch.ModuleList", "torch.ModuleList", "range", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "activations.get", "utils.has_arg", "math.ceil", "warnings.warn", "torch.Linear", "torch.Linear", "norms.get", "attention.DPTransformer.layers.append", "torch.PReLU", "torch.PReLU", "torch.Conv1d", "torch.Conv1d", "torch.Tanh", "torch.Tanh", "torch.Conv1d", "torch.Conv1d", "torch.Sigmoid", "torch.Sigmoid", "activations.get.", "activations.get.", "torch.ModuleList", "torch.ModuleList", "attention.ImprovedTransformedLayer", "attention.ImprovedTransformedLayer"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.has_arg", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_chan", ",", "\n", "n_src", ",", "\n", "n_heads", "=", "4", ",", "\n", "ff_hid", "=", "256", ",", "\n", "chunk_size", "=", "100", ",", "\n", "hop_size", "=", "None", ",", "\n", "n_repeats", "=", "6", ",", "\n", "norm_type", "=", "\"gLN\"", ",", "\n", "ff_activation", "=", "\"relu\"", ",", "\n", "mask_act", "=", "\"relu\"", ",", "\n", "bidirectional", "=", "True", ",", "\n", "dropout", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", "DPTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_chan", "=", "in_chan", "\n", "self", ".", "n_src", "=", "n_src", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "self", ".", "ff_hid", "=", "ff_hid", "\n", "self", ".", "chunk_size", "=", "chunk_size", "\n", "hop_size", "=", "hop_size", "if", "hop_size", "is", "not", "None", "else", "chunk_size", "//", "2", "\n", "self", ".", "hop_size", "=", "hop_size", "\n", "self", ".", "n_repeats", "=", "n_repeats", "\n", "self", ".", "n_src", "=", "n_src", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "self", ".", "ff_activation", "=", "ff_activation", "\n", "self", ".", "mask_act", "=", "mask_act", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "mha_in_dim", "=", "ceil", "(", "self", ".", "in_chan", "/", "self", ".", "n_heads", ")", "*", "self", ".", "n_heads", "\n", "if", "self", ".", "in_chan", "%", "self", ".", "n_heads", "!=", "0", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "f\"DPTransformer input dim ({self.in_chan}) is not a multiple of the number of \"", "\n", "f\"heads ({self.n_heads}). Adding extra linear layer at input to accomodate \"", "\n", "f\"(size [{self.in_chan} x {self.mha_in_dim}])\"", "\n", ")", "\n", "self", ".", "input_layer", "=", "nn", ".", "Linear", "(", "self", ".", "in_chan", ",", "self", ".", "mha_in_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "input_layer", "=", "None", "\n", "\n", "", "self", ".", "in_norm", "=", "norms", ".", "get", "(", "norm_type", ")", "(", "self", ".", "mha_in_dim", ")", "\n", "self", ".", "ola", "=", "DualPathProcessing", "(", "self", ".", "chunk_size", ",", "self", ".", "hop_size", ")", "\n", "\n", "# Succession of DPRNNBlocks.", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "for", "x", "in", "range", "(", "self", ".", "n_repeats", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "ImprovedTransformedLayer", "(", "\n", "self", ".", "mha_in_dim", ",", "\n", "self", ".", "n_heads", ",", "\n", "self", ".", "ff_hid", ",", "\n", "self", ".", "dropout", ",", "\n", "self", ".", "ff_activation", ",", "\n", "True", ",", "\n", "self", ".", "norm_type", ",", "\n", ")", ",", "\n", "ImprovedTransformedLayer", "(", "\n", "self", ".", "mha_in_dim", ",", "\n", "self", ".", "n_heads", ",", "\n", "self", ".", "ff_hid", ",", "\n", "self", ".", "dropout", ",", "\n", "self", ".", "ff_activation", ",", "\n", "self", ".", "bidirectional", ",", "\n", "self", ".", "norm_type", ",", "\n", ")", ",", "\n", "]", "\n", ")", "\n", ")", "\n", "", "net_out_conv", "=", "nn", ".", "Conv2d", "(", "self", ".", "mha_in_dim", ",", "n_src", "*", "self", ".", "in_chan", ",", "1", ")", "\n", "self", ".", "first_out", "=", "nn", ".", "Sequential", "(", "nn", ".", "PReLU", "(", ")", ",", "net_out_conv", ")", "\n", "# Gating and masking in 2D space (after fold)", "\n", "self", ".", "net_out", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv1d", "(", "self", ".", "in_chan", ",", "self", ".", "in_chan", ",", "1", ")", ",", "nn", ".", "Tanh", "(", ")", ")", "\n", "self", ".", "net_gate", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv1d", "(", "self", ".", "in_chan", ",", "self", ".", "in_chan", ",", "1", ")", ",", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "\n", "# Get activation function.", "\n", "mask_nl_class", "=", "activations", ".", "get", "(", "mask_act", ")", "\n", "# For softmax, feed the source dimension.", "\n", "if", "has_arg", "(", "mask_nl_class", ",", "\"dim\"", ")", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.attention.DPTransformer.forward": [[183, 214], ["attention.DPTransformer.in_norm", "attention.DPTransformer.ola.unfold", "attention.DPTransformer.size", "range", "attention.DPTransformer.first_out", "output.reshape.reshape.reshape", "attention.DPTransformer.ola.fold", "output.reshape.reshape.reshape", "attention.DPTransformer.output_act", "attention.DPTransformer.input_layer().transpose", "len", "attention.DPTransformer.ola.intra_process", "attention.DPTransformer.ola.inter_process", "attention.DPTransformer.net_out", "attention.DPTransformer.net_gate", "attention.DPTransformer.input_layer", "attention.DPTransformer.transpose"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.unfold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.fold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.intra_process", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.inter_process"], ["", "", "def", "forward", "(", "self", ",", "mixture_w", ")", ":", "\n", "        ", "r\"\"\"Forward.\n\n        Args:\n            mixture_w (:class:`torch.Tensor`): Tensor of shape $(batch, nfilters, nframes)$\n\n        Returns:\n            :class:`torch.Tensor`: estimated mask of shape $(batch, nsrc, nfilters, nframes)$\n        \"\"\"", "\n", "if", "self", ".", "input_layer", "is", "not", "None", ":", "\n", "            ", "mixture_w", "=", "self", ".", "input_layer", "(", "mixture_w", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "", "mixture_w", "=", "self", ".", "in_norm", "(", "mixture_w", ")", "# [batch, bn_chan, n_frames]", "\n", "n_orig_frames", "=", "mixture_w", ".", "shape", "[", "-", "1", "]", "\n", "\n", "mixture_w", "=", "self", ".", "ola", ".", "unfold", "(", "mixture_w", ")", "\n", "batch", ",", "n_filters", ",", "self", ".", "chunk_size", ",", "n_chunks", "=", "mixture_w", ".", "size", "(", ")", "\n", "\n", "for", "layer_idx", "in", "range", "(", "len", "(", "self", ".", "layers", ")", ")", ":", "\n", "            ", "intra", ",", "inter", "=", "self", ".", "layers", "[", "layer_idx", "]", "\n", "mixture_w", "=", "self", ".", "ola", ".", "intra_process", "(", "mixture_w", ",", "intra", ")", "\n", "mixture_w", "=", "self", ".", "ola", ".", "inter_process", "(", "mixture_w", ",", "inter", ")", "\n", "\n", "", "output", "=", "self", ".", "first_out", "(", "mixture_w", ")", "\n", "output", "=", "output", ".", "reshape", "(", "batch", "*", "self", ".", "n_src", ",", "self", ".", "in_chan", ",", "self", ".", "chunk_size", ",", "n_chunks", ")", "\n", "output", "=", "self", ".", "ola", ".", "fold", "(", "output", ",", "output_size", "=", "n_orig_frames", ")", "\n", "\n", "output", "=", "self", ".", "net_out", "(", "output", ")", "*", "self", ".", "net_gate", "(", "output", ")", "\n", "# Compute mask", "\n", "output", "=", "output", ".", "reshape", "(", "batch", ",", "self", ".", "n_src", ",", "self", ".", "in_chan", ",", "-", "1", ")", "\n", "est_mask", "=", "self", ".", "output_act", "(", "output", ")", "\n", "return", "est_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.attention.DPTransformer.get_config": [[215, 231], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "\"in_chan\"", ":", "self", ".", "in_chan", ",", "\n", "\"ff_hid\"", ":", "self", ".", "ff_hid", ",", "\n", "\"n_heads\"", ":", "self", ".", "n_heads", ",", "\n", "\"chunk_size\"", ":", "self", ".", "chunk_size", ",", "\n", "\"hop_size\"", ":", "self", ".", "hop_size", ",", "\n", "\"n_repeats\"", ":", "self", ".", "n_repeats", ",", "\n", "\"n_src\"", ":", "self", ".", "n_src", ",", "\n", "\"norm_type\"", ":", "self", ".", "norm_type", ",", "\n", "\"ff_activation\"", ":", "self", ".", "ff_activation", ",", "\n", "\"mask_act\"", ":", "self", ".", "mask_act", ",", "\n", "\"bidirectional\"", ":", "self", ".", "bidirectional", ",", "\n", "\"dropout\"", ":", "self", ".", "dropout", ",", "\n", "}", "\n", "return", "config", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn._dcunet_architectures.make_unet_encoder_decoder_args": [[4, 35], ["tuple", "utils.generic_utils.unet_decoder_args", "tuple", "tuple", "tuple"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.unet_decoder_args"], ["def", "make_unet_encoder_decoder_args", "(", "encoder_args", ",", "decoder_args", ")", ":", "\n", "    ", "encoder_args", "=", "tuple", "(", "\n", "(", "\n", "in_chan", ",", "\n", "out_chan", ",", "\n", "kernel_size", ",", "\n", "stride", ",", "\n", "tuple", "(", "[", "n", "//", "2", "for", "n", "in", "kernel_size", "]", ")", "if", "padding", "==", "\"auto\"", "else", "padding", ",", "\n", ")", "\n", "for", "in_chan", ",", "out_chan", ",", "kernel_size", ",", "stride", ",", "padding", "in", "encoder_args", "\n", ")", "\n", "\n", "if", "decoder_args", "==", "\"auto\"", ":", "\n", "        ", "decoder_args", "=", "unet_decoder_args", "(", "\n", "encoder_args", ",", "\n", "skip_connections", "=", "True", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "decoder_args", "=", "tuple", "(", "\n", "(", "\n", "in_chan", ",", "\n", "out_chan", ",", "\n", "kernel_size", ",", "\n", "stride", ",", "\n", "tuple", "(", "[", "n", "//", "2", "for", "n", "in", "kernel_size", "]", ")", "if", "padding", "==", "\"auto\"", "else", "padding", ",", "\n", "output_padding", ",", "\n", ")", "\n", "for", "in_chan", ",", "out_chan", ",", "kernel_size", ",", "stride", ",", "padding", ",", "output_padding", "in", "decoder_args", "\n", ")", "\n", "\n", "", "return", "encoder_args", ",", "decoder_args", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional._Chop1d.__init__": [[21, 24], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "chop_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "chop_size", "=", "chop_size", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional._Chop1d.forward": [[25, 27], ["x[].contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "[", "...", ",", ":", "-", "self", ".", "chop_size", "]", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.Conv1DBlock.__init__": [[58, 89], ["torch.nn.Module.__init__", "norms.get", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Sequential", "torch.nn.Conv1d", "torch.nn.Sequential", "torch.nn.PReLU", "norms.get.", "torch.nn.PReLU", "norms.get.", "torch.nn.Conv1d", "convolutional._Chop1d"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_chan", ",", "\n", "hid_chan", ",", "\n", "skip_out_chan", ",", "\n", "kernel_size", ",", "\n", "padding", ",", "\n", "dilation", ",", "\n", "norm_type", "=", "\"gLN\"", ",", "\n", "causal", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "Conv1DBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "skip_out_chan", "=", "skip_out_chan", "\n", "conv_norm", "=", "norms", ".", "get", "(", "norm_type", ")", "\n", "in_conv1d", "=", "nn", ".", "Conv1d", "(", "in_chan", ",", "hid_chan", ",", "1", ")", "\n", "depth_conv1d", "=", "nn", ".", "Conv1d", "(", "\n", "hid_chan", ",", "hid_chan", ",", "kernel_size", ",", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "groups", "=", "hid_chan", "\n", ")", "\n", "if", "causal", ":", "\n", "            ", "depth_conv1d", "=", "nn", ".", "Sequential", "(", "depth_conv1d", ",", "_Chop1d", "(", "padding", ")", ")", "\n", "", "self", ".", "shared_block", "=", "nn", ".", "Sequential", "(", "\n", "in_conv1d", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "conv_norm", "(", "hid_chan", ")", ",", "\n", "depth_conv1d", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "conv_norm", "(", "hid_chan", ")", ",", "\n", ")", "\n", "self", ".", "res_conv", "=", "nn", ".", "Conv1d", "(", "hid_chan", ",", "in_chan", ",", "1", ")", "\n", "if", "skip_out_chan", ":", "\n", "            ", "self", ".", "skip_conv", "=", "nn", ".", "Conv1d", "(", "hid_chan", ",", "skip_out_chan", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.Conv1DBlock.forward": [[90, 98], ["convolutional.Conv1DBlock.shared_block", "convolutional.Conv1DBlock.res_conv", "convolutional.Conv1DBlock.skip_conv"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "r\"\"\"Input shape $(batch, feats, seq)$.\"\"\"", "\n", "shared_out", "=", "self", ".", "shared_block", "(", "x", ")", "\n", "res_out", "=", "self", ".", "res_conv", "(", "shared_out", ")", "\n", "if", "not", "self", ".", "skip_out_chan", ":", "\n", "            ", "return", "res_out", "\n", "", "skip_out", "=", "self", ".", "skip_conv", "(", "shared_out", ")", "\n", "return", "res_out", ",", "skip_out", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.TDConvNet.__init__": [[130, 193], ["torch.nn.Module.__init__", "torch.nn.Conv1d", "torch.nn.Sequential", "torch.nn.ModuleList", "range", "torch.nn.Conv1d", "torch.nn.Sequential", "activations.get", "utils.has_arg", "norms.get", "range", "torch.nn.PReLU", "activations.get.", "activations.get.", "convolutional.TDConvNet.TCN.append", "convolutional.Conv1DBlock"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.has_arg", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_chan", ",", "\n", "n_src", ",", "\n", "out_chan", "=", "None", ",", "\n", "n_blocks", "=", "8", ",", "\n", "n_repeats", "=", "3", ",", "\n", "bn_chan", "=", "128", ",", "\n", "hid_chan", "=", "512", ",", "\n", "skip_chan", "=", "128", ",", "\n", "conv_kernel_size", "=", "3", ",", "\n", "norm_type", "=", "\"gLN\"", ",", "\n", "mask_act", "=", "\"relu\"", ",", "\n", "causal", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "TDConvNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_chan", "=", "in_chan", "\n", "self", ".", "n_src", "=", "n_src", "\n", "out_chan", "=", "out_chan", "if", "out_chan", "else", "in_chan", "\n", "self", ".", "out_chan", "=", "out_chan", "\n", "self", ".", "n_blocks", "=", "n_blocks", "\n", "self", ".", "n_repeats", "=", "n_repeats", "\n", "self", ".", "bn_chan", "=", "bn_chan", "\n", "self", ".", "hid_chan", "=", "hid_chan", "\n", "self", ".", "skip_chan", "=", "skip_chan", "\n", "self", ".", "conv_kernel_size", "=", "conv_kernel_size", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "self", ".", "mask_act", "=", "mask_act", "\n", "self", ".", "causal", "=", "causal", "\n", "\n", "layer_norm", "=", "norms", ".", "get", "(", "norm_type", ")", "(", "in_chan", ")", "\n", "bottleneck_conv", "=", "nn", ".", "Conv1d", "(", "in_chan", ",", "bn_chan", ",", "1", ")", "\n", "self", ".", "bottleneck", "=", "nn", ".", "Sequential", "(", "layer_norm", ",", "bottleneck_conv", ")", "\n", "# Succession of Conv1DBlock with exponentially increasing dilation.", "\n", "self", ".", "TCN", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "r", "in", "range", "(", "n_repeats", ")", ":", "\n", "            ", "for", "x", "in", "range", "(", "n_blocks", ")", ":", "\n", "                ", "if", "not", "causal", ":", "\n", "                    ", "padding", "=", "(", "conv_kernel_size", "-", "1", ")", "*", "2", "**", "x", "//", "2", "\n", "", "else", ":", "\n", "                    ", "padding", "=", "(", "conv_kernel_size", "-", "1", ")", "*", "2", "**", "x", "\n", "", "self", ".", "TCN", ".", "append", "(", "\n", "Conv1DBlock", "(", "\n", "bn_chan", ",", "\n", "hid_chan", ",", "\n", "skip_chan", ",", "\n", "conv_kernel_size", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation", "=", "2", "**", "x", ",", "\n", "norm_type", "=", "norm_type", ",", "\n", "causal", "=", "causal", ",", "\n", ")", "\n", ")", "\n", "", "", "mask_conv_inp", "=", "skip_chan", "if", "skip_chan", "else", "bn_chan", "\n", "mask_conv", "=", "nn", ".", "Conv1d", "(", "mask_conv_inp", ",", "n_src", "*", "out_chan", ",", "1", ")", "\n", "self", ".", "mask_net", "=", "nn", ".", "Sequential", "(", "nn", ".", "PReLU", "(", ")", ",", "mask_conv", ")", "\n", "# Get activation function.", "\n", "mask_nl_class", "=", "activations", ".", "get", "(", "mask_act", ")", "\n", "# For softmax, feed the source dimension.", "\n", "if", "has_arg", "(", "mask_nl_class", ",", "\"dim\"", ")", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.TDConvNet.forward": [[194, 221], ["mixture_w.size", "convolutional.TDConvNet.bottleneck", "torch.tensor", "convolutional.TDConvNet.mask_net", "score.view.view.view", "convolutional.TDConvNet.output_act", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "mixture_w", ")", ":", "\n", "        ", "r\"\"\"Forward.\n\n        Args:\n            mixture_w (:class:`torch.Tensor`): Tensor of shape $(batch, nfilters, nframes)$\n\n        Returns:\n            :class:`torch.Tensor`: estimated mask of shape $(batch, nsrc, nfilters, nframes)$\n        \"\"\"", "\n", "batch", ",", "_", ",", "n_frames", "=", "mixture_w", ".", "size", "(", ")", "\n", "output", "=", "self", ".", "bottleneck", "(", "mixture_w", ")", "\n", "skip_connection", "=", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "device", "=", "output", ".", "device", ")", "\n", "for", "layer", "in", "self", ".", "TCN", ":", "\n", "# Common to w. skip and w.o skip architectures", "\n", "            ", "tcn_out", "=", "layer", "(", "output", ")", "\n", "if", "self", ".", "skip_chan", ":", "\n", "                ", "residual", ",", "skip", "=", "tcn_out", "\n", "skip_connection", "=", "skip_connection", "+", "skip", "\n", "", "else", ":", "\n", "                ", "residual", "=", "tcn_out", "\n", "", "output", "=", "output", "+", "residual", "\n", "# Use residual output when no skip connection", "\n", "", "mask_inp", "=", "skip_connection", "if", "self", ".", "skip_chan", "else", "output", "\n", "score", "=", "self", ".", "mask_net", "(", "mask_inp", ")", "\n", "score", "=", "score", ".", "view", "(", "batch", ",", "self", ".", "n_src", ",", "self", ".", "out_chan", ",", "n_frames", ")", "\n", "est_mask", "=", "self", ".", "output_act", "(", "score", ")", "\n", "return", "est_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.TDConvNet.get_config": [[222, 238], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "\"in_chan\"", ":", "self", ".", "in_chan", ",", "\n", "\"out_chan\"", ":", "self", ".", "out_chan", ",", "\n", "\"bn_chan\"", ":", "self", ".", "bn_chan", ",", "\n", "\"hid_chan\"", ":", "self", ".", "hid_chan", ",", "\n", "\"skip_chan\"", ":", "self", ".", "skip_chan", ",", "\n", "\"conv_kernel_size\"", ":", "self", ".", "conv_kernel_size", ",", "\n", "\"n_blocks\"", ":", "self", ".", "n_blocks", ",", "\n", "\"n_repeats\"", ":", "self", ".", "n_repeats", ",", "\n", "\"n_src\"", ":", "self", ".", "n_src", ",", "\n", "\"norm_type\"", ":", "self", ".", "norm_type", ",", "\n", "\"mask_act\"", ":", "self", ".", "mask_act", ",", "\n", "\"causal\"", ":", "self", ".", "causal", ",", "\n", "}", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.TDConvNetpp.__init__": [[280, 349], ["torch.nn.Module.__init__", "torch.nn.Conv1d", "torch.nn.Sequential", "torch.nn.ModuleList", "range", "torch.nn.ModuleList", "range", "torch.Tensor", "scaling_param.unsqueeze().expand().clone.unsqueeze().expand().clone.unsqueeze().expand().clone", "torch.nn.Parameter", "torch.nn.Conv1d", "torch.nn.Sequential", "activations.get", "utils.has_arg", "torch.nn.Linear", "norms.get", "range", "convolutional.TDConvNetpp.dense_skip.append", "torch.nn.PReLU", "activations.get.", "activations.get.", "convolutional.TDConvNetpp.TCN.append", "torch.nn.Conv1d", "scaling_param.unsqueeze().expand().clone.unsqueeze().expand().clone.unsqueeze().expand", "convolutional.Conv1DBlock", "range", "scaling_param.unsqueeze().expand().clone.unsqueeze().expand().clone.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.has_arg", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_chan", ",", "\n", "n_src", ",", "\n", "out_chan", "=", "None", ",", "\n", "n_blocks", "=", "8", ",", "\n", "n_repeats", "=", "3", ",", "\n", "bn_chan", "=", "128", ",", "\n", "hid_chan", "=", "512", ",", "\n", "skip_chan", "=", "128", ",", "\n", "conv_kernel_size", "=", "3", ",", "\n", "norm_type", "=", "\"fgLN\"", ",", "\n", "mask_act", "=", "\"relu\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_chan", "=", "in_chan", "\n", "self", ".", "n_src", "=", "n_src", "\n", "out_chan", "=", "out_chan", "if", "out_chan", "else", "in_chan", "\n", "self", ".", "out_chan", "=", "out_chan", "\n", "self", ".", "n_blocks", "=", "n_blocks", "\n", "self", ".", "n_repeats", "=", "n_repeats", "\n", "self", ".", "bn_chan", "=", "bn_chan", "\n", "self", ".", "hid_chan", "=", "hid_chan", "\n", "self", ".", "skip_chan", "=", "skip_chan", "\n", "self", ".", "conv_kernel_size", "=", "conv_kernel_size", "\n", "self", ".", "norm_type", "=", "norm_type", "\n", "self", ".", "mask_act", "=", "mask_act", "\n", "\n", "layer_norm", "=", "norms", ".", "get", "(", "norm_type", ")", "(", "in_chan", ")", "\n", "bottleneck_conv", "=", "nn", ".", "Conv1d", "(", "in_chan", ",", "bn_chan", ",", "1", ")", "\n", "self", ".", "bottleneck", "=", "nn", ".", "Sequential", "(", "layer_norm", ",", "bottleneck_conv", ")", "\n", "# Succession of Conv1DBlock with exponentially increasing dilation.", "\n", "self", ".", "TCN", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "r", "in", "range", "(", "n_repeats", ")", ":", "\n", "            ", "for", "x", "in", "range", "(", "n_blocks", ")", ":", "\n", "                ", "padding", "=", "(", "conv_kernel_size", "-", "1", ")", "*", "2", "**", "x", "//", "2", "\n", "self", ".", "TCN", ".", "append", "(", "\n", "Conv1DBlock", "(", "\n", "bn_chan", ",", "\n", "hid_chan", ",", "\n", "skip_chan", ",", "\n", "conv_kernel_size", ",", "\n", "padding", "=", "padding", ",", "\n", "dilation", "=", "2", "**", "x", ",", "\n", "norm_type", "=", "norm_type", ",", "\n", ")", "\n", ")", "\n", "# Dense connection in TDCNpp", "\n", "", "", "self", ".", "dense_skip", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "r", "in", "range", "(", "n_repeats", "-", "1", ")", ":", "\n", "            ", "self", ".", "dense_skip", ".", "append", "(", "nn", ".", "Conv1d", "(", "bn_chan", ",", "bn_chan", ",", "1", ")", ")", "\n", "\n", "", "scaling_param", "=", "torch", ".", "Tensor", "(", "[", "0.9", "**", "l", "for", "l", "in", "range", "(", "1", ",", "n_blocks", ")", "]", ")", "\n", "scaling_param", "=", "scaling_param", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "n_repeats", ",", "n_blocks", "-", "1", ")", ".", "clone", "(", ")", "\n", "self", ".", "scaling_param", "=", "nn", ".", "Parameter", "(", "scaling_param", ",", "requires_grad", "=", "True", ")", "\n", "\n", "mask_conv_inp", "=", "skip_chan", "if", "skip_chan", "else", "bn_chan", "\n", "mask_conv", "=", "nn", ".", "Conv1d", "(", "mask_conv_inp", ",", "n_src", "*", "out_chan", ",", "1", ")", "\n", "self", ".", "mask_net", "=", "nn", ".", "Sequential", "(", "nn", ".", "PReLU", "(", ")", ",", "mask_conv", ")", "\n", "# Get activation function.", "\n", "mask_nl_class", "=", "activations", ".", "get", "(", "mask_act", ")", "\n", "# For softmax, feed the source dimension.", "\n", "if", "has_arg", "(", "mask_nl_class", ",", "\"dim\"", ")", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", ")", "\n", "\n", "", "out_size", "=", "skip_chan", "if", "skip_chan", "else", "bn_chan", "\n", "self", ".", "consistency", "=", "nn", ".", "Linear", "(", "out_size", ",", "n_src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.TDConvNetpp.forward": [[350, 394], ["mixture_w.size", "convolutional.TDConvNetpp.bottleneck", "range", "convolutional.TDConvNetpp.mask_net", "score.view.view.view", "convolutional.TDConvNetpp.output_act", "convolutional.TDConvNetpp.consistency", "torch.nn.functional.softmax", "range", "mask_inp.mean"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax"], ["", "def", "forward", "(", "self", ",", "mixture_w", ")", ":", "\n", "        ", "r\"\"\"Forward.\n\n        Args:\n            mixture_w (:class:`torch.Tensor`): Tensor of shape $(batch, nfilters, nframes)$\n\n        Returns:\n            :class:`torch.Tensor`: estimated mask of shape $(batch, nsrc, nfilters, nframes)$\n        \"\"\"", "\n", "batch", ",", "n_filters", ",", "n_frames", "=", "mixture_w", ".", "size", "(", ")", "\n", "output", "=", "self", ".", "bottleneck", "(", "mixture_w", ")", "\n", "output_copy", "=", "output", "\n", "\n", "skip_connection", "=", "0.0", "\n", "for", "r", "in", "range", "(", "self", ".", "n_repeats", ")", ":", "\n", "# Long range skip connection TDCNpp", "\n", "            ", "if", "r", "!=", "0", ":", "\n", "# Transform the input to repeat r-1 and add to new repeat inp", "\n", "                ", "output", "=", "self", ".", "dense_skip", "[", "r", "-", "1", "]", "(", "output_copy", ")", "+", "output", "\n", "# Copy this for later.", "\n", "output_copy", "=", "output", "\n", "", "for", "x", "in", "range", "(", "self", ".", "n_blocks", ")", ":", "\n", "# Common to w. skip and w.o skip architectures", "\n", "                ", "i", "=", "r", "*", "self", ".", "n_blocks", "+", "x", "\n", "tcn_out", "=", "self", ".", "TCN", "[", "i", "]", "(", "output", ")", "\n", "if", "self", ".", "skip_chan", ":", "\n", "                    ", "residual", ",", "skip", "=", "tcn_out", "\n", "skip_connection", "=", "skip_connection", "+", "skip", "\n", "", "else", ":", "\n", "                    ", "residual", ",", "_", "=", "tcn_out", "\n", "# Initialized exp decay scale factor TDCNpp for residual connections", "\n", "", "scale", "=", "self", ".", "scaling_param", "[", "r", ",", "x", "-", "1", "]", "if", "x", ">", "0", "else", "1.0", "\n", "residual", "=", "residual", "*", "scale", "\n", "output", "=", "output", "+", "residual", "\n", "# Use residual output when no skip connection", "\n", "", "", "mask_inp", "=", "skip_connection", "if", "self", ".", "skip_chan", "else", "output", "\n", "score", "=", "self", ".", "mask_net", "(", "mask_inp", ")", "\n", "score", "=", "score", ".", "view", "(", "batch", ",", "self", ".", "n_src", ",", "self", ".", "out_chan", ",", "n_frames", ")", "\n", "est_mask", "=", "self", ".", "output_act", "(", "score", ")", "\n", "\n", "weights", "=", "self", ".", "consistency", "(", "mask_inp", ".", "mean", "(", "-", "1", ")", ")", "\n", "weights", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "weights", ",", "-", "1", ")", "\n", "\n", "return", "est_mask", ",", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.TDConvNetpp.get_config": [[395, 410], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "\"in_chan\"", ":", "self", ".", "in_chan", ",", "\n", "\"out_chan\"", ":", "self", ".", "out_chan", ",", "\n", "\"bn_chan\"", ":", "self", ".", "bn_chan", ",", "\n", "\"hid_chan\"", ":", "self", ".", "hid_chan", ",", "\n", "\"skip_chan\"", ":", "self", ".", "skip_chan", ",", "\n", "\"conv_kernel_size\"", ":", "self", ".", "conv_kernel_size", ",", "\n", "\"n_blocks\"", ":", "self", ".", "n_blocks", ",", "\n", "\"n_repeats\"", ":", "self", ".", "n_repeats", ",", "\n", "\"n_src\"", ":", "self", ".", "n_src", ",", "\n", "\"norm_type\"", ":", "self", ".", "norm_type", ",", "\n", "\"mask_act\"", ":", "self", ".", "mask_act", ",", "\n", "}", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.DCUNetComplexEncoderBlock.__init__": [[431, 451], ["torch.nn.Module.__init__", "complex_nn.ComplexConv2d", "activations.get_complex", "activations.get_complex.", "norms.get_complex"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get_complex", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get_complex"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_chan", ",", "\n", "out_chan", ",", "\n", "kernel_size", ",", "\n", "stride", ",", "\n", "padding", ",", "\n", "norm_type", "=", "\"bN\"", ",", "\n", "activation", "=", "\"leaky_relu\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "complex_nn", ".", "ComplexConv2d", "(", "\n", "in_chan", ",", "out_chan", ",", "kernel_size", ",", "stride", ",", "padding", ",", "bias", "=", "norm_type", "is", "None", "\n", ")", "\n", "\n", "self", ".", "norm", "=", "norms", ".", "get_complex", "(", "norm_type", ")", "(", "out_chan", ")", "\n", "\n", "activation_class", "=", "activations", ".", "get_complex", "(", "activation", ")", "\n", "self", ".", "activation", "=", "activation_class", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.DCUNetComplexEncoderBlock.forward": [[452, 454], ["convolutional.DCUNetComplexEncoderBlock.activation", "convolutional.DCUNetComplexEncoderBlock.norm", "convolutional.DCUNetComplexEncoderBlock.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "complex_nn", ".", "ComplexTensor", ")", ":", "\n", "        ", "return", "self", ".", "activation", "(", "self", ".", "norm", "(", "self", ".", "conv", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.DCUNetComplexDecoderBlock.__init__": [[475, 503], ["torch.nn.Module.__init__", "complex_nn.ComplexConvTranspose2d", "activations.get_complex", "activations.get_complex.", "norms.get_complex"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get_complex", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get_complex"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_chan", ",", "\n", "out_chan", ",", "\n", "kernel_size", ",", "\n", "stride", ",", "\n", "padding", ",", "\n", "output_padding", "=", "(", "0", ",", "0", ")", ",", "\n", "norm_type", "=", "\"bN\"", ",", "\n", "activation", "=", "\"leaky_relu\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_chan", "=", "in_chan", "\n", "self", ".", "out_chan", "=", "out_chan", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "output_padding", "=", "output_padding", "\n", "\n", "self", ".", "deconv", "=", "complex_nn", ".", "ComplexConvTranspose2d", "(", "\n", "in_chan", ",", "out_chan", ",", "kernel_size", ",", "stride", ",", "padding", ",", "output_padding", ",", "bias", "=", "norm_type", "is", "None", "\n", ")", "\n", "\n", "self", ".", "norm", "=", "norms", ".", "get_complex", "(", "norm_type", ")", "(", "out_chan", ")", "\n", "\n", "activation_class", "=", "activations", ".", "get_complex", "(", "activation", ")", "\n", "self", ".", "activation", "=", "activation_class", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.DCUNetComplexDecoderBlock.forward": [[504, 506], ["convolutional.DCUNetComplexDecoderBlock.activation", "convolutional.DCUNetComplexDecoderBlock.norm", "convolutional.DCUNetComplexDecoderBlock.deconv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "complex_nn", ".", "ComplexTensor", ")", ":", "\n", "        ", "return", "self", ".", "activation", "(", "self", ".", "norm", "(", "self", ".", "deconv", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.DCUMaskNet.__init__": [[528, 542], ["numpy.prod", "base.BaseDCUMaskNet.__init__", "complex_nn.ComplexConvTranspose2d", "convolutional.DCUNetComplexEncoderBlock", "convolutional.DCUNetComplexDecoderBlock"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "encoders", ",", "decoders", ",", "fix_length_mode", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "fix_length_mode", "=", "fix_length_mode", "\n", "self", ".", "encoders_stride_product", "=", "np", ".", "prod", "(", "\n", "[", "enc_stride", "for", "_", ",", "_", ",", "_", ",", "enc_stride", ",", "_", "in", "encoders", "]", ",", "axis", "=", "0", "\n", ")", "\n", "\n", "# Avoid circual import", "\n", "from", ".", "convolutional", "import", "DCUNetComplexDecoderBlock", ",", "DCUNetComplexEncoderBlock", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "encoders", "=", "[", "DCUNetComplexEncoderBlock", "(", "*", "args", ")", "for", "args", "in", "encoders", "]", ",", "\n", "decoders", "=", "[", "DCUNetComplexDecoderBlock", "(", "*", "args", ")", "for", "args", "in", "decoders", "[", ":", "-", "1", "]", "]", ",", "\n", "output_layer", "=", "complex_nn", ".", "ComplexConvTranspose2d", "(", "*", "decoders", "[", "-", "1", "]", ")", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.DCUMaskNet.fix_input_dims": [[544, 547], ["convolutional._fix_dcu_input_dims", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional._fix_dcu_input_dims"], ["", "def", "fix_input_dims", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "_fix_dcu_input_dims", "(", "\n", "self", ".", "fix_length_mode", ",", "x", ",", "torch", ".", "from_numpy", "(", "self", ".", "encoders_stride_product", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.DCUMaskNet.fix_output_dims": [[549, 551], ["convolutional._fix_dcu_output_dims"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional._fix_dcu_output_dims"], ["", "def", "fix_output_dims", "(", "self", ",", "out", ",", "x", ")", ":", "\n", "        ", "return", "_fix_dcu_output_dims", "(", "self", ".", "fix_length_mode", ",", "out", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.SuDORMRF.__init__": [[604, 655], ["torch.nn.Module.__init__", "torch.nn.GroupNorm", "torch.nn.Conv1d", "torch.nn.Sequential", "torch.nn.Conv2d", "activations.get", "utils.has_arg", "torch.nn.Conv1d", "activations.get.", "activations.get.", "convolutional.UBlock", "range"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.has_arg"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_chan", ",", "\n", "n_src", ",", "\n", "bn_chan", "=", "128", ",", "\n", "num_blocks", "=", "16", ",", "\n", "upsampling_depth", "=", "4", ",", "\n", "mask_act", "=", "\"softmax\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_chan", "=", "in_chan", "\n", "self", ".", "n_src", "=", "n_src", "\n", "self", ".", "bn_chan", "=", "bn_chan", "\n", "self", ".", "num_blocks", "=", "num_blocks", "\n", "self", ".", "upsampling_depth", "=", "upsampling_depth", "\n", "self", ".", "mask_act", "=", "mask_act", "\n", "\n", "# Norm before the rest, and apply one more dense layer", "\n", "self", ".", "ln", "=", "nn", ".", "GroupNorm", "(", "1", ",", "in_chan", ",", "eps", "=", "1e-08", ")", "\n", "self", ".", "l1", "=", "nn", ".", "Conv1d", "(", "in_chan", ",", "bn_chan", ",", "kernel_size", "=", "1", ")", "\n", "\n", "# Separation module", "\n", "self", ".", "sm", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "UBlock", "(", "\n", "out_chan", "=", "bn_chan", ",", "\n", "in_chan", "=", "in_chan", ",", "\n", "upsampling_depth", "=", "upsampling_depth", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_blocks", ")", "\n", "]", "\n", ")", "\n", "\n", "if", "bn_chan", "!=", "in_chan", ":", "\n", "            ", "self", ".", "reshape_before_masks", "=", "nn", ".", "Conv1d", "(", "bn_chan", ",", "in_chan", ",", "kernel_size", "=", "1", ")", "\n", "\n", "# Masks layer", "\n", "", "self", ".", "m", "=", "nn", ".", "Conv2d", "(", "\n", "1", ",", "\n", "n_src", ",", "\n", "kernel_size", "=", "(", "in_chan", "+", "1", ",", "1", ")", ",", "\n", "padding", "=", "(", "in_chan", "-", "in_chan", "//", "2", ",", "0", ")", ",", "\n", ")", "\n", "\n", "# Get activation function.", "\n", "mask_nl_class", "=", "activations", ".", "get", "(", "mask_act", ")", "\n", "# For softmax, feed the source dimension.", "\n", "if", "has_arg", "(", "mask_nl_class", ",", "\"dim\"", ")", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.SuDORMRF.forward": [[656, 668], ["convolutional.SuDORMRF.ln", "convolutional.SuDORMRF.l1", "convolutional.SuDORMRF.sm", "convolutional.SuDORMRF.m", "convolutional.SuDORMRF.output_act", "convolutional.SuDORMRF.reshape_before_masks", "convolutional.SuDORMRF.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "ln", "(", "x", ")", "\n", "x", "=", "self", ".", "l1", "(", "x", ")", "\n", "x", "=", "self", ".", "sm", "(", "x", ")", "\n", "\n", "if", "self", ".", "bn_chan", "!=", "self", ".", "in_chan", ":", "\n", "            ", "x", "=", "self", ".", "reshape_before_masks", "(", "x", ")", "\n", "\n", "# Get output + activation", "\n", "", "x", "=", "self", ".", "m", "(", "x", ".", "unsqueeze", "(", "1", ")", ")", "\n", "x", "=", "self", ".", "output_act", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.SuDORMRF.get_config": [[669, 679], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "\"in_chan\"", ":", "self", ".", "in_chan", ",", "\n", "\"n_src\"", ":", "self", ".", "n_src", ",", "\n", "\"bn_chan\"", ":", "self", ".", "bn_chan", ",", "\n", "\"num_blocks\"", ":", "self", ".", "num_blocks", ",", "\n", "\"upsampling_depth\"", ":", "self", ".", "upsampling_depth", ",", "\n", "\"mask_act\"", ":", "self", ".", "mask_act", ",", "\n", "}", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.SuDORMRFImproved.__init__": [[698, 741], ["torch.nn.Module.__init__", "norms.GlobLN", "torch.nn.Conv1d", "torch.nn.Sequential", "torch.nn.Conv1d", "torch.nn.Sequential", "activations.get", "utils.has_arg", "torch.nn.PReLU", "activations.get.", "activations.get.", "convolutional.UConvBlock", "range"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.has_arg"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_chan", ",", "\n", "n_src", ",", "\n", "bn_chan", "=", "128", ",", "\n", "num_blocks", "=", "16", ",", "\n", "upsampling_depth", "=", "4", ",", "\n", "mask_act", "=", "\"relu\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_chan", "=", "in_chan", "\n", "self", ".", "n_src", "=", "n_src", "\n", "self", ".", "bn_chan", "=", "bn_chan", "\n", "self", ".", "num_blocks", "=", "num_blocks", "\n", "self", ".", "upsampling_depth", "=", "upsampling_depth", "\n", "self", ".", "mask_act", "=", "mask_act", "\n", "\n", "# Norm before the rest, and apply one more dense layer", "\n", "self", ".", "ln", "=", "GlobLN", "(", "in_chan", ")", "\n", "self", ".", "bottleneck", "=", "nn", ".", "Conv1d", "(", "in_chan", ",", "bn_chan", ",", "kernel_size", "=", "1", ")", "\n", "\n", "# Separation module", "\n", "self", ".", "sm", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "UConvBlock", "(", "\n", "out_chan", "=", "bn_chan", ",", "\n", "in_chan", "=", "in_chan", ",", "\n", "upsampling_depth", "=", "upsampling_depth", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_blocks", ")", "\n", "]", "\n", ")", "\n", "\n", "mask_conv", "=", "nn", ".", "Conv1d", "(", "bn_chan", ",", "n_src", "*", "in_chan", ",", "1", ")", "\n", "self", ".", "mask_net", "=", "nn", ".", "Sequential", "(", "nn", ".", "PReLU", "(", ")", ",", "mask_conv", ")", "\n", "\n", "# Get activation function.", "\n", "mask_nl_class", "=", "activations", ".", "get", "(", "mask_act", ")", "\n", "# For softmax, feed the source dimension.", "\n", "if", "has_arg", "(", "mask_nl_class", ",", "\"dim\"", ")", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "output_act", "=", "mask_nl_class", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.SuDORMRFImproved.forward": [[742, 751], ["convolutional.SuDORMRFImproved.ln", "convolutional.SuDORMRFImproved.bottleneck", "convolutional.SuDORMRFImproved.sm", "convolutional.SuDORMRFImproved.mask_net", "convolutional.SuDORMRFImproved.view", "convolutional.SuDORMRFImproved.output_act"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "ln", "(", "x", ")", "\n", "x", "=", "self", ".", "bottleneck", "(", "x", ")", "\n", "x", "=", "self", ".", "sm", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "mask_net", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "shape", "[", "0", "]", ",", "self", ".", "n_src", ",", "self", ".", "in_chan", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "output_act", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.SuDORMRFImproved.get_config": [[752, 762], ["None"], "methods", ["None"], ["", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "{", "\n", "\"in_chan\"", ":", "self", ".", "in_chan", ",", "\n", "\"n_src\"", ":", "self", ".", "n_src", ",", "\n", "\"bn_chan\"", ":", "self", ".", "bn_chan", ",", "\n", "\"num_blocks\"", ":", "self", ".", "num_blocks", ",", "\n", "\"upsampling_depth\"", ":", "self", ".", "upsampling_depth", ",", "\n", "\"mask_act\"", ":", "self", ".", "mask_act", ",", "\n", "}", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional._BaseUBlock.__init__": [[765, 803], ["torch.nn.Module.__init__", "_local._ConvNormAct", "torch.nn.ModuleList", "convolutional._BaseUBlock.spp_dw.append", "range", "_local._DilatedConvNorm", "convolutional._BaseUBlock.spp_dw.append", "torch.nn.Upsample", "_local._DilatedConvNorm"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "out_chan", "=", "128", ",", "in_chan", "=", "512", ",", "upsampling_depth", "=", "4", ",", "use_globln", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "proj_1x1", "=", "_ConvNormAct", "(", "\n", "out_chan", ",", "in_chan", ",", "1", ",", "stride", "=", "1", ",", "groups", "=", "1", ",", "use_globln", "=", "use_globln", "\n", ")", "\n", "self", ".", "depth", "=", "upsampling_depth", "\n", "self", ".", "spp_dw", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "spp_dw", ".", "append", "(", "\n", "_DilatedConvNorm", "(", "\n", "in_chan", ",", "\n", "in_chan", ",", "\n", "kSize", "=", "5", ",", "\n", "stride", "=", "1", ",", "\n", "groups", "=", "in_chan", ",", "\n", "d", "=", "1", ",", "\n", "use_globln", "=", "use_globln", ",", "\n", ")", "\n", ")", "\n", "\n", "for", "i", "in", "range", "(", "1", ",", "upsampling_depth", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "stride", "=", "1", "\n", "", "else", ":", "\n", "                ", "stride", "=", "2", "\n", "", "self", ".", "spp_dw", ".", "append", "(", "\n", "_DilatedConvNorm", "(", "\n", "in_chan", ",", "\n", "in_chan", ",", "\n", "kSize", "=", "2", "*", "stride", "+", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "groups", "=", "in_chan", ",", "\n", "d", "=", "1", ",", "\n", "use_globln", "=", "use_globln", ",", "\n", ")", "\n", ")", "\n", "", "if", "upsampling_depth", ">", "1", ":", "\n", "            ", "self", ".", "upsampler", "=", "torch", ".", "nn", ".", "Upsample", "(", "\n", "scale_factor", "=", "2", ",", "\n", "# align_corners=True,", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.UBlock.__init__": [[814, 819], ["convolutional._BaseUBlock.__init__", "_local._ConvNorm", "_local._NormAct", "_local._NormAct"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "out_chan", "=", "128", ",", "in_chan", "=", "512", ",", "upsampling_depth", "=", "4", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "out_chan", ",", "in_chan", ",", "upsampling_depth", ",", "use_globln", "=", "False", ")", "\n", "self", ".", "conv_1x1_exp", "=", "_ConvNorm", "(", "in_chan", ",", "out_chan", ",", "1", ",", "1", ",", "groups", "=", "1", ")", "\n", "self", ".", "final_norm", "=", "_NormAct", "(", "in_chan", ")", "\n", "self", ".", "module_act", "=", "_NormAct", "(", "out_chan", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.UBlock.forward": [[820, 846], ["convolutional.UBlock.proj_1x1", "range", "range", "convolutional.UBlock.conv_1x1_exp", "convolutional.UBlock.module_act", "output.append", "convolutional.UBlock.upsampler", "convolutional.UBlock.final_norm", "output.pop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x: input feature map\n\n        Returns:\n            transformed feature map\n        \"\"\"", "\n", "\n", "# Reduce --> project high-dimensional feature maps to low-dimensional space", "\n", "output1", "=", "self", ".", "proj_1x1", "(", "x", ")", "\n", "output", "=", "[", "self", ".", "spp_dw", "[", "0", "]", "(", "output1", ")", "]", "\n", "\n", "# Do the downsampling process from the previous level", "\n", "for", "k", "in", "range", "(", "1", ",", "self", ".", "depth", ")", ":", "\n", "            ", "out_k", "=", "self", ".", "spp_dw", "[", "k", "]", "(", "output", "[", "-", "1", "]", ")", "\n", "output", ".", "append", "(", "out_k", ")", "\n", "\n", "# Gather them now in reverse order", "\n", "", "for", "_", "in", "range", "(", "self", ".", "depth", "-", "1", ")", ":", "\n", "            ", "resampled_out_k", "=", "self", ".", "upsampler", "(", "output", ".", "pop", "(", "-", "1", ")", ")", "\n", "output", "[", "-", "1", "]", "=", "output", "[", "-", "1", "]", "+", "resampled_out_k", "[", "...", ",", ":", "output", "[", "-", "1", "]", ".", "shape", "[", "-", "1", "]", "]", "\n", "\n", "", "expanded", "=", "self", ".", "conv_1x1_exp", "(", "self", ".", "final_norm", "(", "output", "[", "-", "1", "]", ")", ")", "\n", "\n", "return", "self", ".", "module_act", "(", "expanded", "+", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.UConvBlock.__init__": [[853, 857], ["convolutional._BaseUBlock.__init__", "_local._NormAct", "torch.nn.Conv1d"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "out_chan", "=", "128", ",", "in_chan", "=", "512", ",", "upsampling_depth", "=", "4", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "out_chan", ",", "in_chan", ",", "upsampling_depth", ",", "use_globln", "=", "True", ")", "\n", "self", ".", "final_norm", "=", "_NormAct", "(", "in_chan", ",", "use_globln", "=", "True", ")", "\n", "self", ".", "res_conv", "=", "nn", ".", "Conv1d", "(", "in_chan", ",", "out_chan", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.UConvBlock.forward": [[858, 884], ["x.clone", "convolutional.UConvBlock.proj_1x1", "range", "range", "convolutional.UConvBlock.final_norm", "output.append", "convolutional.UConvBlock.upsampler", "convolutional.UConvBlock.res_conv", "output.pop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Args\n            x: input feature map\n\n        Returns:\n            transformed feature map\n        \"\"\"", "\n", "residual", "=", "x", ".", "clone", "(", ")", "\n", "# Reduce --> project high-dimensional feature maps to low-dimensional space", "\n", "output1", "=", "self", ".", "proj_1x1", "(", "x", ")", "\n", "output", "=", "[", "self", ".", "spp_dw", "[", "0", "]", "(", "output1", ")", "]", "\n", "\n", "# Do the downsampling process from the previous level", "\n", "for", "k", "in", "range", "(", "1", ",", "self", ".", "depth", ")", ":", "\n", "            ", "out_k", "=", "self", ".", "spp_dw", "[", "k", "]", "(", "output", "[", "-", "1", "]", ")", "\n", "output", ".", "append", "(", "out_k", ")", "\n", "\n", "# Gather them now in reverse order", "\n", "", "for", "_", "in", "range", "(", "self", ".", "depth", "-", "1", ")", ":", "\n", "            ", "resampled_out_k", "=", "self", ".", "upsampler", "(", "output", ".", "pop", "(", "-", "1", ")", ")", "\n", "output", "[", "-", "1", "]", "=", "output", "[", "-", "1", "]", "+", "resampled_out_k", "[", "...", ",", ":", "output", "[", "-", "1", "]", ".", "shape", "[", "-", "1", "]", "]", "\n", "\n", "", "expanded", "=", "self", ".", "final_norm", "(", "output", "[", "-", "1", "]", ")", "\n", "\n", "return", "self", ".", "res_conv", "(", "expanded", ")", "+", "residual", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional._fix_dcu_input_dims": [[553, 580], ["int", "int", "TypeError", "TypeError", "torch.nn.functional.pad", "torch.nn.functional.pad", "ValueError"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad"], ["", "", "@", "script_if_tracing", "\n", "def", "_fix_dcu_input_dims", "(", "fix_length_mode", ":", "Optional", "[", "str", "]", ",", "x", ",", "encoders_stride_product", ")", ":", "\n", "    ", "\"\"\"Pad or trim `x` to a length compatible with DCUNet.\"\"\"", "\n", "freq_prod", "=", "int", "(", "encoders_stride_product", "[", "0", "]", ")", "\n", "time_prod", "=", "int", "(", "encoders_stride_product", "[", "1", "]", ")", "\n", "if", "(", "x", ".", "shape", "[", "1", "]", "-", "1", ")", "%", "freq_prod", ":", "\n", "        ", "raise", "TypeError", "(", "\n", "f\"Input shape must be [batch, freq + 1, time + 1] with freq divisible by \"", "\n", "f\"{freq_prod}, got {x.shape} instead\"", "\n", ")", "\n", "", "time_remainder", "=", "(", "x", ".", "shape", "[", "2", "]", "-", "1", ")", "%", "time_prod", "\n", "if", "time_remainder", ":", "\n", "        ", "if", "fix_length_mode", "is", "None", ":", "\n", "            ", "raise", "TypeError", "(", "\n", "f\"Input shape must be [batch, freq + 1, time + 1] with time divisible by \"", "\n", "f\"{time_prod}, got {x.shape} instead. Set the 'fix_length_mode' argument \"", "\n", "f\"in 'DCUNet' to 'pad' or 'trim' to fix shapes automatically.\"", "\n", ")", "\n", "", "elif", "fix_length_mode", "==", "\"pad\"", ":", "\n", "            ", "pad_shape", "=", "[", "0", ",", "time_prod", "-", "time_remainder", "]", "\n", "x", "=", "nn", ".", "functional", ".", "pad", "(", "x", ",", "pad_shape", ",", "mode", "=", "\"constant\"", ")", "\n", "", "elif", "fix_length_mode", "==", "\"trim\"", ":", "\n", "            ", "pad_shape", "=", "[", "0", ",", "-", "time_remainder", "]", "\n", "x", "=", "nn", ".", "functional", ".", "pad", "(", "x", ",", "pad_shape", ",", "mode", "=", "\"constant\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unknown fix_length mode '{fix_length_mode}'\"", ")", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional._fix_dcu_output_dims": [[582, 586], ["utils.torch_utils.pad_x_to_y"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.pad_x_to_y"], ["", "@", "script_if_tracing", "\n", "def", "_fix_dcu_output_dims", "(", "fix_length_mode", ":", "Optional", "[", "str", "]", ",", "out", ",", "x", ")", ":", "\n", "    ", "\"\"\"Fix shape of `out` to the original shape of `x`.\"\"\"", "\n", "return", "pad_x_to_y", "(", "out", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn._local._ConvNormAct.__init__": [[19, 32], ["torch.nn.Module.__init__", "int", "torch.nn.Conv1d", "norms.GlobLN", "torch.nn.PReLU", "torch.nn.GroupNorm", "torch.nn.PReLU"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "nIn", ",", "nOut", ",", "kSize", ",", "stride", "=", "1", ",", "groups", "=", "1", ",", "use_globln", "=", "False", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "padding", "=", "int", "(", "(", "kSize", "-", "1", ")", "/", "2", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv1d", "(", "\n", "nIn", ",", "nOut", ",", "kSize", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "bias", "=", "True", ",", "groups", "=", "groups", "\n", ")", "\n", "if", "use_globln", ":", "\n", "            ", "self", ".", "norm", "=", "GlobLN", "(", "nOut", ")", "\n", "self", ".", "act", "=", "nn", ".", "PReLU", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "norm", "=", "nn", ".", "GroupNorm", "(", "1", ",", "nOut", ",", "eps", "=", "1e-08", ")", "\n", "self", ".", "act", "=", "nn", ".", "PReLU", "(", "nOut", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn._local._ConvNormAct.forward": [[33, 37], ["_local._ConvNormAct.conv", "_local._ConvNormAct.norm", "_local._ConvNormAct.act"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "output", "=", "self", ".", "conv", "(", "inp", ")", "\n", "output", "=", "self", ".", "norm", "(", "output", ")", "\n", "return", "self", ".", "act", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn._local._ConvNorm.__init__": [[54, 62], ["torch.nn.Module.__init__", "int", "torch.nn.Conv1d", "torch.nn.GroupNorm"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "nIn", ",", "nOut", ",", "kSize", ",", "stride", "=", "1", ",", "groups", "=", "1", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "padding", "=", "int", "(", "(", "kSize", "-", "1", ")", "/", "2", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv1d", "(", "\n", "nIn", ",", "nOut", ",", "kSize", ",", "stride", "=", "stride", ",", "padding", "=", "padding", ",", "bias", "=", "True", ",", "groups", "=", "groups", "\n", ")", "\n", "self", ".", "norm", "=", "nn", ".", "GroupNorm", "(", "1", ",", "nOut", ",", "eps", "=", "1e-08", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn._local._ConvNorm.forward": [[63, 66], ["_local._ConvNorm.conv", "_local._ConvNorm.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "output", "=", "self", ".", "conv", "(", "inp", ")", "\n", "return", "self", ".", "norm", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn._local._NormAct.__init__": [[79, 86], ["torch.nn.Module.__init__", "torch.nn.PReLU", "norms.GlobLN", "torch.nn.GroupNorm"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "nOut", ",", "use_globln", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "use_globln", ":", "\n", "            ", "self", ".", "norm", "=", "GlobLN", "(", "nOut", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "norm", "=", "nn", ".", "GroupNorm", "(", "1", ",", "nOut", ",", "eps", "=", "1e-08", ")", "\n", "", "self", ".", "act", "=", "nn", ".", "PReLU", "(", "nOut", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn._local._NormAct.forward": [[87, 90], ["_local._NormAct.norm", "_local._NormAct.act"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "output", "=", "self", ".", "norm", "(", "inp", ")", "\n", "return", "self", ".", "act", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn._local._DilatedConvNorm.__init__": [[107, 122], ["torch.nn.Module.__init__", "torch.nn.Conv1d", "norms.GlobLN", "torch.nn.GroupNorm"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "nIn", ",", "nOut", ",", "kSize", ",", "stride", "=", "1", ",", "d", "=", "1", ",", "groups", "=", "1", ",", "use_globln", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv1d", "(", "\n", "nIn", ",", "\n", "nOut", ",", "\n", "kSize", ",", "\n", "stride", "=", "stride", ",", "\n", "dilation", "=", "d", ",", "\n", "padding", "=", "(", "(", "kSize", "-", "1", ")", "//", "2", ")", "*", "d", ",", "\n", "groups", "=", "groups", ",", "\n", ")", "\n", "if", "use_globln", ":", "\n", "            ", "self", ".", "norm", "=", "GlobLN", "(", "nOut", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "norm", "=", "nn", ".", "GroupNorm", "(", "1", ",", "nOut", ",", "eps", "=", "1e-08", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn._local._DilatedConvNorm.forward": [[123, 126], ["_local._DilatedConvNorm.conv", "_local._DilatedConvNorm.norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "output", "=", "self", ".", "conv", "(", "inp", ")", "\n", "return", "self", ".", "norm", "(", "output", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.Swish.__init__": [[8, 10], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Swish", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.Swish.forward": [[11, 13], ["torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.sigmoid"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.linear": [[15, 17], ["torch.nn.Identity"], "function", ["None"], ["", "", "def", "linear", "(", ")", ":", "\n", "    ", "return", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu": [[19, 21], ["torch.nn.ReLU"], "function", ["None"], ["", "def", "relu", "(", ")", ":", "\n", "    ", "return", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.prelu": [[23, 25], ["torch.nn.PReLU"], "function", ["None"], ["", "def", "prelu", "(", ")", ":", "\n", "    ", "return", "nn", ".", "PReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.leaky_relu": [[27, 29], ["torch.nn.LeakyReLU"], "function", ["None"], ["", "def", "leaky_relu", "(", ")", ":", "\n", "    ", "return", "nn", ".", "LeakyReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.sigmoid": [[31, 33], ["torch.nn.Sigmoid"], "function", ["None"], ["", "def", "sigmoid", "(", ")", ":", "\n", "    ", "return", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax": [[35, 37], ["torch.nn.Softmax"], "function", ["None"], ["", "def", "softmax", "(", "dim", "=", "None", ")", ":", "\n", "    ", "return", "nn", ".", "Softmax", "(", "dim", "=", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.tanh": [[39, 41], ["torch.nn.Tanh"], "function", ["None"], ["", "def", "tanh", "(", ")", ":", "\n", "    ", "return", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.gelu": [[43, 45], ["torch.nn.GELU"], "function", ["None"], ["", "def", "gelu", "(", ")", ":", "\n", "    ", "return", "nn", ".", "GELU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.swish": [[47, 49], ["activations.Swish"], "function", ["None"], ["", "def", "swish", "(", ")", ":", "\n", "    ", "return", "Swish", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.register_activation": [[51, 61], ["globals().update", "ValueError", "globals().keys", "custom_act.__name__.lower", "globals().keys", "globals", "globals", "globals"], "function", ["None"], ["", "def", "register_activation", "(", "custom_act", ")", ":", "\n", "    ", "\"\"\"Register a custom activation, gettable with `activation.get`.\n\n    Args:\n        custom_act: Custom activation function to register.\n\n    \"\"\"", "\n", "if", "custom_act", ".", "__name__", "in", "globals", "(", ")", ".", "keys", "(", ")", "or", "custom_act", ".", "__name__", ".", "lower", "(", ")", "in", "globals", "(", ")", ".", "keys", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Activation {custom_act.__name__} already exists. Choose another name.\"", ")", "\n", "", "globals", "(", ")", ".", "update", "(", "{", "custom_act", ".", "__name__", ":", "custom_act", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get": [[63, 84], ["callable", "isinstance", "globals().get", "ValueError", "ValueError", "globals", "str", "str"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "def", "get", "(", "identifier", ")", ":", "\n", "    ", "\"\"\"Returns an activation function from a string. Returns its input if it\n    is callable (already an activation for example).\n\n    Args:\n        identifier (str or Callable or None): the activation identifier.\n\n    Returns:\n        :class:`nn.Module` or None\n    \"\"\"", "\n", "if", "identifier", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "elif", "callable", "(", "identifier", ")", ":", "\n", "        ", "return", "identifier", "\n", "", "elif", "isinstance", "(", "identifier", ",", "str", ")", ":", "\n", "        ", "cls", "=", "globals", "(", ")", ".", "get", "(", "identifier", ")", "\n", "if", "cls", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Could not interpret activation identifier: \"", "+", "str", "(", "identifier", ")", ")", "\n", "", "return", "cls", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Could not interpret activation identifier: \"", "+", "str", "(", "identifier", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get_complex": [[86, 93], ["activations.get", "functools.partial"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "", "def", "get_complex", "(", "identifier", ")", ":", "\n", "    ", "\"\"\"Like `.get` but returns a complex activation created with `asteroid.complex_nn.OnReIm`.\"\"\"", "\n", "activation", "=", "get", "(", "identifier", ")", "\n", "if", "activation", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "partial", "(", "complex_nn", ".", "OnReIm", ",", "activation", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.tac.TAC.__init__": [[24, 37], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "norms.get", "activations.get", "activations.get", "activations.get"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "hidden_dim", "=", "384", ",", "activation", "=", "\"prelu\"", ",", "norm_type", "=", "\"gLN\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "input_tf", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "hidden_dim", ")", ",", "activations", ".", "get", "(", "activation", ")", "(", ")", "\n", ")", "\n", "self", ".", "avg_tf", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ",", "activations", ".", "get", "(", "activation", ")", "(", ")", "\n", ")", "\n", "self", ".", "concat_tf", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2", "*", "hidden_dim", ",", "input_dim", ")", ",", "activations", ".", "get", "(", "activation", ")", "(", ")", "\n", ")", "\n", "self", ".", "norm", "=", "norms", ".", "get", "(", "norm_type", ")", "(", "input_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.tac.TAC.forward": [[38, 95], ["x.size", "tac.TAC.input_tf().reshape", "tac.TAC.avg_tf", "torch.cat.reshape().unsqueeze().expand_as", "torch.cat.reshape().unsqueeze().expand_as", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tac.TAC.concat_tf().reshape", "tac.TAC.norm().reshape", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor.max", "torch.LongTensor.max", "tac.TAC.mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.reshape", "torch.cat.reshape", "tac.TAC.input_tf", "output[].mean().unsqueeze", "torch.cat.reshape().unsqueeze", "torch.cat.reshape().unsqueeze", "tac.TAC.concat_tf", "tac.TAC.norm", "x.permute().reshape", "range", "tac.TAC.reshape", "tac.TAC.permute().reshape", "output[].mean", "torch.cat.reshape", "torch.cat.reshape", "x.permute", "tac.TAC.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "valid_mics", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            x: (:class:`torch.Tensor`): Input multi-channel DPRNN features.\n                Shape: :math:`(batch, mic\\_channels, features, chunk\\_size, n\\_chunks)`.\n            valid_mics: (:class:`torch.LongTensor`): tensor containing effective number of microphones on each batch.\n                Batches can be composed of examples coming from arrays with a different\n                number of microphones and thus the ``mic_channels`` dimension is padded.\n                E.g. torch.tensor([4, 3]) means first example has 4 channels and the second 3.\n                Shape:  :math`(batch)`.\n\n        Returns:\n            output (:class:`torch.Tensor`): features for each mic_channel after TAC inter-channel processing.\n                Shape :math:`(batch, mic\\_channels, features, chunk\\_size, n\\_chunks)`.\n        \"\"\"", "\n", "# Input is 5D because it is multi-channel DPRNN. DPRNN single channel is 4D.", "\n", "batch_size", ",", "nmics", ",", "channels", ",", "chunk_size", ",", "n_chunks", "=", "x", ".", "size", "(", ")", "\n", "if", "valid_mics", "is", "None", ":", "\n", "            ", "valid_mics", "=", "torch", ".", "LongTensor", "(", "[", "nmics", "]", "*", "batch_size", ")", "\n", "# First operation: transform the input for each frame and independently on each mic channel.", "\n", "", "output", "=", "self", ".", "input_tf", "(", "\n", "x", ".", "permute", "(", "0", ",", "3", ",", "4", ",", "1", ",", "2", ")", ".", "reshape", "(", "batch_size", "*", "nmics", "*", "chunk_size", "*", "n_chunks", ",", "channels", ")", "\n", ")", ".", "reshape", "(", "batch_size", ",", "chunk_size", ",", "n_chunks", ",", "nmics", ",", "self", ".", "hidden_dim", ")", "\n", "\n", "# Mean pooling across channels", "\n", "if", "valid_mics", ".", "max", "(", ")", "==", "0", ":", "\n", "# Fixed geometry array", "\n", "            ", "mics_mean", "=", "output", ".", "mean", "(", "1", ")", "\n", "", "else", ":", "\n", "# Only consider valid channels in each batch element: each example can have different number of microphones.", "\n", "            ", "mics_mean", "=", "[", "\n", "output", "[", "b", ",", ":", ",", ":", ",", ":", "valid_mics", "[", "b", "]", "]", ".", "mean", "(", "2", ")", ".", "unsqueeze", "(", "0", ")", "for", "b", "in", "range", "(", "batch_size", ")", "\n", "]", "# 1, dim1*dim2, H", "\n", "mics_mean", "=", "torch", ".", "cat", "(", "mics_mean", ",", "0", ")", "# B*dim1*dim2, H", "\n", "\n", "# The average is processed by a non-linear transform", "\n", "", "mics_mean", "=", "self", ".", "avg_tf", "(", "\n", "mics_mean", ".", "reshape", "(", "batch_size", "*", "chunk_size", "*", "n_chunks", ",", "self", ".", "hidden_dim", ")", "\n", ")", "\n", "mics_mean", "=", "(", "\n", "mics_mean", ".", "reshape", "(", "batch_size", ",", "chunk_size", ",", "n_chunks", ",", "self", ".", "hidden_dim", ")", "\n", ".", "unsqueeze", "(", "3", ")", "\n", ".", "expand_as", "(", "output", ")", "\n", ")", "\n", "\n", "# Concatenate the transformed average in each channel with the original feats and", "\n", "# project back to same number of features", "\n", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "mics_mean", "]", ",", "-", "1", ")", "\n", "output", "=", "self", ".", "concat_tf", "(", "\n", "output", ".", "reshape", "(", "batch_size", "*", "chunk_size", "*", "n_chunks", "*", "nmics", ",", "-", "1", ")", "\n", ")", ".", "reshape", "(", "batch_size", ",", "chunk_size", ",", "n_chunks", ",", "nmics", ",", "-", "1", ")", "\n", "output", "=", "self", ".", "norm", "(", "\n", "output", ".", "permute", "(", "0", ",", "3", ",", "4", ",", "1", ",", "2", ")", ".", "reshape", "(", "batch_size", "*", "nmics", ",", "-", "1", ",", "chunk_size", ",", "n_chunks", ")", "\n", ")", ".", "reshape", "(", "batch_size", ",", "nmics", ",", "-", "1", ",", "chunk_size", ",", "n_chunks", ")", "\n", "\n", "output", "+=", "x", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional_test.test_tdconvnet": [[6, 30], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "asteroid.masknn.TDConvNet", "torch.randn", "asteroid.masknn.TDConvNet.", "asteroid.masknn.TDConvNet.get_config"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.SuDORMRFImproved.get_config"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"mask_act\"", ",", "[", "\"relu\"", ",", "\"softmax\"", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"out_chan\"", ",", "[", "None", ",", "10", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"skip_chan\"", ",", "[", "0", ",", "12", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"causal\"", ",", "[", "True", ",", "False", "]", ")", "\n", "def", "test_tdconvnet", "(", "mask_act", ",", "out_chan", ",", "skip_chan", ",", "causal", ")", ":", "\n", "    ", "in_chan", ",", "n_src", "=", "20", ",", "2", "\n", "model", "=", "TDConvNet", "(", "\n", "in_chan", "=", "in_chan", ",", "\n", "n_src", "=", "n_src", ",", "\n", "mask_act", "=", "mask_act", ",", "\n", "n_blocks", "=", "2", ",", "\n", "n_repeats", "=", "2", ",", "\n", "bn_chan", "=", "10", ",", "\n", "hid_chan", "=", "11", ",", "\n", "skip_chan", "=", "skip_chan", ",", "\n", "out_chan", "=", "out_chan", ",", "\n", "causal", "=", "causal", ",", "\n", ")", "\n", "batch", ",", "n_frames", "=", "2", ",", "24", "\n", "inp", "=", "torch", ".", "randn", "(", "batch", ",", "in_chan", ",", "n_frames", ")", "\n", "out", "=", "model", "(", "inp", ")", "\n", "_", "=", "model", ".", "get_config", "(", ")", "\n", "out_chan", "=", "out_chan", "if", "out_chan", "else", "in_chan", "\n", "assert", "out", ".", "shape", "==", "(", "batch", ",", "n_src", ",", "out_chan", ",", "n_frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional_test.test_tdconvnetpp": [[32, 54], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "asteroid.masknn.TDConvNetpp", "torch.randn", "asteroid.masknn.TDConvNetpp.", "asteroid.masknn.TDConvNetpp.get_config"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.SuDORMRFImproved.get_config"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"mask_act\"", ",", "[", "\"relu\"", ",", "\"softmax\"", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"out_chan\"", ",", "[", "None", ",", "10", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"skip_chan\"", ",", "[", "0", ",", "12", "]", ")", "\n", "def", "test_tdconvnetpp", "(", "mask_act", ",", "out_chan", ",", "skip_chan", ")", ":", "\n", "    ", "in_chan", ",", "n_src", "=", "20", ",", "2", "\n", "model", "=", "TDConvNetpp", "(", "\n", "in_chan", "=", "in_chan", ",", "\n", "n_src", "=", "n_src", ",", "\n", "mask_act", "=", "mask_act", ",", "\n", "n_blocks", "=", "2", ",", "\n", "n_repeats", "=", "2", ",", "\n", "bn_chan", "=", "10", ",", "\n", "hid_chan", "=", "11", ",", "\n", "skip_chan", "=", "skip_chan", ",", "\n", "out_chan", "=", "out_chan", ",", "\n", ")", "\n", "batch", ",", "n_frames", "=", "2", ",", "24", "\n", "inp", "=", "torch", ".", "randn", "(", "batch", ",", "in_chan", ",", "n_frames", ")", "\n", "out", ",", "consistency_weights", "=", "model", "(", "inp", ")", "\n", "_", "=", "model", ".", "get_config", "(", ")", "\n", "out_chan", "=", "out_chan", "if", "out_chan", "else", "in_chan", "\n", "assert", "out", ".", "shape", "==", "(", "batch", ",", "n_src", ",", "out_chan", ",", "n_frames", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations_test.activation_mapping": [[11, 21], ["None"], "function", ["None"], ["def", "activation_mapping", "(", ")", ":", "\n", "    ", "mapping_list", "=", "[", "\n", "(", "nn", ".", "Identity", ",", "\"linear\"", ")", ",", "\n", "(", "nn", ".", "ReLU", ",", "\"relu\"", ")", ",", "\n", "(", "nn", ".", "PReLU", ",", "\"prelu\"", ")", ",", "\n", "(", "nn", ".", "LeakyReLU", ",", "\"leaky_relu\"", ")", ",", "\n", "(", "nn", ".", "Sigmoid", ",", "\"sigmoid\"", ")", ",", "\n", "(", "nn", ".", "Tanh", ",", "\"tanh\"", ")", ",", "\n", "]", "\n", "return", "mapping_list", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations_test.test_activations": [[23, 31], ["pytest.mark.parametrize", "torch_act.", "torch.randn", "torch.testing.assert_allclose", "activations_test.activation_mapping", "asteroid.masknn.activations.get", "torch_act.", "asteroid_act"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations_test.activation_mapping", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"activation_tuple\"", ",", "activation_mapping", "(", ")", ")", "\n", "def", "test_activations", "(", "activation_tuple", ")", ":", "\n", "    ", "torch_act", ",", "asteroid_act", "=", "activation_tuple", "\n", "torch_act", "=", "torch_act", "(", ")", "\n", "asteroid_act", "=", "activations", ".", "get", "(", "asteroid_act", ")", "(", ")", "\n", "\n", "inp", "=", "torch", ".", "randn", "(", "10", ",", "11", ",", "12", ")", "\n", "assert_allclose", "(", "torch_act", "(", "inp", ")", ",", "asteroid_act", "(", "inp", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations_test.test_softmax": [[33, 39], ["torch.nn.Softmax", "torch.randn", "torch.testing.assert_allclose", "asteroid.masknn.activations.get", "nn.Softmax.", "asteroid_softmax", "asteroid.masknn.activations.get"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "def", "test_softmax", "(", ")", ":", "\n", "    ", "torch_softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "asteroid_softmax", "=", "activations", ".", "get", "(", "\"softmax\"", ")", "(", "dim", "=", "-", "1", ")", "\n", "inp", "=", "torch", ".", "randn", "(", "10", ",", "11", ",", "12", ")", "\n", "assert_allclose", "(", "torch_softmax", "(", "inp", ")", ",", "asteroid_softmax", "(", "inp", ")", ")", "\n", "assert", "torch_softmax", "==", "activations", ".", "get", "(", "torch_softmax", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations_test.test_get_errors": [[41, 46], ["pytest.mark.parametrize", "pytest.raises", "asteroid.masknn.activations.get", "object"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"wrong\"", ",", "[", "\"wrong_string\"", ",", "12", ",", "object", "(", ")", "]", ")", "\n", "def", "test_get_errors", "(", "wrong", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# Should raise for anything not a Optimizer instance + unknown string", "\n", "        ", "activations", ".", "get", "(", "wrong", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations_test.test_get_none": [[48, 50], ["asteroid.masknn.activations.get"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "", "def", "test_get_none", "(", ")", ":", "\n", "    ", "assert", "activations", ".", "get", "(", "None", ")", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations_test.test_register": [[52, 63], ["asteroid.masknn.activations.register_activation", "asteroid.masknn.activations.get", "pytest.raises", "asteroid.masknn.activations.register_activation", "super().__init__"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.register_activation", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.register_activation", "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["", "def", "test_register", "(", ")", ":", "\n", "    ", "class", "Custom", "(", "nn", ".", "Module", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "", "", "activations", ".", "register_activation", "(", "Custom", ")", "\n", "cls", "=", "activations", ".", "get", "(", "\"Custom\"", ")", "\n", "assert", "cls", "==", "Custom", "\n", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "activations", ".", "register_activation", "(", "activations", ".", "relu", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent_test.test_dprnn": [[6, 30], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "asteroid.masknn.recurrent.DPRNN", "torch.randn", "rec.DPRNN.", "rec.DPRNN.get_config"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.convolutional.SuDORMRFImproved.get_config"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"mask_act\"", ",", "[", "\"relu\"", ",", "\"softmax\"", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"out_chan\"", ",", "[", "None", ",", "10", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"hop_size\"", ",", "[", "None", ",", "5", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"use_mulcat\"", ",", "[", "True", ",", "False", "]", ")", "\n", "def", "test_dprnn", "(", "mask_act", ",", "out_chan", ",", "hop_size", ",", "use_mulcat", ")", ":", "\n", "    ", "in_chan", ",", "n_src", "=", "20", ",", "2", "\n", "model", "=", "rec", ".", "DPRNN", "(", "\n", "in_chan", "=", "in_chan", ",", "\n", "n_src", "=", "n_src", ",", "\n", "mask_act", "=", "mask_act", ",", "\n", "chunk_size", "=", "20", ",", "\n", "n_repeats", "=", "2", ",", "\n", "bn_chan", "=", "10", ",", "\n", "hid_size", "=", "11", ",", "\n", "out_chan", "=", "out_chan", ",", "\n", "hop_size", "=", "hop_size", ",", "\n", "use_mulcat", "=", "use_mulcat", ",", "\n", ")", "\n", "batch", ",", "n_frames", "=", "2", ",", "78", "\n", "inp", "=", "torch", ".", "randn", "(", "batch", ",", "in_chan", ",", "n_frames", ")", "\n", "out", "=", "model", "(", "inp", ")", "\n", "_", "=", "model", ".", "get_config", "(", ")", "\n", "out_chan", "=", "out_chan", "if", "out_chan", "else", "in_chan", "\n", "assert", "out", ".", "shape", "==", "(", "batch", ",", "n_src", ",", "out_chan", ",", "n_frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent_test.test_res_rnn": [[32, 43], ["pytest.mark.parametrize", "pytest.mark.parametrize", "asteroid.masknn.recurrent.StackedResidualRNN", "torch.randn", "rec.StackedResidualRNN."], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"rnn_type\"", ",", "[", "\"LSTM\"", ",", "\"GRU\"", ",", "\"RNN\"", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"dropout\"", ",", "[", "0.0", ",", "0.2", "]", ")", "\n", "def", "test_res_rnn", "(", "rnn_type", ",", "dropout", ")", ":", "\n", "    ", "n_units", ",", "n_layers", "=", "20", ",", "3", "\n", "model", "=", "rec", ".", "StackedResidualRNN", "(", "\n", "rnn_type", ",", "n_units", ",", "n_layers", "=", "n_layers", ",", "dropout", "=", "dropout", ",", "bidirectional", "=", "False", "\n", ")", "\n", "batch", ",", "n_frames", "=", "2", ",", "78", "\n", "inp", "=", "torch", ".", "randn", "(", "batch", ",", "n_frames", ",", "n_units", ")", "\n", "out", "=", "model", "(", "inp", ")", "\n", "assert", "out", ".", "shape", "==", "(", "batch", ",", "n_frames", ",", "n_units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.recurrent_test.test_res_birnn": [[45, 56], ["pytest.mark.parametrize", "pytest.mark.parametrize", "asteroid.masknn.recurrent.StackedResidualBiRNN", "torch.randn", "rec.StackedResidualBiRNN."], "function", ["None"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"rnn_type\"", ",", "[", "\"LSTM\"", ",", "\"GRU\"", ",", "\"RNN\"", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"dropout\"", ",", "[", "0.0", ",", "0.2", "]", ")", "\n", "def", "test_res_birnn", "(", "rnn_type", ",", "dropout", ")", ":", "\n", "    ", "n_units", ",", "n_layers", "=", "20", ",", "3", "\n", "model", "=", "rec", ".", "StackedResidualBiRNN", "(", "\n", "rnn_type", ",", "n_units", ",", "n_layers", "=", "n_layers", ",", "dropout", "=", "dropout", ",", "bidirectional", "=", "True", "\n", ")", "\n", "batch", ",", "n_frames", "=", "2", ",", "78", "\n", "inp", "=", "torch", ".", "randn", "(", "batch", ",", "n_frames", ",", "n_units", ")", "\n", "out", "=", "model", "(", "inp", ")", "\n", "assert", "out", ".", "shape", "==", "(", "batch", ",", "n_frames", ",", "2", "*", "n_units", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms_test.test_norms": [[8, 24], ["pytest.mark.parametrize", "pytest.mark.parametrize", "asteroid.masknn.norms.get", "asteroid.masknn.norms.get", "norm_layer.", "asteroid.masknn.norms.get", "torch.randn", "norm_layer.", "torch.isnan().any", "torch.isnan"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"norm_str\"", ",", "[", "\"gLN\"", ",", "\"cLN\"", ",", "\"cgLN\"", ",", "\"bN\"", ",", "\"fgLN\"", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"channel_size\"", ",", "[", "8", ",", "128", ",", "4", "]", ")", "\n", "def", "test_norms", "(", "norm_str", ",", "channel_size", ")", ":", "\n", "    ", "norm_layer", "=", "norms", ".", "get", "(", "norm_str", ")", "\n", "# Use get on the class", "\n", "out_from_get", "=", "norms", ".", "get", "(", "norm_layer", ")", "\n", "assert", "out_from_get", "==", "norm_layer", "\n", "# Use get on the instance", "\n", "norm_layer", "=", "norm_layer", "(", "channel_size", ")", "\n", "out_from_get", "=", "norms", ".", "get", "(", "norm_layer", ")", "\n", "assert", "out_from_get", "==", "norm_layer", "\n", "\n", "# Test forward", "\n", "inp", "=", "torch", ".", "randn", "(", "4", ",", "channel_size", ",", "12", ")", "\n", "out", "=", "norm_layer", "(", "inp", ")", "\n", "assert", "not", "torch", ".", "isnan", "(", "out", ")", ".", "any", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms_test.test_get_errors": [[26, 31], ["pytest.mark.parametrize", "pytest.raises", "asteroid.masknn.norms.get", "object"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"wrong\"", ",", "[", "\"wrong_string\"", ",", "12", ",", "object", "(", ")", "]", ")", "\n", "def", "test_get_errors", "(", "wrong", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "# Should raise for anything not a Optimizer instance + unknown string", "\n", "        ", "norms", ".", "get", "(", "wrong", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms_test.test_get_none": [[33, 35], ["asteroid.masknn.norms.get"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["", "", "def", "test_get_none", "(", ")", ":", "\n", "    ", "assert", "norms", ".", "get", "(", "None", ")", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms_test.test_register": [[37, 48], ["asteroid.masknn.norms.register_norm", "asteroid.masknn.norms.get", "pytest.raises", "asteroid.masknn.norms.register_norm", "super().__init__"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.register_norm", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.norms.register_norm", "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["", "def", "test_register", "(", ")", ":", "\n", "    ", "class", "Custom", "(", "nn", ".", "Module", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "", "", "norms", ".", "register_norm", "(", "Custom", ")", "\n", "cls", "=", "norms", ".", "get", "(", "\"Custom\"", ")", "\n", "assert", "cls", "==", "Custom", "\n", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "norms", ".", "register_norm", "(", "norms", ".", "CumLN", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read": [[28, 31], ["codecs.open", "fp.read", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["def", "read", "(", "*", "parts", ")", ":", "\n", "    ", "with", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "PATH_ROOT", ",", "*", "parts", ")", ",", "\"r\"", ")", "as", "fp", ":", "\n", "        ", "return", "fp", ".", "read", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.find_version": [[33, 39], ["conf.read", "re.search", "RuntimeError", "re.search.group"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "", "def", "find_version", "(", "*", "file_paths", ")", ":", "\n", "    ", "version_file", "=", "read", "(", "*", "file_paths", ")", "\n", "version_match", "=", "re", ".", "search", "(", "r\"^__version__ = ['\\\"]([^'\\\"]*)['\\\"]\"", ",", "version_file", ",", "re", ".", "M", ")", "\n", "if", "version_match", ":", "\n", "        ", "return", "version_match", ".", "group", "(", "1", ")", "\n", "", "raise", "RuntimeError", "(", "\"Unable to find version string.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.linkcode_resolve": [[125, 161], ["info[].replace", "info[].replace", "out.replace", "info[].split", "inspect.getsourcefile", "inspect.getsourcelines", "conf.linkcode_resolve.find_source"], "function", ["None"], ["def", "linkcode_resolve", "(", "domain", ",", "info", ")", ":", "\n", "    ", "if", "domain", "!=", "\"py\"", "or", "not", "info", "[", "\"module\"", "]", ":", "\n", "        ", "return", "None", "\n", "", "info", "[", "\"module\"", "]", "=", "info", "[", "\"module\"", "]", ".", "replace", "(", "\"asteroid.filterbanks\"", ",", "\"asteroid_filterbanks\"", ")", "\n", "link_to_afb", "=", "\"asteroid_filterbanks\"", "in", "info", "[", "\"module\"", "]", "\n", "repos_name", "=", "\"asteroid_filterbanks\"", "if", "link_to_afb", "else", "\"asteroid\"", "\n", "\n", "def", "str_from", "(", "string", ",", "start", "=", "\"asteroid\"", ")", ":", "\n", "        ", "return", "string", "[", "string", ".", "find", "(", "start", ")", ":", "]", "\n", "\n", "", "def", "find_source", "(", ")", ":", "\n", "        ", "import", "inspect", "\n", "\n", "# try to find the correct line number, based on code from numpy and lasagne (5 years old)", "\n", "# get(asteroid, engine) -> get(engine, system) -> get(system, engine)", "\n", "obj", "=", "sys", ".", "modules", "[", "info", "[", "\"module\"", "]", "]", "\n", "for", "part", "in", "info", "[", "\"fullname\"", "]", ".", "split", "(", "\".\"", ")", ":", "\n", "            ", "obj", "=", "getattr", "(", "obj", ",", "part", ")", "\n", "", "fn", "=", "inspect", ".", "getsourcefile", "(", "obj", ")", "\n", "source", ",", "lineno", "=", "inspect", ".", "getsourcelines", "(", "obj", ")", "\n", "return", "fn", ",", "lineno", ",", "lineno", "+", "len", "(", "source", ")", "-", "1", "\n", "\n", "", "filename", "=", "info", "[", "\"module\"", "]", ".", "replace", "(", "\".\"", ",", "\"/\"", ")", "\n", "tag", "=", "\"master\"", "if", "\"dev\"", "in", "release", "else", "(", "\"v\"", "+", "release", ")", "\n", "\n", "if", "\"asteroid_filterbanks\"", "in", "filename", ":", "\n", "        ", "base_url", "=", "\"https://github.com/asteroid-team/asteroid-filterbanks/blob/master/%s\"", "\n", "", "else", ":", "\n", "        ", "base_url", "=", "f\"https://github.com/asteroid-team/asteroid/blob/{tag}/%s\"", "\n", "\n", "", "try", ":", "\n", "        ", "file", ",", "start", ",", "end", "=", "find_source", "(", ")", "\n", "", "except", ":", "\n", "        ", "return", "base_url", "%", "str_from", "(", "filename", ",", "start", "=", "repos_name", ")", "\n", "", "out", "=", "base_url", "%", "str_from", "(", "file", ",", "start", "=", "repos_name", ")", "+", "\"#L%d-L%d\"", "%", "(", "start", ",", "end", ")", "\n", "return", "out", ".", "replace", "(", "\"asteroid/asteroid/asteroid/\"", ",", "\"asteroid/\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.run_apidoc": [[296, 320], ["os.makedirs", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "apidoc.main", "argv.insert", "apidoc.main"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.CaCGMM.start_evaluation.main", "home.repos.pwc.inspect_result.mpariente_AsSteroid.CaCGMM.start_evaluation.main"], ["def", "run_apidoc", "(", "_", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "PATH_HERE", ",", "\"apidoc\"", ")", ",", "exist_ok", "=", "True", ")", "\n", "for", "pkg", "in", "PACKAGES", ":", "\n", "        ", "argv", "=", "[", "\n", "\"-e\"", ",", "\n", "\"-o\"", ",", "\n", "os", ".", "path", ".", "join", "(", "PATH_HERE", ",", "\"apidoc\"", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "PATH_HERE", ",", "PATH_ROOT", ",", "pkg", ")", ",", "\n", "\"**/test_*\"", ",", "\n", "\"--force\"", ",", "\n", "\"--private\"", ",", "\n", "\"--module-first\"", ",", "\n", "]", "\n", "try", ":", "\n", "# Sphinx 1.7+", "\n", "            ", "from", "sphinx", ".", "ext", "import", "apidoc", "\n", "\n", "apidoc", ".", "main", "(", "argv", ")", "\n", "", "except", "ImportError", ":", "\n", "# Sphinx 1.6 (and earlier)", "\n", "            ", "from", "sphinx", "import", "apidoc", "\n", "\n", "argv", ".", "insert", "(", "0", ",", "apidoc", ".", "__file__", ")", "\n", "apidoc", ".", "main", "(", "argv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.setup": [[322, 324], ["None"], "function", ["None"], ["", "", "", "def", "setup", "(", "app", ")", ":", "\n", "    ", "return", "\n", "# app.connect(\"builder-inited\", run_apidoc)", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.train.main": [[23, 96], ["asteroid.data.DNSDataset", "int", "torch.utils.data.random_split", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "model.make_model_and_optimizer", "os.makedirs", "os.path.join", "functools.partial", "model.SimpleSystem", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "len", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "len", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer"], ["def", "main", "(", "conf", ")", ":", "\n", "    ", "total_set", "=", "DNSDataset", "(", "conf", "[", "\"data\"", "]", "[", "\"json_dir\"", "]", ")", "\n", "train_len", "=", "int", "(", "len", "(", "total_set", ")", "*", "(", "1", "-", "conf", "[", "\"data\"", "]", "[", "\"val_prop\"", "]", ")", ")", "\n", "val_len", "=", "len", "(", "total_set", ")", "-", "train_len", "\n", "train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.eval_on_synthetic.main": [[34, 58], ["model.load_best_model", "model.cuda.cuda", "eval_on_synthetic.get_wavs_dict_list", "os.path.join", "os.makedirs", "eval_on_synthetic.evaluate", "evaluate.to_csv", "print", "pprint.pprint", "os.path.join", "os.path.join", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.load_best_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.eval_on_synthetic.get_wavs_dict_list", "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.eval_on_synthetic.evaluate"], ["def", "main", "(", "conf", ")", ":", "\n", "# Get best trained model", "\n", "    ", "model", "=", "load_best_model", "(", "conf", "[", "\"train_conf\"", "]", ",", "conf", "[", "\"exp_dir\"", "]", ")", "\n", "if", "conf", "[", "\"use_gpu\"", "]", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "# Evaluate performances separately w/ and w/o reverb", "\n", "", "for", "subdir", "in", "[", "\"with_reverb\"", ",", "\"no_reverb\"", "]", ":", "\n", "        ", "dict_list", "=", "get_wavs_dict_list", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"test_dir\"", "]", ",", "subdir", ")", ")", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "subdir", "+", "\"examples/\"", ")", "\n", "os", ".", "makedirs", "(", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "all_metrics_df", "=", "evaluate", "(", "dict_list", ",", "model", ",", "conf", "=", "conf", ",", "save_dir", "=", "save_dir", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics_{}.csv\"", ".", "format", "(", "subdir", ")", ")", ")", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "COMPUTE_METRICS", ":", "\n", "            ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics {} :\"", ".", "format", "(", "subdir", ")", ")", "\n", "pprint", "(", "final_results", ")", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics_{}.json\"", ".", "format", "(", "subdir", ")", ")", "\n", "with", "open", "(", "filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.eval_on_synthetic.get_wavs_dict_list": [[60, 83], ["glob.glob", "local.preprocess_dns.make_wav_id_dict", "glob.glob", "local.preprocess_dns.make_wav_id_dict", "os.path.join", "os.path.join", "local.preprocess_dns.make_wav_id_dict.keys", "local.preprocess_dns.make_wav_id_dict.keys", "dict", "local.preprocess_dns.make_wav_id_dict.keys"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_dns.make_wav_id_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_dns.make_wav_id_dict"], ["", "", "", "def", "get_wavs_dict_list", "(", "test_dir", ")", ":", "\n", "    ", "\"\"\"Creates a list of example pair dictionaries.\n\n    Args:\n        test_dir (str): Directory where clean/ and noisy/ subdirectories can\n            be found.\n    Returns:\n        List[dict] : list of noisy/clean pair dictionaries.\n            Each dict looks like :\n                {'clean': clean_path,\n                'noisy': noisy_path,\n                'id': 3}\n    \"\"\"", "\n", "# Find all clean files and make an {id: filepath} dictionary", "\n", "clean_wavs", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "test_dir", ",", "\"clean/*.wav\"", ")", ")", "\n", "clean_dic", "=", "make_wav_id_dict", "(", "clean_wavs", ")", "\n", "# Same for noisy files", "\n", "noisy_wavs", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "test_dir", ",", "\"noisy/*.wav\"", ")", ")", "\n", "noisy_dic", "=", "make_wav_id_dict", "(", "noisy_wavs", ")", "\n", "assert", "clean_dic", ".", "keys", "(", ")", "==", "noisy_dic", ".", "keys", "(", ")", "\n", "# Combine both dictionaries", "\n", "dict_list", "=", "[", "dict", "(", "clean", "=", "clean_dic", "[", "k", "]", ",", "noisy", "=", "noisy_dic", "[", "k", "]", ",", "id", "=", "k", ")", "for", "k", "in", "clean_dic", ".", "keys", "(", ")", "]", "\n", "return", "dict_list", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.eval_on_synthetic.evaluate": [[85, 125], ["random.sample", "enumerate", "pandas.DataFrame", "next", "len", "range", "tqdm.tqdm", "eval_on_synthetic.load_wav_dic", "asteroid.metrics.get_metrics", "series_list.append", "model.parameters", "len", "torch.no_grad", "[].to", "model.denoise().squeeze().cpu().data.numpy", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "soundfile.write", "soundfile.write", "open", "json.dump", "torch.tensor", "model.denoise().squeeze().cpu", "model.denoise().squeeze", "model.denoise"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.eval_on_synthetic.load_wav_dic", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.model.Model.denoise"], ["", "def", "evaluate", "(", "dict_list", ",", "model", ",", "conf", ",", "save_dir", "=", "None", ")", ":", "\n", "    ", "model_device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "# Randomly choose the indexes of sentences to save.", "\n", "if", "save_dir", "is", "None", ":", "\n", "        ", "conf", "[", "\"n_save_ex\"", "]", "=", "0", "\n", "", "if", "conf", "[", "\"n_save_ex\"", "]", "==", "-", "1", ":", "\n", "        ", "conf", "[", "\"n_save_ex\"", "]", "=", "len", "(", "dict_list", ")", "\n", "", "save_idx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "dict_list", ")", ")", ",", "conf", "[", "\"n_save_ex\"", "]", ")", "\n", "series_list", "=", "[", "]", "\n", "for", "idx", ",", "wav_dic", "in", "enumerate", "(", "tqdm", "(", "dict_list", ")", ")", ":", "\n", "# Forward the network on the mixture.", "\n", "        ", "noisy_np", ",", "clean_np", ",", "fs", "=", "load_wav_dic", "(", "wav_dic", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "net_input", "=", "torch", ".", "tensor", "(", "noisy_np", ")", "[", "None", ",", "None", "]", ".", "to", "(", "model_device", ")", "\n", "est_clean_np", "=", "model", ".", "denoise", "(", "net_input", ")", ".", "squeeze", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "\n", "", "utt_metrics", "=", "get_metrics", "(", "\n", "mix", "=", "noisy_np", ",", "\n", "clean", "=", "clean_np", ",", "\n", "estimate", "=", "est_clean_np", ",", "\n", "sample_rate", "=", "fs", ",", "\n", "metrics_list", "=", "COMPUTE_METRICS", ",", "\n", ")", "\n", "utt_metrics", "[", "\"noisy_path\"", "]", "=", "wav_dic", "[", "\"noisy\"", "]", "\n", "utt_metrics", "[", "\"clean_path\"", "]", "=", "wav_dic", "[", "\"clean\"", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"noisy.wav\"", ",", "noisy_np", ",", "fs", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"clean.wav\"", ",", "clean_np", ",", "fs", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"estimate.wav\"", ",", "est_clean_np", ",", "fs", ")", "\n", "# Write local metrics to the example folder.", "\n", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "return", "all_metrics_df", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.eval_on_synthetic.load_wav_dic": [[127, 137], ["soundfile.read", "soundfile.read"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "load_wav_dic", "(", "wav_dic", ")", ":", "\n", "    ", "\"\"\"Load wavs files from a dictionary with path entries.\n\n    Returns:\n        tuple: noisy speech waveform, clean speech waveform.\n    \"\"\"", "\n", "noisy_path", ",", "clean_path", "=", "wav_dic", "[", "\"noisy\"", "]", ",", "wav_dic", "[", "\"clean\"", "]", "\n", "noisy", ",", "fs", "=", "sf", ".", "read", "(", "noisy_path", ",", "dtype", "=", "\"float32\"", ")", "\n", "clean", ",", "fs", "=", "sf", ".", "read", "(", "clean_path", ",", "dtype", "=", "\"float32\"", ")", "\n", "return", "noisy", ",", "clean", ",", "fs", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.model.Model.__init__": [[62, 70], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "masker", ",", "decoder", ",", "is_complex", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "masker", "=", "masker", "\n", "# Decoder is not used for training but eventually, we want to invert", "\n", "# the encoder. Might as well include it in the model.", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "is_complex", "=", "is_complex", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.model.Model.forward": [[71, 89], ["model.Model.encoder", "model.Model.masker().transpose", "len", "x.unsqueeze.unsqueeze.unsqueeze", "asteroid_filterbanks.transforms.magreim", "asteroid_filterbanks.transforms.mag", "asteroid_filterbanks.transforms.apply_real_mask", "asteroid_filterbanks.transforms.apply_mag_mask", "model.Model.masker", "asteroid_filterbanks.transforms.mag.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "len", "(", "x", ".", "shape", ")", "==", "2", ":", "\n", "            ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "# Compute STFT", "\n", "", "tf_rep", "=", "self", ".", "encoder", "(", "x", ")", "\n", "# Estimate TF mask from STFT features : cat([re, im, mag])", "\n", "if", "self", ".", "is_complex", ":", "\n", "            ", "to_masker", "=", "magreim", "(", "tf_rep", ")", "\n", "", "else", ":", "\n", "            ", "to_masker", "=", "mag", "(", "tf_rep", ")", "\n", "# LSTM masker expects a feature dimension last (not like 1D conv)", "\n", "", "est_masks", "=", "self", ".", "masker", "(", "to_masker", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# Apply TF mask", "\n", "if", "self", ".", "is_complex", ":", "\n", "            ", "masked_tf_rep", "=", "apply_real_mask", "(", "tf_rep", ",", "est_masks", ")", "\n", "", "else", ":", "\n", "            ", "masked_tf_rep", "=", "apply_mag_mask", "(", "tf_rep", ",", "est_masks", ")", "\n", "", "return", "masked_tf_rep", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.model.Model.denoise": [[90, 94], ["model.Model.", "model.Model.decoder", "asteroid.torch_utils.pad_x_to_y"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.pad_x_to_y"], ["", "def", "denoise", "(", "self", ",", "x", ")", ":", "\n", "        ", "estimate_stft", "=", "self", "(", "x", ")", "\n", "wav", "=", "self", ".", "decoder", "(", "estimate_stft", ")", "\n", "return", "torch_utils", ".", "pad_x_to_y", "(", "wav", ",", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.model.SimpleModel.__init__": [[109, 122], ["torch.nn.Module.__init__", "torch.nn.Linear", "asteroid.masknn.recurrent.StackedResidualRNN", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "input_size", ",", "hidden_size", ",", "output_size", "=", "None", ",", "rnn_type", "=", "\"gru\"", ",", "n_layers", "=", "3", ",", "dropout", "=", "0.3", "\n", ")", ":", "\n", "        ", "super", "(", "SimpleModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "output_size", "=", "input_size", "if", "output_size", "is", "None", "else", "output_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "in_proj_layer", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "residual_rec", "=", "StackedResidualRNN", "(", "\n", "rnn_type", ",", "hidden_size", ",", "n_layers", "=", "n_layers", ",", "dropout", "=", "dropout", "\n", ")", "\n", "self", ".", "out_proj_layer", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.model.SimpleModel.forward": [[123, 129], ["model.SimpleModel.residual_rec", "torch.relu", "torch.relu", "model.SimpleModel.out_proj_layer", "model.SimpleModel.in_proj_layer"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Mask estimator's forward pass. Expects [batch, time, input_size]\"\"\"", "\n", "# Non negative features from input", "\n", "out_rec", "=", "self", ".", "residual_rec", "(", "torch", ".", "relu", "(", "self", ".", "in_proj_layer", "(", "x", ")", ")", ")", "\n", "# Activation is relu on the mask (better gradients allegedly)", "\n", "return", "torch", ".", "relu", "(", "self", ".", "out_proj_layer", "(", "out_rec", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.model.SimpleSystem.common_step": [[132, 140], ["model.SimpleSystem.", "model.SimpleSystem.model.encoder", "model.SimpleSystem.loss_func", "mixture.unsqueeze", "speech.unsqueeze"], "methods", ["None"], ["    ", "def", "common_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "mixture", ",", "speech", ",", "noise", "=", "batch", "\n", "estimate", "=", "self", "(", "mixture", ".", "unsqueeze", "(", "1", ")", ")", "\n", "speech_stft", "=", "self", ".", "model", ".", "encoder", "(", "speech", ".", "unsqueeze", "(", "1", ")", ")", "\n", "# The loss function can be something like", "\n", "# loss_func = partial(distance, is_complex=some_bool)", "\n", "loss", "=", "self", ".", "loss_func", "(", "estimate", ",", "speech_stft", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.model.make_model_and_optimizer": [[17, 42], ["asteroid_filterbanks.make_enc_dec", "conf[].update", "model.SimpleModel", "model.Model", "asteroid.engine.optimizers.make_optimizer", "int", "int", "dict", "Model.parameters"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer"], ["def", "make_model_and_optimizer", "(", "conf", ")", ":", "\n", "    ", "\"\"\"Function to define the model and optimizer for a config dictionary.\n    Args:\n        conf: Dictionary containing the output of hierachical argparse.\n    Returns:\n        model, optimizer.\n    The main goal of this function is to make reloading for resuming\n    and evaluation very simple.\n    \"\"\"", "\n", "# Define building blocks for local model", "\n", "stft", ",", "istft", "=", "make_enc_dec", "(", "\"stft\"", ",", "**", "conf", "[", "\"filterbank\"", "]", ")", "\n", "# Because we concatenate (re, im, mag) as input and compute a complex mask.", "\n", "if", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ":", "\n", "        ", "inp_size", "=", "int", "(", "stft", ".", "n_feats_out", "*", "3", "/", "2", ")", "\n", "output_size", "=", "stft", ".", "n_feats_out", "\n", "", "else", ":", "\n", "        ", "inp_size", "=", "output_size", "=", "int", "(", "stft", ".", "n_feats_out", "/", "2", ")", "\n", "# Add these fields to the mask model dict", "\n", "", "conf", "[", "\"masknet\"", "]", ".", "update", "(", "dict", "(", "input_size", "=", "inp_size", ",", "output_size", "=", "output_size", ")", ")", "\n", "masker", "=", "SimpleModel", "(", "**", "conf", "[", "\"masknet\"", "]", ")", "\n", "# Make the complete model", "\n", "model", "=", "Model", "(", "stft", ",", "masker", ",", "istft", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "# Define optimizer of this model", "\n", "optimizer", "=", "make_optimizer", "(", "model", ".", "parameters", "(", ")", ",", "**", "conf", "[", "\"optim\"", "]", ")", "\n", "return", "model", ",", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.model.distance": [[142, 162], ["asteroid_filterbanks.transforms.mag().pow().mean", "asteroid_filterbanks.transforms.mag().pow", "asteroid_filterbanks.transforms.mag", "asteroid_filterbanks.transforms.mag", "asteroid_filterbanks.transforms.mag"], "function", ["None"], ["", "", "def", "distance", "(", "estimate", ",", "target", ",", "is_complex", "=", "True", ")", ":", "\n", "    ", "\"\"\"Compute the average distance in the complex plane. Makes more sense\n    when the network computes a complex mask.\n\n    Args:\n        estimate (torch.Tensor): Estimate complex spectrogram.\n        target (torch.Tensor): Speech target complex spectrogram.\n        is_complex (bool): Whether to compute the distance in the complex or\n            the magnitude space.\n\n    Returns:\n        torch.Tensor the loss value, in a tensor of size 1.\n    \"\"\"", "\n", "if", "is_complex", ":", "\n", "# Take the difference in the complex plane and compute the squared norm", "\n", "# of the remaining vector.", "\n", "        ", "return", "mag", "(", "estimate", "-", "target", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "# Compute the mean difference between magnitudes.", "\n", "        ", "return", "(", "mag", "(", "estimate", ")", "-", "mag", "(", "target", ")", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.model.load_best_model": [[164, 187], ["model.make_model_and_optimizer", "min", "torch.load", "asteroid.torch_utils.load_state_dict_in", "torch_utils.load_state_dict_in.eval", "open", "json.load", "os.path.join"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.load_state_dict_in"], ["", "", "def", "load_best_model", "(", "train_conf", ",", "exp_dir", ")", ":", "\n", "    ", "\"\"\"Load best model after training.\n\n    Args:\n        train_conf (dict): dictionary as expected by `make_model_and_optimizer`\n        exp_dir(str): Experiment directory. Expects to find\n            `'best_k_models.json'` there.\n\n    Returns:\n        nn.Module the best pretrained model according to the val_loss.\n    \"\"\"", "\n", "# Create the model from recipe-local function", "\n", "model", ",", "_", "=", "make_model_and_optimizer", "(", "train_conf", ")", "\n", "# Last best model summary", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "best_k", "=", "json", ".", "load", "(", "f", ")", "\n", "", "best_model_path", "=", "min", "(", "best_k", ",", "key", "=", "best_k", ".", "get", ")", "\n", "# Load checkpoint", "\n", "checkpoint", "=", "torch", ".", "load", "(", "best_model_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "# Load state_dict into model.", "\n", "model", "=", "torch_utils", ".", "load_state_dict_in", "(", "checkpoint", "[", "\"state_dict\"", "]", ",", "model", ")", "\n", "model", ".", "eval", "(", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.denoise.main": [[23, 48], ["model.load_best_model", "os.path.join", "os.makedirs", "os.path.isfile", "tqdm.tqdm", "model.cuda.cuda", "next", "os.path.join", "glob.glob", "soundfile.read", "os.path.basename", "soundfile.write", "model.cuda.parameters", "os.path.basename", "torch.no_grad", "[].to", "model.cuda.denoise().squeeze().cpu().data.numpy", "os.path.join", "torch.tensor", "model.cuda.denoise().squeeze().cpu", "model.cuda.denoise().squeeze", "model.cuda.denoise"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.load_best_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.baseline.model.Model.denoise"], ["def", "main", "(", "conf", ")", ":", "\n", "# Get best trained model", "\n", "    ", "model", "=", "load_best_model", "(", "conf", "[", "\"train_conf\"", "]", ",", "conf", "[", "\"exp_dir\"", "]", ")", "\n", "if", "conf", "[", "\"use_gpu\"", "]", ":", "\n", "        ", "model", "=", "model", ".", "cuda", "(", ")", "\n", "", "model_device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "# Get a list of wav files (or single wav file)", "\n", "save_folder", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"denoise\"", ")", "\n", "os", ".", "makedirs", "(", "save_folder", ",", "exist_ok", "=", "True", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "conf", "[", "\"denoise_path\"", "]", ")", ":", "\n", "        ", "all_wavs", "=", "[", "conf", "[", "\"denoise_path\"", "]", "]", "\n", "", "else", ":", "\n", "# If this is a bunch of files we need to denoise, call the subdir", "\n", "# of denoise the same way as the basename of the denoise dir.", "\n", "        ", "save_folder", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "os", ".", "path", ".", "basename", "(", "conf", "[", "\"denoise_path\"", "]", ")", ")", "\n", "all_wavs", "=", "glob", ".", "glob", "(", "conf", "[", "\"denoise_path\"", "]", "+", "\"*.wav\"", ")", "\n", "\n", "", "for", "wav_path", "in", "tqdm", "(", "all_wavs", ")", ":", "\n", "        ", "mix", ",", "fs", "=", "sf", ".", "read", "(", "wav_path", ",", "dtype", "=", "\"float32\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "net_inp", "=", "torch", ".", "tensor", "(", "mix", ")", "[", "None", "]", ".", "to", "(", "model_device", ")", "\n", "estimate", "=", "model", ".", "denoise", "(", "net_inp", ")", ".", "squeeze", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "# Save the estimate speech", "\n", "", "wav_name", "=", "os", ".", "path", ".", "basename", "(", "wav_path", ")", "\n", "sf", ".", "write", "(", "os", ".", "path", ".", "join", "(", "save_folder", ",", "wav_name", ")", ",", "estimate", ",", "fs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_dns.preprocess_dns": [[8, 39], ["glob.glob", "preprocess_dns.make_wav_id_dict", "glob.glob", "preprocess_dns.make_wav_id_dict", "glob.glob", "preprocess_dns.make_wav_id_dict", "os.path.join", "os.path.join", "os.path.join", "make_wav_id_dict.keys", "make_wav_id_dict.keys", "make_wav_id_dict.keys", "dict", "open", "json.dump", "make_wav_id_dict.keys", "os.path.join", "preprocess_dns.get_snr_from_mix_path", "len", "soundfile.SoundFile"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_dns.make_wav_id_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_dns.make_wav_id_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_dns.make_wav_id_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_dns.get_snr_from_mix_path"], ["def", "preprocess_dns", "(", "in_dir", ",", "out_dir", "=", "\"./data\"", ")", ":", "\n", "    ", "\"\"\"Create json file from dataset folder.\n\n    Args:\n        in_dir (str): Location of the DNS data\n        out_dir (str): Where to save the json files.\n    \"\"\"", "\n", "# Get all file ids", "\n", "clean_wavs", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "in_dir", ",", "\"clean/*.wav\"", ")", ")", "\n", "clean_dic", "=", "make_wav_id_dict", "(", "clean_wavs", ")", "\n", "\n", "mix_wavs", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "in_dir", ",", "\"noisy/*.wav\"", ")", ")", "\n", "mix_dic", "=", "make_wav_id_dict", "(", "mix_wavs", ")", "\n", "\n", "noise_wavs", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "in_dir", ",", "\"noise/*.wav\"", ")", ")", "\n", "noise_dic", "=", "make_wav_id_dict", "(", "noise_wavs", ")", "\n", "assert", "clean_dic", ".", "keys", "(", ")", "==", "mix_dic", ".", "keys", "(", ")", "==", "noise_dic", ".", "keys", "(", ")", "\n", "file_infos", "=", "{", "\n", "k", ":", "dict", "(", "\n", "mix", "=", "mix_dic", "[", "k", "]", ",", "\n", "clean", "=", "clean_dic", "[", "k", "]", ",", "\n", "noise", "=", "noise_dic", "[", "k", "]", ",", "\n", "snr", "=", "get_snr_from_mix_path", "(", "mix_dic", "[", "k", "]", ")", ",", "\n", "file_len", "=", "len", "(", "sf", ".", "SoundFile", "(", "mix_dic", "[", "k", "]", ")", ")", ",", "\n", ")", "\n", "for", "k", "in", "clean_dic", ".", "keys", "(", ")", "\n", "}", "\n", "\n", "# Save to JSON", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"file_infos.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "file_infos", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_dns.make_wav_id_dict": [[41, 50], ["preprocess_dns.get_file_id"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_dns.get_file_id"], ["", "", "def", "make_wav_id_dict", "(", "file_list", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        file_list(List[str]): List of DNS challenge filenames.\n\n    Returns:\n        dict: Look like {file_id: filename, ...}\n    \"\"\"", "\n", "return", "{", "get_file_id", "(", "fp", ")", ":", "fp", "for", "fp", "in", "file_list", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_dns.get_file_id": [[52, 55], ["[].split", "fp.split"], "function", ["None"], ["", "def", "get_file_id", "(", "fp", ")", ":", "\n", "    ", "\"\"\"Split string to get wave id in DNS challenge dataset.\"\"\"", "\n", "return", "fp", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_dns.get_snr_from_mix_path": [[57, 74], ["[].split", "int", "mix_path.split"], "function", ["None"], ["", "def", "get_snr_from_mix_path", "(", "mix_path", ")", ":", "\n", "    ", "\"\"\" Retrieves mixing SNR from mixture filename.\n\n    Args:\n        mix_path (str): Path to the mixture. Something like :\n        book_11346_chp_0012_reader_08537_8_kFu2mH7D77k-5YOmLILWHyg-\\\n        gWMWteRIgiw_snr6_tl-35_fileid_3614.wav\n\n    Returns:\n        int or None: the SNR value if we could parse it.\n    \"\"\"", "\n", "snr_str", "=", "mix_path", ".", "split", "(", "\"snr\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "try", ":", "\n", "        ", "snr", "=", "int", "(", "snr_str", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "snr", "=", "None", "\n", "", "return", "snr", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_kinect_wsj.preprocess_one_dir": [[7, 23], ["os.path.abspath", "os.listdir", "os.listdir.sort", "os.path.join", "soundfile.SoundFile", "file_infos.append", "os.path.exists", "os.makedirs", "open", "json.dump", "wav_file.endswith", "os.path.join", "len"], "function", ["None"], ["def", "preprocess_one_dir", "(", "in_dir", ",", "out_dir", ",", "out_filename", ")", ":", "\n", "    ", "\"\"\"Create .json file for one condition.\"\"\"", "\n", "file_infos", "=", "[", "]", "\n", "in_dir", "=", "os", ".", "path", ".", "abspath", "(", "in_dir", ")", "\n", "wav_list", "=", "os", ".", "listdir", "(", "in_dir", ")", "\n", "wav_list", ".", "sort", "(", ")", "\n", "for", "wav_file", "in", "wav_list", ":", "\n", "        ", "if", "not", "wav_file", ".", "endswith", "(", "\".wav\"", ")", ":", "\n", "            ", "continue", "\n", "", "wav_path", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "wav_file", ")", "\n", "samples", "=", "sf", ".", "SoundFile", "(", "wav_path", ")", "\n", "file_infos", ".", "append", "(", "(", "wav_path", ",", "len", "(", "samples", ")", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "out_filename", "+", "\".json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "file_infos", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_kinect_wsj.preprocess": [[25, 34], ["preprocess_kinect_wsj.preprocess_one_dir", "range", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_wham.preprocess_one_dir"], ["", "", "def", "preprocess", "(", "inp_args", ")", ":", "\n", "    ", "\"\"\"Create .json files for all conditions.\"\"\"", "\n", "speaker_list", "=", "[", "\"mix\"", "]", "+", "[", "f\"s{n+1}\"", "for", "n", "in", "range", "(", "inp_args", ".", "n_src", ")", "]", "\n", "for", "data_type", "in", "[", "\"tr\"", ",", "\"cv\"", ",", "\"tt\"", "]", ":", "\n", "        ", "for", "spk", "in", "speaker_list", ":", "\n", "            ", "preprocess_one_dir", "(", "\n", "os", ".", "path", ".", "join", "(", "inp_args", ".", "in_dir", ",", "data_type", ",", "spk", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "inp_args", ".", "out_dir", ",", "data_type", ")", ",", "\n", "spk", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_whamr.preprocess_one_dir": [[7, 21], ["os.path.abspath", "os.listdir", "os.listdir.sort", "os.path.join", "soundfile.SoundFile", "file_infos.append", "wav_file.endswith", "len"], "function", ["None"], ["def", "preprocess_one_dir", "(", "in_dir", ")", ":", "\n", "    ", "\"\"\"Create list of list for one condition, each list contains\n    [path, wav_length].\"\"\"", "\n", "file_infos", "=", "[", "]", "\n", "in_dir", "=", "os", ".", "path", ".", "abspath", "(", "in_dir", ")", "\n", "wav_list", "=", "os", ".", "listdir", "(", "in_dir", ")", "\n", "wav_list", ".", "sort", "(", ")", "\n", "for", "wav_file", "in", "wav_list", ":", "\n", "        ", "if", "not", "wav_file", ".", "endswith", "(", "\".wav\"", ")", ":", "\n", "            ", "continue", "\n", "", "wav_path", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "wav_file", ")", "\n", "samples", "=", "sf", ".", "SoundFile", "(", "wav_path", ")", "\n", "file_infos", ".", "append", "(", "(", "wav_path", ",", "len", "(", "samples", ")", ")", ")", "\n", "", "return", "file_infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_whamr.preprocess": [[23, 54], ["os.path.join", "preprocess_whamr.preprocess_one_dir", "os.path.exists", "os.makedirs", "os.path.join", "local_to_json.append", "open", "json.dump", "os.path.join", "name.replace"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_wham.preprocess_one_dir"], ["", "def", "preprocess", "(", "inp_args", ")", ":", "\n", "    ", "\"\"\"Create .json files for all conditions.\"\"\"", "\n", "# The filenames are shared between directories (and lengths as well) so", "\n", "# we can just search once and replace directory name after.", "\n", "speaker_list", "=", "[", "\n", "\"s1_anechoic\"", ",", "\n", "\"s2_anechoic\"", ",", "\n", "\"s1_reverb\"", ",", "\n", "\"s2_reverb\"", ",", "\n", "\"mix_single_anechoic\"", ",", "\n", "\"mix_clean_anechoic\"", ",", "\n", "\"mix_both_anechoic\"", ",", "\n", "\"mix_single_reverb\"", ",", "\n", "\"mix_clean_reverb\"", ",", "\n", "\"mix_both_reverb\"", ",", "\n", "]", "\n", "for", "data_type", "in", "[", "\"tr\"", ",", "\"cv\"", ",", "\"tt\"", "]", ":", "\n", "        ", "out_dir", "=", "os", ".", "path", ".", "join", "(", "inp_args", ".", "out_dir", ",", "data_type", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "# Create the first list of wavs", "\n", "", "spk_0", "=", "speaker_list", "[", "0", "]", "\n", "to_json", "=", "preprocess_one_dir", "(", "os", ".", "path", ".", "join", "(", "inp_args", ".", "in_dir", ",", "data_type", ",", "spk_0", ")", ")", "\n", "# Replace directory names to match all conditions", "\n", "for", "spk", "in", "speaker_list", ":", "\n", "            ", "local_to_json", "=", "[", "]", "\n", "for", "wav_info", "in", "to_json", ":", "\n", "                ", "name", ",", "wav_len", "=", "wav_info", "\n", "local_to_json", ".", "append", "(", "[", "name", ".", "replace", "(", "spk_0", ",", "spk", ")", ",", "wav_len", "]", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "spk", "+", "\".json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "local_to_json", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_wsj0mix.preprocess_one_dir": [[7, 23], ["os.path.abspath", "os.listdir", "os.listdir.sort", "os.path.join", "soundfile.SoundFile", "file_infos.append", "os.path.exists", "os.makedirs", "open", "json.dump", "wav_file.endswith", "os.path.join", "len"], "function", ["None"], ["def", "preprocess_one_dir", "(", "in_dir", ",", "out_dir", ",", "out_filename", ")", ":", "\n", "    ", "\"\"\"Create .json file for one condition.\"\"\"", "\n", "file_infos", "=", "[", "]", "\n", "in_dir", "=", "os", ".", "path", ".", "abspath", "(", "in_dir", ")", "\n", "wav_list", "=", "os", ".", "listdir", "(", "in_dir", ")", "\n", "wav_list", ".", "sort", "(", ")", "\n", "for", "wav_file", "in", "wav_list", ":", "\n", "        ", "if", "not", "wav_file", ".", "endswith", "(", "\".wav\"", ")", ":", "\n", "            ", "continue", "\n", "", "wav_path", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "wav_file", ")", "\n", "samples", "=", "sf", ".", "SoundFile", "(", "wav_path", ")", "\n", "file_infos", ".", "append", "(", "(", "wav_path", ",", "len", "(", "samples", ")", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "out_filename", "+", "\".json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "file_infos", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_wsj0mix.preprocess": [[25, 34], ["preprocess_wsj0mix.preprocess_one_dir", "range", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_wham.preprocess_one_dir"], ["", "", "def", "preprocess", "(", "inp_args", ")", ":", "\n", "    ", "\"\"\"Create .json files for all conditions.\"\"\"", "\n", "speaker_list", "=", "[", "\"mix\"", "]", "+", "[", "f\"s{n+1}\"", "for", "n", "in", "range", "(", "inp_args", ".", "n_src", ")", "]", "\n", "for", "data_type", "in", "[", "\"tr\"", ",", "\"cv\"", ",", "\"tt\"", "]", ":", "\n", "        ", "for", "spk", "in", "speaker_list", ":", "\n", "            ", "preprocess_one_dir", "(", "\n", "os", ".", "path", ".", "join", "(", "inp_args", ".", "in_dir", ",", "data_type", ",", "spk", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "inp_args", ".", "out_dir", ",", "data_type", ")", ",", "\n", "spk", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.parse_data.parse_dataset": [[14, 37], ["glob.glob", "os.makedirs", "os.path.join", "glob.glob", "open", "json.dump", "os.path.join", "glob.glob", "examples.append", "pathlib.Path", "os.path.join", "int", "len", "pathlib.Path().stem.split", "soundfile.SoundFile", "c_ex.keys", "re.findall", "pathlib.Path", "pathlib.Path().stem.split", "pathlib.Path"], "function", ["None"], ["def", "parse_dataset", "(", "in_dir", ",", "out_json", ")", ":", "\n", "\n", "    ", "examples", "=", "[", "]", "\n", "for", "n_mic_f", "in", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "in_dir", ",", "\"*\"", ")", ")", ":", "\n", "        ", "for", "sample_dir", "in", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "n_mic_f", ",", "\"*\"", ")", ")", ":", "\n", "            ", "c_ex", "=", "{", "}", "\n", "for", "wav", "in", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "sample_dir", ",", "\"*.wav\"", ")", ")", ":", "\n", "\n", "                ", "source_or_mix", "=", "Path", "(", "wav", ")", ".", "stem", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "n_mic", "=", "int", "(", "re", ".", "findall", "(", "\"\\d+\"", ",", "Path", "(", "wav", ")", ".", "stem", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ")", "[", "0", "]", ")", "\n", "length", "=", "len", "(", "sf", ".", "SoundFile", "(", "wav", ")", ")", "\n", "\n", "if", "n_mic", "not", "in", "c_ex", ".", "keys", "(", ")", ":", "\n", "                    ", "c_ex", "[", "n_mic", "]", "=", "{", "source_or_mix", ":", "wav", ",", "\"length\"", ":", "length", "}", "\n", "", "else", ":", "\n", "                    ", "assert", "c_ex", "[", "n_mic", "]", "[", "\"length\"", "]", "==", "length", "\n", "c_ex", "[", "n_mic", "]", "[", "source_or_mix", "]", "=", "wav", "\n", "", "", "examples", ".", "append", "(", "c_ex", ")", "\n", "\n", "", "", "os", ".", "makedirs", "(", "Path", "(", "out_json", ")", ".", "parent", ",", "exist_ok", "=", "True", ")", "\n", "\n", "with", "open", "(", "out_json", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "examples", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.tac_dataset.TACDataset.__init__": [[24, 51], ["open", "json.load", "int", "print", "sorted", "tac_dataset.TACDataset.examples.append", "len", "len", "len", "str().strip", "str", "pathlib.Path"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "json_file", ",", "segment", "=", "None", ",", "sample_rate", "=", "16000", ",", "max_mics", "=", "6", ",", "train", "=", "True", ")", ":", "\n", "        ", "self", ".", "segment", "=", "segment", "\n", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "max_mics", "=", "max_mics", "\n", "self", ".", "train", "=", "train", "\n", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "examples", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "if", "self", ".", "segment", ":", "\n", "            ", "target_len", "=", "int", "(", "segment", "*", "sample_rate", ")", "\n", "self", ".", "examples", "=", "[", "]", "\n", "for", "ex", "in", "examples", ":", "\n", "                ", "if", "ex", "[", "\"1\"", "]", "[", "\"length\"", "]", "<", "target_len", ":", "\n", "                    ", "continue", "\n", "", "self", ".", "examples", ".", "append", "(", "ex", ")", "\n", "", "print", "(", "\n", "\"Discarded {} out of {} because too short\"", ".", "format", "(", "\n", "len", "(", "examples", ")", "-", "len", "(", "self", ".", "examples", ")", ",", "len", "(", "examples", ")", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "examples", "=", "examples", "\n", "", "if", "not", "train", ":", "\n", "# sort examples based on number", "\n", "            ", "self", ".", "examples", "=", "sorted", "(", "\n", "self", ".", "examples", ",", "key", "=", "lambda", "x", ":", "str", "(", "Path", "(", "x", "[", "\"2\"", "]", "[", "\"spk1\"", "]", ")", ".", "parent", ")", ".", "strip", "(", "\"sample\"", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.tac_dataset.TACDataset.__len__": [[53, 55], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.tac_dataset.TACDataset.__getitem__": [[56, 117], ["range", "torch.cat", "torch.stack", "numpy.random.shuffle", "len", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.from_numpy().unsqueeze", "torch.cat.append", "torch.cat.append", "torch.zeros", "torch.cat", "torch.cat", "c_ex.keys", "soundfile.read", "soundfile.read", "soundfile.read", "soundfile.read", "soundfile.read", "soundfile.read", "torch.cat", "int", "numpy.random.randint", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.zeros.unsqueeze().repeat", "int", "int", "int", "int", "torch.zeros.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "\"\"\"Returns mixtures, sources and the number of mics in the recording, padded to `max_mics`.\"\"\"", "\n", "c_ex", "=", "self", ".", "examples", "[", "item", "]", "\n", "# randomly select ref mic", "\n", "mics", "=", "[", "x", "for", "x", "in", "c_ex", ".", "keys", "(", ")", "]", "\n", "if", "self", ".", "train", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "mics", ")", "# randomly permute during training to change ref mics", "\n", "\n", "", "mixtures", "=", "[", "]", "\n", "sources", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "mics", ")", ")", ":", "\n", "            ", "c_mic", "=", "c_ex", "[", "mics", "[", "i", "]", "]", "\n", "\n", "if", "self", ".", "segment", ":", "\n", "                ", "offset", "=", "0", "\n", "if", "c_mic", "[", "\"length\"", "]", ">", "int", "(", "self", ".", "segment", "*", "self", ".", "sample_rate", ")", ":", "\n", "                    ", "offset", "=", "np", ".", "random", ".", "randint", "(", "\n", "0", ",", "c_mic", "[", "\"length\"", "]", "-", "int", "(", "self", ".", "segment", "*", "self", ".", "sample_rate", ")", "\n", ")", "\n", "\n", "# we load mixture", "\n", "", "mixture", ",", "fs", "=", "sf", ".", "read", "(", "\n", "c_mic", "[", "\"mixture\"", "]", ",", "\n", "start", "=", "offset", ",", "\n", "stop", "=", "offset", "+", "int", "(", "self", ".", "segment", "*", "self", ".", "sample_rate", ")", ",", "\n", "dtype", "=", "\"float32\"", ",", "\n", ")", "\n", "spk1", ",", "fs", "=", "sf", ".", "read", "(", "\n", "c_mic", "[", "\"spk1\"", "]", ",", "\n", "start", "=", "offset", ",", "\n", "stop", "=", "offset", "+", "int", "(", "self", ".", "segment", "*", "self", ".", "sample_rate", ")", ",", "\n", "dtype", "=", "\"float32\"", ",", "\n", ")", "\n", "spk2", ",", "fs", "=", "sf", ".", "read", "(", "\n", "c_mic", "[", "\"spk2\"", "]", ",", "\n", "start", "=", "offset", ",", "\n", "stop", "=", "offset", "+", "int", "(", "self", ".", "segment", "*", "self", ".", "sample_rate", ")", ",", "\n", "dtype", "=", "\"float32\"", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "mixture", ",", "fs", "=", "sf", ".", "read", "(", "c_mic", "[", "\"mixture\"", "]", ",", "dtype", "=", "\"float32\"", ")", "# load all", "\n", "spk1", ",", "fs", "=", "sf", ".", "read", "(", "c_mic", "[", "\"spk1\"", "]", ",", "dtype", "=", "\"float32\"", ")", "\n", "spk2", ",", "fs", "=", "sf", ".", "read", "(", "c_mic", "[", "\"spk2\"", "]", ",", "dtype", "=", "\"float32\"", ")", "\n", "\n", "", "mixture", "=", "torch", ".", "from_numpy", "(", "mixture", ")", ".", "unsqueeze", "(", "0", ")", "\n", "spk1", "=", "torch", ".", "from_numpy", "(", "spk1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "spk2", "=", "torch", ".", "from_numpy", "(", "spk2", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "assert", "fs", "==", "self", ".", "sample_rate", "\n", "mixtures", ".", "append", "(", "mixture", ")", "\n", "sources", ".", "append", "(", "torch", ".", "cat", "(", "(", "spk1", ",", "spk2", ")", ",", "0", ")", ")", "\n", "\n", "", "mixtures", "=", "torch", ".", "cat", "(", "mixtures", ",", "0", ")", "\n", "sources", "=", "torch", ".", "stack", "(", "sources", ")", "\n", "# we pad till max_mic", "\n", "valid_mics", "=", "mixtures", ".", "shape", "[", "0", "]", "\n", "if", "mixtures", ".", "shape", "[", "0", "]", "<", "self", ".", "max_mics", ":", "\n", "            ", "dummy", "=", "torch", ".", "zeros", "(", "(", "self", ".", "max_mics", "-", "mixtures", ".", "shape", "[", "0", "]", ",", "mixtures", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "mixtures", "=", "torch", ".", "cat", "(", "(", "mixtures", ",", "dummy", ")", ",", "0", ")", "\n", "sources", "=", "torch", ".", "cat", "(", "(", "sources", ",", "dummy", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "sources", ".", "shape", "[", "1", "]", ",", "1", ")", ")", ",", "0", ")", "\n", "", "return", "mixtures", ",", "sources", ",", "valid_mics", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.tac_dataset.TACDataset.get_infos": [[118, 129], ["dict"], "methods", ["None"], ["", "def", "get_infos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get dataset infos (for publishing models).\n\n        Returns:\n            dict, dataset infos with keys `dataset`, `task` and `licences`.\n        \"\"\"", "\n", "infos", "=", "dict", "(", ")", "\n", "infos", "[", "\"dataset\"", "]", "=", "self", ".", "dataset_name", "\n", "infos", "[", "\"task\"", "]", "=", "\"separate_noisy\"", "\n", "infos", "[", "\"licenses\"", "]", "=", "[", "librispeech_license", ",", "tac_license", "]", "\n", "return", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.__init__": [[64, 95], ["open", "json.load", "demask_dataset.DeMaskDataset.clean.append", "open", "json.load", "open", "json.load", "demask_dataset.DeMaskDataset.clean.append"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "configs", ",", "clean_speech_dataset", ",", "train", ",", "rirs_dataset", "=", "None", ",", "noises_dataset", "=", "None", "\n", ")", ":", "\n", "        ", "self", ".", "configs", "=", "configs", "\n", "self", ".", "train", "=", "train", "\n", "\n", "with", "open", "(", "clean_speech_dataset", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "clean", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "clean", "=", "[", "]", "\n", "for", "c", "in", "clean", ":", "\n", "            ", "if", "c", "[", "\"length\"", "]", "<", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"fs\"", "]", "*", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"length\"", "]", ":", "\n", "                ", "continue", "\n", "", "self", ".", "clean", ".", "append", "(", "c", "[", "\"file\"", "]", ")", "\n", "\n", "", "self", ".", "firs", "=", "mask_firs", "\n", "\n", "self", ".", "rirs", "=", "None", "\n", "if", "rirs_dataset", ":", "\n", "            ", "with", "open", "(", "rirs_dataset", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "rirs", "=", "json", ".", "load", "(", "f", ")", "\n", "", "self", ".", "rirs", "=", "[", "x", "[", "\"file\"", "]", "for", "x", "in", "rirs", "]", "\n", "\n", "", "self", ".", "noises", "=", "None", "\n", "if", "noises_dataset", ":", "\n", "            ", "with", "open", "(", "noises_dataset", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "noises", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "n", "in", "noises", ":", "\n", "                    ", "if", "n", "[", "\"length\"", "]", "<", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"fs\"", "]", "*", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"length\"", "]", ":", "\n", "                        ", "continue", "\n", "", "self", ".", "clean", ".", "append", "(", "n", "[", "\"file\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.__len__": [[96, 98], ["len"], "methods", ["None"], ["", "", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "clean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.augment_clean": [[99, 117], ["eval", "eval", "pysndfx.AudioEffectsChain().speed", "pysndfx.AudioEffectsChain().custom.", "pysndfx.AudioEffectsChain().custom", "pysndfx.AudioEffectsChain().custom.", "soundfile.read", "scipy.signal.fftconvolve", "pysndfx.AudioEffectsChain", "numpy.random.choice", "pysndfx.AudioEffectsChain"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "augment_clean", "(", "self", ",", "clean", ")", ":", "\n", "\n", "        ", "speed", "=", "eval", "(", "self", ".", "configs", "[", "\"training\"", "]", "[", "\"speed_augm\"", "]", ")", "\n", "c_gain", "=", "eval", "(", "self", ".", "configs", "[", "\"training\"", "]", "[", "\"gain_augm\"", "]", ")", "\n", "\n", "fx", "=", "AudioEffectsChain", "(", ")", ".", "speed", "(", "speed", ")", "# speed perturb", "\n", "clean", "=", "fx", "(", "clean", ")", "\n", "\n", "if", "self", ".", "rirs", ":", "\n", "            ", "c_rir", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "rirs", ",", "1", ")", "[", "0", "]", "\n", "c_rir", ",", "fs", "=", "sf", ".", "read", "(", "c_rir", ")", "\n", "assert", "fs", "==", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"fs\"", "]", "\n", "clean", "=", "fftconvolve", "(", "clean", ",", "c_rir", ")", "\n", "\n", "", "fx", "=", "AudioEffectsChain", "(", ")", ".", "custom", "(", "\"norm {}\"", ".", "format", "(", "c_gain", ")", ")", "# random gain", "\n", "clean", "=", "fx", "(", "clean", ")", "\n", "\n", "return", "clean", ",", "c_gain", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.add_noise": [[118, 141], ["pysndfx.AudioEffectsChain().custom", "soundfile.read", "int", "pysndfx.AudioEffectsChain().custom.", "numpy.random.choice", "len", "len", "numpy.random.randint", "pysndfx.AudioEffectsChain", "eval", "len", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "add_noise", "(", "self", ",", "clean", ",", "masked", ",", "c_gain", ")", ":", "\n", "\n", "        ", "fx", "=", "AudioEffectsChain", "(", ")", ".", "custom", "(", "\n", "\"norm {}\"", ".", "format", "(", "eval", "(", "c_gain", "-", "self", ".", "configs", "[", "\"training\"", "]", "[", "\"snr\"", "]", ")", ")", "\n", ")", "\n", "\n", "noise", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "noises", ",", "1", ")", "[", "0", "]", "\n", "noise", ",", "fs", "=", "sf", ".", "read", "(", "noise", ")", "\n", "if", "len", "(", "noise", ".", "shape", ")", ">", "2", ":", "\n", "# select random channel", "\n", "            ", "noise", "=", "noise", "[", ":", ",", "np", ".", "random", ".", "randint", "(", "0", ",", "noise", ".", "shape", "-", "1", ")", "]", "\n", "", "offset", "=", "0", "\n", "target_len", "=", "int", "(", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"fs\"", "]", "*", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"length\"", "]", ")", "\n", "if", "len", "(", "noise", ")", ">", "target_len", ":", "\n", "            ", "offset", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "noise", ")", "-", "target_len", ")", "\n", "\n", "", "noise", "=", "noise", "[", "offset", ":", "offset", "+", "target_len", "]", "\n", "assert", "fs", "==", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"fs\"", "]", "\n", "noise", "=", "fx", "(", "noise", ")", "\n", "clean", "=", "clean", "+", "noise", "# NB demask is not doing denoising", "\n", "masked", "=", "masked", "+", "noise", "\n", "\n", "return", "clean", ",", "masked", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.__getitem__": [[142, 207], ["soundfile.read", "int", "demask_dataset.DeMaskDataset.augment_clean", "list", "numpy.array", "numpy.array", "scipy.signal.firwin2", "scipy.signal.fftconvolve", "numpy.pad", "len", "numpy.random.randint", "demask_dataset.DeMaskDataset.firs.keys", "numpy.random.choice", "numpy.random.normal", "len", "demask_dataset.DeMaskDataset.add_noise", "torch.from_numpy().float", "torch.from_numpy().float", "len", "len", "len", "len", "numpy.pad", "numpy.pad", "numpy.random.normal", "len", "eval", "numpy.var", "torch.from_numpy", "torch.from_numpy", "len", "eval", "numpy.var", "int", "len", "int", "len"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.augment_clean", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.add_noise", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "# 1 we sample a clean utterance", "\n", "        ", "clean", "=", "self", ".", "clean", "[", "item", "]", "\n", "clean", ",", "fs", "=", "sf", ".", "read", "(", "clean", ")", "\n", "assert", "fs", "==", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"fs\"", "]", "\n", "# we sample a random window", "\n", "target_len", "=", "int", "(", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"fs\"", "]", "*", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"length\"", "]", ")", "\n", "offset", "=", "0", "\n", "if", "len", "(", "clean", ")", ">", "target_len", ":", "\n", "            ", "offset", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "clean", ")", "-", "target_len", ")", "\n", "\n", "", "clean", "=", "clean", "[", "offset", ":", "offset", "+", "target_len", "]", "\n", "clean", ",", "c_gain", "=", "self", ".", "augment_clean", "(", "clean", ")", "\n", "\n", "# we add reverberation, speed perturb and random scaling", "\n", "masks", "=", "list", "(", "self", ".", "firs", ".", "keys", "(", ")", ")", "\n", "c_mask", "=", "np", ".", "random", ".", "choice", "(", "masks", ",", "1", ")", "[", "0", "]", "\n", "c_mask", "=", "self", ".", "firs", "[", "c_mask", "]", "\n", "\n", "gains", "=", "np", ".", "array", "(", "c_mask", "[", "\"gain\"", "]", ")", "\n", "freqs", "=", "np", ".", "array", "(", "c_mask", "[", "\"freq\"", "]", ")", "\n", "\n", "if", "self", ".", "train", ":", "\n", "# augment the gains with random noise: no mask is created equal", "\n", "            ", "snr", "=", "10", "**", "(", "eval", "(", "self", ".", "configs", "[", "\"training\"", "]", "[", "\"gaussian_mask_noise_snr_dB\"", "]", ")", "/", "20", ")", "\n", "gains", "+=", "np", ".", "random", ".", "normal", "(", "0", ",", "np", ".", "var", "(", "gains", ")", "/", "snr", ",", "gains", ".", "shape", ")", "\n", "\n", "", "fir", "=", "firwin2", "(", "\n", "self", ".", "configs", "[", "\"training\"", "]", "[", "\"n_taps\"", "]", ",", "freqs", ",", "gains", ",", "fs", "=", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"fs\"", "]", "\n", ")", "\n", "\n", "masked", "=", "fftconvolve", "(", "clean", ",", "fir", ")", "\n", "clean", "=", "np", ".", "pad", "(", "clean", ",", "(", "(", "len", "(", "fir", ")", "-", "1", ")", "//", "2", ",", "0", ")", ",", "mode", "=", "\"constant\"", ")", "\n", "trim_start", "=", "(", "len", "(", "fir", ")", "-", "1", ")", "//", "2", "\n", "trim_end", "=", "len", "(", "clean", ")", "-", "len", "(", "fir", ")", "+", "1", "\n", "clean", "=", "clean", "[", "trim_start", ":", "trim_end", "]", "\n", "masked", "=", "masked", "[", "trim_start", ":", "trim_end", "]", "\n", "\n", "if", "len", "(", "clean", ")", ">", "target_len", ":", "\n", "            ", "clean", "=", "clean", "[", ":", "target_len", "]", "\n", "masked", "=", "masked", "[", ":", "target_len", "]", "\n", "", "elif", "len", "(", "clean", ")", "<", "target_len", ":", "\n", "            ", "clean", "=", "np", ".", "pad", "(", "\n", "clean", ",", "\n", "(", "0", ",", "int", "(", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"fs\"", "]", "*", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"length\"", "]", ")", "-", "len", "(", "clean", ")", ")", ",", "\n", "mode", "=", "\"constant\"", ",", "\n", ")", "\n", "masked", "=", "np", ".", "pad", "(", "\n", "masked", ",", "\n", "(", "0", ",", "int", "(", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"fs\"", "]", "*", "self", ".", "configs", "[", "\"data\"", "]", "[", "\"length\"", "]", ")", "-", "len", "(", "masked", ")", ")", ",", "\n", "mode", "=", "\"constant\"", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "if", "self", ".", "noises", ":", "\n", "            ", "clean", ",", "masked", "=", "self", ".", "add_noise", "(", "clean", ",", "masked", ",", "c_gain", ")", "\n", "", "else", ":", "# if no noises still add gaussian noise when training", "\n", "            ", "if", "self", ".", "train", ":", "\n", "                ", "snr", "=", "10", "**", "(", "eval", "(", "self", ".", "configs", "[", "\"training\"", "]", "[", "\"white_noise_dB\"", "]", ")", "/", "20", ")", "\n", "noise", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "np", ".", "var", "(", "masked", ")", "/", "snr", ",", "masked", ".", "shape", ")", "\n", "masked", "+=", "noise", "# NB demask is not doing denoising", "\n", "clean", "+=", "noise", "\n", "\n", "", "", "return", "torch", ".", "from_numpy", "(", "masked", ")", ".", "float", "(", ")", ",", "torch", ".", "from_numpy", "(", "clean", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos": [[208, 219], ["dict"], "methods", ["None"], ["", "def", "get_infos", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get dataset infos (for publishing models).\n\n        Returns:\n            dict, dataset infos with keys `dataset`, `task` and `licences`.\n        \"\"\"", "\n", "infos", "=", "dict", "(", ")", "\n", "infos", "[", "\"dataset\"", "]", "=", "self", ".", "dataset_name", "\n", "infos", "[", "\"task\"", "]", "=", "\"enhancement\"", "\n", "infos", "[", "\"licenses\"", "]", "=", "[", "librispeech_license", ",", "fuss_license", ",", "demask_license", "]", "\n", "return", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.dataloader.Compose.__init__": [[87, 89], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.dataloader.Compose.__call__": [[90, 94], ["transform"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "audio", ")", ":", "\n", "        ", "for", "transform", "in", "self", ".", "transforms", ":", "\n", "            ", "audio", "=", "transform", "(", "audio", ")", "\n", "", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.dataloader.load_datasets": [[23, 64], ["parser.parse_args", "dataloader.Compose", "asteroid.data.MUSDB18Dataset", "dataloader.filtering_out_valid", "asteroid.data.MUSDB18Dataset", "pathlib.Path", "globals"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.local.dataloader.filtering_out_valid"], ["def", "load_datasets", "(", "parser", ",", "args", ")", ":", "\n", "    ", "\"\"\"Loads the specified dataset from commandline arguments\n\n    Returns:\n        train_dataset, validation_dataset\n    \"\"\"", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "dataset_kwargs", "=", "{", "\n", "\"root\"", ":", "Path", "(", "args", ".", "train_dir", ")", ",", "\n", "}", "\n", "\n", "source_augmentations", "=", "Compose", "(", "\n", "[", "globals", "(", ")", "[", "\"_augment_\"", "+", "aug", "]", "for", "aug", "in", "args", ".", "source_augmentations", "]", "\n", ")", "\n", "\n", "train_dataset", "=", "MUSDB18Dataset", "(", "\n", "split", "=", "\"train\"", ",", "\n", "sources", "=", "args", ".", "sources", ",", "\n", "targets", "=", "args", ".", "sources", ",", "\n", "source_augmentations", "=", "source_augmentations", ",", "\n", "random_track_mix", "=", "True", ",", "\n", "segment", "=", "args", ".", "seq_dur", ",", "\n", "random_segments", "=", "True", ",", "\n", "sample_rate", "=", "args", ".", "sample_rate", ",", "\n", "samples_per_track", "=", "args", ".", "samples_per_track", ",", "\n", "**", "dataset_kwargs", ",", "\n", ")", "\n", "train_dataset", "=", "filtering_out_valid", "(", "train_dataset", ")", "\n", "\n", "valid_dataset", "=", "MUSDB18Dataset", "(", "\n", "split", "=", "\"train\"", ",", "\n", "subset", "=", "validation_tracks", ",", "\n", "sources", "=", "args", ".", "sources", ",", "\n", "targets", "=", "args", ".", "sources", ",", "\n", "segment", "=", "None", ",", "\n", "**", "dataset_kwargs", ",", "\n", ")", "\n", "\n", "return", "train_dataset", ",", "valid_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.dataloader.filtering_out_valid": [[66, 79], ["str().split", "str"], "function", ["None"], ["", "def", "filtering_out_valid", "(", "input_dataset", ")", ":", "\n", "    ", "\"\"\"Filtering out validation tracks from input dataset.\n\n    Return:\n        input_dataset (w/o validation tracks)\n    \"\"\"", "\n", "input_dataset", ".", "tracks", "=", "[", "\n", "tmp", "\n", "for", "tmp", "in", "input_dataset", ".", "tracks", "\n", "if", "not", "(", "str", "(", "tmp", "[", "\"path\"", "]", ")", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "in", "validation_tracks", ")", "\n", "]", "\n", "\n", "return", "input_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.dataloader._augment_gain": [[96, 100], ["torch.rand"], "function", ["None"], ["", "", "def", "_augment_gain", "(", "audio", ",", "low", "=", "0.25", ",", "high", "=", "1.25", ")", ":", "\n", "    ", "\"\"\"Applies a random gain to each source between `low` and `high`\"\"\"", "\n", "gain", "=", "low", "+", "torch", ".", "rand", "(", "1", ")", "*", "(", "high", "-", "low", ")", "\n", "return", "audio", "*", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.dataloader._augment_channelswap": [[102, 108], ["torch.flip", "torch.FloatTensor().uniform_", "torch.FloatTensor"], "function", ["None"], ["", "def", "_augment_channelswap", "(", "audio", ")", ":", "\n", "    ", "\"\"\"Randomly swap channels of stereo sources\"\"\"", "\n", "if", "audio", ".", "shape", "[", "0", "]", "==", "2", "and", "torch", ".", "FloatTensor", "(", "1", ")", ".", "uniform_", "(", ")", "<", "0.5", ":", "\n", "        ", "return", "torch", ".", "flip", "(", "audio", ",", "[", "0", "]", ")", "\n", "\n", "", "return", "audio", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.resample_dataset.main": [[16, 24], ["glob.glob", "os.path.join", "soundfile.read", "scipy.signal.resample_poly", "soundfile.write"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["def", "main", "(", "out_dir", ",", "original_sr", ",", "target_sr", ",", "extension", ")", ":", "\n", "    ", "assert", "original_sr", ">=", "target_sr", ",", "\"Upsampling not supported\"", "\n", "wavs", "=", "glob", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"**/*.{}\"", ".", "format", "(", "extension", ")", ")", ",", "recursive", "=", "True", ")", "\n", "for", "wav", "in", "wavs", ":", "\n", "        ", "data", ",", "fs", "=", "sf", ".", "read", "(", "wav", ")", "\n", "assert", "fs", "==", "original_sr", "\n", "data", "=", "resample_poly", "(", "data", ",", "target_sr", ",", "fs", ")", "\n", "sf", ".", "write", "(", "wav", ",", "data", ",", "samplerate", "=", "target_sr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.__init__": [[41, 91], ["torch.utils.data.Dataset.__init__", "augmented_wham.AugmentedWhamDataset.parse_wsj0", "asteroid.data.wham_dataset.WHAM_TASKS.keys", "ValueError", "RuntimeError", "int", "augmented_wham.AugmentedWhamDataset.parse_wham", "asteroid.data.wham_dataset.WHAM_TASKS.keys"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.parse_wsj0", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.parse_wham"], ["def", "__init__", "(", "\n", "self", ",", "\n", "wsj0train", ",", "\n", "task", ",", "\n", "noise_dir", "=", "None", ",", "\n", "json_dir", "=", "None", ",", "\n", "orig_percentage", "=", "0.0", ",", "\n", "sample_rate", "=", "8000", ",", "\n", "segment", "=", "4.0", ",", "\n", "nondefault_nsrc", "=", "None", ",", "\n", "global_db_range", "=", "(", "-", "45", ",", "0", ")", ",", "\n", "abs_stats", "=", "(", "-", "16.7", ",", "7", ")", ",", "\n", "rel_stats", "=", "(", "2.52", ",", "4", ")", ",", "\n", "noise_stats", "=", "(", "5.1", ",", "6.4", ")", ",", "\n", "speed_perturb", "=", "(", "0.95", ",", "1.05", ")", ",", "\n", ")", ":", "\n", "        ", "super", "(", "AugmentedWhamDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "task", "not", "in", "WHAM_TASKS", ".", "keys", "(", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Unexpected task {}, expected one of \"", "\"{}\"", ".", "format", "(", "task", ",", "WHAM_TASKS", ".", "keys", "(", ")", ")", "\n", ")", "\n", "# Task setting", "\n", "", "self", ".", "task", "=", "task", "\n", "if", "self", ".", "task", "in", "[", "\"sep_noisy\"", ",", "\"enh_single\"", "]", "and", "not", "noise_dir", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"noise directory must be specified if task is sep_noisy or enh_single\"", "\n", ")", "\n", "", "self", ".", "task_dict", "=", "WHAM_TASKS", "[", "task", "]", "\n", "self", ".", "orig_percentage", "=", "orig_percentage", "\n", "if", "json_dir", ":", "\n", "            ", "self", ".", "use_original", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "use_original", "=", "False", "\n", "", "self", ".", "sample_rate", "=", "sample_rate", "\n", "self", ".", "seg_len", "=", "None", "if", "segment", "is", "None", "else", "int", "(", "segment", "*", "sample_rate", ")", "\n", "\n", "self", ".", "global_db_range", "=", "global_db_range", "\n", "self", ".", "abs_stats", "=", "abs_stats", "\n", "self", ".", "rel_stats", "=", "rel_stats", "\n", "self", ".", "noise_stats", "=", "noise_stats", "\n", "self", ".", "speed_perturb", "=", "speed_perturb", "\n", "\n", "if", "not", "nondefault_nsrc", ":", "\n", "            ", "self", ".", "n_src", "=", "self", ".", "task_dict", "[", "\"default_nsrc\"", "]", "\n", "", "else", ":", "\n", "            ", "assert", "nondefault_nsrc", ">=", "self", ".", "task_dict", "[", "\"default_nsrc\"", "]", "\n", "self", ".", "n_src", "=", "nondefault_nsrc", "\n", "", "if", "json_dir", ":", "\n", "            ", "self", ".", "wham_mix", ",", "self", ".", "wham_sources", "=", "self", ".", "parse_wham", "(", "json_dir", ")", "\n", "", "self", ".", "hashtab_synth", "=", "self", ".", "parse_wsj0", "(", "wsj0train", ",", "noise_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.parse_wham": [[92, 126], ["os.path.join", "len", "range", "print", "os.path.join", "open", "json.load", "len", "sources_infos.append", "open", "sources_infos.append", "len", "json.load", "range", "len"], "methods", ["None"], ["", "def", "parse_wham", "(", "self", ",", "json_dir", ")", ":", "\n", "        ", "mix_json", "=", "os", ".", "path", ".", "join", "(", "json_dir", ",", "self", ".", "task_dict", "[", "\"mixture\"", "]", "+", "\".json\"", ")", "\n", "sources_json", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "json_dir", ",", "source", "+", "\".json\"", ")", "for", "source", "in", "self", ".", "task_dict", "[", "\"sources\"", "]", "\n", "]", "\n", "with", "open", "(", "mix_json", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "mix_infos", "=", "json", ".", "load", "(", "f", ")", "\n", "", "sources_infos", "=", "[", "]", "\n", "for", "src_json", "in", "sources_json", ":", "\n", "            ", "with", "open", "(", "src_json", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "sources_infos", ".", "append", "(", "json", ".", "load", "(", "f", ")", ")", "\n", "# Filter out short utterances only when segment is specified", "\n", "", "", "orig_len", "=", "len", "(", "mix_infos", ")", "\n", "drop_utt", ",", "drop_len", "=", "0", ",", "0", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "mix_infos", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "# Go backward", "\n", "            ", "if", "mix_infos", "[", "i", "]", "[", "1", "]", "<", "self", ".", "seg_len", ":", "\n", "                ", "drop_utt", "+=", "1", "\n", "drop_len", "+=", "mix_infos", "[", "i", "]", "[", "1", "]", "\n", "del", "mix_infos", "[", "i", "]", "\n", "for", "src_inf", "in", "sources_infos", ":", "\n", "                    ", "del", "src_inf", "[", "i", "]", "\n", "\n", "", "", "", "print", "(", "\n", "\"Drop {} utts({:.2f} h) from {} (shorter than {} samples)\"", ".", "format", "(", "\n", "drop_utt", ",", "drop_len", "/", "self", ".", "sample_rate", "/", "36000", ",", "orig_len", ",", "self", ".", "seg_len", "\n", ")", "\n", ")", "\n", "mix", "=", "mix_infos", "\n", "# Handle the case n_src > default_nsrc", "\n", "while", "len", "(", "sources_infos", ")", "<", "self", ".", "n_src", ":", "\n", "            ", "sources_infos", ".", "append", "(", "[", "None", "for", "_", "in", "range", "(", "len", "(", "mix", ")", ")", "]", ")", "\n", "", "sources", "=", "sources_infos", "\n", "return", "mix", ",", "sources", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.parse_wsj0": [[127, 192], ["glob.glob", "print", "print", "os.path.join", "glob.glob", "soundfile.SoundFile", "len", "print", "os.path.join", "len", "int", "utt.split", "examples_hashtab.keys", "examples_hashtab[].append", "len", "soundfile.SoundFile", "len", "examples_hashtab[].append", "numpy.ceil", "int", "len", "numpy.ceil"], "methods", ["None"], ["", "def", "parse_wsj0", "(", "self", ",", "wsj_train_dir", ",", "noise_dir", ")", ":", "\n", "\n", "# Load json files", "\n", "        ", "utterances", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "wsj_train_dir", ",", "\"**/*.wav\"", ")", ",", "recursive", "=", "True", ")", "\n", "noises", "=", "None", "\n", "if", "self", ".", "task", "in", "[", "\"sep_noisy\"", ",", "\"enh_single\"", ",", "\"enhance_single\"", ",", "\"enh_both\"", "]", ":", "\n", "            ", "noises", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "noise_dir", ",", "\"*.wav\"", ")", ")", "\n", "assert", "len", "(", "noises", ")", ">", "0", ",", "\"No noises parsed. Wrong path?\"", "\n", "\n", "# parse utterances according to speaker", "\n", "", "drop_utt", ",", "drop_len", "=", "0", ",", "0", "\n", "print", "(", "\"Parsing WSJ speakers\"", ")", "\n", "examples_hashtab", "=", "{", "}", "\n", "for", "utt", "in", "utterances", ":", "\n", "# exclude if too short", "\n", "            ", "meta", "=", "sf", ".", "SoundFile", "(", "utt", ")", "\n", "c_len", "=", "len", "(", "meta", ")", "\n", "assert", "meta", ".", "samplerate", "==", "self", ".", "sample_rate", "\n", "\n", "target_length", "=", "(", "\n", "int", "(", "np", ".", "ceil", "(", "self", ".", "speed_perturb", "[", "1", "]", "*", "self", ".", "seg_len", ")", ")", "\n", "if", "self", ".", "speed_perturb", "\n", "else", "self", ".", "seg_len", "\n", ")", "\n", "if", "c_len", "<", "target_length", ":", "# speed perturbation", "\n", "                ", "drop_utt", "+=", "1", "\n", "drop_len", "+=", "c_len", "\n", "continue", "\n", "", "speaker", "=", "utt", ".", "split", "(", "\"/\"", ")", "[", "-", "2", "]", "\n", "if", "speaker", "not", "in", "examples_hashtab", ".", "keys", "(", ")", ":", "\n", "                ", "examples_hashtab", "[", "speaker", "]", "=", "[", "(", "utt", ",", "c_len", ")", "]", "\n", "", "else", ":", "\n", "                ", "examples_hashtab", "[", "speaker", "]", ".", "append", "(", "(", "utt", ",", "c_len", ")", ")", "\n", "\n", "", "", "print", "(", "\n", "\"Drop {} utts({:.2f} h) from {} (shorter than {} samples)\"", ".", "format", "(", "\n", "drop_utt", ",", "drop_len", "/", "self", ".", "sample_rate", "/", "36000", ",", "len", "(", "utterances", ")", ",", "self", ".", "seg_len", "\n", ")", "\n", ")", "\n", "\n", "drop_utt", ",", "drop_len", "=", "0", ",", "0", "\n", "if", "noises", ":", "\n", "            ", "examples_hashtab", "[", "\"noise\"", "]", "=", "[", "]", "\n", "for", "noise", "in", "noises", ":", "\n", "                ", "meta", "=", "sf", ".", "SoundFile", "(", "noise", ")", "\n", "c_len", "=", "len", "(", "meta", ")", "\n", "assert", "meta", ".", "samplerate", "==", "self", ".", "sample_rate", "\n", "target_length", "=", "(", "\n", "int", "(", "np", ".", "ceil", "(", "self", ".", "speed_perturb", "[", "1", "]", "*", "self", ".", "seg_len", ")", ")", "\n", "if", "self", ".", "speed_perturb", "\n", "else", "self", ".", "seg_len", "\n", ")", "\n", "if", "c_len", "<", "target_length", ":", "# speed perturbation", "\n", "                    ", "drop_utt", "+=", "1", "\n", "drop_len", "+=", "c_len", "\n", "continue", "\n", "", "examples_hashtab", "[", "\"noise\"", "]", ".", "append", "(", "(", "noise", ",", "c_len", ")", ")", "\n", "\n", "", "print", "(", "\n", "\"Drop {} noises({:.2f} h) from {} (shorter than {} samples)\"", ".", "format", "(", "\n", "drop_utt", ",", "drop_len", "/", "self", ".", "sample_rate", "/", "36000", ",", "len", "(", "noises", ")", ",", "self", ".", "seg_len", "\n", ")", "\n", ")", "\n", "\n", "", "return", "examples_hashtab", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.__add__": [[193, 195], ["None"], "methods", ["None"], ["", "def", "__add__", "(", "self", ",", "wham", ")", ":", "\n", "        ", "raise", "NotImplementedError", "# It will require different handling of other datasets, I suggest using dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.__len__": [[196, 204], ["len", "sum", "len", "augmented_wham.AugmentedWhamDataset.hashtab_synth.keys"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "use_original", ":", "\n", "            ", "return", "len", "(", "\n", "self", ".", "wham_mix", "\n", ")", "# same length as original wham (actually if orig_percentage = 1 the data is original wham)", "\n", "", "else", ":", "\n", "            ", "return", "sum", "(", "\n", "[", "len", "(", "self", ".", "hashtab_synth", "[", "x", "]", ")", "for", "x", "in", "self", ".", "hashtab_synth", ".", "keys", "(", ")", "]", "\n", ")", "# we account only the wsj0 length", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.random_data_augmentation": [[206, 216], ["pysndfx.AudioEffectsChain().custom.", "pysndfx.AudioEffectsChain().speed().custom", "pysndfx.AudioEffectsChain().custom", "pysndfx.AudioEffectsChain().speed", "pysndfx.AudioEffectsChain", "pysndfx.AudioEffectsChain"], "methods", ["None"], ["", "", "def", "random_data_augmentation", "(", "self", ",", "signal", ",", "c_gain", ",", "speed", ")", ":", "\n", "        ", "if", "self", ".", "speed_perturb", ":", "\n", "            ", "fx", "=", "(", "\n", "AudioEffectsChain", "(", ")", ".", "speed", "(", "speed", ")", ".", "custom", "(", "\"norm {}\"", ".", "format", "(", "c_gain", ")", ")", "\n", ")", "# speed perturb and then apply gain", "\n", "", "else", ":", "\n", "            ", "fx", "=", "AudioEffectsChain", "(", ")", ".", "custom", "(", "\"norm {}\"", ".", "format", "(", "c_gain", ")", ")", "\n", "", "signal", "=", "fx", "(", "signal", ")", "\n", "\n", "return", "signal", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.get_random_subsegment": [[217, 230], ["soundfile.read", "numpy.random.randint", "len", "random.randint"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "@", "staticmethod", "\n", "def", "get_random_subsegment", "(", "array", ",", "desired_len", ",", "tot_length", ")", ":", "\n", "\n", "        ", "offset", "=", "0", "\n", "if", "desired_len", "<", "tot_length", ":", "\n", "            ", "offset", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "tot_length", "-", "desired_len", ")", "\n", "\n", "", "out", ",", "_", "=", "sf", ".", "read", "(", "array", ",", "start", "=", "offset", ",", "stop", "=", "offset", "+", "desired_len", ",", "dtype", "=", "\"float32\"", ")", "\n", "\n", "if", "len", "(", "out", ".", "shape", ")", ">", "1", ":", "\n", "            ", "out", "=", "out", "[", ":", ",", "random", ".", "randint", "(", "0", ",", "1", ")", "]", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.__getitem__": [[231, 315], ["numpy.random.choice", "enumerate", "numpy.sum", "numpy.max", "numpy.stack", "random.choice", "augmented_wham.AugmentedWhamDataset.get_random_subsegment", "augmented_wham.AugmentedWhamDataset.random_data_augmentation", "torch.from_numpy.append", "random.choice", "augmented_wham.AugmentedWhamDataset.get_random_subsegment", "numpy.clip", "augmented_wham.AugmentedWhamDataset.random_data_augmentation", "torch.from_numpy.append", "numpy.stack", "numpy.abs", "torch.from_numpy().float", "torch.from_numpy().float", "random.random", "soundfile.read", "torch.as_tensor", "torch.from_numpy", "random.uniform", "int", "numpy.clip", "numpy.clip", "random.uniform", "int", "numpy.random.randint", "source_arrays.append", "numpy.vstack", "torch.from_numpy", "augmented_wham.AugmentedWhamDataset.hashtab_synth.keys", "numpy.ceil", "random.normalvariate", "numpy.ceil", "random.normalvariate", "torch.from_numpy", "torch.from_numpy", "len", "numpy.zeros", "soundfile.read", "random.normalvariate"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.get_random_subsegment", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.random_data_augmentation", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.get_random_subsegment", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.augmented_wham.AugmentedWhamDataset.random_data_augmentation", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.as_tensor", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Gets a mixture/sources pair.\n        Returns:\n            mixture, vstack([source_arrays])\n        \"\"\"", "\n", "if", "self", ".", "use_original", "==", "True", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", "<=", "self", ".", "orig_percentage", ":", "# if true sample wham example", "\n", "                ", "mix_file", ",", "mixlen", "=", "self", ".", "wham_mix", "[", "idx", "]", "\n", "\n", "offset", "=", "0", "\n", "if", "self", ".", "seg_len", "<", "mixlen", ":", "\n", "                    ", "offset", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "mixlen", "-", "self", ".", "seg_len", ")", "\n", "\n", "", "x", ",", "_", "=", "sf", ".", "read", "(", "mix_file", ",", "start", "=", "offset", ",", "stop", "=", "offset", "+", "self", ".", "seg_len", ",", "dtype", "=", "\"float32\"", ")", "\n", "\n", "seg_len", "=", "torch", ".", "as_tensor", "(", "[", "len", "(", "x", ")", "]", ")", "\n", "# Load sources", "\n", "source_arrays", "=", "[", "]", "\n", "for", "src", "in", "self", ".", "wham_sources", ":", "\n", "                    ", "if", "src", "[", "idx", "]", "is", "None", ":", "\n", "# Target is filled with zeros if n_src > default_nsrc", "\n", "                        ", "s", "=", "np", ".", "zeros", "(", "(", "seg_len", ",", ")", ")", "\n", "", "else", ":", "\n", "                        ", "s", ",", "_", "=", "sf", ".", "read", "(", "\n", "src", "[", "idx", "]", "[", "0", "]", ",", "start", "=", "offset", ",", "stop", "=", "offset", "+", "self", ".", "seg_len", ",", "dtype", "=", "\"float32\"", "\n", ")", "\n", "", "source_arrays", ".", "append", "(", "s", ")", "\n", "", "sources", "=", "torch", ".", "from_numpy", "(", "np", ".", "vstack", "(", "source_arrays", ")", ")", "\n", "return", "torch", ".", "from_numpy", "(", "x", ")", ",", "sources", "\n", "\n", "# else return augmented data: Sample k speakers randomly", "\n", "", "", "c_speakers", "=", "np", ".", "random", ".", "choice", "(", "\n", "[", "x", "for", "x", "in", "self", ".", "hashtab_synth", ".", "keys", "(", ")", "if", "x", "!=", "\"noise\"", "]", ",", "self", ".", "n_src", "\n", ")", "\n", "\n", "sources", "=", "[", "]", "\n", "first_lvl", "=", "None", "\n", "floor", ",", "ceil", "=", "self", ".", "global_db_range", "\n", "for", "i", ",", "spk", "in", "enumerate", "(", "c_speakers", ")", ":", "\n", "            ", "tmp", ",", "tmp_spk_len", "=", "random", ".", "choice", "(", "self", ".", "hashtab_synth", "[", "c_speakers", "[", "i", "]", "]", ")", "\n", "# account for sample reduction in speed perturb", "\n", "if", "self", ".", "speed_perturb", ":", "\n", "                ", "c_speed", "=", "random", ".", "uniform", "(", "*", "self", ".", "speed_perturb", ")", "\n", "target_len", "=", "int", "(", "np", ".", "ceil", "(", "c_speed", "*", "self", ".", "seg_len", ")", ")", "\n", "", "else", ":", "\n", "                ", "target_len", "=", "self", ".", "seg_len", "\n", "", "tmp", "=", "self", ".", "get_random_subsegment", "(", "tmp", ",", "target_len", ",", "tmp_spk_len", ")", "\n", "if", "i", "==", "0", ":", "# we model the signal level distributions with gaussians", "\n", "                ", "c_lvl", "=", "np", ".", "clip", "(", "random", ".", "normalvariate", "(", "*", "self", ".", "abs_stats", ")", ",", "floor", ",", "ceil", ")", "\n", "first_lvl", "=", "c_lvl", "\n", "", "else", ":", "\n", "                ", "c_lvl", "=", "np", ".", "clip", "(", "first_lvl", "-", "random", ".", "normalvariate", "(", "*", "self", ".", "rel_stats", ")", ",", "floor", ",", "ceil", ")", "\n", "", "tmp", "=", "self", ".", "random_data_augmentation", "(", "tmp", ",", "c_lvl", ",", "c_speed", ")", "\n", "tmp", "=", "tmp", "[", ":", "self", ".", "seg_len", "]", "\n", "sources", ".", "append", "(", "tmp", ")", "\n", "\n", "", "if", "self", ".", "task", "in", "[", "\"sep_noisy\"", ",", "\"enh_single\"", ",", "\"enh_both\"", ",", "\"enhance_single\"", "]", ":", "\n", "# add also noise", "\n", "            ", "tmp", ",", "tmp_spk_len", "=", "random", ".", "choice", "(", "self", ".", "hashtab_synth", "[", "\"noise\"", "]", ")", "\n", "if", "self", ".", "speed_perturb", ":", "\n", "                ", "c_speed", "=", "random", ".", "uniform", "(", "*", "self", ".", "speed_perturb", ")", "\n", "target_len", "=", "int", "(", "np", ".", "ceil", "(", "c_speed", "*", "self", ".", "seg_len", ")", ")", "\n", "", "else", ":", "\n", "                ", "target_len", "=", "self", ".", "seg_len", "\n", "", "tmp", "=", "self", ".", "get_random_subsegment", "(", "tmp", ",", "target_len", ",", "tmp_spk_len", ")", "\n", "c_lvl", "=", "np", ".", "clip", "(", "first_lvl", "-", "random", ".", "normalvariate", "(", "*", "self", ".", "noise_stats", ")", ",", "floor", ",", "ceil", ")", "\n", "tmp", "=", "self", ".", "random_data_augmentation", "(", "tmp", ",", "c_lvl", ",", "c_speed", ")", "\n", "tmp", "=", "tmp", "[", ":", "self", ".", "seg_len", "]", "\n", "sources", ".", "append", "(", "tmp", ")", "\n", "\n", "", "mix", "=", "np", ".", "sum", "(", "np", ".", "stack", "(", "sources", ")", ",", "0", ")", "\n", "\n", "if", "self", ".", "task", "in", "[", "\"sep_noisy\"", ",", "\"enh_single\"", ",", "\"enhance_single\"", ",", "\"enh_both\"", "]", ":", "\n", "            ", "sources", "=", "sources", "[", ":", "-", "1", "]", "# discard noise", "\n", "\n", "# check for clipping", "\n", "", "absmax", "=", "np", ".", "max", "(", "np", ".", "abs", "(", "mix", ")", ")", "\n", "if", "absmax", ">", "1", ":", "\n", "            ", "mix", "=", "mix", "/", "absmax", "\n", "sources", "=", "[", "x", "/", "absmax", "for", "x", "in", "sources", "]", "\n", "\n", "", "sources", "=", "np", ".", "stack", "(", "sources", ")", "\n", "\n", "return", "torch", ".", "from_numpy", "(", "mix", ")", ".", "float", "(", ")", ",", "torch", ".", "from_numpy", "(", "sources", ")", ".", "float", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_wham.preprocess_one_dir": [[7, 23], ["os.path.abspath", "os.listdir", "os.listdir.sort", "os.path.join", "soundfile.SoundFile", "file_infos.append", "os.path.exists", "os.makedirs", "open", "json.dump", "wav_file.endswith", "os.path.join", "len"], "function", ["None"], ["def", "preprocess_one_dir", "(", "in_dir", ",", "out_dir", ",", "out_filename", ")", ":", "\n", "    ", "\"\"\"Create .json file for one condition.\"\"\"", "\n", "file_infos", "=", "[", "]", "\n", "in_dir", "=", "os", ".", "path", ".", "abspath", "(", "in_dir", ")", "\n", "wav_list", "=", "os", ".", "listdir", "(", "in_dir", ")", "\n", "wav_list", ".", "sort", "(", ")", "\n", "for", "wav_file", "in", "wav_list", ":", "\n", "        ", "if", "not", "wav_file", ".", "endswith", "(", "\".wav\"", ")", ":", "\n", "            ", "continue", "\n", "", "wav_path", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "wav_file", ")", "\n", "samples", "=", "sf", ".", "SoundFile", "(", "wav_path", ")", "\n", "file_infos", ".", "append", "(", "(", "wav_path", ",", "len", "(", "samples", ")", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "out_filename", "+", "\".json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "file_infos", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_wham.preprocess": [[25, 34], ["preprocess_wham.preprocess_one_dir", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.local.preprocess_wham.preprocess_one_dir"], ["", "", "def", "preprocess", "(", "inp_args", ")", ":", "\n", "    ", "\"\"\"Create .json files for all conditions.\"\"\"", "\n", "speaker_list", "=", "[", "\"mix_both\"", ",", "\"mix_clean\"", ",", "\"mix_single\"", ",", "\"s1\"", ",", "\"s2\"", ",", "\"noise\"", "]", "\n", "for", "data_type", "in", "[", "\"tr\"", ",", "\"cv\"", ",", "\"tt\"", "]", ":", "\n", "        ", "for", "spk", "in", "speaker_list", ":", "\n", "            ", "preprocess_one_dir", "(", "\n", "os", ".", "path", ".", "join", "(", "inp_args", ".", "in_dir", ",", "data_type", ",", "spk", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "inp_args", ".", "out_dir", ",", "data_type", ")", ",", "\n", "spk", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.create_local_metadata.main": [[13, 16], ["create_local_metadata.create_local_metadata"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.local.create_local_metadata.create_local_metadata"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "librimix_dir", "=", "args", ".", "librimix_dir", "\n", "create_local_metadata", "(", "librimix_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.create_local_metadata.create_local_metadata": [[18, 30], ["glob.glob", "f.endswith", "os.path.join().replace", "os.makedirs", "shutil.copy", "os.path.join", "os.listdir", "f.startswith", "md_file.split", "os.path.join", "os.path.join", "os.path.relpath"], "function", ["None"], ["", "def", "create_local_metadata", "(", "librimix_dir", ")", ":", "\n", "\n", "    ", "md_dirs", "=", "[", "f", "for", "f", "in", "glob", "(", "os", ".", "path", ".", "join", "(", "librimix_dir", ",", "\"*/*/*\"", ")", ")", "if", "f", ".", "endswith", "(", "\"metadata\"", ")", "]", "\n", "for", "md_dir", "in", "md_dirs", ":", "\n", "        ", "md_files", "=", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "md_dir", ")", "if", "f", ".", "startswith", "(", "\"mix\"", ")", "]", "\n", "for", "md_file", "in", "md_files", ":", "\n", "            ", "subset", "=", "md_file", ".", "split", "(", "\"_\"", ")", "[", "1", "]", "\n", "local_path", "=", "os", ".", "path", ".", "join", "(", "\n", "\"data\"", ",", "os", ".", "path", ".", "relpath", "(", "md_dir", ",", "librimix_dir", ")", ",", "subset", "\n", ")", ".", "replace", "(", "\"/metadata\"", ",", "\"\"", ")", "\n", "os", ".", "makedirs", "(", "local_path", ",", "exist_ok", "=", "True", ")", "\n", "shutil", ".", "copy", "(", "os", ".", "path", ".", "join", "(", "md_dir", ",", "md_file", ")", ",", "local_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.eval.main": [[35, 109], ["model.load_best_model", "asteroid.data.Wsj0mixDataset", "asteroid.losses.PITLossWrapper", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "model.load_best_model.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "asteroid.losses.PITLossWrapper.", "mix[].cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "open", "json.dump", "model.load_best_model.parameters", "len", "torch.no_grad", "len", "model.load_best_model.dc_head_separate", "model.load_best_model.separate", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "os.path.join", "soundfile.write", "soundfile.write", "open", "json.dump", "mix[].cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.load_best_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.model.Model.dc_head_separate", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate"], ["def", "main", "(", "conf", ")", ":", "\n", "    ", "model", "=", "load_best_model", "(", "conf", "[", "\"train_conf\"", "]", ",", "conf", "[", "\"exp_dir\"", "]", ")", "\n", "# Handle device placement", "\n", "if", "conf", "[", "\"use_gpu\"", "]", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "", "model_device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "test_set", "=", "KinectWsjMixDataset", "(", "conf", "[", "\"test_dir\"", "]", ",", "n_src", "=", "conf", "[", "\"n_src\"", "]", ",", "segment", "=", "None", ")", "\n", "# Used to reorder sources only", "\n", "loss_func", "=", "PITLossWrapper", "(", "pairwise_neg_sisdr", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "\n", "# Randomly choose the indexes of sentences to save.", "\n", "ex_save_dir", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"examples/\"", ")", "\n", "if", "conf", "[", "\"n_save_ex\"", "]", "==", "-", "1", ":", "\n", "        ", "conf", "[", "\"n_save_ex\"", "]", "=", "len", "(", "test_set", ")", "\n", "", "save_idx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "test_set", ")", ")", ",", "conf", "[", "\"n_save_ex\"", "]", ")", "\n", "series_list", "=", "[", "]", "\n", "torch", ".", "no_grad", "(", ")", ".", "__enter__", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "test_set", ")", ")", ")", ":", "\n", "# Forward the network on the mixture.", "\n", "        ", "mix", ",", "sources", ",", "noises", "=", "tensors_to_device", "(", "test_set", "[", "idx", "]", ",", "device", "=", "model_device", ")", "\n", "mix", "=", "mix", "[", "...", ",", "0", "]", "\n", "sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "utt_metrics", "=", "get_metrics", "(", "\n", "mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.train.ChimeraSystem.__init__": [[84, 87], ["asteroid.engine.system.System.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.train.ChimeraSystem.common_step": [[88, 99], ["train.ChimeraSystem.unpack_data", "train.ChimeraSystem.", "asteroid_filterbanks.transforms.mag", "train.ChimeraSystem.loss_func", "train.ChimeraSystem.model.encoder", "inputs.unsqueeze", "asteroid_filterbanks.transforms.mag.unsqueeze", "asteroid_filterbanks.transforms.mag.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.train.ChimeraSystem.unpack_data"], ["limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.train.ChimeraSystem.training_step": [[100, 106], ["train.ChimeraSystem.common_step", "dict"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.common_step"], ["from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.train.ChimeraSystem.validation_step": [[107, 113], ["train.ChimeraSystem.common_step", "dict"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.common_step"], ["        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.train.ChimeraSystem.validation_end": [[114, 126], ["torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "dict", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.train.ChimeraSystem.unpack_data": [[128, 136], ["asteroid_filterbanks.transforms.mag", "real_mask.argmax", "train.ChimeraSystem.model.encoder", "asteroid_filterbanks.transforms.mag.sum"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.train.ChimeraLoss.__init__": [[146, 153], ["torch.nn.Module.__init__", "asteroid.losses.PITLossWrapper"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.train.ChimeraLoss.forward": [[154, 187], ["asteroid.losses.deep_clustering_loss", "train.ChimeraLoss.src_mse", "dict", "ValueError", "asteroid.dsp.vad.ebased_vad", "asteroid.losses.deep_clustering_loss.mean", "asteroid.losses.deep_clustering_loss.mean"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.cluster.deep_clustering_loss", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.vad.ebased_vad"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.train.main": [[23, 81], ["asteroid.data.wsj0_mix.make_dataloaders", "conf[].update", "model.make_model_and_optimizer", "os.makedirs", "os.path.join", "train.ChimeraLoss", "train.ChimeraSystem", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.save", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "ChimeraSystem.model.state_dict", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.wsj0_mix.make_dataloaders", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.state_dict"], ["def", "main", "(", "conf", ")", ":", "\n", "    ", "total_set", "=", "DNSDataset", "(", "conf", "[", "\"data\"", "]", "[", "\"json_dir\"", "]", ")", "\n", "train_len", "=", "int", "(", "len", "(", "total_set", ")", "*", "(", "1", "-", "conf", "[", "\"data\"", "]", "[", "\"val_prop\"", "]", ")", ")", "\n", "val_len", "=", "len", "(", "total_set", ")", "-", "train_len", "\n", "train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.model.Chimera.__init__": [[33, 69], ["torch.nn.Module.__init__", "asteroid.masknn.recurrent.SingleRNN", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["        ", "inp_size", "=", "output_size", "=", "int", "(", "stft", ".", "n_feats_out", "/", "2", ")", "\n", "# Add these fields to the mask model dict", "\n", "", "conf", "[", "\"masknet\"", "]", ".", "update", "(", "dict", "(", "input_size", "=", "inp_size", ",", "output_size", "=", "output_size", ")", ")", "\n", "masker", "=", "SimpleModel", "(", "**", "conf", "[", "\"masknet\"", "]", ")", "\n", "# Make the complete model", "\n", "model", "=", "Model", "(", "stft", ",", "masker", ",", "istft", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "# Define optimizer of this model", "\n", "optimizer", "=", "make_optimizer", "(", "model", ".", "parameters", "(", ")", ",", "**", "conf", "[", "\"optim\"", "]", ")", "\n", "return", "model", ",", "optimizer", "\n", "\n", "\n", "", "class", "Model", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Speech enhancement model.\n\n    Args:\n        encoder (~.Encoder): instance of a complex filterbank encoder\n            `Encoder(STFTBFB(**))`.\n        masker (nn.Module): Mask estimator network.\n        decoder (~.Decoder): instance of a complex filterbank decoder\n            `Decoder(STFTBFB(**))`.\n        is_complex (bool): If the network works on the complex domain.\n\n    If `is_complex` is `True`, the input to the network are complex features,\n    the network estimates a complex mask and returns a complex speech estimate.\n    Else, the input is the magnitude, the network estimates a magnitude mask\n    and the returns a **complex** speech estimate.\n    The loss function needs to be adapted to complex representations.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "encoder", ",", "masker", ",", "decoder", ",", "is_complex", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "masker", "=", "masker", "\n", "# Decoder is not used for training but eventually, we want to invert", "\n", "# the encoder. Might as well include it in the model.", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "is_complex", "=", "is_complex", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.model.Chimera.forward": [[70, 92], ["model.Chimera.rnn", "model.Chimera.dropout", "model.Chimera.embedding_layer", "model.Chimera.embedding_act", "proj.reshape.reshape.view().transpose", "proj.reshape.reshape.reshape", "torch.norm", "model.Chimera.mask_layer().view", "model.Chimera.permute", "model.Chimera.mask_act", "torch.log", "torch.log.permute", "proj.reshape.reshape.view", "model.Chimera.mask_layer"], "methods", ["None"], ["\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "len", "(", "x", ".", "shape", ")", "==", "2", ":", "\n", "            ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "# Compute STFT", "\n", "", "tf_rep", "=", "self", ".", "encoder", "(", "x", ")", "\n", "# Estimate TF mask from STFT features : cat([re, im, mag])", "\n", "if", "self", ".", "is_complex", ":", "\n", "            ", "to_masker", "=", "magreim", "(", "tf_rep", ")", "\n", "", "else", ":", "\n", "            ", "to_masker", "=", "mag", "(", "tf_rep", ")", "\n", "# LSTM masker expects a feature dimension last (not like 1D conv)", "\n", "", "est_masks", "=", "self", ".", "masker", "(", "to_masker", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# Apply TF mask", "\n", "if", "self", ".", "is_complex", ":", "\n", "            ", "masked_tf_rep", "=", "apply_real_mask", "(", "tf_rep", ",", "est_masks", ")", "\n", "", "else", ":", "\n", "            ", "masked_tf_rep", "=", "apply_mag_mask", "(", "tf_rep", ",", "est_masks", ")", "\n", "", "return", "masked_tf_rep", "\n", "\n", "", "def", "denoise", "(", "self", ",", "x", ")", ":", "\n", "        ", "estimate_stft", "=", "self", "(", "x", ")", "\n", "wav", "=", "self", ".", "decoder", "(", "estimate_stft", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.model.Model.__init__": [[95, 100], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["\n", "", "", "class", "SimpleModel", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.model.Model.forward": [[101, 107], ["model.Model.encoder", "model.Model.masker", "len", "x.unsqueeze.unsqueeze.unsqueeze", "asteroid_filterbanks.transforms.mag"], "methods", ["None"], ["\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.model.Model.separate": [[108, 118], ["model.Model.encoder", "model.Model.masker", "asteroid_filterbanks.transforms.apply_mag_mask", "asteroid.torch_utils.pad_x_to_y", "dict", "len", "x.unsqueeze.unsqueeze.unsqueeze", "asteroid_filterbanks.transforms.mag", "model.Model.unsqueeze", "model.Model.decoder"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.pad_x_to_y"], ["\n", "def", "__init__", "(", "\n", "self", ",", "input_size", ",", "hidden_size", ",", "output_size", "=", "None", ",", "rnn_type", "=", "\"gru\"", ",", "n_layers", "=", "3", ",", "dropout", "=", "0.3", "\n", ")", ":", "\n", "        ", "super", "(", "SimpleModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "output_size", "=", "input_size", "if", "output_size", "is", "None", "else", "output_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "in_proj_layer", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "residual_rec", "=", "StackedResidualRNN", "(", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.model.Model.dc_head_separate": [[119, 144], ["sklearn.cluster.KMeans", "model.Model.encoder", "asteroid_filterbanks.transforms.mag", "model.Model.masker", "asteroid.dsp.vad.ebased_vad", "sklearn.cluster.KMeans.fit_predict", "range", "torch.stack", "asteroid_filterbanks.transforms.apply_mag_mask", "asteroid.utils.torch_utils.pad_x_to_y", "dict", "len", "x.unsqueeze.unsqueeze.unsqueeze", "active_proj.cpu().data.numpy", "torch.from_numpy().to", "est_mask_list.append", "model.Model.decoder", "asteroid.dsp.vad.ebased_vad.view", "mask.float", "torch.from_numpy", "active_proj.cpu"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.vad.ebased_vad", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.pad_x_to_y"], ["rnn_type", ",", "hidden_size", ",", "n_layers", "=", "n_layers", ",", "dropout", "=", "dropout", "\n", ")", "\n", "self", ".", "out_proj_layer", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "output_size", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Mask estimator's forward pass. Expects [batch, time, input_size]\"\"\"", "\n", "# Non negative features from input", "\n", "out_rec", "=", "self", ".", "residual_rec", "(", "torch", ".", "relu", "(", "self", ".", "in_proj_layer", "(", "x", ")", ")", ")", "\n", "# Activation is relu on the mask (better gradients allegedly)", "\n", "return", "torch", ".", "relu", "(", "self", ".", "out_proj_layer", "(", "out_rec", ")", ")", "\n", "\n", "\n", "", "", "class", "SimpleSystem", "(", "System", ")", ":", "\n", "    ", "def", "common_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "mixture", ",", "speech", ",", "noise", "=", "batch", "\n", "estimate", "=", "self", "(", "mixture", ".", "unsqueeze", "(", "1", ")", ")", "\n", "speech_stft", "=", "self", ".", "model", ".", "encoder", "(", "speech", ".", "unsqueeze", "(", "1", ")", ")", "\n", "# The loss function can be something like", "\n", "# loss_func = partial(distance, is_complex=some_bool)", "\n", "loss", "=", "self", ".", "loss_func", "(", "estimate", ",", "speech_stft", ")", "\n", "return", "loss", "\n", "\n", "\n", "", "", "def", "distance", "(", "estimate", ",", "target", ",", "is_complex", "=", "True", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.model.make_model_and_optimizer": [[16, 30], ["asteroid_filterbanks.make_enc_dec", "model.Chimera", "model.Model", "asteroid.engine.optimizers.make_optimizer", "Model.parameters"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer"], ["\n", "def", "make_model_and_optimizer", "(", "conf", ")", ":", "\n", "    ", "\"\"\"Function to define the model and optimizer for a config dictionary.\n    Args:\n        conf: Dictionary containing the output of hierachical argparse.\n    Returns:\n        model, optimizer.\n    The main goal of this function is to make reloading for resuming\n    and evaluation very simple.\n    \"\"\"", "\n", "# Define building blocks for local model", "\n", "stft", ",", "istft", "=", "make_enc_dec", "(", "\"stft\"", ",", "**", "conf", "[", "\"filterbank\"", "]", ")", "\n", "# Because we concatenate (re, im, mag) as input and compute a complex mask.", "\n", "if", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ":", "\n", "        ", "inp_size", "=", "int", "(", "stft", ".", "n_feats_out", "*", "3", "/", "2", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DeepClustering.model.load_best_model": [[146, 180], ["model.make_model_and_optimizer", "torch.load", "asteroid.torch_utils.load_state_dict_in", "torch_utils.load_state_dict_in.eval", "min", "open", "json.load", "os.listdir", "os.listdir.sort", "os.path.join", "os.path.join", "os.path.join", "int", "ckpt.find", "filter", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.load_state_dict_in"], ["\n", "if", "is_complex", ":", "\n", "# Take the difference in the complex plane and compute the squared norm", "\n", "# of the remaining vector.", "\n", "        ", "return", "mag", "(", "estimate", "-", "target", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "# Compute the mean difference between magnitudes.", "\n", "        ", "return", "(", "mag", "(", "estimate", ")", "-", "mag", "(", "target", ")", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "\n", "\n", "", "", "def", "load_best_model", "(", "train_conf", ",", "exp_dir", ")", ":", "\n", "    ", "\"\"\"Load best model after training.\n\n    Args:\n        train_conf (dict): dictionary as expected by `make_model_and_optimizer`\n        exp_dir(str): Experiment directory. Expects to find\n            `'best_k_models.json'` there.\n\n    Returns:\n        nn.Module the best pretrained model according to the val_loss.\n    \"\"\"", "\n", "# Create the model from recipe-local function", "\n", "model", ",", "_", "=", "make_model_and_optimizer", "(", "train_conf", ")", "\n", "# Last best model summary", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "best_k", "=", "json", ".", "load", "(", "f", ")", "\n", "", "best_model_path", "=", "min", "(", "best_k", ",", "key", "=", "best_k", ".", "get", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TasNet.eval.main": [[44, 118], ["model.load_best_model", "asteroid.data.WhamRDataset", "asteroid.losses.PITLossWrapper", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "model.load_best_model.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "model.load_best_model.", "asteroid.losses.PITLossWrapper.", "mix[].cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "open", "json.dump", "model.load_best_model.parameters", "len", "torch.no_grad", "len", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "os.path.join", "soundfile.write", "soundfile.write", "open", "json.dump", "mix[].cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.load_best_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics"], ["\n", "# Randomly choose the indexes of sentences to save.", "\n", "ex_save_dir", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"examples/\"", ")", "\n", "if", "conf", "[", "\"n_save_ex\"", "]", "==", "-", "1", ":", "\n", "        ", "conf", "[", "\"n_save_ex\"", "]", "=", "len", "(", "test_set", ")", "\n", "", "save_idx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "test_set", ")", ")", ",", "conf", "[", "\"n_save_ex\"", "]", ")", "\n", "series_list", "=", "[", "]", "\n", "torch", ".", "no_grad", "(", ")", ".", "__enter__", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "test_set", ")", ")", ")", ":", "\n", "# Forward the network on the mixture.", "\n", "        ", "mix", ",", "sources", ",", "noises", "=", "tensors_to_device", "(", "test_set", "[", "idx", "]", ",", "device", "=", "model_device", ")", "\n", "mix", "=", "mix", "[", "...", ",", "0", "]", "\n", "sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "utt_metrics", "=", "get_metrics", "(", "\n", "mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TasNet.train.main": [[29, 112], ["asteroid.data.WhamRDataset", "asteroid.data.WhamRDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "conf[].update", "model.make_model_and_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "asteroid.engine.system.System", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer"], ["train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TasNet.model.TasNet.__init__": [[27, 49], ["torch.nn.Module.__init__", "asteroid_filterbanks.Encoder", "asteroid_filterbanks.Encoder", "asteroid_filterbanks.Decoder", "asteroid.masknn.norms.GlobLN", "torch.nn.Sequential", "asteroid_filterbanks.FreeFB", "asteroid_filterbanks.FreeFB", "asteroid_filterbanks.FreeFB", "asteroid.masknn.recurrent.SingleRNN", "torch.nn.Linear", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["stft", ",", "istft", "=", "make_enc_dec", "(", "\"stft\"", ",", "**", "conf", "[", "\"filterbank\"", "]", ")", "\n", "# Because we concatenate (re, im, mag) as input and compute a complex mask.", "\n", "if", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ":", "\n", "        ", "inp_size", "=", "int", "(", "stft", ".", "n_feats_out", "*", "3", "/", "2", ")", "\n", "output_size", "=", "stft", ".", "n_feats_out", "\n", "", "else", ":", "\n", "        ", "inp_size", "=", "output_size", "=", "int", "(", "stft", ".", "n_feats_out", "/", "2", ")", "\n", "# Add these fields to the mask model dict", "\n", "", "conf", "[", "\"masknet\"", "]", ".", "update", "(", "dict", "(", "input_size", "=", "inp_size", ",", "output_size", "=", "output_size", ")", ")", "\n", "masker", "=", "SimpleModel", "(", "**", "conf", "[", "\"masknet\"", "]", ")", "\n", "# Make the complete model", "\n", "model", "=", "Model", "(", "stft", ",", "masker", ",", "istft", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "# Define optimizer of this model", "\n", "optimizer", "=", "make_optimizer", "(", "model", ".", "parameters", "(", ")", ",", "**", "conf", "[", "\"optim\"", "]", ")", "\n", "return", "model", ",", "optimizer", "\n", "\n", "\n", "", "class", "Model", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TasNet.model.TasNet.forward": [[51, 61], ["model.TasNet.encode", "model.TasNet.bn_layer", "model.TasNet.masker().transpose", "est_masks.view.view.view", "asteroid.torch_utils.pad_x_to_y", "len", "x.unsqueeze.unsqueeze.unsqueeze", "model.TasNet.unsqueeze", "model.TasNet.decoder", "model.TasNet.masker", "model.TasNet.transpose"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TasNet.model.TasNet.encode", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.pad_x_to_y"], ["\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TasNet.model.TasNet.encode": [[62, 66], ["torch.relu", "torch.sigmoid", "model.TasNet.encoder_relu", "model.TasNet.encoder_sig"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.sigmoid"], ["def", "__init__", "(", "self", ",", "encoder", ",", "masker", ",", "decoder", ",", "is_complex", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "masker", "=", "masker", "\n", "# Decoder is not used for training but eventually, we want to invert", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TasNet.model.make_model_and_optimizer": [[68, 81], ["model.TasNet", "asteroid.engine.optimizers.make_optimizer", "TasNet.parameters"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer"], ["self", ".", "decoder", "=", "decoder", "\n", "self", ".", "is_complex", "=", "is_complex", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "len", "(", "x", ".", "shape", ")", "==", "2", ":", "\n", "            ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "# Compute STFT", "\n", "", "tf_rep", "=", "self", ".", "encoder", "(", "x", ")", "\n", "# Estimate TF mask from STFT features : cat([re, im, mag])", "\n", "if", "self", ".", "is_complex", ":", "\n", "            ", "to_masker", "=", "magreim", "(", "tf_rep", ")", "\n", "", "else", ":", "\n", "            ", "to_masker", "=", "mag", "(", "tf_rep", ")", "\n", "# LSTM masker expects a feature dimension last (not like 1D conv)", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TasNet.model.load_best_model": [[83, 106], ["model.make_model_and_optimizer", "min", "torch.load", "asteroid.torch_utils.load_state_dict_in", "torch_utils.load_state_dict_in.eval", "open", "json.load", "os.path.join"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.load_state_dict_in"], ["# Apply TF mask", "\n", "if", "self", ".", "is_complex", ":", "\n", "            ", "masked_tf_rep", "=", "apply_real_mask", "(", "tf_rep", ",", "est_masks", ")", "\n", "", "else", ":", "\n", "            ", "masked_tf_rep", "=", "apply_mag_mask", "(", "tf_rep", ",", "est_masks", ")", "\n", "", "return", "masked_tf_rep", "\n", "\n", "", "def", "denoise", "(", "self", ",", "x", ")", ":", "\n", "        ", "estimate_stft", "=", "self", "(", "x", ")", "\n", "wav", "=", "self", ".", "decoder", "(", "estimate_stft", ")", "\n", "return", "torch_utils", ".", "pad_x_to_y", "(", "wav", ",", "x", ")", "\n", "\n", "\n", "", "", "class", "SimpleModel", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.metrics.PairwiseNegSDR_Loss.__init__": [[13, 20], ["torch.nn.modules.loss._Loss.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["\n", "ALL_METRICS", "=", "[", "\"si_sdr\"", ",", "\"sdr\"", ",", "\"sir\"", ",", "\"sar\"", ",", "\"stoi\"", ",", "\"pesq\"", "]", "\n", "\n", "\n", "def", "get_metrics", "(", "\n", "mix", ",", "\n", "clean", ",", "\n", "estimate", ",", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.metrics.PairwiseNegSDR_Loss.forward": [[21, 53], ["torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.unsqueeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.unsqueeze.repeat", "torch.unsqueeze.repeat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log10", "torch.log10", "torch.log10", "torch.log10"], "methods", ["None"], ["sample_rate", "=", "16000", ",", "\n", "metrics_list", "=", "\"all\"", ",", "\n", "average", "=", "True", ",", "\n", "compute_permutation", "=", "False", ",", "\n", "ignore_metrics_errors", "=", "False", ",", "\n", "filename", "=", "None", ",", "\n", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.metrics.Penalized_PIT_Wrapper.__init__": [[63, 69], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.metrics.Penalized_PIT_Wrapper.forward": [[70, 87], ["est_targets.size", "est_targets.size", "metrics.Penalized_PIT_Wrapper.loss_func().squeeze", "metrics.Penalized_PIT_Wrapper.transpose", "pwl[].mean", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "max", "metrics.Penalized_PIT_Wrapper.loss_func", "scipy.optimize.linear_sum_assignment", "est_targets.unsqueeze", "targets.unsqueeze", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "metrics.Penalized_PIT_Wrapper.transpose.detach().cpu", "min", "abs", "metrics.Penalized_PIT_Wrapper.transpose.detach"], "methods", ["None"], ["\n", "if", "metrics_list", "==", "\"all\"", ":", "\n", "        ", "metrics_list", "=", "ALL_METRICS", "\n", "", "if", "isinstance", "(", "metrics_list", ",", "str", ")", ":", "\n", "        ", "metrics_list", "=", "[", "metrics_list", "]", "\n", "# For each utterance, we get a dictionary with the input and output metrics", "\n", "", "input_metrics", "=", "InputMetrics", "(", "\n", "observation", "=", "mix", ",", "speech_source", "=", "clean", ",", "enable_si_sdr", "=", "True", ",", "sample_rate", "=", "sample_rate", "\n", ")", "\n", "output_metrics", "=", "OutputMetrics", "(", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.eval.main": [[51, 132], ["os.path.join", "wsj0_mix_variable.Wsj0mixVariable", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "os.path.exists", "model.load_best_model", "torch.save", "model.make_model_and_optimizer", "model.load_best_model.eval", "model.load_best_model.load_state_dict", "model.load_best_model.cuda", "next", "conf[].format", "len", "range", "range", "model.load_best_model.separate", "series_list.append", "os.path.join", "all_metrics_df[].mean", "open", "json.dump", "model.load_best_model.state_dict", "torch.load", "model.load_best_model.parameters", "len", "torch.no_grad", "len", "torch.Tensor", "metrics.Penalized_PIT_Wrapper", "p_si_snr.item", "float", "pandas.Series", "mix[].cpu().data.numpy", "sources.cpu().data.numpy", "model.separate.cpu().data.numpy", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "os.path.join", "asteroid.utils.tensors_to_device", "soundfile.write", "soundfile.write", "open", "json.dump", "sources.size", "model.separate.size", "mix[].cpu", "sources.cpu", "model.separate.cpu"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.load_best_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device"], ["torch", ".", "no_grad", "(", ")", ".", "__enter__", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "test_set", ")", ")", ")", ":", "\n", "# Forward the network on the mixture.", "\n", "        ", "mix", ",", "sources", ",", "noises", "=", "tensors_to_device", "(", "test_set", "[", "idx", "]", ",", "device", "=", "model_device", ")", "\n", "mix", "=", "mix", "[", "...", ",", "0", "]", "\n", "sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "utt_metrics", "=", "get_metrics", "(", "\n", "mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ")", "as", "f", ":", "\n", "        ", "train_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "arg_dic", "[", "\"sample_rate\"", "]", "=", "train_conf", "[", "\"data\"", "]", "[", "\"sample_rate\"", "]", "\n", "arg_dic", "[", "\"train_conf\"", "]", "=", "train_conf", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.train.VarSpkrSystem.common_step": [[121, 137], ["train.VarSpkrSystem.", "pred_tensor.size", "range", "num_sources.tolist", "train.VarSpkrSystem.loss_func", "spks_sdr.append"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.train.VarSpkrSystem.training_step": [[138, 145], ["train.VarSpkrSystem.common_step", "train.VarSpkrSystem.log", "train.VarSpkrSystem.log", "train.VarSpkrSystem.log"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.common_step"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.train.VarSpkrSystem.validation_step": [[146, 155], ["train.VarSpkrSystem.common_step", "train.VarSpkrSystem.log", "train.VarSpkrSystem.log", "torch.mean", "train.VarSpkrSystem.log", "train.VarSpkrSystem.log", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.common_step"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.train.WeightedPITLoss.__init__": [[164, 169], ["torch.nn.Module.__init__", "torch.nn.CrossEntropyLoss", "enumerate"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.train.WeightedPITLoss.forward": [[170, 198], ["est_src.size", "src.unsqueeze().repeat", "asteroid.losses.pairwise_neg_sisdr", "asteroid.losses.PITLossWrapper.find_best_perm", "torch.LongTensor().to", "train.WeightedPITLoss.cce", "torch.Tensor().to", "torch.sum", "src.size", "logits[].argmax().item", "torch.Tensor().to.size", "sdr_loss.size", "train.WeightedPITLoss.size", "est_src.size", "src.unsqueeze", "torch.LongTensor", "torch.Tensor", "logits[].argmax", "range"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.find_best_perm"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.train.main": [[26, 118], ["wsj0_mix_variable.Wsj0mixVariable", "wsj0_mix_variable.Wsj0mixVariable", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "model.make_model_and_optimizer", "os.makedirs", "os.path.join", "train.WeightedPITLoss", "train.VarSpkrSystem", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.save", "[].format", "[].format", "scheduler.append", "scheduler.append", "open", "yaml.safe_dump", "callbacks.append", "torch.cuda.is_available", "v.item", "open", "json.dump", "VarSpkrSystem.model.state_dict", "os.path.join", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ExponentialLR", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.state_dict"], ["val_len", "=", "len", "(", "total_set", ")", "-", "train_len", "\n", "train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.model.MultiDecoderDPRNN.__init__": [[81, 148], ["asteroid.models.BaseModel.__init__", "asteroid_filterbanks.make_enc_dec", "model.DPRNN_MultiStage", "model.Decoder_Select", "asteroid.masknn.activations.get"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["# LSTM masker expects a feature dimension last (not like 1D conv)", "\n", "", "est_masks", "=", "self", ".", "masker", "(", "to_masker", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# Apply TF mask", "\n", "if", "self", ".", "is_complex", ":", "\n", "            ", "masked_tf_rep", "=", "apply_real_mask", "(", "tf_rep", ",", "est_masks", ")", "\n", "", "else", ":", "\n", "            ", "masked_tf_rep", "=", "apply_mag_mask", "(", "tf_rep", ",", "est_masks", ")", "\n", "", "return", "masked_tf_rep", "\n", "\n", "", "def", "denoise", "(", "self", ",", "x", ")", ":", "\n", "        ", "estimate_stft", "=", "self", "(", "x", ")", "\n", "wav", "=", "self", ".", "decoder", "(", "estimate_stft", ")", "\n", "return", "torch_utils", ".", "pad_x_to_y", "(", "wav", ",", "x", ")", "\n", "\n", "\n", "", "", "class", "SimpleModel", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Simple recurrent model for the DNS challenge.\n\n    Args:\n        input_size (int): input size along the features dimension\n        hidden_size (int): hidden size in the recurrent net\n        output_size (int): output size, defaults to `:attr:` input_size\n        rnn_type (str): Select from ``'RNN'``, ``'LSTM'``, ``'GRU'``. Can also\n            be passed in lowercase letters.\n        n_layers (int): Number of recurrent layers.\n        dropout (float): dropout value between recurrent layers.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "input_size", ",", "hidden_size", ",", "output_size", "=", "None", ",", "rnn_type", "=", "\"gru\"", ",", "n_layers", "=", "3", ",", "dropout", "=", "0.3", "\n", ")", ":", "\n", "        ", "super", "(", "SimpleModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "output_size", "=", "input_size", "if", "output_size", "is", "None", "else", "output_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "in_proj_layer", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "residual_rec", "=", "StackedResidualRNN", "(", "\n", "rnn_type", ",", "hidden_size", ",", "n_layers", "=", "n_layers", ",", "dropout", "=", "dropout", "\n", ")", "\n", "self", ".", "out_proj_layer", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "output_size", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Mask estimator's forward pass. Expects [batch, time, input_size]\"\"\"", "\n", "# Non negative features from input", "\n", "out_rec", "=", "self", ".", "residual_rec", "(", "torch", ".", "relu", "(", "self", ".", "in_proj_layer", "(", "x", ")", ")", ")", "\n", "# Activation is relu on the mask (better gradients allegedly)", "\n", "return", "torch", ".", "relu", "(", "self", ".", "out_proj_layer", "(", "out_rec", ")", ")", "\n", "\n", "\n", "", "", "class", "SimpleSystem", "(", "System", ")", ":", "\n", "    ", "def", "common_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "mixture", ",", "speech", ",", "noise", "=", "batch", "\n", "estimate", "=", "self", "(", "mixture", ".", "unsqueeze", "(", "1", ")", ")", "\n", "speech_stft", "=", "self", ".", "model", ".", "encoder", "(", "speech", ".", "unsqueeze", "(", "1", ")", ")", "\n", "# The loss function can be something like", "\n", "# loss_func = partial(distance, is_complex=some_bool)", "\n", "loss", "=", "self", ".", "loss_func", "(", "estimate", ",", "speech_stft", ")", "\n", "return", "loss", "\n", "\n", "\n", "", "", "def", "distance", "(", "estimate", ",", "target", ",", "is_complex", "=", "True", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.model.MultiDecoderDPRNN.forward": [[149, 161], ["asteroid.utils.torch_utils.jitable_shape", "asteroid.models.base_models._unsqueeze_to_3d", "model.MultiDecoderDPRNN.enc_activation", "model.MultiDecoderDPRNN.masker", "model.MultiDecoderDPRNN.decoder_select", "asteroid.utils.torch_utils.pad_x_to_y", "model.MultiDecoderDPRNN.encoder", "asteroid.models.base_models._shape_reconstructed", "asteroid.models.base_models._shape_reconstructed"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.jitable_shape", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models._unsqueeze_to_3d", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.pad_x_to_y", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models._shape_reconstructed", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models._shape_reconstructed"], ["\n", "if", "is_complex", ":", "\n", "# Take the difference in the complex plane and compute the squared norm", "\n", "# of the remaining vector.", "\n", "        ", "return", "mag", "(", "estimate", "-", "target", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "# Compute the mean difference between magnitudes.", "\n", "        ", "return", "(", "mag", "(", "estimate", ")", "-", "mag", "(", "target", ")", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.model.MultiDecoderDPRNN.forward_wav": [[163, 214], ["wav.reshape.reshape.size", "torch.pad", "torch.pad", "wav.reshape.reshape.unfold", "slices.squeeze().unsqueeze.squeeze().unsqueeze.size", "slices.squeeze().unsqueeze.squeeze().unsqueeze.squeeze().unsqueeze", "model.MultiDecoderDPRNN.enc_activation", "model.MultiDecoderDPRNN.masker", "model.MultiDecoderDPRNN.decoder_select.selector().reshape", "model.MultiDecoderDPRNN.argmax().mode", "model.MultiDecoderDPRNN.decoder_select", "output_wavs.new_zeros", "range", "wav.reshape.reshape.reshape", "max", "model.MultiDecoderDPRNN.encoder", "output_wavs.squeeze", "output_cat[].unsqueeze", "asteroid.losses.pairwise_neg_sisdr", "asteroid.losses.PITLossWrapper.find_best_perm", "asteroid.losses.PITLossWrapper.reorder_source", "asteroid.losses.PITLossWrapper.reorder_source.squeeze", "wav.reshape.reshape.size", "int", "slices.squeeze().unsqueeze.squeeze().unsqueeze.squeeze", "model.MultiDecoderDPRNN.decoder_select.selector", "model.MultiDecoderDPRNN.argmax", "numpy.ceil"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.unfold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.pit_wrapper.PITLossWrapper.find_best_perm", "home.repos.pwc.inspect_result.mpariente_AsSteroid.losses.mixit_wrapper.MixITLossWrapper.reorder_source"], ["\n", "", "", "def", "load_best_model", "(", "train_conf", ",", "exp_dir", ")", ":", "\n", "    ", "\"\"\"Load best model after training.\n\n    Args:\n        train_conf (dict): dictionary as expected by `make_model_and_optimizer`\n        exp_dir(str): Experiment directory. Expects to find\n            `'best_k_models.json'` there.\n\n    Returns:\n        nn.Module the best pretrained model according to the val_loss.\n    \"\"\"", "\n", "# Create the model from recipe-local function", "\n", "model", ",", "_", "=", "make_model_and_optimizer", "(", "train_conf", ")", "\n", "# Last best model summary", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "best_k", "=", "json", ".", "load", "(", "f", ")", "\n", "", "best_model_path", "=", "min", "(", "best_k", ",", "key", "=", "best_k", ".", "get", ")", "\n", "# Load checkpoint", "\n", "checkpoint", "=", "torch", ".", "load", "(", "best_model_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "# Load state_dict into model.", "\n", "model", "=", "torch_utils", ".", "load_state_dict_in", "(", "checkpoint", "[", "\"state_dict\"", "]", ",", "model", ")", "\n", "model", ".", "eval", "(", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.model.DPRNN_MultiStage.__init__": [[221, 267], ["torch.nn.Module.__init__", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "asteroid.masknn.norms.get", "model.DPRNN_MultiStage.net.append", "asteroid.masknn.recurrent.DPRNNBlock"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.model.DPRNN_MultiStage.forward": [[270, 293], ["mixture_w.size", "model.DPRNN_MultiStage.bottleneck", "torch.nn.functional.unfold", "torch.nn.functional.unfold", "output.reshape.reshape.reshape", "range", "output.reshape.reshape.unsqueeze", "output_list.append"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.unfold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.unfold"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.model.SingleDecoder.__init__": [[301, 332], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Conv1d", "torch.nn.Conv1d", "asteroid.masknn.activations.get", "asteroid.utils.generic_utils.has_arg", "asteroid_filterbanks.make_enc_dec", "torch.nn.PReLU", "torch.nn.PReLU", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Tanh", "torch.nn.Tanh", "torch.nn.Conv1d", "torch.nn.Conv1d", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "asteroid.masknn.activations.get.", "asteroid.masknn.activations.get."], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.generic_utils.has_arg"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.model.SingleDecoder.forward": [[334, 372], ["output.reshape.reshape.size", "mixture_w.unsqueeze.unsqueeze.size", "model.SingleDecoder.first_out", "output.reshape.reshape.reshape", "torch.nn.functional.fold", "torch.nn.functional.fold", "output.reshape.reshape.reshape", "model.SingleDecoder.mask_net", "model.SingleDecoder.output_act", "est_mask.reshape.reshape.reshape", "mixture_w.unsqueeze.unsqueeze.unsqueeze", "source_w.reshape.reshape.reshape", "model.SingleDecoder.trans_conv", "est_wavs.reshape.reshape.reshape", "output.reshape.reshape.reshape", "model.SingleDecoder.net_out", "model.SingleDecoder.net_gate"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.fold", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.overlap_add.DualPathProcessing.fold"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.model.Decoder_Select.__init__": [[381, 414], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Sequential", "torch.nn.Sequential", "model.Decoder_Select.decoders.append", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.Conv2d", "enumerate", "model.SingleDecoder", "len"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.model.Decoder_Select.forward": [[416, 455], ["output_list[].size", "mixture_w.unsqueeze().repeat.unsqueeze().repeat.size", "len", "torch.stack().reshape", "torch.stack().reshape", "torch.stack().reshape", "torch.stack().reshape", "model.Decoder_Select.selector().reshape", "output.reshape.reshape.reshape", "mixture_w.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "model.Decoder_Select.reshape().argmax", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "model.Decoder_Select.selector", "mixture_w.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "model.Decoder_Select.reshape", "max"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.model.make_model_and_optimizer": [[33, 45], ["model.MultiDecoderDPRNN", "asteroid.engine.optimizers.make_optimizer", "MultiDecoderDPRNN.parameters"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer"], ["        ", "inp_size", "=", "output_size", "=", "int", "(", "stft", ".", "n_feats_out", "/", "2", ")", "\n", "# Add these fields to the mask model dict", "\n", "", "conf", "[", "\"masknet\"", "]", ".", "update", "(", "dict", "(", "input_size", "=", "inp_size", ",", "output_size", "=", "output_size", ")", ")", "\n", "masker", "=", "SimpleModel", "(", "**", "conf", "[", "\"masknet\"", "]", ")", "\n", "# Make the complete model", "\n", "model", "=", "Model", "(", "stft", ",", "masker", ",", "istft", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "# Define optimizer of this model", "\n", "optimizer", "=", "make_optimizer", "(", "model", ".", "parameters", "(", ")", ",", "**", "conf", "[", "\"optim\"", "]", ")", "\n", "return", "model", ",", "optimizer", "\n", "\n", "\n", "", "class", "Model", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.model.load_best_model": [[457, 491], ["model.make_model_and_optimizer", "torch.load", "torch.load", "asteroid.torch_utils.load_state_dict_in", "torch_utils.load_state_dict_in.eval", "min", "open", "json.load", "os.listdir", "os.listdir.sort", "os.path.join", "os.path.join", "os.path.join", "int", "ckpt.find", "filter", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.load_state_dict_in"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.wsj0_mix_variable.Wsj0mixVariable.__init__": [[43, 90], ["zip", "len", "print", "random.seed", "random.sample", "numpy.unique", "dict", "print", "int", "int", "os.path.join", "list", "list", "list", "range", "len", "len", "numpy.array", "zip", "zip", "os.path.join", "list.append", "zip", "zip", "len", "wsj0_mix_variable.load_json", "range", "wsj0_mix_variable.load_json"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.wsj0_mix_variable.load_json", "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.wsj0_mix_variable.load_json"], ["def", "__init__", "(", "\n", "self", ",", "json_dirs", ",", "n_srcs", "=", "[", "2", ",", "3", ",", "4", ",", "5", "]", ",", "sample_rate", "=", "8000", ",", "seglen", "=", "4.0", ",", "minlen", "=", "2.0", "\n", ")", ":", "# segment and cv_maxlen not implemented", "\n", "        ", "if", "seglen", "is", "None", ":", "\n", "            ", "self", ".", "seg_len", "=", "None", "\n", "self", ".", "min_len", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "seg_len", "=", "int", "(", "seglen", "*", "sample_rate", ")", "\n", "self", ".", "min_len", "=", "int", "(", "minlen", "*", "sample_rate", ")", "\n", "", "self", ".", "like_test", "=", "self", ".", "seg_len", "is", "None", "\n", "self", ".", "sr", "=", "sample_rate", "\n", "self", ".", "data", "=", "[", "]", "\n", "for", "json_dir", ",", "n_src", "in", "zip", "(", "json_dirs", ",", "n_srcs", ")", ":", "\n", "            ", "mix_json", "=", "os", ".", "path", ".", "join", "(", "json_dir", ",", "\"mix.json\"", ")", "\n", "mixfiles", ",", "wavlens", "=", "list", "(", "zip", "(", "*", "load_json", "(", "mix_json", ")", ")", ")", "\n", "sources_json", "=", "[", "\n", "os", ".", "path", ".", "join", "(", "json_dir", ",", "tmp_str", "+", "\".json\"", ")", "\n", "for", "tmp_str", "in", "[", "f\"s{n+1}\"", "for", "n", "in", "range", "(", "n_src", ")", "]", "\n", "]", "\n", "sourcefiles", "=", "[", "]", "\n", "for", "source_json", "in", "sources_json", ":", "\n", "                ", "sourcefiles", ".", "append", "(", "[", "line", "[", "0", "]", "for", "line", "in", "load_json", "(", "source_json", ")", "]", ")", "\n", "", "sourcefiles", "=", "list", "(", "zip", "(", "*", "sourcefiles", ")", ")", "\n", "self", ".", "data", "+=", "list", "(", "zip", "(", "mixfiles", ",", "sourcefiles", ",", "wavlens", ")", ")", "\n", "\n", "", "orig_len", "=", "len", "(", "self", ".", "data", ")", "\n", "drop_utt", ",", "drop_len", "=", "0", ",", "0", "\n", "if", "not", "self", ".", "like_test", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "data", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "# Go backward, since we will delete stuff", "\n", "                ", "if", "self", ".", "data", "[", "i", "]", "[", "2", "]", "<", "self", ".", "min_len", ":", "\n", "                    ", "drop_utt", "+=", "1", "\n", "drop_len", "+=", "self", ".", "data", "[", "i", "]", "[", "2", "]", "\n", "del", "self", ".", "data", "[", "i", "]", "\n", "\n", "", "", "", "print", "(", "\n", "\"Drop {} utts({:.2f} h) from {} (shorter than {} samples)\"", ".", "format", "(", "\n", "drop_utt", ",", "drop_len", "/", "self", ".", "sr", "/", "3600", ",", "orig_len", ",", "self", ".", "min_len", "\n", ")", "\n", ")", "\n", "\n", "random", ".", "seed", "(", "0", ")", "\n", "self", ".", "data", "=", "random", ".", "sample", "(", "self", ".", "data", ",", "len", "(", "self", ".", "data", ")", ")", "\n", "# Count for resampling", "\n", "data_n_src", "=", "[", "len", "(", "tmp", "[", "1", "]", ")", "for", "tmp", "in", "self", ".", "data", "]", "\n", "unique", ",", "counts", "=", "np", ".", "unique", "(", "np", ".", "array", "(", "data_n_src", ")", ",", "return_counts", "=", "True", ")", "\n", "n_src2counts", "=", "dict", "(", "zip", "(", "unique", ",", "counts", ")", ")", "\n", "print", "(", "\"count of mixtures by number of sources:\"", ",", "n_src2counts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.wsj0_mix_variable.Wsj0mixVariable.__len__": [[91, 93], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.wsj0_mix_variable.Wsj0mixVariable.__getitem__": [[94, 116], ["soundfile.read", "numpy.random.randint", "min", "soundfile.read"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            mixture: [T]\n            sources: list of C, each [T]\n        \"\"\"", "\n", "mixfile", ",", "sourcefiles", ",", "length", "=", "self", ".", "data", "[", "idx", "]", "\n", "if", "self", ".", "like_test", ":", "\n", "            ", "rand_start", "=", "0", "\n", "", "else", ":", "\n", "            ", "rand_start", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "length", "-", "self", ".", "min_len", "+", "1", ")", "\n", "", "if", "self", ".", "like_test", ":", "\n", "            ", "stop", "=", "None", "\n", "", "else", ":", "\n", "            ", "stop", "=", "min", "(", "rand_start", "+", "self", ".", "seg_len", ",", "length", ")", "\n", "", "mixture", ",", "sr", "=", "sf", ".", "read", "(", "mixfile", ",", "start", "=", "rand_start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ")", "\n", "assert", "sr", "==", "self", ".", "sr", ",", "\"need to resample\"", "\n", "sources", "=", "[", "\n", "sf", ".", "read", "(", "sourcefile", ",", "start", "=", "rand_start", ",", "stop", "=", "stop", ",", "dtype", "=", "\"float32\"", ")", "[", "0", "]", "\n", "for", "sourcefile", "in", "sourcefiles", "\n", "]", "\n", "return", "mixture", ",", "sources", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.wsj0_mix_variable.load_json": [[17, 21], ["open", "json.load"], "function", ["None"], ["def", "load_json", "(", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.wsj0_mix_variable.pad_audio": [[23, 27], ["len", "numpy.concatenate", "numpy.zeros", "len"], "function", ["None"], ["", "def", "pad_audio", "(", "audio", ",", "len_samples", ")", ":", "\n", "    ", "if", "len", "(", "audio", ")", "<", "len_samples", ":", "\n", "        ", "audio", "=", "np", ".", "concatenate", "(", "[", "audio", ",", "np", ".", "zeros", "(", "len_samples", "-", "len", "(", "audio", ")", ")", "]", ")", "\n", "", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.Multi-Decoder-DPRNN.wsj0_mix_variable._collate_fn": [[118, 143], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "torch.Tensor().int", "torch.Tensor().int", "torch.Tensor().int", "torch.Tensor().int", "len", "len", "len", "max", "len", "max", "max", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "len", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.stack", "numpy.stack", "numpy.stack"], "function", ["None"], ["", "", "def", "_collate_fn", "(", "batch", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        batch: list, len(batch) = batch_size, each entry is a tuple of (mixture, sources)\n    Returns:\n        mixtures_tensor: B x T, torch.Tensor, padded mixtures\n        source_tensor: B x C x T, torch.Tensor, padded in both channel and time dimension\n        ilens : B, torch.Tensor, length of each mixture\n        num_sources : B, torch.Tensor, number of sources for each mixture\n    \"\"\"", "\n", "ilens", "=", "[", "len", "(", "mixture", ")", "for", "mixture", ",", "_", "in", "batch", "]", "\n", "num_sources", "=", "[", "len", "(", "sources", ")", "for", "_", ",", "sources", "in", "batch", "]", "\n", "mixture_tensor", "=", "torch", ".", "zeros", "(", "len", "(", "batch", ")", ",", "max", "(", "ilens", ")", ")", "\n", "source_tensor", "=", "torch", ".", "zeros", "(", "len", "(", "batch", ")", ",", "max", "(", "num_sources", ")", ",", "max", "(", "ilens", ")", ")", "\n", "\n", "for", "i", ",", "(", "mixture", ",", "sources", ")", "in", "enumerate", "(", "batch", ")", ":", "# compute length to pad to", "\n", "        ", "assert", "len", "(", "mixture", ")", "==", "len", "(", "sources", "[", "0", "]", ")", "\n", "mixture_tensor", "[", "i", ",", ":", "ilens", "[", "i", "]", "]", "=", "torch", ".", "Tensor", "(", "mixture", ")", ".", "float", "(", ")", "\n", "source_tensor", "[", "i", ",", ":", "num_sources", "[", "i", "]", ",", ":", "ilens", "[", "i", "]", "]", "=", "torch", ".", "Tensor", "(", "\n", "np", ".", "stack", "(", "sources", ",", "axis", "=", "0", ")", "\n", ")", ".", "float", "(", ")", "\n", "", "ilens", "=", "torch", ".", "Tensor", "(", "np", ".", "stack", "(", "ilens", ")", ")", ".", "int", "(", ")", "\n", "num_sources", "=", "torch", ".", "Tensor", "(", "np", ".", "stack", "(", "num_sources", ")", ")", ".", "int", "(", ")", "\n", "\n", "return", "mixture_tensor", ",", "source_tensor", ",", "ilens", ",", "num_sources", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TAC.eval.main": [[33, 112], ["os.path.join", "asteroid.models.fasnet.FasNetTAC.from_pretrained", "local.tac_dataset.TACDataset", "asteroid.losses.PITLossWrapper", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "torch.load", "asteroid.models.save_publishable", "FasNetTAC.from_pretrained.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "torch.tensor().to", "FasNetTAC.from_pretrained.", "asteroid.losses.PITLossWrapper.", "mix.cpu().data.numpy", "sources[].cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "open", "json.dump", "os.path.join", "FasNetTAC.from_pretrained.parameters", "len", "torch.no_grad", "len", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "os.path.join", "torch.tensor", "soundfile.write", "soundfile.write", "open", "json.dump", "mix.cpu", "sources[].cpu", "reordered_sources.squeeze().cpu", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics"], ["\n", "\n", "def", "main", "(", "conf", ")", ":", "\n", "    ", "model", "=", "load_best_model", "(", "conf", "[", "\"train_conf\"", "]", ",", "conf", "[", "\"exp_dir\"", "]", ")", "\n", "# Handle device placement", "\n", "if", "conf", "[", "\"use_gpu\"", "]", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "", "model_device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "test_set", "=", "KinectWsjMixDataset", "(", "conf", "[", "\"test_dir\"", "]", ",", "n_src", "=", "conf", "[", "\"n_src\"", "]", ",", "segment", "=", "None", ")", "\n", "# Used to reorder sources only", "\n", "loss_func", "=", "PITLossWrapper", "(", "pairwise_neg_sisdr", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "\n", "# Randomly choose the indexes of sentences to save.", "\n", "ex_save_dir", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"examples/\"", ")", "\n", "if", "conf", "[", "\"n_save_ex\"", "]", "==", "-", "1", ":", "\n", "        ", "conf", "[", "\"n_save_ex\"", "]", "=", "len", "(", "test_set", ")", "\n", "", "save_idx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "test_set", ")", ")", ",", "conf", "[", "\"n_save_ex\"", "]", ")", "\n", "series_list", "=", "[", "]", "\n", "torch", ".", "no_grad", "(", ")", ".", "__enter__", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "test_set", ")", ")", ")", ":", "\n", "# Forward the network on the mixture.", "\n", "        ", "mix", ",", "sources", ",", "noises", "=", "tensors_to_device", "(", "test_set", "[", "idx", "]", ",", "device", "=", "model_device", ")", "\n", "mix", "=", "mix", "[", "...", ",", "0", "]", "\n", "sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "utt_metrics", "=", "get_metrics", "(", "\n", "mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TAC.train.TACSystem.common_step": [[29, 38], ["train.TACSystem.model", "train.TACSystem.loss_func().mean", "train.TACSystem.loss_func"], "methods", ["None"], ["train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TAC.train.main": [[40, 135], ["local.tac_dataset.TACDataset", "local.tac_dataset.TACDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "asteroid.models.fasnet.FasNetTAC", "asteroid.engine.optimizers.make_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "train.TACSystem", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "TACSystem.load_state_dict", "TACSystem.cpu", "TACSystem.model.serialize", "system.model.serialize.update", "torch.save", "asteroid.models.save_publishable", "asteroid.models.fasnet.FasNetTAC.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "local.tac_dataset.TACDataset.get_infos", "os.path.join", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "dict", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], ["num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.demask.train.DeMaskSystem.common_step": [[29, 35], ["train.DeMaskSystem.", "train.DeMaskSystem.loss_func().mean", "train.DeMaskSystem.loss_func", "train.DeMaskSystem.squeeze"], "methods", ["None"], ["train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.demask.train.main": [[37, 129], ["local.demask_dataset.DeMaskDataset", "local.demask_dataset.DeMaskDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "asteroid.DeMask", "asteroid.engine.optimizers.make_optimizer", "os.makedirs", "os.path.join", "train.DeMaskSystem", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "DeMaskSystem.load_state_dict", "DeMaskSystem.cpu", "DeMaskSystem.model.serialize", "system.model.serialize.update", "torch.save", "asteroid.models.save_publishable", "asteroid.DeMask.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "local.demask_dataset.DeMaskDataset.get_infos", "os.path.join", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "dict", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], ["val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.LibriVAD.eval.main": [[42, 98], ["asteroid.data.vad_dataset.LibriVADDataset", "asteroid.models.conv_tasnet.VADNet.from_pretrained", "os.path.join", "os.path.join", "random.sample", "torch.no_grad().__enter__", "asteroid.metrics.F1Tracker", "asteroid.binarize.Binarize", "tqdm.tqdm", "pandas.DataFrame", "pd.read_csv.to_csv", "pandas.read_csv", "print", "pprint.pprint", "os.path.join", "len", "range", "range", "VADNet.from_pretrained.", "asteroid.binarize.Binarize.", "asteroid.metrics.F1Tracker.", "series_list.append", "os.path.join", "os.path.join", "all_metrics_df[].mean", "open", "json.dump", "len", "torch.no_grad", "len", "mix.unsqueeze", "pandas.Series", "os.path.join", "os.makedirs", "matplotlib.subplots", "axs[].plot", "axs[].plot", "axs[].plot", "axs[].title.set_text", "axs[].title.set_text", "axs[].title.set_text", "matplotlib.savefig", "os.path.join", "labels.squeeze().data.numpy", "binarizer.squeeze().data.numpy", "model.squeeze().data.numpy", "os.path.join", "open", "json.dump", "labels.squeeze", "binarizer.squeeze", "model.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.plot", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.plot", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.plot"], ["# Used to reorder sources only", "\n", "loss_func", "=", "PITLossWrapper", "(", "pairwise_neg_sisdr", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "\n", "# Randomly choose the indexes of sentences to save.", "\n", "ex_save_dir", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"examples/\"", ")", "\n", "if", "conf", "[", "\"n_save_ex\"", "]", "==", "-", "1", ":", "\n", "        ", "conf", "[", "\"n_save_ex\"", "]", "=", "len", "(", "test_set", ")", "\n", "", "save_idx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "test_set", ")", ")", ",", "conf", "[", "\"n_save_ex\"", "]", ")", "\n", "series_list", "=", "[", "]", "\n", "torch", ".", "no_grad", "(", ")", ".", "__enter__", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "test_set", ")", ")", ")", ":", "\n", "# Forward the network on the mixture.", "\n", "        ", "mix", ",", "sources", ",", "noises", "=", "tensors_to_device", "(", "test_set", "[", "idx", "]", ",", "device", "=", "model_device", ")", "\n", "mix", "=", "mix", "[", "...", ",", "0", "]", "\n", "sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "utt_metrics", "=", "get_metrics", "(", "\n", "mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.LibriVAD.train.main": [[27, 107], ["asteroid.data.vad_dataset.LibriVADDataset", "asteroid.data.vad_dataset.LibriVADDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "asteroid.models.conv_tasnet.VADNet", "asteroid.engine.optimizers.make_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.soft_f1.F1_loss", "asteroid.engine.system.System", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "asteroid.engine.system.System.load_state_dict", "asteroid.engine.system.System.cpu", "asteroid.engine.system.System.model.serialize", "torch.save", "asteroid.models.conv_tasnet.VADNet.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize"], ["train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.OpenUnmix.test_dataloader.Compose.__init__": [[14, 16], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.OpenUnmix.test_dataloader.Compose.__call__": [[17, 21], ["transform"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "audio", ")", ":", "\n", "        ", "for", "transform", "in", "self", ".", "transforms", ":", "\n", "            ", "audio", "=", "transform", "(", "audio", ")", "\n", "", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.OpenUnmix.test_dataloader._augment_gain": [[23, 27], ["torch.rand"], "function", ["None"], ["", "", "def", "_augment_gain", "(", "audio", ",", "low", "=", "0.25", ",", "high", "=", "1.25", ")", ":", "\n", "    ", "\"\"\"Applies a random gain to each source between `low` and `high`\"\"\"", "\n", "gain", "=", "low", "+", "torch", ".", "rand", "(", "1", ")", "*", "(", "high", "-", "low", ")", "\n", "return", "audio", "*", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.OpenUnmix.test_dataloader._augment_channelswap": [[29, 35], ["torch.flip", "torch.FloatTensor().uniform_", "torch.FloatTensor"], "function", ["None"], ["", "def", "_augment_channelswap", "(", "audio", ")", ":", "\n", "    ", "\"\"\"Randomly swap channels of stereo sources\"\"\"", "\n", "if", "audio", ".", "shape", "[", "0", "]", "==", "2", "and", "torch", ".", "FloatTensor", "(", "1", ")", ".", "uniform_", "(", ")", "<", "0.5", ":", "\n", "        ", "return", "torch", ".", "flip", "(", "audio", ",", "[", "0", "]", ")", "\n", "\n", "", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.load_model": [[18, 24], ["print", "asteroid.models.XUMX.from_pretrained", "XUMX.from_pretrained.eval", "XUMX.from_pretrained.to"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained"], ["\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test_dir\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"Local data directory with test files\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_src\"", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft": [[26, 31], ["scipy.signal.istft"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft"], ["\"--use_gpu\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"Whether to use the GPU for model execution\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--exp_dir\"", ",", "default", "=", "\"exp/tmp\"", ",", "help", "=", "\"Experiment root\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--n_save_ex\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"Number of audio examples to save, -1 means all\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate": [[33, 126], ["torch.tensor().float().to", "x_umx_target", "enumerate", "numpy.transpose", "x_umx_target.encoder", "asteroid.complex_nn.torch_complex_from_magphase", "X[].transpose.detach().cpu().numpy", "X[].transpose", "norbert.wiener", "enumerate", "masked_tf_rep[].cpu().detach().numpy", "norbert.residual_model.append", "numpy.array", "tmp[].permute", "norbert.residual_model", "X[].transpose.astype", "eval.istft", "torch.tensor().float", "X[].transpose.detach().cpu", "len", "masked_tf_rep[].cpu().detach", "len", "torch.tensor", "X[].transpose.detach", "masked_tf_rep[].cpu"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_magphase", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.istft"], ["\n", "\n", "def", "main", "(", "conf", ")", ":", "\n", "    ", "model", "=", "load_best_model", "(", "conf", "[", "\"train_conf\"", "]", ",", "conf", "[", "\"exp_dir\"", "]", ")", "\n", "# Handle device placement", "\n", "if", "conf", "[", "\"use_gpu\"", "]", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "", "model_device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "test_set", "=", "KinectWsjMixDataset", "(", "conf", "[", "\"test_dir\"", "]", ",", "n_src", "=", "conf", "[", "\"n_src\"", "]", ",", "segment", "=", "None", ")", "\n", "# Used to reorder sources only", "\n", "loss_func", "=", "PITLossWrapper", "(", "pairwise_neg_sisdr", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "\n", "# Randomly choose the indexes of sentences to save.", "\n", "ex_save_dir", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"examples/\"", ")", "\n", "if", "conf", "[", "\"n_save_ex\"", "]", "==", "-", "1", ":", "\n", "        ", "conf", "[", "\"n_save_ex\"", "]", "=", "len", "(", "test_set", ")", "\n", "", "save_idx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "test_set", ")", ")", ",", "conf", "[", "\"n_save_ex\"", "]", ")", "\n", "series_list", "=", "[", "]", "\n", "torch", ".", "no_grad", "(", ")", ".", "__enter__", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "test_set", ")", ")", ")", ":", "\n", "# Forward the network on the mixture.", "\n", "        ", "mix", ",", "sources", ",", "noises", "=", "tensors_to_device", "(", "test_set", "[", "idx", "]", ",", "device", "=", "model_device", ")", "\n", "mix", "=", "mix", "[", "...", ",", "0", "]", "\n", "sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "utt_metrics", "=", "get_metrics", "(", "\n", "mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ")", "as", "f", ":", "\n", "        ", "train_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "arg_dic", "[", "\"sample_rate\"", "]", "=", "train_conf", "[", "\"data\"", "]", "[", "\"sample_rate\"", "]", "\n", "arg_dic", "[", "\"train_conf\"", "]", "=", "train_conf", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.inference_args": [[128, 160], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.eval_main": [[162, 255], ["os.path.abspath", "pathlib.Path().mkdir", "print", "torch.device", "eval.load_model", "musdb.DB", "museval.EvalStore", "pathlib.Path().mkdir", "os.path.join", "open", "print", "print", "museval.EvalStore.save", "print", "print", "open.close", "os.path.exists", "os.path.abspath", "os.path.join", "torch.cuda.is_available", "os.path.join", "soundfile.info", "int", "soundfile.read", "eval.separate", "pathlib.Path", "pathlib.Path.mkdir", "print", "print", "separate.items", "museval.eval_mus_track", "museval.EvalStore.add_track", "print", "print", "os.path.join", "os.path.abspath", "pathlib.Path", "pathlib.Path", "warnings.warn", "resampy.resample", "numpy.repeat", "os.path.join", "soundfile.write", "int", "str", "pathlib.Path().with_suffix", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.load_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.source.conf.read", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.eval.separate", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.resample"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.MultiDomainLoss.__init__": [[237, 266], ["torch.nn.modules.loss._Loss.__init__", "torch.nn.Sequential", "print", "asteroid.models.x_umx._STFT", "asteroid.models.x_umx._Spectrogram", "print", "print"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.MultiDomainLoss.forward": [[267, 293], ["targets.view.view.view", "train.MultiDomainLoss.transform", "sum", "train.freq_domain_loss", "train.time_domain_loss", "train.freq_domain_loss", "float", "range"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.freq_domain_loss", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.time_domain_loss", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.freq_domain_loss"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.XUMXManager.__init__": [[322, 337], ["config[].pop", "config[].pop", "asteroid.engine.system.System.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.XUMXManager.validation_step": [[338, 363], ["int", "train.XUMXManager.log", "train.XUMXManager.common_step"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.common_step"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.bandwidth_to_max_bin": [[35, 39], ["numpy.linspace", "numpy.max", "float", "numpy.where"], "function", ["None"], [")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.get_statistics": [[41, 64], ["sklearn.preprocessing.StandardScaler", "torch.nn.Sequential", "copy.deepcopy", "tqdm.tqdm", "numpy.maximum", "asteroid.models.x_umx._STFT", "asteroid.models.x_umx._Spectrogram", "range", "tqdm.tqdm.set_description", "sklearn.preprocessing.StandardScaler.partial_fit", "len", "torch.nn.Sequential.", "numpy.squeeze", "numpy.max"], "function", ["None"], ["drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.freq_domain_loss": [[66, 113], ["len", "enumerate", "range", "inferences.append", "refrences.append", "asteroid.losses.singlesrc_mse().mean", "range", "range", "list", "asteroid.losses.singlesrc_mse", "itertools.combinations", "asteroid.losses.singlesrc_mse().mean", "asteroid.losses.singlesrc_mse", "sum", "sum", "operator.itemgetter", "operator.itemgetter"], "function", ["None"], ["val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.time_domain_loss": [[115, 178], ["torch.cat.extend", "torch.stack", "torch.cat.view", "torch.cat.view", "train.weighted_sdr", "range", "mix_ref[].repeat", "mix_ref[].repeat", "range", "indices.extend", "sum", "sum", "torch.cat", "torch.cat", "range", "list", "len", "itertools.combinations", "range", "range", "range", "range", "mix_ref[].clone", "time_hat[].clone", "len", "len", "len", "len", "range", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.weighted_sdr"], ["arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.weighted_sdr": [[180, 210], ["torch.mean", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt"], "function", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.main": [[365, 478], ["torch.manual_seed", "random.seed", "pathlib.Path", "pathlib.Path.mkdir", "local.dataloader.load_datasets", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "train.bandwidth_to_max_bin", "asteroid.models.XUMX", "asteroid.engine.optimizers.make_optimizer", "torch.optim.lr_scheduler.ReduceLROnPlateau", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "train.MultiDomainLoss", "train.XUMXManager", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "XUMXManager.load_state_dict", "XUMXManager.cpu", "XUMXManager.model.serialize", "system.model.serialize.update", "torch.save", "torch.cuda.is_available", "train.get_statistics", "asteroid.models.XUMX.parameters", "open", "yaml.safe_dump", "v.item", "open", "json.dump", "train_dataset.get_infos", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.local.dataloader.load_datasets", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.bandwidth_to_max_bin", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.X-UMX.train.get_statistics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.eval.validate": [[17, 39], ["collections.OrderedDict", "catalyst.dl.utils.get_loader", "catalyst.dl.runner.SupervisedRunner", "catalyst.dl.runner.SupervisedRunner.infer", "collections.OrderedDict", "train.SNRCallback", "train.SDRCallback"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_cli.infer"], ["from", "asteroid", ".", "data", "import", "KinectWsjMixDataset", "\n", "\n", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test_dir\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"Local data directory with test files\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_src\"", ",", "type", "=", "int", ",", "default", "=", "2", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use_gpu\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"Whether to use the GPU for model execution\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--exp_dir\"", ",", "default", "=", "\"exp/tmp\"", ",", "help", "=", "\"Experiment root\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--n_save_ex\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"Number of audio examples to save, -1 means all\"", "\n", ")", "\n", "compute_metrics", "=", "[", "\"si_sdr\"", ",", "\"sdr\"", ",", "\"sir\"", ",", "\"sar\"", ",", "\"stoi\"", "]", "\n", "\n", "\n", "def", "main", "(", "conf", ")", ":", "\n", "    ", "model", "=", "load_best_model", "(", "conf", "[", "\"train_conf\"", "]", ",", "conf", "[", "\"exp_dir\"", "]", ")", "\n", "# Handle device placement", "\n", "if", "conf", "[", "\"use_gpu\"", "]", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.eval.main": [[42, 68], ["train.ParamConfig", "asteroid.data.avspeech_dataset.AVSpeechDataset", "model.load_best_model", "print", "eval.validate", "pathlib.Path", "pathlib.Path", "torch.cuda.device_count", "print", "torch.nn.DataParallel", "list", "sum", "map", "[].split", "numpy.prod", "torch.nn.DataParallel.parameters"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.load_best_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.eval.validate"], ["# Used to reorder sources only", "\n", "loss_func", "=", "PITLossWrapper", "(", "pairwise_neg_sisdr", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "\n", "# Randomly choose the indexes of sentences to save.", "\n", "ex_save_dir", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"examples/\"", ")", "\n", "if", "conf", "[", "\"n_save_ex\"", "]", "==", "-", "1", ":", "\n", "        ", "conf", "[", "\"n_save_ex\"", "]", "=", "len", "(", "test_set", ")", "\n", "", "save_idx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "test_set", ")", ")", ",", "conf", "[", "\"n_save_ex\"", "]", ")", "\n", "series_list", "=", "[", "]", "\n", "torch", ".", "no_grad", "(", ")", ".", "__enter__", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "test_set", ")", ")", ")", ":", "\n", "# Forward the network on the mixture.", "\n", "        ", "mix", ",", "sources", ",", "noises", "=", "tensors_to_device", "(", "test_set", "[", "idx", "]", ",", "device", "=", "model_device", ")", "\n", "mix", "=", "mix", "[", "...", ",", "0", "]", "\n", "sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.train.DiscriminativeLoss.__init__": [[17, 22], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--exp_dir\"", ",", "default", "=", "\"exp/tmp\"", ",", "help", "=", "\"Full path to save best validation model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--is_complex\"", ",", "default", "=", "True", ",", "type", "=", "str2bool_arg", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.train.DiscriminativeLoss.forward": [[23, 34], ["torch.zeros_like", "range", "torch.mean", "range", "torch.mean.view"], "methods", ["None"], ["def", "main", "(", "conf", ")", ":", "\n", "    ", "total_set", "=", "DNSDataset", "(", "conf", "[", "\"data\"", "]", "[", "\"json_dir\"", "]", ")", "\n", "train_len", "=", "int", "(", "len", "(", "total_set", ")", "*", "(", "1", "-", "conf", "[", "\"data\"", "]", "[", "\"val_prop\"", "]", ")", ")", "\n", "val_len", "=", "len", "(", "total_set", ")", "-", "train_len", "\n", "train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.train.main": [[36, 79], ["train.ParamConfig", "asteroid.data.avspeech_dataset.AVSpeechDataset", "asteroid.data.avspeech_dataset.AVSpeechDataset", "model.make_model_and_optimizer", "print", "train.DiscriminativeLoss", "model_path.is_file", "train.train", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "print", "model_path.as_posix", "torch.cuda.device_count", "print", "torch.nn.DataParallel", "pathlib.Path", "list", "sum", "map", "[].split", "numpy.prod", "torch.nn.DataParallel.parameters"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.train.trainer.train"], ["val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Audio_Model.__init__": [[122, 265], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding", "model.Audio_Model.get_padding"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding"], ["\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Mask estimator's forward pass. Expects [batch, time, input_size]\"\"\"", "\n", "# Non negative features from input", "\n", "out_rec", "=", "self", ".", "residual_rec", "(", "torch", ".", "relu", "(", "self", ".", "in_proj_layer", "(", "x", ")", ")", ")", "\n", "# Activation is relu on the mask (better gradients allegedly)", "\n", "return", "torch", ".", "relu", "(", "self", ".", "out_proj_layer", "(", "out_rec", ")", ")", "\n", "\n", "\n", "", "", "class", "SimpleSystem", "(", "System", ")", ":", "\n", "    ", "def", "common_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "mixture", ",", "speech", ",", "noise", "=", "batch", "\n", "estimate", "=", "self", "(", "mixture", ".", "unsqueeze", "(", "1", ")", ")", "\n", "speech_stft", "=", "self", ".", "model", ".", "encoder", "(", "speech", ".", "unsqueeze", "(", "1", ")", ")", "\n", "# The loss function can be something like", "\n", "# loss_func = partial(distance, is_complex=some_bool)", "\n", "loss", "=", "self", ".", "loss_func", "(", "estimate", ",", "speech_stft", ")", "\n", "return", "loss", "\n", "\n", "\n", "", "", "def", "distance", "(", "estimate", ",", "target", ",", "is_complex", "=", "True", ")", ":", "\n", "    ", "\"\"\"Compute the average distance in the complex plane. Makes more sense\n    when the network computes a complex mask.\n\n    Args:\n        estimate (torch.Tensor): Estimate complex spectrogram.\n        target (torch.Tensor): Speech target complex spectrogram.\n        is_complex (bool): Whether to compute the distance in the complex or\n            the magnitude space.\n\n    Returns:\n        torch.Tensor the loss value, in a tensor of size 1.\n    \"\"\"", "\n", "if", "is_complex", ":", "\n", "# Take the difference in the complex plane and compute the squared norm", "\n", "# of the remaining vector.", "\n", "        ", "return", "mag", "(", "estimate", "-", "target", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "# Compute the mean difference between magnitudes.", "\n", "        ", "return", "(", "mag", "(", "estimate", ")", "-", "mag", "(", "target", ")", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "\n", "\n", "", "", "def", "load_best_model", "(", "train_conf", ",", "exp_dir", ")", ":", "\n", "    ", "\"\"\"Load best model after training.\n\n    Args:\n        train_conf (dict): dictionary as expected by `make_model_and_optimizer`\n        exp_dir(str): Experiment directory. Expects to find\n            `'best_k_models.json'` there.\n\n    Returns:\n        nn.Module the best pretrained model according to the val_loss.\n    \"\"\"", "\n", "# Create the model from recipe-local function", "\n", "model", ",", "_", "=", "make_model_and_optimizer", "(", "train_conf", ")", "\n", "# Last best model summary", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "best_k", "=", "json", ".", "load", "(", "f", ")", "\n", "", "best_model_path", "=", "min", "(", "best_k", ",", "key", "=", "best_k", ".", "get", ")", "\n", "# Load checkpoint", "\n", "checkpoint", "=", "torch", ".", "load", "(", "best_model_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "# Load state_dict into model.", "\n", "model", "=", "torch_utils", ".", "load_state_dict_in", "(", "checkpoint", "[", "\"state_dict\"", "]", ",", "model", ")", "\n", "model", ".", "eval", "(", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Audio_Model.get_padding": [[266, 272], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Audio_Model.forward": [[273, 299], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "output_layer.transpose().reshape.transpose().reshape.size", "output_layer.transpose().reshape.transpose().reshape.size", "output_layer.transpose().reshape.transpose().reshape.transpose().reshape", "model.Audio_Model.batch_norm1", "model.Audio_Model.batch_norm2", "model.Audio_Model.batch_norm3", "model.Audio_Model.batch_norm4", "model.Audio_Model.batch_norm5", "model.Audio_Model.batch_norm6", "model.Audio_Model.batch_norm7", "model.Audio_Model.batch_norm8", "model.Audio_Model.batch_norm9", "model.Audio_Model.batch_norm10", "model.Audio_Model.batch_norm11", "model.Audio_Model.batch_norm12", "model.Audio_Model.batch_norm13", "model.Audio_Model.batch_norm14", "model.Audio_Model.batch_norm15", "model.Audio_Model.conv1", "model.Audio_Model.conv2", "model.Audio_Model.conv3", "model.Audio_Model.conv4", "model.Audio_Model.conv5", "model.Audio_Model.conv6", "model.Audio_Model.conv7", "model.Audio_Model.conv8", "model.Audio_Model.conv9", "model.Audio_Model.conv10", "model.Audio_Model.conv11", "model.Audio_Model.conv12", "model.Audio_Model.conv13", "model.Audio_Model.conv14", "model.Audio_Model.conv15", "output_layer.transpose().reshape.transpose().reshape.transpose"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.__init__": [[302, 361], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "torch.nn.BatchNorm2d", "model.Video_Model.get_padding", "model.Video_Model.get_padding", "model.Video_Model.get_padding", "model.Video_Model.get_padding", "model.Video_Model.get_padding", "model.Video_Model.get_padding"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.get_padding": [[362, 368], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Video_Model.forward": [[369, 389], ["torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.nn.functional.interpolate", "torch.nn.functional.interpolate", "len", "input_video.unsqueeze.unsqueeze.unsqueeze", "model.Video_Model.batch_norm1", "model.Video_Model.batch_norm2", "model.Video_Model.batch_norm3", "model.Video_Model.batch_norm4", "model.Video_Model.batch_norm5", "model.Video_Model.batch_norm6", "model.Video_Model.conv1", "model.Video_Model.conv2", "model.Video_Model.conv3", "model.Video_Model.conv4", "model.Video_Model.conv5", "model.Video_Model.conv6"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Audio_Visual_Fusion.__init__": [[413, 460], ["isinstance", "torch.nn.Module.__init__", "model.Audio_Model", "model.Video_Model", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.Audio_Visual_Fusion.forward": [[461, 504], ["asteroid_filterbanks.transforms.to_torchaudio().transpose", "model.Audio_Visual_Fusion.audio_output", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.Audio_Visual_Fusion.squeeze", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "model.Audio_Visual_Fusion.lstm.flatten_parameters", "model.Audio_Visual_Fusion.lstm", "model.Audio_Visual_Fusion.batch_norm1", "model.Audio_Visual_Fusion.drop1", "model.Audio_Visual_Fusion.batch_norm2", "model.Audio_Visual_Fusion.drop2", "model.Audio_Visual_Fusion.batch_norm3", "model.Audio_Visual_Fusion.drop3", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "complex_mask.view().transpose.view().transpose.size", "complex_mask.view().transpose.view().transpose.view().transpose", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "range", "output_audio.permute().reshape.permute().reshape.permute().reshape", "model.Audio_Visual_Fusion.video_output", "AVFusion.append", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.Audio_Visual_Fusion.complex_mask_layer", "model.fast_icRM", "asteroid_filterbanks.transforms.to_torchaudio", "model.Audio_Visual_Fusion.fc1", "model.Audio_Visual_Fusion.fc2", "model.Audio_Visual_Fusion.fc3", "complex_mask.view().transpose.view().transpose.view", "output_audio.permute().reshape.permute().reshape.permute"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.sigmoid", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.sigmoid", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.sigmoid", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.sigmoid", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.fast_icRM"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.generate_cRM": [[13, 37], ["torch.zeros", "torch.zeros"], "function", ["None"], ["from", "asteroid", ".", "engine", ".", "optimizers", "import", "make_optimizer", "\n", "from", "asteroid", "import", "torch_utils", "\n", "\n", "\n", "def", "make_model_and_optimizer", "(", "conf", ")", ":", "\n", "    ", "\"\"\"Function to define the model and optimizer for a config dictionary.\n    Args:\n        conf: Dictionary containing the output of hierachical argparse.\n    Returns:\n        model, optimizer.\n    The main goal of this function is to make reloading for resuming\n    and evaluation very simple.\n    \"\"\"", "\n", "# Define building blocks for local model", "\n", "stft", ",", "istft", "=", "make_enc_dec", "(", "\"stft\"", ",", "**", "conf", "[", "\"filterbank\"", "]", ")", "\n", "# Because we concatenate (re, im, mag) as input and compute a complex mask.", "\n", "if", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ":", "\n", "        ", "inp_size", "=", "int", "(", "stft", ".", "n_feats_out", "*", "3", "/", "2", ")", "\n", "output_size", "=", "stft", ".", "n_feats_out", "\n", "", "else", ":", "\n", "        ", "inp_size", "=", "output_size", "=", "int", "(", "stft", ".", "n_feats_out", "/", "2", ")", "\n", "# Add these fields to the mask model dict", "\n", "", "conf", "[", "\"masknet\"", "]", ".", "update", "(", "dict", "(", "input_size", "=", "inp_size", ",", "output_size", "=", "output_size", ")", ")", "\n", "masker", "=", "SimpleModel", "(", "**", "conf", "[", "\"masknet\"", "]", ")", "\n", "# Make the complete model", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.cRM_tanh_compress": [[39, 61], ["torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["# Define optimizer of this model", "\n", "optimizer", "=", "make_optimizer", "(", "model", ".", "parameters", "(", ")", ",", "**", "conf", "[", "\"optim\"", "]", ")", "\n", "return", "model", ",", "optimizer", "\n", "\n", "\n", "", "class", "Model", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Speech enhancement model.\n\n    Args:\n        encoder (~.Encoder): instance of a complex filterbank encoder\n            `Encoder(STFTBFB(**))`.\n        masker (nn.Module): Mask estimator network.\n        decoder (~.Decoder): instance of a complex filterbank decoder\n            `Decoder(STFTBFB(**))`.\n        is_complex (bool): If the network works on the complex domain.\n\n    If `is_complex` is `True`, the input to the network are complex features,\n    the network estimates a complex mask and returns a complex speech estimate.\n    Else, the input is the magnitude, the network estimates a magnitude mask\n    and the returns a **complex** speech estimate.\n    The loss function needs to be adapted to complex representations.\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.cRM_tanh_recover": [[63, 81], ["torch.log", "torch.log"], "function", ["None"], ["        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "masker", "=", "masker", "\n", "# Decoder is not used for training but eventually, we want to invert", "\n", "# the encoder. Might as well include it in the model.", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "is_complex", "=", "is_complex", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "len", "(", "x", ".", "shape", ")", "==", "2", ":", "\n", "            ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "# Compute STFT", "\n", "", "tf_rep", "=", "self", ".", "encoder", "(", "x", ")", "\n", "# Estimate TF mask from STFT features : cat([re, im, mag])", "\n", "if", "self", ".", "is_complex", ":", "\n", "            ", "to_masker", "=", "magreim", "(", "tf_rep", ")", "\n", "", "else", ":", "\n", "            ", "to_masker", "=", "mag", "(", "tf_rep", ")", "\n", "# LSTM masker expects a feature dimension last (not like 1D conv)", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.fast_cRM": [[83, 99], ["model.generate_cRM", "model.cRM_tanh_compress"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.generate_cRM", "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.cRM_tanh_compress"], ["# Apply TF mask", "\n", "if", "self", ".", "is_complex", ":", "\n", "            ", "masked_tf_rep", "=", "apply_real_mask", "(", "tf_rep", ",", "est_masks", ")", "\n", "", "else", ":", "\n", "            ", "masked_tf_rep", "=", "apply_mag_mask", "(", "tf_rep", ",", "est_masks", ")", "\n", "", "return", "masked_tf_rep", "\n", "\n", "", "def", "denoise", "(", "self", ",", "x", ")", ":", "\n", "        ", "estimate_stft", "=", "self", "(", "x", ")", "\n", "wav", "=", "self", ".", "decoder", "(", "estimate_stft", ")", "\n", "return", "torch_utils", ".", "pad_x_to_y", "(", "wav", ",", "x", ")", "\n", "\n", "\n", "", "", "class", "SimpleModel", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.fast_icRM": [[101, 119], ["model.cRM_tanh_recover", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.cRM_tanh_recover"], ["\n", "\n", "def", "__init__", "(", "\n", "self", ",", "input_size", ",", "hidden_size", ",", "output_size", "=", "None", ",", "rnn_type", "=", "\"gru\"", ",", "n_layers", "=", "3", ",", "dropout", "=", "0.3", "\n", ")", ":", "\n", "        ", "super", "(", "SimpleModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "output_size", "=", "input_size", "if", "output_size", "is", "None", "else", "output_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "in_proj_layer", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "residual_rec", "=", "StackedResidualRNN", "(", "\n", "rnn_type", ",", "hidden_size", ",", "n_layers", "=", "n_layers", ",", "dropout", "=", "dropout", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.make_model_and_optimizer": [[506, 528], ["torch.device", "torch.device", "model.Audio_Visual_Fusion", "torch.nn.DataParallel.to", "torch.cuda.device_count", "torch.cuda.device_count", "asteroid.engine.optimizers.make_optimizer", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel.parameters", "len", "len", "print", "print"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.looking-to-listen.model.load_best_model": [[530, 554], ["model.make_model_and_optimizer", "torch.load", "torch.load", "asteroid.torch_utils.load_state_dict_in", "isinstance", "pathlib.Path", "best_model_path.is_file", "print"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.load_state_dict_in"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.postprocess.postprocess_audio.filter_audio": [[5, 16], ["scipy.butter", "scipy.sosfilt"], "function", ["None"], ["def", "filter_audio", "(", "y", ",", "sr", "=", "16_000", ",", "cutoff", "=", "15_000", ",", "low_cutoff", "=", "1", ",", "filter_order", "=", "5", ")", ":", "\n", "    ", "sos", "=", "sg", ".", "butter", "(", "\n", "filter_order", ",", "\n", "[", "low_cutoff", "/", "sr", "/", "2", ",", "cutoff", "/", "sr", "/", "2", "]", ",", "\n", "btype", "=", "\"band\"", ",", "\n", "analog", "=", "False", ",", "\n", "output", "=", "\"sos\"", ",", "\n", ")", "\n", "filtered", "=", "sg", ".", "sosfilt", "(", "sos", ",", "y", ")", "\n", "\n", "return", "filtered", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.postprocess.postprocess_audio.shelf": [[18, 27], ["pysndfx.AudioEffectsChain", "pysndfx.AudioEffectsChain.lowshelf().highshelf", "afc.lowshelf().highshelf.", "pysndfx.AudioEffectsChain.lowshelf"], "function", ["None"], ["", "def", "shelf", "(", "y", ",", "sr", "=", "16_000", ",", "gain", "=", "5", ",", "frequency", "=", "500", ",", "slope", "=", "0.5", ",", "high_frequency", "=", "7_000", ")", ":", "\n", "    ", "afc", "=", "AudioEffectsChain", "(", ")", "\n", "fx", "=", "afc", ".", "lowshelf", "(", "gain", "=", "gain", ",", "frequency", "=", "frequency", ",", "slope", "=", "slope", ")", ".", "highshelf", "(", "\n", "gain", "=", "-", "gain", ",", "frequency", "=", "high_frequency", ",", "slope", "=", "slope", "\n", ")", "\n", "\n", "y", "=", "fx", "(", "y", ",", "sample_in", "=", "sr", ",", "sample_out", "=", "sr", ")", "\n", "\n", "return", "y", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.remove_empty_audio.remove_corrupt_audio": [[13, 33], ["audio_dir.rglob", "print", "print", "filtered_df.to_csv", "pathlib.Path.as_posix().startswith", "pathlib.Path.stat", "pathlib.Path", "corrupt_audio.append", "pathlib.Path.as_posix", "pathlib.Path.as_posix", "len", "df[].isin"], "function", ["None"], ["def", "remove_corrupt_audio", "(", "audio_dir", ",", "df", ",", "path", ",", "expected_audio_size", "=", "96_000", ")", ":", "\n", "    ", "files", "=", "audio_dir", ".", "rglob", "(", "\"*wav\"", ")", "\n", "\n", "corrupt_audio", "=", "[", "]", "\n", "\n", "for", "f", "in", "files", ":", "\n", "        ", "size", "=", "f", ".", "stat", "(", ")", ".", "st_size", "\n", "if", "f", ".", "as_posix", "(", ")", ".", "startswith", "(", "\"../..\"", ")", ":", "\n", "# pathname should match with content of {train/val}.csv", "\n", "            ", "f", "=", "Path", "(", "*", "f", ".", "parts", "[", "2", ":", "]", ")", "\n", "\n", "", "if", "size", "<", "expected_audio_size", ":", "\n", "            ", "corrupt_audio", ".", "append", "(", "f", ".", "as_posix", "(", ")", ")", "\n", "\n", "", "", "print", "(", "f\"Found total corrupted files: {len(corrupt_audio)}\"", ")", "\n", "\n", "filtered_df", "=", "df", "[", "~", "df", "[", "\"mixed_audio\"", "]", ".", "isin", "(", "corrupt_audio", ")", "]", "\n", "print", "(", "df", ".", "shape", ",", "filtered_df", ".", "shape", ")", "\n", "\n", "filtered_df", ".", "to_csv", "(", "path", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.audio_mixer_generator.sample_audio_set": [[23, 35], ["glob.glob", "len", "max", "list", "random.shuffle", "os.path.join", "int", "range", "random.gauss"], "function", ["None"], ["def", "sample_audio_set", "(", ")", ":", "\n", "    ", "\"\"\"\n    sample random audio files as a noise from audio set dataset\n    \"\"\"", "\n", "audio_files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "AUDIO_SET_DIR", ",", "\"*\"", ")", ")", "\n", "total_files", "=", "len", "(", "audio_files", ")", "\n", "\n", "total_choices", "=", "max", "(", "1", ",", "int", "(", "random", ".", "gauss", "(", "mu", "=", "1", ",", "sigma", "=", "1", ")", ")", ")", "\n", "choices", "=", "list", "(", "range", "(", "total_files", ")", ")", "\n", "random", ".", "shuffle", "(", "choices", ")", "\n", "\n", "return", "[", "audio_files", "[", "i", "]", "for", "i", "in", "choices", "[", ":", "total_choices", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.audio_mixer_generator.requires_excess_storage_space": [[37, 49], ["math.factorial"], "function", ["None"], ["", "def", "requires_excess_storage_space", "(", "n", ",", "r", ")", ":", "\n", "# r will be very small anyway", "\n", "    ", "total", "=", "n", "**", "r", "/", "math", ".", "factorial", "(", "r", ")", "\n", "# total bytes", "\n", "storage_space", "=", "(", "\n", "total", "*", "96", "\n", ")", "# approximate storage requirement is (600K for spec and 90K for audio)", "\n", "\n", "if", "storage_space", ">", "STORAGE_LIMIT", ":", "\n", "        ", "return", "storage_space", ",", "True", "\n", "\n", "", "return", "storage_space", ",", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.audio_mixer_generator.nCr": [[51, 53], ["math.factorial", "math.factorial", "math.factorial"], "function", ["None"], ["", "def", "nCr", "(", "n", ",", "r", ")", ":", "\n", "    ", "return", "math", ".", "factorial", "(", "n", ")", "/", "(", "math", ".", "factorial", "(", "r", ")", "*", "math", ".", "factorial", "(", "n", "-", "r", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.audio_mixer_generator.audio_mixer": [[55, 202], ["glob.glob", "len", "int", "audio_mixer_generator.requires_excess_storage_space", "audio_mixer_generator.requires_excess_storage_space", "print", "audio_mixer_generator.audio_mixer.mix"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.audio_mixer_generator.requires_excess_storage_space", "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.audio_mixer_generator.requires_excess_storage_space"], ["", "def", "audio_mixer", "(", "\n", "dataset_size", ":", "int", ",", "\n", "n_src", "=", "2", ",", "\n", "video_ext", "=", "\".mp4\"", ",", "\n", "audio_ext", "=", "\".wav\"", ",", "\n", "file_name", "=", "\"temp.csv\"", ",", "\n", "audio_set", "=", "False", ",", "\n", "validation_size", "=", "0.3", ",", "\n", "remove_random_chance", "=", "0.9", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    generate the combination dataframe used in data_loader.py\n\n    Args:\n        dataset_size: restrict total possible combinations\n        n_src: input size\n        video_ext: extension of video\n        audio_ext: extension of audio\n        file_name: file name of combination dataframe to save\n        audio_set: use audio set dataset\n    \"\"\"", "\n", "audio_mix_command_suffix", "=", "\"-filter_complex amix=inputs={}:duration=longest \"", "\n", "audio_files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "AUDIO_DIR", ",", "\"*\"", ")", ")", "\n", "total_audio_files", "=", "len", "(", "audio_files", ")", "\n", "\n", "total_val_files", "=", "int", "(", "total_audio_files", "*", "validation_size", ")", "\n", "total_train_files", "=", "total_audio_files", "-", "total_val_files", "\n", "\n", "train_files", "=", "audio_files", "[", ":", "total_train_files", "]", "\n", "val_files", "=", "audio_files", "[", "-", "total_val_files", ":", "]", "\n", "\n", "storage_space_train", ",", "excess_storage", "=", "requires_excess_storage_space", "(", "len", "(", "train_files", ")", ",", "n_src", ")", "\n", "\n", "storage_space_val", ",", "_", "=", "requires_excess_storage_space", "(", "len", "(", "val_files", ")", ",", "n_src", ")", "\n", "\n", "storage_space", "=", "storage_space_train", "+", "storage_space_val", "\n", "if", "excess_storage", ":", "\n", "        ", "storage_space", "=", "(", "1", "-", "remove_random_chance", ")", "*", "storage_space", "\n", "print", "(", "f\"Removing {remove_random_chance * 100} percent of combinations\"", ")", "\n", "print", "(", "\n", "f\"Saving total space: {storage_space - storage_space * remove_random_chance:,} Kbytes\"", "\n", ")", "\n", "\n", "", "print", "(", "f\"Occupying space: {storage_space:,} Kbytes\"", ")", "\n", "\n", "def", "retrieve_name", "(", "f", ")", ":", "\n", "        ", "f", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "f", ")", ")", "[", "0", "]", "\n", "return", "re", ".", "sub", "(", "r\"_part\\d\"", ",", "\"\"", ",", "f", ")", "\n", "\n", "", "def", "mix", "(", "audio_filtered_files", ",", "file_name_df", ",", "offset", ",", "excess_storage", ")", ":", "\n", "# Generate all combinations and trim total possibilities", "\n", "        ", "audio_combinations", "=", "itertools", ".", "combinations", "(", "audio_filtered_files", ",", "n_src", ")", "\n", "audio_combinations", "=", "itertools", ".", "islice", "(", "audio_combinations", ",", "dataset_size", ")", "\n", "\n", "# Store list of tuples, consisting of `n_src`", "\n", "# Audio and their corresponding video path", "\n", "video_inputs", "=", "[", "]", "\n", "audio_inputs", "=", "[", "]", "\n", "mixed_audio", "=", "[", "]", "\n", "noises", "=", "[", "]", "\n", "\n", "total_comb_size", "=", "nCr", "(", "len", "(", "audio_filtered_files", ")", ",", "n_src", ")", "\n", "for", "indx", ",", "audio_comb", "in", "tqdm", "(", "enumerate", "(", "audio_combinations", ")", ",", "total", "=", "total_comb_size", ")", ":", "\n", "# skip few combinations if required storage is very high", "\n", "            ", "try", ":", "\n", "                ", "if", "excess_storage", "and", "random", ".", "random", "(", ")", "<", "remove_random_chance", ":", "\n", "                    ", "continue", "\n", "\n", "", "base_names", "=", "[", "os", ".", "path", ".", "basename", "(", "fname", ")", "[", ":", "11", "]", "for", "fname", "in", "audio_comb", "]", "\n", "if", "len", "(", "base_names", ")", "!=", "len", "(", "set", "(", "base_names", ")", ")", ":", "\n", "# if audio from the same video, assume same speaker and ignore it.", "\n", "                    ", "continue", "\n", "", "if", "audio_set", ":", "\n", "                    ", "noise_input", "=", "sample_audio_set", "(", ")", "\n", "noises", ".", "append", "(", "\":\"", ".", "join", "(", "noise_input", ")", ")", "\n", "audio_comb", "=", "(", "*", "audio_comb", ",", "*", "noise_input", ")", "\n", "\n", "", "audio_inputs", ".", "append", "(", "audio_comb", ")", "\n", "# Convert audio file path to corresponding video path", "\n", "video_inputs", ".", "append", "(", "\n", "tuple", "(", "os", ".", "path", ".", "join", "(", "VIDEO_DIR", ",", "retrieve_name", "(", "f", ")", "+", "video_ext", ")", "for", "f", "in", "audio_comb", ")", "\n", ")", "\n", "\n", "audio_mix_input", "=", "\"\"", "\n", "for", "audio", "in", "audio_comb", ":", "\n", "                    ", "audio_mix_input", "+=", "f\"-i {audio} \"", "\n", "\n", "", "mixed_audio_name", "=", "os", ".", "path", ".", "join", "(", "MIXED_AUDIO_DIR", ",", "f\"{indx+offset}{audio_ext}\"", ")", "\n", "audio_command", "=", "(", "\n", "AUDIO_MIX_COMMAND_PREFIX", "\n", "+", "audio_mix_input", "\n", "+", "audio_mix_command_suffix", ".", "format", "(", "len", "(", "audio_comb", ")", ")", "\n", "+", "mixed_audio_name", "\n", ")", "\n", "\n", "process", "=", "subprocess", ".", "Popen", "(", "\n", "audio_command", ",", "\n", "shell", "=", "True", ",", "\n", "stdout", "=", "subprocess", ".", "PIPE", ",", "\n", "stderr", "=", "subprocess", ".", "PIPE", ",", "\n", ")", "# .communicate()", "\n", "mixed_audio", ".", "append", "(", "mixed_audio_name", ")", "\n", "# print(video_inputs, audio_inputs, mixed_audio, noises)", "\n", "", "except", "KeyboardInterrupt", "as", "e", ":", "\n", "                ", "print", "(", "\"Caught Interrupt!\"", ")", "\n", "break", "\n", "\n", "", "", "combinations", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "n_src", ")", ":", "\n", "            ", "combinations", "[", "f\"video_{i+1}\"", "]", "=", "[", "]", "\n", "combinations", "[", "f\"audio_{i+1}\"", "]", "=", "[", "]", "\n", "", "combinations", "[", "\"mixed_audio\"", "]", "=", "[", "]", "\n", "\n", "min_length", "=", "min", "(", "min", "(", "len", "(", "video_inputs", ")", ",", "len", "(", "audio_inputs", ")", ")", ",", "len", "(", "mixed_audio", ")", ")", "\n", "print", "(", "f\"Total combinations: {min_length}\"", ")", "\n", "\n", "video_inputs", "=", "video_inputs", "[", ":", "min_length", "]", "\n", "audio_inputs", "=", "audio_inputs", "[", ":", "min_length", "]", "\n", "mixed_audio", "=", "mixed_audio", "[", ":", "min_length", "]", "\n", "\n", "assert", "len", "(", "video_inputs", ")", "==", "len", "(", "audio_inputs", ")", "==", "len", "(", "mixed_audio", ")", "\n", "\n", "for", "videos", ",", "audios", ",", "mixed", "in", "zip", "(", "video_inputs", ",", "audio_inputs", ",", "mixed_audio", ")", ":", "\n", "# fix proper path issue", "\n", "            ", "mixed", "=", "re", ".", "sub", "(", "r\"../../\"", ",", "\"\"", ",", "mixed", ")", "\n", "for", "i", "in", "range", "(", "n_src", ")", ":", "\n", "                ", "v", "=", "re", ".", "sub", "(", "r\"../../\"", ",", "\"\"", ",", "videos", "[", "i", "]", ")", "\n", "a", "=", "re", ".", "sub", "(", "r\"../../\"", ",", "\"\"", ",", "audios", "[", "i", "]", ")", "\n", "\n", "combinations", "[", "f\"video_{i+1}\"", "]", ".", "append", "(", "v", ")", "\n", "combinations", "[", "f\"audio_{i+1}\"", "]", ".", "append", "(", "a", ")", "\n", "", "combinations", "[", "\"mixed_audio\"", "]", ".", "append", "(", "mixed", ")", "\n", "\n", "", "columns", "=", "(", "\n", "[", "f\"video_{i+1}\"", "for", "i", "in", "range", "(", "n_src", ")", "]", "\n", "+", "[", "f\"audio_{i+1}\"", "for", "i", "in", "range", "(", "n_src", ")", "]", "\n", "+", "[", "\"mixed_audio\"", "]", "\n", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "combinations", ")", ".", "reindex", "(", "columns", "=", "columns", ")", "\n", "df", ".", "to_csv", "(", "file_name_df", ",", "index", "=", "False", ")", "\n", "\n", "if", "audio_set", ":", "\n", "            ", "pd", ".", "Series", "(", "noises", ")", ".", "to_csv", "(", "\"../../data/noise_only.csv\"", ",", "index", "=", "False", ",", "header", "=", "False", ")", "\n", "", "return", "df", ".", "shape", "[", "0", "]", "\n", "\n", "", "offset", "=", "mix", "(", "train_files", ",", "\"../../data/train.csv\"", ",", "0", ",", "excess_storage", ")", "\n", "mix", "(", "val_files", ",", "\"../../data/val.csv\"", ",", "offset", ",", "excess_storage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.extract_audio.extract": [[14, 35], ["os.path.join", "cv2.VideoCapture", "cv2.VideoCapture.get", "range", "path.as_posix", "subprocess.Popen().communicate", "int", "path.as_posix", "subprocess.Popen"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.get"], ["def", "extract", "(", "path", ")", ":", "\n", "    ", "name", "=", "path", ".", "stem", "\n", "\n", "dir_name", "=", "path", ".", "parents", "[", "0", "]", "\n", "audio_dir", "=", "args", ".", "aud_dir", "\n", "audio_path", "=", "os", ".", "path", ".", "join", "(", "audio_dir", ",", "name", ")", "\n", "video", "=", "cv2", ".", "VideoCapture", "(", "path", ".", "as_posix", "(", ")", ")", "\n", "length_orig_video", "=", "video", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", "\n", "# already pre-processed at 25 fps for 3 or more seconds", "\n", "length", "=", "int", "(", "length_orig_video", ")", "//", "25", "//", "3", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "        ", "t", "=", "i", "*", "3", "\n", "command", "=", "(", "\n", "f\"ffmpeg -y -i {path.as_posix()} -f {args.audio_extension} -ab 64000 \"", "\n", "f\"-vn -ar {args.sampling_rate} -ac {args.audio_channel} - | sox -t \"", "\n", "f\"{args.audio_extension} - -r 16000 -c 1 -b 8 \"", "\n", "f\"{audio_path}_part{i}.{args.audio_extension} trim {t} 00:{args.duration:02d}\"", "\n", ")", "\n", "\n", "subprocess", ".", "Popen", "(", "\n", "command", ",", "shell", "=", "True", ",", "stdout", "=", "subprocess", ".", "DEVNULL", ",", "stderr", "=", "subprocess", ".", "DEVNULL", "\n", ")", ".", "communicate", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.extract_audio.main": [[38, 47], ["pathlib.Path", "concurrent.futures.ThreadPoolExecutor", "list", "os.path.join", "os.listdir", "i.endswith", "tqdm.tqdm", "executor.map", "len"], "function", ["None"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "file_names", "=", "[", "\n", "Path", "(", "os", ".", "path", ".", "join", "(", "args", ".", "vid_dir", ",", "i", ")", ")", "\n", "for", "i", "in", "os", ".", "listdir", "(", "args", ".", "vid_dir", ")", "\n", "if", "i", ".", "endswith", "(", "\"_final.mp4\"", ")", "\n", "]", "\n", "\n", "with", "concurrent", ".", "futures", ".", "ThreadPoolExecutor", "(", "args", ".", "jobs", ")", "as", "executor", ":", "\n", "        ", "results", "=", "list", "(", "tqdm", "(", "executor", ".", "map", "(", "extract", ",", "file_names", ")", ",", "total", "=", "len", "(", "file_names", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.download.download": [[13, 29], ["subprocess.Popen().communicate", "os.path.exists", "os.path.isfile", "print", "os.path.isfile", "print", "subprocess.Popen", "command.format"], "function", ["None"], ["def", "download", "(", "link", ",", "path", ",", "final_name", "=", "None", ")", ":", "\n", "    ", "command", "=", "\"youtube-dl {} --no-check-certificate --output {}.mp4 -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4'\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", "and", "os", ".", "path", ".", "isfile", "(", "path", ")", ":", "\n", "        ", "print", "(", "\"File already downloaded\"", ")", "\n", "return", "False", "\n", "", "if", "final_name", "is", "not", "None", "and", "os", ".", "path", ".", "isfile", "(", "final_name", ")", ":", "\n", "        ", "print", "(", "\"File already cropped\"", ")", "\n", "return", "True", "\n", "\n", "", "p", "=", "subprocess", ".", "Popen", "(", "\n", "command", ".", "format", "(", "link", ",", "path", ")", ",", "\n", "shell", "=", "True", ",", "\n", "stdout", "=", "subprocess", ".", "PIPE", ",", "\n", "stderr", "=", "subprocess", ".", "PIPE", ",", "\n", ")", ".", "communicate", "(", ")", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.download.crop": [[31, 58], ["command.format.format", "subprocess.Popen().communicate", "subprocess.Popen().communicate", "int", "int", "os.path.exists", "os.path.isfile", "int", "int", "subprocess.Popen", "subprocess.Popen"], "function", ["None"], ["", "def", "crop", "(", "path", ",", "start", ",", "end", ",", "downloaded_name", ")", ":", "\n", "    ", "command", "=", "(", "\n", "\"ffmpeg -y -i {}.mp4 -ss {} -t {} -c:v libx264 -crf 18 -preset veryfast -pix_fmt yuv420p \"", "\n", "\"-c:a aac -b:a 128k -strict experimental -r 25 {}\"", "\n", ")", "\n", "\n", "start_minute", ",", "start_second", "=", "int", "(", "start", "//", "60", ")", ",", "int", "(", "start", "%", "60", ")", "\n", "end_minute", ",", "end_second", "=", "int", "(", "end", "//", "60", ")", "-", "start_minute", ",", "int", "(", "end", "%", "60", ")", "-", "start_second", "\n", "\n", "new_filepath", "=", "downloaded_name", "+", "\"_final.mp4\"", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "new_filepath", ")", "and", "os", ".", "path", ".", "isfile", "(", "new_filepath", ")", ":", "\n", "        ", "return", "\n", "\n", "", "command", "=", "command", ".", "format", "(", "\n", "downloaded_name", ",", "\n", "f\"{start_minute}:{start_second}\"", ",", "\n", "f\"{end_minute}:{end_second}\"", ",", "\n", "new_filepath", ",", "\n", ")", "\n", "subprocess", ".", "Popen", "(", "\n", "command", ",", "shell", "=", "True", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "PIPE", "\n", ")", ".", "communicate", "(", ")", "\n", "\n", "remove_orig_file", "=", "f\"rm -f {downloaded_name}.mp4\"", "\n", "subprocess", ".", "Popen", "(", "\n", "remove_orig_file", ",", "shell", "=", "True", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "stderr", "=", "subprocess", ".", "PIPE", "\n", ")", ".", "communicate", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.download.save_video": [[61, 69], ["int", "int", "download.download", "path.as_posix", "download.crop"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.download.download", "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.download.crop"], ["", "def", "save_video", "(", "zargs", ")", ":", "\n", "    ", "link", ",", "path", ",", "start", ",", "end", ",", "pos_x", ",", "pos_y", "=", "zargs", "\n", "x", "=", "int", "(", "pos_x", "*", "10000", ")", "\n", "y", "=", "int", "(", "pos_y", "*", "10000", ")", "\n", "downloaded_name", "=", "path", ".", "as_posix", "(", ")", "+", "f\"_{x}_{y}\"", "\n", "cropped", "=", "download", "(", "link", ",", "downloaded_name", ",", "final_name", "=", "downloaded_name", "+", "\"_final.mp4\"", ")", "\n", "if", "not", "cropped", ":", "\n", "        ", "crop", "(", "path", ",", "start", ",", "end", ",", "downloaded_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.download.main": [[71, 85], ["pandas.read_csv", "zip", "pathlib.Path", "concurrent.futures.ThreadPoolExecutor", "list", "os.path.join", "tqdm.tqdm", "executor.map", "len"], "function", ["None"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "df", "=", "pd", ".", "read_csv", "(", "args", ".", "path", ")", "\n", "links", "=", "df", ".", "iloc", "[", ":", ",", "0", "]", "[", "args", ".", "start", ":", "args", ".", "end", "]", "\n", "start_times", "=", "df", ".", "iloc", "[", ":", ",", "1", "]", "[", "args", ".", "start", ":", "args", ".", "end", "]", "\n", "end_times", "=", "df", ".", "iloc", "[", ":", ",", "2", "]", "[", "args", ".", "start", ":", "args", ".", "end", "]", "\n", "pos_x", "=", "df", ".", "iloc", "[", ":", ",", "3", "]", "[", "args", ".", "start", ":", "args", ".", "end", "]", "\n", "pos_y", "=", "df", ".", "iloc", "[", ":", ",", "4", "]", "[", "args", ".", "start", ":", "args", ".", "end", "]", "\n", "\n", "yt_links", "=", "[", "\"https://youtube.com/watch\\?v\\=\"", "+", "l", "for", "l", "in", "links", "]", "\n", "paths", "=", "[", "Path", "(", "os", ".", "path", ".", "join", "(", "args", ".", "vid_dir", ",", "f", ")", ")", "for", "f", "in", "links", "]", "\n", "\n", "link_path", "=", "zip", "(", "yt_links", ",", "paths", ",", "start_times", ",", "end_times", ",", "pos_x", ",", "pos_y", ")", "\n", "with", "concurrent", ".", "futures", ".", "ThreadPoolExecutor", "(", "args", ".", "jobs", ")", "as", "executor", ":", "\n", "        ", "results", "=", "list", "(", "tqdm", ".", "tqdm", "(", "executor", ".", "map", "(", "save_video", ",", "link_path", ")", ",", "total", "=", "len", "(", "links", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.frames.input_face_embeddings": [[10, 104], ["enumerate", "torch.stack", "result_cropped_tensors.half.to", "emb.float.to", "torch.cuda.is_available", "torch.device", "torch.device", "result_cropped_tensors.half.append", "len", "result_cropped_tensors.half.half", "torch.no_grad", "resnet", "emb.float.float", "PIL.Image.open", "PIL.Image.fromarray", "torch.no_grad", "mtcnn.detect", "torch.zeros", "no_face_indices.append", "name.replace.replace", "facenet_pytorch.extract_face.detach().cpu().numpy().astype", "numpy.squeeze", "PIL.Image.fromarray().save", "facenet_pytorch.extract_face.to", "f.astype", "np.squeeze.transpose", "facenet_pytorch.extract_face.detach().cpu().numpy", "PIL.Image.fromarray", "facenet_pytorch.extract_face", "facenet_pytorch.extract_face.detach().cpu", "facenet_pytorch.extract_face.detach"], "function", ["None"], ["def", "input_face_embeddings", "(", "\n", "frames", ":", "Union", "[", "List", "[", "str", "]", ",", "np", ".", "ndarray", "]", ",", "\n", "is_path", ":", "bool", ",", "\n", "mtcnn", ":", "MTCNN", ",", "\n", "resnet", ":", "InceptionResnetV1", ",", "\n", "face_embed_cuda", ":", "bool", ",", "\n", "use_half", ":", "bool", ",", "\n", "coord", ":", "List", ",", "\n", "name", ":", "str", "=", "None", ",", "\n", "save_frames", ":", "bool", "=", "False", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Get the face embedding\n\n    NOTE: If a face is not detected by the detector,\n    instead of throwing an error it zeros the input\n    for embedder.\n\n    NOTE: Memory hungry function, hence the profiler.\n\n    Args:\n        frames: Frames from the video\n        is_path: Whether to read from filesystem or memory\n        mtcnn: face detector\n        resnet: face embedder\n        face_embed_cuda: use cuda for model\n        use_half: use half precision\n\n    Returns:\n        emb: Embedding for all input frames\n    \"\"\"", "\n", "if", "face_embed_cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "result_cropped_tensors", "=", "[", "]", "\n", "no_face_indices", "=", "[", "]", "\n", "for", "i", ",", "f", "in", "enumerate", "(", "frames", ")", ":", "\n", "        ", "if", "is_path", ":", "\n", "            ", "frame", "=", "Image", ".", "open", "(", "f", ")", "\n", "", "else", ":", "\n", "            ", "frame", "=", "Image", ".", "fromarray", "(", "f", ".", "astype", "(", "\"uint8\"", ")", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "cropped_tensors", "=", "None", "\n", "height", ",", "width", ",", "c", "=", "f", ".", "shape", "\n", "bounding_box", ",", "prob", "=", "mtcnn", ".", "detect", "(", "frame", ")", "\n", "\n", "if", "bounding_box", "is", "not", "None", ":", "\n", "                ", "for", "box", "in", "bounding_box", ":", "\n", "                    ", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "box", "\n", "if", "x1", ">", "x2", ":", "\n", "                        ", "x1", ",", "x2", "=", "x2", ",", "x1", "\n", "", "if", "y1", ">", "y2", ":", "\n", "                        ", "y1", ",", "y2", "=", "y2", ",", "y1", "\n", "\n", "# for point in coord:", "\n", "", "x", ",", "y", "=", "coord", "[", "0", "]", ",", "coord", "[", "1", "]", "\n", "x", "*=", "width", "\n", "y", "*=", "height", "\n", "if", "x", ">=", "x1", "and", "y", ">=", "y1", "and", "x", "<=", "x2", "and", "y", "<=", "y2", ":", "\n", "                        ", "cropped_tensors", "=", "extract_face", "(", "frame", ",", "box", ")", "\n", "# print(\"found\", box, x, y, end='\\r')", "\n", "break", "\n", "\n", "", "", "", "", "if", "cropped_tensors", "is", "None", ":", "\n", "# Face not detected, for some reason", "\n", "            ", "cropped_tensors", "=", "torch", ".", "zeros", "(", "(", "3", ",", "160", ",", "160", ")", ")", "\n", "no_face_indices", ".", "append", "(", "i", ")", "\n", "\n", "", "if", "save_frames", ":", "\n", "            ", "name", "=", "name", ".", "replace", "(", "\".mp4\"", ",", "\"\"", ")", "\n", "saveimg", "=", "cropped_tensors", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "\"uint8\"", ")", "\n", "saveimg", "=", "np", ".", "squeeze", "(", "saveimg", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "Image", ".", "fromarray", "(", "saveimg", ")", ".", "save", "(", "f\"{name}_{i}.png\"", ")", "\n", "\n", "", "result_cropped_tensors", ".", "append", "(", "cropped_tensors", ".", "to", "(", "device", ")", ")", "\n", "\n", "", "if", "len", "(", "no_face_indices", ")", ">", "20", ":", "\n", "# few videos start with silence, allow 0.5 seconds of silence else remove", "\n", "        ", "return", "None", "\n", "", "del", "frames", "\n", "# Stack all frames", "\n", "result_cropped_tensors", "=", "torch", ".", "stack", "(", "result_cropped_tensors", ")", "\n", "# Embed all frames", "\n", "result_cropped_tensors", "=", "result_cropped_tensors", ".", "to", "(", "device", ")", "\n", "if", "use_half", ":", "\n", "        ", "result_cropped_tensors", "=", "result_cropped_tensors", ".", "half", "(", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "emb", "=", "resnet", "(", "result_cropped_tensors", ")", "\n", "", "if", "use_half", ":", "\n", "        ", "emb", "=", "emb", ".", "float", "(", ")", "\n", "", "return", "emb", ".", "to", "(", "cpu_device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.generate_video_embedding._get_video": [[16, 23], ["df[].values.reshape().tolist", "sorted", "set", "list", "df[].values.reshape"], "function", ["None"], ["def", "_get_video", "(", "df", ")", ":", "\n", "    ", "video_columns", "=", "[", "i", "for", "i", "in", "list", "(", "df", ")", "if", "\"video\"", "in", "i", "]", "\n", "\n", "video_paths", "=", "df", "[", "video_columns", "]", ".", "values", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "video_paths", "=", "sorted", "(", "set", "(", "video_paths", ")", ",", "key", "=", "video_paths", ".", "index", ")", "\n", "\n", "return", "video_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.generate_video_embedding.store_corrupt": [[25, 28], ["open", "f.write", "path.as_posix"], "function", ["None"], ["", "def", "store_corrupt", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "args", ".", "corrupt_file", ",", "\"a\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "path", ".", "as_posix", "(", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.generate_video_embedding.cache_embed": [[30, 83], ["path.stem.split", "asteroid.data.avspeech_dataset.get_frames", "range", "path.is_file", "len", "generate_video_embedding.store_corrupt", "cv2.VideoCapture", "pathlib.Path", "pathlib.Path.is_file", "frames.input_face_embeddings", "embeddings.append", "numpy.save", "print", "generate_video_embedding.store_corrupt", "path.as_posix", "generate_video_embedding.store_corrupt", "print", "frames.input_face_embeddings.cpu().numpy", "int", "int", "str", "frames.input_face_embeddings.cpu"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.get_frames", "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.generate_video_embedding.store_corrupt", "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.frames.input_face_embeddings", "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.generate_video_embedding.store_corrupt", "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.generate_video_embedding.store_corrupt"], ["", "", "def", "cache_embed", "(", "path", ",", "mtcnn", ",", "resnet", ",", "args", ")", ":", "\n", "    ", "orig_path", "=", "path", "\n", "if", "not", "path", ".", "is_file", "(", ")", ":", "\n", "        ", "path", "=", "\"../..\"", "/", "path", "\n", "", "video_file_name", "=", "path", ".", "stem", ".", "split", "(", "\"_\"", ")", "\n", "\n", "if", "len", "(", "video_file_name", ")", "<", "3", ":", "\n", "        ", "store_corrupt", "(", "orig_path", ")", "\n", "return", "\n", "\n", "", "try", ":", "\n", "        ", "pos_x", ",", "pos_y", "=", "(", "\n", "int", "(", "video_file_name", "[", "-", "3", "]", ")", "/", "10000", ",", "\n", "int", "(", "video_file_name", "[", "-", "2", "]", ")", "/", "10000", ",", "\n", ")", "\n", "", "except", "ValueError", "as", "e", ":", "\n", "        ", "print", "(", "str", "(", "e", ")", ")", "\n", "store_corrupt", "(", "orig_path", ")", "\n", "return", "\n", "\n", "", "video_buffer", "=", "get_frames", "(", "cv2", ".", "VideoCapture", "(", "path", ".", "as_posix", "(", ")", ")", ")", "\n", "total_frames", "=", "video_buffer", ".", "shape", "[", "0", "]", "\n", "\n", "video_parts", "=", "total_frames", "//", "FRAMES", "# (25fps * 3)", "\n", "\n", "embeddings", "=", "[", "]", "\n", "for", "part", "in", "range", "(", "video_parts", ")", ":", "\n", "        ", "frame_name", "=", "path", ".", "stem", "+", "f\"_part{part}\"", "\n", "embed_path", "=", "Path", "(", "args", ".", "embed_dir", ",", "frame_name", "+", "\".npy\"", ")", "\n", "if", "embed_path", ".", "is_file", "(", ")", ":", "\n", "            ", "continue", "\n", "", "raw_frames", "=", "video_buffer", "[", "part", "*", "FRAMES", ":", "(", "part", "+", "1", ")", "*", "FRAMES", "]", "\n", "\n", "embed", "=", "input_face_embeddings", "(", "\n", "raw_frames", ",", "\n", "is_path", "=", "False", ",", "\n", "mtcnn", "=", "mtcnn", ",", "\n", "resnet", "=", "resnet", ",", "\n", "face_embed_cuda", "=", "args", ".", "cuda", ",", "\n", "use_half", "=", "args", ".", "use_half", ",", "\n", "coord", "=", "[", "pos_x", ",", "pos_y", "]", ",", "\n", ")", "\n", "\n", "if", "embed", "is", "None", ":", "\n", "            ", "store_corrupt", "(", "orig_path", ")", "\n", "print", "(", "\"Corrupt\"", ",", "path", ")", "\n", "return", "\n", "\n", "", "embeddings", ".", "append", "(", "(", "embed", ",", "embed_path", ")", ")", "\n", "\n", "# save if all parts are not corrupted", "\n", "", "for", "embed", ",", "embed_path", "in", "embeddings", ":", "\n", "        ", "np", ".", "save", "(", "embed_path", ",", "embed", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.generate_video_embedding.main": [[85, 105], ["pandas.read_csv", "pandas.read_csv", "facenet_pytorch.MTCNN().eval().to", "facenet_pytorch.InceptionResnetV1().eval().to", "generate_video_embedding._get_video", "generate_video_embedding._get_video", "print", "tqdm.tqdm", "torch.cuda.is_available", "torch.device", "torch.device", "generate_video_embedding.cache_embed", "facenet_pytorch.MTCNN().eval", "facenet_pytorch.InceptionResnetV1().eval", "len", "pathlib.Path", "len", "facenet_pytorch.MTCNN", "facenet_pytorch.InceptionResnetV1"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.generate_video_embedding._get_video", "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.generate_video_embedding._get_video", "home.repos.pwc.inspect_result.mpariente_AsSteroid.loader.generate_video_embedding.cache_embed"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "    ", "train_df", "=", "pd", ".", "read_csv", "(", "args", ".", "train_path", ")", "\n", "val_df", "=", "pd", ".", "read_csv", "(", "args", ".", "val_path", ")", "\n", "\n", "if", "args", ".", "cuda", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "", "mtcnn", "=", "MTCNN", "(", "keep_all", "=", "True", ")", ".", "eval", "(", ")", ".", "to", "(", "device", ")", "\n", "mtcnn", ".", "device", "=", "device", "\n", "\n", "resnet", "=", "InceptionResnetV1", "(", "pretrained", "=", "\"vggface2\"", ")", ".", "eval", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "video_paths", "=", "_get_video", "(", "train_df", ")", "\n", "video_paths", "+=", "_get_video", "(", "val_df", ")", "\n", "\n", "print", "(", "f\"Total embeddings: {len(video_paths)}\"", ")", "\n", "for", "path", "in", "tqdm", "(", "video_paths", ",", "total", "=", "len", "(", "video_paths", ")", ")", ":", "\n", "        ", "cache_embed", "(", "Path", "(", "path", ")", ",", "mtcnn", ",", "resnet", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.train.metric_utils.snr": [[8, 26], ["torch.log10"], "function", ["None"], ["def", "snr", "(", "pred_signal", ":", "torch", ".", "Tensor", ",", "true_signal", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "    ", "\"\"\"\n    Calculate the Signal-to-Noise Ratio\n    from two signals\n\n    Args:\n        pred_signal (torch.Tensor): predicted signal spectrogram.\n        true_signal (torch.Tensor): original signal spectrogram.\n\n    \"\"\"", "\n", "inter_signal", "=", "true_signal", "-", "pred_signal", "\n", "\n", "true_power", "=", "(", "true_signal", "**", "2", ")", ".", "sum", "(", ")", "\n", "inter_power", "=", "(", "inter_signal", "**", "2", ")", ".", "sum", "(", ")", "\n", "\n", "snr", "=", "10", "*", "torch", ".", "log10", "(", "true_power", "/", "inter_power", ")", "\n", "\n", "return", "snr", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.train.metric_utils.sdr": [[28, 49], ["numpy.zeros", "numpy.zeros", "range", "mir_eval.separation.bss_eval_sources", "asteroid.data.avspeech_dataset.AVSpeechDataset.decode().numpy", "asteroid.data.avspeech_dataset.AVSpeechDataset.decode().numpy", "asteroid.data.avspeech_dataset.AVSpeechDataset.decode", "asteroid.data.avspeech_dataset.AVSpeechDataset.decode"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.AVSpeechDataset.decode", "home.repos.pwc.inspect_result.mpariente_AsSteroid.data.avspeech_dataset.AVSpeechDataset.decode"], ["", "def", "sdr", "(", "pred_signal", ":", "torch", ".", "Tensor", ",", "true_signal", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "    ", "\"\"\"\n    Calculate the Signal-to-Distortion Ratio\n    from two signals\n\n    Args:\n        pred_signal (torch.Tensor): predicted signal spectrogram.\n        true_signal (torch.Tensor): original signal spectrogram.\n\n    \"\"\"", "\n", "n_sources", "=", "pred_signal", ".", "shape", "[", "0", "]", "\n", "\n", "y_pred_wav", "=", "np", ".", "zeros", "(", "(", "n_sources", ",", "48_000", ")", ")", "\n", "y_wav", "=", "np", ".", "zeros", "(", "(", "n_sources", ",", "48_000", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_sources", ")", ":", "\n", "        ", "y_pred_wav", "[", "i", "]", "=", "AVSpeechDataset", ".", "decode", "(", "pred_signal", "[", "i", ",", "...", "]", ")", ".", "numpy", "(", ")", "\n", "y_wav", "[", "i", "]", "=", "AVSpeechDataset", ".", "decode", "(", "true_signal", "[", "i", ",", "...", "]", ")", ".", "numpy", "(", ")", "\n", "", "sdr", ",", "sir", ",", "sar", ",", "_", "=", "mir_eval", ".", "separation", ".", "bss_eval_sources", "(", "y_wav", ",", "y_pred_wav", ")", "\n", "\n", "return", "sdr", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.train.config.ParamConfig.__init__": [[3, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "batch_size", ",", "epochs", ",", "workers", ",", "cuda", ",", "use_half", ",", "learning_rate", ")", ":", "\n", "        ", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "epochs", "=", "epochs", "\n", "self", ".", "workers", "=", "workers", "\n", "self", ".", "cuda", "=", "cuda", "\n", "self", ".", "use_half", "=", "use_half", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.train.trainer.train": [[15, 81], ["collections.OrderedDict", "catalyst.dl.utils.get_loader", "catalyst.dl.utils.get_loader", "torch.optim.lr_scheduler.CyclicLR", "catalyst.dl.runner.SupervisedRunner", "catalyst.dl.runner.SupervisedRunner.train", "collections.OrderedDict", "len", "catalyst.dl.callbacks.checkpoint.IterationCheckpointCallback", "train.SNRCallback", "catalyst.dl.callbacks.scheduler.SchedulerCallback"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.train.trainer.train"], ["def", "train", "(", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "dataset", ":", "torch", ".", "utils", ".", "data", ".", "Dataset", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "criterion", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "config", ":", "ParamConfig", ",", "\n", "val_dataset", ":", "torch", ".", "utils", ".", "data", ".", "Dataset", "=", "None", ",", "\n", "logdir", ":", "str", "=", "\"./logdir\"", ",", "\n", "resume", ":", "Union", "[", "str", ",", "None", "]", "=", "\"logdir/checkpoints/best_full.pth\"", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    train the model with specified paremeters\n    Args:\n        model: neural network model\n        dataset: training dataset\n        optimizer: optimizer\n        criterion: loss function\n        val_dataset: validation dataset\n        logdir: logdir location to save checkpoints\n        resume: path where the partially trained model is stored\n    \"\"\"", "\n", "\n", "loaders", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "train_loader", "=", "utils", ".", "get_loader", "(", "\n", "dataset", ",", "\n", "open_fn", "=", "lambda", "x", ":", "{", "\"input_audio\"", ":", "x", "[", "-", "1", "]", ",", "\"input_video\"", ":", "x", "[", "1", "]", ",", "\"targets\"", ":", "x", "[", "0", "]", "}", ",", "\n", "batch_size", "=", "config", ".", "batch_size", ",", "\n", "num_workers", "=", "config", ".", "workers", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "utils", ".", "get_loader", "(", "\n", "val_dataset", ",", "\n", "open_fn", "=", "lambda", "x", ":", "{", "\"input_audio\"", ":", "x", "[", "-", "1", "]", ",", "\"input_video\"", ":", "x", "[", "1", "]", ",", "\"targets\"", ":", "x", "[", "0", "]", "}", ",", "\n", "batch_size", "=", "config", ".", "batch_size", ",", "\n", "num_workers", "=", "config", ".", "workers", ",", "\n", "shuffle", "=", "True", ",", "\n", ")", "\n", "loaders", "=", "{", "\"train\"", ":", "train_loader", ",", "\"valid\"", ":", "val_loader", "}", "\n", "\n", "scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "CyclicLR", "(", "\n", "optimizer", ",", "\n", "base_lr", "=", "config", ".", "learning_rate", ",", "\n", "max_lr", "=", "config", ".", "learning_rate", "*", "10", ",", "\n", "step_size_up", "=", "4", "*", "len", "(", "train_loader", ")", ",", "\n", "mode", "=", "\"triangular\"", ",", "\n", "cycle_momentum", "=", "False", ",", "\n", ")", "\n", "\n", "runner", "=", "SupervisedRunner", "(", "input_key", "=", "[", "\"input_audio\"", ",", "\"input_video\"", "]", ")", "\n", "runner", ".", "train", "(", "\n", "model", "=", "model", ",", "\n", "criterion", "=", "criterion", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "loaders", "=", "loaders", ",", "\n", "logdir", "=", "logdir", ",", "\n", "verbose", "=", "True", ",", "\n", "num_epochs", "=", "config", ".", "epochs", ",", "\n", "resume", "=", "resume", ",", "\n", "callbacks", "=", "collections", ".", "OrderedDict", "(", "\n", "{", "\n", "\"iteration_checkpoint\"", ":", "IterationCheckpointCallback", "(", "\n", "save_n_last", "=", "1", ",", "num_iters", "=", "10_000", "\n", ")", ",", "\n", "\"snr_callback\"", ":", "SNRCallback", "(", ")", ",", "\n", "\"sched_callback\"", ":", "SchedulerCallback", "(", "mode", "=", "\"batch\"", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.train.callbacks.SNRCallback.__init__": [[21, 30], ["catalyst.dl.core.MetricCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_key", ":", "str", "=", "\"targets\"", ",", "\n", "output_key", ":", "str", "=", "\"logits\"", ",", "\n", "prefix", ":", "str", "=", "\"snr\"", ",", "\n", "mixed_audio_key", ":", "str", "=", "\"input_audio\"", ",", "\n", ")", ":", "\n", "        ", "self", ".", "mixed_audio_key", "=", "mixed_audio_key", "\n", "super", "(", ")", ".", "__init__", "(", "prefix", "=", "prefix", ",", "metric_fn", "=", "snr", ",", "input_key", "=", "input_key", ",", "output_key", "=", "output_key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.train.callbacks.SNRCallback.on_batch_end": [[31, 50], ["hasattr", "range", "state.metrics.add_batch_value", "train.snr().item", "train.snr"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.train.metric_utils.snr"], ["", "def", "on_batch_end", "(", "self", ",", "state", ")", ":", "\n", "        ", "output_audios", "=", "state", ".", "output", "[", "self", ".", "output_key", "]", "\n", "true_audios", "=", "state", ".", "input", "[", "self", ".", "input_key", "]", "\n", "\n", "if", "hasattr", "(", "state", ".", "model", ",", "\"module\"", ")", ":", "\n", "            ", "num_person", "=", "state", ".", "model", ".", "module", ".", "num_person", "\n", "", "else", ":", "\n", "            ", "num_person", "=", "state", ".", "model", ".", "num_person", "\n", "\n", "", "avg_snr", "=", "0", "\n", "for", "n", "in", "range", "(", "num_person", ")", ":", "\n", "            ", "output_audio", "=", "output_audios", "[", ":", ",", "n", ",", "...", "]", "\n", "true_audio", "=", "true_audios", "[", ":", ",", "n", ",", "...", "]", "\n", "\n", "snr_value", "=", "snr", "(", "output_audio", ",", "true_audio", ")", ".", "item", "(", ")", "\n", "avg_snr", "+=", "snr_value", "\n", "\n", "", "avg_snr", "/=", "num_person", "\n", "state", ".", "metrics", ".", "add_batch_value", "(", "name", "=", "self", ".", "prefix", ",", "value", "=", "avg_snr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.train.callbacks.SDRCallback.__init__": [[63, 72], ["catalyst.dl.core.MetricCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_key", ":", "str", "=", "\"targets\"", ",", "\n", "output_key", ":", "str", "=", "\"logits\"", ",", "\n", "prefix", ":", "str", "=", "\"sdr\"", ",", "\n", "mixed_audio_key", ":", "str", "=", "\"input_audio\"", ",", "\n", ")", ":", "\n", "        ", "self", ".", "mixed_audio_key", "=", "mixed_audio_key", "\n", "super", "(", ")", ".", "__init__", "(", "prefix", "=", "prefix", ",", "metric_fn", "=", "snr", ",", "input_key", "=", "input_key", ",", "output_key", "=", "output_key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.train.callbacks.SDRCallback.on_batch_end": [[73, 97], ["hasattr", "range", "state.metrics.add_batch_value", "output_audio.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "true_audio.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "train.sdr", "numpy.mean", "output_audio.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "true_audio.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "output_audio.detach().cpu().numpy.detach().cpu().numpy.detach", "true_audio.detach().cpu().numpy.detach().cpu().numpy.detach"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.train.metric_utils.sdr"], ["", "def", "on_batch_end", "(", "self", ",", "state", ")", ":", "\n", "        ", "output_audios", "=", "state", ".", "output", "[", "self", ".", "output_key", "]", "\n", "true_audios", "=", "state", ".", "input", "[", "self", ".", "input_key", "]", "\n", "\n", "if", "hasattr", "(", "state", ".", "model", ",", "\"module\"", ")", ":", "\n", "            ", "num_person", "=", "state", ".", "model", ".", "module", ".", "num_person", "\n", "", "else", ":", "\n", "            ", "num_person", "=", "state", ".", "model", ".", "num_person", "\n", "\n", "", "batch", "=", "output_audios", ".", "shape", "[", "0", "]", "\n", "avg_sdr", "=", "0", "\n", "for", "n", "in", "range", "(", "batch", ")", ":", "\n", "            ", "output_audio", "=", "output_audios", "[", "n", ",", "...", "]", "\n", "true_audio", "=", "true_audios", "[", "n", ",", "...", "]", "\n", "\n", "output_audio", "=", "output_audio", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "true_audio", "=", "true_audio", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "sdr_value", "=", "sdr", "(", "output_audio", ",", "true_audio", ")", "\n", "sdr_value", "=", "np", ".", "mean", "(", "sdr_value", ")", "\n", "avg_sdr", "+=", "sdr_value", "\n", "\n", "", "avg_sdr", "/=", "batch", "\n", "state", ".", "metrics", ".", "add_batch_value", "(", "name", "=", "self", ".", "prefix", ",", "value", "=", "avg_sdr", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.FilterbankDesign.train.main": [[18, 90], ["asteroid.data.wham_dataset.WhamDataset", "asteroid.data.wham_dataset.WhamDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "conf[].update", "model.make_model_and_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "asteroid.engine.system.System", "pytorch_lightning.Trainer", "pl.Trainer.fit", "open", "yaml.safe_dump", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer"], ["parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--exp_dir\"", ",", "default", "=", "\"exp/tmp\"", ",", "help", "=", "\"Full path to save best validation model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--is_complex\"", ",", "default", "=", "True", ",", "type", "=", "str2bool_arg", ")", "\n", "\n", "\n", "def", "main", "(", "conf", ")", ":", "\n", "    ", "total_set", "=", "DNSDataset", "(", "conf", "[", "\"data\"", "]", "[", "\"json_dir\"", "]", ")", "\n", "train_len", "=", "int", "(", "len", "(", "total_set", ")", "*", "(", "1", "-", "conf", "[", "\"data\"", "]", "[", "\"val_prop\"", "]", ")", ")", "\n", "val_len", "=", "len", "(", "total_set", ")", "-", "train_len", "\n", "train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.FilterbankDesign.model.Model.__init__": [[9, 16], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["from", "asteroid_filterbanks", ".", "transforms", "import", "magreim", ",", "mag", "\n", "from", "asteroid_filterbanks", ".", "transforms", "import", "apply_real_mask", "\n", "from", "asteroid_filterbanks", ".", "transforms", "import", "apply_mag_mask", "\n", "from", "asteroid", ".", "masknn", ".", "recurrent", "import", "StackedResidualRNN", "\n", "from", "asteroid", ".", "engine", ".", "optimizers", "import", "make_optimizer", "\n", "from", "asteroid", "import", "torch_utils", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.FilterbankDesign.model.Model.forward": [[17, 32], ["model.Model.encoder", "model.Model.masker", "model.Model.encoder.apply_mask", "model.Model.pad_output_to_inp", "len", "x.unsqueeze.unsqueeze.unsqueeze", "model.Model.unsqueeze", "model.Model.decoder"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.Model.pad_output_to_inp"], ["def", "make_model_and_optimizer", "(", "conf", ")", ":", "\n", "    ", "\"\"\"Function to define the model and optimizer for a config dictionary.\n    Args:\n        conf: Dictionary containing the output of hierachical argparse.\n    Returns:\n        model, optimizer.\n    The main goal of this function is to make reloading for resuming\n    and evaluation very simple.\n    \"\"\"", "\n", "# Define building blocks for local model", "\n", "stft", ",", "istft", "=", "make_enc_dec", "(", "\"stft\"", ",", "**", "conf", "[", "\"filterbank\"", "]", ")", "\n", "# Because we concatenate (re, im, mag) as input and compute a complex mask.", "\n", "if", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ":", "\n", "        ", "inp_size", "=", "int", "(", "stft", ".", "n_feats_out", "*", "3", "/", "2", ")", "\n", "output_size", "=", "stft", ".", "n_feats_out", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.FilterbankDesign.model.Model.pad_output_to_inp": [[33, 39], ["inp.size", "output.size", "torch.nn.functional.pad"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad"], ["        ", "inp_size", "=", "output_size", "=", "int", "(", "stft", ".", "n_feats_out", "/", "2", ")", "\n", "# Add these fields to the mask model dict", "\n", "", "conf", "[", "\"masknet\"", "]", ".", "update", "(", "dict", "(", "input_size", "=", "inp_size", ",", "output_size", "=", "output_size", ")", ")", "\n", "masker", "=", "SimpleModel", "(", "**", "conf", "[", "\"masknet\"", "]", ")", "\n", "# Make the complete model", "\n", "model", "=", "Model", "(", "stft", ",", "masker", ",", "istft", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "# Define optimizer of this model", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.FilterbankDesign.model.make_model_and_optimizer": [[41, 69], ["asteroid_filterbanks.make_enc_dec", "int", "int", "asteroid.masknn.TDConvNet", "model.Model", "asteroid.engine.optimizers.make_optimizer", "Model.parameters"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer"], ["return", "model", ",", "optimizer", "\n", "\n", "\n", "", "class", "Model", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Speech enhancement model.\n\n    Args:\n        encoder (~.Encoder): instance of a complex filterbank encoder\n            `Encoder(STFTBFB(**))`.\n        masker (nn.Module): Mask estimator network.\n        decoder (~.Decoder): instance of a complex filterbank decoder\n            `Decoder(STFTBFB(**))`.\n        is_complex (bool): If the network works on the complex domain.\n\n    If `is_complex` is `True`, the input to the network are complex features,\n    the network estimates a complex mask and returns a complex speech estimate.\n    Else, the input is the magnitude, the network estimates a magnitude mask\n    and the returns a **complex** speech estimate.\n    The loss function needs to be adapted to complex representations.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "encoder", ",", "masker", ",", "decoder", ",", "is_complex", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "masker", "=", "masker", "\n", "# Decoder is not used for training but eventually, we want to invert", "\n", "# the encoder. Might as well include it in the model.", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "is_complex", "=", "is_complex", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.eval.main": [[40, 114], ["model.load_best_model", "asteroid.data.wham_dataset.WhamDataset", "asteroid.losses.PITLossWrapper", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "model.load_best_model.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "model.load_best_model.", "asteroid.losses.PITLossWrapper.", "mix[].cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "open", "json.dump", "model.load_best_model.parameters", "len", "torch.no_grad", "len", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "os.path.join", "soundfile.write", "soundfile.write", "open", "json.dump", "mix[].cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.load_best_model", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics"], ["", "model_device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "test_set", "=", "KinectWsjMixDataset", "(", "conf", "[", "\"test_dir\"", "]", ",", "n_src", "=", "conf", "[", "\"n_src\"", "]", ",", "segment", "=", "None", ")", "\n", "# Used to reorder sources only", "\n", "loss_func", "=", "PITLossWrapper", "(", "pairwise_neg_sisdr", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "\n", "# Randomly choose the indexes of sentences to save.", "\n", "ex_save_dir", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"examples/\"", ")", "\n", "if", "conf", "[", "\"n_save_ex\"", "]", "==", "-", "1", ":", "\n", "        ", "conf", "[", "\"n_save_ex\"", "]", "=", "len", "(", "test_set", ")", "\n", "", "save_idx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "test_set", ")", ")", ",", "conf", "[", "\"n_save_ex\"", "]", ")", "\n", "series_list", "=", "[", "]", "\n", "torch", ".", "no_grad", "(", ")", ".", "__enter__", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "test_set", ")", ")", ")", ":", "\n", "# Forward the network on the mixture.", "\n", "        ", "mix", ",", "sources", ",", "noises", "=", "tensors_to_device", "(", "test_set", "[", "idx", "]", ",", "device", "=", "model_device", ")", "\n", "mix", "=", "mix", "[", "...", ",", "0", "]", "\n", "sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "utt_metrics", "=", "get_metrics", "(", "\n", "mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.train.main": [[31, 126], ["asteroid.data.wham_dataset.WhamDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "conf[].update", "model.make_model_and_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "asteroid.engine.system.System", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "AugmentedWhamDataset", "asteroid.data.wham_dataset.WhamDataset", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer"], ["shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.Model.__init__": [[13, 18], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["from", "asteroid", ".", "engine", ".", "optimizers", "import", "make_optimizer", "\n", "from", "asteroid", "import", "torch_utils", "\n", "\n", "\n", "def", "make_model_and_optimizer", "(", "conf", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.Model.forward": [[19, 26], ["model.Model.encoder", "model.Model.masker", "model.Model.pad_output_to_inp", "len", "x.unsqueeze.unsqueeze.unsqueeze", "model.Model.unsqueeze", "model.Model.decoder"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.Model.pad_output_to_inp"], ["\n", "# Define building blocks for local model", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.Model.pad_output_to_inp": [[27, 33], ["inp.size", "output.size", "torch.nn.functional.pad"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.sudormrf.pad"], ["stft", ",", "istft", "=", "make_enc_dec", "(", "\"stft\"", ",", "**", "conf", "[", "\"filterbank\"", "]", ")", "\n", "# Because we concatenate (re, im, mag) as input and compute a complex mask.", "\n", "if", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ":", "\n", "        ", "inp_size", "=", "int", "(", "stft", ".", "n_feats_out", "*", "3", "/", "2", ")", "\n", "output_size", "=", "stft", ".", "n_feats_out", "\n", "", "else", ":", "\n", "        ", "inp_size", "=", "output_size", "=", "int", "(", "stft", ".", "n_feats_out", "/", "2", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.make_model_and_optimizer": [[35, 51], ["asteroid_filterbanks.make_enc_dec", "asteroid.masknn.DPRNN", "model.Model", "asteroid.engine.optimizers.make_optimizer", "Model.parameters"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer"], ["", "conf", "[", "\"masknet\"", "]", ".", "update", "(", "dict", "(", "input_size", "=", "inp_size", ",", "output_size", "=", "output_size", ")", ")", "\n", "masker", "=", "SimpleModel", "(", "**", "conf", "[", "\"masknet\"", "]", ")", "\n", "# Make the complete model", "\n", "model", "=", "Model", "(", "stft", ",", "masker", ",", "istft", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "# Define optimizer of this model", "\n", "optimizer", "=", "make_optimizer", "(", "model", ".", "parameters", "(", ")", ",", "**", "conf", "[", "\"optim\"", "]", ")", "\n", "return", "model", ",", "optimizer", "\n", "\n", "\n", "", "class", "Model", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DynamicMixing.model.load_best_model": [[53, 76], ["model.make_model_and_optimizer", "min", "torch.load", "asteroid.torch_utils.load_state_dict_in", "torch_utils.load_state_dict_in.eval", "open", "json.load", "os.path.join"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.load_state_dict_in"], ["\n", "\n", "def", "__init__", "(", "self", ",", "encoder", ",", "masker", ",", "decoder", ",", "is_complex", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "masker", "=", "masker", "\n", "# Decoder is not used for training but eventually, we want to invert", "\n", "# the encoder. Might as well include it in the model.", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "is_complex", "=", "is_complex", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "len", "(", "x", ".", "shape", ")", "==", "2", ":", "\n", "            ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "# Compute STFT", "\n", "", "tf_rep", "=", "self", ".", "encoder", "(", "x", ")", "\n", "# Estimate TF mask from STFT features : cat([re, im, mag])", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DPTNet.eval.main": [[70, 182], ["eval.update_compute_metrics", "pandas.read_csv", "os.path.join", "asteroid.DPTNet.from_pretrained", "asteroid.data.librimix_dataset.LibriMix", "asteroid.losses.PITLossWrapper", "os.path.join", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "torch.load", "os.makedirs", "asteroid.models.save_publishable", "asteroid.metrics.MockWERTracker", "asteroid.metrics.WERTracker", "DPTNet.from_pretrained.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "DPTNet.from_pretrained.", "asteroid.losses.PITLossWrapper.", "mix.cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "asteroid.dsp.normalization.normalize_estimates", "asteroid.metrics.get_metrics.update", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "print", "wer_tracker.final_report_as_markdown", "print", "open", "json.dump", "os.path.join", "os.path.join", "DPTNet.from_pretrained.parameters", "len", "torch.no_grad", "len", "mix.unsqueeze", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "open", "f.write", "os.path.join", "wer_tracker", "soundfile.write", "soundfile.write", "open", "json.dump", "os.path.join", "mix.cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "pathlib.Path", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DCUNet.eval.update_compute_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.normalization.normalize_estimates", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.final_report_as_markdown"], ["mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ")", "as", "f", ":", "\n", "        ", "train_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "arg_dic", "[", "\"sample_rate\"", "]", "=", "train_conf", "[", "\"data\"", "]", "[", "\"sample_rate\"", "]", "\n", "arg_dic", "[", "\"train_conf\"", "]", "=", "train_conf", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DPTNet.train.main": [[27, 119], ["asteroid.data.LibriMix", "asteroid.data.LibriMix", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "conf[].update", "asteroid.models.DPTNet", "asteroid.engine.optimizers.make_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "asteroid.engine.system.System", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "asteroid.engine.system.System.load_state_dict", "asteroid.engine.system.System.cpu", "asteroid.engine.system.System.model.serialize", "system.model.serialize.update", "torch.save", "asteroid.models.DPTNet.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "asteroid.data.LibriMix.get_infos", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], ["train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DPTNet.eval.update_compute_metrics": [[56, 68], ["warnings.warn"], "function", ["None"], ["sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.ConvTasNet.eval.main": [[70, 184], ["eval.update_compute_metrics", "pandas.read_csv", "os.path.join", "asteroid.ConvTasNet.from_pretrained", "asteroid.data.librimix_dataset.LibriMix", "asteroid.losses.PITLossWrapper", "os.path.join", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "torch.load", "os.makedirs", "asteroid.models.save_publishable", "asteroid.metrics.MockWERTracker", "asteroid.metrics.WERTracker", "ConvTasNet.from_pretrained.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "ConvTasNet.from_pretrained.", "asteroid.losses.PITLossWrapper.", "mix.cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "asteroid.dsp.normalization.normalize_estimates", "asteroid.metrics.get_metrics.update", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "print", "wer_tracker.final_report_as_markdown", "print", "open", "json.dump", "os.path.join", "os.path.join", "ConvTasNet.from_pretrained.parameters", "len", "torch.no_grad", "len", "mix.unsqueeze", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "open", "f.write", "os.path.join", "wer_tracker", "soundfile.write", "soundfile.write", "open", "json.dump", "os.path.join", "mix.cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "pathlib.Path", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DCUNet.eval.update_compute_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.normalization.normalize_estimates", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.final_report_as_markdown"], ["mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ")", "as", "f", ":", "\n", "        ", "train_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "arg_dic", "[", "\"sample_rate\"", "]", "=", "train_conf", "[", "\"data\"", "]", "[", "\"sample_rate\"", "]", "\n", "arg_dic", "[", "\"train_conf\"", "]", "=", "train_conf", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.ConvTasNet.train.main": [[27, 121], ["asteroid.data.LibriMix", "asteroid.data.LibriMix", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "conf[].update", "asteroid.models.ConvTasNet", "asteroid.engine.optimizers.make_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "asteroid.engine.system.System", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "asteroid.engine.system.System.load_state_dict", "asteroid.engine.system.System.cpu", "asteroid.engine.system.System.model.serialize", "system.model.serialize.update", "torch.save", "asteroid.models.ConvTasNet.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "asteroid.data.LibriMix.get_infos", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], ["train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.ConvTasNet.eval.split_metric_dict": [[147, 162], ["dict", "dic.items", "isinstance", "float", "float", "float", "v.mean"], "function", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.ConvTasNet.train.Combine_Loss.__init__": [[133, 138], ["super().__init__", "asteroid.losses.SingleSrcNegSTOI", "torch.nn.L1Loss"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.ConvTasNet.train.Combine_Loss.forward": [[139, 145], ["train.Combine_Loss.loss_vocal", "train.Combine_Loss.loss_background", "torch.mean"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.ConvTasNet.eval.update_compute_metrics": [[56, 68], ["warnings.warn"], "function", ["None"], ["sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DPRNN.eval.main": [[41, 123], ["os.path.join", "asteroid.DPRNNTasNet.from_pretrained", "asteroid.data.wham_dataset.WhamDataset", "asteroid.losses.PITLossWrapper", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "torch.load", "asteroid.models.save_publishable", "DPRNNTasNet.from_pretrained.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "DPRNNTasNet.from_pretrained.", "asteroid.losses.PITLossWrapper.", "mix[].cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "open", "json.dump", "os.path.join", "DPRNNTasNet.from_pretrained.parameters", "len", "torch.no_grad", "len", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "os.path.join", "soundfile.write", "soundfile.write", "open", "json.dump", "mix[].cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics"], ["test_set", "=", "KinectWsjMixDataset", "(", "conf", "[", "\"test_dir\"", "]", ",", "n_src", "=", "conf", "[", "\"n_src\"", "]", ",", "segment", "=", "None", ")", "\n", "# Used to reorder sources only", "\n", "loss_func", "=", "PITLossWrapper", "(", "pairwise_neg_sisdr", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "\n", "# Randomly choose the indexes of sentences to save.", "\n", "ex_save_dir", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"examples/\"", ")", "\n", "if", "conf", "[", "\"n_save_ex\"", "]", "==", "-", "1", ":", "\n", "        ", "conf", "[", "\"n_save_ex\"", "]", "=", "len", "(", "test_set", ")", "\n", "", "save_idx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "test_set", ")", ")", ",", "conf", "[", "\"n_save_ex\"", "]", ")", "\n", "series_list", "=", "[", "]", "\n", "torch", ".", "no_grad", "(", ")", ".", "__enter__", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "test_set", ")", ")", ")", ":", "\n", "# Forward the network on the mixture.", "\n", "        ", "mix", ",", "sources", ",", "noises", "=", "tensors_to_device", "(", "test_set", "[", "idx", "]", ",", "device", "=", "model_device", ")", "\n", "mix", "=", "mix", "[", "...", ",", "0", "]", "\n", "sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "utt_metrics", "=", "get_metrics", "(", "\n", "mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ")", "as", "f", ":", "\n", "        ", "train_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "arg_dic", "[", "\"sample_rate\"", "]", "=", "train_conf", "[", "\"data\"", "]", "[", "\"sample_rate\"", "]", "\n", "arg_dic", "[", "\"train_conf\"", "]", "=", "train_conf", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DPRNN.train.main": [[27, 118], ["asteroid.data.wham_dataset.WhamDataset", "asteroid.data.wham_dataset.WhamDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "conf[].update", "asteroid.DPRNNTasNet", "asteroid.engine.optimizers.make_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "asteroid.engine.system.System", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "asteroid.engine.system.System.load_state_dict", "asteroid.engine.system.System.cpu", "asteroid.engine.system.System.model.serialize", "system.model.serialize.update", "torch.save", "asteroid.DPRNNTasNet.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "asteroid.data.wham_dataset.WhamDataset.get_infos", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], ["train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.MixIT.eval.main": [[42, 131], ["os.path.join", "asteroid.models.DPRNNTasNet.from_pretrained", "asteroid.data.wham_dataset.WhamDataset", "asteroid.losses.PITLossWrapper", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "torch.load", "os.makedirs", "asteroid.models.save_publishable", "DPRNNTasNet.from_pretrained.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "DPRNNTasNet.from_pretrained.", "torch.sort", "est_sources.gather.gather", "asteroid.losses.PITLossWrapper.", "mix[].cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "open", "json.dump", "os.path.join", "os.path.join", "DPRNNTasNet.from_pretrained.parameters", "len", "torch.no_grad", "len", "torch.sqrt", "indxs.unsqueeze().repeat", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "os.path.join", "torch.mean", "soundfile.write", "soundfile.write", "open", "json.dump", "indxs.unsqueeze", "mix[].cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "numpy.max", "numpy.max", "numpy.abs", "numpy.abs", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics"], ["# Used to reorder sources only", "\n", "loss_func", "=", "PITLossWrapper", "(", "pairwise_neg_sisdr", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "\n", "# Randomly choose the indexes of sentences to save.", "\n", "ex_save_dir", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"examples/\"", ")", "\n", "if", "conf", "[", "\"n_save_ex\"", "]", "==", "-", "1", ":", "\n", "        ", "conf", "[", "\"n_save_ex\"", "]", "=", "len", "(", "test_set", ")", "\n", "", "save_idx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "test_set", ")", ")", ",", "conf", "[", "\"n_save_ex\"", "]", ")", "\n", "series_list", "=", "[", "]", "\n", "torch", ".", "no_grad", "(", ")", ".", "__enter__", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "test_set", ")", ")", ")", ":", "\n", "# Forward the network on the mixture.", "\n", "        ", "mix", ",", "sources", ",", "noises", "=", "tensors_to_device", "(", "test_set", "[", "idx", "]", ",", "device", "=", "model_device", ")", "\n", "mix", "=", "mix", "[", "...", ",", "0", "]", "\n", "sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "utt_metrics", "=", "get_metrics", "(", "\n", "mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ")", "as", "f", ":", "\n", "        ", "train_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "arg_dic", "[", "\"sample_rate\"", "]", "=", "train_conf", "[", "\"data\"", "]", "[", "\"sample_rate\"", "]", "\n", "arg_dic", "[", "\"train_conf\"", "]", "=", "train_conf", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.MixIT.train.MixITSystem.training_step": [[29, 49], ["train.MixITSystem.", "torch.stack().transpose", "torch.no_grad", "torch.cat", "torch.stack"], "methods", ["None"], ["train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.MixIT.train.MixITSystem.validation_step": [[50, 62], ["train.MixITSystem.", "torch.sort", "est_sources.gather.gather.gather", "torch.sqrt", "indxs.unsqueeze().repeat", "torch.mean", "indxs.unsqueeze"], "methods", ["None"], ["if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.MixIT.train.main": [[64, 162], ["asteroid.data.wham_dataset.WhamDataset", "asteroid.data.wham_dataset.WhamDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "asteroid.DPRNNTasNet", "asteroid.engine.optimizers.make_optimizer", "os.makedirs", "os.path.join", "train.MixITSystem", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "MixITSystem.load_state_dict", "MixITSystem.cpu", "MixITSystem.model.serialize", "system.model.serialize.update", "torch.save", "asteroid.DPRNNTasNet.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "asteroid.losses.PITLossWrapper", "asteroid.losses.MixITLossWrapper", "callbacks.append", "v.item", "open", "json.dump", "asteroid.data.wham_dataset.WhamDataset.get_infos", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], ["optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.eval.main": [[40, 123], ["model.load_best_separator_if_available", "asteroid.data.wham_dataset.WhamDataset", "asteroid.losses.PITLossWrapper", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "model.load_best_separator_if_available.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "model.load_best_separator_if_available.", "min", "asteroid.losses.PITLossWrapper.", "mix[].cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "open", "json.dump", "model.load_best_separator_if_available.parameters", "len", "torch.no_grad", "len", "mix.unsqueeze", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "os.path.join", "soundfile.write", "soundfile.write", "open", "json.dump", "mix[].cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.load_best_separator_if_available", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics"], ["", "model_device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "\n", "test_set", "=", "KinectWsjMixDataset", "(", "conf", "[", "\"test_dir\"", "]", ",", "n_src", "=", "conf", "[", "\"n_src\"", "]", ",", "segment", "=", "None", ")", "\n", "# Used to reorder sources only", "\n", "loss_func", "=", "PITLossWrapper", "(", "pairwise_neg_sisdr", ",", "pit_from", "=", "\"pw_mtx\"", ")", "\n", "\n", "# Randomly choose the indexes of sentences to save.", "\n", "ex_save_dir", "=", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"examples/\"", ")", "\n", "if", "conf", "[", "\"n_save_ex\"", "]", "==", "-", "1", ":", "\n", "        ", "conf", "[", "\"n_save_ex\"", "]", "=", "len", "(", "test_set", ")", "\n", "", "save_idx", "=", "random", ".", "sample", "(", "range", "(", "len", "(", "test_set", ")", ")", ",", "conf", "[", "\"n_save_ex\"", "]", ")", "\n", "series_list", "=", "[", "]", "\n", "torch", ".", "no_grad", "(", ")", ".", "__enter__", "(", ")", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "test_set", ")", ")", ")", ":", "\n", "# Forward the network on the mixture.", "\n", "        ", "mix", ",", "sources", ",", "noises", "=", "tensors_to_device", "(", "test_set", "[", "idx", "]", ",", "device", "=", "model_device", ")", "\n", "mix", "=", "mix", "[", "...", ",", "0", "]", "\n", "sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "utt_metrics", "=", "get_metrics", "(", "\n", "mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ")", "as", "f", ":", "\n", "        ", "train_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "arg_dic", "[", "\"sample_rate\"", "]", "=", "train_conf", "[", "\"data\"", "]", "[", "\"sample_rate\"", "]", "\n", "arg_dic", "[", "\"train_conf\"", "]", "=", "train_conf", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.train.get_data_loaders": [[31, 68], ["asteroid.data.wham_dataset.WhamDataset", "asteroid.data.wham_dataset.WhamDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "conf[].update", "ValueError"], "function", ["None"], ["shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.train.train_model_part": [[70, 127], ["train.get_data_loaders", "model.make_model_and_optimizer", "model.get_encoded_paths", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "system.SystemTwoStep", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "asteroid.losses.PairwiseNegSDR", "callbacks.append", "open", "json.dump", "pytorch_lightning.callbacks.EarlyStopping", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.train.get_data_loaders", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.get_encoded_paths"], ["\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.train.main": [[129, 146], ["model.load_best_filterbank_if_available", "model.get_encoded_paths", "train.train_model_part", "print", "train.train_model_part", "model.load_best_filterbank_if_available", "print", "print", "train.train_model_part", "model.load_best_filterbank_if_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.load_best_filterbank_if_available", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.get_encoded_paths", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.train.train_model_part", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.train.train_model_part", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.load_best_filterbank_if_available", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.train.train_model_part", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.load_best_filterbank_if_available"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.__init__": [[35, 61], ["asteroid.engine.system.System.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["\n", "\n", "default_monitor", ":", "str", "=", "\"val_loss\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "optimizer", ",", "\n", "loss_func", ",", "\n", "train_loader", ",", "\n", "val_loader", "=", "None", ",", "\n", "scheduler", "=", "None", ",", "\n", "config", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "loss_func", "=", "loss_func", "\n", "self", ".", "train_loader", "=", "train_loader", "\n", "self", ".", "val_loader", "=", "val_loader", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.common_step": [[62, 120], ["system.SystemTwoStep.", "system.SystemTwoStep.mean", "true_sources_time.mean", "system.SystemTwoStep.loss_func", "system.SystemTwoStep.model.get_ideal_latent_targets", "system.SystemTwoStep.model.estimate_latent_representations", "system.SystemTwoStep.loss_func", "system.SystemTwoStep.model", "system.SystemTwoStep.mean", "true_sources_time.mean", "system.SystemTwoStep.loss_func", "system.SystemTwoStep.view", "system.SystemTwoStep.view"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.Model.get_ideal_latent_targets", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.Model.estimate_latent_representations"], ["self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "config", "=", "{", "}", "if", "config", "is", "None", "else", "config", "\n", "# Save lightning's AttributeDict under self.hparams", "\n", "self", ".", "save_hyperparameters", "(", "self", ".", "config_to_hparams", "(", "self", ".", "config", ")", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Applies forward pass of the model.\n\n        Returns:\n            :class:`torch.Tensor`\n        \"\"\"", "\n", "return", "self", ".", "model", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "def", "common_step", "(", "self", ",", "batch", ",", "batch_nb", ",", "train", "=", "True", ")", ":", "\n", "        ", "\"\"\"Common forward step between training and validation.\n\n        The function of this method is to unpack the data given by the loader,\n        forward the batch through the model and compute the loss.\n        Pytorch-lightning handles all the rest.\n\n        Args:\n            batch: the object returned by the loader (a list of torch.Tensor\n                in most cases) but can be something else.\n            batch_nb (int): The number of the batch in the epoch.\n            train (bool): Whether in training mode. Needed only if the training\n                and validation steps are fundamentally different, otherwise,\n                pytorch-lightning handles the usual differences.\n\n        Returns:\n            :class:`torch.Tensor` : The loss value on this batch.\n\n        .. note::\n            This is typically the method to overwrite when subclassing\n            ``System``. If the training and validation steps are somehow\n            different (except for ``loss.backward()`` and ``optimzer.step()``),\n            the argument ``train`` can be used to switch behavior.\n            Otherwise, ``training_step`` and ``validation_step`` can be overwriten.\n        \"\"\"", "\n", "inputs", ",", "targets", "=", "batch", "\n", "est_targets", "=", "self", "(", "inputs", ")", "\n", "loss", "=", "self", ".", "loss_func", "(", "est_targets", ",", "targets", ")", "\n", "return", "loss", "\n", "\n", "", "def", "training_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "\"\"\"Pass data through the model and compute the loss.\n\n        Backprop is **not** performed (meaning PL will do it for you).\n\n        Args:\n            batch: the object returned by the loader (a list of torch.Tensor\n                in most cases) but can be something else.\n            batch_nb (int): The number of the batch in the epoch.\n\n        Returns:\n            torch.Tensor, the value of the loss.\n        \"\"\"", "\n", "loss", "=", "self", ".", "common_step", "(", "batch", ",", "batch_nb", ",", "train", "=", "True", ")", "\n", "self", ".", "log", "(", "\"loss\"", ",", "loss", ",", "logger", "=", "True", ")", "\n", "return", "loss", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.training_step": [[122, 126], ["system.SystemTwoStep.common_step"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.common_step"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.validation_step": [[127, 130], ["system.SystemTwoStep.common_step"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.system.SystemTwoStep.common_step"], ["\n", "loss", "=", "self", ".", "common_step", "(", "batch", ",", "batch_nb", ",", "train", "=", "False", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.TwoStepTDCN.__init__": [[44, 111], ["torch.Module.__init__", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "print", "ValueError", "model.SeparableDilatedConv1DBlock", "range", "range"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["", "class", "Model", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Speech enhancement model.\n\n    Args:\n        encoder (~.Encoder): instance of a complex filterbank encoder\n            `Encoder(STFTBFB(**))`.\n        masker (nn.Module): Mask estimator network.\n        decoder (~.Decoder): instance of a complex filterbank decoder\n            `Decoder(STFTBFB(**))`.\n        is_complex (bool): If the network works on the complex domain.\n\n    If `is_complex` is `True`, the input to the network are complex features,\n    the network estimates a complex mask and returns a complex speech estimate.\n    Else, the input is the magnitude, the network estimates a magnitude mask\n    and the returns a **complex** speech estimate.\n    The loss function needs to be adapted to complex representations.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "encoder", ",", "masker", ",", "decoder", ",", "is_complex", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "masker", "=", "masker", "\n", "# Decoder is not used for training but eventually, we want to invert", "\n", "# the encoder. Might as well include it in the model.", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "is_complex", "=", "is_complex", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "len", "(", "x", ".", "shape", ")", "==", "2", ":", "\n", "            ", "x", "=", "x", ".", "unsqueeze", "(", "1", ")", "\n", "# Compute STFT", "\n", "", "tf_rep", "=", "self", ".", "encoder", "(", "x", ")", "\n", "# Estimate TF mask from STFT features : cat([re, im, mag])", "\n", "if", "self", ".", "is_complex", ":", "\n", "            ", "to_masker", "=", "magreim", "(", "tf_rep", ")", "\n", "", "else", ":", "\n", "            ", "to_masker", "=", "mag", "(", "tf_rep", ")", "\n", "# LSTM masker expects a feature dimension last (not like 1D conv)", "\n", "", "est_masks", "=", "self", ".", "masker", "(", "to_masker", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# Apply TF mask", "\n", "if", "self", ".", "is_complex", ":", "\n", "            ", "masked_tf_rep", "=", "apply_real_mask", "(", "tf_rep", ",", "est_masks", ")", "\n", "", "else", ":", "\n", "            ", "masked_tf_rep", "=", "apply_mag_mask", "(", "tf_rep", ",", "est_masks", ")", "\n", "", "return", "masked_tf_rep", "\n", "\n", "", "def", "denoise", "(", "self", ",", "x", ")", ":", "\n", "        ", "estimate_stft", "=", "self", "(", "x", ")", "\n", "wav", "=", "self", ".", "decoder", "(", "estimate_stft", ")", "\n", "return", "torch_utils", ".", "pad_x_to_y", "(", "wav", ",", "x", ")", "\n", "\n", "\n", "", "", "class", "SimpleModel", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Simple recurrent model for the DNS challenge.\n\n    Args:\n        input_size (int): input size along the features dimension\n        hidden_size (int): hidden size in the recurrent net\n        output_size (int): output size, defaults to `:attr:` input_size\n        rnn_type (str): Select from ``'RNN'``, ``'LSTM'``, ``'GRU'``. Can also\n            be passed in lowercase letters.\n        n_layers (int): Number of recurrent layers.\n        dropout (float): dropout value between recurrent layers.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "input_size", ",", "hidden_size", ",", "output_size", "=", "None", ",", "rnn_type", "=", "\"gru\"", ",", "n_layers", "=", "3", ",", "dropout", "=", "0.3", "\n", ")", ":", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.TwoStepTDCN.forward": [[113, 131], ["model.TwoStepTDCN.encoder", "model.TwoStepTDCN.clone", "model.TwoStepTDCN.ln_in", "model.TwoStepTDCN.l1", "model.TwoStepTDCN.separator", "model.TwoStepTDCN.ln_mask_in", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "torch.functional.relu", "model.TwoStepTDCN.mask_layer", "torch.functional.softmax", "torch.functional.softmax", "torch.functional.softmax", "torch.functional.softmax", "torch.functional.softmax", "model.TwoStepTDCN.out_reshape", "model.TwoStepTDCN.unsqueeze", "model.TwoStepTDCN.clone.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax"], ["self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "output_size", "=", "input_size", "if", "output_size", "is", "None", "else", "output_size", "\n", "self", ".", "output_size", "=", "output_size", "\n", "self", ".", "in_proj_layer", "=", "nn", ".", "Linear", "(", "input_size", ",", "hidden_size", ")", "\n", "self", ".", "residual_rec", "=", "StackedResidualRNN", "(", "\n", "rnn_type", ",", "hidden_size", ",", "n_layers", "=", "n_layers", ",", "dropout", "=", "dropout", "\n", ")", "\n", "self", ".", "out_proj_layer", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "output_size", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Mask estimator's forward pass. Expects [batch, time, input_size]\"\"\"", "\n", "# Non negative features from input", "\n", "out_rec", "=", "self", ".", "residual_rec", "(", "torch", ".", "relu", "(", "self", ".", "in_proj_layer", "(", "x", ")", ")", ")", "\n", "# Activation is relu on the mask (better gradients allegedly)", "\n", "return", "torch", ".", "relu", "(", "self", ".", "out_proj_layer", "(", "out_rec", ")", ")", "\n", "\n", "\n", "", "", "class", "SimpleSystem", "(", "System", ")", ":", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.TwoStepTDCN.infer_source_signals": [[132, 138], ["model.TwoStepTDCN.forward", "model.TwoStepTDCN.decoder", "model.TwoStepTDCN.view"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.Model.forward"], ["    ", "def", "common_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "mixture", ",", "speech", ",", "noise", "=", "batch", "\n", "estimate", "=", "self", "(", "mixture", ".", "unsqueeze", "(", "1", ")", ")", "\n", "speech_stft", "=", "self", ".", "model", ".", "encoder", "(", "speech", ".", "unsqueeze", "(", "1", ")", ")", "\n", "# The loss function can be something like", "\n", "# loss_func = partial(distance, is_complex=some_bool)", "\n", "loss", "=", "self", ".", "loss_func", "(", "estimate", ",", "speech_stft", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.SeparableDilatedConv1DBlock.__init__": [[163, 180], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "torch.GroupNorm", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["\n", "", "", "def", "load_best_model", "(", "train_conf", ",", "exp_dir", ")", ":", "\n", "    ", "\"\"\"Load best model after training.\n\n    Args:\n        train_conf (dict): dictionary as expected by `make_model_and_optimizer`\n        exp_dir(str): Experiment directory. Expects to find\n            `'best_k_models.json'` there.\n\n    Returns:\n        nn.Module the best pretrained model according to the val_loss.\n    \"\"\"", "\n", "# Create the model from recipe-local function", "\n", "model", ",", "_", "=", "make_model_and_optimizer", "(", "train_conf", ")", "\n", "# Last best model summary", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "best_k", "=", "json", ".", "load", "(", "f", ")", "\n", "", "best_model_path", "=", "min", "(", "best_k", ",", "key", "=", "best_k", ".", "get", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.SeparableDilatedConv1DBlock.forward": [[182, 186], ["x.clone", "model.SeparableDilatedConv1DBlock.module"], "methods", ["None"], ["checkpoint", "=", "torch", ".", "load", "(", "best_model_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "# Load state_dict into model.", "\n", "model", "=", "torch_utils", ".", "load_state_dict_in", "(", "checkpoint", "[", "\"state_dict\"", "]", ",", "model", ")", "\n", "model", ".", "eval", "(", ")", "\n", "return", "model", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveEncoder1D.__init__": [[200, 204], ["torch.Module.__init__", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveEncoder1D.forward": [[206, 208], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "model.AdaptiveEncoder1D.conv"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveDecoder1D.__init__": [[219, 229], ["torch.Module.__init__", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d", "torch.ConvTranspose1d"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveDecoder1D.forward": [[231, 233], ["model.AdaptiveDecoder1D.deconv"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveEncoderDecoder.__init__": [[252, 259], ["torch.Module.__init__", "model.AdaptiveEncoder1D", "model.AdaptiveDecoder1D"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveEncoderDecoder.get_target_masks": [[260, 272], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "model.AdaptiveEncoderDecoder.mix_encoder", "clean_sources[].unsqueeze", "range"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.softmax"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveEncoderDecoder.reconstruct": [[273, 276], ["model.AdaptiveEncoderDecoder.mix_encoder", "model.AdaptiveEncoderDecoder.decoder", "mixture.unsqueeze"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveEncoderDecoder.get_encoded_sources": [[277, 282], ["model.AdaptiveEncoderDecoder.mix_encoder", "model.AdaptiveEncoderDecoder.get_target_masks", "mixture.unsqueeze", "model.AdaptiveEncoderDecoder.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveEncoderDecoder.get_target_masks"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveEncoderDecoder.forward": [[283, 292], ["model.AdaptiveEncoderDecoder.mix_encoder", "model.AdaptiveEncoderDecoder.get_target_masks", "model.AdaptiveEncoderDecoder.decoder", "mixture.unsqueeze", "model.AdaptiveEncoderDecoder.unsqueeze", "s_recon_enc.view"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveEncoderDecoder.get_target_masks"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.Model.__init__": [[295, 306], ["torch.Module.__init__", "model.TwoStepTDCN"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.Model.get_ideal_targets": [[308, 319], ["model.Model.pretrained_filterbank.get_encoded_sources"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveEncoderDecoder.get_encoded_sources"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.Model.estimate_latent_representations": [[320, 322], ["model.Model.separator", "mixture.unsqueeze"], "methods", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.Model.get_ideal_latent_targets": [[323, 325], ["model.Model.pretrained_filterbank.get_encoded_sources"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.AdaptiveEncoderDecoder.get_encoded_sources"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.Model.forward": [[326, 329], ["model.Model.separator.infer_source_signals", "x.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.TwoStepTDCN.infer_source_signals"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.get_encoded_paths": [[331, 337], ["os.path.join"], "function", ["None"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.load_best_separator_if_available": [[339, 369], ["model.load_best_filterbank_if_available", "model.get_encoded_paths", "model.get_encoded_paths", "os.path.exists", "os.path.join", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "model.make_model_and_optimizer", "asteroid.torch_utils.load_state_dict_in", "print", "FileNotFoundError", "FileNotFoundError", "os.listdir"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.load_best_filterbank_if_available", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.get_encoded_paths", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.get_encoded_paths", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.load_state_dict_in"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.load_best_filterbank_if_available": [[371, 392], ["model.get_encoded_paths", "os.path.exists", "os.path.join", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "conf[].update", "model.make_model_and_optimizer", "asteroid.torch_utils.load_state_dict_in", "print", "os.listdir"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.get_encoded_paths", "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.load_state_dict_in"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.TwoStep.model.make_model_and_optimizer": [[394, 429], ["asteroid.engine.optimizers.make_optimizer", "model.AdaptiveEncoderDecoder", "Model.parameters", "model.Model", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer"], []], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DCCRNet.eval.update_compute_metrics": [[56, 68], ["warnings.warn"], "function", ["None"], ["sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DCCRNet.eval.main": [[70, 182], ["eval.update_compute_metrics", "pandas.read_csv", "os.path.join", "asteroid.DCCRNet.from_pretrained", "asteroid.data.librimix_dataset.LibriMix", "asteroid.losses.PITLossWrapper", "os.path.join", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "torch.load", "os.makedirs", "asteroid.models.save_publishable", "asteroid.metrics.MockWERTracker", "asteroid.metrics.WERTracker", "DCCRNet.from_pretrained.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "DCCRNet.from_pretrained.", "asteroid.losses.PITLossWrapper.", "mix.cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "asteroid.dsp.normalization.normalize_estimates", "asteroid.metrics.get_metrics.update", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "print", "wer_tracker.final_report_as_markdown", "print", "open", "json.dump", "os.path.join", "os.path.join", "DCCRNet.from_pretrained.parameters", "len", "torch.no_grad", "len", "mix.unsqueeze", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "open", "f.write", "os.path.join", "wer_tracker", "soundfile.write", "soundfile.write", "open", "json.dump", "os.path.join", "mix.cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "pathlib.Path", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DCUNet.eval.update_compute_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.normalization.normalize_estimates", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.final_report_as_markdown"], ["mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ")", "as", "f", ":", "\n", "        ", "train_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "arg_dic", "[", "\"sample_rate\"", "]", "=", "train_conf", "[", "\"data\"", "]", "[", "\"sample_rate\"", "]", "\n", "arg_dic", "[", "\"train_conf\"", "]", "=", "train_conf", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DCCRNet.train.main": [[27, 121], ["asteroid.data.LibriMix", "asteroid.data.LibriMix", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "conf[].update", "asteroid.models.DCCRNet", "asteroid.engine.optimizers.make_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "asteroid.engine.system.System", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "asteroid.engine.system.System.load_state_dict", "asteroid.engine.system.System.cpu", "asteroid.engine.system.System.model.serialize", "system.model.serialize.update", "torch.save", "asteroid.models.DCCRNet.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "asteroid.data.LibriMix.get_infos", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], ["train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DPRNNTasNet.eval.update_compute_metrics": [[56, 68], ["warnings.warn"], "function", ["None"], ["sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DPRNNTasNet.eval.main": [[70, 182], ["eval.update_compute_metrics", "pandas.read_csv", "os.path.join", "asteroid.DPRNNTasNet.from_pretrained", "asteroid.data.librimix_dataset.LibriMix", "asteroid.losses.PITLossWrapper", "os.path.join", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "torch.load", "os.makedirs", "asteroid.models.save_publishable", "asteroid.metrics.MockWERTracker", "asteroid.metrics.WERTracker", "DPRNNTasNet.from_pretrained.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "DPRNNTasNet.from_pretrained.", "asteroid.losses.PITLossWrapper.", "mix.cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "asteroid.dsp.normalization.normalize_estimates", "asteroid.metrics.get_metrics.update", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "print", "wer_tracker.final_report_as_markdown", "print", "open", "json.dump", "os.path.join", "os.path.join", "DPRNNTasNet.from_pretrained.parameters", "len", "torch.no_grad", "len", "mix.unsqueeze", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "open", "f.write", "os.path.join", "wer_tracker", "soundfile.write", "soundfile.write", "open", "json.dump", "os.path.join", "mix.cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "pathlib.Path", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DCUNet.eval.update_compute_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.normalization.normalize_estimates", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.final_report_as_markdown"], ["mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ")", "as", "f", ":", "\n", "        ", "train_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "arg_dic", "[", "\"sample_rate\"", "]", "=", "train_conf", "[", "\"data\"", "]", "[", "\"sample_rate\"", "]", "\n", "arg_dic", "[", "\"train_conf\"", "]", "=", "train_conf", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DPRNNTasNet.train.main": [[27, 121], ["asteroid.data.LibriMix", "asteroid.data.LibriMix", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "conf[].update", "asteroid.models.DPRNNTasNet", "asteroid.engine.optimizers.make_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "asteroid.engine.system.System", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "asteroid.engine.system.System.load_state_dict", "asteroid.engine.system.System.cpu", "asteroid.engine.system.System.model.serialize", "system.model.serialize.update", "torch.save", "asteroid.models.DPRNNTasNet.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "asteroid.data.LibriMix.get_infos", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], ["train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.SuDORMRFNet.eval.update_compute_metrics": [[56, 68], ["warnings.warn"], "function", ["None"], ["sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.SuDORMRFNet.eval.main": [[70, 182], ["eval.update_compute_metrics", "pandas.read_csv", "os.path.join", "asteroid.models.SuDORMRFNet.from_pretrained", "asteroid.data.librimix_dataset.LibriMix", "asteroid.losses.PITLossWrapper", "os.path.join", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "torch.load", "os.makedirs", "asteroid.models.save_publishable", "asteroid.metrics.MockWERTracker", "asteroid.metrics.WERTracker", "SuDORMRFNet.from_pretrained.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "SuDORMRFNet.from_pretrained.", "asteroid.losses.PITLossWrapper.", "mix.cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "asteroid.dsp.normalization.normalize_estimates", "asteroid.metrics.get_metrics.update", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "print", "wer_tracker.final_report_as_markdown", "print", "open", "json.dump", "os.path.join", "os.path.join", "SuDORMRFNet.from_pretrained.parameters", "len", "torch.no_grad", "len", "mix.unsqueeze", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "open", "f.write", "os.path.join", "wer_tracker", "soundfile.write", "soundfile.write", "open", "json.dump", "os.path.join", "mix.cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "pathlib.Path", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DCUNet.eval.update_compute_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.normalization.normalize_estimates", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.final_report_as_markdown"], ["mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ")", "as", "f", ":", "\n", "        ", "train_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "arg_dic", "[", "\"sample_rate\"", "]", "=", "train_conf", "[", "\"data\"", "]", "[", "\"sample_rate\"", "]", "\n", "arg_dic", "[", "\"train_conf\"", "]", "=", "train_conf", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.SuDORMRFNet.train.main": [[27, 121], ["asteroid.data.LibriMix", "asteroid.data.LibriMix", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "conf[].update", "asteroid.models.SuDORMRFNet", "asteroid.engine.optimizers.make_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "asteroid.engine.system.System", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "asteroid.engine.system.System.load_state_dict", "asteroid.engine.system.System.cpu", "asteroid.engine.system.System.model.serialize", "system.model.serialize.update", "torch.save", "asteroid.models.SuDORMRFNet.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "asteroid.data.LibriMix.get_infos", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], ["train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.SuDORMRFImprovedNet.eval.update_compute_metrics": [[56, 68], ["warnings.warn"], "function", ["None"], ["sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.SuDORMRFImprovedNet.eval.main": [[70, 182], ["eval.update_compute_metrics", "pandas.read_csv", "os.path.join", "asteroid.models.SuDORMRFImprovedNet.from_pretrained", "asteroid.data.librimix_dataset.LibriMix", "asteroid.losses.PITLossWrapper", "os.path.join", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "torch.load", "os.makedirs", "asteroid.models.save_publishable", "asteroid.metrics.MockWERTracker", "asteroid.metrics.WERTracker", "SuDORMRFImprovedNet.from_pretrained.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "SuDORMRFImprovedNet.from_pretrained.", "asteroid.losses.PITLossWrapper.", "mix.cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "asteroid.dsp.normalization.normalize_estimates", "asteroid.metrics.get_metrics.update", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "print", "wer_tracker.final_report_as_markdown", "print", "open", "json.dump", "os.path.join", "os.path.join", "SuDORMRFImprovedNet.from_pretrained.parameters", "len", "torch.no_grad", "len", "mix.unsqueeze", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "open", "f.write", "os.path.join", "wer_tracker", "soundfile.write", "soundfile.write", "open", "json.dump", "os.path.join", "mix.cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "pathlib.Path", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DCUNet.eval.update_compute_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.normalization.normalize_estimates", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.final_report_as_markdown"], ["mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ")", "as", "f", ":", "\n", "        ", "train_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "arg_dic", "[", "\"sample_rate\"", "]", "=", "train_conf", "[", "\"data\"", "]", "[", "\"sample_rate\"", "]", "\n", "arg_dic", "[", "\"train_conf\"", "]", "=", "train_conf", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.SuDORMRFImprovedNet.train.main": [[27, 121], ["asteroid.data.LibriMix", "asteroid.data.LibriMix", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "conf[].update", "asteroid.models.SuDORMRFImprovedNet", "asteroid.engine.optimizers.make_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "asteroid.engine.system.System", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "asteroid.engine.system.System.load_state_dict", "asteroid.engine.system.System.cpu", "asteroid.engine.system.System.model.serialize", "system.model.serialize.update", "torch.save", "asteroid.models.SuDORMRFImprovedNet.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "asteroid.data.LibriMix.get_infos", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], ["train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DCUNet.eval.update_compute_metrics": [[56, 68], ["warnings.warn"], "function", ["None"], ["sources", "=", "sources", "[", "...", ",", "0", "]", "\n", "# noise = noise[..., 0]", "\n", "if", "conf", "[", "\"train_conf\"", "]", "[", "\"training\"", "]", "[", "\"loss_alpha\"", "]", "==", "1", ":", "\n", "# If Deep clustering only, use DC masks.", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "dc_head_separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "", "else", ":", "\n", "# If Chimera, use mask-inference head masks", "\n", "            ", "est_sources", ",", "dic_out", "=", "model", ".", "separate", "(", "mix", "[", "None", ",", "None", "]", ")", "\n", "\n", "", "loss", ",", "reordered_sources", "=", "loss_func", "(", "est_sources", ",", "sources", "[", "None", "]", ",", "return_est", "=", "True", ")", "\n", "mix_np", "=", "mix", "[", "None", "]", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "sources_np", "=", "sources", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "est_sources_np", "=", "reordered_sources", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DCUNet.eval.main": [[70, 182], ["eval.update_compute_metrics", "pandas.read_csv", "os.path.join", "asteroid.DCUNet.from_pretrained", "asteroid.data.librimix_dataset.LibriMix", "asteroid.losses.PITLossWrapper", "os.path.join", "os.path.join", "random.sample", "torch.no_grad().__enter__", "tqdm.tqdm", "pandas.DataFrame", "pd.DataFrame.to_csv", "print", "pprint.pprint", "torch.load", "os.makedirs", "asteroid.models.save_publishable", "asteroid.metrics.MockWERTracker", "asteroid.metrics.WERTracker", "DCUNet.from_pretrained.cuda", "next", "len", "range", "range", "asteroid.utils.tensors_to_device", "DCUNet.from_pretrained.", "asteroid.losses.PITLossWrapper.", "mix.cpu().data.numpy", "sources.cpu().data.numpy", "reordered_sources.squeeze().cpu().data.numpy", "asteroid.metrics.get_metrics", "asteroid.dsp.normalization.normalize_estimates", "asteroid.metrics.get_metrics.update", "series_list.append", "os.path.join", "all_metrics_df[].mean", "ldf.mean", "print", "wer_tracker.final_report_as_markdown", "print", "open", "json.dump", "os.path.join", "os.path.join", "DCUNet.from_pretrained.parameters", "len", "torch.no_grad", "len", "mix.unsqueeze", "pandas.Series", "os.path.join", "os.makedirs", "soundfile.write", "enumerate", "enumerate", "open", "f.write", "os.path.join", "wer_tracker", "soundfile.write", "soundfile.write", "open", "json.dump", "os.path.join", "mix.cpu", "sources.cpu", "reordered_sources.squeeze().cpu", "pathlib.Path", "reordered_sources.squeeze"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.DCUNet.eval.update_compute_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.from_pretrained", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable", "home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.tensors_to_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.dsp.normalization.normalize_estimates", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.WERTracker.final_report_as_markdown"], ["mix_np", ",", "\n", "sources_np", ",", "\n", "est_sources_np", ",", "\n", "sample_rate", "=", "conf", "[", "\"sample_rate\"", "]", ",", "\n", "metrics_list", "=", "compute_metrics", ",", "\n", ")", "\n", "utt_metrics", "[", "\"mix_path\"", "]", "=", "test_set", ".", "mix", "[", "idx", "]", "[", "0", "]", "\n", "series_list", ".", "append", "(", "pd", ".", "Series", "(", "utt_metrics", ")", ")", "\n", "\n", "# Save some examples in a folder. Wav files and metrics as text.", "\n", "if", "idx", "in", "save_idx", ":", "\n", "            ", "local_save_dir", "=", "os", ".", "path", ".", "join", "(", "ex_save_dir", ",", "\"ex_{}/\"", ".", "format", "(", "idx", ")", ")", "\n", "os", ".", "makedirs", "(", "local_save_dir", ",", "exist_ok", "=", "True", ")", "\n", "sf", ".", "write", "(", "local_save_dir", "+", "\"mixture.wav\"", ",", "mix_np", "[", "0", "]", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "# Loop over the sources and estimates", "\n", "for", "src_idx", ",", "src", "in", "enumerate", "(", "sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "local_save_dir", "+", "\"s{}.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "src", ",", "conf", "[", "\"sample_rate\"", "]", ")", "\n", "", "for", "src_idx", ",", "est_src", "in", "enumerate", "(", "est_sources_np", ")", ":", "\n", "                ", "sf", ".", "write", "(", "\n", "local_save_dir", "+", "\"s{}_estimate.wav\"", ".", "format", "(", "src_idx", "+", "1", ")", ",", "\n", "est_src", ",", "\n", "conf", "[", "\"sample_rate\"", "]", ",", "\n", ")", "\n", "# Write local metrics to the example folder.", "\n", "", "with", "open", "(", "local_save_dir", "+", "\"metrics.json\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "utt_metrics", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "# Save all metrics to the experiment folder.", "\n", "", "", "", "all_metrics_df", "=", "pd", ".", "DataFrame", "(", "series_list", ")", "\n", "all_metrics_df", ".", "to_csv", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"all_metrics.csv\"", ")", ")", "\n", "\n", "# Print and save summary metrics", "\n", "final_results", "=", "{", "}", "\n", "for", "metric_name", "in", "compute_metrics", ":", "\n", "        ", "input_metric_name", "=", "\"input_\"", "+", "metric_name", "\n", "ldf", "=", "all_metrics_df", "[", "metric_name", "]", "-", "all_metrics_df", "[", "input_metric_name", "]", "\n", "final_results", "[", "metric_name", "]", "=", "all_metrics_df", "[", "metric_name", "]", ".", "mean", "(", ")", "\n", "final_results", "[", "metric_name", "+", "\"_imp\"", "]", "=", "ldf", ".", "mean", "(", ")", "\n", "", "print", "(", "\"Overall metrics :\"", ")", "\n", "pprint", "(", "final_results", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "conf", "[", "\"exp_dir\"", "]", ",", "\"final_metrics.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "final_results", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "arg_dic", "=", "dict", "(", "vars", "(", "args", ")", ")", "\n", "# Load training config", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ")", "as", "f", ":", "\n", "        ", "train_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "\n", "", "arg_dic", "[", "\"sample_rate\"", "]", "=", "train_conf", "[", "\"data\"", "]", "[", "\"sample_rate\"", "]", "\n", "arg_dic", "[", "\"train_conf\"", "]", "=", "train_conf", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.DCUNet.train.main": [[27, 119], ["asteroid.data.LibriMix", "asteroid.data.LibriMix", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "conf[].update", "asteroid.models.DCUNet", "asteroid.engine.optimizers.make_optimizer", "os.makedirs", "os.path.join", "asteroid.losses.PITLossWrapper", "asteroid.engine.system.System", "os.path.join", "pytorch_lightning.callbacks.ModelCheckpoint", "callbacks.append", "pytorch_lightning.Trainer", "pl.Trainer.fit", "torch.load", "asteroid.engine.system.System.load_state_dict", "asteroid.engine.system.System.cpu", "asteroid.engine.system.System.model.serialize", "system.model.serialize.update", "torch.save", "asteroid.models.DCUNet.parameters", "torch.optim.lr_scheduler.ReduceLROnPlateau", "open", "yaml.safe_dump", "callbacks.append", "v.item", "open", "json.dump", "asteroid.data.LibriMix.get_infos", "os.path.join", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint.best_k_models.items", "os.path.join", "torch.cuda.is_available"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.optimizers.make_optimizer", "home.repos.pwc.inspect_result.mpariente_AsSteroid.engine.schedulers.BaseScheduler.load_state_dict", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.local.demask_dataset.DeMaskDataset.get_infos"], ["train_set", ",", "val_set", "=", "random_split", "(", "total_set", ",", "[", "train_len", ",", "val_len", "]", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "shuffle", "=", "False", ",", "\n", "batch_size", "=", "conf", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", ",", "\n", "num_workers", "=", "conf", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "# Define model and optimizer in a local function (defined in the recipe).", "\n", "# Two advantages to this : re-instantiating the model and optimizer", "\n", "# for retraining and evaluating is straight-forward.", "\n", "model", ",", "optimizer", "=", "make_model_and_optimizer", "(", "conf", ")", "\n", "# Define scheduler", "\n", "scheduler", "=", "None", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"half_lr\"", "]", ":", "\n", "        ", "scheduler", "=", "ReduceLROnPlateau", "(", "optimizer", "=", "optimizer", ",", "factor", "=", "0.5", ",", "patience", "=", "5", ")", "\n", "# Just after instantiating, save the args. Easy loading in the future.", "\n", "", "exp_dir", "=", "conf", "[", "\"main_args\"", "]", "[", "\"exp_dir\"", "]", "\n", "os", ".", "makedirs", "(", "exp_dir", ",", "exist_ok", "=", "True", ")", "\n", "conf_path", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"conf.yml\"", ")", "\n", "with", "open", "(", "conf_path", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "        ", "yaml", ".", "safe_dump", "(", "conf", ",", "outfile", ")", "\n", "\n", "# Define Loss function.", "\n", "", "loss_func", "=", "partial", "(", "distance", ",", "is_complex", "=", "conf", "[", "\"main_args\"", "]", "[", "\"is_complex\"", "]", ")", "\n", "system", "=", "SimpleSystem", "(", "\n", "model", "=", "model", ",", "\n", "loss_func", "=", "loss_func", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "train_loader", "=", "train_loader", ",", "\n", "val_loader", "=", "val_loader", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "config", "=", "conf", ",", "\n", ")", "\n", "\n", "# Define callbacks", "\n", "callbacks", "=", "[", "]", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"checkpoints/\"", ")", "\n", "checkpoint", "=", "ModelCheckpoint", "(", "\n", "checkpoint_dir", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "5", ",", "verbose", "=", "True", "\n", ")", "\n", "callbacks", ".", "append", "(", "checkpoint", ")", "\n", "if", "conf", "[", "\"training\"", "]", "[", "\"early_stop\"", "]", ":", "\n", "        ", "callbacks", ".", "append", "(", "EarlyStopping", "(", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "patience", "=", "30", ",", "verbose", "=", "True", ")", ")", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "conf", "[", "\"training\"", "]", "[", "\"epochs\"", "]", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "default_root_dir", "=", "exp_dir", ",", "\n", "accelerator", "=", "\"gpu\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ",", "\n", "strategy", "=", "\"ddp\"", ",", "\n", "devices", "=", "\"auto\"", ",", "\n", "limit_train_batches", "=", "1.0", ",", "# Useful for fast experiment", "\n", "gradient_clip_val", "=", "5.0", ",", "\n", ")", "\n", "trainer", ".", "fit", "(", "system", ")", "\n", "\n", "best_k", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "checkpoint", ".", "best_k_models", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "exp_dir", ",", "\"best_k_models.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "best_k", ",", "f", ",", "indent", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "import", "yaml", "\n", "from", "pprint", "import", "pprint", "\n", "from", "asteroid", ".", "utils", "import", "prepare_parser_from_dict", ",", "parse_args_as_dict", "\n", "\n", "# We start with opening the config file conf.yml as a dictionary from", "\n", "# which we can create parsers. Each top level key in the dictionary defined", "\n", "# by the YAML file creates a group in the parser.", "\n", "with", "open", "(", "\"local/conf.yml\"", ")", "as", "f", ":", "\n", "        ", "def_conf", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "parser", "=", "prepare_parser_from_dict", "(", "def_conf", ",", "parser", "=", "parser", ")", "\n", "# Arguments are then parsed into a hierarchical dictionary (instead of", "\n", "# flat, as returned by argparse) to facilitate calls to the different", "\n", "# asteroid methods (see in main).", "\n", "# plain_args is the direct output of parser.parse_args() and contains all", "\n", "# the attributes in an non-hierarchical structure. It can be useful to also", "\n", "# have it so we included it here but it is not used.", "\n", "arg_dic", ",", "plain_args", "=", "parse_args_as_dict", "(", "parser", ",", "return_plain_args", "=", "True", ")", "\n", "pprint", "(", "arg_dic", ")", "\n", "main", "(", "arg_dic", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.CaCGMM.start_evaluation.main": [[12, 15], ["sms_wsj.examples.reference_systems.experiment.run", "dict"], "function", ["None"], ["def", "main", "(", "conf", ")", ":", "\n", "    ", "experiment", ".", "run", "(", "\n", "config_updates", "=", "dict", "(", "json_path", "=", "conf", "[", "\"main_args\"", "]", "[", "\"json_path\"", "]", ",", "**", "conf", "[", "\"mm_config\"", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.binarize_test.test_Binarize": [[6, 26], ["asteroid.binarize.Binarize", "range", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "len", "asteroid.binarize.Binarize.", "torch.allclose", "inputs_list[].unsqueeze().unsqueeze", "inputs_list[].unsqueeze"], "function", ["None"], ["def", "test_Binarize", "(", ")", ":", "\n", "# fmt: off", "\n", "    ", "inputs_list", "=", "[", "\n", "torch", ".", "Tensor", "(", "[", "0.1", ",", "0.6", ",", "0.2", ",", "0.6", ",", "0.1", ",", "0.1", ",", "0.1", ",", "0.7", ",", "0.7", ",", "0.7", ",", "0.1", ",", "0.7", ",", "0.7", ",", "0.7", ",", "0.1", ",", "\n", "0.8", ",", "0.9", ",", "0.2", ",", "0.7", ",", "0.1", ",", "0.1", ",", "0.1", ",", "0.8", ",", "0.1", "]", ")", ",", "\n", "torch", ".", "Tensor", "(", "[", "0.1", ",", "0.1", ",", "0.2", ",", "0.1", "]", ")", ",", "\n", "torch", ".", "Tensor", "(", "[", "0.7", ",", "0.7", ",", "0.7", ",", "0.7", "]", ")", ",", "\n", "torch", ".", "Tensor", "(", "[", "0.1", ",", "0.7", "]", ")", ",", "\n", "]", "\n", "# fmt: on", "\n", "expected_result_list", "=", "[", "\n", "torch", ".", "Tensor", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", ",", "\n", "torch", ".", "Tensor", "(", "[", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", ")", ",", "\n", "torch", ".", "Tensor", "(", "[", "1", ",", "1", ",", "1", ",", "1", "]", ")", ",", "\n", "torch", ".", "Tensor", "(", "[", "0.0", ",", "0.0", "]", ")", ",", "\n", "]", "\n", "binarizer", "=", "Binarize", "(", "0.5", ",", "3", ",", "1", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "inputs_list", ")", ")", ":", "\n", "        ", "result", "=", "binarizer", "(", "inputs_list", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "assert", "torch", ".", "allclose", "(", "result", ",", "expected_result_list", "[", "i", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.cli_test.test_asteroid_versions": [[4, 9], ["asteroid.scripts.asteroid_versions.asteroid_versions"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.asteroid_versions"], ["def", "test_asteroid_versions", "(", ")", ":", "\n", "    ", "versions", "=", "asteroid_versions", ".", "asteroid_versions", "(", ")", "\n", "assert", "\"Asteroid\"", "in", "versions", "\n", "assert", "\"PyTorch\"", "in", "versions", "\n", "assert", "\"PyTorch-Lightning\"", "in", "versions", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.cli_test.test_print_versions": [[11, 13], ["asteroid.scripts.asteroid_versions.print_versions"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.print_versions"], ["", "def", "test_print_versions", "(", ")", ":", "\n", "    ", "asteroid_versions", ".", "print_versions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.cli_test.test_asteroid_versions_without_git": [[15, 18], ["monkeypatch.setenv", "asteroid.scripts.asteroid_versions.asteroid_versions"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_versions.asteroid_versions"], ["", "def", "test_asteroid_versions_without_git", "(", "monkeypatch", ")", ":", "\n", "    ", "monkeypatch", ".", "setenv", "(", "\"PATH\"", ",", "\"\"", ")", "\n", "asteroid_versions", ".", "asteroid_versions", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.cli_test.test_infer_device": [[20, 46], ["FakeModel", "monkeypatch.setattr", "asteroid.scripts.asteroid_cli.infer"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.scripts.asteroid_cli.infer"], ["", "def", "test_infer_device", "(", "monkeypatch", ")", ":", "\n", "    ", "\"\"\"Test that inference is performed on the PyTorch device given by '--device'.\n\n    We can't properly test this in environments with only CPU device available.\n    As an approximation we test that the '.to()' method of the model is called\n    with the device given by '--device'.\n    \"\"\"", "\n", "# We can't use a real model to test this because calling .to() with a fake device", "\n", "# on a real model will fail.", "\n", "class", "FakeModel", ":", "\n", "        ", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "            ", "self", ".", "device", "=", "device", "\n", "\n", "", "", "fake_model", "=", "FakeModel", "(", ")", "\n", "\n", "# Monkeypatch 'from_pretrained' to load our fake model.", "\n", "from", "asteroid", ".", "models", "import", "BaseModel", "\n", "\n", "monkeypatch", ".", "setattr", "(", "BaseModel", ",", "\"from_pretrained\"", ",", "lambda", "*", "args", ",", "**", "kwargs", ":", "fake_model", ")", "\n", "\n", "# Note that this will issue a warning about the missing file.", "\n", "asteroid_cli", ".", "infer", "(", "\n", "[", "\"--device\"", ",", "\"cuda:42\"", ",", "\"somemodel\"", ",", "\"--files\"", ",", "\"file_that_does_not_exist.wav\"", "]", "\n", ")", "\n", "\n", "assert", "fake_model", ".", "device", "==", "\"cuda:42\"", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.cli_setup.setup_register_sr": [[9, 22], ["asteroid.models.ConvTasNet", "asteroid.models.ConvTasNet.serialize", "to_save[].pop", "torch.save"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize"], ["def", "setup_register_sr", "(", ")", ":", "\n", "    ", "model", "=", "ConvTasNet", "(", "\n", "n_src", "=", "2", ",", "\n", "n_repeats", "=", "2", ",", "\n", "n_blocks", "=", "3", ",", "\n", "bn_chan", "=", "16", ",", "\n", "hid_chan", "=", "4", ",", "\n", "skip_chan", "=", "8", ",", "\n", "n_filters", "=", "32", ",", "\n", ")", "\n", "to_save", "=", "model", ".", "serialize", "(", ")", "\n", "to_save", "[", "\"model_args\"", "]", ".", "pop", "(", "\"sample_rate\"", ")", "\n", "torch", ".", "save", "(", "to_save", ",", "\"tmp.th\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.cli_setup.setup_infer": [[24, 27], ["soundfile.write", "soundfile.write", "numpy.random.randn", "numpy.random.randn"], "function", ["None"], ["", "def", "setup_infer", "(", ")", ":", "\n", "    ", "sf", ".", "write", "(", "\"tmp.wav\"", ",", "np", ".", "random", ".", "randn", "(", "16000", ")", ",", "8000", ")", "\n", "sf", ".", "write", "(", "\"tmp2.wav\"", ",", "np", ".", "random", ".", "randn", "(", "16000", ")", ",", "8000", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.cli_setup.setup_upload": [[29, 52], ["dict", "asteroid.models.ConvTasNet", "asteroid.models.ConvTasNet.serialize", "model.serialize.update", "os.makedirs", "asteroid.models.save_publishable", "dict"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.models.base_models.BaseModel.serialize", "home.repos.pwc.inspect_result.mpariente_AsSteroid.models.publisher.save_publishable"], ["", "def", "setup_upload", "(", ")", ":", "\n", "    ", "train_set_infos", "=", "dict", "(", "\n", "dataset", "=", "\"WHAM\"", ",", "task", "=", "\"sep_noisy\"", ",", "licenses", "=", "[", "wsj0_license", ",", "wham_noise_license", "]", "\n", ")", "\n", "final_results", "=", "{", "\"si_sdr\"", ":", "8.67", ",", "\"si_sdr_imp\"", ":", "13.16", "}", "\n", "model", "=", "ConvTasNet", "(", "\n", "n_src", "=", "2", ",", "\n", "n_repeats", "=", "2", ",", "\n", "n_blocks", "=", "3", ",", "\n", "bn_chan", "=", "16", ",", "\n", "hid_chan", "=", "4", ",", "\n", "skip_chan", "=", "8", ",", "\n", "n_filters", "=", "32", ",", "\n", ")", "\n", "model_dict", "=", "model", ".", "serialize", "(", ")", "\n", "model_dict", ".", "update", "(", "train_set_infos", ")", "\n", "\n", "os", ".", "makedirs", "(", "\"publish_dir\"", ",", "exist_ok", "=", "True", ")", "\n", "save_publishable", "(", "\n", "\"publish_dir\"", ",", "\n", "model_dict", ",", "\n", "metrics", "=", "final_results", ",", "\n", "train_conf", "=", "dict", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.complex_nn_test.test_is_torch_complex": [[11, 13], ["asteroid.complex_nn.is_torch_complex", "torch.randn"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.is_torch_complex"], ["def", "test_is_torch_complex", "(", ")", ":", "\n", "    ", "cnn", ".", "is_torch_complex", "(", "torch", ".", "randn", "(", "10", ",", "10", ",", "dtype", "=", "torch", ".", "complex64", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.complex_nn_test.test_torch_complex_from_magphase": [[15, 22], ["torch.randn().abs", "torch.remainder", "asteroid.complex_nn.torch_complex_from_magphase", "torch.testing.assert_allclose", "torch.testing.assert_allclose", "torch.randn", "torch.abs", "cnn.torch_complex_from_magphase.angle", "torch.randn"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_magphase"], ["", "def", "test_torch_complex_from_magphase", "(", ")", ":", "\n", "    ", "shape", "=", "(", "1", ",", "257", ",", "100", ")", "\n", "mag", "=", "torch", ".", "randn", "(", "shape", ")", ".", "abs", "(", ")", "\n", "phase", "=", "torch", ".", "remainder", "(", "torch", ".", "randn", "(", "shape", ")", ",", "math", ".", "pi", ")", "\n", "out", "=", "cnn", ".", "torch_complex_from_magphase", "(", "mag", ",", "phase", ")", "\n", "assert_allclose", "(", "torch", ".", "abs", "(", "out", ")", ",", "mag", ")", "\n", "assert_allclose", "(", "out", ".", "angle", "(", ")", ",", "phase", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.complex_nn_test.test_torch_complex_from_reim": [[24, 27], ["torch.randn", "torch.testing.assert_allclose", "asteroid.complex_nn.torch_complex_from_reim"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_reim"], ["", "def", "test_torch_complex_from_reim", "(", ")", ":", "\n", "    ", "comp", "=", "torch", ".", "randn", "(", "10", ",", "12", ",", "dtype", "=", "torch", ".", "complex64", ")", "\n", "assert_allclose", "(", "cnn", ".", "torch_complex_from_reim", "(", "comp", ".", "real", ",", "comp", ".", "imag", ")", ",", "comp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.complex_nn_test.test_onreim": [[29, 37], ["torch.randn", "asteroid.complex_nn.on_reim", "torch.testing.assert_allclose", "asteroid.complex_nn.on_reim", "torch.testing.assert_allclose", "cnn.on_reim.", "cnn.on_reim.", "asteroid.complex_nn.torch_complex_from_reim", "x.abs", "torch.randn.real.abs", "torch.randn.imag.abs"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.on_reim", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.on_reim", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_reim"], ["", "def", "test_onreim", "(", ")", ":", "\n", "    ", "inp", "=", "torch", ".", "randn", "(", "10", ",", "10", ",", "dtype", "=", "torch", ".", "complex64", ")", "\n", "# Identity", "\n", "fn", "=", "cnn", ".", "on_reim", "(", "lambda", "x", ":", "x", ")", "\n", "assert_allclose", "(", "fn", "(", "inp", ")", ",", "inp", ")", "\n", "# Top right quadrant", "\n", "fn", "=", "cnn", ".", "on_reim", "(", "lambda", "x", ":", "x", ".", "abs", "(", ")", ")", "\n", "assert_allclose", "(", "fn", "(", "inp", ")", ",", "cnn", ".", "torch_complex_from_reim", "(", "inp", ".", "real", ".", "abs", "(", ")", ",", "inp", ".", "imag", ".", "abs", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.complex_nn_test.test_on_reim_class": [[39, 54], ["torch.randn", "asteroid.complex_nn.OnReIm", "torch.testing.assert_allclose", "asteroid.complex_nn.OnReIm", "torch.testing.assert_allclose", "cnn.OnReIm.", "cnn.OnReIm.", "asteroid.complex_nn.torch_complex_from_reim", "super().__init__"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_reim", "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["", "def", "test_on_reim_class", "(", ")", ":", "\n", "    ", "inp", "=", "torch", ".", "randn", "(", "10", ",", "10", ",", "dtype", "=", "torch", ".", "complex64", ")", "\n", "\n", "class", "Identity", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "        ", "def", "__init__", "(", "self", ",", "a", "=", "0", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "a", "=", "a", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "            ", "return", "x", "+", "self", ".", "a", "\n", "\n", "", "", "fn", "=", "cnn", ".", "OnReIm", "(", "Identity", ",", "0", ")", "\n", "assert_allclose", "(", "fn", "(", "inp", ")", ",", "inp", ")", "\n", "fn", "=", "cnn", ".", "OnReIm", "(", "Identity", ",", "1", ")", "\n", "assert_allclose", "(", "fn", "(", "inp", ")", ",", "cnn", ".", "torch_complex_from_reim", "(", "inp", ".", "real", "+", "1", ",", "inp", ".", "imag", "+", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.complex_nn_test.test_complex_mul_wrapper": [[56, 64], ["torch.randn", "asteroid.complex_nn.ComplexMultiplicationWrapper", "torch.testing.assert_allclose", "cnn.ComplexMultiplicationWrapper.", "asteroid.complex_nn.torch_complex_from_reim", "torch.relu", "torch.relu", "torch.relu", "torch.relu"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_reim", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu", "home.repos.pwc.inspect_result.mpariente_AsSteroid.masknn.activations.relu"], ["", "def", "test_complex_mul_wrapper", "(", ")", ":", "\n", "    ", "a", "=", "torch", ".", "randn", "(", "10", ",", "10", ",", "dtype", "=", "torch", ".", "complex64", ")", "\n", "\n", "fn", "=", "cnn", ".", "ComplexMultiplicationWrapper", "(", "torch", ".", "nn", ".", "ReLU", ")", "\n", "assert_allclose", "(", "\n", "fn", "(", "a", ")", ",", "\n", "cnn", ".", "torch_complex_from_reim", "(", "\n", "torch", ".", "relu", "(", "a", ".", "real", ")", "-", "torch", ".", "relu", "(", "a", ".", "imag", ")", ",", "torch", ".", "relu", "(", "a", ".", "real", ")", "+", "torch", ".", "relu", "(", "a", ".", "imag", ")", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.complex_nn_test.test_bound_complex_mask": [[68, 71], ["pytest.mark.parametrize", "asteroid.complex_nn.bound_complex_mask", "torch.randn"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.bound_complex_mask"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"bound_type\"", ",", "(", "\"BDSS\"", ",", "\"sigmoid\"", ",", "\"BDT\"", ",", "\"tanh\"", ",", "\"UBD\"", ",", "None", ")", ")", "\n", "def", "test_bound_complex_mask", "(", "bound_type", ")", ":", "\n", "    ", "cnn", ".", "bound_complex_mask", "(", "torch", ".", "randn", "(", "4", ",", "2", ",", "257", ",", "dtype", "=", "torch", ".", "complex64", ")", ",", "bound_type", "=", "bound_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.complex_nn_test.test_bound_complex_mask_raises": [[73, 76], ["pytest.raises", "asteroid.complex_nn.bound_complex_mask", "torch.randn"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.bound_complex_mask"], ["", "def", "test_bound_complex_mask_raises", "(", ")", ":", "\n", "    ", "with", "pytest", ".", "raises", "(", "ValueError", ")", ":", "\n", "        ", "cnn", ".", "bound_complex_mask", "(", "torch", ".", "randn", "(", "4", ",", "2", ",", "257", ",", "dtype", "=", "torch", ".", "complex64", ")", ",", "bound_type", "=", "\"foo\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.complex_nn_test.test_complexsinglernn": [[78, 90], ["pytest.mark.parametrize", "asteroid.complex_nn.ComplexSingleRNN", "torch.randn", "cnn.ComplexSingleRNN.", "torch.testing.assert_allclose", "layer.re_module", "layer.im_module", "layer.re_module", "layer.im_module", "asteroid.complex_nn.torch_complex_from_reim"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.complex_nn.torch_complex_from_reim"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"n_layers\"", ",", "[", "1", ",", "2", ",", "3", "]", ")", "\n", "def", "test_complexsinglernn", "(", "n_layers", ")", ":", "\n", "    ", "crnn", "=", "cnn", ".", "ComplexSingleRNN", "(", "\"RNN\"", ",", "10", ",", "10", ",", "n_layers", "=", "n_layers", ",", "dropout", "=", "0", ",", "bidirectional", "=", "False", ")", "\n", "inp", "=", "torch", ".", "randn", "(", "1", ",", "5", ",", "10", ",", "dtype", "=", "torch", ".", "complex64", ")", "\n", "out", "=", "crnn", "(", "inp", ")", "\n", "for", "layer", "in", "crnn", ".", "rnns", ":", "\n", "        ", "rere", "=", "layer", ".", "re_module", "(", "inp", ".", "real", ")", "\n", "imim", "=", "layer", ".", "im_module", "(", "inp", ".", "imag", ")", "\n", "reim", "=", "layer", ".", "re_module", "(", "inp", ".", "imag", ")", "\n", "imre", "=", "layer", ".", "im_module", "(", "inp", ".", "real", ")", "\n", "inp", "=", "cnn", ".", "torch_complex_from_reim", "(", "rere", "-", "imim", ",", "reim", "+", "imre", ")", "\n", "", "assert_allclose", "(", "out", ",", "inp", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.metrics_test.test_get_metrics": [[7, 19], ["pytest.mark.parametrize", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "asteroid.metrics.get_metrics", "asteroid.metrics.get_metrics", "float", "float", "numpy.mean", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"fs\"", ",", "[", "8000", ",", "16000", "]", ")", "\n", "def", "test_get_metrics", "(", "fs", ")", ":", "\n", "    ", "mix", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "16000", ")", "\n", "clean", "=", "np", ".", "random", ".", "randn", "(", "2", ",", "16000", ")", "\n", "est", "=", "np", ".", "random", ".", "randn", "(", "2", ",", "16000", ")", "\n", "metrics_dict", "=", "get_metrics", "(", "mix", ",", "clean", ",", "est", ",", "sample_rate", "=", "fs", ",", "metrics_list", "=", "\"si_sdr\"", ")", "\n", "# Test no average & squeezing", "\n", "metrics_dict_bis", "=", "get_metrics", "(", "\n", "mix", "[", "0", "]", ",", "clean", ",", "est", ",", "sample_rate", "=", "fs", ",", "metrics_list", "=", "\"si_sdr\"", ",", "average", "=", "False", "\n", ")", "\n", "assert", "float", "(", "np", ".", "mean", "(", "metrics_dict_bis", "[", "\"si_sdr\"", "]", ")", ")", "==", "metrics_dict", "[", "\"si_sdr\"", "]", "\n", "assert", "float", "(", "np", ".", "mean", "(", "metrics_dict_bis", "[", "\"input_si_sdr\"", "]", ")", ")", "==", "metrics_dict", "[", "\"input_si_sdr\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.metrics_test.test_all_metrics": [[21, 27], ["numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "asteroid.metrics.get_metrics"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics"], ["", "def", "test_all_metrics", "(", ")", ":", "\n", "# This is separated because very slow (sdr, pesq, stoi)", "\n", "    ", "mix", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "4000", ")", "\n", "clean", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "4000", ")", "\n", "est", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "4000", ")", "\n", "get_metrics", "(", "mix", ",", "clean", ",", "est", ",", "sample_rate", "=", "8000", ",", "metrics_list", "=", "\"all\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.metrics_test.test_get_metrics_multichannel": [[29, 34], ["numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "asteroid.metrics.get_metrics"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics"], ["", "def", "test_get_metrics_multichannel", "(", ")", ":", "\n", "    ", "mix", "=", "np", ".", "random", ".", "randn", "(", "2", ",", "16000", ")", "\n", "clean", "=", "np", ".", "random", ".", "randn", "(", "2", ",", "16000", ")", "\n", "est", "=", "np", ".", "random", ".", "randn", "(", "2", ",", "16000", ")", "\n", "get_metrics", "(", "mix", ",", "clean", ",", "est", ",", "sample_rate", "=", "8000", ",", "metrics_list", "=", "\"si_sdr\"", ",", "average", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.metrics_test.test_error_msg": [[36, 47], ["pytest.mark.parametrize", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "unittest.mock.patch", "pytest.raises", "asteroid.metrics.get_metrics", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"filename\"", ",", "[", "None", ",", "\"example.wav\"", "]", ")", "\n", "def", "test_error_msg", "(", "filename", ")", ":", "\n", "    ", "mix", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "4000", ")", "\n", "clean", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "4000", ")", "\n", "est", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "4000", ")", "\n", "expected_msg", "=", "f\".+si_sdr.+{filename or '<unknown file>'}\"", "\n", "with", "mock", ".", "patch", "(", "\n", "\"pb_bss_eval.evaluation.si_sdr\"", ",", "side_effect", "=", "RuntimeError", "(", "\"Fatal error\"", ")", "\n", ")", ",", "pytest", ".", "raises", "(", "RuntimeError", ",", "match", "=", "expected_msg", ")", ":", "\n", "        ", "metrics_dict", "=", "get_metrics", "(", "\n", "mix", ",", "clean", ",", "est", ",", "sample_rate", "=", "8000", ",", "metrics_list", "=", "[", "\"si_sdr\"", ",", "\"pesq\"", "]", ",", "filename", "=", "filename", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.metrics_test.test_ignore_errors": [[50, 72], ["pytest.mark.parametrize", "pytest.mark.parametrize", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "unittest.mock.patch", "pytest.warns", "asteroid.metrics.get_metrics", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.get_metrics"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"average\"", ",", "[", "True", ",", "False", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"filename\"", ",", "[", "None", ",", "\"example.wav\"", "]", ")", "\n", "def", "test_ignore_errors", "(", "filename", ",", "average", ")", ":", "\n", "    ", "mix", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "4000", ")", "\n", "clean", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "4000", ")", "\n", "est", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "4000", ")", "\n", "expected_msg", "=", "f\".+si_sdr.+{filename or '<unknown file>'}.+Fatal error\"", "\n", "with", "mock", ".", "patch", "(", "\n", "\"pb_bss_eval.evaluation.si_sdr\"", ",", "side_effect", "=", "RuntimeError", "(", "\"Fatal error\"", ")", "\n", ")", ",", "pytest", ".", "warns", "(", "RuntimeWarning", ",", "match", "=", "expected_msg", ")", ":", "\n", "        ", "metrics_dict", "=", "get_metrics", "(", "\n", "mix", ",", "\n", "clean", ",", "\n", "est", ",", "\n", "sample_rate", "=", "8000", ",", "\n", "metrics_list", "=", "[", "\"si_sdr\"", ",", "\"pesq\"", "]", ",", "\n", "ignore_metrics_errors", "=", "True", ",", "\n", "average", "=", "average", ",", "\n", "filename", "=", "filename", ",", "\n", ")", "\n", "", "assert", "metrics_dict", "[", "\"si_sdr\"", "]", "is", "None", "\n", "assert", "metrics_dict", "[", "\"pesq\"", "]", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.tests.metrics_test.test_metric_tracker": [[74, 88], ["asteroid.metrics.MetricTracker", "range", "asteroid.metrics.MetricTracker.final_report", "asteroid.metrics.MetricTracker.final_report", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "asteroid.metrics.MetricTracker.", "asteroid.metrics.MetricTracker.as_df"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.MetricTracker.final_report", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.MetricTracker.final_report", "home.repos.pwc.inspect_result.mpariente_AsSteroid.asteroid.metrics.MetricTracker.as_df"], ["", "def", "test_metric_tracker", "(", ")", ":", "\n", "    ", "metric_tracker", "=", "MetricTracker", "(", "sample_rate", "=", "8000", ",", "metrics_list", "=", "[", "\"si_sdr\"", ",", "\"stoi\"", "]", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "        ", "mix", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "4000", ")", "\n", "clean", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "4000", ")", "\n", "est", "=", "np", ".", "random", ".", "randn", "(", "1", ",", "4000", ")", "\n", "metric_tracker", "(", "mix", "=", "mix", ",", "clean", "=", "clean", ",", "estimate", "=", "est", ",", "mix_path", "=", "f\"path{i}\"", ")", "\n", "\n", "# Test dump & final report", "\n", "", "metric_tracker", ".", "final_report", "(", ")", "\n", "metric_tracker", ".", "final_report", "(", "dump_path", "=", "\"final_metrics.json\"", ")", "\n", "\n", "# Check that kwargs are passed.", "\n", "assert", "\"mix_path\"", "in", "metric_tracker", ".", "as_df", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.version_consistency.dummy_test.dummy_test": [[1, 3], ["None"], "function", ["None"], ["def", "dummy_test", "(", ")", ":", "\n", "    ", "pass", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_torch_utils_test.test_jitable_shape": [[7, 21], ["pytest.mark.parametrize", "asteroid.utils.torch_utils.jitable_shape", "torch.jit.trace", "torch.jit.trace.", "torch.equal", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.utils.torch_utils.jitable_shape"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"data\"", ",", "\n", "(", "\n", "torch", ".", "tensor", "(", "[", "1", "]", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "1", ",", "2", "]", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "[", "1", "]", ",", "[", "2", "]", "]", ")", ",", "\n", "torch", ".", "tensor", "(", "[", "[", "2", ",", "5", "]", ",", "[", "3", ",", "8", "]", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "def", "test_jitable_shape", "(", "data", ")", ":", "\n", "    ", "expected", "=", "torch_utils", ".", "jitable_shape", "(", "data", ")", "\n", "scripted", "=", "torch", ".", "jit", ".", "trace", "(", "torch_utils", ".", "jitable_shape", ",", "torch", ".", "tensor", "(", "[", "1", "]", ")", ")", "\n", "output", "=", "scripted", "(", "data", ")", "\n", "assert", "torch", ".", "equal", "(", "output", ",", "expected", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_masknn_test.test_lns": [[7, 20], ["pytest.mark.parametrize", "cls", "torch.randn", "torch.jit.trace", "torch.randn", "torch.testing.assert_allclose", "torch.randn", "torch.testing.assert_allclose", "torch.jit.trace.", "cls.", "torch.jit.trace.", "cls."], "function", ["None"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"cls\"", ",", "(", "norms", ".", "GlobLN", ",", "norms", ".", "FeatsGlobLN", ",", "norms", ".", "ChanLN", ")", ")", "\n", "def", "test_lns", "(", "cls", ")", ":", "\n", "    ", "chan_size", "=", "10", "\n", "model", "=", "cls", "(", "channel_size", "=", "chan_size", ")", "\n", "x", "=", "torch", ".", "randn", "(", "1", ",", "chan_size", ",", "12", ")", "\n", "\n", "traced", "=", "torch", ".", "jit", ".", "trace", "(", "model", ",", "x", ")", "\n", "\n", "y", "=", "torch", ".", "randn", "(", "3", ",", "chan_size", ",", "18", ",", "12", ")", "\n", "assert_allclose", "(", "traced", "(", "y", ")", ",", "model", "(", "y", ")", ")", "\n", "\n", "y", "=", "torch", ".", "randn", "(", "2", ",", "chan_size", ",", "10", ",", "5", ",", "4", ")", "\n", "assert_allclose", "(", "traced", "(", "y", ")", ",", "model", "(", "y", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_masknn_test.test_cumln": [[22, 31], ["asteroid.masknn.norms.CumLN", "torch.randn", "torch.jit.trace", "torch.randn", "torch.testing.assert_allclose", "torch.jit.trace.", "norms.CumLN."], "function", ["None"], ["", "def", "test_cumln", "(", ")", ":", "\n", "    ", "chan_size", "=", "10", "\n", "model", "=", "norms", ".", "CumLN", "(", "channel_size", "=", "chan_size", ")", "\n", "x", "=", "torch", ".", "randn", "(", "1", ",", "chan_size", ",", "12", ")", "\n", "\n", "traced", "=", "torch", ".", "jit", ".", "trace", "(", "model", ",", "x", ")", "\n", "\n", "y", "=", "torch", ".", "randn", "(", "3", ",", "chan_size", ",", "100", ")", "\n", "assert_allclose", "(", "traced", "(", "y", ")", ",", "model", "(", "y", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__": [[37, 51], ["asteroid_filterbanks.make_enc_dec", "torch.nn.Identity", "asteroid.models.base_models.BaseEncoderMaskerDecoder.__init__"], "methods", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.DummyModel.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "fb_name", "=", "\"free\"", ",", "\n", "kernel_size", "=", "16", ",", "\n", "n_filters", "=", "32", ",", "\n", "stride", "=", "8", ",", "\n", "encoder_activation", "=", "None", ",", "\n", "**", "fb_kwargs", ",", "\n", ")", ":", "\n", "        ", "encoder", ",", "decoder", "=", "make_enc_dec", "(", "\n", "fb_name", ",", "kernel_size", "=", "kernel_size", ",", "n_filters", "=", "n_filters", ",", "stride", "=", "stride", ",", "**", "fb_kwargs", "\n", ")", "\n", "masker", "=", "torch", ".", "nn", ".", "Identity", "(", ")", "\n", "super", "(", ")", ".", "__init__", "(", "encoder", ",", "masker", ",", "decoder", ",", "encoder_activation", "=", "encoder_activation", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_filterbanks_test.test_jit_filterbanks": [[8, 34], ["pytest.mark.parametrize", "pytest.mark.parametrize", "jit_filterbanks_test.DummyModel", "model.eval.eval", "torch.jit.trace", "torch.no_grad", "model.eval.", "torch.jit.trace.", "torch.testing.assert_allclose", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "function", ["None"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"filter_bank_name\"", ",", "\n", "(", "\"free\"", ",", "\"stft\"", ",", "\"analytic_free\"", ",", "\"param_sinc\"", ")", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"inference_data\"", ",", "\n", "(", "\n", "(", "torch", ".", "rand", "(", "240", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "1", ",", "220", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "4", ",", "256", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "1", ",", "3", ",", "312", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "3", ",", "2", ",", "128", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "1", ",", "1", ",", "3", ",", "212", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "2", ",", "4", ",", "3", ",", "128", ")", "-", "0.5", ")", "*", "2", ",", "\n", ")", ",", "\n", ")", "\n", "def", "test_jit_filterbanks", "(", "filter_bank_name", ",", "inference_data", ")", ":", "\n", "    ", "model", "=", "DummyModel", "(", "fb_name", "=", "filter_bank_name", ")", "\n", "model", "=", "model", ".", "eval", "(", ")", "\n", "\n", "inputs", "=", "(", "(", "torch", ".", "rand", "(", "1", ",", "200", ")", "-", "0.5", ")", "*", "2", ",", ")", "\n", "traced", "=", "torch", ".", "jit", ".", "trace", "(", "model", ",", "inputs", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "res", "=", "model", "(", "inference_data", ")", "\n", "out", "=", "traced", "(", "inference_data", ")", "\n", "assert_allclose", "(", "res", ",", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_models_test.assert_consistency": [[19, 24], ["torch.no_grad", "model", "traced", "torch.testing.assert_allclose"], "function", ["None"], ["@", "torch", ".", "no_grad", "(", ")", "\n", "def", "assert_consistency", "(", "model", ",", "traced", ",", "tensor", ")", ":", "\n", "    ", "ref", "=", "model", "(", "tensor", ")", "\n", "out", "=", "traced", "(", "tensor", ")", "\n", "assert_allclose", "(", "ref", ",", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_models_test.small_model_params": [[26, 134], ["pytest.fixture", "dict"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"module\"", ")", "\n", "def", "small_model_params", "(", ")", ":", "\n", "    ", "params", "=", "{", "\n", "ConvTasNet", ".", "__name__", ":", "{", "\n", "\"model_cls\"", ":", "ConvTasNet", ",", "\n", "\"model_args\"", ":", "{", "\n", "\"n_src\"", ":", "2", ",", "\n", "\"n_repeats\"", ":", "2", ",", "\n", "\"n_blocks\"", ":", "2", ",", "\n", "\"bn_chan\"", ":", "8", ",", "\n", "\"hid_chan\"", ":", "4", ",", "\n", "\"skip_chan\"", ":", "4", ",", "\n", "\"n_filters\"", ":", "32", ",", "\n", "\"kernel_size\"", ":", "32", ",", "\n", "\"stride\"", ":", "16", ",", "\n", "}", ",", "\n", "}", ",", "\n", "DPRNNTasNet", ".", "__name__", ":", "{", "\n", "\"model_cls\"", ":", "DPRNNTasNet", ",", "\n", "\"model_args\"", ":", "{", "\n", "\"n_src\"", ":", "2", ",", "\n", "\"n_repeats\"", ":", "2", ",", "\n", "\"bn_chan\"", ":", "8", ",", "\n", "\"hid_size\"", ":", "4", ",", "\n", "\"chunk_size\"", ":", "3", ",", "\n", "\"n_filters\"", ":", "32", ",", "\n", "\"kernel_size\"", ":", "32", ",", "\n", "\"stride\"", ":", "16", ",", "\n", "\"use_mulcat\"", ":", "False", ",", "\n", "}", ",", "\n", "}", ",", "\n", "DPTNet", ".", "__name__", ":", "{", "\n", "\"model_cls\"", ":", "DPTNet", ",", "\n", "\"model_args\"", ":", "{", "\n", "\"n_src\"", ":", "2", ",", "\n", "\"n_heads\"", ":", "2", ",", "\n", "\"ff_hid\"", ":", "4", ",", "\n", "\"chunk_size\"", ":", "4", ",", "\n", "\"n_repeats\"", ":", "1", ",", "\n", "\"n_filters\"", ":", "32", ",", "\n", "\"kernel_size\"", ":", "32", ",", "\n", "\"stride\"", ":", "16", ",", "\n", "}", ",", "\n", "}", ",", "\n", "DCCRNet", ".", "__name__", ":", "{", "\n", "\"model_cls\"", ":", "DCCRNet", ",", "\n", "\"model_args\"", ":", "{", "\n", "\"stft_n_filters\"", ":", "512", ",", "\n", "\"stft_kernel_size\"", ":", "256", ",", "\n", "\"stft_stride\"", ":", "100", ",", "\n", "\"architecture\"", ":", "\"mini\"", ",", "\n", "}", ",", "\n", "}", ",", "\n", "DeMask", ".", "__name__", ":", "{", "\n", "\"model_cls\"", ":", "DeMask", ",", "\n", "\"model_args\"", ":", "{", "\n", "\"input_type\"", ":", "\"mag\"", ",", "\n", "\"output_type\"", ":", "\"mag\"", ",", "\n", "\"hidden_dims\"", ":", "[", "64", "]", ",", "\n", "\"dropout\"", ":", "0", ",", "\n", "\"activation\"", ":", "\"relu\"", ",", "\n", "\"mask_act\"", ":", "\"relu\"", ",", "\n", "\"norm_type\"", ":", "\"gLN\"", ",", "\n", "\"stride\"", ":", "16", ",", "\n", "\"n_filters\"", ":", "32", ",", "\n", "\"kernel_size\"", ":", "32", ",", "\n", "}", ",", "\n", "}", ",", "\n", "LSTMTasNet", ".", "__name__", ":", "{", "\n", "\"model_cls\"", ":", "LSTMTasNet", ",", "\n", "\"model_args\"", ":", "{", "\n", "\"n_src\"", ":", "2", ",", "\n", "\"hid_size\"", ":", "4", ",", "\n", "\"n_layers\"", ":", "2", ",", "\n", "\"dropout\"", ":", "0.0", ",", "\n", "\"n_filters\"", ":", "32", ",", "\n", "\"kernel_size\"", ":", "32", ",", "\n", "\"stride\"", ":", "16", ",", "\n", "}", ",", "\n", "}", ",", "\n", "SuDORMRFNet", ".", "__name__", ":", "{", "\n", "\"model_cls\"", ":", "SuDORMRFNet", ",", "\n", "\"model_args\"", ":", "{", "\n", "\"n_src\"", ":", "2", ",", "\n", "\"bn_chan\"", ":", "10", ",", "\n", "\"num_blocks\"", ":", "2", ",", "\n", "\"upsampling_depth\"", ":", "2", ",", "\n", "\"n_filters\"", ":", "32", ",", "\n", "\"kernel_size\"", ":", "21", ",", "\n", "\"stride\"", ":", "10", ",", "\n", "}", ",", "\n", "}", ",", "\n", "SuDORMRFImprovedNet", ".", "__name__", ":", "{", "\n", "\"model_cls\"", ":", "SuDORMRFImprovedNet", ",", "\n", "\"model_args\"", ":", "{", "\n", "\"n_src\"", ":", "2", ",", "\n", "\"bn_chan\"", ":", "10", ",", "\n", "\"num_blocks\"", ":", "2", ",", "\n", "\"upsampling_depth\"", ":", "2", ",", "\n", "\"n_filters\"", ":", "32", ",", "\n", "\"kernel_size\"", ":", "21", ",", "\n", "\"stride\"", ":", "10", ",", "\n", "}", ",", "\n", "}", ",", "\n", "}", "\n", "params", "[", "\"DPRNNTasNet_mulcat\"", "]", "=", "dict", "(", "params", "[", "DPRNNTasNet", ".", "__name__", "]", ")", "\n", "params", "[", "\"DPRNNTasNet_mulcat\"", "]", "[", "\"model_args\"", "]", "[", "\"use_mulcat\"", "]", "=", "True", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_models_test.test_enhancement_model": [[136, 156], ["pytest.mark.parametrize", "pytest.mark.parametrize", "jit_models_test.get_default_device", "model.eval().to.eval().to", "torch.jit.trace", "jit_models_test.assert_consistency", "model.eval().to.eval", "test_data.to", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_models_test.get_default_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_models_test.assert_consistency"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"model_name\"", ",", "[", "\"DCCRNet\"", ",", "\"DeMask\"", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"test_data\"", ",", "\n", "(", "\n", "(", "torch", ".", "rand", "(", "2001", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "1", ",", "4720", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "4", ",", "1100", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "1", ",", "1", ",", "1502", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "3", ",", "1", ",", "4301", ")", "-", "0.5", ")", "*", "2", ",", "\n", ")", ",", "\n", ")", "\n", "def", "test_enhancement_model", "(", "small_model_params", ",", "model_name", ",", "test_data", ")", ":", "\n", "    ", "device", "=", "get_default_device", "(", ")", "\n", "model_def", "=", "small_model_params", "[", "model_name", "]", "\n", "model", "=", "model_def", "[", "\"model_cls\"", "]", "(", "**", "model_def", "[", "\"model_args\"", "]", ")", "\n", "model", "=", "model", ".", "eval", "(", ")", ".", "to", "(", "device", ")", "\n", "# Random input uniformly distributed in [-1, 1]", "\n", "inputs", "=", "(", "(", "torch", ".", "rand", "(", "1", ",", "2500", ",", "device", "=", "device", ")", "-", "0.5", ")", "*", "2", ",", ")", "\n", "traced", "=", "torch", ".", "jit", ".", "trace", "(", "model", ",", "inputs", ")", "\n", "assert_consistency", "(", "model", "=", "model", ",", "traced", "=", "traced", ",", "tensor", "=", "test_data", ".", "to", "(", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_models_test.test_dcunet_model": [[158, 170], ["pytest.mark.parametrize", "pytest.mark.parametrize", "jit_models_test.get_default_device", "asteroid.models.DCUNet().eval().to", "torch.rand", "torch.jit.trace", "torch.rand", "jit_models_test.assert_consistency", "asteroid.models.DCUNet().eval", "torch.rand.to", "asteroid.models.DCUNet"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_models_test.get_default_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_models_test.assert_consistency"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"test_shape\"", ",", "[", "(", "2", ",", ")", ",", "(", "3", ",", "1", ")", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"matching_samples\"", ",", "[", "4701", ",", "8800", ",", "17001", "]", ")", "\n", "def", "test_dcunet_model", "(", "test_shape", ":", "Tuple", ",", "matching_samples", ")", ":", "\n", "    ", "n_samples", "=", "5010", "\n", "device", "=", "get_default_device", "(", ")", "\n", "model", "=", "DCUNet", "(", "architecture", "=", "\"mini\"", ",", "fix_length_mode", "=", "\"pad\"", ")", ".", "eval", "(", ")", ".", "to", "(", "device", ")", "\n", "# Random input uniformly distributed in [-1, 1]", "\n", "inputs", "=", "torch", ".", "rand", "(", "1", ",", "n_samples", ",", "device", "=", "device", ")", "\n", "traced", "=", "torch", ".", "jit", ".", "trace", "(", "model", ",", "(", "inputs", ",", ")", ")", "\n", "\n", "test_data", "=", "torch", ".", "rand", "(", "*", "test_shape", ",", "matching_samples", ",", "device", "=", "device", ")", "\n", "assert_consistency", "(", "model", "=", "model", ",", "traced", "=", "traced", ",", "tensor", "=", "test_data", ".", "to", "(", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_models_test.test_trace_bss_model": [[172, 206], ["pytest.mark.parametrize", "pytest.mark.parametrize", "jit_models_test.get_default_device", "model.eval().to.eval().to", "torch.jit.trace", "jit_models_test.assert_consistency", "model.eval().to.eval", "test_data.to", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "function", ["home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_models_test.get_default_device", "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_models_test.assert_consistency"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"model_name\"", ",", "\n", "(", "\n", "\"ConvTasNet\"", ",", "\n", "\"DPRNNTasNet\"", ",", "\n", "\"DPRNNTasNet_mulcat\"", ",", "\n", "\"DPTNet\"", ",", "\n", "\"LSTMTasNet\"", ",", "\n", "\"SuDORMRFNet\"", ",", "\n", "\"SuDORMRFImprovedNet\"", ",", "\n", ")", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"test_data\"", ",", "\n", "(", "\n", "(", "torch", ".", "rand", "(", "240", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "1", ",", "220", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "3", ",", "250", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "1", ",", "1", ",", "301", ")", "-", "0.5", ")", "*", "2", ",", "\n", "(", "torch", ".", "rand", "(", "2", ",", "1", ",", "501", ")", "-", "0.5", ")", "*", "2", ",", "\n", ")", ",", "\n", ")", "\n", "def", "test_trace_bss_model", "(", "small_model_params", ",", "model_name", ",", "test_data", ")", ":", "\n", "    ", "device", "=", "get_default_device", "(", ")", "\n", "model_def", "=", "small_model_params", "[", "model_name", "]", "\n", "model", "=", "model_def", "[", "\"model_cls\"", "]", "(", "**", "model_def", "[", "\"model_args\"", "]", ")", "\n", "# params = small_model_params[model_def.__name__]", "\n", "# model = model_def(**params)", "\n", "model", "=", "model", ".", "eval", "(", ")", ".", "to", "(", "device", ")", "\n", "# Random input uniformly distributed in [-1, 1]", "\n", "inputs", "=", "(", "(", "torch", ".", "rand", "(", "1", ",", "201", ",", "device", "=", "device", ")", "-", "0.5", ")", "*", "2", ",", ")", "\n", "traced", "=", "torch", ".", "jit", ".", "trace", "(", "model", ",", "inputs", ")", "\n", "\n", "assert_consistency", "(", "model", "=", "model", ",", "traced", "=", "traced", ",", "tensor", "=", "test_data", ".", "to", "(", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mpariente_AsSteroid.jit.jit_models_test.get_default_device": [[208, 212], ["torch.cuda.is_available"], "function", ["None"], ["", "def", "get_default_device", "(", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "\"cuda\"", "\n", "", "return", "\"cpu\"", "\n", "", ""]]}