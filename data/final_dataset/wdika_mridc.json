{"home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand.__call_checker": [[76, 87], ["list", "list.append", "setup.StyleCommand.announce", "subprocess.call", "list.extend"], "methods", ["None"], ["def", "__call_checker", "(", "self", ",", "base_command", ",", "scope", ",", "check", ")", ":", "\n", "        ", "command", "=", "list", "(", "base_command", ")", "\n", "\n", "command", ".", "append", "(", "scope", ")", "\n", "\n", "if", "check", ":", "\n", "            ", "command", ".", "extend", "(", "[", "\"--check\"", ",", "\"--diff\"", "]", ")", "\n", "\n", "", "self", ".", "announce", "(", "msg", "=", "f'Running command: {\" \".join(command)}'", ",", "level", "=", "distutils_log", ".", "INFO", ")", "\n", "\n", "return", "subprocess", ".", "call", "(", "command", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand._isort": [[88, 90], ["setup.StyleCommand.__call_checker", "setup.StyleCommand.__ISORT_BASE.split"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand.__call_checker"], ["", "def", "_isort", "(", "self", ",", "scope", ",", "check", ")", ":", "\n", "        ", "return", "self", ".", "__call_checker", "(", "base_command", "=", "self", ".", "__ISORT_BASE", ".", "split", "(", ")", ",", "scope", "=", "scope", ",", "check", "=", "check", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand._black": [[91, 93], ["setup.StyleCommand.__call_checker", "setup.StyleCommand.__BLACK_BASE.split"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand.__call_checker"], ["", "def", "_black", "(", "self", ",", "scope", ",", "check", ")", ":", "\n", "        ", "return", "self", ".", "__call_checker", "(", "base_command", "=", "self", ".", "__BLACK_BASE", ".", "split", "(", ")", ",", "scope", "=", "scope", ",", "check", "=", "check", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand._pass": [[94, 96], ["setup.StyleCommand.announce"], "methods", ["None"], ["", "def", "_pass", "(", "self", ")", ":", "\n", "        ", "self", ".", "announce", "(", "msg", "=", "\"\\033[32mPASS\\x1b[0m\"", ",", "level", "=", "distutils_log", ".", "INFO", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand._fail": [[97, 99], ["setup.StyleCommand.announce"], "methods", ["None"], ["", "def", "_fail", "(", "self", ")", ":", "\n", "        ", "self", ".", "announce", "(", "msg", "=", "\"\\033[31mFAIL\\x1b[0m\"", ",", "level", "=", "distutils_log", ".", "INFO", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand.initialize_options": [[101, 104], ["None"], "methods", ["None"], ["", "def", "initialize_options", "(", "self", ")", ":", "\n", "        ", "self", ".", "scope", "=", "\".\"", "\n", "self", ".", "fix", "=", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand.run": [[105, 115], ["setup.StyleCommand._isort", "setup.StyleCommand._black", "setup.StyleCommand._pass", "setup.StyleCommand._fail", "sys.exit"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand._isort", "home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand._black", "home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand._pass", "home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand._fail"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "scope", ",", "check", "=", "self", ".", "scope", ",", "not", "self", ".", "fix", "\n", "isort_return", "=", "self", ".", "_isort", "(", "scope", "=", "scope", ",", "check", "=", "check", ")", "\n", "black_return", "=", "self", ".", "_black", "(", "scope", "=", "scope", ",", "check", "=", "check", ")", "\n", "\n", "if", "isort_return", "==", "0", "and", "black_return", "==", "0", ":", "\n", "            ", "self", ".", "_pass", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_fail", "(", ")", "\n", "sys", ".", "exit", "(", "isort_return", "if", "isort_return", "!=", "0", "else", "black_return", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.None.setup.StyleCommand.finalize_options": [[116, 118], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "finalize_options", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.None.setup._load_requirements": [[40, 49], ["open", "line.strip.strip", "pathlib.Path", "pathlib.Path", "requirements.append", "line.strip.startswith"], "function", ["None"], ["def", "_load_requirements", "(", "requirements_file", ",", "folder", "=", "\"requirements\"", ")", ":", "\n", "    ", "\"\"\"Load requirements from a file.\"\"\"", "\n", "requirements", "=", "[", "]", "\n", "with", "open", "(", "Path", "(", "folder", ")", "/", "Path", "(", "requirements_file", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "and", "not", "line", ".", "startswith", "(", "\"#\"", ")", ":", "\n", "                ", "requirements", ".", "append", "(", "line", ")", "\n", "", "", "", "return", "requirements", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_transforms.test_to_tensor": [[12, 28], ["pytest.mark.parametrize", "mridc.collections.common.parts.utils.to_tensor", "mridc.collections.common.parts.utils.to_tensor.dim", "numpy.zeros().astype", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.to_tensor"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"x\"", ",", "[", "(", "np", ".", "zeros", "(", "[", "1", ",", "320", ",", "320", "]", ")", ".", "astype", "(", "np", ".", "complex64", ")", ")", "]", ")", "\n", "def", "test_to_tensor", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    Test if the to_tensor function works as expected.\n\n    Args:\n        x: The input array.\n\n    Returns:\n        None\n    \"\"\"", "\n", "x", "=", "to_tensor", "(", "x", ")", "\n", "if", "x", ".", "dim", "(", ")", "!=", "4", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "x", ".", "shape", "[", "-", "1", "]", "!=", "2", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_transforms.test_tensor_to_complex_np": [[30, 46], ["pytest.mark.parametrize", "mridc.collections.common.parts.utils.tensor_to_complex_np", "torch.zeros().type", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.tensor_to_complex_np"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"x\"", ",", "[", "(", "torch", ".", "zeros", "(", "[", "1", ",", "320", ",", "320", ",", "2", "]", ")", ".", "type", "(", "torch", ".", "complex64", ")", ")", "]", ")", "\n", "def", "test_tensor_to_complex_np", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    Test if the tensor_to_complex_np function works as expected.\n\n    Args:\n        x: The input array.\n\n    Returns:\n        None\n    \"\"\"", "\n", "x", "=", "tensor_to_complex_np", "(", "x", ")", "\n", "if", "x", ".", "ndim", "!=", "3", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "x", ".", "shape", "[", "-", "1", "]", "==", "2", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_transforms.test_center_crop": [[48, 63], ["pytest.mark.parametrize", "mridc.collections.reconstruction.parts.utils.center_crop", "torch.zeros().type", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"x, crop_size\"", ",", "[", "(", "torch", ".", "zeros", "(", "[", "320", ",", "320", "]", ")", ".", "type", "(", "torch", ".", "complex64", ")", ",", "(", "160", ",", "160", ")", ")", "]", ")", "\n", "def", "test_center_crop", "(", "x", ",", "crop_size", ")", ":", "\n", "    ", "\"\"\"\n    Test if the center_crop function works as expected.\n\n    Args:\n        x: The input array.\n        crop_size: The size of the crop.\n\n    Returns:\n        None\n    \"\"\"", "\n", "x", "=", "center_crop", "(", "x", ",", "crop_size", ")", "\n", "if", "x", ".", "shape", "!=", "crop_size", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_transforms.test_complex_center_crop": [[65, 80], ["pytest.mark.parametrize", "mridc.collections.reconstruction.parts.utils.complex_center_crop", "torch.zeros().type", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_center_crop"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"x, crop_size\"", ",", "[", "(", "torch", ".", "zeros", "(", "[", "320", ",", "320", ",", "2", "]", ")", ".", "type", "(", "torch", ".", "complex64", ")", ",", "(", "160", ",", "160", ")", ")", "]", ")", "\n", "def", "test_complex_center_crop", "(", "x", ",", "crop_size", ")", ":", "\n", "    ", "\"\"\"\n    Test if the center_crop function works as expected.\n\n    Args:\n        x: The input array.\n        crop_size: The size of the crop.\n\n    Returns:\n        None\n    \"\"\"", "\n", "x", "=", "complex_center_crop", "(", "x", ",", "crop_size", ")", "\n", "if", "x", ".", "shape", "[", ":", "-", "1", "]", "!=", "crop_size", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_transforms.test_center_crop_to_smallest": [[82, 99], ["pytest.mark.parametrize", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "torch.zeros().type", "torch.zeros().type", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"x, y\"", ",", "[", "(", "torch", ".", "zeros", "(", "[", "1", ",", "320", ",", "320", "]", ")", ".", "type", "(", "torch", ".", "complex64", ")", ",", "torch", ".", "zeros", "(", "[", "1", ",", "160", ",", "160", "]", ")", ".", "type", "(", "torch", ".", "complex64", ")", ")", "]", "\n", ")", "\n", "def", "test_center_crop_to_smallest", "(", "x", ",", "y", ")", ":", "\n", "    ", "\"\"\"\n    Test if the center_crop_to_smallest function works as expected.\n\n    Args:\n        x: The input array.\n        y: The input array.\n\n    Returns:\n        None\n    \"\"\"", "\n", "x", ",", "y", "=", "center_crop_to_smallest", "(", "x", ",", "y", ")", "\n", "if", "x", ".", "shape", "!=", "y", ".", "shape", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_fft.test_centered_fft2": [[15, 38], ["pytest.mark.parametrize", "tests.collections.reconstruction.fastmri.conftest.create_input", "mridc.collections.common.parts.fft.fft2().numpy", "mridc.collections.common.parts.utils.tensor_to_complex_np", "numpy.fft.ifftshift", "numpy.fft.fft2", "numpy.fft.fftshift", "numpy.allclose", "mridc.collections.common.parts.fft.fft2"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.tensor_to_complex_np", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "3", ",", "3", "]", ",", "[", "4", ",", "6", "]", ",", "[", "10", ",", "8", ",", "4", "]", "]", ")", "\n", "def", "test_centered_fft2", "(", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Test centered 2D Fast Fourier Transform.\n\n    Args:\n        shape: shape of the input\n\n    Returns:\n        None\n    \"\"\"", "\n", "shape", "=", "shape", "+", "[", "2", "]", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "out_torch", "=", "fft2", "(", "x", ",", "centered", "=", "True", ",", "normalization", "=", "\"ortho\"", ",", "spatial_dims", "=", "[", "-", "2", ",", "-", "1", "]", ")", ".", "numpy", "(", ")", "\n", "out_torch", "=", "out_torch", "[", "...", ",", "0", "]", "+", "1j", "*", "out_torch", "[", "...", ",", "1", "]", "\n", "\n", "input_numpy", "=", "tensor_to_complex_np", "(", "x", ")", "\n", "input_numpy", "=", "np", ".", "fft", ".", "ifftshift", "(", "input_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fft2", "(", "input_numpy", ",", "norm", "=", "\"ortho\"", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fftshift", "(", "out_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "if", "not", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_fft.test_non_centered_fft2": [[40, 61], ["pytest.mark.parametrize", "tests.collections.reconstruction.fastmri.conftest.create_input", "mridc.collections.common.parts.fft.fft2().numpy", "mridc.collections.common.parts.utils.tensor_to_complex_np", "numpy.fft.fft2", "numpy.allclose", "mridc.collections.common.parts.fft.fft2"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.tensor_to_complex_np", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "3", ",", "3", "]", ",", "[", "4", ",", "6", "]", ",", "[", "10", ",", "8", ",", "4", "]", "]", ")", "\n", "def", "test_non_centered_fft2", "(", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Test non-centered 2D Fast Fourier Transform.\n\n    Args:\n        shape: shape of the input\n\n    Returns:\n        None\n    \"\"\"", "\n", "shape", "=", "shape", "+", "[", "2", "]", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "out_torch", "=", "fft2", "(", "x", ",", "centered", "=", "False", ",", "normalization", "=", "\"ortho\"", ",", "spatial_dims", "=", "[", "-", "2", ",", "-", "1", "]", ")", ".", "numpy", "(", ")", "\n", "out_torch", "=", "out_torch", "[", "...", ",", "0", "]", "+", "1j", "*", "out_torch", "[", "...", ",", "1", "]", "\n", "\n", "input_numpy", "=", "tensor_to_complex_np", "(", "x", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fft2", "(", "input_numpy", ",", "norm", "=", "\"ortho\"", ")", "\n", "\n", "if", "not", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_fft.test_centered_fft2_backward_normalization": [[63, 86], ["pytest.mark.parametrize", "tests.collections.reconstruction.fastmri.conftest.create_input", "mridc.collections.common.parts.fft.fft2().numpy", "mridc.collections.common.parts.utils.tensor_to_complex_np", "numpy.fft.ifftshift", "numpy.fft.fft2", "numpy.fft.fftshift", "numpy.allclose", "mridc.collections.common.parts.fft.fft2"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.tensor_to_complex_np", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "3", ",", "3", "]", ",", "[", "4", ",", "6", "]", ",", "[", "10", ",", "8", ",", "4", "]", "]", ")", "\n", "def", "test_centered_fft2_backward_normalization", "(", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Test centered 2D Fast Fourier Transform with backward normalization.\n\n    Args:\n        shape: shape of the input\n\n    Returns:\n        None\n    \"\"\"", "\n", "shape", "=", "shape", "+", "[", "2", "]", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "out_torch", "=", "fft2", "(", "x", ",", "centered", "=", "True", ",", "normalization", "=", "\"backward\"", ",", "spatial_dims", "=", "[", "-", "2", ",", "-", "1", "]", ")", ".", "numpy", "(", ")", "\n", "out_torch", "=", "out_torch", "[", "...", ",", "0", "]", "+", "1j", "*", "out_torch", "[", "...", ",", "1", "]", "\n", "\n", "input_numpy", "=", "tensor_to_complex_np", "(", "x", ")", "\n", "input_numpy", "=", "np", ".", "fft", ".", "ifftshift", "(", "input_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fft2", "(", "input_numpy", ",", "norm", "=", "\"backward\"", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fftshift", "(", "out_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "if", "not", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_fft.test_centered_fft2_forward_normalization": [[88, 111], ["pytest.mark.parametrize", "tests.collections.reconstruction.fastmri.conftest.create_input", "mridc.collections.common.parts.fft.fft2().numpy", "mridc.collections.common.parts.utils.tensor_to_complex_np", "numpy.fft.ifftshift", "numpy.fft.fft2", "numpy.fft.fftshift", "numpy.allclose", "mridc.collections.common.parts.fft.fft2"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.tensor_to_complex_np", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "3", ",", "3", "]", ",", "[", "4", ",", "6", "]", ",", "[", "10", ",", "8", ",", "4", "]", "]", ")", "\n", "def", "test_centered_fft2_forward_normalization", "(", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Test centered 2D Fast Fourier Transform with forward normalization.\n\n    Args:\n        shape: shape of the input\n\n    Returns:\n        None\n    \"\"\"", "\n", "shape", "=", "shape", "+", "[", "2", "]", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "out_torch", "=", "fft2", "(", "x", ",", "centered", "=", "True", ",", "normalization", "=", "\"forward\"", ",", "spatial_dims", "=", "[", "-", "2", ",", "-", "1", "]", ")", ".", "numpy", "(", ")", "\n", "out_torch", "=", "out_torch", "[", "...", ",", "0", "]", "+", "1j", "*", "out_torch", "[", "...", ",", "1", "]", "\n", "\n", "input_numpy", "=", "tensor_to_complex_np", "(", "x", ")", "\n", "input_numpy", "=", "np", ".", "fft", ".", "ifftshift", "(", "input_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fft2", "(", "input_numpy", ",", "norm", "=", "\"forward\"", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fftshift", "(", "out_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "if", "not", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_fft.test_centered_ifft2": [[113, 136], ["pytest.mark.parametrize", "tests.collections.reconstruction.fastmri.conftest.create_input", "mridc.collections.common.parts.fft.ifft2().numpy", "mridc.collections.common.parts.utils.tensor_to_complex_np", "numpy.fft.ifftshift", "numpy.fft.ifft2", "numpy.fft.fftshift", "numpy.allclose", "mridc.collections.common.parts.fft.ifft2"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.tensor_to_complex_np", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "3", ",", "3", "]", ",", "[", "4", ",", "6", "]", ",", "[", "10", ",", "8", ",", "4", "]", "]", ")", "\n", "def", "test_centered_ifft2", "(", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Test centered 2D Inverse Fast Fourier Transform.\n\n    Args:\n        shape: shape of the input\n\n    Returns:\n        None\n    \"\"\"", "\n", "shape", "=", "shape", "+", "[", "2", "]", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "out_torch", "=", "ifft2", "(", "x", ",", "centered", "=", "True", ",", "normalization", "=", "\"ortho\"", ",", "spatial_dims", "=", "[", "-", "2", ",", "-", "1", "]", ")", ".", "numpy", "(", ")", "\n", "out_torch", "=", "out_torch", "[", "...", ",", "0", "]", "+", "1j", "*", "out_torch", "[", "...", ",", "1", "]", "\n", "\n", "input_numpy", "=", "tensor_to_complex_np", "(", "x", ")", "\n", "input_numpy", "=", "np", ".", "fft", ".", "ifftshift", "(", "input_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "ifft2", "(", "input_numpy", ",", "norm", "=", "\"ortho\"", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fftshift", "(", "out_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "if", "not", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_fft.test_non_centered_ifft2": [[138, 159], ["pytest.mark.parametrize", "tests.collections.reconstruction.fastmri.conftest.create_input", "mridc.collections.common.parts.fft.ifft2().numpy", "mridc.collections.common.parts.utils.tensor_to_complex_np", "numpy.fft.ifft2", "numpy.allclose", "mridc.collections.common.parts.fft.ifft2"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.tensor_to_complex_np", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "3", ",", "3", "]", ",", "[", "4", ",", "6", "]", ",", "[", "10", ",", "8", ",", "4", "]", "]", ")", "\n", "def", "test_non_centered_ifft2", "(", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Test non-centered 2D Inverse Fast Fourier Transform.\n\n    Args:\n        shape: shape of the input\n\n    Returns:\n        None\n    \"\"\"", "\n", "shape", "=", "shape", "+", "[", "2", "]", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "out_torch", "=", "ifft2", "(", "x", ",", "centered", "=", "False", ",", "normalization", "=", "\"ortho\"", ",", "spatial_dims", "=", "[", "-", "2", ",", "-", "1", "]", ")", ".", "numpy", "(", ")", "\n", "out_torch", "=", "out_torch", "[", "...", ",", "0", "]", "+", "1j", "*", "out_torch", "[", "...", ",", "1", "]", "\n", "\n", "input_numpy", "=", "tensor_to_complex_np", "(", "x", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "ifft2", "(", "input_numpy", ",", "norm", "=", "\"ortho\"", ")", "\n", "\n", "if", "not", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_fft.test_centered_ifft2_backward_normalization": [[161, 184], ["pytest.mark.parametrize", "tests.collections.reconstruction.fastmri.conftest.create_input", "mridc.collections.common.parts.fft.ifft2().numpy", "mridc.collections.common.parts.utils.tensor_to_complex_np", "numpy.fft.ifftshift", "numpy.fft.ifft2", "numpy.fft.fftshift", "numpy.allclose", "mridc.collections.common.parts.fft.ifft2"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.tensor_to_complex_np", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "3", ",", "3", "]", ",", "[", "4", ",", "6", "]", ",", "[", "10", ",", "8", ",", "4", "]", "]", ")", "\n", "def", "test_centered_ifft2_backward_normalization", "(", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Test centered 2D Inverse Fast Fourier Transform with backward normalization.\n\n    Args:\n        shape: shape of the input\n\n    Returns:\n        None\n    \"\"\"", "\n", "shape", "=", "shape", "+", "[", "2", "]", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "out_torch", "=", "ifft2", "(", "x", ",", "centered", "=", "True", ",", "normalization", "=", "\"backward\"", ",", "spatial_dims", "=", "[", "-", "2", ",", "-", "1", "]", ")", ".", "numpy", "(", ")", "\n", "out_torch", "=", "out_torch", "[", "...", ",", "0", "]", "+", "1j", "*", "out_torch", "[", "...", ",", "1", "]", "\n", "\n", "input_numpy", "=", "tensor_to_complex_np", "(", "x", ")", "\n", "input_numpy", "=", "np", ".", "fft", ".", "ifftshift", "(", "input_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "ifft2", "(", "input_numpy", ",", "norm", "=", "\"backward\"", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fftshift", "(", "out_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "if", "not", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_fft.test_centered_ifft2_forward_normalization": [[186, 209], ["pytest.mark.parametrize", "tests.collections.reconstruction.fastmri.conftest.create_input", "mridc.collections.common.parts.fft.ifft2().numpy", "mridc.collections.common.parts.utils.tensor_to_complex_np", "numpy.fft.ifftshift", "numpy.fft.ifft2", "numpy.fft.fftshift", "numpy.allclose", "mridc.collections.common.parts.fft.ifft2"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.tensor_to_complex_np", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "3", ",", "3", "]", ",", "[", "4", ",", "6", "]", ",", "[", "10", ",", "8", ",", "4", "]", "]", ")", "\n", "def", "test_centered_ifft2_forward_normalization", "(", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Test centered 2D Inverse Fast Fourier Transform with forward normalization.\n\n    Args:\n        shape: shape of the input\n\n    Returns:\n        None\n    \"\"\"", "\n", "shape", "=", "shape", "+", "[", "2", "]", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "out_torch", "=", "ifft2", "(", "x", ",", "centered", "=", "True", ",", "normalization", "=", "\"forward\"", ",", "spatial_dims", "=", "[", "-", "2", ",", "-", "1", "]", ")", ".", "numpy", "(", ")", "\n", "out_torch", "=", "out_torch", "[", "...", ",", "0", "]", "+", "1j", "*", "out_torch", "[", "...", ",", "1", "]", "\n", "\n", "input_numpy", "=", "tensor_to_complex_np", "(", "x", ")", "\n", "input_numpy", "=", "np", ".", "fft", ".", "ifftshift", "(", "input_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "ifft2", "(", "input_numpy", ",", "norm", "=", "\"forward\"", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fftshift", "(", "out_numpy", ",", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "if", "not", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_fft.test_complex_abs": [[211, 230], ["pytest.mark.parametrize", "tests.collections.reconstruction.fastmri.conftest.create_input", "mridc.collections.common.parts.utils.complex_abs().numpy", "mridc.collections.common.parts.utils.tensor_to_complex_np", "numpy.abs", "numpy.allclose", "mridc.collections.common.parts.utils.complex_abs"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.tensor_to_complex_np", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_abs"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "3", ",", "3", "]", ",", "[", "4", ",", "6", "]", ",", "[", "10", ",", "8", ",", "4", "]", "]", ")", "\n", "def", "test_complex_abs", "(", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Test complex absolute value.\n\n    Args:\n        shape: shape of the input\n\n    Returns:\n        None\n    \"\"\"", "\n", "shape", "=", "shape", "+", "[", "2", "]", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "out_torch", "=", "complex_abs", "(", "x", ")", ".", "numpy", "(", ")", "\n", "input_numpy", "=", "tensor_to_complex_np", "(", "x", ")", "\n", "out_numpy", "=", "np", ".", "abs", "(", "input_numpy", ")", "\n", "\n", "if", "not", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_fft.test_roll": [[232, 258], ["pytest.mark.parametrize", "pytest.mark.parametrize", "numpy.arange().reshape", "mridc.collections.common.parts.fft.roll().numpy", "numpy.roll", "isinstance", "isinstance", "numpy.allclose", "numpy.arange", "mridc.collections.common.parts.fft.roll", "numpy.product", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.roll", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.roll"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shift, dim\"", ",", "[", "(", "0", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "-", "1", ",", "0", ")", ",", "(", "100", ",", "0", ")", ",", "(", "[", "1", ",", "2", "]", ",", "[", "1", ",", "2", "]", ")", "]", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "5", ",", "6", ",", "2", "]", ",", "[", "3", ",", "4", ",", "5", "]", "]", ")", "\n", "def", "test_roll", "(", "shift", ",", "dim", ",", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Test roll.\n\n    Args:\n        shift: shift of the input\n        dim: dimension of the input\n        shape: shape of the input\n\n    Returns:\n        None\n    \"\"\"", "\n", "x", "=", "np", ".", "arange", "(", "np", ".", "product", "(", "shape", ")", ")", ".", "reshape", "(", "shape", ")", "\n", "if", "isinstance", "(", "shift", ",", "int", ")", "and", "isinstance", "(", "dim", ",", "int", ")", ":", "\n", "        ", "torch_shift", "=", "[", "shift", "]", "\n", "torch_dim", "=", "[", "dim", "]", "\n", "", "else", ":", "\n", "        ", "torch_shift", "=", "shift", "\n", "torch_dim", "=", "dim", "\n", "", "out_torch", "=", "roll", "(", "torch", ".", "from_numpy", "(", "x", ")", ",", "torch_shift", ",", "torch_dim", ")", ".", "numpy", "(", ")", "\n", "out_numpy", "=", "np", ".", "roll", "(", "x", ",", "shift", ",", "dim", ")", "\n", "\n", "if", "not", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_fft.test_fftshift": [[260, 277], ["pytest.mark.parametrize", "numpy.arange().reshape", "mridc.collections.common.parts.fft.fftshift().numpy", "numpy.fft.fftshift", "numpy.allclose", "numpy.arange", "mridc.collections.common.parts.fft.fftshift", "numpy.product", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "5", ",", "3", "]", ",", "[", "2", ",", "4", ",", "6", "]", "]", ")", "\n", "def", "test_fftshift", "(", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Test fftshift.\n\n    Args:\n        shape: shape of the input\n\n    Returns:\n        None\n    \"\"\"", "\n", "x", "=", "np", ".", "arange", "(", "np", ".", "product", "(", "shape", ")", ")", ".", "reshape", "(", "shape", ")", "\n", "out_torch", "=", "fftshift", "(", "torch", ".", "from_numpy", "(", "x", ")", ")", ".", "numpy", "(", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "fftshift", "(", "x", ")", "\n", "\n", "if", "not", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_fft.test_ifftshift": [[279, 296], ["pytest.mark.parametrize", "numpy.arange().reshape", "mridc.collections.common.parts.fft.ifftshift().numpy", "numpy.fft.ifftshift", "numpy.allclose", "numpy.arange", "mridc.collections.common.parts.fft.ifftshift", "numpy.product", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"shape\"", ",", "[", "[", "5", ",", "3", "]", ",", "[", "2", ",", "4", ",", "5", "]", ",", "[", "2", ",", "7", ",", "5", "]", "]", ")", "\n", "def", "test_ifftshift", "(", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Test ifftshift.\n\n    Args:\n        shape: shape of the input\n\n    Returns:\n        None\n    \"\"\"", "\n", "x", "=", "np", ".", "arange", "(", "np", ".", "product", "(", "shape", ")", ")", ".", "reshape", "(", "shape", ")", "\n", "out_torch", "=", "ifftshift", "(", "torch", ".", "from_numpy", "(", "x", ")", ")", ".", "numpy", "(", ")", "\n", "out_numpy", "=", "np", ".", "fft", ".", "ifftshift", "(", "x", ")", "\n", "\n", "if", "not", "np", ".", "allclose", "(", "out_torch", ",", "out_numpy", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_subsample.test_create_mask_for_random_type": [[17, 55], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type.", "mask.squeeze().numpy.squeeze().numpy", "isinstance", "mask.squeeze().numpy.squeeze", "numpy.array", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type.choose_acceleration"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.data.subsample.create_mask_for_mask_type", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.choose_acceleration"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"mask_type, center_fractions, accelerations, expected_mask_func, x, seed, half_scan_percentage\"", ",", "\n", "[", "(", "\"random1d\"", ",", "[", "0.08", ",", "0.04", "]", ",", "[", "4", ",", "8", "]", ",", "RandomMaskFunc", ",", "np", ".", "array", "(", "[", "1", ",", "320", ",", "320", "]", ")", ",", "None", ",", "0", ")", "]", ",", "\n", ")", "\n", "def", "test_create_mask_for_random_type", "(", "\n", "mask_type", ",", "center_fractions", ",", "accelerations", ",", "expected_mask_func", ",", "x", ",", "seed", ",", "half_scan_percentage", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Test that the function returns random 1D masks\n\n    Args:\n        mask_type: The type of mask to be created\n        center_fractions: The center fractions of the mask\n        accelerations: The accelerations of the mask\n        expected_mask_func: The expected mask function\n        x: The shape of the mask\n        seed: The seed of the mask\n        half_scan_percentage: The half scan percentage of the mask\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "create_mask_for_mask_type", "(", "mask_type", ",", "center_fractions", ",", "accelerations", ")", "\n", "\n", "mask", ",", "acc", "=", "mask_func", "(", "x", ",", "seed", ",", "half_scan_percentage", ")", "\n", "mask", "=", "mask", ".", "squeeze", "(", "0", ")", ".", "numpy", "(", ")", "\n", "x", "[", "-", "2", "]", "=", "1", "\n", "\n", "if", "not", "isinstance", "(", "mask_func", ",", "expected_mask_func", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "not", "accelerations", "[", "0", "]", "<=", "mask_func", ".", "choose_acceleration", "(", ")", "[", "1", "]", "<=", "accelerations", "[", "1", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "mask", ".", "shape", "!=", "(", "*", "x", "[", "2", ":", "]", ",", "1", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "mask", ".", "dtype", "!=", "np", ".", "float32", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "not", "accelerations", "[", "0", "]", "<=", "acc", "<=", "accelerations", "[", "1", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_subsample.test_create_mask_for_equispaced_type": [[57, 95], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type.", "mask.squeeze().numpy.squeeze().numpy", "isinstance", "mask.squeeze().numpy.squeeze", "numpy.array", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type.choose_acceleration"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.data.subsample.create_mask_for_mask_type", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.choose_acceleration"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"mask_type, center_fractions, accelerations, expected_mask_func, x, seed, half_scan_percentage\"", ",", "\n", "[", "(", "\"equispaced1d\"", ",", "[", "0.08", ",", "0.04", "]", ",", "[", "4", ",", "8", "]", ",", "EquispacedMaskFunc", ",", "np", ".", "array", "(", "[", "1", ",", "320", ",", "320", "]", ")", ",", "None", ",", "0", ")", "]", ",", "\n", ")", "\n", "def", "test_create_mask_for_equispaced_type", "(", "\n", "mask_type", ",", "center_fractions", ",", "accelerations", ",", "expected_mask_func", ",", "x", ",", "seed", ",", "half_scan_percentage", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Test that the function returns equispaced 1D masks\n\n    Args:\n        mask_type: The type of mask to be created\n        center_fractions: The center fractions of the mask\n        accelerations: The accelerations of the mask\n        expected_mask_func: The expected mask function\n        x: The shape of the mask\n        seed: The seed of the mask\n        half_scan_percentage: The half scan percentage of the mask\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "create_mask_for_mask_type", "(", "mask_type", ",", "center_fractions", ",", "accelerations", ")", "\n", "\n", "mask", ",", "acc", "=", "mask_func", "(", "x", ",", "seed", ",", "half_scan_percentage", ")", "\n", "mask", "=", "mask", ".", "squeeze", "(", "0", ")", ".", "numpy", "(", ")", "\n", "x", "[", "-", "2", "]", "=", "1", "\n", "\n", "if", "not", "isinstance", "(", "mask_func", ",", "expected_mask_func", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "not", "accelerations", "[", "0", "]", "<=", "mask_func", ".", "choose_acceleration", "(", ")", "[", "1", "]", "<=", "accelerations", "[", "1", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "mask", ".", "shape", "!=", "(", "*", "x", "[", "2", ":", "]", ",", "1", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "mask", ".", "dtype", "!=", "np", ".", "float32", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "not", "accelerations", "[", "0", "]", "<=", "acc", "<=", "accelerations", "[", "1", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_subsample.test_create_mask_for_gaussian1d_type": [[97, 136], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type.", "mask.squeeze().numpy.squeeze().numpy", "isinstance", "tuple", "mask.squeeze().numpy.squeeze", "numpy.array", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type.choose_acceleration"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.data.subsample.create_mask_for_mask_type", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.choose_acceleration"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"mask_type, center_fractions, accelerations, expected_mask_func, x, seed, half_scan_percentage, scale\"", ",", "\n", "[", "(", "\"gaussian1d\"", ",", "[", "0.7", ",", "0.7", "]", ",", "[", "4", ",", "10", "]", ",", "Gaussian1DMaskFunc", ",", "np", ".", "array", "(", "[", "1", ",", "320", ",", "320", ",", "1", "]", ")", ",", "None", ",", "0", ",", "0.02", ")", "]", ",", "\n", ")", "\n", "def", "test_create_mask_for_gaussian1d_type", "(", "\n", "mask_type", ",", "center_fractions", ",", "accelerations", ",", "expected_mask_func", ",", "x", ",", "seed", ",", "half_scan_percentage", ",", "scale", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Test that the function returns gaussian 1D masks\n\n    Args:\n        mask_type: The type of mask to be created\n        center_fractions: The center fractions of the mask\n        accelerations: The accelerations of the mask\n        expected_mask_func: The expected mask function\n        x: The shape of the mask\n        seed: The seed of the mask\n        half_scan_percentage: The half scan percentage of the mask\n        scale: The scale of the mask\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "create_mask_for_mask_type", "(", "mask_type", ",", "center_fractions", ",", "accelerations", ")", "\n", "\n", "mask", ",", "acc", "=", "mask_func", "(", "x", ",", "seed", ",", "half_scan_percentage", ",", "scale", ")", "\n", "mask", "=", "mask", ".", "squeeze", "(", "0", ")", ".", "numpy", "(", ")", "\n", "x", "[", "-", "3", "]", "=", "1", "\n", "\n", "if", "not", "isinstance", "(", "mask_func", ",", "expected_mask_func", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "not", "accelerations", "[", "0", "]", "<=", "mask_func", ".", "choose_acceleration", "(", ")", "[", "1", "]", "<=", "accelerations", "[", "1", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "mask", ".", "shape", "!=", "tuple", "(", "x", "[", "1", ":", "]", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "mask", ".", "dtype", "!=", "np", ".", "float32", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "not", "accelerations", "[", "0", "]", "<=", "acc", "<=", "accelerations", "[", "1", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_subsample.test_create_mask_for_gaussian2d_type": [[138, 176], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type.", "mask.squeeze().squeeze().numpy.squeeze().squeeze().numpy", "isinstance", "tuple", "mask.squeeze().squeeze().numpy.squeeze().squeeze", "numpy.array", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type.choose_acceleration", "mask.squeeze().squeeze().numpy.squeeze"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.data.subsample.create_mask_for_mask_type", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.choose_acceleration"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"mask_type, center_fractions, accelerations, expected_mask_func, x, seed, half_scan_percentage, scale\"", ",", "\n", "[", "(", "\"gaussian2d\"", ",", "[", "0.7", ",", "0.7", "]", ",", "[", "4", ",", "10", "]", ",", "Gaussian2DMaskFunc", ",", "np", ".", "array", "(", "[", "1", ",", "320", ",", "320", ",", "1", "]", ")", ",", "None", ",", "0", ",", "0.02", ")", "]", ",", "\n", ")", "\n", "def", "test_create_mask_for_gaussian2d_type", "(", "\n", "mask_type", ",", "center_fractions", ",", "accelerations", ",", "expected_mask_func", ",", "x", ",", "seed", ",", "half_scan_percentage", ",", "scale", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Test that the function returns gaussian 2D masks\n\n    Args:\n        mask_type: The type of mask to be created\n        center_fractions: The center fractions of the mask\n        accelerations: The accelerations of the mask\n        expected_mask_func: The expected mask function\n        x: The shape of the mask\n        seed: The seed of the mask\n        half_scan_percentage: The half scan percentage of the mask\n        scale: The scale of the mask\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "create_mask_for_mask_type", "(", "mask_type", ",", "center_fractions", ",", "accelerations", ")", "\n", "\n", "mask", ",", "acc", "=", "mask_func", "(", "x", ",", "seed", ",", "half_scan_percentage", ",", "scale", ")", "\n", "mask", "=", "mask", ".", "squeeze", "(", "0", ")", ".", "squeeze", "(", "-", "1", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "not", "isinstance", "(", "mask_func", ",", "expected_mask_func", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "not", "accelerations", "[", "0", "]", "<=", "mask_func", ".", "choose_acceleration", "(", ")", "[", "1", "]", "<=", "accelerations", "[", "1", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "mask", ".", "shape", "!=", "tuple", "(", "x", "[", "1", ":", "-", "1", "]", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "mask", ".", "dtype", "!=", "np", ".", "float32", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "not", "accelerations", "[", "0", "]", "<=", "acc", "<=", "accelerations", "[", "1", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.reconstruction.test_subsample.test_create_mask_for_poisson2d_type": [[178, 216], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type.", "mask.squeeze().squeeze().numpy.squeeze().squeeze().numpy", "isinstance", "tuple", "mask.squeeze().squeeze().numpy.squeeze().squeeze", "numpy.array", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type.choose_acceleration", "mask.squeeze().squeeze().numpy.squeeze"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.data.subsample.create_mask_for_mask_type", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.choose_acceleration"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"mask_type, center_fractions, accelerations, expected_mask_func, x, seed, half_scan_percentage, scale\"", ",", "\n", "[", "(", "\"poisson2d\"", ",", "[", "0.7", ",", "0.7", "]", ",", "[", "4", ",", "10", "]", ",", "Poisson2DMaskFunc", ",", "np", ".", "array", "(", "[", "1", ",", "320", ",", "320", ",", "1", "]", ")", ",", "None", ",", "0", ",", "0.02", ")", "]", ",", "\n", ")", "\n", "def", "test_create_mask_for_poisson2d_type", "(", "\n", "mask_type", ",", "center_fractions", ",", "accelerations", ",", "expected_mask_func", ",", "x", ",", "seed", ",", "half_scan_percentage", ",", "scale", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Test that the function returns poisson 2D masks\n\n    Args:\n        mask_type: The type of mask to be created\n        center_fractions: The center fractions of the mask\n        accelerations: The accelerations of the mask\n        expected_mask_func: The expected mask function\n        x: The shape of the mask\n        seed: The seed of the mask\n        half_scan_percentage: The half scan percentage of the mask\n        scale: The scale of the mask\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "create_mask_for_mask_type", "(", "mask_type", ",", "center_fractions", ",", "accelerations", ")", "\n", "\n", "mask", ",", "acc", "=", "mask_func", "(", "x", ",", "seed", ",", "half_scan_percentage", ",", "scale", ")", "\n", "mask", "=", "mask", ".", "squeeze", "(", "0", ")", ".", "squeeze", "(", "-", "1", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "not", "isinstance", "(", "mask_func", ",", "expected_mask_func", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "not", "accelerations", "[", "0", "]", "<=", "mask_func", ".", "choose_acceleration", "(", ")", "[", "1", "]", "<=", "accelerations", "[", "1", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "mask", ".", "shape", "!=", "tuple", "(", "x", "[", "1", ":", "-", "1", "]", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "mask", ".", "dtype", "!=", "np", ".", "float32", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "not", "accelerations", "[", "0", "]", "<=", "acc", "<=", "accelerations", "[", "1", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.hydra.my_app.my_app": [[24, 29], ["mridc.core.config.hydra_runner", "print", "omegaconf.OmegaConf.to_yaml"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.conf.hydra_runner.hydra_runner"], ["", "@", "hydra_runner", "(", "config_name", "=", "\"DefaultConfig\"", ",", "schema", "=", "DefaultConfig", ")", "\n", "def", "my_app", "(", "cfg", ")", ":", "\n", "    ", "print", "(", "OmegaConf", ".", "to_yaml", "(", "cfg", ")", ")", "\n", "# Get dataset_name.", "\n", "dataset_name", "=", "cfg", ".", "dataset_name", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.hydra.test_hydra_runner.TestHydraRunner.test_no_config": [[14, 23], ["pytest.raises", "subprocess.check_call"], "methods", ["None"], ["    ", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_no_config", "(", "self", ")", ":", "\n", "        ", "\"\"\" \"Test app without config - fields missing causes error.\"\"\"", "\n", "# Create system call.", "\n", "call", "=", "\"python tests/hydra/my_app.py\"", "\n", "\n", "with", "pytest", ".", "raises", "(", "subprocess", ".", "CalledProcessError", ")", ":", "\n", "# Run the call as subprocess.", "\n", "            ", "subprocess", ".", "check_call", "(", "call", ",", "shell", "=", "True", ",", "stdout", "=", "sys", ".", "stdout", ",", "stderr", "=", "sys", ".", "stdout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.hydra.test_hydra_runner.TestHydraRunner.test_config1": [[24, 39], ["pytest.raises", "subprocess.check_call", "os.path.exists", "os.path.exists"], "methods", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_config1", "(", "self", ")", ":", "\n", "        ", "\"\"\" \"Test injection of valid config1.\"\"\"", "\n", "# Create system call.", "\n", "call", "=", "\"python tests/hydra/my_app.py --config-name config1.yaml\"", "\n", "\n", "# Run the call as subprocess.", "\n", "with", "pytest", ".", "raises", "(", "subprocess", ".", "CalledProcessError", ")", ":", "\n", "# Run the call as subprocess.", "\n", "            ", "subprocess", ".", "check_call", "(", "call", ",", "shell", "=", "True", ",", "stdout", "=", "sys", ".", "stdout", ",", "stderr", "=", "sys", ".", "stdout", ")", "\n", "\n", "# Make sure that .hydra dir is not present.", "\n", "", "assert", "not", "path", ".", "exists", "(", "\".hydra\"", ")", "\n", "# Make sure that default hydra log file is not present.", "\n", "assert", "not", "path", ".", "exists", "(", "\"my_app.log\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.hydra.test_hydra_runner.TestHydraRunner.test_config1_invalid": [[40, 49], ["pytest.raises", "subprocess.check_call"], "methods", ["None"], ["", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_config1_invalid", "(", "self", ")", ":", "\n", "        ", "\"\"\" \"Test injection of invalid config1.\"\"\"", "\n", "# Create system call.", "\n", "call", "=", "\"python tests/hydra/my_app.py --config-name config1_invalid.yaml\"", "\n", "\n", "with", "pytest", ".", "raises", "(", "subprocess", ".", "CalledProcessError", ")", ":", "\n", "# Run the call as subprocess.", "\n", "            ", "subprocess", ".", "check_call", "(", "call", ",", "shell", "=", "True", ",", "stdout", "=", "sys", ".", "stdout", ",", "stderr", "=", "sys", ".", "stdout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.hydra.test_hydra_runner.TestHydraRunner.test_config2": [[50, 65], ["pytest.raises", "subprocess.check_call", "os.path.exists", "os.path.exists"], "methods", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_config2", "(", "self", ")", ":", "\n", "        ", "\"\"\" \"Test injection of valid config2 from a different folder.\"\"\"", "\n", "# Create system call.", "\n", "call", "=", "\"python tests/hydra/my_app.py --config-name config2.yaml\"", "\n", "\n", "# Run the call as subprocess.", "\n", "with", "pytest", ".", "raises", "(", "subprocess", ".", "CalledProcessError", ")", ":", "\n", "# Run the call as subprocess.", "\n", "            ", "subprocess", ".", "check_call", "(", "call", ",", "shell", "=", "True", ",", "stdout", "=", "sys", ".", "stdout", ",", "stderr", "=", "sys", ".", "stdout", ")", "\n", "\n", "# Make sure that .hydra dir is not present.", "\n", "", "assert", "not", "path", ".", "exists", "(", "\".hydra\"", ")", "\n", "# Make sure that default hydra log file is not present.", "\n", "assert", "not", "path", ".", "exists", "(", "\"my_app.log\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.hydra.test_hydra_runner.TestHydraRunner.test_config2_invalid": [[66, 75], ["pytest.raises", "subprocess.check_call"], "methods", ["None"], ["", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_config2_invalid", "(", "self", ")", ":", "\n", "        ", "\"\"\" \"Test injection of invalid config2 from a different folder.\"\"\"", "\n", "# Create system call.", "\n", "call", "=", "\"python tests/hydra/my_app.py --config-path config_subdir --config-name config2_invalid.yaml\"", "\n", "\n", "with", "pytest", ".", "raises", "(", "subprocess", ".", "CalledProcessError", ")", ":", "\n", "# Run the call as subprocess.", "\n", "            ", "subprocess", ".", "check_call", "(", "call", ",", "shell", "=", "True", ",", "stdout", "=", "sys", ".", "stdout", ",", "stderr", "=", "sys", ".", "stdout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.hydra.test_hydra_runner.TestHydraRunner.test_config2_filepath_schema": [[76, 85], ["pytest.raises", "subprocess.check_call"], "methods", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "integration", "\n", "def", "test_config2_filepath_schema", "(", "self", ")", ":", "\n", "        ", "\"\"\" \"Test injection of valid config2 - using namepath with schema is prohibited.\"\"\"", "\n", "# Create system call.", "\n", "call", "=", "\"python tests/hydra/my_app.py --config-name config_subdir/config2_invalid.yaml\"", "\n", "\n", "with", "pytest", ".", "raises", "(", "subprocess", ".", "CalledProcessError", ")", ":", "\n", "# Run the call as subprocess.", "\n", "            ", "subprocess", ".", "check_call", "(", "call", ",", "shell", "=", "True", ",", "stdout", "=", "sys", ".", "stdout", ",", "stderr", "=", "sys", ".", "stdout", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.fastmri.create_temp_data.create_temp_data": [[10, 105], ["numpy.random.default_rng", "data_splits.items", "enumerate", "np.random.default_rng.integers", "np.random.default_rng.integers", "np.random.default_rng.normal", "numpy.absolute().astype", "np.random.default_rng.integers().astype", "h5py.File", "hf.create_dataset", "numpy.floor_divide", "numpy.floor_divide", "split.split", "split.split", "np.random.default_rng.normal", "split.split", "numpy.dtype", "np.absolute().astype.max", "hf.create_dataset", "str", "numpy.absolute", "np.random.default_rng.integers", "data.astype", "split.split", "hf.create_dataset", "hf.create_dataset", "np.random.default_rng.normal"], "function", ["None"], ["def", "create_temp_data", "(", "path", ")", ":", "\n", "    ", "\"\"\"\n    Creates a temporary dataset for testing purposes.\n\n    Args:\n        path: The path to the dataset.\n\n    Returns:\n        None\n    \"\"\"", "\n", "rg", "=", "np", ".", "random", ".", "default_rng", "(", "seed", "=", "1234", ")", "\n", "max_num_slices", "=", "15", "\n", "max_num_coils", "=", "15", "\n", "data_splits", "=", "{", "\n", "\"knee_data\"", ":", "[", "\n", "\"multicoil_train\"", ",", "\n", "\"multicoil_val\"", ",", "\n", "\"multicoil_test\"", ",", "\n", "\"multicoil_challenge\"", ",", "\n", "\"singlecoil_train\"", ",", "\n", "\"singlecoil_val\"", ",", "\n", "\"singlecoil_test\"", ",", "\n", "\"singlecoil_challenge\"", ",", "\n", "]", ",", "\n", "\"brain_data\"", ":", "[", "\"multicoil_train\"", ",", "\"multicoil_val\"", ",", "\"multicoil_test\"", ",", "\"multicoil_challenge\"", "]", ",", "\n", "}", "\n", "\n", "enc_sizes", "=", "{", "\n", "\"train\"", ":", "[", "(", "1", ",", "128", ",", "64", ")", ",", "(", "1", ",", "128", ",", "49", ")", ",", "(", "1", ",", "150", ",", "67", ")", "]", ",", "\n", "\"val\"", ":", "[", "(", "1", ",", "128", ",", "64", ")", ",", "(", "1", ",", "170", ",", "57", ")", "]", ",", "\n", "\"test\"", ":", "[", "(", "1", ",", "128", ",", "64", ")", ",", "(", "1", ",", "96", ",", "96", ")", "]", ",", "\n", "\"challenge\"", ":", "[", "(", "1", ",", "128", ",", "64", ")", ",", "(", "1", ",", "96", ",", "48", ")", "]", ",", "\n", "}", "\n", "recon_sizes", "=", "{", "\n", "\"train\"", ":", "[", "(", "1", ",", "64", ",", "64", ")", ",", "(", "1", ",", "49", ",", "49", ")", ",", "(", "1", ",", "67", ",", "67", ")", "]", ",", "\n", "\"val\"", ":", "[", "(", "1", ",", "64", ",", "64", ")", ",", "(", "1", ",", "57", ",", "47", ")", "]", ",", "\n", "\"test\"", ":", "[", "(", "1", ",", "64", ",", "64", ")", ",", "(", "1", ",", "96", ",", "96", ")", "]", ",", "\n", "\"challenge\"", ":", "[", "(", "1", ",", "64", ",", "64", ")", ",", "(", "1", ",", "48", ",", "48", ")", "]", ",", "\n", "}", "\n", "\n", "metadata", "=", "{", "}", "\n", "for", "dataset", ",", "value", "in", "data_splits", ".", "items", "(", ")", ":", "\n", "        ", "for", "split", "in", "value", ":", "\n", "            ", "(", "path", "/", "dataset", "/", "split", ")", ".", "mkdir", "(", "parents", "=", "True", ")", "\n", "encs", "=", "enc_sizes", "[", "split", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", "]", "\n", "recs", "=", "recon_sizes", "[", "split", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", "]", "\n", "fcount", "=", "0", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "encs", ")", ":", "\n", "                ", "fname", "=", "path", "/", "dataset", "/", "split", "/", "f\"file{fcount}.h5\"", "\n", "num_slices", "=", "rg", ".", "integers", "(", "2", ",", "max_num_slices", ")", "\n", "if", "\"multicoil\"", "in", "split", ":", "\n", "                    ", "num_coils", "=", "rg", ".", "integers", "(", "2", ",", "max_num_coils", ")", "\n", "enc_size", "=", "(", "num_slices", ",", "num_coils", ",", "encs", "[", "i", "]", "[", "-", "2", "]", ",", "encs", "[", "i", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "enc_size", "=", "(", "num_slices", ",", "encs", "[", "i", "]", "[", "-", "2", "]", ",", "encs", "[", "i", "]", "[", "-", "1", "]", ")", "\n", "", "recon_size", "=", "(", "num_slices", ",", "recs", "[", "i", "]", "[", "-", "2", "]", ",", "recs", "[", "i", "]", "[", "-", "1", "]", ")", "\n", "data", "=", "rg", ".", "normal", "(", "size", "=", "enc_size", ")", "+", "1j", "*", "rg", ".", "normal", "(", "size", "=", "enc_size", ")", "\n", "\n", "if", "split", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", "in", "(", "\"train\"", ",", "\"val\"", ")", ":", "\n", "                    ", "recon", "=", "np", ".", "absolute", "(", "rg", ".", "normal", "(", "size", "=", "recon_size", ")", ")", ".", "astype", "(", "np", ".", "dtype", "(", "\"<f4\"", ")", ")", "\n", "", "else", ":", "\n", "                    ", "mask", "=", "rg", ".", "integers", "(", "0", ",", "2", ",", "size", "=", "recon_size", "[", "-", "1", "]", ")", ".", "astype", "(", "bool", ")", "\n", "\n", "", "with", "h5py", ".", "File", "(", "fname", ",", "\"w\"", ")", "as", "hf", ":", "\n", "                    ", "hf", ".", "create_dataset", "(", "\"kspace\"", ",", "data", "=", "data", ".", "astype", "(", "np", ".", "complex64", ")", ")", "\n", "if", "split", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", "in", "(", "\"train\"", ",", "\"val\"", ")", ":", "\n", "                        ", "hf", ".", "attrs", "[", "\"max\"", "]", "=", "recon", ".", "max", "(", ")", "\n", "if", "\"singlecoil\"", "in", "split", ":", "\n", "                            ", "hf", ".", "create_dataset", "(", "\"reconstruction_esc\"", ",", "data", "=", "recon", ")", "\n", "", "else", ":", "\n", "                            ", "hf", ".", "create_dataset", "(", "\"reconstruction_rss\"", ",", "data", "=", "recon", ")", "\n", "", "", "else", ":", "\n", "                        ", "hf", ".", "create_dataset", "(", "\"mask\"", ",", "data", "=", "mask", ")", "\n", "\n", "", "", "enc_size", "=", "encs", "[", "i", "]", "\n", "\n", "enc_limits_center", "=", "np", ".", "floor_divide", "(", "enc_size", "[", "1", "]", ",", "2", ")", "+", "1", "\n", "enc_limits_max", "=", "enc_size", "[", "1", "]", "-", "2", "\n", "\n", "padding_left", "=", "np", ".", "floor_divide", "(", "enc_size", "[", "1", "]", ",", "2", ")", "-", "enc_limits_center", "\n", "padding_right", "=", "padding_left", "+", "enc_limits_max", "\n", "\n", "metadata", "[", "str", "(", "fname", ")", "]", "=", "(", "\n", "{", "\n", "\"padding_left\"", ":", "padding_left", ",", "\n", "\"padding_right\"", ":", "padding_right", ",", "\n", "\"encoding_size\"", ":", "enc_size", ",", "\n", "\"recon_size\"", ":", "recon_size", ",", "\n", "}", ",", "\n", "num_slices", ",", "\n", ")", "\n", "\n", "fcount", "+=", "1", "\n", "\n", "", "", "", "return", "path", "/", "\"knee_data\"", ",", "path", "/", "\"brain_data\"", ",", "metadata", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.fastmri.test_mri_data.test_slice_datasets": [[8, 53], ["monkeypatch.setattr", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "str", "len", "len"], "function", ["None"], ["def", "test_slice_datasets", "(", "fastmri_mock_dataset", ",", "monkeypatch", ")", ":", "\n", "    ", "\"\"\"\n    Test the slice datasets\n\n    Args:\n        fastmri_mock_dataset: fastMRI mock dataset\n        monkeypatch: monkeypatch\n\n    Returns:\n        None\n    \"\"\"", "\n", "knee_path", ",", "brain_path", ",", "metadata", "=", "fastmri_mock_dataset", "\n", "\n", "def", "retrieve_metadata_mock", "(", "_", ",", "fname", ")", ":", "\n", "        ", "\"\"\"\n        Mock the metadata retrieval\n\n        Args:\n            _: ignored\n            fname: filename\n\n        Returns:\n            metadata: metadata\n        \"\"\"", "\n", "return", "metadata", "[", "str", "(", "fname", ")", "]", "\n", "\n", "", "monkeypatch", ".", "setattr", "(", "FastMRISliceDataset", ",", "\"_retrieve_metadata\"", ",", "retrieve_metadata_mock", ")", "\n", "\n", "for", "challenge", "in", "(", "\"multicoil\"", ",", "\"singlecoil\"", ")", ":", "\n", "        ", "for", "split", "in", "(", "\"train\"", ",", "\"val\"", ",", "\"test\"", ",", "\"challenge\"", ")", ":", "\n", "            ", "dataset", "=", "FastMRISliceDataset", "(", "knee_path", "/", "f\"{challenge}_{split}\"", ",", "transform", "=", "None", ",", "challenge", "=", "challenge", ")", "\n", "\n", "if", "len", "(", "dataset", ")", "<=", "0", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "if", "dataset", "is", "None", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n", "", "", "", "for", "challenge", "in", "(", "\"multicoil\"", ",", ")", ":", "\n", "        ", "for", "split", "in", "(", "\"train\"", ",", "\"val\"", ",", "\"test\"", ",", "\"challenge\"", ")", ":", "\n", "            ", "dataset", "=", "FastMRISliceDataset", "(", "brain_path", "/", "f\"{challenge}_{split}\"", ",", "transform", "=", "None", ",", "challenge", "=", "challenge", ")", "\n", "\n", "if", "len", "(", "dataset", ")", "<=", "0", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "if", "dataset", "is", "None", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.fastmri.test_mri_data.test_combined_slice_dataset": [[55, 108], ["monkeypatch.setattr", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRICombinedSliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRICombinedSliceDataset", "len", "len", "len", "len", "len", "len", "str"], "function", ["None"], ["", "", "", "", "def", "test_combined_slice_dataset", "(", "fastmri_mock_dataset", ",", "monkeypatch", ")", ":", "\n", "    ", "\"\"\"\n    Test the combined slice datasets\n\n    Args:\n        fastmri_mock_dataset: fastMRI mock dataset\n        monkeypatch: monkeypatch\n\n    Returns:\n        None\n    \"\"\"", "\n", "knee_path", ",", "brain_path", ",", "metadata", "=", "fastmri_mock_dataset", "\n", "\n", "def", "retrieve_metadata_mock", "(", "_", ",", "fname", ")", ":", "\n", "        ", "\"\"\"\n        Mock the metadata retrieval\n\n        Args:\n            _: ignored\n            fname: filename\n\n        Returns:\n            metadata: metadata\n        \"\"\"", "\n", "return", "metadata", "[", "str", "(", "fname", ")", "]", "\n", "\n", "", "monkeypatch", ".", "setattr", "(", "FastMRISliceDataset", ",", "\"_retrieve_metadata\"", ",", "retrieve_metadata_mock", ")", "\n", "\n", "roots", "=", "[", "knee_path", "/", "\"multicoil_train\"", ",", "knee_path", "/", "\"multicoil_val\"", "]", "\n", "challenges", "=", "[", "\"multicoil\"", ",", "\"multicoil\"", "]", "\n", "transforms", "=", "[", "None", ",", "None", "]", "\n", "\n", "dataset1", "=", "FastMRISliceDataset", "(", "root", "=", "roots", "[", "0", "]", ",", "challenge", "=", "challenges", "[", "0", "]", ",", "transform", "=", "transforms", "[", "0", "]", ")", "\n", "dataset2", "=", "FastMRISliceDataset", "(", "root", "=", "roots", "[", "1", "]", ",", "challenge", "=", "challenges", "[", "1", "]", ",", "transform", "=", "transforms", "[", "1", "]", ")", "\n", "comb_dataset", "=", "FastMRICombinedSliceDataset", "(", "roots", "=", "roots", ",", "challenges", "=", "challenges", ",", "transforms", "=", "transforms", ")", "\n", "\n", "if", "len", "(", "comb_dataset", ")", "!=", "len", "(", "dataset1", ")", "+", "len", "(", "dataset2", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "comb_dataset", "is", "None", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n", "", "roots", "=", "[", "brain_path", "/", "\"multicoil_train\"", ",", "brain_path", "/", "\"multicoil_val\"", "]", "\n", "challenges", "=", "[", "\"multicoil\"", ",", "\"multicoil\"", "]", "\n", "transforms", "=", "[", "None", ",", "None", "]", "\n", "\n", "dataset1", "=", "FastMRISliceDataset", "(", "root", "=", "roots", "[", "0", "]", ",", "challenge", "=", "challenges", "[", "0", "]", ",", "transform", "=", "transforms", "[", "0", "]", ")", "\n", "dataset2", "=", "FastMRISliceDataset", "(", "root", "=", "roots", "[", "1", "]", ",", "challenge", "=", "challenges", "[", "1", "]", ",", "transform", "=", "transforms", "[", "1", "]", ")", "\n", "comb_dataset", "=", "FastMRICombinedSliceDataset", "(", "roots", "=", "roots", ",", "challenges", "=", "challenges", ",", "transforms", "=", "transforms", ")", "\n", "\n", "if", "len", "(", "comb_dataset", ")", "!=", "len", "(", "dataset1", ")", "+", "len", "(", "dataset2", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "comb_dataset", "is", "None", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.fastmri.test_mri_data.test_slice_dataset_with_transform": [[110, 155], ["monkeypatch.setattr", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "str", "len", "len"], "function", ["None"], ["", "", "def", "test_slice_dataset_with_transform", "(", "fastmri_mock_dataset", ",", "monkeypatch", ")", ":", "\n", "    ", "\"\"\"\n    Test the slice datasets with transforms\n\n    Args:\n        fastmri_mock_dataset: fastMRI mock dataset\n        monkeypatch: monkeypatch\n\n    Returns:\n        None\n    \"\"\"", "\n", "knee_path", ",", "brain_path", ",", "metadata", "=", "fastmri_mock_dataset", "\n", "\n", "def", "retrieve_metadata_mock", "(", "_", ",", "fname", ")", ":", "\n", "        ", "\"\"\"\n        Mock the metadata retrieval\n\n        Args:\n            _: ignored\n            fname: filename\n\n        Returns:\n            metadata: metadata\n        \"\"\"", "\n", "return", "metadata", "[", "str", "(", "fname", ")", "]", "\n", "\n", "", "monkeypatch", ".", "setattr", "(", "FastMRISliceDataset", ",", "\"_retrieve_metadata\"", ",", "retrieve_metadata_mock", ")", "\n", "\n", "for", "challenge", "in", "(", "\"multicoil\"", ",", "\"singlecoil\"", ")", ":", "\n", "        ", "for", "split", "in", "(", "\"train\"", ",", "\"val\"", ",", "\"test\"", ",", "\"challenge\"", ")", ":", "\n", "            ", "dataset", "=", "FastMRISliceDataset", "(", "knee_path", "/", "f\"{challenge}_{split}\"", ",", "transform", "=", "None", ",", "challenge", "=", "challenge", ")", "\n", "\n", "if", "len", "(", "dataset", ")", "<=", "0", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "if", "dataset", "is", "None", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n", "", "", "", "for", "challenge", "in", "(", "\"multicoil\"", ",", ")", ":", "\n", "        ", "for", "split", "in", "(", "\"train\"", ",", "\"val\"", ",", "\"test\"", ",", "\"challenge\"", ")", ":", "\n", "            ", "dataset", "=", "FastMRISliceDataset", "(", "brain_path", "/", "f\"{challenge}_{split}\"", ",", "transform", "=", "None", ",", "challenge", "=", "challenge", ")", "\n", "\n", "if", "len", "(", "dataset", ")", "<=", "0", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "if", "dataset", "is", "None", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.fastmri.test_mri_data.test_combined_slice_dataset_with_transform": [[157, 210], ["monkeypatch.setattr", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRICombinedSliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRICombinedSliceDataset", "len", "len", "len", "len", "len", "len", "str"], "function", ["None"], ["", "", "", "", "def", "test_combined_slice_dataset_with_transform", "(", "fastmri_mock_dataset", ",", "monkeypatch", ")", ":", "\n", "    ", "\"\"\"\n    Test the combined slice datasets with transforms\n\n    Args:\n        fastmri_mock_dataset: fastMRI mock dataset\n        monkeypatch: monkeypatch\n\n    Returns:\n        None\n    \"\"\"", "\n", "knee_path", ",", "brain_path", ",", "metadata", "=", "fastmri_mock_dataset", "\n", "\n", "def", "retrieve_metadata_mock", "(", "_", ",", "fname", ")", ":", "\n", "        ", "\"\"\"\n        Mock the metadata retrieval\n\n        Args:\n            _: ignored\n            fname: filename\n\n        Returns:\n            metadata: metadata\n        \"\"\"", "\n", "return", "metadata", "[", "str", "(", "fname", ")", "]", "\n", "\n", "", "monkeypatch", ".", "setattr", "(", "FastMRISliceDataset", ",", "\"_retrieve_metadata\"", ",", "retrieve_metadata_mock", ")", "\n", "\n", "roots", "=", "[", "knee_path", "/", "\"multicoil_train\"", ",", "knee_path", "/", "\"multicoil_val\"", "]", "\n", "challenges", "=", "[", "\"multicoil\"", ",", "\"multicoil\"", "]", "\n", "transforms", "=", "[", "None", ",", "None", "]", "\n", "\n", "dataset1", "=", "FastMRISliceDataset", "(", "root", "=", "roots", "[", "0", "]", ",", "challenge", "=", "challenges", "[", "0", "]", ",", "transform", "=", "transforms", "[", "0", "]", ")", "\n", "dataset2", "=", "FastMRISliceDataset", "(", "root", "=", "roots", "[", "1", "]", ",", "challenge", "=", "challenges", "[", "1", "]", ",", "transform", "=", "transforms", "[", "1", "]", ")", "\n", "comb_dataset", "=", "FastMRICombinedSliceDataset", "(", "roots", "=", "roots", ",", "challenges", "=", "challenges", ",", "transforms", "=", "transforms", ")", "\n", "\n", "if", "len", "(", "comb_dataset", ")", "!=", "len", "(", "dataset1", ")", "+", "len", "(", "dataset2", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "comb_dataset", "is", "None", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n", "", "roots", "=", "[", "brain_path", "/", "\"multicoil_train\"", ",", "brain_path", "/", "\"multicoil_val\"", "]", "\n", "challenges", "=", "[", "\"multicoil\"", ",", "\"multicoil\"", "]", "\n", "transforms", "=", "[", "None", ",", "None", "]", "\n", "\n", "dataset1", "=", "FastMRISliceDataset", "(", "root", "=", "roots", "[", "0", "]", ",", "challenge", "=", "challenges", "[", "0", "]", ",", "transform", "=", "transforms", "[", "0", "]", ")", "\n", "dataset2", "=", "FastMRISliceDataset", "(", "root", "=", "roots", "[", "1", "]", ",", "challenge", "=", "challenges", "[", "1", "]", ",", "transform", "=", "transforms", "[", "1", "]", ")", "\n", "comb_dataset", "=", "FastMRICombinedSliceDataset", "(", "roots", "=", "roots", ",", "challenges", "=", "challenges", ",", "transforms", "=", "transforms", ")", "\n", "\n", "if", "len", "(", "comb_dataset", ")", "!=", "len", "(", "dataset1", ")", "+", "len", "(", "dataset2", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "comb_dataset", "is", "None", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.fastmri.test_mri_data.test_slice_dataset_with_transform_and_challenge": [[212, 255], ["monkeypatch.setattr", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "len", "len", "str"], "function", ["None"], ["", "", "def", "test_slice_dataset_with_transform_and_challenge", "(", "fastmri_mock_dataset", ",", "monkeypatch", ")", ":", "\n", "    ", "\"\"\"\n    Test the slice datasets with transforms and challenge\n\n    Args:\n        fastmri_mock_dataset: fastMRI mock dataset\n        monkeypatch: monkeypatch\n\n    Returns:\n        None\n    \"\"\"", "\n", "knee_path", ",", "brain_path", ",", "metadata", "=", "fastmri_mock_dataset", "\n", "\n", "def", "retrieve_metadata_mock", "(", "_", ",", "fname", ")", ":", "\n", "        ", "\"\"\"\n        Mock the metadata retrieval\n\n        Args:\n            _: ignored\n            fname: filename\n\n        Returns:\n            metadata: metadata\n        \"\"\"", "\n", "return", "metadata", "[", "str", "(", "fname", ")", "]", "\n", "\n", "", "monkeypatch", ".", "setattr", "(", "FastMRISliceDataset", ",", "\"_retrieve_metadata\"", ",", "retrieve_metadata_mock", ")", "\n", "\n", "for", "split", "in", "(", "\"train\"", ",", "\"val\"", ",", "\"test\"", ",", "\"challenge\"", ")", ":", "\n", "        ", "dataset", "=", "FastMRISliceDataset", "(", "knee_path", "/", "f\"multicoil_{split}\"", ",", "transform", "=", "None", ",", "challenge", "=", "\"multicoil\"", ")", "\n", "\n", "if", "len", "(", "dataset", ")", "<=", "0", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "dataset", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "", "for", "split", "in", "(", "\"train\"", ",", "\"val\"", ",", "\"test\"", ",", "\"challenge\"", ")", ":", "\n", "        ", "dataset", "=", "FastMRISliceDataset", "(", "brain_path", "/", "f\"multicoil_{split}\"", ",", "transform", "=", "None", ",", "challenge", "=", "\"multicoil\"", ")", "\n", "\n", "if", "len", "(", "dataset", ")", "<=", "0", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "dataset", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.fastmri.test_mri_data.test_combined_slice_dataset_with_transform_and_challenge": [[257, 310], ["monkeypatch.setattr", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRICombinedSliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "mridc.collections.reconstruction.data.mri_data.FastMRICombinedSliceDataset", "len", "len", "len", "len", "len", "len", "str"], "function", ["None"], ["", "", "", "def", "test_combined_slice_dataset_with_transform_and_challenge", "(", "fastmri_mock_dataset", ",", "monkeypatch", ")", ":", "\n", "    ", "\"\"\"\n    Test the combined slice datasets with transforms and challenge\n\n    Args:\n        fastmri_mock_dataset: fastMRI mock dataset\n        monkeypatch: monkeypatch\n\n    Returns:\n        None\n    \"\"\"", "\n", "knee_path", ",", "brain_path", ",", "metadata", "=", "fastmri_mock_dataset", "\n", "\n", "def", "retrieve_metadata_mock", "(", "_", ",", "fname", ")", ":", "\n", "        ", "\"\"\"\n        Mock the metadata retrieval\n\n        Args:\n            _: ignored\n            fname: filename\n\n        Returns:\n            metadata: metadata\n        \"\"\"", "\n", "return", "metadata", "[", "str", "(", "fname", ")", "]", "\n", "\n", "", "monkeypatch", ".", "setattr", "(", "FastMRISliceDataset", ",", "\"_retrieve_metadata\"", ",", "retrieve_metadata_mock", ")", "\n", "\n", "roots", "=", "[", "knee_path", "/", "\"multicoil_train\"", ",", "knee_path", "/", "\"multicoil_val\"", "]", "\n", "challenges", "=", "[", "\"multicoil\"", ",", "\"multicoil\"", "]", "\n", "transforms", "=", "[", "None", ",", "None", "]", "\n", "\n", "dataset1", "=", "FastMRISliceDataset", "(", "root", "=", "roots", "[", "0", "]", ",", "challenge", "=", "challenges", "[", "0", "]", ",", "transform", "=", "transforms", "[", "0", "]", ")", "\n", "dataset2", "=", "FastMRISliceDataset", "(", "root", "=", "roots", "[", "1", "]", ",", "challenge", "=", "challenges", "[", "1", "]", ",", "transform", "=", "transforms", "[", "1", "]", ")", "\n", "comb_dataset", "=", "FastMRICombinedSliceDataset", "(", "roots", "=", "roots", ",", "challenges", "=", "challenges", ",", "transforms", "=", "transforms", ")", "\n", "\n", "if", "len", "(", "comb_dataset", ")", "!=", "len", "(", "dataset1", ")", "+", "len", "(", "dataset2", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "comb_dataset", "is", "None", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n", "", "roots", "=", "[", "brain_path", "/", "\"multicoil_train\"", ",", "brain_path", "/", "\"multicoil_val\"", "]", "\n", "challenges", "=", "[", "\"multicoil\"", ",", "\"multicoil\"", "]", "\n", "transforms", "=", "[", "None", ",", "None", "]", "\n", "\n", "dataset1", "=", "FastMRISliceDataset", "(", "root", "=", "roots", "[", "0", "]", ",", "challenge", "=", "challenges", "[", "0", "]", ",", "transform", "=", "transforms", "[", "0", "]", ")", "\n", "dataset2", "=", "FastMRISliceDataset", "(", "root", "=", "roots", "[", "1", "]", ",", "challenge", "=", "challenges", "[", "1", "]", ",", "transform", "=", "transforms", "[", "1", "]", ")", "\n", "comb_dataset", "=", "FastMRICombinedSliceDataset", "(", "roots", "=", "roots", ",", "challenges", "=", "challenges", ",", "transforms", "=", "transforms", ")", "\n", "\n", "if", "len", "(", "comb_dataset", ")", "!=", "len", "(", "dataset1", ")", "+", "len", "(", "dataset2", ")", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "comb_dataset", "is", "None", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.fastmri.conftest.create_input": [[16, 30], ["numpy.arange().reshape", "torch.from_numpy().float", "numpy.arange", "torch.from_numpy", "numpy.product"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "\"\"\"\n    Create a random input tensor of the given shape.\n\n    Args:\n        shape: The shape of the input tensor.\n\n    Returns:\n        A random input tensor.\n    \"\"\"", "\n", "x", "=", "np", ".", "arange", "(", "np", ".", "product", "(", "shape", ")", ")", ".", "reshape", "(", "shape", ")", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "float", "(", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.fastmri.conftest.fastmri_mock_dataset": [[32, 46], ["pytest.fixture", "tmp_path_factory.mktemp", "tests.collections.reconstruction.fastmri.create_temp_data.create_temp_data"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.fastmri.create_temp_data.create_temp_data"], ["", "@", "pytest", ".", "fixture", "(", "scope", "=", "\"session\"", ")", "\n", "def", "fastmri_mock_dataset", "(", "tmp_path_factory", ")", ":", "\n", "    ", "\"\"\"\n    Create a mock dataset for testing.\n\n    Args:\n        tmp_path_factory: A temporary path factory.\n\n    Returns:\n        A mock dataset.\n    \"\"\"", "\n", "path", "=", "tmp_path_factory", ".", "mktemp", "(", "\"fastmri_data\"", ")", "\n", "\n", "return", "create_temp_data", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.fastmri.conftest.skip_integration_tests": [[48, 57], ["None"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "\n", "def", "skip_integration_tests", "(", ")", ":", "\n", "    ", "\"\"\"\n    Skip integration tests if the environment variable is set.\n\n    Returns:\n        A boolean indicating whether to skip integration tests.\n    \"\"\"", "\n", "return", "SKIP_INTEGRATIONS", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.fastmri.conftest.knee_split_lens": [[59, 74], ["None"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "\n", "def", "knee_split_lens", "(", ")", ":", "\n", "    ", "\"\"\"\n    The split lengths for the knee dataset.\n\n    Returns:\n        A dictionary with the split lengths.\n    \"\"\"", "\n", "return", "{", "\n", "\"multicoil_train\"", ":", "34742", ",", "\n", "\"multicoil_val\"", ":", "7135", ",", "\n", "\"multicoil_test\"", ":", "4092", ",", "\n", "\"singlecoil_train\"", ":", "34742", ",", "\n", "\"singlecoil_val\"", ":", "7135", ",", "\n", "\"singlecoil_test\"", ":", "3903", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.fastmri.conftest.brain_split_lens": [[77, 89], ["None"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "\n", "def", "brain_split_lens", "(", ")", ":", "\n", "    ", "\"\"\"\n    The split lengths for the brain dataset.\n\n    Returns:\n        A dictionary with the split lengths.\n    \"\"\"", "\n", "return", "{", "\n", "\"multicoil_train\"", ":", "70748", ",", "\n", "\"multicoil_val\"", ":", "21842", ",", "\n", "\"multicoil_test\"", ":", "8852", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_unet.test_unet": [[16, 124], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "tests.collections.reconstruction.fastmri.conftest.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.unet.UNet", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.unet.UNet.forward", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"channels\"", ":", "14", ",", "\n", "\"pooling_layers\"", ":", "2", ",", "\n", "\"padding_size\"", ":", "11", ",", "\n", "\"normalize\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "5", ",", "15", ",", "12", ",", "2", "]", ",", "\n", "{", "\n", "\"channels\"", ":", "14", ",", "\n", "\"pooling_layers\"", ":", "2", ",", "\n", "\"padding_size\"", ":", "11", ",", "\n", "\"normalize\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"channels\"", ":", "14", ",", "\n", "\"pooling_layers\"", ":", "2", ",", "\n", "\"padding_size\"", ":", "11", ",", "\n", "\"normalize\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"channels\"", ":", "14", ",", "\n", "\"pooling_layers\"", ":", "2", ",", "\n", "\"padding_size\"", ":", "15", ",", "\n", "\"normalize\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_unet", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test UNet with different parameters\n\n    Args:\n        shape: shape of the input\n        cfg: configuration of the model\n        center_fractions: center fractions\n        accelerations: accelerations\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "unet", "=", "UNet", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "unet", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_vn.test_vn": [[16, 132], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "tests.collections.reconstruction.fastmri.conftest.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.vn.VarNet", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.vn.VarNet.forward", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_cascades\"", ":", "12", ",", "\n", "\"channels\"", ":", "14", ",", "\n", "\"no_dc\"", ":", "False", ",", "\n", "\"pooling_layers\"", ":", "2", ",", "\n", "\"padding_size\"", ":", "11", ",", "\n", "\"normalize\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "5", ",", "15", ",", "12", ",", "2", "]", ",", "\n", "{", "\n", "\"num_cascades\"", ":", "12", ",", "\n", "\"channels\"", ":", "14", ",", "\n", "\"no_dc\"", ":", "True", ",", "\n", "\"pooling_layers\"", ":", "2", ",", "\n", "\"padding_size\"", ":", "11", ",", "\n", "\"normalize\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"num_cascades\"", ":", "18", ",", "\n", "\"channels\"", ":", "14", ",", "\n", "\"no_dc\"", ":", "False", ",", "\n", "\"pooling_layers\"", ":", "2", ",", "\n", "\"padding_size\"", ":", "11", ",", "\n", "\"normalize\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"num_cascades\"", ":", "2", ",", "\n", "\"channels\"", ":", "14", ",", "\n", "\"no_dc\"", ":", "False", ",", "\n", "\"pooling_layers\"", ":", "2", ",", "\n", "\"padding_size\"", ":", "15", ",", "\n", "\"normalize\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_vn", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test VN with different parameters\n\n    Args:\n        shape: shape of the input\n        cfg: configuration of the model\n        center_fractions: center fractions\n        accelerations: accelerations\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "vn", "=", "VarNet", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "vn", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_multidomainnet.create_input": [[13, 16], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "\"\"\"Create a random input tensor.\"\"\"", "\n", "return", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_multidomainnet.test_multidomainnet": [[18, 92], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "test_multidomainnet.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.multidomainnet.MultiDomainNet", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.multidomainnet.MultiDomainNet.forward", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"standardization\"", ":", "True", ",", "\n", "\"num_filters\"", ":", "16", ",", "\n", "\"num_pool_layers\"", ":", "2", ",", "\n", "\"dropout_probability\"", ":", "0.0", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"standardization\"", ":", "False", ",", "\n", "\"num_filters\"", ":", "64", ",", "\n", "\"num_pool_layers\"", ":", "4", ",", "\n", "\"dropout_probability\"", ":", "0.0", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_multidomainnet", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test the multidomainnet model.\n\n    Args:\n        shape (): The shape of the input data.\n        cfg (): The configuration of the model.\n        center_fractions (): The center fractions of the subsampling.\n        accelerations (): The accelerations of the subsampling.\n\n    Returns:\n        None.\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "kikinet", "=", "MultiDomainNet", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "kikinet", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_kikinet.create_input": [[13, 16], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "\"\"\"Create a random input tensor.\"\"\"", "\n", "return", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_kikinet.test_kikinet": [[18, 110], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "test_kikinet.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.kikinet.KIKINet", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.kikinet.KIKINet.forward", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_iter\"", ":", "2", ",", "\n", "\"kspace_model_architecture\"", ":", "\"UNET\"", ",", "\n", "\"kspace_unet_num_filters\"", ":", "16", ",", "\n", "\"kspace_unet_num_pool_layers\"", ":", "2", ",", "\n", "\"kspace_unet_dropout_probability\"", ":", "0.0", ",", "\n", "\"kspace_unet_padding_size\"", ":", "11", ",", "\n", "\"kspace_unet_normalize\"", ":", "True", ",", "\n", "\"imspace_model_architecture\"", ":", "\"UNET\"", ",", "\n", "\"imspace_unet_num_filters\"", ":", "16", ",", "\n", "\"imspace_unet_num_pool_layers\"", ":", "2", ",", "\n", "\"imspace_unet_dropout_probability\"", ":", "0.0", ",", "\n", "\"imspace_unet_padding_size\"", ":", "11", ",", "\n", "\"imspace_unet_normalize\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_iter\"", ":", "4", ",", "\n", "\"kspace_model_architecture\"", ":", "\"UNET\"", ",", "\n", "\"kspace_unet_num_filters\"", ":", "4", ",", "\n", "\"kspace_unet_num_pool_layers\"", ":", "2", ",", "\n", "\"kspace_unet_dropout_probability\"", ":", "0.0", ",", "\n", "\"kspace_unet_padding_size\"", ":", "11", ",", "\n", "\"kspace_unet_normalize\"", ":", "True", ",", "\n", "\"imspace_model_architecture\"", ":", "\"UNET\"", ",", "\n", "\"imspace_unet_num_filters\"", ":", "4", ",", "\n", "\"imspace_unet_num_pool_layers\"", ":", "2", ",", "\n", "\"imspace_unet_dropout_probability\"", ":", "0.0", ",", "\n", "\"imspace_unet_padding_size\"", ":", "11", ",", "\n", "\"imspace_unet_normalize\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_kikinet", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test the KIKINet model.\n\n    Args:\n        shape (): The shape of the input data.\n        cfg (): The configuration of the model.\n        center_fractions (): The center fractions of the subsampling.\n        accelerations (): The accelerations of the subsampling.\n\n    Returns:\n        None.\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "kikinet", "=", "KIKINet", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "kikinet", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_cirim.test_cirim": [[16, 208], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "tests.collections.reconstruction.fastmri.conftest.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.cirim.CIRIM", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.cirim.CIRIM.forward", "torch.cat.sum", "next", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"recurrent_layer\"", ":", "\"IndRNN\"", ",", "\n", "\"conv_filters\"", ":", "[", "64", ",", "64", ",", "2", "]", ",", "\n", "\"conv_kernels\"", ":", "[", "5", ",", "3", ",", "3", "]", ",", "\n", "\"conv_dilations\"", ":", "[", "1", ",", "2", ",", "1", "]", ",", "\n", "\"conv_bias\"", ":", "[", "True", ",", "True", ",", "False", "]", ",", "\n", "\"recurrent_filters\"", ":", "[", "64", ",", "64", ",", "0", "]", ",", "\n", "\"recurrent_kernels\"", ":", "[", "1", ",", "1", ",", "0", "]", ",", "\n", "\"recurrent_dilations\"", ":", "[", "1", ",", "1", ",", "0", "]", ",", "\n", "\"recurrent_bias\"", ":", "[", "True", ",", "True", ",", "False", "]", ",", "\n", "\"depth\"", ":", "2", ",", "\n", "\"conv_dim\"", ":", "2", ",", "\n", "\"time_steps\"", ":", "8", ",", "\n", "\"num_cascades\"", ":", "1", ",", "\n", "\"accumulate_estimates\"", ":", "True", ",", "\n", "\"no_dc\"", ":", "True", ",", "\n", "\"keep_eta\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "5", ",", "15", ",", "12", ",", "2", "]", ",", "\n", "{", "\n", "\"recurrent_layer\"", ":", "\"IndRNN\"", ",", "\n", "\"conv_filters\"", ":", "[", "64", ",", "64", ",", "2", "]", ",", "\n", "\"conv_kernels\"", ":", "[", "5", ",", "3", ",", "3", "]", ",", "\n", "\"conv_dilations\"", ":", "[", "1", ",", "2", ",", "1", "]", ",", "\n", "\"conv_bias\"", ":", "[", "True", ",", "True", ",", "False", "]", ",", "\n", "\"recurrent_filters\"", ":", "[", "64", ",", "64", ",", "0", "]", ",", "\n", "\"recurrent_kernels\"", ":", "[", "1", ",", "1", ",", "0", "]", ",", "\n", "\"recurrent_dilations\"", ":", "[", "1", ",", "1", ",", "0", "]", ",", "\n", "\"recurrent_bias\"", ":", "[", "True", ",", "True", ",", "False", "]", ",", "\n", "\"depth\"", ":", "2", ",", "\n", "\"conv_dim\"", ":", "2", ",", "\n", "\"time_steps\"", ":", "8", ",", "\n", "\"num_cascades\"", ":", "32", ",", "\n", "\"accumulate_estimates\"", ":", "True", ",", "\n", "\"no_dc\"", ":", "True", ",", "\n", "\"keep_eta\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "8", ",", "13", ",", "18", ",", "2", "]", ",", "\n", "{", "\n", "\"recurrent_layer\"", ":", "\"IndRNN\"", ",", "\n", "\"conv_filters\"", ":", "[", "64", ",", "64", ",", "2", "]", ",", "\n", "\"conv_kernels\"", ":", "[", "5", ",", "3", ",", "3", "]", ",", "\n", "\"conv_dilations\"", ":", "[", "1", ",", "2", ",", "1", "]", ",", "\n", "\"conv_bias\"", ":", "[", "True", ",", "True", ",", "False", "]", ",", "\n", "\"recurrent_filters\"", ":", "[", "64", ",", "64", ",", "0", "]", ",", "\n", "\"recurrent_kernels\"", ":", "[", "1", ",", "1", ",", "0", "]", ",", "\n", "\"recurrent_dilations\"", ":", "[", "1", ",", "1", ",", "0", "]", ",", "\n", "\"recurrent_bias\"", ":", "[", "True", ",", "True", ",", "False", "]", ",", "\n", "\"depth\"", ":", "2", ",", "\n", "\"conv_dim\"", ":", "2", ",", "\n", "\"time_steps\"", ":", "8", ",", "\n", "\"num_cascades\"", ":", "16", ",", "\n", "\"accumulate_estimates\"", ":", "True", ",", "\n", "\"no_dc\"", ":", "True", ",", "\n", "\"keep_eta\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"recurrent_layer\"", ":", "\"IndRNN\"", ",", "\n", "\"conv_filters\"", ":", "[", "64", ",", "64", ",", "2", "]", ",", "\n", "\"conv_kernels\"", ":", "[", "5", ",", "3", ",", "3", "]", ",", "\n", "\"conv_dilations\"", ":", "[", "1", ",", "2", ",", "1", "]", ",", "\n", "\"conv_bias\"", ":", "[", "True", ",", "True", ",", "False", "]", ",", "\n", "\"recurrent_filters\"", ":", "[", "64", ",", "64", ",", "0", "]", ",", "\n", "\"recurrent_kernels\"", ":", "[", "1", ",", "1", ",", "0", "]", ",", "\n", "\"recurrent_dilations\"", ":", "[", "1", ",", "1", ",", "0", "]", ",", "\n", "\"recurrent_bias\"", ":", "[", "True", ",", "True", ",", "False", "]", ",", "\n", "\"depth\"", ":", "2", ",", "\n", "\"conv_dim\"", ":", "2", ",", "\n", "\"time_steps\"", ":", "8", ",", "\n", "\"num_cascades\"", ":", "8", ",", "\n", "\"accumulate_estimates\"", ":", "True", ",", "\n", "\"no_dc\"", ":", "True", ",", "\n", "\"keep_eta\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"recurrent_layer\"", ":", "\"IndRNN\"", ",", "\n", "\"conv_filters\"", ":", "[", "64", ",", "64", ",", "2", "]", ",", "\n", "\"conv_kernels\"", ":", "[", "5", ",", "3", ",", "3", "]", ",", "\n", "\"conv_dilations\"", ":", "[", "1", ",", "2", ",", "1", "]", ",", "\n", "\"conv_bias\"", ":", "[", "True", ",", "True", ",", "False", "]", ",", "\n", "\"recurrent_filters\"", ":", "[", "64", ",", "64", ",", "0", "]", ",", "\n", "\"recurrent_kernels\"", ":", "[", "1", ",", "1", ",", "0", "]", ",", "\n", "\"recurrent_dilations\"", ":", "[", "1", ",", "1", ",", "0", "]", ",", "\n", "\"recurrent_bias\"", ":", "[", "True", ",", "True", ",", "False", "]", ",", "\n", "\"depth\"", ":", "2", ",", "\n", "\"conv_dim\"", ":", "2", ",", "\n", "\"time_steps\"", ":", "8", ",", "\n", "\"num_cascades\"", ":", "8", ",", "\n", "\"accumulate_estimates\"", ":", "True", ",", "\n", "\"no_dc\"", ":", "True", ",", "\n", "\"keep_eta\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_cirim", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test CIRIM with different parameters\n\n    Args:\n        shape: shape of the input\n        cfg: configuration of the model\n        center_fractions: center fractions\n        accelerations: accelerations\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "cirim", "=", "CIRIM", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "cirim", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ".", "sum", "(", "1", ")", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "try", ":", "\n", "            ", "y", "=", "next", "(", "y", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "pass", "\n", "\n", "", "y", "=", "y", "[", "-", "1", "]", "[", "-", "1", "]", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_jointicnet.create_input": [[13, 16], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "\"\"\"Create a random input tensor.\"\"\"", "\n", "return", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_jointicnet.test_jointicnet": [[18, 114], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "test_jointicnet.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.jointicnet.JointICNet", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.jointicnet.JointICNet.forward", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_iter\"", ":", "2", ",", "\n", "\"kspace_unet_num_filters\"", ":", "4", ",", "\n", "\"kspace_unet_num_pool_layers\"", ":", "2", ",", "\n", "\"kspace_unet_dropout_probability\"", ":", "0.0", ",", "\n", "\"kspace_unet_padding_size\"", ":", "11", ",", "\n", "\"kspace_unet_normalize\"", ":", "True", ",", "\n", "\"imspace_unet_num_filters\"", ":", "4", ",", "\n", "\"imspace_unet_num_pool_layers\"", ":", "2", ",", "\n", "\"imspace_unet_dropout_probability\"", ":", "0.0", ",", "\n", "\"imspace_unet_padding_size\"", ":", "11", ",", "\n", "\"imspace_unet_normalize\"", ":", "True", ",", "\n", "\"sens_unet_num_filters\"", ":", "4", ",", "\n", "\"sens_unet_num_pool_layers\"", ":", "2", ",", "\n", "\"sens_unet_dropout_probability\"", ":", "0.0", ",", "\n", "\"sens_unet_padding_size\"", ":", "11", ",", "\n", "\"sens_unet_normalize\"", ":", "True", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_iter\"", ":", "4", ",", "\n", "\"kspace_unet_num_filters\"", ":", "16", ",", "\n", "\"kspace_unet_num_pool_layers\"", ":", "4", ",", "\n", "\"kspace_unet_dropout_probability\"", ":", "0.05", ",", "\n", "\"kspace_unet_padding_size\"", ":", "15", ",", "\n", "\"kspace_unet_normalize\"", ":", "False", ",", "\n", "\"imspace_unet_num_filters\"", ":", "16", ",", "\n", "\"imspace_unet_num_pool_layers\"", ":", "4", ",", "\n", "\"imspace_unet_dropout_probability\"", ":", "0.05", ",", "\n", "\"imspace_unet_padding_size\"", ":", "11", ",", "\n", "\"imspace_unet_normalize\"", ":", "False", ",", "\n", "\"sens_unet_num_filters\"", ":", "16", ",", "\n", "\"sens_unet_num_pool_layers\"", ":", "4", ",", "\n", "\"sens_unet_dropout_probability\"", ":", "0.05", ",", "\n", "\"sens_unet_padding_size\"", ":", "15", ",", "\n", "\"sens_unet_normalize\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_jointicnet", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test JointICNet\n\n    Args:\n        shape (): shape of the input\n        cfg (): configuration\n        center_fractions (): center fractions\n        accelerations (): accelerations\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "jointicnet", "=", "JointICNet", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "jointicnet", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_conv2dgru.create_input": [[13, 16], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "\"\"\"Create a random input tensor.\"\"\"", "\n", "return", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_conv2dgru.test_conv2dgru": [[18, 47], ["pytest.mark.parametrize", "pytest.mark.parametrize", "mridc.collections.reconstruction.models.recurrentvarnet.conv2gru.Conv2dGRU", "create_input().cpu", "mridc.collections.reconstruction.models.recurrentvarnet.conv2gru.Conv2dGRU.", "list", "test_conv2dgru.create_input"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "2", ",", "32", ",", "32", "]", ",", "\n", "[", "3", ",", "2", ",", "16", ",", "16", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"hidden_channels\"", ",", "\n", "[", "4", ",", "8", "]", ",", "\n", ")", "\n", "def", "test_conv2dgru", "(", "shape", ",", "hidden_channels", ")", ":", "\n", "    ", "\"\"\"\n    Test the Conv2dGRU model.\n\n    Args:\n        shape (): The shape of the input data.\n        hidden_channels (): The number of channels in the hidden state.\n\n    Returns:\n        None\n    \"\"\"", "\n", "model", "=", "Conv2dGRU", "(", "shape", "[", "1", "]", ",", "hidden_channels", ",", "shape", "[", "1", "]", ")", "\n", "data", "=", "create_input", "(", "shape", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "data", ",", "None", ")", "[", "0", "]", "\n", "\n", "if", "list", "(", "out", ".", "shape", ")", "!=", "shape", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_dunet.test_dunet": [[16, 140], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "tests.collections.reconstruction.fastmri.conftest.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.dunet.DUNet", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.dunet.DUNet.forward", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_iter\"", ":", "1", ",", "\n", "\"reg_model_architecture\"", ":", "\"DIDN\"", ",", "\n", "\"didn_hidden_channels\"", ":", "64", ",", "\n", "\"didn_num_dubs\"", ":", "2", ",", "\n", "\"didn_num_convs_recon\"", ":", "1", ",", "\n", "\"data_consistency_term\"", ":", "\"PROX\"", ",", "\n", "\"data_consistency_lambda_init\"", ":", "0.1", ",", "\n", "\"shared_params\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "5", ",", "15", ",", "12", ",", "2", "]", ",", "\n", "{", "\n", "\"num_iter\"", ":", "10", ",", "\n", "\"reg_model_architecture\"", ":", "\"DIDN\"", ",", "\n", "\"didn_hidden_channels\"", ":", "64", ",", "\n", "\"didn_num_dubs\"", ":", "2", ",", "\n", "\"didn_num_convs_recon\"", ":", "5", ",", "\n", "\"data_consistency_term\"", ":", "\"PROX\"", ",", "\n", "\"data_consistency_lambda_init\"", ":", "0.1", ",", "\n", "\"shared_params\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"num_iter\"", ":", "1", ",", "\n", "\"reg_model_architecture\"", ":", "\"DIDN\"", ",", "\n", "\"didn_hidden_channels\"", ":", "128", ",", "\n", "\"didn_num_dubs\"", ":", "4", ",", "\n", "\"didn_num_convs_recon\"", ":", "1", ",", "\n", "\"data_consistency_term\"", ":", "\"PROX\"", ",", "\n", "\"data_consistency_lambda_init\"", ":", "0.1", ",", "\n", "\"shared_params\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"num_iter\"", ":", "4", ",", "\n", "\"reg_model_architecture\"", ":", "\"DIDN\"", ",", "\n", "\"didn_hidden_channels\"", ":", "64", ",", "\n", "\"didn_num_dubs\"", ":", "4", ",", "\n", "\"didn_num_convs_recon\"", ":", "4", ",", "\n", "\"data_consistency_term\"", ":", "\"PROX\"", ",", "\n", "\"data_consistency_lambda_init\"", ":", "0.1", ",", "\n", "\"shared_params\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_dunet", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test DUNet with different parameters\n\n    Args:\n        shape: shape of the input\n        cfg: configuration of the model\n        center_fractions: center fractions\n        accelerations: accelerations\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "dunet", "=", "DUNet", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "dunet", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_crnn.test_crnn": [[16, 135], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "tests.collections.reconstruction.fastmri.conftest.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.crnn.CRNNet", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.crnn.CRNNet.forward", "next", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_iterations\"", ":", "10", ",", "\n", "\"hidden_channels\"", ":", "64", ",", "\n", "\"n_convs\"", ":", "5", ",", "\n", "\"batchnorm\"", ":", "False", ",", "\n", "\"no_dc\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "5", ",", "15", ",", "12", ",", "2", "]", ",", "\n", "{", "\n", "\"num_iterations\"", ":", "10", ",", "\n", "\"hidden_channels\"", ":", "64", ",", "\n", "\"n_convs\"", ":", "5", ",", "\n", "\"batchnorm\"", ":", "False", ",", "\n", "\"no_dc\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"num_iterations\"", ":", "10", ",", "\n", "\"hidden_channels\"", ":", "64", ",", "\n", "\"n_convs\"", ":", "5", ",", "\n", "\"batchnorm\"", ":", "True", ",", "\n", "\"no_dc\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"num_iterations\"", ":", "10", ",", "\n", "\"hidden_channels\"", ":", "64", ",", "\n", "\"n_convs\"", ":", "5", ",", "\n", "\"batchnorm\"", ":", "True", ",", "\n", "\"no_dc\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_crnn", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test CRNNet with different parameters\n\n    Args:\n        shape: shape of the input\n        cfg: configuration of the model\n        center_fractions: center fractions\n        accelerations: accelerations\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "crnn", "=", "CRNNet", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "crnn", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "try", ":", "\n", "            ", "y", "=", "next", "(", "y", ")", "\n", "", "except", "StopIteration", ":", "\n", "            ", "pass", "\n", "\n", "", "y", "=", "y", "[", "-", "1", "]", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_conv.create_input": [[14, 17], ["torch.rand().float", "torch.rand().float", "torch.rand", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "\"\"\"Create a random input tensor.\"\"\"", "\n", "return", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_conv.test_conv": [[19, 69], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "mridc.collections.reconstruction.models.conv.conv2d.Conv2d", "create_input().cpu", "mridc.collections.reconstruction.models.conv.conv2d.Conv2d.", "list", "torch.ReLU", "torch.PReLU", "test_conv.create_input"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "2", ",", "32", ",", "32", "]", ",", "\n", "[", "3", ",", "2", ",", "16", ",", "16", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"out_channels\"", ",", "\n", "[", "3", ",", "5", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"hidden_channels\"", ",", "\n", "[", "16", ",", "8", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"n_convs\"", ",", "\n", "[", "2", ",", "4", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"act\"", ",", "\n", "[", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "PReLU", "(", ")", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"batchnorm\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_conv", "(", "shape", ",", "out_channels", ",", "hidden_channels", ",", "n_convs", ",", "act", ",", "batchnorm", ")", ":", "\n", "    ", "\"\"\"\n    Test the Conv2d class.\n\n    Args:\n        shape (): The shape of the input data.\n        out_channels (): The number of output channels.\n        hidden_channels (): The number of hidden channels.\n        n_convs (): The number of convolutions.\n        act (): The activation function.\n        batchnorm (): Whether to use batch normalization.\n\n    Returns:\n        None\n    \"\"\"", "\n", "model", "=", "Conv2d", "(", "shape", "[", "1", "]", ",", "out_channels", ",", "hidden_channels", ",", "n_convs", ",", "act", ",", "batchnorm", ")", "\n", "\n", "data", "=", "create_input", "(", "shape", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "data", ")", "\n", "\n", "if", "list", "(", "out", ".", "shape", ")", "!=", "[", "shape", "[", "0", "]", "]", "+", "[", "out_channels", "]", "+", "shape", "[", "2", ":", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_mwcnn.create_input": [[14, 17], ["torch.rand().float", "torch.rand().float", "torch.rand", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "\"\"\"Create a random input tensor.\"\"\"", "\n", "return", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_mwcnn.test_mwcnn": [[19, 69], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "mridc.collections.reconstruction.models.mwcnn.mwcnn.MWCNN", "create_input().cpu", "mridc.collections.reconstruction.models.mwcnn.mwcnn.MWCNN.", "list", "torch.ReLU", "torch.PReLU", "test_mwcnn.create_input"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "2", ",", "32", ",", "32", "]", ",", "\n", "[", "3", ",", "2", ",", "20", ",", "34", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"first_conv_hidden_channels\"", ",", "\n", "[", "4", ",", "8", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"n_scales\"", ",", "\n", "[", "2", ",", "3", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"bias\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"batchnorm\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"act\"", ",", "\n", "[", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "PReLU", "(", ")", "]", ",", "\n", ")", "\n", "def", "test_mwcnn", "(", "shape", ",", "first_conv_hidden_channels", ",", "n_scales", ",", "bias", ",", "batchnorm", ",", "act", ")", ":", "\n", "    ", "\"\"\"\n    Test MWCNN model.\n\n    Args:\n        shape (): Shape of input data.\n        first_conv_hidden_channels (): Number of channels in first convolutional layer.\n        n_scales (): Number of scales.\n        bias (): Whether to use bias in convolutional layers.\n        batchnorm (): Whether to use batch normalization in convolutional layers.\n        act (): Activation function.\n\n    Returns:\n        None.\n    \"\"\"", "\n", "model", "=", "MWCNN", "(", "shape", "[", "1", "]", ",", "first_conv_hidden_channels", ",", "n_scales", ",", "bias", ",", "batchnorm", ",", "act", ")", "\n", "\n", "data", "=", "create_input", "(", "shape", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "data", ")", "\n", "\n", "if", "list", "(", "out", ".", "shape", ")", "!=", "shape", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_vsnet.test_vsnet": [[16, 125], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "tests.collections.reconstruction.fastmri.conftest.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.vsnet.VSNet", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.vsnet.VSNet.forward", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_cascades\"", ":", "10", ",", "\n", "\"imspace_model_architecture\"", ":", "\"CONV\"", ",", "\n", "\"imspace_conv_hidden_channels\"", ":", "64", ",", "\n", "\"imspace_conv_n_convs\"", ":", "5", ",", "\n", "\"imspace_conv_batchnorm\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "5", ",", "15", ",", "12", ",", "2", "]", ",", "\n", "{", "\n", "\"num_cascades\"", ":", "10", ",", "\n", "\"imspace_model_architecture\"", ":", "\"CONV\"", ",", "\n", "\"imspace_conv_hidden_channels\"", ":", "64", ",", "\n", "\"imspace_conv_n_convs\"", ":", "5", ",", "\n", "\"imspace_conv_batchnorm\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"num_cascades\"", ":", "10", ",", "\n", "\"imspace_model_architecture\"", ":", "\"CONV\"", ",", "\n", "\"imspace_conv_hidden_channels\"", ":", "16", ",", "\n", "\"imspace_conv_n_convs\"", ":", "5", ",", "\n", "\"imspace_conv_batchnorm\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"num_cascades\"", ":", "2", ",", "\n", "\"imspace_model_architecture\"", ":", "\"CONV\"", ",", "\n", "\"imspace_conv_hidden_channels\"", ":", "128", ",", "\n", "\"imspace_conv_n_convs\"", ":", "2", ",", "\n", "\"imspace_conv_batchnorm\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_vsnet", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test VSNet with different parameters\n\n    Args:\n        shape: shape of the input\n        cfg: configuration of the model\n        center_fractions: center fractions\n        accelerations: accelerations\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "vsnet", "=", "VSNet", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "vsnet", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_lpdnet.create_input": [[13, 16], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "\"\"\"Create a random input tensor.\"\"\"", "\n", "return", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_lpdnet.test_lpdnet": [[18, 114], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "test_lpdnet.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.lpd.LPDNet", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.lpd.LPDNet.forward", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_primal\"", ":", "5", ",", "\n", "\"num_dual\"", ":", "5", ",", "\n", "\"num_iter\"", ":", "5", ",", "\n", "\"primal_model_architecture\"", ":", "\"UNET\"", ",", "\n", "\"primal_unet_num_filters\"", ":", "16", ",", "\n", "\"primal_unet_num_pool_layers\"", ":", "2", ",", "\n", "\"primal_unet_dropout_probability\"", ":", "0.0", ",", "\n", "\"primal_unet_padding_size\"", ":", "11", ",", "\n", "\"primal_unet_normalize\"", ":", "True", ",", "\n", "\"dual_model_architecture\"", ":", "\"UNET\"", ",", "\n", "\"dual_unet_num_filters\"", ":", "16", ",", "\n", "\"dual_unet_num_pool_layers\"", ":", "2", ",", "\n", "\"dual_unet_dropout_probability\"", ":", "0.0", ",", "\n", "\"dual_unet_padding_size\"", ":", "11", ",", "\n", "\"dual_unet_normalize\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_primal\"", ":", "2", ",", "\n", "\"num_dual\"", ":", "2", ",", "\n", "\"num_iter\"", ":", "2", ",", "\n", "\"primal_model_architecture\"", ":", "\"UNET\"", ",", "\n", "\"primal_unet_num_filters\"", ":", "4", ",", "\n", "\"primal_unet_num_pool_layers\"", ":", "4", ",", "\n", "\"primal_unet_dropout_probability\"", ":", "0.0", ",", "\n", "\"primal_unet_padding_size\"", ":", "15", ",", "\n", "\"primal_unet_normalize\"", ":", "False", ",", "\n", "\"dual_model_architecture\"", ":", "\"UNET\"", ",", "\n", "\"dual_unet_num_filters\"", ":", "4", ",", "\n", "\"dual_unet_num_pool_layers\"", ":", "4", ",", "\n", "\"dual_unet_dropout_probability\"", ":", "0.0", ",", "\n", "\"dual_unet_padding_size\"", ":", "15", ",", "\n", "\"dual_unet_normalize\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_lpdnet", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test the LPDNet model.\n\n    Args:\n        shape (): The shape of the input data.\n        cfg (): The configuration of the LPDNet model.\n        center_fractions (): The center fractions of the subsampling.\n        accelerations (): The accelerations of the subsampling.\n\n    Returns:\n        None.\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "lpdnet", "=", "LPDNet", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "lpdnet", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_ccnn.test_ccnn": [[16, 128], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "tests.collections.reconstruction.fastmri.conftest.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.ccnn.CascadeNet", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.ccnn.CascadeNet.forward", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_cascades\"", ":", "10", ",", "\n", "\"hidden_channels\"", ":", "64", ",", "\n", "\"n_convs\"", ":", "5", ",", "\n", "\"batchnorm\"", ":", "False", ",", "\n", "\"no_dc\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "5", ",", "15", ",", "12", ",", "2", "]", ",", "\n", "{", "\n", "\"num_cascades\"", ":", "10", ",", "\n", "\"hidden_channels\"", ":", "64", ",", "\n", "\"n_convs\"", ":", "5", ",", "\n", "\"batchnorm\"", ":", "False", ",", "\n", "\"no_dc\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"num_cascades\"", ":", "10", ",", "\n", "\"hidden_channels\"", ":", "64", ",", "\n", "\"n_convs\"", ":", "5", ",", "\n", "\"batchnorm\"", ":", "True", ",", "\n", "\"no_dc\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"num_cascades\"", ":", "10", ",", "\n", "\"hidden_channels\"", ":", "64", ",", "\n", "\"n_convs\"", ":", "5", ",", "\n", "\"batchnorm\"", ":", "True", ",", "\n", "\"no_dc\"", ":", "True", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_ccnn", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test CascadeNet with different parameters\n\n    Args:\n        shape: shape of the input\n        cfg: configuration of the model\n        center_fractions: center fractions\n        accelerations: accelerations\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "ccnn", "=", "CascadeNet", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "ccnn", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_xpdnet.create_input": [[13, 16], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "\"\"\"Create a random input tensor.\"\"\"", "\n", "return", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_xpdnet.test_xpdnet": [[18, 112], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "test_xpdnet.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.xpdnet.XPDNet", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.xpdnet.XPDNet.forward", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_primal\"", ":", "5", ",", "\n", "\"num_dual\"", ":", "5", ",", "\n", "\"num_iter\"", ":", "20", ",", "\n", "\"use_primal_only\"", ":", "True", ",", "\n", "\"kspace_model_architecture\"", ":", "\"CONV\"", ",", "\n", "\"dual_conv_hidden_channels\"", ":", "16", ",", "\n", "\"dual_conv_num_dubs\"", ":", "2", ",", "\n", "\"dual_conv_batchnorm\"", ":", "False", ",", "\n", "\"image_model_architecture\"", ":", "\"MWCNN\"", ",", "\n", "\"mwcnn_hidden_channels\"", ":", "16", ",", "\n", "\"mwcnn_num_scales\"", ":", "2", ",", "\n", "\"mwcnn_bias\"", ":", "True", ",", "\n", "\"mwcnn_batchnorm\"", ":", "False", ",", "\n", "\"normalize_image\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"num_primal\"", ":", "5", ",", "\n", "\"num_dual\"", ":", "5", ",", "\n", "\"num_iter\"", ":", "20", ",", "\n", "\"use_primal_only\"", ":", "True", ",", "\n", "\"kspace_model_architecture\"", ":", "\"CONV\"", ",", "\n", "\"dual_conv_hidden_channels\"", ":", "16", ",", "\n", "\"dual_conv_num_dubs\"", ":", "2", ",", "\n", "\"dual_conv_batchnorm\"", ":", "False", ",", "\n", "\"image_model_architecture\"", ":", "\"MWCNN\"", ",", "\n", "\"mwcnn_hidden_channels\"", ":", "16", ",", "\n", "\"mwcnn_num_scales\"", ":", "2", ",", "\n", "\"mwcnn_bias\"", ":", "True", ",", "\n", "\"mwcnn_batchnorm\"", ":", "False", ",", "\n", "\"normalize_image\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_xpdnet", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test the XPDNet model.\n\n    Args:\n        shape (): The shape of the input data.\n        cfg (): The configuration of the model.\n        center_fractions (): The center fractions of the subsampling.\n        accelerations (): The accelerations of the subsampling.\n\n    Returns:\n        None.\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "xpdnet", "=", "XPDNet", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "xpdnet", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input": [[13, 16], ["torch.rand().float", "torch.rand"], "function", ["None"], ["def", "create_input", "(", "shape", ")", ":", "\n", "    ", "\"\"\"Create a random input tensor.\"\"\"", "\n", "return", "torch", ".", "rand", "(", "shape", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.test_didn": [[18, 68], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "mridc.collections.reconstruction.models.didn.didn.DIDN", "create_input().cpu", "mridc.collections.reconstruction.models.didn.didn.DIDN.", "list", "test_didn.create_input"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape\"", ",", "\n", "[", "\n", "[", "3", ",", "2", ",", "32", ",", "32", "]", ",", "\n", "[", "3", ",", "2", ",", "16", ",", "16", "]", ",", "\n", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"out_channels\"", ",", "\n", "[", "3", ",", "5", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"hidden_channels\"", ",", "\n", "[", "16", ",", "8", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"n_dubs\"", ",", "\n", "[", "3", ",", "4", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"num_convs_recon\"", ",", "\n", "[", "3", ",", "4", "]", ",", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"skip\"", ",", "\n", "[", "True", ",", "False", "]", ",", "\n", ")", "\n", "def", "test_didn", "(", "shape", ",", "out_channels", ",", "hidden_channels", ",", "n_dubs", ",", "num_convs_recon", ",", "skip", ")", ":", "\n", "    ", "\"\"\"\n    Test the DIDN\n\n    Args:\n        shape (): shape of the input\n        out_channels (): number of output channels\n        hidden_channels (): number of hidden channels\n        n_dubs (): number of dubs\n        num_convs_recon (): number of convolutions in the reconstruction network\n        skip (): whether to use skip connections or not\n\n    Returns:\n        None\n    \"\"\"", "\n", "model", "=", "DIDN", "(", "shape", "[", "1", "]", ",", "out_channels", ",", "hidden_channels", ",", "n_dubs", ",", "num_convs_recon", ",", "skip", ")", "\n", "\n", "data", "=", "create_input", "(", "shape", ")", ".", "cpu", "(", ")", "\n", "\n", "out", "=", "model", "(", "data", ")", "\n", "\n", "if", "list", "(", "out", ".", "shape", ")", "!=", "[", "shape", "[", "0", "]", "]", "+", "[", "out_channels", "]", "+", "shape", "[", "2", ":", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.test_recurrentvarnet.test_recurrentvarnet": [[16, 159], ["pytest.mark.parametrize", "mridc.collections.reconstruction.data.subsample.RandomMaskFunc", "tests.collections.reconstruction.fastmri.conftest.create_input", "range", "torch.cat", "torch.cat", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.create", "mridc.collections.reconstruction.models.rvn.RecurrentVarNet", "mridc.collections.reconstruction.parts.transforms.apply_mask", "outputs.append", "masks.append", "omegaconf.OmegaConf.to_container", "torch.no_grad", "mridc.collections.reconstruction.models.rvn.RecurrentVarNet.forward", "tests.collections.reconstruction.fastmri.conftest.create_input.sum", "torch.abs", "torch.view_as_complex"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.models.test_didn.create_input", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"shape, cfg, center_fractions, accelerations\"", ",", "\n", "[", "\n", "(", "\n", "[", "1", ",", "3", ",", "32", ",", "16", ",", "2", "]", ",", "\n", "{", "\n", "\"in_channels\"", ":", "2", ",", "\n", "\"recurrent_hidden_channels\"", ":", "64", ",", "\n", "\"recurrent_num_layers\"", ":", "4", ",", "\n", "\"num_steps\"", ":", "8", ",", "\n", "\"no_parameter_sharing\"", ":", "True", ",", "\n", "\"learned_initializer\"", ":", "True", ",", "\n", "\"initializer_initialization\"", ":", "\"sense\"", ",", "\n", "\"initializer_channels\"", ":", "[", "32", ",", "32", ",", "64", ",", "64", "]", ",", "\n", "\"initializer_dilations\"", ":", "[", "1", ",", "1", ",", "2", ",", "4", "]", ",", "\n", "\"initializer_multiscale\"", ":", "1", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "5", ",", "15", ",", "12", ",", "2", "]", ",", "\n", "{", "\n", "\"in_channels\"", ":", "2", ",", "\n", "\"recurrent_hidden_channels\"", ":", "64", ",", "\n", "\"recurrent_num_layers\"", ":", "4", ",", "\n", "\"num_steps\"", ":", "8", ",", "\n", "\"no_parameter_sharing\"", ":", "False", ",", "\n", "\"learned_initializer\"", ":", "True", ",", "\n", "\"initializer_initialization\"", ":", "\"sense\"", ",", "\n", "\"initializer_channels\"", ":", "[", "32", ",", "32", ",", "64", ",", "64", "]", ",", "\n", "\"initializer_dilations\"", ":", "[", "1", ",", "1", ",", "2", ",", "4", "]", ",", "\n", "\"initializer_multiscale\"", ":", "1", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "8", ",", "13", ",", "18", ",", "2", "]", ",", "\n", "{", "\n", "\"in_channels\"", ":", "2", ",", "\n", "\"recurrent_hidden_channels\"", ":", "64", ",", "\n", "\"recurrent_num_layers\"", ":", "4", ",", "\n", "\"num_steps\"", ":", "8", ",", "\n", "\"no_parameter_sharing\"", ":", "False", ",", "\n", "\"learned_initializer\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"in_channels\"", ":", "2", ",", "\n", "\"recurrent_hidden_channels\"", ":", "64", ",", "\n", "\"recurrent_num_layers\"", ":", "4", ",", "\n", "\"num_steps\"", ":", "8", ",", "\n", "\"no_parameter_sharing\"", ":", "True", ",", "\n", "\"learned_initializer\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "(", "\n", "[", "1", ",", "2", ",", "17", ",", "19", ",", "2", "]", ",", "\n", "{", "\n", "\"in_channels\"", ":", "2", ",", "\n", "\"recurrent_hidden_channels\"", ":", "64", ",", "\n", "\"recurrent_num_layers\"", ":", "4", ",", "\n", "\"num_steps\"", ":", "18", ",", "\n", "\"no_parameter_sharing\"", ":", "True", ",", "\n", "\"learned_initializer\"", ":", "False", ",", "\n", "\"use_sens_net\"", ":", "False", ",", "\n", "\"coil_combination_method\"", ":", "\"SENSE\"", ",", "\n", "\"fft_centered\"", ":", "True", ",", "\n", "\"fft_normalization\"", ":", "\"ortho\"", ",", "\n", "\"spatial_dims\"", ":", "[", "-", "2", ",", "-", "1", "]", ",", "\n", "\"coil_dim\"", ":", "1", ",", "\n", "}", ",", "\n", "[", "0.08", "]", ",", "\n", "[", "4", "]", ",", "\n", ")", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_recurrentvarnet", "(", "shape", ",", "cfg", ",", "center_fractions", ",", "accelerations", ")", ":", "\n", "    ", "\"\"\"\n    Test RecurrentVarNet with different parameters\n\n    Args:\n        shape: shape of the input\n        cfg: configuration of the model\n        center_fractions: center fractions\n        accelerations: accelerations\n\n    Returns:\n        None\n    \"\"\"", "\n", "mask_func", "=", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "x", "=", "create_input", "(", "shape", ")", "\n", "\n", "outputs", ",", "masks", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "mask", ",", "_", "=", "transforms", ".", "apply_mask", "(", "x", "[", "i", ":", "i", "+", "1", "]", ",", "mask_func", ",", "seed", "=", "123", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "outputs", ")", "\n", "mask", "=", "torch", ".", "cat", "(", "masks", ")", "\n", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ")", "\n", "\n", "rvn", "=", "RecurrentVarNet", "(", "cfg", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y", "=", "rvn", ".", "forward", "(", "output", ",", "output", ",", "mask", ",", "output", ",", "eta", "=", "x", ".", "sum", "(", "1", ")", ",", "target", "=", "torch", ".", "abs", "(", "torch", ".", "view_as_complex", "(", "output", ")", ")", ")", "\n", "\n", "", "if", "y", ".", "shape", "[", "1", ":", "]", "!=", "x", ".", "shape", "[", "2", ":", "4", "]", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.vsnet.VSNet.__init__": [[44, 110], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "mridc.collections.reconstruction.models.variablesplittingnet.vsnet_block.VSNetBlock", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.conv.conv2d.Conv2d", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.reconstruction.models.mwcnn.mwcnn.MWCNN", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet", "NotImplementedError", "mridc.collections.reconstruction.models.variablesplittingnet.vsnet_block.DataConsistencyLayer", "mridc.collections.reconstruction.models.variablesplittingnet.vsnet_block.WeightedAverageTerm", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "num_cascades", "=", "cfg_dict", ".", "get", "(", "\"num_cascades\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "self", ".", "num_cascades", "=", "cfg_dict", ".", "get", "(", "\"num_cascades\"", ")", "\n", "\n", "image_model_architecture", "=", "cfg_dict", ".", "get", "(", "\"imspace_model_architecture\"", ")", "\n", "if", "image_model_architecture", "==", "\"CONV\"", ":", "\n", "            ", "image_model", "=", "Conv2d", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"imspace_conv_hidden_channels\"", ")", ",", "\n", "n_convs", "=", "cfg_dict", ".", "get", "(", "\"imspace_conv_n_convs\"", ")", ",", "\n", "batchnorm", "=", "cfg_dict", ".", "get", "(", "\"imspace_conv_batchnorm\"", ")", ",", "\n", ")", "\n", "", "elif", "image_model_architecture", "==", "\"MWCNN\"", ":", "\n", "            ", "image_model", "=", "MWCNN", "(", "\n", "input_channels", "=", "2", ",", "\n", "first_conv_hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"image_mwcnn_hidden_channels\"", ")", ",", "\n", "num_scales", "=", "cfg_dict", ".", "get", "(", "\"image_mwcnn_num_scales\"", ")", ",", "\n", "bias", "=", "cfg_dict", ".", "get", "(", "\"image_mwcnn_bias\"", ")", ",", "\n", "batchnorm", "=", "cfg_dict", ".", "get", "(", "\"image_mwcnn_batchnorm\"", ")", ",", "\n", ")", "\n", "", "elif", "image_model_architecture", "in", "[", "\"UNET\"", ",", "\"NORMUNET\"", "]", ":", "\n", "            ", "image_model", "=", "NormUnet", "(", "\n", "cfg_dict", ".", "get", "(", "\"imspace_unet_num_filters\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"imspace_unet_num_pool_layers\"", ")", ",", "\n", "in_chans", "=", "2", ",", "\n", "out_chans", "=", "2", ",", "\n", "drop_prob", "=", "cfg_dict", ".", "get", "(", "\"imspace_unet_dropout_probability\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"imspace_unet_padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"imspace_unet_normalize\"", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"VSNet is currently implemented only with image_model_architecture == 'MWCNN' or 'UNet'.\"", "\n", "f\"Got {image_model_architecture}.\"", "\n", ")", "\n", "\n", "", "image_model", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "image_model", "]", "*", "num_cascades", ")", "\n", "data_consistency_model", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "DataConsistencyLayer", "(", ")", "]", "*", "num_cascades", ")", "\n", "weighted_average_model", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "WeightedAverageTerm", "(", ")", "]", "*", "num_cascades", ")", "\n", "\n", "self", ".", "model", "=", "VSNetBlock", "(", "\n", "denoiser_block", "=", "image_model", ",", "\n", "data_consistency_block", "=", "data_consistency_model", ",", "\n", "weighted_average_block", "=", "weighted_average_model", ",", "\n", "num_cascades", "=", "num_cascades", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", "coil_dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", "\n", "self", ".", "coil_combination_method", "=", "cfg_dict", ".", "get", "(", "\"coil_combination_method\"", ")", "\n", "\n", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "accumulate_estimates", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.vsnet.VSNet.forward": [[111, 159], ["mridc.core.classes.common.typecheck", "vsnet.VSNet.model", "torch.view_as_complex", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "vsnet.VSNet.sens_net", "mridc.collections.common.parts.utils.coil_combination", "mridc.collections.common.parts.fft.ifft2"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.coil_combination", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "sensitivity_maps", "=", "self", ".", "sens_net", "(", "y", ",", "mask", ")", "if", "self", ".", "use_sens_net", "else", "sensitivity_maps", "\n", "image", "=", "self", ".", "model", "(", "y", ",", "sensitivity_maps", ",", "mask", ")", "\n", "image", "=", "torch", ".", "view_as_complex", "(", "\n", "coil_combination", "(", "\n", "ifft2", "(", "\n", "image", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "sensitivity_maps", ",", "\n", "method", "=", "self", ".", "coil_combination_method", ",", "\n", "dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", ")", "\n", "_", ",", "image", "=", "center_crop_to_smallest", "(", "target", ",", "image", ")", "\n", "return", "image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.base.DistributedMetricSum.__init__": [[40, 44], ["torchmetrics.metric.Metric.__init__", "base.DistributedMetricSum.add_state", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.DistributedMetricSum.update": [[45, 48], ["None"], "methods", ["None"], ["\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.base.DistributedMetricSum.compute": [[49, 52], ["None"], "methods", ["None"], ["if", "fmt", "is", "None", ":", "\n", "            ", "fmt", "=", "self", ".", "DEFAULT_FORMAT", "\n", "\n", "", "if", "datefmt", "is", "None", ":", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.__init__": [[57, 105], ["mridc.utils.model_utils.convert_model_config_to_dict_config", "mridc.utils.model_utils.maybe_update_config_version", "mridc.core.classes.modelPT.ModelPT.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "base.DistributedMetricSum", "base.DistributedMetricSum", "base.DistributedMetricSum", "base.DistributedMetricSum", "base.DistributedMetricSum", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "base.BaseSensitivityModel", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.convert_model_config_to_dict_config", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.maybe_update_config_version", "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["\n", "", "logging", ".", "Formatter", ".", "__init__", "(", "self", ",", "datefmt", "=", "datefmt", ")", "\n", "\n", "self", ".", "_fmt", "=", "fmt", "\n", "self", ".", "_colors", "=", "{", "}", "\n", "self", ".", "_normal", "=", "\"\"", "\n", "\n", "if", "color", "and", "check_color_support", "(", ")", ":", "\n", "            ", "self", ".", "_colors", "=", "colors", "\n", "self", ".", "_normal", "=", "ForegroundColors", ".", "RESET", "\n", "\n", "", "", "def", "format", "(", "self", ",", "record", ")", ":", "\n", "        ", "\"\"\"\n        Formats a record.\n\n        Parameters\n        ----------\n        record: Log record to be formatted.\n            LogRecord\n\n        Returns\n        -------\n        The formatted record as a string.\n            str\n        \"\"\"", "\n", "try", ":", "\n", "            ", "message", "=", "record", ".", "getMessage", "(", ")", "\n", "if", "not", "isinstance", "(", "message", ",", "str", ")", ":", "\n", "                ", "raise", "AssertionError", "\n", "# Encoding notes:  The logging module prefers to work with character", "\n", "# strings, but only enforces that log messages are instances of", "\n", "# basestring.  In python 2, non-ascii bytestrings will make", "\n", "# their way through the logging framework until they blow up with", "\n", "# an unhelpful decoding error (with this formatter it happens", "\n", "# when we attach the prefix, but there are other opportunities for", "\n", "# exceptions further along in the framework).", "\n", "#", "\n", "# If a byte string makes it this far, convert it to unicode to", "\n", "# ensure it will make it out to the logs.  Use repr() as a fallback", "\n", "# to ensure that all byte strings can be converted successfully,", "\n", "# but don't do it by default so we don't add extra quotes to ascii", "\n", "# bytestrings.  This is a bit of a hacky place to do this, but", "\n", "# it's worth it since the encoding errors that would otherwise", "\n", "# result are so useless (and tornado is fond of using utf8-encoded", "\n", "# byte strings wherever possible).", "\n", "", "record", ".", "message", "=", "to_unicode", "(", "message", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "record", ".", "message", "=", "\"Bad message (%r): %r\"", "%", "(", "e", ",", "record", ".", "__dict__", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.process_loss": [[107, 145], ["torch.abs", "base.BaseMRIReconstructionModel.process_loss.loss_fn"], "methods", ["None"], ["", "record", ".", "asctime", "=", "self", ".", "formatTime", "(", "record", ",", "self", ".", "datefmt", ")", "\n", "\n", "if", "record", ".", "levelno", "in", "self", ".", "_colors", ":", "\n", "            ", "record", ".", "color", "=", "self", ".", "_colors", "[", "record", ".", "levelno", "]", "\n", "record", ".", "end_color", "=", "self", ".", "_normal", "\n", "", "else", ":", "\n", "            ", "record", ".", "color", "=", "record", ".", "end_color", "=", "\"\"", "\n", "\n", "", "formatted", "=", "self", ".", "_fmt", "%", "record", ".", "__dict__", "\n", "\n", "if", "record", ".", "exc_info", "and", "not", "record", ".", "exc_text", ":", "\n", "            ", "record", ".", "exc_text", "=", "self", ".", "formatException", "(", "record", ".", "exc_info", ")", "\n", "\n", "", "if", "record", ".", "exc_text", ":", "\n", "# exc_text contains multiple lines.  We need to _safe_unicode", "\n", "# each line separately so that non-utf8 bytes don't cause", "\n", "# all the newlines to turn into '\\n'.", "\n", "            ", "lines", "=", "[", "formatted", ".", "rstrip", "(", ")", "]", "\n", "lines", ".", "extend", "(", "to_unicode", "(", "ln", ")", "for", "ln", "in", "record", ".", "exc_text", ".", "split", "(", "\"\\n\"", ")", ")", "\n", "\n", "formatted", "=", "\"\\n\"", ".", "join", "(", "lines", ")", "\n", "", "return", "formatted", ".", "replace", "(", "\"\\n\"", ",", "\"\\n    \"", ")", "\n", "\n", "\n", "", "", "class", "BaseMRIDCFormatter", "(", "BaseFormatter", ")", ":", "\n", "    ", "\"\"\"Base formatter for MRIDC logs.\"\"\"", "\n", "\n", "DEFAULT_FORMAT", "=", "\"%(color)s[MRIDC %(levelname)1.1s %(asctime)s %(module)s:%(lineno)d]%(end_color)s %(message)s\"", "\n", "\n", "\n", "", "class", "DebugMRIDCFormatter", "(", "BaseFormatter", ")", ":", "\n", "    ", "\"\"\"Debug formatter for MRIDC logs.\"\"\"", "\n", "\n", "DEFAULT_FORMAT", "=", "(", "\n", "\"%(color)s[MRIDC %(levelname)1.1s %(asctime)s %(module)s:%(lineno)d rank:%(rank)s]%(end_color)s %(message)s\"", "\n", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.process_inputs": [[146, 177], ["isinstance", "numpy.random.randint", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.training_step": [[178, 253], ["base.BaseMRIReconstructionModel.process_inputs", "base.BaseMRIReconstructionModel.forward", "base.BaseMRIReconstructionModel.sens_net", "sum", "base.BaseMRIReconstructionModel.process_loss", "base.BaseMRIReconstructionModel.item", "base.BaseMRIReconstructionModel.coil_combination_method.upper", "mridc.collections.common.parts.utils.sense", "next", "base.BaseMRIReconstructionModel.process_loss", "mridc.collections.common.parts.fft.ifft2"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.models.pics.PICS.process_inputs", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward", "home.repos.pwc.inspect_result.wdika_mridc.models.crnn.CRNNet.process_loss", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.sense", "home.repos.pwc.inspect_result.wdika_mridc.models.crnn.CRNNet.process_loss", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.validation_step": [[254, 351], ["base.BaseMRIReconstructionModel.process_inputs", "base.BaseMRIReconstructionModel.forward", "isinstance", "isinstance", "torch.abs().detach().cpu", "torch.abs().detach().cpu", "torch.abs", "base.BaseMRIReconstructionModel.log_image", "base.BaseMRIReconstructionModel.log_image", "base.BaseMRIReconstructionModel.log_image", "mridc.collections.common.parts.utils.sense.numpy", "output.numpy.numpy.numpy", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "base.BaseMRIReconstructionModel.sens_net", "sum", "base.BaseMRIReconstructionModel.process_loss", "output.numpy.numpy.max", "mridc.collections.common.parts.utils.sense.max", "base.BaseMRIReconstructionModel.coil_combination_method.upper", "mridc.collections.common.parts.utils.sense", "next", "base.BaseMRIReconstructionModel.process_loss", "int", "torch.abs().detach", "torch.abs().detach", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.reconstruction.metrics.evaluate.mse", "mridc.collections.reconstruction.metrics.evaluate.nmse", "mridc.collections.reconstruction.metrics.evaluate.ssim", "mridc.collections.reconstruction.metrics.evaluate.psnr", "torch.abs", "torch.abs", "output.numpy.numpy.max", "output.numpy.numpy.min", "output.numpy.numpy.max", "output.numpy.numpy.min"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.models.pics.PICS.process_inputs", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image", "home.repos.pwc.inspect_result.wdika_mridc.models.crnn.CRNNet.process_loss", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.sense", "home.repos.pwc.inspect_result.wdika_mridc.models.crnn.CRNNet.process_loss", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.mse", "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.nmse", "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.ssim", "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.psnr"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.test_step": [[352, 441], ["base.BaseMRIReconstructionModel.process_inputs", "base.BaseMRIReconstructionModel.forward", "isinstance", "isinstance", "int", "str", "torch.abs().detach().cpu", "torch.abs().detach().cpu", "torch.abs", "base.BaseMRIReconstructionModel.log_image", "base.BaseMRIReconstructionModel.log_image", "base.BaseMRIReconstructionModel.log_image", "base.BaseMRIReconstructionModel.sens_net", "torch.abs().detach().cpu.max", "mridc.collections.common.parts.utils.sense.max", "next.detach().cpu().numpy", "base.BaseMRIReconstructionModel.coil_combination_method.upper", "mridc.collections.common.parts.utils.sense", "next", "torch.abs().detach", "torch.abs().detach", "mridc.collections.common.parts.fft.ifft2", "next.detach().cpu", "torch.abs", "torch.abs", "next.detach"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.models.pics.PICS.process_inputs", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.sense", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image": [[442, 457], ["base.BaseMRIReconstructionModel.logger.__module__.lower", "base.BaseMRIReconstructionModel.logger.experiment.log", "base.BaseMRIReconstructionModel.logger.experiment.add_image", "wandb.Image", "image.numpy"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.validation_epoch_end": [[458, 515], ["base.BaseMRIReconstructionModel.log", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "base.BaseMRIReconstructionModel.mse_vals.keys", "base.BaseMRIReconstructionModel.nmse_vals.keys", "base.BaseMRIReconstructionModel.ssim_vals.keys", "base.BaseMRIReconstructionModel.psnr_vals.keys", "base.BaseMRIReconstructionModel.MSE", "base.BaseMRIReconstructionModel.NMSE", "base.BaseMRIReconstructionModel.SSIM", "base.BaseMRIReconstructionModel.PSNR", "base.BaseMRIReconstructionModel.TotExamples", "metrics.items", "torch.stack().mean", "mse_vals[].update", "nmse_vals[].update", "ssim_vals[].update", "psnr_vals[].update", "torch.tensor", "base.BaseMRIReconstructionModel.log", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "v.view", "v.view", "v.view", "v.view", "mse_vals[].items", "nmse_vals[].items", "ssim_vals[].items", "psnr_vals[].items"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.update", "home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.update", "home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.update", "home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.update"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.test_epoch_end": [[516, 541], ["collections.defaultdict", "pathlib.Path", "pathlib.Path.mkdir", "collections.defaultdict.items", "reconstructions[].append", "numpy.stack", "os.path.join", "h5py.File", "hf.create_dataset", "sorted"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.setup_training_data": [[542, 557], ["base.BaseMRIReconstructionModel._setup_dataloader_from_config"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel._setup_dataloader_from_config"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.setup_validation_data": [[558, 573], ["base.BaseMRIReconstructionModel._setup_dataloader_from_config"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel._setup_dataloader_from_config"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.setup_test_data": [[574, 589], ["base.BaseMRIReconstructionModel._setup_dataloader_from_config"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel._setup_dataloader_from_config"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel._setup_dataloader_from_config": [[590, 660], ["cfg.get", "cfg.get.get", "cfg.get.get", "mridc.collections.reconstruction.data.mri_data.FastMRISliceDataset", "torch.utils.data.DataLoader", "cfg.get.get", "cfg.get.get", "cfg.get.get", "torch.utils.data.RandomSampler", "torch.utils.data.SequentialSampler", "cfg.get", "cfg.get", "cfg.get", "mridc.collections.reconstruction.parts.transforms.MRIDataTransforms", "cfg.get", "cfg.get", "cfg.get", "cfg.get", "cfg.get", "len", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type", "mridc.collections.reconstruction.data.subsample.create_mask_for_mask_type", "zip", "cfg.get", "cfg.get", "cfg.get", "cfg.get", "cfg.get", "cfg.get", "cfg.get", "cfg.get", "cfg.get", "cfg.get", "cfg.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.create_mask_for_mask_type", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.create_mask_for_mask_type", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseSensitivityModel.__init__": [[670, 738], ["super().__init__", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseSensitivityModel.chans_to_batch_dim": [[739, 757], ["x.view"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseSensitivityModel.batch_chans_to_chan_dim": [[758, 779], ["torch.div", "x.view"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseSensitivityModel.divide_root_sum_of_squares": [[780, 798], ["mridc.collections.common.parts.utils.rss_complex().unsqueeze().unsqueeze", "mridc.collections.common.parts.utils.rss_complex().unsqueeze", "mridc.collections.common.parts.utils.rss_complex"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.rss_complex"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseSensitivityModel.get_pad_and_num_low_freqs": [[799, 836], ["torch.div", "mask[].to", "torch.div", "torch.argmin", "torch.argmin", "torch.max", "squeezed_mask[].flip", "torch.ones_like", "torch.ones", "torch.min"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseSensitivityModel.forward": [[837, 879], ["base.BaseSensitivityModel.chans_to_batch_dim", "base.BaseSensitivityModel.batch_chans_to_chan_dim", "base.BaseSensitivityModel.get_pad_and_num_low_freqs", "mridc.collections.reconstruction.parts.utils.batched_mask_center", "mridc.collections.common.parts.fft.ifft2", "base.BaseSensitivityModel.norm_unet", "base.BaseSensitivityModel.divide_root_sum_of_squares"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseSensitivityModel.chans_to_batch_dim", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseSensitivityModel.batch_chans_to_chan_dim", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseSensitivityModel.get_pad_and_num_low_freqs", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.batched_mask_center", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseSensitivityModel.divide_root_sum_of_squares"], []], "home.repos.pwc.inspect_result.wdika_mridc.models.kikinet.KIKINet.__init__": [[42, 124], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.Parameter", "mridc.collections.reconstruction.models.conv.conv2d.Conv2d", "mridc.collections.reconstruction.models.mwcnn.mwcnn.MWCNN", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "torch.ones", "mridc.collections.reconstruction.models.didn.didn.DIDN", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet", "NotImplementedError", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet", "NotImplementedError", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.crossdomain.multicoil.MultiCoil", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "self", ".", "num_iter", "=", "cfg_dict", ".", "get", "(", "\"num_iter\"", ")", "\n", "self", ".", "no_dc", "=", "cfg_dict", ".", "get", "(", "\"no_dc\"", ")", "\n", "\n", "kspace_model_architecture", "=", "cfg_dict", ".", "get", "(", "\"kspace_model_architecture\"", ")", "\n", "\n", "if", "kspace_model_architecture", "==", "\"CONV\"", ":", "\n", "            ", "kspace_model", "=", "Conv2d", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"kspace_conv_hidden_channels\"", ")", ",", "\n", "n_convs", "=", "cfg_dict", ".", "get", "(", "\"kspace_conv_n_convs\"", ")", ",", "\n", "batchnorm", "=", "cfg_dict", ".", "get", "(", "\"kspace_conv_batchnorm\"", ")", ",", "\n", ")", "\n", "", "elif", "kspace_model_architecture", "==", "\"DIDN\"", ":", "\n", "            ", "kspace_model", "=", "DIDN", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"kspace_didn_hidden_channels\"", ")", ",", "\n", "num_dubs", "=", "cfg_dict", ".", "get", "(", "\"kspace_didn_num_dubs\"", ")", ",", "\n", "num_convs_recon", "=", "cfg_dict", ".", "get", "(", "\"kspace_didn_num_convs_recon\"", ")", ",", "\n", ")", "\n", "", "elif", "kspace_model_architecture", "in", "[", "\"UNET\"", ",", "\"NORMUNET\"", "]", ":", "\n", "            ", "kspace_model", "=", "NormUnet", "(", "\n", "cfg_dict", ".", "get", "(", "\"kspace_unet_num_filters\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"kspace_unet_num_pool_layers\"", ")", ",", "\n", "in_chans", "=", "2", ",", "\n", "out_chans", "=", "2", ",", "\n", "drop_prob", "=", "cfg_dict", ".", "get", "(", "\"kspace_unet_dropout_probability\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"kspace_unet_padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"kspace_unet_normalize\"", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"KIKINet is currently implemented for kspace_model_architecture == 'CONV' or 'DIDN' or 'UNet'.\"", "\n", "f\"Got kspace_model_architecture == {kspace_model_architecture}.\"", "\n", ")", "\n", "\n", "", "image_model_architecture", "=", "cfg_dict", ".", "get", "(", "\"imspace_model_architecture\"", ")", "\n", "\n", "if", "image_model_architecture", "==", "\"MWCNN\"", ":", "\n", "            ", "image_model", "=", "MWCNN", "(", "\n", "input_channels", "=", "2", ",", "\n", "first_conv_hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"image_mwcnn_hidden_channels\"", ")", ",", "\n", "num_scales", "=", "cfg_dict", ".", "get", "(", "\"image_mwcnn_num_scales\"", ")", ",", "\n", "bias", "=", "cfg_dict", ".", "get", "(", "\"image_mwcnn_bias\"", ")", ",", "\n", "batchnorm", "=", "cfg_dict", ".", "get", "(", "\"image_mwcnn_batchnorm\"", ")", ",", "\n", ")", "\n", "", "elif", "image_model_architecture", "in", "[", "\"UNET\"", ",", "\"NORMUNET\"", "]", ":", "\n", "            ", "image_model", "=", "NormUnet", "(", "\n", "cfg_dict", ".", "get", "(", "\"imspace_unet_num_filters\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"imspace_unet_num_pool_layers\"", ")", ",", "\n", "in_chans", "=", "2", ",", "\n", "out_chans", "=", "2", ",", "\n", "drop_prob", "=", "cfg_dict", ".", "get", "(", "\"imspace_unet_dropout_probability\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"imspace_unet_padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"imspace_unet_normalize\"", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"KIKINet is currently implemented only with image_model_architecture == 'MWCNN' or 'UNet'.\"", "\n", "f\"Got {image_model_architecture}.\"", "\n", ")", "\n", "\n", "", "self", ".", "fft_centered", "=", "cfg_dict", ".", "get", "(", "\"fft_centered\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "\n", "self", ".", "image_model_list", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "image_model", "]", "*", "self", ".", "num_iter", ")", "\n", "self", ".", "kspace_model_list", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "MultiCoil", "(", "kspace_model", ",", "coil_dim", "=", "1", ")", "]", "*", "self", ".", "num_iter", ")", "\n", "\n", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "dc_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "accumulate_estimates", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.kikinet.KIKINet.forward": [[125, 207], ["mridc.core.classes.common.typecheck", "y.clone", "torch.zeros().to", "range", "torch.view_as_complex", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "mridc.collections.common.parts.utils.complex_mul().sum", "torch.zeros", "torch.where", "mridc.collections.common.parts.fft.fft2().type.permute().to", "torch.view_as_real", "mridc.collections.common.parts.fft.fft2().type", "mridc.collections.common.parts.utils.complex_mul().sum", "mridc.collections.common.parts.fft.fft2().type", "mask.bool", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_mul().sum.type", "mridc.collections.common.parts.utils.complex_mul().sum.type", "mridc.collections.common.parts.fft.fft2().type.permute", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj", "mridc.collections.common.parts.utils.complex_mul().sum.unsqueeze", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_mul().sum.unsqueeze", "mridc.collections.common.parts.utils.complex_mul().sum.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "kspace", "=", "y", ".", "clone", "(", ")", "\n", "zero", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ",", "1", ",", "1", ")", ".", "to", "(", "kspace", ")", "\n", "\n", "for", "idx", "in", "range", "(", "self", ".", "num_iter", ")", ":", "\n", "            ", "soft_dc", "=", "torch", ".", "where", "(", "mask", ".", "bool", "(", ")", ",", "kspace", "-", "y", ",", "zero", ")", "*", "self", ".", "dc_weight", "\n", "\n", "kspace", "=", "self", ".", "kspace_model_list", "[", "idx", "]", "(", "kspace", ")", "\n", "if", "kspace", ".", "shape", "[", "-", "1", "]", "!=", "2", ":", "\n", "                ", "kspace", "=", "kspace", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", ".", "to", "(", "target", ")", "\n", "kspace", "=", "torch", ".", "view_as_real", "(", "kspace", "[", "...", ",", "0", "]", "+", "1j", "*", "kspace", "[", "...", ",", "1", "]", ")", "# this is necessary, but why?", "\n", "\n", "", "image", "=", "complex_mul", "(", "\n", "ifft2", "(", "\n", "kspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "complex_conj", "(", "sensitivity_maps", ")", ",", "\n", ")", ".", "sum", "(", "self", ".", "coil_dim", ")", "\n", "image", "=", "self", ".", "image_model_list", "[", "idx", "]", "(", "image", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ")", ".", "squeeze", "(", "self", ".", "coil_dim", ")", "\n", "\n", "if", "not", "self", ".", "no_dc", ":", "\n", "                ", "image", "=", "fft2", "(", "\n", "complex_mul", "(", "image", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ",", "sensitivity_maps", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ".", "type", "(", "image", ".", "type", "(", ")", ")", "\n", "image", "=", "kspace", "-", "soft_dc", "-", "image", "\n", "image", "=", "complex_mul", "(", "\n", "ifft2", "(", "\n", "image", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "complex_conj", "(", "sensitivity_maps", ")", ",", "\n", ")", ".", "sum", "(", "self", ".", "coil_dim", ")", "\n", "\n", "", "if", "idx", "<", "self", ".", "num_iter", "-", "1", ":", "\n", "                ", "kspace", "=", "fft2", "(", "\n", "complex_mul", "(", "image", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ",", "sensitivity_maps", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ".", "type", "(", "image", ".", "type", "(", ")", ")", "\n", "\n", "", "", "image", "=", "torch", ".", "view_as_complex", "(", "image", ")", "\n", "_", ",", "image", "=", "center_crop_to_smallest", "(", "target", ",", "image", ")", "\n", "return", "image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.unet.UNet.__init__": [[36, 63], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet", "omegaconf.OmegaConf.to_container.get", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "self", ".", "fft_centered", "=", "cfg_dict", ".", "get", "(", "\"fft_centered\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "\n", "self", ".", "unet", "=", "NormUnet", "(", "\n", "chans", "=", "cfg_dict", ".", "get", "(", "\"channels\"", ")", ",", "\n", "num_pools", "=", "cfg_dict", ".", "get", "(", "\"pooling_layers\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"normalize\"", ")", ",", "\n", ")", "\n", "\n", "self", ".", "coil_combination_method", "=", "cfg_dict", ".", "get", "(", "\"coil_combination_method\"", ")", "\n", "\n", "# initialize weights if not using pretrained unet", "\n", "# TODO if not cfg_dict.get(\"pretrained\", False):", "\n", "\n", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "accumulate_estimates", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.unet.UNet.forward": [[64, 108], ["mridc.core.classes.common.typecheck", "torch.view_as_complex", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "torch.view_as_complex().squeeze", "mridc.collections.common.parts.utils.coil_combination", "mridc.collections.common.parts.fft.ifft2", "torch.view_as_complex", "unet.UNet.unet", "torch.view_as_real", "torch.view_as_complex.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.coil_combination", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "eta", "=", "torch", ".", "view_as_complex", "(", "\n", "coil_combination", "(", "\n", "ifft2", "(", "\n", "y", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", "\n", ")", ",", "\n", "sensitivity_maps", ",", "\n", "method", "=", "self", ".", "coil_combination_method", ",", "\n", "dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", ")", "\n", "_", ",", "eta", "=", "center_crop_to_smallest", "(", "target", ",", "eta", ")", "\n", "return", "torch", ".", "view_as_complex", "(", "self", ".", "unet", "(", "torch", ".", "view_as_real", "(", "eta", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ")", ")", ")", ".", "squeeze", "(", "\n", "self", ".", "coil_dim", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.cirim.CIRIM.__init__": [[42, 100], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "torch.nn.ModuleList", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "torch.nn.Parameter", "math.ceil", "omegaconf.OmegaConf.to_container.get", "cirim.CIRIM.cirim.apply", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "torch.ones", "mridc.collections.reconstruction.models.rim.rim_block.RIMBlock", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "range", "mridc.collections.common.parts.rnn_utils.rnn_weights_init", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.parts.rnn_utils.rnn_weights_init", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "# Cascades of RIM blocks", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "self", ".", "recurrent_filters", "=", "cfg_dict", ".", "get", "(", "\"recurrent_filters\"", ")", "\n", "\n", "# make time-steps size divisible by 8 for fast fp16 training", "\n", "self", ".", "time_steps", "=", "8", "*", "math", ".", "ceil", "(", "cfg_dict", ".", "get", "(", "\"time_steps\"", ")", "/", "8", ")", "\n", "\n", "self", ".", "no_dc", "=", "cfg_dict", ".", "get", "(", "\"no_dc\"", ")", "\n", "self", ".", "fft_centered", "=", "cfg_dict", ".", "get", "(", "\"fft_centered\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "self", ".", "num_cascades", "=", "cfg_dict", ".", "get", "(", "\"num_cascades\"", ")", "\n", "\n", "self", ".", "cirim", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "RIMBlock", "(", "\n", "recurrent_layer", "=", "cfg_dict", ".", "get", "(", "\"recurrent_layer\"", ")", ",", "\n", "conv_filters", "=", "cfg_dict", ".", "get", "(", "\"conv_filters\"", ")", ",", "\n", "conv_kernels", "=", "cfg_dict", ".", "get", "(", "\"conv_kernels\"", ")", ",", "\n", "conv_dilations", "=", "cfg_dict", ".", "get", "(", "\"conv_dilations\"", ")", ",", "\n", "conv_bias", "=", "cfg_dict", ".", "get", "(", "\"conv_bias\"", ")", ",", "\n", "recurrent_filters", "=", "self", ".", "recurrent_filters", ",", "\n", "recurrent_kernels", "=", "cfg_dict", ".", "get", "(", "\"recurrent_kernels\"", ")", ",", "\n", "recurrent_dilations", "=", "cfg_dict", ".", "get", "(", "\"recurrent_dilations\"", ")", ",", "\n", "recurrent_bias", "=", "cfg_dict", ".", "get", "(", "\"recurrent_bias\"", ")", ",", "\n", "depth", "=", "cfg_dict", ".", "get", "(", "\"depth\"", ")", ",", "\n", "time_steps", "=", "self", ".", "time_steps", ",", "\n", "conv_dim", "=", "cfg_dict", ".", "get", "(", "\"conv_dim\"", ")", ",", "\n", "no_dc", "=", "self", ".", "no_dc", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", "coil_dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_cascades", ")", "\n", "]", "\n", ")", "\n", "\n", "# Keep estimation through the cascades if keep_eta is True or re-estimate it if False.", "\n", "self", ".", "keep_eta", "=", "cfg_dict", ".", "get", "(", "\"keep_eta\"", ")", "\n", "self", ".", "coil_combination_method", "=", "cfg_dict", ".", "get", "(", "\"coil_combination_method\"", ")", "\n", "\n", "# initialize weights if not using pretrained cirim", "\n", "if", "not", "cfg_dict", ".", "get", "(", "\"pretrained\"", ",", "False", ")", ":", "\n", "            ", "std_init_range", "=", "1", "/", "self", ".", "recurrent_filters", "[", "0", "]", "**", "0.5", "\n", "self", ".", "cirim", ".", "apply", "(", "lambda", "module", ":", "rnn_weights_init", "(", "module", ",", "std_init_range", ")", ")", "\n", "\n", "", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "dc_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "accumulate_estimates", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.cirim.CIRIM.forward": [[101, 152], ["mridc.core.classes.common.typecheck", "y.clone", "enumerate", "cascade", "cascades_etas.append", "cirim.CIRIM.process_intermediate_pred", "init_pred.dim"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.models.crnn.CRNNet.process_intermediate_pred"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Union", "[", "Generator", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "prediction", "=", "y", ".", "clone", "(", ")", "\n", "init_pred", "=", "None", "if", "init_pred", "is", "None", "or", "init_pred", ".", "dim", "(", ")", "<", "4", "else", "init_pred", "\n", "hx", "=", "None", "\n", "sigma", "=", "1.0", "\n", "cascades_etas", "=", "[", "]", "\n", "for", "i", ",", "cascade", "in", "enumerate", "(", "self", ".", "cirim", ")", ":", "\n", "# Forward pass through the cascades", "\n", "            ", "prediction", ",", "hx", "=", "cascade", "(", "\n", "prediction", ",", "\n", "y", ",", "\n", "sensitivity_maps", ",", "\n", "mask", ",", "\n", "init_pred", ",", "\n", "hx", ",", "\n", "sigma", ",", "\n", "keep_eta", "=", "False", "if", "i", "==", "0", "else", "self", ".", "keep_eta", ",", "\n", ")", "\n", "time_steps_etas", "=", "[", "self", ".", "process_intermediate_pred", "(", "pred", ",", "sensitivity_maps", ",", "target", ")", "for", "pred", "in", "prediction", "]", "\n", "cascades_etas", ".", "append", "(", "time_steps_etas", ")", "\n", "", "yield", "cascades_etas", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.cirim.CIRIM.process_intermediate_pred": [[153, 182], ["torch.view_as_complex", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.coil_combination"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.coil_combination"], ["", "def", "process_intermediate_pred", "(", "self", ",", "pred", ",", "sensitivity_maps", ",", "target", ",", "do_coil_combination", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Process the intermediate prediction.\n\n        Parameters\n        ----------\n        pred: Intermediate prediction.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        target: Target data to crop to size.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        do_coil_combination: Whether to do coil combination.\n            bool, default False\n\n        Returns\n        -------\n        pred: torch.Tensor, shape [batch_size, n_x, n_y, 2]\n            Processed prediction.\n        \"\"\"", "\n", "# Take the last time step of the eta", "\n", "if", "not", "self", ".", "no_dc", "or", "do_coil_combination", ":", "\n", "            ", "pred", "=", "ifft2", "(", "\n", "pred", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", "\n", ")", "\n", "pred", "=", "coil_combination", "(", "pred", ",", "sensitivity_maps", ",", "method", "=", "self", ".", "coil_combination_method", ",", "dim", "=", "self", ".", "coil_dim", ")", "\n", "", "pred", "=", "torch", ".", "view_as_complex", "(", "pred", ")", "\n", "_", ",", "pred", "=", "center_crop_to_smallest", "(", "target", ",", "pred", ")", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.cirim.CIRIM.process_loss": [[183, 231], ["torch.abs", "str().lower", "numpy.array().astype", "cirim.CIRIM.process_loss.loss_fn"], "methods", ["None"], ["", "def", "process_loss", "(", "self", ",", "target", ",", "pred", ",", "_loss_fn", ")", ":", "\n", "        ", "\"\"\"\n        Process the loss.\n\n        Parameters\n        ----------\n        target: Target data.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        pred: Final prediction(s).\n            list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        _loss_fn: Loss function.\n            torch.nn.Module, default torch.nn.L1Loss()\n\n        Returns\n        -------\n        loss: torch.FloatTensor, shape [1]\n            If self.accumulate_loss is True, returns an accumulative result of all intermediate losses.\n        \"\"\"", "\n", "target", "=", "torch", ".", "abs", "(", "target", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "target", ")", ")", ")", "\n", "if", "\"ssim\"", "in", "str", "(", "_loss_fn", ")", ".", "lower", "(", ")", ":", "\n", "            ", "max_value", "=", "np", ".", "array", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "target", ")", ")", ".", "item", "(", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "def", "loss_fn", "(", "x", ",", "y", ")", ":", "\n", "                ", "\"\"\"Calculate the ssim loss.\"\"\"", "\n", "return", "_loss_fn", "(", "\n", "x", ".", "unsqueeze", "(", "dim", "=", "self", ".", "coil_dim", ")", ",", "\n", "torch", ".", "abs", "(", "y", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "y", ")", ")", ")", ".", "unsqueeze", "(", "dim", "=", "self", ".", "coil_dim", ")", ",", "\n", "data_range", "=", "torch", ".", "tensor", "(", "max_value", ")", ".", "unsqueeze", "(", "dim", "=", "0", ")", ".", "to", "(", "x", ".", "device", ")", ",", "\n", ")", "\n", "\n", "", "", "else", ":", "\n", "\n", "            ", "def", "loss_fn", "(", "x", ",", "y", ")", ":", "\n", "                ", "\"\"\"Calculate other loss.\"\"\"", "\n", "return", "_loss_fn", "(", "x", ",", "torch", ".", "abs", "(", "y", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "y", ")", ")", ")", ")", "\n", "\n", "", "", "if", "self", ".", "accumulate_estimates", ":", "\n", "            ", "cascades_loss", "=", "[", "]", "\n", "for", "cascade_pred", "in", "pred", ":", "\n", "                ", "time_steps_loss", "=", "[", "loss_fn", "(", "target", ",", "time_step_pred", ")", "for", "time_step_pred", "in", "cascade_pred", "]", "\n", "_loss", "=", "[", "\n", "x", "*", "torch", ".", "logspace", "(", "-", "1", ",", "0", ",", "steps", "=", "self", ".", "time_steps", ")", ".", "to", "(", "time_steps_loss", "[", "0", "]", ")", "for", "x", "in", "time_steps_loss", "\n", "]", "\n", "cascades_loss", ".", "append", "(", "sum", "(", "sum", "(", "_loss", ")", "/", "self", ".", "time_steps", ")", ")", "\n", "", "yield", "sum", "(", "list", "(", "cascades_loss", ")", ")", "/", "len", "(", "self", ".", "cirim", ")", "\n", "", "else", ":", "\n", "            ", "return", "loss_fn", "(", "target", ",", "pred", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.xpdnet.XPDNet.__init__": [[39, 176], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.crossdomain.crossdomain.CrossDomainNetwork", "torch.nn.ModuleList", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "torch.nn.ModuleList", "torch.nn.ModuleList", "NotImplementedError", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "torch.nn.ModuleList", "torch.nn.Sequential", "mridc.collections.reconstruction.models.crossdomain.multicoil.MultiCoil", "torch.nn.ModuleList", "NotImplementedError", "mridc.collections.reconstruction.models.mwcnn.mwcnn.MWCNN", "torch.nn.Conv2d", "range", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet", "mridc.collections.reconstruction.models.conv.conv2d.Conv2d", "range", "mridc.collections.reconstruction.models.crossdomain.multicoil.MultiCoil", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "range", "mridc.collections.reconstruction.models.didn.didn.DIDN", "range", "mridc.collections.reconstruction.models.crossdomain.multicoil.MultiCoil", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet", "range", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "num_primal", "=", "cfg_dict", ".", "get", "(", "\"num_primal\"", ")", "\n", "num_dual", "=", "cfg_dict", ".", "get", "(", "\"num_dual\"", ")", "\n", "num_iter", "=", "cfg_dict", ".", "get", "(", "\"num_iter\"", ")", "\n", "\n", "kspace_model_architecture", "=", "cfg_dict", ".", "get", "(", "\"kspace_model_architecture\"", ")", "\n", "dual_conv_hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"dual_conv_hidden_channels\"", ")", "\n", "dual_conv_num_dubs", "=", "cfg_dict", ".", "get", "(", "\"dual_conv_num_dubs\"", ")", "\n", "dual_conv_batchnorm", "=", "cfg_dict", ".", "get", "(", "\"dual_conv_batchnorm\"", ")", "\n", "dual_didn_hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"dual_didn_hidden_channels\"", ")", "\n", "dual_didn_num_dubs", "=", "cfg_dict", ".", "get", "(", "\"dual_didn_num_dubs\"", ")", "\n", "dual_didn_num_convs_recon", "=", "cfg_dict", ".", "get", "(", "\"dual_didn_num_convs_recon\"", ")", "\n", "\n", "if", "cfg_dict", ".", "get", "(", "\"use_primal_only\"", ")", ":", "\n", "            ", "kspace_model_list", "=", "None", "\n", "num_dual", "=", "1", "\n", "", "elif", "kspace_model_architecture", "==", "\"CONV\"", ":", "\n", "            ", "kspace_model_list", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "MultiCoil", "(", "\n", "Conv2d", "(", "\n", "2", "*", "(", "num_dual", "+", "num_primal", "+", "1", ")", ",", "\n", "2", "*", "num_dual", ",", "\n", "dual_conv_hidden_channels", ",", "\n", "dual_conv_num_dubs", ",", "\n", "batchnorm", "=", "dual_conv_batchnorm", ",", "\n", ")", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_iter", ")", "\n", "]", "\n", ")", "\n", "", "elif", "kspace_model_architecture", "==", "\"DIDN\"", ":", "\n", "            ", "kspace_model_list", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "MultiCoil", "(", "\n", "DIDN", "(", "\n", "in_channels", "=", "2", "*", "(", "num_dual", "+", "num_primal", "+", "1", ")", ",", "\n", "out_channels", "=", "2", "*", "num_dual", ",", "\n", "hidden_channels", "=", "dual_didn_hidden_channels", ",", "\n", "num_dubs", "=", "dual_didn_num_dubs", ",", "\n", "num_convs_recon", "=", "dual_didn_num_convs_recon", ",", "\n", ")", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_iter", ")", "\n", "]", "\n", ")", "\n", "", "elif", "kspace_model_architecture", "in", "[", "\"UNET\"", ",", "\"NORMUNET\"", "]", ":", "\n", "            ", "kspace_model_list", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "MultiCoil", "(", "\n", "NormUnet", "(", "\n", "cfg_dict", ".", "get", "(", "\"kspace_unet_num_filters\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"kspace_unet_num_pool_layers\"", ")", ",", "\n", "in_chans", "=", "2", "*", "(", "num_dual", "+", "num_primal", "+", "1", ")", ",", "\n", "out_chans", "=", "2", "*", "num_dual", ",", "\n", "drop_prob", "=", "cfg_dict", ".", "get", "(", "\"kspace_unet_dropout_probability\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"kspace_unet_padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"kspace_unet_normalize\"", ")", ",", "\n", ")", ",", "\n", "coil_to_batch", "=", "True", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_iter", ")", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"XPDNet is currently implemented for kspace_model_architecture == 'CONV' or 'DIDN'.\"", "\n", "f\"Got kspace_model_architecture == {kspace_model_architecture}.\"", "\n", ")", "\n", "\n", "", "image_model_architecture", "=", "cfg_dict", ".", "get", "(", "\"image_model_architecture\"", ")", "\n", "mwcnn_hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"mwcnn_hidden_channels\"", ")", "\n", "mwcnn_num_scales", "=", "cfg_dict", ".", "get", "(", "\"mwcnn_num_scales\"", ")", "\n", "mwcnn_bias", "=", "cfg_dict", ".", "get", "(", "\"mwcnn_bias\"", ")", "\n", "mwcnn_batchnorm", "=", "cfg_dict", ".", "get", "(", "\"mwcnn_batchnorm\"", ")", "\n", "\n", "if", "image_model_architecture", "==", "\"MWCNN\"", ":", "\n", "            ", "image_model_list", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "torch", ".", "nn", ".", "Sequential", "(", "\n", "MWCNN", "(", "\n", "input_channels", "=", "2", "*", "(", "num_primal", "+", "num_dual", ")", ",", "\n", "first_conv_hidden_channels", "=", "mwcnn_hidden_channels", ",", "\n", "num_scales", "=", "mwcnn_num_scales", ",", "\n", "bias", "=", "mwcnn_bias", ",", "\n", "batchnorm", "=", "mwcnn_batchnorm", ",", "\n", ")", ",", "\n", "torch", ".", "nn", ".", "Conv2d", "(", "2", "*", "(", "num_primal", "+", "num_dual", ")", ",", "2", "*", "num_primal", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_iter", ")", "\n", "]", "\n", ")", "\n", "", "elif", "image_model_architecture", "in", "[", "\"UNET\"", ",", "\"NORMUNET\"", "]", ":", "\n", "            ", "image_model_list", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "NormUnet", "(", "\n", "cfg_dict", ".", "get", "(", "\"imspace_unet_num_filters\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"imspace_unet_num_pool_layers\"", ")", ",", "\n", "in_chans", "=", "2", "*", "(", "num_primal", "+", "num_dual", ")", ",", "\n", "out_chans", "=", "2", "*", "num_primal", ",", "\n", "drop_prob", "=", "cfg_dict", ".", "get", "(", "\"imspace_unet_dropout_probability\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"imspace_unet_padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"imspace_unet_normalize\"", ")", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_iter", ")", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"Image model architecture {image_model_architecture} not found for XPDNet.\"", ")", "\n", "\n", "", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "self", ".", "num_cascades", "=", "cfg_dict", ".", "get", "(", "\"num_cascades\"", ")", "\n", "\n", "self", ".", "xpdnet", "=", "CrossDomainNetwork", "(", "\n", "image_model_list", "=", "image_model_list", ",", "\n", "kspace_model_list", "=", "kspace_model_list", ",", "\n", "domain_sequence", "=", "\"KI\"", "*", "num_iter", ",", "\n", "image_buffer_size", "=", "num_primal", ",", "\n", "kspace_buffer_size", "=", "num_dual", ",", "\n", "normalize_image", "=", "cfg_dict", ".", "get", "(", "\"normalize_image\"", ")", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", "coil_dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", "\n", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "accumulate_estimates", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.xpdnet.XPDNet.forward": [[177, 212], ["mridc.core.classes.common.typecheck", "xpdnet.XPDNet.xpdnet", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "eta", "=", "self", ".", "xpdnet", "(", "y", ",", "sensitivity_maps", ",", "mask", ")", "\n", "eta", "=", "(", "eta", "**", "2", ")", ".", "sqrt", "(", ")", ".", "sum", "(", "-", "1", ")", "\n", "_", ",", "eta", "=", "center_crop_to_smallest", "(", "target", ",", "eta", ")", "\n", "return", "eta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.rvn.RecurrentVarNet.__init__": [[40, 116], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "torch.nn.ModuleList", "range", "math.ceil", "mridc.collections.reconstruction.models.recurrentvarnet.recurentvarnet.RecurrentInit", "rvn.RecurrentVarNet.block_list.append", "omegaconf.OmegaConf.to_container.get", "rvn.RecurrentVarNet.block_list.apply", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "ValueError", "mridc.collections.reconstruction.models.recurrentvarnet.recurentvarnet.RecurrentVarNetBlock", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.common.parts.rnn_utils.rnn_weights_init"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.parts.rnn_utils.rnn_weights_init"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "# Cascades of RIM blocks", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "self", ".", "in_channels", "=", "cfg_dict", ".", "get", "(", "\"in_channels\"", ")", "\n", "self", ".", "recurrent_hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"recurrent_hidden_channels\"", ")", "\n", "self", ".", "recurrent_num_layers", "=", "cfg_dict", ".", "get", "(", "\"recurrent_num_layers\"", ")", "\n", "self", ".", "no_parameter_sharing", "=", "cfg_dict", ".", "get", "(", "\"no_parameter_sharing\"", ")", "\n", "\n", "# make time-steps size divisible by 8 for fast fp16 training", "\n", "self", ".", "num_steps", "=", "8", "*", "math", ".", "ceil", "(", "cfg_dict", ".", "get", "(", "\"num_steps\"", ")", "/", "8", ")", "\n", "\n", "self", ".", "learned_initializer", "=", "cfg_dict", ".", "get", "(", "\"learned_initializer\"", ")", "\n", "self", ".", "initializer_initialization", "=", "cfg_dict", ".", "get", "(", "\"initializer_initialization\"", ")", "\n", "self", ".", "initializer_channels", "=", "cfg_dict", ".", "get", "(", "\"initializer_channels\"", ")", "\n", "self", ".", "initializer_dilations", "=", "cfg_dict", ".", "get", "(", "\"initializer_dilations\"", ")", "\n", "\n", "if", "(", "\n", "self", ".", "learned_initializer", "\n", "and", "self", ".", "initializer_initialization", "is", "not", "None", "\n", "and", "self", ".", "initializer_channels", "is", "not", "None", "\n", "and", "self", ".", "initializer_dilations", "is", "not", "None", "\n", ")", ":", "\n", "            ", "if", "self", ".", "initializer_initialization", "not", "in", "[", "\n", "\"sense\"", ",", "\n", "\"input_image\"", ",", "\n", "\"zero_filled\"", ",", "\n", "]", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Unknown initializer_initialization. Expected `sense`, `'input_image` or `zero_filled`.\"", "\n", "f\"Got {self.initializer_initialization}.\"", "\n", ")", "\n", "", "self", ".", "initializer", "=", "RecurrentInit", "(", "\n", "self", ".", "in_channels", ",", "\n", "self", ".", "recurrent_hidden_channels", ",", "\n", "channels", "=", "self", ".", "initializer_channels", ",", "\n", "dilations", "=", "self", ".", "initializer_dilations", ",", "\n", "depth", "=", "self", ".", "recurrent_num_layers", ",", "\n", "multiscale_depth", "=", "cfg_dict", ".", "get", "(", "\"initializer_multiscale\"", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "initializer", "=", "None", "# type: ignore", "\n", "\n", "", "self", ".", "fft_centered", "=", "cfg_dict", ".", "get", "(", "\"fft_centered\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "self", ".", "coil_combination_method", "=", "cfg_dict", ".", "get", "(", "\"coil_combination_method\"", ")", "\n", "\n", "self", ".", "block_list", ":", "torch", ".", "nn", ".", "Module", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_steps", "if", "self", ".", "no_parameter_sharing", "else", "1", ")", ":", "\n", "            ", "self", ".", "block_list", ".", "append", "(", "\n", "RecurrentVarNetBlock", "(", "\n", "in_channels", "=", "self", ".", "in_channels", ",", "\n", "hidden_channels", "=", "self", ".", "recurrent_hidden_channels", ",", "\n", "num_layers", "=", "self", ".", "recurrent_num_layers", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", "coil_dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", ")", "\n", "\n", "", "std_init_range", "=", "1", "/", "self", ".", "recurrent_hidden_channels", "**", "0.5", "\n", "\n", "# initialize weights if not using pretrained cirim", "\n", "if", "not", "cfg_dict", ".", "get", "(", "\"pretrained\"", ",", "False", ")", ":", "\n", "            ", "self", ".", "block_list", ".", "apply", "(", "lambda", "module", ":", "rnn_weights_init", "(", "module", ",", "std_init_range", ")", ")", "\n", "\n", "", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "accumulate_estimates", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.rvn.RecurrentVarNet.forward": [[117, 214], ["mridc.core.classes.common.typecheck", "y.clone", "range", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.coil_combination", "torch.view_as_complex", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "rvn.RecurrentVarNet.initializer", "block", "mridc.collections.common.parts.utils.complex_mul().sum().unsqueeze", "mridc.collections.common.parts.fft.fft2().sum().permute", "kwargs[].unsqueeze", "mridc.collections.common.parts.utils.complex_mul().sum", "ValueError", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.fft.fft2().sum", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.coil_combination", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "previous_state", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", "\n", "\n", "if", "self", ".", "initializer", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "initializer_initialization", "==", "\"sense\"", ":", "\n", "                ", "initializer_input_image", "=", "(", "\n", "complex_mul", "(", "\n", "ifft2", "(", "\n", "y", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "complex_conj", "(", "sensitivity_maps", ")", ",", "\n", ")", "\n", ".", "sum", "(", "self", ".", "coil_dim", ")", "\n", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", "\n", ")", "\n", "", "elif", "self", ".", "initializer_initialization", "==", "\"input_image\"", ":", "\n", "                ", "if", "\"initial_image\"", "not", "in", "kwargs", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"`'initial_image` is required as input if initializer_initialization \"", "\n", "f\"is {self.initializer_initialization}.\"", "\n", ")", "\n", "", "initializer_input_image", "=", "kwargs", "[", "\"initial_image\"", "]", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", "\n", "", "elif", "self", ".", "initializer_initialization", "==", "\"zero_filled\"", ":", "\n", "                ", "initializer_input_image", "=", "ifft2", "(", "\n", "y", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "\n", "", "previous_state", "=", "self", ".", "initializer", "(", "\n", "fft2", "(", "\n", "initializer_input_image", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", ".", "sum", "(", "1", ")", "\n", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", ")", "\n", "\n", "", "kspace_prediction", "=", "y", ".", "clone", "(", ")", "\n", "\n", "for", "step", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "block", "=", "self", ".", "block_list", "[", "step", "]", "if", "self", ".", "no_parameter_sharing", "else", "self", ".", "block_list", "[", "0", "]", "\n", "kspace_prediction", ",", "previous_state", "=", "block", "(", "\n", "kspace_prediction", ",", "\n", "y", ",", "\n", "mask", ",", "\n", "sensitivity_maps", ",", "\n", "previous_state", ",", "\n", ")", "\n", "\n", "", "eta", "=", "ifft2", "(", "\n", "kspace_prediction", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "eta", "=", "coil_combination", "(", "eta", ",", "sensitivity_maps", ",", "method", "=", "self", ".", "coil_combination_method", ",", "dim", "=", "self", ".", "coil_dim", ")", "\n", "eta", "=", "torch", ".", "view_as_complex", "(", "eta", ")", "\n", "_", ",", "eta", "=", "center_crop_to_smallest", "(", "target", ",", "eta", ")", "\n", "return", "eta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.vn.VarNet.__init__": [[37, 80], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "torch.nn.ModuleList", "omegaconf.OmegaConf.to_container.get", "torch.nn.Parameter", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "torch.ones", "mridc.collections.reconstruction.models.varnet.vn_block.VarNetBlock", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet", "range", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "self", ".", "no_dc", "=", "cfg_dict", ".", "get", "(", "\"no_dc\"", ")", "\n", "self", ".", "fft_centered", "=", "cfg_dict", ".", "get", "(", "\"fft_centered\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "self", ".", "num_cascades", "=", "cfg_dict", ".", "get", "(", "\"num_cascades\"", ")", "\n", "\n", "# Cascades of VN blocks", "\n", "self", ".", "cascades", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "VarNetBlock", "(", "\n", "NormUnet", "(", "\n", "chans", "=", "cfg_dict", ".", "get", "(", "\"channels\"", ")", ",", "\n", "num_pools", "=", "cfg_dict", ".", "get", "(", "\"pooling_layers\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"normalize\"", ")", ",", "\n", ")", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", "coil_dim", "=", "self", ".", "coil_dim", ",", "\n", "no_dc", "=", "self", ".", "no_dc", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "num_cascades", ")", "\n", "]", "\n", ")", "\n", "\n", "self", ".", "coil_combination_method", "=", "cfg_dict", ".", "get", "(", "\"coil_combination_method\"", ")", "\n", "\n", "# initialize weights if not using pretrained vn", "\n", "# TODO if not cfg_dict.get(\"pretrained\", False)", "\n", "\n", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "dc_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "accumulate_estimates", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.vn.VarNet.forward": [[81, 130], ["mridc.core.classes.common.typecheck", "y.clone", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.coil_combination", "torch.view_as_complex", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "cascade"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.coil_combination", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "estimation", "=", "y", ".", "clone", "(", ")", "\n", "\n", "for", "cascade", "in", "self", ".", "cascades", ":", "\n", "# Forward pass through the cascades", "\n", "            ", "estimation", "=", "cascade", "(", "estimation", ",", "y", ",", "sensitivity_maps", ",", "mask", ")", "\n", "\n", "", "estimation", "=", "ifft2", "(", "\n", "estimation", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "estimation", "=", "coil_combination", "(", "\n", "estimation", ",", "sensitivity_maps", ",", "method", "=", "self", ".", "coil_combination_method", ",", "dim", "=", "self", ".", "coil_dim", "\n", ")", "\n", "estimation", "=", "torch", ".", "view_as_complex", "(", "estimation", ")", "\n", "_", ",", "estimation", "=", "center_crop_to_smallest", "(", "target", ",", "estimation", ")", "\n", "return", "estimation", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.lpd.LPDNet.__init__": [[40, 131], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "torch.nn.ModuleList", "torch.nn.ModuleList", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "torch.nn.Sequential", "mridc.collections.reconstruction.models.conv.conv2d.Conv2d", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet", "NotImplementedError", "mridc.collections.reconstruction.models.didn.didn.DIDN", "mridc.collections.reconstruction.models.primaldual.pd.PrimalNet", "mridc.collections.reconstruction.models.primaldual.pd.DualNet", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet", "NotImplementedError", "range", "range", "mridc.collections.reconstruction.models.mwcnn.mwcnn.MWCNN", "torch.nn.Conv2d", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "self", ".", "num_iter", "=", "cfg_dict", ".", "get", "(", "\"num_iter\"", ")", "\n", "self", ".", "num_primal", "=", "cfg_dict", ".", "get", "(", "\"num_primal\"", ")", "\n", "self", ".", "num_dual", "=", "cfg_dict", ".", "get", "(", "\"num_dual\"", ")", "\n", "\n", "primal_model_architecture", "=", "cfg_dict", ".", "get", "(", "\"primal_model_architecture\"", ")", "\n", "\n", "if", "primal_model_architecture", "==", "\"MWCNN\"", ":", "\n", "            ", "primal_model", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "MWCNN", "(", "\n", "input_channels", "=", "2", "*", "(", "self", ".", "num_primal", "+", "1", ")", ",", "\n", "first_conv_hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"primal_mwcnn_hidden_channels\"", ")", ",", "\n", "num_scales", "=", "cfg_dict", ".", "get", "(", "\"primal_mwcnn_num_scales\"", ")", ",", "\n", "bias", "=", "cfg_dict", ".", "get", "(", "\"primal_mwcnn_bias\"", ")", ",", "\n", "batchnorm", "=", "cfg_dict", ".", "get", "(", "\"primal_mwcnn_batchnorm\"", ")", ",", "\n", ")", ",", "\n", "torch", ".", "nn", ".", "Conv2d", "(", "2", "*", "(", "self", ".", "num_primal", "+", "1", ")", ",", "2", "*", "self", ".", "num_primal", ",", "kernel_size", "=", "1", ")", ",", "\n", "]", "\n", ")", "\n", "", "elif", "primal_model_architecture", "in", "[", "\"UNET\"", ",", "\"NORMUNET\"", "]", ":", "\n", "            ", "primal_model", "=", "NormUnet", "(", "\n", "cfg_dict", ".", "get", "(", "\"primal_unet_num_filters\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"primal_unet_num_pool_layers\"", ")", ",", "\n", "in_chans", "=", "2", "*", "(", "self", ".", "num_primal", "+", "1", ")", ",", "\n", "out_chans", "=", "2", "*", "self", ".", "num_primal", ",", "\n", "drop_prob", "=", "cfg_dict", ".", "get", "(", "\"primal_unet_dropout_probability\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"primal_unet_padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"primal_unet_normalize\"", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"LPDNet is currently implemented for primal_model_architecture == 'CONV' or 'UNet'.\"", "\n", "f\"Got primal_model_architecture == {primal_model_architecture}.\"", "\n", ")", "\n", "\n", "", "dual_model_architecture", "=", "cfg_dict", ".", "get", "(", "\"dual_model_architecture\"", ")", "\n", "\n", "if", "dual_model_architecture", "==", "\"CONV\"", ":", "\n", "            ", "dual_model", "=", "Conv2d", "(", "\n", "in_channels", "=", "2", "*", "(", "self", ".", "num_dual", "+", "2", ")", ",", "\n", "out_channels", "=", "2", "*", "self", ".", "num_dual", ",", "\n", "hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"kspace_conv_hidden_channels\"", ")", ",", "\n", "n_convs", "=", "cfg_dict", ".", "get", "(", "\"kspace_conv_n_convs\"", ")", ",", "\n", "batchnorm", "=", "cfg_dict", ".", "get", "(", "\"kspace_conv_batchnorm\"", ")", ",", "\n", ")", "\n", "", "elif", "dual_model_architecture", "==", "\"DIDN\"", ":", "\n", "            ", "dual_model", "=", "DIDN", "(", "\n", "in_channels", "=", "2", "*", "(", "self", ".", "num_dual", "+", "2", ")", ",", "\n", "out_channels", "=", "2", "*", "self", ".", "num_dual", ",", "\n", "hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"kspace_didn_hidden_channels\"", ")", ",", "\n", "num_dubs", "=", "cfg_dict", ".", "get", "(", "\"kspace_didn_num_dubs\"", ")", ",", "\n", "num_convs_recon", "=", "cfg_dict", ".", "get", "(", "\"kspace_didn_num_convs_recon\"", ")", ",", "\n", ")", "\n", "", "elif", "dual_model_architecture", "in", "[", "\"UNET\"", ",", "\"NORMUNET\"", "]", ":", "\n", "            ", "dual_model", "=", "NormUnet", "(", "\n", "cfg_dict", ".", "get", "(", "\"dual_unet_num_filters\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"dual_unet_num_pool_layers\"", ")", ",", "\n", "in_chans", "=", "2", "*", "(", "self", ".", "num_dual", "+", "2", ")", ",", "\n", "out_chans", "=", "2", "*", "self", ".", "num_dual", ",", "\n", "drop_prob", "=", "cfg_dict", ".", "get", "(", "\"dual_unet_dropout_probability\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"dual_unet_padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"dual_unet_normalize\"", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"LPDNet is currently implemented for dual_model_architecture == 'CONV' or 'DIDN' or 'UNet'.\"", "\n", "f\"Got dual_model_architecture == {dual_model_architecture}.\"", "\n", ")", "\n", "\n", "", "self", ".", "primal_net", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "PrimalNet", "(", "self", ".", "num_primal", ",", "primal_architecture", "=", "primal_model", ")", "for", "_", "in", "range", "(", "self", ".", "num_iter", ")", "]", "\n", ")", "\n", "self", ".", "dual_net", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "DualNet", "(", "self", ".", "num_dual", ",", "dual_architecture", "=", "dual_model", ")", "for", "_", "in", "range", "(", "self", ".", "num_iter", ")", "]", "\n", ")", "\n", "\n", "self", ".", "fft_centered", "=", "cfg_dict", ".", "get", "(", "\"fft_centered\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "\n", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "accumulate_estimates", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.lpd.LPDNet.forward": [[132, 207], ["mridc.core.classes.common.typecheck", "mridc.collections.common.parts.utils.complex_mul().sum", "torch.cat().to", "torch.cat().to", "range", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "primal_buffer[].clone", "torch.where", "dual_buffer[].clone", "mridc.collections.common.parts.utils.complex_mul().sum", "mridc.collections.common.parts.utils.complex_mul", "torch.cat", "torch.cat", "torch.tensor().to", "mridc.collections.common.parts.fft.fft2().type", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj", "torch.where.type", "mridc.collections.common.parts.utils.complex_mul", "torch.where", "torch.tensor", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj", "torch.tensor().to", "mridc.collections.common.parts.utils.complex_mul", "torch.where", "torch.where.unsqueeze", "torch.tensor().to", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "input_image", "=", "complex_mul", "(", "\n", "ifft2", "(", "\n", "torch", ".", "where", "(", "mask", "==", "0", ",", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "y", ".", "dtype", ")", ".", "to", "(", "y", ".", "device", ")", ",", "y", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "complex_conj", "(", "sensitivity_maps", ")", ",", "\n", ")", ".", "sum", "(", "self", ".", "coil_dim", ")", "\n", "dual_buffer", "=", "torch", ".", "cat", "(", "[", "y", "]", "*", "self", ".", "num_dual", ",", "-", "1", ")", ".", "to", "(", "y", ".", "device", ")", "\n", "primal_buffer", "=", "torch", ".", "cat", "(", "[", "input_image", "]", "*", "self", ".", "num_primal", ",", "-", "1", ")", ".", "to", "(", "y", ".", "device", ")", "\n", "\n", "for", "idx", "in", "range", "(", "self", ".", "num_iter", ")", ":", "\n", "# Dual", "\n", "            ", "f_2", "=", "primal_buffer", "[", "...", ",", "2", ":", "4", "]", ".", "clone", "(", ")", "\n", "f_2", "=", "torch", ".", "where", "(", "\n", "mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "f_2", ".", "dtype", ")", ".", "to", "(", "f_2", ".", "device", ")", ",", "\n", "fft2", "(", "\n", "complex_mul", "(", "f_2", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ",", "sensitivity_maps", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ".", "type", "(", "f_2", ".", "type", "(", ")", ")", ",", "\n", ")", "\n", "dual_buffer", "=", "self", ".", "dual_net", "[", "idx", "]", "(", "dual_buffer", ",", "f_2", ",", "y", ")", "\n", "\n", "# Primal", "\n", "h_1", "=", "dual_buffer", "[", "...", ",", "0", ":", "2", "]", ".", "clone", "(", ")", "\n", "h_1", "=", "complex_mul", "(", "\n", "ifft2", "(", "\n", "torch", ".", "where", "(", "mask", "==", "0", ",", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "h_1", ".", "dtype", ")", ".", "to", "(", "h_1", ".", "device", ")", ",", "h_1", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "complex_conj", "(", "sensitivity_maps", ")", ",", "\n", ")", ".", "sum", "(", "self", ".", "coil_dim", ")", "\n", "primal_buffer", "=", "self", ".", "primal_net", "[", "idx", "]", "(", "primal_buffer", ",", "h_1", ")", "\n", "\n", "", "output", "=", "primal_buffer", "[", "...", ",", "0", ":", "2", "]", "\n", "output", "=", "(", "output", "**", "2", ")", ".", "sum", "(", "-", "1", ")", ".", "sqrt", "(", ")", "\n", "_", ",", "output", "=", "center_crop_to_smallest", "(", "target", ",", "output", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.dunet.DUNet.__init__": [[45, 121], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.sigmanet.sensitivity_net.SensitivityNetwork", "torch.nn.Parameter", "mridc.collections.reconstruction.models.didn.didn.DIDN", "mridc.collections.reconstruction.models.sigmanet.dc_layers.DataGDLayer", "omegaconf.OmegaConf.to_container.get", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "torch.ones", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet", "NotImplementedError", "mridc.collections.reconstruction.models.sigmanet.dc_layers.DataProxCGLayer", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.sigmanet.dc_layers.DataVSLayer", "mridc.collections.reconstruction.models.sigmanet.dc_layers.DataIDLayer", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "self", ".", "fft_centered", "=", "cfg_dict", ".", "get", "(", "\"fft_centered\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "\n", "reg_model_architecture", "=", "cfg_dict", ".", "get", "(", "\"reg_model_architecture\"", ")", "\n", "if", "reg_model_architecture", "==", "\"DIDN\"", ":", "\n", "            ", "reg_model", "=", "DIDN", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"didn_hidden_channels\"", ")", ",", "\n", "num_dubs", "=", "cfg_dict", ".", "get", "(", "\"didn_num_dubs\"", ")", ",", "\n", "num_convs_recon", "=", "cfg_dict", ".", "get", "(", "\"didn_num_convs_recon\"", ")", ",", "\n", ")", "\n", "", "elif", "reg_model_architecture", "in", "[", "\"UNET\"", ",", "\"NORMUNET\"", "]", ":", "\n", "            ", "reg_model", "=", "NormUnet", "(", "\n", "cfg_dict", ".", "get", "(", "\"unet_num_filters\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"unet_num_pool_layers\"", ")", ",", "\n", "in_chans", "=", "2", ",", "\n", "out_chans", "=", "2", ",", "\n", "drop_prob", "=", "cfg_dict", ".", "get", "(", "\"unet_dropout_probability\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"unet_padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"unet_normalize\"", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"DUNET is currently implemented for reg_model_architecture == 'DIDN' or 'UNet'.\"", "\n", "f\"Got reg_model_architecture == {reg_model_architecture}.\"", "\n", ")", "\n", "\n", "", "data_consistency_term", "=", "cfg_dict", ".", "get", "(", "\"data_consistency_term\"", ")", "\n", "\n", "if", "data_consistency_term", "==", "\"GD\"", ":", "\n", "            ", "dc_layer", "=", "DataGDLayer", "(", "\n", "lambda_init", "=", "cfg_dict", ".", "get", "(", "\"data_consistency_lambda_init\"", ")", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "", "elif", "data_consistency_term", "==", "\"PROX\"", ":", "\n", "            ", "dc_layer", "=", "DataProxCGLayer", "(", "\n", "lambda_init", "=", "cfg_dict", ".", "get", "(", "\"data_consistency_lambda_init\"", ")", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "", "elif", "data_consistency_term", "==", "\"VS\"", ":", "\n", "            ", "dc_layer", "=", "DataVSLayer", "(", "\n", "alpha_init", "=", "cfg_dict", ".", "get", "(", "\"data_consistency_alpha_init\"", ")", ",", "\n", "beta_init", "=", "cfg_dict", ".", "get", "(", "\"data_consistency_beta_init\"", ")", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "dc_layer", "=", "DataIDLayer", "(", ")", "\n", "\n", "", "self", ".", "model", "=", "SensitivityNetwork", "(", "\n", "cfg_dict", ".", "get", "(", "\"num_iter\"", ")", ",", "\n", "reg_model", ",", "\n", "dc_layer", ",", "\n", "shared_params", "=", "cfg_dict", ".", "get", "(", "\"shared_params\"", ")", ",", "\n", "save_space", "=", "False", ",", "\n", "reset_cache", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "dc_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "accumulate_estimates", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.dunet.DUNet.forward": [[122, 167], ["mridc.core.classes.common.typecheck", "torch.sum", "dunet.DUNet.model", "torch.sum", "torch.view_as_complex", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj", "mridc.collections.common.parts.utils.complex_conj"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "init_pred", "=", "torch", ".", "sum", "(", "\n", "complex_mul", "(", "\n", "ifft2", "(", "\n", "y", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", "\n", ")", ",", "\n", "complex_conj", "(", "sensitivity_maps", ")", ",", "\n", ")", ",", "\n", "self", ".", "coil_dim", ",", "\n", ")", "\n", "image", "=", "self", ".", "model", "(", "init_pred", ",", "y", ",", "sensitivity_maps", ",", "mask", ")", "\n", "image", "=", "torch", ".", "sum", "(", "complex_mul", "(", "image", ",", "complex_conj", "(", "sensitivity_maps", ")", ")", ",", "self", ".", "coil_dim", ")", "\n", "image", "=", "torch", ".", "view_as_complex", "(", "image", ")", "\n", "_", ",", "image", "=", "center_crop_to_smallest", "(", "target", ",", "image", ")", "\n", "return", "image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.crnn.CRNNet.__init__": [[41, 79], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.convrecnet.crnn_block.RecurrentConvolutionalNetBlock", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.conv.gruconv2d.GRUConv2d", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "self", ".", "no_dc", "=", "cfg_dict", ".", "get", "(", "\"no_dc\"", ")", "\n", "self", ".", "fft_centered", "=", "cfg_dict", ".", "get", "(", "\"fft_centered\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "self", ".", "num_iterations", "=", "cfg_dict", ".", "get", "(", "\"num_iterations\"", ")", "\n", "\n", "self", ".", "crnn", "=", "RecurrentConvolutionalNetBlock", "(", "\n", "GRUConv2d", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"hidden_channels\"", ")", ",", "\n", "n_convs", "=", "cfg_dict", ".", "get", "(", "\"n_convs\"", ")", ",", "\n", "batchnorm", "=", "cfg_dict", ".", "get", "(", "\"batchnorm\"", ")", ",", "\n", ")", ",", "\n", "num_iterations", "=", "self", ".", "num_iterations", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", "coil_dim", "=", "self", ".", "coil_dim", ",", "\n", "no_dc", "=", "self", ".", "no_dc", ",", "\n", ")", "\n", "\n", "self", ".", "coil_combination_method", "=", "cfg_dict", ".", "get", "(", "\"coil_combination_method\"", ")", "\n", "\n", "# initialize weights if not using pretrained ccnn", "\n", "# TODO if not ccnn_cfg_dict.get(\"pretrained\", False)", "\n", "\n", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "accumulate_estimates", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.crnn.CRNNet.forward": [[80, 113], ["mridc.core.classes.common.typecheck", "crnn.CRNNet.crnn", "crnn.CRNNet.process_intermediate_pred"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.models.crnn.CRNNet.process_intermediate_pred"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Union", "[", "Generator", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "pred", "=", "self", ".", "crnn", "(", "y", ",", "sensitivity_maps", ",", "mask", ")", "\n", "yield", "[", "self", ".", "process_intermediate_pred", "(", "x", ",", "sensitivity_maps", ",", "target", ")", "for", "x", "in", "pred", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.crnn.CRNNet.process_intermediate_pred": [[114, 139], ["mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.coil_combination", "torch.view_as_complex", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.coil_combination", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest"], ["", "def", "process_intermediate_pred", "(", "self", ",", "pred", ",", "sensitivity_maps", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Process the intermediate prediction.\n\n        Parameters\n        ----------\n        pred: Intermediate prediction.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        target: Target data to crop to size.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: torch.Tensor, shape [batch_size, n_x, n_y, 2]\n            Processed prediction.\n        \"\"\"", "\n", "pred", "=", "ifft2", "(", "\n", "pred", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", "\n", ")", "\n", "pred", "=", "coil_combination", "(", "pred", ",", "sensitivity_maps", ",", "method", "=", "self", ".", "coil_combination_method", ",", "dim", "=", "self", ".", "coil_dim", ")", "\n", "pred", "=", "torch", ".", "view_as_complex", "(", "pred", ")", "\n", "_", ",", "pred", "=", "center_crop_to_smallest", "(", "target", ",", "pred", ")", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.crnn.CRNNet.process_loss": [[140, 181], ["torch.abs", "str().lower", "numpy.array().astype", "crnn.CRNNet.process_loss.loss_fn"], "methods", ["None"], ["", "def", "process_loss", "(", "self", ",", "target", ",", "pred", ",", "_loss_fn", ")", ":", "\n", "        ", "\"\"\"\n        Process the loss.\n\n        Parameters\n        ----------\n        target: Target data.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        pred: Final prediction(s).\n            list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        _loss_fn: Loss function.\n            torch.nn.Module, default torch.nn.L1Loss()\n\n        Returns\n        -------\n        loss: torch.FloatTensor, shape [1]\n            If self.accumulate_loss is True, returns an accumulative result of all intermediate losses.\n        \"\"\"", "\n", "target", "=", "torch", ".", "abs", "(", "target", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "target", ")", ")", ")", "\n", "\n", "if", "\"ssim\"", "in", "str", "(", "_loss_fn", ")", ".", "lower", "(", ")", ":", "\n", "            ", "max_value", "=", "np", ".", "array", "(", "torch", ".", "max", "(", "torch", ".", "abs", "(", "target", ")", ")", ".", "item", "(", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "def", "loss_fn", "(", "x", ",", "y", ")", ":", "\n", "                ", "\"\"\"Calculate the ssim loss.\"\"\"", "\n", "return", "_loss_fn", "(", "\n", "x", ".", "unsqueeze", "(", "dim", "=", "self", ".", "coil_dim", ")", ",", "\n", "torch", ".", "abs", "(", "y", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "y", ")", ")", ")", ".", "unsqueeze", "(", "dim", "=", "self", ".", "coil_dim", ")", ",", "\n", "data_range", "=", "torch", ".", "tensor", "(", "max_value", ")", ".", "unsqueeze", "(", "dim", "=", "0", ")", ".", "to", "(", "x", ".", "device", ")", ",", "\n", ")", "\n", "\n", "", "", "else", ":", "\n", "\n", "            ", "def", "loss_fn", "(", "x", ",", "y", ")", ":", "\n", "                ", "\"\"\"Calculate other loss.\"\"\"", "\n", "return", "_loss_fn", "(", "x", ",", "torch", ".", "abs", "(", "y", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "y", ")", ")", ")", ")", "\n", "\n", "", "", "iterations_loss", "=", "[", "loss_fn", "(", "target", ",", "iteration_pred", ")", "for", "iteration_pred", "in", "pred", "]", "\n", "_loss", "=", "[", "x", "*", "torch", ".", "logspace", "(", "-", "1", ",", "0", ",", "steps", "=", "self", ".", "num_iterations", ")", ".", "to", "(", "iterations_loss", "[", "0", "]", ")", "for", "x", "in", "iterations_loss", "]", "\n", "yield", "sum", "(", "sum", "(", "_loss", ")", "/", "self", ".", "num_iterations", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.multidomainnet.MultiDomainNet.__init__": [[25, 58], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.multidomain.multidomain.MultiDomainUnet2d", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.multidomain.multidomain.StandardizationLayer", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "self", ".", "num_cascades", "=", "cfg_dict", ".", "get", "(", "\"num_cascades\"", ")", "\n", "\n", "standardization", "=", "cfg_dict", "[", "\"standardization\"", "]", "\n", "if", "standardization", ":", "\n", "            ", "self", ".", "standardization", "=", "StandardizationLayer", "(", "self", ".", "coil_dim", ",", "-", "1", ")", "\n", "\n", "", "self", ".", "unet", "=", "MultiDomainUnet2d", "(", "\n", "in_channels", "=", "4", "if", "standardization", "else", "2", ",", "# if standardization, in_channels is 4 due to standardized input", "\n", "out_channels", "=", "2", ",", "\n", "num_filters", "=", "cfg_dict", "[", "\"num_filters\"", "]", ",", "\n", "num_pool_layers", "=", "cfg_dict", "[", "\"num_pool_layers\"", "]", ",", "\n", "dropout_probability", "=", "cfg_dict", "[", "\"dropout_probability\"", "]", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", "coil_dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", "\n", "self", ".", "coil_combination_method", "=", "cfg_dict", ".", "get", "(", "\"coil_combination_method\"", ")", "\n", "\n", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "accumulate_estimates", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.multidomainnet.MultiDomainNet._compute_model_per_coil": [[59, 81], ["range", "torch.stack", "data.size", "data.select", "torch.stack.append", "model"], "methods", ["None"], ["", "def", "_compute_model_per_coil", "(", "self", ",", "model", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        Compute the model per coil.\n\n        Parameters\n        ----------\n        model: torch.nn.Module\n            The model to be computed.\n        data: torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n            The data to be computed.\n\n        Returns\n        -------\n        torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n            The computed output.\n        \"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "data", ".", "size", "(", "self", ".", "coil_dim", ")", ")", ":", "\n", "            ", "subselected_data", "=", "data", ".", "select", "(", "self", ".", "coil_dim", ",", "idx", ")", "\n", "output", ".", "append", "(", "model", "(", "subselected_data", ")", ")", "\n", "", "output", "=", "torch", ".", "stack", "(", "output", ",", "dim", "=", "self", ".", "coil_dim", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.multidomainnet.MultiDomainNet.forward": [[82, 127], ["mridc.core.classes.common.typecheck", "mridc.collections.common.parts.fft.ifft2", "hasattr", "multidomainnet.MultiDomainNet._compute_model_per_coil().permute", "mridc.collections.common.parts.utils.coil_combination", "torch.view_as_complex", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "multidomainnet.MultiDomainNet.standardization", "multidomainnet.MultiDomainNet._compute_model_per_coil", "multidomainnet.MultiDomainNet.permute"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.coil_combination", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest", "home.repos.pwc.inspect_result.wdika_mridc.crossdomain.multicoil.MultiCoil._compute_model_per_coil"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "image", "=", "ifft2", "(", "\n", "y", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", "\n", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "\"standardization\"", ")", ":", "\n", "            ", "image", "=", "self", ".", "standardization", "(", "image", ",", "sensitivity_maps", ")", "\n", "\n", "", "output_image", "=", "self", ".", "_compute_model_per_coil", "(", "self", ".", "unet", ",", "image", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", ")", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", "\n", "output_image", "=", "coil_combination", "(", "\n", "output_image", ",", "sensitivity_maps", ",", "method", "=", "self", ".", "coil_combination_method", ",", "dim", "=", "self", ".", "coil_dim", "\n", ")", "\n", "output_image", "=", "torch", ".", "view_as_complex", "(", "output_image", ")", "\n", "_", ",", "output_image", "=", "center_crop_to_smallest", "(", "target", ",", "output_image", ")", "\n", "return", "output_image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.jointicnet.JointICNet.__init__": [[38, 99], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet", "mridc.collections.reconstruction.models.unet_base.unet_block.NormUnet", "mridc.collections.reconstruction.models.base.BaseSensitivityModel", "torch.nn.Conv2d", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "self", ".", "num_iter", "=", "cfg_dict", ".", "get", "(", "\"num_iter\"", ")", "\n", "self", ".", "fft_centered", "=", "cfg_dict", ".", "get", "(", "\"fft_centered\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "\n", "self", ".", "kspace_model", "=", "NormUnet", "(", "\n", "cfg_dict", ".", "get", "(", "\"kspace_unet_num_filters\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"kspace_unet_num_pool_layers\"", ")", ",", "\n", "in_chans", "=", "2", ",", "\n", "out_chans", "=", "2", ",", "\n", "drop_prob", "=", "cfg_dict", ".", "get", "(", "\"kspace_unet_dropout_probability\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"kspace_unet_padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"kspace_unet_normalize\"", ")", ",", "\n", ")", "\n", "\n", "self", ".", "image_model", "=", "NormUnet", "(", "\n", "cfg_dict", ".", "get", "(", "\"imspace_unet_num_filters\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"imspace_unet_num_pool_layers\"", ")", ",", "\n", "in_chans", "=", "2", ",", "\n", "out_chans", "=", "2", ",", "\n", "drop_prob", "=", "cfg_dict", ".", "get", "(", "\"imspace_unet_dropout_probability\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"imspace_unet_padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"imspace_unet_normalize\"", ")", ",", "\n", ")", "\n", "\n", "self", ".", "sens_net", "=", "BaseSensitivityModel", "(", "\n", "cfg_dict", ".", "get", "(", "\"sens_unet_num_filters\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"sens_unet_num_pool_layers\"", ")", ",", "\n", "mask_center", "=", "cfg_dict", ".", "get", "(", "\"sens_unet_mask_center\"", ")", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", "coil_dim", "=", "self", ".", "coil_dim", ",", "\n", "mask_type", "=", "cfg_dict", ".", "get", "(", "\"sens_mask_type\"", ")", ",", "\n", "drop_prob", "=", "cfg_dict", ".", "get", "(", "\"sens_unet_dropout_probability\"", ")", ",", "\n", "padding_size", "=", "cfg_dict", ".", "get", "(", "\"sens_unet_padding_size\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"sens_unet_normalize\"", ")", ",", "\n", ")", "\n", "\n", "self", ".", "conv_out", "=", "torch", ".", "nn", ".", "Conv2d", "(", "in_channels", "=", "2", ",", "out_channels", "=", "2", ",", "kernel_size", "=", "1", ")", "\n", "\n", "self", ".", "reg_param_I", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "self", ".", "num_iter", ")", ")", "\n", "self", ".", "reg_param_F", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "self", ".", "num_iter", ")", ")", "\n", "self", ".", "reg_param_C", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "self", ".", "num_iter", ")", ")", "\n", "\n", "self", ".", "lr_image", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "self", ".", "num_iter", ")", ")", "\n", "self", ".", "lr_sens", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "self", ".", "num_iter", ")", ")", "\n", "\n", "self", ".", "coil_combination_method", "=", "cfg_dict", ".", "get", "(", "\"coil_combination_method\"", ")", "\n", "\n", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "accumulate_estimates", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.jointicnet.JointICNet.update_C": [[100, 161], ["mridc.collections.common.parts.fft.fft2", "torch.where", "torch.where", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_mul", "torch.tensor().to", "torch.tensor().to", "mridc.collections.common.parts.utils.complex_conj().unsqueeze", "image.unsqueeze", "torch.tensor", "torch.tensor", "mridc.collections.common.parts.utils.complex_conj"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "def", "update_C", "(", "self", ",", "idx", ",", "DC_sens", ",", "sensitivity_maps", ",", "image", ",", "y", ",", "mask", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Update the coil sensitivity maps.\n\n        .. math::\n            C = (1 - 2 * \\lambda_{k}^{C} * ni_{k}) * C_{k}\n\n            C = 2 * \\lambda_{k}^{C} * ni_{k} * D_{C}(F^-1(b))\n\n            A(x_{k}) = M * F * (C * x_{k})\n\n            C = 2 * ni_{k} * F^-1(M.T * (M * F * (C * x_{k}) - b)) * x_{k}^*\n\n        Parameters\n        ----------\n        idx: int\n            The current iteration index.\n        DC_sens: torch.Tensor [batch_size, num_coils, num_sens_maps, num_rows, num_cols]\n            The initial coil sensitivity maps.\n        sensitivity_maps: torch.Tensor [batch_size, num_coils, num_sens_maps, num_rows, num_cols]\n            The coil sensitivity maps.\n        image: torch.Tensor [batch_size, num_coils, num_rows, num_cols]\n            The predicted image.\n        y: torch.Tensor [batch_size, num_coils, num_rows, num_cols]\n            The subsampled k-space data.\n        mask: torch.Tensor [batch_size, 1, num_rows, num_cols]\n            The subsampled mask.\n\n        Returns\n        -------\n        sensitivity_maps: torch.Tensor [batch_size, num_coils, num_sens_maps, num_rows, num_cols]\n            The updated coil sensitivity maps.\n        \"\"\"", "\n", "# (1 - 2 * lambda_{k}^{C} * ni_{k}) * C_{k}", "\n", "sense_term_1", "=", "(", "1", "-", "2", "*", "self", ".", "reg_param_C", "[", "idx", "]", "*", "self", ".", "lr_sens", "[", "idx", "]", ")", "*", "sensitivity_maps", "\n", "# 2 * lambda_{k}^{C} * ni_{k} * D_{C}(F^-1(b))", "\n", "sense_term_2", "=", "2", "*", "self", ".", "reg_param_C", "[", "idx", "]", "*", "self", ".", "lr_sens", "[", "idx", "]", "*", "DC_sens", "\n", "# A(x_{k}) = M * F * (C * x_{k})", "\n", "sense_term_3_A", "=", "fft2", "(", "\n", "complex_mul", "(", "image", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ",", "sensitivity_maps", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "sense_term_3_A", "=", "torch", ".", "where", "(", "mask", "==", "0", ",", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "y", ".", "dtype", ")", ".", "to", "(", "y", ".", "device", ")", ",", "sense_term_3_A", ")", "\n", "# 2 * ni_{k} * F^-1(M.T * (M * F * (C * x_{k}) - b)) * x_{k}^*", "\n", "sense_term_3_mask", "=", "torch", ".", "where", "(", "\n", "mask", "==", "1", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "y", ".", "dtype", ")", ".", "to", "(", "y", ".", "device", ")", ",", "\n", "sense_term_3_A", "-", "y", ",", "\n", ")", "\n", "\n", "sense_term_3_backward", "=", "ifft2", "(", "\n", "sense_term_3_mask", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "sense_term_3", "=", "2", "*", "self", ".", "lr_sens", "[", "idx", "]", "*", "sense_term_3_backward", "*", "complex_conj", "(", "image", ")", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", "\n", "sensitivity_maps", "=", "sense_term_1", "+", "sense_term_2", "-", "sense_term_3", "\n", "return", "sensitivity_maps", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.jointicnet.JointICNet.update_X": [[162, 241], ["jointicnet.JointICNet.image_model().squeeze().contiguous", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.utils.complex_mul().sum", "jointicnet.JointICNet.kspace_model().squeeze().contiguous", "mridc.collections.common.parts.utils.complex_mul", "torch.where", "jointicnet.JointICNet.image_model().squeeze", "image.unsqueeze", "torch.tensor().to", "mridc.collections.common.parts.utils.complex_mul", "jointicnet.JointICNet.kspace_model().squeeze", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj", "jointicnet.JointICNet.image_model", "torch.tensor", "image.unsqueeze", "jointicnet.JointICNet.kspace_model", "mridc.collections.common.parts.fft.fft2().unsqueeze", "mridc.collections.common.parts.fft.fft2"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2"], ["", "def", "update_X", "(", "self", ",", "idx", ",", "image", ",", "sensitivity_maps", ",", "y", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        Update the image.\n\n        .. math::\n            x_{k} = (1 - 2 * \\lamdba_{{k}_{I}} * mi_{k} - 2 * \\lamdba_{{k}_{F}} * mi_{k}) * x_{k}\n\n            x_{k} = 2 * mi_{k} * (\\lambda_{{k}_{I}} * D_I(x_{k}) + \\lambda_{{k}_{F}} * F^-1(D_F(f)))\n\n            A(x{k} - b) = M * F * (C * x{k}) - b\n\n            x_{k} = 2 * mi_{k} * A^* * (A(x{k} - b))\n\n        Parameters\n        ----------\n        idx: int\n            The current iteration index.\n        image: torch.Tensor [batch_size, num_coils, num_rows, num_cols]\n            The predicted image.\n        sensitivity_maps: torch.Tensor [batch_size, num_coils, num_sens_maps, num_rows, num_cols]\n            The coil sensitivity maps.\n        y: torch.Tensor [batch_size, num_coils, num_rows, num_cols]\n            The subsampled k-space data.\n        mask: torch.Tensor [batch_size, 1, num_rows, num_cols]\n            The subsampled mask.\n\n        Returns\n        -------\n        image: torch.Tensor [batch_size, num_coils, num_rows, num_cols]\n            The updated image.\n        \"\"\"", "\n", "# (1 - 2 * lamdba_{k}_{I} * mi_{k} - 2 * lamdba_{k}_{F} * mi_{k}) * x_{k}", "\n", "image_term_1", "=", "(", "\n", "1", "-", "2", "*", "self", ".", "reg_param_I", "[", "idx", "]", "*", "self", ".", "lr_image", "[", "idx", "]", "-", "2", "*", "self", ".", "reg_param_F", "[", "idx", "]", "*", "self", ".", "lr_image", "[", "idx", "]", "\n", ")", "*", "image", "\n", "# D_I(x_{k})", "\n", "image_term_2_DI", "=", "self", ".", "image_model", "(", "image", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ")", ".", "squeeze", "(", "self", ".", "coil_dim", ")", ".", "contiguous", "(", ")", "\n", "image_term_2_DF", "=", "ifft2", "(", "\n", "self", ".", "kspace_model", "(", "\n", "fft2", "(", "\n", "image", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", "\n", ")", "\n", ".", "squeeze", "(", "self", ".", "coil_dim", ")", "\n", ".", "contiguous", "(", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "# 2 * mi_{k} * (lambda_{k}_{I} * D_I(x_{k}) + lambda_{k}_{F} * F^-1(D_F(f)))", "\n", "image_term_2", "=", "(", "\n", "2", "\n", "*", "self", ".", "lr_image", "[", "idx", "]", "\n", "*", "(", "self", ".", "reg_param_I", "[", "idx", "]", "*", "image_term_2_DI", "+", "self", ".", "reg_param_F", "[", "idx", "]", "*", "image_term_2_DF", ")", "\n", ")", "\n", "# A(x{k}) - b) = M * F * (C * x{k}) - b", "\n", "image_term_3_A", "=", "fft2", "(", "\n", "complex_mul", "(", "image", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ",", "sensitivity_maps", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "image_term_3_A", "=", "torch", ".", "where", "(", "mask", "==", "0", ",", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "y", ".", "dtype", ")", ".", "to", "(", "y", ".", "device", ")", ",", "image_term_3_A", ")", "-", "y", "\n", "# 2 * mi_{k} * A^* * (A(x{k}) - b))", "\n", "image_term_3_Aconj", "=", "complex_mul", "(", "\n", "ifft2", "(", "\n", "image_term_3_A", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "complex_conj", "(", "sensitivity_maps", ")", ",", "\n", ")", ".", "sum", "(", "self", ".", "coil_dim", ")", "\n", "image_term_3", "=", "2", "*", "self", ".", "lr_image", "[", "idx", "]", "*", "image_term_3_Aconj", "\n", "image", "=", "image_term_1", "+", "image_term_2", "-", "image_term_3", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.jointicnet.JointICNet.forward": [[242, 285], ["mridc.core.classes.common.typecheck", "jointicnet.JointICNet.sens_net", "jointicnet.JointICNet.clone", "mridc.collections.common.parts.utils.complex_mul().sum", "range", "torch.view_as_complex", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "jointicnet.JointICNet.update_C", "jointicnet.JointICNet.update_X", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest", "home.repos.pwc.inspect_result.wdika_mridc.models.jointicnet.JointICNet.update_C", "home.repos.pwc.inspect_result.wdika_mridc.models.jointicnet.JointICNet.update_X", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "DC_sens", "=", "self", ".", "sens_net", "(", "y", ",", "mask", ")", "\n", "sensitivity_maps", "=", "DC_sens", ".", "clone", "(", ")", "\n", "image", "=", "complex_mul", "(", "\n", "ifft2", "(", "y", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", ")", ",", "\n", "complex_conj", "(", "sensitivity_maps", ")", ",", "\n", ")", ".", "sum", "(", "self", ".", "coil_dim", ")", "\n", "for", "idx", "in", "range", "(", "self", ".", "num_iter", ")", ":", "\n", "            ", "sensitivity_maps", "=", "self", ".", "update_C", "(", "idx", ",", "DC_sens", ",", "sensitivity_maps", ",", "image", ",", "y", ",", "mask", ")", "\n", "image", "=", "self", ".", "update_X", "(", "idx", ",", "image", ",", "sensitivity_maps", ",", "y", ",", "mask", ")", "\n", "", "image", "=", "torch", ".", "view_as_complex", "(", "image", ")", "\n", "_", ",", "image", "=", "center_crop_to_smallest", "(", "target", ",", "image", ")", "\n", "return", "image", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.zf.ZF.__init__": [[37, 61], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.base.BaseSensitivityModel", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "self", ".", "coil_combination_method", "=", "cfg_dict", ".", "get", "(", "\"coil_combination_method\"", ")", "\n", "self", ".", "fft_centered", "=", "cfg_dict", ".", "get", "(", "\"fft_centered\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "\n", "# Initialize the sensitivity network if use_sens_net is True", "\n", "self", ".", "use_sens_net", "=", "cfg_dict", ".", "get", "(", "\"use_sens_net\"", ")", "\n", "if", "self", ".", "use_sens_net", ":", "\n", "            ", "self", ".", "sens_net", "=", "BaseSensitivityModel", "(", "\n", "cfg_dict", ".", "get", "(", "\"sens_chans\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"sens_pools\"", ")", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", "coil_dim", "=", "self", ".", "coil_dim", ",", "\n", "mask_type", "=", "cfg_dict", ".", "get", "(", "\"sens_mask_type\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"sens_normalize\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.zf.ZF.process_inputs": [[63, 90], ["isinstance", "numpy.random.randint", "len"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "process_inputs", "(", "y", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        Process the inputs to the method.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            list of torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            list of torch.Tensor, shape [1, 1, n_x, n_y, 1]\n\n        Returns\n        -------\n        y: Subsampled k-space data.\n            randomly selected y\n        mask: Sampling mask.\n            randomly selected mask\n        r: Random index.\n        \"\"\"", "\n", "if", "isinstance", "(", "y", ",", "list", ")", ":", "\n", "            ", "r", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "y", ")", ")", "\n", "y", "=", "y", "[", "r", "]", "\n", "mask", "=", "mask", "[", "r", "]", "\n", "", "else", ":", "\n", "            ", "r", "=", "0", "\n", "", "return", "y", ",", "mask", ",", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.zf.ZF.forward": [[91, 129], ["mridc.core.classes.common.typecheck", "mridc.collections.common.parts.utils.coil_combination", "mridc.collections.common.parts.utils.check_stacked_complex", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "mridc.collections.common.parts.fft.ifft2", "zf.ZF.coil_combination_method.upper"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.coil_combination", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.check_stacked_complex", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", ")", "->", "Union", "[", "list", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass of the zero-filled method.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: torch.Tensor, shape [batch_size, n_x, n_y, 2]\n            Predicted data.\n        \"\"\"", "\n", "pred", "=", "coil_combination", "(", "\n", "ifft2", "(", "y", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", ")", ",", "\n", "sensitivity_maps", ",", "\n", "method", "=", "self", ".", "coil_combination_method", ".", "upper", "(", ")", ",", "\n", "dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", "pred", "=", "check_stacked_complex", "(", "pred", ")", "\n", "_", ",", "pred", "=", "center_crop_to_smallest", "(", "target", ",", "pred", ")", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.zf.ZF.test_step": [[130, 182], ["zf.ZF.process_inputs", "zf.ZF.forward", "int", "str", "torch.abs().detach().cpu", "torch.abs().detach().cpu", "torch.abs", "zf.ZF.log_image", "zf.ZF.log_image", "zf.ZF.log_image", "zf.ZF.sens_net", "torch.abs().detach().cpu.max", "mridc.collections.common.parts.utils.sense.max", "zf.ZF.detach().cpu().numpy", "zf.ZF.coil_combination_method.upper", "mridc.collections.common.parts.utils.sense", "torch.abs().detach", "torch.abs().detach", "mridc.collections.common.parts.fft.ifft2", "zf.ZF.detach().cpu", "torch.abs", "torch.abs", "zf.ZF.detach"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.models.pics.PICS.process_inputs", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.sense", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], ["", "def", "test_step", "(", "self", ",", "batch", ":", "Dict", "[", "float", ",", "torch", ".", "Tensor", "]", ",", "batch_idx", ":", "int", ")", "->", "Tuple", "[", "str", ",", "int", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Test step.\n\n        Parameters\n        ----------\n        batch: Batch of data.\n            Dict of torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        batch_idx: Batch index.\n            int\n\n        Returns\n        -------\n        name: Name of the volume.\n            str\n        slice_num: Slice number.\n            int\n        pred: Predicted data.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        \"\"\"", "\n", "kspace", ",", "y", ",", "sensitivity_maps", ",", "mask", ",", "init_pred", ",", "target", ",", "fname", ",", "slice_num", ",", "_", "=", "batch", "\n", "y", ",", "mask", ",", "_", "=", "self", ".", "process_inputs", "(", "y", ",", "mask", ")", "\n", "\n", "if", "self", ".", "use_sens_net", ":", "\n", "            ", "sensitivity_maps", "=", "self", ".", "sens_net", "(", "kspace", ",", "mask", ")", "\n", "if", "self", ".", "coil_combination_method", ".", "upper", "(", ")", "==", "\"SENSE\"", ":", "\n", "                ", "target", "=", "sense", "(", "\n", "ifft2", "(", "\n", "kspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "sensitivity_maps", ",", "\n", "dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", "\n", "", "", "prediction", "=", "self", ".", "forward", "(", "y", ",", "sensitivity_maps", ",", "mask", ",", "target", ")", "\n", "\n", "slice_num", "=", "int", "(", "slice_num", ")", "\n", "name", "=", "str", "(", "fname", "[", "0", "]", ")", "# type: ignore", "\n", "key", "=", "f\"{name}_images_idx_{slice_num}\"", "# type: ignore", "\n", "output", "=", "torch", ".", "abs", "(", "prediction", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "target", "=", "torch", ".", "abs", "(", "target", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "output", "=", "output", "/", "output", ".", "max", "(", ")", "# type: ignore", "\n", "target", "=", "target", "/", "target", ".", "max", "(", ")", "# type: ignore", "\n", "error", "=", "torch", ".", "abs", "(", "target", "-", "output", ")", "\n", "self", ".", "log_image", "(", "f\"{key}/target\"", ",", "target", ")", "\n", "self", ".", "log_image", "(", "f\"{key}/reconstruction\"", ",", "output", ")", "\n", "self", ".", "log_image", "(", "f\"{key}/error\"", ",", "error", ")", "\n", "\n", "return", "name", ",", "slice_num", ",", "prediction", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.ccnn.CascadeNet.__init__": [[39, 82], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "torch.nn.ModuleList", "omegaconf.OmegaConf.to_container.get", "torch.nn.Parameter", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "mridc.collections.common.losses.ssim.SSIMLoss", "torch.nn.L1Loss", "torch.ones", "mridc.collections.reconstruction.models.cascadenet.ccnn_block.CascadeNetBlock", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.conv.conv2d.Conv2d", "range", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "self", ".", "coil_combination_method", "=", "cfg_dict", ".", "get", "(", "\"coil_combination_method\"", ")", "\n", "\n", "self", ".", "fft_centered", "=", "cfg_dict", ".", "get", "(", "\"fft_centered\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "\n", "# Cascades of CascadeCNN blocks", "\n", "self", ".", "cascades", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "CascadeNetBlock", "(", "\n", "Conv2d", "(", "\n", "in_channels", "=", "2", ",", "\n", "out_channels", "=", "2", ",", "\n", "hidden_channels", "=", "cfg_dict", ".", "get", "(", "\"hidden_channels\"", ")", ",", "\n", "n_convs", "=", "cfg_dict", ".", "get", "(", "\"n_convs\"", ")", ",", "\n", "batchnorm", "=", "cfg_dict", ".", "get", "(", "\"batchnorm\"", ")", ",", "\n", ")", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", "coil_dim", "=", "self", ".", "coil_dim", ",", "\n", "no_dc", "=", "cfg_dict", ".", "get", "(", "\"no_dc\"", ")", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "cfg_dict", ".", "get", "(", "\"num_cascades\"", ")", ")", "\n", "]", "\n", ")", "\n", "\n", "self", ".", "coil_combination_method", "=", "cfg_dict", ".", "get", "(", "\"coil_combination_method\"", ")", "\n", "\n", "# initialize weights if not using pretrained ccnn", "\n", "# TODO if not cfg_dict.get(\"pretrained\", False)", "\n", "self", ".", "train_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"train_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "self", ".", "eval_loss_fn", "=", "SSIMLoss", "(", ")", "if", "cfg_dict", ".", "get", "(", "\"eval_loss_fn\"", ")", "==", "\"ssim\"", "else", "L1Loss", "(", ")", "\n", "\n", "self", ".", "accumulate_estimates", "=", "False", "\n", "self", ".", "dc_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.ccnn.CascadeNet.forward": [[83, 132], ["mridc.core.classes.common.typecheck", "y.clone", "torch.view_as_complex", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest", "cascade", "mridc.collections.common.parts.utils.coil_combination", "mridc.collections.common.parts.fft.ifft2"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.coil_combination", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "init_pred", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the network.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: list of torch.Tensor, shape [batch_size, n_x, n_y, 2], or  torch.Tensor, shape [batch_size, n_x, n_y, 2]\n             If self.accumulate_loss is True, returns a list of all intermediate estimates.\n             If False, returns the final estimate.\n        \"\"\"", "\n", "pred", "=", "y", ".", "clone", "(", ")", "\n", "for", "cascade", "in", "self", ".", "cascades", ":", "\n", "            ", "pred", "=", "cascade", "(", "pred", ",", "y", ",", "sensitivity_maps", ",", "mask", ")", "\n", "", "pred", "=", "torch", ".", "view_as_complex", "(", "\n", "coil_combination", "(", "\n", "ifft2", "(", "\n", "pred", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "sensitivity_maps", ",", "\n", "method", "=", "self", ".", "coil_combination_method", ",", "\n", "dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", ")", "\n", "_", ",", "pred", "=", "center_crop_to_smallest", "(", "target", ",", "pred", ")", "\n", "return", "pred", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.models.pics.PICS.__init__": [[35, 63], ["mridc.collections.reconstruction.models.base.BaseMRIReconstructionModel.__init__", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "mridc.collections.reconstruction.models.base.BaseSensitivityModel", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "# init superclass", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "\n", "cfg_dict", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "\n", "self", ".", "reg_wt", "=", "cfg_dict", ".", "get", "(", "\"reg_wt\"", ")", "\n", "self", ".", "num_iters", "=", "cfg_dict", ".", "get", "(", "\"num_iters\"", ")", "\n", "self", ".", "_device", "=", "cfg_dict", ".", "get", "(", "\"device\"", ")", "\n", "self", ".", "fft_normalization", "=", "cfg_dict", ".", "get", "(", "\"fft_normalization\"", ")", "\n", "self", ".", "spatial_dims", "=", "cfg_dict", ".", "get", "(", "\"spatial_dims\"", ")", "\n", "self", ".", "coil_dim", "=", "cfg_dict", ".", "get", "(", "\"coil_dim\"", ")", "\n", "self", ".", "num_cascades", "=", "cfg_dict", ".", "get", "(", "\"num_cascades\"", ")", "\n", "\n", "self", ".", "coil_combination_method", "=", "cfg_dict", ".", "get", "(", "\"coil_combination_method\"", ")", "\n", "\n", "# Initialize the sensitivity network if use_sens_net is True", "\n", "self", ".", "use_sens_net", "=", "cfg_dict", ".", "get", "(", "\"use_sens_net\"", ")", "\n", "if", "self", ".", "use_sens_net", ":", "\n", "            ", "self", ".", "sens_net", "=", "BaseSensitivityModel", "(", "\n", "cfg_dict", ".", "get", "(", "\"sens_chans\"", ")", ",", "\n", "cfg_dict", ".", "get", "(", "\"sens_pools\"", ")", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", "coil_dim", "=", "self", ".", "coil_dim", ",", "\n", "mask_type", "=", "cfg_dict", ".", "get", "(", "\"sens_mask_type\"", ")", ",", "\n", "normalize", "=", "cfg_dict", ".", "get", "(", "\"sens_normalize\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.pics.PICS.process_inputs": [[65, 92], ["isinstance", "numpy.random.randint", "len"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "process_inputs", "(", "y", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        Process the inputs to the method.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            list of torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            list of torch.Tensor, shape [1, 1, n_x, n_y, 1]\n\n        Returns\n        -------\n        y: Subsampled k-space data.\n            randomly selected y\n        mask: Sampling mask.\n            randomly selected mask\n        r: Random index.\n        \"\"\"", "\n", "if", "isinstance", "(", "y", ",", "list", ")", ":", "\n", "            ", "r", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "y", ")", ")", "\n", "y", "=", "y", "[", "r", "]", "\n", "mask", "=", "mask", "[", "r", "]", "\n", "", "else", ":", "\n", "            ", "r", "=", "0", "\n", "", "return", "y", ",", "mask", ",", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.pics.PICS.forward": [[93, 129], ["mridc.core.classes.common.typecheck", "torch.zeros_like", "mridc.collections.reconstruction.parts.utils.center_crop_to_smallest"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "y", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "target", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", ")", "->", "Union", "[", "list", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass of PICS.\n\n        Parameters\n        ----------\n        y: Subsampled k-space data.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        sensitivity_maps: Coil sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        mask: Sampling mask.\n            torch.Tensor, shape [1, 1, n_x, n_y, 1]\n        init_pred: Initial prediction.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        target: Target data to compute the loss.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n\n        Returns\n        -------\n        pred: torch.Tensor, shape [batch_size, n_x, n_y, 2]\n            Predicted data.\n        \"\"\"", "\n", "pred", "=", "torch", ".", "zeros_like", "(", "sensitivity_maps", ")", "\n", "# if \"cuda\" in str(self._device):", "\n", "#     pred = bart.bart(1, f\"pics -d0 -g -S -R W:7:0:{self.reg_wt} -i {self.num_iters}\", y, sensitivity_maps)[0]", "\n", "# else:", "\n", "#     pred = bart.bart(1, f\"pics -d0 -S -R W:7:0:{self.reg_wt} -i {self.num_iters}\", y, sensitivity_maps)[0]", "\n", "_", ",", "pred", "=", "center_crop_to_smallest", "(", "target", ",", "pred", ")", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.models.pics.PICS.test_step": [[130, 197], ["pics.PICS.process_inputs", "torch.view_as_complex().permute().detach().cpu().numpy", "torch.view_as_complex", "torch.fft.fftshift.permute().detach().cpu().numpy", "torch.from_numpy().unsqueeze", "int", "str", "torch.abs().detach().cpu", "torch.abs().detach().cpu", "torch.abs", "pics.PICS.log_image", "pics.PICS.log_image", "pics.PICS.log_image", "pics.PICS.sens_net", "ValueError", "torch.fft.fftshift", "torch.fft.fftshift", "torch.abs().detach().cpu.max", "mridc.collections.common.parts.utils.sense.max", "torch.fft.fftshift.detach().cpu().numpy", "pics.PICS.coil_combination_method.upper", "mridc.collections.common.parts.utils.sense", "torch.view_as_complex().permute().detach().cpu", "torch.fft.fftshift.permute().detach().cpu", "torch.from_numpy", "torch.abs().detach", "torch.abs().detach", "mridc.collections.common.parts.fft.ifft2", "pics.PICS.forward", "torch.fft.fftshift.detach().cpu", "torch.view_as_complex().permute().detach", "torch.fft.fftshift.permute().detach", "torch.abs", "torch.abs", "torch.fft.fftshift.detach", "torch.view_as_complex().permute", "torch.fft.fftshift.permute", "torch.view_as_complex"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.models.pics.PICS.process_inputs", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image", "home.repos.pwc.inspect_result.wdika_mridc.models.base.BaseMRIReconstructionModel.log_image", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.sense", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward"], ["", "def", "test_step", "(", "self", ",", "batch", ":", "Dict", "[", "float", ",", "torch", ".", "Tensor", "]", ",", "batch_idx", ":", "int", ")", "->", "Tuple", "[", "str", ",", "int", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Test step.\n\n        Parameters\n        ----------\n        batch: Batch of data.\n            Dict of torch.Tensor, shape [batch_size, n_coils, n_x, n_y, 2]\n        batch_idx: Batch index.\n            int\n\n        Returns\n        -------\n        name: Name of the volume.\n            str\n        slice_num: Slice number.\n            int\n        pred: Predicted data.\n            torch.Tensor, shape [batch_size, n_x, n_y, 2]\n        \"\"\"", "\n", "kspace", ",", "y", ",", "sensitivity_maps", ",", "mask", ",", "_", ",", "target", ",", "fname", ",", "slice_num", ",", "_", "=", "batch", "\n", "y", ",", "mask", ",", "_", "=", "self", ".", "process_inputs", "(", "y", ",", "mask", ")", "\n", "\n", "if", "self", ".", "use_sens_net", ":", "\n", "            ", "sensitivity_maps", "=", "self", ".", "sens_net", "(", "kspace", ",", "mask", ")", "\n", "if", "self", ".", "coil_combination_method", ".", "upper", "(", ")", "==", "\"SENSE\"", ":", "\n", "                ", "target", "=", "sense", "(", "\n", "ifft2", "(", "\n", "kspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "sensitivity_maps", ",", "\n", "dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", "\n", "", "", "y", "=", "torch", ".", "view_as_complex", "(", "y", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "sensitivity_maps", "is", "None", "and", "not", "self", ".", "sens_net", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Sensitivity maps are required for PICS. \"", "\n", "\"Please set use_sens_net to True if you precomputed sensitivity maps are not available.\"", "\n", ")", "\n", "\n", "", "sensitivity_maps", "=", "torch", ".", "view_as_complex", "(", "sensitivity_maps", ")", "\n", "if", "self", ".", "fft_type", "!=", "\"orthogonal\"", ":", "\n", "            ", "sensitivity_maps", "=", "torch", ".", "fft", ".", "fftshift", "(", "sensitivity_maps", ",", "dim", "=", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "", "sensitivity_maps", "=", "sensitivity_maps", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "# type: ignore", "\n", "\n", "prediction", "=", "torch", ".", "from_numpy", "(", "self", ".", "forward", "(", "y", ",", "sensitivity_maps", ",", "mask", ",", "target", ")", ")", ".", "unsqueeze", "(", "0", ")", "\n", "if", "self", ".", "fft_type", "!=", "\"orthogonal\"", ":", "\n", "            ", "prediction", "=", "torch", ".", "fft", ".", "fftshift", "(", "prediction", ",", "dim", "=", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "\n", "", "slice_num", "=", "int", "(", "slice_num", ")", "\n", "name", "=", "str", "(", "fname", "[", "0", "]", ")", "# type: ignore", "\n", "key", "=", "f\"{name}_images_idx_{slice_num}\"", "# type: ignore", "\n", "output", "=", "torch", ".", "abs", "(", "prediction", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "target", "=", "torch", ".", "abs", "(", "target", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "output", "=", "output", "/", "output", ".", "max", "(", ")", "# type: ignore", "\n", "target", "=", "target", "/", "target", ".", "max", "(", ")", "# type: ignore", "\n", "error", "=", "torch", ".", "abs", "(", "target", "-", "output", ")", "\n", "self", ".", "log_image", "(", "f\"{key}/target\"", ",", "target", ")", "\n", "self", ".", "log_image", "(", "f\"{key}/reconstruction\"", ",", "output", ")", "\n", "self", ".", "log_image", "(", "f\"{key}/error\"", ",", "error", ")", "\n", "\n", "return", "name", ",", "slice_num", ",", "prediction", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.MockModel.__init__": [[51, 62], ["mridc.core.classes.modelPT.ModelPT.__init__", "torch.nn.Linear", "test_save_restore.MockModel.register_artifact", "open", "f.readlines"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.register_artifact"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "trainer", "=", "None", ")", ":", "\n", "        ", "super", "(", "MockModel", ",", "self", ")", ".", "__init__", "(", "cfg", "=", "cfg", ",", "trainer", "=", "trainer", ")", "\n", "self", ".", "w", "=", "torch", ".", "nn", ".", "Linear", "(", "10", ",", "1", ")", "\n", "# mock temp file", "\n", "if", "\"temp_file\"", "in", "self", ".", "cfg", "and", "self", ".", "cfg", ".", "temp_file", "is", "not", "None", ":", "\n", "            ", "self", ".", "temp_file", "=", "self", ".", "register_artifact", "(", "\"temp_file\"", ",", "self", ".", "cfg", ".", "temp_file", ")", "\n", "with", "open", "(", "self", ".", "temp_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "                ", "self", ".", "temp_data", "=", "f", ".", "readlines", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "temp_file", "=", "None", "\n", "self", ".", "temp_data", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.MockModel.forward": [[63, 66], ["test_save_restore.MockModel.w"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "y", "=", "self", ".", "w", "(", "x", ")", "\n", "return", "y", ",", "self", ".", "cfg", ".", "temp_file", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.MockModel.setup_training_data": [[67, 69], ["None"], "methods", ["None"], ["", "def", "setup_training_data", "(", "self", ",", "train_data_config", ":", "Union", "[", "DictConfig", ",", "Dict", "]", ")", ":", "\n", "        ", "self", ".", "_train_dl", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.MockModel.setup_validation_data": [[70, 72], ["None"], "methods", ["None"], ["", "def", "setup_validation_data", "(", "self", ",", "val_data_config", ":", "Union", "[", "DictConfig", ",", "Dict", "]", ")", ":", "\n", "        ", "self", ".", "_validation_dl", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.MockModel.setup_test_data": [[73, 75], ["None"], "methods", ["None"], ["", "def", "setup_test_data", "(", "self", ",", "test_data_config", ":", "Union", "[", "DictConfig", ",", "Dict", "]", ")", ":", "\n", "        ", "self", ".", "_test_dl", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.MockModel.list_available_models": [[76, 78], ["None"], "methods", ["None"], ["", "def", "list_available_models", "(", "cls", ")", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.TestSaveRestore.__test_restore_elsewhere": [[88, 135], ["tempfile.TemporaryDirectory", "os.path.exists", "model.__class__.restore_from", "tempfile.TemporaryDirectory", "os.path.join", "model.save_to", "os.path.join", "shutil.copy", "os.path.exists", "os.path.exists", "test_save_restore.getattr2", "test_save_restore.getattr2"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.restore_from", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.save_to", "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.getattr2", "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.getattr2"], ["    ", "def", "__test_restore_elsewhere", "(", "\n", "self", ",", "\n", "model", ":", "ModelPT", ",", "\n", "attr_for_eq_check", ":", "Set", "[", "str", "]", "=", "None", ",", "\n", "override_config_path", ":", "Optional", "[", "Union", "[", "str", ",", "DictConfig", "]", "]", "=", "None", ",", "\n", "map_location", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", "strict", ":", "bool", "=", "False", ",", "\n", "return_config", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Test's logic:\n        1. Save model into temporary folder (save_folder)\n        2. Copy .mridc file from save_folder to restore_folder\n        3. Delete save_folder\n        4. Attempt to restore from .mridc file in restore_folder and compare to original instance\n        \"\"\"", "\n", "# Create a new temporary directory", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "restore_folder", ":", "\n", "            ", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "save_folder", ":", "\n", "                ", "save_folder_path", "=", "save_folder", "\n", "# Where model will be saved", "\n", "model_save_path", "=", "os", ".", "path", ".", "join", "(", "save_folder", ",", "f\"{model.__class__.__name__}.mridc\"", ")", "\n", "model", ".", "save_to", "(", "save_path", "=", "model_save_path", ")", "\n", "# Where model will be restored from", "\n", "model_restore_path", "=", "os", ".", "path", ".", "join", "(", "restore_folder", ",", "f\"{model.__class__.__name__}.mridc\"", ")", "\n", "shutil", ".", "copy", "(", "model_save_path", ",", "model_restore_path", ")", "\n", "# at this point save_folder should not exist", "\n", "", "assert", "save_folder_path", "is", "not", "None", "and", "not", "os", ".", "path", ".", "exists", "(", "save_folder_path", ")", "\n", "assert", "not", "os", ".", "path", ".", "exists", "(", "model_save_path", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "model_restore_path", ")", "\n", "# attempt to restore", "\n", "model_copy", "=", "model", ".", "__class__", ".", "restore_from", "(", "\n", "restore_path", "=", "model_restore_path", ",", "\n", "map_location", "=", "map_location", ",", "\n", "strict", "=", "strict", ",", "\n", "return_config", "=", "return_config", ",", "\n", "override_config_path", "=", "override_config_path", ",", "\n", ")", "\n", "\n", "if", "return_config", ":", "\n", "                ", "return", "model_copy", "\n", "\n", "", "assert", "model", ".", "num_weights", "==", "model_copy", ".", "num_weights", "\n", "if", "attr_for_eq_check", "is", "not", "None", "and", "attr_for_eq_check", ":", "\n", "                ", "for", "attr", "in", "attr_for_eq_check", ":", "\n", "                    ", "assert", "getattr2", "(", "model", ",", "attr", ")", "==", "getattr2", "(", "model_copy", ",", "attr", ")", "\n", "\n", "", "", "return", "model_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.TestSaveRestore.test_mock_restore_from_config_override_with_OmegaConf": [[136, 167], ["tempfile.NamedTemporaryFile", "empty_file.writelines", "empty_file.flush", "test_save_restore._mock_model_config", "test_save_restore.MockModel", "model.to.to.to", "test_save_restore.TestSaveRestore.__test_restore_elsewhere", "diff.mean", "omegaconf.open_dict"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore._mock_model_config", "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.TestSaveRestore.__test_restore_elsewhere"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_mock_restore_from_config_override_with_OmegaConf", "(", "self", ")", ":", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", "\"w\"", ")", "as", "empty_file", ":", "\n", "# Write some data", "\n", "            ", "empty_file", ".", "writelines", "(", "[", "\"*****\\n\"", "]", ")", "\n", "empty_file", ".", "flush", "(", ")", "\n", "\n", "# Update config", "\n", "cfg", "=", "_mock_model_config", "(", ")", "\n", "cfg", ".", "model", ".", "temp_file", "=", "empty_file", ".", "name", "\n", "\n", "# Create model", "\n", "model", "=", "MockModel", "(", "cfg", "=", "cfg", ".", "model", ",", "trainer", "=", "None", ")", "\n", "model", "=", "model", ".", "to", "(", "\"cpu\"", ")", "\n", "\n", "assert", "model", ".", "temp_file", "==", "empty_file", ".", "name", "\n", "\n", "# Inject arbitrary config arguments (after creating model)", "\n", "with", "open_dict", "(", "cfg", ".", "model", ")", ":", "\n", "                ", "cfg", ".", "model", ".", "xyz", "=", "\"abc\"", "\n", "\n", "# Save test (with overriden config as OmegaConf object)", "\n", "", "model_copy", "=", "self", ".", "__test_restore_elsewhere", "(", "model", ",", "map_location", "=", "\"cpu\"", ",", "override_config_path", "=", "cfg", ")", "\n", "\n", "# Restore test", "\n", "", "diff", "=", "model", ".", "w", ".", "weight", "-", "model_copy", ".", "w", ".", "weight", "\n", "assert", "diff", ".", "mean", "(", ")", "<=", "1e-9", "\n", "assert", "model_copy", ".", "temp_data", "==", "[", "\"*****\\n\"", "]", "\n", "\n", "# Test that new config has arbitrary content", "\n", "assert", "model_copy", ".", "cfg", ".", "xyz", "==", "\"abc\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.TestSaveRestore.test_mock_restore_from_config_override_with_yaml": [[168, 205], ["tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile", "empty_file.writelines", "empty_file.flush", "test_save_restore._mock_model_config", "test_save_restore.MockModel", "model.to.to.to", "omegaconf.OmegaConf.save", "test_save_restore.TestSaveRestore.__test_restore_elsewhere", "filecmp.cmp", "omegaconf.open_dict", "diff.mean"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore._mock_model_config", "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.TestSaveRestore.__test_restore_elsewhere"], ["", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_mock_restore_from_config_override_with_yaml", "(", "self", ")", ":", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", "\"w\"", ")", "as", "empty_file", ",", "tempfile", ".", "NamedTemporaryFile", "(", "\"w\"", ")", "as", "config_file", ":", "\n", "# Write some data", "\n", "            ", "empty_file", ".", "writelines", "(", "[", "\"*****\\n\"", "]", ")", "\n", "empty_file", ".", "flush", "(", ")", "\n", "\n", "# Update config", "\n", "cfg", "=", "_mock_model_config", "(", ")", "\n", "cfg", ".", "model", ".", "temp_file", "=", "empty_file", ".", "name", "\n", "\n", "# Create model", "\n", "model", "=", "MockModel", "(", "cfg", "=", "cfg", ".", "model", ",", "trainer", "=", "None", ")", "\n", "model", "=", "model", ".", "to", "(", "\"cpu\"", ")", "\n", "\n", "assert", "model", ".", "temp_file", "==", "empty_file", ".", "name", "\n", "\n", "# Inject arbitrary config arguments (after creating model)", "\n", "with", "open_dict", "(", "cfg", ".", "model", ")", ":", "\n", "                ", "cfg", ".", "model", ".", "xyz", "=", "\"abc\"", "\n", "\n", "# Write new config into file", "\n", "", "OmegaConf", ".", "save", "(", "cfg", ",", "config_file", ")", "\n", "\n", "# Save test (with overriden config as OmegaConf object)", "\n", "model_copy", "=", "self", ".", "__test_restore_elsewhere", "(", "\n", "model", ",", "map_location", "=", "\"cpu\"", ",", "override_config_path", "=", "config_file", ".", "name", "\n", ")", "\n", "\n", "# Restore test", "\n", "diff", "=", "model", ".", "w", ".", "weight", "-", "model_copy", ".", "w", ".", "weight", "\n", "assert", "diff", ".", "mean", "(", ")", "<=", "1e-9", "\n", "assert", "filecmp", ".", "cmp", "(", "model", ".", "temp_file", ",", "model_copy", ".", "temp_file", ")", "\n", "assert", "model_copy", ".", "temp_data", "==", "[", "\"*****\\n\"", "]", "\n", "\n", "# Test that new config has arbitrary content", "\n", "assert", "model_copy", ".", "cfg", ".", "xyz", "==", "\"abc\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.TestSaveRestore.test_mock_save_to_multiple_times": [[206, 227], ["tempfile.NamedTemporaryFile", "tempfile.TemporaryDirectory", "empty_file.writelines", "empty_file.flush", "test_save_restore._mock_model_config", "test_save_restore.MockModel", "model.to.to.to", "model.to.to.save_to", "model.to.to.save_to", "model.to.to.save_to", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore._mock_model_config", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.save_to", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.save_to", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.save_to"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_mock_save_to_multiple_times", "(", "self", ")", ":", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", "\"w\"", ")", "as", "empty_file", ",", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "# Write some data", "\n", "            ", "empty_file", ".", "writelines", "(", "[", "\"*****\\n\"", "]", ")", "\n", "empty_file", ".", "flush", "(", ")", "\n", "\n", "# Update config", "\n", "cfg", "=", "_mock_model_config", "(", ")", "\n", "cfg", ".", "model", ".", "temp_file", "=", "empty_file", ".", "name", "\n", "\n", "# Create model", "\n", "model", "=", "MockModel", "(", "cfg", "=", "cfg", ".", "model", ",", "trainer", "=", "None", ")", "# type: MockModel", "\n", "model", "=", "model", ".", "to", "(", "\"cpu\"", ")", "\n", "\n", "assert", "model", ".", "temp_file", "==", "empty_file", ".", "name", "\n", "\n", "# Save test", "\n", "model", ".", "save_to", "(", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"save_0.mridc\"", ")", ")", "\n", "model", ".", "save_to", "(", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"save_1.mridc\"", ")", ")", "\n", "model", ".", "save_to", "(", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"save_2.mridc\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.TestSaveRestore.test_multiple_model_save_restore_connector": [[228, 249], ["tempfile.TemporaryDirectory", "test_save_restore._mock_model_config", "test_save_restore.MockModel", "test_save_restore.MockModel", "MySaveRestoreConnector", "MockModel.save_to", "os.path.exists", "isinstance", "isinstance", "save_path.replace.replace.replace", "super().save_to", "os.path.join", "os.path.join", "type"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore._mock_model_config", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.save_to", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.save_to"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_multiple_model_save_restore_connector", "(", "self", ")", ":", "\n", "        ", "class", "MySaveRestoreConnector", "(", "save_restore_connector", ".", "SaveRestoreConnector", ")", ":", "\n", "            ", "def", "save_to", "(", "self", ",", "model", ",", "save_path", ":", "str", ")", ":", "\n", "                ", "save_path", "=", "save_path", ".", "replace", "(", "\".mridc\"", ",", "\"_XYZ.mridc\"", ")", "\n", "super", "(", "MySaveRestoreConnector", ",", "self", ")", ".", "save_to", "(", "model", ",", "save_path", ")", "\n", "\n", "", "", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "# Update config", "\n", "            ", "cfg", "=", "_mock_model_config", "(", ")", "\n", "# Create model", "\n", "model", "=", "MockModel", "(", "cfg", "=", "cfg", ".", "model", ",", "trainer", "=", "None", ")", "\n", "model_with_custom_connector", "=", "MockModel", "(", "cfg", "=", "cfg", ".", "model", ",", "trainer", "=", "None", ")", "\n", "model_with_custom_connector", ".", "_save_restore_connector", "=", "MySaveRestoreConnector", "(", ")", "\n", "model_with_custom_connector", ".", "save_to", "(", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"save_custom.mridc\"", ")", ")", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"save_custom_XYZ.mridc\"", ")", ")", "\n", "assert", "isinstance", "(", "model", ".", "_save_restore_connector", ",", "save_restore_connector", ".", "SaveRestoreConnector", ")", "\n", "assert", "isinstance", "(", "model_with_custom_connector", ".", "_save_restore_connector", ",", "MySaveRestoreConnector", ")", "\n", "\n", "assert", "type", "(", "MockModel", ".", "_save_restore_connector", ")", "==", "save_restore_connector", ".", "SaveRestoreConnector", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.TestSaveRestore.test_restore_from_save_restore_connector": [[250, 277], ["tempfile.TemporaryDirectory", "test_save_restore._mock_model_config", "os.path.join", "test_save_restore.MockModel", "MySaveRestoreConnector", "MockModel.save_to", "os.path.exists", "MockModelV2.restore_from", "save_path.replace.replace.replace", "super().save_to", "os.path.join", "save_path.replace.replace.replace", "type", "type", "MySaveRestoreConnector"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore._mock_model_config", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.save_to", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.restore_from", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.save_to"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_restore_from_save_restore_connector", "(", "self", ")", ":", "\n", "        ", "class", "MySaveRestoreConnector", "(", "save_restore_connector", ".", "SaveRestoreConnector", ")", ":", "\n", "            ", "def", "save_to", "(", "self", ",", "model", ",", "save_path", ":", "str", ")", ":", "\n", "                ", "save_path", "=", "save_path", ".", "replace", "(", "\".mridc\"", ",", "\"_XYZ.mridc\"", ")", "\n", "super", "(", ")", ".", "save_to", "(", "model", ",", "save_path", ")", "\n", "\n", "", "", "class", "MockModelV2", "(", "MockModel", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "# Update config", "\n", "            ", "cfg", "=", "_mock_model_config", "(", ")", "\n", "\n", "# Create model", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"save_custom.mridc\"", ")", "\n", "model_with_custom_connector", "=", "MockModel", "(", "cfg", "=", "cfg", ".", "model", ",", "trainer", "=", "None", ")", "\n", "model_with_custom_connector", ".", "_save_restore_connector", "=", "MySaveRestoreConnector", "(", ")", "\n", "model_with_custom_connector", ".", "save_to", "(", "save_path", ")", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"save_custom_XYZ.mridc\"", ")", ")", "\n", "\n", "restored_model", "=", "MockModelV2", ".", "restore_from", "(", "\n", "save_path", ".", "replace", "(", "\".mridc\"", ",", "\"_XYZ.mridc\"", ")", ",", "save_restore_connector", "=", "MySaveRestoreConnector", "(", ")", "\n", ")", "\n", "assert", "type", "(", "restored_model", ")", "==", "MockModelV2", "\n", "assert", "type", "(", "restored_model", ".", "_save_restore_connector", ")", "==", "MySaveRestoreConnector", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.TestSaveRestore.test_mock_model_model_collision": [[278, 295], ["test_save_restore._mock_model_config", "test_save_restore.MockModel", "model.to.to.to", "test_save_restore._mock_model_config", "omegaconf.OmegaConf.set_struct", "omegaconf.OmegaConf.set_struct", "pytest.raises", "test_save_restore.MockModel", "model.to.to.to"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore._mock_model_config", "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore._mock_model_config"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_mock_model_model_collision", "(", "self", ")", ":", "\n", "# The usual pipeline is working just fine.", "\n", "        ", "cfg", "=", "_mock_model_config", "(", ")", "\n", "model", "=", "MockModel", "(", "cfg", "=", "cfg", ".", "model", ",", "trainer", "=", "None", ")", "# type: MockModel", "\n", "model", "=", "model", ".", "to", "(", "\"cpu\"", ")", "\n", "\n", "# Let's create a custom config with a 'model.model' node.", "\n", "cfg", "=", "_mock_model_config", "(", ")", "\n", "OmegaConf", ".", "set_struct", "(", "cfg", ",", "False", ")", "\n", "cfg", ".", "model", ".", "model", "=", "\"aaa\"", "\n", "OmegaConf", ".", "set_struct", "(", "cfg", ",", "True", ")", "\n", "\n", "# Failing due to collision.", "\n", "with", "pytest", ".", "raises", "(", "ValueError", ",", "match", "=", "\"Creating model config node is forbidden\"", ")", ":", "\n", "            ", "model", "=", "MockModel", "(", "cfg", "=", "cfg", ".", "model", ",", "trainer", "=", "None", ")", "# type: MockModel", "\n", "model", "=", "model", ".", "to", "(", "\"cpu\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.TestSaveRestore.test_restore_from_save_restore_connector_extracted_dir": [[296, 359], ["mridc.utils.app_state.AppState", "mridc.utils.app_state.AppState.get_model_metadata_from_guid", "mridc.utils.app_state.AppState.get_model_metadata_from_guid", "MockModel.to", "MockModelV2.restore_from.to", "MockModel.state_dict", "MockModelV2.restore_from.state_dict", "zip", "tempfile.TemporaryDirectory", "MockModelV2.restore_from", "type", "type", "os.path.exists", "MockModel.state_dict.keys", "MockModelV2.restore_from.state_dict.keys", "os.path.join.replace", "super().save_to", "tempfile.TemporaryDirectory", "test_save_restore._mock_model_config", "os.path.join", "test_save_restore.MockModel", "MySaveRestoreConnector", "MockModel.save_to", "os.path.join", "os.path.exists", "MySaveRestoreConnector", "MySaveRestoreConnector._unpack_mridc_file", "test_save_restore.get_size"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.get_model_metadata_from_guid", "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.get_model_metadata_from_guid", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.state_dict", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.state_dict", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.restore_from", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.save_to", "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore._mock_model_config", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.save_to", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._unpack_mridc_file", "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.get_size"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_restore_from_save_restore_connector_extracted_dir", "(", "self", ")", ":", "\n", "        ", "class", "MySaveRestoreConnector", "(", "save_restore_connector", ".", "SaveRestoreConnector", ")", ":", "\n", "            ", "def", "save_to", "(", "self", ",", "model", ",", "save_path", ":", "str", ")", ":", "\n", "                ", "save_path", "=", "save_path", ".", "replace", "(", "\".mridc\"", ",", "\"_XYZ.mridc\"", ")", "\n", "super", "(", ")", ".", "save_to", "(", "model", ",", "save_path", ")", "\n", "\n", "", "", "class", "MockModelV2", "(", "MockModel", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "extracted_tempdir", ":", "\n", "            ", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "# Update config", "\n", "                ", "cfg", "=", "_mock_model_config", "(", ")", "\n", "\n", "# Create model", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"save_custom.mridc\"", ")", "\n", "model_with_custom_connector", "=", "MockModel", "(", "cfg", "=", "cfg", ".", "model", ",", "trainer", "=", "None", ")", "\n", "model_with_custom_connector", ".", "_save_restore_connector", "=", "MySaveRestoreConnector", "(", ")", "\n", "model_with_custom_connector", ".", "save_to", "(", "save_path", ")", "\n", "\n", "mridc_filepath", "=", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "\"save_custom_XYZ.mridc\"", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "mridc_filepath", ")", "\n", "\n", "# extract the contents to this dir apriori", "\n", "# simulate by extracting now before calling restore_from", "\n", "connector", "=", "MySaveRestoreConnector", "(", ")", "\n", "MySaveRestoreConnector", ".", "_unpack_mridc_file", "(", "mridc_filepath", ",", "extracted_tempdir", ")", "\n", "assert", "get_size", "(", "extracted_tempdir", ")", ">", "0", "\n", "\n", "# delete the old directory and preserve only the new extracted directory (escape scope of old dir)", "\n", "\n", "# next, set the model's extracted directory path", "\n", "", "connector", ".", "model_extracted_dir", "=", "extracted_tempdir", "\n", "\n", "# note, we pass in the \"old\" mridc_filepath, stored somewhere other than the extracted directory", "\n", "# this mridc_filepath is no longer valid, and has been deleted.", "\n", "restored_model", "=", "MockModelV2", ".", "restore_from", "(", "mridc_filepath", ",", "save_restore_connector", "=", "connector", ")", "\n", "", "assert", "type", "(", "restored_model", ")", "==", "MockModelV2", "\n", "assert", "type", "(", "restored_model", ".", "_save_restore_connector", ")", "==", "MySaveRestoreConnector", "\n", "\n", "# assert models have correct restoration information and paths", "\n", "appstate", "=", "AppState", "(", ")", "\n", "original_metadata", "=", "appstate", ".", "get_model_metadata_from_guid", "(", "model_with_custom_connector", ".", "model_guid", ")", "\n", "assert", "original_metadata", ".", "restoration_path", "is", "None", "\n", "\n", "restored_metadata", "=", "appstate", ".", "get_model_metadata_from_guid", "(", "restored_model", ".", "model_guid", ")", "\n", "assert", "restored_metadata", ".", "restoration_path", "is", "not", "None", "\n", "\n", "# assert that the restore path was the path of the pre-extracted directory", "\n", "# irrespective of whether an old `mridc_filepath` (which doesnt exist anymore) was passed to restore_from.", "\n", "assert", "extracted_tempdir", "in", "restored_metadata", ".", "restoration_path", "\n", "assert", "extracted_tempdir", "not", "in", "mridc_filepath", "\n", "assert", "not", "os", ".", "path", ".", "exists", "(", "mridc_filepath", ")", "\n", "\n", "# test for parameter equality", "\n", "model_with_custom_connector", "=", "model_with_custom_connector", ".", "to", "(", "\"cpu\"", ")", "\n", "restored_model", "=", "restored_model", ".", "to", "(", "\"cpu\"", ")", "\n", "\n", "original_state_dict", "=", "model_with_custom_connector", ".", "state_dict", "(", ")", "\n", "restored_state_dict", "=", "restored_model", ".", "state_dict", "(", ")", "\n", "for", "orig", ",", "restored", "in", "zip", "(", "original_state_dict", ".", "keys", "(", ")", ",", "restored_state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "assert", "(", "original_state_dict", "[", "orig", "]", "-", "restored_state_dict", "[", "restored", "]", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", "<", "1e-6", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.classpath": [[21, 23], ["None"], "function", ["None"], ["def", "classpath", "(", "cls", ")", ":", "\n", "    ", "return", "f\"{cls.__module__}.{cls.__name__}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.get_dir_size": [[25, 34], ["os.scandir", "entry.is_file", "entry.is_dir", "entry.stat", "test_save_restore.get_dir_size"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.get_dir_size"], ["", "def", "get_dir_size", "(", "path", "=", "\".\"", ")", ":", "\n", "    ", "total", "=", "0", "\n", "with", "os", ".", "scandir", "(", "path", ")", "as", "it", ":", "\n", "        ", "for", "entry", "in", "it", ":", "\n", "            ", "if", "entry", ".", "is_file", "(", ")", ":", "\n", "                ", "total", "+=", "entry", ".", "stat", "(", ")", ".", "st_size", "\n", "", "elif", "entry", ".", "is_dir", "(", ")", ":", "\n", "                ", "total", "+=", "get_dir_size", "(", "entry", ".", "path", ")", "\n", "", "", "", "return", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.get_size": [[36, 41], ["os.path.isfile", "os.path.getsize", "os.path.isdir", "test_save_restore.get_dir_size"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.get_dir_size"], ["", "def", "get_size", "(", "path", "=", "\".\"", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "path", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "getsize", "(", "path", ")", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "path", ")", ":", "\n", "        ", "return", "get_dir_size", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.getattr2": [[43, 48], ["attr.split", "test_save_restore.getattr2", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.getattr2"], ["", "", "def", "getattr2", "(", "object", ",", "attr", ")", ":", "\n", "    ", "if", "\".\"", "not", "in", "attr", ":", "\n", "        ", "return", "getattr", "(", "object", ",", "attr", ")", "\n", "", "arr", "=", "attr", ".", "split", "(", "\".\"", ")", "\n", "return", "getattr2", "(", "getattr", "(", "object", ",", "arr", "[", "0", "]", ")", ",", "\".\"", ".", "join", "(", "arr", "[", "1", ":", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore._mock_model_config": [[80, 85], ["omegaconf.OmegaConf.create", "omegaconf.OmegaConf.set_struct", "test_save_restore.classpath"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_save_restore.classpath"], ["", "", "def", "_mock_model_config", "(", ")", ":", "\n", "    ", "conf", "=", "{", "\"temp_file\"", ":", "None", ",", "\"target\"", ":", "classpath", "(", "MockModel", ")", "}", "\n", "conf", "=", "OmegaConf", ".", "create", "(", "{", "\"model\"", ":", "conf", "}", ")", "\n", "OmegaConf", ".", "set_struct", "(", "conf", ",", "True", ")", "\n", "return", "conf", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_typecheck.recursive_assert_shape": [[9, 18], ["isinstance", "test_typecheck.recursive_assert_shape"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_typecheck.recursive_assert_shape"], ["def", "recursive_assert_shape", "(", "x", ",", "shape", ")", ":", "\n", "    ", "\"\"\"Perform recursive shape assert\"\"\"", "\n", "if", "isinstance", "(", "x", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "for", "xi", "in", "x", ":", "\n", "            ", "recursive_assert_shape", "(", "xi", ",", "shape", ")", "\n", "", "return", "\n", "\n", "", "if", "x", ".", "shape", "!=", "shape", ":", "\n", "        ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_typecheck.recursive_assert_homogeneous_type": [[20, 29], ["isinstance", "x.neural_type.compare", "test_typecheck.recursive_assert_homogeneous_type"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.compare", "home.repos.pwc.inspect_result.wdika_mridc.core.test_typecheck.recursive_assert_homogeneous_type"], ["", "", "def", "recursive_assert_homogeneous_type", "(", "x", ",", "type_val", ")", ":", "\n", "    ", "\"\"\"Perform recursive type homogeneous assert\"\"\"", "\n", "if", "isinstance", "(", "x", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "for", "xi", "in", "x", ":", "\n", "            ", "recursive_assert_homogeneous_type", "(", "xi", ",", "type_val", ")", "\n", "", "return", "\n", "\n", "", "if", "x", ".", "neural_type", ".", "compare", "(", "type_val", ")", "!=", "NeuralTypeComparisonResult", ".", "SAME", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_neural_types.TestNeuralTypeSystem.test_transpose_same_1": [[15, 22], ["mridc.core.neural_types.neural_type.NeuralType", "mridc.core.neural_types.neural_type.NeuralType", "mridc.core.neural_types.neural_type.NeuralType.compare", "mridc.core.neural_types.neural_type.NeuralType.compare"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.compare", "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.compare"], ["    ", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_transpose_same_1", "(", "self", ")", ":", "\n", "        ", "type1", "=", "NeuralType", "(", "axes", "=", "(", "\"B\"", ",", "\"T\"", ",", "\"C\"", ")", ")", "\n", "type2", "=", "NeuralType", "(", "axes", "=", "(", "\"T\"", ",", "\"B\"", ",", "\"C\"", ")", ")", "\n", "\n", "assert", "type1", ".", "compare", "(", "type2", ")", "==", "NeuralTypeComparisonResult", ".", "TRANSPOSE_SAME", "\n", "assert", "type2", ".", "compare", "(", "type1", ")", "==", "NeuralTypeComparisonResult", ".", "TRANSPOSE_SAME", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_neural_types.TestNeuralTypeSystem.test_singletone": [[23, 30], ["mridc.core.neural_types.neural_type.NeuralType", "mridc.core.neural_types.neural_type.NeuralType", "mridc.core.neural_types.neural_type.NeuralType.compare", "mridc.core.neural_types.neural_type.NeuralType.compare"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.compare", "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.compare"], ["", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_singletone", "(", "self", ")", ":", "\n", "        ", "loss_output1", "=", "NeuralType", "(", "axes", "=", "None", ")", "\n", "loss_output2", "=", "NeuralType", "(", "axes", "=", "None", ")", "\n", "\n", "assert", "loss_output1", ".", "compare", "(", "loss_output2", ")", "==", "NeuralTypeComparisonResult", ".", "SAME", "\n", "assert", "loss_output2", ".", "compare", "(", "loss_output1", ")", "==", "NeuralTypeComparisonResult", ".", "SAME", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_neural_types.TestNeuralTypeSystem.test_struct": [[31, 57], ["mridc.core.neural_types.neural_type.NeuralType", "mridc.core.neural_types.neural_type.NeuralType", "mridc.core.neural_types.neural_type.NeuralType.compare", "BoundingBox", "BadBoundingBox", "mridc.core.neural_types.axes.AxisType", "mridc.core.neural_types.axes.AxisType"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.compare"], ["", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_struct", "(", "self", ")", ":", "\n", "        ", "class", "BoundingBox", "(", "ElementType", ")", ":", "\n", "            ", "def", "__str__", "(", "self", ")", ":", "\n", "                ", "return", "\"bounding box from detection model\"", "\n", "\n", "", "def", "fields", "(", "self", ")", ":", "\n", "                ", "return", "(", "\"X\"", ",", "\"Y\"", ",", "\"W\"", ",", "\"H\"", ")", "\n", "\n", "", "", "T1", "=", "NeuralType", "(", "\n", "elements_type", "=", "BoundingBox", "(", ")", ",", "\n", "axes", "=", "(", "AxisType", "(", "kind", "=", "AxisKind", ".", "Batch", ",", "size", "=", "None", ",", "is_list", "=", "True", ")", ",", ")", ",", "\n", ")", "\n", "\n", "class", "BadBoundingBox", "(", "ElementType", ")", ":", "\n", "            ", "def", "__str__", "(", "self", ")", ":", "\n", "                ", "return", "\"bad bounding box from detection model\"", "\n", "\n", "", "def", "fields", "(", "self", ")", ":", "\n", "                ", "return", "(", "\"X\"", ",", "\"Y\"", ",", "\"H\"", ")", "\n", "\n", "", "", "T2", "=", "NeuralType", "(", "\n", "elements_type", "=", "BadBoundingBox", "(", ")", ",", "\n", "axes", "=", "(", "AxisType", "(", "kind", "=", "AxisKind", ".", "Batch", ",", "size", "=", "None", ",", "is_list", "=", "True", ")", ",", ")", ",", "\n", ")", "\n", "assert", "T2", ".", "compare", "(", "T1", ")", "==", "NeuralTypeComparisonResult", ".", "INCOMPATIBLE", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_config_utils.TestConfigUtils.test_all_args_exist": [[30, 52], ["mridc.utils.config_utils.assert_dataclass_signature_match"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.config_utils.assert_dataclass_signature_match"], ["@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_all_args_exist", "(", "self", ",", "cls", ")", ":", "\n", "        ", "\"\"\"Test that all arguments exist in the dataclass.\"\"\"", "\n", "\n", "@", "dataclass", "\n", "class", "DummyDataClass", ":", "\n", "            ", "\"\"\"Dummy data class.\"\"\"", "\n", "\n", "a", ":", "int", "=", "-", "1", "\n", "b", ":", "int", "=", "5", "\n", "c", ":", "int", "=", "0", "\n", "d", ":", "Any", "=", "None", "\n", "\n", "", "result", "=", "config_utils", ".", "assert_dataclass_signature_match", "(", "cls", ",", "DummyDataClass", ")", "\n", "signatures_match", ",", "cls_subset", ",", "dataclass_subset", "=", "result", "\n", "\n", "if", "not", "signatures_match", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "cls_subset", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "dataclass_subset", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_config_utils.TestConfigUtils.test_extra_args_exist_but_is_ignored": [[53, 75], ["mridc.utils.config_utils.assert_dataclass_signature_match"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.config_utils.assert_dataclass_signature_match"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_extra_args_exist_but_is_ignored", "(", "self", ",", "cls", ")", ":", "\n", "        ", "\"\"\"Test that extra arguments exist in the dataclass.\"\"\"", "\n", "\n", "@", "dataclass", "\n", "class", "DummyDataClass", ":", "\n", "            ", "\"\"\"Dummy data class.\"\"\"", "\n", "\n", "a", ":", "int", "=", "-", "1", "\n", "b", ":", "int", "=", "5", "\n", "c", ":", "int", "=", "0", "\n", "d", ":", "Any", "=", "None", "\n", "\n", "", "result", "=", "config_utils", ".", "assert_dataclass_signature_match", "(", "cls", ",", "DummyDataClass", ",", "ignore_args", "=", "[", "\"e\"", "]", ")", "\n", "signatures_match", ",", "cls_subset", ",", "dataclass_subset", "=", "result", "\n", "\n", "if", "not", "signatures_match", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "cls_subset", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "dataclass_subset", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_config_utils.TestConfigUtils.test_args_exist_but_is_remapped": [[76, 98], ["mridc.utils.config_utils.assert_dataclass_signature_match"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.config_utils.assert_dataclass_signature_match"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_args_exist_but_is_remapped", "(", "self", ",", "cls", ")", ":", "\n", "        ", "\"\"\"Test that arguments exist in the dataclass but are remapped.\"\"\"", "\n", "\n", "@", "dataclass", "\n", "class", "DummyDataClass", ":", "\n", "            ", "\"\"\"Dummy data class.\"\"\"", "\n", "\n", "a", ":", "int", "=", "-", "1", "\n", "b", ":", "int", "=", "5", "\n", "c", ":", "int", "=", "0", "\n", "e", ":", "Any", "=", "None", "# Assume remapped", "\n", "\n", "", "result", "=", "config_utils", ".", "assert_dataclass_signature_match", "(", "cls", ",", "DummyDataClass", ",", "remap_args", "=", "{", "\"e\"", ":", "\"d\"", "}", ")", "\n", "signatures_match", ",", "cls_subset", ",", "dataclass_subset", "=", "result", "\n", "\n", "if", "not", "signatures_match", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "cls_subset", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "dataclass_subset", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_config_utils.cls": [[14, 25], ["pytest.fixture"], "function", ["None"], ["@", "pytest", ".", "fixture", "(", ")", "\n", "def", "cls", "(", ")", ":", "\n", "    ", "\"\"\"Create a class with a config attribute.\"\"\"", "\n", "\n", "class", "DummyClass", ":", "\n", "        ", "\"\"\"Dummy class.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "a", ",", "b", "=", "5", ",", "c", ":", "int", "=", "0", ",", "d", ":", "\"ABC\"", "=", "None", ")", ":", "\n", "            ", "pass", "\n", "\n", "", "", "return", "DummyClass", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.MyTestOptimizer.__init__": [[27, 30], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "_step", "=", "0", "\n", "super", "(", ")", ".", "__init__", "(", "params", ",", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.MyTestOptimizer.step": [[31, 47], ["torch.no_grad", "torch.enable_grad", "closure", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "enable_grad", "(", ")", ":", "\n", "                ", "loss", "=", "closure", "(", ")", "\n", "", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "self", ".", "_step", "==", "0", ":", "\n", "                    ", "p", ".", "data", "=", "0.1", "*", "torch", ".", "ones", "(", "p", ".", "shape", ")", "\n", "", "elif", "self", ".", "_step", "==", "1", ":", "\n", "                    ", "p", ".", "data", "=", "0.0", "*", "torch", ".", "ones", "(", "p", ".", "shape", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", "=", "0.01", "*", "torch", ".", "ones", "(", "p", ".", "shape", ")", "\n", "", "", "", "self", ".", "_step", "+=", "1", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.DoNothingOptimizer.__init__": [[50, 53], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "_step", "=", "0", "\n", "super", "(", ")", ".", "__init__", "(", "params", ",", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.DoNothingOptimizer.step": [[54, 62], ["torch.no_grad", "torch.enable_grad", "closure"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "enable_grad", "(", ")", ":", "\n", "                ", "loss", "=", "closure", "(", ")", "\n", "", "", "self", ".", "_step", "+=", "1", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.OnesDataset.__init__": [[65, 68], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dataset_len", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "__dataset_len", "=", "dataset_len", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.OnesDataset.__getitem__": [[69, 71], ["torch.ones"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "torch", ".", "ones", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.OnesDataset.__len__": [[72, 74], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__dataset_len", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.ExampleModel.__init__": [[77, 82], ["omegaconf.OmegaConf.structured", "mridc.core.classes.modelPT.ModelPT.__init__", "pytorch_lightning.seed_everything", "torch.nn.modules.Linear"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "cfg", "=", "OmegaConf", ".", "structured", "(", "{", "}", ")", "\n", "super", "(", ")", ".", "__init__", "(", "cfg", ")", "\n", "pl", ".", "seed_everything", "(", "1234", ")", "\n", "self", ".", "l1", "=", "torch", ".", "nn", ".", "modules", ".", "Linear", "(", "in_features", "=", "2", ",", "out_features", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.ExampleModel.train_dataloader": [[83, 86], ["test_exp_manager.OnesDataset", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "dataset", "=", "OnesDataset", "(", "2", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.ExampleModel.val_dataloader": [[87, 90], ["test_exp_manager.OnesDataset", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "dataset", "=", "OnesDataset", "(", "10", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.ExampleModel.forward": [[91, 95], ["test_exp_manager.ExampleModel.l1", "torch.nn.functional.l1_loss", "torch.zeros().to", "torch.zeros", "torch.nn.functional.l1_loss.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "output", "=", "self", ".", "l1", "(", "batch", ")", "\n", "output", "=", "torch", ".", "nn", ".", "functional", ".", "l1_loss", "(", "output", ",", "torch", ".", "zeros", "(", "output", ".", "size", "(", ")", ")", ".", "to", "(", "output", ".", "device", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.ExampleModel.validation_step": [[96, 98], ["test_exp_manager.ExampleModel."], "methods", ["None"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "return", "self", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.ExampleModel.training_step": [[99, 101], ["test_exp_manager.ExampleModel."], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "return", "self", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.ExampleModel.configure_optimizers": [[102, 104], ["test_exp_manager.MyTestOptimizer", "test_exp_manager.ExampleModel.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "MyTestOptimizer", "(", "self", ".", "parameters", "(", ")", ")", "\n", "# return torch.optim.Adam(self.parameters(), lr=0.1)", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.ExampleModel.list_available_models": [[106, 108], ["None"], "methods", ["None"], ["", "def", "list_available_models", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.ExampleModel.setup_training_data": [[109, 111], ["None"], "methods", ["None"], ["", "def", "setup_training_data", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.ExampleModel.setup_validation_data": [[112, 114], ["None"], "methods", ["None"], ["", "def", "setup_validation_data", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.ExampleModel.validation_epoch_end": [[115, 117], ["test_exp_manager.ExampleModel.log", "torch.stack().mean", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "loss", ")", ":", "\n", "        ", "self", ".", "log", "(", "\"val_loss\"", ",", "torch", ".", "stack", "(", "loss", ")", ".", "mean", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.DoNothingModel.configure_optimizers": [[120, 122], ["test_exp_manager.DoNothingOptimizer", "test_exp_manager.DoNothingModel.parameters"], "methods", ["None"], ["    ", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "DoNothingOptimizer", "(", "self", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.TestExpManager.test_omegaconf": [[125, 136], ["pytest.raises", "mridc.utils.exp_manager.exp_manager", "pytorch_lightning.Trainer"], "methods", ["None"], ["    ", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_omegaconf", "(", "self", ")", ":", "\n", "        ", "\"\"\"Ensure omegaconf raises an error when an unexcepted argument is passed\"\"\"", "\n", "with", "pytest", ".", "raises", "(", "OmegaConfBaseException", ")", ":", "\n", "            ", "exp_manager", "(", "\n", "pl", ".", "Trainer", "(", "\n", "accelerator", "=", "\"cpu\"", ",", "\n", "max_epochs", "=", "1", ",", "\n", "devices", "=", "1", ",", "\n", ")", ",", "\n", "{", "\"unused\"", ":", "1", "}", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_exp_manager.TestExpManager.test_mridc_checkpoint_restore_model": [[138, 150], ["pytorch_lightning.Trainer", "test_exp_manager.ExampleModel", "pytorch_lightning.Trainer.fit", "pytorch_lightning.Trainer", "test_exp_manager.DoNothingModel", "torch.nn.Parameter", "torch.nn.Parameter", "pytorch_lightning.Trainer.fit", "torch.tensor().unsqueeze", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_mridc_checkpoint_restore_model", "(", "self", ",", "tmp_path", ")", ":", "\n", "        ", "\"\"\"Ensure that the model is restored correctly when a checkpoint is provided\"\"\"", "\n", "test_trainer", "=", "pl", ".", "Trainer", "(", "accelerator", "=", "\"cpu\"", ",", "enable_checkpointing", "=", "False", ",", "logger", "=", "False", ",", "max_epochs", "=", "4", ")", "\n", "model", "=", "ExampleModel", "(", ")", "\n", "test_trainer", ".", "fit", "(", "model", ")", "\n", "\n", "test_trainer", "=", "pl", ".", "Trainer", "(", "accelerator", "=", "\"cpu\"", ",", "enable_checkpointing", "=", "False", ",", "logger", "=", "False", ",", "max_epochs", "=", "5", ")", "\n", "model", "=", "DoNothingModel", "(", ")", "\n", "model", ".", "l1", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "(", "0.0", ",", "0.0", ")", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "model", ".", "l1", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "1.0", ")", ")", "\n", "test_trainer", ".", "fit", "(", "model", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TempModel.__init__": [[32, 35], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "TempModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer", "=", "torch", ".", "nn", ".", "Linear", "(", "5", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TempModel.forward": [[36, 40], ["test_optimizers_schedulers.TempModel.layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Forward pass.\"\"\"", "\n", "x", "=", "self", ".", "layer", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.OptCounter.__init__": [[45, 49], ["super().__init__", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", ".", "setdefault", "(", "\"count\"", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.OptCounter.step": [[50, 55], ["super().step"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step"], ["", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\"\"\"", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", "[", "\"count\"", "]", "+=", "1", "\n", "", "super", "(", ")", ".", "step", "(", "closure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.RandomDataset.__init__": [[60, 63], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "dataset_len", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "__dataset_len", "=", "dataset_len", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.RandomDataset.__getitem__": [[64, 66], ["torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "torch", ".", "randn", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.RandomDataset.__len__": [[67, 69], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__dataset_len", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.ExampleModel.__init__": [[74, 83], ["super().__init__", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.Linear", "torch.nn.modules.Linear"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "dataset_len", ",", "drop_last", ",", "max_steps", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "l1", "=", "torch", ".", "nn", ".", "modules", ".", "Linear", "(", "in_features", "=", "2", ",", "out_features", "=", "1", ")", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "dataset_len", "=", "dataset_len", "\n", "self", ".", "drop_last", "=", "drop_last", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "\n", "self", ".", "my_opt", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.ExampleModel.train_dataloader": [[84, 88], ["test_optimizers_schedulers.RandomDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return a training data loader.\"\"\"", "\n", "dataset", "=", "RandomDataset", "(", "self", ".", "dataset_len", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "self", ".", "batch_size", ",", "drop_last", "=", "self", ".", "drop_last", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.ExampleModel.training_step": [[89, 94], ["test_optimizers_schedulers.ExampleModel.l1", "torch.nn.functional.l1_loss", "torch.nn.functional.l1_loss", "torch.nn.functional.l1_loss", "torch.nn.functional.l1_loss", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.nn.functional.l1_loss.size", "torch.nn.functional.l1_loss.size"], "methods", ["None"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "\"\"\"Set training step.\"\"\"", "\n", "output", "=", "self", ".", "l1", "(", "batch", ")", "\n", "output", "=", "torch", ".", "nn", ".", "functional", ".", "l1_loss", "(", "output", ",", "torch", ".", "ones", "(", "output", ".", "size", "(", ")", ")", ".", "to", "(", "output", ".", "device", ")", ")", "\n", "return", "{", "\"loss\"", ":", "output", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.ExampleModel.configure_optimizers": [[95, 99], ["test_optimizers_schedulers.OptCounter", "test_optimizers_schedulers.ExampleModel.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Configure optimizers for the model.\"\"\"", "\n", "self", ".", "my_opt", "=", "OptCounter", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "0.02", ")", "\n", "return", "self", ".", "my_opt", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.Callback.on_train_end": [[104, 120], ["test_optimizers_schedulers.Callback.assert_counts", "mridc.utils.logging.debug", "mridc.utils.logging.debug", "mridc.utils.logging.debug", "mridc.utils.logging.debug", "mridc.utils.logging.debug", "mridc.utils.logging.debug", "mridc.utils.logging.debug", "mridc.utils.logging.debug", "mridc.utils.logging.debug", "len"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.SchedulerNoOpCallback.assert_counts", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.debug", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.debug", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.debug", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.debug", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.debug", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.debug", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.debug", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.debug", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.debug"], ["@", "pl", ".", "utilities", ".", "distributed", ".", "rank_zero_only", "\n", "def", "on_train_end", "(", "self", ",", "trainer", ",", "module", ")", ":", "\n", "        ", "\"\"\"On train end, check that the number of steps is correct\"\"\"", "\n", "count", "=", "module", ".", "my_opt", ".", "param_groups", "[", "0", "]", "[", "\"count\"", "]", "\n", "if", "trainer", ".", "global_step", "!=", "count", "or", "trainer", ".", "global_step", "!=", "module", ".", "max_steps", ":", "\n", "            ", "logging", ".", "debug", "(", "f\"max_epochs: {trainer.max_epochs}\"", ")", "\n", "logging", ".", "debug", "(", "f\"accumulate_grad_batches: {trainer.accumulate_grad_batches}\"", ")", "\n", "logging", ".", "debug", "(", "f\"limit_train_batches: {trainer.limit_train_batches}\"", ")", "\n", "logging", ".", "debug", "(", "f\"num_processes: {trainer.num_processes}\"", ")", "\n", "logging", ".", "debug", "(", "f\"batch_size: {module.batch_size}\"", ")", "\n", "logging", ".", "debug", "(", "f\"dataset_len: {module.dataset_len}\"", ")", "\n", "logging", ".", "debug", "(", "f\"drop_last: {module.drop_last}\"", ")", "\n", "logging", ".", "debug", "(", "f\"{len(trainer.train_dataloader)}\"", ")", "\n", "logging", ".", "debug", "(", "f\"{trainer.num_training_batches}\"", ")", "\n", "\n", "", "self", ".", "assert_counts", "(", "trainer", ",", "module", ",", "count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.Callback.assert_counts": [[121, 128], ["AssertionError", "AssertionError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "assert_counts", "(", "trainer", ",", "module", ",", "count", ")", ":", "\n", "        ", "\"\"\"Assert that the number of steps is correct\"\"\"", "\n", "if", "trainer", ".", "global_step", "!=", "count", ":", "\n", "            ", "raise", "AssertionError", "(", "f\"{trainer.global_step} != {count} != {module.max_steps}\"", ")", "\n", "", "if", "trainer", ".", "global_step", "!=", "module", ".", "max_steps", ":", "\n", "            ", "raise", "AssertionError", "(", "f\"{trainer.global_step} != {count} != {module.max_steps}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.SchedulerNoOpCallback.on_train_batch_end": [[133, 148], ["scheduler[].step"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step"], ["@", "staticmethod", "\n", "def", "on_train_batch_end", "(", "trainer", ":", "pl", ".", "Trainer", ",", "pl_module", ",", "outputs", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "\"\"\"On each training batch end\"\"\"", "\n", "# pl_module.max_steps is \"original\" max steps without trainer extra steps.", "\n", "if", "(", "trainer", ".", "global_step", "+", "1", ")", "%", "3", "==", "0", "and", "(", "trainer", ".", "global_step", "+", "1", ")", "<", "pl_module", ".", "max_steps", ":", "\n", "            ", "schedulers", "=", "trainer", ".", "lr_schedulers", "\n", "\n", "for", "scheduler", "in", "schedulers", ":", "\n", "# Decrement the counter by 2, then perform a scheduler.step() to perform a no-up", "\n", "# as well as update the optimizer lr in all param groups", "\n", "                ", "scheduler", "[", "\"scheduler\"", "]", ".", "last_epoch", "-=", "2", "\n", "scheduler", "[", "\"scheduler\"", "]", ".", "step", "(", ")", "\n", "\n", "# Increase the max step count by 1", "\n", "", "trainer", ".", "fit_loop", ".", "max_steps", "=", "trainer", ".", "fit_loop", ".", "max_steps", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.SchedulerNoOpCallback.assert_counts": [[149, 157], ["torch.div", "torch.div", "torch.div", "torch.div", "AssertionError", "AssertionError"], "methods", ["None"], ["", "", "def", "assert_counts", "(", "self", ",", "trainer", ",", "module", ",", "count", ")", ":", "\n", "        ", "\"\"\"This is a no-op callback, so the counts should not change\"\"\"", "\n", "num_skips", "=", "torch", ".", "div", "(", "module", ".", "max_steps", ",", "3", ",", "rounding_mode", "=", "\"trunc\"", ")", "\n", "extra_steps", "=", "module", ".", "max_steps", "+", "num_skips", "\n", "if", "trainer", ".", "global_step", "!=", "count", ":", "\n", "            ", "raise", "AssertionError", "(", "f\"{trainer.global_step} != {count} != {extra_steps}\"", ")", "\n", "", "if", "trainer", ".", "global_step", "!=", "extra_steps", ":", "\n", "            ", "raise", "AssertionError", "(", "f\"{trainer.global_step} != {count} != {extra_steps}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_get_optimizer": [[167, 184], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.optimizers.get_optimizer.", "isinstance", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "TempModel.parameters", "TempModel.parameters"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer"], ["@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_get_optimizer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test that the optimizer is correctly created\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "\n", "for", "opt_name", "in", "AVAILABLE_OPTIMIZERS", ":", "\n", "            ", "if", "opt_name", "==", "\"fused_adam\"", "and", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "continue", "\n", "", "opt_cls", "=", "get_optimizer", "(", "opt_name", ")", "\n", "if", "opt_name", "==", "\"adafactor\"", ":", "\n", "# Adafactor's default mode uses relative_step without any lr.", "\n", "                ", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "opt", ",", "AVAILABLE_OPTIMIZERS", "[", "opt_name", "]", ")", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_register_optimizer": [[185, 203], ["mridc.core.optim.optimizers.register_optimizer", "test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "TempModel.parameters", "isinstance"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.register_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer"], ["", "", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_register_optimizer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test that we can register a new optimizer\"\"\"", "\n", "\n", "class", "TempOpt", "(", "torch", ".", "optim", ".", "SGD", ")", ":", "\n", "            ", "\"\"\"A dummy optimizer\"\"\"", "\n", "\n", "", "class", "TempOptParams", "(", "optimizers", ".", "SGDParams", ")", ":", "\n", "            ", "\"\"\"A dummy optimizer params\"\"\"", "\n", "\n", "", "register_optimizer", "(", "\"TempOpt\"", ",", "TempOpt", ",", "TempOptParams", ")", "\n", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"TempOpt\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "if", "not", "isinstance", "(", "opt", ",", "TempOpt", ")", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_optim_config_parse_bypass": [[204, 224], ["mridc.core.optim.optimizers.parse_optimizer_args", "omegaconf.OmegaConf.create", "mridc.core.optim.optimizers.parse_optimizer_args"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.parse_optimizer_args", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.parse_optimizer_args"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_optim_config_parse_bypass", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test that the optimizer config is parsed correctly when the optimizer is not registered.\"\"\"", "\n", "basic_optim_config", "=", "{", "\"weight_decay\"", ":", "0.001", ",", "\"betas\"", ":", "[", "0.8", ",", "0.5", "]", "}", "\n", "parsed_params", "=", "parse_optimizer_args", "(", "\"novograd\"", ",", "basic_optim_config", ")", "\n", "if", "parsed_params", "[", "\"weight_decay\"", "]", "!=", "basic_optim_config", "[", "\"weight_decay\"", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "parsed_params", "[", "\"betas\"", "]", "[", "0", "]", "!=", "basic_optim_config", "[", "\"betas\"", "]", "[", "0", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "parsed_params", "[", "\"betas\"", "]", "[", "1", "]", "!=", "basic_optim_config", "[", "\"betas\"", "]", "[", "1", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "dict_config", "=", "omegaconf", ".", "OmegaConf", ".", "create", "(", "basic_optim_config", ")", "\n", "parsed_params", "=", "parse_optimizer_args", "(", "\"novograd\"", ",", "dict_config", ")", "\n", "if", "parsed_params", "[", "\"weight_decay\"", "]", "!=", "dict_config", "[", "\"weight_decay\"", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "parsed_params", "[", "\"betas\"", "]", "[", "0", "]", "!=", "dict_config", "[", "\"betas\"", "]", "[", "0", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "parsed_params", "[", "\"betas\"", "]", "[", "1", "]", "!=", "dict_config", "[", "\"betas\"", "]", "[", "1", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_optim_config_parse_arg_by_target": [[225, 260], ["omegaconf.OmegaConf.create", "mridc.core.optim.optimizers.parse_optimizer_args", "omegaconf.OmegaConf.create", "mridc.core.optim.optimizers.parse_optimizer_args", "mridc.core.optim.optimizers.parse_optimizer_args", "vars", "vars", "mridc.core.conf.optimizers.SGDParams", "mridc.core.conf.optimizers.NovogradParams", "set", "set", "set", "set", "mridc.core.optim.optimizers.parse_optimizer_args.keys", "vars.keys", "mridc.core.optim.optimizers.parse_optimizer_args.keys"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.parse_optimizer_args", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.parse_optimizer_args", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.parse_optimizer_args"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_optim_config_parse_arg_by_target", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test that the optimizer config is parsed correctly by target.\"\"\"", "\n", "basic_optim_config", "=", "{", "\n", "\"_target_\"", ":", "\"mridc.core.conf.optimizers.NovogradParams\"", ",", "\n", "\"params\"", ":", "{", "\"weight_decay\"", ":", "0.001", ",", "\"betas\"", ":", "[", "0.8", ",", "0.5", "]", "}", ",", "\n", "}", "\n", "basic_optim_config", "=", "omegaconf", ".", "OmegaConf", ".", "create", "(", "basic_optim_config", ")", "\n", "parsed_params", "=", "parse_optimizer_args", "(", "\"novograd\"", ",", "basic_optim_config", ")", "\n", "if", "parsed_params", "[", "\"weight_decay\"", "]", "!=", "basic_optim_config", "[", "\"params\"", "]", "[", "\"weight_decay\"", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "parsed_params", "[", "\"betas\"", "]", "[", "0", "]", "!=", "basic_optim_config", "[", "\"params\"", "]", "[", "\"betas\"", "]", "[", "0", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "parsed_params", "[", "\"betas\"", "]", "[", "1", "]", "!=", "basic_optim_config", "[", "\"params\"", "]", "[", "\"betas\"", "]", "[", "1", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "dict_config", "=", "omegaconf", ".", "OmegaConf", ".", "create", "(", "basic_optim_config", ")", "\n", "parsed_params", "=", "parse_optimizer_args", "(", "\"novograd\"", ",", "dict_config", ")", "\n", "if", "parsed_params", "[", "\"weight_decay\"", "]", "!=", "dict_config", "[", "\"params\"", "]", "[", "\"weight_decay\"", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "parsed_params", "[", "\"betas\"", "]", "[", "0", "]", "!=", "dict_config", "[", "\"params\"", "]", "[", "\"betas\"", "]", "[", "0", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "parsed_params", "[", "\"betas\"", "]", "[", "1", "]", "!=", "dict_config", "[", "\"params\"", "]", "[", "\"betas\"", "]", "[", "1", "]", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Names are ignored when passing class path", "\n", "# This will be captured during optimizer instantiation", "\n", "", "output_config", "=", "parse_optimizer_args", "(", "\"sgd\"", ",", "dict_config", ")", "\n", "sgd_config", "=", "vars", "(", "SGDParams", "(", ")", ")", "\n", "novograd_config", "=", "vars", "(", "NovogradParams", "(", ")", ")", "\n", "\n", "if", "set", "(", "output_config", ".", "keys", "(", ")", ")", "==", "set", "(", "sgd_config", ".", "keys", "(", ")", ")", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "if", "set", "(", "output_config", ".", "keys", "(", ")", ")", "!=", "set", "(", "novograd_config", ")", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_get_scheduler": [[261, 285], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.novograd.Novograd", "TempModel.parameters", "mridc.core.optim.lr_scheduler.get_scheduler", "mridc.core.optim.lr_scheduler.get_scheduler.", "mridc.core.optim.lr_scheduler.get_scheduler.", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.get_scheduler"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_get_scheduler", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test that get_scheduler returns the correct scheduler class.\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "optimizer", "=", "Novograd", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "for", "sched_name", "in", "AVAILABLE_SCHEDULERS", ":", "\n", "            ", "sched_cls", "=", "optim", ".", "lr_scheduler", ".", "get_scheduler", "(", "sched_name", ")", "\n", "\n", "try", ":", "\n", "                ", "sched", "=", "sched_cls", "(", "optimizer", ")", "\n", "if", "not", "isinstance", "(", "sched", ",", "AVAILABLE_SCHEDULERS", "[", "sched_name", "]", ")", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "continue", "\n", "", "except", "Exception", ":", "\n", "                ", "pass", "\n", "\n", "", "try", ":", "\n", "                ", "sched", "=", "sched_cls", "(", "optimizer", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ")", "\n", "if", "not", "isinstance", "(", "sched", ",", "AVAILABLE_SCHEDULERS", "[", "sched_name", "]", ")", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "continue", "\n", "", "except", "Exception", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_register_scheduler": [[286, 306], ["mridc.core.optim.lr_scheduler.register_scheduler", "test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.get_scheduler", "mridc.core.optim.lr_scheduler.get_scheduler.", "TempModel.parameters", "isinstance"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.register_scheduler", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.get_scheduler"], ["", "", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_register_scheduler", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test registering a new scheduler\"\"\"", "\n", "\n", "class", "TempSched", "(", "optim", ".", "lr_scheduler", ".", "CosineAnnealing", ")", ":", "\n", "            ", "\"\"\"Temporary scheduler class.\"\"\"", "\n", "\n", "", "class", "TempSchedParams", "(", "CosineAnnealingParams", ")", ":", "\n", "            ", "\"\"\"Temporary scheduler class.\"\"\"", "\n", "\n", "", "optim", ".", "lr_scheduler", ".", "register_scheduler", "(", "\"TempSched\"", ",", "TempSched", ",", "TempSchedParams", ")", "\n", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "sched_cls", "=", "optim", ".", "lr_scheduler", ".", "get_scheduler", "(", "\"TempSched\"", ")", "\n", "sched", "=", "sched_cls", "(", "opt", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ")", "\n", "\n", "if", "not", "isinstance", "(", "sched", ",", "TempSched", ")", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_sched_config_parse_simple": [[307, 323], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.prepare_lr_scheduler", "omegaconf.OmegaConf.create", "mridc.core.optim.lr_scheduler.prepare_lr_scheduler", "TempModel.parameters", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.prepare_lr_scheduler", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.prepare_lr_scheduler"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_sched_config_parse_simple", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test that scheduler config is parsed correctly\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "basic_sched_config", "=", "{", "\"name\"", ":", "\"CosineAnnealing\"", ",", "\"max_steps\"", ":", "10", "}", "\n", "scheduler_setup", "=", "optim", ".", "lr_scheduler", ".", "prepare_lr_scheduler", "(", "opt", ",", "basic_sched_config", ")", "\n", "if", "not", "isinstance", "(", "scheduler_setup", "[", "\"scheduler\"", "]", ",", "optim", ".", "lr_scheduler", ".", "CosineAnnealing", ")", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "dict_config", "=", "omegaconf", ".", "OmegaConf", ".", "create", "(", "basic_sched_config", ")", "\n", "scheduler_setup", "=", "optim", ".", "lr_scheduler", ".", "prepare_lr_scheduler", "(", "opt", ",", "dict_config", ")", "\n", "if", "not", "isinstance", "(", "scheduler_setup", "[", "\"scheduler\"", "]", ",", "optim", ".", "lr_scheduler", ".", "CosineAnnealing", ")", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_sched_config_parse_from_cls": [[324, 344], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.prepare_lr_scheduler", "omegaconf.OmegaConf.create", "mridc.core.optim.lr_scheduler.prepare_lr_scheduler", "TempModel.parameters", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.prepare_lr_scheduler", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.prepare_lr_scheduler"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_sched_config_parse_from_cls", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test that we can parse a scheduler from a class\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "basic_sched_config", "=", "{", "\n", "\"_target_\"", ":", "\"mridc.core.conf.schedulers.CosineAnnealingParams\"", ",", "\n", "\"params\"", ":", "{", "\"min_lr\"", ":", "0.1", "}", ",", "\n", "\"max_steps\"", ":", "self", ".", "MAX_STEPS", ",", "\n", "}", "\n", "scheduler_setup", "=", "optim", ".", "lr_scheduler", ".", "prepare_lr_scheduler", "(", "opt", ",", "basic_sched_config", ")", "\n", "if", "not", "isinstance", "(", "scheduler_setup", "[", "\"scheduler\"", "]", ",", "optim", ".", "lr_scheduler", ".", "CosineAnnealing", ")", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "dict_config", "=", "omegaconf", ".", "OmegaConf", ".", "create", "(", "basic_sched_config", ")", "\n", "scheduler_setup", "=", "optim", ".", "lr_scheduler", ".", "prepare_lr_scheduler", "(", "opt", ",", "dict_config", ")", "\n", "if", "not", "isinstance", "(", "scheduler_setup", "[", "\"scheduler\"", "]", ",", "optim", ".", "lr_scheduler", ".", "CosineAnnealing", ")", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_WarmupPolicy": [[345, 392], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.WarmupPolicy", "range", "mridc.core.optim.lr_scheduler.WarmupPolicy.step", "mridc.core.optim.lr_scheduler.WarmupPolicy", "range", "mridc.core.optim.lr_scheduler.WarmupPolicy.step", "TempModel.parameters", "mridc.core.optim.lr_scheduler.WarmupPolicy.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.WarmupPolicy.step", "mridc.core.optim.lr_scheduler.WarmupPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupPolicy.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.WarmupPolicy.step", "mridc.core.optim.lr_scheduler.WarmupPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupPolicy.get_last_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_WarmupPolicy", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test WarmupPolicy\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "# No warmup case", "\n", "policy", "=", "optim", ".", "lr_scheduler", ".", "WarmupPolicy", "(", "opt", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", "!=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "!=", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "WarmupPolicy", "(", "opt", ",", "warmup_steps", "=", "5", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "i", "<=", "4", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "!=", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_WarmupHoldPolicy": [[393, 465], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy", "range", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy", "range", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy", "range", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.step", "TempModel.parameters", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_WarmupHoldPolicy", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test WarmupHoldPolicy\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "# No warmup case", "\n", "policy", "=", "optim", ".", "lr_scheduler", ".", "WarmupHoldPolicy", "(", "opt", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", "!=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "!=", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "<=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "WarmupHoldPolicy", "(", "opt", ",", "warmup_steps", "=", "5", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "i", "<=", "4", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "!=", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "<=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup + Hold steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "WarmupHoldPolicy", "(", "\n", "opt", ",", "warmup_steps", "=", "5", ",", "hold_steps", "=", "3", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", "\n", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "i", "<=", "4", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "!=", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "<", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_WarmupAnnealing": [[466, 538], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.WarmupAnnealing", "range", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.step", "mridc.core.optim.lr_scheduler.WarmupAnnealing", "range", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy", "range", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.step", "TempModel.parameters", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.step", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr", "mridc.core.optim.lr_scheduler.WarmupHoldPolicy.get_last_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_WarmupAnnealing", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test that the warmup annealing policy works as expected.\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "# No warmup case", "\n", "policy", "=", "optim", ".", "lr_scheduler", ".", "WarmupAnnealing", "(", "opt", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", "!=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "<", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "WarmupAnnealing", "(", "opt", ",", "warmup_steps", "=", "5", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "i", "<=", "5", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">=", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup + Hold steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "WarmupHoldPolicy", "(", "\n", "opt", ",", "warmup_steps", "=", "5", ",", "hold_steps", "=", "3", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", "\n", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "i", "<=", "4", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "!=", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "<", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_SquareAnnealing": [[539, 587], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.SquareAnnealing", "range", "mridc.core.optim.lr_scheduler.SquareAnnealing.step", "mridc.core.optim.lr_scheduler.SquareAnnealing", "range", "mridc.core.optim.lr_scheduler.SquareAnnealing.step", "TempModel.parameters", "mridc.core.optim.lr_scheduler.SquareAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.SquareAnnealing.step", "mridc.core.optim.lr_scheduler.SquareAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.SquareAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.SquareAnnealing.step", "mridc.core.optim.lr_scheduler.SquareAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.SquareAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.SquareAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.SquareAnnealing.get_last_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_SquareAnnealing", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test SquareAnnealing\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "# No warmup case", "\n", "policy", "=", "optim", ".", "lr_scheduler", ".", "SquareAnnealing", "(", "opt", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", "!=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "SquareAnnealing", "(", "opt", ",", "warmup_steps", "=", "5", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "i", "<=", "5", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">=", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_SquareRootAnnealing": [[588, 638], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.SquareRootAnnealing", "range", "mridc.core.optim.lr_scheduler.SquareRootAnnealing.step", "mridc.core.optim.lr_scheduler.SquareRootAnnealing", "range", "mridc.core.optim.lr_scheduler.SquareRootAnnealing.step", "TempModel.parameters", "mridc.core.optim.lr_scheduler.SquareRootAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.SquareRootAnnealing.step", "mridc.core.optim.lr_scheduler.SquareRootAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.SquareRootAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.SquareRootAnnealing.step", "mridc.core.optim.lr_scheduler.SquareRootAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.SquareRootAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.SquareRootAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.SquareRootAnnealing.get_last_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_SquareRootAnnealing", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test SquareRootAnnealing\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "# No warmup case", "\n", "policy", "=", "SquareRootAnnealing", "(", "opt", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", "!=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "SquareRootAnnealing", "(", "\n", "opt", ",", "warmup_steps", "=", "5", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", "\n", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "i", "<=", "5", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">=", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_CosineAnnealing": [[639, 715], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.CosineAnnealing", "range", "mridc.core.optim.lr_scheduler.CosineAnnealing.step", "mridc.core.optim.lr_scheduler.CosineAnnealing", "range", "mridc.core.optim.lr_scheduler.CosineAnnealing.step", "mridc.core.optim.lr_scheduler.CosineAnnealing", "range", "mridc.core.optim.lr_scheduler.CosineAnnealing.step", "TempModel.parameters", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.CosineAnnealing.step", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.CosineAnnealing.step", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.CosineAnnealing.step", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.CosineAnnealing._get_lr", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor._get_lr"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_CosineAnnealing", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test CosineAnnealing\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "# No warmup case", "\n", "policy", "=", "optim", ".", "lr_scheduler", ".", "CosineAnnealing", "(", "opt", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", "!=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "CosineAnnealing", "(", "opt", ",", "warmup_steps", "=", "5", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "i", "<=", "5", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">=", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup + Constant steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "CosineAnnealing", "(", "\n", "opt", ",", "warmup_steps", "=", "3", ",", "constant_steps", "=", "2", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", "\n", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "i", "<=", "3", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", "+", "1e-5", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "3", "<", "i", "<=", "8", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "!=", "policy", ".", "_get_lr", "(", "i", ")", "[", "0", "]", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "!=", "self", ".", "MIN_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_PolynomialDecayAnnealing": [[716, 768], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing", "range", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing.step", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing", "range", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing.step", "TempModel.parameters", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing.step", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing.step", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.PolynomialDecayAnnealing.get_last_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_PolynomialDecayAnnealing", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test PolynomialDecayAnnealing\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "# No warmup case", "\n", "policy", "=", "optim", ".", "lr_scheduler", ".", "PolynomialDecayAnnealing", "(", "\n", "opt", ",", "power", "=", "2", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", "\n", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", "!=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "PolynomialDecayAnnealing", "(", "\n", "opt", ",", "warmup_steps", "=", "5", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", "\n", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "i", "<=", "5", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">=", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_PolynomialHoldDecayAnnealing": [[769, 845], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing", "range", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.step", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing", "range", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.step", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing", "range", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.step", "TempModel.parameters", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.step", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.step", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.step", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.PolynomialHoldDecayAnnealing.get_last_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_PolynomialHoldDecayAnnealing", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test PolynomialHoldDecayAnnealing\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "# No warmup case", "\n", "policy", "=", "optim", ".", "lr_scheduler", ".", "PolynomialHoldDecayAnnealing", "(", "\n", "opt", ",", "power", "=", "2", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", "\n", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", "!=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "<=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "PolynomialHoldDecayAnnealing", "(", "\n", "opt", ",", "power", "=", "2", ",", "warmup_steps", "=", "5", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", "\n", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "<", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup + Hold steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "PolynomialHoldDecayAnnealing", "(", "\n", "opt", ",", "warmup_steps", "=", "5", ",", "hold_steps", "=", "3", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ",", "power", "=", "2", "\n", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "i", "<=", "4", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "i", "<=", "8", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "<", "self", ".", "INITIAL_LR", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "<", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_InverseSquareRootAnnealing": [[846, 896], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing", "range", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing.step", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing", "range", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing.step", "TempModel.parameters", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing.step", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing.step", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.InverseSquareRootAnnealing.get_last_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_InverseSquareRootAnnealing", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test InverseSquareRootAnnealing\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "# No warmup case", "\n", "policy", "=", "optim", ".", "lr_scheduler", ".", "InverseSquareRootAnnealing", "(", "opt", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", "!=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "_", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# Warmup steps available", "\n", "", "policy", "=", "optim", ".", "lr_scheduler", ".", "InverseSquareRootAnnealing", "(", "\n", "opt", ",", "warmup_steps", "=", "5", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", "\n", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", ">=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "i", "<=", "5", ":", "\n", "                ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                    ", "raise", "AssertionError", "\n", "", "", "elif", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">=", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "", "policy", ".", "step", "(", ")", "\n", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "final_lr", "!=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_CosineAnnealing_with_noop_steps": [[897, 938], ["test_optimizers_schedulers.TempModel", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer.", "mridc.core.optim.lr_scheduler.CosineAnnealing", "range", "mridc.core.optim.lr_scheduler.CosineAnnealing.step", "TempModel.parameters", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.optimizers.get_optimizer.step", "mridc.core.optim.lr_scheduler.CosineAnnealing.step", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr", "mridc.core.optim.lr_scheduler.CosineAnnealing._get_lr", "mridc.core.optim.lr_scheduler.CosineAnnealing.get_last_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor._get_lr"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_CosineAnnealing_with_noop_steps", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test CosineAnnealing with noop steps.\"\"\"", "\n", "model", "=", "TempModel", "(", ")", "\n", "opt_cls", "=", "get_optimizer", "(", "\"novograd\"", ")", "\n", "opt", "=", "opt_cls", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "INITIAL_LR", ")", "\n", "\n", "# No warmup case", "\n", "policy", "=", "optim", ".", "lr_scheduler", ".", "CosineAnnealing", "(", "opt", ",", "max_steps", "=", "self", ".", "MAX_STEPS", ",", "min_lr", "=", "self", ".", "MIN_LR", ")", "\n", "initial_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "\n", "if", "initial_lr", "!=", "self", ".", "INITIAL_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "update_steps", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "MAX_STEPS", ")", ":", "\n", "            ", "if", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", ">", "self", ".", "INITIAL_LR", ":", "\n", "                ", "raise", "AssertionError", "\n", "", "opt", ".", "step", "(", ")", "\n", "policy", ".", "step", "(", ")", "\n", "\n", "# Perform a No-Op for scheduler every 2 steps", "\n", "if", "i", "%", "2", "==", "0", ":", "\n", "                ", "policy", ".", "last_epoch", "-=", "1", "\n", "", "else", ":", "\n", "                ", "update_steps", "+=", "1", "\n", "\n", "", "", "policy", ".", "step", "(", ")", "\n", "update_steps", "+=", "1", "\n", "\n", "if", "update_steps", ">=", "self", ".", "MAX_STEPS", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "final_lr", "=", "policy", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "if", "final_lr", "<=", "self", ".", "MIN_LR", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "# update step = true number of updates performed after some number of skipped steps", "\n", "", "true_end_lr", "=", "policy", ".", "_get_lr", "(", "step", "=", "update_steps", ")", "[", "0", "]", "\n", "if", "final_lr", "!=", "true_end_lr", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_max_step_computation": [[939, 1027], ["pytest.mark.run_only_on", "test_optimizers_schedulers.TestOptimizersSchedulers.test_max_step_computation.train"], "methods", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "@", "pytest", ".", "mark", ".", "run_only_on", "(", "\"CPU\"", ")", "\n", "def", "test_max_step_computation", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test max step computation.\"\"\"", "\n", "\n", "def", "train", "(", "\n", "max_epochs", ",", "accumulate_grad_batches", ",", "limit_train_batches", ",", "devices", ",", "batch_size", ",", "dataset_len", ",", "drop_last", "\n", ")", ":", "\n", "            ", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "max_epochs", ",", "\n", "strategy", "=", "\"ddp_spawn\"", ",", "\n", "accelerator", "=", "\"cpu\"", ",", "\n", "devices", "=", "devices", ",", "\n", "accumulate_grad_batches", "=", "accumulate_grad_batches", ",", "\n", "limit_train_batches", "=", "limit_train_batches", ",", "\n", "enable_checkpointing", "=", "False", ",", "\n", "progress_bar_refresh_rate", "=", "0", ",", "\n", "weights_summary", "=", "None", ",", "\n", ")", "\n", "max_steps", "=", "optim", ".", "lr_scheduler", ".", "compute_max_steps", "(", "\n", "max_epochs", ",", "\n", "accumulate_grad_batches", ",", "\n", "limit_train_batches", ",", "\n", "devices", ",", "\n", "dataset_len", ",", "\n", "batch_size", ",", "\n", "drop_last", ",", "\n", ")", "\n", "model", "=", "ExampleModel", "(", "batch_size", ",", "dataset_len", ",", "drop_last", ",", "max_steps", ")", "\n", "trainer", ".", "callbacks", ".", "append", "(", "Callback", "(", ")", ")", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "\n", "# This test will break once we and lightning upgrade to pytorch 1.7.0 due to a bug fix in pytorch 1.7.0", "\n", "", "train", "(", "\n", "31", ",", "\n", "accumulate_grad_batches", "=", "1", ",", "\n", "limit_train_batches", "=", "1.0", ",", "\n", "devices", "=", "9", ",", "\n", "batch_size", "=", "60", ",", "\n", "dataset_len", "=", "1613", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "train", "(", "\n", "5", ",", "\n", "accumulate_grad_batches", "=", "1", ",", "\n", "limit_train_batches", "=", "1.0", ",", "\n", "devices", "=", "4", ",", "\n", "batch_size", "=", "97", ",", "\n", "dataset_len", "=", "498", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "train", "(", "\n", "5", ",", "\n", "accumulate_grad_batches", "=", "8", ",", "\n", "limit_train_batches", "=", "1.0", ",", "\n", "devices", "=", "4", ",", "\n", "batch_size", "=", "54", ",", "\n", "dataset_len", "=", "629", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "train", "(", "\n", "5", ",", "\n", "accumulate_grad_batches", "=", "1", ",", "\n", "limit_train_batches", "=", "1.0", ",", "\n", "devices", "=", "1", ",", "\n", "batch_size", "=", "68", ",", "\n", "dataset_len", "=", "488", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "5", ")", ":", "\n", "            ", "drop_last", "=", "bool", "(", "random", ".", "randint", "(", "0", ",", "1", ")", ")", "\n", "accumulate_grad_batches", "=", "random", ".", "randint", "(", "1", ",", "10", ")", "\n", "\n", "limit_train_batches_int", "=", "random", ".", "randint", "(", "1", ",", "10", ")", "\n", "limit_train_batches_float", "=", "1.0", "\n", "limit_train_batches", "=", "random", ".", "choice", "(", "[", "limit_train_batches_int", ",", "limit_train_batches_float", "]", ")", "\n", "max_epochs", "=", "random", ".", "randint", "(", "4", ",", "20", ")", "\n", "devices", "=", "random", ".", "randint", "(", "1", ",", "5", ")", "\n", "dataset_len", "=", "random", ".", "randint", "(", "20", ",", "devices", "*", "500", ")", "\n", "batch_size", "=", "random", ".", "randint", "(", "math", ".", "ceil", "(", "5.0", "/", "devices", ")", ",", "min", "(", "dataset_len", "//", "devices", ",", "128", ")", ")", "\n", "train", "(", "\n", "max_epochs", ",", "\n", "accumulate_grad_batches", ",", "\n", "limit_train_batches", ",", "\n", "devices", ",", "\n", "batch_size", ",", "\n", "dataset_len", ",", "\n", "drop_last", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_max_step_computation_with_sched_no_ops": [[1029, 1062], ["pytest.mark.run_only_on", "test_optimizers_schedulers.TestOptimizersSchedulers.test_max_step_computation.train"], "methods", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "unit", "\n", "@", "pytest", ".", "mark", ".", "run_only_on", "(", "\"CPU\"", ")", "\n", "def", "test_max_step_computation_with_sched_no_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Test that max_step is computed correctly when scheduler has no_ops\"\"\"", "\n", "\n", "def", "train", "(", "\n", "max_steps", ",", "accumulate_grad_batches", ",", "limit_train_batches", ",", "num_processes", ",", "batch_size", ",", "dataset_len", ",", "drop_last", "\n", ")", ":", "\n", "            ", "\"\"\"Set up trainer and model\"\"\"", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_steps", "=", "max_steps", ",", "\n", "strategy", "=", "\"ddp_spawn\"", ",", "\n", "accelerator", "=", "\"cpu\"", ",", "\n", "num_processes", "=", "num_processes", ",", "\n", "accumulate_grad_batches", "=", "accumulate_grad_batches", ",", "\n", "limit_train_batches", "=", "limit_train_batches", ",", "\n", "enable_checkpointing", "=", "False", ",", "\n", "progress_bar_refresh_rate", "=", "0", ",", "\n", "weights_summary", "=", "None", ",", "\n", ")", "\n", "model", "=", "ExampleModel", "(", "batch_size", ",", "dataset_len", ",", "drop_last", ",", "max_steps", ")", "\n", "trainer", ".", "callbacks", ".", "append", "(", "SchedulerNoOpCallback", "(", ")", ")", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "\n", "# This test will break once we and lightning upgrade to pytorch 1.7.0 due to a bug fix in pytorch 1.7.0", "\n", "", "train", "(", "\n", "max_steps", "=", "20", ",", "\n", "accumulate_grad_batches", "=", "1", ",", "\n", "limit_train_batches", "=", "1.0", ",", "\n", "num_processes", "=", "4", ",", "\n", "batch_size", "=", "60", ",", "\n", "dataset_len", "=", "2000", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_optimizers_schedulers.TestOptimizersSchedulers.test_remove_logs_left": [[1064, 1069], ["os.path.exists", "os.path.join", "shutil.rmtree", "os.getcwd", "os.path.join", "os.getcwd"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "test_remove_logs_left", "(", ")", ":", "\n", "        ", "\"\"\"Remove logs left by the trainer.\"\"\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "\"lightning_logs\"", ")", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "\"lightning_logs\"", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_serialization.MockSerializationImpl.__init__": [[17, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ")", ":", "\n", "        ", "self", ".", "cfg", "=", "cfg", "\n", "self", ".", "value", "=", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_serialization.TestSerialization.test_self_class_instantiation": [[27, 36], ["omegaconf.DictConfig", "MockSerializationImpl.from_config_dict", "MockSerializationImpl.from_config_dict.to_config_dict", "isinstance", "test_serialization.get_class_path"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_serialization.get_class_path"], ["    ", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_self_class_instantiation", "(", "self", ")", ":", "\n", "# Target class is V1 impl, calling class is V1 (same class)", "\n", "        ", "config", "=", "DictConfig", "(", "{", "\"target\"", ":", "get_class_path", "(", "MockSerializationImpl", ")", "}", ")", "\n", "obj", "=", "MockSerializationImpl", ".", "from_config_dict", "(", "config", "=", "config", ")", "# Serialization is base class", "\n", "new_config", "=", "obj", ".", "to_config_dict", "(", ")", "\n", "assert", "config", "==", "new_config", "\n", "assert", "isinstance", "(", "obj", ",", "MockSerializationImpl", ")", "\n", "assert", "obj", ".", "value", "==", "\"MockSerializationImpl\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_serialization.TestSerialization.test_sub_class_instantiation": [[37, 46], ["omegaconf.DictConfig", "MockSerializationImplV2.from_config_dict", "MockSerializationImplV2.from_config_dict.to_config_dict", "isinstance", "test_serialization.get_class_path"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.core.test_serialization.get_class_path"], ["", "@", "pytest", ".", "mark", ".", "unit", "\n", "def", "test_sub_class_instantiation", "(", "self", ")", ":", "\n", "# Target class is V1 impl, calling class is V2 (sub class)", "\n", "        ", "config", "=", "DictConfig", "(", "{", "\"target\"", ":", "get_class_path", "(", "MockSerializationImpl", ")", "}", ")", "\n", "obj", "=", "MockSerializationImplV2", ".", "from_config_dict", "(", "config", "=", "config", ")", "# Serialization is base class", "\n", "new_config", "=", "obj", ".", "to_config_dict", "(", ")", "\n", "assert", "config", "==", "new_config", "\n", "assert", "isinstance", "(", "obj", ",", "MockSerializationImplV2", ")", "\n", "assert", "obj", ".", "value", "==", "\"MockSerializationImplV2\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.core.test_serialization.get_class_path": [[12, 14], ["None"], "function", ["None"], ["def", "get_class_path", "(", "cls", ")", ":", "\n", "    ", "return", "f\"{cls.__module__}.{cls.__name__}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.mridc.launch.main": [[28, 96], ["mridc.core.conf.hydra_runner.hydra_runner", "mridc.utils.logging.info", "pytorch_lightning.Trainer", "mridc.utils.exp_manager.exp_manager", "cfg.model[].upper", "cfg.get", "cfg.get", "mridc.collections.reconstruction.models.ccnn.CascadeNet", "cfg.get", "mridc.utils.logging.info", "mridc.collections.reconstruction.models.zf.ZF.load_state_dict", "cfg.get", "mridc.utils.logging.info", "pl.Trainer.validate", "mridc.utils.logging.info", "pl.Trainer.fit", "mridc.utils.logging.info", "pl.Trainer.test", "mridc.collections.reconstruction.models.cirim.CIRIM", "omegaconf.OmegaConf.to_yaml", "mridc.collections.reconstruction.models.crnn.CRNNet", "torch.load", "mridc.collections.reconstruction.models.dunet.DUNet", "mridc.collections.reconstruction.models.vn.VarNet", "mridc.collections.reconstruction.models.jointicnet.JointICNet", "mridc.collections.reconstruction.models.kikinet.KIKINet", "mridc.collections.reconstruction.models.lpd.LPDNet", "mridc.collections.reconstruction.models.multidomainnet.MultiDomainNet", "mridc.collections.reconstruction.models.pics.PICS", "mridc.collections.reconstruction.models.rvn.RecurrentVarNet", "mridc.collections.reconstruction.models.unet.UNet", "mridc.collections.reconstruction.models.vsnet.VSNet", "mridc.collections.reconstruction.models.xpdnet.XPDNet", "mridc.collections.reconstruction.models.zf.ZF", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.conf.hydra_runner.hydra_runner", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.load_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info"], ["@", "hydra_runner", "(", "config_path", "=", "\".\"", ",", "config_name", "=", "\"config\"", ")", "\n", "def", "main", "(", "cfg", ":", "DictConfig", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Main function for training and running a model\n\n    Parameters\n    ----------\n    cfg: Configuration (yaml) file.\n        DictConfig\n    \"\"\"", "\n", "logging", ".", "info", "(", "f\"Config: {OmegaConf.to_yaml(cfg)}\"", ")", "\n", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "**", "cfg", ".", "trainer", ")", "\n", "exp_manager", "(", "trainer", ",", "cfg", ".", "get", "(", "\"exp_manager\"", ",", "None", ")", ")", "\n", "\n", "model_name", "=", "(", "cfg", ".", "model", "[", "\"model_name\"", "]", ")", ".", "upper", "(", ")", "\n", "\n", "if", "model_name", "==", "\"CASCADENET\"", ":", "\n", "        ", "model", "=", "CascadeNet", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"CIRIM\"", ":", "\n", "        ", "model", "=", "CIRIM", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"CRNNET\"", ":", "\n", "        ", "model", "=", "CRNNet", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"DUNET\"", ":", "\n", "        ", "model", "=", "DUNet", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "in", "(", "\"E2EVN\"", ",", "\"VN\"", ")", ":", "\n", "        ", "model", "=", "VarNet", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"JOINTICNET\"", ":", "\n", "        ", "model", "=", "JointICNet", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"KIKINET\"", ":", "\n", "        ", "model", "=", "KIKINet", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"LPDNET\"", ":", "\n", "        ", "model", "=", "LPDNet", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"MULTIDOMAINNET\"", ":", "\n", "        ", "model", "=", "MultiDomainNet", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"PICS\"", ":", "\n", "        ", "model", "=", "PICS", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"RVN\"", ":", "\n", "        ", "model", "=", "RecurrentVarNet", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"UNET\"", ":", "\n", "        ", "model", "=", "UNet", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"VSNET\"", ":", "\n", "        ", "model", "=", "VSNet", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"XPDNET\"", ":", "\n", "        ", "model", "=", "XPDNet", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "elif", "model_name", "==", "\"ZF\"", ":", "\n", "        ", "model", "=", "ZF", "(", "cfg", ".", "model", ",", "trainer", "=", "trainer", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "f\"{model_name} is not implemented in MRIDC. You can use one of the following methods: \"", "\n", "\"CASCADENET, CIRIM, CRNNET, DUNET, E2EVN, JOINTICNET, KIKINET, LPDNET, MULTIDOMAINNET, PICS, RVN, UNET, \"", "\n", "\"VSNET, XPDNET, or Zero-Filled. /n\"", "\n", "\"If you implemented a new model, please consider adding it through a PR on GitHub.\"", "\n", ")", "\n", "\n", "", "if", "cfg", ".", "get", "(", "\"pretrained\"", ",", "None", ")", ":", "\n", "        ", "checkpoint", "=", "cfg", ".", "get", "(", "\"checkpoint\"", ",", "None", ")", "\n", "logging", ".", "info", "(", "f\"Loading pretrained model from {checkpoint}\"", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint", ")", "[", "\"state_dict\"", "]", ")", "\n", "\n", "", "if", "cfg", ".", "get", "(", "\"mode\"", ",", "None", ")", "==", "\"train\"", ":", "\n", "        ", "logging", ".", "info", "(", "\"Validating\"", ")", "\n", "trainer", ".", "validate", "(", "model", ")", "\n", "logging", ".", "info", "(", "\"Training\"", ")", "\n", "trainer", ".", "fit", "(", "model", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "\"Evaluating\"", ")", "\n", "trainer", ".", "test", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.CoercionError.__init__": [[30, 33], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "key", ",", "value", ",", "func", ")", ":", "\n", "        ", "msg", "=", "f\"Unable to coerce '{key}={value}' using {func.__name__}.\"", "\n", "super", "(", "CoercionError", ",", "self", ")", ".", "__init__", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.RequiredSettingMissingError.__init__": [[38, 41], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "key", ")", ":", "\n", "        ", "msg", "=", "f\"Required env var '{key}' is missing.\"", "\n", "super", "(", "RequiredSettingMissingError", ",", "self", ")", ".", "__init__", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing._get_env": [[43, 71], ["coerce", "env_var_parsing.CoercionError", "env_var_parsing.RequiredSettingMissingError"], "function", ["None"], ["", "", "def", "_get_env", "(", "key", ",", "default", "=", "None", ",", "coerce", "=", "lambda", "x", ":", "x", ",", "required", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Return env var coerced into a type other than string. This function extends the standard os.getenv function to \\\n    enable the coercion of values into data types other than string (all env vars are strings by default).\n\n    Parameters\n    ----------\n    key: The name of the env var to retrieve.\n    default: The default value to return if the env var is not set. NB the default value is **not** coerced, and is \\\n    assumed to be of the correct type.\n    coerce: A function that takes a string and returns a value of the desired type.\n    required: If True, raises a RequiredSettingMissingError if the env var is not set.\n\n    Returns\n    -------\n    The value of the env var coerced into the desired type.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "value", "=", "os", ".", "environ", "[", "key", "]", "\n", "", "except", "KeyError", "as", "e", ":", "\n", "        ", "if", "required", "is", "True", ":", "\n", "            ", "raise", "RequiredSettingMissingError", "(", "key", ")", "from", "e", "\n", "", "return", "default", "\n", "\n", "", "try", ":", "\n", "        ", "return", "coerce", "(", "value", ")", "\n", "", "except", "Exception", "as", "exc", ":", "\n", "        ", "raise", "CoercionError", "(", "key", ",", "value", ",", "coerce", ")", "from", "exc", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing._bool": [[74, 86], ["isinstance", "value.lower"], "function", ["None"], ["", "", "def", "_bool", "(", "value", ")", ":", "\n", "    ", "\"\"\"Return env var cast as boolean.\"\"\"", "\n", "if", "isinstance", "(", "value", ",", "bool", ")", ":", "\n", "        ", "return", "value", "\n", "\n", "", "return", "value", "is", "not", "None", "and", "value", ".", "lower", "(", ")", "not", "in", "(", "\n", "\"false\"", ",", "\n", "\"0\"", ",", "\n", "\"no\"", ",", "\n", "\"n\"", ",", "\n", "\"f\"", ",", "\n", "\"none\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing._int": [[89, 92], ["int"], "function", ["None"], ["", "def", "_int", "(", "value", ")", ":", "\n", "    ", "\"\"\"Return env var cast as integer.\"\"\"", "\n", "return", "int", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing._float": [[94, 97], ["float"], "function", ["None"], ["", "def", "_float", "(", "value", ")", ":", "\n", "    ", "\"\"\"Return env var cast as float.\"\"\"", "\n", "return", "float", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing._decimal": [[99, 102], ["decimal.Decimal"], "function", ["None"], ["", "def", "_decimal", "(", "value", ")", ":", "\n", "    ", "\"\"\"Return env var cast as Decimal.\"\"\"", "\n", "return", "decimal", ".", "Decimal", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing._dict": [[104, 107], ["json.loads"], "function", ["None"], ["", "def", "_dict", "(", "value", ")", ":", "\n", "    ", "\"\"\"Return env var as a dict.\"\"\"", "\n", "return", "json", ".", "loads", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing._datetime": [[109, 112], ["dateutil.parser.parse"], "function", ["None"], ["", "def", "_datetime", "(", "value", ")", ":", "\n", "    ", "\"\"\"Return env var as a datetime.\"\"\"", "\n", "return", "parser", ".", "parse", "(", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing._date": [[114, 117], ["dateutil.parser.parse().date", "dateutil.parser.parse"], "function", ["None"], ["", "def", "_date", "(", "value", ")", ":", "\n", "    ", "\"\"\"Return env var as a date.\"\"\"", "\n", "return", "parser", ".", "parse", "(", "value", ")", ".", "date", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_env": [[119, 143], ["kwargs.get", "env_var_parsing._get_env", "len", "AssertionError", "len"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing._get_env"], ["", "def", "get_env", "(", "key", ",", "*", "default", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Return env var. This is the parent function of all other get_foo functions, and is responsible for unpacking \\\n    args/kwargs into the values that _get_env expects (it is the root function that actually interacts with environ).\n\n    Parameters\n    ----------\n    key: string, the env var name to look up.\n    default: (optional) the value to use if the env var does not exist. If this value is not supplied, then the \\\n    env var is considered to be required, and a RequiredSettingMissingError error will be raised if it does not exist.\n    kwargs:\n        coerce: a func that may be supplied to coerce the value into something else. This is used by the default \\\n        get_foo functions to cast strings to builtin types, but could be a function that returns a custom class.\n\n    Returns\n    -------\n    The env var, coerced if required, and a default if supplied.\n    \"\"\"", "\n", "if", "len", "(", "default", ")", "not", "in", "(", "0", ",", "1", ")", ":", "\n", "        ", "raise", "AssertionError", "(", "\"Too many args supplied.\"", ")", "\n", "", "func", "=", "kwargs", ".", "get", "(", "\"coerce\"", ",", "lambda", "x", ":", "x", ")", "\n", "required", "=", "len", "(", "default", ")", "==", "0", "\n", "default", "=", "None", "if", "required", "else", "default", "[", "0", "]", "\n", "return", "_get_env", "(", "key", ",", "default", "=", "default", ",", "coerce", "=", "func", ",", "required", "=", "required", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envbool": [[145, 148], ["env_var_parsing.get_env"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_env"], ["", "def", "get_envbool", "(", "key", ",", "*", "default", ")", ":", "\n", "    ", "\"\"\"Return env var cast as boolean.\"\"\"", "\n", "return", "get_env", "(", "key", ",", "*", "default", ",", "coerce", "=", "_bool", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envint": [[150, 153], ["env_var_parsing.get_env"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_env"], ["", "def", "get_envint", "(", "key", ",", "*", "default", ")", ":", "\n", "    ", "\"\"\"Return env var cast as integer.\"\"\"", "\n", "return", "get_env", "(", "key", ",", "*", "default", ",", "coerce", "=", "_int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envfloat": [[155, 158], ["env_var_parsing.get_env"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_env"], ["", "def", "get_envfloat", "(", "key", ",", "*", "default", ")", ":", "\n", "    ", "\"\"\"Return env var cast as float.\"\"\"", "\n", "return", "get_env", "(", "key", ",", "*", "default", ",", "coerce", "=", "_float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envdecimal": [[160, 163], ["env_var_parsing.get_env"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_env"], ["", "def", "get_envdecimal", "(", "key", ",", "*", "default", ")", ":", "\n", "    ", "\"\"\"Return env var cast as Decimal.\"\"\"", "\n", "return", "get_env", "(", "key", ",", "*", "default", ",", "coerce", "=", "_decimal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envdate": [[165, 168], ["env_var_parsing.get_env"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_env"], ["", "def", "get_envdate", "(", "key", ",", "*", "default", ")", ":", "\n", "    ", "\"\"\"Return env var as a date.\"\"\"", "\n", "return", "get_env", "(", "key", ",", "*", "default", ",", "coerce", "=", "_date", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envdatetime": [[170, 173], ["env_var_parsing.get_env"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_env"], ["", "def", "get_envdatetime", "(", "key", ",", "*", "default", ")", ":", "\n", "    ", "\"\"\"Return env var as a datetime.\"\"\"", "\n", "return", "get_env", "(", "key", ",", "*", "default", ",", "coerce", "=", "_datetime", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envlist": [[175, 179], ["kwargs.get", "env_var_parsing.get_env", "x.split"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_env"], ["", "def", "get_envlist", "(", "key", ",", "*", "default", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Return env var as a list.\"\"\"", "\n", "separator", "=", "kwargs", ".", "get", "(", "\"separator\"", ",", "\" \"", ")", "\n", "return", "get_env", "(", "key", ",", "*", "default", ",", "coerce", "=", "lambda", "x", ":", "x", ".", "split", "(", "separator", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envdict": [[181, 184], ["env_var_parsing.get_env"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_env"], ["", "def", "get_envdict", "(", "key", ",", "*", "default", ")", ":", "\n", "    ", "\"\"\"Return env var as a dict.\"\"\"", "\n", "return", "get_env", "(", "key", ",", "*", "default", ",", "coerce", "=", "_dict", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.distributed.initialize_distributed": [[13, 53], ["int", "int", "mridc.utils.logging.info", "torch.cuda.set_device", "os.getenv", "os.getenv", "torch.distributed.init_process_group", "os.getenv", "os.getenv", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info"], ["def", "initialize_distributed", "(", "args", ",", "backend", "=", "\"nccl\"", ")", ":", "\n", "    ", "\"\"\"\n    Initialize distributed training.\n\n    Parameters\n    ----------\n    args: The arguments object.\n    backend: The backend to use.\n        default: \"nccl\"\n\n    Returns\n    -------\n    local_rank: The local rank of the process.\n    rank: The rank of the process.\n    world_size: The number of processes.\n    \"\"\"", "\n", "# Get local rank in case it is provided.", "\n", "local_rank", "=", "args", ".", "local_rank", "\n", "\n", "# Get rank and world size.", "\n", "rank", "=", "int", "(", "os", ".", "getenv", "(", "\"RANK\"", ",", "\"0\"", ")", ")", "\n", "world_size", "=", "int", "(", "os", ".", "getenv", "(", "\"WORLD_SIZE\"", ",", "\"1\"", ")", ")", "\n", "\n", "logging", ".", "info", "(", "\n", "f\"Initializing torch.distributed with local_rank: {local_rank}, rank: {rank}, world_size: {world_size}\"", "\n", ")", "\n", "\n", "# Set the device id.", "\n", "device", "=", "rank", "%", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "if", "local_rank", "is", "not", "None", ":", "\n", "        ", "device", "=", "local_rank", "\n", "", "torch", ".", "cuda", ".", "set_device", "(", "device", ")", "\n", "\n", "# Call the init process.", "\n", "init_method", "=", "\"tcp://\"", "\n", "master_ip", "=", "os", ".", "getenv", "(", "\"MASTER_ADDR\"", ",", "\"localhost\"", ")", "\n", "master_port", "=", "os", ".", "getenv", "(", "\"MASTER_PORT\"", ",", "\"6000\"", ")", "\n", "init_method", "+=", "f\"{master_ip}:{master_port}\"", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "backend", ",", "world_size", "=", "world_size", ",", "rank", "=", "rank", ",", "init_method", "=", "init_method", ")", "\n", "return", "local_rank", ",", "rank", ",", "world_size", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_dataset_name_from_cfg": [[72, 156], ["cfg.items", "isinstance", "type", "str", "len", "os.path.exists", "os.path.isdir", "os.path.exists", "os.path.isdir", "str", "str"], "function", ["None"], ["", "def", "resolve_dataset_name_from_cfg", "(", "cfg", ":", "\"DictConfig\"", ")", "->", "Union", "[", "Union", "[", "str", ",", "int", ",", "Enum", ",", "float", ",", "bool", ",", "None", "]", ",", "Any", "]", ":", "\n", "    ", "\"\"\"\n    Parses items of the provided sub-config to find the first potential key that resolves to an existing file or\n    directory.\n\n    # Fast-path Resolution\n    In order to handle cases where we need to resolve items that are not paths, a fastpath key can be provided as\n    defined in the global `_VAL_TEST_FASTPATH_KEY`.\n\n    This key can be used in two ways :\n    ## _VAL_TEST_FASTPATH_KEY points to another key in the config\n    If this _VAL_TEST_FASTPATH_KEY points to another key in this config itself, then we assume we want to loop through\n    the values of that key. This allows for any key in the config to become a fastpath key.\n\n    Example\n    -------\n    validation_ds:\n\n    .. code-block::\n\n        splits: \"val\"\n        ...\n        <_VAL_TEST_FASTPATH_KEY>: \"splits\"  <-- this points to the key name \"splits\"\n\n    Then we can write the following when overriding in hydra:\n    ```python\n    python train_file.py ... model.validation_ds.splits=[val1, val2, dev1, dev2] ...\n    ```\n    ## _VAL_TEST_FASTPATH_KEY itself acts as the resolved key\n    If this _VAL_TEST_FASTPATH_KEY does not point to another key in the config, then it is assumed that the items of\n    this key itself are used for resolution.\n\n    Example\n    -------\n    validation_ds:\n\n    .. code-block::\n\n        <_VAL_TEST_FASTPATH_KEY>: \"val\"  <-- this points to the key name \"splits\"\n\n    Then we can write the following when overriding in hydra:\n    ```python\n    python train_file.py ... model.validation_ds.<_VAL_TEST_FASTPATH_KEY>=[val1, val2, dev1, dev2] ...\n    ```\n    # IMPORTANT NOTE:\n    It <can> potentially mismatch if there exist more than 2 valid paths, and the first path does *not* resolve the\n    path of the data file (but does resolve to some other valid path). To avoid this side effect, place the data path\n    as the first item on the config file.\n\n    Parameters\n    ----------\n    cfg: Sub-config of the config file.\n\n    Returns\n    -------\n    A str representing the `key` of the config which hosts the filepath(s), or None in case path could not be resolved.\n    \"\"\"", "\n", "if", "_VAL_TEST_FASTPATH_KEY", "in", "cfg", "and", "cfg", "[", "_VAL_TEST_FASTPATH_KEY", "]", "is", "not", "None", ":", "\n", "        ", "fastpath_key", "=", "cfg", "[", "_VAL_TEST_FASTPATH_KEY", "]", "\n", "\n", "if", "isinstance", "(", "fastpath_key", ",", "str", ")", "and", "fastpath_key", "in", "cfg", ":", "\n", "            ", "return", "cfg", "[", "fastpath_key", "]", "\n", "", "return", "_VAL_TEST_FASTPATH_KEY", "\n", "\n", "", "for", "key", ",", "value", "in", "cfg", ".", "items", "(", ")", ":", "\n", "        ", "if", "type", "(", "value", ")", "in", "[", "list", ",", "tuple", ",", "ListConfig", "]", ":", "\n", "# Count the number of valid paths in the list", "\n", "            ", "values_are_paths", "=", "0", "\n", "for", "val_i", "in", "value", ":", "\n", "                ", "val_i", "=", "str", "(", "val_i", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "val_i", ")", "or", "os", ".", "path", ".", "isdir", "(", "val_i", ")", ":", "\n", "                    ", "values_are_paths", "+=", "1", "\n", "", "else", ":", "\n", "# reset counter and break inner loop", "\n", "                    ", "break", "\n", "\n", "", "", "if", "values_are_paths", "==", "len", "(", "value", ")", ":", "\n", "                ", "return", "key", "\n", "\n", "", "", "elif", "os", ".", "path", ".", "exists", "(", "str", "(", "value", ")", ")", "or", "os", ".", "path", ".", "isdir", "(", "str", "(", "value", ")", ")", ":", "\n", "            ", "return", "key", "\n", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.parse_dataset_as_name": [[158, 194], ["name.replace.replace", "name.replace.replace", "name.replace.replace", "ValueError", "os.path.exists", "os.path.isdir", "pathlib.Path"], "function", ["None"], ["", "def", "parse_dataset_as_name", "(", "name", ":", "str", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Constructs a valid prefix-name from a provided file path.\n\n    Parameters\n    ----------\n    name: Path to some valid data/manifest file or a python object that will be used as a name for the data loader (via\n    str() cast).\n\n    Returns\n    -------\n    A valid prefix-name for the data loader.\n    \"\"\"", "\n", "name", "=", "Path", "(", "name", ")", ".", "stem", "if", "os", ".", "path", ".", "exists", "(", "name", ")", "or", "os", ".", "path", ".", "isdir", "(", "name", ")", "else", "name", "\n", "# cleanup name", "\n", "name", "=", "name", ".", "replace", "(", "\"-\"", ",", "\"_\"", ")", "\n", "\n", "if", "\"manifest\"", "in", "name", ":", "\n", "        ", "name", "=", "name", ".", "replace", "(", "\"manifest\"", ",", "\"\"", ")", "\n", "\n", "", "if", "\"dataset\"", "in", "name", ":", "\n", "        ", "name", "=", "name", ".", "replace", "(", "\"dataset\"", ",", "\"\"", ")", "\n", "\n", "# Test if the manifest/dataset name was simply `manifest.yaml` or `dataset.yaml`: Invalid names.", "\n", "", "if", "name", "==", "\"\"", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Provided dataset / manifest filename was `manifest.json` or `dataset.json`.\\n\"", "\n", "\"Such a name is invalid, since multiple datasets/manifests can share the same name,\\n\"", "\n", "\"thereby overriding their results during logging. Please pick a more descriptive filename \\n\"", "\n", "\"for the provided dataset / manifest file.\"", "\n", ")", "\n", "\n", "", "if", "name", "[", "-", "1", "]", "!=", "\"_\"", ":", "\n", "        ", "name", "=", "f\"{name}_\"", "\n", "\n", "", "return", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.unique_names_check": [[196, 219], ["set", "mridc.utils.logging.warning", "set.add"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning"], ["", "def", "unique_names_check", "(", "name_list", ":", "Optional", "[", "List", "[", "str", "]", "]", ")", ":", "\n", "    ", "\"\"\"\n    Performs a uniqueness check on the name list resolved, so that it can warn users about non-unique keys.\n\n    Parameters\n    ----------\n    name_list: List of strings resolved for data loaders.\n    \"\"\"", "\n", "if", "name_list", "is", "None", ":", "\n", "        ", "return", "\n", "\n", "# Name uniqueness checks", "\n", "", "names", "=", "set", "(", ")", "\n", "for", "name", "in", "name_list", ":", "\n", "        ", "if", "name", "in", "names", ":", "\n", "            ", "logging", ".", "warning", "(", "\n", "\"Name resolution has found more than one data loader having the same name !\\n\"", "\n", "\"In such cases, logs will nor be properly generated. \"", "\n", "\"Please rename the item to have unique names.\\n\"", "\n", "f\"Resolved name : {name}\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "names", ".", "add", "(", "name", ")", "# we need just hash key check, value is just a placeholder", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_validation_dataloaders": [[221, 287], ["copy.deepcopy", "model_utils.resolve_dataset_name_from_cfg", "isinstance", "model.setup_validation_data", "model_utils.unique_names_check", "mridc.utils.logging.error", "sys.exit", "omegaconf.OmegaConf.to_container", "cfg[].pop", "omegaconf.OmegaConf.create", "mridc.utils.logging.debug", "model.setup_validation_data", "model_utils.unique_names_check", "model_utils.parse_dataset_as_name", "model.setup_validation_data", "dataloaders.append", "model_utils.parse_dataset_as_name"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_dataset_name_from_cfg", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_validation_data", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.unique_names_check", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.debug", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_validation_data", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.unique_names_check", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.parse_dataset_as_name", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_validation_data", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.parse_dataset_as_name"], ["", "", "", "def", "resolve_validation_dataloaders", "(", "model", ":", "ModelPT", ")", ":", "\n", "    ", "\"\"\"\n    Helper method that operates on the ModelPT class to automatically support multiple dataloaders for the validation\n    set. It does so by first resolving the path to one/more data files via `resolve_dataset_name_from_cfg()`.\n    If this resolution fails, it assumes the data loader is prepared to manually support / not support multiple data\n    loaders and simply calls the appropriate setup method.\n    If resolution succeeds:\n    - Checks if provided path is to a single file or a list of files.\n    If a single file is provided, simply tags that file as such and loads it via the setup method.\n    If multiple files are provided:\n    - Inject a new manifest path at index \"i\" into the resolved key.\n    - Calls the appropriate setup method to set the data loader.\n    - Collects the initialized data loader in a list and preserves it.\n    - Once all data loaders are processed, assigns the list of loaded loaders to the ModelPT.\n    - Finally, assigns a list of unique names resolved from the file paths to the ModelPT.\n\n    Parameters\n    ----------\n    model: ModelPT subclass, which requires >=1 Validation Dataloaders to be setup.\n    \"\"\"", "\n", "if", "not", "_HAS_HYDRA", ":", "\n", "        ", "logging", ".", "error", "(", "\"This function requires Hydra/OmegaConf and it was not installed.\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "cfg", "=", "copy", ".", "deepcopy", "(", "model", ".", "_cfg", ")", "\n", "dataloaders", ":", "List", "[", "Any", "]", "=", "[", "]", "\n", "\n", "# process val_loss_idx", "\n", "if", "\"val_dl_idx\"", "in", "cfg", ".", "validation_ds", ":", "\n", "        ", "cfg", "=", "OmegaConf", ".", "to_container", "(", "cfg", ")", "\n", "val_dl_idx", "=", "cfg", "[", "\"validation_ds\"", "]", ".", "pop", "(", "\"val_dl_idx\"", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "", "else", ":", "\n", "        ", "val_dl_idx", "=", "0", "\n", "\n", "# Set val_loss_idx", "\n", "", "model", ".", "_val_dl_idx", "=", "val_dl_idx", "\n", "\n", "ds_key", "=", "resolve_dataset_name_from_cfg", "(", "cfg", ".", "validation_ds", ")", "\n", "\n", "if", "ds_key", "is", "None", ":", "\n", "        ", "logging", ".", "debug", "(", "\n", "f\"Could not resolve file path from provided config - {cfg.validation_ds}. \"", "\n", "\"Disabling support for multi-dataloaders.\"", "\n", ")", "\n", "\n", "model", ".", "setup_validation_data", "(", "cfg", ".", "validation_ds", ")", "\n", "return", "\n", "\n", "", "ds_values", "=", "cfg", ".", "validation_ds", "[", "ds_key", "]", "\n", "\n", "if", "isinstance", "(", "ds_values", ",", "(", "list", ",", "tuple", ",", "ListConfig", ")", ")", ":", "\n", "\n", "        ", "for", "ds_value", "in", "ds_values", ":", "\n", "            ", "cfg", ".", "validation_ds", "[", "ds_key", "]", "=", "ds_value", "\n", "model", ".", "setup_validation_data", "(", "cfg", ".", "validation_ds", ")", "\n", "dataloaders", ".", "append", "(", "model", ".", "validation_dl", ")", "\n", "\n", "", "model", ".", "validation_dl", "=", "dataloaders", "# type: ignore", "\n", "model", ".", "validation_names", "=", "[", "parse_dataset_as_name", "(", "ds", ")", "for", "ds", "in", "ds_values", "]", "# type: ignore", "\n", "\n", "unique_names_check", "(", "name_list", "=", "model", ".", "validation_names", ")", "\n", "return", "\n", "", "model", ".", "setup_validation_data", "(", "cfg", ".", "validation_ds", ")", "\n", "model", ".", "validation_names", "=", "[", "parse_dataset_as_name", "(", "ds_values", ")", "]", "\n", "\n", "unique_names_check", "(", "name_list", "=", "model", ".", "validation_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_test_dataloaders": [[289, 356], ["copy.deepcopy", "model_utils.resolve_dataset_name_from_cfg", "isinstance", "model.setup_test_data", "model_utils.unique_names_check", "mridc.utils.logging.error", "sys.exit", "omegaconf.OmegaConf.to_container", "cfg[].pop", "omegaconf.OmegaConf.create", "mridc.utils.logging.debug", "model.setup_test_data", "model_utils.unique_names_check", "model_utils.parse_dataset_as_name", "model.setup_test_data", "dataloaders.append", "model_utils.parse_dataset_as_name"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_dataset_name_from_cfg", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_test_data", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.unique_names_check", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.debug", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_test_data", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.unique_names_check", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.parse_dataset_as_name", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_test_data", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.parse_dataset_as_name"], ["", "def", "resolve_test_dataloaders", "(", "model", ":", "\"ModelPT\"", ")", ":", "\n", "    ", "\"\"\"\n    Helper method that operates on the ModelPT class to automatically support\n    multiple dataloaders for the test set.\n    It does so by first resolving the path to one/more data files via `resolve_dataset_name_from_cfg()`.\n    If this resolution fails, it assumes the data loader is prepared to manually support / not support\n    multiple data loaders and simply calls the appropriate setup method.\n    If resolution succeeds:\n        Checks if provided path is to a single file or a list of files.\n        If a single file is provided, simply tags that file as such and loads it via the setup method.\n        If multiple files are provided:\n            Inject a new manifest path at index \"i\" into the resolved key.\n            Calls the appropriate setup method to set the data loader.\n            Collects the initialized data loader in a list and preserves it.\n            Once all data loaders are processed, assigns the list of loaded loaders to the ModelPT.\n            Finally, assigns a list of unique names resolved from the file paths to the ModelPT.\n\n    Parameters\n    ----------\n    model: ModelPT subclass, which requires >=1 Test Dataloaders to be setup.\n    \"\"\"", "\n", "if", "not", "_HAS_HYDRA", ":", "\n", "        ", "logging", ".", "error", "(", "\"This function requires Hydra/OmegaConf and it was not installed.\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "cfg", "=", "copy", ".", "deepcopy", "(", "model", ".", "_cfg", ")", "\n", "dataloaders", ":", "List", "[", "Any", "]", "=", "[", "]", "\n", "\n", "# process test_loss_idx", "\n", "if", "\"test_dl_idx\"", "in", "cfg", ".", "test_ds", ":", "\n", "        ", "cfg", "=", "OmegaConf", ".", "to_container", "(", "cfg", ")", "\n", "test_dl_idx", "=", "cfg", "[", "\"test_ds\"", "]", ".", "pop", "(", "\"test_dl_idx\"", ")", "\n", "cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "", "else", ":", "\n", "        ", "test_dl_idx", "=", "0", "\n", "\n", "# Set val_loss_idx", "\n", "", "model", ".", "_test_dl_idx", "=", "test_dl_idx", "\n", "\n", "ds_key", "=", "resolve_dataset_name_from_cfg", "(", "cfg", ".", "test_ds", ")", "\n", "\n", "if", "ds_key", "is", "None", ":", "\n", "        ", "logging", ".", "debug", "(", "\n", "f\"Could not resolve file path from provided config - {cfg.test_ds}. \"", "\n", "\"Disabling support for multi-dataloaders.\"", "\n", ")", "\n", "\n", "model", ".", "setup_test_data", "(", "cfg", ".", "test_ds", ")", "\n", "return", "\n", "\n", "", "ds_values", "=", "cfg", ".", "test_ds", "[", "ds_key", "]", "\n", "\n", "if", "isinstance", "(", "ds_values", ",", "(", "list", ",", "tuple", ",", "ListConfig", ")", ")", ":", "\n", "\n", "        ", "for", "ds_value", "in", "ds_values", ":", "\n", "            ", "cfg", ".", "test_ds", "[", "ds_key", "]", "=", "ds_value", "\n", "model", ".", "setup_test_data", "(", "cfg", ".", "test_ds", ")", "\n", "dataloaders", ".", "append", "(", "model", ".", "test_dl", ")", "\n", "\n", "", "model", ".", "test_dl", "=", "dataloaders", "# type: ignore", "\n", "model", ".", "test_names", "=", "[", "parse_dataset_as_name", "(", "ds", ")", "for", "ds", "in", "ds_values", "]", "# type: ignore", "\n", "\n", "unique_names_check", "(", "name_list", "=", "model", ".", "test_names", ")", "\n", "return", "\n", "", "model", ".", "setup_test_data", "(", "cfg", ".", "test_ds", ")", "\n", "model", ".", "test_names", "=", "[", "parse_dataset_as_name", "(", "ds_values", ")", "]", "\n", "\n", "unique_names_check", "(", "name_list", "=", "model", ".", "test_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.wrap_training_step": [[358, 381], ["wrapped", "isinstance", "wrapped.pop", "instance.log_dict"], "function", ["None"], ["", "@", "wrapt", ".", "decorator", "\n", "def", "wrap_training_step", "(", "wrapped", ",", "instance", ":", "LightningModule", ",", "args", ",", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Wraps the training step of the LightningModule.\n\n    Parameters\n    ----------\n    wrapped: The wrapped function.\n    instance: The LightningModule instance.\n    args: The arguments passed to the wrapped function.\n    kwargs: The keyword arguments passed to the wrapped function.\n\n    Returns\n    -------\n    The return value of the wrapped function.\n    \"\"\"", "\n", "output_dict", "=", "wrapped", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "if", "isinstance", "(", "output_dict", ",", "dict", ")", "and", "output_dict", "is", "not", "None", "and", "\"log\"", "in", "output_dict", ":", "\n", "        ", "log_dict", "=", "output_dict", ".", "pop", "(", "\"log\"", ")", "\n", "instance", ".", "log_dict", "(", "log_dict", ",", "on_step", "=", "True", ")", "\n", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.convert_model_config_to_dict_config": [[383, 411], ["omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.create", "mridc.utils.logging.error", "sys.exit", "dataclasses.is_dataclass", "omegaconf.OmegaConf.structured", "isinstance", "ValueError", "isinstance", "type"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error"], ["", "def", "convert_model_config_to_dict_config", "(", "cfg", ":", "Union", "[", "DictConfig", ",", "MRIDCConfig", "]", ")", "->", "DictConfig", ":", "\n", "    ", "\"\"\"\n    Converts its input into a standard DictConfig.\n\n    Possible input values are:\n        - DictConfig\n        - A dataclass which is a subclass of MRIDCConfig\n\n    Parameters\n    ----------\n    cfg: A dict-like object.\n\n    Returns\n    -------\n    The equivalent DictConfig.\n    \"\"\"", "\n", "if", "not", "_HAS_HYDRA", ":", "\n", "        ", "logging", ".", "error", "(", "\"This function requires Hydra/OmegaConf and it was not installed.\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "if", "not", "isinstance", "(", "cfg", ",", "(", "OmegaConf", ",", "DictConfig", ")", ")", "and", "is_dataclass", "(", "cfg", ")", ":", "\n", "        ", "cfg", "=", "OmegaConf", ".", "structured", "(", "cfg", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "cfg", ",", "DictConfig", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"cfg constructor argument must be of type DictConfig/dict but got {type(cfg)} instead.\"", ")", "\n", "\n", "", "config", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", "\n", "config", "=", "OmegaConf", ".", "create", "(", "config", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils._convert_config": [[413, 436], ["mridc.utils.logging.error", "sys.exit", "cfg.pop", "cfg.pop", "cfg.pop.items", "cfg.items", "isinstance", "mridc.utils.logging.warning", "model_utils._convert_config"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils._convert_config"], ["", "def", "_convert_config", "(", "cfg", ":", "\"OmegaConf\"", ")", ":", "\n", "    ", "\"\"\"Recursive function converting the configuration from old hydra format to the new one.\"\"\"", "\n", "if", "not", "_HAS_HYDRA", ":", "\n", "        ", "logging", ".", "error", "(", "\"This function requires Hydra/OmegaConf and it was not installed.\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n", "# Get rid of cls -> _target_.", "\n", "", "if", "\"cls\"", "in", "cfg", "and", "\"_target_\"", "not", "in", "cfg", ":", "\n", "        ", "cfg", ".", "_target_", "=", "cfg", ".", "pop", "(", "\"cls\"", ")", "# type: ignore", "\n", "\n", "# Get rid of params.", "\n", "", "if", "\"params\"", "in", "cfg", ":", "\n", "        ", "params", "=", "cfg", ".", "pop", "(", "\"params\"", ")", "# type: ignore", "\n", "for", "param_key", ",", "param_val", "in", "params", ".", "items", "(", ")", ":", "\n", "            ", "cfg", "[", "param_key", "]", "=", "param_val", "\n", "\n", "# Recursion.", "\n", "", "", "try", ":", "\n", "        ", "for", "_", ",", "sub_cfg", "in", "cfg", ".", "items", "(", ")", ":", "# type: ignore", "\n", "            ", "if", "isinstance", "(", "sub_cfg", ",", "DictConfig", ")", ":", "\n", "                ", "_convert_config", "(", "sub_cfg", ")", "# type: ignore", "\n", "", "", "", "except", "OmegaConfBaseException", "as", "e", ":", "\n", "        ", "logging", ".", "warning", "(", "f\"Skipped conversion for config/subconfig:\\n{cfg}\\n Reason: {e}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.maybe_update_config_version": [[438, 476], ["copy.deepcopy", "omegaconf.OmegaConf.set_struct", "model_utils._convert_config", "omegaconf.OmegaConf.set_struct", "mridc.utils.logging.error", "sys.exit", "isinstance", "omegaconf.OmegaConf.create"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils._convert_config", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error"], ["", "", "def", "maybe_update_config_version", "(", "cfg", ":", "\"DictConfig\"", ")", ":", "\n", "    ", "\"\"\"\n    Recursively convert Hydra 0.x configs to Hydra 1.x configs.\n    Changes include:\n    -   `cls` -> `_target_`.\n    -   `params` -> drop params and shift all arguments to parent.\n    -   `target` -> `_target_` cannot be performed due to ModelPT injecting `target` inside class.\n\n    Parameters\n    ----------\n    cfg: Any Hydra compatible DictConfig\n\n    Returns\n    -------\n    An updated DictConfig that conforms to Hydra 1.x format.\n    \"\"\"", "\n", "if", "not", "_HAS_HYDRA", ":", "\n", "        ", "logging", ".", "error", "(", "\"This function requires Hydra/OmegaConf and it was not installed.\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "if", "cfg", "is", "not", "None", "and", "not", "isinstance", "(", "cfg", ",", "DictConfig", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "temp_cfg", "=", "OmegaConf", ".", "create", "(", "cfg", ")", "\n", "cfg", "=", "temp_cfg", "\n", "", "except", "OmegaConfBaseException", ":", "\n", "# Cannot be cast to DictConfig, skip updating.", "\n", "            ", "return", "cfg", "\n", "\n", "# Make a copy of model config.", "\n", "", "", "cfg", "=", "copy", ".", "deepcopy", "(", "cfg", ")", "\n", "OmegaConf", ".", "set_struct", "(", "cfg", ",", "False", ")", "\n", "\n", "# Convert config.", "\n", "_convert_config", "(", "cfg", ")", "# type: ignore", "\n", "\n", "# Update model config.", "\n", "OmegaConf", ".", "set_struct", "(", "cfg", ",", "True", ")", "\n", "\n", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.import_class_by_path": [[478, 486], ["path.split", "__import__", "getattr"], "function", ["None"], ["", "def", "import_class_by_path", "(", "path", ":", "str", ")", ":", "\n", "    ", "\"\"\"Recursive import of class by path string.\"\"\"", "\n", "paths", "=", "path", ".", "split", "(", "\".\"", ")", "\n", "path", "=", "\".\"", ".", "join", "(", "paths", "[", ":", "-", "1", "]", ")", "\n", "class_name", "=", "paths", "[", "-", "1", "]", "\n", "mod", "=", "__import__", "(", "path", ",", "fromlist", "=", "[", "class_name", "]", ")", "\n", "mod", "=", "getattr", "(", "mod", ",", "class_name", ")", "\n", "return", "mod", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_subclass_pretrained_model_info": [[488, 535], ["set", "model_utils.resolve_subclass_pretrained_model_info.recursive_subclass_walk"], "function", ["None"], ["", "def", "resolve_subclass_pretrained_model_info", "(", "base_class", ")", "->", "Union", "[", "List", "[", "PretrainedModelInfo", "]", ",", "Set", "[", "Any", "]", "]", ":", "\n", "    ", "\"\"\"\n    Recursively traverses the inheritance graph of subclasses to extract all pretrained model info.\n    First constructs a set of unique pretrained model info by performing DFS over the inheritance graph.\n    All model info belonging to the same class is added together.\n\n    Parameters\n    ----------\n    base_class: The root class, whose subclass graph will be traversed.\n\n    Returns\n    -------\n    A list of unique pretrained model infos belonging to all the inherited subclasses of this baseclass.\n    \"\"\"", "\n", "list_of_models", "=", "set", "(", ")", "\n", "\n", "def", "recursive_subclass_walk", "(", "cls", ")", ":", "\n", "        ", "\"\"\"\n        Recursively traverses the inheritance graph of subclasses to extract all pretrained model info.\n\n        Parameters\n        ----------\n        cls: The class to be traversed.\n\n        Returns\n        -------\n        A list of unique pretrained model infos belonging to all the inherited subclasses of this baseclass.\n        \"\"\"", "\n", "for", "subclass", "in", "cls", ".", "__subclasses__", "(", ")", ":", "\n", "# step into its immediate subclass", "\n", "            ", "recursive_subclass_walk", "(", "subclass", ")", "\n", "\n", "subclass_models", "=", "subclass", ".", "list_available_models", "(", ")", "\n", "\n", "if", "subclass_models", "is", "not", "None", "and", "len", "(", "subclass_models", ")", ">", "0", ":", "\n", "# Inject subclass info into pretrained model info, if not already overridden by subclass.", "\n", "                ", "for", "model_info", "in", "subclass_models", ":", "\n", "# If subclass manually injects class_, dont override.", "\n", "                    ", "if", "model_info", ".", "class_", "is", "None", ":", "\n", "                        ", "model_info", ".", "class_", "=", "subclass", "\n", "\n", "", "", "for", "model_info", "in", "subclass_models", ":", "\n", "                    ", "list_of_models", ".", "add", "(", "model_info", ")", "\n", "\n", "", "", "", "", "recursive_subclass_walk", "(", "base_class", ")", "\n", "list_of_models", "=", "list", "(", "sorted", "(", "list_of_models", ")", ")", "# type: ignore", "\n", "return", "list_of_models", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.check_lib_version": [[537, 588], ["hasattr", "model_utils.import_class_by_path", "__import__", "distutils.version.Version", "distutils.version.Version", "operator"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.import_class_by_path"], ["", "def", "check_lib_version", "(", "lib_name", ":", "str", ",", "checked_version", ":", "str", ",", "operator", ")", "->", "Tuple", "[", "Optional", "[", "bool", "]", ",", "str", "]", ":", "\n", "    ", "\"\"\"\n    Checks if a library is installed, and if it is, checks the operator(lib.__version__, checked_version) as a result.\n    This bool result along with a string analysis of result is returned.\n    If the library is not installed at all, then returns None instead, along with a string explaining\n    that the library is not installed\n\n    Parameters\n    ----------\n    lib_name: lower case str name of the library that must be imported.\n    checked_version: semver string that is compared against lib.__version__.\n    operator: binary callable function func(a, b) -> bool; that compares lib.__version__ against version in some\n    manner. Must return a boolean.\n\n    Returns\n    -------\n    A tuple of results:\n        -   Bool or None. Bool if the library could be imported, and the result of\n            operator(lib.__version__, checked_version) or False if __version__ is not implemented in lib.\n            None is passed if the library is not installed at all.\n        -   A string analysis of the check.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "if", "\".\"", "in", "lib_name", ":", "\n", "            ", "mod", "=", "import_class_by_path", "(", "lib_name", ")", "\n", "", "else", ":", "\n", "            ", "mod", "=", "__import__", "(", "lib_name", ")", "\n", "\n", "", "if", "hasattr", "(", "mod", ",", "\"__version__\"", ")", ":", "\n", "            ", "lib_ver", "=", "Version", "(", "mod", ".", "__version__", ")", "# type: ignore", "\n", "match_ver", "=", "Version", "(", "checked_version", ")", "# type: ignore", "\n", "\n", "if", "operator", "(", "lib_ver", ",", "match_ver", ")", ":", "\n", "                ", "msg", "=", "f\"Lib {lib_name} version is satisfied !\"", "\n", "return", "True", ",", "msg", "\n", "", "msg", "=", "(", "\n", "f\"Lib {lib_name} version ({lib_ver}) is not {operator.__name__} than required version \"", "\n", "f\"{checked_version}.\\n\"", "\n", "\"Please upgrade the lib using either pip or conda to the latest version.\"", "\n", ")", "\n", "return", "False", ",", "msg", "\n", "", "msg", "=", "(", "\n", "f\"Lib {lib_name} does not implement __version__ in its init file. \"", "\n", "\"Could not check version compatibility.\"", "\n", ")", "\n", "return", "False", ",", "msg", "\n", "", "except", "ImportError", ":", "\n", "        ", "pass", "\n", "\n", "", "msg", "=", "f\"Lib {lib_name} has not been installed. Please use pip or conda to install this package.\"", "\n", "return", "None", ",", "msg", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_cache_dir": [[590, 606], ["os.environ.get", "pathlib.Path.joinpath", "pathlib.Path().resolve", "pathlib.Path.home", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["", "def", "resolve_cache_dir", "(", ")", "->", "Path", ":", "\n", "    ", "\"\"\"\n    Utility method to resolve a cache directory for MRIDC that can be overridden by an environment variable.\n    Example:\n        MRIDC_CACHE_DIR=\"~/mridc_cache_dir/\" python mridc_example_script.py\n\n    Returns\n    -------\n    A Path object, resolved to the absolute path of the cache directory. If no override is provided, uses an inbuilt\n    default which adapts to mridc versions strings.\n    \"\"\"", "\n", "override_dir", "=", "os", ".", "environ", ".", "get", "(", "MRIDC_ENV_CACHE_DIR", ",", "\"\"", ")", "\n", "return", "(", "\n", "Path", ".", "joinpath", "(", "Path", ".", "home", "(", ")", ",", "f\".cache/torch/MRIDC/MRIDC_{mridc.__version__}\"", ")", "\n", "if", "override_dir", "==", "\"\"", "\n", "else", "Path", "(", "override_dir", ")", ".", "resolve", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.uninject_model_parallel_rank": [[609, 617], ["str", "os.path.dirname", "os.path.basename", "os.path.join", "os.path.dirname"], "function", ["None"], ["", "def", "uninject_model_parallel_rank", "(", "filepath", ")", ":", "\n", "    ", "\"\"\"Uninjects tensor/pipeline model parallel ranks from the filepath.\"\"\"", "\n", "filepath", "=", "str", "(", "filepath", ")", "\n", "if", "\"mp_rank\"", "in", "filepath", "or", "\"tp_rank\"", "in", "filepath", ":", "\n", "        ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "filepath", ")", ")", "\n", "basename", "=", "os", ".", "path", ".", "basename", "(", "filepath", ")", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "basename", ")", "\n", "", "return", "filepath", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.inject_model_parallel_rank": [[619, 636], ["model_utils.uninject_model_parallel_rank", "mridc.utils.app_state.AppState", "os.path.dirname", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.uninject_model_parallel_rank"], ["", "def", "inject_model_parallel_rank", "(", "filepath", ")", ":", "\n", "    ", "\"\"\"Injects tensor/pipeline model parallel ranks into the filepath. Does nothing if not using model parallelism.\"\"\"", "\n", "filepath", "=", "uninject_model_parallel_rank", "(", "filepath", ")", "\n", "app_state", "=", "AppState", "(", ")", "\n", "if", "app_state", ".", "model_parallel_size", "is", "not", "None", "and", "app_state", ".", "model_parallel_size", ">", "1", ":", "\n", "# filepath needs to be updated to include mp_rank", "\n", "        ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "filepath", ")", "\n", "basename", "=", "os", ".", "path", ".", "basename", "(", "filepath", ")", "\n", "if", "app_state", ".", "pipeline_model_parallel_size", "is", "None", "or", "app_state", ".", "pipeline_model_parallel_size", "==", "1", ":", "\n", "            ", "filepath", "=", "f\"{dirname}/mp_rank_{app_state.tensor_model_parallel_rank:02d}/{basename}\"", "\n", "", "else", ":", "\n", "            ", "filepath", "=", "(", "\n", "f\"{dirname}/tp_rank_{app_state.tensor_model_parallel_rank:02d}_pp_rank_\"", "\n", "f\"{app_state.pipeline_model_parallel_rank:03d}/{basename} \"", "\n", ")", "\n", "", "return", "filepath", "\n", "", "return", "filepath", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.arguments.add_optimizer_args": [[10, 55], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "add_optimizer_args", "(", "\n", "parent_parser", ":", "ArgumentParser", ",", "\n", "optimizer", ":", "str", "=", "\"adam\"", ",", "\n", "default_lr", ":", "float", "=", "None", ",", "\n", "default_opt_args", ":", "Optional", "[", "Union", "[", "Dict", "[", "str", ",", "Any", "]", ",", "List", "[", "str", "]", "]", "]", "=", "None", ",", "\n", ")", "->", "ArgumentParser", ":", "\n", "    ", "\"\"\"\n    Extends existing argparse with default optimizer args.\n\n    # Example of adding optimizer args to command line:\n    python train_script.py ... --optimizer \"novograd\" --lr 0.01 --opt_args betas=0.95,0.5 weight_decay=0.001\n\n    Parameters\n    ----------\n    parent_parser: Custom CLI parser that will be extended.\n        ArgumentParser\n    optimizer: Default optimizer required.\n        str, default \"adam\"\n    default_lr: Default learning rate.\n        float, default None\n    default_opt_args: Default optimizer arguments.\n        Optional[Union[Dict[str, Any], List[str]]], default None\n\n    Returns\n    -------\n    Parser extended by Optimizers arguments.\n        ArgumentParser\n    \"\"\"", "\n", "if", "default_opt_args", "is", "None", ":", "\n", "        ", "default_opt_args", "=", "[", "]", "\n", "\n", "", "parser", "=", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "True", ",", "conflict_handler", "=", "\"resolve\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--optimizer\"", ",", "type", "=", "str", ",", "default", "=", "optimizer", ",", "help", "=", "\"Name of the optimizer. Defaults to Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "default_lr", ",", "help", "=", "\"Learning rate of the optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--opt_args\"", ",", "\n", "default", "=", "default_opt_args", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Overriding arguments for the optimizer. \\n Must follow the pattern : \\n name=value separated by spaces.\"", "\n", "\"Example: --opt_args weight_decay=0.001 eps=1e-8 betas=0.9,0.999\"", ",", "\n", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.arguments.add_scheduler_args": [[57, 93], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "add_scheduler_args", "(", "parent_parser", ":", "ArgumentParser", ")", "->", "ArgumentParser", ":", "\n", "    ", "\"\"\"\n    Extends existing argparse with default scheduler args.\n\n    Parameters\n    ----------\n    parent_parser: Custom CLI parser that will be extended.\n        ArgumentParser\n\n    Returns\n    -------\n    Parser extended by Schedulers arguments.\n        ArgumentParser\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "False", ",", "conflict_handler", "=", "\"resolve\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "None", ",", "help", "=", "\"Number of warmup steps\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--warmup_ratio\"", ",", "\n", "type", "=", "float", ",", "\n", "required", "=", "False", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Number of warmup steps as a percentage of total training steps\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--hold_steps\"", ",", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "None", ",", "help", "=", "\"Number of hold LR steps\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--hold_ratio\"", ",", "\n", "type", "=", "float", ",", "\n", "required", "=", "False", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Number of hold LR steps as a percentage of total training steps\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--min_lr\"", ",", "type", "=", "float", ",", "required", "=", "False", ",", "default", "=", "0.0", ",", "help", "=", "\"Minimum learning rate\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--last_epoch\"", ",", "type", "=", "int", ",", "required", "=", "False", ",", "default", "=", "-", "1", ",", "help", "=", "\"Last epoch id. -1 indicates training from scratch\"", "\n", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.arguments.add_recon_args": [[95, 119], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "add_recon_args", "(", "parent_parser", ":", "ArgumentParser", ")", "->", "ArgumentParser", ":", "\n", "    ", "\"\"\"\n    Extends existing argparse with default reconstruction args.\n\n    Parameters\n    ----------\n    parent_parser: Custom CLI parser that will be extended.\n        ArgumentParser\n\n    Returns\n    -------\n    Parser extended by Reconstruction arguments.\n        ArgumentParser\n    \"\"\"", "\n", "parser", "=", "ArgumentParser", "(", "parents", "=", "[", "parent_parser", "]", ",", "add_help", "=", "False", ",", "conflict_handler", "=", "\"resolve\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "\"data directory to training or/and evaluation dataset\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--config_file\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "default", "=", "None", ",", "help", "=", "\"Recon model configuration file\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pretrained_model_name\"", ",", "default", "=", "\"recon-base-uncased\"", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "\"pretrained model name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "required", "=", "False", ",", "help", "=", "\"lower case data\"", ")", "\n", "return", "parser", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.metaclasses.Singleton.__call__": [[18, 29], ["super().__call__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.transforms.MRIDataTransforms.__call__"], ["def", "__call__", "(", "cls", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Returns singleton instance. A thread safe implementation.\"\"\"", "\n", "if", "cls", "not", "in", "cls", ".", "__instances", ":", "\n", "# Enter critical section.", "\n", "            ", "with", "cls", ".", "__lock", ":", "\n", "# Check once again.", "\n", "                ", "if", "cls", "not", "in", "cls", ".", "__instances", ":", "\n", "# Create a new object instance - one per class.", "\n", "                    ", "cls", ".", "__instances", "[", "cls", "]", "=", "super", "(", "Singleton", ",", "cls", ")", ".", "__call__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "# Return the instance.", "\n", "", "", "", "return", "cls", ".", "__instances", "[", "cls", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.cloud.maybe_download_from_cloud": [[15, 78], ["pathlib.Path.joinpath", "os.path.exists", "mridc.utils.logging.info", "ValueError", "pathlib.Path.joinpath", "pathlib.Path.joinpath", "os.path.exists", "os.makedirs", "mridc.utils.logging.info", "pathlib.Path.home", "mridc.utils.logging.info", "mridc.utils.logging.info", "os.remove", "mridc.utils.logging.info", "str", "wget.download", "os.path.exists", "str", "str", "str", "mridc.utils.logging.info", "mridc.utils.logging.info", "time.sleep"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info"], ["def", "maybe_download_from_cloud", "(", "url", ",", "filename", ",", "subfolder", "=", "None", ",", "cache_dir", "=", "None", ",", "refresh_cache", "=", "False", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Download a file from a URL if it does not exist in the cache.\n\n    Parameters\n    ----------\n    url: URL to download the file from.\n        str\n    filename: What to download. The request will be issued to url/filename\n        str\n    subfolder: Subfolder within cache_dir. The file will be stored in cache_dir/subfolder. Subfolder can be empty.\n        str\n    cache_dir: A cache directory where to download. If not present, this function will attempt to create it.\n        str, If None (default), then it will be $HOME/.cache/torch/mridc\n    refresh_cache: If True and cached file is present, it will delete it and re-fetch\n        bool\n\n    Returns\n    -------\n    If successful - absolute local path to the downloaded file else empty string.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_location", "=", "Path", ".", "joinpath", "(", "Path", ".", "home", "(", ")", ",", "\".cache/torch/mridc\"", ")", "\n", "", "else", ":", "\n", "        ", "cache_location", "=", "cache_dir", "\n", "", "if", "subfolder", "is", "not", "None", ":", "\n", "        ", "destination", "=", "Path", ".", "joinpath", "(", "cache_location", ",", "subfolder", ")", "\n", "", "else", ":", "\n", "        ", "destination", "=", "cache_location", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "destination", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "destination", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "destination_file", "=", "Path", ".", "joinpath", "(", "destination", ",", "filename", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "destination_file", ")", ":", "\n", "        ", "logging", ".", "info", "(", "f\"Found existing object {destination_file}.\"", ")", "\n", "if", "refresh_cache", ":", "\n", "            ", "logging", ".", "info", "(", "\"Asked to refresh the cache.\"", ")", "\n", "logging", ".", "info", "(", "f\"Deleting file: {destination_file}\"", ")", "\n", "os", ".", "remove", "(", "destination_file", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Re-using file from: {destination_file}\"", ")", "\n", "return", "str", "(", "destination_file", ")", "\n", "# download file", "\n", "", "", "wget_uri", "=", "url", "+", "filename", "\n", "logging", ".", "info", "(", "f\"Downloading from: {wget_uri} to {str(destination_file)}\"", ")", "\n", "# NGC links do not work everytime so we try and wait", "\n", "i", "=", "0", "\n", "max_attempts", "=", "3", "\n", "while", "i", "<", "max_attempts", ":", "\n", "        ", "i", "+=", "1", "\n", "try", ":", "\n", "            ", "wget", ".", "download", "(", "wget_uri", ",", "str", "(", "destination_file", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "destination_file", ")", ":", "\n", "                ", "return", "str", "(", "destination_file", ")", "\n", "", "return", "\"\"", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Download from cloud failed. Attempt {i} of {max_attempts}\"", ")", "\n", "logging", ".", "info", "(", "f\"Error: {e}\"", ")", "\n", "sleep", "(", "0.05", ")", "\n", "continue", "\n", "", "", "raise", "ValueError", "(", "\"Not able to download url right now, please try again.\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.exceptions.LightningNotInstalledException.__init__": [[15, 21], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "obj", ")", ":", "\n", "        ", "message", "=", "(", "\n", "f\" You are trying to use {obj} without installing all of pytorch_lightning, hydra, and \"", "\n", "f\"omegaconf. Please install those packages before trying to access {obj}.\"", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.exceptions.CheckInstall.__init__": [[26, 28], ["exceptions.LightningNotInstalledException"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "LightningNotInstalledException", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.exceptions.CheckInstall.__call__": [[29, 31], ["exceptions.LightningNotInstalledException"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "LightningNotInstalledException", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.exceptions.CheckInstall.__getattr__": [[32, 34], ["exceptions.LightningNotInstalledException"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "LightningNotInstalledException", "(", "self", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.__init__": [[53, 63], ["threading.Lock", "mridc_logging.Logger._define_logger", "set", "mridc.utils.get_rank.is_global_rank_zero"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger._define_logger", "home.repos.pwc.inspect_result.wdika_mridc.utils.get_rank.is_global_rank_zero"], ["def", "__init__", "(", "self", ",", "capture_warnings", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "_logger", "=", "None", "\n", "# Multi-GPU runs run in separate processes, thread locks shouldn't be needed", "\n", "self", ".", "_logger_lock", "=", "threading", ".", "Lock", "(", ")", "\n", "self", ".", "_handlers", "=", "{", "}", "\n", "self", ".", "old_warnings_showwarning", "=", "None", "\n", "self", ".", "_define_logger", "(", "capture_warnings", ")", "\n", "self", ".", "once_logged", "=", "set", "(", ")", "\n", "self", ".", "rank", "=", "0", "if", "is_global_rank_zero", "(", ")", "else", "\"UNK\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger._define_logger": [[64, 112], ["logging.getLogger", "mridc_logging.Logger.remove_stream_handlers", "mridc.utils.env_var_parsing.get_envbool", "mridc.utils.get_rank.is_global_rank_zero", "logging.handlers.MemoryHandler", "mridc_logging.Logger._handlers[].setFormatter", "mridc_logging.Logger._logger.addHandler", "mridc.utils.env_var_parsing.get_envbool", "mridc_logging.Logger.set_verbosity", "mridc_logging.Logger.captureWarnings", "logging.getLogRecordFactory", "logging.setLogRecordFactory", "mridc_logging.Logger.add_stream_handlers", "mridc.utils.get_rank.is_global_rank_zero", "logging.handlers.MemoryHandler", "mridc_logging.Logger._handlers[].addFilter", "mridc_logging.Logger._handlers[].setFormatter", "mridc_logging.Logger._logger.addHandler", "formatter", "logging.getLogRecordFactory.", "mridc_logging.Logger.add_stream_handlers", "formatter"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.remove_stream_handlers", "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envbool", "home.repos.pwc.inspect_result.wdika_mridc.utils.get_rank.is_global_rank_zero", "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envbool", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.set_verbosity", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.captureWarnings", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.add_stream_handlers", "home.repos.pwc.inspect_result.wdika_mridc.utils.get_rank.is_global_rank_zero", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.add_stream_handlers"], ["", "def", "_define_logger", "(", "self", ",", "capture_warnings", "=", "True", ")", ":", "\n", "        ", "\"\"\"Creates the logger if not already created. Called in init\"\"\"", "\n", "# Use double-checked locking to avoid taking lock unnecessarily.", "\n", "if", "self", ".", "_logger", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_logger", "\n", "\n", "", "with", "self", ".", "_logger_lock", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "_logger", "=", "_logging", ".", "getLogger", "(", "\"mridc_logger\"", ")", "\n", "# By default, silence all loggers except the logger for rank 0", "\n", "self", ".", "remove_stream_handlers", "(", ")", "\n", "# If MRIDC_TESTING is set, add a streamhandler to all ranks", "\n", "if", "get_envbool", "(", "MRIDC_ENV_VARNAME_TESTING", ",", "False", ")", ":", "\n", "                    ", "old_factory", "=", "_logging", ".", "getLogRecordFactory", "(", ")", "\n", "\n", "def", "record_factory", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "                        ", "record", "=", "old_factory", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "record", ".", "rank", "=", "self", ".", "rank", "\n", "return", "record", "\n", "\n", "", "_logging", ".", "setLogRecordFactory", "(", "record_factory", ")", "\n", "self", ".", "add_stream_handlers", "(", "formatter", "=", "DebugMRIDCFormatter", ")", "\n", "", "elif", "is_global_rank_zero", "(", ")", ":", "\n", "                    ", "self", ".", "add_stream_handlers", "(", ")", "\n", "\n", "# Add memoryhandlers, essentially buffers. They are used to save messages that we will flush to file", "\n", "# once the appropriate file handlers are added.", "\n", "", "if", "is_global_rank_zero", "(", ")", ":", "\n", "# Add a memoryhandler for error messages. Only logged on rank 0", "\n", "                    ", "self", ".", "_handlers", "[", "\"memory_err\"", "]", "=", "MemoryHandler", "(", "-", "1", ")", "\n", "self", ".", "_handlers", "[", "\"memory_err\"", "]", ".", "addFilter", "(", "lambda", "record", ":", "record", ".", "levelno", ">", "_logging", ".", "INFO", ")", "\n", "formatter", "=", "BaseMRIDCFormatter", "\n", "self", ".", "_handlers", "[", "\"memory_err\"", "]", ".", "setFormatter", "(", "formatter", "(", ")", ")", "\n", "self", ".", "_logger", ".", "addHandler", "(", "self", ".", "_handlers", "[", "\"memory_err\"", "]", ")", "\n", "# Add a memoryhandler for all messages on all ranks", "\n", "", "self", ".", "_handlers", "[", "\"memory_all\"", "]", "=", "MemoryHandler", "(", "-", "1", ")", "\n", "formatter", "=", "BaseMRIDCFormatter", "\n", "self", ".", "_handlers", "[", "\"memory_all\"", "]", ".", "setFormatter", "(", "formatter", "(", ")", ")", "\n", "self", ".", "_logger", ".", "addHandler", "(", "self", ".", "_handlers", "[", "\"memory_all\"", "]", ")", "\n", "\n", "", "finally", ":", "\n", "                ", "level", "=", "Logger", ".", "INFO", "\n", "if", "get_envbool", "(", "MRIDC_ENV_VARNAME_TESTING", ",", "False", ")", ":", "\n", "                    ", "level", "=", "Logger", ".", "DEBUG", "\n", "", "self", ".", "set_verbosity", "(", "verbosity_level", "=", "level", ")", "\n", "self", ".", "captureWarnings", "(", "capture_warnings", ")", "\n", "\n", "", "", "self", ".", "_logger", ".", "propagate", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.remove_stream_handlers": [[113, 131], ["RuntimeError", "mridc_logging.Logger._logger.removeHandler", "mridc_logging.Logger._logger.removeHandler"], "methods", ["None"], ["", "def", "remove_stream_handlers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Removes StreamHandler that log to stdout and stderr from the logger.\"\"\"", "\n", "if", "self", ".", "_logger", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Impossible to set handlers if the Logger is not predefined\"", ")", "\n", "\n", "# ======== Remove Handler if already existing ========", "\n", "\n", "", "try", ":", "\n", "            ", "self", ".", "_logger", ".", "removeHandler", "(", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ")", "\n", "del", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "pass", "\n", "\n", "", "try", ":", "\n", "            ", "self", ".", "_logger", ".", "removeHandler", "(", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ")", "\n", "del", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", "\n", "", "except", "KeyError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.add_stream_handlers": [[132, 160], ["mridc.utils.env_var_parsing.get_envbool", "mridc_logging.Logger._handlers[].setFormatter", "mridc_logging.Logger._logger.addHandler", "RuntimeError", "logging.StreamHandler", "logging.StreamHandler", "mridc_logging.Logger._handlers[].addFilter", "logging.StreamHandler", "mridc_logging.Logger._handlers[].addFilter", "formatter", "mridc_logging.Logger._handlers[].setFormatter", "mridc_logging.Logger._logger.addHandler", "formatter"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envbool"], ["", "", "def", "add_stream_handlers", "(", "self", ",", "formatter", "=", "BaseMRIDCFormatter", ")", ":", "\n", "        ", "\"\"\"\n        Add StreamHandler that log to stdout and stderr to the logger. INFO and lower logs are streamed to stdout\n        while WARNING and higher are streamed to stderr. If the MRIDC_ENV_VARNAME_REDIRECT_LOGS_TO_STDERR environment\n        variable is set, all logs are sent to stderr instead.\n        \"\"\"", "\n", "if", "self", ".", "_logger", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Impossible to set handlers if the Logger is not predefined\"", ")", "\n", "\n", "# Add the output handler.", "\n", "", "if", "get_envbool", "(", "MRIDC_ENV_VARNAME_REDIRECT_LOGS_TO_STDERR", ",", "False", ")", ":", "\n", "            ", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", "=", "_logging", ".", "StreamHandler", "(", "sys", ".", "stderr", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", "=", "_logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "\n", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ".", "addFilter", "(", "lambda", "record", ":", "record", ".", "levelno", "<=", "_logging", ".", "INFO", ")", "\n", "\n", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", "=", "_logging", ".", "StreamHandler", "(", "sys", ".", "stderr", ")", "\n", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ".", "addFilter", "(", "lambda", "record", ":", "record", ".", "levelno", ">", "_logging", ".", "INFO", ")", "\n", "\n", "", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ".", "setFormatter", "(", "formatter", "(", ")", ")", "\n", "self", ".", "_logger", ".", "addHandler", "(", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ")", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ".", "setFormatter", "(", "formatter", "(", ")", ")", "\n", "self", ".", "_logger", ".", "addHandler", "(", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ")", "\n", "", "except", "KeyError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.reset_stream_handler": [[161, 165], ["mridc_logging.Logger.remove_stream_handlers", "mridc_logging.Logger.add_stream_handlers"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.remove_stream_handlers", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.add_stream_handlers"], ["", "", "def", "reset_stream_handler", "(", "self", ",", "formatter", "=", "BaseMRIDCFormatter", ")", ":", "\n", "        ", "\"\"\"Removes then adds stream handlers.\"\"\"", "\n", "self", ".", "remove_stream_handlers", "(", ")", "\n", "self", ".", "add_stream_handlers", "(", "formatter", "=", "formatter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.add_file_handler": [[166, 184], ["logging.FileHandler", "mridc_logging.Logger._handlers[].setFormatter", "mridc_logging.Logger._logger.addHandler", "mridc_logging.Logger._handlers.get", "RuntimeError", "formatter", "mridc_logging.Logger._handlers[].setTarget", "mridc_logging.Logger._handlers[].close"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["", "def", "add_file_handler", "(", "self", ",", "log_file", ")", ":", "\n", "        ", "\"\"\"\n        Add a FileHandler to logger that logs all messages to a file. If the logger had a MemoryHandler at\n        self._handlers[\"memory_all\"], those buffered messages are flushed to the new file, and the MemoryHandler is\n        closed.\n        \"\"\"", "\n", "if", "self", ".", "_logger", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Impossible to set handlers if the Logger is not predefined\"", ")", "\n", "\n", "", "self", ".", "_handlers", "[", "\"file\"", "]", "=", "_logging", ".", "FileHandler", "(", "log_file", ")", "\n", "formatter", "=", "BaseMRIDCFormatter", "\n", "self", ".", "_handlers", "[", "\"file\"", "]", ".", "setFormatter", "(", "formatter", "(", ")", ")", "\n", "self", ".", "_logger", ".", "addHandler", "(", "self", ".", "_handlers", "[", "\"file\"", "]", ")", "\n", "\n", "if", "self", ".", "_handlers", ".", "get", "(", "\"memory_all\"", ")", ":", "\n", "            ", "self", ".", "_handlers", "[", "\"memory_all\"", "]", ".", "setTarget", "(", "self", ".", "_handlers", "[", "\"file\"", "]", ")", "\n", "self", ".", "_handlers", "[", "\"memory_all\"", "]", ".", "close", "(", ")", "# flush and remove", "\n", "del", "self", ".", "_handlers", "[", "\"memory_all\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.add_err_file_handler": [[185, 205], ["logging.FileHandler", "mridc_logging.Logger._handlers[].addFilter", "mridc_logging.Logger._handlers[].setFormatter", "mridc_logging.Logger._logger.addHandler", "mridc_logging.Logger._handlers.get", "RuntimeError", "formatter", "mridc_logging.Logger._handlers[].setTarget", "mridc_logging.Logger._handlers[].close"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["", "", "def", "add_err_file_handler", "(", "self", ",", "log_file", ")", ":", "\n", "        ", "\"\"\"\n        Add a FileHandler to logger that logs all WARNING and higher messages to a file. If the logger had a\n        MemoryHandler at self._handlers[\"memory_err\"], those buffered messages are flushed to the new file, and the\n        MemoryHandler is closed.\n        \"\"\"", "\n", "if", "self", ".", "_logger", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Impossible to set handlers if the Logger is not predefined\"", ")", "\n", "\n", "", "self", ".", "_handlers", "[", "\"file_err\"", "]", "=", "_logging", ".", "FileHandler", "(", "log_file", ")", "\n", "self", ".", "_handlers", "[", "\"file_err\"", "]", ".", "addFilter", "(", "lambda", "record", ":", "record", ".", "levelno", ">", "_logging", ".", "INFO", ")", "\n", "\n", "formatter", "=", "BaseMRIDCFormatter", "\n", "self", ".", "_handlers", "[", "\"file_err\"", "]", ".", "setFormatter", "(", "formatter", "(", ")", ")", "\n", "self", ".", "_logger", ".", "addHandler", "(", "self", ".", "_handlers", "[", "\"file_err\"", "]", ")", "\n", "\n", "if", "self", ".", "_handlers", ".", "get", "(", "\"memory_err\"", ")", ":", "\n", "            ", "self", ".", "_handlers", "[", "\"memory_err\"", "]", ".", "setTarget", "(", "self", ".", "_handlers", "[", "\"file_err\"", "]", ")", "\n", "self", ".", "_handlers", "[", "\"memory_err\"", "]", ".", "close", "(", ")", "# flush and remove", "\n", "del", "self", ".", "_handlers", "[", "\"memory_err\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.getEffectiveLevel": [[206, 210], ["mridc_logging.Logger._logger.getEffectiveLevel"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.getEffectiveLevel"], ["", "", "def", "getEffectiveLevel", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return how much logging output will be produced.\"\"\"", "\n", "if", "self", ".", "_logger", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_logger", ".", "getEffectiveLevel", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.get_verbosity": [[211, 214], ["mridc_logging.Logger.getEffectiveLevel"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.getEffectiveLevel"], ["", "", "def", "get_verbosity", "(", "self", ")", ":", "\n", "        ", "\"\"\"See getEffectiveLevel\"\"\"", "\n", "return", "self", ".", "getEffectiveLevel", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.setLevel": [[215, 222], ["mridc_logging.Logger._logger.setLevel", "handler.setLevel"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.setLevel", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.setLevel"], ["", "def", "setLevel", "(", "self", ",", "verbosity_level", ")", ":", "\n", "        ", "\"\"\"Sets the threshold for what messages will be logged.\"\"\"", "\n", "if", "self", ".", "_logger", "is", "not", "None", ":", "\n", "            ", "self", ".", "_logger", ".", "setLevel", "(", "verbosity_level", ")", "\n", "\n", "for", "handler", "in", "self", ".", "_logger", ".", "handlers", ":", "\n", "                ", "handler", ".", "setLevel", "(", "verbosity_level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.set_verbosity": [[223, 226], ["mridc_logging.Logger.setLevel"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.setLevel"], ["", "", "", "def", "set_verbosity", "(", "self", ",", "verbosity_level", ")", ":", "\n", "        ", "\"\"\"See setLevel\"\"\"", "\n", "self", ".", "setLevel", "(", "verbosity_level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.patch_stderr_handler": [[227, 257], ["RuntimeError", "mridc_logging.Logger._handlers[].acquire", "mridc_logging.Logger._handlers[].acquire", "mridc_logging.Logger._handlers[].flush", "mridc_logging.Logger._handlers[].release", "RuntimeError", "mridc_logging.Logger._handlers[].flush", "mridc_logging.Logger._handlers[].release"], "methods", ["None"], ["", "@", "contextmanager", "\n", "def", "patch_stderr_handler", "(", "self", ",", "stream", ")", ":", "\n", "        ", "\"\"\"Sends messages that should log to stderr to stream instead. Useful for unittests\"\"\"", "\n", "if", "self", ".", "_logger", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Impossible to patch logging handlers if handler does not exist\"", ")", "\n", "", "try", ":", "\n", "            ", "old_stream", "=", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ".", "stream", "\n", "if", "old_stream", "is", "None", ":", "\n", "                ", "raise", "ValueError", "\n", "\n", "# Port backwards set_stream() from python 3.7", "\n", "", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ".", "acquire", "(", ")", "\n", "try", ":", "\n", "                ", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ".", "flush", "(", ")", "\n", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ".", "stream", "=", "stream", "\n", "", "finally", ":", "\n", "                ", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ".", "release", "(", ")", "\n", "\n", "", "yield", "stream", "\n", "", "except", "(", "KeyError", ",", "ValueError", ")", "as", "e", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Impossible to patch logging handlers if handler does not exist\"", ")", "from", "e", "\n", "\n", "", "finally", ":", "\n", "# Port backwards set_stream() from python 3.7", "\n", "            ", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ".", "acquire", "(", ")", "\n", "try", ":", "\n", "                ", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ".", "flush", "(", ")", "\n", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ".", "stream", "=", "old_stream", "\n", "", "finally", ":", "\n", "                ", "self", ".", "_handlers", "[", "\"stream_stderr\"", "]", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.patch_stdout_handler": [[258, 288], ["RuntimeError", "mridc_logging.Logger._handlers[].acquire", "mridc_logging.Logger._handlers[].acquire", "mridc_logging.Logger._handlers[].flush", "mridc_logging.Logger._handlers[].release", "RuntimeError", "mridc_logging.Logger._handlers[].flush", "mridc_logging.Logger._handlers[].release"], "methods", ["None"], ["", "", "", "@", "contextmanager", "\n", "def", "patch_stdout_handler", "(", "self", ",", "stream", ")", ":", "\n", "        ", "\"\"\"Sends messages that should log to stdout to stream instead. Useful for unittests\"\"\"", "\n", "if", "self", ".", "_logger", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Impossible to patch logging handlers if handler does not exist\"", ")", "\n", "", "try", ":", "\n", "            ", "old_stream", "=", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ".", "stream", "\n", "if", "old_stream", "is", "None", ":", "\n", "                ", "raise", "ValueError", "\n", "\n", "# Port backwards set_stream() from python 3.7", "\n", "", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ".", "acquire", "(", ")", "\n", "try", ":", "\n", "                ", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ".", "flush", "(", ")", "\n", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ".", "stream", "=", "stream", "\n", "", "finally", ":", "\n", "                ", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ".", "release", "(", ")", "\n", "\n", "", "yield", "stream", "\n", "", "except", "(", "KeyError", ",", "ValueError", ")", "as", "e", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Impossible to patch logging handlers if handler does not exist\"", ")", "from", "e", "\n", "\n", "", "finally", ":", "\n", "# Port backwards set_stream() from python 3.7", "\n", "            ", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ".", "acquire", "(", ")", "\n", "try", ":", "\n", "                ", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ".", "flush", "(", ")", "\n", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ".", "stream", "=", "old_stream", "\n", "", "finally", ":", "\n", "                ", "self", ".", "_handlers", "[", "\"stream_stdout\"", "]", ".", "release", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.temp_verbosity": [[289, 309], ["mridc_logging.Logger.get_verbosity", "mridc_logging.Logger.set_verbosity", "mridc_logging.Logger.set_verbosity"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.get_verbosity", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.set_verbosity", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.set_verbosity"], ["", "", "", "@", "contextmanager", "\n", "def", "temp_verbosity", "(", "self", ",", "verbosity_level", ")", ":", "\n", "        ", "\"\"\"Sets a temporary threshold for what messages will be logged.\"\"\"", "\n", "if", "self", ".", "_logger", "is", "not", "None", ":", "\n", "\n", "            ", "old_verbosity", "=", "self", ".", "get_verbosity", "(", ")", "\n", "\n", "try", ":", "\n", "                ", "self", ".", "set_verbosity", "(", "verbosity_level", ")", "\n", "yield", "\n", "\n", "", "finally", ":", "\n", "                ", "self", ".", "set_verbosity", "(", "old_verbosity", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "yield", "\n", "\n", "", "finally", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.captureWarnings": [[310, 326], ["None"], "methods", ["None"], ["", "", "", "def", "captureWarnings", "(", "self", ",", "capture", ")", ":", "\n", "        ", "\"\"\"\n        If capture is true, redirect all warnings to the logging package.\n        If capture is False, ensure that warnings are not redirected to logging but to their original destinations.\n        \"\"\"", "\n", "if", "self", ".", "_logger", "is", "not", "None", ":", "\n", "\n", "            ", "if", "capture", "and", "self", ".", "old_warnings_showwarning", "is", "None", ":", "\n", "# Backup Method", "\n", "                ", "self", ".", "old_warnings_showwarning", "=", "warnings", ".", "showwarning", "\n", "warnings", ".", "showwarning", "=", "self", ".", "_showwarning", "\n", "\n", "", "elif", "not", "capture", "and", "self", ".", "old_warnings_showwarning", "is", "not", "None", ":", "\n", "# Restore Method", "\n", "                ", "warnings", ".", "showwarning", "=", "self", ".", "old_warnings_showwarning", "\n", "self", ".", "old_warnings_showwarning", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger._showwarning": [[327, 334], ["warnings.formatwarning", "mridc_logging.Logger.warning"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning"], ["", "", "", "def", "_showwarning", "(", "self", ",", "message", ",", "category", ",", "filename", ",", "lineno", ",", "file", "=", "None", ",", "line", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Implementation of show warnings which redirects to logging.\n        It will call warnings.formatwarning and will log the resulting string with level logging.WARNING.\n        \"\"\"", "\n", "s", "=", "warnings", ".", "formatwarning", "(", "message", ",", "category", ",", "filename", ",", "lineno", ",", "line", ")", "\n", "self", ".", "warning", "(", "\"%s\"", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger._logged_once": [[335, 354], ["mridc_logging.Logger.once_logged.add"], "methods", ["None"], ["", "def", "_logged_once", "(", "self", ",", "msg", ",", "mode", ")", ":", "\n", "        ", "\"\"\"\n        Returns True if the given message has been logged at least once in the given mode.\n\n        Parameters\n        ----------\n        msg: The message to check.\n        mode: The mode to check.\n\n        Returns\n        -------\n        True if the message has been logged at least once in the given mode.\n        \"\"\"", "\n", "if", "mode", "==", "LogMode", ".", "ONCE", ":", "\n", "            ", "PREFIX_LEN", "=", "12", "\n", "if", "msg", "[", "PREFIX_LEN", ":", "]", "in", "self", ".", "once_logged", ":", "\n", "                ", "return", "True", "\n", "", "self", ".", "once_logged", ".", "add", "(", "msg", "[", "PREFIX_LEN", ":", "]", ")", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.debug": [[355, 363], ["mridc_logging.Logger._logger.isEnabledFor", "mridc_logging.Logger._logger._log", "mridc_logging.Logger._logged_once"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger._logged_once"], ["", "def", "debug", "(", "self", ",", "msg", ",", "*", "args", ",", "mode", "=", "LogMode", ".", "EACH", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Log 'msg % args' with severity 'DEBUG'.\n        To pass exception information, use the keyword argument exc_info with a true value, e.g.\n        logger.debug(\"Houston, we have %s\", \"thorny problem\", exc_info=1)\n        \"\"\"", "\n", "if", "self", ".", "_logger", "is", "not", "None", "and", "self", ".", "_logger", ".", "isEnabledFor", "(", "Logger", ".", "DEBUG", ")", "and", "not", "self", ".", "_logged_once", "(", "msg", ",", "mode", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "_log", "(", "Logger", ".", "DEBUG", ",", "msg", ",", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info": [[364, 372], ["mridc_logging.Logger._logger.isEnabledFor", "mridc_logging.Logger._logger._log", "mridc_logging.Logger._logged_once"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger._logged_once"], ["", "", "def", "info", "(", "self", ",", "msg", ",", "*", "args", ",", "mode", "=", "LogMode", ".", "EACH", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Log 'msg % args' with severity 'INFO'.\n        To pass exception information, use the keyword argument exc_info with a true value, e.g.\n        logger.info(\"Houston, we have %s\", \"interesting problem\", exc_info=1)\n        \"\"\"", "\n", "if", "self", ".", "_logger", "is", "not", "None", "and", "self", ".", "_logger", ".", "isEnabledFor", "(", "Logger", ".", "INFO", ")", "and", "not", "self", ".", "_logged_once", "(", "msg", ",", "mode", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "_log", "(", "Logger", ".", "INFO", ",", "msg", ",", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning": [[373, 381], ["mridc_logging.Logger._logger.isEnabledFor", "mridc_logging.Logger._logger._log", "mridc_logging.Logger._logged_once"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger._logged_once"], ["", "", "def", "warning", "(", "self", ",", "msg", ",", "*", "args", ",", "mode", "=", "LogMode", ".", "EACH", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Log 'msg % args' with severity 'WARNING'.\n        To pass exception information, use the keyword argument exc_info with a true value, e.g.\n        logger.warning(\"Houston, we have %s\", \"bit of a problem\", exc_info=1)\n        \"\"\"", "\n", "if", "self", ".", "_logger", "is", "not", "None", "and", "self", ".", "_logger", ".", "isEnabledFor", "(", "Logger", ".", "WARNING", ")", "and", "not", "self", ".", "_logged_once", "(", "msg", ",", "mode", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "_log", "(", "Logger", ".", "WARNING", ",", "msg", ",", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error": [[382, 390], ["mridc_logging.Logger._logger.isEnabledFor", "mridc_logging.Logger._logger._log", "mridc_logging.Logger._logged_once"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger._logged_once"], ["", "", "def", "error", "(", "self", ",", "msg", ",", "*", "args", ",", "mode", "=", "LogMode", ".", "EACH", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Log 'msg % args' with severity 'ERROR'.\n        To pass exception information, use the keyword argument exc_info with a true value, e.g.\n        logger.error(\"Houston, we have %s\", \"major problem\", exc_info=1)\n        \"\"\"", "\n", "if", "self", ".", "_logger", "is", "not", "None", "and", "self", ".", "_logger", ".", "isEnabledFor", "(", "Logger", ".", "ERROR", ")", "and", "not", "self", ".", "_logged_once", "(", "msg", ",", "mode", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "_log", "(", "Logger", ".", "ERROR", ",", "msg", ",", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.critical": [[391, 410], ["mridc_logging.Logger._logger.isEnabledFor", "mridc_logging.Logger._logger._log", "mridc_logging.Logger._logged_once"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger._logged_once"], ["", "", "def", "critical", "(", "self", ",", "msg", ",", "*", "args", ",", "mode", "=", "LogMode", ".", "EACH", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Log 'msg % args' with severity 'CRITICAL'.\n        To pass exception information, use the keyword argument exc_info with a true value, e.g.\n        logger.critical(\"Houston, we have %s\", \"major disaster\", exc_info=1)\n\n        Parameters\n        ----------\n        msg: the message to log\n        *args: the arguments to the message\n        mode: the mode to log the message in\n        **kwargs: the keyword arguments to the message\n        \"\"\"", "\n", "if", "(", "\n", "self", ".", "_logger", "is", "not", "None", "\n", "and", "self", ".", "_logger", ".", "isEnabledFor", "(", "Logger", ".", "CRITICAL", ")", "\n", "and", "not", "self", ".", "_logged_once", "(", "msg", ",", "mode", ")", "\n", ")", ":", "\n", "            ", "self", ".", "_logger", ".", "_log", "(", "Logger", ".", "CRITICAL", ",", "msg", ",", "args", ",", "**", "kwargs", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.get_rank.is_global_rank_zero": [[8, 25], ["mridc.utils.env_var_parsing.get_envint", "mridc.utils.env_var_parsing.get_envint", "mridc.utils.env_var_parsing.get_envint", "mridc.utils.env_var_parsing.get_envint", "mridc.utils.env_var_parsing.get_envint"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envint", "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envint", "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envint", "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envint", "home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envint"], ["def", "is_global_rank_zero", "(", ")", ":", "\n", "    ", "\"\"\"Helper function to determine if the current process is global_rank 0 (the main process).\"\"\"", "\n", "# Try to get the pytorch RANK env var RANK is set by torch.distributed.launch", "\n", "rank", "=", "get_envint", "(", "\"RANK\"", ",", "None", ")", "\n", "if", "rank", "is", "not", "None", ":", "\n", "        ", "return", "rank", "==", "0", "\n", "\n", "# Try to get the SLURM global rank env var SLURM_PROCID is set by SLURM", "\n", "", "slurm_rank", "=", "get_envint", "(", "\"SLURM_PROCID\"", ",", "None", ")", "\n", "if", "slurm_rank", "is", "not", "None", ":", "\n", "        ", "return", "slurm_rank", "==", "0", "\n", "\n", "# if neither pytorch and SLURM env vars are set check NODE_RANK/GROUP_RANK and LOCAL_RANK env vars assume", "\n", "# global_rank is zero if undefined", "\n", "", "node_rank", "=", "get_envint", "(", "\"NODE_RANK\"", ",", "get_envint", "(", "\"GROUP_RANK\"", ",", "0", ")", ")", "\n", "local_rank", "=", "get_envint", "(", "\"LOCAL_RANK\"", ",", "0", ")", "\n", "return", "node_rank", "==", "0", "and", "local_rank", "==", "0", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.lightning_logger_patch.add_memory_handlers_to_pl_logger": [[16, 28], ["logging.handlers.MemoryHandler", "HANDLERS[].addFilter", "logging.handlers.MemoryHandler", "pytorch_lightning._logger.addHandler", "pytorch_lightning._logger.addHandler"], "function", ["None"], ["def", "add_memory_handlers_to_pl_logger", "(", ")", ":", "\n", "    ", "\"\"\"\n    Adds two MemoryHandlers to pytorch_lightning's logger. These two handlers are essentially message buffers. This\n    function is called in mridc.utils.__init__.py. These handlers are used in add_filehandlers_to_pl_logger to flush\n    buffered messages to files.\n    \"\"\"", "\n", "if", "not", "HANDLERS", ":", "\n", "        ", "HANDLERS", "[", "\"memory_err\"", "]", "=", "MemoryHandler", "(", "-", "1", ")", "\n", "HANDLERS", "[", "\"memory_err\"", "]", ".", "addFilter", "(", "lambda", "record", ":", "record", ".", "levelno", ">", "_logging", ".", "INFO", ")", "\n", "HANDLERS", "[", "\"memory_all\"", "]", "=", "MemoryHandler", "(", "-", "1", ")", "\n", "pl", ".", "_logger", ".", "addHandler", "(", "HANDLERS", "[", "\"memory_err\"", "]", ")", "\n", "pl", ".", "_logger", ".", "addHandler", "(", "HANDLERS", "[", "\"memory_all\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.lightning_logger_patch.add_filehandlers_to_pl_logger": [[30, 51], ["logging.FileHandler", "pytorch_lightning._logger.addHandler", "logging.FileHandler", "HANDLERS[].addFilter", "pytorch_lightning._logger.addHandler", "HANDLERS.get", "HANDLERS.get", "HANDLERS[].setTarget", "HANDLERS[].close", "HANDLERS[].setTarget", "HANDLERS[].close"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["", "", "def", "add_filehandlers_to_pl_logger", "(", "all_log_file", ",", "err_log_file", ")", ":", "\n", "    ", "\"\"\"\n    Adds two filehandlers to pytorch_lightning's logger. Called in mridc.utils.exp_manager(). The first filehandler\n    logs all messages to all_log_file while the second filehandler logs all WARNING and higher messages to\n    err_log_file. If \"memory_err\" and \"memory_all\" exist in HANDLERS, then those buffers are flushed to err_log_file\n    and all_log_file respectively, and then closed.\n    \"\"\"", "\n", "HANDLERS", "[", "\"file\"", "]", "=", "_logging", ".", "FileHandler", "(", "all_log_file", ")", "\n", "pl", ".", "_logger", ".", "addHandler", "(", "HANDLERS", "[", "\"file\"", "]", ")", "\n", "HANDLERS", "[", "\"file_err\"", "]", "=", "_logging", ".", "FileHandler", "(", "err_log_file", ")", "\n", "HANDLERS", "[", "\"file_err\"", "]", ".", "addFilter", "(", "lambda", "record", ":", "record", ".", "levelno", ">", "_logging", ".", "INFO", ")", "\n", "pl", ".", "_logger", ".", "addHandler", "(", "HANDLERS", "[", "\"file_err\"", "]", ")", "\n", "\n", "if", "HANDLERS", ".", "get", "(", "\"memory_all\"", ")", ":", "\n", "        ", "HANDLERS", "[", "\"memory_all\"", "]", ".", "setTarget", "(", "HANDLERS", "[", "\"file\"", "]", ")", "\n", "HANDLERS", "[", "\"memory_all\"", "]", ".", "close", "(", ")", "\n", "del", "HANDLERS", "[", "\"memory_all\"", "]", "\n", "", "if", "HANDLERS", ".", "get", "(", "\"memory_err\"", ")", ":", "\n", "        ", "HANDLERS", "[", "\"memory_err\"", "]", ".", "setTarget", "(", "HANDLERS", "[", "\"file_err\"", "]", ")", "\n", "HANDLERS", "[", "\"memory_err\"", "]", ".", "close", "(", ")", "\n", "del", "HANDLERS", "[", "\"memory_err\"", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.timers.NamedTimer.__init__": [[24, 41], ["timers.NamedTimer.reset", "ValueError"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.timers.NamedTimer.reset"], ["def", "__init__", "(", "self", ",", "reduction", "=", "\"mean\"", ",", "sync_cuda", "=", "False", ",", "buffer_size", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        reduction: Reduction over multiple timings of the same timer (none - returns the list instead of a scalar).\n        sync_cuda: If True torch.cuda.synchronize() is called for start/stop\n        buffer_size: If positive, limits the number of stored measures per name\n        \"\"\"", "\n", "if", "reduction", "not", "in", "self", ".", "_REDUCTION_TYPE", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Unknown reduction={reduction} please use one of {self._REDUCTION_TYPE}\"", ")", "\n", "\n", "", "self", ".", "_reduction", "=", "reduction", "\n", "self", ".", "_sync_cuda", "=", "sync_cuda", "\n", "self", ".", "_buffer_size", "=", "buffer_size", "\n", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.timers.NamedTimer.__getitem__": [[42, 44], ["timers.NamedTimer.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["", "def", "__getitem__", "(", "self", ",", "k", ")", ":", "\n", "        ", "return", "self", ".", "get", "(", "k", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.timers.NamedTimer.buffer_size": [[45, 49], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "buffer_size", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the buffer size of the timer.\"\"\"", "\n", "return", "self", ".", "_buffer_size", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.timers.NamedTimer._reduction_fn": [[50, 62], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "_reduction_fn", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the reduction function for the timer.\"\"\"", "\n", "if", "self", ".", "_reduction", "==", "\"none\"", ":", "\n", "\n", "            ", "def", "fn", "(", "x", ")", ":", "\n", "                ", "return", "x", "\n", "\n", "", "", "else", ":", "\n", "            ", "fn", "=", "getattr", "(", "np", ",", "self", ".", "_reduction", ")", "\n", "\n", "", "return", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.timers.NamedTimer.reset": [[63, 75], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ",", "name", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Resents all / specific timer\n\n        Parameters\n        ----------\n        name: Timer name to reset (if None all timers are reset)\n        \"\"\"", "\n", "if", "name", "is", "None", ":", "\n", "            ", "self", ".", "timers", "=", "{", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "timers", "[", "name", "]", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.timers.NamedTimer.start": [[76, 96], ["timers.NamedTimer.timers.get", "time.time", "RuntimeError", "torch.cuda.is_initialized", "torch.cuda.synchronize"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["", "", "def", "start", "(", "self", ",", "name", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Starts measuring a named timer.\n\n        Parameters\n        ----------\n        name: timer name to start\n        \"\"\"", "\n", "timer_data", "=", "self", ".", "timers", ".", "get", "(", "name", ",", "{", "}", ")", "\n", "\n", "if", "\"start\"", "in", "timer_data", ":", "\n", "            ", "raise", "RuntimeError", "(", "f\"Cannot start timer = '{name}' since it is already active\"", ")", "\n", "\n", "# synchronize pytorch cuda execution if supported", "\n", "", "if", "self", ".", "_sync_cuda", "and", "torch", ".", "cuda", ".", "is_initialized", "(", ")", ":", "\n", "            ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "", "timer_data", "[", "\"start\"", "]", "=", "time", ".", "time", "(", ")", "\n", "\n", "self", ".", "timers", "[", "name", "]", "=", "timer_data", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.timers.NamedTimer.stop": [[97, 124], ["timers.NamedTimer.timers.get", "RuntimeError", "torch.cuda.is_initialized", "torch.cuda.synchronize", "time.time", "timers.NamedTimer.pop", "timers.NamedTimer.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["", "def", "stop", "(", "self", ",", "name", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Stops measuring a named timer.\n\n        Parameters\n        ----------\n        name: timer name to stop\n        \"\"\"", "\n", "timer_data", "=", "self", ".", "timers", ".", "get", "(", "name", ")", "\n", "if", "(", "timer_data", "is", "None", ")", "or", "(", "\"start\"", "not", "in", "timer_data", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "f\"Cannot end timer = '{name}' since it is not active\"", ")", "\n", "\n", "# synchronize pytorch cuda execution if supported", "\n", "", "if", "self", ".", "_sync_cuda", "and", "torch", ".", "cuda", ".", "is_initialized", "(", ")", ":", "\n", "            ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "# compute dt and make timer inactive", "\n", "", "dt", "=", "time", ".", "time", "(", ")", "-", "timer_data", ".", "pop", "(", "\"start\"", ")", "\n", "\n", "# store dt", "\n", "timer_data", "[", "\"dt\"", "]", "=", "timer_data", ".", "get", "(", "\"dt\"", ",", "[", "]", ")", "+", "[", "dt", "]", "\n", "\n", "# enforce buffer_size if positive", "\n", "if", "self", ".", "_buffer_size", ">", "0", ":", "\n", "            ", "timer_data", "[", "\"dt\"", "]", "=", "timer_data", "[", "\"dt\"", "]", "[", "-", "self", ".", "_buffer_size", ":", "]", "\n", "\n", "", "self", ".", "timers", "[", "name", "]", "=", "timer_data", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.timers.NamedTimer.active_timers": [[125, 128], ["timers.NamedTimer.timers.items"], "methods", ["None"], ["", "def", "active_timers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return list of all active named timers\"\"\"", "\n", "return", "[", "k", "for", "k", ",", "v", "in", "self", ".", "timers", ".", "items", "(", ")", "if", "\"start\"", "in", "v", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.timers.NamedTimer.get": [[129, 140], ["timers.NamedTimer.timers[].get", "timers.NamedTimer._reduction_fn"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.utils.timers.NamedTimer._reduction_fn"], ["", "def", "get", "(", "self", ",", "name", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"\n        Returns the value of a named timer\n\n        Parameters\n        ----------\n        name: timer name to return\n        \"\"\"", "\n", "dt_list", "=", "self", ".", "timers", "[", "name", "]", ".", "get", "(", "\"dt\"", ",", "[", "]", ")", "\n", "\n", "return", "self", ".", "_reduction_fn", "(", "dt_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.timers.NamedTimer.export": [[141, 146], ["timers.NamedTimer._reduction_fn.fn", "timers.NamedTimer.timers.items"], "methods", ["None"], ["", "def", "export", "(", "self", ")", ":", "\n", "        ", "\"\"\"Exports a dictionary with average/all dt per named timer\"\"\"", "\n", "fn", "=", "self", ".", "_reduction_fn", "\n", "\n", "return", "{", "k", ":", "fn", "(", "v", "[", "\"dt\"", "]", ")", "for", "k", ",", "v", "in", "self", ".", "timers", ".", "items", "(", ")", "if", "\"dt\"", "in", "v", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.config_utils.update_model_config": [[21, 88], ["dataclasses.is_dataclass", "config_utils._update_subconfig", "config_utils._update_subconfig", "config_utils._update_subconfig", "config_utils._update_subconfig", "config_utils._add_subconfig_keys", "omegaconf.OmegaConf.merge", "mridc.utils.logging.error", "sys.exit", "ValueError", "isinstance", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.structured", "dataclasses.is_dataclass", "isinstance", "omegaconf.open_dict", "OmegaConf.create.model.pop", "omegaconf.open_dict", "OmegaConf.create.model.pop"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.config_utils._update_subconfig", "home.repos.pwc.inspect_result.wdika_mridc.utils.config_utils._update_subconfig", "home.repos.pwc.inspect_result.wdika_mridc.utils.config_utils._update_subconfig", "home.repos.pwc.inspect_result.wdika_mridc.utils.config_utils._update_subconfig", "home.repos.pwc.inspect_result.wdika_mridc.utils.config_utils._add_subconfig_keys", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error"], ["def", "update_model_config", "(", "model_cls", ":", "MRIDCConfig", ",", "update_cfg", ":", "\"DictConfig\"", ",", "drop_missing_subconfigs", ":", "bool", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Helper class that updates the default values of a ModelPT config class with the values in a DictConfig that \\\n    mirrors the structure of the config class. Assumes the `update_cfg` is a DictConfig (either generated manually, \\\n    via hydra or instantiated via yaml/model.cfg). This update_cfg is then used to override the default values \\\n    preset inside the ModelPT config class. If `drop_missing_subconfigs` is set, the certain sub-configs of the \\\n    ModelPT config class will be removed, if they are not found in the mirrored `update_cfg`. The following \\\n    sub-configs are subject to potential removal:\n        -   `train_ds`\n        -   `validation_ds`\n        -   `test_ds`\n        -   `optim` + nested sched\n\n    Parameters\n    ----------\n    model_cls: A subclass of MRIDC, that details in entirety all the parameters that constitute the MRIDC Model.\n    update_cfg: A DictConfig that mirrors the structure of the MRIDCConfig data class. Used to update the default \\\n    values of the config class.\n    drop_missing_subconfigs: Bool which determines whether to drop certain sub-configs from the MRIDCConfig class, \\\n    if the corresponding sub-config is missing from `update_cfg`.\n\n    Returns\n    -------\n    A DictConfig with updated values that can be used to instantiate the MRIDC Model along with supporting \\\n    infrastructure.\n    \"\"\"", "\n", "if", "not", "_HAS_HYDRA", ":", "\n", "        ", "logging", ".", "error", "(", "\"This function requires Hydra/Omegaconf and it was not installed.\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "if", "not", "(", "is_dataclass", "(", "model_cls", ")", "or", "isinstance", "(", "model_cls", ",", "DictConfig", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"`model_cfg` must be a dataclass or a structured OmegaConf object\"", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "update_cfg", ",", "DictConfig", ")", ":", "\n", "        ", "update_cfg", "=", "OmegaConf", ".", "create", "(", "update_cfg", ")", "\n", "\n", "", "if", "is_dataclass", "(", "model_cls", ")", ":", "\n", "        ", "model_cls", "=", "OmegaConf", ".", "structured", "(", "model_cls", ")", "\n", "\n", "# Update optional configs", "\n", "", "model_cls", "=", "_update_subconfig", "(", "\n", "model_cls", ",", "update_cfg", ",", "subconfig_key", "=", "\"train_ds\"", ",", "drop_missing_subconfigs", "=", "drop_missing_subconfigs", "\n", ")", "\n", "model_cls", "=", "_update_subconfig", "(", "\n", "model_cls", ",", "update_cfg", ",", "subconfig_key", "=", "\"validation_ds\"", ",", "drop_missing_subconfigs", "=", "drop_missing_subconfigs", "\n", ")", "\n", "model_cls", "=", "_update_subconfig", "(", "\n", "model_cls", ",", "update_cfg", ",", "subconfig_key", "=", "\"test_ds\"", ",", "drop_missing_subconfigs", "=", "drop_missing_subconfigs", "\n", ")", "\n", "model_cls", "=", "_update_subconfig", "(", "\n", "model_cls", ",", "update_cfg", ",", "subconfig_key", "=", "\"optim\"", ",", "drop_missing_subconfigs", "=", "drop_missing_subconfigs", "\n", ")", "\n", "\n", "# Add optim and sched additional keys to model cls", "\n", "model_cls", "=", "_add_subconfig_keys", "(", "model_cls", ",", "update_cfg", ",", "subconfig_key", "=", "\"optim\"", ")", "\n", "\n", "# Perform full merge of model config class and update config", "\n", "# Remove ModelPT artifact `target`", "\n", "if", "\"target\"", "in", "update_cfg", ".", "model", "and", "\"target\"", "not", "in", "model_cls", ".", "model", ":", "# type: ignore", "\n", "        ", "with", "open_dict", "(", "update_cfg", ".", "model", ")", ":", "\n", "            ", "update_cfg", ".", "model", ".", "pop", "(", "\"target\"", ")", "\n", "\n", "# Remove ModelPT artifact `mridc_version`", "\n", "", "", "if", "\"mridc_version\"", "in", "update_cfg", ".", "model", "and", "\"mridc_version\"", "not", "in", "model_cls", ".", "model", ":", "# type: ignore", "\n", "        ", "with", "open_dict", "(", "update_cfg", ".", "model", ")", ":", "\n", "            ", "update_cfg", ".", "model", ".", "pop", "(", "\"mridc_version\"", ")", "\n", "\n", "", "", "return", "OmegaConf", ".", "merge", "(", "model_cls", ",", "update_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.config_utils._update_subconfig": [[90, 127], ["mridc.utils.logging.error", "sys.exit", "omegaconf.open_dict", "model_cfg.model.pop"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error"], ["", "def", "_update_subconfig", "(", "\n", "model_cfg", ":", "\"DictConfig\"", ",", "update_cfg", ":", "\"DictConfig\"", ",", "subconfig_key", ":", "str", ",", "drop_missing_subconfigs", ":", "bool", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Updates the MRIDCConfig DictConfig such that:\n        1)  If the sub-config key exists in the `update_cfg`, but does not exist in ModelPT config:\n            - Add the sub-config from update_cfg to ModelPT config\n        2) If the sub-config key does not exist in `update_cfg`, but exists in ModelPT config:\n            - Remove the sub-config from the ModelPT config; iff the `drop_missing_subconfigs` flag is set.\n\n    Parameters\n    ----------\n    model_cfg: A DictConfig instantiated from the MRIDCConfig subclass.\n    update_cfg: A DictConfig that mirrors the structure of `model_cfg`, used to update its default values.\n    subconfig_key: A str key used to check and update the sub-config.\n    drop_missing_subconfigs: A bool flag, whether to allow deletion of the MRIDCConfig sub-config, if its mirror\n    sub-config does not exist in the `update_cfg`.\n\n    Returns\n    -------\n    The updated DictConfig for the MRIDCConfig\n    \"\"\"", "\n", "if", "not", "_HAS_HYDRA", ":", "\n", "        ", "logging", ".", "error", "(", "\"This function requires Hydra/Omegaconf and it was not installed.\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "with", "open_dict", "(", "model_cfg", ".", "model", ")", ":", "\n", "# If update config has the key, but model cfg doesnt have the key", "\n", "# Add the update cfg subconfig to the model cfg", "\n", "        ", "if", "subconfig_key", "in", "update_cfg", ".", "model", "and", "subconfig_key", "not", "in", "model_cfg", ".", "model", ":", "\n", "            ", "model_cfg", ".", "model", "[", "subconfig_key", "]", "=", "update_cfg", ".", "model", "[", "subconfig_key", "]", "\n", "\n", "# If update config does not the key, but model cfg has the key", "\n", "# Remove the model cfg subconfig in order to match layout of update cfg", "\n", "", "if", "subconfig_key", "not", "in", "update_cfg", ".", "model", "and", "subconfig_key", "in", "model_cfg", ".", "model", "and", "drop_missing_subconfigs", ":", "\n", "            ", "model_cfg", ".", "model", ".", "pop", "(", "subconfig_key", ")", "\n", "\n", "", "", "return", "model_cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.config_utils._add_subconfig_keys": [[129, 174], ["mridc.utils.logging.error", "sys.exit", "omegaconf.open_dict", "copy.deepcopy", "copy.deepcopy", "omegaconf.OmegaConf.merge"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error"], ["", "def", "_add_subconfig_keys", "(", "model_cfg", ":", "\"DictConfig\"", ",", "update_cfg", ":", "\"DictConfig\"", ",", "subconfig_key", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    For certain sub-configs, the default values specified by the MRIDCConfig class is insufficient.\n    In order to support every potential value in the merge between the `update_cfg`, it would require explicit\n    definition of all possible cases.\n    An example of such a case is Optimizers, and their equivalent Schedulers. All optimizers share a few basic details\n    - such as name and lr, but almost all require additional parameters - such as weight decay.\n    It is impractical to create a config for every single optimizer + every single scheduler combination.\n    In such a case, we perform a dual merge. The Optim and Sched Dataclass contain the bare minimum essential\n    components. The extra values are provided via update_cfg.\n    In order to enable the merge, we first need to update the update sub-config to incorporate the keys, with dummy\n    temporary values (merge update config with model config). This is done on a copy of the update sub-config, as the\n    actual override values might be overridden by the MRIDCConfig defaults.\n    Then we perform a merge of this temporary sub-config with the actual override config in a later step (merge\n    model_cfg with original update_cfg, done outside this function).\n\n    Parameters\n    ----------\n    model_cfg: A DictConfig instantiated from the MRIDCConfig subclass.\n    update_cfg: A DictConfig that mirrors the structure of `model_cfg`, used to update its default values.\n    subconfig_key: A str key used to check and update the sub-config.\n\n    Returns\n    -------\n    A ModelPT DictConfig with additional keys added to the sub-config.\n    \"\"\"", "\n", "if", "not", "_HAS_HYDRA", ":", "\n", "        ", "logging", ".", "error", "(", "\"This function requires Hydra/Omegaconf and it was not installed.\"", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "with", "open_dict", "(", "model_cfg", ".", "model", ")", ":", "\n", "# Create copy of original model sub config", "\n", "        ", "if", "subconfig_key", "in", "update_cfg", ".", "model", ":", "\n", "            ", "if", "subconfig_key", "not", "in", "model_cfg", ".", "model", ":", "\n", "# create the key as a placeholder", "\n", "                ", "model_cfg", ".", "model", "[", "subconfig_key", "]", "=", "None", "\n", "\n", "", "subconfig", "=", "copy", ".", "deepcopy", "(", "model_cfg", ".", "model", "[", "subconfig_key", "]", ")", "\n", "update_subconfig", "=", "copy", ".", "deepcopy", "(", "update_cfg", ".", "model", "[", "subconfig_key", "]", ")", "\n", "\n", "# Add the keys and update temporary values, will be updated during full merge", "\n", "subconfig", "=", "OmegaConf", ".", "merge", "(", "update_subconfig", ",", "subconfig", ")", "\n", "# Update sub config", "\n", "model_cfg", ".", "model", "[", "subconfig_key", "]", "=", "subconfig", "\n", "\n", "", "", "return", "model_cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.config_utils.assert_dataclass_signature_match": [[176, 258], ["inspect.signature", "dict", "set.pop", "inspect.signature", "dict", "set.pop", "set", "set", "set.intersection", "set.keys", "set.keys", "remap_args.items", "set", "mridc.utils.logging.info", "mridc.utils.logging.error", "len", "len", "len", "len", "len", "len", "mridc.utils.logging.error", "mridc.utils.logging.error", "set.remove", "set.add", "mridc.utils.logging.info", "set.remove", "set.add", "mridc.utils.logging.info"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info"], ["", "def", "assert_dataclass_signature_match", "(", "\n", "cls", ":", "\"class_type\"", ",", "# type: ignore", "\n", "datacls", ":", "\"dataclass\"", ",", "# type: ignore", "\n", "ignore_args", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "remap_args", ":", "Optional", "[", "Dict", "[", "str", ",", "str", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Analyses the signature of a provided class and its respective data class,\n    asserting that the dataclass signature matches the class __init__ signature.\n    Note:\n        This is not a value based check. This function only checks if all argument\n        names exist on both class and dataclass and logs mismatches.\n\n    Parameters\n    ----------\n    cls: Any class type - but not an instance of a class. Pass type(x) where x is an instance\n        if class type is not easily available.\n    datacls: A corresponding dataclass for the above class.\n    ignore_args: (Optional) A list of string argument names which are forcibly ignored,\n        even if mismatched in the signature. Useful when a dataclass is a superset of the\n        arguments of a class.\n    remap_args: (Optional) A dictionary, mapping an argument name that exists (in either the\n        class or its dataclass), to another name. Useful when argument names are mismatched between\n        a class and its dataclass due to indirect instantiation via a helper method.\n\n    Returns\n    -------\n    A tuple containing information about the analysis:\n        1) A bool value which is True if the signatures matched exactly / after ignoring values.\n            False otherwise.\n        2) A set of arguments names that exist in the class, but *do not* exist in the dataclass.\n            If exact signature match occurs, this will be None instead.\n        3) A set of argument names that exist in the data class, but *do not* exist in the class itself.\n            If exact signature match occurs, this will be None instead.\n    \"\"\"", "\n", "class_sig", "=", "inspect", ".", "signature", "(", "cls", ".", "__init__", ")", "\n", "\n", "class_params", "=", "dict", "(", "**", "class_sig", ".", "parameters", ")", "\n", "class_params", ".", "pop", "(", "\"self\"", ")", "\n", "\n", "dataclass_sig", "=", "inspect", ".", "signature", "(", "datacls", ")", "\n", "\n", "dataclass_params", "=", "dict", "(", "**", "dataclass_sig", ".", "parameters", ")", "\n", "dataclass_params", ".", "pop", "(", "\"_target_\"", ",", "None", ")", "\n", "\n", "class_params", "=", "set", "(", "class_params", ".", "keys", "(", ")", ")", "# type: ignore", "\n", "dataclass_params", "=", "set", "(", "dataclass_params", ".", "keys", "(", ")", ")", "# type: ignore", "\n", "\n", "if", "remap_args", "is", "not", "None", ":", "\n", "        ", "for", "original_arg", ",", "new_arg", "in", "remap_args", ".", "items", "(", ")", ":", "\n", "            ", "if", "original_arg", "in", "class_params", ":", "\n", "                ", "class_params", ".", "remove", "(", "original_arg", ")", "# type: ignore", "\n", "class_params", ".", "add", "(", "new_arg", ")", "# type: ignore", "\n", "logging", ".", "info", "(", "f\"Remapped {original_arg} -> {new_arg} in {cls.__name__}\"", ")", "\n", "\n", "", "if", "original_arg", "in", "dataclass_params", ":", "\n", "                ", "dataclass_params", ".", "remove", "(", "original_arg", ")", "# type: ignore", "\n", "dataclass_params", ".", "add", "(", "new_arg", ")", "# type: ignore", "\n", "logging", ".", "info", "(", "f\"Remapped {original_arg} -> {new_arg} in {datacls.__name__}\"", ")", "\n", "\n", "", "", "", "if", "ignore_args", "is", "not", "None", ":", "\n", "        ", "ignore_args", "=", "set", "(", "ignore_args", ")", "# type: ignore", "\n", "\n", "class_params", "=", "class_params", "-", "ignore_args", "# type: ignore", "\n", "dataclass_params", "=", "dataclass_params", "-", "ignore_args", "# type: ignore", "\n", "logging", ".", "info", "(", "f\"Removing ignored arguments - {ignore_args}\"", ")", "\n", "\n", "", "intersection", ":", "Set", "[", "type", "]", "=", "set", ".", "intersection", "(", "class_params", ",", "dataclass_params", ")", "# type: ignore", "\n", "subset_cls", "=", "class_params", "-", "intersection", "# type: ignore", "\n", "subset_datacls", "=", "dataclass_params", "-", "intersection", "# type: ignore", "\n", "\n", "if", "(", "len", "(", "class_params", ")", "!=", "len", "(", "dataclass_params", ")", ")", "or", "len", "(", "subset_cls", ")", ">", "0", "or", "len", "(", "subset_datacls", ")", ">", "0", ":", "\n", "        ", "logging", ".", "error", "(", "f\"Class {cls.__name__} arguments do not match \"", "f\"Dataclass {datacls.__name__}!\"", ")", "\n", "\n", "if", "len", "(", "subset_cls", ")", ">", "0", ":", "\n", "            ", "logging", ".", "error", "(", "f\"Class {cls.__name__} has additional arguments :\\n\"", "f\"{subset_cls}\"", ")", "\n", "\n", "", "if", "len", "(", "subset_datacls", ")", ":", "\n", "            ", "logging", ".", "error", "(", "f\"Dataclass {datacls.__name__} has additional arguments :\\n{subset_datacls}\"", ")", "\n", "\n", "", "return", "False", ",", "subset_cls", ",", "subset_datacls", "\n", "", "return", "True", ",", "None", ",", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.__init__": [[25, 72], ["threading.Lock"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initializes the AppState class.\"\"\"", "\n", "# method call lock", "\n", "self", ".", "model_parallel_rank", "=", "None", "\n", "self", ".", "__lock", "=", "Lock", "(", ")", "\n", "\n", "# TODO: should we store global config in hydra_runner?", "\n", "self", ".", "_app_cfg", "=", "None", "\n", "\n", "# World info", "\n", "self", ".", "_device_id", "=", "None", "\n", "self", ".", "_local_rank", "=", "None", "\n", "self", ".", "_global_rank", "=", "None", "\n", "self", ".", "_model_parallel_rank", "=", "None", "\n", "self", ".", "_tensor_model_parallel_rank", "=", "None", "\n", "self", ".", "_pipeline_model_parallel_rank", "=", "None", "\n", "self", ".", "_data_parallel_rank", "=", "None", "\n", "\n", "self", ".", "_world_size", "=", "None", "\n", "self", ".", "_model_parallel_size", "=", "None", "\n", "self", ".", "_tensor_model_parallel_size", "=", "None", "\n", "self", ".", "_tensor_model_parallel_group", "=", "None", "\n", "self", ".", "_pipeline_model_parallel_size", "=", "None", "\n", "self", ".", "_pipeline_model_parallel_group", "=", "None", "\n", "self", ".", "_pipeline_model_parallel_split_rank", "=", "None", "\n", "self", ".", "_model_parallel_group", "=", "None", "\n", "self", ".", "_data_parallel_size", "=", "None", "\n", "self", ".", "_data_parallel_group", "=", "None", "\n", "\n", "self", ".", "_random_seed", "=", "None", "\n", "\n", "# Logging info", "\n", "self", ".", "_log_dir", "=", "None", "\n", "self", ".", "_exp_dir", "=", "None", "\n", "self", ".", "_name", "=", "None", "\n", "self", ".", "_checkpoint_name", "=", "None", "\n", "self", ".", "_version", "=", "None", "\n", "self", ".", "_create_checkpoint_callback", "=", "None", "\n", "self", ".", "_checkpoint_callback_params", "=", "None", "\n", "\n", "# Save and Restore (.mridc)", "\n", "self", ".", "_tmpdir_name", "=", "None", "\n", "self", ".", "_is_model_being_restored", "=", "False", "\n", "self", ".", "_mridc_file_folder", "=", "None", "\n", "self", ".", "_model_restore_path", "=", "None", "\n", "self", ".", "_all_model_restore_paths", "=", "[", "]", "\n", "self", ".", "_model_guid_map", "=", "{", "}", "# type: Dict[str, ModelMetadataRegistry]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.device_id": [[78, 82], ["None"], "methods", ["None"], ["", "@", "device_id", ".", "setter", "\n", "def", "device_id", "(", "self", ",", "id", ":", "int", ")", ":", "\n", "        ", "\"\"\"Property sets the device_id.\"\"\"", "\n", "self", ".", "_device_id", "=", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.world_size": [[88, 92], ["None"], "methods", ["None"], ["", "@", "world_size", ".", "setter", "\n", "def", "world_size", "(", "self", ",", "size", ":", "int", ")", ":", "\n", "        ", "\"\"\"Property sets the total number of GPUs.\"\"\"", "\n", "self", ".", "_world_size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.model_parallel_size": [[98, 102], ["None"], "methods", ["None"], ["", "@", "model_parallel_size", ".", "setter", "\n", "def", "model_parallel_size", "(", "self", ",", "size", ":", "int", ")", ":", "\n", "        ", "\"\"\"Property sets the number of GPUs in each model parallel group.\"\"\"", "\n", "self", ".", "_model_parallel_size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.tensor_model_parallel_size": [[108, 112], ["None"], "methods", ["None"], ["", "@", "tensor_model_parallel_size", ".", "setter", "\n", "def", "tensor_model_parallel_size", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"Property sets the number of GPUs in each model parallel group.\"\"\"", "\n", "self", ".", "_tensor_model_parallel_size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.pipeline_model_parallel_size": [[118, 122], ["None"], "methods", ["None"], ["", "@", "pipeline_model_parallel_size", ".", "setter", "\n", "def", "pipeline_model_parallel_size", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"Property sets the number of GPUs in each model parallel group.\"\"\"", "\n", "self", ".", "_pipeline_model_parallel_size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.data_parallel_size": [[128, 132], ["None"], "methods", ["None"], ["", "@", "data_parallel_size", ".", "setter", "\n", "def", "data_parallel_size", "(", "self", ",", "size", ":", "int", ")", ":", "\n", "        ", "\"\"\"Property sets the number of GPUs in each data parallel group.\"\"\"", "\n", "self", ".", "_data_parallel_size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.local_rank": [[138, 142], ["None"], "methods", ["None"], ["", "@", "local_rank", ".", "setter", "\n", "def", "local_rank", "(", "self", ",", "rank", ":", "int", ")", ":", "\n", "        ", "\"\"\"Property sets the local rank.\"\"\"", "\n", "self", ".", "_local_rank", "=", "rank", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.global_rank": [[148, 152], ["None"], "methods", ["None"], ["", "@", "global_rank", ".", "setter", "\n", "def", "global_rank", "(", "self", ",", "rank", ":", "int", ")", ":", "\n", "        ", "\"\"\"Property sets the global rank.\"\"\"", "\n", "self", ".", "_global_rank", "=", "rank", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.tensor_model_parallel_rank": [[158, 162], ["None"], "methods", ["None"], ["", "@", "tensor_model_parallel_rank", ".", "setter", "\n", "def", "tensor_model_parallel_rank", "(", "self", ",", "rank", ")", ":", "\n", "        ", "\"\"\"Property sets the model parallel rank.\"\"\"", "\n", "self", ".", "_tensor_model_parallel_rank", "=", "rank", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.tensor_model_parallel_group": [[168, 172], ["None"], "methods", ["None"], ["", "@", "tensor_model_parallel_group", ".", "setter", "\n", "def", "tensor_model_parallel_group", "(", "self", ",", "group", ")", ":", "\n", "        ", "\"\"\"Property sets the model parallel group.\"\"\"", "\n", "self", ".", "_tensor_model_parallel_group", "=", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.pipeline_model_parallel_rank": [[178, 182], ["None"], "methods", ["None"], ["", "@", "pipeline_model_parallel_rank", ".", "setter", "\n", "def", "pipeline_model_parallel_rank", "(", "self", ",", "rank", ")", ":", "\n", "        ", "\"\"\"Property sets the model parallel rank.\"\"\"", "\n", "self", ".", "_pipeline_model_parallel_rank", "=", "rank", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.pipeline_model_parallel_split_rank": [[188, 192], ["None"], "methods", ["None"], ["", "@", "pipeline_model_parallel_split_rank", ".", "setter", "\n", "def", "pipeline_model_parallel_split_rank", "(", "self", ",", "rank", ")", ":", "\n", "        ", "\"\"\"Property sets the model parallel split rank.\"\"\"", "\n", "self", ".", "_pipeline_model_parallel_split_rank", "=", "rank", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.pipeline_model_parallel_group": [[198, 202], ["None"], "methods", ["None"], ["", "@", "pipeline_model_parallel_group", ".", "setter", "\n", "def", "pipeline_model_parallel_group", "(", "self", ",", "group", ")", ":", "\n", "        ", "\"\"\"Property sets the model parallel group.\"\"\"", "\n", "self", ".", "_pipeline_model_parallel_group", "=", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.data_parallel_rank": [[208, 212], ["None"], "methods", ["None"], ["", "@", "data_parallel_rank", ".", "setter", "\n", "def", "data_parallel_rank", "(", "self", ",", "rank", ":", "int", ")", ":", "\n", "        ", "\"\"\"Property sets the data parallel rank.\"\"\"", "\n", "self", ".", "_data_parallel_rank", "=", "rank", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.data_parallel_group": [[218, 222], ["None"], "methods", ["None"], ["", "@", "data_parallel_group", ".", "setter", "\n", "def", "data_parallel_group", "(", "self", ",", "group", ")", ":", "\n", "        ", "\"\"\"Property sets the data parallel group.\"\"\"", "\n", "self", ".", "_data_parallel_group", "=", "group", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.random_seed": [[228, 232], ["None"], "methods", ["None"], ["", "@", "random_seed", ".", "setter", "\n", "def", "random_seed", "(", "self", ",", "seed", ":", "int", ")", ":", "\n", "        ", "\"\"\"Property sets the random seed.\"\"\"", "\n", "self", ".", "_random_seed", "=", "seed", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.log_dir": [[238, 242], ["None"], "methods", ["None"], ["", "@", "log_dir", ".", "setter", "\n", "def", "log_dir", "(", "self", ",", "dir", ")", ":", "\n", "        ", "\"\"\"Sets the log_dir property.\"\"\"", "\n", "self", ".", "_log_dir", "=", "dir", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.exp_dir": [[248, 252], ["None"], "methods", ["None"], ["", "@", "exp_dir", ".", "setter", "\n", "def", "exp_dir", "(", "self", ",", "dir", ")", ":", "\n", "        ", "\"\"\"Sets the log_dir property.\"\"\"", "\n", "self", ".", "_exp_dir", "=", "dir", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.name": [[258, 262], ["None"], "methods", ["None"], ["", "@", "name", ".", "setter", "\n", "def", "name", "(", "self", ",", "name", ":", "str", ")", ":", "\n", "        ", "\"\"\"Sets the name property.\"\"\"", "\n", "self", ".", "_name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.checkpoint_name": [[268, 272], ["None"], "methods", ["None"], ["", "@", "checkpoint_name", ".", "setter", "\n", "def", "checkpoint_name", "(", "self", ",", "name", ":", "str", ")", ":", "\n", "        ", "\"\"\"Sets the name property.\"\"\"", "\n", "self", ".", "_checkpoint_name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.version": [[278, 282], ["None"], "methods", ["None"], ["", "@", "version", ".", "setter", "\n", "def", "version", "(", "self", ",", "version", ":", "str", ")", ":", "\n", "        ", "\"\"\"Sets the version property.\"\"\"", "\n", "self", ".", "_version", "=", "version", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.create_checkpoint_callback": [[288, 292], ["None"], "methods", ["None"], ["", "@", "create_checkpoint_callback", ".", "setter", "\n", "def", "create_checkpoint_callback", "(", "self", ",", "create_checkpoint_callback", ":", "bool", ")", ":", "\n", "        ", "\"\"\"Sets the create_checkpoint_callback property.\"\"\"", "\n", "self", ".", "_create_checkpoint_callback", "=", "create_checkpoint_callback", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.checkpoint_callback_params": [[298, 302], ["None"], "methods", ["None"], ["", "@", "checkpoint_callback_params", ".", "setter", "\n", "def", "checkpoint_callback_params", "(", "self", ",", "params", ":", "dict", ")", ":", "\n", "        ", "\"\"\"Sets the name property.\"\"\"", "\n", "self", ".", "_checkpoint_callback_params", "=", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.model_restore_path": [[308, 314], ["app_state.AppState._all_model_restore_paths.append"], "methods", ["None"], ["", "@", "model_restore_path", ".", "setter", "\n", "def", "model_restore_path", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Sets the model_restore_path property.\"\"\"", "\n", "with", "self", ".", "__lock", ":", "\n", "            ", "self", ".", "_model_restore_path", "=", "path", "\n", "self", ".", "_all_model_restore_paths", ".", "append", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.register_model_guid": [[315, 323], ["app_state.ModelMetadataRegistry", "len"], "methods", ["None"], ["", "", "def", "register_model_guid", "(", "self", ",", "guid", ":", "str", ",", "restoration_path", ":", "Optional", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"Maps a guid to its restore path (None or last absolute path).\"\"\"", "\n", "with", "self", ".", "__lock", ":", "\n", "            ", "if", "guid", "in", "self", ".", "_model_guid_map", ":", "\n", "                ", "idx", "=", "self", ".", "_model_guid_map", "[", "guid", "]", ".", "gidx", "\n", "", "else", ":", "\n", "                ", "idx", "=", "len", "(", "self", ".", "_model_guid_map", ")", "\n", "", "self", ".", "_model_guid_map", "[", "guid", "]", "=", "ModelMetadataRegistry", "(", "guid", ",", "idx", ",", "restoration_path", "=", "restoration_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.reset_model_guid_registry": [[324, 328], ["app_state.AppState._model_guid_map.clear"], "methods", ["None"], ["", "", "def", "reset_model_guid_registry", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the model guid registry.\"\"\"", "\n", "with", "self", ".", "__lock", ":", "\n", "            ", "self", ".", "_model_guid_map", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.get_model_metadata_from_guid": [[329, 332], ["None"], "methods", ["None"], ["", "", "def", "get_model_metadata_from_guid", "(", "self", ",", "guid", ")", "->", "ModelMetadataRegistry", ":", "\n", "        ", "\"\"\"Returns the global model idx and restoration path.\"\"\"", "\n", "return", "self", ".", "_model_guid_map", "[", "guid", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.is_model_being_restored": [[338, 342], ["None"], "methods", ["None"], ["", "@", "is_model_being_restored", ".", "setter", "\n", "def", "is_model_being_restored", "(", "self", ",", "is_restored", ":", "bool", ")", ":", "\n", "        ", "\"\"\"Sets whether a model is being restored.\"\"\"", "\n", "self", ".", "_is_model_being_restored", "=", "is_restored", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.mridc_file_folder": [[348, 352], ["None"], "methods", ["None"], ["", "@", "mridc_file_folder", ".", "setter", "\n", "def", "mridc_file_folder", "(", "self", ",", "path", ":", "str", ")", ":", "\n", "        ", "\"\"\"Sets the mridc_file_folder property.\"\"\"", "\n", "self", ".", "_mridc_file_folder", "=", "path", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.neural_type_utils.get_io_names": [[12, 30], ["list", "types.keys", "list.remove"], "function", ["None"], ["def", "get_io_names", "(", "types", ",", "disabled_names", ")", ":", "\n", "    ", "\"\"\"\n    This method will return a list of input and output names for a given NeuralType.\n\n    Parameters\n    ----------\n    types: The NeuralType of the module or model to be inspected.\n    disabled_names: A list of names that should be excluded from the result.\n\n    Returns\n    -------\n    A list of input and output names.\n    \"\"\"", "\n", "names", "=", "list", "(", "types", ".", "keys", "(", ")", ")", "\n", "for", "name", "in", "disabled_names", ":", "\n", "        ", "if", "name", "in", "names", ":", "\n", "            ", "names", ".", "remove", "(", "name", ")", "\n", "", "", "return", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.neural_type_utils.extract_dynamic_axes": [[32, 75], ["collections.defaultdict", "type", "neural_type_utils.extract_dynamic_axes.unpack_nested_neural_type"], "function", ["None"], ["", "def", "extract_dynamic_axes", "(", "name", ":", "str", ",", "ntype", ":", "NeuralType", ")", ":", "\n", "    ", "\"\"\"\n    This method will extract BATCH and TIME dimension ids from each provided input/output name argument.\n\n    For example, if module/model accepts argument named \"input_signal\" with type corresponding to [Batch, Time, Dim]\n    shape, then the returned result should contain \"input_signal\" -> [0, 1] because Batch and Time are dynamic axes\n    as they can change from call to call during inference.\n\n    Parameters\n    ----------\n    name: Name of input or output parameter\n    ntype: Corresponding Neural Type\n\n    Returns\n    -------\n    A dictionary with input/output name as key and a list of dynamic axes as value.\n    \"\"\"", "\n", "\n", "def", "unpack_nested_neural_type", "(", "neural_type", ")", ":", "\n", "        ", "\"\"\"\n        This method will unpack nested NeuralTypes.\n\n        Parameters\n        ----------\n        neural_type: The NeuralType to be unpacked.\n\n        Returns\n        -------\n        A list of all the nested NeuralTypes.\n        \"\"\"", "\n", "if", "type", "(", "neural_type", ")", "in", "(", "list", ",", "tuple", ")", ":", "\n", "            ", "return", "unpack_nested_neural_type", "(", "neural_type", "[", "0", "]", ")", "\n", "", "return", "neural_type", "\n", "\n", "", "dynamic_axes", "=", "defaultdict", "(", "list", ")", "\n", "if", "type", "(", "ntype", ")", "in", "(", "list", ",", "tuple", ")", ":", "\n", "        ", "ntype", "=", "unpack_nested_neural_type", "(", "ntype", ")", "\n", "\n", "", "if", "ntype", ".", "axes", ":", "\n", "        ", "for", "ind", ",", "axis", "in", "enumerate", "(", "ntype", ".", "axes", ")", ":", "\n", "            ", "if", "axis", ".", "kind", "in", "[", "AxisKind", ".", "Batch", ",", "AxisKind", ".", "Time", ",", "AxisKind", ".", "Width", ",", "AxisKind", ".", "Height", "]", ":", "\n", "                ", "dynamic_axes", "[", "name", "]", ".", "append", "(", "ind", ")", "\n", "", "", "", "return", "dynamic_axes", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.neural_type_utils.get_dynamic_axes": [[77, 95], ["collections.defaultdict", "neural_type_utils.extract_dynamic_axes"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.neural_type_utils.extract_dynamic_axes"], ["", "def", "get_dynamic_axes", "(", "types", ",", "names", ")", ":", "\n", "    ", "\"\"\"\n    This method will return a dictionary with input/output names as keys and a list of dynamic axes as values.\n\n    Parameters\n    ----------\n    types: The NeuralType of the module or model to be inspected.\n    names: A list of names that should be inspected.\n\n    Returns\n    -------\n    A dictionary with input/output names as keys and a list of dynamic axes as values.\n    \"\"\"", "\n", "dynamic_axes", "=", "defaultdict", "(", "list", ")", "\n", "for", "name", "in", "names", ":", "\n", "        ", "if", "name", "in", "types", ":", "\n", "            ", "dynamic_axes", "|=", "extract_dynamic_axes", "(", "name", ",", "types", "[", "name", "]", ")", "\n", "", "", "return", "dynamic_axes", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.utils.numba_utils.is_numba_compat_strict": [[42, 50], ["None"], "function", ["None"], ["", "def", "is_numba_compat_strict", "(", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Returns strictness level of numba cuda compatibility checks.\n    If value is true, numba cuda compatibility matrix must be satisfied.\n    If value is false, only cuda availability is checked, not compatibility.\n    Numba Cuda may still compile and run without issues in such a case, or it may fail.\n    \"\"\"", "\n", "return", "STRICT_NUMBA_COMPAT_CHECK", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.numba_utils.set_numba_compat_strictness": [[52, 65], ["None"], "function", ["None"], ["", "def", "set_numba_compat_strictness", "(", "strict", ":", "bool", ")", ":", "\n", "    ", "\"\"\"\n    Sets the strictness level of numba cuda compatibility checks.\n    If value is true, numba cuda compatibility matrix must be satisfied.\n    If value is false, only cuda availability is checked, not compatibility.\n    Numba Cuda may still compile and run without issues in such a case, or it may fail.\n\n    Parameters\n    ----------\n    strict: Whether to enforce strict compatibility checks or relax them.\n    \"\"\"", "\n", "global", "STRICT_NUMBA_COMPAT_CHECK", "\n", "STRICT_NUMBA_COMPAT_CHECK", "=", "strict", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.numba_utils.with_numba_compat_strictness": [[67, 74], ["numba_utils.is_numba_compat_strict", "numba_utils.set_numba_compat_strictness", "numba_utils.set_numba_compat_strictness"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.numba_utils.is_numba_compat_strict", "home.repos.pwc.inspect_result.wdika_mridc.utils.numba_utils.set_numba_compat_strictness", "home.repos.pwc.inspect_result.wdika_mridc.utils.numba_utils.set_numba_compat_strictness"], ["", "@", "contextlib", ".", "contextmanager", "\n", "def", "with_numba_compat_strictness", "(", "strict", ":", "bool", ")", ":", "\n", "    ", "\"\"\"Context manager to temporarily set numba cuda compatibility strictness.\"\"\"", "\n", "initial_strictness", "=", "is_numba_compat_strict", "(", ")", "\n", "set_numba_compat_strictness", "(", "strict", "=", "strict", ")", "\n", "yield", "\n", "set_numba_compat_strictness", "(", "strict", "=", "initial_strictness", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.numba_utils.numba_cpu_is_supported": [[76, 94], ["mridc.utils.model_utils.check_lib_version"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.check_lib_version"], ["", "def", "numba_cpu_is_supported", "(", "min_version", ":", "str", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Tests if an appropriate version of numba is installed.\n\n    Parameters\n    ----------\n    min_version: The minimum version of numba that is required.\n\n    Returns\n    -------\n    bool, whether numba CPU supported with this current installation or not.\n    \"\"\"", "\n", "module_available", ",", "_", "=", "check_lib_version", "(", "\"numba\"", ",", "checked_version", "=", "min_version", ",", "operator", "=", "operator", ".", "ge", ")", "\n", "\n", "# If numba is not installed", "\n", "if", "module_available", "is", "None", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.numba_utils.numba_cuda_is_supported": [[96, 133], ["numba_utils.numba_cpu_is_supported", "hasattr", "cuda.is_available", "numba_utils.is_numba_compat_strict", "cuda.is_supported_version"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.numba_utils.numba_cpu_is_supported", "home.repos.pwc.inspect_result.wdika_mridc.utils.numba_utils.is_numba_compat_strict"], ["", "def", "numba_cuda_is_supported", "(", "min_version", ":", "str", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Tests if an appropriate version of numba is installed, and if it is,\n    if cuda is supported properly within it.\n\n    Parameters\n    ----------\n    min_version: The minimum version of numba that is required.\n\n    Returns\n    -------\n    Whether cuda is supported with this current installation or not.\n    \"\"\"", "\n", "module_available", "=", "numba_cpu_is_supported", "(", "min_version", ")", "\n", "\n", "# If numba is not installed", "\n", "if", "module_available", "is", "None", ":", "\n", "        ", "return", "False", "\n", "\n", "", "if", "module_available", "is", "not", "True", ":", "\n", "        ", "return", "False", "\n", "", "from", "numba", "import", "cuda", "\n", "\n", "if", "not", "hasattr", "(", "cuda", ",", "\"is_supported_version\"", ")", ":", "\n", "# assume cuda is supported, but it may fail due to CUDA incompatibility", "\n", "        ", "return", "False", "\n", "\n", "", "try", ":", "\n", "        ", "cuda_available", "=", "cuda", ".", "is_available", "(", ")", "\n", "cuda_compatible", "=", "cuda", ".", "is_supported_version", "(", ")", "if", "cuda_available", "else", "False", "\n", "if", "is_numba_compat_strict", "(", ")", ":", "\n", "            ", "return", "cuda_available", "and", "cuda_compatible", "\n", "", "return", "cuda_available", "\n", "\n", "", "except", "OSError", ":", "\n", "# dlopen(libcudart.dylib) might fail if CUDA was never installed in the first place.", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.utils.numba_utils.skip_numba_cuda_test_if_unsupported": [[135, 148], ["numba_utils.numba_cuda_is_supported", "pytest.skip"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.numba_utils.numba_cuda_is_supported"], ["", "", "def", "skip_numba_cuda_test_if_unsupported", "(", "min_version", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Helper method to skip pytest test case if numba cuda is not supported.\n\n    Parameters\n    ----------\n    min_version: The minimum version of numba that is required.\n    \"\"\"", "\n", "numba_cuda_support", "=", "numba_cuda_is_supported", "(", "min_version", ")", "\n", "if", "not", "numba_cuda_support", ":", "\n", "        ", "import", "pytest", "\n", "\n", "pytest", ".", "skip", "(", "f\"Numba cuda test is being skipped. Minimum version required : {min_version}\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.decorators.experimental.experimental": [[11, 45], ["experimental.experimental.wrapped"], "function", ["None"], ["def", "experimental", "(", "cls", ")", ":", "\n", "    ", "\"\"\"\n    Decorator to mark a class as experimental.\n\n    Parameters\n    ----------\n    cls: The class to be decorated.\n        class\n\n    Returns\n    -------\n    The decorated class.\n    \"\"\"", "\n", "\n", "def", "wrapped", "(", "x", ")", ":", "\n", "        ", "\"\"\"\n        Wrapper function.\n\n        Parameters\n        ----------\n        x: The class to be decorated.\n            class\n\n        Returns\n        -------\n        The decorated class with the experimental flag set.\n        \"\"\"", "\n", "logging", ".", "warning", "(", "\n", "f\"Module {x} is experimental, not ready for production and is not fully supported. Use at your own risk.\"", "\n", ")", "\n", "\n", "return", "x", "\n", "\n", "", "return", "wrapped", "(", "x", "=", "cls", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.decorators.deprecated.deprecated": [[20, 80], ["deprecated.deprecated.wrapper"], "function", ["None"], ["def", "deprecated", "(", "wrapped", "=", "None", ",", "version", "=", "None", ",", "explanation", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    This is a decorator which can be used to mark functions as deprecated. It will result in a warning being emitted\n    when the function is used.\n\n    Parameters\n    ----------\n    wrapped: The function to be decorated.\n        function\n    version: The version of the package where the function was deprecated.\n        str\n    explanation: The explanation of the deprecation.\n        str\n\n    Returns\n    -------\n    The decorated function.\n    \"\"\"", "\n", "if", "wrapped", "is", "None", ":", "\n", "        ", "return", "functools", ".", "partial", "(", "deprecated", ",", "version", "=", "version", ",", "explanation", "=", "explanation", ")", "\n", "\n", "", "@", "wrapt", ".", "decorator", "\n", "def", "wrapper", "(", "_wrapped", ",", "args", ",", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Prints the adequate warning (only once per function) when required and calls the function func, passing the\n        original arguments, i.e. version and explanation.\n\n        Parameters\n        ----------\n        _wrapped: The function to be decorated.\n        args: The arguments passed to the function to be decorated.\n        kwargs: The keyword arguments passed to the function to be decorated.\n\n        Returns\n        -------\n        The decorated function.\n        \"\"\"", "\n", "# Check if we already warned about that function.", "\n", "if", "_wrapped", ".", "__name__", "not", "in", "_PRINTED_WARNING", ":", "\n", "# Add to list so we won't print it again.", "\n", "            ", "_PRINTED_WARNING", "[", "_wrapped", ".", "__name__", "]", "=", "True", "\n", "\n", "# Prepare the warning message.", "\n", "entity_name", "=", "\"Class\"", "if", "inspect", ".", "isclass", "(", "wrapped", ")", "else", "\"Function\"", "\n", "msg", "=", "f\"{entity_name} '{_wrapped.__name__}' is deprecated.\"", "\n", "\n", "# Optionally, add version and explanation.", "\n", "if", "version", "is", "not", "None", ":", "\n", "                ", "msg", "=", "f\"{msg} It is going to be removed in the {version} version.\"", "\n", "\n", "", "if", "explanation", "is", "not", "None", ":", "\n", "                ", "msg", "=", "f\"{msg} {explanation}\"", "\n", "\n", "# Display the deprecated warning.", "\n", "", "logging", ".", "warning", "(", "msg", ")", "\n", "\n", "# Call the function.", "\n", "", "return", "_wrapped", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "return", "wrapper", "(", "wrapped", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.base.BaseFormatter.__init__": [[34, 67], ["logging.Formatter.__init__", "mridc.utils.formaters.utils.check_color_support"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.formaters.utils.check_color_support"], ["def", "__init__", "(", "self", ",", "color", "=", "True", ",", "fmt", "=", "None", ",", "datefmt", "=", "None", ",", "colors", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        color: Enable color support.\n            bool, default: True\n        fmt: Log message format. It will be applied to the attributes dict of log records. The text between\n        ``%(color)s`` and ``%(end_color)s`` will be colored depending on the level if color support is on.\n            str, default: None\n        datefmt: Datetime format. Used for formatting ``(asctime)`` placeholder in ``prefix_fmt``.\n            str, default: None\n        colors: Dictionary mapping logging level to terminal color code.\n            dict, default: None\n        \"\"\"", "\n", "if", "fmt", "is", "None", ":", "\n", "            ", "fmt", "=", "self", ".", "DEFAULT_FORMAT", "\n", "\n", "", "if", "datefmt", "is", "None", ":", "\n", "            ", "datefmt", "=", "self", ".", "DEFAULT_DATE_FORMAT", "\n", "\n", "", "if", "colors", "is", "None", ":", "\n", "            ", "colors", "=", "self", ".", "DEFAULT_COLORS", "\n", "\n", "", "logging", ".", "Formatter", ".", "__init__", "(", "self", ",", "datefmt", "=", "datefmt", ")", "\n", "\n", "self", ".", "_fmt", "=", "fmt", "\n", "self", ".", "_colors", "=", "{", "}", "\n", "self", ".", "_normal", "=", "\"\"", "\n", "\n", "if", "color", "and", "check_color_support", "(", ")", ":", "\n", "            ", "self", ".", "_colors", "=", "colors", "\n", "self", ".", "_normal", "=", "ForegroundColors", ".", "RESET", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.base.BaseFormatter.format": [[68, 129], ["base.BaseFormatter.formatTime", "formatted.replace", "record.getMessage", "mridc.utils.formaters.utils.to_unicode", "base.BaseFormatter.formatException", "lines.extend", "isinstance", "formatted.rstrip", "mridc.utils.formaters.utils.to_unicode", "record.exc_text.split"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.formaters.utils.to_unicode", "home.repos.pwc.inspect_result.wdika_mridc.formaters.utils.to_unicode"], ["", "", "def", "format", "(", "self", ",", "record", ")", ":", "\n", "        ", "\"\"\"\n        Formats a record.\n\n        Parameters\n        ----------\n        record: Log record to be formatted.\n            LogRecord\n\n        Returns\n        -------\n        The formatted record as a string.\n            str\n        \"\"\"", "\n", "try", ":", "\n", "            ", "message", "=", "record", ".", "getMessage", "(", ")", "\n", "if", "not", "isinstance", "(", "message", ",", "str", ")", ":", "\n", "                ", "raise", "AssertionError", "\n", "# Encoding notes:  The logging module prefers to work with character", "\n", "# strings, but only enforces that log messages are instances of", "\n", "# basestring.  In python 2, non-ascii bytestrings will make", "\n", "# their way through the logging framework until they blow up with", "\n", "# an unhelpful decoding error (with this formatter it happens", "\n", "# when we attach the prefix, but there are other opportunities for", "\n", "# exceptions further along in the framework).", "\n", "#", "\n", "# If a byte string makes it this far, convert it to unicode to", "\n", "# ensure it will make it out to the logs.  Use repr() as a fallback", "\n", "# to ensure that all byte strings can be converted successfully,", "\n", "# but don't do it by default so we don't add extra quotes to ascii", "\n", "# bytestrings.  This is a bit of a hacky place to do this, but", "\n", "# it's worth it since the encoding errors that would otherwise", "\n", "# result are so useless (and tornado is fond of using utf8-encoded", "\n", "# byte strings wherever possible).", "\n", "", "record", ".", "message", "=", "to_unicode", "(", "message", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "record", ".", "message", "=", "\"Bad message (%r): %r\"", "%", "(", "e", ",", "record", ".", "__dict__", ")", "\n", "\n", "", "record", ".", "asctime", "=", "self", ".", "formatTime", "(", "record", ",", "self", ".", "datefmt", ")", "\n", "\n", "if", "record", ".", "levelno", "in", "self", ".", "_colors", ":", "\n", "            ", "record", ".", "color", "=", "self", ".", "_colors", "[", "record", ".", "levelno", "]", "\n", "record", ".", "end_color", "=", "self", ".", "_normal", "\n", "", "else", ":", "\n", "            ", "record", ".", "color", "=", "record", ".", "end_color", "=", "\"\"", "\n", "\n", "", "formatted", "=", "self", ".", "_fmt", "%", "record", ".", "__dict__", "\n", "\n", "if", "record", ".", "exc_info", "and", "not", "record", ".", "exc_text", ":", "\n", "            ", "record", ".", "exc_text", "=", "self", ".", "formatException", "(", "record", ".", "exc_info", ")", "\n", "\n", "", "if", "record", ".", "exc_text", ":", "\n", "# exc_text contains multiple lines.  We need to _safe_unicode", "\n", "# each line separately so that non-utf8 bytes don't cause", "\n", "# all the newlines to turn into '\\n'.", "\n", "            ", "lines", "=", "[", "formatted", ".", "rstrip", "(", ")", "]", "\n", "lines", ".", "extend", "(", "to_unicode", "(", "ln", ")", "for", "ln", "in", "record", ".", "exc_text", ".", "split", "(", "\"\\n\"", ")", ")", "\n", "\n", "formatted", "=", "\"\\n\"", ".", "join", "(", "lines", ")", "\n", "", "return", "formatted", ".", "replace", "(", "\"\\n\"", ",", "\"\\n    \"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.colors.AnsiCodes.__init__": [[82, 90], ["dir", "name.startswith", "getattr", "setattr", "colors.code_to_chars"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.formaters.colors.code_to_chars"], ["def", "__init__", "(", "self", ")", ":", "\n", "# the subclasses declare class attributes which are numbers.", "\n", "# Upon instantiation we define instance attributes, which are the same", "\n", "# as the class attributes but wrapped with the ANSI escape sequence", "\n", "        ", "for", "name", "in", "dir", "(", "self", ")", ":", "\n", "            ", "if", "not", "name", ".", "startswith", "(", "\"_\"", ")", ":", "\n", "                ", "value", "=", "getattr", "(", "self", ",", "name", ")", "\n", "setattr", "(", "self", ",", "name", ",", "code_to_chars", "(", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.colors.AnsiCursor.UP": [[95, 111], ["str"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "UP", "(", "n", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Move the cursor up n lines.\n\n        Parameters\n        ----------\n        n: Number of lines.\n            int\n\n        Returns\n        -------\n        String of characters.\n            str\n        \"\"\"", "\n", "return", "CSI", "+", "str", "(", "n", ")", "+", "\"A\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.colors.AnsiCursor.DOWN": [[112, 128], ["str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "DOWN", "(", "n", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Move the cursor down n lines.\n\n        Parameters\n        ----------\n        n: Number of lines.\n            int\n\n        Returns\n        -------\n        String of characters.\n            str\n        \"\"\"", "\n", "return", "CSI", "+", "str", "(", "n", ")", "+", "\"B\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.colors.AnsiCursor.FORWARD": [[129, 145], ["str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "FORWARD", "(", "n", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Move the cursor forward n lines.\n\n        Parameters\n        ----------\n        n: Number of lines.\n            int\n\n        Returns\n        -------\n        String of characters.\n            str\n        \"\"\"", "\n", "return", "CSI", "+", "str", "(", "n", ")", "+", "\"C\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.colors.AnsiCursor.BACK": [[146, 162], ["str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "BACK", "(", "n", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Move the cursor back n lines.\n\n        Parameters\n        ----------\n        n: Number of lines.\n            int\n\n        Returns\n        -------\n        String of characters.\n            str\n        \"\"\"", "\n", "return", "CSI", "+", "str", "(", "n", ")", "+", "\"D\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.colors.AnsiCursor.POS": [[163, 181], ["str", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "POS", "(", "x", "=", "1", ",", "y", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Move the cursor to the specified position.\n\n        Parameters\n        ----------\n        x: X position.\n            int\n        y: Y position.\n            int\n\n        Returns\n        -------\n        String of characters.\n            str\n        \"\"\"", "\n", "return", "CSI", "+", "str", "(", "y", ")", "+", "\";\"", "+", "str", "(", "x", ")", "+", "\"H\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.colors.code_to_chars": [[11, 26], ["str"], "function", ["None"], ["def", "code_to_chars", "(", "code", ")", ":", "\n", "    ", "\"\"\"\n    Convert ANSI color code to string of characters.\n\n    Parameters\n    ----------\n    code: ANSI color code.\n        int\n\n    Returns\n    -------\n    String of characters.\n        str\n    \"\"\"", "\n", "return", "CSI", "+", "str", "(", "code", ")", "+", "\"m\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.colors.set_title": [[28, 43], ["None"], "function", ["None"], ["", "def", "set_title", "(", "title", ")", ":", "\n", "    ", "\"\"\"\n    Set terminal title.\n\n    Parameters\n    ----------\n    title: Title.\n        str\n\n    Returns\n    -------\n    String of characters.\n        str\n    \"\"\"", "\n", "return", "f\"{OSC}2;{title}{BEL}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.colors.clear_screen": [[45, 60], ["str"], "function", ["None"], ["", "def", "clear_screen", "(", "mode", "=", "2", ")", ":", "\n", "    ", "\"\"\"\n    Clear terminal screen.\n\n    Parameters\n    ----------\n    mode: Mode.\n        int\n\n    Returns\n    -------\n    String of characters.\n        str\n    \"\"\"", "\n", "return", "CSI", "+", "str", "(", "mode", ")", "+", "\"J\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.colors.clear_line": [[62, 77], ["str"], "function", ["None"], ["", "def", "clear_line", "(", "mode", "=", "2", ")", ":", "\n", "    ", "\"\"\"\n    Clear terminal line.\n\n    Parameters\n    ----------\n    mode: Mode.\n        int\n\n    Returns\n    -------\n    String of characters.\n        str\n    \"\"\"", "\n", "return", "CSI", "+", "str", "(", "mode", ")", "+", "\"K\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.utils.check_color_support": [[14, 24], ["bool", "mridc.utils.env_var_parsing.get_envbool", "sys.platform.lower().startswith", "sys.platform.lower"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.env_var_parsing.get_envbool"], ["def", "check_color_support", "(", ")", ":", "\n", "    ", "\"\"\"\n\n    Returns\n    -------\n    True if the terminal supports color, False otherwise.\n        bool\n    \"\"\"", "\n", "# Colors can be forced with an env variable", "\n", "return", "bool", "(", "not", "sys", ".", "platform", ".", "lower", "(", ")", ".", "startswith", "(", "\"win\"", ")", "and", "get_envbool", "(", "MRIDC_ENV_VARNAME_ENABLE_COLORING", ",", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.formaters.utils.to_unicode": [[26, 52], ["isinstance", "value.decode", "isinstance", "TypeError", "repr", "type", "type"], "function", ["None"], ["", "def", "to_unicode", "(", "value", ")", ":", "\n", "    ", "\"\"\"\n    Converts a string to unicode. If the string is already unicode, it is returned as is. If it is a byte string, it is\n    decoded using utf-8.\n\n    Parameters\n    ----------\n    value: The string to convert.\n        str\n\n    Returns\n    -------\n    The converted string.\n        str\n    \"\"\"", "\n", "try", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "(", "str", ",", "type", "(", "None", ")", ")", ")", ":", "\n", "            ", "return", "value", "\n", "\n", "", "if", "not", "isinstance", "(", "value", ",", "bytes", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Expected bytes, unicode, or None; got %r\"", "%", "type", "(", "value", ")", ")", "\n", "\n", "", "return", "value", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "", "except", "UnicodeDecodeError", ":", "\n", "        ", "return", "repr", "(", "value", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.crossdomain.multicoil.MultiCoil.__init__": [[18, 36], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "model", ":", "nn", ".", "Module", ",", "coil_dim", ":", "int", "=", "1", ",", "coil_to_batch", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"Inits MultiCoil.\n\n        Parameters\n        ----------\n        model: Any nn.Module that takes as input with 4D data (N, H, W, C). Typically, a convolutional-like model.\n            torch.nn.Module\n        coil_dim: Coil dimension.\n            int, Default: 1.\n        coil_to_batch: If True batch and coil dimensions are merged when forwarded by the model and unmerged when\n        outputted. Otherwise, input is forwarded to the model per coil.\n            bool, Default: False.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "coil_to_batch", "=", "coil_to_batch", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.crossdomain.multicoil.MultiCoil._compute_model_per_coil": [[37, 49], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "data.size", "data.select", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "data.select.dim", "multicoil.MultiCoil.model", "multicoil.MultiCoil.model().squeeze", "data.select.permute", "multicoil.MultiCoil.model", "data.select.unsqueeze"], "methods", ["None"], ["", "def", "_compute_model_per_coil", "(", "self", ",", "data", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Computes the model per coil.\"\"\"", "\n", "output", "=", "[", "]", "\n", "\n", "for", "idx", "in", "range", "(", "data", ".", "size", "(", "self", ".", "coil_dim", ")", ")", ":", "\n", "            ", "subselected_data", "=", "data", ".", "select", "(", "self", ".", "coil_dim", ",", "idx", ")", "\n", "if", "subselected_data", ".", "shape", "[", "-", "1", "]", "==", "2", "and", "subselected_data", ".", "dim", "(", ")", "==", "4", ":", "\n", "                ", "output", ".", "append", "(", "self", ".", "model", "(", "subselected_data", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "self", ".", "model", "(", "subselected_data", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ")", ".", "squeeze", "(", "self", ".", "coil_dim", ")", ")", "\n", "", "", "output", "=", "torch", ".", "stack", "(", "output", ",", "dim", "=", "self", ".", "coil_dim", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.crossdomain.multicoil.MultiCoil.forward": [[50, 75], ["multicoil.MultiCoil.clone", "multicoil.MultiCoil.size", "multicoil.MultiCoil.reshape().contiguous", "multicoil.MultiCoil.model().permute", "multicoil.MultiCoil.reshape().permute", "multicoil.MultiCoil._compute_model_per_coil().contiguous", "multicoil.MultiCoil.reshape", "multicoil.MultiCoil.model", "multicoil.MultiCoil.reshape", "multicoil.MultiCoil._compute_model_per_coil"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.crossdomain.multicoil.MultiCoil._compute_model_per_coil"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Performs the forward pass of MultiCoil.\n\n        Parameters\n        ----------\n        x: Multi-coil input.\n            torch.Tensor, shape (N, N_coils, H, W, C)\n\n        Returns\n        -------\n        Multi-coil output.\n            torch.Tensor, shape (N, N_coils, H, W, C)\n        \"\"\"", "\n", "if", "self", ".", "coil_to_batch", ":", "\n", "            ", "x", "=", "x", ".", "clone", "(", ")", "\n", "\n", "batch", ",", "coil", ",", "channels", ",", "height", ",", "width", "=", "x", ".", "size", "(", ")", "\n", "x", "=", "x", ".", "reshape", "(", "batch", "*", "coil", ",", "channels", ",", "height", ",", "width", ")", ".", "contiguous", "(", ")", "\n", "x", "=", "self", ".", "model", "(", "x", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "x", "=", "x", ".", "reshape", "(", "batch", ",", "coil", ",", "height", ",", "width", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "self", ".", "_compute_model_per_coil", "(", "x", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.crossdomain.crossdomain.CrossDomainNetwork.__init__": [[18, 84], ["torch.Module.__init__", "list", "list.strip", "set().issubset", "ValueError", "ValueError", "len", "list.count", "ValueError", "len", "list.count", "set"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "image_model_list", ":", "nn", ".", "Module", ",", "\n", "kspace_model_list", ":", "Optional", "[", "Union", "[", "nn", ".", "Module", ",", "None", "]", "]", "=", "None", ",", "\n", "domain_sequence", ":", "str", "=", "\"KIKI\"", ",", "\n", "image_buffer_size", ":", "int", "=", "1", ",", "\n", "kspace_buffer_size", ":", "int", "=", "1", ",", "\n", "normalize_image", ":", "bool", "=", "False", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Inits CrossDomainNetwork.\n\n        Parameters\n        ----------\n        image_model_list: Image domain model list.\n            torch.nn.Module\n        kspace_model_list: K-space domain model list. If set to None, a correction step is applied.\n            torch.nn.Module, Default: None.\n        domain_sequence: Domain sequence containing only \"K\" (k-space domain) and/or \"I\" (image domain).\n            str, Default: \"KIKI\".\n        image_buffer_size: Image buffer size.\n            int, Default: 1.\n        kspace_buffer_size: K-space buffer size.\n            int, Default: 1.\n        normalize_image: If True, input is normalized.\n            bool, Default: False.\n        fft_centered: If True, FFT is centered.\n            bool, Default: True.\n        fft_normalization: FFT normalization.\n            str, Default: \"ortho\".\n        spatial_dims: Spatial dimensions.\n            Tuple[int, int], Default: None.\n        coil_dim: Coil dimension.\n            int, Default: 1.\n        kwargs:Keyword Arguments.\n            dict\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "\n", "domain_sequence", "=", "list", "(", "domain_sequence", ".", "strip", "(", ")", ")", "# type: ignore", "\n", "if", "not", "set", "(", "domain_sequence", ")", ".", "issubset", "(", "{", "\"K\"", ",", "\"I\"", "}", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Invalid domain sequence. Got {domain_sequence}. Should only contain 'K' and 'I'.\"", ")", "\n", "\n", "", "if", "kspace_model_list", "is", "not", "None", "and", "len", "(", "kspace_model_list", ")", "!=", "domain_sequence", ".", "count", "(", "\"K\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"K-space domain steps do not match k-space model list length.\"", ")", "\n", "\n", "", "if", "len", "(", "image_model_list", ")", "!=", "domain_sequence", ".", "count", "(", "\"I\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Image domain steps do not match image model list length.\"", ")", "\n", "\n", "", "self", ".", "domain_sequence", "=", "domain_sequence", "\n", "\n", "self", ".", "kspace_model_list", "=", "kspace_model_list", "\n", "self", ".", "kspace_buffer_size", "=", "kspace_buffer_size", "\n", "\n", "self", ".", "image_model_list", "=", "image_model_list", "\n", "self", ".", "image_buffer_size", "=", "image_buffer_size", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.crossdomain.crossdomain.CrossDomainNetwork.kspace_correction": [[85, 103], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "crossdomain.CrossDomainNetwork._forward_operator", "image.clone", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat.permute", "torch.cat.permute"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.crossdomain.crossdomain.CrossDomainNetwork._forward_operator"], ["", "def", "kspace_correction", "(", "self", ",", "block_idx", ",", "image_buffer", ",", "kspace_buffer", ",", "sampling_mask", ",", "sensitivity_map", ",", "masked_kspace", ")", ":", "\n", "        ", "\"\"\"Performs k-space correction.\"\"\"", "\n", "forward_buffer", "=", "[", "\n", "self", ".", "_forward_operator", "(", "image", ".", "clone", "(", ")", ",", "sampling_mask", ",", "sensitivity_map", ")", "\n", "for", "image", "in", "torch", ".", "split", "(", "image_buffer", ",", "2", ",", "-", "1", ")", "\n", "]", "\n", "forward_buffer", "=", "torch", ".", "cat", "(", "forward_buffer", ",", "-", "1", ")", "\n", "\n", "kspace_buffer", "=", "torch", ".", "cat", "(", "[", "kspace_buffer", ",", "forward_buffer", ",", "masked_kspace", "]", ",", "-", "1", ")", "\n", "\n", "if", "self", ".", "kspace_model_list", "is", "not", "None", ":", "\n", "            ", "kspace_buffer", "=", "self", ".", "kspace_model_list", "[", "block_idx", "]", "(", "kspace_buffer", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", ")", ".", "permute", "(", "\n", "0", ",", "1", ",", "3", ",", "4", ",", "2", "\n", ")", "\n", "", "else", ":", "\n", "            ", "kspace_buffer", "=", "kspace_buffer", "[", "...", ",", ":", "2", "]", "-", "kspace_buffer", "[", "...", ",", "2", ":", "4", "]", "\n", "\n", "", "return", "kspace_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.crossdomain.crossdomain.CrossDomainNetwork.image_correction": [[104, 116], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "crossdomain.CrossDomainNetwork._backward_operator", "kspace.clone", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.crossdomain.crossdomain.CrossDomainNetwork._backward_operator"], ["", "def", "image_correction", "(", "self", ",", "block_idx", ",", "image_buffer", ",", "kspace_buffer", ",", "sampling_mask", ",", "sensitivity_map", ")", ":", "\n", "        ", "\"\"\"Performs image correction.\"\"\"", "\n", "backward_buffer", "=", "[", "\n", "self", ".", "_backward_operator", "(", "kspace", ".", "clone", "(", ")", ",", "sampling_mask", ",", "sensitivity_map", ")", "\n", "for", "kspace", "in", "torch", ".", "split", "(", "kspace_buffer", ",", "2", ",", "-", "1", ")", "\n", "]", "\n", "backward_buffer", "=", "torch", ".", "cat", "(", "backward_buffer", ",", "-", "1", ")", "\n", "\n", "image_buffer", "=", "torch", ".", "cat", "(", "[", "image_buffer", ",", "backward_buffer", "]", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "image_buffer", "=", "self", ".", "image_model_list", "[", "block_idx", "]", "(", "image_buffer", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "return", "image_buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.crossdomain.crossdomain.CrossDomainNetwork._forward_operator": [[117, 128], ["torch.where", "torch.where", "torch.where", "torch.where", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "mridc.collections.common.parts.fft.fft2().type", "image.type", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.utils.complex_mul", "image.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul"], ["", "def", "_forward_operator", "(", "self", ",", "image", ",", "sampling_mask", ",", "sensitivity_map", ")", ":", "\n", "        ", "\"\"\"Forward operator.\"\"\"", "\n", "return", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "image", ".", "dtype", ")", ".", "to", "(", "image", ".", "device", ")", ",", "\n", "fft2", "(", "\n", "complex_mul", "(", "image", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ",", "sensitivity_map", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ".", "type", "(", "image", ".", "type", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.crossdomain.crossdomain.CrossDomainNetwork._backward_operator": [[130, 145], ["torch.where", "torch.where", "torch.where", "torch.where", "mridc.collections.common.parts.utils.complex_mul().sum().type", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.where.type", "torch.where.type", "mridc.collections.common.parts.utils.complex_mul().sum", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj", "torch.where.float", "torch.where.float"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "def", "_backward_operator", "(", "self", ",", "kspace", ",", "sampling_mask", ",", "sensitivity_map", ")", ":", "\n", "        ", "\"\"\"Backward operator.\"\"\"", "\n", "kspace", "=", "torch", ".", "where", "(", "sampling_mask", "==", "0", ",", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "kspace", ".", "dtype", ")", ".", "to", "(", "kspace", ".", "device", ")", ",", "kspace", ")", "\n", "return", "(", "\n", "complex_mul", "(", "\n", "ifft2", "(", "\n", "kspace", ".", "float", "(", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "complex_conj", "(", "sensitivity_map", ")", ",", "\n", ")", "\n", ".", "sum", "(", "self", ".", "coil_dim", ")", "\n", ".", "type", "(", "kspace", ".", "type", "(", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.crossdomain.crossdomain.CrossDomainNetwork.forward": [[147, 189], ["crossdomain.CrossDomainNetwork._backward_operator", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "crossdomain.CrossDomainNetwork.kspace_correction", "crossdomain.CrossDomainNetwork.image_correction"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.crossdomain.crossdomain.CrossDomainNetwork._backward_operator", "home.repos.pwc.inspect_result.wdika_mridc.crossdomain.crossdomain.CrossDomainNetwork.kspace_correction", "home.repos.pwc.inspect_result.wdika_mridc.crossdomain.crossdomain.CrossDomainNetwork.image_correction"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", "sampling_mask", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes the forward pass of CrossDomainNetwork.\n\n        Parameters\n        ----------\n        masked_kspace: Subsampled k-space data.\n            torch.tenor, shape [batch_size, n_coil, height, width, 2]\n        sensitivity_map: Sensitivity map.\n            torch.tenor, shape [batch_size, n_coil, height, width, 2]\n        sampling_mask: Sampling mask.\n            torch.tenor, shape [batch_size, 1, height, width, 1]\n\n        Returns\n        -------\n        Output image.\n            torch.tenor, shape [batch_size, height, width, 2]\n        \"\"\"", "\n", "input_image", "=", "self", ".", "_backward_operator", "(", "masked_kspace", ",", "sampling_mask", ",", "sensitivity_map", ")", "\n", "\n", "image_buffer", "=", "torch", ".", "cat", "(", "[", "input_image", "]", "*", "self", ".", "image_buffer_size", ",", "-", "1", ")", ".", "to", "(", "masked_kspace", ".", "device", ")", "\n", "kspace_buffer", "=", "torch", ".", "cat", "(", "[", "masked_kspace", "]", "*", "self", ".", "kspace_buffer_size", ",", "-", "1", ")", ".", "to", "(", "masked_kspace", ".", "device", ")", "\n", "\n", "kspace_block_idx", ",", "image_block_idx", "=", "0", ",", "0", "\n", "for", "block_domain", "in", "self", ".", "domain_sequence", ":", "\n", "            ", "if", "block_domain", "==", "\"K\"", ":", "\n", "                ", "kspace_buffer", "=", "self", ".", "kspace_correction", "(", "\n", "kspace_block_idx", ",", "image_buffer", ",", "kspace_buffer", ",", "sampling_mask", ",", "sensitivity_map", ",", "masked_kspace", "\n", ")", "\n", "kspace_block_idx", "+=", "1", "\n", "", "else", ":", "\n", "                ", "image_buffer", "=", "self", ".", "image_correction", "(", "\n", "image_block_idx", ",", "image_buffer", ",", "kspace_buffer", ",", "sampling_mask", ",", "sensitivity_map", "\n", ")", "\n", "image_block_idx", "+=", "1", "\n", "\n", "", "", "return", "image_buffer", "[", "...", ",", ":", "2", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DataIDLayer.__init__": [[18, 20], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DataGDLayer.__init__": [[25, 54], ["super().__init__", "torch.nn.Parameter", "torch.tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "lambda_init", ",", "\n", "learnable", "=", "True", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        lambda_init: Init value of data term weight lambda.\n        learnable: If True, the data term weight lambda is learnable.\n        fft_centered: If True, the FFT is centered.\n        fft_normalization: If \"ortho\", the FFT is normalized.\n        spatial_dims: If not None, the spatial dimensions of the FFT.\n        \"\"\"", "\n", "super", "(", "DataGDLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lambda_init", "=", "lambda_init", "\n", "self", ".", "data_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ")", ")", "\n", "self", ".", "data_weight", ".", "data", "=", "torch", ".", "tensor", "(", "\n", "lambda_init", ",", "\n", "dtype", "=", "self", ".", "data_weight", ".", "dtype", ",", "\n", ")", "\n", "self", ".", "data_weight", ".", "requires_grad", "=", "learnable", "\n", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DataGDLayer.forward": [[55, 96], ["torch.sum", "torch.sum", "mridc.collections.common.parts.utils.complex_mul", "ifft2c", "mridc.collections.common.parts.utils.complex_conj", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.utils.complex_mul", "x.unsqueeze().expand_as", "x.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "smaps", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        x: Input image.\n        y: Subsampled k-space data.\n        smaps: Coil sensitivity maps.\n        mask: Sampling mask.\n\n        Returns\n        -------\n        data_loss: Data term loss.\n        \"\"\"", "\n", "A_x_y", "=", "(", "\n", "torch", ".", "sum", "(", "\n", "fft2", "(", "\n", "complex_mul", "(", "x", ".", "unsqueeze", "(", "-", "5", ")", ".", "expand_as", "(", "smaps", ")", ",", "smaps", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "*", "mask", ",", "\n", "-", "4", ",", "\n", "keepdim", "=", "True", ",", "\n", ")", "\n", "-", "y", "\n", ")", "\n", "gradD_x", "=", "torch", ".", "sum", "(", "\n", "complex_mul", "(", "\n", "ifft2c", "(", "\n", "A_x_y", "*", "mask", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "complex_conj", "(", "smaps", ")", ",", "\n", ")", ",", "\n", "dim", "=", "(", "-", "5", ")", ",", "\n", ")", "\n", "return", "x", "-", "self", ".", "data_weight", "*", "gradD_x", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DataProxCGLayer.__init__": [[101, 126], ["super().__init__", "torch.nn.Parameter", "torch.tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "lambda_init", ",", "\n", "tol", "=", "1e-6", ",", "\n", "iter", "=", "10", ",", "\n", "learnable", "=", "True", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "super", "(", "DataProxCGLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "lambdaa", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ")", ")", "\n", "self", ".", "lambdaa", ".", "data", "=", "torch", ".", "tensor", "(", "lambda_init", ")", "\n", "self", ".", "lambdaa_init", "=", "lambda_init", "\n", "self", ".", "lambdaa", ".", "requires_grad", "=", "learnable", "\n", "\n", "self", ".", "tol", "=", "tol", "\n", "self", ".", "iter", "=", "iter", "\n", "\n", "self", ".", "op", "=", "ConjugateGradient", "\n", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DataProxCGLayer.forward": [[127, 152], ["dc_layers.DataProxCGLayer.op.apply"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "f", ",", "smaps", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        x: Input image.\n        f: Subsampled k-space data.\n        smaps: Coil sensitivity maps.\n        mask: Sampling mask.\n\n        Returns\n        -------\n        data_loss: Data term loss.\n        \"\"\"", "\n", "return", "self", ".", "op", ".", "apply", "(", "\n", "x", ",", "\n", "self", ".", "lambdaa", ",", "\n", "f", ",", "\n", "smaps", ",", "\n", "mask", ",", "\n", "self", ".", "tol", ",", "\n", "self", ".", "iter", ",", "\n", "self", ".", "fft_centered", ",", "\n", "self", ".", "fft_normalization", ",", "\n", "self", ".", "spatial_dims", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DataProxCGLayer.set_learnable": [[154, 156], ["None"], "methods", ["None"], ["", "def", "set_learnable", "(", "self", ",", "flag", ")", ":", "\n", "        ", "self", ".", "lambdaa", ".", "requires_grad", "=", "flag", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.ConjugateGradient.complexDot": [[161, 168], ["mridc.collections.common.parts.utils.complex_mul", "torch.unbind", "torch.stack", "mridc.collections.common.parts.utils.complex_conj", "torch.sum", "torch.sum", "re.view", "im.view"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["@", "staticmethod", "\n", "def", "complexDot", "(", "data1", ",", "data2", ")", ":", "\n", "        ", "\"\"\"Complex dot product of two tensors.\"\"\"", "\n", "nBatch", "=", "data1", ".", "shape", "[", "0", "]", "\n", "mult", "=", "complex_mul", "(", "data1", ",", "complex_conj", "(", "data2", ")", ")", "\n", "re", ",", "im", "=", "torch", ".", "unbind", "(", "mult", ",", "dim", "=", "-", "1", ")", "\n", "return", "torch", ".", "stack", "(", "[", "torch", ".", "sum", "(", "re", ".", "view", "(", "nBatch", ",", "-", "1", ")", ",", "dim", "=", "-", "1", ")", ",", "torch", ".", "sum", "(", "im", ".", "view", "(", "nBatch", ",", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "]", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.ConjugateGradient.solve": [[169, 198], ["torch.zeros().to", "x0.clone", "x0.clone", "x0.pow().view().sum", "torch.stack", "dc_layers.ConjugateGradient.forward.M", "dc_layers.ConjugateGradient.complexDot", "torch.unbind", "torch.unbind", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_mul", "torch.stack", "torch.stack", "torch.stack.clone", "torch.zeros", "x0.pow().view", "x0.clone.pow().view().sum", "torch.zeros().to", "torch.min", "torch.stack", "alpha.reshape", "x0.clone.clone", "alpha.reshape", "M.clone", "x0.clone.clone", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_abs", "x0.clone.pow().view().sum", "torch.zeros().to", "torch.zeros().to", "torch.stack.reshape", "x0.pow", "x0.clone.pow().view", "torch.zeros", "x0.clone.pow().view", "torch.zeros", "torch.zeros", "x0.clone.pow", "x0.clone.pow"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.ConjugateGradient.complexDot", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_abs"], ["", "@", "staticmethod", "\n", "def", "solve", "(", "x0", ",", "M", ",", "tol", ",", "max_iter", ")", ":", "\n", "        ", "\"\"\"Solve the linear system Mx=b using conjugate gradient.\"\"\"", "\n", "nBatch", "=", "x0", ".", "shape", "[", "0", "]", "\n", "x", "=", "torch", ".", "zeros", "(", "x0", ".", "shape", ")", ".", "to", "(", "x0", ".", "device", ")", "\n", "r", "=", "x0", ".", "clone", "(", ")", "\n", "p", "=", "x0", ".", "clone", "(", ")", "\n", "x0x0", "=", "(", "x0", ".", "pow", "(", "2", ")", ")", ".", "view", "(", "nBatch", ",", "-", "1", ")", ".", "sum", "(", "-", "1", ")", "\n", "rr", "=", "torch", ".", "stack", "(", "[", "(", "r", ".", "pow", "(", "2", ")", ")", ".", "view", "(", "nBatch", ",", "-", "1", ")", ".", "sum", "(", "-", "1", ")", ",", "torch", ".", "zeros", "(", "nBatch", ")", ".", "to", "(", "x0", ".", "device", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "it", "=", "0", "\n", "while", "torch", ".", "min", "(", "rr", "[", "...", ",", "0", "]", "/", "x0x0", ")", ">", "tol", "and", "it", "<", "max_iter", ":", "\n", "            ", "it", "+=", "1", "\n", "q", "=", "M", "(", "p", ")", "\n", "\n", "data1", "=", "rr", "\n", "data2", "=", "ConjugateGradient", ".", "complexDot", "(", "p", ",", "q", ")", "\n", "\n", "re1", ",", "im1", "=", "torch", ".", "unbind", "(", "data1", ",", "-", "1", ")", "\n", "re2", ",", "im2", "=", "torch", ".", "unbind", "(", "data2", ",", "-", "1", ")", "\n", "alpha", "=", "torch", ".", "stack", "(", "[", "re1", "*", "re2", "+", "im1", "*", "im2", ",", "im1", "*", "re2", "-", "re1", "*", "im2", "]", ",", "-", "1", ")", "/", "complex_abs", "(", "data2", ")", "**", "2", "\n", "\n", "x", "+=", "complex_mul", "(", "alpha", ".", "reshape", "(", "nBatch", ",", "1", ",", "1", ",", "1", ",", "-", "1", ")", ",", "p", ".", "clone", "(", ")", ")", "\n", "r", "-=", "complex_mul", "(", "alpha", ".", "reshape", "(", "nBatch", ",", "1", ",", "1", ",", "1", ",", "-", "1", ")", ",", "q", ".", "clone", "(", ")", ")", "\n", "rr_new", "=", "torch", ".", "stack", "(", "[", "(", "r", ".", "pow", "(", "2", ")", ")", ".", "view", "(", "nBatch", ",", "-", "1", ")", ".", "sum", "(", "-", "1", ")", ",", "torch", ".", "zeros", "(", "nBatch", ")", ".", "to", "(", "x0", ".", "device", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "beta", "=", "torch", ".", "stack", "(", "[", "rr_new", "[", "...", ",", "0", "]", "/", "rr", "[", "...", ",", "0", "]", ",", "torch", ".", "zeros", "(", "nBatch", ")", ".", "to", "(", "x0", ".", "device", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "p", "=", "r", ".", "clone", "(", ")", "+", "complex_mul", "(", "beta", ".", "reshape", "(", "nBatch", ",", "1", ",", "1", ",", "1", ",", "-", "1", ")", ",", "p", ")", "\n", "rr", "=", "rr_new", ".", "clone", "(", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.ConjugateGradient.forward": [[199, 256], ["ctx.save_for_backward", "dc_layers.ConjugateGradient.solve", "torch.sum", "torch.sum", "dc_layers.ConjugateGradient.forward.AT"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.ConjugateGradient.solve"], ["", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "z", ",", "lambdaa", ",", "y", ",", "smaps", ",", "mask", ",", "tol", ",", "max_iter", ",", "fft_centered", ",", "fft_normalization", ",", "spatial_dims", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass of the conjugate gradient solver.\n\n        Parameters\n        ----------\n        ctx: Context object.\n        z: Input image.\n        lambdaa: Regularization parameter.\n        y: Subsampled k-space data.\n        smaps: Coil sensitivity maps.\n        mask: Sampling mask.\n        tol: Tolerance for the stopping criterion.\n        max_iter: Maximum number of iterations.\n        fft_centered: Boolean flag for centering the FFT.\n        fft_normalization: Boolean flag for normalizing the FFT.\n        spatial_dims: Spatial dimensions.\n\n        Returns\n        -------\n        z: Output image.\n        \"\"\"", "\n", "ctx", ".", "tol", "=", "tol", "\n", "ctx", ".", "max_iter", "=", "max_iter", "\n", "ctx", ".", "fft_centered", "=", "fft_centered", "\n", "ctx", ".", "fft_normalization", "=", "fft_normalization", "\n", "ctx", ".", "spatial_dims", "=", "spatial_dims", "\n", "\n", "def", "A", "(", "x", ")", ":", "\n", "            ", "x", "=", "(", "\n", "fft2", "(", "\n", "complex_mul", "(", "x", ".", "expand_as", "(", "smaps", ")", ",", "smaps", ")", ",", "\n", "centered", "=", "fft_centered", ",", "\n", "normalization", "=", "fft_normalization", ",", "\n", "spatial_dims", "=", "spatial_dims", ",", "\n", ")", "\n", "*", "mask", "\n", ")", "\n", "return", "torch", ".", "sum", "(", "x", ",", "dim", "=", "-", "4", ",", "keepdim", "=", "True", ")", "\n", "\n", "", "def", "AT", "(", "x", ")", ":", "\n", "            ", "return", "torch", ".", "sum", "(", "\n", "complex_mul", "(", "\n", "ifft2", "(", "x", "*", "mask", ",", "centered", "=", "fft_centered", ",", "normalization", "=", "fft_normalization", ",", "spatial_dims", "=", "spatial_dims", ")", ",", "\n", "complex_conj", "(", "smaps", ")", ",", "\n", ")", ",", "\n", "dim", "=", "(", "-", "5", ")", ",", "\n", ")", "\n", "\n", "", "def", "M", "(", "p", ")", ":", "\n", "            ", "return", "lambdaa", "*", "AT", "(", "A", "(", "p", ")", ")", "+", "p", "\n", "\n", "", "x0", "=", "lambdaa", "*", "AT", "(", "y", ")", "+", "z", "\n", "ctx", ".", "save_for_backward", "(", "AT", "(", "y", ")", ",", "x0", ",", "smaps", ",", "mask", ",", "lambdaa", ")", "\n", "\n", "return", "ConjugateGradient", ".", "solve", "(", "x0", ",", "M", ",", "ctx", ".", "tol", ",", "ctx", ".", "max_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.ConjugateGradient.backward": [[257, 323], ["dc_layers.ConjugateGradient.solve", "dc_layers.ConjugateGradient.solve", "torch.sum", "torch.sum", "mridc.collections.common.parts.utils.complex_mul().sum", "mridc.collections.common.parts.utils.complex_mul().sum", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj", "dc_layers.ConjugateGradient.forward.AT"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.ConjugateGradient.solve", "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.ConjugateGradient.solve", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_x", ")", ":", "\n", "        ", "\"\"\"\n        Backward pass of the conjugate gradient solver.\n\n        Parameters\n        ----------\n        ctx: Context object.\n        grad_x: Gradient of the output image.\n\n        Returns\n        -------\n        grad_z: Gradient of the input image.\n        \"\"\"", "\n", "ATy", ",", "rhs", ",", "smaps", ",", "mask", ",", "lambdaa", "=", "ctx", ".", "saved_tensors", "\n", "\n", "def", "A", "(", "x", ")", ":", "\n", "            ", "x", "=", "(", "\n", "fft2", "(", "\n", "complex_mul", "(", "x", ".", "expand_as", "(", "smaps", ")", ",", "smaps", ")", ",", "\n", "centered", "=", "ctx", ".", "fft_centered", ",", "\n", "normalization", "=", "ctx", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "ctx", ".", "spatial_dims", ",", "\n", ")", "\n", "*", "mask", "\n", ")", "\n", "return", "torch", ".", "sum", "(", "x", ",", "dim", "=", "-", "4", ",", "keepdim", "=", "True", ")", "\n", "\n", "", "def", "AT", "(", "x", ")", ":", "\n", "            ", "return", "torch", ".", "sum", "(", "\n", "complex_mul", "(", "\n", "ifft2", "(", "\n", "x", "*", "mask", ",", "\n", "centered", "=", "ctx", ".", "fft_centered", ",", "\n", "normalization", "=", "ctx", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "ctx", ".", "spatial_dimso", ",", "\n", ")", ",", "\n", "complex_conj", "(", "smaps", ")", ",", "\n", ")", ",", "\n", "dim", "=", "(", "-", "5", ")", ",", "\n", ")", "\n", "\n", "", "def", "M", "(", "p", ")", ":", "\n", "            ", "return", "lambdaa", "*", "AT", "(", "A", "(", "p", ")", ")", "+", "p", "\n", "\n", "", "Qe", "=", "ConjugateGradient", ".", "solve", "(", "grad_x", ",", "M", ",", "ctx", ".", "tol", ",", "ctx", ".", "max_iter", ")", "\n", "QQe", "=", "ConjugateGradient", ".", "solve", "(", "Qe", ",", "M", ",", "ctx", ".", "tol", ",", "ctx", ".", "max_iter", ")", "\n", "\n", "grad_z", "=", "Qe", "\n", "\n", "grad_lambdaa", "=", "(", "\n", "complex_mul", "(", "\n", "ifft2", "(", "\n", "Qe", ",", "centered", "=", "ctx", ".", "fft_centered", ",", "normalization", "=", "ctx", ".", "fft_normalization", ",", "spatial_dims", "=", "ctx", ".", "spatial_dims", "\n", ")", ",", "\n", "complex_conj", "(", "ATy", ")", ",", "\n", ")", ".", "sum", "(", ")", "\n", "-", "complex_mul", "(", "\n", "ifft2", "(", "\n", "QQe", ",", "centered", "=", "ctx", ".", "fft_centered", ",", "normalization", "=", "ctx", ".", "fft_normalization", ",", "spatial_dims", "=", "ctx", ".", "spatial_dims", "\n", ")", ",", "\n", "complex_conj", "(", "rhs", ")", ",", "\n", ")", ".", "sum", "(", ")", "\n", ")", "\n", "\n", "return", "grad_z", ",", "grad_lambdaa", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DataVSLayer.__init__": [[330, 362], ["super().__init__", "torch.nn.Parameter", "torch.tensor", "torch.nn.Parameter", "torch.tensor", "dc_layers.DataVSLayer.set_learnable", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DCLayer.set_learnable"], ["def", "__init__", "(", "\n", "self", ",", "\n", "alpha_init", ",", "\n", "beta_init", ",", "\n", "learnable", "=", "True", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        alpha_init: Init value of data consistency block (DCB)\n        beta_init: Init value of weighted averaging block (WAB)\n        learnable: If True, the parameters of the model are learnable\n        fft_centered: If True, the FFT is centered\n        fft_normalization: If \"ortho\", the FFT is normalized to be orthogonal\n        spatial_dims: If not None, the spatial dimensions of the FFT\n        \"\"\"", "\n", "super", "(", "DataVSLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "alpha", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ")", ")", "\n", "self", ".", "alpha", ".", "data", "=", "torch", ".", "tensor", "(", "alpha_init", ",", "dtype", "=", "self", ".", "alpha", ".", "dtype", ")", "\n", "\n", "self", ".", "beta", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ")", ")", "\n", "self", ".", "beta", ".", "data", "=", "torch", ".", "tensor", "(", "beta_init", ",", "dtype", "=", "self", ".", "beta", ".", "dtype", ")", "\n", "\n", "self", ".", "learnable", "=", "learnable", "\n", "self", ".", "set_learnable", "(", "learnable", ")", "\n", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DataVSLayer.forward": [[363, 402], ["torch.sum", "torch.sum", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj", "x.unsqueeze().expand_as", "x.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "smaps", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass of the data-consistency block.\n\n        Parameters\n        ----------\n        x: Input image.\n        y: Subsampled k-space data.\n        smaps: Coil sensitivity maps.\n        mask: Sampling mask.\n\n        Returns\n        -------\n        Output image.\n        \"\"\"", "\n", "A_x", "=", "torch", ".", "sum", "(", "\n", "fft2", "(", "\n", "complex_mul", "(", "x", ".", "unsqueeze", "(", "-", "5", ")", ".", "expand_as", "(", "smaps", ")", ",", "smaps", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "-", "4", ",", "\n", "keepdim", "=", "True", ",", "\n", ")", "\n", "k_dc", "=", "(", "1", "-", "mask", ")", "*", "A_x", "+", "mask", "*", "(", "self", ".", "alpha", "*", "A_x", "+", "(", "1", "-", "self", ".", "alpha", ")", "*", "y", ")", "\n", "x_dc", "=", "torch", ".", "sum", "(", "\n", "complex_mul", "(", "\n", "ifft2", "(", "\n", "k_dc", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "complex_conj", "(", "smaps", ")", ",", "\n", ")", ",", "\n", "dim", "=", "(", "-", "5", ")", ",", "\n", ")", "\n", "return", "self", ".", "beta", "*", "x", "+", "(", "1", "-", "self", ".", "beta", ")", "*", "x_dc", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DataVSLayer.set_learnable": [[403, 414], ["None"], "methods", ["None"], ["", "def", "set_learnable", "(", "self", ",", "flag", ")", ":", "\n", "        ", "\"\"\"\n        Set the learnable flag of the parameters.\n\n        Parameters\n        ----------\n        flag: If True, the parameters of the model are learnable.\n        \"\"\"", "\n", "self", ".", "learnable", "=", "flag", "\n", "self", ".", "alpha", ".", "requires_grad", "=", "self", ".", "learnable", "\n", "self", ".", "beta", ".", "requires_grad", "=", "self", ".", "learnable", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DCLayer.__init__": [[421, 448], ["super().__init__", "torch.nn.Parameter", "torch.tensor", "dc_layers.DCLayer.set_learnable", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DCLayer.set_learnable"], ["def", "__init__", "(", "\n", "self", ",", "\n", "lambda_init", "=", "0.0", ",", "\n", "learnable", "=", "True", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        lambda_init: Init value of data consistency block (DCB)\n        learnable: If True, the parameters of the model are learnable\n        fft_centered: If True, the FFT is centered\n        fft_normalization: If \"ortho\", the FFT is normalized to be orthogonal\n        spatial_dims: If not None, the spatial dimensions of the FFT\n        \"\"\"", "\n", "super", "(", "DCLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lambda_", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ")", ")", "\n", "self", ".", "lambda_", ".", "data", "=", "torch", ".", "tensor", "(", "lambda_init", ",", "dtype", "=", "self", ".", "lambda_", ".", "dtype", ")", "\n", "\n", "self", ".", "learnable", "=", "learnable", "\n", "self", ".", "set_learnable", "(", "learnable", ")", "\n", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DCLayer.forward": [[449, 467], ["mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.fft.ifft2"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass of the data-consistency block.\n\n        Parameters\n        ----------\n        x: Input image.\n        y: Subsampled k-space data.\n        mask: Sampling mask.\n\n        Returns\n        -------\n        Output image.\n        \"\"\"", "\n", "A_x", "=", "fft2", "(", "x", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", ")", "\n", "k_dc", "=", "(", "1", "-", "mask", ")", "*", "A_x", "+", "mask", "*", "(", "self", ".", "lambda_", "*", "A_x", "+", "(", "1", "-", "self", ".", "lambda_", ")", "*", "y", ")", "\n", "return", "ifft2", "(", "\n", "k_dc", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.dc_layers.DCLayer.set_learnable": [[469, 479], ["None"], "methods", ["None"], ["", "def", "set_learnable", "(", "self", ",", "flag", ")", ":", "\n", "        ", "\"\"\"\n        Set the learnable flag of the parameters.\n\n        Parameters\n        ----------\n        flag: If True, the parameters of the model are learnable.\n        \"\"\"", "\n", "self", ".", "learnable", "=", "flag", "\n", "self", ".", "lambda_", ".", "requires_grad", "=", "self", ".", "learnable", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.__init__": [[19, 26], ["super().__init__", "numpy.sqrt", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "ComplexInstanceNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mean", "=", "0", "\n", "self", ".", "cov_xx_half", "=", "1", "/", "np", ".", "sqrt", "(", "2", ")", "\n", "self", ".", "cov_xy_half", "=", "0", "\n", "self", ".", "cov_yx_half", "=", "0", "\n", "self", ".", "cov_yy_half", "=", "1", "/", "np", ".", "sqrt", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.complex_instance_norm": [[27, 34], ["torch.sum", "torch.sum.mean", "sensitivity_net.ComplexInstanceNorm.complex_pseudocovariance"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.complex_pseudocovariance"], ["", "def", "complex_instance_norm", "(", "self", ",", "x", ",", "eps", "=", "1e-5", ")", ":", "\n", "        ", "\"\"\"Operates on images x of size [nBatch, nSmaps, nFE, nPE, 2]\"\"\"", "\n", "x_combined", "=", "torch", ".", "sum", "(", "x", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "mean", "=", "x_combined", ".", "mean", "(", "dim", "=", "(", "1", ",", "2", ",", "3", ")", ",", "keepdim", "=", "True", ")", "\n", "x_m", "=", "x", "-", "mean", "\n", "self", ".", "mean", "=", "mean", "\n", "self", ".", "complex_pseudocovariance", "(", "x_m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.complex_pseudocovariance": [[35, 86], ["torch.unbind", "list", "torch.sqrt", "torch.sqrt", "v1x.div.div.div", "v1y.div.div.div", "v2x.div.div.div", "v2y.div.div.div", "torch.sqrt().div", "torch.sqrt().div", "data.size", "range", "torch.sqrt", "torch.sqrt", "torch.sum", "torch.sum", "torch.sqrt", "torch.sqrt", "len"], "methods", ["None"], ["", "def", "complex_pseudocovariance", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\"Data variable hast to be already mean-free! Operates on images x of size [nBatch, nSmaps, nFE, nPE, 2]\"\"\"", "\n", "if", "data", ".", "size", "(", "-", "1", ")", "!=", "2", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "shape", "=", "data", ".", "shape", "\n", "\n", "# compute number of elements", "\n", "N", "=", "shape", "[", "2", "]", "*", "shape", "[", "3", "]", "\n", "\n", "# separate real/imaginary channel", "\n", "re", ",", "im", "=", "torch", ".", "unbind", "(", "data", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# dimensions is now length of original shape - 1 (because channels are seperated)", "\n", "dim", "=", "list", "(", "range", "(", "1", ",", "len", "(", "shape", ")", "-", "1", ")", ")", "\n", "\n", "# compute covariance entries. cxy = cyx", "\n", "cxx", "=", "(", "re", "*", "re", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "/", "(", "N", "-", "1", ")", "\n", "cyy", "=", "(", "im", "*", "im", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "/", "(", "N", "-", "1", ")", "\n", "cxy", "=", "(", "re", "*", "im", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", "/", "(", "N", "-", "1", ")", "\n", "\n", "# Eigenvalue decomposition C = V*S*inv(V)", "\n", "# compute eigenvalues", "\n", "s1", "=", "(", "cxx", "+", "cyy", ")", "/", "2", "-", "torch", ".", "sqrt", "(", "(", "cxx", "+", "cyy", ")", "**", "2", "/", "4", "-", "cxx", "*", "cyy", "+", "cxy", "**", "2", ")", "\n", "s2", "=", "(", "cxx", "+", "cyy", ")", "/", "2", "+", "torch", ".", "sqrt", "(", "(", "cxx", "+", "cyy", ")", "**", "2", "/", "4", "-", "cxx", "*", "cyy", "+", "cxy", "**", "2", ")", "\n", "\n", "# compute eigenvectors", "\n", "v1x", "=", "s1", "-", "cyy", "\n", "v1y", "=", "cxy", "\n", "v2x", "=", "s2", "-", "cyy", "\n", "v2y", "=", "cxy", "\n", "\n", "# normalize eigenvectors", "\n", "norm1", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "v1x", "*", "v1x", "+", "v1y", "*", "v1y", ",", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", ")", "\n", "norm2", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "v2x", "*", "v2x", "+", "v2y", "*", "v2y", ",", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", ")", "\n", "\n", "v1x", "=", "v1x", ".", "div", "(", "norm1", ")", "\n", "v1y", "=", "v1y", ".", "div", "(", "norm1", ")", "\n", "\n", "v2x", "=", "v2x", ".", "div", "(", "norm2", ")", "\n", "v2y", "=", "v2y", ".", "div", "(", "norm2", ")", "\n", "\n", "# now we need the sqrt of the covariance matrix.", "\n", "# C^{-0.5} = V * sqrt(S) * inv(V)", "\n", "det", "=", "v1x", "*", "v2y", "-", "v2x", "*", "v1y", "\n", "s1", "=", "torch", ".", "sqrt", "(", "s1", ")", ".", "div", "(", "det", ")", "\n", "s2", "=", "torch", ".", "sqrt", "(", "s2", ")", ".", "div", "(", "det", ")", "\n", "\n", "self", ".", "cov_xx_half", "=", "v1x", "*", "v2y", "*", "s1", "-", "v1y", "*", "v2x", "*", "s2", "\n", "self", ".", "cov_yy_half", "=", "v1x", "*", "v2y", "*", "s2", "-", "v1y", "*", "v2x", "*", "s1", "\n", "self", ".", "cov_xy_half", "=", "v1x", "*", "v2x", "*", "(", "s2", "-", "s1", ")", "\n", "self", ".", "cov_yx_half", "=", "v1y", "*", "v2y", "*", "(", "s1", "-", "s2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.forward": [[87, 90], ["sensitivity_net.ComplexInstanceNorm.normalize"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.normalize"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Operates on images x of size [nBatch, nSmaps, nFE, nPE, 2]\"\"\"", "\n", "return", "self", ".", "normalize", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.set_normalization": [[91, 100], ["torch.tensor().to", "sensitivity_net.ComplexInstanceNorm.complex_pseudocovariance", "torch.tensor().to.unsqueeze().unsqueeze().unsqueeze", "sensitivity_net.ComplexInstanceNorm.cov_xx_half.view", "sensitivity_net.ComplexInstanceNorm.cov_xy_half.view", "sensitivity_net.ComplexInstanceNorm.cov_yx_half.view", "sensitivity_net.ComplexInstanceNorm.cov_yy_half.view", "torch.tensor", "torch.tensor().to.unsqueeze().unsqueeze", "torch.mean().item", "torch.tensor().to.unsqueeze", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.complex_pseudocovariance"], ["", "def", "set_normalization", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"Set the normalization parameters for a given input.\"\"\"", "\n", "mean", "=", "torch", ".", "tensor", "(", "[", "torch", ".", "mean", "(", "input", ")", ".", "item", "(", ")", "]", ")", ".", "to", "(", "input", ")", "\n", "self", ".", "complex_pseudocovariance", "(", "input", "-", "mean", ")", "\n", "self", ".", "mean", "=", "mean", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "self", ".", "cov_xx_half", "=", "self", ".", "cov_xx_half", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "cov_xy_half", "=", "self", ".", "cov_xy_half", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "cov_yx_half", "=", "self", ".", "cov_yx_half", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "cov_yy_half", "=", "self", ".", "cov_yy_half", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.normalize": [[101, 114], ["torch.unbind", "sensitivity_net.matrix_invert", "torch.stack", "img.clamp.clamp.clamp"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.matrix_invert"], ["", "def", "normalize", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Normalize the input x.\"\"\"", "\n", "x_m", "=", "x", "-", "self", ".", "mean", "\n", "re", ",", "im", "=", "torch", ".", "unbind", "(", "x_m", ",", "dim", "=", "-", "1", ")", "\n", "\n", "cov_xx_half_inv", ",", "cov_xy_half_inv", ",", "cov_yx_half_inv", ",", "cov_yy_half_inv", "=", "matrix_invert", "(", "\n", "self", ".", "cov_xx_half", ",", "self", ".", "cov_xy_half", ",", "self", ".", "cov_yx_half", ",", "self", ".", "cov_yy_half", "\n", ")", "\n", "x_norm_re", "=", "cov_xx_half_inv", "*", "re", "+", "cov_xy_half_inv", "*", "im", "\n", "x_norm_im", "=", "cov_yx_half_inv", "*", "re", "+", "cov_yy_half_inv", "*", "im", "\n", "img", "=", "torch", ".", "stack", "(", "[", "x_norm_re", ",", "x_norm_im", "]", ",", "dim", "=", "-", "1", ")", "\n", "img", "=", "img", ".", "clamp", "(", "-", "6", ",", "6", ")", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.unnormalize": [[115, 121], ["torch.unbind", "torch.stack"], "methods", ["None"], ["", "def", "unnormalize", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Unnormalize the input x.\"\"\"", "\n", "re", ",", "im", "=", "torch", ".", "unbind", "(", "x", ",", "dim", "=", "-", "1", ")", "\n", "x_unnorm_re", "=", "self", ".", "cov_xx_half", "*", "re", "+", "self", ".", "cov_xy_half", "*", "im", "\n", "x_unnorm_im", "=", "self", ".", "cov_yx_half", "*", "re", "+", "self", ".", "cov_yy_half", "*", "im", "\n", "return", "torch", ".", "stack", "(", "[", "x_unnorm_re", ",", "x_unnorm_im", "]", ",", "dim", "=", "-", "1", ")", "+", "self", ".", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexNormWrapper.__init__": [[126, 130], ["super().__init__", "sensitivity_net.ComplexInstanceNorm"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "model", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "complex_instance_norm", "=", "ComplexInstanceNorm", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexNormWrapper.forward": [[131, 149], ["sensitivity_net.ComplexNormWrapper.complex_instance_norm.set_normalization", "sensitivity_net.ComplexNormWrapper.complex_instance_norm.normalize", "sensitivity_net.ComplexNormWrapper.view().permute", "sensitivity_net.ComplexNormWrapper.model", "sensitivity_net.ComplexNormWrapper.permute().view", "sensitivity_net.ComplexNormWrapper.complex_instance_norm.unnormalize", "sensitivity_net.ComplexNormWrapper.view", "sensitivity_net.ComplexNormWrapper.permute"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.set_normalization", "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.normalize", "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.ComplexInstanceNorm.unnormalize"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# compute complex instance norm on sample of size [nBatch, nSmaps, nFE, nPE, 2]", "\n", "        ", "self", ".", "complex_instance_norm", ".", "set_normalization", "(", "input", ")", "\n", "output", "=", "self", ".", "complex_instance_norm", ".", "normalize", "(", "input", ")", "\n", "\n", "# re-shape data from [nBatch, nSmaps, nFE, nPE, 2] to [nBatch*nSmaps, 2, nFE, nPE]", "\n", "shp", "=", "output", ".", "shape", "\n", "output", "=", "output", ".", "view", "(", "shp", "[", "0", "]", "*", "shp", "[", "1", "]", ",", "*", "shp", "[", "2", ":", "]", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "\n", "# apply denoising", "\n", "output", "=", "self", ".", "model", "(", "output", ")", "\n", "\n", "# re-shape data from [nBatch*nSmaps, 2, nFE, nPE]", "\n", "# to [nBatch, nSmaps, nFE, nPE, 2]", "\n", "output", "=", "output", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "view", "(", "*", "shp", ")", "\n", "# unnormalize", "\n", "output", "=", "self", ".", "complex_instance_norm", ".", "unnormalize", "(", "output", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.__init__": [[154, 192], ["super().__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "sensitivity_net.ComplexNormWrapper", "range", "range"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_iter", ",", "\n", "model", ",", "\n", "datalayer", ",", "\n", "shared_params", "=", "True", ",", "\n", "save_space", "=", "False", ",", "\n", "reset_cache", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        num_iter: Number of iterations.\n        model: Model to be used for the forward and adjoint.\n        datalayer: Data layer to be used for the forward and adjoint.\n        shared_params: If True, the parameters of the model are shared between the forward and adjoint.\n        save_space: If True, the adjoint is computed in the forward pass.\n        reset_cache: If True, the adjoint is computed in the forward pass.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "shared_params", "=", "shared_params", "\n", "\n", "self", ".", "num_iter", "=", "1", "if", "self", ".", "shared_params", "else", "num_iter", "\n", "self", ".", "num_iter_total", "=", "num_iter", "\n", "\n", "self", ".", "is_trainable", "=", "[", "True", "]", "*", "num_iter", "\n", "\n", "# setup the modules", "\n", "self", ".", "gradR", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "ComplexNormWrapper", "(", "model", ")", "for", "_", "in", "range", "(", "self", ".", "num_iter", ")", "]", ")", "\n", "\n", "self", ".", "gradD", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "datalayer", "for", "_", "in", "range", "(", "self", ".", "num_iter", ")", "]", ")", "\n", "\n", "self", ".", "save_space", "=", "save_space", "\n", "if", "self", ".", "save_space", ":", "\n", "            ", "self", ".", "forward", "=", "self", ".", "forward_save_space", "\n", "", "self", ".", "reset_cache", "=", "reset_cache", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.forward": [[193, 221], ["range", "min", "x_all.append", "x_half_all.append", "numpy.where"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "smaps", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        x: Input data.\n        y: Subsampled k-space data.\n        smaps: Coil sensitivity maps.\n        mask: Sampling mask.\n\n        Returns\n        -------\n        Output data.\n        \"\"\"", "\n", "x_all", "=", "[", "x", "]", "\n", "x_half_all", "=", "[", "]", "\n", "if", "self", ".", "shared_params", ":", "\n", "            ", "num_iter", "=", "self", ".", "num_iter_total", "\n", "", "else", ":", "\n", "            ", "num_iter", "=", "min", "(", "np", ".", "where", "(", "self", ".", "is_trainable", ")", "[", "0", "]", "[", "-", "1", "]", "+", "1", ",", "self", ".", "num_iter", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "num_iter", ")", ":", "\n", "            ", "x_thalf", "=", "x", "-", "self", ".", "gradR", "[", "i", "%", "self", ".", "num_iter", "]", "(", "x", ")", "\n", "x", "=", "self", ".", "gradD", "[", "i", "%", "self", ".", "num_iter", "]", "(", "x_thalf", ",", "y", ",", "smaps", ",", "mask", ")", "\n", "x_all", ".", "append", "(", "x", ")", "\n", "x_half_all", ".", "append", "(", "x_thalf", ")", "\n", "\n", "", "return", "x_all", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.forward_save_space": [[222, 252], ["range", "min", "torch.cuda.empty_cache", "torch.backends.cuda.cufft_plan_cache.clear", "numpy.where"], "methods", ["None"], ["", "def", "forward_save_space", "(", "self", ",", "x", ",", "y", ",", "smaps", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        x: Input data.\n        y: Subsampled k-space data.\n        smaps: Coil sensitivity maps.\n        mask: Sampling mask.\n\n        Returns\n        -------\n        Output data.\n        \"\"\"", "\n", "if", "self", ".", "shared_params", ":", "\n", "            ", "num_iter", "=", "self", ".", "num_iter_total", "\n", "", "else", ":", "\n", "            ", "num_iter", "=", "min", "(", "np", ".", "where", "(", "self", ".", "is_trainable", ")", "[", "0", "]", "[", "-", "1", "]", "+", "1", ",", "self", ".", "num_iter", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "num_iter", ")", ":", "\n", "            ", "x_thalf", "=", "x", "-", "self", ".", "gradR", "[", "i", "%", "self", ".", "num_iter", "]", "(", "x", ")", "\n", "x", "=", "self", ".", "gradD", "[", "i", "%", "self", ".", "num_iter", "]", "(", "x_thalf", ",", "y", ",", "smaps", ",", "mask", ")", "\n", "\n", "# would run out of memory at test time", "\n", "# if this is False for some cases", "\n", "if", "self", ".", "reset_cache", ":", "\n", "                ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "torch", ".", "backends", ".", "cuda", ".", "cufft_plan_cache", ".", "clear", "(", ")", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.freeze": [[253, 258], ["sensitivity_net.SensitivityNetwork.gradR[].parameters"], "methods", ["None"], ["", "def", "freeze", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"\"\"freeze parameter of cascade i\"\"\"", "\n", "for", "param", "in", "self", ".", "gradR", "[", "i", "]", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "require_grad_", "=", "False", "\n", "", "self", ".", "is_trainable", "[", "i", "]", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.unfreeze": [[259, 264], ["sensitivity_net.SensitivityNetwork.gradR[].parameters"], "methods", ["None"], ["", "def", "unfreeze", "(", "self", ",", "i", ")", ":", "\n", "        ", "\"\"\"freeze parameter of cascade i\"\"\"", "\n", "for", "param", "in", "self", ".", "gradR", "[", "i", "]", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "require_grad_", "=", "True", "\n", "", "self", ".", "is_trainable", "[", "i", "]", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.freeze_all": [[265, 269], ["range", "sensitivity_net.SensitivityNetwork.freeze"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.freeze"], ["", "def", "freeze_all", "(", "self", ")", ":", "\n", "        ", "\"\"\"freeze parameter of cascade i\"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "num_iter", ")", ":", "\n", "            ", "self", ".", "freeze", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.unfreeze_all": [[270, 274], ["range", "sensitivity_net.SensitivityNetwork.unfreeze"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.unfreeze"], ["", "", "def", "unfreeze_all", "(", "self", ")", ":", "\n", "        ", "\"\"\"freeze parameter of cascade i\"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "num_iter", ")", ":", "\n", "            ", "self", ".", "unfreeze", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.copy_params": [[275, 282], ["sensitivity_net.SensitivityNetwork.gradR[].parameters", "sensitivity_net.SensitivityNetwork.gradR[].parameters", "zip", "trg_param.data.copy_"], "methods", ["None"], ["", "", "def", "copy_params", "(", "self", ",", "src_i", ",", "trg_j", ")", ":", "\n", "        ", "\"\"\"copy i-th cascade net parameters to j-th cascade net parameters\"\"\"", "\n", "src_params", "=", "self", ".", "gradR", "[", "src_i", "]", ".", "parameters", "(", ")", "\n", "trg_params", "=", "self", ".", "gradR", "[", "trg_j", "]", ".", "parameters", "(", ")", "\n", "\n", "for", "trg_param", ",", "src_param", "in", "zip", "(", "trg_params", ",", "src_params", ")", ":", "\n", "            ", "trg_param", ".", "data", ".", "copy_", "(", "src_param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.stage_training_init": [[283, 288], ["sensitivity_net.SensitivityNetwork.freeze_all", "sensitivity_net.SensitivityNetwork.unfreeze", "print"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.freeze_all", "home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.unfreeze"], ["", "", "def", "stage_training_init", "(", "self", ")", ":", "\n", "        ", "\"\"\"set stage training flag to True\"\"\"", "\n", "self", ".", "freeze_all", "(", ")", "\n", "self", ".", "unfreeze", "(", "0", ")", "\n", "print", "(", "self", ".", "is_trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.stage_training_transition_i": [[289, 310], ["numpy.all", "range", "sensitivity_net.SensitivityNetwork.unfreeze_all", "sensitivity_net.SensitivityNetwork.freeze", "sensitivity_net.SensitivityNetwork.unfreeze", "sensitivity_net.SensitivityNetwork.copy_params"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.unfreeze_all", "home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.freeze", "home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.unfreeze", "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.SensitivityNetwork.copy_params"], ["", "def", "stage_training_transition_i", "(", "self", ",", "copy", "=", "False", ")", ":", "\n", "        ", "\"\"\"set stage training flag to True\"\"\"", "\n", "if", "self", ".", "shared_params", ":", "\n", "            ", "return", "\n", "\n", "# if all unlocked, don't do anything", "\n", "", "if", "not", "np", ".", "all", "(", "self", ".", "is_trainable", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "num_iter", ")", ":", "\n", "\n", "# if last cascade is reached, unlock all", "\n", "                ", "if", "i", "==", "self", ".", "num_iter", "-", "1", ":", "\n", "                    ", "self", ".", "unfreeze_all", "(", ")", "\n", "break", "\n", "\n", "# freeze current i, unlock next. copy parameter if specified", "\n", "", "if", "self", ".", "is_trainable", "[", "i", "]", ":", "\n", "                    ", "self", ".", "freeze", "(", "i", ")", "\n", "self", ".", "unfreeze", "(", "i", "+", "1", ")", "\n", "if", "copy", ":", "\n", "                        ", "self", ".", "copy_params", "(", "i", ",", "i", "+", "1", ")", "\n", "", "break", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.sigmanet.sensitivity_net.matrix_invert": [[10, 14], ["yy.div", "xx.div", "xy.div", "yx.div"], "function", ["None"], ["def", "matrix_invert", "(", "xx", ",", "xy", ",", "yx", ",", "yy", ")", ":", "\n", "    ", "\"\"\"Invert a 2x2 matrix.\"\"\"", "\n", "det", "=", "xx", "*", "yy", "-", "xy", "*", "yx", "\n", "return", "yy", ".", "div", "(", "det", ")", ",", "-", "xy", ".", "div", "(", "det", ")", ",", "-", "yx", ".", "div", "(", "det", ")", ",", "xx", ".", "div", "(", "det", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.__init__": [[19, 53], ["super().__init__", "unet_block.Unet"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "chans", ":", "int", ",", "\n", "num_pools", ":", "int", ",", "\n", "in_chans", ":", "int", "=", "2", ",", "\n", "out_chans", ":", "int", "=", "2", ",", "\n", "drop_prob", ":", "float", "=", "0.0", ",", "\n", "padding_size", ":", "int", "=", "15", ",", "\n", "normalize", ":", "bool", "=", "True", ",", "\n", "norm_groups", ":", "int", "=", "2", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        chans : Number of output channels of the first convolution layer.\n        num_pools : Number of down-sampling and up-sampling layers.\n        in_chans : Number of channels in the input to the U-Net model.\n        out_chans : Number of channels in the output to the U-Net model.\n        drop_prob : Dropout probability.\n        padding_size: Size of the padding.\n        normalize: Whether to normalize the input.\n        norm_groups: Number of groups to use for group normalization.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "unet", "=", "Unet", "(", "\n", "in_chans", "=", "in_chans", ",", "out_chans", "=", "out_chans", ",", "chans", "=", "chans", ",", "num_pool_layers", "=", "num_pools", ",", "drop_prob", "=", "drop_prob", "\n", ")", "\n", "\n", "self", ".", "padding_size", "=", "padding_size", "\n", "self", ".", "normalize", "=", "normalize", "\n", "\n", "self", ".", "norm_groups", "=", "norm_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.complex_to_chan_dim": [[54, 61], ["x.permute().reshape", "x.permute"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "complex_to_chan_dim", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Convert the last dimension of the input to complex.\"\"\"", "\n", "b", ",", "c", ",", "h", ",", "w", ",", "two", "=", "x", ".", "shape", "\n", "if", "two", "!=", "2", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "return", "x", ".", "permute", "(", "0", ",", "4", ",", "1", ",", "2", ",", "3", ")", ".", "reshape", "(", "b", ",", "2", "*", "c", ",", "h", ",", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.chan_complex_to_last_dim": [[62, 70], ["torch.div", "x.view().permute().contiguous", "x.view().permute", "x.view"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "chan_complex_to_last_dim", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Convert the last dimension of the input to complex.\"\"\"", "\n", "b", ",", "c2", ",", "h", ",", "w", "=", "x", ".", "shape", "\n", "if", "c2", "%", "2", "!=", "0", ":", "\n", "            ", "raise", "AssertionError", "\n", "", "c", "=", "torch", ".", "div", "(", "c2", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", "\n", "return", "x", ".", "view", "(", "b", ",", "2", ",", "c", ",", "h", ",", "w", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "4", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.norm": [[71, 86], ["x.reshape.reshape.reshape", "x.reshape.reshape.mean", "x.reshape.reshape.std", "x.reshape.reshape.reshape"], "methods", ["None"], ["", "def", "norm", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Normalize the input.\"\"\"", "\n", "# group norm", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "x", ".", "shape", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "b", ",", "self", ".", "norm_groups", ",", "-", "1", ")", "\n", "\n", "mean", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "x", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "x", "=", "(", "x", "-", "mean", ")", "/", "std", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n", "return", "x", ",", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.unnorm": [[87, 92], ["x.reshape"], "methods", ["None"], ["", "def", "unnorm", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "mean", ":", "torch", ".", "Tensor", ",", "std", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Unnormalize the input.\"\"\"", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "x", ".", "shape", "\n", "input_data", "=", "x", ".", "reshape", "(", "b", ",", "self", ".", "norm_groups", ",", "-", "1", ")", "\n", "return", "(", "input_data", "*", "std", "+", "mean", ")", ".", "reshape", "(", "b", ",", "c", ",", "h", ",", "w", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.pad": [[93, 107], ["torch.nn.functional.pad", "math.floor", "math.ceil", "math.floor", "math.ceil"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad"], ["", "def", "pad", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "Tuple", "[", "List", "[", "int", "]", ",", "List", "[", "int", "]", ",", "int", ",", "int", "]", "]", ":", "\n", "        ", "\"\"\"Pad the input with zeros to make it square.\"\"\"", "\n", "_", ",", "_", ",", "h", ",", "w", "=", "x", ".", "shape", "\n", "w_mult", "=", "(", "(", "w", "-", "1", ")", "|", "self", ".", "padding_size", ")", "+", "1", "\n", "h_mult", "=", "(", "(", "h", "-", "1", ")", "|", "self", ".", "padding_size", ")", "+", "1", "\n", "w_pad", "=", "[", "math", ".", "floor", "(", "(", "w_mult", "-", "w", ")", "/", "2", ")", ",", "math", ".", "ceil", "(", "(", "w_mult", "-", "w", ")", "/", "2", ")", "]", "\n", "h_pad", "=", "[", "math", ".", "floor", "(", "(", "h_mult", "-", "h", ")", "/", "2", ")", ",", "math", ".", "ceil", "(", "(", "h_mult", "-", "h", ")", "/", "2", ")", "]", "\n", "# TODO: fix this type when PyTorch fixes theirs", "\n", "# the documentation lies - this actually takes a list", "\n", "# https://github.com/pytorch/pytorch/blob/master/torch/nn/functional.py#L3457", "\n", "# https://github.com/pytorch/pytorch/pull/16949", "\n", "x", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "x", ",", "w_pad", "+", "h_pad", ")", "\n", "\n", "return", "x", ",", "(", "h_pad", ",", "w_pad", ",", "h_mult", ",", "w_mult", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.unpad": [[108, 112], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "unpad", "(", "x", ":", "torch", ".", "Tensor", ",", "h_pad", ":", "List", "[", "int", "]", ",", "w_pad", ":", "List", "[", "int", "]", ",", "h_mult", ":", "int", ",", "w_mult", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Unpad the input.\"\"\"", "\n", "return", "x", "[", "...", ",", "h_pad", "[", "0", "]", ":", "h_mult", "-", "h_pad", "[", "1", "]", ",", "w_pad", "[", "0", "]", ":", "w_mult", "-", "w_pad", "[", "1", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.forward": [[113, 137], ["unet_block.NormUnet.pad", "unet_block.NormUnet.unet", "unet_block.NormUnet.unpad", "unet_block.NormUnet.complex_to_chan_dim", "unet_block.NormUnet.norm", "unet_block.NormUnet.unnorm", "unet_block.NormUnet.chan_complex_to_last_dim"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.unpad", "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.complex_to_chan_dim", "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.norm", "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.unnorm", "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.chan_complex_to_last_dim"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Forward pass of the network.\"\"\"", "\n", "iscomplex", "=", "False", "\n", "if", "x", ".", "shape", "[", "-", "1", "]", "==", "2", ":", "\n", "            ", "x", "=", "self", ".", "complex_to_chan_dim", "(", "x", ")", "\n", "iscomplex", "=", "True", "\n", "\n", "", "mean", "=", "1.0", "\n", "std", "=", "1.0", "\n", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "x", ",", "mean", ",", "std", "=", "self", ".", "norm", "(", "x", ")", "\n", "\n", "", "x", ",", "pad_sizes", "=", "self", ".", "pad", "(", "x", ")", "\n", "x", "=", "self", ".", "unet", "(", "x", ")", "\n", "x", "=", "self", ".", "unpad", "(", "x", ",", "*", "pad_sizes", ")", "\n", "\n", "if", "self", ".", "normalize", ":", "\n", "            ", "x", "=", "self", ".", "unnorm", "(", "x", ",", "mean", ",", "std", ")", "\n", "\n", "", "if", "iscomplex", ":", "\n", "            ", "x", "=", "self", ".", "chan_complex_to_last_dim", "(", "x", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.Unet.__init__": [[148, 186], ["super().__init__", "torch.nn.ModuleList", "range", "unet_block.ConvBlock", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "unet_block.Unet.up_transpose_conv.append", "unet_block.Unet.up_conv.append", "unet_block.Unet.down_sample_layers.append", "unet_block.Unet.up_transpose_conv.append", "unet_block.Unet.up_conv.append", "unet_block.TransposeConvBlock", "torch.nn.Sequential", "unet_block.ConvBlock", "unet_block.ConvBlock", "unet_block.TransposeConvBlock", "unet_block.ConvBlock", "unet_block.ConvBlock", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "in_chans", ":", "int", ",", "out_chans", ":", "int", ",", "chans", ":", "int", "=", "32", ",", "num_pool_layers", ":", "int", "=", "4", ",", "drop_prob", ":", "float", "=", "0.0", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        in_chans: Number of channels in the input to the U-Net model.\n        out_chans: Number of channels in the output to the U-Net model.\n        chans: Number of output channels of the first convolution layer.\n        num_pool_layers: Number of down-sampling and up-sampling layers.\n        drop_prob: Dropout probability.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_chans", "=", "in_chans", "\n", "self", ".", "out_chans", "=", "out_chans", "\n", "self", ".", "chans", "=", "chans", "\n", "self", ".", "num_pool_layers", "=", "num_pool_layers", "\n", "self", ".", "drop_prob", "=", "drop_prob", "\n", "\n", "self", ".", "down_sample_layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "ConvBlock", "(", "in_chans", ",", "chans", ",", "drop_prob", ")", "]", ")", "\n", "ch", "=", "chans", "\n", "for", "_", "in", "range", "(", "num_pool_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "down_sample_layers", ".", "append", "(", "ConvBlock", "(", "ch", ",", "ch", "*", "2", ",", "drop_prob", ")", ")", "\n", "ch", "*=", "2", "\n", "", "self", ".", "conv", "=", "ConvBlock", "(", "ch", ",", "ch", "*", "2", ",", "drop_prob", ")", "\n", "\n", "self", ".", "up_conv", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "up_transpose_conv", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "num_pool_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "up_transpose_conv", ".", "append", "(", "TransposeConvBlock", "(", "ch", "*", "2", ",", "ch", ")", ")", "\n", "self", ".", "up_conv", ".", "append", "(", "ConvBlock", "(", "ch", "*", "2", ",", "ch", ",", "drop_prob", ")", ")", "\n", "ch", "//=", "2", "\n", "\n", "", "self", ".", "up_transpose_conv", ".", "append", "(", "TransposeConvBlock", "(", "ch", "*", "2", ",", "ch", ")", ")", "\n", "self", ".", "up_conv", ".", "append", "(", "\n", "torch", ".", "nn", ".", "Sequential", "(", "\n", "ConvBlock", "(", "ch", "*", "2", ",", "ch", ",", "drop_prob", ")", ",", "torch", ".", "nn", ".", "Conv2d", "(", "ch", ",", "self", ".", "out_chans", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.Unet.forward": [[189, 228], ["unet_block.Unet.conv", "zip", "layer", "stack.append", "torch.nn.functional.avg_pool2d", "stack.pop", "transpose_conv", "torch.cat", "conv", "torch.sum", "torch.nn.functional.pad", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad"], ["", "def", "forward", "(", "self", ",", "image", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        image: Input 4D tensor of shape `(N, in_chans, H, W)`.\n\n        Returns\n        -------\n        Output tensor of shape `(N, out_chans, H, W)`.\n        \"\"\"", "\n", "stack", "=", "[", "]", "\n", "output", "=", "image", "\n", "\n", "# apply down-sampling layers", "\n", "for", "layer", "in", "self", ".", "down_sample_layers", ":", "\n", "            ", "output", "=", "layer", "(", "output", ")", "\n", "stack", ".", "append", "(", "output", ")", "\n", "output", "=", "torch", ".", "nn", ".", "functional", ".", "avg_pool2d", "(", "output", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "", "output", "=", "self", ".", "conv", "(", "output", ")", "\n", "\n", "# apply up-sampling layers", "\n", "for", "transpose_conv", ",", "conv", "in", "zip", "(", "self", ".", "up_transpose_conv", ",", "self", ".", "up_conv", ")", ":", "\n", "            ", "downsample_layer", "=", "stack", ".", "pop", "(", ")", "\n", "output", "=", "transpose_conv", "(", "output", ")", "\n", "\n", "# reflect pad on the right/bottom if needed to handle odd input dimensions", "\n", "padding", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "if", "output", ".", "shape", "[", "-", "1", "]", "!=", "downsample_layer", ".", "shape", "[", "-", "1", "]", ":", "\n", "                ", "padding", "[", "1", "]", "=", "1", "# padding right", "\n", "", "if", "output", ".", "shape", "[", "-", "2", "]", "!=", "downsample_layer", ".", "shape", "[", "-", "2", "]", ":", "\n", "                ", "padding", "[", "3", "]", "=", "1", "# padding bottom", "\n", "", "if", "torch", ".", "sum", "(", "torch", ".", "tensor", "(", "padding", ")", ")", "!=", "0", ":", "\n", "                ", "output", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "output", ",", "padding", ",", "\"reflect\"", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "downsample_layer", "]", ",", "dim", "=", "1", ")", "\n", "output", "=", "conv", "(", "output", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.ConvBlock.__init__": [[236, 259], ["super().__init__", "torch.nn.Sequential", "torch.nn.Conv2d", "torch.nn.InstanceNorm2d", "torch.nn.LeakyReLU", "torch.nn.Dropout2d", "torch.nn.Conv2d", "torch.nn.InstanceNorm2d", "torch.nn.LeakyReLU", "torch.nn.Dropout2d"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "in_chans", ":", "int", ",", "out_chans", ":", "int", ",", "drop_prob", ":", "float", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        in_chans: Number of channels in the input.\n        out_chans: Number of channels in the output.\n        drop_prob: Dropout probability.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_chans", "=", "in_chans", "\n", "self", ".", "out_chans", "=", "out_chans", "\n", "self", ".", "drop_prob", "=", "drop_prob", "\n", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Conv2d", "(", "in_chans", ",", "out_chans", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "torch", ".", "nn", ".", "InstanceNorm2d", "(", "out_chans", ")", ",", "\n", "torch", ".", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Dropout2d", "(", "drop_prob", ")", ",", "\n", "torch", ".", "nn", ".", "Conv2d", "(", "out_chans", ",", "out_chans", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "torch", ".", "nn", ".", "InstanceNorm2d", "(", "out_chans", ")", ",", "\n", "torch", ".", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "torch", ".", "nn", ".", "Dropout2d", "(", "drop_prob", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.ConvBlock.forward": [[261, 272], ["unet_block.ConvBlock.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        image: Input 4D tensor of shape `(N, in_chans, H, W)`.\n\n        Returns\n        -------\n        Output tensor of shape `(N, out_chans, H, W)`.\n        \"\"\"", "\n", "return", "self", ".", "layers", "(", "image", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.TransposeConvBlock.__init__": [[280, 296], ["super().__init__", "torch.nn.Sequential", "torch.nn.ConvTranspose2d", "torch.nn.InstanceNorm2d", "torch.nn.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "in_chans", ":", "int", ",", "out_chans", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        in_chans: Number of channels in the input.\n        out_chans: Number of channels in the output.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_chans", "=", "in_chans", "\n", "self", ".", "out_chans", "=", "out_chans", "\n", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "ConvTranspose2d", "(", "in_chans", ",", "out_chans", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "bias", "=", "False", ")", ",", "\n", "torch", ".", "nn", ".", "InstanceNorm2d", "(", "out_chans", ")", ",", "\n", "torch", ".", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.TransposeConvBlock.forward": [[298, 309], ["unet_block.TransposeConvBlock.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "image", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        image: Input 4D tensor of shape `(N, in_chans, H, W)`.\n\n        Returns\n        -------\n        Output tensor of shape `(N, out_chans, H*2, W*2)`.\n        \"\"\"", "\n", "return", "self", ".", "layers", "(", "image", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.recurrentvarnet.conv2gru.Conv2dGRU.__init__": [[17, 111], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "range", "block.append", "conv2gru.Conv2dGRU.conv_blocks.append", "zip", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block.append", "gru_part.append", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.orthogonal_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "block.append", "block.append", "block.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "min", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "hidden_channels", ":", "int", ",", "\n", "out_channels", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "num_layers", ":", "int", "=", "2", ",", "\n", "gru_kernel_size", "=", "1", ",", "\n", "orthogonal_initialization", ":", "bool", "=", "True", ",", "\n", "instance_norm", ":", "bool", "=", "False", ",", "\n", "dense_connect", ":", "int", "=", "0", ",", "\n", "replication_padding", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Inits Conv2dGRU.\n\n        Parameters\n        ----------\n        in_channels: Number of input channels.\n            int\n        hidden_channels: Number of hidden channels.\n            int\n        out_channels: Number of output channels. If None, same as in_channels.\n            int (optional), Default: None.\n        num_layers: Number of layers.\n            int, Default: 2.\n        gru_kernel_size: Size of the GRU kernel.\n            int, Default: 1.\n        orthogonal_initialization: Orthogonal initialization is used if set to True.\n            bool, Default: True.\n        instance_norm: Instance norm is used if set to True.\n            bool, Default: False.\n        dense_connect: Number of dense connections.\n        replication_padding: If set to true replication padding is applied.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "out_channels", "is", "None", ":", "\n", "            ", "out_channels", "=", "in_channels", "\n", "\n", "", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "hidden_channels", "=", "hidden_channels", "\n", "self", ".", "dense_connect", "=", "dense_connect", "\n", "\n", "self", ".", "reset_gates", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "update_gates", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "out_gates", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "self", ".", "conv_blocks", "=", "nn", ".", "ModuleList", "(", "[", "]", ")", "\n", "\n", "# Create convolutional blocks", "\n", "for", "idx", "in", "range", "(", "num_layers", "+", "1", ")", ":", "\n", "            ", "in_ch", "=", "in_channels", "if", "idx", "==", "0", "else", "(", "1", "+", "min", "(", "idx", ",", "dense_connect", ")", ")", "*", "hidden_channels", "\n", "out_ch", "=", "hidden_channels", "if", "idx", "<", "num_layers", "else", "out_channels", "\n", "padding", "=", "0", "if", "replication_padding", "else", "(", "2", "if", "idx", "==", "0", "else", "1", ")", "\n", "block", "=", "[", "]", "\n", "if", "replication_padding", ":", "\n", "                ", "if", "idx", "==", "1", ":", "\n", "                    ", "block", ".", "append", "(", "nn", ".", "ReplicationPad2d", "(", "2", ")", ")", "\n", "", "else", ":", "\n", "                    ", "block", ".", "append", "(", "nn", ".", "ReplicationPad2d", "(", "2", "if", "idx", "==", "0", "else", "1", ")", ")", "\n", "", "", "block", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "in_ch", ",", "\n", "out_channels", "=", "out_ch", ",", "\n", "kernel_size", "=", "5", "if", "idx", "==", "0", "else", "3", ",", "\n", "dilation", "=", "(", "2", "if", "idx", "==", "1", "else", "1", ")", ",", "\n", "padding", "=", "padding", ",", "\n", ")", "\n", ")", "\n", "self", ".", "conv_blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block", ")", ")", "\n", "\n", "# Create GRU blocks", "\n", "", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "for", "gru_part", "in", "[", "self", ".", "reset_gates", ",", "self", ".", "update_gates", ",", "self", ".", "out_gates", "]", ":", "\n", "                ", "block", "=", "[", "]", "\n", "if", "instance_norm", ":", "\n", "                    ", "block", ".", "append", "(", "nn", ".", "InstanceNorm2d", "(", "2", "*", "hidden_channels", ")", ")", "\n", "", "block", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "2", "*", "hidden_channels", ",", "\n", "out_channels", "=", "hidden_channels", ",", "\n", "kernel_size", "=", "gru_kernel_size", ",", "\n", "padding", "=", "gru_kernel_size", "//", "2", ",", "\n", ")", "\n", ")", "\n", "gru_part", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block", ")", ")", "\n", "\n", "", "", "if", "orthogonal_initialization", ":", "\n", "            ", "for", "reset_gate", ",", "update_gate", ",", "out_gate", "in", "zip", "(", "self", ".", "reset_gates", ",", "self", ".", "update_gates", ",", "self", ".", "out_gates", ")", ":", "\n", "                ", "nn", ".", "init", ".", "orthogonal_", "(", "reset_gate", "[", "-", "1", "]", ".", "weight", ")", "\n", "nn", ".", "init", ".", "orthogonal_", "(", "update_gate", "[", "-", "1", "]", ".", "weight", ")", "\n", "nn", ".", "init", ".", "orthogonal_", "(", "out_gate", "[", "-", "1", "]", ".", "weight", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "reset_gate", "[", "-", "1", "]", ".", "bias", ",", "-", "1.0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "update_gate", "[", "-", "1", "]", ".", "bias", ",", "0.0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "out_gate", "[", "-", "1", "]", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.recurrentvarnet.conv2gru.Conv2dGRU.forward": [[112, 164], ["range", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "new_states.append", "torch.relu", "torch.relu", "torch.relu", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.relu.size", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "conv_skip.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu.size", "torch.relu.size", "list", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "", "", "def", "forward", "(", "\n", "self", ",", "\n", "cell_input", ":", "torch", ".", "Tensor", ",", "\n", "previous_state", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Computes Conv2dGRU forward pass given tensors `cell_input` and `previous_state`.\n\n        Parameters\n        ----------\n        cell_input: Reconstruction input\n        previous_state: Tensor of previous states.\n\n        Returns\n        -------\n        Output and new states.\n        \"\"\"", "\n", "new_states", ":", "List", "[", "torch", ".", "Tensor", "]", "=", "[", "]", "\n", "conv_skip", ":", "List", "[", "torch", ".", "Tensor", "]", "=", "[", "]", "\n", "\n", "if", "previous_state", "is", "None", ":", "\n", "            ", "batch_size", ",", "spatial_size", "=", "cell_input", ".", "size", "(", "0", ")", ",", "(", "cell_input", ".", "size", "(", "2", ")", ",", "cell_input", ".", "size", "(", "3", ")", ")", "\n", "state_size", "=", "[", "batch_size", ",", "self", ".", "hidden_channels", "]", "+", "list", "(", "spatial_size", ")", "+", "[", "self", ".", "num_layers", "]", "\n", "previous_state", "=", "torch", ".", "zeros", "(", "*", "state_size", ",", "dtype", "=", "cell_input", ".", "dtype", ")", ".", "to", "(", "cell_input", ".", "device", ")", "\n", "\n", "", "for", "idx", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "if", "conv_skip", ":", "\n", "                ", "cell_input", "=", "F", ".", "relu", "(", "\n", "self", ".", "conv_blocks", "[", "idx", "]", "(", "torch", ".", "cat", "(", "[", "*", "conv_skip", "[", "-", "self", ".", "dense_connect", ":", "]", ",", "cell_input", "]", ",", "dim", "=", "1", ")", ")", ",", "\n", "inplace", "=", "True", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "cell_input", "=", "F", ".", "relu", "(", "self", ".", "conv_blocks", "[", "idx", "]", "(", "cell_input", ")", ",", "inplace", "=", "True", ")", "\n", "", "if", "self", ".", "dense_connect", ">", "0", ":", "\n", "                ", "conv_skip", ".", "append", "(", "cell_input", ")", "\n", "\n", "", "stacked_inputs", "=", "torch", ".", "cat", "(", "[", "cell_input", ",", "previous_state", "[", ":", ",", ":", ",", ":", ",", ":", ",", "idx", "]", "]", ",", "dim", "=", "1", ")", "\n", "\n", "update", "=", "torch", ".", "sigmoid", "(", "self", ".", "update_gates", "[", "idx", "]", "(", "stacked_inputs", ")", ")", "\n", "reset", "=", "torch", ".", "sigmoid", "(", "self", ".", "reset_gates", "[", "idx", "]", "(", "stacked_inputs", ")", ")", "\n", "delta", "=", "torch", ".", "tanh", "(", "\n", "self", ".", "out_gates", "[", "idx", "]", "(", "torch", ".", "cat", "(", "[", "cell_input", ",", "previous_state", "[", ":", ",", ":", ",", ":", ",", ":", ",", "idx", "]", "*", "reset", "]", ",", "dim", "=", "1", ")", ")", "\n", ")", "\n", "cell_input", "=", "previous_state", "[", ":", ",", ":", ",", ":", ",", ":", ",", "idx", "]", "*", "(", "1", "-", "update", ")", "+", "delta", "*", "update", "\n", "new_states", ".", "append", "(", "cell_input", ")", "\n", "cell_input", "=", "F", ".", "relu", "(", "cell_input", ",", "inplace", "=", "False", ")", "\n", "", "if", "conv_skip", ":", "\n", "            ", "out", "=", "self", ".", "conv_blocks", "[", "self", ".", "num_layers", "]", "(", "torch", ".", "cat", "(", "[", "*", "conv_skip", "[", "-", "self", ".", "dense_connect", ":", "]", ",", "cell_input", "]", ",", "dim", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "conv_blocks", "[", "self", ".", "num_layers", "]", "(", "cell_input", ")", "\n", "\n", "", "return", "out", ",", "torch", ".", "stack", "(", "new_states", ",", "dim", "=", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.recurrentvarnet.recurentvarnet.RecurrentInit.__init__": [[36, 82], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "zip", "numpy.sum", "range", "recurentvarnet.RecurrentInit.conv_blocks.append", "recurentvarnet.RecurrentInit.out_blocks.append", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.ReplicationPad2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "channels", ":", "Tuple", "[", "int", ",", "...", "]", ",", "\n", "dilations", ":", "Tuple", "[", "int", ",", "...", "]", ",", "\n", "depth", ":", "int", "=", "2", ",", "\n", "multiscale_depth", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Inits RecurrentInit.\n\n        Parameters\n        ----------\n        in_channels: Input channels.\n            int\n        out_channels: Number of hidden channels of the recurrent unit of RecurrentVarNet Block.\n            int\n        channels: Channels :math:`n_d` in the convolutional layers of initializer.\n            Tuple[int, ...]\n        dilations: Dilations :math:`p` of the convolutional layers of the initializer.\n            Tuple[int, ...]\n        depth: RecurrentVarNet Block number of layers :math:`n_l`.\n            int\n        multiscale_depth: Number of feature layers to aggregate for the output, if 1, multi-scale context aggregation\n        is disabled.\n            int\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "out_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "multiscale_depth", "=", "multiscale_depth", "\n", "tch", "=", "in_channels", "\n", "for", "(", "curr_channels", ",", "curr_dilations", ")", "in", "zip", "(", "channels", ",", "dilations", ")", ":", "\n", "            ", "block", "=", "[", "\n", "nn", ".", "ReplicationPad2d", "(", "curr_dilations", ")", ",", "\n", "nn", ".", "Conv2d", "(", "tch", ",", "curr_channels", ",", "3", ",", "padding", "=", "0", ",", "dilation", "=", "curr_dilations", ")", ",", "\n", "]", "\n", "tch", "=", "curr_channels", "\n", "self", ".", "conv_blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block", ")", ")", "\n", "", "tch", "=", "np", ".", "sum", "(", "channels", "[", "-", "multiscale_depth", ":", "]", ")", "\n", "for", "_", "in", "range", "(", "depth", ")", ":", "\n", "            ", "block", "=", "[", "nn", ".", "Conv2d", "(", "tch", ",", "out_channels", ",", "1", ",", "padding", "=", "0", ")", "]", "\n", "self", ".", "out_blocks", ".", "append", "(", "nn", ".", "Sequential", "(", "*", "block", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.recurrentvarnet.recurentvarnet.RecurrentInit.forward": [[83, 107], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.relu", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "output_list.append", "block", "features.append", "block"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes initialization for recurrent unit given input `x`.\n\n        Parameters\n        ----------\n        x: Initialization for RecurrentInit.\n\n        Returns\n        -------\n        Initial recurrent hidden state from input `x`.\n        \"\"\"", "\n", "features", "=", "[", "]", "\n", "for", "block", "in", "self", ".", "conv_blocks", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "block", "(", "x", ")", ",", "inplace", "=", "True", ")", "\n", "if", "self", ".", "multiscale_depth", ">", "1", ":", "\n", "                ", "features", ".", "append", "(", "x", ")", "\n", "", "", "if", "self", ".", "multiscale_depth", ">", "1", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "features", "[", "-", "self", ".", "multiscale_depth", ":", "]", ",", "dim", "=", "1", ")", "\n", "", "output_list", "=", "[", "]", "\n", "for", "block", "in", "self", ".", "out_blocks", ":", "\n", "            ", "y", "=", "F", ".", "relu", "(", "block", "(", "x", ")", ",", "inplace", "=", "True", ")", "\n", "output_list", ".", "append", "(", "y", ")", "\n", "", "return", "torch", ".", "stack", "(", "output_list", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.recurrentvarnet.recurentvarnet.RecurrentVarNetBlock.__init__": [[125, 167], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "mridc.collections.reconstruction.models.recurrentvarnet.conv2gru.Conv2dGRU", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", "=", "2", ",", "\n", "hidden_channels", ":", "int", "=", "64", ",", "\n", "num_layers", ":", "int", "=", "4", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Inits RecurrentVarNetBlock.\n\n        Parameters\n        ----------\n        in_channels: Input channel number.\n            int, Default is 2 for complex data.\n        hidden_channels: Hidden channels.\n            int, Default: 64.\n        num_layers: Number of layers of :math:`n_l` recurrent unit.\n            int, Default: 4.\n        fft_centered: Whether to center the FFT.\n            bool, Default: True.\n        fft_normalization: Whether to normalize the FFT.\n            str, Default: \"ortho\".\n        spatial_dims: Spatial dimensions of the input.\n            Tuple[int, int], Default: None.\n        coil_dim: Number of coils.\n            int, Default: 1.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "\n", "self", ".", "learning_rate", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "[", "1.0", "]", ")", ")", "# :math:`\\alpha_t`", "\n", "self", ".", "regularizer", "=", "Conv2dGRU", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "hidden_channels", "=", "hidden_channels", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "replication_padding", "=", "True", ",", "\n", ")", "# Recurrent Unit of RecurrentVarNet Block :math:`\\mathcal{H}_{\\theta_t}`", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.recurrentvarnet.recurentvarnet.RecurrentVarNetBlock.forward": [[169, 241], ["torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "recurentvarnet.RecurrentVarNetBlock.regularizer", "torch.cat.permute", "torch.cat.permute", "torch.cat.permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mridc.collections.common.parts.fft.fft2", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "mridc.collections.common.parts.utils.complex_mul", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "mridc.collections.common.parts.utils.complex_mul().sum", "image.unsqueeze", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "current_kspace", ":", "torch", ".", "Tensor", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sampling_mask", ":", "torch", ".", "Tensor", ",", "\n", "sensitivity_map", ":", "torch", ".", "Tensor", ",", "\n", "hidden_state", ":", "Union", "[", "None", ",", "torch", ".", "Tensor", "]", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Computes forward pass of RecurrentVarNetBlock.\n\n        Parameters\n        ----------\n        current_kspace: Current k-space prediction.\n            torch.Tensor, shape [batch_size, n_coil, height, width, 2]\n        masked_kspace: Subsampled k-space.\n            torch.Tensor, shape [batch_size, n_coil, height, width, 2]\n        sampling_mask: Sampling mask.\n            torch.Tensor, shape [batch_size, 1, height, width, 1]\n        sensitivity_map: Coil sensitivities.\n            torch.Tensor, shape [batch_size, n_coil, height, width, 2]\n        hidden_state: ConvGRU hidden state.\n            None or torch.Tensor, shape [batch_size, n_l, height, width, hidden_channels]\n\n        Returns\n        -------\n        new_kspace: New k-space prediction.\n            torch.Tensor, shape [batch_size, n_coil, height, width, 2]\n        hidden_state: Next hidden state.\n            list of torch.Tensor, shape [batch_size, hidden_channels, height, width, num_layers]\n        \"\"\"", "\n", "kspace_error", "=", "torch", ".", "where", "(", "\n", "sampling_mask", "==", "0", ",", "\n", "torch", ".", "tensor", "(", "[", "0.0", "]", ",", "dtype", "=", "masked_kspace", ".", "dtype", ")", ".", "to", "(", "masked_kspace", ".", "device", ")", ",", "\n", "current_kspace", "-", "masked_kspace", ",", "\n", ")", "\n", "\n", "recurrent_term", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "complex_mul", "(", "\n", "ifft2", "(", "\n", "kspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "complex_conj", "(", "sensitivity_map", ")", ",", "\n", ")", ".", "sum", "(", "self", ".", "coil_dim", ")", "\n", "for", "kspace", "in", "torch", ".", "split", "(", "current_kspace", ",", "2", ",", "-", "1", ")", "\n", "]", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "\n", "recurrent_term", ",", "hidden_state", "=", "self", ".", "regularizer", "(", "recurrent_term", ",", "hidden_state", ")", "# :math:`w_t`, :math:`h_{t+1}`", "\n", "recurrent_term", "=", "recurrent_term", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "recurrent_term", "=", "torch", ".", "cat", "(", "\n", "[", "\n", "fft2", "(", "\n", "complex_mul", "(", "image", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ",", "sensitivity_map", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "for", "image", "in", "torch", ".", "split", "(", "recurrent_term", ",", "2", ",", "-", "1", ")", "\n", "]", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", "\n", "\n", "new_kspace", "=", "current_kspace", "-", "self", ".", "learning_rate", "*", "kspace_error", "+", "recurrent_term", "\n", "\n", "return", "new_kspace", ",", "hidden_state", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.mwcnn.mwcnn.DWT.__init__": [[29, 33], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Inits DWT.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.mwcnn.mwcnn.DWT.forward": [[34, 59], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "forward", "(", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes DWT(`x`) given tensor `x`.\n\n        Parameters\n        ----------\n        x: Input tensor.\n\n        Returns\n        -------\n        DWT of `x`.\n        \"\"\"", "\n", "x01", "=", "x", "[", ":", ",", ":", ",", "0", ":", ":", "2", ",", ":", "]", "/", "2", "\n", "x02", "=", "x", "[", ":", ",", ":", ",", "1", ":", ":", "2", ",", ":", "]", "/", "2", "\n", "x1", "=", "x01", "[", ":", ",", ":", ",", ":", ",", "0", ":", ":", "2", "]", "\n", "x2", "=", "x02", "[", ":", ",", ":", ",", ":", ",", "0", ":", ":", "2", "]", "\n", "x3", "=", "x01", "[", ":", ",", ":", ",", ":", ",", "1", ":", ":", "2", "]", "\n", "x4", "=", "x02", "[", ":", ",", ":", ",", ":", ",", "1", ":", ":", "2", "]", "\n", "x_LL", "=", "x1", "+", "x2", "+", "x3", "+", "x4", "\n", "x_HL", "=", "-", "x1", "-", "x2", "+", "x3", "+", "x4", "\n", "x_LH", "=", "-", "x1", "+", "x2", "-", "x3", "+", "x4", "\n", "x_HH", "=", "x1", "-", "x2", "-", "x3", "+", "x4", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "x_LL", ",", "x_HL", ",", "x_LH", ",", "x_HH", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.mwcnn.mwcnn.IWT.__init__": [[75, 80], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Inits IWT.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "requires_grad", "=", "False", "\n", "self", ".", "_r", "=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.mwcnn.mwcnn.IWT.forward": [[81, 109], ["x.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes IWT(`x`) given tensor `x`.\n\n        Parameters\n        ----------\n        x: Input tensor.\n\n        Returns\n        -------\n        IWT of `x`.\n        \"\"\"", "\n", "batch", ",", "in_channel", ",", "in_height", ",", "in_width", "=", "x", ".", "size", "(", ")", "\n", "out_channel", ",", "out_height", ",", "out_width", "=", "int", "(", "in_channel", "/", "(", "self", ".", "_r", "**", "2", ")", ")", ",", "self", ".", "_r", "*", "in_height", ",", "self", ".", "_r", "*", "in_width", "\n", "\n", "x1", "=", "x", "[", ":", ",", "0", ":", "out_channel", ",", ":", ",", ":", "]", "/", "2", "\n", "x2", "=", "x", "[", ":", ",", "out_channel", ":", "out_channel", "*", "2", ",", ":", ",", ":", "]", "/", "2", "\n", "x3", "=", "x", "[", ":", ",", "out_channel", "*", "2", ":", "out_channel", "*", "3", ",", ":", ",", ":", "]", "/", "2", "\n", "x4", "=", "x", "[", ":", ",", "out_channel", "*", "3", ":", "out_channel", "*", "4", ",", ":", ",", ":", "]", "/", "2", "\n", "\n", "h", "=", "torch", ".", "zeros", "(", "[", "batch", ",", "out_channel", ",", "out_height", ",", "out_width", "]", ",", "dtype", "=", "x", ".", "dtype", ")", ".", "to", "(", "x", ".", "device", ")", "\n", "\n", "h", "[", ":", ",", ":", ",", "0", ":", ":", "2", ",", "0", ":", ":", "2", "]", "=", "x1", "-", "x2", "-", "x3", "+", "x4", "\n", "h", "[", ":", ",", ":", ",", "1", ":", ":", "2", ",", "0", ":", ":", "2", "]", "=", "x1", "-", "x2", "+", "x3", "-", "x4", "\n", "h", "[", ":", ",", ":", ",", "0", ":", ":", "2", ",", "1", ":", ":", "2", "]", "=", "x1", "+", "x2", "-", "x3", "-", "x4", "\n", "h", "[", ":", ",", ":", ",", "1", ":", ":", "2", ",", "1", ":", ":", "2", "]", "=", "x1", "+", "x2", "+", "x3", "+", "x4", "\n", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.mwcnn.mwcnn.ConvBlock.__init__": [[125, 173], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "net.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "net.append", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "kernel_size", ":", "int", ",", "\n", "bias", ":", "bool", "=", "True", ",", "\n", "batchnorm", ":", "bool", "=", "False", ",", "\n", "activation", ":", "nn", ".", "Module", "=", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "scale", ":", "Optional", "[", "float", "]", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Inits ConvBlock.\n\n        Parameters\n        ----------\n        in_channels: Number of input channels.\n            int\n        out_channels: Number of output channels.\n            int\n        kernel_size: Conv kernel size.\n            int\n        bias: Use convolution bias.\n            bool, Default: True.\n        batchnorm: Use batch normalization.\n            bool, Default: False.\n        activation: Activation function.\n            torch.nn.Module, Default: nn.ReLU(True).\n        scale: Scale factor for convolution.\n            float (optional), Default: 1.0.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "net", "=", "[", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "padding", "=", "kernel_size", "//", "2", ",", "\n", ")", "\n", "]", "\n", "\n", "if", "batchnorm", ":", "\n", "            ", "net", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "num_features", "=", "out_channels", ",", "eps", "=", "1e-4", ",", "momentum", "=", "0.95", ")", ")", "\n", "", "net", ".", "append", "(", "activation", ")", "\n", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "net", ")", "\n", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.mwcnn.mwcnn.ConvBlock.forward": [[174, 187], ["mwcnn.ConvBlock.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Performs forward pass of ConvBlock.\n\n        Parameters\n        ----------\n        x: Input with shape (N, C, H, W).\n\n        Returns\n        -------\n        Output with shape (N, C', H', W').\n        \"\"\"", "\n", "return", "self", ".", "net", "(", "x", ")", "*", "self", ".", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.mwcnn.mwcnn.DilatedConvBlock.__init__": [[203, 269], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "net.append", "net.append", "net.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "net.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "net.append", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "dilations", ":", "Tuple", "[", "int", ",", "int", "]", ",", "\n", "kernel_size", ":", "int", ",", "\n", "out_channels", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "bias", ":", "bool", "=", "True", ",", "\n", "batchnorm", ":", "bool", "=", "False", ",", "\n", "activation", ":", "nn", ".", "Module", "=", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "scale", ":", "Optional", "[", "float", "]", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Inits DilatedConvBlock.\n\n        Parameters\n        ----------\n        in_channels: Number of input channels.\n            int\n        dilations: Number of dilations.\n            Tuple[int, int], Default: (1, 1).\n        kernel_size: Conv kernel size.\n            int\n        out_channels: Number of output channels.\n            int (optional), Default: None.\n        bias: Use convolution bias.\n            bool, Default: True.\n        batchnorm: Use batch normalization.\n            bool, Default: False.\n        activation: Activation function.\n            torch.nn.Module, Default: nn.ReLU(True).\n        scale: Scale factor for convolution.\n            float (optional), Default: 1.0.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "net", "=", "[", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "in_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "dilation", "=", "dilations", "[", "0", "]", ",", "\n", "padding", "=", "kernel_size", "//", "2", "+", "dilations", "[", "0", "]", "-", "1", ",", "\n", ")", "\n", "]", "\n", "\n", "if", "batchnorm", ":", "\n", "            ", "net", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "num_features", "=", "in_channels", ",", "eps", "=", "1e-4", ",", "momentum", "=", "0.95", ")", ")", "\n", "", "net", ".", "append", "(", "activation", ")", "\n", "if", "out_channels", "is", "None", ":", "\n", "            ", "out_channels", "=", "in_channels", "\n", "", "net", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "dilation", "=", "dilations", "[", "1", "]", ",", "\n", "padding", "=", "kernel_size", "//", "2", "+", "dilations", "[", "1", "]", "-", "1", ",", "\n", ")", "\n", ")", "\n", "if", "batchnorm", ":", "\n", "            ", "net", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "num_features", "=", "in_channels", ",", "eps", "=", "1e-4", ",", "momentum", "=", "0.95", ")", ")", "\n", "", "net", ".", "append", "(", "activation", ")", "\n", "\n", "self", ".", "net", "=", "nn", ".", "Sequential", "(", "*", "net", ")", "\n", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.mwcnn.mwcnn.DilatedConvBlock.forward": [[270, 283], ["mwcnn.DilatedConvBlock.net"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Performs forward pass of DilatedConvBlock.\n\n        Parameters\n        ----------\n        x: Input with shape (N, C, H, W).\n\n        Returns\n        -------\n        Output with shape (N, C', H', W').\n        \"\"\"", "\n", "return", "self", ".", "net", "(", "x", ")", "*", "self", ".", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.mwcnn.mwcnn.MWCNN.__init__": [[299, 402], ["torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Module.__init__", "mwcnn.DWT", "mwcnn.IWT", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "mwcnn.MWCNN.down.append", "range", "mwcnn.MWCNN.up.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "collections.OrderedDict", "collections.OrderedDict", "mwcnn.ConvBlock", "mwcnn.DilatedConvBlock", "mwcnn.DilatedConvBlock", "mwcnn.ConvBlock"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_channels", ":", "int", ",", "\n", "first_conv_hidden_channels", ":", "int", ",", "\n", "num_scales", ":", "int", "=", "4", ",", "\n", "bias", ":", "bool", "=", "True", ",", "\n", "batchnorm", ":", "bool", "=", "False", ",", "\n", "activation", ":", "nn", ".", "Module", "=", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Inits MWCNN.\n\n        Parameters\n        ----------\n        input_channels: Input channels dimension.\n            int\n        first_conv_hidden_channels: First convolution output channels dimension.\n            int\n        num_scales: Number of scales.\n            int, Default: 4.\n        bias: Convolution bias. If True, adds a learnable bias to the output.\n            bool, Default: True.\n        batchnorm: If True, a batchnorm layer is added after each convolution.\n            bool, Default: False.\n        activation: Activation function applied after each convolution.\n            torch.nn.Module, Default: nn.ReLU().\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_kernel_size", "=", "3", "\n", "self", ".", "DWT", "=", "DWT", "(", ")", "\n", "self", ".", "IWT", "=", "IWT", "(", ")", "\n", "\n", "self", ".", "down", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "idx", "in", "range", "(", "num_scales", ")", ":", "\n", "            ", "in_channels", "=", "input_channels", "if", "idx", "==", "0", "else", "first_conv_hidden_channels", "*", "2", "**", "(", "idx", "+", "1", ")", "\n", "out_channels", "=", "first_conv_hidden_channels", "*", "2", "**", "idx", "\n", "dilations", "=", "(", "2", ",", "1", ")", "if", "idx", "!=", "num_scales", "-", "1", "else", "(", "2", ",", "3", ")", "\n", "self", ".", "down", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "OrderedDict", "(", "\n", "[", "\n", "(", "\n", "f\"convblock{idx}\"", ",", "\n", "ConvBlock", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "self", ".", "_kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "batchnorm", "=", "batchnorm", ",", "\n", "activation", "=", "activation", ",", "\n", ")", ",", "\n", ")", ",", "\n", "(", "\n", "f\"dilconvblock{idx}\"", ",", "\n", "DilatedConvBlock", "(", "\n", "in_channels", "=", "out_channels", ",", "\n", "dilations", "=", "dilations", ",", "\n", "kernel_size", "=", "self", ".", "_kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "batchnorm", "=", "batchnorm", ",", "\n", "activation", "=", "activation", ",", "\n", ")", ",", "\n", ")", ",", "\n", "]", "\n", ")", "\n", ")", "\n", ")", "\n", "", "self", ".", "up", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "idx", "in", "range", "(", "num_scales", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "in_channels", "=", "first_conv_hidden_channels", "*", "2", "**", "idx", "\n", "out_channels", "=", "input_channels", "if", "idx", "==", "0", "else", "first_conv_hidden_channels", "*", "2", "**", "(", "idx", "+", "1", ")", "\n", "dilations", "=", "(", "2", ",", "1", ")", "if", "idx", "!=", "num_scales", "-", "1", "else", "(", "3", ",", "2", ")", "\n", "self", ".", "up", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "OrderedDict", "(", "\n", "[", "\n", "(", "\n", "f\"invdilconvblock{num_scales - 2 - idx}\"", ",", "\n", "DilatedConvBlock", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "dilations", "=", "dilations", ",", "\n", "kernel_size", "=", "self", ".", "_kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "batchnorm", "=", "batchnorm", ",", "\n", "activation", "=", "activation", ",", "\n", ")", ",", "\n", ")", ",", "\n", "(", "\n", "f\"invconvblock{num_scales - 2 - idx}\"", ",", "\n", "ConvBlock", "(", "\n", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "self", ".", "_kernel_size", ",", "\n", "bias", "=", "bias", ",", "\n", "batchnorm", "=", "batchnorm", ",", "\n", "activation", "=", "activation", ",", "\n", ")", ",", "\n", ")", ",", "\n", "]", "\n", ")", "\n", ")", "\n", ")", "\n", "", "self", ".", "num_scales", "=", "num_scales", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.mwcnn.mwcnn.MWCNN.pad": [[403, 425], ["sum", "torch.pad", "torch.pad", "torch.pad"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad"], ["", "@", "staticmethod", "\n", "def", "pad", "(", "x", ")", ":", "\n", "        ", "\"\"\"\n        Pad the input with zeros.\n\n        Parameters\n        ----------\n        x: Input tensor.\n\n        Returns\n        -------\n        Padded tensor.\n        \"\"\"", "\n", "padding", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "\n", "if", "x", ".", "shape", "[", "-", "2", "]", "%", "2", "!=", "0", ":", "\n", "            ", "padding", "[", "3", "]", "=", "1", "# Padding right - width", "\n", "", "if", "x", ".", "shape", "[", "-", "1", "]", "%", "2", "!=", "0", ":", "\n", "            ", "padding", "[", "1", "]", "=", "1", "# Padding bottom - height", "\n", "", "if", "sum", "(", "padding", ")", "!=", "0", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "padding", ",", "\"reflect\"", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.mwcnn.mwcnn.MWCNN.crop_to_shape": [[426, 447], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "crop_to_shape", "(", "x", ",", "shape", ")", ":", "\n", "        ", "\"\"\"\n        Crop the input to the given shape.\n\n        Parameters\n        ----------\n        x: Input tensor.\n        shape: Tuple of (height, width).\n\n        Returns\n        -------\n        Cropped tensor.\n        \"\"\"", "\n", "h", ",", "w", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "if", "h", ">", "shape", "[", "0", "]", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", "shape", "[", "0", "]", ",", ":", "]", "\n", "", "if", "w", ">", "shape", "[", "1", "]", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", ",", ":", "shape", "[", "1", "]", "]", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.mwcnn.mwcnn.MWCNN.forward": [[448, 486], ["mwcnn.MWCNN.pad", "range", "range", "input_tensor.clone", "mwcnn.MWCNN.pad", "res_values.append", "mwcnn.MWCNN.crop_to_shape", "mwcnn.MWCNN.pad", "res_values.append", "mwcnn.MWCNN.crop_to_shape", "mwcnn.MWCNN.DWT", "mwcnn.MWCNN.IWT", "mwcnn.MWCNN.DWT"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DIDN.crop_to_shape", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DIDN.crop_to_shape"], ["", "def", "forward", "(", "self", ",", "input_tensor", ":", "torch", ".", "Tensor", ",", "res", ":", "bool", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes forward pass of MWCNN.\n\n        Parameters\n        ----------\n        input_tensor: Input tensor.\n            torch.tensor\n        res: If True, residual connection is applied to the output.\n            bool, Default: False.\n\n        Returns\n        -------\n        Output tensor.\n        \"\"\"", "\n", "res_values", "=", "[", "]", "\n", "x", "=", "self", ".", "pad", "(", "input_tensor", ".", "clone", "(", ")", ")", "\n", "for", "idx", "in", "range", "(", "self", ".", "num_scales", ")", ":", "\n", "            ", "if", "idx", "==", "0", ":", "\n", "                ", "x", "=", "self", ".", "pad", "(", "self", ".", "down", "[", "idx", "]", "(", "x", ")", ")", "\n", "res_values", ".", "append", "(", "x", ")", "\n", "", "elif", "idx", "==", "self", ".", "num_scales", "-", "1", ":", "\n", "                ", "x", "=", "self", ".", "down", "[", "idx", "]", "(", "self", ".", "DWT", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "self", ".", "pad", "(", "self", ".", "down", "[", "idx", "]", "(", "self", ".", "DWT", "(", "x", ")", ")", ")", "\n", "res_values", ".", "append", "(", "x", ")", "\n", "\n", "", "", "for", "idx", "in", "range", "(", "self", ".", "num_scales", ")", ":", "\n", "            ", "if", "idx", "!=", "self", ".", "num_scales", "-", "1", ":", "\n", "                ", "x", "=", "(", "\n", "self", ".", "crop_to_shape", "(", "self", ".", "IWT", "(", "self", ".", "up", "[", "idx", "]", "(", "x", ")", ")", ",", "res_values", "[", "self", ".", "num_scales", "-", "2", "-", "idx", "]", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "+", "res_values", "[", "self", ".", "num_scales", "-", "2", "-", "idx", "]", "\n", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "self", ".", "crop_to_shape", "(", "self", ".", "up", "[", "idx", "]", "(", "x", ")", ",", "input_tensor", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "if", "res", ":", "\n", "                    ", "x", "+=", "input_tensor", "\n", "", "", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.Subpixel.__init__": [[27, 44], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PixelShuffle", "torch.PixelShuffle", "torch.PixelShuffle"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "upscale_factor", ",", "kernel_size", ",", "padding", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Inits Subpixel.\n\n        Parameters\n        ----------\n        in_channels: Number of input channels.\n        out_channels: Number of output channels.\n        upscale_factor: Subpixel upscale factor.\n        kernel_size: Convolution kernel size.\n        padding: Padding size. Default: 0.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", "*", "upscale_factor", "**", "2", ",", "kernel_size", "=", "kernel_size", ",", "padding", "=", "padding", "\n", ")", "\n", "self", ".", "pixelshuffle", "=", "nn", ".", "PixelShuffle", "(", "upscale_factor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.Subpixel.forward": [[45, 48], ["didn.Subpixel.pixelshuffle", "didn.Subpixel.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Computes Subpixel convolution on input torch.Tensor ``x``.\"\"\"", "\n", "return", "self", ".", "pixelshuffle", "(", "self", ".", "conv", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.ReconBlock.__init__": [[64, 87], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "didn.ReconBlock.convs.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "range", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "num_convs", ")", ":", "\n", "        ", "\"\"\"\n        Inits ReconBlock.\n\n        Parameters\n        ----------\n        in_channels: Number of input channels.\n        num_convs: Number of convolution blocks.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "convs", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "in_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "]", "\n", ")", "\n", "for", "_", "in", "range", "(", "num_convs", "-", "1", ")", "\n", "]", "\n", ")", "\n", "self", ".", "convs", ".", "append", "(", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "in_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ")", "\n", "self", ".", "num_convs", "=", "num_convs", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.ReconBlock.forward": [[88, 101], ["input_data.clone", "range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_data", ")", ":", "\n", "        ", "\"\"\"\n        Computes num_convs convolutions followed by PReLU activation on `input_data`.\n\n        Parameters\n        ----------\n        input_data: Input tensor.\n        \"\"\"", "\n", "output", "=", "input_data", ".", "clone", "(", ")", "\n", "for", "idx", "in", "range", "(", "self", ".", "num_convs", ")", ":", "\n", "            ", "output", "=", "self", ".", "convs", "[", "idx", "]", "(", "output", ")", "\n", "\n", "", "return", "input_data", "+", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.__init__": [[117, 164], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "didn.Subpixel", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "didn.Subpixel", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Inits DUB.\n\n        Parameters\n        ----------\n        in_channels: Number of input channels.\n        out_channels: Number of output channels.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "\n", "# Scale 1", "\n", "self", ".", "conv1_1", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Conv2d", "(", "in_channels", ",", "in_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "nn", ".", "PReLU", "(", ")", "]", "*", "2", ")", "\n", "self", ".", "down1", "=", "nn", ".", "Conv2d", "(", "in_channels", ",", "in_channels", "*", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "# Scale 2", "\n", "self", ".", "conv2_1", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "nn", ".", "Conv2d", "(", "in_channels", "*", "2", ",", "in_channels", "*", "2", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "nn", ".", "PReLU", "(", ")", "]", "\n", ")", "\n", "self", ".", "down2", "=", "nn", ".", "Conv2d", "(", "in_channels", "*", "2", ",", "in_channels", "*", "4", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "# Scale 3", "\n", "self", ".", "conv3_1", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "nn", ".", "Conv2d", "(", "in_channels", "*", "4", ",", "in_channels", "*", "4", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "]", "\n", ")", "\n", "self", ".", "up1", "=", "nn", ".", "Sequential", "(", "*", "[", "Subpixel", "(", "in_channels", "*", "4", ",", "in_channels", "*", "2", ",", "2", ",", "1", ",", "0", ")", "]", ")", "\n", "# Scale 2", "\n", "self", ".", "conv_agg_1", "=", "nn", ".", "Conv2d", "(", "in_channels", "*", "4", ",", "in_channels", "*", "2", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "conv2_2", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "nn", ".", "Conv2d", "(", "in_channels", "*", "2", ",", "in_channels", "*", "2", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "]", "\n", ")", "\n", "self", ".", "up2", "=", "nn", ".", "Sequential", "(", "*", "[", "Subpixel", "(", "in_channels", "*", "2", ",", "in_channels", ",", "2", ",", "1", ",", "0", ")", "]", ")", "\n", "# Scale 1", "\n", "self", ".", "conv_agg_2", "=", "nn", ".", "Conv2d", "(", "in_channels", "*", "2", ",", "in_channels", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "conv1_2", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Conv2d", "(", "in_channels", ",", "in_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "nn", ".", "PReLU", "(", ")", "]", "*", "2", ")", "\n", "self", ".", "conv_out", "=", "nn", ".", "Sequential", "(", "*", "[", "nn", ".", "Conv2d", "(", "in_channels", ",", "in_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "nn", ".", "PReLU", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad": [[165, 187], ["sum", "torch.pad", "torch.pad", "torch.pad"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad"], ["", "@", "staticmethod", "\n", "def", "pad", "(", "x", ")", ":", "\n", "        ", "\"\"\"\n        Pads input to height and width dimensions if odd.\n\n        Parameters\n        ----------\n        x: Input to pad.\n\n        Returns\n        -------\n        Padded tensor.\n        \"\"\"", "\n", "padding", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "\n", "if", "x", ".", "shape", "[", "-", "2", "]", "%", "2", "!=", "0", ":", "\n", "            ", "padding", "[", "3", "]", "=", "1", "# Padding right - width", "\n", "", "if", "x", ".", "shape", "[", "-", "1", "]", "%", "2", "!=", "0", ":", "\n", "            ", "padding", "[", "1", "]", "=", "1", "# Padding bottom - height", "\n", "", "if", "sum", "(", "padding", ")", "!=", "0", ":", "\n", "            ", "x", "=", "F", ".", "pad", "(", "x", ",", "padding", ",", "\"reflect\"", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.crop_to_shape": [[188, 209], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "crop_to_shape", "(", "x", ",", "shape", ")", ":", "\n", "        ", "\"\"\"\n        Crops ``x`` to specified shape.\n\n        Parameters\n        ----------\n        x: Input tensor with shape (\\*, H, W).\n        shape: Crop shape corresponding to H, W.\n\n        Returns\n        -------\n        Cropped tensor.\n        \"\"\"", "\n", "h", ",", "w", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "if", "h", ">", "shape", "[", "0", "]", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", "shape", "[", "0", "]", ",", ":", "]", "\n", "", "if", "w", ">", "shape", "[", "1", "]", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", ",", ":", "shape", "[", "1", "]", "]", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.forward": [[210, 236], ["didn.DUB.pad", "didn.DUB.down1", "didn.DUB.down2", "didn.DUB.up1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "didn.DUB.conv_agg_1", "didn.DUB.up2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "didn.DUB.conv_agg_2", "x.clone", "didn.DUB.conv1_1", "didn.DUB.conv2_1", "didn.DUB.conv3_1", "didn.DUB.conv2_2", "didn.DUB.conv1_2", "didn.DUB.crop_to_shape", "didn.DUB.crop_to_shape", "didn.DUB.crop_to_shape", "didn.DUB.conv_out"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DIDN.crop_to_shape", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DIDN.crop_to_shape", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DIDN.crop_to_shape"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        x: Input tensor.\n\n        Returns\n        -------\n        DUB output.\n        \"\"\"", "\n", "x1", "=", "self", ".", "pad", "(", "x", ".", "clone", "(", ")", ")", "\n", "x1", "=", "x1", "+", "self", ".", "conv1_1", "(", "x1", ")", "\n", "x2", "=", "self", ".", "down1", "(", "x1", ")", "\n", "x2", "=", "x2", "+", "self", ".", "conv2_1", "(", "x2", ")", "\n", "out", "=", "self", ".", "down2", "(", "x2", ")", "\n", "out", "=", "out", "+", "self", ".", "conv3_1", "(", "out", ")", "\n", "out", "=", "self", ".", "up1", "(", "out", ")", "\n", "out", "=", "torch", ".", "cat", "(", "[", "x2", ",", "self", ".", "crop_to_shape", "(", "out", ",", "x2", ".", "shape", "[", "-", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "out", "=", "self", ".", "conv_agg_1", "(", "out", ")", "\n", "out", "=", "out", "+", "self", ".", "conv2_2", "(", "out", ")", "\n", "out", "=", "self", ".", "up2", "(", "out", ")", "\n", "out", "=", "torch", ".", "cat", "(", "[", "x1", ",", "self", ".", "crop_to_shape", "(", "out", ",", "x1", ".", "shape", "[", "-", "2", ":", "]", ")", "]", ",", "dim", "=", "1", ")", "\n", "out", "=", "self", ".", "conv_agg_2", "(", "out", ")", "\n", "out", "=", "out", "+", "self", ".", "conv1_2", "(", "out", ")", "\n", "out", "=", "x", "+", "self", ".", "crop_to_shape", "(", "self", ".", "conv_out", "(", "out", ")", ",", "x", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DIDN.__init__": [[252, 315], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "didn.ReconBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "didn.Subpixel", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "didn.DUB", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU", "range", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.PReLU"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "hidden_channels", ":", "int", "=", "128", ",", "\n", "num_dubs", ":", "int", "=", "6", ",", "\n", "num_convs_recon", ":", "int", "=", "9", ",", "\n", "skip_connection", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Inits DIDN.\n\n        Parameters\n        ----------\n        in_channels: Number of input channels.\n            int\n        out_channels: Number of output channels.\n            int\n        hidden_channels: Number of hidden channels. First convolution out_channels.\n            int, Default: 128.\n        num_dubs: Number of DUB networks.\n            int, Default: 6.\n        num_convs_recon: Number of ReconBlock convolutions.\n            int, Default: 9.\n        skip_connection: Use skip connection.\n            bool, Default: False.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_in", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "hidden_channels", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "nn", ".", "PReLU", "(", ")", "]", "\n", ")", "\n", "self", ".", "down", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "hidden_channels", ",", "\n", "out_channels", "=", "hidden_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "2", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", "self", ".", "dubs", "=", "nn", ".", "ModuleList", "(", "\n", "[", "DUB", "(", "in_channels", "=", "hidden_channels", ",", "out_channels", "=", "hidden_channels", ")", "for", "_", "in", "range", "(", "num_dubs", ")", "]", "\n", ")", "\n", "self", ".", "recon_block", "=", "ReconBlock", "(", "in_channels", "=", "hidden_channels", ",", "num_convs", "=", "num_convs_recon", ")", "\n", "self", ".", "recon_agg", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "hidden_channels", "*", "num_dubs", ",", "out_channels", "=", "hidden_channels", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "hidden_channels", ",", "\n", "out_channels", "=", "hidden_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "]", "\n", ")", "\n", "self", ".", "up2", "=", "Subpixel", "(", "hidden_channels", ",", "hidden_channels", ",", "2", ",", "1", ")", "\n", "self", ".", "conv_out", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", "=", "hidden_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", "self", ".", "num_dubs", "=", "num_dubs", "\n", "self", ".", "skip_connection", "=", "(", "in_channels", "==", "out_channels", ")", "and", "skip_connection", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DIDN.crop_to_shape": [[316, 337], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "crop_to_shape", "(", "x", ",", "shape", ")", ":", "\n", "        ", "\"\"\"\n        Crops ``x`` to specified shape.\n\n        Parameters\n        ----------\n        x: Input tensor with shape (\\*, H, W).\n        shape: Crop shape corresponding to H, W.\n\n        Returns\n        -------\n        Cropped tensor.\n        \"\"\"", "\n", "h", ",", "w", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "\n", "\n", "if", "h", ">", "shape", "[", "0", "]", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", "shape", "[", "0", "]", ",", ":", "]", "\n", "", "if", "w", ">", "shape", "[", "1", "]", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", ":", ",", ":", ",", ":", "shape", "[", "1", "]", "]", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DIDN.forward": [[338, 369], ["didn.DIDN.conv_in", "didn.DIDN.down", "didn.DIDN.recon_agg", "didn.DIDN.conv", "didn.DIDN.up2", "didn.DIDN.conv_out", "didn.DIDN.crop_to_shape", "dub", "dub_outs.append", "didn.DIDN.recon_block", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DIDN.crop_to_shape"], ["", "def", "forward", "(", "self", ",", "x", ",", "channel_dim", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Takes as input a torch.Tensor `x` and computes DIDN(x).\n\n        Parameters\n        ----------\n        x: Input tensor.\n        channel_dim: Channel dimension. Default: 1.\n\n        Returns\n        -------\n        DIDN output tensor.\n        \"\"\"", "\n", "out", "=", "self", ".", "conv_in", "(", "x", ")", "\n", "out", "=", "self", ".", "down", "(", "out", ")", "\n", "\n", "dub_outs", "=", "[", "]", "\n", "for", "dub", "in", "self", ".", "dubs", ":", "\n", "            ", "out", "=", "dub", "(", "out", ")", "\n", "dub_outs", ".", "append", "(", "out", ")", "\n", "\n", "", "out", "=", "[", "self", ".", "recon_block", "(", "dub_out", ")", "for", "dub_out", "in", "dub_outs", "]", "\n", "out", "=", "self", ".", "recon_agg", "(", "torch", ".", "cat", "(", "out", ",", "dim", "=", "channel_dim", ")", ")", "\n", "out", "=", "self", ".", "conv", "(", "out", ")", "\n", "out", "=", "self", ".", "up2", "(", "out", ")", "\n", "out", "=", "self", ".", "conv_out", "(", "out", ")", "\n", "out", "=", "self", ".", "crop_to_shape", "(", "out", ",", "x", ".", "shape", "[", "-", "2", ":", "]", ")", "\n", "\n", "if", "self", ".", "skip_connection", ":", "\n", "            ", "out", "=", "x", "+", "out", "\n", "", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.primaldual.pd.DualNet.__init__": [[14, 41], ["torch.Module.__init__", "kwargs.get", "kwargs.get", "torch.Sequential", "torch.Sequential", "kwargs.get", "ValueError", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "num_dual", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Inits DualNet.\n\n        Parameters\n        ----------\n        num_dual: Number of dual for LPD algorithm.\n        kwargs: Keyword arguments.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "kwargs", ".", "get", "(", "\"dual_architecture\"", ")", "is", "None", ":", "\n", "            ", "n_hidden", "=", "kwargs", ".", "get", "(", "\"n_hidden\"", ")", "\n", "if", "n_hidden", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"n_hidden is required for DualNet\"", ")", "\n", "\n", "", "self", ".", "dual_block", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "nn", ".", "Conv2d", "(", "2", "*", "(", "num_dual", "+", "2", ")", ",", "n_hidden", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_hidden", ",", "n_hidden", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_hidden", ",", "2", "*", "num_dual", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dual_block", "=", "kwargs", ".", "get", "(", "\"dual_architecture\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.primaldual.pd.DualNet.compute_model_per_coil": [[42, 62], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "data.size", "data.select", "torch.stack.append", "torch.stack.append", "model"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "compute_model_per_coil", "(", "model", ",", "data", ")", ":", "\n", "        ", "\"\"\"\n        Computes model per coil.\n\n        Parameters\n        ----------\n        model: Model to compute.\n        data: Multi-coil input.\n\n        Returns\n        -------\n        Multi-coil output.\n        \"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "data", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "subselected_data", "=", "data", ".", "select", "(", "1", ",", "idx", ")", "\n", "output", ".", "append", "(", "model", "(", "subselected_data", ")", ")", "\n", "", "output", "=", "torch", ".", "stack", "(", "output", ",", "dim", "=", "1", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.primaldual.pd.DualNet.forward": [[63, 67], ["torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "pd.DualNet.compute_model_per_coil().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pd.DualNet.compute_model_per_coil"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.primaldual.pd.DualNet.compute_model_per_coil"], ["", "def", "forward", "(", "self", ",", "h", ",", "forward_f", ",", "g", ")", ":", "\n", "        ", "\"\"\"Forward pass.\"\"\"", "\n", "inp", "=", "torch", ".", "cat", "(", "[", "h", ",", "forward_f", ",", "g", "]", ",", "dim", "=", "-", "1", ")", ".", "permute", "(", "0", ",", "1", ",", "4", ",", "2", ",", "3", ")", "\n", "return", "self", ".", "compute_model_per_coil", "(", "self", ".", "dual_block", ",", "inp", ")", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.primaldual.pd.PrimalNet.__init__": [[72, 97], ["torch.Module.__init__", "kwargs.get", "kwargs.get", "torch.Sequential", "torch.Sequential", "kwargs.get", "ValueError", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d", "torch.PReLU", "torch.PReLU", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "self", ",", "num_primal", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Inits PrimalNet.\n\n        Parameters\n        ----------\n        num_primal: Number of primal for LPD algorithm.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "kwargs", ".", "get", "(", "\"primal_architecture\"", ")", "is", "None", ":", "\n", "            ", "n_hidden", "=", "kwargs", ".", "get", "(", "\"n_hidden\"", ")", "\n", "if", "n_hidden", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"Missing argument n_hidden.\"", ")", "\n", "", "self", ".", "primal_block", "=", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "nn", ".", "Conv2d", "(", "2", "*", "(", "num_primal", "+", "1", ")", ",", "n_hidden", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_hidden", ",", "n_hidden", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "nn", ".", "PReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "n_hidden", ",", "2", "*", "num_primal", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ")", ",", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "primal_block", "=", "kwargs", ".", "get", "(", "\"primal_architecture\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.primaldual.pd.PrimalNet.forward": [[98, 113], ["torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "pd.PrimalNet.primal_block().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pd.PrimalNet.primal_block"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "f", ",", "backward_h", ")", ":", "\n", "        ", "\"\"\"\n        Forward pass of primal network.\n\n        Parameters\n        ----------\n        f: Forward function.\n        backward_h: Backward function.\n\n        Returns\n        -------\n        Primal function.\n        \"\"\"", "\n", "inp", "=", "torch", ".", "cat", "(", "[", "f", ",", "backward_h", "]", ",", "dim", "=", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "self", ".", "primal_block", "(", "inp", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.variablesplittingnet.vsnet_block.DataConsistencyLayer.__init__": [[18, 22], ["super().__init__", "torch.nn.Parameter", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initializes the data consistency layer.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dc_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.variablesplittingnet.vsnet_block.DataConsistencyLayer.forward": [[23, 26], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pred_kspace", ",", "ref_kspace", ",", "mask", ")", ":", "\n", "        ", "\"\"\"Forward pass of the data consistency layer.\"\"\"", "\n", "return", "(", "(", "1", "-", "mask", ")", "*", "pred_kspace", "+", "mask", "*", "ref_kspace", ")", "*", "self", ".", "dc_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.variablesplittingnet.vsnet_block.WeightedAverageTerm.__init__": [[31, 34], ["super().__init__", "torch.nn.Parameter", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "param", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.variablesplittingnet.vsnet_block.WeightedAverageTerm.forward": [[35, 37], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "Sx", ")", ":", "\n", "        ", "return", "self", ".", "param", "*", "x", "+", "(", "1", "-", "self", ".", "param", ")", "*", "Sx", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.variablesplittingnet.vsnet_block.VSNetBlock.__init__": [[48, 82], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "denoiser_block", ":", "torch", ".", "nn", ".", "ModuleList", ",", "\n", "data_consistency_block", ":", "torch", ".", "nn", ".", "ModuleList", ",", "\n", "weighted_average_block", ":", "torch", ".", "nn", ".", "ModuleList", ",", "\n", "num_cascades", ":", "int", "=", "8", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        denoiser_block: Model to apply denoising.\n        data_consistency_block: Model to apply data consistency.\n        weighted_average_block: Model to apply weighted average.\n        num_cascades: Number of cascades.\n        fft_centered: Whether to center the fft.\n        fft_normalization: The normalization of the fft.\n        spatial_dims: The spatial dimensions of the data.\n        coil_dim: The dimension of the coil.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "denoiser_block", "=", "denoiser_block", "\n", "self", ".", "data_consistency_block", "=", "data_consistency_block", "\n", "self", ".", "weighted_average_block", "=", "weighted_average_block", "\n", "self", ".", "num_cascades", "=", "num_cascades", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.variablesplittingnet.vsnet_block.VSNetBlock.sens_expand": [[83, 101], ["mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.utils.complex_mul"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul"], ["", "def", "sens_expand", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "sens_maps", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Expand the sensitivity maps to the same size as the input.\n\n        Parameters\n        ----------\n        x: Input data.\n        sens_maps: Coil Sensitivity maps.\n\n        Returns\n        -------\n        SENSE reconstruction expanded to the same size as the input sens_maps.\n        \"\"\"", "\n", "return", "fft2", "(", "\n", "complex_mul", "(", "x", ",", "sens_maps", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.variablesplittingnet.vsnet_block.VSNetBlock.sens_reduce": [[103, 118], ["mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_mul().sum", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_conj"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "def", "sens_reduce", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "sens_maps", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Reduce the sensitivity maps.\n\n        Parameters\n        ----------\n        x: Input data.\n        sens_maps: Coil Sensitivity maps.\n\n        Returns\n        -------\n        SENSE coil-combined reconstruction.\n        \"\"\"", "\n", "x", "=", "ifft2", "(", "x", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", ")", "\n", "return", "complex_mul", "(", "x", ",", "complex_conj", "(", "sens_maps", ")", ")", ".", "sum", "(", "self", ".", "coil_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.variablesplittingnet.vsnet_block.VSNetBlock.forward": [[119, 145], ["range", "vsnet_block.VSNetBlock.sens_reduce", "vsnet_block.VSNetBlock.sens_expand", "vsnet_block.VSNetBlock.sens_reduce", "vsnet_block.VSNetBlock.permute"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.sens_reduce", "home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.sens_expand", "home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.sens_reduce"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "kspace", ":", "torch", ".", "Tensor", ",", "\n", "sens_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "List", "[", "Union", "[", "torch", ".", "Tensor", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        kspace: Reference k-space data.\n        sens_maps: Coil sensitivity maps.\n        mask: Mask to apply to the data.\n\n        Returns\n        -------\n        Reconstructed image.\n        \"\"\"", "\n", "for", "idx", "in", "range", "(", "self", ".", "num_cascades", ")", ":", "\n", "            ", "pred", "=", "self", ".", "sens_reduce", "(", "kspace", ",", "sens_maps", ")", "\n", "pred", "=", "self", ".", "denoiser_block", "[", "idx", "]", "(", "pred", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "pred", "=", "self", ".", "sens_expand", "(", "pred", ",", "sens_maps", ")", "\n", "sx", "=", "self", ".", "data_consistency_block", "[", "idx", "]", "(", "pred", ",", "kspace", ",", "mask", ")", "\n", "sx", "=", "self", ".", "sens_reduce", "(", "sx", ",", "sens_maps", ")", "\n", "kspace", "=", "self", ".", "weighted_average_block", "[", "idx", "]", "(", "kspace", "+", "pred", ",", "sx", ")", "\n", "", "return", "kspace", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.cascadenet.ccnn_block.CascadeNetBlock.__init__": [[20, 56], ["super().__init__", "torch.nn.Parameter", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", "no_dc", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Initializes the model block.\n\n        Parameters\n        ----------\n        model: Model to apply soft data consistency.\n            torch.nn.Module\n        fft_centered: Whether to center the FFT.\n            bool\n        fft_normalization: Whether to normalize the FFT.\n            str\n        spatial_dims: Spatial dimensions of the input.\n            Tuple[int, int]\n        coil_dim: Coil dimension.\n            int\n        no_dc: Flag to disable the soft data consistency.\n            bool\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "self", ".", "no_dc", "=", "no_dc", "\n", "self", ".", "dc_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.cascadenet.ccnn_block.CascadeNetBlock.sens_expand": [[57, 78], ["mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.utils.complex_mul"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul"], ["", "def", "sens_expand", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "sens_maps", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Expand the sensitivity maps to the same size as the input.\n\n        Parameters\n        ----------\n        x: Input data.\n            torch.Tensor, shape [batch_size, n_coils, height, width, 2]\n        sens_maps: Sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, height, width, 2]\n\n        Returns\n        -------\n        SENSE reconstruction expanded to the same size as the input.\n            torch.Tensor, shape [batch_size, n_coils, height, width, 2]\n        \"\"\"", "\n", "return", "fft2", "(", "\n", "complex_mul", "(", "x", ",", "sens_maps", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.cascadenet.ccnn_block.CascadeNetBlock.sens_reduce": [[80, 98], ["mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_mul().sum", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_conj"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "def", "sens_reduce", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "sens_maps", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Reduce the sensitivity maps to the same size as the input.\n\n        Parameters\n        ----------\n        x: Input data.\n            torch.Tensor, shape [batch_size, n_coils, height, width, 2]\n        sens_maps: Sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, height, width, 2]\n\n        Returns\n        -------\n        SENSE reconstruction.\n            torch.Tensor, shape [batch_size, height, width, 2]\n        \"\"\"", "\n", "x", "=", "ifft2", "(", "x", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", ")", "\n", "return", "complex_mul", "(", "x", ",", "complex_conj", "(", "sens_maps", ")", ")", ".", "sum", "(", "dim", "=", "self", ".", "coil_dim", ",", "keepdim", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.cascadenet.ccnn_block.CascadeNetBlock.forward": [[99, 136], ["torch.zeros().to", "ccnn_block.CascadeNetBlock.sens_reduce", "ccnn_block.CascadeNetBlock.model().permute", "ccnn_block.CascadeNetBlock.sens_expand", "torch.where", "torch.zeros", "mask.bool", "ccnn_block.CascadeNetBlock.model", "ccnn_block.CascadeNetBlock.squeeze().permute", "ccnn_block.CascadeNetBlock.squeeze"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.sens_reduce", "home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.sens_expand"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "pred", ":", "torch", ".", "Tensor", ",", "\n", "ref_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sens_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the model block.\n\n        Parameters\n        ----------\n        pred: Predicted k-space data.\n            torch.Tensor, shape [batch_size, n_coils, height, width, 2]\n        ref_kspace: Reference k-space data.\n            torch.Tensor, shape [batch_size, n_coils, height, width, 2]\n        sens_maps: Sensitivity maps.\n            torch.Tensor, shape [batch_size, n_coils, height, width, 2]\n        mask: Mask to apply to the data.\n            torch.Tensor, shape [batch_size, 1, height, width, 1]\n\n        Returns\n        -------\n        Reconstructed image.\n            torch.Tensor, shape [batch_size, height, width, 2]\n        \"\"\"", "\n", "zero", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ",", "1", ",", "1", ")", ".", "to", "(", "pred", ")", "\n", "soft_dc", "=", "torch", ".", "where", "(", "mask", ".", "bool", "(", ")", ",", "pred", "-", "ref_kspace", ",", "zero", ")", "*", "self", ".", "dc_weight", "\n", "\n", "eta", "=", "self", ".", "sens_reduce", "(", "pred", ",", "sens_maps", ")", "\n", "eta", "=", "self", ".", "model", "(", "eta", ".", "squeeze", "(", "self", ".", "coil_dim", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "eta", "=", "self", ".", "sens_expand", "(", "eta", ",", "sens_maps", ")", "\n", "\n", "if", "not", "self", ".", "no_dc", ":", "\n", "            ", "eta", "=", "pred", "-", "soft_dc", "-", "eta", "\n", "\n", "", "return", "eta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.convrecnet.crnn_block.DataConsistencyLayer.__init__": [[18, 22], ["super().__init__", "torch.nn.Parameter", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initializes the data consistency layer.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dc_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.convrecnet.crnn_block.DataConsistencyLayer.forward": [[23, 27], ["torch.zeros().to", "torch.where", "torch.zeros", "mask.bool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pred_kspace", ",", "ref_kspace", ",", "mask", ")", ":", "\n", "        ", "\"\"\"Forward pass of the data consistency layer.\"\"\"", "\n", "zero", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ",", "1", ",", "1", ")", ".", "to", "(", "pred_kspace", ")", "\n", "return", "torch", ".", "where", "(", "mask", ".", "bool", "(", ")", ",", "pred_kspace", "-", "ref_kspace", ",", "zero", ")", "*", "self", ".", "dc_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.convrecnet.crnn_block.RecurrentConvolutionalNetBlock.__init__": [[38, 72], ["super().__init__", "torch.nn.Parameter", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "num_iterations", ":", "int", "=", "10", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", "no_dc", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the model block.\n\n        Parameters\n        ----------\n        model: Model to apply soft data consistency.\n        num_iterations: Number of iterations.\n        fft_centered: Whether to use centered FFT.\n        fft_normalization: Whether to use normalized FFT.\n        spatial_dims: Spatial dimensions of the input.\n        coil_dim: Dimension of the coil.\n        no_dc: Whether to remove the DC component.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "num_iterations", "=", "num_iterations", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "self", ".", "no_dc", "=", "no_dc", "\n", "\n", "self", ".", "dc_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.convrecnet.crnn_block.RecurrentConvolutionalNetBlock.sens_expand": [[73, 91], ["mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.utils.complex_mul"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul"], ["", "def", "sens_expand", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "sens_maps", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Expand the sensitivity maps to the same size as the input.\n\n        Parameters\n        ----------\n        x: Input data.\n        sens_maps: Sensitivity maps.\n\n        Returns\n        -------\n        SENSE reconstruction expanded to the same size as the input.\n        \"\"\"", "\n", "return", "fft2", "(", "\n", "complex_mul", "(", "x", ",", "sens_maps", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.convrecnet.crnn_block.RecurrentConvolutionalNetBlock.sens_reduce": [[93, 108], ["mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_mul().sum", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_conj"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "def", "sens_reduce", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "sens_maps", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Reduce the sensitivity maps to the same size as the input.\n\n        Parameters\n        ----------\n        x: Input data.\n        sens_maps: Sensitivity maps.\n\n        Returns\n        -------\n        SENSE reconstruction reduced to the same size as the input.\n        \"\"\"", "\n", "x", "=", "ifft2", "(", "x", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", ")", "\n", "return", "complex_mul", "(", "x", ",", "complex_conj", "(", "sens_maps", ")", ")", ".", "sum", "(", "self", ".", "coil_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.convrecnet.crnn_block.RecurrentConvolutionalNetBlock.forward": [[109, 147], ["torch.zeros().to", "ref_kspace.clone", "range", "crnn_block.RecurrentConvolutionalNetBlock.sens_reduce", "crnn_block.RecurrentConvolutionalNetBlock.sens_expand", "preds.append", "torch.zeros", "torch.where", "crnn_block.RecurrentConvolutionalNetBlock.model().permute", "crnn_block.RecurrentConvolutionalNetBlock.unsqueeze", "mask.bool", "crnn_block.RecurrentConvolutionalNetBlock.model", "crnn_block.RecurrentConvolutionalNetBlock.permute"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.sens_reduce", "home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.sens_expand"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "ref_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sens_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "List", "[", "Union", "[", "torch", ".", "Tensor", ",", "Any", "]", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass of the model.\n\n        Parameters\n        ----------\n        ref_kspace: Reference k-space data.\n        sens_maps: Sensitivity maps.\n        mask: Mask to apply to the data.\n\n        Returns\n        -------\n        Reconstructed image.\n        \"\"\"", "\n", "zero", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ",", "1", ",", "1", ")", ".", "to", "(", "ref_kspace", ")", "\n", "pred", "=", "ref_kspace", ".", "clone", "(", ")", "\n", "\n", "preds", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "num_iterations", ")", ":", "\n", "            ", "soft_dc", "=", "torch", ".", "where", "(", "mask", ".", "bool", "(", ")", ",", "pred", "-", "ref_kspace", ",", "zero", ")", "*", "self", ".", "dc_weight", "\n", "\n", "eta", "=", "self", ".", "sens_reduce", "(", "pred", ",", "sens_maps", ")", "\n", "eta", "=", "self", ".", "model", "(", "eta", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "+", "eta", "\n", "eta", "=", "self", ".", "sens_expand", "(", "eta", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ",", "sens_maps", ")", "\n", "\n", "if", "not", "self", ".", "no_dc", ":", "\n", "# TODO: Check if this is correct", "\n", "                ", "eta", "=", "pred", "-", "soft_dc", "-", "eta", "\n", "", "pred", "=", "eta", "\n", "\n", "preds", ".", "append", "(", "eta", ")", "\n", "\n", "", "return", "preds", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.__init__": [[20, 50], ["super().__init__", "torch.nn.Parameter", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", "no_dc", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the model block.\n\n        Parameters\n        ----------\n        model: Model to apply soft data consistency.\n        fft_centered: Whether to center the fft.\n        fft_normalization: The normalization of the fft.\n        spatial_dims: The spatial dimensions of the data.\n        coil_dim: The dimension of the coil dimension.\n        no_dc: Whether to remove the DC component.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "self", ".", "no_dc", "=", "no_dc", "\n", "self", ".", "dc_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.sens_expand": [[51, 69], ["mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.utils.complex_mul"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul"], ["", "def", "sens_expand", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "sens_maps", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Expand the sensitivity maps to the same size as the input.\n\n        Parameters\n        ----------\n        x: Input data.\n        sens_maps: Coil Sensitivity maps.\n\n        Returns\n        -------\n        SENSE reconstruction expanded to the same size as the input sens_maps.\n        \"\"\"", "\n", "return", "fft2", "(", "\n", "complex_mul", "(", "x", ",", "sens_maps", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.sens_reduce": [[71, 86], ["mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_mul().sum", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_conj"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "def", "sens_reduce", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "sens_maps", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Reduce the sensitivity maps.\n\n        Parameters\n        ----------\n        x: Input data.\n        sens_maps: Coil Sensitivity maps.\n\n        Returns\n        -------\n        SENSE coil-combined reconstruction.\n        \"\"\"", "\n", "x", "=", "ifft2", "(", "x", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", ")", "\n", "return", "complex_mul", "(", "x", ",", "complex_conj", "(", "sens_maps", ")", ")", ".", "sum", "(", "dim", "=", "self", ".", "coil_dim", ",", "keepdim", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.forward": [[87, 118], ["torch.zeros().to", "vn_block.VarNetBlock.sens_reduce", "vn_block.VarNetBlock.model", "vn_block.VarNetBlock.sens_expand", "torch.where", "torch.zeros", "mask.bool"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.sens_reduce", "home.repos.pwc.inspect_result.wdika_mridc.varnet.vn_block.VarNetBlock.sens_expand"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "pred", ":", "torch", ".", "Tensor", ",", "\n", "ref_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sens_maps", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        pred: Input data.\n        ref_kspace: Reference k-space data.\n        sens_maps: Coil sensitivity maps.\n        mask: Mask to apply to the data.\n\n        Returns\n        -------\n        Reconstructed image.\n        \"\"\"", "\n", "zero", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ",", "1", ",", "1", ")", ".", "to", "(", "pred", ")", "\n", "soft_dc", "=", "torch", ".", "where", "(", "mask", ".", "bool", "(", ")", ",", "pred", "-", "ref_kspace", ",", "zero", ")", "*", "self", ".", "dc_weight", "\n", "\n", "eta", "=", "self", ".", "sens_reduce", "(", "pred", ",", "sens_maps", ")", "\n", "eta", "=", "self", ".", "model", "(", "eta", ")", "\n", "eta", "=", "self", ".", "sens_expand", "(", "eta", ",", "sens_maps", ")", "\n", "\n", "if", "not", "self", ".", "no_dc", ":", "\n", "            ", "eta", "=", "pred", "-", "soft_dc", "-", "eta", "\n", "\n", "", "return", "eta", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.MultiDomainConv2d.__init__": [[20, 39], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Sequence", "[", "int", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", "in_channels", ":", "int", "=", "4", ",", "\n", "out_channels", ":", "int", "=", "4", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "image_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", "//", "2", ",", "**", "kwargs", ")", "\n", "self", ".", "kspace_conv", "=", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", "//", "2", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "self", ".", "coil_dim", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.MultiDomainConv2d.forward": [[40, 63], ["torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "multidomain.MultiDomainConv2d.kspace_conv", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "multidomain.MultiDomainConv2d.image_conv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.fft.ifft2().type", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.type", "torch.cat.type", "torch.cat.type", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.permute().contiguous", "torch.cat.permute().contiguous", "torch.cat.permute().contiguous", "mridc.collections.common.parts.fft.ifft2", "multidomain.MultiDomainConv2d.permute().contiguous", "ks.float", "torch.cat.permute", "torch.cat.permute", "torch.cat.permute", "multidomain.MultiDomainConv2d.permute"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], ["", "def", "forward", "(", "self", ",", "image", ")", ":", "\n", "        ", "\"\"\"Forward method for the MultiDomainConv2d class.\"\"\"", "\n", "kspace", "=", "[", "\n", "fft2", "(", "im", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", ")", "\n", "for", "im", "in", "torch", ".", "split", "(", "image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ",", "2", ",", "-", "1", ")", "\n", "]", "\n", "kspace", "=", "torch", ".", "cat", "(", "kspace", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "kspace", "=", "self", ".", "kspace_conv", "(", "kspace", ")", "\n", "\n", "backward", "=", "[", "\n", "ifft2", "(", "\n", "ks", ".", "float", "(", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ".", "type", "(", "image", ".", "type", "(", ")", ")", "\n", "for", "ks", "in", "torch", ".", "split", "(", "kspace", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ",", "2", ",", "-", "1", ")", "\n", "]", "\n", "backward", "=", "torch", ".", "cat", "(", "backward", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "\n", "image", "=", "self", ".", "image_conv", "(", "image", ")", "\n", "image", "=", "torch", ".", "cat", "(", "[", "image", ",", "backward", "]", ",", "dim", "=", "self", ".", "coil_dim", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.MultiDomainConvTranspose2d.__init__": [[68, 86], ["torch.Module.__init__", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.ConvTranspose2d"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Sequence", "[", "int", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", "in_channels", ":", "int", "=", "4", ",", "\n", "out_channels", ":", "int", "=", "4", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "image_conv", "=", "nn", ".", "ConvTranspose2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", "//", "2", ",", "**", "kwargs", ")", "\n", "self", ".", "kspace_conv", "=", "nn", ".", "ConvTranspose2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", "//", "2", ",", "**", "kwargs", ")", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "self", ".", "coil_dim", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.MultiDomainConvTranspose2d.forward": [[87, 109], ["torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "multidomain.MultiDomainConvTranspose2d.kspace_conv", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "torch.cat().permute", "multidomain.MultiDomainConvTranspose2d.image_conv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.fft.ifft2().type", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multidomain.MultiDomainConvTranspose2d.type", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multidomain.MultiDomainConvTranspose2d.permute().contiguous", "mridc.collections.common.parts.fft.ifft2", "multidomain.MultiDomainConvTranspose2d.permute().contiguous", "ks.float", "multidomain.MultiDomainConvTranspose2d.permute", "multidomain.MultiDomainConvTranspose2d.permute"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2"], ["", "def", "forward", "(", "self", ",", "image", ")", ":", "\n", "        ", "\"\"\"Forward method for the MultiDomainConvTranspose2d class.\"\"\"", "\n", "kspace", "=", "[", "\n", "fft2", "(", "im", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "self", ".", "fft_normalization", ",", "spatial_dims", "=", "self", ".", "spatial_dims", ")", "\n", "for", "im", "in", "torch", ".", "split", "(", "image", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ",", "2", ",", "-", "1", ")", "\n", "]", "\n", "kspace", "=", "torch", ".", "cat", "(", "kspace", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "kspace", "=", "self", ".", "kspace_conv", "(", "kspace", ")", "\n", "\n", "backward", "=", "[", "\n", "ifft2", "(", "\n", "ks", ".", "float", "(", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ".", "type", "(", "image", ".", "type", "(", ")", ")", "\n", "for", "ks", "in", "torch", ".", "split", "(", "kspace", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ".", "contiguous", "(", ")", ",", "2", ",", "-", "1", ")", "\n", "]", "\n", "backward", "=", "torch", ".", "cat", "(", "backward", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "\n", "image", "=", "self", ".", "image_conv", "(", "image", ")", "\n", "return", "torch", ".", "cat", "(", "[", "image", ",", "backward", "]", ",", "dim", "=", "self", ".", "coil_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.MultiDomainConvBlock.__init__": [[117, 178], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "multidomain.MultiDomainConv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d", "multidomain.MultiDomainConv2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Dropout2d", "torch.Dropout2d", "torch.Dropout2d"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Sequence", "[", "int", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", "in_channels", ":", "int", "=", "4", ",", "\n", "out_channels", ":", "int", "=", "4", ",", "\n", "dropout_probability", ":", "float", "=", "0.0", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        fft_centered : Whether to center the FFT.\n        fft_normalization : Whether to normalize the FFT.\n        spatial_dims : The spatial dimensions to apply the FFT to.\n        coil_dim : The dimension of the coil.\n        in_channels: Number of input channels.\n        out_channels: Number of output channels.\n        dropout_probability: Dropout probability.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "dropout_probability", "=", "dropout_probability", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "\n", "MultiDomainConv2d", "(", "\n", "self", ".", "fft_centered", ",", "\n", "self", ".", "fft_normalization", ",", "\n", "self", ".", "spatial_dims", ",", "\n", "self", ".", "coil_dim", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout2d", "(", "dropout_probability", ")", ",", "\n", "MultiDomainConv2d", "(", "\n", "self", ".", "fft_centered", ",", "\n", "self", ".", "fft_normalization", ",", "\n", "self", ".", "spatial_dims", ",", "\n", "self", ".", "coil_dim", ",", "\n", "out_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout2d", "(", "dropout_probability", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.MultiDomainConvBlock.forward": [[180, 183], ["multidomain.MultiDomainConvBlock.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "_input", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Forward method for the MultiDomainConvBlock class.\"\"\"", "\n", "return", "self", ".", "layers", "(", "_input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.MultiDomainConvBlock.__repr__": [[184, 187], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "f\"MultiDomainConvBlock(in_channels={self.in_channels}, out_channels={self.out_channels}, \"", "\n", "f\"dropout_probability={self.dropout_probability})\"", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.TransposeMultiDomainConvBlock.__init__": [[197, 233], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "multidomain.MultiDomainConvTranspose2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.InstanceNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Sequence", "[", "int", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", "in_channels", ":", "int", "=", "4", ",", "\n", "out_channels", ":", "int", "=", "4", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        fft_centered : Whether to center the FFT.\n        fft_normalization : Whether to normalize the FFT.\n        spatial_dims : The spatial dimensions to apply the FFT to.\n        coil_dim : The dimension of the coil.\n        in_channels: Number of input channels.\n        out_channels: Number of output channels.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "\n", "MultiDomainConvTranspose2d", "(", "\n", "fft_centered", ",", "\n", "fft_normalization", ",", "\n", "spatial_dims", ",", "\n", "coil_dim", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "2", ",", "\n", "stride", "=", "2", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "InstanceNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "negative_slope", "=", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.TransposeMultiDomainConvBlock.forward": [[235, 238], ["multidomain.TransposeMultiDomainConvBlock.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_data", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Forward method for the TransposeMultiDomainConvBlock class.\"\"\"", "\n", "return", "self", ".", "layers", "(", "input_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.TransposeMultiDomainConvBlock.__repr__": [[239, 241], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"MultiDomainConvBlock(in_channels={self.in_channels}, out_channels={self.out_channels})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.StandardizationLayer.__init__": [[260, 264], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "coil_dim", "=", "1", ",", "channel_dim", "=", "-", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "self", ".", "channel_dim", "=", "channel_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.StandardizationLayer.forward": [[265, 280], ["mridc.collections.common.parts.utils.complex_mul().sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "mridc.collections.common.parts.utils.complex_mul().sum.unsqueeze", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.common.parts.utils.complex_mul().sum.unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "mridc.collections.common.parts.utils.complex_conj", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "coil_images.size", "residual_image.select"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "def", "forward", "(", "self", ",", "coil_images", ":", "torch", ".", "Tensor", ",", "sensitivity_map", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"Forward pass.\"\"\"", "\n", "combined_image", "=", "complex_mul", "(", "coil_images", ",", "complex_conj", "(", "sensitivity_map", ")", ")", ".", "sum", "(", "self", ".", "coil_dim", ")", "\n", "residual_image", "=", "combined_image", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", "-", "complex_mul", "(", "\n", "combined_image", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ",", "sensitivity_map", "\n", ")", "\n", "return", "torch", ".", "cat", "(", "\n", "[", "\n", "torch", ".", "cat", "(", "\n", "[", "combined_image", ",", "residual_image", ".", "select", "(", "self", ".", "coil_dim", ",", "idx", ")", "]", ",", "\n", "self", ".", "channel_dim", ",", "\n", ")", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", "\n", "for", "idx", "in", "range", "(", "coil_images", ".", "size", "(", "self", ".", "coil_dim", ")", ")", "\n", "]", ",", "\n", "self", ".", "coil_dim", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.MultiDomainUnet2d.__init__": [[289, 401], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "multidomain.MultiDomainConvBlock", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "multidomain.TransposeMultiDomainConvBlock", "torch.Sequential", "torch.Sequential", "torch.Sequential", "multidomain.MultiDomainConvBlock", "multidomain.MultiDomainConvBlock", "multidomain.TransposeMultiDomainConvBlock", "multidomain.MultiDomainConvBlock", "multidomain.MultiDomainConvBlock", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ":", "int", ",", "\n", "out_channels", ":", "int", ",", "\n", "num_filters", ":", "int", ",", "\n", "num_pool_layers", ":", "int", ",", "\n", "dropout_probability", ":", "float", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        in_channels: Number of input channels to the u-net.\n        out_channels: Number of output channels to the u-net.\n        num_filters: Number of output channels of the first convolutional layer.\n        num_pool_layers: Number of down-sampling and up-sampling layers (depth).\n        dropout_probability: Dropout probability.\n        fft_centered: Whether to use centered FFT.\n        fft_normalization: Whether to use normalization.\n        spatial_dims: Spatial dimensions of the input data.\n        coil_dim: Dimension of the coil dimension.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "num_filters", "=", "num_filters", "\n", "self", ".", "num_pool_layers", "=", "num_pool_layers", "\n", "self", ".", "dropout_probability", "=", "dropout_probability", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "\n", "self", ".", "down_sample_layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "MultiDomainConvBlock", "(", "\n", "self", ".", "fft_centered", ",", "\n", "self", ".", "fft_normalization", ",", "\n", "self", ".", "spatial_dims", ",", "\n", "self", ".", "coil_dim", ",", "\n", "in_channels", ",", "\n", "num_filters", ",", "\n", "dropout_probability", ",", "\n", ")", "\n", "]", "\n", ")", "\n", "ch", "=", "num_filters", "\n", "for", "_", "in", "range", "(", "num_pool_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "down_sample_layers", "+=", "[", "\n", "MultiDomainConvBlock", "(", "\n", "self", ".", "fft_centered", ",", "\n", "self", ".", "fft_normalization", ",", "\n", "self", ".", "spatial_dims", ",", "\n", "self", ".", "coil_dim", ",", "\n", "ch", ",", "\n", "ch", "*", "2", ",", "\n", "dropout_probability", ",", "\n", ")", "\n", "]", "\n", "ch", "*=", "2", "\n", "", "self", ".", "conv", "=", "MultiDomainConvBlock", "(", "\n", "self", ".", "fft_centered", ",", "\n", "self", ".", "fft_normalization", ",", "\n", "self", ".", "spatial_dims", ",", "\n", "self", ".", "coil_dim", ",", "\n", "ch", ",", "\n", "ch", "*", "2", ",", "\n", "dropout_probability", ",", "\n", ")", "\n", "\n", "self", ".", "up_conv", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "up_transpose_conv", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "num_pool_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "up_transpose_conv", "+=", "[", "\n", "TransposeMultiDomainConvBlock", "(", "\n", "self", ".", "fft_centered", ",", "self", ".", "fft_normalization", ",", "self", ".", "spatial_dims", ",", "self", ".", "coil_dim", ",", "ch", "*", "2", ",", "ch", "\n", ")", "\n", "]", "\n", "self", ".", "up_conv", "+=", "[", "\n", "MultiDomainConvBlock", "(", "\n", "self", ".", "fft_centered", ",", "\n", "self", ".", "fft_normalization", ",", "\n", "self", ".", "spatial_dims", ",", "\n", "self", ".", "coil_dim", ",", "\n", "ch", "*", "2", ",", "\n", "ch", ",", "\n", "dropout_probability", ",", "\n", ")", "\n", "]", "\n", "ch", "//=", "2", "\n", "\n", "", "self", ".", "up_transpose_conv", "+=", "[", "\n", "TransposeMultiDomainConvBlock", "(", "\n", "self", ".", "fft_centered", ",", "self", ".", "fft_normalization", ",", "self", ".", "spatial_dims", ",", "self", ".", "coil_dim", ",", "ch", "*", "2", ",", "ch", "\n", ")", "\n", "]", "\n", "self", ".", "up_conv", "+=", "[", "\n", "nn", ".", "Sequential", "(", "\n", "MultiDomainConvBlock", "(", "\n", "self", ".", "fft_centered", ",", "\n", "self", ".", "fft_normalization", ",", "\n", "self", ".", "spatial_dims", ",", "\n", "self", ".", "coil_dim", ",", "\n", "ch", "*", "2", ",", "\n", "ch", ",", "\n", "dropout_probability", ",", "\n", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ch", ",", "self", ".", "out_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.multidomain.multidomain.MultiDomainUnet2d.forward": [[404, 435], ["multidomain.MultiDomainUnet2d.conv", "zip", "layer", "stack.append", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "stack.pop", "transpose_conv", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "conv", "sum", "torch.pad", "torch.pad", "torch.pad"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad"], ["", "def", "forward", "(", "self", ",", "input_data", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"Forward pass of the u-net.\"\"\"", "\n", "stack", "=", "[", "]", "\n", "output", "=", "input_data", "\n", "\n", "# Apply down-sampling layers", "\n", "for", "layer", "in", "self", ".", "down_sample_layers", ":", "\n", "            ", "output", "=", "layer", "(", "output", ")", "\n", "stack", ".", "append", "(", "output", ")", "\n", "output", "=", "F", ".", "avg_pool2d", "(", "output", ",", "kernel_size", "=", "2", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "", "output", "=", "self", ".", "conv", "(", "output", ")", "\n", "\n", "# Apply up-sampling layers", "\n", "for", "transpose_conv", ",", "conv", "in", "zip", "(", "self", ".", "up_transpose_conv", ",", "self", ".", "up_conv", ")", ":", "\n", "            ", "downsample_layer", "=", "stack", ".", "pop", "(", ")", "\n", "output", "=", "transpose_conv", "(", "output", ")", "\n", "\n", "# Reflect pad on the right/bottom if needed to handle odd input dimensions.", "\n", "padding", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "if", "output", ".", "shape", "[", "-", "1", "]", "!=", "downsample_layer", ".", "shape", "[", "-", "1", "]", ":", "\n", "                ", "padding", "[", "1", "]", "=", "1", "# Padding right", "\n", "", "if", "output", ".", "shape", "[", "-", "2", "]", "!=", "downsample_layer", ".", "shape", "[", "-", "2", "]", ":", "\n", "                ", "padding", "[", "3", "]", "=", "1", "# Padding bottom", "\n", "", "if", "sum", "(", "padding", ")", "!=", "0", ":", "\n", "                ", "output", "=", "F", ".", "pad", "(", "output", ",", "padding", ",", "\"reflect\"", ")", "\n", "\n", "", "output", "=", "torch", ".", "cat", "(", "[", "output", ",", "downsample_layer", "]", ",", "dim", "=", "1", ")", "\n", "output", "=", "conv", "(", "output", ")", "\n", "\n", "", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.conv.gruconv2d.GRUConv2d.__init__": [[22, 89], ["torch.Module.__init__", "torch.ModuleList", "gruconv2d.GRUConv2d.layers.append", "range", "gruconv2d.GRUConv2d.layers.append", "mridc.collections.reconstruction.models.rim.rnn_cells.ConvGRUCell", "gruconv2d.GRUConv2d.layers.append", "torch.Sequential", "mridc.collections.reconstruction.models.rim.conv_layers.ConvNonlinear", "mridc.collections.reconstruction.models.rim.conv_layers.ConvNonlinear"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "hidden_channels", ",", "\n", "n_convs", "=", "3", ",", "\n", "activation", "=", "\"ReLU\"", ",", "\n", "batchnorm", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Inits Conv2d.\n\n        Parameters\n        ----------\n        in_channels: Number of input channels.\n            int\n        out_channels: Number of output channels.\n            int\n        hidden_channels: Number of hidden channels.\n            int\n        n_convs: Number of convolutional layers.\n            int\n        activation: Activation function.\n            torch.nn.Module\n        batchnorm: If True a batch normalization layer is applied after every convolution.\n            bool\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layers", ".", "append", "(", "\n", "ConvGRUCell", "(", "\n", "in_channels", ",", "\n", "hidden_channels", ",", "\n", "conv_dim", "=", "2", ",", "\n", "kernel_size", "=", "3", ",", "\n", "dilation", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", ")", "\n", "for", "_", "in", "range", "(", "n_convs", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "ConvNonlinear", "(", "\n", "hidden_channels", ",", "\n", "hidden_channels", ",", "\n", "conv_dim", "=", "2", ",", "\n", "kernel_size", "=", "3", ",", "\n", "dilation", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "nonlinear", "=", "activation", ",", "\n", ")", "\n", ")", "\n", "", "self", ".", "layers", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "ConvNonlinear", "(", "\n", "hidden_channels", ",", "\n", "out_channels", ",", "\n", "conv_dim", "=", "2", ",", "\n", "kernel_size", "=", "3", ",", "\n", "dilation", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", "nonlinear", "=", "activation", ",", "\n", ")", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "hidden_channels", "=", "hidden_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.conv.gruconv2d.GRUConv2d.forward": [[90, 111], ["enumerate", "x.new_zeros", "layer", "layer", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "hx", ":", "Optional", "[", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Performs the forward pass of Conv2d.\n\n        Parameters\n        ----------\n        x: Input tensor.\n            torch.Tensor\n        hx: Initial hidden state.\n            torch.Tensor\n\n        Returns\n        -------\n        Convoluted output.\n        \"\"\"", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "hx", "=", "x", ".", "new_zeros", "(", "(", "x", ".", "size", "(", "0", ")", ",", "self", ".", "hidden_channels", ",", "*", "x", ".", "size", "(", ")", "[", "2", ":", "]", ")", ")", "\n", "\n", "", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "hx", ")", "if", "i", "==", "0", "else", "layer", "(", "x", ")", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.conv.conv2d.Conv2d.__init__": [[16, 52], ["torch.PReLU", "torch.Module.__init__", "range", "torch.Sequential", "conv2d.Conv2d.conv.append", "torch.Conv2d", "conv2d.Conv2d.conv.append", "conv2d.Conv2d.conv.append", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "hidden_channels", ",", "n_convs", "=", "3", ",", "activation", "=", "nn", ".", "PReLU", "(", ")", ",", "batchnorm", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Inits Conv2d.\n\n        Parameters\n        ----------\n        in_channels: Number of input channels.\n            int\n        out_channels: Number of output channels.\n            int\n        hidden_channels: Number of hidden channels.\n            int\n        n_convs: Number of convolutional layers.\n            int\n        activation: Activation function.\n            torch.nn.Module\n        batchnorm: If True a batch normalization layer is applied after every convolution.\n            bool\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "n_convs", ")", ":", "\n", "            ", "self", ".", "conv", ".", "append", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", "if", "idx", "==", "0", "else", "hidden_channels", ",", "\n", "hidden_channels", "if", "idx", "!=", "n_convs", "-", "1", "else", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", ")", "\n", ")", "\n", "if", "batchnorm", ":", "\n", "                ", "self", ".", "conv", ".", "append", "(", "nn", ".", "BatchNorm2d", "(", "hidden_channels", "if", "idx", "!=", "n_convs", "-", "1", "else", "out_channels", ",", "eps", "=", "1e-4", ")", ")", "\n", "", "if", "idx", "!=", "n_convs", "-", "1", ":", "\n", "                ", "self", ".", "conv", ".", "append", "(", "activation", ")", "\n", "", "", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "*", "self", ".", "conv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.conv.conv2d.Conv2d.forward": [[53, 70], ["conv2d.Conv2d.conv", "x.permute.permute.dim", "x.permute.permute.squeeze", "x.permute.permute.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Performs the forward pass of Conv2d.\n\n        Parameters\n        ----------\n        x: Input tensor.\n\n        Returns\n        -------\n        Convoluted output.\n        \"\"\"", "\n", "if", "x", ".", "dim", "(", ")", "==", "5", ":", "\n", "            ", "x", "=", "x", ".", "squeeze", "(", "1", ")", "\n", "if", "x", ".", "shape", "[", "-", "1", "]", "==", "2", ":", "\n", "                ", "x", "=", "x", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "", "", "return", "self", ".", "conv", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.rim.conv_layers.ConvRNNStack.__init__": [[11, 21], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "convs", ",", "rnn", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        convs: list of convolutional layers\n        rnn: list of RNN layers\n        \"\"\"", "\n", "super", "(", "ConvRNNStack", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "convs", "=", "convs", "\n", "self", ".", "rnn", "=", "rnn", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.conv_layers.ConvRNNStack.forward": [[22, 34], ["conv_layers.ConvRNNStack.rnn", "conv_layers.ConvRNNStack.convs"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "hidden", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        x: [batch_size, seq_len, input_size]\n        hidden: [num_layers * num_directions, batch_size, hidden_size\n\n        Returns\n        -------\n        output: [batch_size, seq_len, hidden_size]\n        \"\"\"", "\n", "return", "self", ".", "rnn", "(", "self", ".", "convs", "(", "x", ")", ",", "hidden", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.conv_layers.ConvNonlinear.__init__": [[39, 86], ["torch.Module.__init__", "conv_layers.ConvNonlinear.determine_conv_class", "conv_layers.ConvNonlinear.conv_class", "conv_layers.ConvNonlinear.reset_parameters", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "nonlinear.upper", "ValueError", "torch.nn.ReplicationPad1d", "torch.nn.ReplicationPad1d", "torch.nn.ReplicationPad1d", "torch.nn.ReplicationPad1d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad2d", "torch.nn.ReplicationPad3d", "torch.nn.ReplicationPad3d", "torch.nn.ReplicationPad3d", "torch.nn.ReplicationPad3d", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.determine_conv_class", "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.reset_parameters"], ["def", "__init__", "(", "self", ",", "input_size", ",", "features", ",", "conv_dim", ",", "kernel_size", ",", "dilation", ",", "bias", ",", "nonlinear", "=", "\"relu\"", ")", ":", "\n", "        ", "\"\"\"\n        Initializes the convolutional layer.\n\n        Parameters\n        ----------\n        input_size: number of input channels.\n        features: number of output channels.\n        conv_dim: number of dimensions of the convolutional layer.\n        kernel_size: size of the convolutional kernel.\n        dilation: dilation of the convolutional kernel.\n        bias: whether to use bias.\n        nonlinear: nonlinearity of the convolutional layer.\n        \"\"\"", "\n", "super", "(", "ConvNonlinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "features", "=", "features", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "conv_dim", "=", "conv_dim", "\n", "self", ".", "conv_class", "=", "self", ".", "determine_conv_class", "(", "conv_dim", ")", "\n", "\n", "if", "nonlinear", "is", "not", "None", "and", "nonlinear", ".", "upper", "(", ")", "==", "\"RELU\"", ":", "\n", "            ", "self", ".", "nonlinear", "=", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "", "elif", "nonlinear", "is", "None", ":", "\n", "            ", "self", ".", "nonlinear", "=", "lambda", "x", ":", "x", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Please specify a proper nonlinearity\"", ")", "\n", "\n", "", "self", ".", "padding", "=", "[", "\n", "torch", ".", "nn", ".", "ReplicationPad1d", "(", "torch", ".", "div", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", ".", "item", "(", ")", ")", ",", "\n", "torch", ".", "nn", ".", "ReplicationPad2d", "(", "torch", ".", "div", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", ".", "item", "(", ")", ")", ",", "\n", "torch", ".", "nn", ".", "ReplicationPad3d", "(", "torch", ".", "div", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", ".", "item", "(", ")", ")", ",", "\n", "]", "[", "conv_dim", "-", "1", "]", "\n", "\n", "self", ".", "conv_layer", "=", "self", ".", "conv_class", "(", "\n", "in_channels", "=", "input_size", ",", "\n", "out_channels", "=", "features", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "padding", "=", "0", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.conv_layers.ConvNonlinear.reset_parameters": [[87, 93], ["torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the parameters of the convolutional layer.\"\"\"", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "conv_layer", ".", "weight", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "\n", "if", "self", ".", "conv_layer", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "conv_layer", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.conv_layers.ConvNonlinear.determine_conv_class": [[94, 104], ["ValueError"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "determine_conv_class", "(", "n_dim", ")", ":", "\n", "        ", "\"\"\"Determines the convolutional layer class.\"\"\"", "\n", "if", "n_dim", "==", "1", ":", "\n", "            ", "return", "nn", ".", "Conv1d", "\n", "", "if", "n_dim", "==", "2", ":", "\n", "            ", "return", "nn", ".", "Conv2d", "\n", "", "if", "n_dim", "==", "3", ":", "\n", "            ", "return", "nn", ".", "Conv3d", "\n", "", "raise", "ValueError", "(", "f\"Convolution of: {n_dim} dims is not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.conv_layers.ConvNonlinear.extra_repr": [[105, 113], ["s.format"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.formaters.base.BaseFormatter.format"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Extra information about the layer.\"\"\"", "\n", "s", "=", "\"{input_size}, {features}\"", "\n", "if", "\"bias\"", "in", "self", ".", "__dict__", "and", "self", ".", "bias", "is", "not", "True", ":", "\n", "            ", "s", "+=", "\", bias={bias}\"", "\n", "", "if", "\"nonlinear\"", "in", "self", ".", "__dict__", "and", "self", ".", "nonlinear", "!=", "\"tanh\"", ":", "\n", "            ", "s", "+=", "\", nonlinearity={nonlinear}\"", "\n", "", "return", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.conv_layers.ConvNonlinear.check_forward_input": [[114, 118], ["_input.size", "RuntimeError", "_input.size"], "methods", ["None"], ["", "def", "check_forward_input", "(", "self", ",", "_input", ")", ":", "\n", "        ", "\"\"\"Checks input for correct size and shape.\"\"\"", "\n", "if", "_input", ".", "size", "(", "1", ")", "!=", "self", ".", "input_size", ":", "\n", "            ", "raise", "RuntimeError", "(", "f\"input has inconsistent input_size: got {_input.size(1)}, expected {self.input_size}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.conv_layers.ConvNonlinear.forward": [[119, 122], ["conv_layers.ConvNonlinear.nonlinear", "conv_layers.ConvNonlinear.conv_layer", "conv_layers.ConvNonlinear.padding"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "_input", ")", ":", "\n", "        ", "\"\"\"Forward pass of the convolutional layer.\"\"\"", "\n", "return", "self", ".", "nonlinear", "(", "self", ".", "conv_layer", "(", "self", ".", "padding", "(", "_input", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvGRUCellBase.__init__": [[14, 41], ["torch.Module.__init__", "rnn_cells.ConvGRUCellBase.determine_conv_class", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "rnn_cells.ConvGRUCellBase.reset_parameters", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.determine_conv_class", "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.reset_parameters"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "conv_dim", ",", "kernel_size", ",", "dilation", ",", "bias", ")", ":", "\n", "        ", "super", "(", "ConvGRUCellBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "conv_dim", "=", "conv_dim", "\n", "self", ".", "conv_class", "=", "self", ".", "determine_conv_class", "(", "conv_dim", ")", "\n", "\n", "self", ".", "ih", "=", "nn", ".", "Conv2d", "(", "\n", "input_size", ",", "\n", "3", "*", "hidden_size", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "torch", ".", "div", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", ".", "item", "(", ")", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", "self", ".", "hh", "=", "nn", ".", "Conv2d", "(", "\n", "hidden_size", ",", "\n", "3", "*", "hidden_size", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "torch", ".", "div", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", ".", "item", "(", ")", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvGRUCellBase.reset_parameters": [[42, 49], ["rnn_cells.ConvGRUCellBase.orthotogonalize_weights", "rnn_cells.ConvGRUCellBase.orthotogonalize_weights", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.orthotogonalize_weights", "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.orthotogonalize_weights"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize parameters following the way proposed in the paper.\"\"\"", "\n", "self", ".", "ih", ".", "weight", ".", "data", "=", "self", ".", "orthotogonalize_weights", "(", "self", ".", "ih", ".", "weight", ".", "data", ")", "\n", "self", ".", "hh", ".", "weight", ".", "data", "=", "self", ".", "orthotogonalize_weights", "(", "self", ".", "hh", ".", "weight", ".", "data", ")", "\n", "\n", "if", "self", ".", "bias", "is", "True", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "ih", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvGRUCellBase.orthotogonalize_weights": [[50, 54], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.init.orthogonal_", "torch.init.orthogonal_", "weights.chunk"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "orthotogonalize_weights", "(", "weights", ",", "chunks", "=", "1", ")", ":", "\n", "        ", "\"\"\"Orthogonalize the weights of a convolutional layer.\"\"\"", "\n", "return", "torch", ".", "cat", "(", "[", "nn", ".", "init", ".", "orthogonal_", "(", "w", ")", "for", "w", "in", "weights", ".", "chunk", "(", "chunks", ",", "0", ")", "]", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvGRUCellBase.determine_conv_class": [[55, 65], ["NotImplementedError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "determine_conv_class", "(", "n_dim", ")", ":", "\n", "        ", "\"\"\"Determine the convolutional class to use.\"\"\"", "\n", "if", "n_dim", "==", "1", ":", "\n", "            ", "return", "nn", ".", "Conv1d", "\n", "", "if", "n_dim", "==", "2", ":", "\n", "            ", "return", "nn", ".", "Conv2d", "\n", "", "if", "n_dim", "==", "3", ":", "\n", "            ", "return", "nn", ".", "Conv3d", "\n", "", "raise", "NotImplementedError", "(", "\"No convolution of this dimensionality implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvGRUCellBase.extra_repr": [[66, 74], ["s.format"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.formaters.base.BaseFormatter.format"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Extra information to be printed when printing the model.\"\"\"", "\n", "s", "=", "\"{input_size}, {hidden_size}\"", "\n", "if", "\"bias\"", "in", "self", ".", "__dict__", "and", "self", ".", "bias", "is", "not", "True", ":", "\n", "            ", "s", "+=", "\", bias={bias}\"", "\n", "", "if", "\"nonlinearity\"", "in", "self", ".", "__dict__", "and", "self", ".", "nonlinearity", "!=", "\"tanh\"", ":", "\n", "            ", "s", "+=", "\", nonlinearity={nonlinearity}\"", "\n", "", "return", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvGRUCellBase.check_forward_input": [[75, 79], ["_input.size", "RuntimeError", "_input.size"], "methods", ["None"], ["", "def", "check_forward_input", "(", "self", ",", "_input", ")", ":", "\n", "        ", "\"\"\"Check forward input.\"\"\"", "\n", "if", "_input", ".", "size", "(", "1", ")", "!=", "self", ".", "input_size", ":", "\n", "            ", "raise", "RuntimeError", "(", "f\"input has inconsistent input_size: got {_input.size(1)}, expected {self.input_size}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvGRUCellBase.check_forward_hidden": [[80, 90], ["_input.size", "hx.size", "RuntimeError", "hx.size", "RuntimeError", "_input.size", "hx.size", "hx.size"], "methods", ["None"], ["", "", "def", "check_forward_hidden", "(", "self", ",", "_input", ",", "hx", ",", "hidden_label", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"Check forward hidden.\"\"\"", "\n", "if", "_input", ".", "size", "(", "0", ")", "!=", "hx", ".", "size", "(", "0", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "f\"Input batch size {_input.size(0)} doesn't match hidden{hidden_label} batch size {hx.size(0)}\"", "\n", ")", "\n", "\n", "", "if", "hx", ".", "size", "(", "1", ")", "!=", "self", ".", "hidden_size", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "f\"hidden{hidden_label} has inconsistent hidden_size: got {hx.size(1)}, expected {self.hidden_size}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvGRUCell.__init__": [[96, 110], ["rnn_cells.ConvGRUCellBase.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "conv_dim", ",", "kernel_size", ",", "dilation", "=", "1", ",", "bias", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the ConvGRUCell.\n\n        Parameters\n        ----------\n        input_size: The number of channels in the input.\n        hidden_size: The number of channels in the hidden state.\n        conv_dim: The number of dimensions of the convolutional layer.\n        kernel_size: The size of the convolutional kernel.\n        dilation: The dilation of the convolutional kernel.\n        bias: Whether to add a bias.\n        \"\"\"", "\n", "super", "(", "ConvGRUCell", ",", "self", ")", ".", "__init__", "(", "input_size", ",", "hidden_size", ",", "conv_dim", ",", "kernel_size", ",", "dilation", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvGRUCell.forward": [[111, 123], ["rnn_cells.ConvGRUCell.ih().chunk", "rnn_cells.ConvGRUCell.hh().chunk", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "rnn_cells.ConvGRUCell.ih", "rnn_cells.ConvGRUCell.hh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "_input", ",", "hx", ")", ":", "\n", "        ", "\"\"\"Forward pass of the ConvGRUCell.\"\"\"", "\n", "ih", "=", "self", ".", "ih", "(", "_input", ")", ".", "chunk", "(", "3", ",", "1", ")", "\n", "hh", "=", "self", ".", "hh", "(", "hx", ")", ".", "chunk", "(", "3", ",", "1", ")", "\n", "\n", "r", "=", "torch", ".", "sigmoid", "(", "ih", "[", "0", "]", "+", "hh", "[", "0", "]", ")", "\n", "z", "=", "torch", ".", "sigmoid", "(", "ih", "[", "1", "]", "+", "hh", "[", "1", "]", ")", "\n", "n", "=", "torch", ".", "tanh", "(", "ih", "[", "2", "]", "+", "r", "*", "hh", "[", "2", "]", ")", "\n", "\n", "hx", "=", "n", "*", "(", "1", "-", "z", ")", "+", "z", "*", "hx", "\n", "\n", "return", "hx", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvMGUCellBase.__init__": [[131, 170], ["torch.Module.__init__", "rnn_cells.ConvMGUCellBase.determine_conv_class", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "rnn_cells.ConvMGUCellBase.reset_parameters", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.determine_conv_class", "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.reset_parameters"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "conv_dim", ",", "kernel_size", ",", "dilation", ",", "bias", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the ConvMGUCellBase.\n\n        Parameters\n        ----------\n        input_size: The number of channels in the input.\n        hidden_size: The number of channels in the hidden state.\n        conv_dim: The number of dimensions of the convolutional layer.\n        kernel_size: The size of the convolutional kernel.\n        dilation: The dilation of the convolutional kernel.\n        bias: Whether to add a bias.\n        \"\"\"", "\n", "super", "(", "ConvMGUCellBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "conv_dim", "=", "conv_dim", "\n", "self", ".", "conv_class", "=", "self", ".", "determine_conv_class", "(", "conv_dim", ")", "\n", "\n", "self", ".", "ih", "=", "nn", ".", "Conv2d", "(", "\n", "input_size", ",", "\n", "2", "*", "hidden_size", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "torch", ".", "div", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", ".", "item", "(", ")", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", "self", ".", "hh", "=", "nn", ".", "Conv2d", "(", "\n", "hidden_size", ",", "\n", "2", "*", "hidden_size", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "torch", ".", "div", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", ".", "item", "(", ")", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvMGUCellBase.reset_parameters": [[171, 181], ["rnn_cells.ConvMGUCellBase.orthotogonalize_weights", "rnn_cells.ConvMGUCellBase.orthotogonalize_weights", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.calculate_gain", "torch.init.calculate_gain", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.orthotogonalize_weights", "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.orthotogonalize_weights"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the parameters.\"\"\"", "\n", "self", ".", "ih", ".", "weight", ".", "data", "=", "self", ".", "orthotogonalize_weights", "(", "self", ".", "ih", ".", "weight", ".", "data", ")", "\n", "self", ".", "hh", ".", "weight", ".", "data", "=", "self", ".", "orthotogonalize_weights", "(", "self", ".", "hh", ".", "weight", ".", "data", ")", "\n", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "ih", ".", "weight", ",", "nn", ".", "init", ".", "calculate_gain", "(", "\"relu\"", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "hh", ".", "weight", ")", "\n", "\n", "if", "self", ".", "bias", "is", "True", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "ih", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvMGUCellBase.orthotogonalize_weights": [[182, 186], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.init.orthogonal_", "torch.init.orthogonal_", "weights.chunk"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "orthotogonalize_weights", "(", "weights", ",", "chunks", "=", "1", ")", ":", "\n", "        ", "\"\"\"Orthogonalize the weights.\"\"\"", "\n", "return", "torch", ".", "cat", "(", "[", "nn", ".", "init", ".", "orthogonal_", "(", "w", ")", "for", "w", "in", "weights", ".", "chunk", "(", "chunks", ",", "0", ")", "]", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvMGUCellBase.determine_conv_class": [[187, 197], ["ValueError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "determine_conv_class", "(", "n_dim", ")", ":", "\n", "        ", "\"\"\"Determine the convolutional class.\"\"\"", "\n", "if", "n_dim", "==", "1", ":", "\n", "            ", "return", "nn", ".", "Conv1d", "\n", "", "if", "n_dim", "==", "2", ":", "\n", "            ", "return", "nn", ".", "Conv2d", "\n", "", "if", "n_dim", "==", "3", ":", "\n", "            ", "return", "nn", ".", "Conv3d", "\n", "", "raise", "ValueError", "(", "f\"Convolution of: {n_dim} dims is not implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvMGUCellBase.extra_repr": [[198, 206], ["s.format"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.formaters.base.BaseFormatter.format"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Extra information about the ConvMGUCellBase.\"\"\"", "\n", "s", "=", "\"{input_size}, {hidden_size}\"", "\n", "if", "\"bias\"", "in", "self", ".", "__dict__", "and", "self", ".", "bias", "is", "not", "True", ":", "\n", "            ", "s", "+=", "\", bias={bias}\"", "\n", "", "if", "\"nonlinearity\"", "in", "self", ".", "__dict__", "and", "self", ".", "nonlinearity", "!=", "\"tanh\"", ":", "\n", "            ", "s", "+=", "\", nonlinearity={nonlinearity}\"", "\n", "", "return", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvMGUCellBase.check_forward_input": [[207, 211], ["_input.size", "RuntimeError", "_input.size"], "methods", ["None"], ["", "def", "check_forward_input", "(", "self", ",", "_input", ")", ":", "\n", "        ", "\"\"\"Check the forward input.\"\"\"", "\n", "if", "_input", ".", "size", "(", "1", ")", "!=", "self", ".", "input_size", ":", "\n", "            ", "raise", "RuntimeError", "(", "f\"input has inconsistent input_size: got {_input.size(1)}, expected {self.input_size}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvMGUCellBase.check_forward_hidden": [[212, 222], ["_input.size", "hx.size", "RuntimeError", "hx.size", "RuntimeError", "_input.size", "hx.size", "hx.size"], "methods", ["None"], ["", "", "def", "check_forward_hidden", "(", "self", ",", "_input", ",", "hx", ",", "hidden_label", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"Check the forward hidden.\"\"\"", "\n", "if", "_input", ".", "size", "(", "0", ")", "!=", "hx", ".", "size", "(", "0", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "f\"Input batch size {_input.size(0)} doesn't match hidden{hidden_label} batch size {hx.size(0)}\"", "\n", ")", "\n", "\n", "", "if", "hx", ".", "size", "(", "1", ")", "!=", "self", ".", "hidden_size", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "f\"hidden{hidden_label} has inconsistent hidden_size: got {hx.size(1)}, expected {self.hidden_size}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvMGUCell.__init__": [[228, 242], ["rnn_cells.ConvMGUCellBase.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "conv_dim", ",", "kernel_size", ",", "dilation", "=", "1", ",", "bias", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the ConvMGUCell.\n\n        Parameters\n        ----------\n        input_size: The input size.\n        hidden_size: The hidden size.\n        conv_dim: The convolutional dimension.\n        kernel_size: The kernel size.\n        dilation: The dilation.\n        bias: Whether to use a bias.\n        \"\"\"", "\n", "super", "(", "ConvMGUCell", ",", "self", ")", ".", "__init__", "(", "input_size", ",", "hidden_size", ",", "conv_dim", ",", "kernel_size", ",", "dilation", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.ConvMGUCell.forward": [[243, 252], ["rnn_cells.ConvMGUCell.ih().chunk", "rnn_cells.ConvMGUCell.hh().chunk", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "rnn_cells.ConvMGUCell.ih", "rnn_cells.ConvMGUCell.hh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "_input", ",", "hx", ")", ":", "\n", "        ", "\"\"\"Forward the ConvMGUCell.\"\"\"", "\n", "ih", "=", "self", ".", "ih", "(", "_input", ")", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "hh", "=", "self", ".", "hh", "(", "hx", ")", ".", "chunk", "(", "2", ",", "dim", "=", "1", ")", "\n", "\n", "f", "=", "torch", ".", "sigmoid", "(", "ih", "[", "0", "]", "+", "hh", "[", "0", "]", ")", "\n", "c", "=", "torch", ".", "tanh", "(", "ih", "[", "1", "]", "+", "f", "*", "hh", "[", "1", "]", ")", "\n", "\n", "return", "c", "+", "f", "*", "(", "hx", "-", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.__init__": [[263, 298], ["torch.Module.__init__", "rnn_cells.IndRNNCellBase.determine_conv_class", "torch.Conv2d", "torch.Conv2d", "torch.Parameter", "torch.Parameter", "rnn_cells.IndRNNCellBase.reset_parameters", "torch.init.normal_", "torch.init.normal_", "torch.div().item", "torch.div().item", "torch.div().item", "torch.div().item", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.div", "torch.div", "torch.div", "torch.div"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.determine_conv_class", "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.reset_parameters"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "conv_dim", ",", "kernel_size", ",", "dilation", ",", "bias", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the IndRNNCellBase.\n\n        Parameters\n        ----------\n        input_size: The input size.\n        hidden_size: The hidden size.\n        conv_dim: The convolutional dimension.\n        kernel_size: The kernel size.\n        dilation: The dilation.\n        bias: Whether to use a bias.\n        \"\"\"", "\n", "super", "(", "IndRNNCellBase", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "conv_dim", "=", "conv_dim", "\n", "self", ".", "conv_class", "=", "self", ".", "determine_conv_class", "(", "conv_dim", ")", "\n", "\n", "self", ".", "ih", "=", "nn", ".", "Conv2d", "(", "\n", "input_size", ",", "\n", "hidden_size", ",", "\n", "kernel_size", ",", "\n", "padding", "=", "torch", ".", "div", "(", "dilation", "*", "(", "kernel_size", "-", "1", ")", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", ".", "item", "(", ")", ",", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "bias", ",", "\n", ")", "\n", "self", ".", "hh", "=", "nn", ".", "Parameter", "(", "\n", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "1", ",", "hidden_size", ",", "1", ",", "1", ")", ",", "std", "=", "1.0", "/", "(", "hidden_size", "*", "(", "1", "+", "kernel_size", "**", "2", ")", ")", ")", "\n", ")", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.reset_parameters": [[299, 307], ["rnn_cells.IndRNNCellBase.orthotogonalize_weights", "torch.init.normal_", "torch.init.normal_", "torch.init.zeros_", "torch.init.zeros_"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.orthotogonalize_weights"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the parameters.\"\"\"", "\n", "self", ".", "ih", ".", "weight", ".", "data", "=", "self", ".", "orthotogonalize_weights", "(", "self", ".", "ih", ".", "weight", ".", "data", ")", "\n", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "ih", ".", "weight", ",", "std", "=", "1.0", "/", "(", "self", ".", "hidden_size", "*", "(", "1", "+", "self", ".", "kernel_size", "**", "2", ")", ")", ")", "\n", "\n", "if", "self", ".", "bias", "is", "True", ":", "\n", "            ", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "ih", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.orthotogonalize_weights": [[308, 312], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.init.orthogonal_", "torch.init.orthogonal_", "weights.chunk"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "orthotogonalize_weights", "(", "weights", ",", "chunks", "=", "1", ")", ":", "\n", "        ", "\"\"\"Orthogonalize the weights.\"\"\"", "\n", "return", "torch", ".", "cat", "(", "[", "nn", ".", "init", ".", "orthogonal_", "(", "w", ")", "for", "w", "in", "weights", ".", "chunk", "(", "chunks", ",", "0", ")", "]", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.determine_conv_class": [[313, 323], ["NotImplementedError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "determine_conv_class", "(", "n_dim", ")", ":", "\n", "        ", "\"\"\"Determine the convolutional class.\"\"\"", "\n", "if", "n_dim", "==", "1", ":", "\n", "            ", "return", "nn", ".", "Conv1d", "\n", "", "if", "n_dim", "==", "2", ":", "\n", "            ", "return", "nn", ".", "Conv2d", "\n", "", "if", "n_dim", "==", "3", ":", "\n", "            ", "return", "nn", ".", "Conv3d", "\n", "", "raise", "NotImplementedError", "(", "\"No convolution of this dimensionality implemented\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.extra_repr": [[324, 332], ["s.format"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.formaters.base.BaseFormatter.format"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Extra information about the module, used for printing.\"\"\"", "\n", "s", "=", "\"{input_size}, {hidden_size}\"", "\n", "if", "\"bias\"", "in", "self", ".", "__dict__", "and", "self", ".", "bias", "is", "not", "True", ":", "\n", "            ", "s", "+=", "\", bias={bias}\"", "\n", "", "if", "\"nonlinearity\"", "in", "self", ".", "__dict__", "and", "self", ".", "nonlinearity", "!=", "\"tanh\"", ":", "\n", "            ", "s", "+=", "\", nonlinearity={nonlinearity}\"", "\n", "", "return", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.check_forward_input": [[333, 337], ["_input.size", "RuntimeError", "_input.size"], "methods", ["None"], ["", "def", "check_forward_input", "(", "self", ",", "_input", ")", ":", "\n", "        ", "\"\"\"Check forward input.\"\"\"", "\n", "if", "_input", ".", "size", "(", "1", ")", "!=", "self", ".", "input_size", ":", "\n", "            ", "raise", "RuntimeError", "(", "f\"input has inconsistent input_size: got {_input.size(1)}, expected {self.input_size}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCellBase.check_forward_hidden": [[338, 348], ["_input.size", "hx.size", "RuntimeError", "hx.size", "RuntimeError", "_input.size", "hx.size", "hx.size"], "methods", ["None"], ["", "", "def", "check_forward_hidden", "(", "self", ",", "_input", ",", "hx", ",", "hidden_label", "=", "\"\"", ")", ":", "\n", "        ", "\"\"\"Check forward hidden.\"\"\"", "\n", "if", "_input", ".", "size", "(", "0", ")", "!=", "hx", ".", "size", "(", "0", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "f\"Input batch size {_input.size(0)} doesn't match hidden{hidden_label} batch size {hx.size(0)}\"", "\n", ")", "\n", "\n", "", "if", "hx", ".", "size", "(", "1", ")", "!=", "self", ".", "hidden_size", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "f\"hidden{hidden_label} has inconsistent hidden_size: got {hx.size(1)}, expected {self.hidden_size}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCell.__init__": [[354, 366], ["rnn_cells.IndRNNCellBase.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "conv_dim", ",", "kernel_size", ",", "dilation", "=", "1", ",", "bias", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        input_size: The number of expected features in the input.\n        hidden_size: The number of features in the hidden state.\n        conv_dim: The dimension of the convolutional layer.\n        kernel_size: The size of the convolved kernel.\n        dilation: The spacing between the kernel points.\n        bias: If ``False``, then the layer does not use bias weights `b_ih` and `b_hh`.\n        \"\"\"", "\n", "super", "(", "IndRNNCell", ",", "self", ")", ".", "__init__", "(", "input_size", ",", "hidden_size", ",", "conv_dim", ",", "kernel_size", ",", "dilation", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rnn_cells.IndRNNCell.forward": [[367, 370], ["torch.ReLU", "torch.ReLU", "rnn_cells.IndRNNCell.ih"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "_input", ",", "hx", ")", ":", "\n", "        ", "\"\"\"Forward propagate the RNN cell.\"\"\"", "\n", "return", "nn", ".", "ReLU", "(", ")", "(", "self", ".", "ih", "(", "_input", ")", "+", "self", ".", "hh", "*", "hx", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.rim.utils.log_likelihood_gradient": [[11, 72], ["map", "sense.chunk", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.fft.ifft2.chunk", "eta_real.squeeze.squeeze", "eta_imag.squeeze.squeeze", "torch.cat().unsqueeze().squeeze", "eta.chunk", "torch.sum", "torch.sum", "torch.unsqueeze", "torch.cat().unsqueeze", "mridc.collections.common.parts.fft.fft2", "torch.cat", "torch.cat"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2"], ["from", "mridc", ".", "utils", ".", "env_var_parsing", "import", "get_envbool", "\n", "\n", "\n", "def", "check_color_support", "(", ")", ":", "\n", "    ", "\"\"\"\n\n    Returns\n    -------\n    True if the terminal supports color, False otherwise.\n        bool\n    \"\"\"", "\n", "# Colors can be forced with an env variable", "\n", "return", "bool", "(", "not", "sys", ".", "platform", ".", "lower", "(", ")", ".", "startswith", "(", "\"win\"", ")", "and", "get_envbool", "(", "MRIDC_ENV_VARNAME_ENABLE_COLORING", ",", "False", ")", ")", "\n", "\n", "\n", "", "def", "to_unicode", "(", "value", ")", ":", "\n", "    ", "\"\"\"\n    Converts a string to unicode. If the string is already unicode, it is returned as is. If it is a byte string, it is\n    decoded using utf-8.\n\n    Parameters\n    ----------\n    value: The string to convert.\n        str\n\n    Returns\n    -------\n    The converted string.\n        str\n    \"\"\"", "\n", "try", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "(", "str", ",", "type", "(", "None", ")", ")", ")", ":", "\n", "            ", "return", "value", "\n", "\n", "", "if", "not", "isinstance", "(", "value", ",", "bytes", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Expected bytes, unicode, or None; got %r\"", "%", "type", "(", "value", ")", ")", "\n", "\n", "", "return", "value", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "", "except", "UnicodeDecodeError", ":", "\n", "        ", "return", "repr", "(", "value", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rim_block.RIMBlock.__init__": [[18, 131], ["super().__init__", "torch.nn.ModuleList", "zip", "torch.nn.Sequential", "zip", "zip", "torch.nn.Parameter", "torch.zeros", "mridc.collections.reconstruction.models.rim.conv_layers.ConvNonlinear", "rnn_type", "rim_block.RIMBlock.layers.append", "torch.ones", "rnn_type.upper", "mridc.collections.reconstruction.models.rim.conv_layers.ConvRNNStack", "rnn_type.upper", "rnn_type.upper", "ValueError"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "recurrent_layer", "=", "None", ",", "\n", "conv_filters", "=", "None", ",", "\n", "conv_kernels", "=", "None", ",", "\n", "conv_dilations", "=", "None", ",", "\n", "conv_bias", "=", "None", ",", "\n", "recurrent_filters", "=", "None", ",", "\n", "recurrent_kernels", "=", "None", ",", "\n", "recurrent_dilations", "=", "None", ",", "\n", "recurrent_bias", "=", "None", ",", "\n", "depth", ":", "int", "=", "2", ",", "\n", "time_steps", ":", "int", "=", "8", ",", "\n", "conv_dim", ":", "int", "=", "2", ",", "\n", "no_dc", ":", "bool", "=", "False", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the RIMBlock.\n\n        Parameters\n        ----------\n        recurrent_layer: Type of recurrent layer.\n        conv_filters: Number of filters in the convolutional layers.\n        conv_kernels: Kernel size of the convolutional layers.\n        conv_dilations: Dilation of the convolutional layers.\n        conv_bias: Bias of the convolutional layers.\n        recurrent_filters: Number of filters in the recurrent layers.\n        recurrent_kernels: Kernel size of the recurrent layers.\n        recurrent_dilations: Dilation of the recurrent layers.\n        recurrent_bias: Bias of the recurrent layers.\n        depth: Number of layers in the block.\n        time_steps: Number of time steps in the block.\n        conv_dim: Dimension of the convolutional layers.\n        no_dc: If True, the DC component is removed from the input.\n        fft_centered: If True, the FFT is centered.\n        fft_normalization: Normalization of the FFT.\n        spatial_dims: Spatial dimensions of the input.\n        coil_dim: Coils dimension of the input.\n        \"\"\"", "\n", "super", "(", "RIMBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_size", "=", "depth", "*", "2", "\n", "self", ".", "time_steps", "=", "time_steps", "\n", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "for", "(", "\n", "(", "conv_features", ",", "conv_k_size", ",", "conv_dilation", ",", "l_conv_bias", ",", "nonlinear", ")", ",", "\n", "(", "rnn_features", ",", "rnn_k_size", ",", "rnn_dilation", ",", "rnn_bias", ",", "rnn_type", ")", ",", "\n", ")", "in", "zip", "(", "\n", "zip", "(", "conv_filters", ",", "conv_kernels", ",", "conv_dilations", ",", "conv_bias", ",", "[", "\"relu\"", ",", "\"relu\"", ",", "None", "]", ")", ",", "\n", "zip", "(", "\n", "recurrent_filters", ",", "\n", "recurrent_kernels", ",", "\n", "recurrent_dilations", ",", "\n", "recurrent_bias", ",", "\n", "[", "recurrent_layer", ",", "recurrent_layer", ",", "None", "]", ",", "\n", ")", ",", "\n", ")", ":", "\n", "            ", "conv_layer", "=", "None", "\n", "\n", "if", "conv_features", "!=", "0", ":", "\n", "                ", "conv_layer", "=", "ConvNonlinear", "(", "\n", "self", ".", "input_size", ",", "\n", "conv_features", ",", "\n", "conv_dim", "=", "conv_dim", ",", "\n", "kernel_size", "=", "conv_k_size", ",", "\n", "dilation", "=", "conv_dilation", ",", "\n", "bias", "=", "l_conv_bias", ",", "\n", "nonlinear", "=", "nonlinear", ",", "\n", ")", "\n", "self", ".", "input_size", "=", "conv_features", "\n", "\n", "", "if", "rnn_features", "!=", "0", "and", "rnn_type", "is", "not", "None", ":", "\n", "                ", "if", "rnn_type", ".", "upper", "(", ")", "==", "\"GRU\"", ":", "\n", "                    ", "rnn_type", "=", "ConvGRUCell", "\n", "", "elif", "rnn_type", ".", "upper", "(", ")", "==", "\"MGU\"", ":", "\n", "                    ", "rnn_type", "=", "ConvMGUCell", "\n", "", "elif", "rnn_type", ".", "upper", "(", ")", "==", "\"INDRNN\"", ":", "\n", "                    ", "rnn_type", "=", "IndRNNCell", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\"Please specify a proper recurrent layer type.\"", ")", "\n", "\n", "", "rnn_layer", "=", "rnn_type", "(", "\n", "self", ".", "input_size", ",", "\n", "rnn_features", ",", "\n", "conv_dim", "=", "2", ",", "\n", "kernel_size", "=", "rnn_k_size", ",", "\n", "dilation", "=", "rnn_dilation", ",", "\n", "bias", "=", "rnn_bias", ",", "\n", ")", "\n", "\n", "self", ".", "input_size", "=", "rnn_features", "\n", "\n", "self", ".", "layers", ".", "append", "(", "ConvRNNStack", "(", "conv_layer", ",", "rnn_layer", ")", ")", "\n", "\n", "", "", "self", ".", "final_layer", "=", "torch", ".", "nn", ".", "Sequential", "(", "conv_layer", ")", "\n", "\n", "self", ".", "recurrent_filters", "=", "recurrent_filters", "\n", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "self", ".", "coil_dim", "=", "coil_dim", "\n", "\n", "self", ".", "no_dc", "=", "no_dc", "\n", "\n", "if", "not", "self", ".", "no_dc", ":", "\n", "            ", "self", ".", "dc_weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ")", ")", "\n", "self", ".", "zero", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.rim.rim_block.RIMBlock.forward": [[132, 229], ["isinstance", "range", "pred[].detach", "mridc.collections.reconstruction.models.rim.utils.log_likelihood_gradient().contiguous", "enumerate", "etas.append", "torch.where", "masked_kspace.new_zeros", "torch.sum", "convrnn", "rim_block.RIMBlock.final_layer().permute", "rim_block.RIMBlock.zero.to", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.utils.complex_mul", "mridc.collections.reconstruction.models.rim.utils.log_likelihood_gradient", "mridc.collections.common.parts.utils.complex_mul", "masked_kspace.size", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj", "rim_block.RIMBlock.final_layer", "e.unsqueeze", "masked_kspace.size"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.rim.utils.log_likelihood_gradient", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "pred", ":", "torch", ".", "Tensor", ",", "\n", "masked_kspace", ":", "torch", ".", "Tensor", ",", "\n", "sense", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", ",", "\n", "eta", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "hx", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "sigma", ":", "float", "=", "1.0", ",", "\n", "keep_eta", ":", "bool", "=", "False", ",", "\n", ")", "->", "Tuple", "[", "Any", ",", "Union", "[", "list", ",", "torch", ".", "Tensor", ",", "None", "]", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass of the RIMBlock.\n\n        Parameters\n        ----------\n        pred: Predicted k-space.\n        masked_kspace: Subsampled k-space.\n        sense: Coil sensitivity maps.\n        mask: Sample mask.\n        eta: Initial guess for the eta.\n        hx: Initial guess for the hidden state.\n        sigma: Noise level.\n        keep_eta: Whether to keep the eta.\n\n        Returns\n        -------\n        Reconstructed image and hidden states.\n        \"\"\"", "\n", "if", "hx", "is", "None", ":", "\n", "            ", "hx", "=", "[", "\n", "masked_kspace", ".", "new_zeros", "(", "(", "masked_kspace", ".", "size", "(", "0", ")", ",", "f", ",", "*", "masked_kspace", ".", "size", "(", ")", "[", "2", ":", "-", "1", "]", ")", ")", "\n", "for", "f", "in", "self", ".", "recurrent_filters", "\n", "if", "f", "!=", "0", "\n", "]", "\n", "\n", "", "if", "isinstance", "(", "pred", ",", "list", ")", ":", "\n", "            ", "pred", "=", "pred", "[", "-", "1", "]", ".", "detach", "(", ")", "\n", "\n", "", "if", "eta", "is", "None", "or", "eta", ".", "ndim", "<", "3", ":", "\n", "            ", "eta", "=", "(", "\n", "pred", "\n", "if", "keep_eta", "\n", "else", "torch", ".", "sum", "(", "\n", "complex_mul", "(", "\n", "ifft2", "(", "\n", "pred", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "complex_conj", "(", "sense", ")", ",", "\n", ")", ",", "\n", "self", ".", "coil_dim", ",", "\n", ")", "\n", ")", "\n", "\n", "", "etas", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "time_steps", ")", ":", "\n", "            ", "grad_eta", "=", "log_likelihood_gradient", "(", "\n", "eta", ",", "\n", "masked_kspace", ",", "\n", "sense", ",", "\n", "mask", ",", "\n", "sigma", "=", "sigma", ",", "\n", "fft_centered", "=", "self", ".", "fft_centered", ",", "\n", "fft_normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", "coil_dim", "=", "self", ".", "coil_dim", ",", "\n", ")", ".", "contiguous", "(", ")", "\n", "\n", "for", "h", ",", "convrnn", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hx", "[", "h", "]", "=", "convrnn", "(", "grad_eta", ",", "hx", "[", "h", "]", ")", "\n", "grad_eta", "=", "hx", "[", "h", "]", "\n", "\n", "", "eta", "=", "eta", "+", "self", ".", "final_layer", "(", "grad_eta", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "etas", ".", "append", "(", "eta", ")", "\n", "\n", "", "eta", "=", "etas", "\n", "\n", "if", "self", ".", "no_dc", ":", "\n", "            ", "return", "eta", ",", "None", "\n", "\n", "", "soft_dc", "=", "torch", ".", "where", "(", "mask", ",", "pred", "-", "masked_kspace", ",", "self", ".", "zero", ".", "to", "(", "masked_kspace", ")", ")", "*", "self", ".", "dc_weight", "\n", "current_kspace", "=", "[", "\n", "masked_kspace", "\n", "-", "soft_dc", "\n", "-", "fft2", "(", "\n", "complex_mul", "(", "e", ".", "unsqueeze", "(", "self", ".", "coil_dim", ")", ",", "sense", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "for", "e", "in", "eta", "\n", "]", "\n", "\n", "return", "current_kspace", ",", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.Metrics.__init__": [[64, 76], ["runstats.Statistics"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "metric_funcs", ",", "output_path", ",", "method", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        metric_funcs (dict): A dict where the keys are metric names and the values are Python functions for evaluating\n        that metric.\n        output_path: path to the output directory\n        method: reconstruction method\n        \"\"\"", "\n", "self", ".", "metrics_scores", "=", "{", "metric", ":", "Statistics", "(", ")", "for", "metric", "in", "metric_funcs", "}", "\n", "self", ".", "output_path", "=", "output_path", "\n", "self", ".", "method", "=", "method", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.Metrics.push": [[77, 92], ["METRIC_FUNCS.items", "evaluate.Metrics.metrics_scores[].push", "func"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.Metrics.push"], ["", "def", "push", "(", "self", ",", "target", ",", "recons", ")", ":", "\n", "        ", "\"\"\"\n        Pushes a new batch of metrics to the running statistics.\n\n        Parameters\n        ----------\n        target: target image\n        recons: reconstructed image\n\n        Returns\n        -------\n        dict: A dict where the keys are metric names and the values are\n        \"\"\"", "\n", "for", "metric", ",", "func", "in", "METRIC_FUNCS", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "metrics_scores", "[", "metric", "]", ".", "push", "(", "func", "(", "target", ",", "recons", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.Metrics.means": [[93, 96], ["stat.mean", "evaluate.Metrics.metrics_scores.items"], "methods", ["None"], ["", "", "def", "means", "(", "self", ")", ":", "\n", "        ", "\"\"\"Mean of the means of each metric.\"\"\"", "\n", "return", "{", "metric", ":", "stat", ".", "mean", "(", ")", "for", "metric", ",", "stat", "in", "self", ".", "metrics_scores", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.Metrics.stddevs": [[97, 100], ["stat.stddev", "evaluate.Metrics.metrics_scores.items"], "methods", ["None"], ["", "def", "stddevs", "(", "self", ")", ":", "\n", "        ", "\"\"\"Standard deviation of the means of each metric.\"\"\"", "\n", "return", "{", "metric", ":", "stat", ".", "stddev", "(", ")", "for", "metric", ",", "stat", "in", "self", ".", "metrics_scores", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.Metrics.__repr__": [[101, 113], ["evaluate.Metrics.means", "evaluate.Metrics.stddevs", "sorted", "list", "open", "output.write"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.Metrics.means", "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.Metrics.stddevs"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Representation of the metrics.\"\"\"", "\n", "means", "=", "self", ".", "means", "(", ")", "\n", "stddevs", "=", "self", ".", "stddevs", "(", ")", "\n", "metric_names", "=", "sorted", "(", "list", "(", "means", ")", ")", "\n", "\n", "res", "=", "\" \"", ".", "join", "(", "f\"{name} = {means[name]:.4g} +/- {2 * stddevs[name]:.4g}\"", "for", "name", "in", "metric_names", ")", "+", "\"\\n\"", "\n", "\n", "with", "open", "(", "f\"{self.output_path}metrics.txt\"", ",", "\"a\"", ")", "as", "output", ":", "\n", "            ", "output", ".", "write", "(", "f\"{self.method}: {res}\"", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.mse": [[25, 28], ["numpy.mean"], "function", ["None"], ["def", "mse", "(", "gt", ":", "np", ".", "ndarray", ",", "pred", ":", "np", ".", "ndarray", ")", "->", "float", ":", "\n", "    ", "\"\"\"Compute Mean Squared Error (MSE)\"\"\"", "\n", "return", "np", ".", "mean", "(", "(", "gt", "-", "pred", ")", "**", "2", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.nmse": [[30, 33], ["numpy.linalg.norm", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.norm", "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.norm"], ["", "def", "nmse", "(", "gt", ":", "np", ".", "ndarray", ",", "pred", ":", "np", ".", "ndarray", ")", "->", "float", ":", "\n", "    ", "\"\"\"Compute Normalized Mean Squared Error (NMSE)\"\"\"", "\n", "return", "np", ".", "linalg", ".", "norm", "(", "gt", "-", "pred", ")", "**", "2", "/", "np", ".", "linalg", ".", "norm", "(", "gt", ")", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.psnr": [[35, 40], ["skimage.metrics.peak_signal_noise_ratio", "numpy.max"], "function", ["None"], ["", "def", "psnr", "(", "gt", ":", "np", ".", "ndarray", ",", "pred", ":", "np", ".", "ndarray", ",", "maxval", ":", "np", ".", "ndarray", "=", "None", ")", "->", "float", ":", "\n", "    ", "\"\"\"Compute Peak Signal to Noise Ratio metric (PSNR)\"\"\"", "\n", "if", "maxval", "is", "None", ":", "\n", "        ", "maxval", "=", "np", ".", "max", "(", "gt", ")", "\n", "", "return", "peak_signal_noise_ratio", "(", "gt", ",", "pred", ",", "data_range", "=", "maxval", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.ssim": [[42, 56], ["sum", "ValueError", "ValueError", "numpy.max", "skimage.metrics.structural_similarity", "range"], "function", ["None"], ["", "def", "ssim", "(", "gt", ":", "np", ".", "ndarray", ",", "pred", ":", "np", ".", "ndarray", ",", "maxval", ":", "np", ".", "ndarray", "=", "None", ")", "->", "float", ":", "\n", "    ", "\"\"\"Compute Structural Similarity Index Metric (SSIM)\"\"\"", "\n", "if", "gt", ".", "ndim", "!=", "3", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unexpected number of dimensions in ground truth.\"", ")", "\n", "", "if", "gt", ".", "ndim", "!=", "pred", ".", "ndim", ":", "\n", "        ", "raise", "ValueError", "(", "\"Ground truth dimensions does not match pred.\"", ")", "\n", "\n", "", "maxval", "=", "np", ".", "max", "(", "gt", ")", "if", "maxval", "is", "None", "else", "maxval", "\n", "\n", "_ssim", "=", "sum", "(", "\n", "structural_similarity", "(", "gt", "[", "slice_num", "]", ",", "pred", "[", "slice_num", "]", ",", "data_range", "=", "maxval", ")", "for", "slice_num", "in", "range", "(", "gt", ".", "shape", "[", "0", "]", ")", "\n", ")", "\n", "\n", "return", "_ssim", "/", "gt", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.evaluate": [[115, 237], ["tqdm.tqdm", "evaluate.Metrics", "arguments.target_path.iterdir", "os.path.exists", "h5py.File", "h5py.File", "np.transpose.squeeze().astype", "numpy.abs", "range", "numpy.abs", "numpy.abs", "numpy.transpose", "mridc.collections.common.parts.utils.tensor_to_complex_np", "mridc.collections.reconstruction.parts.utils.center_crop.squeeze", "min", "min", "min", "min", "mridc.collections.reconstruction.parts.utils.center_crop", "mridc.collections.reconstruction.parts.utils.center_crop", "range", "_metrics.push", "numpy.expand_dims", "numpy.expand_dims", "range", "np.transpose.squeeze", "torch.sum", "int", "int", "int", "int", "skimage.morphology.convex_hull_image", "numpy.max", "numpy.max", "pandas.DataFrame().to_csv", "h5py.File", "mridc.collections.common.parts.utils.complex_mul", "numpy.where", "numpy.abs", "numpy.abs", "evaluate.mse", "evaluate.nmse", "evaluate.psnr", "evaluate.ssim", "os.path.exists", "pandas.DataFrame().to_csv", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.complex_conj", "pandas.DataFrame", "mridc.collections.common.parts.utils.to_tensor", "mridc.collections.common.parts.utils.to_tensor", "numpy.abs", "skimage.filters.threshold_otsu", "pandas.DataFrame", "numpy.abs", "str().lower", "_metrics.keys", "str"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.tensor_to_complex_np", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop", "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.Metrics.push", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.mse", "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.nmse", "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.psnr", "home.repos.pwc.inspect_result.wdika_mridc.metrics.evaluate.ssim", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.to_tensor", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.to_tensor"], ["", "", "def", "evaluate", "(", "\n", "arguments", ",", "\n", "reconstruction_key", ",", "\n", "mask_background", ",", "\n", "output_path", ",", "\n", "method", ",", "\n", "acc", ",", "\n", "no_params", ",", "\n", "slice_start", ",", "\n", "slice_end", ",", "\n", "coil_dim", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Evaluates the reconstructions.\n\n    Parameters\n    ----------\n    arguments: The CLI arguments.\n    reconstruction_key: The key of the reconstruction to evaluate.\n    mask_background: The background mask.\n    output_path: The output path.\n    method: The reconstruction method.\n    acc: The acceleration factor.\n    no_params: The number of parameters.\n    slice_start: The start slice. (optional)\n    slice_end: The end slice. (optional)\n    coil_dim: The coil dimension. (optional)\n\n    Returns\n    -------\n    dict: A dict where the keys are metric names and the values are the mean of the metric.\n    \"\"\"", "\n", "_metrics", "=", "Metrics", "(", "METRIC_FUNCS", ",", "output_path", ",", "method", ")", "if", "arguments", ".", "type", "==", "\"mean_std\"", "else", "{", "}", "\n", "\n", "for", "tgt_file", "in", "tqdm", "(", "arguments", ".", "target_path", ".", "iterdir", "(", ")", ")", ":", "\n", "        ", "if", "exists", "(", "arguments", ".", "predictions_path", "/", "tgt_file", ".", "name", ")", ":", "\n", "            ", "with", "h5py", ".", "File", "(", "tgt_file", ",", "\"r\"", ")", "as", "target", ",", "h5py", ".", "File", "(", "\n", "arguments", ".", "predictions_path", "/", "tgt_file", ".", "name", ",", "\"r\"", "\n", ")", "as", "recons", ":", "\n", "                ", "kspace", "=", "target", "[", "\"kspace\"", "]", "[", "(", ")", "]", "\n", "\n", "if", "arguments", ".", "sense_path", "is", "not", "None", ":", "\n", "                    ", "sense", "=", "h5py", ".", "File", "(", "arguments", ".", "sense_path", "/", "tgt_file", ".", "name", ",", "\"r\"", ")", "[", "\"sensitivity_map\"", "]", "[", "(", ")", "]", "\n", "", "elif", "\"sensitivity_map\"", "in", "target", ":", "\n", "                    ", "sense", "=", "target", "[", "\"sensitivity_map\"", "]", "[", "(", ")", "]", "\n", "\n", "", "sense", "=", "sense", ".", "squeeze", "(", ")", ".", "astype", "(", "np", ".", "complex64", ")", "\n", "\n", "if", "sense", ".", "shape", "!=", "kspace", ".", "shape", ":", "\n", "                    ", "sense", "=", "np", ".", "transpose", "(", "sense", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "\n", "", "target", "=", "np", ".", "abs", "(", "\n", "tensor_to_complex_np", "(", "\n", "torch", ".", "sum", "(", "\n", "complex_mul", "(", "\n", "ifft2", "(", "to_tensor", "(", "kspace", ")", ",", "centered", "=", "\"fastmri\"", "in", "str", "(", "arguments", ".", "sense_path", ")", ".", "lower", "(", ")", ")", ",", "\n", "complex_conj", "(", "to_tensor", "(", "sense", ")", ")", ",", "\n", ")", ",", "\n", "coil_dim", ",", "\n", ")", "\n", ")", "\n", ")", "\n", "\n", "recons", "=", "recons", "[", "reconstruction_key", "]", "[", "(", ")", "]", "\n", "\n", "if", "recons", ".", "ndim", "==", "4", ":", "\n", "                    ", "recons", "=", "recons", ".", "squeeze", "(", "coil_dim", ")", "\n", "\n", "", "if", "arguments", ".", "crop_size", "is", "not", "None", ":", "\n", "                    ", "crop_size", "=", "arguments", ".", "crop_size", "\n", "crop_size", "[", "0", "]", "=", "min", "(", "target", ".", "shape", "[", "-", "2", "]", ",", "int", "(", "crop_size", "[", "0", "]", ")", ")", "\n", "crop_size", "[", "1", "]", "=", "min", "(", "target", ".", "shape", "[", "-", "1", "]", ",", "int", "(", "crop_size", "[", "1", "]", ")", ")", "\n", "crop_size", "[", "0", "]", "=", "min", "(", "recons", ".", "shape", "[", "-", "2", "]", ",", "int", "(", "crop_size", "[", "0", "]", ")", ")", "\n", "crop_size", "[", "1", "]", "=", "min", "(", "recons", ".", "shape", "[", "-", "1", "]", ",", "int", "(", "crop_size", "[", "1", "]", ")", ")", "\n", "\n", "target", "=", "center_crop", "(", "target", ",", "crop_size", ")", "\n", "recons", "=", "center_crop", "(", "recons", ",", "crop_size", ")", "\n", "\n", "", "if", "mask_background", ":", "\n", "                    ", "for", "sl", "in", "range", "(", "target", ".", "shape", "[", "0", "]", ")", ":", "\n", "                        ", "mask", "=", "convex_hull_image", "(", "\n", "np", ".", "where", "(", "np", ".", "abs", "(", "target", "[", "sl", "]", ")", ">", "threshold_otsu", "(", "np", ".", "abs", "(", "target", "[", "sl", "]", ")", ")", ",", "1", ",", "0", ")", "# type: ignore", "\n", ")", "\n", "target", "[", "sl", "]", "=", "target", "[", "sl", "]", "*", "mask", "\n", "recons", "[", "sl", "]", "=", "recons", "[", "sl", "]", "*", "mask", "\n", "\n", "", "", "if", "slice_start", "is", "not", "None", ":", "\n", "                    ", "target", "=", "target", "[", "slice_start", ":", "]", "\n", "recons", "=", "recons", "[", "slice_start", ":", "]", "\n", "\n", "", "if", "slice_end", "is", "not", "None", ":", "\n", "                    ", "target", "=", "target", "[", ":", "slice_end", "]", "\n", "recons", "=", "recons", "[", ":", "slice_end", "]", "\n", "\n", "", "for", "sl", "in", "range", "(", "target", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "target", "[", "sl", "]", "=", "target", "[", "sl", "]", "/", "np", ".", "max", "(", "np", ".", "abs", "(", "target", "[", "sl", "]", ")", ")", "\n", "recons", "[", "sl", "]", "=", "recons", "[", "sl", "]", "/", "np", ".", "max", "(", "np", ".", "abs", "(", "recons", "[", "sl", "]", ")", ")", "\n", "\n", "", "target", "=", "np", ".", "abs", "(", "target", ")", "\n", "recons", "=", "np", ".", "abs", "(", "recons", ")", "\n", "\n", "if", "arguments", ".", "type", "==", "\"mean_std\"", ":", "\n", "                    ", "_metrics", ".", "push", "(", "target", ",", "recons", ")", "\n", "", "else", ":", "\n", "                    ", "_target", "=", "np", ".", "expand_dims", "(", "target", ",", "coil_dim", ")", "\n", "_recons", "=", "np", ".", "expand_dims", "(", "recons", ",", "coil_dim", ")", "\n", "for", "sl", "in", "range", "(", "target", ".", "shape", "[", "0", "]", ")", ":", "\n", "                        ", "_metrics", "[", "\"FNAME\"", "]", "=", "tgt_file", ".", "name", "\n", "_metrics", "[", "\"SLICE\"", "]", "=", "sl", "\n", "_metrics", "[", "\"ACC\"", "]", "=", "acc", "\n", "_metrics", "[", "\"METHOD\"", "]", "=", "method", "\n", "_metrics", "[", "\"MSE\"", "]", "=", "[", "mse", "(", "target", "[", "sl", "]", ",", "recons", "[", "sl", "]", ")", "]", "\n", "_metrics", "[", "\"NMSE\"", "]", "=", "[", "nmse", "(", "target", "[", "sl", "]", ",", "recons", "[", "sl", "]", ")", "]", "\n", "_metrics", "[", "\"PSNR\"", "]", "=", "[", "psnr", "(", "target", "[", "sl", "]", ",", "recons", "[", "sl", "]", ")", "]", "\n", "_metrics", "[", "\"SSIM\"", "]", "=", "[", "ssim", "(", "_target", "[", "sl", "]", ",", "_recons", "[", "sl", "]", ")", "]", "\n", "_metrics", "[", "\"PARAMS\"", "]", "=", "no_params", "\n", "\n", "if", "not", "exists", "(", "arguments", ".", "output_path", ")", ":", "\n", "                            ", "pd", ".", "DataFrame", "(", "columns", "=", "_metrics", ".", "keys", "(", ")", ")", ".", "to_csv", "(", "arguments", ".", "output_path", ",", "index", "=", "False", ",", "mode", "=", "\"w\"", ")", "\n", "", "pd", ".", "DataFrame", "(", "_metrics", ")", ".", "to_csv", "(", "arguments", ".", "output_path", ",", "index", "=", "False", ",", "header", "=", "False", ",", "mode", "=", "\"a\"", ")", "\n", "\n", "", "", "", "", "", "return", "_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.__init__": [[36, 43], ["torchmetrics.Metric.__init__", "global_average_loss_metric.GlobalAverageLossMetric.add_state", "global_average_loss_metric.GlobalAverageLossMetric.add_state", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "compute_on_step", "=", "True", ",", "dist_sync_on_step", "=", "False", ",", "process_group", "=", "None", ",", "take_avg_loss", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "compute_on_step", "=", "compute_on_step", ",", "dist_sync_on_step", "=", "dist_sync_on_step", ",", "process_group", "=", "process_group", "\n", ")", "\n", "self", ".", "add_state", "(", "\"loss_sum\"", ",", "torch", ".", "tensor", "(", "0.0", ",", "dtype", "=", "torch", ".", "float64", ")", ",", "dist_reduce_fx", "=", "\"sum\"", ")", "\n", "self", ".", "add_state", "(", "\"num_measurements\"", ",", "torch", ".", "tensor", "(", "0", ",", "dtype", "=", "torch", ".", "int64", ")", ",", "dist_reduce_fx", "=", "\"sum\"", ")", "\n", "self", ".", "take_avg_loss", "=", "take_avg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.update": [[44, 60], ["loss.detach", "loss.detach"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "loss", ",", "num_measurements", ")", ":", "\n", "        ", "\"\"\"\n        Updates :attr:`loss_sum` and :attr:`num_measurements`.\n\n        Parameters\n        ----------\n        loss: A float zero dimensional ``torch.Tensor`` which is either sum or average of losses for processed \\\n        examples. See ``take_avg_loss`` parameter of :meth:`__init__`.\n        num_measurements: An integer zero dimensional ``torch.Tensor`` which contains a number of loss measurements. \\\n        The sum or mean of the results of these measurements are in the ``loss`` parameter.\n        \"\"\"", "\n", "if", "self", ".", "take_avg_loss", ":", "\n", "            ", "self", ".", "loss_sum", "+=", "loss", ".", "detach", "(", ")", "*", "num_measurements", "\n", "", "else", ":", "\n", "            ", "self", ".", "loss_sum", "+=", "loss", ".", "detach", "(", ")", "\n", "", "self", ".", "num_measurements", "+=", "num_measurements", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.compute": [[61, 66], ["global_average_loss_metric.GlobalAverageLossMetric.num_measurements.eq", "torch.tensor", "float"], "methods", ["None"], ["", "def", "compute", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns mean loss.\"\"\"", "\n", "if", "self", ".", "num_measurements", ".", "eq", "(", "0", ")", ":", "\n", "            ", "return", "torch", ".", "tensor", "(", "float", "(", "\"nan\"", ")", ")", "\n", "", "return", "self", ".", "loss_sum", "/", "self", ".", "num_measurements", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.FastMRICombinedSliceDataset.__init__": [[52, 115], ["enumerate", "ValueError", "ValueError", "mri_data.FastMRICombinedSliceDataset.datasets.append", "len", "len", "len", "len", "len", "len", "len", "len", "mri_data.FastMRISliceDataset"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "roots", ":", "Sequence", "[", "Path", "]", ",", "\n", "challenges", ":", "Sequence", "[", "str", "]", ",", "\n", "sense_roots", ":", "Optional", "[", "Sequence", "[", "Path", "]", "]", "=", "None", ",", "\n", "transforms", ":", "Optional", "[", "Sequence", "[", "Optional", "[", "Callable", "]", "]", "]", "=", "None", ",", "\n", "sample_rates", ":", "Optional", "[", "Sequence", "[", "Optional", "[", "float", "]", "]", "]", "=", "None", ",", "\n", "volume_sample_rates", ":", "Optional", "[", "Sequence", "[", "Optional", "[", "float", "]", "]", "]", "=", "None", ",", "\n", "use_dataset_cache", ":", "bool", "=", "False", ",", "\n", "dataset_cache_file", ":", "Union", "[", "str", ",", "Path", ",", "os", ".", "PathLike", "]", "=", "\"dataset_cache.yaml\"", ",", "\n", "num_cols", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        roots: Paths to the datasets.\n        challenges: \"singlecoil\" or \"multicoil\" depending on which challenge to use.\n        sense_roots: Load pre-computed (stored) sensitivity maps.\n        transforms: Optional; A sequence of callable objects that preprocesses the raw data into appropriate form.\n            The transform function should take 'kspace', 'target', 'attributes', 'filename', and 'slice' as inputs.\n            'target' may be null for test data.\n        sample_rates: Optional; A sequence of floats between 0 and 1. This controls what fraction of the slices\n            should be loaded. When creating subsampled datasets either set sample_rates (sample by slices) or\n            volume_sample_rates (sample by volumes) but not both.\n        volume_sample_rates: Optional; A sequence of floats between 0 and 1. This controls what fraction of the\n            volumes should be loaded. When creating subsampled datasets either set sample_rates (sample by slices)\n            or volume_sample_rates (sample by volumes) but not both.\n        use_dataset_cache: Whether to cache dataset metadata. This is very useful for large datasets like the brain\n            data.\n        dataset_cache_file: Optional; A file in which to cache dataset information for faster load times.\n        num_cols: Optional; If provided, only slices with the desired number of columns will be considered.\n        \"\"\"", "\n", "if", "sample_rates", "is", "not", "None", "and", "volume_sample_rates", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"either set sample_rates (sample by slices) or volume_sample_rates (sample by volumes) but not both\"", "\n", ")", "\n", "", "if", "transforms", "is", "None", ":", "\n", "            ", "transforms", "=", "[", "None", "]", "*", "len", "(", "roots", ")", "\n", "", "if", "sample_rates", "is", "None", ":", "\n", "            ", "sample_rates", "=", "[", "None", "]", "*", "len", "(", "roots", ")", "\n", "", "if", "volume_sample_rates", "is", "None", ":", "\n", "            ", "volume_sample_rates", "=", "[", "None", "]", "*", "len", "(", "roots", ")", "\n", "", "if", "not", "len", "(", "roots", ")", "==", "len", "(", "transforms", ")", "==", "len", "(", "challenges", ")", "==", "len", "(", "sample_rates", ")", "==", "len", "(", "volume_sample_rates", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Lengths of roots, transforms, challenges, sample_rates do not match\"", ")", "\n", "\n", "", "self", ".", "datasets", "=", "[", "]", "\n", "self", ".", "examples", ":", "List", "[", "Tuple", "[", "Path", ",", "int", ",", "Dict", "[", "str", ",", "object", "]", "]", "]", "=", "[", "]", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "roots", ")", ":", "\n", "            ", "self", ".", "datasets", ".", "append", "(", "\n", "FastMRISliceDataset", "(", "\n", "root", "=", "roots", "[", "i", "]", ",", "\n", "transform", "=", "transforms", "[", "i", "]", ",", "\n", "sense_root", "=", "sense_roots", "[", "i", "]", "if", "sense_roots", "is", "not", "None", "else", "None", ",", "\n", "challenge", "=", "challenges", "[", "i", "]", ",", "\n", "sample_rate", "=", "sample_rates", "[", "i", "]", ",", "\n", "volume_sample_rate", "=", "volume_sample_rates", "[", "i", "]", ",", "\n", "use_dataset_cache", "=", "use_dataset_cache", ",", "\n", "dataset_cache_file", "=", "dataset_cache_file", ",", "\n", "num_cols", "=", "num_cols", ",", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "examples", "+=", "self", ".", "datasets", "[", "-", "1", "]", ".", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.FastMRICombinedSliceDataset.__len__": [[116, 118], ["sum", "len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "len", "(", "dataset", ")", "for", "dataset", "in", "self", ".", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.FastMRICombinedSliceDataset.__getitem__": [[119, 124], ["len", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "for", "dataset", "in", "self", ".", "datasets", ":", "\n", "            ", "if", "i", "<", "len", "(", "dataset", ")", ":", "\n", "                ", "return", "dataset", "[", "i", "]", "\n", "", "i", "=", "i", "-", "len", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.FastMRISliceDataset.__init__": [[129, 224], ["pathlib.Path", "ValueError", "ValueError", "mri_data.FastMRISliceDataset.dataset_cache_file.exists", "list", "sorted", "logging.info", "random.shuffle", "round", "open", "yaml.safe_load", "yaml.safe_load.get", "pathlib.Path().iterdir", "mri_data.FastMRISliceDataset._retrieve_metadata", "logging.info", "sorted", "random.shuffle", "round", "yaml.safe_load.get", "open", "yaml.dump", "len", "list", "pathlib.Path", "range", "len"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.FastMRISliceDataset._retrieve_metadata", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "\n", "self", ",", "\n", "root", ":", "Union", "[", "str", ",", "Path", ",", "os", ".", "PathLike", "]", ",", "\n", "challenge", ":", "str", "=", "\"multicoil\"", ",", "\n", "transform", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "sense_root", ":", "Union", "[", "str", ",", "Path", ",", "os", ".", "PathLike", "]", "=", "None", ",", "\n", "use_dataset_cache", ":", "bool", "=", "False", ",", "\n", "sample_rate", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "volume_sample_rate", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "dataset_cache_file", ":", "Union", "[", "str", ",", "Path", ",", "os", ".", "PathLike", "]", "=", "\"dataset_cache.yaml\"", ",", "\n", "num_cols", ":", "Optional", "[", "Tuple", "[", "int", "]", "]", "=", "None", ",", "\n", "mask_root", ":", "Union", "[", "str", ",", "Path", ",", "os", ".", "PathLike", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        root: Path to the dataset.\n        challenge: \"singlecoil\" or \"multicoil\" depending on which challenge to use.\n        transform: Optional; A sequence of callable objects that preprocesses the raw data into appropriate form.\n            The transform function should take 'kspace', 'target', 'attributes', 'filename', and 'slice' as inputs.\n            'target' may be null for test data.\n        sense_root: Path to the coil sensitivities maps dataset.\n        use_dataset_cache: Whether to cache dataset metadata. This is very useful for large datasets like the brain\n            data.\n        sample_rate: Optional; A sequence of floats between 0 and 1. This controls what fraction of the slices\n            should be loaded. When creating subsampled datasets either set sample_rates (sample by slices) or\n            volume_sample_rates (sample by volumes) but not both.\n        volume_sample_rate: Optional; A sequence of floats between 0 and 1. This controls what fraction of the\n             volumes should be loaded. When creating subsampled datasets either set sample_rates (sample by slices)\n              or volume_sample_rates (sample by volumes) but not both.\n        dataset_cache_file: Optional; A file in which to cache dataset information for faster load times.\n        num_cols: Optional; If provided, only slices with the desired number of columns will be considered.\n        mask_root: Path to stored masks.\n        \"\"\"", "\n", "if", "challenge", "not", "in", "(", "\"singlecoil\"", ",", "\"multicoil\"", ")", ":", "\n", "            ", "raise", "ValueError", "(", "'challenge should be either \"singlecoil\" or \"multicoil\"'", ")", "\n", "\n", "", "if", "sample_rate", "is", "not", "None", "and", "volume_sample_rate", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"either set sample_rate (sample by slices) or volume_sample_rate (sample by volumes) but not both\"", "\n", ")", "\n", "\n", "", "self", ".", "sense_root", "=", "sense_root", "\n", "self", ".", "mask_root", "=", "mask_root", "\n", "\n", "self", ".", "dataset_cache_file", "=", "Path", "(", "dataset_cache_file", ")", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "recons_key", "=", "\"reconstruction_esc\"", "if", "challenge", "==", "\"singlecoil\"", "else", "\"reconstruction_rss\"", "\n", "self", ".", "examples", "=", "[", "]", "\n", "\n", "# set default sampling mode if none given", "\n", "if", "sample_rate", "is", "None", ":", "\n", "            ", "sample_rate", "=", "1.0", "\n", "", "if", "volume_sample_rate", "is", "None", ":", "\n", "            ", "volume_sample_rate", "=", "1.0", "\n", "\n", "# load dataset cache if we have and user wants to use it", "\n", "", "if", "self", ".", "dataset_cache_file", ".", "exists", "(", ")", "and", "use_dataset_cache", ":", "\n", "            ", "with", "open", "(", "self", ".", "dataset_cache_file", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "dataset_cache", "=", "yaml", ".", "safe_load", "(", "f", ")", "\n", "", "", "else", ":", "\n", "            ", "dataset_cache", "=", "{", "}", "\n", "\n", "# check if our dataset is in the cache", "\n", "# if there, use that metadata, if not, then regenerate the metadata", "\n", "", "if", "dataset_cache", ".", "get", "(", "root", ")", "is", "None", "or", "not", "use_dataset_cache", ":", "\n", "            ", "files", "=", "list", "(", "Path", "(", "root", ")", ".", "iterdir", "(", ")", ")", "\n", "for", "fname", "in", "sorted", "(", "files", ")", ":", "\n", "                ", "metadata", ",", "num_slices", "=", "self", ".", "_retrieve_metadata", "(", "fname", ")", "\n", "self", ".", "examples", "+=", "[", "(", "fname", ",", "slice_ind", ",", "metadata", ")", "for", "slice_ind", "in", "range", "(", "num_slices", ")", "]", "\n", "\n", "", "if", "dataset_cache", ".", "get", "(", "root", ")", "is", "None", "and", "use_dataset_cache", ":", "\n", "                ", "dataset_cache", "[", "root", "]", "=", "self", ".", "examples", "\n", "logging", ".", "info", "(", "f\"Saving dataset cache to {self.dataset_cache_file}.\"", ")", "\n", "with", "open", "(", "self", ".", "dataset_cache_file", ",", "\"wb\"", ")", "as", "f", ":", "# type: ignore", "\n", "                    ", "yaml", ".", "dump", "(", "dataset_cache", ",", "f", ")", "# type: ignore", "\n", "", "", "", "else", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Using dataset cache from {self.dataset_cache_file}.\"", ")", "\n", "self", ".", "examples", "=", "dataset_cache", "[", "root", "]", "\n", "\n", "# subsample if desired", "\n", "", "if", "sample_rate", "<", "1.0", ":", "# sample by slice", "\n", "            ", "random", ".", "shuffle", "(", "self", ".", "examples", ")", "\n", "num_examples", "=", "round", "(", "len", "(", "self", ".", "examples", ")", "*", "sample_rate", ")", "\n", "self", ".", "examples", "=", "self", ".", "examples", "[", ":", "num_examples", "]", "\n", "", "elif", "volume_sample_rate", "<", "1.0", ":", "# sample by volume", "\n", "            ", "vol_names", "=", "sorted", "(", "list", "(", "{", "f", "[", "0", "]", ".", "stem", "for", "f", "in", "self", ".", "examples", "}", ")", ")", "\n", "random", ".", "shuffle", "(", "vol_names", ")", "\n", "num_volumes", "=", "round", "(", "len", "(", "vol_names", ")", "*", "volume_sample_rate", ")", "\n", "sampled_vols", "=", "vol_names", "[", ":", "num_volumes", "]", "\n", "self", ".", "examples", "=", "[", "example", "for", "example", "in", "self", ".", "examples", "if", "example", "[", "0", "]", ".", "stem", "in", "sampled_vols", "]", "\n", "\n", "", "if", "num_cols", ":", "\n", "            ", "self", ".", "examples", "=", "[", "ex", "for", "ex", "in", "self", ".", "examples", "if", "ex", "[", "2", "]", "[", "\"encoding_size\"", "]", "[", "1", "]", "in", "num_cols", "]", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.FastMRISliceDataset._retrieve_metadata": [[225, 277], ["h5py.File", "defusedxml.ElementTree.fromstring", "int", "int", "int", "int", "int", "int", "int", "mri_data.et_query", "int", "torch.div().item", "mri_data.et_query", "mri_data.et_query", "mri_data.et_query", "mri_data.et_query", "mri_data.et_query", "mri_data.et_query", "mri_data.et_query", "torch.div"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.et_query", "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.et_query", "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.et_query", "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.et_query", "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.et_query", "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.et_query", "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.et_query", "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.et_query"], ["", "", "@", "staticmethod", "\n", "def", "_retrieve_metadata", "(", "fname", ")", ":", "\n", "        ", "\"\"\"\n        Retrieve metadata from a given file.\n\n        Parameters\n        ----------\n        fname: Path to file.\n\n        Returns\n        -------\n        A dictionary containing the metadata.\n        \"\"\"", "\n", "with", "h5py", ".", "File", "(", "fname", ",", "\"r\"", ")", "as", "hf", ":", "\n", "            ", "if", "\"ismrmrd_header\"", "in", "hf", ":", "\n", "                ", "et_root", "=", "fromstring", "(", "hf", "[", "\"ismrmrd_header\"", "]", "[", "(", ")", "]", ")", "\n", "\n", "enc", "=", "[", "\"encoding\"", ",", "\"encodedSpace\"", ",", "\"matrixSize\"", "]", "\n", "enc_size", "=", "(", "\n", "int", "(", "et_query", "(", "et_root", ",", "enc", "+", "[", "\"x\"", "]", ")", ")", ",", "\n", "int", "(", "et_query", "(", "et_root", ",", "enc", "+", "[", "\"y\"", "]", ")", ")", ",", "\n", "int", "(", "et_query", "(", "et_root", ",", "enc", "+", "[", "\"z\"", "]", ")", ")", ",", "\n", ")", "\n", "rec", "=", "[", "\"encoding\"", ",", "\"reconSpace\"", ",", "\"matrixSize\"", "]", "\n", "recon_size", "=", "(", "\n", "int", "(", "et_query", "(", "et_root", ",", "rec", "+", "[", "\"x\"", "]", ")", ")", ",", "\n", "int", "(", "et_query", "(", "et_root", ",", "rec", "+", "[", "\"y\"", "]", ")", ")", ",", "\n", "int", "(", "et_query", "(", "et_root", ",", "rec", "+", "[", "\"z\"", "]", ")", ")", ",", "\n", ")", "\n", "\n", "params", "=", "[", "\"encoding\"", ",", "\"encodingLimits\"", ",", "\"kspace_encoding_step_1\"", "]", "\n", "enc_limits_center", "=", "int", "(", "et_query", "(", "et_root", ",", "params", "+", "[", "\"center\"", "]", ")", ")", "\n", "enc_limits_max", "=", "int", "(", "et_query", "(", "et_root", ",", "params", "+", "[", "\"maximum\"", "]", ")", ")", "+", "1", "\n", "\n", "padding_left", "=", "torch", ".", "div", "(", "enc_size", "[", "1", "]", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", ".", "item", "(", ")", "-", "enc_limits_center", "\n", "padding_right", "=", "padding_left", "+", "enc_limits_max", "\n", "", "else", ":", "\n", "                ", "padding_left", "=", "0", "\n", "padding_right", "=", "0", "\n", "enc_size", "=", "0", "\n", "recon_size", "=", "(", "0", ",", "0", ")", "\n", "\n", "", "num_slices", "=", "hf", "[", "\"kspace\"", "]", ".", "shape", "[", "0", "]", "\n", "\n", "", "metadata", "=", "{", "\n", "\"padding_left\"", ":", "padding_left", ",", "\n", "\"padding_right\"", ":", "padding_right", ",", "\n", "\"encoding_size\"", ":", "enc_size", ",", "\n", "\"recon_size\"", ":", "recon_size", ",", "\n", "}", "\n", "\n", "return", "metadata", ",", "num_slices", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.FastMRISliceDataset.__len__": [[278, 280], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.FastMRISliceDataset.__getitem__": [[281, 345], ["h5py.File", "[].astype", "dict", "numpy.transpose", "mri_data.FastMRISliceDataset.transform", "[].astype", "numpy.asarray", "[].astype", "numpy.array", "[].astype", "numpy.array", "numpy.load", "h5py.File", "sensitivity_map.squeeze().astype.squeeze().astype.squeeze().astype", "pathlib.Path", "pathlib.Path", "str", "sensitivity_map.squeeze().astype.squeeze().astype.squeeze", "pathlib.Path", "pathlib.Path", "next", "str().split", "iter", "str().split", "sf.keys", "str", "str"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ":", "int", ")", ":", "\n", "        ", "fname", ",", "dataslice", ",", "metadata", "=", "self", ".", "examples", "[", "i", "]", "\n", "with", "h5py", ".", "File", "(", "fname", ",", "\"r\"", ")", "as", "hf", ":", "\n", "            ", "kspace", "=", "hf", "[", "\"kspace\"", "]", "[", "dataslice", "]", ".", "astype", "(", "np", ".", "complex64", ")", "\n", "\n", "if", "\"sensitivity_map\"", "in", "hf", ":", "\n", "                ", "sensitivity_map", "=", "hf", "[", "\"sensitivity_map\"", "]", "[", "dataslice", "]", ".", "astype", "(", "np", ".", "complex64", ")", "\n", "", "elif", "self", ".", "sense_root", "is", "not", "None", "and", "self", ".", "sense_root", "!=", "\"None\"", ":", "\n", "                ", "with", "h5py", ".", "File", "(", "Path", "(", "self", ".", "sense_root", ")", "/", "Path", "(", "str", "(", "fname", ")", ".", "split", "(", "\"/\"", ")", "[", "-", "2", "]", ")", "/", "fname", ".", "name", ",", "\"r\"", ")", "as", "sf", ":", "\n", "                    ", "sensitivity_map", "=", "(", "\n", "sf", "[", "\"sensitivity_map\"", "]", "[", "dataslice", "]", "\n", "if", "\"sensitivity_map\"", "in", "sf", "or", "\"sensitivity_map\"", "in", "next", "(", "iter", "(", "sf", ".", "keys", "(", ")", ")", ")", "\n", "else", "sf", "[", "\"sense\"", "]", "[", "dataslice", "]", "\n", ")", "\n", "sensitivity_map", "=", "sensitivity_map", ".", "squeeze", "(", ")", ".", "astype", "(", "np", ".", "complex64", ")", "\n", "", "", "else", ":", "\n", "                ", "sensitivity_map", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "", "if", "\"mask\"", "in", "hf", ":", "\n", "                ", "mask", "=", "np", ".", "asarray", "(", "hf", "[", "\"mask\"", "]", ")", "\n", "\n", "if", "mask", ".", "ndim", "==", "3", ":", "\n", "                    ", "mask", "=", "mask", "[", "dataslice", "]", "\n", "\n", "", "", "elif", "self", ".", "mask_root", "is", "not", "None", "and", "self", ".", "mask_root", "!=", "\"None\"", ":", "\n", "                ", "mask_path", "=", "Path", "(", "self", ".", "mask_root", ")", "/", "Path", "(", "str", "(", "fname", ".", "name", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "+", "\".npy\"", ")", "\n", "mask", "=", "np", ".", "load", "(", "str", "(", "mask_path", ")", ")", "\n", "", "else", ":", "\n", "                ", "mask", "=", "None", "\n", "\n", "", "eta", "=", "hf", "[", "\"eta\"", "]", "[", "dataslice", "]", ".", "astype", "(", "np", ".", "complex64", ")", "if", "\"eta\"", "in", "hf", "else", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "if", "\"reconstruction_sense\"", "in", "hf", ":", "\n", "                ", "self", ".", "recons_key", "=", "\"reconstruction_sense\"", "\n", "\n", "", "target", "=", "hf", "[", "self", ".", "recons_key", "]", "[", "dataslice", "]", ".", "astype", "(", "np", ".", "float32", ")", "if", "self", ".", "recons_key", "in", "hf", "else", "None", "\n", "\n", "attrs", "=", "dict", "(", "hf", ".", "attrs", ")", "\n", "attrs", "|=", "metadata", "\n", "\n", "", "if", "sensitivity_map", ".", "shape", "!=", "kspace", ".", "shape", ":", "\n", "            ", "sensitivity_map", "=", "np", ".", "transpose", "(", "sensitivity_map", ",", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "", "return", "(", "\n", "(", "\n", "kspace", ",", "\n", "sensitivity_map", ",", "\n", "mask", ",", "\n", "eta", ",", "\n", "target", ",", "\n", "attrs", ",", "\n", "fname", ".", "name", ",", "\n", "dataslice", ",", "\n", ")", "\n", "if", "self", ".", "transform", "is", "None", "\n", "else", "self", ".", "transform", "(", "\n", "kspace", ",", "\n", "sensitivity_map", ",", "\n", "mask", ",", "\n", "eta", ",", "\n", "target", ",", "\n", "attrs", ",", "\n", "fname", ".", "name", ",", "\n", "dataslice", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.mri_data.et_query": [[20, 47], ["root.find", "str"], "function", ["None"], ["def", "et_query", "(", "root", ":", "str", ",", "qlist", ":", "Sequence", "[", "str", "]", ",", "namespace", ":", "str", "=", "\"https://www.ismrm.org/ISMRMRD\"", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Query an XML element for a list of attributes.\n\n    Parameters\n    ----------\n    root: The root element of the XML tree.\n    qlist: A list of strings, each of which is an attribute name.\n    namespace: The namespace of the XML tree.\n\n    Returns\n    -------\n    A string containing the value of the last attribute in the list.\n    \"\"\"", "\n", "s", "=", "\".\"", "\n", "prefix", "=", "\"ismrmrd_namespace\"", "\n", "\n", "ns", "=", "{", "prefix", ":", "namespace", "}", "\n", "\n", "for", "el", "in", "qlist", ":", "\n", "        ", "s", "+=", "f\"//{prefix}:{el}\"", "\n", "\n", "", "value", "=", "root", ".", "find", "(", "s", ",", "ns", ")", "# type: ignore", "\n", "if", "value", "is", "None", ":", "\n", "        ", "return", "\"0\"", "\n", "\n", "", "return", "str", "(", "value", ".", "text", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.__init__": [[43, 61], ["numpy.random.RandomState", "len", "len", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "center_fractions", ":", "Sequence", "[", "float", "]", ",", "accelerations", ":", "Sequence", "[", "int", "]", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the mask function.\n\n        Parameters\n        ----------\n        center_fractions: Fraction of low-frequency columns to be retained. If multiple values are provided, then \\\n        one of these numbers is chosen uniformly each time. For 2D setting this value corresponds to setting the \\\n        Full-Width-Half-Maximum.\n        accelerations: Amount of under-sampling. This should have the same length as center_fractions. If multiple \\\n        values are provided, then one of these is chosen uniformly each time.\n        \"\"\"", "\n", "if", "len", "(", "center_fractions", ")", "!=", "len", "(", "accelerations", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Number of center fractions should match number of accelerations\"", ")", "\n", "\n", "", "self", ".", "center_fractions", "=", "center_fractions", "\n", "self", ".", "accelerations", "=", "accelerations", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", ")", "# pylint: disable=no-member", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.__call__": [[62, 83], ["None"], "methods", ["None"], ["", "def", "__call__", "(", "\n", "self", ",", "\n", "shape", ":", "Sequence", "[", "int", "]", ",", "\n", "seed", ":", "Optional", "[", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "...", "]", "]", "]", "=", "None", ",", "\n", "half_scan_percentage", ":", "Optional", "[", "float", "]", "=", "0.0", ",", "\n", "scale", ":", "Optional", "[", "float", "]", "=", "0.02", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        shape: Shape of the input tensor.\n        seed: Seed for the random number generator.\n        half_scan_percentage: Percentage of the low-frequency columns to be retained.\n        scale: Scale of the mask.\n\n        Returns\n        -------\n        A tuple of the mask and the number of low-frequency columns retained.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.choose_acceleration": [[84, 91], ["subsample.MaskFunc.rng.randint", "len"], "methods", ["None"], ["", "def", "choose_acceleration", "(", "self", ")", ":", "\n", "        ", "\"\"\"Choose acceleration.\"\"\"", "\n", "choice", "=", "self", ".", "rng", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "accelerations", ")", ")", "\n", "center_fraction", "=", "self", ".", "center_fractions", "[", "choice", "]", "\n", "acceleration", "=", "self", ".", "accelerations", "[", "choice", "]", "\n", "\n", "return", "center_fraction", ",", "acceleration", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.RandomMaskFunc.__call__": [[112, 153], ["len", "ValueError", "subsample.temp_seed", "subsample.RandomMaskFunc.choose_acceleration", "int", "torch.div().item", "torch.from_numpy", "round", "subsample.RandomMaskFunc.rng.uniform", "torch.from_numpy.reshape().astype", "torch.div", "torch.from_numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.data.subsample.temp_seed", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.choose_acceleration"], ["def", "__call__", "(", "\n", "self", ",", "\n", "shape", ":", "Sequence", "[", "int", "]", ",", "\n", "seed", ":", "Optional", "[", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "...", "]", "]", "]", "=", "None", ",", "\n", "half_scan_percentage", ":", "Optional", "[", "float", "]", "=", "0.0", ",", "\n", "scale", ":", "Optional", "[", "float", "]", "=", "0.02", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        shape: The shape of the mask to be created. The shape should have at least 3 dimensions. Samples are drawn \\\n        along the second last dimension.\n        seed: Seed for the random number generator. Setting the seed ensures the same mask is generated each time \\\n        for the same shape. The random state is reset afterwards.\n        half_scan_percentage: Optional; Defines a fraction of the k-space data that is not sampled.\n        scale: Optional; Defines the scale of the center of the mask.\n\n        Returns\n        -------\n        A tuple of the mask and the number of columns selected.\n        \"\"\"", "\n", "if", "len", "(", "shape", ")", "<", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"Shape should have 3 or more dimensions\"", ")", "\n", "\n", "", "with", "temp_seed", "(", "self", ".", "rng", ",", "seed", ")", ":", "\n", "            ", "num_cols", "=", "shape", "[", "-", "2", "]", "\n", "center_fraction", ",", "acceleration", "=", "self", ".", "choose_acceleration", "(", ")", "\n", "\n", "# create the mask", "\n", "num_low_freqs", "=", "int", "(", "round", "(", "num_cols", "*", "center_fraction", ")", ")", "\n", "prob", "=", "(", "num_cols", "/", "acceleration", "-", "num_low_freqs", ")", "/", "(", "num_cols", "-", "num_low_freqs", ")", "\n", "mask", "=", "self", ".", "rng", ".", "uniform", "(", "size", "=", "num_cols", ")", "<", "prob", "# type: ignore", "\n", "pad", "=", "torch", ".", "div", "(", "(", "num_cols", "-", "num_low_freqs", "+", "1", ")", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", ".", "item", "(", ")", "\n", "mask", "[", "pad", ":", "pad", "+", "num_low_freqs", "]", "=", "True", "\n", "\n", "# reshape the mask", "\n", "mask_shape", "=", "[", "1", "for", "_", "in", "shape", "]", "\n", "mask_shape", "[", "-", "2", "]", "=", "num_cols", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ".", "reshape", "(", "*", "mask_shape", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "", "return", "mask", ",", "acceleration", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.EquispacedMaskFunc.__call__": [[174, 222], ["len", "ValueError", "subsample.temp_seed", "subsample.EquispacedMaskFunc.choose_acceleration", "int", "numpy.zeros", "torch.div().item", "subsample.EquispacedMaskFunc.rng.randint", "numpy.arange", "numpy.around().astype", "torch.from_numpy", "round", "round", "torch.from_numpy.reshape().astype", "torch.div", "numpy.around", "torch.from_numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.data.subsample.temp_seed", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.choose_acceleration"], ["def", "__call__", "(", "\n", "self", ",", "\n", "shape", ":", "Sequence", "[", "int", "]", ",", "\n", "seed", ":", "Optional", "[", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "...", "]", "]", "]", "=", "None", ",", "\n", "half_scan_percentage", ":", "Optional", "[", "float", "]", "=", "0.0", ",", "\n", "scale", ":", "Optional", "[", "float", "]", "=", "0.02", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        shape: The shape of the mask to be created. The shape should have at least 3 dimensions. Samples are drawn \\\n        along the second last dimension.\n        seed: Seed for the random number generator. Setting the seed ensures the same mask is generated each time for \\\n        the same shape. The random state is reset afterwards.\n        half_scan_percentage: Optional; Defines a fraction of the k-space data that is not sampled.\n        scale: Optional; Defines the scale of the center of the mask.\n\n        Returns\n        -------\n        A tuple of the mask and the number of columns selected.\n        \"\"\"", "\n", "if", "len", "(", "shape", ")", "<", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"Shape should have 3 or more dimensions\"", ")", "\n", "\n", "", "with", "temp_seed", "(", "self", ".", "rng", ",", "seed", ")", ":", "\n", "            ", "center_fraction", ",", "acceleration", "=", "self", ".", "choose_acceleration", "(", ")", "\n", "num_cols", "=", "shape", "[", "-", "2", "]", "\n", "num_low_freqs", "=", "int", "(", "round", "(", "num_cols", "*", "center_fraction", ")", ")", "\n", "\n", "# create the mask", "\n", "mask", "=", "np", ".", "zeros", "(", "num_cols", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "pad", "=", "torch", ".", "div", "(", "(", "num_cols", "-", "num_low_freqs", "+", "1", ")", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", ".", "item", "(", ")", "\n", "mask", "[", "pad", ":", "pad", "+", "num_low_freqs", "]", "=", "True", "# type: ignore", "\n", "\n", "# determine acceleration rate by adjusting for the number of low frequencies", "\n", "adjusted_accel", "=", "(", "acceleration", "*", "(", "num_low_freqs", "-", "num_cols", ")", ")", "/", "(", "num_low_freqs", "*", "acceleration", "-", "num_cols", ")", "\n", "offset", "=", "self", ".", "rng", ".", "randint", "(", "0", ",", "round", "(", "adjusted_accel", ")", ")", "\n", "\n", "accel_samples", "=", "np", ".", "arange", "(", "offset", ",", "num_cols", "-", "1", ",", "adjusted_accel", ")", "\n", "accel_samples", "=", "np", ".", "around", "(", "accel_samples", ")", ".", "astype", "(", "np", ".", "uint", ")", "\n", "mask", "[", "accel_samples", "]", "=", "True", "\n", "\n", "# reshape the mask", "\n", "mask_shape", "=", "[", "1", "for", "_", "in", "shape", "]", "\n", "mask_shape", "[", "-", "2", "]", "=", "num_cols", "\n", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ".", "reshape", "(", "*", "mask_shape", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "\n", "", "return", "mask", ",", "acceleration", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian1DMaskFunc.__call__": [[235, 278], ["tuple", "subsample.Gaussian1DMaskFunc.choose_acceleration", "subsample.Gaussian1DMaskFunc.gaussian_kspace", "numpy.fft.ifftshift", "isinstance", "numpy.fft.ifftshift", "torch.from_numpy", "tuple", "numpy.fft.ifftshift", "mask[].reshape().astype", "subsample.Gaussian1DMaskFunc.gaussian_coordinates", "int", "mask[].reshape", "numpy.round"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.choose_acceleration", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian2DMaskFunc.gaussian_kspace", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian2DMaskFunc.gaussian_coordinates"], ["def", "__call__", "(", "\n", "self", ",", "\n", "shape", ":", "Union", "[", "Sequence", "[", "int", "]", ",", "np", ".", "ndarray", "]", ",", "\n", "seed", ":", "Optional", "[", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "...", "]", "]", "]", "=", "None", ",", "\n", "half_scan_percentage", ":", "Optional", "[", "float", "]", "=", "0.0", ",", "\n", "scale", ":", "Optional", "[", "float", "]", "=", "0.02", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        shape: The shape of the mask to be created. The shape should have at least 3 dimensions. Samples are drawn \\\n        along the second last dimension.\n        seed: Seed for the random number generator. Setting the seed ensures the same mask is generated each time \\\n        for the same shape. The random state is reset afterwards.\n        half_scan_percentage: Optional; Defines a fraction of the k-space data that is not sampled.\n        scale: For autocalibration purposes, data points near the k-space center will be fully sampled within an \\\n        ellipse of which the half-axes will set to the set scale % of the fully sampled region\n\n        Returns\n        -------\n        A tuple of the mask and the number of columns selected.\n        \"\"\"", "\n", "dims", "=", "[", "1", "for", "_", "in", "shape", "]", "\n", "self", ".", "shape", "=", "tuple", "(", "shape", "[", "-", "3", ":", "-", "1", "]", ")", "\n", "dims", "[", "-", "2", "]", "=", "self", ".", "shape", "[", "-", "1", "]", "\n", "\n", "full_width_half_maximum", ",", "acceleration", "=", "self", ".", "choose_acceleration", "(", ")", "\n", "if", "not", "isinstance", "(", "full_width_half_maximum", ",", "list", ")", ":", "\n", "            ", "full_width_half_maximum", "=", "[", "full_width_half_maximum", "]", "*", "2", "\n", "", "self", ".", "full_width_half_maximum", "=", "full_width_half_maximum", "\n", "self", ".", "acceleration", "=", "acceleration", "\n", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "mask", "=", "self", ".", "gaussian_kspace", "(", ")", "\n", "mask", "[", "tuple", "(", "self", ".", "gaussian_coordinates", "(", ")", ")", "]", "=", "1.0", "\n", "\n", "mask", "=", "np", ".", "fft", ".", "ifftshift", "(", "np", ".", "fft", ".", "ifftshift", "(", "np", ".", "fft", ".", "ifftshift", "(", "mask", ",", "axes", "=", "0", ")", ",", "axes", "=", "0", ")", ",", "axes", "=", "(", "0", ",", "1", ")", ")", "\n", "\n", "if", "half_scan_percentage", "!=", "0", ":", "\n", "            ", "mask", "[", ":", "int", "(", "np", ".", "round", "(", "mask", ".", "shape", "[", "0", "]", "*", "half_scan_percentage", ")", ")", ",", ":", "]", "=", "0.0", "\n", "\n", "", "return", "torch", ".", "from_numpy", "(", "mask", "[", "0", "]", ".", "reshape", "(", "dims", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", ",", "acceleration", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian1DMaskFunc.gaussian_kspace": [[279, 288], ["int", "numpy.ones", "torch.div().item", "numpy.zeros", "numpy.zeros", "numpy.concatenate", "torch.div"], "methods", ["None"], ["", "def", "gaussian_kspace", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates a Gaussian sampled k-space center.\"\"\"", "\n", "scaled", "=", "int", "(", "self", ".", "shape", "[", "0", "]", "*", "self", ".", "scale", ")", "\n", "center", "=", "np", ".", "ones", "(", "(", "scaled", ",", "self", ".", "shape", "[", "1", "]", ")", ")", "\n", "top_scaled", "=", "torch", ".", "div", "(", "(", "self", ".", "shape", "[", "0", "]", "-", "scaled", ")", ",", "2", ",", "rounding_mode", "=", "\"trunc\"", ")", ".", "item", "(", ")", "\n", "bottom_scaled", "=", "self", ".", "shape", "[", "0", "]", "-", "scaled", "-", "top_scaled", "\n", "top", "=", "np", ".", "zeros", "(", "(", "top_scaled", ",", "self", ".", "shape", "[", "1", "]", ")", ")", "\n", "btm", "=", "np", ".", "zeros", "(", "(", "bottom_scaled", ",", "self", ".", "shape", "[", "1", "]", ")", ")", "\n", "return", "np", ".", "concatenate", "(", "(", "top", ",", "center", ",", "btm", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian1DMaskFunc.gaussian_coordinates": [[289, 297], ["int", "subsample.Gaussian1DMaskFunc.gaussian_kernel", "numpy.random.choice", "numpy.concatenate", "numpy.concatenate", "range", "numpy.tile", "range"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian2DMaskFunc.gaussian_kernel"], ["", "def", "gaussian_coordinates", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates a Gaussian sampled k-space coordinates.\"\"\"", "\n", "n_sample", "=", "int", "(", "self", ".", "shape", "[", "0", "]", "/", "self", ".", "acceleration", ")", "\n", "kernel", "=", "self", ".", "gaussian_kernel", "(", ")", "\n", "idxs", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "self", ".", "shape", "[", "0", "]", ")", ",", "size", "=", "n_sample", ",", "replace", "=", "False", ",", "p", "=", "kernel", ")", "\n", "xsamples", "=", "np", ".", "concatenate", "(", "[", "np", ".", "tile", "(", "i", ",", "self", ".", "shape", "[", "1", "]", ")", "for", "i", "in", "idxs", "]", ")", "\n", "ysamples", "=", "np", ".", "concatenate", "(", "[", "range", "(", "self", ".", "shape", "[", "1", "]", ")", "for", "_", "in", "idxs", "]", ")", "\n", "return", "xsamples", ",", "ysamples", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian1DMaskFunc.gaussian_kernel": [[298, 309], ["zip", "numpy.linspace", "numpy.exp", "kernel.sum", "numpy.sqrt", "numpy.log"], "methods", ["None"], ["", "def", "gaussian_kernel", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates a Gaussian sampled k-space kernel.\"\"\"", "\n", "kernel", "=", "1", "\n", "for", "fwhm", ",", "kern_len", "in", "zip", "(", "self", ".", "full_width_half_maximum", ",", "self", ".", "shape", ")", ":", "\n", "            ", "sigma", "=", "fwhm", "/", "np", ".", "sqrt", "(", "8", "*", "np", ".", "log", "(", "2", ")", ")", "\n", "x", "=", "np", ".", "linspace", "(", "-", "1.0", ",", "1.0", ",", "kern_len", ")", "\n", "g", "=", "np", ".", "exp", "(", "-", "(", "x", "**", "2", "/", "(", "2", "*", "sigma", "**", "2", ")", ")", ")", "\n", "kernel", "=", "g", "\n", "break", "\n", "", "kernel", "=", "kernel", "/", "kernel", ".", "sum", "(", ")", "\n", "return", "kernel", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian2DMaskFunc.__call__": [[322, 364], ["tuple", "subsample.Gaussian2DMaskFunc.choose_acceleration", "subsample.Gaussian2DMaskFunc.gaussian_kspace", "isinstance", "torch.from_numpy", "tuple", "subsample.Gaussian2DMaskFunc.reshape().astype", "subsample.Gaussian2DMaskFunc.gaussian_coordinates", "int", "subsample.Gaussian2DMaskFunc.reshape", "numpy.round"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.choose_acceleration", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian2DMaskFunc.gaussian_kspace", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian2DMaskFunc.gaussian_coordinates"], ["def", "__call__", "(", "\n", "self", ",", "\n", "shape", ":", "Union", "[", "Sequence", "[", "int", "]", ",", "np", ".", "ndarray", "]", ",", "\n", "seed", ":", "Optional", "[", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "...", "]", "]", "]", "=", "None", ",", "\n", "half_scan_percentage", ":", "Optional", "[", "float", "]", "=", "0.0", ",", "\n", "scale", ":", "Optional", "[", "float", "]", "=", "0.02", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        shape: The shape of the mask to be created. The shape should have at least 3 dimensions. Samples are drawn \\\n        along the second last dimension.\n        seed: Seed for the random number generator. Setting the seed ensures the same mask is generated each time for \\\n         the same shape. The random state is reset afterwards.\n        half_scan_percentage: Optional; Defines a fraction of the k-space data that is not sampled.\n        scale: For autocalibration purposes, data points near the k-space center will be fully sampled within an \\\n        ellipse of which the half-axes will set to the set scale % of the fully sampled region\n\n        Returns\n        -------\n        A tuple of the mask and the number of columns selected.\n        \"\"\"", "\n", "dims", "=", "[", "1", "for", "_", "in", "shape", "]", "\n", "self", ".", "shape", "=", "tuple", "(", "shape", "[", "-", "3", ":", "-", "1", "]", ")", "\n", "dims", "[", "-", "3", ":", "-", "1", "]", "=", "self", ".", "shape", "\n", "\n", "full_width_half_maximum", ",", "acceleration", "=", "self", ".", "choose_acceleration", "(", ")", "\n", "\n", "if", "not", "isinstance", "(", "full_width_half_maximum", ",", "list", ")", ":", "\n", "            ", "full_width_half_maximum", "=", "[", "full_width_half_maximum", "]", "*", "2", "\n", "", "self", ".", "full_width_half_maximum", "=", "full_width_half_maximum", "\n", "\n", "self", ".", "acceleration", "=", "acceleration", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "mask", "=", "self", ".", "gaussian_kspace", "(", ")", "\n", "mask", "[", "tuple", "(", "self", ".", "gaussian_coordinates", "(", ")", ")", "]", "=", "1.0", "\n", "\n", "if", "half_scan_percentage", "!=", "0", ":", "\n", "            ", "mask", "[", ":", "int", "(", "np", ".", "round", "(", "mask", ".", "shape", "[", "0", "]", "*", "half_scan_percentage", ")", ")", ",", ":", "]", "=", "0.0", "\n", "\n", "", "return", "torch", ".", "from_numpy", "(", "mask", ".", "reshape", "(", "dims", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", ",", "acceleration", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian2DMaskFunc.gaussian_kspace": [[365, 372], ["numpy.power", "numpy.power"], "methods", ["None"], ["", "def", "gaussian_kspace", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates a Gaussian sampled k-space center.\"\"\"", "\n", "a", ",", "b", "=", "self", ".", "scale", "*", "self", ".", "shape", "[", "0", "]", ",", "self", ".", "scale", "*", "self", ".", "shape", "[", "1", "]", "\n", "afocal", ",", "bfocal", "=", "self", ".", "shape", "[", "0", "]", "/", "2", ",", "self", ".", "shape", "[", "1", "]", "/", "2", "\n", "xx", ",", "yy", "=", "np", ".", "mgrid", "[", ":", "self", ".", "shape", "[", "0", "]", ",", ":", "self", ".", "shape", "[", "1", "]", "]", "\n", "ellipse", "=", "np", ".", "power", "(", "(", "xx", "-", "afocal", ")", "/", "a", ",", "2", ")", "+", "np", ".", "power", "(", "(", "yy", "-", "bfocal", ")", "/", "b", ",", "2", ")", "\n", "return", "(", "ellipse", "<", "1", ")", ".", "astype", "(", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian2DMaskFunc.gaussian_coordinates": [[373, 380], ["int", "list", "subsample.Gaussian2DMaskFunc.gaussian_kernel", "numpy.random.choice", "list", "numpy.ndindex", "range", "zip", "len", "subsample.Gaussian2DMaskFunc.flatten", "list", "map"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian2DMaskFunc.gaussian_kernel"], ["", "def", "gaussian_coordinates", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates a Gaussian sampled k-space coordinates.\"\"\"", "\n", "n_sample", "=", "int", "(", "self", ".", "shape", "[", "0", "]", "*", "self", ".", "shape", "[", "1", "]", "/", "self", ".", "acceleration", ")", "\n", "cartesian_prod", "=", "list", "(", "np", ".", "ndindex", "(", "self", ".", "shape", ")", ")", "# type: ignore", "\n", "kernel", "=", "self", ".", "gaussian_kernel", "(", ")", "\n", "idxs", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "len", "(", "cartesian_prod", ")", ")", ",", "size", "=", "n_sample", ",", "replace", "=", "False", ",", "p", "=", "kernel", ".", "flatten", "(", ")", ")", "\n", "return", "list", "(", "zip", "(", "*", "list", "(", "map", "(", "cartesian_prod", ".", "__getitem__", ",", "idxs", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Gaussian2DMaskFunc.gaussian_kernel": [[381, 392], ["zip", "numpy.sqrt", "numpy.linspace", "numpy.exp", "kernels.append", "numpy.outer", "numpy.sqrt.sum", "numpy.sqrt", "numpy.log"], "methods", ["None"], ["", "def", "gaussian_kernel", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates a Gaussian kernel.\"\"\"", "\n", "kernels", "=", "[", "]", "\n", "for", "fwhm", ",", "kern_len", "in", "zip", "(", "self", ".", "full_width_half_maximum", ",", "self", ".", "shape", ")", ":", "\n", "            ", "sigma", "=", "fwhm", "/", "np", ".", "sqrt", "(", "8", "*", "np", ".", "log", "(", "2", ")", ")", "\n", "x", "=", "np", ".", "linspace", "(", "-", "1.0", ",", "1.0", ",", "kern_len", ")", "\n", "g", "=", "np", ".", "exp", "(", "-", "(", "x", "**", "2", "/", "(", "2", "*", "sigma", "**", "2", ")", ")", ")", "\n", "kernels", ".", "append", "(", "g", ")", "\n", "", "kernel", "=", "np", ".", "sqrt", "(", "np", ".", "outer", "(", "kernels", "[", "0", "]", ",", "kernels", "[", "1", "]", ")", ")", "\n", "kernel", "=", "kernel", "/", "kernel", ".", "sum", "(", ")", "\n", "return", "kernel", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Poisson2DMaskFunc.__call__": [[408, 504], ["tuple", "subsample.Poisson2DMaskFunc.choose_acceleration", "subsample.Poisson2DMaskFunc.poisson_disc2d", "subsample.Poisson2DMaskFunc.centered_circle", "numpy.logical_or", "ValueError", "min", "torch.from_numpy", "range", "numpy.logical_or.reshape().astype", "len", "abs", "int", "numpy.logical_or.reshape", "numpy.round"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.data.subsample.MaskFunc.choose_acceleration", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Poisson2DMaskFunc.poisson_disc2d", "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Poisson2DMaskFunc.centered_circle"], ["def", "__call__", "(", "\n", "self", ",", "\n", "shape", ":", "Union", "[", "Sequence", "[", "int", "]", ",", "np", ".", "ndarray", "]", ",", "\n", "seed", ":", "Optional", "[", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "...", "]", "]", "]", "=", "None", ",", "\n", "half_scan_percentage", ":", "Optional", "[", "float", "]", "=", "0.0", ",", "\n", "scale", ":", "Optional", "[", "float", "]", "=", "0.02", ",", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        shape: The shape of the mask to be created. The shape should have at least 3 dimensions. Samples are drawn \\\n        along the second last dimension.\n        seed: Seed for the random number generator. Setting the seed ensures the same mask is generated each time \\\n        for the same shape. The random state is reset afterwards.\n        half_scan_percentage: Optional; Defines a fraction of the k-space data that is not sampled.\n        scale: For autocalibration purposes, data points near the k-space center will be fully sampled within an \\\n        ellipse of which the half-axes will set to the set scale % of the fully sampled region\n\n        Returns\n        -------\n        A tuple of the mask and the number of columns selected.\n        \"\"\"", "\n", "dims", "=", "[", "1", "for", "_", "in", "shape", "]", "\n", "self", ".", "shape", "=", "tuple", "(", "shape", "[", "-", "3", ":", "-", "1", "]", ")", "\n", "dims", "[", "-", "3", ":", "-", "1", "]", "=", "self", ".", "shape", "\n", "\n", "_", ",", "acceleration", "=", "self", ".", "choose_acceleration", "(", ")", "\n", "if", "acceleration", ">", "21.5", "or", "acceleration", "<", "3.5", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Acceleration {acceleration} is not supported for Poisson 2D masking.\"", ")", "\n", "\n", "", "self", ".", "acceleration", "=", "acceleration", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "# TODO: consider moving this to a yaml file", "\n", "rfactor", "=", "[", "\n", "21.22", ",", "\n", "20.32", ",", "\n", "19.06", ",", "\n", "18.22", ",", "\n", "17.41", ",", "\n", "16.56", ",", "\n", "15.86", ",", "\n", "15.12", ",", "\n", "14.42", ",", "\n", "13.88", ",", "\n", "13.17", ",", "\n", "12.76", ",", "\n", "12.21", ",", "\n", "11.72", ",", "\n", "11.09", ",", "\n", "10.68", ",", "\n", "10.35", ",", "\n", "10.02", ",", "\n", "9.61", ",", "\n", "9.22", ",", "\n", "9.03", ",", "\n", "8.66", ",", "\n", "8.28", ",", "\n", "8.1", ",", "\n", "7.74", ",", "\n", "7.62", ",", "\n", "7.32", ",", "\n", "7.04", ",", "\n", "6.94", ",", "\n", "6.61", ",", "\n", "6.5", ",", "\n", "6.27", ",", "\n", "6.15", ",", "\n", "5.96", ",", "\n", "5.83", ",", "\n", "5.59", ",", "\n", "5.46", ",", "\n", "5.38", ",", "\n", "5.15", ",", "\n", "5.05", ",", "\n", "4.9", ",", "\n", "4.86", ",", "\n", "4.67", ",", "\n", "4.56", ",", "\n", "4.52", ",", "\n", "4.41", ",", "\n", "4.31", ",", "\n", "4.21", ",", "\n", "4.11", ",", "\n", "3.99", ",", "\n", "]", "\n", "self", ".", "r", "=", "min", "(", "range", "(", "len", "(", "rfactor", ")", ")", ",", "key", "=", "lambda", "i", ":", "abs", "(", "rfactor", "[", "i", "]", "-", "self", ".", "acceleration", ")", ")", "+", "40", "\n", "\n", "pattern1", "=", "self", ".", "poisson_disc2d", "(", ")", "\n", "pattern2", "=", "self", ".", "centered_circle", "(", ")", "\n", "mask", "=", "np", ".", "logical_or", "(", "pattern1", ",", "pattern2", ")", "\n", "\n", "if", "half_scan_percentage", "!=", "0", ":", "\n", "            ", "mask", "[", ":", "int", "(", "np", ".", "round", "(", "mask", ".", "shape", "[", "0", "]", "*", "half_scan_percentage", ")", ")", ",", ":", "]", "=", "0.0", "\n", "\n", "", "return", "(", "torch", ".", "from_numpy", "(", "mask", ".", "reshape", "(", "dims", ")", ".", "astype", "(", "np", ".", "float32", ")", ")", ",", "acceleration", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Poisson2DMaskFunc.poisson_disc2d": [[505, 645], ["numpy.array", "numpy.linalg.norm", "subsample.Poisson2DMaskFunc.poisson_disc2d.mark_neighbours"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.norm"], ["", "def", "poisson_disc2d", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates a 2D Poisson disc pattern.\"\"\"", "\n", "# Amount of tries before discarding a reference point for new samples", "\n", "k", "=", "10", "\n", "\n", "# Amount of samples to be drawn", "\n", "pattern_shape", "=", "(", "self", ".", "shape", "[", "0", "]", "-", "1", ",", "self", ".", "shape", "[", "1", "]", "-", "1", ")", "\n", "\n", "# Initialize the pattern", "\n", "center", "=", "np", ".", "array", "(", "[", "1.0", "*", "pattern_shape", "[", "0", "]", "/", "2", ",", "1.0", "*", "pattern_shape", "[", "1", "]", "/", "2", "]", ")", "\n", "width", ",", "height", "=", "pattern_shape", "\n", "\n", "# Cell side length (equal to r_min)", "\n", "a", "=", "1", "\n", "\n", "# Number of cells in the x- and y-directions of the grid", "\n", "nx", ",", "ny", "=", "int", "(", "width", "/", "a", ")", ",", "int", "(", "height", "/", "a", ")", "\n", "\n", "# A list of coordinates in the grid of cells", "\n", "coords_list", "=", "[", "(", "ix", ",", "iy", ")", "for", "ix", "in", "range", "(", "nx", "+", "1", ")", "for", "iy", "in", "range", "(", "ny", "+", "1", ")", "]", "\n", "\n", "# Initialize the dictionary of cells: each key is a cell's coordinates, the corresponding value is the index", "\n", "# of that cell's point's that might cause conflict when adding a new point.", "\n", "cells", "=", "{", "coords", ":", "[", "]", "for", "coords", "in", "coords_list", "}", "\n", "centernorm", "=", "np", ".", "linalg", ".", "norm", "(", "center", ")", "\n", "\n", "def", "calc_r", "(", "coords", ")", ":", "\n", "            ", "\"\"\"Calculate r for the given coordinates.\"\"\"", "\n", "return", "(", "(", "np", ".", "linalg", ".", "norm", "(", "np", ".", "asarray", "(", "coords", ")", "-", "center", ")", "/", "centernorm", ")", "*", "240", "+", "50", ")", "/", "self", ".", "r", "\n", "\n", "", "def", "get_cell_coords", "(", "pt", ")", ":", "\n", "            ", "\"\"\"Get the coordinates of the cell that pt = (x,y) falls in.\"\"\"", "\n", "return", "int", "(", "np", ".", "floor_divide", "(", "pt", "[", "0", "]", ",", "a", ")", ")", ",", "int", "(", "np", ".", "floor_divide", "(", "pt", "[", "1", "]", ",", "a", ")", ")", "\n", "\n", "", "def", "mark_neighbours", "(", "idx", ")", ":", "\n", "            ", "\"\"\"Add sample index to the cells within r(point) range of the point.\"\"\"", "\n", "coords", "=", "samples", "[", "idx", "]", "\n", "if", "idx", "in", "cells", "[", "get_cell_coords", "(", "coords", ")", "]", ":", "\n", "# This point is already marked on the grid, so we can skip", "\n", "                ", "return", "\n", "\n", "# Mark the point on the grid", "\n", "", "rx", "=", "calc_r", "(", "coords", ")", "\n", "xvals", "=", "np", ".", "arange", "(", "coords", "[", "0", "]", "-", "rx", ",", "coords", "[", "0", "]", "+", "rx", ")", "\n", "yvals", "=", "np", ".", "arange", "(", "coords", "[", "1", "]", "-", "rx", ",", "coords", "[", "1", "]", "+", "rx", ")", "\n", "\n", "# Get the coordinates of the cells that the point falls in", "\n", "xvals", "=", "xvals", "[", "(", "xvals", ">=", "0", ")", "&", "(", "xvals", "<=", "width", ")", "]", "\n", "yvals", "=", "yvals", "[", "(", "yvals", ">=", "0", ")", "&", "(", "yvals", "<=", "height", ")", "]", "\n", "\n", "def", "dist", "(", "x", ",", "y", ")", ":", "\n", "                ", "\"\"\"Calculate the distance between the point and the cell.\"\"\"", "\n", "return", "np", ".", "sqrt", "(", "(", "coords", "[", "0", "]", "-", "x", ")", "**", "2", "+", "(", "coords", "[", "1", "]", "-", "y", ")", "**", "2", ")", "<", "rx", "\n", "\n", "", "xx", ",", "yy", "=", "np", ".", "meshgrid", "(", "xvals", ",", "yvals", ",", "sparse", "=", "False", ")", "\n", "\n", "# Mark the points in the grid", "\n", "pts", "=", "np", ".", "vstack", "(", "(", "xx", ".", "ravel", "(", ")", ",", "yy", ".", "ravel", "(", ")", ")", ")", ".", "T", "\n", "pts", "=", "pts", "[", "dist", "(", "pts", "[", ":", ",", "0", "]", ",", "pts", "[", ":", ",", "1", "]", ")", "]", "\n", "\n", "return", "[", "cells", "[", "get_cell_coords", "(", "pt", ")", "]", ".", "append", "(", "idx", ")", "for", "pt", "in", "pts", "]", "\n", "\n", "", "def", "point_valid", "(", "pt", ")", ":", "\n", "            ", "\"\"\"Check if the point is valid.\"\"\"", "\n", "rx", "=", "calc_r", "(", "pt", ")", "\n", "if", "rx", "<", "1", ":", "\n", "                ", "if", "np", ".", "linalg", ".", "norm", "(", "pt", "-", "center", ")", "<", "self", ".", "scale", "*", "width", ":", "\n", "                    ", "return", "False", "\n", "", "rx", "=", "1", "\n", "\n", "# Get the coordinates of the cells that the point falls in", "\n", "", "neighbour_idxs", "=", "cells", "[", "get_cell_coords", "(", "pt", ")", "]", "\n", "for", "n", "in", "neighbour_idxs", ":", "\n", "                ", "n_coords", "=", "samples", "[", "n", "]", "\n", "\n", "# Squared distance between or candidate point, pt, and this nearby_pt.", "\n", "distance", "=", "np", ".", "sqrt", "(", "(", "n_coords", "[", "0", "]", "-", "pt", "[", "0", "]", ")", "**", "2", "+", "(", "n_coords", "[", "1", "]", "-", "pt", "[", "1", "]", ")", "**", "2", ")", "\n", "if", "distance", "<", "rx", ":", "\n", "# The points are too close, so pt is not a candidate.", "\n", "                    ", "return", "False", "\n", "\n", "# All points tested: if we're here, pt is", "\n", "", "", "return", "True", "\n", "\n", "", "def", "get_point", "(", "k", ",", "refpt", ")", ":", "\n", "            ", "\"\"\"\n            Try to find a candidate point relative to refpt to emit in the sample. We draw up to k points from the\n            annulus of inner radius r, outer radius 2r around the reference point, refpt. If none of them are suitable\n            return False. Otherwise, return the pt.\n            \"\"\"", "\n", "i", "=", "0", "\n", "rx", "=", "calc_r", "(", "refpt", ")", "\n", "while", "i", "<", "k", ":", "\n", "                ", "rho", ",", "theta", "=", "np", ".", "random", ".", "uniform", "(", "rx", ",", "2", "*", "rx", ")", ",", "np", ".", "random", ".", "uniform", "(", "0", ",", "2", "*", "np", ".", "pi", ")", "\n", "pt", "=", "refpt", "[", "0", "]", "+", "rho", "*", "np", ".", "cos", "(", "theta", ")", ",", "refpt", "[", "1", "]", "+", "rho", "*", "np", ".", "sin", "(", "theta", ")", "\n", "if", "not", "(", "0", "<", "pt", "[", "0", "]", "<", "width", "and", "0", "<", "pt", "[", "1", "]", "<", "height", ")", ":", "\n", "# Off the grid, try again.", "\n", "                    ", "continue", "\n", "", "if", "point_valid", "(", "pt", ")", ":", "\n", "                    ", "return", "pt", "\n", "", "i", "+=", "1", "\n", "\n", "# We failed to find a suitable point in the vicinity of refpt.", "\n", "", "return", "False", "\n", "\n", "# Pick a random point to start with.", "\n", "", "pt", "=", "(", "np", ".", "random", ".", "uniform", "(", "0", ",", "width", ")", ",", "np", ".", "random", ".", "uniform", "(", "0", ",", "height", ")", ")", "\n", "samples", "=", "[", "pt", "]", "\n", "cursample", "=", "0", "\n", "mark_neighbours", "(", "0", ")", "\n", "\n", "# Set active, in the sense that we're going to look for more points in its neighbourhood.", "\n", "active", "=", "[", "0", "]", "\n", "\n", "# As long as there are points in the active list, keep trying to find samples.", "\n", "while", "active", ":", "\n", "# choose a random \"reference\" point from the active list.", "\n", "            ", "idx", "=", "np", ".", "random", ".", "choice", "(", "active", ")", "\n", "refpt", "=", "samples", "[", "idx", "]", "\n", "\n", "# Try to pick a new point relative to the reference point.", "\n", "pt", "=", "get_point", "(", "k", ",", "refpt", ")", "\n", "if", "pt", ":", "\n", "# Point pt is valid: add it to the samples list and mark it as active", "\n", "                ", "samples", ".", "append", "(", "pt", ")", "\n", "cursample", "+=", "1", "\n", "active", ".", "append", "(", "cursample", ")", "\n", "mark_neighbours", "(", "cursample", ")", "\n", "", "else", ":", "\n", "# We had to give up looking for valid points near refpt, so remove it from the list of \"active\" points.", "\n", "                ", "active", ".", "remove", "(", "idx", ")", "\n", "\n", "", "", "samples", "=", "np", ".", "rint", "(", "np", ".", "array", "(", "samples", ")", ")", ".", "astype", "(", "int", ")", "\n", "samples", "=", "np", ".", "unique", "(", "samples", "[", ":", ",", "0", "]", "+", "1j", "*", "samples", "[", ":", ",", "1", "]", ")", "\n", "samples", "=", "np", ".", "column_stack", "(", "(", "samples", ".", "real", ",", "samples", ".", "imag", ")", ")", ".", "astype", "(", "int", ")", "\n", "\n", "poisson_pattern", "=", "np", ".", "zeros", "(", "(", "pattern_shape", "[", "0", "]", "+", "1", ",", "pattern_shape", "[", "1", "]", "+", "1", ")", ",", "dtype", "=", "bool", ")", "\n", "poisson_pattern", "[", "samples", "[", ":", ",", "0", "]", ",", "samples", "[", ":", ",", "1", "]", "]", "=", "True", "\n", "\n", "return", "poisson_pattern", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.Poisson2DMaskFunc.centered_circle": [[646, 654], ["int", "int", "numpy.indices", "int"], "methods", ["None"], ["", "def", "centered_circle", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates a boolean centered circle image using the scale as a radius.\"\"\"", "\n", "center_x", "=", "int", "(", "(", "self", ".", "shape", "[", "0", "]", "-", "1", ")", "/", "2", ")", "\n", "center_y", "=", "int", "(", "(", "self", ".", "shape", "[", "1", "]", "-", "1", ")", "/", "2", ")", "\n", "\n", "X", ",", "Y", "=", "np", ".", "indices", "(", "self", ".", "shape", ")", "\n", "radius", "=", "int", "(", "self", ".", "shape", "[", "0", "]", "*", "self", ".", "scale", ")", "\n", "return", "(", "(", "X", "-", "center_x", ")", "**", "2", "+", "(", "Y", "-", "center_y", ")", "**", "2", ")", "<", "radius", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.temp_seed": [[12, 38], ["rng.get_state", "rng.seed", "rng.set_state"], "function", ["None"], ["@", "contextlib", ".", "contextmanager", "\n", "def", "temp_seed", "(", "rng", ":", "np", ".", "random", ",", "seed", ":", "Optional", "[", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "...", "]", "]", "]", ")", ":", "\n", "    ", "\"\"\"\n    Temporarily sets the seed of the given random number generator.\n\n    Parameters\n    ----------\n    rng: The random number generator.\n    seed: The seed to set.\n\n    Returns\n    -------\n    A context manager.\n    \"\"\"", "\n", "if", "seed", "is", "None", ":", "\n", "        ", "try", ":", "\n", "            ", "yield", "\n", "", "finally", ":", "\n", "            ", "pass", "\n", "", "", "else", ":", "\n", "        ", "state", "=", "rng", ".", "get_state", "(", ")", "\n", "rng", ".", "seed", "(", "seed", ")", "\n", "try", ":", "\n", "            ", "yield", "\n", "", "finally", ":", "\n", "            ", "rng", ".", "set_state", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.subsample.create_mask_for_mask_type": [[656, 683], ["NotImplementedError", "subsample.RandomMaskFunc", "subsample.EquispacedMaskFunc", "subsample.Gaussian1DMaskFunc", "subsample.Gaussian2DMaskFunc", "subsample.Poisson2DMaskFunc"], "function", ["None"], ["", "", "def", "create_mask_for_mask_type", "(", "\n", "mask_type_str", ":", "str", ",", "center_fractions", ":", "Sequence", "[", "float", "]", ",", "accelerations", ":", "Sequence", "[", "int", "]", "\n", ")", "->", "MaskFunc", ":", "\n", "    ", "\"\"\"\n    Creates a MaskFunc object for the given mask type.\n\n    Parameters\n    ----------\n    mask_type_str: The string representation of the mask type.\n    center_fractions: The center fractions for the mask.\n    accelerations: The accelerations for the mask.\n\n    Returns\n    -------\n    A MaskFunc object.\n    \"\"\"", "\n", "if", "mask_type_str", "==", "\"random1d\"", ":", "\n", "        ", "return", "RandomMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "", "if", "mask_type_str", "==", "\"equispaced1d\"", ":", "\n", "        ", "return", "EquispacedMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "", "if", "mask_type_str", "==", "\"gaussian1d\"", ":", "\n", "        ", "return", "Gaussian1DMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "", "if", "mask_type_str", "==", "\"gaussian2d\"", ":", "\n", "        ", "return", "Gaussian2DMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "", "if", "mask_type_str", "==", "\"poisson2d\"", ":", "\n", "        ", "return", "Poisson2DMaskFunc", "(", "center_fractions", ",", "accelerations", ")", "\n", "", "raise", "NotImplementedError", "(", "f\"{mask_type_str} not supported\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.data.dataset.ConcatDataset.__init__": [[31, 72], ["super().__init__", "isinstance", "len", "isinstance", "ValueError", "ValueError", "numpy.floor_divide", "len", "len"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "datasets", ":", "List", "[", "Any", "]", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "sampling_technique", ":", "str", "=", "\"random\"", ",", "\n", "sampling_probabilities", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "global_rank", ":", "int", "=", "0", ",", "\n", "world_size", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "iterables", "=", "[", "None", "]", "*", "len", "(", "datasets", ")", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "global_rank", "=", "global_rank", "\n", "self", ".", "world_size", "=", "world_size", "\n", "self", ".", "sampling_kwargs", "=", "{", "}", "\n", "if", "sampling_technique", "==", "\"random\"", ":", "\n", "            ", "self", ".", "index_generator", "=", "ConcatDataset", ".", "random_generator", "\n", "self", ".", "sampling_kwargs", "[", "\"p\"", "]", "=", "sampling_probabilities", "# type: ignore", "\n", "", "elif", "sampling_technique", "==", "\"round-robin\"", ":", "\n", "            ", "self", ".", "index_generator", "=", "ConcatDataset", ".", "round_robin_generator", "\n", "", "else", ":", "\n", "            ", "supported_sampling_techniques", "=", "[", "\"random\"", ",", "\"round-robin\"", "]", "\n", "raise", "ValueError", "(", "f\"Currently we only support sampling techniques in {supported_sampling_techniques}.\"", ")", "\n", "", "self", ".", "length", "=", "0", "\n", "\n", "if", "isinstance", "(", "datasets", "[", "0", "]", ",", "pt_data", ".", "IterableDataset", ")", ":", "\n", "            ", "self", ".", "kind", "=", "\"iterable\"", "\n", "", "else", ":", "\n", "            ", "self", ".", "kind", "=", "\"map\"", "\n", "\n", "", "for", "dataset", "in", "datasets", ":", "\n", "            ", "isiterable", "=", "isinstance", "(", "dataset", ",", "pt_data", ".", "IterableDataset", ")", "\n", "if", "isiterable", "and", "self", ".", "kind", "!=", "\"iterable\"", "or", "(", "not", "isiterable", "and", "self", ".", "kind", "==", "\"iterable\"", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"All datasets in ConcatDataset must be of the same kind (Iterable or Map).\"", ")", "\n", "\n", "", "if", "self", ".", "kind", "==", "\"map\"", ":", "\n", "                ", "self", ".", "length", "+=", "np", ".", "floor_divide", "(", "len", "(", "dataset", ")", ",", "world_size", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "length", "+=", "len", "(", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.dataset.ConcatDataset.get_iterable": [[73, 81], ["isinstance", "numpy.arange", "iter", "dataset.__iter__", "len", "numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.data.dataset.ConcatDataset.__iter__"], ["", "", "", "def", "get_iterable", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"Returns an iterable dataset.\"\"\"", "\n", "if", "isinstance", "(", "dataset", ",", "pt_data", ".", "IterableDataset", ")", ":", "\n", "            ", "return", "dataset", ".", "__iter__", "(", ")", "\n", "", "indices", "=", "np", ".", "arange", "(", "len", "(", "dataset", ")", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "", "return", "iter", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.dataset.ConcatDataset.__iter__": [[82, 123], ["torch.get_worker_info", "enumerate", "dataset.ConcatDataset.index_generator", "len", "range", "dataset.ConcatDataset.get_iterable", "range", "len", "range", "torch.Subset", "next", "next", "numpy.floor_divide", "numpy.floor_divide", "len", "dataset.ConcatDataset.get_iterable", "len", "len"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.data.dataset.ConcatDataset.get_iterable", "home.repos.pwc.inspect_result.wdika_mridc.data.dataset.ConcatDataset.get_iterable"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns an iterator over the dataset.\"\"\"", "\n", "worker_info", "=", "pt_data", ".", "get_worker_info", "(", ")", "\n", "if", "worker_info", "is", "None", ":", "\n", "            ", "max_elements", "=", "self", ".", "length", "\n", "wid", "=", "0", "\n", "wnum", "=", "1", "\n", "", "else", ":", "\n", "            ", "wid", "=", "worker_info", ".", "id", "\n", "wnum", "=", "worker_info", ".", "num_workers", "\n", "max_elements", "=", "len", "(", "range", "(", "wid", ",", "self", ".", "length", ",", "wnum", ")", ")", "\n", "\n", "", "if", "self", ".", "kind", "==", "\"map\"", ":", "\n", "            ", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "datasets", ")", ")", ":", "\n", "                ", "start_idx", "=", "np", ".", "floor_divide", "(", "len", "(", "self", ".", "datasets", "[", "idx", "]", ")", ",", "self", ".", "world_size", ")", "*", "self", ".", "global_rank", "\n", "end_idx", "=", "start_idx", "+", "np", ".", "floor_divide", "(", "len", "(", "self", ".", "datasets", "[", "idx", "]", ")", ",", "self", ".", "world_size", ")", "\n", "if", "self", ".", "global_rank", "==", "self", ".", "world_size", "-", "1", ":", "\n", "                    ", "end_idx", "=", "len", "(", "self", ".", "datasets", "[", "idx", "]", ")", "\n", "", "indices", "=", "range", "(", "start_idx", "+", "wid", ",", "end_idx", ",", "wnum", ")", "\n", "self", ".", "datasets", "[", "idx", "]", "=", "pt_data", ".", "Subset", "(", "self", ".", "datasets", "[", "idx", "]", ",", "indices", ")", "\n", "\n", "", "", "for", "idx", ",", "dataset", "in", "enumerate", "(", "self", ".", "datasets", ")", ":", "\n", "            ", "iterable", "=", "self", ".", "get_iterable", "(", "dataset", ")", "\n", "self", ".", "iterables", "[", "idx", "]", "=", "iterable", "# type: ignore", "\n", "\n", "", "n", "=", "0", "\n", "ind_gen", "=", "self", ".", "index_generator", "(", "self", ".", "datasets", ",", "**", "self", ".", "sampling_kwargs", ")", "\n", "while", "n", "<", "max_elements", ":", "\n", "            ", "n", "+=", "1", "\n", "try", ":", "\n", "                ", "ind", "=", "next", "(", "ind_gen", ")", "\n", "", "except", "StopIteration", ":", "\n", "                ", "return", "\n", "", "try", ":", "\n", "                ", "val", "=", "next", "(", "self", ".", "iterables", "[", "ind", "]", ")", "# type: ignore", "\n", "if", "self", ".", "kind", "==", "\"map\"", ":", "\n", "                    ", "val", "=", "self", ".", "datasets", "[", "ind", "]", "[", "val", "]", "\n", "", "yield", "val", "\n", "", "except", "StopIteration", ":", "\n", "                ", "self", ".", "iterables", "[", "ind", "]", "=", "self", ".", "get_iterable", "(", "self", ".", "datasets", "[", "ind", "]", ")", "# type: ignore", "\n", "n", "-=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.dataset.ConcatDataset.__len__": [[124, 127], ["None"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the number of elements in the dataset.\"\"\"", "\n", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.dataset.ConcatDataset.round_robin_generator": [[128, 134], ["len", "range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "round_robin_generator", "(", "datasets", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Generates indices in a round-robin fashion.\"\"\"", "\n", "num", "=", "len", "(", "datasets", ")", "\n", "while", "True", ":", "\n", "            ", "yield", "from", "range", "(", "num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.data.dataset.ConcatDataset.random_generator": [[135, 148], ["kwargs.get", "len", "ValueError", "len", "ValueError", "numpy.random.choice", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["", "", "@", "staticmethod", "\n", "def", "random_generator", "(", "datasets", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Generates random indices.\"\"\"", "\n", "p", "=", "kwargs", ".", "get", "(", "\"p\"", ")", "\n", "if", "not", "p", ":", "\n", "            ", "raise", "ValueError", "(", "\"Random generator expects a 'p' keyowrd argument for sampling probabilities.\"", ")", "\n", "\n", "", "num", "=", "len", "(", "datasets", ")", "\n", "if", "len", "(", "p", ")", "!=", "num", ":", "\n", "            ", "raise", "ValueError", "(", "\"Length of probabilities list must be equal to the number of datasets.\"", ")", "\n", "\n", "", "while", "True", ":", "\n", "            ", "yield", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "num", ")", ",", "p", "=", "p", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.parts.transforms.MRIDataTransforms.__init__": [[22, 78], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "coil_combination_method", ":", "str", "=", "\"SENSE\"", ",", "\n", "dimensionality", ":", "int", "=", "2", ",", "\n", "mask_func", ":", "Optional", "[", "List", "[", "MaskFunc", "]", "]", "=", "None", ",", "\n", "shift_mask", ":", "bool", "=", "False", ",", "\n", "mask_center_scale", ":", "Optional", "[", "float", "]", "=", "0.02", ",", "\n", "half_scan_percentage", ":", "float", "=", "0.0", ",", "\n", "crop_size", ":", "Optional", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "kspace_crop", ":", "bool", "=", "False", ",", "\n", "crop_before_masking", ":", "bool", "=", "True", ",", "\n", "kspace_zero_filling_size", ":", "Optional", "[", "Tuple", "]", "=", "None", ",", "\n", "normalize_inputs", ":", "bool", "=", "False", ",", "\n", "fft_centered", ":", "bool", "=", "True", ",", "\n", "fft_normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Sequence", "[", "int", "]", "=", "None", ",", "\n", "coil_dim", ":", "int", "=", "0", ",", "\n", "use_seed", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the data transform.\n\n        Parameters\n        ----------\n        coil_combination_method : The coil combination method to use. Default: 'SENSE'\n        dimensionality : The dimensionality of the data. Default: 2\n        mask_func: The function that masks the kspace.\n        shift_mask: Whether to shift the mask.\n        mask_center_scale: The scale of the center of the mask.\n        half_scan_percentage: The percentage of the scan to be used.\n        crop_size: The size of the crop.\n        kspace_crop: Whether to crop the kspace.\n        crop_before_masking: Whether to crop before masking.\n        kspace_zero_filling_size: The size of padding in kspace -> zero filling.\n        normalize_inputs: Whether to normalize the inputs.\n        fft_centered: Whether to center the fft.\n        fft_normalization: The normalization of the fft.\n        spatial_dims: The spatial dimensions of the data.\n        coil_dim: The coil dimension of the data.\n        use_seed: Whether to use the seed.\n        \"\"\"", "\n", "self", ".", "coil_combination_method", "=", "coil_combination_method", "\n", "self", ".", "mask_func", "=", "mask_func", "\n", "self", ".", "shift_mask", "=", "shift_mask", "\n", "self", ".", "mask_center_scale", "=", "mask_center_scale", "\n", "self", ".", "half_scan_percentage", "=", "half_scan_percentage", "\n", "self", ".", "crop_size", "=", "crop_size", "\n", "self", ".", "kspace_crop", "=", "kspace_crop", "\n", "self", ".", "crop_before_masking", "=", "crop_before_masking", "\n", "self", ".", "kspace_zero_filling_size", "=", "kspace_zero_filling_size", "\n", "self", ".", "normalize_inputs", "=", "normalize_inputs", "\n", "self", ".", "fft_centered", "=", "fft_centered", "\n", "self", ".", "fft_normalization", "=", "fft_normalization", "\n", "self", ".", "spatial_dims", "=", "spatial_dims", "if", "spatial_dims", "is", "not", "None", "else", "[", "-", "2", ",", "-", "1", "]", "\n", "self", ".", "coil_dim", "=", "coil_dim", "-", "1", "if", "dimensionality", "==", "2", "else", "coil_dim", "\n", "self", ".", "use_seed", "=", "use_seed", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.parts.transforms.MRIDataTransforms.__call__": [[79, 471], ["mridc.collections.common.parts.utils.to_tensor", "torch.view_as_complex", "torch.abs", "mridc.collections.common.parts.utils.to_tensor", "numpy.floor_divide", "numpy.floor_divide", "torch.view_as_complex", "torch.nn.functional.pad", "torch.view_as_real", "mridc.collections.common.parts.fft.fft2", "torch.view_as_complex", "torch.nn.functional.pad", "torch.view_as_real", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.utils.to_tensor", "torch.tensor", "transforms.MRIDataTransforms.coil_combination_method.upper", "mridc.collections.common.parts.utils.rss", "tuple", "min", "min", "mridc.collections.reconstruction.parts.utils.center_crop", "torch.ones.byte", "isinstance", "mridc.collections.reconstruction.parts.utils.center_crop().unsqueeze", "isinstance", "abs", "abs", "mridc.collections.common.parts.fft.ifft2", "transforms.MRIDataTransforms.coil_combination_method.upper", "torch.max", "map", "int", "int", "int", "int", "mridc.collections.reconstruction.parts.utils.complex_center_crop", "mridc.collections.common.parts.fft.fft2", "torch.tensor", "torch.tensor", "torch.ones", "torch.from_numpy", "numpy.expand_dims", "torch.from_numpy().unsqueeze().unsqueeze", "torch.ones.unsqueeze().unsqueeze", "torch.fft.fftshift", "mridc.collections.reconstruction.parts.utils.apply_mask", "torch.ones.byte", "mridc.collections.reconstruction.parts.utils.complex_center_crop", "mridc.collections.common.parts.fft.fft2", "torch.max", "mridc.collections.common.parts.utils.sense", "mridc.collections.common.parts.utils.to_tensor", "torch.abs", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.reconstruction.parts.utils.complex_center_crop", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.reconstruction.parts.utils.complex_center_crop", "mridc.collections.reconstruction.parts.utils.complex_center_crop", "torch.ones.permute", "mridc.collections.reconstruction.parts.utils.center_crop", "mridc.collections.reconstruction.parts.utils.apply_mask", "masked_kspaces.append", "masks.append", "accs.append", "mridc.collections.reconstruction.parts.utils.complex_center_crop", "mridc.collections.reconstruction.parts.utils.center_crop", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.fft.fft2", "torch.max", "torch.max", "torch.abs", "int", "int", "mridc.collections.common.parts.fft.ifft2", "torch.tensor", "ValueError", "mridc.collections.reconstruction.parts.utils.complex_center_crop", "mridc.collections.reconstruction.parts.utils.complex_center_crop", "mridc.collections.common.parts.fft.ifft2", "numpy.around", "torch.ones", "torch.from_numpy().unsqueeze", "torch.ones.unsqueeze", "_mask.byte", "mridc.collections.common.parts.fft.ifft2", "torch.ones.squeeze", "mridc.collections.common.parts.fft.ifft2", "masked_kspaces.append", "torch.max", "mridc.collections.common.parts.fft.fft2", "torch.abs", "torch.abs", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.fft.fft2", "torch.max", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.fft.ifft2", "masked_kspaces.append", "torch.abs", "mridc.collections.common.parts.fft.ifft2", "mridc.collections.common.parts.fft.fft2", "torch.fft.ifftn", "torch.view_as_real", "torch.ones.sum", "torch.from_numpy", "torch.abs", "mridc.collections.common.parts.fft.fft2", "mridc.collections.common.parts.fft.ifft2", "masked_kspaces.append", "torch.fft.ifftn", "masked_kspaces.append", "mridc.collections.common.parts.fft.ifft2", "torch.view_as_complex", "torch.max", "torch.fft.fftn", "mridc.collections.common.parts.fft.fft2", "torch.view_as_complex", "torch.max", "torch.view_as_real", "torch.abs", "torch.abs", "torch.fft.fftn"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.to_tensor", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.to_tensor", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.didn.didn.DUB.pad", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.to_tensor", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.rss", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.sense", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.to_tensor", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2"], ["", "def", "__call__", "(", "\n", "self", ",", "\n", "kspace", ":", "np", ".", "ndarray", ",", "\n", "sensitivity_map", ":", "np", ".", "ndarray", ",", "\n", "mask", ":", "np", ".", "ndarray", ",", "\n", "eta", ":", "np", ".", "ndarray", ",", "\n", "target", ":", "np", ".", "ndarray", ",", "\n", "attrs", ":", "Dict", ",", "\n", "fname", ":", "str", ",", "\n", "slice_idx", ":", "int", ",", "\n", ")", "->", "Tuple", "[", "\n", "torch", ".", "Tensor", ",", "\n", "Union", "[", "Union", "[", "List", ",", "torch", ".", "Tensor", "]", ",", "torch", ".", "Tensor", "]", ",", "\n", "Union", "[", "Optional", "[", "torch", ".", "Tensor", "]", ",", "Any", "]", ",", "\n", "Union", "[", "List", ",", "Any", "]", ",", "\n", "Union", "[", "Optional", "[", "torch", ".", "Tensor", "]", ",", "Any", "]", ",", "\n", "Union", "[", "torch", ".", "Tensor", ",", "Any", "]", ",", "\n", "str", ",", "\n", "int", ",", "\n", "Union", "[", "Union", "[", "List", ",", "torch", ".", "Tensor", "]", ",", "Any", "]", ",", "\n", "]", ":", "\n", "        ", "\"\"\"\n        Apply the data transform.\n\n        Parameters\n        ----------\n        kspace: The kspace.\n        sensitivity_map: The sensitivity map.\n        mask: The mask.\n        eta: The initial estimation.\n        target: The target.\n        attrs: The attributes.\n        fname: The file name.\n        slice_idx: The slice number.\n\n        Returns\n        -------\n        The transformed data.\n        \"\"\"", "\n", "kspace", "=", "to_tensor", "(", "kspace", ")", "\n", "\n", "# This condition is necessary in case of auto estimation of sense maps.", "\n", "if", "sensitivity_map", "is", "not", "None", "and", "sensitivity_map", ".", "size", "!=", "0", ":", "\n", "            ", "sensitivity_map", "=", "to_tensor", "(", "sensitivity_map", ")", "\n", "\n", "# Apply zero-filling on kspace", "\n", "", "if", "self", ".", "kspace_zero_filling_size", "is", "not", "None", "and", "self", ".", "kspace_zero_filling_size", "not", "in", "(", "\"\"", ",", "\"None\"", ")", ":", "\n", "            ", "padding_top", "=", "np", ".", "floor_divide", "(", "abs", "(", "int", "(", "self", ".", "kspace_zero_filling_size", "[", "0", "]", ")", "-", "kspace", ".", "shape", "[", "1", "]", ")", ",", "2", ")", "\n", "padding_bottom", "=", "padding_top", "\n", "padding_left", "=", "np", ".", "floor_divide", "(", "abs", "(", "int", "(", "self", ".", "kspace_zero_filling_size", "[", "1", "]", ")", "-", "kspace", ".", "shape", "[", "2", "]", ")", ",", "2", ")", "\n", "padding_right", "=", "padding_left", "\n", "\n", "kspace", "=", "torch", ".", "view_as_complex", "(", "kspace", ")", "\n", "kspace", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "\n", "kspace", ",", "pad", "=", "(", "padding_left", ",", "padding_right", ",", "padding_top", ",", "padding_bottom", ")", ",", "mode", "=", "\"constant\"", ",", "value", "=", "0", "\n", ")", "\n", "kspace", "=", "torch", ".", "view_as_real", "(", "kspace", ")", "\n", "\n", "sensitivity_map", "=", "fft2", "(", "\n", "sensitivity_map", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "sensitivity_map", "=", "torch", ".", "view_as_complex", "(", "sensitivity_map", ")", "\n", "sensitivity_map", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "\n", "sensitivity_map", ",", "\n", "pad", "=", "(", "padding_left", ",", "padding_right", ",", "padding_top", ",", "padding_bottom", ")", ",", "\n", "mode", "=", "\"constant\"", ",", "\n", "value", "=", "0", ",", "\n", ")", "\n", "sensitivity_map", "=", "torch", ".", "view_as_real", "(", "sensitivity_map", ")", "\n", "sensitivity_map", "=", "ifft2", "(", "\n", "sensitivity_map", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "\n", "# Initial estimation", "\n", "", "eta", "=", "to_tensor", "(", "eta", ")", "if", "eta", "is", "not", "None", "and", "eta", ".", "size", "!=", "0", "else", "torch", ".", "tensor", "(", "[", "]", ")", "\n", "\n", "# If the target is not given, we need to compute it.", "\n", "if", "self", ".", "coil_combination_method", ".", "upper", "(", ")", "==", "\"RSS\"", ":", "\n", "            ", "target", "=", "rss", "(", "\n", "ifft2", "(", "\n", "kspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", "", "elif", "self", ".", "coil_combination_method", ".", "upper", "(", ")", "==", "\"SENSE\"", ":", "\n", "            ", "if", "sensitivity_map", "is", "not", "None", "and", "sensitivity_map", ".", "size", "!=", "0", ":", "\n", "                ", "target", "=", "sense", "(", "\n", "ifft2", "(", "\n", "kspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "sensitivity_map", ",", "\n", "dim", "=", "self", ".", "coil_dim", ",", "\n", ")", "\n", "", "", "elif", "target", "is", "not", "None", "and", "target", ".", "size", "!=", "0", ":", "\n", "            ", "target", "=", "to_tensor", "(", "target", ")", "\n", "", "elif", "\"target\"", "in", "attrs", "or", "\"target_rss\"", "in", "attrs", ":", "\n", "            ", "target", "=", "torch", ".", "tensor", "(", "attrs", "[", "\"target\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"No target found\"", ")", "\n", "\n", "", "target", "=", "torch", ".", "view_as_complex", "(", "target", ")", "\n", "target", "=", "torch", ".", "abs", "(", "target", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "target", ")", ")", ")", "\n", "\n", "seed", "=", "tuple", "(", "map", "(", "ord", ",", "fname", ")", ")", "if", "self", ".", "use_seed", "else", "None", "\n", "acq_start", "=", "attrs", "[", "\"padding_left\"", "]", "if", "\"padding_left\"", "in", "attrs", "else", "0", "\n", "acq_end", "=", "attrs", "[", "\"padding_right\"", "]", "if", "\"padding_left\"", "in", "attrs", "else", "0", "\n", "\n", "# This should be outside the condition because it needs to be returned in the end, even if cropping is off.", "\n", "# crop_size = torch.tensor([attrs[\"recon_size\"][0], attrs[\"recon_size\"][1]])", "\n", "crop_size", "=", "target", ".", "shape", "\n", "if", "self", ".", "crop_size", "is", "not", "None", "and", "self", ".", "crop_size", "not", "in", "(", "\"\"", ",", "\"None\"", ")", ":", "\n", "# Check for smallest size against the target shape.", "\n", "            ", "h", "=", "min", "(", "int", "(", "self", ".", "crop_size", "[", "0", "]", ")", ",", "target", ".", "shape", "[", "0", "]", ")", "\n", "w", "=", "min", "(", "int", "(", "self", ".", "crop_size", "[", "1", "]", ")", ",", "target", ".", "shape", "[", "1", "]", ")", "\n", "\n", "# Check for smallest size against the stored recon shape in metadata.", "\n", "if", "crop_size", "[", "0", "]", "!=", "0", ":", "\n", "                ", "h", "=", "h", "if", "h", "<=", "crop_size", "[", "0", "]", "else", "crop_size", "[", "0", "]", "\n", "", "if", "crop_size", "[", "1", "]", "!=", "0", ":", "\n", "                ", "w", "=", "w", "if", "w", "<=", "crop_size", "[", "1", "]", "else", "crop_size", "[", "1", "]", "\n", "\n", "", "self", ".", "crop_size", "=", "(", "int", "(", "h", ")", ",", "int", "(", "w", ")", ")", "\n", "\n", "target", "=", "center_crop", "(", "target", ",", "self", ".", "crop_size", ")", "\n", "if", "sensitivity_map", "is", "not", "None", "and", "sensitivity_map", ".", "size", "!=", "0", ":", "\n", "                ", "sensitivity_map", "=", "(", "\n", "ifft2", "(", "\n", "complex_center_crop", "(", "\n", "fft2", "(", "\n", "sensitivity_map", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "self", ".", "crop_size", ",", "\n", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "if", "self", ".", "kspace_crop", "\n", "else", "complex_center_crop", "(", "sensitivity_map", ",", "self", ".", "crop_size", ")", "\n", ")", "\n", "\n", "", "if", "eta", "is", "not", "None", "and", "eta", ".", "ndim", ">", "2", ":", "\n", "                ", "eta", "=", "(", "\n", "ifft2", "(", "\n", "complex_center_crop", "(", "\n", "fft2", "(", "\n", "eta", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "self", ".", "crop_size", ",", "\n", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "if", "self", ".", "kspace_crop", "\n", "else", "complex_center_crop", "(", "eta", ",", "self", ".", "crop_size", ")", "\n", ")", "\n", "\n", "# Cropping before masking will maintain the shape of original kspace intact for masking.", "\n", "", "", "if", "self", ".", "crop_size", "is", "not", "None", "and", "self", ".", "crop_size", "not", "in", "(", "\"\"", ",", "\"None\"", ")", "and", "self", ".", "crop_before_masking", ":", "\n", "            ", "kspace", "=", "(", "\n", "complex_center_crop", "(", "kspace", ",", "self", ".", "crop_size", ")", "\n", "if", "self", ".", "kspace_crop", "\n", "else", "fft2", "(", "\n", "complex_center_crop", "(", "\n", "ifft2", "(", "\n", "kspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "self", ".", "crop_size", ",", "\n", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", ")", "\n", "\n", "# Undersample kspace if undersampling is enabled.", "\n", "", "if", "self", ".", "mask_func", "is", "None", ":", "\n", "            ", "masked_kspace", "=", "kspace", "\n", "acc", "=", "torch", ".", "tensor", "(", "[", "np", ".", "around", "(", "mask", ".", "size", "/", "mask", ".", "sum", "(", ")", ")", "]", ")", "if", "mask", "is", "not", "None", "else", "torch", ".", "tensor", "(", "[", "1", "]", ")", "\n", "\n", "if", "mask", "is", "None", ":", "\n", "                ", "mask", "=", "torch", ".", "ones", "(", "\n", "[", "masked_kspace", ".", "shape", "[", "-", "3", "]", ",", "masked_kspace", ".", "shape", "[", "-", "2", "]", "]", ",", "dtype", "=", "torch", ".", "float32", "# type: ignore", "\n", ")", "\n", "", "else", ":", "\n", "                ", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", "\n", "if", "mask", ".", "shape", "[", "0", "]", "==", "masked_kspace", ".", "shape", "[", "2", "]", ":", "# type: ignore", "\n", "                    ", "mask", "=", "mask", ".", "permute", "(", "1", ",", "0", ")", "\n", "", "elif", "mask", ".", "shape", "[", "0", "]", "!=", "masked_kspace", ".", "shape", "[", "1", "]", ":", "# type: ignore", "\n", "                    ", "mask", "=", "torch", ".", "ones", "(", "\n", "[", "masked_kspace", ".", "shape", "[", "-", "3", "]", ",", "masked_kspace", ".", "shape", "[", "-", "2", "]", "]", ",", "dtype", "=", "torch", ".", "float32", "# type: ignore", "\n", ")", "\n", "\n", "", "", "if", "mask", ".", "ndim", "==", "1", ":", "\n", "                ", "mask", "=", "np", ".", "expand_dims", "(", "mask", ",", "axis", "=", "0", ")", "\n", "\n", "", "if", "mask", ".", "shape", "[", "-", "2", "]", "==", "1", ":", "# 1D mask", "\n", "                ", "mask", "=", "torch", ".", "from_numpy", "(", "mask", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "else", ":", "# 2D mask", "\n", "# Crop loaded mask.", "\n", "                ", "if", "self", ".", "crop_size", "is", "not", "None", "and", "self", ".", "crop_size", "not", "in", "(", "\"\"", ",", "\"None\"", ")", ":", "\n", "                    ", "mask", "=", "center_crop", "(", "mask", ",", "self", ".", "crop_size", ")", "\n", "\n", "", "mask", "=", "mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "if", "self", ".", "shift_mask", ":", "\n", "                ", "mask", "=", "torch", ".", "fft", ".", "fftshift", "(", "mask", ",", "dim", "=", "[", "-", "3", ",", "-", "2", "]", ")", "\n", "\n", "", "masked_kspace", "=", "masked_kspace", "*", "mask", "\n", "mask", "=", "mask", ".", "byte", "(", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "mask_func", ",", "list", ")", ":", "\n", "            ", "masked_kspaces", "=", "[", "]", "\n", "masks", "=", "[", "]", "\n", "accs", "=", "[", "]", "\n", "for", "m", "in", "self", ".", "mask_func", ":", "\n", "                ", "_masked_kspace", ",", "_mask", ",", "_acc", "=", "apply_mask", "(", "\n", "kspace", ",", "\n", "m", ",", "\n", "seed", ",", "\n", "(", "acq_start", ",", "acq_end", ")", ",", "\n", "shift", "=", "self", ".", "shift_mask", ",", "\n", "half_scan_percentage", "=", "self", ".", "half_scan_percentage", ",", "\n", "center_scale", "=", "self", ".", "mask_center_scale", ",", "\n", ")", "\n", "masked_kspaces", ".", "append", "(", "_masked_kspace", ")", "\n", "masks", ".", "append", "(", "_mask", ".", "byte", "(", ")", ")", "\n", "accs", ".", "append", "(", "_acc", ")", "\n", "", "masked_kspace", "=", "masked_kspaces", "\n", "mask", "=", "masks", "\n", "acc", "=", "accs", "\n", "", "else", ":", "\n", "            ", "masked_kspace", ",", "mask", ",", "acc", "=", "apply_mask", "(", "\n", "kspace", ",", "\n", "self", ".", "mask_func", "[", "0", "]", ",", "# type: ignore", "\n", "seed", ",", "\n", "(", "acq_start", ",", "acq_end", ")", ",", "\n", "shift", "=", "self", ".", "shift_mask", ",", "\n", "half_scan_percentage", "=", "self", ".", "half_scan_percentage", ",", "\n", "center_scale", "=", "self", ".", "mask_center_scale", ",", "\n", ")", "\n", "mask", "=", "mask", ".", "byte", "(", ")", "\n", "\n", "# Cropping after masking.", "\n", "", "if", "self", ".", "crop_size", "is", "not", "None", "and", "self", ".", "crop_size", "not", "in", "(", "\"\"", ",", "\"None\"", ")", "and", "not", "self", ".", "crop_before_masking", ":", "\n", "            ", "masked_kspace", "=", "(", "\n", "complex_center_crop", "(", "masked_kspace", ",", "self", ".", "crop_size", ")", "\n", "if", "self", ".", "kspace_crop", "\n", "else", "fft2", "(", "\n", "complex_center_crop", "(", "\n", "ifft2", "(", "\n", "masked_kspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "self", ".", "crop_size", ",", "\n", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", ")", "\n", "\n", "mask", "=", "center_crop", "(", "mask", ".", "squeeze", "(", "-", "1", ")", ",", "self", ".", "crop_size", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "# Normalize by the max value.", "\n", "", "if", "self", ".", "normalize_inputs", ":", "\n", "            ", "if", "isinstance", "(", "self", ".", "mask_func", ",", "list", ")", ":", "\n", "                ", "masked_kspaces", "=", "[", "]", "\n", "for", "y", "in", "masked_kspace", ":", "\n", "                    ", "if", "self", ".", "fft_normalization", "in", "(", "\"orthogonal\"", ",", "\"orthogonal_norm_only\"", ",", "\"ortho\"", ")", ":", "\n", "                        ", "imspace", "=", "ifft2", "(", "\n", "y", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "imspace", "=", "imspace", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "imspace", ")", ")", "\n", "masked_kspaces", ".", "append", "(", "\n", "fft2", "(", "\n", "imspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", ")", "\n", "", "elif", "self", ".", "fft_normalization", "==", "\"fft_norm\"", ":", "\n", "                        ", "imspace", "=", "ifft2", "(", "\n", "y", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "masked_kspaces", ".", "append", "(", "\n", "fft2", "(", "\n", "imspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", ")", "\n", "", "elif", "self", ".", "fft_normalization", "==", "\"backward\"", ":", "\n", "                        ", "imspace", "=", "ifft2", "(", "\n", "y", ",", "centered", "=", "self", ".", "fft_centered", ",", "normalization", "=", "\"backward\"", ",", "spatial_dims", "=", "self", ".", "spatial_dims", "\n", ")", "\n", "masked_kspaces", ".", "append", "(", "\n", "fft2", "(", "\n", "imspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "\"backward\"", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "imspace", "=", "torch", ".", "fft", ".", "ifftn", "(", "torch", ".", "view_as_complex", "(", "y", ")", ",", "dim", "=", "[", "-", "2", ",", "-", "1", "]", ",", "norm", "=", "None", ")", "\n", "imspace", "=", "imspace", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "imspace", ")", ")", "\n", "masked_kspaces", ".", "append", "(", "torch", ".", "view_as_real", "(", "torch", ".", "fft", ".", "fftn", "(", "imspace", ",", "dim", "=", "[", "-", "2", ",", "-", "1", "]", ",", "norm", "=", "None", ")", ")", ")", "\n", "", "", "masked_kspace", "=", "masked_kspaces", "\n", "", "elif", "self", ".", "fft_normalization", "in", "(", "\"orthogonal\"", ",", "\"orthogonal_norm_only\"", ",", "\"ortho\"", ")", ":", "\n", "                ", "imspace", "=", "ifft2", "(", "\n", "masked_kspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "imspace", "=", "imspace", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "imspace", ")", ")", "\n", "masked_kspace", "=", "fft2", "(", "\n", "imspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "", "elif", "self", ".", "fft_normalization", "==", "\"fft_norm\"", ":", "\n", "                ", "masked_kspace", "=", "fft2", "(", "\n", "ifft2", "(", "\n", "masked_kspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "self", ".", "fft_normalization", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "", "elif", "self", ".", "fft_normalization", "==", "\"backward\"", ":", "\n", "                ", "masked_kspace", "=", "fft2", "(", "\n", "ifft2", "(", "\n", "masked_kspace", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "\"backward\"", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", ",", "\n", "centered", "=", "self", ".", "fft_centered", ",", "\n", "normalization", "=", "\"backward\"", ",", "\n", "spatial_dims", "=", "self", ".", "spatial_dims", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "imspace", "=", "torch", ".", "fft", ".", "ifftn", "(", "torch", ".", "view_as_complex", "(", "masked_kspace", ")", ",", "dim", "=", "[", "-", "2", ",", "-", "1", "]", ",", "norm", "=", "None", ")", "\n", "imspace", "=", "imspace", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "imspace", ")", ")", "\n", "masked_kspace", "=", "torch", ".", "view_as_real", "(", "torch", ".", "fft", ".", "fftn", "(", "imspace", ",", "dim", "=", "[", "-", "2", ",", "-", "1", "]", ",", "norm", "=", "None", ")", ")", "\n", "\n", "", "if", "sensitivity_map", ".", "size", "!=", "0", ":", "\n", "                ", "sensitivity_map", "=", "sensitivity_map", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "sensitivity_map", ")", ")", "\n", "\n", "", "if", "eta", ".", "size", "!=", "0", "and", "eta", ".", "ndim", ">", "2", ":", "\n", "                ", "eta", "=", "eta", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "eta", ")", ")", "\n", "\n", "", "target", "=", "target", "/", "torch", ".", "max", "(", "torch", ".", "abs", "(", "target", ")", ")", "\n", "\n", "", "return", "kspace", ",", "masked_kspace", ",", "sensitivity_map", ",", "mask", ",", "eta", ",", "target", ",", "fname", ",", "slice_idx", ",", "acc", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.apply_mask": [[23, 64], ["numpy.array", "mask_func", "torch.fft.fftshift"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift"], ["return", "bool", "(", "not", "sys", ".", "platform", ".", "lower", "(", ")", ".", "startswith", "(", "\"win\"", ")", "and", "get_envbool", "(", "MRIDC_ENV_VARNAME_ENABLE_COLORING", ",", "False", ")", ")", "\n", "\n", "\n", "", "def", "to_unicode", "(", "value", ")", ":", "\n", "    ", "\"\"\"\n    Converts a string to unicode. If the string is already unicode, it is returned as is. If it is a byte string, it is\n    decoded using utf-8.\n\n    Parameters\n    ----------\n    value: The string to convert.\n        str\n\n    Returns\n    -------\n    The converted string.\n        str\n    \"\"\"", "\n", "try", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "(", "str", ",", "type", "(", "None", ")", ")", ")", ":", "\n", "            ", "return", "value", "\n", "\n", "", "if", "not", "isinstance", "(", "value", ",", "bytes", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Expected bytes, unicode, or None; got %r\"", "%", "type", "(", "value", ")", ")", "\n", "\n", "", "return", "value", ".", "decode", "(", "\"utf-8\"", ")", "\n", "\n", "", "except", "UnicodeDecodeError", ":", "\n", "        ", "return", "repr", "(", "value", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.mask_center": [[66, 97], ["torch.zeros_like", "isinstance", "isinstance"], "function", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.batched_mask_center": [[99, 131], ["ValueError", "ValueError", "ValueError", "utils.mask_center", "torch.zeros_like", "enumerate", "int", "int", "zip"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.mask_center"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop": [[133, 156], ["torch.div", "torch.div", "ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_center_crop": [[158, 181], ["torch.div", "torch.div", "ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop_to_smallest": [[183, 207], ["min", "min", "utils.center_crop", "utils.center_crop"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.center_crop"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.ptl_overrides.MRIDCNativeMixedPrecisionPlugin.__init__": [[13, 16], ["pytorch_lightning.plugins.precision.native_amp.NativeMixedPrecisionPlugin.__init__", "torch.cuda.amp.GradScaler"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "init_scale", ":", "float", "=", "2", "**", "32", ",", "growth_interval", ":", "int", "=", "1000", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "precision", "=", "16", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "scaler", "=", "torch", ".", "cuda", ".", "amp", ".", "GradScaler", "(", "init_scale", "=", "init_scale", ",", "growth_interval", "=", "growth_interval", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2": [[14, 52], ["torch.fft.fft2", "torch.view_as_real", "torch.view_as_complex", "fft.ifftshift", "fft.fftshift"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift"], ["def", "fft2", "(", "\n", "data", ":", "torch", ".", "Tensor", ",", "\n", "centered", ":", "bool", "=", "True", ",", "\n", "normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Sequence", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Apply 2 dimensional Fast Fourier Transform.\n\n    Parameters\n    ----------\n    data: Complex valued input data containing at least 3 dimensions: dimensions -2 & -1 are spatial dimensions. All\n    other dimensions are assumed to be batch dimensions.\n    centered: Whether to center the fft.\n    normalization: \"ortho\" is the default normalization used by PyTorch. Can be changed to \"ortho\" or None.\n    spatial_dims: dimensions to apply the FFT\n\n    Returns\n    -------\n    The FFT of the input.\n    \"\"\"", "\n", "if", "data", ".", "shape", "[", "-", "1", "]", "==", "2", ":", "\n", "        ", "data", "=", "torch", ".", "view_as_complex", "(", "data", ")", "\n", "\n", "", "if", "spatial_dims", "is", "None", ":", "\n", "        ", "spatial_dims", "=", "[", "-", "2", ",", "-", "1", "]", "\n", "\n", "", "if", "centered", ":", "\n", "        ", "data", "=", "ifftshift", "(", "data", ",", "dim", "=", "spatial_dims", ")", "\n", "\n", "", "data", "=", "torch", ".", "fft", ".", "fft2", "(", "data", ",", "dim", "=", "spatial_dims", ",", "norm", "=", "normalization", ")", "\n", "\n", "if", "centered", ":", "\n", "        ", "data", "=", "fftshift", "(", "data", ",", "dim", "=", "spatial_dims", ")", "\n", "\n", "", "data", "=", "torch", ".", "view_as_real", "(", "data", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2": [[54, 92], ["torch.fft.ifft2", "torch.view_as_real", "torch.view_as_complex", "fft.ifftshift", "fft.fftshift"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifft2", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift", "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift"], ["", "def", "ifft2", "(", "\n", "data", ":", "torch", ".", "Tensor", ",", "\n", "centered", ":", "bool", "=", "True", ",", "\n", "normalization", ":", "str", "=", "\"ortho\"", ",", "\n", "spatial_dims", ":", "Sequence", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Apply 2 dimensional Inverse Fast Fourier Transform.\n\n    Parameters\n    ----------\n    data: Complex valued input data containing at least 3 dimensions: dimensions -2 & -1 are spatial dimensions. All\n    other dimensions are assumed to be batch dimensions.\n    centered: Whether to center the fft.\n    normalization: \"ortho\" is the default normalization used by PyTorch. Can be changed to \"ortho\" or None.\n    spatial_dims: dimensions to apply the FFT\n\n    Returns\n    -------\n    The FFT of the input.\n    \"\"\"", "\n", "if", "data", ".", "shape", "[", "-", "1", "]", "==", "2", ":", "\n", "        ", "data", "=", "torch", ".", "view_as_complex", "(", "data", ")", "\n", "\n", "", "if", "spatial_dims", "is", "None", ":", "\n", "        ", "spatial_dims", "=", "[", "-", "2", ",", "-", "1", "]", "\n", "\n", "", "if", "centered", ":", "\n", "        ", "data", "=", "ifftshift", "(", "data", ",", "dim", "=", "spatial_dims", ")", "\n", "\n", "", "data", "=", "torch", ".", "fft", ".", "ifft2", "(", "data", ",", "dim", "=", "spatial_dims", ",", "norm", "=", "normalization", ")", "\n", "\n", "if", "centered", ":", "\n", "        ", "data", "=", "fftshift", "(", "data", ",", "dim", "=", "spatial_dims", ")", "\n", "\n", "", "data", "=", "torch", ".", "view_as_real", "(", "data", ")", "\n", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.roll_one_dim": [[94, 116], ["x.size", "x.narrow", "x.narrow", "torch.cat", "x.size", "x.size"], "function", ["None"], ["", "def", "roll_one_dim", "(", "x", ":", "torch", ".", "Tensor", ",", "shift", ":", "int", ",", "dim", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Similar to roll but for only one dim.\n\n    Parameters\n    ----------\n    x: A PyTorch tensor.\n    shift: Amount to roll.\n    dim: Which dimension to roll.\n\n    Returns\n    -------\n    Rolled version of x.\n    \"\"\"", "\n", "shift", "%=", "x", ".", "size", "(", "dim", ")", "\n", "if", "shift", "==", "0", ":", "\n", "        ", "return", "x", "\n", "\n", "", "left", "=", "x", ".", "narrow", "(", "dim", ",", "0", ",", "x", ".", "size", "(", "dim", ")", "-", "shift", ")", "\n", "right", "=", "x", ".", "narrow", "(", "dim", ",", "x", ".", "size", "(", "dim", ")", "-", "shift", ",", "shift", ")", "\n", "\n", "return", "torch", ".", "cat", "(", "(", "right", ",", "left", ")", ",", "dim", "=", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.roll": [[118, 139], ["zip", "len", "len", "ValueError", "fft.roll_one_dim"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.roll_one_dim"], ["", "def", "roll", "(", "x", ":", "torch", ".", "Tensor", ",", "shift", ":", "List", "[", "int", "]", ",", "dim", ":", "Union", "[", "List", "[", "int", "]", ",", "Sequence", "[", "int", "]", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Similar to np.roll but applies to PyTorch Tensors.\n\n    Parameters\n    ----------\n    x: A PyTorch tensor.\n    shift: Amount to roll.\n    dim: Which dimension to roll.\n\n    Returns\n    -------\n    Rolled version of x.\n    \"\"\"", "\n", "if", "len", "(", "shift", ")", "!=", "len", "(", "dim", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"len(shift) must match len(dim)\"", ")", "\n", "\n", "", "for", "(", "s", ",", "d", ")", "in", "zip", "(", "shift", ",", "dim", ")", ":", "\n", "        ", "x", "=", "roll_one_dim", "(", "x", ",", "s", ",", "d", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.fftshift": [[141, 166], ["enumerate", "fft.roll", "range", "len", "numpy.floor_divide", "x.dim", "x.dim"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.roll"], ["", "def", "fftshift", "(", "x", ":", "torch", ".", "Tensor", ",", "dim", ":", "Union", "[", "List", "[", "int", "]", ",", "Sequence", "[", "int", "]", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Similar to np.fft.fftshift but applies to PyTorch Tensors\n\n    Parameters\n    ----------\n    x: A PyTorch tensor.\n    dim: Which dimension to fftshift.\n\n    Returns\n    -------\n    fftshifted version of x.\n    \"\"\"", "\n", "if", "dim", "is", "None", ":", "\n", "# this weird code is necessary for torch.jit.script typing", "\n", "        ", "dim", "=", "[", "0", "]", "*", "(", "x", ".", "dim", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "x", ".", "dim", "(", ")", ")", ":", "\n", "            ", "dim", "[", "i", "]", "=", "i", "\n", "\n", "# Also necessary for torch.jit.script", "\n", "", "", "shift", "=", "[", "0", "]", "*", "len", "(", "dim", ")", "\n", "for", "i", ",", "dim_num", "in", "enumerate", "(", "dim", ")", ":", "\n", "        ", "shift", "[", "i", "]", "=", "np", ".", "floor_divide", "(", "x", ".", "shape", "[", "dim_num", "]", ",", "2", ")", "\n", "\n", "", "return", "roll", "(", "x", ",", "shift", ",", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.parts.fft.ifftshift": [[168, 193], ["enumerate", "fft.roll", "range", "len", "numpy.floor_divide", "x.dim", "x.dim"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.fft.roll"], ["", "def", "ifftshift", "(", "x", ":", "torch", ".", "Tensor", ",", "dim", ":", "Union", "[", "List", "[", "int", "]", ",", "Sequence", "[", "int", "]", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Similar to np.fft.ifftshift but applies to PyTorch Tensors\n\n    Parameters\n    ----------\n    x: A PyTorch tensor.\n    dim: Which dimension to ifftshift.\n\n    Returns\n    -------\n    ifftshifted version of x.\n    \"\"\"", "\n", "if", "dim", "is", "None", ":", "\n", "# this weird code is necessary for torch.jit.script typing", "\n", "        ", "dim", "=", "[", "0", "]", "*", "(", "x", ".", "dim", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "x", ".", "dim", "(", ")", ")", ":", "\n", "            ", "dim", "[", "i", "]", "=", "i", "\n", "\n", "# Also necessary for torch.jit.script", "\n", "", "", "shift", "=", "[", "0", "]", "*", "len", "(", "dim", ")", "\n", "for", "i", ",", "dim_num", "in", "enumerate", "(", "dim", ")", ":", "\n", "        ", "shift", "[", "i", "]", "=", "np", ".", "floor_divide", "(", "x", ".", "shape", "[", "dim_num", "]", "+", "1", ",", "2", ")", "\n", "\n", "", "return", "roll", "(", "x", ",", "shift", ",", "dim", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.parts.rnn_utils.rnn_weights_init": [[9, 33], ["isinstance", "isinstance", "torch.init.xavier_uniform_", "torch.init.normal_", "torch.init.constant_", "torch.init.normal_", "isinstance", "torch.init.constant_", "torch.init.constant_"], "function", ["None"], ["def", "rnn_weights_init", "(", "module", ",", "std_init_range", "=", "0.02", ",", "xavier", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    # TODO: check if this is the correct way to initialize RNN weights\n    Initialize different weights in Transformer model.\n\n    Parameters\n    ----------\n    module: torch.nn.Module to be initialized\n    std_init_range: standard deviation of normal initializer\n    xavier: if True, xavier initializer will be used in Linear layers as was proposed in AIAYN paper, otherwise normal\n    initializer will be used (like in BERT paper)\n    \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "if", "xavier", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "module", ".", "weight", ")", "\n", "", "else", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "weight", ",", "mean", "=", "0.0", ",", "std", "=", "std_init_range", ")", "\n", "", "if", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "module", ".", "bias", ",", "0.0", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "weight", ",", "mean", "=", "0.0", ",", "std", "=", "std_init_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "module", ".", "weight", ",", "1.0", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "module", ".", "bias", ",", "0.0", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.to_tensor": [[29, 48], ["numpy.iscomplexobj", "torch.from_numpy", "numpy.stack"], "function", ["None"], ["\n", "try", ":", "\n", "        ", "if", "isinstance", "(", "value", ",", "(", "str", ",", "type", "(", "None", ")", ")", ")", ":", "\n", "            ", "return", "value", "\n", "\n", "", "if", "not", "isinstance", "(", "value", ",", "bytes", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Expected bytes, unicode, or None; got %r\"", "%", "type", "(", "value", ")", ")", "\n", "\n", "", "return", "value", ".", "decode", "(", "\"utf-8\"", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.tensor_to_complex_np": [[50, 65], ["data.numpy.numpy"], "function", ["None"], ["", "except", "UnicodeDecodeError", ":", "\n", "        ", "return", "repr", "(", "value", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul": [[67, 90], ["torch.stack", "ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj": [[92, 111], ["torch.stack", "ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_abs": [[113, 129], ["ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_abs_sq": [[131, 147], ["ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.check_stacked_complex": [[149, 163], ["torch.view_as_complex"], "function", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.rss": [[165, 181], ["torch.sqrt"], "function", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.rss_complex": [[183, 199], ["torch.sqrt", "complex_abs_sq().sum", "utils.complex_abs_sq"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_abs_sq"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.sense": [[201, 220], ["complex_mul().sum", "utils.complex_mul", "utils.complex_conj"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_mul", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.complex_conj"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.coil_combination": [[222, 244], ["ValueError", "utils.sense", "utils.rss"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.parts.utils.sense", "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.rss"], []], "home.repos.pwc.inspect_result.wdika_mridc.parts.utils.save_reconstructions": [[246, 262], ["out_dir.mkdir", "reconstructions.items", "h5py.File", "hf.create_dataset"], "function", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.callbacks.callbacks.LogEpochTimeCallback.__init__": [[15, 19], ["pytorch_lightning.callbacks.base.Callback.__init__", "time.time"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initialize the callback.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "epoch_start", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.callbacks.callbacks.LogEpochTimeCallback.on_train_epoch_start": [[20, 24], ["time.time"], "methods", ["None"], ["", "@", "rank_zero_only", "\n", "def", "on_train_epoch_start", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "\"\"\"Called at the start of each epoch.\"\"\"", "\n", "self", ".", "epoch_start", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.callbacks.callbacks.LogEpochTimeCallback.on_train_epoch_end": [[25, 31], ["time.time", "trainer.logger.log_metrics"], "methods", ["None"], ["", "@", "rank_zero_only", "\n", "def", "on_train_epoch_end", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "\"\"\"Called at the end of each epoch.\"\"\"", "\n", "curr_time", "=", "time", ".", "time", "(", ")", "\n", "duration", "=", "curr_time", "-", "self", ".", "epoch_start", "\n", "trainer", ".", "logger", ".", "log_metrics", "(", "{", "\"epoch_time\"", ":", "duration", "}", ",", "step", "=", "trainer", ".", "global_step", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.losses.aggregator.AggregatorLoss.input_types": [[28, 32], ["mridc.core.neural_types.neural_type.NeuralType", "range", "str", "mridc.core.neural_types.elements.LossType"], "methods", ["None"], ["@", "property", "\n", "def", "input_types", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns definitions of module input ports.\"\"\"", "\n", "return", "{", "f\"loss_{str(i + 1)}\"", ":", "NeuralType", "(", "elements_type", "=", "LossType", "(", ")", ")", "for", "i", "in", "range", "(", "self", ".", "_num_losses", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.losses.aggregator.AggregatorLoss.output_types": [[33, 37], ["mridc.core.neural_types.neural_type.NeuralType", "mridc.core.neural_types.elements.LossType"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_types", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns definitions of module output ports.\"\"\"", "\n", "return", "{", "\"loss\"", ":", "NeuralType", "(", "elements_type", "=", "LossType", "(", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.losses.aggregator.AggregatorLoss.__init__": [[38, 45], ["mridc.core.classes.loss.Loss.__init__", "ValueError", "len"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["", "def", "__init__", "(", "self", ",", "num_inputs", ":", "int", "=", "2", ",", "weights", ":", "List", "[", "float", "]", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_num_losses", "=", "num_inputs", "\n", "if", "weights", "is", "not", "None", "and", "len", "(", "weights", ")", "!=", "num_inputs", ":", "\n", "            ", "raise", "ValueError", "(", "\"Length of weights should be equal to the number of inputs (num_inputs)\"", ")", "\n", "\n", "", "self", ".", "_weights", "=", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.losses.aggregator.AggregatorLoss.forward": [[46, 57], ["mridc.core.classes.common.typecheck", "torch.zeros_like", "enumerate", "sorted", "loss.add.add.add", "loss.add.add.add", "kwargs.keys"], "methods", ["None"], ["", "@", "typecheck", "(", ")", "\n", "def", "forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Computes the sum of the losses.\"\"\"", "\n", "values", "=", "[", "kwargs", "[", "x", "]", "for", "x", "in", "sorted", "(", "kwargs", ".", "keys", "(", ")", ")", "]", "\n", "loss", "=", "torch", ".", "zeros_like", "(", "values", "[", "0", "]", ")", "\n", "for", "loss_idx", ",", "loss_value", "in", "enumerate", "(", "values", ")", ":", "\n", "            ", "if", "self", ".", "_weights", "is", "not", "None", ":", "\n", "                ", "loss", "=", "loss", ".", "add", "(", "loss_value", ",", "alpha", "=", "self", ".", "_weights", "[", "loss_idx", "]", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss", ".", "add", "(", "loss_value", ")", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.__init__": [[14, 27], ["torch.Module.__init__", "ssim.SSIMLoss.register_buffer", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "win_size", ":", "int", "=", "7", ",", "k1", ":", "float", "=", "0.01", ",", "k2", ":", "float", "=", "0.03", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            win_size: Window size for SSIM calculation.\n            k1: k1 parameter for SSIM calculation.\n            k2: k2 parameter for SSIM calculation.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "win_size", "=", "win_size", "\n", "self", ".", "k1", ",", "self", ".", "k2", "=", "k1", ",", "k2", "\n", "self", ".", "register_buffer", "(", "\"w\"", ",", "torch", ".", "ones", "(", "1", ",", "1", ",", "win_size", ",", "win_size", ")", "/", "win_size", "**", "2", ")", "\n", "NP", "=", "win_size", "**", "2", "\n", "self", ".", "cov_norm", "=", "NP", "/", "(", "NP", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward": [[28, 60], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "isinstance", "S.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X", ":", "torch", ".", "Tensor", ",", "Y", ":", "torch", ".", "Tensor", ",", "data_range", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        X: First input tensor.\n        Y: Second input tensor.\n        data_range: Data range of the input tensors.\n\n        Returns\n        -------\n        SSIM loss.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "self", ".", "w", ",", "torch", ".", "Tensor", ")", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "data_range", "=", "data_range", "[", ":", ",", "None", ",", "None", ",", "None", "]", "\n", "C1", "=", "(", "self", ".", "k1", "*", "data_range", ")", "**", "2", "\n", "C2", "=", "(", "self", ".", "k2", "*", "data_range", ")", "**", "2", "\n", "ux", "=", "F", ".", "conv2d", "(", "X", ",", "self", ".", "w", ")", "# typing: ignore", "\n", "uy", "=", "F", ".", "conv2d", "(", "Y", ",", "self", ".", "w", ")", "#", "\n", "uxx", "=", "F", ".", "conv2d", "(", "X", "*", "X", ",", "self", ".", "w", ")", "\n", "uyy", "=", "F", ".", "conv2d", "(", "Y", "*", "Y", ",", "self", ".", "w", ")", "\n", "uxy", "=", "F", ".", "conv2d", "(", "X", "*", "Y", ",", "self", ".", "w", ")", "\n", "vx", "=", "self", ".", "cov_norm", "*", "(", "uxx", "-", "ux", "*", "ux", ")", "\n", "vy", "=", "self", ".", "cov_norm", "*", "(", "uyy", "-", "uy", "*", "uy", ")", "\n", "vxy", "=", "self", ".", "cov_norm", "*", "(", "uxy", "-", "ux", "*", "uy", ")", "\n", "A1", ",", "A2", ",", "B1", ",", "B2", "=", "(", "2", "*", "ux", "*", "uy", "+", "C1", ",", "2", "*", "vxy", "+", "C2", ",", "ux", "**", "2", "+", "uy", "**", "2", "+", "C1", ",", "vx", "+", "vy", "+", "C2", ")", "\n", "D", "=", "B1", "*", "B2", "\n", "S", "=", "(", "A1", "*", "A2", ")", "/", "D", "\n", "\n", "return", "1", "-", "S", ".", "mean", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.__init__": [[56, 76], ["torch.zeros", "ImportError", "torch.cumsum", "torch.cuda.current_device", "optimizer_with_master_params.GradBucket.numel_per_chunk.append", "torch.tensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "numel", ",", "chunk_size_mb", ")", ":", "\n", "        ", "if", "not", "HAVE_APEX", ":", "\n", "            ", "raise", "ImportError", "(", "\"Apex was not found. Using model parallel models will error out.\"", ")", "\n", "\n", "", "self", ".", "numel", "=", "numel", "\n", "self", ".", "data", "=", "torch", ".", "zeros", "(", "self", ".", "numel", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "self", ".", "chunk_size_mb", "=", "chunk_size_mb", "\n", "if", "self", ".", "chunk_size_mb", ">", "0", ":", "\n", "            ", "chunk_size_bytes", "=", "chunk_size_mb", "*", "1024", "*", "1024", "\n", "self", ".", "chunk_size_numel", "=", "chunk_size_bytes", "//", "4", "\n", "self", ".", "num_chunks", "=", "self", ".", "numel", "//", "self", ".", "chunk_size_numel", "\n", "self", ".", "numel_per_chunk", "=", "[", "self", ".", "chunk_size_numel", "]", "*", "self", ".", "num_chunks", "\n", "if", "self", ".", "numel", "%", "self", ".", "chunk_size_numel", "!=", "0", ":", "\n", "                ", "self", ".", "num_chunks", "+=", "1", "\n", "self", ".", "numel_per_chunk", ".", "append", "(", "self", ".", "numel", "%", "self", ".", "chunk_size_numel", ")", "\n", "\n", "", "self", ".", "start_index_per_chunk", "=", "torch", ".", "cumsum", "(", "torch", ".", "tensor", "(", "[", "0", "]", "+", "self", ".", "numel_per_chunk", "[", ":", "-", "1", "]", ")", ",", "dim", "=", "0", ")", "\n", "self", ".", "current_chunk", "=", "0", "\n", "self", ".", "computed_numel_per_chunk", "=", "[", "0", "]", "*", "self", ".", "num_chunks", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.zero": [[77, 80], ["optimizer_with_master_params.GradBucket.data.zero_"], "methods", ["None"], ["", "", "def", "zero", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reset the buffer to zero.\"\"\"", "\n", "self", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.allreduce_buffer": [[81, 85], ["optimizer_with_master_params.GradBucket.data.div_", "torch.distributed.all_reduce", "get_data_parallel_world_size", "get_data_parallel_group"], "methods", ["None"], ["", "def", "allreduce_buffer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Synchronous buffer data allreduce\"\"\"", "\n", "self", ".", "data", ".", "div_", "(", "get_data_parallel_world_size", "(", ")", ")", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "self", ".", "data", ",", "group", "=", "get_data_parallel_group", "(", ")", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get": [[86, 107], ["buffer_tensor.view.view.view", "shape.numel", "AssertionError", "min", "min"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "shape", ",", "start_index", ")", ":", "\n", "        ", "\"\"\"Return a tensor with the input `shape` as a view into the 1-D data starting at `start_index`.\"\"\"", "\n", "end_index", "=", "start_index", "+", "shape", ".", "numel", "(", ")", "\n", "if", "end_index", ">", "self", ".", "numel", ":", "\n", "            ", "raise", "AssertionError", "(", "\"requested tensor is out of the buffer range.\"", ")", "\n", "", "buffer_tensor", "=", "self", ".", "data", "[", "start_index", ":", "end_index", "]", "\n", "buffer_tensor", "=", "buffer_tensor", ".", "view", "(", "shape", ")", "\n", "\n", "grad_chunk_info", "=", "None", "\n", "if", "self", ".", "chunk_size_mb", ">", "0", ":", "\n", "            ", "chunk", "=", "start_index", "//", "self", ".", "chunk_size_numel", "\n", "chunk_start_index", "=", "self", ".", "start_index_per_chunk", "[", "chunk", "]", "\n", "chunk_end_index", "=", "chunk_start_index", "+", "self", ".", "numel_per_chunk", "[", "chunk", "]", "\n", "grad_chunk_info", "=", "{", "chunk", ":", "min", "(", "chunk_end_index", ",", "end_index", ")", "-", "start_index", "}", "\n", "while", "chunk_end_index", "<", "end_index", ":", "\n", "                ", "chunk", "+=", "1", "\n", "chunk_start_index", "=", "self", ".", "start_index_per_chunk", "[", "chunk", "]", "\n", "chunk_end_index", "=", "chunk_start_index", "+", "self", ".", "numel_per_chunk", "[", "chunk", "]", "\n", "grad_chunk_info", "[", "chunk", "]", "=", "min", "(", "chunk_end_index", ",", "end_index", ")", "-", "chunk_start_index", "\n", "\n", "", "", "return", "buffer_tensor", ",", "grad_chunk_info", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.update_chunk_info": [[108, 112], ["grad_chunk_info.keys"], "methods", ["None"], ["", "def", "update_chunk_info", "(", "self", ",", "grad_chunk_info", ")", ":", "\n", "        ", "\"\"\"Update the chunk info with the grad_chunk_info.\"\"\"", "\n", "for", "chunk", "in", "grad_chunk_info", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "computed_numel_per_chunk", "[", "chunk", "]", "+=", "grad_chunk_info", "[", "chunk", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get_allreduce_tensor": [[113, 126], ["None"], "methods", ["None"], ["", "", "def", "get_allreduce_tensor", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get a tensor that can be used for allreduce.\"\"\"", "\n", "if", "self", ".", "computed_numel_per_chunk", "[", "self", ".", "current_chunk", "]", "!=", "self", ".", "numel_per_chunk", "[", "self", ".", "current_chunk", "]", ":", "\n", "            ", "return", "None", "\n", "\n", "", "chunk_start_index", "=", "self", ".", "start_index_per_chunk", "[", "self", ".", "current_chunk", "]", "\n", "chunk_end_index", "=", "chunk_start_index", "+", "self", ".", "numel_per_chunk", "[", "self", ".", "current_chunk", "]", "\n", "self", ".", "computed_numel_per_chunk", "[", "self", ".", "current_chunk", "]", "=", "0", "\n", "self", ".", "current_chunk", "+=", "1", "\n", "if", "self", ".", "current_chunk", "==", "self", ".", "num_chunks", ":", "\n", "            ", "self", ".", "current_chunk", "=", "0", "\n", "\n", "", "return", "self", ".", "data", "[", "chunk_start_index", ":", "chunk_end_index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.__init__": [[144, 272], ["super().__init__", "enumerate", "optimizer_with_master_params.MainParamsOptimizerWrapper.optimizer.load_state_dict", "ImportError", "AssertionError", "AssertionError", "enumerate", "enumerate", "optimizer_with_master_params.MainParamsOptimizerWrapper.float16_groups.append", "optimizer_with_master_params.MainParamsOptimizerWrapper.fp32_from_float16_groups.append", "optimizer_with_master_params.MainParamsOptimizerWrapper.fp32_from_fp32_groups.append", "optimizer_with_master_params.MainParamsOptimizerWrapper.optimizer.state_dict", "AssertionError", "AssertionError", "optimizer_with_master_params.GradBucket", "param.expand_as", "grad_acc.register_hook", "optimizer_with_master_params.MainParamsOptimizerWrapper.grad_accs.append", "param.type", "float16_params_this_group.append", "param.detach().clone().float", "copy_tensor_model_parallel_attributes", "hasattr", "fp32_from_float16_params_this_group.append", "optimizer_with_master_params.MainParamsOptimizerWrapper._make_param_hook", "num_elements.get", "param.data.nelement", "param.data.nelement", "optimizer_with_master_params.MainParamsOptimizerWrapper._main_grad_buffers[].get", "optimizer_with_master_params.MainParamsOptimizerWrapper.optimizer.state.pop", "param.type", "fp32_params_this_group.append", "TypeError", "param.detach().clone", "param.detach", "param.type"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.load_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.state_dict", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._make_param_hook", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ",", "\n", "fp32_grad_accum", "=", "False", ",", "\n", "contiguous_grad_bucket", "=", "False", ",", "\n", "async_grad_allreduce", "=", "False", ",", "\n", "grad_allreduce_chunk_size_mb", "=", "0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "optimizer", ".", "param_groups", ")", "\n", "if", "not", "HAVE_APEX", ":", "\n", "            ", "raise", "ImportError", "(", "\"Apex was not found. Using model parallel models will error out.\"", ")", "\n", "\n", "", "self", ".", "optimizer", "=", "optimizer", "\n", "if", "not", "self", ".", "optimizer", ":", "\n", "            ", "raise", "AssertionError", "(", "\"no optimizer is provided.\"", ")", "\n", "", "if", "contiguous_grad_bucket", "and", "not", "fp32_grad_accum", ":", "\n", "            ", "raise", "AssertionError", "(", "\"contiguous gradient buffer assumes using fp32 grad.\"", ")", "\n", "", "if", "async_grad_allreduce", ":", "\n", "            ", "if", "not", "fp32_grad_accum", ":", "\n", "                ", "raise", "AssertionError", "(", "\n", "\"async allreduce applies to master gradients only, \"", "\n", "\"which is supposed to be accumulated after grad op.\"", "\n", ")", "\n", "", "if", "not", "contiguous_grad_bucket", ":", "\n", "                ", "raise", "AssertionError", "(", "\n", "\"currently async_grad_allreduce is supported only \"", "\"with contiguous_grad_bucket.\"", "\n", ")", "\n", "\n", "", "", "self", ".", "_fp32_grad_accum", "=", "fp32_grad_accum", "\n", "self", ".", "_contiguous_grad_bucket", "=", "contiguous_grad_bucket", "\n", "self", ".", "_async_grad_allreduce", "=", "async_grad_allreduce", "\n", "\n", "if", "self", ".", "_async_grad_allreduce", ":", "\n", "# use @no_sync to disable backward grad sync during gradient accumulation", "\n", "            ", "self", ".", "_require_backward_grad_sync", "=", "True", "\n", "self", ".", "_grad_allreduce_chunk_size_mb", "=", "grad_allreduce_chunk_size_mb", "\n", "", "else", ":", "\n", "            ", "self", ".", "_require_backward_grad_sync", "=", "False", "\n", "self", ".", "_grad_allreduce_chunk_size_mb", "=", "0", "\n", "\n", "# Dummy tensor needed for apex multi-apply tensor.", "\n", "", "self", ".", "_dummy_overflow_buf", "=", "None", "\n", "\n", "# Create persistent buffers for main gradients in contiguous memory space", "\n", "# - Chunked element-wise and allreduce ops without creating a temporary buffer for merged operation", "\n", "# - Low memory fragmentation", "\n", "self", ".", "_main_grad_buffers", "=", "None", "\n", "if", "self", ".", "_contiguous_grad_bucket", ":", "\n", "            ", "self", ".", "_main_grad_buffers", "=", "{", "}", "\n", "# get the size of buffers", "\n", "num_elements", "=", "{", "}", "\n", "for", "i", ",", "param_group", "in", "enumerate", "(", "self", ".", "optimizer", ".", "param_groups", ")", ":", "\n", "                ", "for", "param", "in", "param_group", "[", "\"params\"", "]", ":", "\n", "                    ", "if", "param", ".", "requires_grad", ":", "\n", "                        ", "num_elements", "[", "i", "]", "=", "num_elements", ".", "get", "(", "i", ",", "0", ")", "+", "param", ".", "data", ".", "nelement", "(", ")", "\n", "\n", "# Allocate gradient memory buffers for each data type", "\n", "", "", "self", ".", "_main_grad_buffers", "[", "i", "]", "=", "GradBucket", "(", "num_elements", "[", "i", "]", ",", "self", ".", "_grad_allreduce_chunk_size_mb", ")", "\n", "\n", "# Three groups of parameters:", "\n", "", "", "self", ".", "float16_groups", "=", "[", "]", "# original float16 parameters", "\n", "self", ".", "fp32_from_float16_groups", "=", "[", "]", "# fp32 copy of float16 parameters", "\n", "self", ".", "fp32_from_fp32_groups", "=", "[", "]", "# original fp32 parameters", "\n", "\n", "# gradient function hooks", "\n", "if", "self", ".", "_fp32_grad_accum", ":", "\n", "            ", "self", ".", "grad_accs", "=", "[", "]", "\n", "\n", "# For all the groups in the original optimizer:", "\n", "", "for", "i", ",", "param_group", "in", "enumerate", "(", "self", ".", "optimizer", ".", "param_groups", ")", ":", "\n", "            ", "float16_params_this_group", "=", "[", "]", "\n", "fp32_params_this_group", "=", "[", "]", "\n", "fp32_from_float16_params_this_group", "=", "[", "]", "\n", "# For all the parameters in this group:", "\n", "for", "j", ",", "param", "in", "enumerate", "(", "param_group", "[", "\"params\"", "]", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", ":", "\n", "# float16 params:", "\n", "                    ", "if", "param", ".", "type", "(", ")", "in", "[", "\"torch.cuda.HalfTensor\"", ",", "\"torch.cuda.BFloat16Tensor\"", "]", ":", "\n", "                        ", "float16_params_this_group", ".", "append", "(", "param", ")", "\n", "\n", "# Allocate the main parameter", "\n", "main_param", "=", "param", ".", "detach", "(", ")", ".", "clone", "(", ")", ".", "float", "(", ")", "\n", "\n", "# Copy tensor model parallel attributes.", "\n", "copy_tensor_model_parallel_attributes", "(", "main_param", ",", "param", ")", "\n", "if", "hasattr", "(", "param", ",", "\"shared\"", ")", ":", "\n", "                            ", "main_param", ".", "shared", "=", "param", ".", "shared", "\n", "\n", "# Assign the grad buffer offset to main parameters", "\n", "", "if", "self", ".", "_contiguous_grad_bucket", ":", "\n", "                            ", "num_elements", "[", "i", "]", "-=", "param", ".", "data", ".", "nelement", "(", ")", "\n", "main_param", ".", "grad", ",", "grad_chunk_info", "=", "self", ".", "_main_grad_buffers", "[", "i", "]", ".", "get", "(", "\n", "param", ".", "data", ".", "shape", ",", "num_elements", "[", "i", "]", "\n", ")", "\n", "param", ".", "main_grad", "=", "main_param", ".", "grad", "\n", "\n", "# Replace the optimizer params with the new fp32 copy.", "\n", "", "param_group", "[", "\"params\"", "]", "[", "j", "]", "=", "main_param", "\n", "fp32_from_float16_params_this_group", ".", "append", "(", "main_param", ")", "\n", "# Reset existing state dict key to the new main param.", "\n", "if", "param", "in", "self", ".", "optimizer", ".", "state", ":", "\n", "                            ", "self", ".", "optimizer", ".", "state", "[", "main_param", "]", "=", "self", ".", "optimizer", ".", "state", ".", "pop", "(", "param", ")", "\n", "", "", "elif", "param", ".", "type", "(", ")", "==", "\"torch.cuda.FloatTensor\"", ":", "\n", "                        ", "fp32_params_this_group", ".", "append", "(", "param", ")", "\n", "param_group", "[", "\"params\"", "]", "[", "j", "]", "=", "param", "\n", "\n", "", "else", ":", "\n", "                        ", "raise", "TypeError", "(", "\n", "\"Wrapped parameters must be one of torch.cuda.FloatTensor,  torch.cuda.HalfTensor, \"", "\n", "f\"or torch.cuda.BFloat16Tensor. Received {param.type()}\"", "\n", ")", "\n", "\n", "# Add gradient accumulation hook for fp32 grad accumulation", "\n", "", "", "if", "self", ".", "_fp32_grad_accum", ":", "\n", "# Expand so we get access to grad_fn.", "\n", "                    ", "param_tmp", "=", "param", ".", "expand_as", "(", "param", ")", "\n", "# Get the gradient accumulator function.", "\n", "grad_acc", "=", "param_tmp", ".", "grad_fn", ".", "next_functions", "[", "0", "]", "[", "0", "]", "\n", "grad_acc", ".", "register_hook", "(", "self", ".", "_make_param_hook", "(", "param", ",", "main_param", ",", "i", ",", "grad_chunk_info", ")", ")", "\n", "self", ".", "grad_accs", ".", "append", "(", "grad_acc", ")", "\n", "\n", "", "", "self", ".", "float16_groups", ".", "append", "(", "float16_params_this_group", ")", "\n", "self", ".", "fp32_from_float16_groups", ".", "append", "(", "fp32_from_float16_params_this_group", ")", "\n", "self", ".", "fp32_from_fp32_groups", ".", "append", "(", "fp32_params_this_group", ")", "\n", "\n", "# Leverage state_dict() and load_state_dict() to", "\n", "# recast preexisting per-param state tensors", "\n", "", "self", ".", "optimizer", ".", "load_state_dict", "(", "self", ".", "optimizer", ".", "state_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._make_param_hook": [[273, 304], ["param.grad.float", "main_param.grad.add_", "optimizer_with_master_params.MainParamsOptimizerWrapper._main_grad_buffers[].update_chunk_info", "main_param.grad.div_", "torch.distributed.all_reduce", "optimizer_with_master_params.MainParamsOptimizerWrapper._main_grad_buffers[].get_allreduce_tensor", "optimizer_with_master_params.MainParamsOptimizerWrapper.div_", "torch.distributed.all_reduce", "get_data_parallel_world_size", "get_data_parallel_world_size", "get_data_parallel_group", "get_data_parallel_group"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.update_chunk_info", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get_allreduce_tensor"], ["", "def", "_make_param_hook", "(", "self", ",", "param", ",", "main_param", ",", "i", ",", "grad_chunk_info", ")", ":", "\n", "        ", "\"\"\"Create the grad accumulation and all-reduce hook for back prop.\"\"\"", "\n", "\n", "def", "param_hook", "(", "*", "unused", ")", ":", "\n", "            ", "\"\"\"Gradient accumulation and all-reduce.\"\"\"", "\n", "if", "param", ".", "grad", ".", "data", "is", "None", ":", "\n", "                ", "return", "\n", "", "if", "main_param", ".", "grad", "is", "None", ":", "\n", "                ", "main_param", ".", "grad", "=", "param", ".", "grad", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "                ", "main_param", ".", "grad", ".", "add_", "(", "param", ".", "grad", ".", "data", ")", "\n", "# Deallocate grad memory.", "\n", "", "param", ".", "grad", "=", "None", "\n", "\n", "# Asynchronous gradients allreduce across data_parallel ranks", "\n", "if", "self", ".", "_require_backward_grad_sync", ":", "\n", "                ", "if", "self", ".", "_grad_allreduce_chunk_size_mb", ">", "0", ":", "\n", "                    ", "self", ".", "_main_grad_buffers", "[", "i", "]", ".", "update_chunk_info", "(", "grad_chunk_info", ")", "\n", "while", "True", ":", "\n", "                        ", "allreduce_tensor", "=", "self", ".", "_main_grad_buffers", "[", "i", "]", ".", "get_allreduce_tensor", "(", ")", "\n", "if", "allreduce_tensor", "is", "None", ":", "\n", "                            ", "break", "\n", "", "allreduce_tensor", ".", "div_", "(", "get_data_parallel_world_size", "(", ")", ")", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "allreduce_tensor", ",", "group", "=", "get_data_parallel_group", "(", ")", ",", "async_op", "=", "True", ")", "\n", "", "", "else", ":", "\n", "                    ", "main_param", ".", "grad", ".", "div_", "(", "get_data_parallel_world_size", "(", ")", ")", "\n", "torch", ".", "distributed", ".", "all_reduce", "(", "# type: ignore", "\n", "main_param", ".", "grad", ",", "group", "=", "get_data_parallel_group", "(", ")", ",", "async_op", "=", "True", "\n", ")", "\n", "\n", "", "", "", "return", "param_hook", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.zero_grad": [[305, 321], ["optimizer_with_master_params._zero_grad_group_helper", "optimizer_with_master_params._zero_grad_group_helper", "optimizer_with_master_params.MainParamsOptimizerWrapper._main_grad_buffers[].zero", "optimizer_with_master_params._zero_grad_group_helper"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params._zero_grad_group_helper", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params._zero_grad_group_helper", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.zero", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params._zero_grad_group_helper"], ["", "def", "zero_grad", "(", "self", ",", "set_to_none", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        We only need to zero the model related parameters, i.e., float16_groups & fp32_from_fp32_groups. We\n        additionally zero fp32_from_float16_groups as a memory optimization to reduce fragmentation; in the case of\n        set_to_none==True, the space used by this field can be safely deallocated at this point.\n        \"\"\"", "\n", "for", "group", "in", "self", ".", "float16_groups", ":", "\n", "            ", "_zero_grad_group_helper", "(", "group", ",", "set_to_none", ")", "\n", "", "if", "self", ".", "_contiguous_grad_bucket", ":", "\n", "            ", "for", "i", "in", "self", ".", "_main_grad_buffers", ":", "\n", "                ", "self", ".", "_main_grad_buffers", "[", "i", "]", ".", "zero", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "group", "in", "self", ".", "fp32_from_float16_groups", ":", "\n", "                ", "_zero_grad_group_helper", "(", "group", ",", "set_to_none", ")", "\n", "", "", "for", "group", "in", "self", ".", "fp32_from_fp32_groups", ":", "\n", "            ", "_zero_grad_group_helper", "(", "group", ",", "set_to_none", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.copy_model_grads_to_main_grads": [[322, 334], ["zip", "zip", "model_param.grad.float"], "methods", ["None"], ["", "", "def", "copy_model_grads_to_main_grads", "(", "self", ")", ":", "\n", "        ", "\"\"\"Copy model grads to main grads.\"\"\"", "\n", "# This only needs to be done for the float16 group.", "\n", "for", "model_group", ",", "main_group", "in", "zip", "(", "self", ".", "float16_groups", ",", "self", ".", "fp32_from_float16_groups", ")", ":", "\n", "            ", "for", "model_param", ",", "main_param", "in", "zip", "(", "model_group", ",", "main_group", ")", ":", "\n", "                ", "if", "model_param", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "main_param", ".", "grad", "=", "model_param", ".", "grad", ".", "float", "(", ")", "\n", "\n", "# Safe to deallocate model's grad after copying.", "\n", "# (If using contiguous buffers, main_grad's memory should", "\n", "# persist and therefore should not be deallocated.)", "\n", "", "model_param", ".", "grad", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._get_model_and_main_params_data_float16": [[335, 347], ["zip", "zip", "model_data.append", "main_data.append"], "methods", ["None"], ["", "", "", "def", "_get_model_and_main_params_data_float16", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get model and main params data in float16.\"\"\"", "\n", "model_data", "=", "[", "]", "\n", "main_data", "=", "[", "]", "\n", "half_dtype", "=", "None", "\n", "for", "model_group", ",", "main_group", "in", "zip", "(", "self", ".", "float16_groups", ",", "self", ".", "fp32_from_float16_groups", ")", ":", "\n", "            ", "for", "model_param", ",", "main_param", "in", "zip", "(", "model_group", ",", "main_group", ")", ":", "\n", "                ", "if", "half_dtype", "is", "None", ":", "\n", "                    ", "half_dtype", "=", "model_param", ".", "data", ".", "dtype", "\n", "", "model_data", ".", "append", "(", "model_param", ".", "data", ")", "\n", "main_data", ".", "append", "(", "main_param", ".", "data", ")", "\n", "", "", "return", "model_data", ",", "main_data", ",", "half_dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._set_overflow_buffer": [[348, 355], ["torch.cuda.IntTensor", "optimizer_with_master_params.MainParamsOptimizerWrapper._dummy_overflow_buf.fill_"], "methods", ["None"], ["", "def", "_set_overflow_buffer", "(", "self", ",", "half_dtype", ")", ":", "\n", "        ", "\"\"\"Set overflow buffer.\"\"\"", "\n", "if", "half_dtype", "==", "torch", ".", "float16", ":", "\n", "            ", "if", "self", ".", "_dummy_overflow_buf", "is", "None", ":", "\n", "                ", "self", ".", "_dummy_overflow_buf", "=", "torch", ".", "cuda", ".", "IntTensor", "(", "[", "0", "]", ")", "# type: ignore", "\n", "", "else", ":", "\n", "                ", "self", ".", "_dummy_overflow_buf", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._copy_main_params_to_model_params": [[356, 362], ["optimizer_with_master_params.MainParamsOptimizerWrapper._get_model_and_main_params_data_float16", "optimizer_with_master_params.MainParamsOptimizerWrapper._set_overflow_buffer", "optimizer_with_master_params._multi_tensor_copy_this_to_that"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._get_model_and_main_params_data_float16", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._set_overflow_buffer", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params._multi_tensor_copy_this_to_that"], ["", "", "", "def", "_copy_main_params_to_model_params", "(", "self", ")", ":", "\n", "        ", "\"\"\"Copy main params to model params.\"\"\"", "\n", "# Only needed for the float16 params.", "\n", "model_data", ",", "main_data", ",", "half_dtype", "=", "self", ".", "_get_model_and_main_params_data_float16", "(", ")", "\n", "self", ".", "_set_overflow_buffer", "(", "half_dtype", ")", "\n", "_multi_tensor_copy_this_to_that", "(", "this", "=", "main_data", ",", "that", "=", "model_data", ",", "overflow_buf", "=", "self", ".", "_dummy_overflow_buf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._copy_model_params_to_main_params": [[363, 369], ["optimizer_with_master_params.MainParamsOptimizerWrapper._get_model_and_main_params_data_float16", "optimizer_with_master_params.MainParamsOptimizerWrapper._set_overflow_buffer", "optimizer_with_master_params._multi_tensor_copy_this_to_that"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._get_model_and_main_params_data_float16", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._set_overflow_buffer", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params._multi_tensor_copy_this_to_that"], ["", "def", "_copy_model_params_to_main_params", "(", "self", ")", ":", "\n", "        ", "\"\"\"Copy model params to main params.\"\"\"", "\n", "# Only needed for the float16 params.", "\n", "model_data", ",", "main_data", ",", "half_dtype", "=", "self", ".", "_get_model_and_main_params_data_float16", "(", ")", "\n", "self", ".", "_set_overflow_buffer", "(", "half_dtype", ")", "\n", "_multi_tensor_copy_this_to_that", "(", "this", "=", "model_data", ",", "that", "=", "main_data", ",", "overflow_buf", "=", "self", ".", "_dummy_overflow_buf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.reload_model_params": [[370, 373], ["optimizer_with_master_params.MainParamsOptimizerWrapper._copy_model_params_to_main_params"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._copy_model_params_to_main_params"], ["", "def", "reload_model_params", "(", "self", ")", ":", "\n", "        ", "\"\"\"Reload model params.\"\"\"", "\n", "self", ".", "_copy_model_params_to_main_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.step": [[374, 383], ["torch.no_grad", "optimizer_with_master_params.MainParamsOptimizerWrapper.optimizer.step", "torch.no_grad", "optimizer_with_master_params.MainParamsOptimizerWrapper._copy_main_params_to_model_params"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._copy_main_params_to_model_params"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "step", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Step the optimizer.\"\"\"", "\n", "self", ".", "optimizer", ".", "step", "(", "closure", "=", "None", ",", "**", "kwargs", ")", "\n", "# Update params from main params.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "_copy_main_params_to_model_params", "(", ")", "\n", "# Successful update.", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.state_dict": [[384, 387], ["optimizer_with_master_params.MainParamsOptimizerWrapper.optimizer.state_dict"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the state of the optimizer.\"\"\"", "\n", "return", "{", "\"optimizer\"", ":", "self", ".", "optimizer", ".", "state_dict", "(", ")", ",", "\"fp32_from_fp16_params\"", ":", "self", ".", "fp32_from_float16_groups", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.load_state_dict": [[388, 404], ["optimizer_with_master_params.MainParamsOptimizerWrapper.optimizer.load_state_dict", "zip", "mridc.utils.logging.info", "zip", "current_param.data.copy_"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.load_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load the state of the optimizer.\"\"\"", "\n", "# Optimizer.", "\n", "optimizer_key", "=", "\"optimizer\"", "\n", "if", "optimizer_key", "not", "in", "state_dict", ":", "\n", "            ", "optimizer_key", "=", "\"optimizer_state_dict\"", "\n", "logging", ".", "info", "(", "\"***WARNING*** loading optimizer from \"", "\"an old checkpoint ...\"", ")", "\n", "", "self", ".", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "optimizer_key", "]", ")", "\n", "\n", "# Copy data for the main params.", "\n", "fp32_from_float16_params_key", "=", "\"fp32_from_fp16_params\"", "\n", "if", "fp32_from_float16_params_key", "not", "in", "state_dict", ":", "\n", "            ", "fp32_from_float16_params_key", "=", "\"fp32_from_fp16\"", "\n", "", "for", "current_group", ",", "saved_group", "in", "zip", "(", "self", ".", "fp32_from_float16_groups", ",", "state_dict", "[", "fp32_from_float16_params_key", "]", ")", ":", "\n", "            ", "for", "current_param", ",", "saved_param", "in", "zip", "(", "current_group", ",", "saved_group", ")", ":", "\n", "                ", "current_param", ".", "data", ".", "copy_", "(", "saved_param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.allreduce_main_grads": [[405, 409], ["optimizer_with_master_params.MainParamsOptimizerWrapper._main_grad_buffers[].allreduce_buffer"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.allreduce_buffer"], ["", "", "", "def", "allreduce_main_grads", "(", "self", ")", ":", "\n", "        ", "\"\"\"All reduce main grads.\"\"\"", "\n", "for", "i", "in", "self", ".", "_main_grad_buffers", ":", "\n", "            ", "self", ".", "_main_grad_buffers", "[", "i", "]", ".", "allreduce_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.no_sync": [[410, 419], ["None"], "methods", ["None"], ["", "", "@", "contextmanager", "\n", "def", "no_sync", "(", "self", ")", ":", "\n", "        ", "\"\"\"A context manager to disable gradient synchronizations across data-parallel ranks.\"\"\"", "\n", "old_require_backward_grad_sync", "=", "self", ".", "_require_backward_grad_sync", "\n", "self", ".", "_require_backward_grad_sync", "=", "False", "\n", "try", ":", "\n", "            ", "yield", "\n", "", "finally", ":", "\n", "            ", "self", ".", "_require_backward_grad_sync", "=", "old_require_backward_grad_sync", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.async_master_grads_allreduce": [[420, 424], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "async_master_grads_allreduce", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return whether to use async allreduce for master grads.\"\"\"", "\n", "return", "self", ".", "_async_grad_allreduce", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.fp32_grad_accumulation": [[425, 429], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "fp32_grad_accumulation", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return whether to accumulate gradients in fp32.\"\"\"", "\n", "return", "self", ".", "_fp32_grad_accum", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.get_parameters": [[430, 436], ["params.extend", "iter"], "methods", ["None"], ["", "def", "get_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the parameters of the optimizer.\"\"\"", "\n", "params", "=", "[", "]", "\n", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "            ", "params", ".", "extend", "(", "iter", "(", "param_group", "[", "\"params\"", "]", ")", ")", "\n", "", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._get_state": [[437, 440], ["None"], "methods", ["None"], ["", "def", "_get_state", "(", "self", ")", ":", "\n", "        ", "\"\"\"Promote state, so it can be retrieved or set via \"optimizer_instance.state.\"\"\"", "\n", "return", "self", ".", "optimizer", ".", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._set_state": [[441, 444], ["None"], "methods", ["None"], ["", "def", "_set_state", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\"Promote state, so it can be retrieved or set via \"optimizer_instance.state.\"\"\"", "\n", "self", ".", "optimizer", ".", "state", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._get_param_groups": [[447, 453], ["None"], "methods", ["None"], ["def", "_get_param_groups", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Promote param_groups, so it can be retrieved or set via \"optimizer_instance.param_groups.\n        (for example, to adjust the learning rate)\n        \"\"\"", "\n", "return", "self", ".", "optimizer", ".", "param_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper._set_param_groups": [[454, 457], ["None"], "methods", ["None"], ["", "def", "_set_param_groups", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\"Set param_groups.\"\"\"", "\n", "self", ".", "optimizer", ".", "param_groups", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params._zero_grad_group_helper": [[25, 37], ["param.grad.zero_", "param.grad.detach_", "param.grad.requires_grad_"], "function", ["None"], ["", "def", "_zero_grad_group_helper", "(", "group", ",", "set_to_none", ")", ":", "\n", "    ", "\"\"\"Zero out the gradient for a group of parameters. Note: copied from torch.optim.optimizer.\"\"\"", "\n", "for", "param", "in", "group", ":", "\n", "        ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "            ", "if", "set_to_none", ":", "\n", "                ", "param", ".", "grad", "=", "None", "\n", "", "else", ":", "\n", "                ", "if", "param", ".", "grad", ".", "grad_fn", "is", "not", "None", ":", "\n", "                    ", "param", ".", "grad", ".", "detach_", "(", ")", "\n", "", "else", ":", "\n", "                    ", "param", ".", "grad", ".", "requires_grad_", "(", "False", ")", "\n", "", "param", ".", "grad", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params._multi_tensor_copy_this_to_that": [[39, 51], ["multi_tensor_applier", "zip", "that_.copy_"], "function", ["None"], ["", "", "", "", "def", "_multi_tensor_copy_this_to_that", "(", "this", ",", "that", ",", "overflow_buf", ")", ":", "\n", "    ", "\"\"\"\n    Use multi-tensor-applier to copy values from one list to another. We don't have a blfoat16 implementation so for\n    now if the overflow_buf is not provided, we default back to simple loop copy to be compatible with bfloat16.\n    \"\"\"", "\n", "if", "overflow_buf", ":", "\n", "# Scaling with factor `1.0` is equivalent to copy.", "\n", "        ", "multi_tensor_applier", "(", "amp_C", ".", "multi_tensor_scale", ",", "overflow_buf", ",", "[", "this", ",", "that", "]", ",", "1.0", ")", "\n", "", "else", ":", "\n", "# FIXME: use multi-tensor applier for bf16", "\n", "        ", "for", "this_", ",", "that_", "in", "zip", "(", "this", ",", "that", ")", ":", "\n", "            ", "that_", ".", "copy_", "(", "this_", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupPolicy.__init__": [[39, 67], ["torch.optim.lr_scheduler._LRScheduler.__init__", "AssertionError", "AssertionError", "int"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "*", ",", "warmup_steps", "=", "None", ",", "warmup_ratio", "=", "None", ",", "max_steps", "=", "None", ",", "min_lr", "=", "0.0", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        optimizer: optimizer\n        warmup_steps: Number of training steps in warmup stage\n        warmup_ratio: Ratio of warmup steps to total steps\n        max_steps: Total number of steps while training or `None` for infinite training\n        min_lr: Minimum learning rate\n        last_epoch: Last epoch\n        \"\"\"", "\n", "if", "warmup_steps", "is", "not", "None", "and", "warmup_ratio", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Either use particular number of step or ratio\"", ")", "\n", "", "if", "warmup_ratio", "is", "not", "None", "and", "max_steps", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"If there is a ratio, there should be a total steps\"", ")", "\n", "\n", "# It is necessary to assign all attributes *before* __init__,", "\n", "# as class is wrapped by an inner class.", "\n", "", "self", ".", "max_steps", "=", "max_steps", "\n", "if", "warmup_steps", "is", "not", "None", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "", "elif", "warmup_ratio", "is", "not", "None", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "int", "(", "warmup_ratio", "*", "max_steps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "0", "\n", "\n", "", "self", ".", "min_lr", "=", "min_lr", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupPolicy.get_lr": [[68, 84], ["lr_scheduler.WarmupPolicy._get_lr", "warnings.warn", "lr_scheduler.WarmupPolicy._get_warmup_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor._get_lr", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing._get_warmup_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "if", "not", "self", ".", "_get_lr_called_within_step", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\"", ",", "UserWarning", "\n", ")", "\n", "\n", "", "step", "=", "self", ".", "last_epoch", "\n", "\n", "if", "0", "<", "self", ".", "warmup_steps", ">=", "step", ":", "\n", "            ", "return", "self", ".", "_get_warmup_lr", "(", "step", ")", "\n", "\n", "", "if", "step", ">", "self", ".", "max_steps", ":", "\n", "            ", "return", "[", "self", ".", "min_lr", "for", "_", "in", "self", ".", "base_lrs", "]", "\n", "\n", "", "return", "self", ".", "_get_lr", "(", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupPolicy._get_warmup_lr": [[85, 89], ["None"], "methods", ["None"], ["", "def", "_get_warmup_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Linear warmup\"\"\"", "\n", "lr_val", "=", "(", "step", "+", "1", ")", "/", "(", "self", ".", "warmup_steps", "+", "1", ")", "\n", "return", "[", "initial_lr", "*", "lr_val", "for", "initial_lr", "in", "self", ".", "base_lrs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupPolicy._get_lr": [[90, 93], ["None"], "methods", ["None"], ["", "def", "_get_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Simple const lr policy\"\"\"", "\n", "return", "self", ".", "base_lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.SquareRootConstantPolicy.__init__": [[105, 136], ["torch.optim.lr_scheduler._LRScheduler.__init__", "AssertionError", "AssertionError", "int"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "optimizer", ",", "*", ",", "constant_steps", "=", "None", ",", "constant_ratio", "=", "None", ",", "max_steps", "=", "None", ",", "min_lr", "=", "0.0", ",", "last_epoch", "=", "-", "1", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        optimizer: optimizer\n        constant_steps: Number of training steps in constant stage\n        constant_ratio: Ratio of constant steps to total steps\n        max_steps: Total number of steps while training or `None` for infinite training\n        min_lr: Minimum learning rate\n        last_epoch: Last epoch\n        \"\"\"", "\n", "if", "constant_steps", "is", "not", "None", "and", "constant_ratio", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Either use particular number of step or ratio\"", ")", "\n", "\n", "", "if", "constant_ratio", "is", "not", "None", "and", "max_steps", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"If there is a ratio, there should be a total steps\"", ")", "\n", "\n", "# It is necessary to assign all attributes *before* __init__, as class is wrapped by an inner class.", "\n", "", "self", ".", "max_steps", "=", "max_steps", "\n", "if", "constant_steps", "is", "not", "None", ":", "\n", "            ", "self", ".", "constant_steps", "=", "constant_steps", "\n", "", "elif", "constant_ratio", "is", "not", "None", ":", "\n", "            ", "self", ".", "constant_steps", "=", "int", "(", "constant_ratio", "*", "max_steps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "constant_steps", "=", "0", "\n", "\n", "", "self", ".", "constant_lr", "=", "1", "/", "(", "constant_steps", "**", "0.5", ")", "\n", "self", ".", "min_lr", "=", "min_lr", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.SquareRootConstantPolicy.get_lr": [[137, 153], ["lr_scheduler.SquareRootConstantPolicy._get_lr", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor._get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "if", "not", "self", ".", "_get_lr_called_within_step", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\"", ",", "UserWarning", "\n", ")", "\n", "\n", "", "step", "=", "self", ".", "last_epoch", "\n", "\n", "if", "step", "<=", "self", ".", "constant_steps", ":", "\n", "            ", "return", "[", "self", ".", "constant_lr", "for", "_", "in", "self", ".", "base_lrs", "]", "\n", "\n", "", "if", "step", ">", "self", ".", "max_steps", ":", "\n", "            ", "return", "[", "self", ".", "min_lr", "for", "_", "in", "self", ".", "base_lrs", "]", "\n", "\n", "", "return", "self", ".", "_get_lr", "(", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.SquareRootConstantPolicy._get_lr": [[154, 157], ["None"], "methods", ["None"], ["", "def", "_get_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Simple const lr policy\"\"\"", "\n", "return", "self", ".", "base_lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupHoldPolicy.__init__": [[178, 234], ["lr_scheduler.WarmupPolicy.__init__", "AssertionError", "AssertionError", "int", "int"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ",", "\n", "*", ",", "\n", "warmup_steps", "=", "None", ",", "\n", "warmup_ratio", "=", "None", ",", "\n", "hold_steps", "=", "None", ",", "\n", "hold_ratio", "=", "None", ",", "\n", "max_steps", "=", "None", ",", "\n", "min_lr", "=", "0.0", ",", "\n", "last_epoch", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n\n        Parameters\n        ----------\n        optimizer: optimizer\n        warmup_steps: Number of training steps in warmup stage.\n        warmup_ratio: Ratio of warmup steps to total steps.\n        hold_steps: Number of training steps to hold the learning rate after warm up.\n        hold_ratio: Ratio of hold steps to total steps.\n        max_steps: Total number of steps while training or `None` for infinite training.\n        min_lr: Minimum learning rate.\n        last_epoch: Last epoch.\n        \"\"\"", "\n", "if", "hold_steps", "is", "not", "None", "and", "hold_ratio", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Either use particular number of step or ratio\"", ")", "\n", "", "if", "hold_ratio", "is", "not", "None", "and", "max_steps", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"If there is a ratio, there should be a total steps\"", ")", "\n", "\n", "", "self", ".", "min_lr", "=", "min_lr", "\n", "self", ".", "_last_warmup_lr", "=", "0.0", "\n", "\n", "# Necessary to duplicate as class attributes are hidden in inner class", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "if", "warmup_steps", "is", "not", "None", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "", "elif", "warmup_ratio", "is", "not", "None", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "int", "(", "warmup_ratio", "*", "max_steps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "0", "\n", "\n", "", "if", "hold_steps", "is", "not", "None", ":", "\n", "            ", "self", ".", "hold_steps", "=", "hold_steps", "+", "self", ".", "warmup_steps", "\n", "", "elif", "hold_ratio", "is", "not", "None", ":", "\n", "            ", "self", ".", "hold_steps", "=", "int", "(", "hold_ratio", "*", "max_steps", ")", "+", "self", ".", "warmup_steps", "\n", "", "else", ":", "\n", "            ", "self", ".", "hold_steps", "=", "0", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "\n", "optimizer", ",", "\n", "warmup_steps", "=", "warmup_steps", ",", "\n", "warmup_ratio", "=", "warmup_ratio", ",", "\n", "max_steps", "=", "max_steps", ",", "\n", "last_epoch", "=", "last_epoch", ",", "\n", "min_lr", "=", "min_lr", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupHoldPolicy.get_lr": [[236, 257], ["lr_scheduler.WarmupHoldPolicy._get_lr", "warnings.warn", "lr_scheduler.WarmupHoldPolicy._get_warmup_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor._get_lr", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing._get_warmup_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "if", "not", "self", ".", "_get_lr_called_within_step", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"To get the last learning rate computed by the scheduler, \"", "\"please use `get_last_lr()`.\"", ",", "UserWarning", "\n", ")", "\n", "\n", "", "step", "=", "self", ".", "last_epoch", "\n", "\n", "# Warmup phase", "\n", "if", "0", "<", "self", ".", "warmup_steps", ">=", "step", ":", "\n", "            ", "return", "self", ".", "_get_warmup_lr", "(", "step", ")", "\n", "\n", "# Hold phase", "\n", "", "if", "self", ".", "hold_steps", "<", "step", ">=", "self", ".", "warmup_steps", ":", "\n", "            ", "return", "self", ".", "base_lrs", "\n", "\n", "", "if", "step", ">", "self", ".", "max_steps", ":", "\n", "            ", "return", "[", "self", ".", "min_lr", "for", "_", "in", "self", ".", "base_lrs", "]", "\n", "\n", "", "return", "self", ".", "_get_lr", "(", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupAnnealHoldPolicy.__init__": [[273, 325], ["torch.optim.lr_scheduler._LRScheduler.__init__", "AssertionError", "AssertionError", "AssertionError", "int", "int"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ",", "\n", "*", ",", "\n", "warmup_steps", "=", "None", ",", "\n", "warmup_ratio", "=", "None", ",", "\n", "constant_steps", "=", "None", ",", "\n", "constant_ratio", "=", "None", ",", "\n", "max_steps", "=", "None", ",", "\n", "min_lr", "=", "0.0", ",", "\n", "last_epoch", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        optimizer: Optimizer\n        warmup_steps: Number of training steps in warmup stage.\n        warmup_ratio: Ratio of warmup steps to total steps.\n        constant_steps: Number of steps to keep lr constant at.\n        constant_ratio: Ratio of steps to keep lr constant.\n        max_steps: Total number of steps while training or `None` for infinite training.\n        min_lr: Minimum lr to hold the learning rate after decay at.\n        last_epoch: The index of last epoch.\n        \"\"\"", "\n", "if", "warmup_steps", "is", "not", "None", "and", "warmup_ratio", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Either use particular number of step or ratio\"", ")", "\n", "", "if", "constant_steps", "is", "not", "None", "and", "constant_ratio", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Either use constant_steps or constant_ratio\"", ")", "\n", "", "if", "warmup_ratio", "is", "not", "None", "and", "max_steps", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"If there is a ratio, there should be a total steps\"", ")", "\n", "\n", "# It is necessary to assign all attributes *before* __init__, as class is wrapped by an inner class.", "\n", "", "self", ".", "max_steps", "=", "max_steps", "\n", "\n", "if", "warmup_steps", "is", "not", "None", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "", "elif", "warmup_ratio", "is", "not", "None", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "int", "(", "warmup_ratio", "*", "max_steps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "0", "\n", "\n", "", "if", "constant_steps", "is", "not", "None", ":", "\n", "            ", "self", ".", "constant_steps", "=", "constant_steps", "\n", "", "elif", "constant_ratio", "is", "not", "None", ":", "\n", "            ", "self", ".", "constant_steps", "=", "int", "(", "constant_ratio", "*", "max_steps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "constant_steps", "=", "0", "\n", "\n", "", "self", ".", "decay_steps", "=", "max_steps", "-", "(", "self", ".", "constant_steps", "+", "self", ".", "warmup_steps", ")", "\n", "\n", "self", ".", "min_lr", "=", "min_lr", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupAnnealHoldPolicy.get_lr": [[326, 348], ["lr_scheduler.WarmupAnnealHoldPolicy._get_lr", "warnings.warn", "lr_scheduler.WarmupAnnealHoldPolicy._get_warmup_lr", "lr_scheduler.WarmupAnnealHoldPolicy._get_constant_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor._get_lr", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing._get_warmup_lr", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing._get_constant_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "if", "not", "self", ".", "_get_lr_called_within_step", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\"", ",", "UserWarning", "\n", ")", "\n", "\n", "", "step", "=", "self", ".", "last_epoch", "\n", "\n", "# Warmup steps", "\n", "if", "0", "<", "self", ".", "warmup_steps", ">=", "step", ":", "\n", "            ", "return", "self", ".", "_get_warmup_lr", "(", "step", ")", "\n", "\n", "# Constant steps after warmup and decay", "\n", "", "if", "self", ".", "constant_steps", ">", "0", "and", "(", "self", ".", "warmup_steps", "+", "self", ".", "decay_steps", ")", "<", "step", "<=", "self", ".", "max_steps", ":", "\n", "            ", "return", "self", ".", "_get_constant_lr", "(", "step", ")", "\n", "\n", "# Min lr after max steps of updates", "\n", "", "if", "step", ">", "self", ".", "max_steps", ":", "\n", "            ", "return", "[", "self", ".", "min_lr", "for", "_", "in", "self", ".", "base_lrs", "]", "\n", "\n", "", "return", "self", ".", "_get_lr", "(", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupAnnealHoldPolicy._get_warmup_lr": [[349, 353], ["None"], "methods", ["None"], ["", "def", "_get_warmup_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Get learning rate at warmup stage.\"\"\"", "\n", "lr_val", "=", "(", "step", "+", "1", ")", "/", "(", "self", ".", "warmup_steps", "+", "1", ")", "\n", "return", "[", "initial_lr", "*", "lr_val", "for", "initial_lr", "in", "self", ".", "base_lrs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupAnnealHoldPolicy._get_constant_lr": [[354, 357], ["None"], "methods", ["None"], ["", "def", "_get_constant_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Get learning rate at constant stage.\"\"\"", "\n", "return", "[", "self", ".", "min_lr", "for", "_", "in", "self", ".", "base_lrs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupAnnealHoldPolicy._get_lr": [[358, 361], ["None"], "methods", ["None"], ["", "def", "_get_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Simple const lr policy\"\"\"", "\n", "return", "self", ".", "base_lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.SquareAnnealing.__init__": [[428, 430], ["lr_scheduler.WarmupPolicy.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "*", ",", "max_steps", ",", "min_lr", "=", "1e-5", ",", "last_epoch", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "optimizer", "=", "optimizer", ",", "max_steps", "=", "max_steps", ",", "last_epoch", "=", "last_epoch", ",", "min_lr", "=", "min_lr", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.SquareAnnealing._get_lr": [[431, 441], ["lr_scheduler._square_annealing"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler._square_annealing"], ["", "def", "_get_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "return", "[", "\n", "_square_annealing", "(", "\n", "initial_lr", "=", "initial_lr", ",", "\n", "step", "=", "step", "-", "self", ".", "warmup_steps", ",", "\n", "max_steps", "=", "self", ".", "max_steps", "-", "self", ".", "warmup_steps", ",", "\n", "min_lr", "=", "self", ".", "min_lr", ",", "\n", ")", "\n", "for", "initial_lr", "in", "self", ".", "base_lrs", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.SquareRootAnnealing.__init__": [[447, 449], ["lr_scheduler.WarmupPolicy.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "*", ",", "max_steps", ",", "min_lr", "=", "0", ",", "last_epoch", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "optimizer", "=", "optimizer", ",", "max_steps", "=", "max_steps", ",", "last_epoch", "=", "last_epoch", ",", "min_lr", "=", "min_lr", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.SquareRootAnnealing._get_lr": [[450, 460], ["lr_scheduler._sqrt_annealing"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler._sqrt_annealing"], ["", "def", "_get_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "return", "[", "\n", "_sqrt_annealing", "(", "\n", "initial_lr", "=", "initial_lr", ",", "\n", "step", "=", "step", ",", "\n", "max_steps", "=", "self", ".", "max_steps", ",", "\n", "min_lr", "=", "self", ".", "min_lr", ",", "\n", ")", "\n", "for", "initial_lr", "in", "self", ".", "base_lrs", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing.__init__": [[466, 468], ["lr_scheduler.WarmupAnnealHoldPolicy.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "*", ",", "max_steps", ",", "min_lr", "=", "0", ",", "last_epoch", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "optimizer", "=", "optimizer", ",", "max_steps", "=", "max_steps", ",", "last_epoch", "=", "last_epoch", ",", "min_lr", "=", "min_lr", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing._get_lr": [[469, 489], ["lr_scheduler.CosineAnnealing._get_linear_warmup_with_cosine_annealing_lr", "ValueError", "lr_scheduler._cosine_annealing"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing._get_linear_warmup_with_cosine_annealing_lr", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler._cosine_annealing"], ["", "def", "_get_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "for", "initial_lr", "in", "self", ".", "base_lrs", ":", "\n", "            ", "if", "initial_lr", "<", "self", ".", "min_lr", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"{self} received an initial learning rate that was lower than the minimum learning rate.\"", "\n", ")", "\n", "\n", "", "", "return", "(", "\n", "[", "\n", "_cosine_annealing", "(", "\n", "initial_lr", "=", "initial_lr", ",", "\n", "step", "=", "step", "-", "self", ".", "warmup_steps", ",", "\n", "max_steps", "=", "self", ".", "max_steps", "-", "self", ".", "warmup_steps", ",", "\n", "min_lr", "=", "self", ".", "min_lr", ",", "\n", ")", "\n", "for", "initial_lr", "in", "self", ".", "base_lrs", "\n", "]", "\n", "if", "self", ".", "constant_steps", "is", "None", "or", "self", ".", "constant_steps", "==", "0", "\n", "else", "self", ".", "_get_linear_warmup_with_cosine_annealing_lr", "(", "step", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing._get_warmup_lr": [[491, 498], ["lr_scheduler.CosineAnnealing._get_linear_warmup_with_cosine_annealing_lr", "lr_scheduler.WarmupAnnealHoldPolicy._get_warmup_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing._get_linear_warmup_with_cosine_annealing_lr", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing._get_warmup_lr"], ["", "def", "_get_warmup_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Get the warmup learning rate for the given step.\"\"\"", "\n", "if", "self", ".", "constant_steps", "is", "None", "or", "self", ".", "constant_steps", "==", "0", ":", "\n", "            ", "return", "super", "(", ")", ".", "_get_warmup_lr", "(", "step", ")", "\n", "\n", "# Use linear warmup for the initial part.", "\n", "", "return", "self", ".", "_get_linear_warmup_with_cosine_annealing_lr", "(", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing._get_constant_lr": [[499, 502], ["lr_scheduler.CosineAnnealing._get_linear_warmup_with_cosine_annealing_lr"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing._get_linear_warmup_with_cosine_annealing_lr"], ["", "def", "_get_constant_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Only called when constant_steps is not None and not 0.\"\"\"", "\n", "return", "self", ".", "_get_linear_warmup_with_cosine_annealing_lr", "(", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.CosineAnnealing._get_linear_warmup_with_cosine_annealing_lr": [[503, 514], ["lr_scheduler._linear_warmup_with_cosine_annealing"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler._linear_warmup_with_cosine_annealing"], ["", "def", "_get_linear_warmup_with_cosine_annealing_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Cosine Schedule, slightly different warmup schedule + constant LR at the end.\"\"\"", "\n", "return", "[", "\n", "_linear_warmup_with_cosine_annealing", "(", "\n", "max_lr", "=", "self", ".", "base_lrs", "[", "0", "]", ",", "\n", "warmup_steps", "=", "self", ".", "warmup_steps", ",", "\n", "step", "=", "step", ",", "\n", "decay_steps", "=", "self", ".", "decay_steps", ",", "\n", "min_lr", "=", "self", ".", "min_lr", ",", "\n", ")", "\n", "for", "_", "in", "self", ".", "base_lrs", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.NoamAnnealing.__init__": [[520, 541], ["torch.optim.lr_scheduler._LRScheduler.__init__", "AssertionError", "AssertionError", "int"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "optimizer", ",", "*", ",", "d_model", ",", "warmup_steps", "=", "None", ",", "warmup_ratio", "=", "None", ",", "max_steps", "=", "None", ",", "min_lr", "=", "0.0", ",", "last_epoch", "=", "-", "1", "\n", ")", ":", "\n", "        ", "self", ".", "_normalize", "=", "d_model", "**", "(", "-", "0.5", ")", "\n", "if", "warmup_steps", "is", "not", "None", "and", "warmup_ratio", "is", "not", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Either use particular number of step or ratio\"", ")", "\n", "", "if", "warmup_ratio", "is", "not", "None", "and", "max_steps", "is", "None", ":", "\n", "            ", "raise", "AssertionError", "(", "\"If there is a ratio, there should be a total steps\"", ")", "\n", "\n", "# It is necessary to assign all attributes *before* __init__,", "\n", "# as class is wrapped by an inner class.", "\n", "", "self", ".", "max_steps", "=", "max_steps", "\n", "if", "warmup_steps", "is", "not", "None", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "", "elif", "warmup_ratio", "is", "not", "None", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "int", "(", "warmup_ratio", "*", "max_steps", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "warmup_steps", "=", "0", "\n", "\n", "", "self", ".", "min_lr", "=", "min_lr", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.NoamAnnealing.get_lr": [[542, 561], ["max", "warnings.warn", "lr_scheduler.NoamAnnealing._noam_annealing", "ValueError"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.NoamAnnealing._noam_annealing"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "if", "not", "self", ".", "_get_lr_called_within_step", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "\"To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\"", ",", "UserWarning", "\n", ")", "\n", "\n", "", "step", "=", "max", "(", "1", ",", "self", ".", "last_epoch", ")", "\n", "\n", "if", "step", ">", "self", ".", "max_steps", ":", "\n", "            ", "return", "[", "self", ".", "min_lr", "for", "_", "in", "self", ".", "base_lrs", "]", "\n", "\n", "", "for", "initial_lr", "in", "self", ".", "base_lrs", ":", "\n", "            ", "if", "initial_lr", "<", "self", ".", "min_lr", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"{self} received an initial learning rate that was lower than the minimum learning rate.\"", "\n", ")", "\n", "\n", "", "", "return", "[", "self", ".", "_noam_annealing", "(", "initial_lr", "=", "initial_lr", ",", "step", "=", "step", ")", "for", "initial_lr", "in", "self", ".", "base_lrs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.NoamAnnealing._noam_annealing": [[562, 569], ["min", "max"], "methods", ["None"], ["", "def", "_noam_annealing", "(", "self", ",", "initial_lr", ",", "step", ")", ":", "\n", "        ", "\"\"\"Noam learning rate annealing.\"\"\"", "\n", "mult", "=", "self", ".", "_normalize", "*", "min", "(", "step", "**", "(", "-", "0.5", ")", ",", "step", "*", "(", "self", ".", "warmup_steps", "**", "(", "-", "1.5", ")", ")", ")", "\n", "out_lr", "=", "initial_lr", "*", "mult", "\n", "if", "step", ">", "self", ".", "warmup_steps", ":", "\n", "            ", "out_lr", "=", "max", "(", "out_lr", ",", "self", ".", "min_lr", ")", "\n", "", "return", "out_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupAnnealing.__init__": [[574, 576], ["lr_scheduler.WarmupPolicy.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "*", ",", "max_steps", ",", "last_epoch", "=", "-", "1", ",", "min_lr", "=", "0.0", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "optimizer", "=", "optimizer", ",", "max_steps", "=", "max_steps", ",", "last_epoch", "=", "last_epoch", ",", "min_lr", "=", "min_lr", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.WarmupAnnealing._get_lr": [[577, 582], ["None"], "methods", ["None"], ["", "def", "_get_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "delta_lr", "=", "self", ".", "base_lrs", "[", "0", "]", "-", "self", ".", "min_lr", "\n", "mult", "=", "(", "step", "-", "self", ".", "warmup_steps", ")", "/", "(", "self", ".", "max_steps", "-", "self", ".", "warmup_steps", ")", "\n", "return", "[", "self", ".", "min_lr", "+", "(", "1", "-", "mult", ")", "*", "delta_lr", "for", "_", "in", "self", ".", "base_lrs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.InverseSquareRootAnnealing.__init__": [[587, 589], ["lr_scheduler.WarmupPolicy.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "*", ",", "max_steps", ",", "last_epoch", "=", "-", "1", ",", "min_lr", "=", "0.0", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "optimizer", "=", "optimizer", ",", "max_steps", "=", "max_steps", ",", "**", "kwargs", ",", "last_epoch", "=", "last_epoch", ",", "min_lr", "=", "min_lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.InverseSquareRootAnnealing._get_lr": [[590, 594], ["None"], "methods", ["None"], ["", "def", "_get_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "denom", "=", "(", "(", "step", "+", "1", ")", "/", "(", "self", ".", "warmup_steps", "+", "1", ")", ")", "**", "0.5", "\n", "return", "[", "initial_lr", "/", "denom", "for", "initial_lr", "in", "self", ".", "base_lrs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.T5InverseSquareRootAnnealing.__init__": [[599, 601], ["lr_scheduler.SquareRootConstantPolicy.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "*", ",", "max_steps", ",", "last_epoch", "=", "-", "1", ",", "min_lr", "=", "0.0", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "optimizer", "=", "optimizer", ",", "max_steps", "=", "max_steps", ",", "**", "kwargs", ",", "last_epoch", "=", "last_epoch", ",", "min_lr", "=", "min_lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.T5InverseSquareRootAnnealing._get_lr": [[602, 605], ["None"], "methods", ["None"], ["", "def", "_get_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "return", "[", "1", "/", "(", "step", "**", "0.5", ")", "for", "_", "in", "self", ".", "base_lrs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.PolynomialDecayAnnealing.__init__": [[610, 615], ["lr_scheduler.WarmupPolicy.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "*", ",", "max_steps", ",", "min_lr", "=", "0.0", ",", "power", "=", "1.0", ",", "cycle", "=", "False", ",", "last_epoch", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "power", "=", "power", "\n", "self", ".", "cycle", "=", "cycle", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", "=", "optimizer", ",", "max_steps", "=", "max_steps", ",", "last_epoch", "=", "last_epoch", ",", "min_lr", "=", "min_lr", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.PolynomialDecayAnnealing._get_lr": [[616, 628], ["lr_scheduler._poly_decay"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler._poly_decay"], ["", "def", "_get_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "return", "[", "\n", "_poly_decay", "(", "\n", "initial_lr", ",", "\n", "step", "=", "step", "-", "self", ".", "warmup_steps", ",", "\n", "decay_steps", "=", "self", ".", "max_steps", "-", "self", ".", "warmup_steps", ",", "\n", "power", "=", "self", ".", "power", ",", "\n", "min_lr", "=", "self", ".", "min_lr", ",", "\n", "cycle", "=", "self", ".", "cycle", ",", "\n", ")", "\n", "for", "initial_lr", "in", "self", ".", "base_lrs", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.PolynomialHoldDecayAnnealing.__init__": [[634, 639], ["lr_scheduler.WarmupHoldPolicy.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "*", ",", "max_steps", ",", "min_lr", "=", "0.0", ",", "power", "=", "1.0", ",", "cycle", "=", "False", ",", "last_epoch", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "power", "=", "power", "\n", "self", ".", "cycle", "=", "cycle", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", "=", "optimizer", ",", "max_steps", "=", "max_steps", ",", "last_epoch", "=", "last_epoch", ",", "min_lr", "=", "min_lr", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.PolynomialHoldDecayAnnealing._get_lr": [[640, 652], ["lr_scheduler._poly_decay", "max"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler._poly_decay"], ["", "def", "_get_lr", "(", "self", ",", "step", ")", ":", "\n", "        ", "\"\"\"Get learning rate at current step.\"\"\"", "\n", "return", "[", "\n", "_poly_decay", "(", "\n", "initial_lr", ",", "\n", "step", "=", "step", "-", "self", ".", "hold_steps", ",", "\n", "decay_steps", "=", "self", ".", "max_steps", "-", "max", "(", "self", ".", "warmup_steps", ",", "self", ".", "hold_steps", ")", ",", "\n", "power", "=", "self", ".", "power", ",", "\n", "min_lr", "=", "self", ".", "min_lr", ",", "\n", "cycle", "=", "self", ".", "cycle", ",", "\n", ")", "\n", "for", "initial_lr", "in", "self", ".", "base_lrs", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler._sqrt_annealing": [[363, 369], ["max"], "function", ["None"], ["", "", "def", "_sqrt_annealing", "(", "initial_lr", ",", "step", ",", "max_steps", ",", "min_lr", ")", ":", "\n", "    ", "\"\"\"Anneal learning rate by sqrt.\"\"\"", "\n", "mult", "=", "(", "(", "max_steps", "-", "step", ")", "/", "max_steps", ")", "**", "0.5", "\n", "out_lr", "=", "initial_lr", "*", "mult", "\n", "out_lr", "=", "max", "(", "out_lr", ",", "min_lr", ")", "\n", "return", "out_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler._square_annealing": [[371, 377], ["max"], "function", ["None"], ["", "def", "_square_annealing", "(", "initial_lr", ",", "step", ",", "max_steps", ",", "min_lr", ")", ":", "\n", "    ", "\"\"\"Anneal learning rate by square.\"\"\"", "\n", "mult", "=", "(", "(", "max_steps", "-", "step", ")", "/", "max_steps", ")", "**", "2", "\n", "out_lr", "=", "initial_lr", "*", "mult", "\n", "out_lr", "=", "max", "(", "out_lr", ",", "min_lr", ")", "\n", "return", "out_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler._cosine_annealing": [[379, 383], ["math.cos"], "function", ["None"], ["", "def", "_cosine_annealing", "(", "initial_lr", ",", "step", ",", "max_steps", ",", "min_lr", ")", ":", "\n", "    ", "\"\"\"Anneal learning rate by cosine.\"\"\"", "\n", "mult", "=", "0.5", "*", "(", "1", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "step", "/", "max_steps", ")", ")", "\n", "return", "(", "initial_lr", "-", "min_lr", ")", "*", "mult", "+", "min_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler._linear_warmup_with_cosine_annealing": [[385, 410], ["float", "float", "float", "math.cos", "float"], "function", ["None"], ["", "def", "_linear_warmup_with_cosine_annealing", "(", "max_lr", ",", "warmup_steps", ",", "step", ",", "decay_steps", ",", "min_lr", ")", ":", "\n", "    ", "\"\"\"Anneal learning rate by linear warmup and cosine annealing.\"\"\"", "\n", "if", "max_lr", "<=", "min_lr", ":", "\n", "        ", "raise", "AssertionError", "\n", "# Use linear warmup for the initial part.", "\n", "", "if", "warmup_steps", ">", "0", "and", "step", "<=", "warmup_steps", ":", "\n", "        ", "return", "max_lr", "*", "float", "(", "step", ")", "/", "float", "(", "warmup_steps", ")", "\n", "\n", "# For any steps larger than `decay_steps`, use `min_lr`.", "\n", "", "if", "step", ">", "warmup_steps", "+", "decay_steps", ":", "\n", "        ", "return", "min_lr", "\n", "\n", "# If we are done with the warmup period, use the decay style.", "\n", "", "num_steps_", "=", "step", "-", "warmup_steps", "\n", "decay_steps_", "=", "decay_steps", "\n", "decay_ratio", "=", "float", "(", "num_steps_", ")", "/", "float", "(", "decay_steps_", ")", "\n", "if", "decay_ratio", "<", "0.0", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "if", "decay_ratio", ">", "1.0", ":", "\n", "        ", "raise", "AssertionError", "\n", "", "delta_lr", "=", "max_lr", "-", "min_lr", "\n", "\n", "coeff", "=", "0.5", "*", "(", "math", ".", "cos", "(", "math", ".", "pi", "*", "decay_ratio", ")", "+", "1.0", ")", "\n", "\n", "return", "min_lr", "+", "coeff", "*", "delta_lr", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler._poly_decay": [[412, 423], ["min", "math.pow", "math.ceil"], "function", ["None"], ["", "def", "_poly_decay", "(", "initial_lr", ",", "step", ",", "decay_steps", ",", "power", ",", "min_lr", ",", "cycle", ")", ":", "\n", "    ", "\"\"\"Polynomial decay of learning rate.\"\"\"", "\n", "if", "cycle", ":", "\n", "        ", "multiplier", "=", "1.0", "if", "step", "==", "0", "else", "math", ".", "ceil", "(", "step", "/", "decay_steps", ")", "\n", "decay_steps", "*=", "multiplier", "\n", "", "else", ":", "\n", "        ", "step", "=", "min", "(", "step", ",", "decay_steps", ")", "\n", "", "p", "=", "step", "/", "decay_steps", "\n", "lr", "=", "(", "initial_lr", "-", "min_lr", ")", "*", "math", ".", "pow", "(", "1.0", "-", "p", ",", "power", ")", "\n", "lr", "+=", "min_lr", "\n", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.register_scheduler": [[655, 673], ["mridc.core.conf.schedulers.register_scheduler_params", "ValueError"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.conf.schedulers.register_scheduler_params"], ["", "", "def", "register_scheduler", "(", "name", ":", "str", ",", "scheduler", ":", "_LRScheduler", ",", "scheduler_params", ":", "SchedulerParams", ")", ":", "\n", "    ", "\"\"\"\n    Checks if the scheduler name exists in the registry, and if it doesn't, adds it.\n    This allows custom schedulers to be added and called by name during instantiation.\n\n    Parameters\n    ----------\n    name: Name of the optimizer. Will be used as key to retrieve the optimizer.\n    scheduler: Scheduler class (inherits from _LRScheduler)\n    scheduler_params: The parameters as a dataclass of the scheduler\n    \"\"\"", "\n", "if", "name", "in", "AVAILABLE_SCHEDULERS", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Cannot override pre-existing schedulers. Conflicting scheduler name = {name}\"", ")", "\n", "\n", "", "AVAILABLE_SCHEDULERS", "[", "name", "]", "=", "scheduler", "\n", "\n", "sched_name", "=", "f\"{scheduler.__name__}_params\"", "\n", "register_scheduler_params", "(", "name", "=", "sched_name", ",", "scheduler_params", "=", "scheduler_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.get_scheduler": [[675, 695], ["functools.partial", "ValueError", "AVAILABLE_SCHEDULERS.keys"], "function", ["None"], ["", "def", "get_scheduler", "(", "name", ":", "str", ",", "**", "kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "_LRScheduler", ":", "\n", "    ", "\"\"\"\n    Convenience method to obtain an _LRScheduler class and partially instantiate it with optimizer kwargs.\n\n    Parameters\n    ----------\n    name: Name of the scheduler in the registry.\n    kwargs: Optional kwargs of the scheduler used during instantiation.\n\n    Returns\n    -------\n    A partially instantiated _LRScheduler\n    \"\"\"", "\n", "if", "name", "not", "in", "AVAILABLE_SCHEDULERS", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Cannot resolve scheduler{name}'. Available optimizers are : \"", "f\"{AVAILABLE_SCHEDULERS.keys()}\"", "\n", ")", "\n", "\n", "", "scheduler_cls", "=", "AVAILABLE_SCHEDULERS", "[", "name", "]", "\n", "return", "partial", "(", "scheduler_cls", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.prepare_lr_scheduler": [[697, 953], ["isinstance", "lr_scheduler.get_scheduler", "get_scheduler.", "mridc.utils.logging.info", "isinstance", "mridc.utils.model_utils.maybe_update_config_version", "omegaconf.OmegaConf.to_container", "dataclasses.is_dataclass", "mridc.utils.logging.info", "omegaconf.OmegaConf.create", "hydra.utils.instantiate", "vars", "OmegaConf.to_container.get", "str", "omegaconf.OmegaConf.to_yaml", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.to_container", "OmegaConf.to_container.pop", "copy.deepcopy", "vars.pop", "vars.pop", "vars.pop", "vars.pop", "vars.pop", "vars.pop", "vars.pop", "scheduler_name.replace.replace", "mridc.utils.logging.warning", "vars.get", "isinstance", "mridc.core.conf.schedulers.get_scheduler_config", "vars", "OmegaConf.to_container.get", "OmegaConf.to_container.get", "OmegaConf.to_container.get", "OmegaConf.to_container.get", "len", "lr_scheduler.compute_max_steps", "mridc.utils.logging.warning", "OmegaConf.to_container.get", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.to_container", "mridc.utils.logging.warning", "OmegaConf.to_container.get", "mridc.utils.logging.warning", "hasattr", "ValueError", "ValueError"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.get_scheduler", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.maybe_update_config_version", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.conf.schedulers.get_scheduler_config", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.compute_max_steps", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning"], ["", "def", "prepare_lr_scheduler", "(", "\n", "optimizer", ":", "optim", ".", "Optimizer", ",", "\n", "scheduler_config", ":", "Union", "[", "Dict", "[", "str", ",", "Any", "]", ",", "DictConfig", ",", "None", "]", ",", "\n", "train_dataloader", ":", "Optional", "[", "dataloader", ".", "DataLoader", "]", "=", "None", ",", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", ":", "\n", "    ", "\"\"\"\n    Constructs an LR Scheduler (optionally) for a given optimizer, based on a config with the following schema.\n\n    Parameters\n    ----------\n    optimizer: The optimizer to use for the scheduler.\n        name: <name of optimizer>\n\n        lr: <maximal learning rate>\n\n        # <additional optimizer arguments>\n\n        args:\n\n            name: auto  # special keyword, resolves to correct optimizer config for given optimizer name\n\n            # cls: mridc.core.config.optimizers.NovogradParams  # explicit instantiation by class path\n\n            params:  # optional override parameters for the optimizer config\n\n                betas: [0.8, 0.5]\n\n                weight_decay: 0.001\n\n    scheduler_config: The scheduler config.\n\n        name: <name of scheduler>\n\n        iters_per_batch: null # computed at runtime; mandatory to have\n\n        max_steps: null # computed at runtime or explicitly set here; mandatory to have\n\n        # pytorch lightning args <mandatory>\n\n        monitor: val_loss\n\n        reduce_on_plateau: false\n\n        # <scheduler config override>\n\n        args:\n\n            name: auto  # special keyword, resolves to correct optimizer config for given optimizer name\n\n            # cls: mridc.core.config.schedulers.CosineAnnealingParams  # explicit instantiation by class path\n\n            params:  # optional override parameters for the optimizer config\n\n                warmup_steps: null\n\n                warmup_ratio: null\n\n                min_lr: 0.0\n\n                last_epoch: -1\n\n    train_dataloader: Optional requirement, must be passed if \"iters_per_batch\" is defined instead of \"max_steps\". \\\n    Used to compute effective \"max_steps\".\n\n    Returns\n    -------\n    A dictionary containing the LR Scheduler implementation if the config was successfully parsed along with other \\\n    parameters required by Pytorch Lightning, otherwise None.\n    \"\"\"", "\n", "if", "scheduler_config", "is", "not", "None", ":", "\n", "        ", "scheduler_config", "=", "maybe_update_config_version", "(", "scheduler_config", ")", "\n", "\n", "# Build nested dictionary for convenience out of structured objects", "\n", "", "if", "isinstance", "(", "scheduler_config", ",", "DictConfig", ")", ":", "\n", "        ", "scheduler_config", "=", "OmegaConf", ".", "to_container", "(", "scheduler_config", ",", "resolve", "=", "True", ")", "\n", "\n", "", "elif", "dataclasses", ".", "is_dataclass", "(", "scheduler_config", ")", ":", "\n", "# Recursively transform data classes to basic dictionaries", "\n", "        ", "scheduler_config", "=", "OmegaConf", ".", "create", "(", "scheduler_config", ")", "\n", "scheduler_config", "=", "OmegaConf", ".", "to_container", "(", "scheduler_config", ",", "resolve", "=", "True", ")", "\n", "\n", "# Test to see if config follows above schema", "\n", "\n", "", "add_max_args_flag", "=", "True", "\n", "interval", "=", "\"step\"", "\n", "if", "scheduler_config", "is", "not", "None", ":", "\n", "        ", "if", "\"args\"", "in", "scheduler_config", ":", "\n", "            ", "scheduler_args", "=", "scheduler_config", ".", "pop", "(", "\"args\"", ")", "\n", "", "else", ":", "\n", "            ", "scheduler_args", "=", "copy", ".", "deepcopy", "(", "scheduler_config", ")", "\n", "\n", "# Remove extra parameters from scheduler_args nest", "\n", "# Assume all other parameters are to be passed into scheduler constructor", "\n", "\n", "if", "\"name\"", "in", "scheduler_args", "and", "scheduler_args", "[", "\"name\"", "]", "==", "\"ReduceLROnPlateau\"", ":", "\n", "                ", "add_max_args_flag", "=", "False", "\n", "interval", "=", "\"epoch\"", "\n", "\n", "", "scheduler_args", ".", "pop", "(", "\"name\"", ",", "None", ")", "\n", "scheduler_args", ".", "pop", "(", "\"t_max_epochs\"", ",", "None", ")", "\n", "scheduler_args", ".", "pop", "(", "\"t_accumulate_grad_batches\"", ",", "None", ")", "\n", "scheduler_args", ".", "pop", "(", "\"t_limit_train_batches\"", ",", "None", ")", "\n", "scheduler_args", ".", "pop", "(", "\"t_num_workers\"", ",", "None", ")", "\n", "scheduler_args", ".", "pop", "(", "\"monitor\"", ",", "None", ")", "\n", "scheduler_args", ".", "pop", "(", "\"reduce_on_plateau\"", ",", "None", ")", "\n", "\n", "", "", "else", ":", "\n", "# Return gracefully in case `sched` was not supplied; inform user", "\n", "        ", "logging", ".", "info", "(", "\"Scheduler not initialized as no `sched` config supplied to setup_optimizer()\"", ")", "\n", "return", "None", "\n", "\n", "# Try instantiation of scheduler params from config class path", "\n", "", "if", "\"_target_\"", "in", "scheduler_args", ":", "\n", "        ", "scheduler_args_cfg", "=", "OmegaConf", ".", "create", "(", "scheduler_args", ")", "\n", "scheduler_conf", "=", "hydra", ".", "utils", ".", "instantiate", "(", "scheduler_args_cfg", ")", "\n", "scheduler_args", "=", "vars", "(", "scheduler_conf", ")", "\n", "\n", "# Get name of the scheduler", "\n", "scheduler_name", "=", "scheduler_conf", ".", "__class__", ".", "__name__", "\n", "\n", "if", "\"Params\"", "in", "scheduler_name", ":", "\n", "            ", "scheduler_name", "=", "scheduler_name", ".", "replace", "(", "\"Params\"", ",", "\"\"", ")", "\n", "\n", "", "", "else", ":", "\n", "# Class path instantiation failed; try resolving \"name\" component", "\n", "\n", "# Get name of the scheduler", "\n", "        ", "if", "\"name\"", "in", "scheduler_config", ":", "\n", "            ", "scheduler_name", "=", "scheduler_config", "[", "\"name\"", "]", "\n", "", "else", ":", "\n", "            ", "logging", ".", "warning", "(", "\n", "\"Could not resolve classpath for Scheduler Config, and `name` \"", "\n", "\"was not provided either. \\n\"", "\n", "\"Scheduler cannot be instantiated !\"", "\n", ")", "\n", "return", "None", "\n", "\n", "# If class path was not provided, perhaps `name` is provided for resolution", "\n", "", "if", "\"name\"", "in", "scheduler_args", ":", "\n", "# If `auto` is passed as name for resolution of optimizer name,", "\n", "# then lookup optimizer name and resolve its parameter config", "\n", "            ", "if", "scheduler_args", "[", "\"name\"", "]", "==", "\"auto\"", ":", "\n", "                ", "scheduler_params_name", "=", "f\"{scheduler_name}Params\"", "\n", "", "else", ":", "\n", "                ", "scheduler_params_name", "=", "scheduler_args", "[", "\"name\"", "]", "\n", "\n", "# Get override arguments provided in the config yaml file / Dict Config", "\n", "", "scheduler_params_override", "=", "scheduler_args", ".", "get", "(", "\"params\"", ",", "{", "}", ")", "\n", "\n", "# If params is itself a dict config object provided explicitly in Dict Config", "\n", "# Resolve to dictionary for convenience", "\n", "if", "isinstance", "(", "scheduler_params_override", ",", "DictConfig", ")", ":", "\n", "                ", "scheduler_params_override", "=", "OmegaConf", ".", "to_container", "(", "scheduler_params_override", ",", "resolve", "=", "True", ")", "\n", "\n", "# Get and instantiate the Config dataclass for this scheduler", "\n", "", "scheduler_params_cls", "=", "get_scheduler_config", "(", "scheduler_params_name", ",", "**", "scheduler_params_override", ")", "\n", "scheduler_params", "=", "scheduler_params_cls", "# instantiate the parameters object", "\n", "scheduler_args", "=", "vars", "(", "scheduler_params", ")", "# extract just the dictionary from the Config object", "\n", "\n", "# Extract value to monitor in losses, if provided.", "\n", "", "", "if", "\"monitor\"", "in", "scheduler_config", ":", "\n", "        ", "monitor", "=", "scheduler_config", ".", "get", "(", "\"monitor\"", ")", "\n", "", "else", ":", "\n", "# Default to train loss", "\n", "        ", "monitor", "=", "\"loss\"", "\n", "\n", "# Store exact max_steps if it is provided", "\n", "", "if", "\"max_steps\"", "in", "scheduler_config", "and", "scheduler_config", "[", "\"max_steps\"", "]", "is", "not", "None", ":", "\n", "        ", "max_steps", "=", "scheduler_config", "[", "\"max_steps\"", "]", "\n", "\n", "", "elif", "\"t_max_epochs\"", "in", "scheduler_config", ":", "\n", "# Compute effective max_steps if t_max_epochs is provided", "\n", "        ", "if", "train_dataloader", "is", "None", ":", "\n", "            ", "logging", ".", "warning", "(", "\n", "\"As `t_max_epochs` is provided/computed, it is required to pass the train dataloader in order\\n\"", "\n", "\"to compute effective maximum number of steps.\\n\"", "\n", "\"Scheduler will not be instantiated !\"", "\n", ")", "\n", "return", "None", "\n", "\n", "# Raise exception if neither `max_steps` nor `t_max_epochs` is provided", "\n", "", "if", "scheduler_config", ".", "get", "(", "\"t_max_epochs\"", ",", "None", ")", "is", "None", ":", "\n", "            ", "logging", ".", "warning", "(", "\n", "\"`t_max_epochs` cannot be None when `max_steps` is not not provided.\\n\"", "\n", "\"This can occur when `train dataloader` is not available to correctly \"", "\n", "\"prepare the scheduler.\\n\"", "\n", "\"Scheduler will not be instantiated !\"", "\n", ")", "\n", "return", "None", "\n", "\n", "# Get iters_per_batch", "\n", "", "max_epochs", "=", "scheduler_config", ".", "get", "(", "\"t_max_epochs\"", ")", "\n", "accumulate_grad_batches", "=", "scheduler_config", ".", "get", "(", "\"t_accumulate_grad_batches\"", ")", "\n", "limit_train_batches", "=", "scheduler_config", ".", "get", "(", "\"t_limit_train_batches\"", ")", "\n", "num_workers", "=", "scheduler_config", ".", "get", "(", "\"t_num_workers\"", ")", "\n", "\n", "# Compute effective num max_steps", "\n", "num_samples", "=", "len", "(", "train_dataloader", ".", "dataset", ")", "# type: ignore", "\n", "\n", "# we may need to override ModelPT setup_optimization", "\n", "if", "train_dataloader", ".", "batch_size", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "train_dataloader", ".", "batch_size", "\n", "", "elif", "hasattr", "(", "train_dataloader", ",", "\"batch_sampler\"", ")", "and", "train_dataloader", ".", "batch_sampler", "is", "not", "None", ":", "\n", "            ", "if", "train_dataloader", ".", "batch_sampler", ".", "micro_batch_size", "is", "not", "None", ":", "\n", "                ", "batch_size", "=", "train_dataloader", ".", "batch_sampler", ".", "micro_batch_size", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Could not find batch_size from batch_sampler: {train_dataloader.batch_sampler}\"", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Could not find batch_size from train_dataloader: {train_dataloader}\"", ")", "\n", "", "drop_last", "=", "train_dataloader", ".", "drop_last", "\n", "\n", "max_steps", "=", "compute_max_steps", "(", "\n", "max_epochs", "=", "max_epochs", ",", "\n", "accumulate_grad_batches", "=", "accumulate_grad_batches", ",", "\n", "limit_train_batches", "=", "limit_train_batches", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "num_samples", "=", "num_samples", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "drop_last", "=", "drop_last", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "        ", "logging", ".", "warning", "(", "\n", "\"Neither `max_steps` nor `iters_per_batch` were provided to `optim.sched`, \"", "\n", "\"cannot compute effective `max_steps` !\\n\"", "\n", "\"Scheduler will not be instantiated !\"", "\n", ")", "\n", "return", "None", "\n", "\n", "# Inject max_steps (effective or provided) into the scheduler config", "\n", "", "if", "add_max_args_flag", "and", "scheduler_config", ".", "get", "(", "\"name\"", ",", "\"\"", ")", "!=", "\"ExponentialLR\"", ":", "\n", "        ", "scheduler_args", "[", "\"max_steps\"", "]", "=", "max_steps", "\n", "\n", "# Get the scheduler class from the config", "\n", "", "scheduler_cls", "=", "get_scheduler", "(", "scheduler_name", ",", "**", "scheduler_args", ")", "\n", "\n", "# Instantiate the LR schedule", "\n", "schedule", "=", "scheduler_cls", "(", "optimizer", ",", "**", "scheduler_args", ")", "\n", "\n", "logging", ".", "info", "(", "\n", "'Scheduler \"%s\" \\nwill be used during training (effective maximum steps = %d) - \\nParameters : \\n(%s)'", ",", "\n", "str", "(", "schedule", ")", ",", "\n", "max_steps", ",", "\n", "OmegaConf", ".", "to_yaml", "(", "OmegaConf", ".", "create", "(", "scheduler_args", ")", ")", ",", "\n", ")", "\n", "\n", "# Wrap the schedule in PTL arguments to perform stepwise computation", "\n", "# Rather than epoch level computation", "\n", "reduce_lr_on_plateau", "=", "isinstance", "(", "schedule", ",", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", ")", "\n", "\n", "return", "{", "\n", "\"scheduler\"", ":", "schedule", ",", "\n", "\"interval\"", ":", "interval", ",", "\n", "\"frequency\"", ":", "1", ",", "\n", "\"monitor\"", ":", "monitor", ",", "\n", "\"reduce_on_plateau\"", ":", "reduce_lr_on_plateau", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.compute_max_steps": [[956, 977], ["math.ceil", "_round", "mridc.utils.logging.warning", "isinstance", "min", "math.ceil", "max", "int", "float", "int"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning"], ["", "def", "compute_max_steps", "(", "\n", "max_epochs", ",", "accumulate_grad_batches", ",", "limit_train_batches", ",", "num_workers", ",", "num_samples", ",", "batch_size", ",", "drop_last", "\n", ")", ":", "\n", "    ", "\"\"\"Compute effective max_steps from the provided parameters.\"\"\"", "\n", "_round", "=", "math", ".", "floor", "if", "drop_last", "else", "math", ".", "ceil", "\n", "\n", "sampler_num_samples", "=", "math", ".", "ceil", "(", "num_samples", "/", "max", "(", "1", ",", "num_workers", ")", ")", "\n", "\n", "if", "drop_last", "and", "num_workers", ">", "1", ":", "\n", "        ", "logging", ".", "warning", "(", "\n", "\"Please note that drop_last is broken in pytorch 1.6.0. We will fix when pytorch 1.7.0 is released\"", "\n", ")", "\n", "\n", "", "steps_per_epoch", "=", "_round", "(", "sampler_num_samples", "/", "batch_size", ")", "\n", "if", "isinstance", "(", "limit_train_batches", ",", "int", ")", "or", "limit_train_batches", "==", "0.0", ":", "\n", "        ", "steps_per_epoch", "=", "min", "(", "steps_per_epoch", ",", "int", "(", "limit_train_batches", ")", ")", "\n", "", "elif", "steps_per_epoch", "!=", "float", "(", "\"inf\"", ")", ":", "\n", "# limit_train_batches is a percentage of batches per epoch", "\n", "        ", "steps_per_epoch", "=", "int", "(", "steps_per_epoch", "*", "limit_train_batches", ")", "\n", "\n", "", "return", "math", ".", "ceil", "(", "steps_per_epoch", "/", "accumulate_grad_batches", ")", "*", "max_epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.novograd.Novograd.__init__": [[44, 65], ["novograd._check_valid_opt_params", "dict", "torch.optim.optimizer.Optimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.novograd._check_valid_opt_params", "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "params", ",", "\n", "lr", "=", "1e-3", ",", "\n", "betas", "=", "(", "0.95", ",", "0.98", ")", ",", "\n", "eps", "=", "1e-8", ",", "\n", "weight_decay", "=", "0", ",", "\n", "grad_averaging", "=", "False", ",", "\n", "amsgrad", "=", "False", ",", "\n", "luc", "=", "False", ",", "\n", "luc_trust", "=", "1e-3", ",", "\n", "luc_eps", "=", "1e-8", ",", "\n", ")", ":", "\n", "        ", "_check_valid_opt_params", "(", "lr", ",", "eps", ",", "betas", ")", "\n", "defaults", "=", "dict", "(", "\n", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "grad_averaging", "=", "grad_averaging", ",", "amsgrad", "=", "amsgrad", "\n", ")", "\n", "self", ".", "luc", "=", "luc", "\n", "self", ".", "luc_trust", "=", "luc_trust", "\n", "self", ".", "luc_eps", "=", "luc_eps", "\n", "super", "(", "Novograd", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.novograd.Novograd.__setstate__": [[66, 70], ["super().__setstate__", "group.setdefault"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.novograd.Novograd.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "super", "(", "Novograd", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "group", ".", "setdefault", "(", "\"amsgrad\"", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.novograd.Novograd.step": [[71, 145], ["closure", "grad.norm().pow", "grad.div_", "exp_avg.mul_().add_", "RuntimeError", "torch.zeros_like", "torch.zeros().to", "exp_avg_sq.copy_", "exp_avg_sq.mul_().add_", "torch.max", "max_exp_avg_sq.sqrt().add_", "exp_avg_sq.sqrt().add_", "grad.add_", "grad.mul_", "torch.norm", "torch.norm", "min", "p.data.add_", "p.data.add_", "torch.zeros().to", "grad.norm", "exp_avg.mul_", "torch.zeros", "exp_avg_sq.mul_", "max_exp_avg_sq.sqrt", "exp_avg_sq.sqrt", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.norm", "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.norm", "home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.norm"], ["", "", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Performs a single optimization step.\n\n        Parameters\n        ----------\n        closure: A closure that reevaluates the model and returns the loss.\n\n        Returns\n        -------\n        loss: Loss (if provided)\n        \"\"\"", "\n", "loss", "=", "closure", "(", ")", "if", "closure", "is", "not", "None", "else", "None", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"Sparse gradients are not supported.\"", ")", "\n", "", "amsgrad", "=", "group", "[", "\"amsgrad\"", "]", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "not", "state", ":", "\n", "                    ", "state", "[", "\"step\"", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "\"exp_avg\"", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "\"exp_avg_sq\"", "]", "=", "torch", ".", "zeros", "(", "[", "]", ")", ".", "to", "(", "state", "[", "\"exp_avg\"", "]", ".", "device", ")", "\n", "if", "amsgrad", ":", "\n", "# Maintains max of all exp moving avg of squared grad", "\n", "                        ", "state", "[", "\"max_exp_avg_sq\"", "]", "=", "torch", ".", "zeros", "(", "[", "]", ")", ".", "to", "(", "state", "[", "\"exp_avg\"", "]", ".", "device", ")", "\n", "\n", "", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "\"exp_avg\"", "]", ",", "state", "[", "\"exp_avg_sq\"", "]", "\n", "if", "amsgrad", ":", "\n", "                    ", "max_exp_avg_sq", "=", "state", "[", "\"max_exp_avg_sq\"", "]", "\n", "", "beta1", ",", "beta2", "=", "group", "[", "\"betas\"", "]", "\n", "\n", "state", "[", "\"step\"", "]", "+=", "1", "\n", "\n", "norm", "=", "grad", ".", "norm", "(", ")", ".", "pow", "(", "2", ")", "\n", "\n", "if", "exp_avg_sq", "==", "0", ":", "\n", "                    ", "exp_avg_sq", ".", "copy_", "(", "norm", ")", "\n", "", "else", ":", "\n", "                    ", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "add_", "(", "norm", ",", "alpha", "=", "1.0", "-", "beta2", ")", "\n", "\n", "", "if", "amsgrad", ":", "\n", "# Maintains max of all 2nd moment running avg till now", "\n", "                    ", "torch", ".", "max", "(", "max_exp_avg_sq", ",", "exp_avg_sq", ",", "out", "=", "max_exp_avg_sq", ")", "\n", "# Use the max for normalizing running avg. of gradient", "\n", "denom", "=", "max_exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "\"eps\"", "]", ")", "\n", "", "else", ":", "\n", "                    ", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "\"eps\"", "]", ")", "\n", "\n", "", "grad", ".", "div_", "(", "denom", ")", "\n", "if", "group", "[", "\"weight_decay\"", "]", "!=", "0", ":", "\n", "                    ", "grad", ".", "add_", "(", "p", ".", "data", ",", "alpha", "=", "group", "[", "\"weight_decay\"", "]", ")", "\n", "", "if", "group", "[", "\"grad_averaging\"", "]", ":", "\n", "                    ", "grad", ".", "mul_", "(", "1", "-", "beta1", ")", "\n", "", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "grad", ")", "\n", "\n", "if", "self", ".", "luc", ":", "\n", "# Clip update so that updates are less than eta*weights", "\n", "                    ", "data_norm", "=", "torch", ".", "norm", "(", "p", ".", "data", ")", "\n", "grad_norm", "=", "torch", ".", "norm", "(", "exp_avg", ".", "data", ")", "\n", "luc_factor", "=", "self", ".", "luc_trust", "*", "data_norm", "/", "(", "grad_norm", "+", "self", ".", "luc_eps", ")", "\n", "luc_factor", "=", "min", "(", "luc_factor", ",", "group", "[", "\"lr\"", "]", ")", "\n", "p", ".", "data", ".", "add_", "(", "exp_avg", ",", "alpha", "=", "-", "luc_factor", ")", "\n", "", "else", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "exp_avg", ",", "alpha", "=", "-", "group", "[", "\"lr\"", "]", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.optim.novograd._check_valid_opt_params": [[12, 20], ["ValueError", "ValueError", "ValueError"], "function", ["None"], ["def", "_check_valid_opt_params", "(", "lr", ",", "eps", ",", "betas", ")", ":", "\n", "    ", "\"\"\"Check if the given learning rate and epsilon are valid.\"\"\"", "\n", "if", "lr", "<", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Invalid learning rate: {lr}\"", ")", "\n", "", "if", "eps", "<", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Invalid epsilon value: {eps}\"", ")", "\n", "", "if", "not", "(", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", "and", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ")", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Betas have to be between 0 and 1: {betas}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.__init__": [[53, 86], ["dict", "torch.optim.optimizer.Optimizer.__init__", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "params", ",", "\n", "lr", "=", "None", ",", "\n", "eps", "=", "(", "1e-30", ",", "1e-3", ")", ",", "\n", "clip_threshold", "=", "1.0", ",", "\n", "decay_rate", "=", "-", "0.8", ",", "\n", "beta1", "=", "None", ",", "\n", "weight_decay", "=", "0.0", ",", "\n", "scale_parameter", "=", "True", ",", "\n", "relative_step", "=", "True", ",", "\n", "warmup_init", "=", "False", ",", "\n", "min_step", "=", "1e-2", ",", "\n", ")", ":", "\n", "        ", "if", "lr", "is", "not", "None", "and", "relative_step", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot combine manual lr and relative_step options\"", ")", "\n", "", "if", "warmup_init", "and", "not", "relative_step", ":", "\n", "            ", "raise", "ValueError", "(", "\"warmup_init requires relative_step=True\"", ")", "\n", "", "self", ".", "min_step", "=", "min_step", "\n", "\n", "defaults", "=", "dict", "(", "\n", "lr", "=", "lr", ",", "\n", "eps", "=", "eps", ",", "\n", "clip_threshold", "=", "clip_threshold", ",", "\n", "decay_rate", "=", "decay_rate", ",", "\n", "beta1", "=", "beta1", ",", "\n", "weight_decay", "=", "weight_decay", ",", "\n", "scale_parameter", "=", "scale_parameter", ",", "\n", "relative_step", "=", "relative_step", ",", "\n", "warmup_init", "=", "warmup_init", ",", "\n", "min_step", "=", "min_step", ",", "\n", ")", "\n", "super", "(", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.supports_memory_efficient_fp16": [[87, 91], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_memory_efficient_fp16", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether optimizer supports memory efficient fp16\"\"\"", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.supports_flat_params": [[92, 96], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supports_flat_params", "(", "self", ")", ":", "\n", "        ", "\"\"\"Whether the optimizer supports flat parameters.\"\"\"", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor._get_lr": [[97, 107], ["min", "max", "math.sqrt"], "methods", ["None"], ["", "def", "_get_lr", "(", "self", ",", "param_group", ",", "param_state", ")", ":", "\n", "        ", "\"\"\"Returns the learning rate for the current layer.\"\"\"", "\n", "rel_step_sz", "=", "param_group", "[", "\"lr\"", "]", "\n", "if", "param_group", "[", "\"relative_step\"", "]", ":", "\n", "            ", "min_step", "=", "1e-6", "*", "param_state", "[", "\"step\"", "]", "if", "param_group", "[", "\"warmup_init\"", "]", "else", "self", ".", "min_step", "\n", "rel_step_sz", "=", "min", "(", "min_step", ",", "1.0", "/", "math", ".", "sqrt", "(", "param_state", "[", "\"step\"", "]", ")", ")", "\n", "", "param_scale", "=", "1.0", "\n", "if", "param_group", "[", "\"scale_parameter\"", "]", ":", "\n", "            ", "param_scale", "=", "max", "(", "param_group", "[", "\"eps\"", "]", "[", "1", "]", ",", "param_state", "[", "\"RMS\"", "]", ")", "\n", "", "return", "param_scale", "*", "rel_step_sz", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor.step": [[108, 198], ["closure", "adafactor.Adafactor._get_options"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor._get_options"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Performs a single optimization step.\n\n        Parameters\n        ----------\n        closure: A closure that reevaluates the model and returns the loss.\n            callable (optional)\n        \"\"\"", "\n", "loss", "=", "closure", "(", ")", "if", "closure", "is", "not", "None", "else", "None", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "grad", "=", "grad", ".", "float", "(", ")", "\n", "", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"Adafactor does not support sparse gradients.\"", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "grad_shape", "=", "grad", ".", "shape", "\n", "\n", "factored", ",", "use_first_moment", "=", "_get_options", "(", "group", ",", "grad_shape", ")", "\n", "# State Initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "\"step\"", "]", "=", "0", "\n", "\n", "if", "use_first_moment", ":", "\n", "# Exponential moving average of gradient values", "\n", "                        ", "state", "[", "\"exp_avg\"", "]", "=", "torch", ".", "zeros_like", "(", "grad", ")", "\n", "", "if", "factored", ":", "\n", "                        ", "state", "[", "\"exp_avg_sq_row\"", "]", "=", "torch", ".", "zeros", "(", "grad_shape", "[", ":", "-", "1", "]", ")", ".", "to", "(", "grad", ")", "\n", "state", "[", "\"exp_avg_sq_col\"", "]", "=", "torch", ".", "zeros", "(", "grad_shape", "[", ":", "-", "2", "]", "+", "grad_shape", "[", "-", "1", ":", "]", ")", ".", "to", "(", "grad", ")", "\n", "", "else", ":", "\n", "                        ", "state", "[", "\"exp_avg_sq\"", "]", "=", "torch", ".", "zeros_like", "(", "grad", ")", "\n", "\n", "", "state", "[", "\"RMS\"", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "if", "use_first_moment", ":", "\n", "                        ", "state", "[", "\"exp_avg\"", "]", "=", "state", "[", "\"exp_avg\"", "]", ".", "to", "(", "grad", ")", "\n", "", "if", "factored", ":", "\n", "                        ", "state", "[", "\"exp_avg_sq_row\"", "]", "=", "state", "[", "\"exp_avg_sq_row\"", "]", ".", "to", "(", "grad", ")", "\n", "state", "[", "\"exp_avg_sq_col\"", "]", "=", "state", "[", "\"exp_avg_sq_col\"", "]", ".", "to", "(", "grad", ")", "\n", "", "else", ":", "\n", "                        ", "state", "[", "\"exp_avg_sq\"", "]", "=", "state", "[", "\"exp_avg_sq\"", "]", ".", "to", "(", "grad", ")", "\n", "\n", "", "", "p_data_fp32", "=", "p", ".", "data", "\n", "if", "p", ".", "data", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "p_data_fp32", "=", "p_data_fp32", ".", "float", "(", ")", "\n", "\n", "", "state", "[", "\"step\"", "]", "+=", "1", "\n", "state", "[", "\"RMS\"", "]", "=", "_rms", "(", "p_data_fp32", ")", "\n", "group", "[", "\"lr\"", "]", "=", "self", ".", "_get_lr", "(", "group", ",", "state", ")", "\n", "\n", "beta2t", "=", "1.0", "-", "math", ".", "pow", "(", "state", "[", "\"step\"", "]", ",", "group", "[", "\"decay_rate\"", "]", ")", "\n", "update", "=", "(", "grad", "**", "2", ")", "+", "group", "[", "\"eps\"", "]", "[", "0", "]", "\n", "if", "factored", ":", "\n", "                    ", "exp_avg_sq_row", "=", "state", "[", "\"exp_avg_sq_row\"", "]", "\n", "exp_avg_sq_col", "=", "state", "[", "\"exp_avg_sq_col\"", "]", "\n", "\n", "exp_avg_sq_row", ".", "mul_", "(", "beta2t", ")", ".", "add_", "(", "update", ".", "mean", "(", "dim", "=", "-", "1", ")", ",", "alpha", "=", "1.0", "-", "beta2t", ")", "\n", "exp_avg_sq_col", ".", "mul_", "(", "beta2t", ")", ".", "add_", "(", "update", ".", "mean", "(", "dim", "=", "-", "2", ")", ",", "alpha", "=", "1.0", "-", "beta2t", ")", "\n", "\n", "# Approximation of exponential moving average of square of gradient", "\n", "update", "=", "_approx_sq_grad", "(", "exp_avg_sq_row", ",", "exp_avg_sq_col", ")", "\n", "update", ".", "mul_", "(", "grad", ")", "\n", "", "else", ":", "\n", "                    ", "exp_avg_sq", "=", "state", "[", "\"exp_avg_sq\"", "]", "\n", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2t", ")", ".", "add_", "(", "update", ",", "alpha", "=", "1.0", "-", "beta2t", ")", "\n", "update", "=", "exp_avg_sq", ".", "rsqrt", "(", ")", ".", "mul_", "(", "grad", ")", "\n", "\n", "", "update", ".", "div_", "(", "(", "_rms", "(", "update", ")", "/", "group", "[", "\"clip_threshold\"", "]", ")", ".", "clamp_", "(", "min", "=", "1.0", ")", ")", "\n", "update", ".", "mul_", "(", "group", "[", "\"lr\"", "]", ")", "\n", "\n", "if", "use_first_moment", ":", "\n", "                    ", "exp_avg", "=", "state", "[", "\"exp_avg\"", "]", "\n", "exp_avg", ".", "mul_", "(", "group", "[", "\"beta1\"", "]", ")", ".", "add_", "(", "update", ",", "alpha", "=", "1", "-", "group", "[", "\"beta1\"", "]", ")", "\n", "update", "=", "exp_avg", "\n", "\n", "", "if", "group", "[", "\"weight_decay\"", "]", "!=", "0", ":", "\n", "                    ", "p_data_fp32", ".", "add_", "(", "p_data_fp32", ",", "alpha", "=", "-", "group", "[", "\"weight_decay\"", "]", "*", "group", "[", "\"lr\"", "]", ")", "\n", "\n", "", "p_data_fp32", ".", "add_", "(", "-", "update", ")", "\n", "\n", "if", "p", ".", "data", ".", "dtype", "in", "{", "torch", ".", "float16", ",", "torch", ".", "bfloat16", "}", ":", "\n", "                    ", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor._get_options": [[199, 205], ["len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_options", "(", "param_group", ",", "param_shape", ")", ":", "\n", "        ", "\"\"\"Returns the options for the current layer.\"\"\"", "\n", "factored", "=", "len", "(", "param_shape", ")", ">=", "2", "\n", "use_first_moment", "=", "param_group", "[", "\"beta1\"", "]", "is", "not", "None", "\n", "return", "factored", ",", "use_first_moment", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor._rms": [[206, 210], ["tensor.norm", "tensor.numel"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.unet_base.unet_block.NormUnet.norm"], ["", "@", "staticmethod", "\n", "def", "_rms", "(", "tensor", ")", ":", "\n", "        ", "\"\"\"Compute the root-mean-square of a tensor.\"\"\"", "\n", "return", "tensor", ".", "norm", "(", "2", ")", "/", "(", "tensor", ".", "numel", "(", ")", "**", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.adafactor.Adafactor._approx_sq_grad": [[211, 220], ["exp_avg_sq_col.unsqueeze().rsqrt", "torch.mul", "exp_avg_sq_col.unsqueeze", "exp_avg_sq_row.mean"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_approx_sq_grad", "(", "exp_avg_sq_row", ",", "exp_avg_sq_col", ")", ":", "\n", "        ", "\"\"\"\n        Compute the square of the gradient, but approximate the sqrt using the exponential moving average of the\n        squared gradient.\n        \"\"\"", "\n", "r_factor", "=", "(", "exp_avg_sq_row", "/", "exp_avg_sq_row", ".", "mean", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", ")", ".", "rsqrt_", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "c_factor", "=", "exp_avg_sq_col", ".", "unsqueeze", "(", "-", "2", ")", ".", "rsqrt", "(", ")", "\n", "return", "torch", ".", "mul", "(", "r_factor", ",", "c_factor", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.parse_optimizer_args": [[38, 113], ["copy.deepcopy", "mridc.utils.model_utils.maybe_update_config_version", "isinstance", "hasattr", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.create", "hydra.utils.instantiate", "vars", "isinstance", "mridc.core.conf.optimizers.get_optimizer_config", "vars", "OmegaConf.to_container.pop", "OmegaConf.to_container.pop", "OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container", "vars"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.maybe_update_config_version", "home.repos.pwc.inspect_result.wdika_mridc.conf.optimizers.get_optimizer_config", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["def", "parse_optimizer_args", "(", "\n", "optimizer_name", ":", "str", ",", "optimizer_kwargs", ":", "Union", "[", "DictConfig", ",", "Dict", "[", "str", ",", "Any", "]", "]", "\n", ")", "->", "Union", "[", "Dict", "[", "str", ",", "Any", "]", ",", "DictConfig", "]", ":", "\n", "    ", "\"\"\"\n    Parses a list of strings, of the format \"key=value\" or \"key2=val1,val2,...\"\n    into a dictionary of type {key=value, key2=[val1, val2], ...}\n    This dictionary is then used to instantiate the chosen Optimizer.\n\n    Parameters\n    ----------\n    optimizer_name: string name of the optimizer, used for auto resolution of params.\n    optimizer_kwargs: Either a list of strings in a specified format, or a dictionary. If a dictionary is provided, it\n    is assumed the dictionary is the final parsed value, and simply returned. If a list of strings is provided, each\n    item in the list is parsed into a new dictionary.\n\n    Returns\n    -------\n    A dictionary of the parsed arguments.\n    \"\"\"", "\n", "kwargs", ":", "Dict", "[", "Any", ",", "Any", "]", "=", "{", "}", "\n", "\n", "if", "optimizer_kwargs", "is", "None", ":", "\n", "        ", "return", "kwargs", "\n", "\n", "", "optimizer_kwargs", "=", "copy", ".", "deepcopy", "(", "optimizer_kwargs", ")", "\n", "optimizer_kwargs", "=", "maybe_update_config_version", "(", "optimizer_kwargs", ")", "\n", "\n", "if", "isinstance", "(", "optimizer_kwargs", ",", "DictConfig", ")", ":", "\n", "        ", "optimizer_kwargs", "=", "OmegaConf", ".", "to_container", "(", "optimizer_kwargs", ",", "resolve", "=", "True", ")", "\n", "\n", "# If it is a dictionary, perform stepwise resolution", "\n", "", "if", "hasattr", "(", "optimizer_kwargs", ",", "\"keys\"", ")", ":", "\n", "# Attempt class path resolution", "\n", "        ", "if", "\"_target_\"", "in", "optimizer_kwargs", ":", "# captures (target, _target_)", "\n", "            ", "optimizer_kwargs_config", "=", "OmegaConf", ".", "create", "(", "optimizer_kwargs", ")", "\n", "optimizer_instance", "=", "hydra", ".", "utils", ".", "instantiate", "(", "optimizer_kwargs_config", ")", "# type: DictConfig", "\n", "optimizer_instance", "=", "vars", "(", "optimizer_instance", ")", "# type: ignore", "\n", "return", "optimizer_instance", "\n", "\n", "# If class path was not provided, perhaps `name` is provided for resolution", "\n", "", "if", "\"name\"", "in", "optimizer_kwargs", ":", "\n", "# If `auto` is passed as name for resolution of optimizer name,", "\n", "# then lookup optimizer name and resolve its parameter config", "\n", "            ", "if", "optimizer_kwargs", "[", "\"name\"", "]", "==", "\"auto\"", ":", "\n", "                ", "optimizer_params_name", "=", "f\"{optimizer_name}_params\"", "\n", "optimizer_kwargs", ".", "pop", "(", "\"name\"", ")", "\n", "", "else", ":", "\n", "                ", "optimizer_params_name", "=", "optimizer_kwargs", ".", "pop", "(", "\"name\"", ")", "\n", "\n", "# Override arguments provided in the config yaml file", "\n", "", "if", "\"params\"", "in", "optimizer_kwargs", ":", "\n", "# If optimizer kwarg overrides are wrapped in yaml `params`", "\n", "                ", "optimizer_params_override", "=", "optimizer_kwargs", ".", "get", "(", "\"params\"", ")", "\n", "", "else", ":", "\n", "# If the kwargs themselves are a DictConfig", "\n", "                ", "optimizer_params_override", "=", "optimizer_kwargs", "\n", "\n", "", "if", "isinstance", "(", "optimizer_params_override", ",", "DictConfig", ")", ":", "\n", "                ", "optimizer_params_override", "=", "OmegaConf", ".", "to_container", "(", "optimizer_params_override", ",", "resolve", "=", "True", ")", "\n", "\n", "", "optimizer_params_cls", "=", "get_optimizer_config", "(", "optimizer_params_name", ",", "**", "optimizer_params_override", ")", "\n", "\n", "# If we are provided just a Config object, simply return the dictionary of that object", "\n", "if", "optimizer_params_name", "is", "None", ":", "\n", "                ", "optimizer_params", "=", "vars", "(", "optimizer_params_cls", ")", "\n", "return", "optimizer_params", "\n", "# If we are provided a partial class instantiation of a Config, instantiate it and retrieve its vars", "\n", "# as a dictionary.", "\n", "", "optimizer_params", "=", "vars", "(", "optimizer_params_cls", ")", "# instantiate the parameters object", "\n", "return", "optimizer_params", "\n", "\n", "# simply return the dictionary that was provided", "\n", "", "return", "optimizer_kwargs", "\n", "\n", "", "return", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.register_optimizer": [[115, 133], ["mridc.core.conf.optimizers.register_optimizer_params", "ValueError"], "function", ["home.repos.pwc.inspect_result.wdika_mridc.conf.optimizers.register_optimizer_params"], ["", "def", "register_optimizer", "(", "name", ":", "str", ",", "optimizer", ":", "Optimizer", ",", "optimizer_params", ":", "OptimizerParams", ")", ":", "\n", "    ", "\"\"\"\n    Checks if the optimizer name exists in the registry, and if it doesn't, adds it.\n    This allows custom optimizers to be added and called by name during instantiation.\n\n    Parameters\n    ----------\n    name: Name of the optimizer. Will be used as key to retrieve the optimizer.\n    optimizer: Optimizer class.\n    optimizer_params: The parameters as a dataclass of the optimizer.\n    \"\"\"", "\n", "if", "name", "in", "AVAILABLE_OPTIMIZERS", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Cannot override pre-existing optimizers. Conflicting optimizer name = {name}\"", ")", "\n", "\n", "", "AVAILABLE_OPTIMIZERS", "[", "name", "]", "=", "optimizer", "\n", "\n", "optim_name", "=", "f\"{optimizer.__name__}_params\"", "\n", "register_optimizer_params", "(", "name", "=", "optim_name", ",", "optimizer_params", "=", "optimizer_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer": [[135, 158], ["functools.partial", "ValueError", "ValueError", "torch.cuda.is_available", "torch.cuda.is_available", "AVAILABLE_OPTIMIZERS.keys"], "function", ["None"], ["", "def", "get_optimizer", "(", "name", ":", "str", ",", "**", "kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "partial", ":", "\n", "    ", "\"\"\"\n    Convenience method to obtain an Optimizer class and partially instantiate it with optimizer kwargs.\n\n    Parameters\n    ----------\n    name: Name of the Optimizer in the registry.\n    kwargs: Optional kwargs of the optimizer used during instantiation.\n\n    Returns\n    -------\n    A partially instantiated Optimizer.\n    \"\"\"", "\n", "if", "name", "not", "in", "AVAILABLE_OPTIMIZERS", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Cannot resolve optimizer '{name}'. Available optimizers are : \"", "f\"{AVAILABLE_OPTIMIZERS.keys()}\"", "\n", ")", "\n", "", "if", "name", "==", "\"fused_adam\"", "and", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"CUDA must be available to use fused_adam.\"", ")", "\n", "\n", "", "optimizer", "=", "AVAILABLE_OPTIMIZERS", "[", "name", "]", "\n", "optimizer", "=", "partial", "(", "optimizer", ",", "**", "kwargs", ")", "\n", "return", "optimizer", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector.__init__": [[27, 31], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_model_config_yaml", "=", "\"model_config.yaml\"", "\n", "self", ".", "_model_weights_ckpt", "=", "\"model_weights.ckpt\"", "\n", "self", ".", "_model_extracted_dir", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector.save_to": [[32, 59], ["mridc.utils.get_rank.is_global_rank_zero", "tempfile.TemporaryDirectory", "os.path.join", "os.path.join", "model.to_config_file", "save_restore_connector.SaveRestoreConnector._save_state_dict_to_disk", "save_restore_connector.SaveRestoreConnector._make_mridc_file_from_folder", "hasattr", "save_restore_connector.SaveRestoreConnector._handle_artifacts", "save_restore_connector.SaveRestoreConnector._update_artifact_paths", "model.state_dict"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.get_rank.is_global_rank_zero", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._save_state_dict_to_disk", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._make_mridc_file_from_folder", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._handle_artifacts", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._update_artifact_paths", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.state_dict"], ["", "def", "save_to", "(", "self", ",", "model", ",", "save_path", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Saves model instance (weights and configuration) into .mridc file.\n        You can use \"restore_from\" method to fully restore instance from .mridc file.\n        .mridc file is an archive (tar.gz) with the following:\n        - model_config.yaml - model configuration in .yaml format. You can deserialize this into cfg argument for \\\n        model's constructor\n        - model_wights.chpt - model checkpoint\n\n        Parameters\n        ----------\n        model: ModelPT object to be saved.\n        save_path: Path to .mridc file where model instance should be saved\n        \"\"\"", "\n", "if", "is_global_rank_zero", "(", ")", ":", "\n", "            ", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "                ", "config_yaml", "=", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "self", ".", "model_config_yaml", ")", "\n", "model_weights", "=", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "self", ".", "model_weights_ckpt", ")", "\n", "model", ".", "to_config_file", "(", "path2yaml_file", "=", "config_yaml", ")", "\n", "if", "hasattr", "(", "model", ",", "\"artifacts\"", ")", "and", "model", ".", "artifacts", "is", "not", "None", ":", "\n", "                    ", "self", ".", "_handle_artifacts", "(", "model", ",", "mridc_file_folder", "=", "tmpdir", ")", "\n", "# We should not update self._cfg here - the model can still be in use", "\n", "self", ".", "_update_artifact_paths", "(", "model", ",", "path2yaml_file", "=", "config_yaml", ")", "\n", "", "self", ".", "_save_state_dict_to_disk", "(", "model", ".", "state_dict", "(", ")", ",", "model_weights", ")", "\n", "self", ".", "_make_mridc_file_from_folder", "(", "filename", "=", "save_path", ",", "source_dir", "=", "tmpdir", ")", "\n", "", "", "else", ":", "\n", "            ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector.load_config_and_state_dict": [[60, 166], ["os.getcwd", "mridc.utils.app_state.AppState", "torch.cuda.is_available", "tempfile.TemporaryDirectory", "torch.device", "torch.device", "os.chdir", "omegaconf.OmegaConf.set_struct", "os.chdir", "calling_cls._set_model_restore_state", "calling_cls.from_config_dict", "instance.to.to.to", "instance.to.to.load_state_dict", "mridc.utils.logging.info", "instance.to.to._set_model_restore_state", "os.chdir", "os.path.isdir", "mridc.utils.logging.info", "save_restore_connector.SaveRestoreConnector._unpack_mridc_file", "os.path.join", "isinstance", "omegaconf.OmegaConf.load", "save_restore_connector.SaveRestoreConnector._inject_model_parallel_rank_for_ckpt", "os.path.join", "save_restore_connector.SaveRestoreConnector._inject_model_parallel_rank_for_ckpt", "save_restore_connector.SaveRestoreConnector._load_state_dict_from_disk", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.create"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._set_model_restore_state", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.load_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._set_model_restore_state", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._unpack_mridc_file", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._inject_model_parallel_rank_for_ckpt", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._inject_model_parallel_rank_for_ckpt", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._load_state_dict_from_disk"], ["", "", "def", "load_config_and_state_dict", "(", "\n", "self", ",", "\n", "calling_cls", ",", "\n", "restore_path", ":", "str", ",", "\n", "override_config_path", ":", "Optional", "[", "Union", "[", "OmegaConf", ",", "str", "]", "]", "=", "None", ",", "\n", "map_location", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", "strict", ":", "bool", "=", "True", ",", "\n", "return_config", ":", "bool", "=", "False", ",", "\n", "trainer", ":", "Trainer", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Restores model instance (weights and configuration) into .mridc file\n\n        Parameters\n        ----------\n        calling_cls: Class of the model to be restored.\n        restore_path: path to .mridc file from which model should be instantiated\n        override_config_path: path to a yaml config that will override the internal config file or an\n        OmegaConf/DictConfig object representing the model config.\n        map_location: Optional torch.device() to map the instantiated model to a device. By default (None), it will\n        select a GPU if available, falling back to CPU otherwise.\n        strict: Passed to load_state_dict. By default, True.\n        return_config: If set to true, will return just the underlying config of the restored model as an OmegaConf\n        DictConfig object without instantiating the model.\n        trainer: Optional trainer object to be used for model parallelism.\n\n        Example\n        -------\n            ```\n            model = mridc.collections.asr.models.EncDecCTCModel.restore_from('asr.mridc')\n            assert isinstance(model, mridc.collections.asr.models.EncDecCTCModel)\n            ```\n\n        Returns\n        -------\n        An instance of type cls or its underlying config (if return_config is set).\n        \"\"\"", "\n", "# Get path where the command is executed - the artifacts will be \"retrieved\" there", "\n", "# (original .mridc behavior)", "\n", "cwd", "=", "os", ".", "getcwd", "(", ")", "\n", "\n", "if", "map_location", "is", "None", ":", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "map_location", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "                ", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "", "", "app_state", "=", "AppState", "(", ")", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "            ", "try", ":", "\n", "# Check if self.model_extracted_dir is set, and is a valid path", "\n", "                ", "if", "self", ".", "model_extracted_dir", "is", "not", "None", "and", "os", ".", "path", ".", "isdir", "(", "self", ".", "model_extracted_dir", ")", ":", "\n", "# Log that MRIDC will use the provided `model_extracted_dir`", "\n", "                    ", "logging", ".", "info", "(", "\n", "\"Restoration will occur within pre-extracted directory : \"", "f\"`{self.model_extracted_dir}`.\"", "\n", ")", "\n", "# Override `tmpdir` above with the pre-extracted `model_extracted_dir`", "\n", "tmpdir", "=", "self", ".", "model_extracted_dir", "\n", "", "else", ":", "\n", "# Extract the nemo file into the temporary directory", "\n", "                    ", "self", ".", "_unpack_mridc_file", "(", "path2file", "=", "restore_path", ",", "out_folder", "=", "tmpdir", ")", "\n", "\n", "# Change current working directory to the temporary directory", "\n", "", "os", ".", "chdir", "(", "tmpdir", ")", "\n", "if", "override_config_path", "is", "None", ":", "\n", "                    ", "config_yaml", "=", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "self", ".", "model_config_yaml", ")", "\n", "", "else", ":", "\n", "# can be str path or OmegaConf / DictConfig object", "\n", "                    ", "config_yaml", "=", "override_config_path", "\n", "", "if", "not", "isinstance", "(", "config_yaml", ",", "(", "OmegaConf", ",", "DictConfig", ")", ")", ":", "\n", "                    ", "conf", "=", "OmegaConf", ".", "load", "(", "config_yaml", ")", "\n", "", "else", ":", "\n", "                    ", "conf", "=", "config_yaml", "\n", "if", "override_config_path", "is", "not", "None", ":", "\n", "# Resolve the override config", "\n", "                        ", "conf", "=", "OmegaConf", ".", "to_container", "(", "conf", ",", "resolve", "=", "True", ")", "\n", "conf", "=", "OmegaConf", ".", "create", "(", "conf", ")", "\n", "# If override is top level config, extract just `model` from it", "\n", "", "", "if", "\"model\"", "in", "conf", ":", "\n", "                    ", "conf", "=", "conf", ".", "model", "\n", "\n", "", "if", "return_config", ":", "\n", "                    ", "instance", "=", "conf", "\n", "return", "instance", "\n", "", "if", "app_state", ".", "model_parallel_rank", "is", "not", "None", "and", "app_state", ".", "model_parallel_size", ">", "1", ":", "\n", "                    ", "model_weights", "=", "self", ".", "_inject_model_parallel_rank_for_ckpt", "(", "tmpdir", ",", "self", ".", "model_weights_ckpt", ")", "\n", "", "else", ":", "\n", "                    ", "model_weights", "=", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "self", ".", "model_weights_ckpt", ")", "\n", "", "OmegaConf", ".", "set_struct", "(", "conf", ",", "True", ")", "\n", "os", ".", "chdir", "(", "cwd", ")", "\n", "# get the class", "\n", "calling_cls", ".", "_set_model_restore_state", "(", "is_being_restored", "=", "True", ",", "folder", "=", "tmpdir", ")", "# type: ignore", "\n", "instance", "=", "calling_cls", ".", "from_config_dict", "(", "config", "=", "conf", ",", "trainer", "=", "trainer", ")", "\n", "instance", "=", "instance", ".", "to", "(", "map_location", ")", "\n", "# add load_state_dict override", "\n", "if", "app_state", ".", "model_parallel_size", "is", "not", "None", "and", "app_state", ".", "model_parallel_size", ">", "1", ":", "\n", "                    ", "model_weights", "=", "self", ".", "_inject_model_parallel_rank_for_ckpt", "(", "tmpdir", ",", "self", ".", "model_weights_ckpt", ")", "\n", "", "instance", ".", "load_state_dict", "(", "\n", "self", ".", "_load_state_dict_from_disk", "(", "model_weights", ",", "map_location", "=", "map_location", ")", ",", "strict", "=", "strict", "\n", ")", "\n", "logging", ".", "info", "(", "f\"Model {instance.__class__.__name__} was successfully restored from {restore_path}.\"", ")", "\n", "instance", ".", "_set_model_restore_state", "(", "is_being_restored", "=", "False", ")", "# type: ignore", "\n", "", "finally", ":", "\n", "                ", "os", ".", "chdir", "(", "cwd", ")", "\n", "\n", "", "", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector.load_instance_with_state_dict": [[167, 172], ["instance.load_state_dict", "instance._set_model_restore_state"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.load_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._set_model_restore_state"], ["", "@", "staticmethod", "\n", "def", "load_instance_with_state_dict", "(", "instance", ",", "state_dict", ",", "strict", ")", ":", "\n", "        ", "\"\"\"Loads the state dict into the instance.\"\"\"", "\n", "instance", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "strict", ")", "\n", "instance", ".", "_set_model_restore_state", "(", "is_being_restored", "=", "False", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector.restore_from": [[173, 221], ["save_restore_connector.SaveRestoreConnector.load_config_and_state_dict", "save_restore_connector.SaveRestoreConnector.load_instance_with_state_dict", "mridc.utils.logging.info", "isinstance"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector.load_config_and_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector.load_instance_with_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info"], ["", "def", "restore_from", "(", "\n", "self", ",", "\n", "calling_cls", ",", "\n", "restore_path", ":", "str", ",", "\n", "override_config_path", ":", "Optional", "[", "Union", "[", "OmegaConf", ",", "str", "]", "]", "=", "None", ",", "\n", "map_location", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", "strict", ":", "bool", "=", "True", ",", "\n", "return_config", ":", "bool", "=", "False", ",", "\n", "trainer", ":", "Trainer", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Restores model instance (weights and configuration) into .mridc file\n\n        Parameters\n        ----------\n        calling_cls: The class of the model to be restored.\n        restore_path: path to .mridc file from which model should be instantiated\n        override_config_path: path to a yaml config that will override the internal config file or an\n        OmegaConf/DictConfig object representing the model config.\n        map_location: Optional torch.device() to map the instantiated model to a device. By default (None), it will\n        select a GPU if available, falling back to CPU otherwise.\n        strict: Passed to load_state_dict. By default, True.\n        return_config: If set to true, will return just the underlying config of the restored model as an\n        OmegaConf/DictConfig object without instantiating the model.\n        trainer: Optional trainer object to be used for restoring the model.\n\n        Returns\n        -------\n        An instance of type cls or its underlying config (if return_config is set).\n        \"\"\"", "\n", "# Get path where the command is executed - the artifacts will be \"retrieved\" there (original .mridc behavior)", "\n", "loaded_params", "=", "self", ".", "load_config_and_state_dict", "(", "\n", "calling_cls", ",", "\n", "restore_path", ",", "\n", "override_config_path", ",", "\n", "map_location", ",", "\n", "strict", ",", "\n", "return_config", ",", "\n", "trainer", ",", "\n", ")", "\n", "\n", "if", "not", "isinstance", "(", "loaded_params", ",", "tuple", ")", ":", "\n", "            ", "return", "loaded_params", "\n", "\n", "", "_", ",", "instance", ",", "state_dict", "=", "loaded_params", "\n", "self", ".", "load_instance_with_state_dict", "(", "instance", ",", "state_dict", ",", "strict", ")", "\n", "logging", ".", "info", "(", "f\"Model {instance.__class__.__name__} was successfully restored from {restore_path}.\"", ")", "\n", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector.extract_state_dict_from": [[222, 290], ["os.getcwd", "os.path.abspath", "os.path.exists", "os.makedirs", "tempfile.TemporaryDirectory", "save_restore_connector.SaveRestoreConnector._unpack_mridc_file", "os.chdir", "os.path.join", "save_restore_connector.SaveRestoreConnector._load_state_dict_from_disk", "mridc.utils.logging.info", "os.chdir", "os.path.join", "save_restore_connector.SaveRestoreConnector._save_state_dict_to_disk", "os.path.join", "save_restore_connector.SaveRestoreConnector._save_state_dict_to_disk", "key.split", "save_restore_connector.SaveRestoreConnector.keys", "save_restore_connector.SaveRestoreConnector.keys", "inner_key.split", "key.split"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._unpack_mridc_file", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._load_state_dict_from_disk", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._save_state_dict_to_disk", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._save_state_dict_to_disk"], ["", "def", "extract_state_dict_from", "(", "self", ",", "restore_path", ":", "str", ",", "save_dir", ":", "str", ",", "split_by_module", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Extract the state dict(s) from a provided .mridc tarfile and save it to a directory.\n\n        Parameters\n        ----------\n        restore_path: path to .mridc file from which state dict(s) should be extracted\n        save_dir: directory in which the saved state dict(s) should be stored\n        split_by_module: bool flag, which determines whether the output checkpoint should be for the entire Model, or\n        the individual module's that comprise the Model.\n\n        Example\n        -------\n        To convert the .mridc tarfile into a single Model level PyTorch checkpoint\n        ::\n        state_dict = mridc.collections.asr.models.EncDecCTCModel.extract_state_dict_from('asr.mridc',\n        './asr_ckpts')\n        To restore a model from a Model level checkpoint\n        ::\n        model = mridc.collections.asr.models.EncDecCTCModel(cfg)  # or any other method of restoration\n        model.load_state_dict(torch.load(\"./asr_ckpts/model_weights.ckpt\"))\n        To convert the .mridc tarfile into multiple Module level PyTorch checkpoints\n        ::\n        state_dict = mridc.collections.asr.models.EncDecCTCModel.extract_state_dict_from('asr.mridc',\n        './asr_ckpts', split_by_module=True). To restore a module from a Module level checkpoint\n        ::\n        model = mridc.collections.asr.models.EncDecCTCModel(cfg)  # or any other method of restoration\n        # load the individual components\n        model.preprocessor.load_state_dict(torch.load(\"./asr_ckpts/preprocessor.ckpt\"))\n        model.encoder.load_state_dict(torch.load(\"./asr_ckpts/encoder.ckpt\"))\n        model.decoder.load_state_dict(torch.load(\"./asr_ckpts/decoder.ckpt\"))\n\n        Returns\n        -------\n        The state dict that was loaded from the original .mridc checkpoint.\n        \"\"\"", "\n", "cwd", "=", "os", ".", "getcwd", "(", ")", "\n", "\n", "save_dir", "=", "os", ".", "path", ".", "abspath", "(", "save_dir", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdir", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "_unpack_mridc_file", "(", "path2file", "=", "restore_path", ",", "out_folder", "=", "tmpdir", ")", "\n", "os", ".", "chdir", "(", "tmpdir", ")", "\n", "model_weights", "=", "os", ".", "path", ".", "join", "(", "tmpdir", ",", "self", ".", "model_weights_ckpt", ")", "\n", "state_dict", "=", "self", ".", "_load_state_dict_from_disk", "(", "model_weights", ")", "\n", "\n", "if", "not", "split_by_module", ":", "\n", "                    ", "filepath", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "self", ".", "model_weights_ckpt", ")", "\n", "self", ".", "_save_state_dict_to_disk", "(", "state_dict", ",", "filepath", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "key_set", "=", "{", "key", ".", "split", "(", "\".\"", ")", "[", "0", "]", "for", "key", "in", "state_dict", ".", "keys", "(", ")", "}", "\n", "for", "primary_key", "in", "key_set", ":", "\n", "                        ", "inner_keys", "=", "[", "key", "for", "key", "in", "state_dict", ".", "keys", "(", ")", "if", "key", ".", "split", "(", "\".\"", ")", "[", "0", "]", "==", "primary_key", "]", "\n", "state_dict_subset", "=", "{", "\n", "\".\"", ".", "join", "(", "inner_key", ".", "split", "(", "\".\"", ")", "[", "1", ":", "]", ")", ":", "state_dict", "[", "inner_key", "]", "for", "inner_key", "in", "inner_keys", "\n", "}", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "f\"{primary_key}.ckpt\"", ")", "\n", "self", ".", "_save_state_dict_to_disk", "(", "state_dict_subset", ",", "filepath", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "f\"Checkpoints from {restore_path} were successfully extracted into {save_dir}.\"", ")", "\n", "", "finally", ":", "\n", "                ", "os", ".", "chdir", "(", "cwd", ")", "\n", "\n", "", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector.register_artifact": [[291, 364], ["mridc.utils.app_state.AppState", "mridc.utils.model_utils.ArtifactItem", "os.path.basename", "os.path.exists", "os.path.abspath", "hasattr", "os.path.abspath", "os.path.abspath", "os.path.abspath", "src.startswith", "os.path.exists", "os.path.join", "os.path.abspath", "os.path.exists", "omegaconf.omegaconf.open_dict", "omegaconf.OmegaConf.update", "os.path.join", "FileNotFoundError", "os.path.abspath"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.update"], ["", "@", "staticmethod", "\n", "def", "register_artifact", "(", "model", ",", "config_path", ":", "str", ",", "src", ":", "str", ",", "verify_src_exists", ":", "bool", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Register model artifacts with this function. These artifacts (files) will be included inside .mridc file\n        when model.save_to(\"mymodel.mridc\") is called.\n\n        How it works:\n        1. It always returns existing absolute path which can be used during Model constructor call. EXCEPTION: src is\n        None or \"\" in which case nothing will be done and src will be returned\n        2. It will add (config_path, model_utils.ArtifactItem()) pair to self.artifacts. If \"src\" is local existing\n        path, then it will be returned in absolute path form. elif \"src\" starts with \"mridc_file:unique_artifact_name\":\n        .mridc will be untarred to a temporary folder location and an actual existing path will be returned else an\n        error will be raised.\n\n        WARNING: use .register_artifact calls in your models' constructors.\n        The returned path is not guaranteed to exist after you have exited your model's constructor.\n\n        Parameters\n        ----------\n        model: ModelPT object to register artifact for.\n        config_path: Artifact key. Usually corresponds to the model config.\n        src: Path to artifact.\n        verify_src_exists: If set to False, then the artifact is optional and register_artifact will return None\n         even if src is not found. Defaults to True.\n\n        Returns\n        --------\n        If src is not None or empty it always returns absolute path which is guaranteed to exist during model instance\n         life.\n        \"\"\"", "\n", "app_state", "=", "AppState", "(", ")", "\n", "\n", "artifact_item", "=", "mridc", ".", "utils", ".", "model_utils", ".", "ArtifactItem", "(", ")", "# type: ignore", "\n", "\n", "# This is for backward compatibility, if the src objects exists simply inside the tarfile", "\n", "# without its key having been overridden, this pathway will be used.", "\n", "src_obj_name", "=", "os", ".", "path", ".", "basename", "(", "src", ")", "\n", "if", "app_state", ".", "mridc_file_folder", "is", "not", "None", ":", "\n", "            ", "src_obj_path", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "app_state", ".", "mridc_file_folder", ",", "src_obj_name", ")", ")", "\n", "", "else", ":", "\n", "            ", "src_obj_path", "=", "src_obj_name", "\n", "\n", "# src is a local existing path - register artifact and return exact same path for usage by the model", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "abspath", "(", "src", ")", ")", ":", "\n", "            ", "return_path", "=", "os", ".", "path", ".", "abspath", "(", "src", ")", "\n", "artifact_item", ".", "path_type", "=", "mridc", ".", "utils", ".", "model_utils", ".", "ArtifactPathType", ".", "LOCAL_PATH", "# type: ignore", "\n", "\n", "", "elif", "src", ".", "startswith", "(", "\"mridc:\"", ")", ":", "\n", "            ", "return_path", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "app_state", ".", "mridc_file_folder", ",", "src", "[", "5", ":", "]", ")", ")", "\n", "artifact_item", ".", "path_type", "=", "mridc", ".", "utils", ".", "model_utils", ".", "ArtifactPathType", ".", "TAR_PATH", "# type: ignore", "\n", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "src_obj_path", ")", ":", "\n", "            ", "return_path", "=", "src_obj_path", "\n", "artifact_item", ".", "path_type", "=", "mridc", ".", "utils", ".", "model_utils", ".", "ArtifactPathType", ".", "TAR_PATH", "# type: ignore", "\n", "", "elif", "verify_src_exists", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "\n", "f\"src path does not exist or it is not a path in mridc file. src value I got was: {src}. \"", "\n", "f\"Absolute: {os.path.abspath(src)}\"", "\n", ")", "\n", "", "else", ":", "\n", "# artifact is optional and we simply return None", "\n", "            ", "return", "None", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "return_path", ")", ":", "\n", "            ", "raise", "AssertionError", "\n", "\n", "", "artifact_item", ".", "path", "=", "os", ".", "path", ".", "abspath", "(", "src", ")", "\n", "model", ".", "artifacts", "[", "config_path", "]", "=", "artifact_item", "\n", "# we were called by ModelPT", "\n", "if", "hasattr", "(", "model", ",", "\"cfg\"", ")", ":", "\n", "            ", "with", "open_dict", "(", "model", ".", "_cfg", ")", ":", "\n", "                ", "OmegaConf", ".", "update", "(", "model", ".", "cfg", ",", "config_path", ",", "return_path", ")", "\n", "", "", "return", "return_path", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._handle_artifacts": [[365, 430], ["mridc.utils.app_state.AppState", "model.artifacts.items", "mridc.utils.app_state.AppState.get_model_metadata_from_guid", "os.getcwd", "os.path.basename", "shutil.copy2", "os.chdir", "os.path.exists", "FileNotFoundError", "os.path.join", "tarfile_artifacts.append", "ValueError", "tempfile.TemporaryDirectory", "save_restore_connector.SaveRestoreConnector._unpack_mridc_file", "os.chdir", "shutil.copy2", "mridc.utils.model_utils.ArtifactItem", "uuid.uuid4", "os.path.basename", "os.path.join", "artiitem.path.split"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.get_model_metadata_from_guid", "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._unpack_mridc_file"], ["", "def", "_handle_artifacts", "(", "self", ",", "model", ",", "mridc_file_folder", ")", ":", "\n", "        ", "\"\"\"\n        This method is called by ModelPT.save_to() and ModelPT.load_from(). It will handle all artifacts and save them\n        to the mridc file.\n\n        Parameters\n        ----------\n        model: ModelPT object to register artifact for.\n        mridc_file_folder: Path to the mridc file.\n        \"\"\"", "\n", "tarfile_artifacts", "=", "[", "]", "\n", "app_state", "=", "AppState", "(", ")", "\n", "for", "conf_path", ",", "artiitem", "in", "model", ".", "artifacts", ".", "items", "(", ")", ":", "\n", "            ", "if", "artiitem", ".", "path_type", "==", "mridc", ".", "utils", ".", "model_utils", ".", "ArtifactPathType", ".", "LOCAL_PATH", ":", "\n", "                ", "if", "not", "os", ".", "path", ".", "exists", "(", "artiitem", ".", "path", ")", ":", "\n", "                    ", "raise", "FileNotFoundError", "(", "f\"Artifact {conf_path} not found at location: {artiitem.path}\"", ")", "\n", "\n", "# Generate new uniq artifact name and copy it to mridc_file_folder", "\n", "# Note uuid.uuid4().hex is guaranteed to be 32 character long", "\n", "", "artifact_base_name", "=", "os", ".", "path", ".", "basename", "(", "artiitem", ".", "path", ")", "\n", "artifact_uniq_name", "=", "f\"{uuid.uuid4().hex}_{artifact_base_name}\"", "\n", "shutil", ".", "copy2", "(", "artiitem", ".", "path", ",", "os", ".", "path", ".", "join", "(", "mridc_file_folder", ",", "artifact_uniq_name", ")", ")", "\n", "\n", "# Update artifacts registry", "\n", "artiitem", ".", "hashed_path", "=", "f\"mridc:{artifact_uniq_name}\"", "\n", "model", ".", "artifacts", "[", "conf_path", "]", "=", "artiitem", "\n", "\n", "", "elif", "artiitem", ".", "path_type", "==", "mridc", ".", "utils", ".", "model_utils", ".", "ArtifactPathType", ".", "TAR_PATH", ":", "\n", "# process all tarfile artifacts in one go, so preserve key-value pair", "\n", "                ", "tarfile_artifacts", ".", "append", "(", "(", "conf_path", ",", "artiitem", ")", ")", "\n", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Directly referencing artifacts from other mridc files isn't supported yet\"", ")", "\n", "\n", "# Process current tarfile artifacts by unpacking the previous tarfile and extract the artifacts", "\n", "# that are currently required.", "\n", "", "", "model_metadata", "=", "app_state", ".", "get_model_metadata_from_guid", "(", "model", ".", "model_guid", ")", "\n", "if", "tarfile_artifacts", "and", "model_metadata", ".", "restoration_path", "is", "not", "None", ":", "\n", "# Need to step into mridc archive to extract file", "\n", "# Get path where the command is executed - the artifacts will be \"retrieved\" there", "\n", "# (original .mridc behavior)", "\n", "            ", "cwd", "=", "os", ".", "getcwd", "(", ")", "\n", "try", ":", "\n", "# Step into the mridc archive to try and find the file", "\n", "                ", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "archive_dir", ":", "\n", "                    ", "self", ".", "_unpack_mridc_file", "(", "path2file", "=", "model_metadata", ".", "restoration_path", ",", "out_folder", "=", "archive_dir", ")", "\n", "os", ".", "chdir", "(", "archive_dir", ")", "\n", "for", "conf_path", ",", "artiitem", "in", "tarfile_artifacts", ":", "\n", "# Get basename and copy it to mridc_file_folder", "\n", "                        ", "if", "\"mridc:\"", "in", "artiitem", ".", "path", ":", "\n", "                            ", "artifact_base_name", "=", "artiitem", ".", "path", ".", "split", "(", "\"mridc:\"", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "                            ", "artifact_base_name", "=", "os", ".", "path", ".", "basename", "(", "artiitem", ".", "path", ")", "\n", "# no need to hash here as we are in tarfile_artifacts which are already hashed", "\n", "", "artifact_uniq_name", "=", "artifact_base_name", "\n", "shutil", ".", "copy2", "(", "artifact_base_name", ",", "os", ".", "path", ".", "join", "(", "mridc_file_folder", ",", "artifact_uniq_name", ")", ")", "\n", "\n", "# Update artifacts registry", "\n", "new_artiitem", "=", "mridc", ".", "utils", ".", "model_utils", ".", "ArtifactItem", "(", ")", "\n", "new_artiitem", ".", "path", "=", "f\"mridc:{artifact_uniq_name}\"", "\n", "new_artiitem", ".", "path_type", "=", "mridc", ".", "utils", ".", "model_utils", ".", "ArtifactPathType", ".", "TAR_PATH", "\n", "model", ".", "artifacts", "[", "conf_path", "]", "=", "new_artiitem", "\n", "", "", "", "finally", ":", "\n", "# change back working directory", "\n", "                ", "os", ".", "chdir", "(", "cwd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._update_artifact_paths": [[431, 446], ["omegaconf.OmegaConf.load", "model.artifacts.items", "len", "open", "omegaconf.OmegaConf.save", "omegaconf.OmegaConf.update", "omegaconf.OmegaConf.update"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.update", "home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.update"], ["", "", "", "@", "staticmethod", "\n", "def", "_update_artifact_paths", "(", "model", ",", "path2yaml_file", ")", ":", "\n", "        ", "\"\"\"\n        This method is called by ModelPT.save_to() and ModelPT.load_from() to update the artifact paths in the\n        model.\n        \"\"\"", "\n", "if", "model", ".", "artifacts", "is", "not", "None", "and", "len", "(", "model", ".", "artifacts", ")", ">", "0", ":", "\n", "            ", "conf", "=", "OmegaConf", ".", "load", "(", "path2yaml_file", ")", "\n", "for", "conf_path", ",", "item", "in", "model", ".", "artifacts", ".", "items", "(", ")", ":", "\n", "                ", "if", "item", ".", "hashed_path", "is", "None", ":", "\n", "                    ", "OmegaConf", ".", "update", "(", "conf", ",", "conf_path", ",", "item", ".", "path", ")", "\n", "", "else", ":", "\n", "                    ", "OmegaConf", ".", "update", "(", "conf", ",", "conf_path", ",", "item", ".", "hashed_path", ")", "\n", "", "", "with", "open", "(", "path2yaml_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fout", ":", "\n", "                ", "OmegaConf", ".", "save", "(", "config", "=", "conf", ",", "f", "=", "fout", ",", "resolve", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._inject_model_parallel_rank_for_ckpt": [[447, 456], ["os.path.join", "mridc.utils.model_utils.inject_model_parallel_rank"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.inject_model_parallel_rank"], ["", "", "", "@", "staticmethod", "\n", "def", "_inject_model_parallel_rank_for_ckpt", "(", "dirname", ",", "basename", ")", ":", "\n", "        ", "\"\"\"\n        This method is called by ModelPT.save_to() and ModelPT.load_from() to inject the parallel rank of the process\n        into the checkpoint file name.\n        \"\"\"", "\n", "model_weights", "=", "os", ".", "path", ".", "join", "(", "dirname", ",", "basename", ")", "\n", "model_weights", "=", "mridc", ".", "utils", ".", "model_utils", ".", "inject_model_parallel_rank", "(", "model_weights", ")", "\n", "return", "model_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._make_mridc_file_from_folder": [[457, 464], ["os.path.dirname", "os.makedirs", "tarfile.open", "tar.add"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_make_mridc_file_from_folder", "(", "filename", ",", "source_dir", ")", ":", "\n", "        ", "\"\"\"This method is called by ModelPT.save_to() and ModelPT.load_from() to create a mridc file from a folder.\"\"\"", "\n", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "filename", ")", "\n", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "with", "tarfile", ".", "open", "(", "filename", ",", "\"w\"", ")", "as", "tar", ":", "\n", "            ", "tar", ".", "add", "(", "source_dir", ",", "arcname", "=", "\".\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._unpack_mridc_file": [[465, 482], ["tarfile.open", "tarfile.open.extractall", "tarfile.open.close", "os.path.exists", "FileNotFoundError", "tarfile.open", "tarfile.open.close"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_unpack_mridc_file", "(", "path2file", ":", "str", ",", "out_folder", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"This method is called by ModelPT.save_to() and ModelPT.load_from() to unpack a mridc file.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path2file", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"{path2file} does not exist\"", ")", "\n", "# we start with an assumption of uncompressed tar, which should be true for versions 1.7.0 and above", "\n", "", "tar_header", "=", "\"r:\"", "\n", "try", ":", "\n", "            ", "tar_test", "=", "tarfile", ".", "open", "(", "path2file", ",", "tar_header", ")", "\n", "tar_test", ".", "close", "(", ")", "\n", "", "except", "tarfile", ".", "ReadError", ":", "\n", "# can be older checkpoint => try compressed tar", "\n", "            ", "tar_header", "=", "\"r:gz\"", "\n", "", "tar", "=", "tarfile", ".", "open", "(", "path2file", ",", "tar_header", ")", "\n", "tar", ".", "extractall", "(", "path", "=", "out_folder", ")", "\n", "tar", ".", "close", "(", ")", "\n", "return", "out_folder", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._save_state_dict_to_disk": [[483, 487], ["torch.save"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_save_state_dict_to_disk", "(", "state_dict", ",", "filepath", ")", ":", "\n", "        ", "\"\"\"This method is called by ModelPT.save_to() and ModelPT.load_from() to save the state dict to disk.\"\"\"", "\n", "torch", ".", "save", "(", "state_dict", ",", "filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector._load_state_dict_from_disk": [[488, 492], ["torch.load"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_load_state_dict_from_disk", "(", "model_weights", ",", "map_location", "=", "None", ")", ":", "\n", "        ", "\"\"\"This method is called by ModelPT.save_to() and ModelPT.load_from() to load the state dict from disk.\"\"\"", "\n", "return", "torch", ".", "load", "(", "model_weights", ",", "map_location", "=", "map_location", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector.model_config_yaml": [[498, 502], ["None"], "methods", ["None"], ["", "@", "model_config_yaml", ".", "setter", "\n", "def", "model_config_yaml", "(", "self", ",", "path", ":", "str", ")", ":", "\n", "        ", "\"\"\"This property is used to set the path to the model config yaml file.\"\"\"", "\n", "self", ".", "_model_config_yaml", "=", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector.model_weights_ckpt": [[508, 512], ["None"], "methods", ["None"], ["", "@", "model_weights_ckpt", ".", "setter", "\n", "def", "model_weights_ckpt", "(", "self", ",", "path", ":", "str", ")", ":", "\n", "        ", "\"\"\"This property is used to set the path to the model weights ckpt file.\"\"\"", "\n", "self", ".", "_model_weights_ckpt", "=", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.connectors.save_restore_connector.SaveRestoreConnector.model_extracted_dir": [[517, 520], ["None"], "methods", ["None"], ["", "@", "model_extracted_dir", ".", "setter", "\n", "def", "model_extracted_dir", "(", "self", ",", "path", ":", "None", ")", ":", "\n", "        ", "self", ".", "_model_extracted_dir", "=", "path", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.__init__": [[37, 148], ["pytorch_lightning.LightningModule.__init__", "mridc.utils.app_state.AppState", "mridc.utils.app_state.AppState", "mridc.utils.model_utils.convert_model_config_to_dict_config", "mridc.utils.model_utils.convert_model_config_to_dict_config", "mridc.utils.model_utils.convert_model_config_to_dict_config", "mridc.utils.model_utils.convert_model_config_to_dict_config", "mridc.utils.model_utils.maybe_update_config_version", "mridc.utils.model_utils.maybe_update_config_version", "mridc.utils.model_utils.maybe_update_config_version", "mridc.utils.model_utils.maybe_update_config_version", "modelPT.ModelPT.save_hyperparameters", "mridc.core.connectors.save_restore_connector.SaveRestoreConnector", "mridc.core.connectors.save_restore_connector.SaveRestoreConnector", "modelPT.ModelPT._set_model_guid", "mridc.utils.model_utils.wrap_training_step", "mridc.utils.model_utils.wrap_training_step", "mridc.utils.model_utils.wrap_training_step", "mridc.utils.model_utils.wrap_training_step", "ValueError", "ValueError", "omegaconf.OmegaConf.set_struct", "omegaconf.OmegaConf.set_struct", "torch.cuda.is_available", "torch.cuda.current_device", "isinstance", "omegaconf.open_dict", "torch.cuda.current_device", "modelPT.ModelPT._is_model_being_restored", "modelPT.ModelPT.setup_training_data", "modelPT.ModelPT.setup_multiple_validation_data", "modelPT.ModelPT.setup_multiple_test_data", "mridc.utils.logging.warning", "mridc.utils.logging.warning", "mridc.utils.logging.warning", "mridc.utils.logging.warning", "mridc.utils.logging.warning", "mridc.utils.logging.warning", "type", "omegaconf.OmegaConf.to_yaml", "omegaconf.OmegaConf.to_yaml", "omegaconf.OmegaConf.to_yaml"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.convert_model_config_to_dict_config", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.convert_model_config_to_dict_config", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.convert_model_config_to_dict_config", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.convert_model_config_to_dict_config", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.maybe_update_config_version", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.maybe_update_config_version", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.maybe_update_config_version", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.maybe_update_config_version", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._set_model_guid", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.wrap_training_step", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.wrap_training_step", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.wrap_training_step", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.wrap_training_step", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._is_model_being_restored", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_training_data", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_multiple_validation_data", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_multiple_test_data", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning"], ["def", "__init__", "(", "self", ",", "cfg", ":", "DictConfig", ",", "trainer", ":", "Trainer", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Base class from which all mridc models should inherit\n\n        Internal global flags that determine core functionality of ModelPT.\n        _MODEL_IS_RESTORED:\n            This flag determines the context of the model - whether the model is currently being\n            restored or not.\n            -   When set, it can be assumed that the model's will disable all automatic methods -\n                setup_training_data(), setup_validation/test_data() and their multi equivalents.\n            -   If a model is being restored from a archive file (tarfile), it can be assumed that\n                under this context, the cwd is *inside* the tarfile itself.\n        _MODEL_RESTORE_PATH:\n            A string path to a a file from which the model is being restored.\n            This file can either be a PyTorch Lightning Checkpoint, or a archive (tarfile) that contains\n            artifact objects.\n            If it is an archive file, during restoration, the cwd will be temporarily moved to inside the\n            archive itself.\n\n        Parameters\n        ----------\n        cfg: configuration object. The cfg object should have (optionally) the following sub-configs:\n            - train_ds - to instantiate training dataset\n            - validation_ds - to instantiate validation dataset\n            - test_ds - to instantiate testing dataset\n            - optim - to instantiate optimizer with learning rate scheduler\n        trainer: Pytorch Lightning Trainer instance\n        \"\"\"", "\n", "if", "trainer", "is", "not", "None", "and", "not", "isinstance", "(", "trainer", ",", "Trainer", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"trainer constructor argument must be either None or pytorch_lightning.Trainer. \"", "\n", "f\"But got {type(trainer)} instead.\"", "\n", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# set global vars in AppState", "\n", "app_state", "=", "AppState", "(", ")", "\n", "\n", "# Convert config to a DictConfig", "\n", "cfg", "=", "mridc", ".", "utils", ".", "model_utils", ".", "convert_model_config_to_dict_config", "(", "cfg", ")", "\n", "\n", "# Convert config to support Hydra 1.0+ instantiation", "\n", "cfg", "=", "mridc", ".", "utils", ".", "model_utils", ".", "maybe_update_config_version", "(", "cfg", ")", "\n", "\n", "if", "\"model\"", "in", "cfg", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Creating model config node is forbidden due to collision problem when loading from checkpoint.\"", "\n", ")", "\n", "\n", "", "if", "\"target\"", "not", "in", "cfg", ":", "\n", "# This is for Jarvis service.", "\n", "            ", "OmegaConf", ".", "set_struct", "(", "cfg", ",", "False", ")", "\n", "cfg", ".", "target", "=", "\"{0}.{1}\"", ".", "format", "(", "self", ".", "__class__", ".", "__module__", ",", "self", ".", "__class__", ".", "__name__", ")", "\n", "OmegaConf", ".", "set_struct", "(", "cfg", ",", "True", ")", "\n", "\n", "", "if", "\"mridc_version\"", "not", "in", "cfg", ":", "\n", "            ", "with", "open_dict", "(", "cfg", ")", ":", "\n", "                ", "cfg", ".", "mridc_version", "=", "package_info", ".", "__version__", "\n", "\n", "", "", "self", ".", "_cfg", "=", "cfg", "\n", "\n", "self", ".", "save_hyperparameters", "(", "\"cfg\"", ")", "\n", "self", ".", "_train_dl", "=", "None", "\n", "self", ".", "_validation_dl", "=", "None", "\n", "self", ".", "_test_dl", "=", "None", "\n", "self", ".", "_optimizer_param_groups", "=", "None", "\n", "self", ".", "_optimizer", "=", "None", "\n", "self", ".", "_scheduler", "=", "None", "\n", "self", ".", "trainer", "=", "trainer", "# reference required for self.*_rank", "\n", "self", ".", "_trainer", "=", "self", ".", "trainer", "# alias for backward compatibility", "\n", "self", ".", "_save_restore_connector", "=", "SaveRestoreConnector", "(", ")", "\n", "\n", "self", ".", "_set_model_guid", "(", ")", "\n", "\n", "# Set device_id in AppState", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "torch", ".", "cuda", ".", "current_device", "(", ")", "is", "not", "None", ":", "\n", "            ", "app_state", ".", "device_id", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "\n", "", "if", "self", ".", "_cfg", "is", "not", "None", "and", "not", "self", ".", "_is_model_being_restored", "(", ")", ":", "\n", "            ", "if", "\"train_ds\"", "in", "self", ".", "_cfg", "and", "self", ".", "_cfg", ".", "train_ds", "is", "not", "None", ":", "\n", "                ", "self", ".", "setup_training_data", "(", "self", ".", "_cfg", ".", "train_ds", ")", "\n", "\n", "", "if", "\"validation_ds\"", "in", "self", ".", "_cfg", "and", "self", ".", "_cfg", ".", "validation_ds", "is", "not", "None", ":", "\n", "                ", "self", ".", "setup_multiple_validation_data", "(", "self", ".", "_cfg", ".", "validation_ds", ")", "# type: ignore", "\n", "\n", "", "if", "\"test_ds\"", "in", "self", ".", "_cfg", "and", "self", ".", "_cfg", ".", "test_ds", "is", "not", "None", ":", "\n", "                ", "self", ".", "setup_multiple_test_data", "(", "test_data_config", "=", "None", ")", "# type: ignore", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "\"train_ds\"", "in", "self", ".", "_cfg", "and", "self", ".", "_cfg", ".", "train_ds", "is", "not", "None", ":", "# type: ignore", "\n", "                ", "logging", ".", "warning", "(", "\n", "\"If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() \"", "\n", "\"method and provide a valid configuration file to setup the train data loader.\\n\"", "\n", "f\"Train config : \\n{OmegaConf.to_yaml(self._cfg.train_ds)}\"", "# type: ignore", "\n", ")", "\n", "", "if", "\"validation_ds\"", "in", "self", ".", "_cfg", "and", "self", ".", "_cfg", ".", "validation_ds", "is", "not", "None", ":", "# type: ignore", "\n", "                ", "logging", ".", "warning", "(", "\n", "\"If you intend to do validation, please call the ModelPT.setup_validation_data() or \"", "\n", "\"ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to \"", "\n", "\"setup the validation data loader(s). \\n\"", "\n", "f\"Validation config : \\n{OmegaConf.to_yaml(self._cfg.validation_ds)}\"", "# type: ignore", "\n", ")", "\n", "", "if", "\"test_ds\"", "in", "self", ".", "_cfg", "and", "self", ".", "_cfg", ".", "test_ds", "is", "not", "None", ":", "# type: ignore", "\n", "                ", "logging", ".", "warning", "(", "\n", "\"Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method \"", "\n", "\"and provide a valid configuration file to setup the test data loader(s).\\n\"", "\n", "f\"Test config : \\n{OmegaConf.to_yaml(self._cfg.test_ds)}\"", "# type: ignore", "\n", ")", "\n", "\n", "# ModelPT wrappers over subclass implementations", "\n", "", "", "self", ".", "_training_step", "=", "mridc", ".", "utils", ".", "model_utils", ".", "wrap_training_step", "(", "self", ".", "training_step", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.__init_subclass__": [[149, 152], ["mridc.core.connectors.save_restore_connector.SaveRestoreConnector", "mridc.core.connectors.save_restore_connector.SaveRestoreConnector"], "methods", ["None"], ["", "def", "__init_subclass__", "(", "cls", ")", "->", "None", ":", "\n", "        ", "\"\"\"This method is called when a subclass is created.\"\"\"", "\n", "cls", ".", "_save_restore_connector", "=", "SaveRestoreConnector", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.register_artifact": [[153, 198], ["modelPT.ModelPT._save_restore_connector.register_artifact", "hasattr", "mridc.utils.logging.warning", "mridc.utils.logging.warning"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.register_artifact", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning"], ["", "def", "register_artifact", "(", "self", ",", "config_path", ":", "str", ",", "src", ":", "str", ",", "verify_src_exists", ":", "bool", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Register model artifacts with this function. These artifacts (files) will be included inside .mridc file when\n        model.save_to(\"model.mridc\") is called.\n\n        How it works:\n            1. It always returns existing absolute path which can be used during Model constructor call EXCEPTION: \\\n            src is None or \"\" in which case nothing will be done and src will be returned\n            2. It will add (config_path, model_utils.ArtifactItem()) pair to self.artifacts\n\n        If \"src\" is local existing path, then it will be returned in absolute path form.\n        elif \"src\" starts with \"mridc_file:unique_artifact_name\" .mridc will be untarred to a temporary folder \\\n        location and an actual existing path will be returned else an error will be raised.\n\n        WARNING: use .register_artifact calls in your models' constructors.\n        The returned path is not guaranteed to exist after you have exited your model's constructor.\n\n        Parameters\n        ----------\n        config_path: Artifact key. Usually corresponds to the model config.\n        src: Path to artifact.\n        verify_src_exists: If set to False, then the artifact is optional and register_artifact will return None \\\n        even if src is not found. Defaults to True.\n\n        Returns\n        -------\n        If src is not None or empty it always returns absolute path which is guaranteed to exist during model \\\n        instance life.\n        \"\"\"", "\n", "if", "src", "is", "None", "or", "not", "src", ":", "\n", "            ", "return", "src", "\n", "\n", "", "if", "not", "hasattr", "(", "self", ",", "\"artifacts\"", ")", ":", "\n", "            ", "self", ".", "artifacts", ":", "Dict", "[", "str", ",", "mridc", ".", "utils", ".", "model_utils", ".", "ArtifactItem", "]", "=", "{", "}", "\n", "\n", "", "if", "self", ".", "artifacts", "is", "None", ":", "\n", "            ", "self", ".", "artifacts", "=", "{", "}", "\n", "\n", "", "if", "config_path", "in", "self", ".", "artifacts", ":", "\n", "            ", "logging", ".", "warning", "(", "\n", "f\"You tried to register an artifact under config key={config_path} but an artifact for \"", "\n", "\"it has already been registered.\"", "\n", ")", "\n", "\n", "", "return", "self", ".", "_save_restore_connector", ".", "register_artifact", "(", "self", ",", "config_path", ",", "src", ",", "verify_src_exists", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.save_to": [[199, 232], ["pathlib.Path().expanduser().resolve", "mridc.utils.app_state.AppState", "mridc.utils.app_state.AppState", "modelPT.ModelPT._save_restore_connector.save_to", "mridc.utils.get_rank.is_global_rank_zero", "mridc.utils.get_rank.is_global_rank_zero", "_path.parent.exists", "_path.parent.mkdir", "pathlib.Path().expanduser", "ValueError", "modelPT.ModelPT.save_to.maybe_make_save_dir"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.save_to", "home.repos.pwc.inspect_result.wdika_mridc.utils.get_rank.is_global_rank_zero", "home.repos.pwc.inspect_result.wdika_mridc.utils.get_rank.is_global_rank_zero"], ["", "def", "save_to", "(", "self", ",", "save_path", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Saves model instance (weights and configuration) into .mridc file. You can use \"restore_from\" method to fully\n        restore instance from .mridc file. .mridc file is an archive (tar.gz) with the following:\n        - model_config.yaml - model configuration in .yaml format. You can deserialize this into cfg argument for \\\n         model's constructor\n        - model_wights.ckpt - model checkpoint\n\n        Parameters\n        ----------\n        Path to .mridc file where model instance should be saved.\n        \"\"\"", "\n", "\n", "def", "maybe_make_save_dir", "(", "_path", ":", "\"Path\"", ")", ":", "\n", "            ", "\"\"\"Creates directory if it does not exist\"\"\"", "\n", "if", "not", "_path", ".", "parent", ".", "exists", "(", ")", ":", "\n", "                ", "_path", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ")", "\n", "\n", "", "", "save_path", "=", "Path", "(", "save_path", ")", ".", "expanduser", "(", ")", ".", "resolve", "(", ")", "# type: ignore", "\n", "app_state", "=", "AppState", "(", ")", "\n", "if", "app_state", ".", "model_parallel_size", "is", "not", "None", ":", "\n", "            ", "if", "app_state", ".", "model_parallel_size", ">", "1", "and", "type", "(", "self", ".", "_save_restore_connector", ")", "is", "SaveRestoreConnector", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Default mridc SaveRestoreConnector will not work in model parallel mode. You should use a \"", "\n", "\"connector which supports model parallel mode. You can also use a custom one.\"", "\n", ")", "\n", "", "if", "app_state", ".", "data_parallel_rank", "==", "0", ":", "\n", "                ", "maybe_make_save_dir", "(", "Path", "(", "save_path", ")", ")", "\n", "# connector checks for ranks properly, no need to check here", "\n", "", "self", ".", "_save_restore_connector", ".", "save_to", "(", "self", ",", "str", "(", "save_path", ")", ")", "# downstream tasks expect str, not Path", "\n", "", "elif", "is_global_rank_zero", "(", ")", ":", "\n", "            ", "maybe_make_save_dir", "(", "Path", "(", "save_path", ")", ")", "\n", "self", ".", "_save_restore_connector", ".", "save_to", "(", "self", ",", "str", "(", "save_path", ")", ")", "# downstream tasks expect str, not Path", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.restore_from": [[233, 295], ["mridc.utils.app_state.AppState", "mridc.utils.app_state.AppState", "cls.update_save_restore_connector", "cls._save_restore_connector.restore_from", "isinstance", "mridc.core.connectors.save_restore_connector.SaveRestoreConnector", "mridc.core.connectors.save_restore_connector.SaveRestoreConnector", "os.path.abspath", "os.path.abspath", "os.path.exists", "FileNotFoundError", "os.path.expanduser", "os.path.expanduser"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.update_save_restore_connector", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.restore_from"], ["", "", "@", "classmethod", "\n", "def", "restore_from", "(", "# type: ignore", "\n", "cls", ",", "\n", "restore_path", ":", "str", ",", "\n", "override_config_path", ":", "Optional", "[", "Union", "[", "OmegaConf", ",", "str", "]", "]", "=", "None", ",", "\n", "map_location", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ",", "\n", "strict", ":", "bool", "=", "True", ",", "\n", "return_config", ":", "bool", "=", "False", ",", "\n", "save_restore_connector", ":", "SaveRestoreConnector", "=", "None", ",", "\n", "trainer", ":", "Optional", "[", "Trainer", "]", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Restores model instance (weights and configuration) from .mridc file.\n\n        Parameters\n        ----------\n        restore_path: path to .mridc file from which model should be instantiated override_config_path: path to a \\\n        yaml config that will override the internal config file or an OmegaConf/DictConfig object representing the \\\n        model config.\n        map_location: Optional torch.device() to map the instantiated model to a device. By default (None), it will \\\n        select a GPU if available, falling back to CPU otherwise.\n        strict: Passed to load_state_dict. By default, True.\n        return_config: If set to true, will return just the underlying config of the restored model as an \\\n        OmegaConf/DictConfig object without instantiating the model.\n        trainer: Optional, a pytorch lightning Trainer object that will be forwarded to the instantiated model's \\\n        constructor.\n        save_restore_connector: Can be overridden to add custom save and restore logic.\n\n        Example\n        -------\n\n        .. code-block::\n\n            model = mridc.collections.asr.models.EncDecCTCModel.restore_from('asr.mridc')\n            assert isinstance(model, mridc.collections.asr.models.EncDecCTCModel)\n\n\n        Returns\n        -------\n        An instance of type cls or its underlying config (if return_config is set).\n        \"\"\"", "\n", "if", "save_restore_connector", "is", "None", ":", "\n", "            ", "save_restore_connector", "=", "SaveRestoreConnector", "(", ")", "\n", "\n", "", "if", "save_restore_connector", ".", "model_extracted_dir", "is", "None", ":", "\n", "            ", "restore_path", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "expanduser", "(", "restore_path", ")", ")", "\n", "", "else", ":", "\n", "            ", "restore_path", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "expanduser", "(", "save_restore_connector", ".", "model_extracted_dir", ")", ")", "\n", "\n", "", "if", "not", "path", ".", "exists", "(", "restore_path", ")", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "f\"Can't find {restore_path}\"", ")", "\n", "\n", "", "app_state", "=", "AppState", "(", ")", "\n", "app_state", ".", "model_restore_path", "=", "restore_path", "\n", "\n", "cls", ".", "update_save_restore_connector", "(", "save_restore_connector", ")", "\n", "instance", "=", "cls", ".", "_save_restore_connector", ".", "restore_from", "(", "\n", "cls", ",", "restore_path", ",", "override_config_path", ",", "map_location", ",", "strict", ",", "return_config", ",", "trainer", "\n", ")", "\n", "if", "isinstance", "(", "instance", ",", "ModelPT", ")", ":", "\n", "            ", "instance", ".", "_save_restore_connector", "=", "save_restore_connector", "\n", "", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.load_from_checkpoint": [[296, 327], ["cls._set_model_restore_state", "super().load_from_checkpoint", "cls._set_model_restore_state"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._set_model_restore_state", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.load_from_checkpoint", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._set_model_restore_state"], ["", "@", "classmethod", "\n", "def", "load_from_checkpoint", "(", "\n", "cls", ",", "\n", "checkpoint_path", ":", "str", ",", "\n", "*", "args", ",", "\n", "map_location", ":", "Optional", "[", "Union", "[", "Dict", "[", "str", ",", "str", "]", ",", "str", ",", "torch", ".", "device", ",", "int", ",", "Callable", "]", "]", "=", "None", ",", "\n", "hparams_file", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "strict", ":", "bool", "=", "True", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Loads ModelPT from checkpoint, with some maintenance of restoration.\n        For documentation, please refer to LightningModule.load_from_checkpoint() documentation.\n        \"\"\"", "\n", "checkpoint", "=", "None", "\n", "\n", "try", ":", "\n", "            ", "cls", ".", "_set_model_restore_state", "(", "is_being_restored", "=", "True", ")", "\n", "\n", "checkpoint", "=", "super", "(", ")", ".", "load_from_checkpoint", "(", "\n", "checkpoint_path", "=", "checkpoint_path", ",", "\n", "*", "args", ",", "# type: ignore", "\n", "map_location", "=", "map_location", ",", "\n", "hparams_file", "=", "hparams_file", ",", "\n", "strict", "=", "strict", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "\n", "", "finally", ":", "\n", "            ", "cls", ".", "_set_model_restore_state", "(", "is_being_restored", "=", "False", ")", "\n", "", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_training_data": [[328, 331], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "setup_training_data", "(", "self", ",", "train_data_config", ":", "Union", "[", "DictConfig", ",", "Dict", "]", ")", ":", "\n", "        ", "\"\"\"Setups data loader to be used in training.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_validation_data": [[332, 335], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "setup_validation_data", "(", "self", ",", "val_data_config", ":", "Union", "[", "DictConfig", ",", "Dict", "]", ")", ":", "\n", "        ", "\"\"\"Setups data loader to be used in validation.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_test_data": [[336, 339], ["NotImplementedError"], "methods", ["None"], ["", "def", "setup_test_data", "(", "self", ",", "test_data_config", ":", "Union", "[", "DictConfig", ",", "Dict", "]", ")", ":", "\n", "        ", "\"\"\"(Optionally) Setups data loader to be used in test.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_multiple_validation_data": [[340, 361], ["modelPT.ModelPT._update_dataset_config", "mridc.utils.model_utils.resolve_validation_dataloaders", "mridc.utils.model_utils.resolve_validation_dataloaders", "mridc.utils.model_utils.resolve_validation_dataloaders", "mridc.utils.model_utils.resolve_validation_dataloaders", "type", "range", "len"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._update_dataset_config", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_validation_dataloaders", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_validation_dataloaders", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_validation_dataloaders", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_validation_dataloaders"], ["", "def", "setup_multiple_validation_data", "(", "self", ",", "val_data_config", ":", "Union", "[", "DictConfig", ",", "Dict", "]", ")", ":", "\n", "        ", "\"\"\"(Optionally) Setups data loader to be used in validation.\"\"\"", "\n", "# Set some placeholder overridden by helper method", "\n", "self", ".", "_val_dl_idx", "=", "0", "\n", "self", ".", "validation_names", "=", "None", "\n", "\n", "# preserve config", "\n", "self", ".", "_update_dataset_config", "(", "dataset_name", "=", "\"validation\"", ",", "config", "=", "val_data_config", ")", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "_multi_dataset_mode", "=", "True", "\n", "mridc", ".", "utils", ".", "model_utils", ".", "resolve_validation_dataloaders", "(", "model", "=", "self", ")", "\n", "", "finally", ":", "\n", "            ", "self", ".", "_multi_dataset_mode", "=", "False", "\n", "\n", "", "if", "(", "\n", "self", ".", "validation_names", "is", "None", "\n", "and", "self", ".", "_validation_dl", "is", "not", "None", "\n", "and", "type", "(", "self", ".", "_validation_dl", ")", "in", "[", "list", ",", "tuple", "]", "\n", ")", ":", "\n", "            ", "self", ".", "validation_names", "=", "[", "f\"val_{idx}_\"", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "_validation_dl", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_multiple_test_data": [[362, 380], ["modelPT.ModelPT._update_dataset_config", "mridc.utils.model_utils.resolve_test_dataloaders", "mridc.utils.model_utils.resolve_test_dataloaders", "mridc.utils.model_utils.resolve_test_dataloaders", "mridc.utils.model_utils.resolve_test_dataloaders", "type", "range", "len"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._update_dataset_config", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_test_dataloaders", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_test_dataloaders", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_test_dataloaders", "home.repos.pwc.inspect_result.wdika_mridc.utils.model_utils.resolve_test_dataloaders"], ["", "", "def", "setup_multiple_test_data", "(", "self", ",", "test_data_config", ":", "Union", "[", "DictConfig", ",", "Dict", "]", ")", ":", "\n", "        ", "\"\"\"(Optionally) Setups data loader to be used in test, with support for multiple data loaders.\"\"\"", "\n", "# Set some placeholder overridden by helper method", "\n", "self", ".", "_test_dl_idx", "=", "0", "\n", "self", ".", "test_names", "=", "None", "\n", "self", ".", "_test_dl", "=", "None", "# type: ignore", "\n", "\n", "# preserve config", "\n", "self", ".", "_update_dataset_config", "(", "dataset_name", "=", "\"test\"", ",", "config", "=", "test_data_config", ")", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "_multi_dataset_mode", "=", "True", "\n", "mridc", ".", "utils", ".", "model_utils", ".", "resolve_test_dataloaders", "(", "model", "=", "self", ")", "\n", "", "finally", ":", "\n", "            ", "self", ".", "_multi_dataset_mode", "=", "False", "\n", "\n", "", "if", "self", ".", "test_names", "is", "None", "and", "self", ".", "_test_dl", "is", "not", "None", "and", "type", "(", "self", ".", "_test_dl", ")", "in", "[", "list", ",", "tuple", "]", ":", "\n", "            ", "self", ".", "test_names", "=", "[", "f\"test_{idx}_\"", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "_test_dl", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_optimization": [[381, 529], ["modelPT.ModelPT.setup_optimizer_param_groups", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.to_container", "omegaconf.OmegaConf.to_container.get", "omegaconf.OmegaConf.to_container.get", "hasattr", "mridc.utils.logging.info", "mridc.utils.logging.info", "isinstance", "omegaconf.OmegaConf.create", "hasattr", "isinstance", "omegaconf.OmegaConf.to_container", "mridc.utils.logging.warning", "mridc.utils.logging.warning", "omegaconf.OmegaConf.to_container.pop", "omegaconf.OmegaConf.to_container.get", "inspect.isclass", "omegaconf.OmegaConf.to_container.pop", "mridc.core.optim.optimizers.parse_optimizer_args", "mridc.core.optim.optimizers.parse_optimizer_args", "mridc.core.optim.optimizers.parse_optimizer_args", "mridc.core.optim.optimizers.parse_optimizer_args", "copy.deepcopy", "copy.deepcopy.pop", "copy.deepcopy.pop", "copy.deepcopy.pop", "mridc.core.optim.lr_scheduler.prepare_lr_scheduler", "mridc.core.optim.lr_scheduler.prepare_lr_scheduler", "mridc.core.optim.lr_scheduler.prepare_lr_scheduler", "mridc.core.optim.lr_scheduler.prepare_lr_scheduler", "copy.deepcopy", "isinstance", "ValueError", "omegaconf.OmegaConf.create.__name__.lower", "[].lower", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer", "mridc.core.optim.optimizers.get_optimizer", "OmegaConf.create.", "mridc.utils.logging.info", "mridc.utils.logging.info", "inspect.isclass", "omegaconf.open_dict", "copy.deepcopy", "str", "omegaconf.OmegaConf.create.", "mridc.utils.logging.info", "mridc.utils.logging.info", "str", "omegaconf.OmegaConf.create", "hydra.utils.instantiate", "mridc.utils.logging.info", "mridc.utils.logging.info", "omegaconf.OmegaConf.create.split", "str", "mridc.utils.logging.error", "mridc.utils.logging.error", "str"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_optimizer_param_groups", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.parse_optimizer_args", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.parse_optimizer_args", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.parse_optimizer_args", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.parse_optimizer_args", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.prepare_lr_scheduler", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.prepare_lr_scheduler", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.prepare_lr_scheduler", "home.repos.pwc.inspect_result.wdika_mridc.optim.lr_scheduler.prepare_lr_scheduler", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizers.get_optimizer", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error"], ["", "", "def", "setup_optimization", "(", "self", ",", "optim_config", ":", "Optional", "[", "Union", "[", "DictConfig", ",", "Dict", "]", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Prepares an optimizer from a string name and its optional config parameters.\n\n        Parameters\n        ----------\n        optim_config: A dictionary containing the following keys:\n            - lr: mandatory key for learning rate. Will raise ValueError if not provided.\n            - optimizer: string name pointing to one of the available optimizers in the registry. If not provided, \\\n            defaults to \"adam\".\n            - opt_args: Optional list of strings, in the format \"arg_name=arg_value\". The list of \"arg_value\" will \\\n            be parsed and a dictionary of optimizer kwargs will be built and supplied to instantiate the optimizer.\n\n        Returns\n        -------\n        An instance of an optimizer.\n        \"\"\"", "\n", "# Setup the optimizer parameter groups (by default use all parameters that are trainable).", "\n", "self", ".", "setup_optimizer_param_groups", "(", ")", "\n", "\n", "# If config was not explicitly provided, use default", "\n", "if", "optim_config", "is", "None", "and", "self", ".", "_cfg", "is", "not", "None", "and", "hasattr", "(", "self", ".", "_cfg", ",", "\"optim\"", ")", ":", "\n", "            ", "optim_config", "=", "self", ".", "_cfg", ".", "optim", "\n", "\n", "# If config is still None, or internal config has no Optim, return without instantiation", "\n", "", "if", "optim_config", "is", "None", ":", "\n", "            ", "logging", ".", "info", "(", "\"No optimizer config provided, therefore no optimizer was created\"", ")", "\n", "return", "\n", "# Preserve the configuration", "\n", "", "if", "not", "isinstance", "(", "optim_config", ",", "DictConfig", ")", ":", "\n", "            ", "optim_config", "=", "OmegaConf", ".", "create", "(", "optim_config", ")", "\n", "\n", "# See if internal config has `optim` namespace before preservation", "\n", "", "if", "self", ".", "_cfg", "is", "not", "None", "and", "hasattr", "(", "self", ".", "_cfg", ",", "\"optim\"", ")", ":", "\n", "            ", "if", "self", ".", "_cfg", ".", "optim", "is", "None", ":", "\n", "                ", "self", ".", "_cfg", ".", "optim", "=", "copy", ".", "deepcopy", "(", "optim_config", ")", "\n", "", "else", ":", "\n", "                ", "with", "open_dict", "(", "self", ".", "_cfg", ".", "optim", ")", ":", "\n", "                    ", "self", ".", "_cfg", ".", "optim", "=", "copy", ".", "deepcopy", "(", "optim_config", ")", "\n", "\n", "# Setup optimizer and scheduler", "\n", "", "", "", "if", "optim_config", "is", "not", "None", "and", "isinstance", "(", "optim_config", ",", "DictConfig", ")", ":", "\n", "            ", "optim_config", "=", "OmegaConf", ".", "to_container", "(", "optim_config", ",", "resolve", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "_trainer", "is", "None", ":", "\n", "            ", "logging", ".", "warning", "(", "\"Trainer wasn't specified in model constructor. Make sure that you really wanted it.\"", ")", "\n", "\n", "", "if", "\"sched\"", "in", "optim_config", "and", "self", ".", "_trainer", "is", "not", "None", ":", "\n", "            ", "if", "not", "isinstance", "(", "self", ".", "_trainer", ".", "accumulate_grad_batches", ",", "int", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"We do not currently support gradient accumulation that is not an integer.\"", ")", "\n", "", "if", "self", ".", "_trainer", ".", "max_steps", "is", "None", "or", "self", ".", "trainer", ".", "max_steps", "<", "0", ":", "# type: ignore", "\n", "# Store information needed to calculate max_steps", "\n", "                ", "optim_config", "[", "\"sched\"", "]", "[", "\"t_max_epochs\"", "]", "=", "self", ".", "_trainer", ".", "max_epochs", "\n", "optim_config", "[", "\"sched\"", "]", "[", "\"t_accumulate_grad_batches\"", "]", "=", "self", ".", "_trainer", ".", "accumulate_grad_batches", "\n", "optim_config", "[", "\"sched\"", "]", "[", "\"t_limit_train_batches\"", "]", "=", "self", ".", "_trainer", ".", "limit_train_batches", "\n", "optim_config", "[", "\"sched\"", "]", "[", "\"t_num_workers\"", "]", "=", "self", ".", "_trainer", ".", "num_devices", "*", "self", ".", "_trainer", ".", "num_nodes", "\n", "", "else", ":", "\n", "                ", "optim_config", "[", "\"sched\"", "]", "[", "\"max_steps\"", "]", "=", "self", ".", "_trainer", ".", "max_steps", "\n", "\n", "# Force into DictConfig from nested structure", "\n", "", "", "optim_config", "=", "OmegaConf", ".", "create", "(", "optim_config", ")", "\n", "# Get back nested dict so we its mutable", "\n", "optim_config", "=", "OmegaConf", ".", "to_container", "(", "optim_config", ",", "resolve", "=", "True", ")", "\n", "\n", "# Extract scheduler config if inside optimizer config", "\n", "if", "\"sched\"", "in", "optim_config", ":", "\n", "            ", "scheduler_config", "=", "optim_config", ".", "pop", "(", "\"sched\"", ")", "\n", "", "else", ":", "\n", "            ", "scheduler_config", "=", "None", "\n", "\n", "# Check if caller provided optimizer name, default to Adam otherwise", "\n", "", "optimizer_cls", "=", "optim_config", ".", "get", "(", "\"_target_\"", ",", "None", ")", "\n", "\n", "if", "optimizer_cls", "is", "None", ":", "\n", "# Try to get optimizer name for dynamic resolution, defaulting to Adam", "\n", "            ", "optimizer_name", "=", "optim_config", ".", "get", "(", "\"name\"", ",", "\"adam\"", ")", "\n", "", "elif", "inspect", ".", "isclass", "(", "optimizer_cls", ")", ":", "\n", "            ", "optimizer_name", "=", "optimizer_cls", ".", "__name__", ".", "lower", "(", ")", "\n", "", "else", ":", "\n", "# resolve the class name (lowercase) from the class path if not provided", "\n", "            ", "optimizer_name", "=", "optimizer_cls", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", ".", "lower", "(", ")", "\n", "\n", "# We are guaranteed to have lr since it is required by the argparser", "\n", "# But maybe user forgot to pass it to this function", "\n", "", "lr", "=", "optim_config", ".", "get", "(", "\"lr\"", ",", "None", ")", "\n", "\n", "# Check if caller has optimizer kwargs, default to empty dictionary", "\n", "if", "\"args\"", "in", "optim_config", ":", "\n", "            ", "optimizer_args", "=", "optim_config", ".", "pop", "(", "\"args\"", ")", "\n", "optimizer_args", "=", "mridc", ".", "core", ".", "optim", ".", "optimizers", ".", "parse_optimizer_args", "(", "optimizer_name", ",", "optimizer_args", ")", "\n", "", "else", ":", "\n", "            ", "optimizer_args", "=", "copy", ".", "deepcopy", "(", "optim_config", ")", "\n", "\n", "# Remove extra parameters from optimizer_args nest", "\n", "# Assume all other parameters are to be passed into optimizer constructor", "\n", "optimizer_args", ".", "pop", "(", "\"name\"", ",", "None", ")", "\n", "optimizer_args", ".", "pop", "(", "\"cls\"", ",", "None", ")", "\n", "optimizer_args", ".", "pop", "(", "\"lr\"", ",", "None", ")", "\n", "\n", "# Adaptive schedulers don't need `lr`", "\n", "", "if", "lr", "is", "not", "None", ":", "\n", "            ", "optimizer_args", "[", "\"lr\"", "]", "=", "lr", "\n", "\n", "# Actually instantiate the optimizer", "\n", "if", "optimizer_cls", "is", "None", ":", "\n", "                ", "optimizer", "=", "mridc", ".", "core", ".", "optim", ".", "optimizers", ".", "get_optimizer", "(", "optimizer_name", ")", "\n", "optimizer", "=", "optimizer", "(", "self", ".", "_optimizer_param_groups", ",", "**", "optimizer_args", ")", "\n", "\n", "logging", ".", "info", "(", "\"Optimizer config = %s\"", ",", "str", "(", "optimizer", ")", ")", "\n", "\n", "self", ".", "_optimizer", "=", "optimizer", "# type: ignore", "\n", "\n", "", "elif", "inspect", ".", "isclass", "(", "optimizer_cls", ")", ":", "\n", "                ", "optimizer", "=", "optimizer_cls", "(", "self", ".", "_optimizer_param_groups", ",", "**", "optimizer_args", ")", "\n", "logging", ".", "info", "(", "\"Optimizer config = %s\"", ",", "str", "(", "optimizer", ")", ")", "\n", "\n", "self", ".", "_optimizer", "=", "optimizer", "# type: ignore", "\n", "\n", "", "else", ":", "\n", "# Attempt class path resolution", "\n", "                ", "try", ":", "\n", "                    ", "optimizer_cls", "=", "OmegaConf", ".", "create", "(", "{", "\"_target_\"", ":", "optimizer_cls", "}", ")", "\n", "optimizer_config", "=", "{", "\"lr\"", ":", "lr", "}", "if", "lr", "is", "not", "None", "else", "{", "}", "\n", "optimizer_config", "|=", "optimizer_args", "\n", "\n", "optimizer_instance", "=", "hydra", ".", "utils", ".", "instantiate", "(", "\n", "optimizer_cls", ",", "self", ".", "_optimizer_param_groups", ",", "**", "optimizer_config", "\n", ")", "# type: DictConfig", "\n", "\n", "logging", ".", "info", "(", "\"Optimizer config = %s\"", ",", "str", "(", "optimizer_instance", ")", ")", "\n", "\n", "self", ".", "_optimizer", "=", "optimizer_instance", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "logging", ".", "error", "(", "\n", "f\"Could not instantiate class path - {optimizer_cls} with kwargs {str(optimizer_config)}\"", "\n", ")", "\n", "\n", "raise", "e", "\n", "\n", "# Try to instantiate scheduler for optimizer", "\n", "", "", "self", ".", "_scheduler", "=", "mridc", ".", "core", ".", "optim", ".", "lr_scheduler", ".", "prepare_lr_scheduler", "(", "# type: ignore", "\n", "optimizer", "=", "self", ".", "_optimizer", ",", "scheduler_config", "=", "scheduler_config", ",", "train_dataloader", "=", "self", ".", "_train_dl", "\n", ")", "\n", "\n", "# Return the optimizer with/without scheduler", "\n", "# This return allows multiple optimizers or schedulers to be created", "\n", "return", "self", ".", "_optimizer", ",", "self", ".", "_scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_optimizer_param_groups": [[530, 549], ["hasattr", "modelPT.ModelPT.parameters"], "methods", ["None"], ["", "", "def", "setup_optimizer_param_groups", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Used to create param groups for the optimizer. As an example, this can be used to specify per-layer learning\n        rates:\n\n        .. code-block::\n\n            optim.SGD([\n                        {'params': model.base.parameters()},\n                        {'params': model.classifier.parameters(), 'lr': 1e-3}\n                        ], lr=1e-2, momentum=0.9)\n\n        See https://pytorch.org/docs/stable/optim.html for more information. By default, ModelPT will use\n        self.parameters(). Override this method to add custom param groups.\n        \"\"\"", "\n", "param_groups", "=", "None", "\n", "if", "hasattr", "(", "self", ",", "\"parameters\"", ")", ":", "\n", "            ", "param_groups", "=", "[", "{", "\"params\"", ":", "self", ".", "parameters", "(", ")", "}", "]", "\n", "", "self", ".", "_optimizer_param_groups", "=", "param_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.configure_optimizers": [[550, 558], ["modelPT.ModelPT.setup_optimization"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.setup_optimization"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Configure optimizers and schedulers for training.\"\"\"", "\n", "self", ".", "setup_optimization", "(", ")", "\n", "\n", "if", "self", ".", "_scheduler", "is", "None", ":", "\n", "            ", "return", "self", ".", "_optimizer", "\n", "\n", "", "return", "[", "self", ".", "_optimizer", "]", ",", "[", "self", ".", "_scheduler", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.train_dataloader": [[559, 562], ["None"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the training dataloader.\"\"\"", "\n", "return", "self", ".", "_train_dl", "if", "self", ".", "_train_dl", "is", "not", "None", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.val_dataloader": [[563, 566], ["None"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the validation dataloader.\"\"\"", "\n", "return", "self", ".", "_validation_dl", "if", "self", ".", "_validation_dl", "is", "not", "None", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.test_dataloader": [[567, 570], ["None"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the test dataloader.\"\"\"", "\n", "return", "self", ".", "_test_dl", "if", "self", ".", "_test_dl", "is", "not", "None", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.validation_epoch_end": [[571, 666], ["enumerate", "type", "modelPT.ModelPT.multi_validation_epoch_end", "modelPT.ModelPT.get_validation_dataloader_prefix", "modelPT.ModelPT.multi_validation_epoch_end", "modelPT.ModelPT.items", "modelPT.ModelPT.log_dict", "len", "modelPT.ModelPT.log_dict", "modelPT.ModelPT.pop", "modelPT.ModelPT.pop", "v.items", "output_logs.update"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.multi_validation_epoch_end", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.get_validation_dataloader_prefix", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.multi_validation_epoch_end", "home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.update"], ["", "def", "validation_epoch_end", "(", "\n", "self", ",", "outputs", ":", "Union", "[", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "List", "[", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", "]", "]", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        Default DataLoader for Validation set which automatically supports multiple data loaders\n        via `multi_validation_epoch_end`.\n        If multi dataset support is not required, override this method entirely in base class.\n        In such a case, there is no need to implement `multi_validation_epoch_end` either.\n\n        .. note::\n            If more than one data loader exists, and they all provide `val_loss`,\n            only the `val_loss` of the first data loader will be used by default.\n            This default can be changed by passing the special key `val_dl_idx: int`\n            inside the `validation_ds` config.\n\n        Parameters\n        ----------\n        outputs: Single or nested list of tensor outputs from one or more data loaders.\n\n        Returns\n        -------\n        A dictionary containing the union of all items from individual data_loaders, along with merged logs from all\n        data loaders.\n        \"\"\"", "\n", "# Case where we dont provide data loaders", "\n", "if", "outputs", "is", "not", "None", "and", "len", "(", "outputs", ")", "==", "0", ":", "\n", "            ", "return", "{", "}", "\n", "\n", "# Case where we provide exactly 1 data loader", "\n", "", "if", "type", "(", "outputs", "[", "0", "]", ")", "is", "dict", ":", "\n", "            ", "output_dict", "=", "self", ".", "multi_validation_epoch_end", "(", "outputs", ",", "dataloader_idx", "=", "0", ")", "# type: ignore", "\n", "\n", "if", "output_dict", "is", "not", "None", "and", "\"log\"", "in", "output_dict", ":", "\n", "                ", "self", ".", "log_dict", "(", "output_dict", ".", "pop", "(", "\"log\"", ")", ",", "on_epoch", "=", "True", ")", "# type: ignore", "\n", "\n", "", "return", "output_dict", "\n", "\n", "", "output_dict", "=", "{", "\"log\"", ":", "{", "}", "}", "\n", "\n", "# The output is a list of list of dicts, outer list corresponds to dataloader idx", "\n", "for", "dataloader_idx", ",", "val_outputs", "in", "enumerate", "(", "outputs", ")", ":", "# type: ignore", "\n", "# Get prefix and dispatch call to multi epoch end", "\n", "            ", "dataloader_prefix", "=", "self", ".", "get_validation_dataloader_prefix", "(", "dataloader_idx", ")", "\n", "dataloader_logs", "=", "self", ".", "multi_validation_epoch_end", "(", "val_outputs", ",", "dataloader_idx", "=", "dataloader_idx", ")", "\n", "\n", "# If result was not provided, generate empty dict", "\n", "dataloader_logs", ":", "Dict", "[", "Any", ",", "Any", "]", "=", "dataloader_logs", "or", "{", "}", "# type: ignore", "\n", "\n", "# Perform `val_loss` resolution first (if provided outside logs)", "\n", "if", "(", "\"val_loss\"", "in", "dataloader_logs", "and", "\"val_loss\"", "not", "in", "output_dict", ")", "and", "(", "# type: ignore", "\n", "dataloader_idx", "==", "self", ".", "_val_dl_idx", "\n", ")", ":", "\n", "                ", "output_dict", "[", "\"val_loss\"", "]", "=", "dataloader_logs", "[", "\"val_loss\"", "]", "# type: ignore", "\n", "\n", "# For every item in the result dictionary", "\n", "", "for", "k", ",", "v", "in", "dataloader_logs", ".", "items", "(", ")", ":", "# type: ignore", "\n", "# If the key is `log`", "\n", "                ", "if", "k", "==", "\"log\"", ":", "\n", "# Parse every element of the log, and attach the prefix name of the data loader", "\n", "                    ", "log_dict", "=", "{", "}", "\n", "\n", "for", "k_log", ",", "v_log", "in", "v", ".", "items", "(", ")", ":", "\n", "# If we are logging the metric, but dont provide it at result level,", "\n", "# store it twice - once in log and once in result level.", "\n", "# Also mark log with prefix name to avoid log level clash with other data loaders", "\n", "                        ", "if", "k_log", "not", "in", "output_dict", "[", "\"log\"", "]", "and", "dataloader_idx", "==", "self", ".", "_val_dl_idx", ":", "# type: ignore", "\n", "                            ", "new_k_log", "=", "k_log", "\n", "\n", "# Also insert duplicate key with prefix for ease of comparison / avoid name clash", "\n", "log_dict", "[", "dataloader_prefix", "+", "k_log", "]", "=", "v_log", "\n", "\n", "", "else", ":", "\n", "# Simply prepend prefix to key and save", "\n", "                            ", "new_k_log", "=", "dataloader_prefix", "+", "k_log", "\n", "\n", "# Store log value", "\n", "", "log_dict", "[", "new_k_log", "]", "=", "v_log", "\n", "\n", "# Update log storage of individual data loader", "\n", "", "output_logs", "=", "output_dict", "[", "\"log\"", "]", "# type: ignore", "\n", "output_logs", ".", "update", "(", "log_dict", ")", "\n", "\n", "# Update global log storage", "\n", "output_dict", "[", "\"log\"", "]", "=", "output_logs", "# type: ignore", "\n", "\n", "", "else", ":", "\n", "# If any values are stored outside 'log', simply prefix name and store", "\n", "                    ", "new_k", "=", "dataloader_prefix", "+", "k", "\n", "output_dict", "[", "new_k", "]", "=", "v", "# type: ignore", "\n", "\n", "", "", "", "if", "\"log\"", "in", "output_dict", ":", "# type: ignore", "\n", "            ", "self", ".", "log_dict", "(", "output_dict", ".", "pop", "(", "\"log\"", ")", ",", "on_epoch", "=", "True", ")", "# type: ignore", "\n", "\n", "# return everything else", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.test_epoch_end": [[667, 762], ["enumerate", "type", "modelPT.ModelPT.multi_test_epoch_end", "modelPT.ModelPT.get_test_dataloader_prefix", "modelPT.ModelPT.multi_test_epoch_end", "dataloader_logs.items", "modelPT.ModelPT.log_dict", "len", "modelPT.ModelPT.log_dict", "modelPT.ModelPT.pop", "modelPT.ModelPT.pop", "v.items", "modelPT.ModelPT.get", "modelPT.ModelPT.get.update"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.multi_test_epoch_end", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.get_test_dataloader_prefix", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.multi_test_epoch_end", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.update"], ["", "def", "test_epoch_end", "(", "\n", "self", ",", "outputs", ":", "Union", "[", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "List", "[", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", "]", "]", "\n", ")", "->", "Optional", "[", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        Default DataLoader for Test set which automatically supports multiple data loaders\n        via `multi_test_epoch_end`.\n        If multi dataset support is not required, override this method entirely in base class.\n        In such a case, there is no need to implement `multi_test_epoch_end` either.\n\n        .. note::\n            If more than one data loader exists, and they all provide `test_loss`,\n            only the `test_loss` of the first data loader will be used by default.\n            This default can be changed by passing the special key `_test_dl_idx: int`\n            inside the `test_ds` config.\n\n        Parameters\n        ----------\n        outputs: Single or nested list of tensor outputs from one or more data loaders.\n\n        Returns\n        -------\n        A dictionary containing the union of all items from individual data_loaders, along with merged logs from all\n        data loaders.\n        \"\"\"", "\n", "# Case where we dont provide data loaders", "\n", "if", "outputs", "is", "not", "None", "and", "len", "(", "outputs", ")", "==", "0", ":", "\n", "            ", "return", "{", "}", "\n", "\n", "# Case where we provide exactly 1 data loader", "\n", "", "if", "type", "(", "outputs", "[", "0", "]", ")", "is", "dict", ":", "\n", "            ", "output_dict", "=", "self", ".", "multi_test_epoch_end", "(", "outputs", ",", "dataloader_idx", "=", "0", ")", "# type: ignore", "\n", "\n", "if", "output_dict", "is", "not", "None", "and", "\"log\"", "in", "output_dict", ":", "\n", "                ", "self", ".", "log_dict", "(", "output_dict", ".", "pop", "(", "\"log\"", ")", ",", "on_epoch", "=", "True", ")", "# type: ignore", "\n", "\n", "", "return", "output_dict", "\n", "\n", "", "output_dict", "=", "{", "\"log\"", ":", "{", "}", "}", "\n", "\n", "# The output is a list of dicts, outer list corresponds to dataloader idx", "\n", "for", "dataloader_idx", ",", "test_outputs", "in", "enumerate", "(", "outputs", ")", ":", "# type: ignore", "\n", "# Get prefix and dispatch call to multi epoch end", "\n", "            ", "dataloader_prefix", "=", "self", ".", "get_test_dataloader_prefix", "(", "dataloader_idx", ")", "\n", "self", ".", "multi_test_epoch_end", "(", "test_outputs", ",", "dataloader_idx", "=", "dataloader_idx", ")", "\n", "\n", "# If result was not provided, generate empty dict", "\n", "dataloader_logs", "=", "dataloader_logs", "or", "{", "}", "# type: ignore", "\n", "\n", "# Perform `test_loss` resolution first (if provided outside logs)", "\n", "if", "(", "\n", "\"test_loss\"", "in", "dataloader_logs", "\n", "and", "\"test_loss\"", "not", "in", "output_dict", "# type: ignore", "\n", "and", "dataloader_idx", "==", "self", ".", "_test_dl_idx", "\n", ")", ":", "# type: ignore", "\n", "                ", "output_dict", "[", "\"test_loss\"", "]", "=", "dataloader_logs", "[", "\"test_loss\"", "]", "# type: ignore", "\n", "\n", "# For every item in the result dictionary", "\n", "", "for", "k", ",", "v", "in", "dataloader_logs", ".", "items", "(", ")", ":", "\n", "# If the key is `log`", "\n", "                ", "if", "k", "==", "\"log\"", ":", "\n", "# Parse every element of the log, and attach the prefix name of the data loader", "\n", "                    ", "log_dict", "=", "{", "}", "\n", "for", "k_log", ",", "v_log", "in", "v", ".", "items", "(", ")", ":", "\n", "# If we are logging the loss, but dont provide it at result level,", "\n", "# store it twice - once in log and once in result level.", "\n", "# Also mark log with prefix name to avoid log level clash with other data loaders", "\n", "                        ", "if", "k_log", "not", "in", "output_dict", "[", "\"log\"", "]", "and", "dataloader_idx", "==", "self", ".", "_test_dl_idx", ":", "# type: ignore", "\n", "                            ", "new_k_log", "=", "k_log", "\n", "\n", "# Also insert duplicate key with prefix for ease of comparison / avoid name clash", "\n", "log_dict", "[", "dataloader_prefix", "+", "k_log", "]", "=", "v_log", "\n", "\n", "", "else", ":", "\n", "# Simply prepend prefix to key and save", "\n", "                            ", "new_k_log", "=", "dataloader_prefix", "+", "k_log", "\n", "\n", "", "log_dict", "[", "new_k_log", "]", "=", "v_log", "\n", "\n", "# Update log storage of individual data loader", "\n", "", "output_logs", "=", "output_dict", ".", "get", "(", "\"log\"", ",", "{", "}", ")", "# type: ignore", "\n", "output_logs", ".", "update", "(", "log_dict", ")", "\n", "\n", "# Update global log storage", "\n", "output_dict", "[", "\"log\"", "]", "=", "output_logs", "# type: ignore", "\n", "\n", "", "else", ":", "\n", "# If any values are stored outside 'log', simply prefix name and store", "\n", "                    ", "new_k", "=", "dataloader_prefix", "+", "k", "\n", "output_dict", "[", "new_k", "]", "=", "v", "# type: ignore", "\n", "\n", "", "", "", "if", "\"log\"", "in", "output_dict", ":", "# type: ignore", "\n", "            ", "self", ".", "log_dict", "(", "output_dict", ".", "pop", "(", "\"log\"", ")", ",", "on_epoch", "=", "True", ")", "# type: ignore", "\n", "\n", "# return everything else", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.multi_validation_epoch_end": [[763, 783], ["mridc.utils.logging.warning", "mridc.utils.logging.warning"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning"], ["", "@", "staticmethod", "\n", "def", "multi_validation_epoch_end", "(", "\n", "outputs", ":", "Union", "[", "object", ",", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", ",", "None", "]", ",", "dataloader_idx", ":", "int", "=", "0", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Adds support for multiple validation datasets. Should be overridden by subclass, to obtain appropriate logs for\n         each of the dataloaders.\n\n        Parameters\n        ----------\n        outputs: Same as that provided by LightningModule.validation_epoch_end() for a single dataloader.\n        dataloader_idx: int representing the index of the dataloader.\n\n        Returns\n        -------\n        A dictionary of values, optionally containing a sub-dict `log`, such that the values in the log will be\n        pre-pended by the dataloader prefix.\n        \"\"\"", "\n", "logging", ".", "warning", "(", "\n", "\"Multi data loader support has been enabled, but `multi_validation_epoch_end(outputs, dataloader_idx) \"", "\n", "\"has not been implemented.\\n\"", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.multi_test_epoch_end": [[788, 806], ["mridc.utils.logging.warning", "mridc.utils.logging.warning"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning"], ["", "@", "staticmethod", "\n", "def", "multi_test_epoch_end", "(", "outputs", ":", "Union", "[", "object", ",", "List", "[", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "]", "]", ",", "dataloader_idx", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Adds support for multiple test datasets. Should be overridden by subclass, to obtain appropriate logs for each\n        of the dataloaders.\n\n        Parameters\n        ----------\n        outputs: Same as that provided by LightningModule.validation_epoch_end() for a single dataloader.\n        dataloader_idx: int representing the index of the dataloader.\n\n        Returns\n        -------\n        A dictionary of values, optionally containing a sub-dict `log`, such that the values in the log will be\n        pre-pended by the dataloader prefix.\n        \"\"\"", "\n", "logging", ".", "warning", "(", "\n", "\"Multi data loader support has been enabled, but `multi_test_epoch_end(outputs, dataloader_idx) has not \"", "\n", "\"been implemented.\\n\"", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.get_validation_dataloader_prefix": [[811, 814], ["None"], "methods", ["None"], ["", "def", "get_validation_dataloader_prefix", "(", "self", ",", "dataloader_idx", ":", "int", "=", "0", ")", "->", "str", ":", "\n", "        ", "\"\"\"Get the name of one or more data loaders, which will be prepended to all logs.\"\"\"", "\n", "return", "self", ".", "validation_names", "[", "dataloader_idx", "]", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.get_test_dataloader_prefix": [[815, 818], ["None"], "methods", ["None"], ["", "def", "get_test_dataloader_prefix", "(", "self", ",", "dataloader_idx", ":", "int", "=", "0", ")", "->", "str", ":", "\n", "        ", "\"\"\"Get the name of one or more data loaders, which will be prepended to all logs.\"\"\"", "\n", "return", "self", ".", "test_names", "[", "dataloader_idx", "]", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.load_part_of_state_dict": [[819, 844], ["state_dict.items", "modelPT.ModelPT.load_state_dict", "mridc.utils.logging.info", "mridc.utils.logging.info", "any", "mridc.utils.logging.info", "mridc.utils.logging.info", "mridc.utils.logging.info", "mridc.utils.logging.info", "excluded_param_names.append"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.load_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info"], ["", "def", "load_part_of_state_dict", "(", "self", ",", "state_dict", ",", "include", ",", "exclude", ",", "load_from_string", ")", ":", "\n", "        ", "\"\"\"Load part of the state dict.\"\"\"", "\n", "excluded_param_names", "=", "[", "]", "\n", "# create dict", "\n", "dict_to_load", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "should_add", "=", "any", "(", "p", "in", "k", "for", "p", "in", "include", ")", "\n", "# except for if any string from exclude is present", "\n", "for", "e", "in", "exclude", ":", "\n", "                ", "if", "e", "in", "k", ":", "\n", "                    ", "excluded_param_names", ".", "append", "(", "k", ")", "\n", "should_add", "=", "False", "\n", "break", "\n", "", "", "if", "should_add", ":", "\n", "                ", "dict_to_load", "[", "k", "]", "=", "v", "\n", "\n", "# Restore checkpoint part into current model", "\n", "", "", "self", ".", "load_state_dict", "(", "dict_to_load", ",", "strict", "=", "False", ")", "# type: ignore", "\n", "logging", ".", "info", "(", "f\"Model checkpoint partially restored from {load_from_string}\"", ")", "\n", "\n", "if", "excluded_param_names", ":", "\n", "            ", "logging", ".", "info", "(", "\n", "f\"The following parameters were excluded from loading from {load_from_string} : {excluded_param_names}\"", "\n", ")", "\n", "logging", ".", "info", "(", "\"Make sure that this is what you wanted!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.maybe_init_from_pretrained_checkpoint": [[845, 987], ["sum", "sum", "ValueError", "omegaconf.open_dict", "isinstance", "omegaconf.open_dict", "isinstance", "omegaconf.open_dict", "isinstance", "modelPT.ModelPT.restore_from", "modelPT.ModelPT.load_state_dict", "mridc.utils.logging.info", "mridc.utils.logging.info", "isinstance", "cfg.pop", "modelPT.ModelPT.from_pretrained", "modelPT.ModelPT.load_state_dict", "mridc.utils.logging.info", "mridc.utils.logging.info", "isinstance", "cfg.pop", "torch.load", "modelPT.ModelPT.load_state_dict", "mridc.utils.logging.info", "mridc.utils.logging.info", "isinstance", "modelPT.ModelPT.state_dict", "model_load_dict.values", "TypeError", "hasattr", "modelPT.ModelPT.state_dict", "isinstance", "model_load_dict.values", "TypeError", "cfg.get", "modelPT.ModelPT.restore_from", "model_load_cfg.pop", "model_load_cfg.pop", "modelPT.ModelPT.load_part_of_state_dict", "hasattr", "mridc.utils.logging.info", "mridc.utils.logging.info", "cfg.get", "model_load_dict.values", "TypeError", "torch.load", "model_load_cfg.pop", "model_load_cfg.pop", "modelPT.ModelPT.load_part_of_state_dict", "enumerate", "modelPT.ModelPT.state_dict", "modelPT.ModelPT.from_pretrained", "model_load_cfg.pop", "model_load_cfg.pop", "modelPT.ModelPT.load_part_of_state_dict", "cfg.get", "modelPT.ModelPT.state_dict", "cfg.get"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.restore_from", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.load_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.load_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.load_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.state_dict", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.state_dict", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.restore_from", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.load_part_of_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.load_part_of_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.state_dict", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.load_part_of_state_dict", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.MainParamsOptimizerWrapper.state_dict", "home.repos.pwc.inspect_result.wdika_mridc.optim.optimizer_with_master_params.GradBucket.get"], ["", "", "@", "rank_zero_only", "\n", "def", "maybe_init_from_pretrained_checkpoint", "(", "self", ",", "cfg", ":", "OmegaConf", ",", "map_location", ":", "str", "=", "\"cpu\"", ")", ":", "\n", "        ", "\"\"\"\n        Initializes a given model with the parameters obtained via specific config arguments. The state dict of the \\\n        provided model will be updated with `strict=False` setting to prevent requirement of exact model parameters \\\n        matching.\n\n        Initializations\n\n        init_from_mridc_model: Str path to a .mridc model, which will be instantiated in order to extract the state \\\n        dict.\n\n        init_from_pretrained_model: Str name of a pretrained model checkpoint (obtained via cloud). The model will \\\n        be downloaded (or a cached copy will be used), instantiated and then its state dict will be extracted.\n\n        init_from_ptl_ckpt: Str name of a Pytorch Lightning checkpoint file. It will be loaded and the state dict \\\n        will extract.\n\n        Parameters\n        ----------\n        cfg: The config used to instantiate the model. It needs only contain one of the above keys.\n        map_location: str or torch.device() which represents where the intermediate state dict (from the pretrained \\\n        model or checkpoint) will be loaded.\n        \"\"\"", "\n", "args", "=", "[", "\"init_from_mridc_model\"", ",", "\"init_from_pretrained_model\"", ",", "\"init_from_ptl_ckpt\"", "]", "\n", "arg_matches", "=", "[", "(", "1", "if", "arg", "in", "cfg", "and", "arg", "is", "not", "None", "else", "0", ")", "for", "arg", "in", "args", "]", "\n", "\n", "if", "sum", "(", "arg_matches", ")", "==", "0", ":", "\n", "# model weights do not need to be restored", "\n", "            ", "return", "\n", "\n", "", "if", "sum", "(", "arg_matches", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Cannot pass more than one model initialization arguments to config!\\n\"", "\n", "f\"Found : {[args[idx] for idx, arg_present in enumerate(arg_matches) if arg_present]}\"", "\n", ")", "\n", "\n", "", "if", "\"init_from_mridc_model\"", "in", "cfg", "and", "cfg", ".", "init_from_mridc_model", "is", "not", "None", ":", "# type: ignore", "\n", "            ", "with", "open_dict", "(", "cfg", ")", ":", "# type: ignore", "\n", "                ", "if", "isinstance", "(", "cfg", ".", "init_from_mridc_model", ",", "str", ")", ":", "# type: ignore", "\n", "                    ", "model_path", "=", "cfg", ".", "init_from_mridc_model", "# type: ignore", "\n", "# Restore model", "\n", "restored_model", "=", "self", ".", "restore_from", "(", "\n", "model_path", ",", "map_location", "=", "map_location", ",", "strict", "=", "cfg", ".", "get", "(", "\"init_strict\"", ",", "True", ")", "# type: ignore", "\n", ")", "\n", "# Restore checkpoint into current model", "\n", "self", ".", "load_state_dict", "(", "restored_model", ".", "state_dict", "(", ")", ",", "strict", "=", "False", ")", "\n", "logging", ".", "info", "(", "f\"Model checkpoint restored from mridc file with path : `{model_path}`\"", ")", "\n", "", "elif", "isinstance", "(", "cfg", ".", "init_from_mridc_model", ",", "(", "DictConfig", ",", "dict", ")", ")", ":", "# type: ignore", "\n", "                    ", "model_load_dict", "=", "cfg", ".", "init_from_mridc_model", "# type: ignore", "\n", "for", "model_load_cfg", "in", "model_load_dict", ".", "values", "(", ")", ":", "\n", "                        ", "model_path", "=", "model_load_cfg", ".", "path", "\n", "# Restore model", "\n", "restored_model", "=", "self", ".", "restore_from", "(", "\n", "model_path", ",", "map_location", "=", "map_location", ",", "strict", "=", "cfg", ".", "get", "(", "\"init_strict\"", ",", "True", ")", "# type: ignore", "\n", ")", "\n", "\n", "include", "=", "model_load_cfg", ".", "pop", "(", "\"include\"", ",", "[", "\"\"", "]", ")", "\n", "exclude", "=", "model_load_cfg", ".", "pop", "(", "\"exclude\"", ",", "[", "]", ")", "\n", "\n", "self", ".", "load_part_of_state_dict", "(", "\n", "restored_model", ".", "state_dict", "(", ")", ",", "include", ",", "exclude", ",", "f\"mridc file with path `{model_path}`\"", "\n", ")", "\n", "", "", "else", ":", "\n", "                    ", "raise", "TypeError", "(", "\"Invalid type: init_from_mridc_model is not a string or a dict!\"", ")", "\n", "\n", "", "", "", "if", "\"init_from_pretrained_model\"", "in", "cfg", "and", "cfg", ".", "init_from_pretrained_model", "is", "not", "None", ":", "# type: ignore", "\n", "            ", "with", "open_dict", "(", "cfg", ")", ":", "# type: ignore", "\n", "# Restore model", "\n", "                ", "if", "isinstance", "(", "cfg", ".", "init_from_pretrained_model", ",", "str", ")", ":", "# type: ignore", "\n", "                    ", "model_name", "=", "cfg", ".", "pop", "(", "\"init_from_pretrained_model\"", ")", "# type: ignore", "\n", "\n", "# Check if model is being resumed or not - only works if `Trainer` is attached to model", "\n", "if", "hasattr", "(", "self", ",", "\"trainer\"", ")", "and", "self", ".", "trainer", "is", "not", "None", ":", "\n", "                        ", "trainer", "=", "self", ".", "trainer", "\n", "if", "(", "\n", "hasattr", "(", "trainer", ",", "\"resume_from_checkpoint\"", ")", "\n", "and", "trainer", ".", "checkpoint_connector", ".", "resume_checkpoint_path", "is", "not", "None", "\n", ")", ":", "\n", "                            ", "logging", ".", "info", "(", "\n", "\"Model training is being resumed via Pytorch Lightning.\\n\"", "\n", "\"Initialization from pretrained model (via cloud) will be skipped.\"", "\n", ")", "\n", "return", "\n", "\n", "", "", "restored_model", "=", "self", ".", "from_pretrained", "(", "\n", "model_name", ",", "map_location", "=", "map_location", ",", "strict", "=", "cfg", ".", "get", "(", "\"init_strict\"", ",", "True", ")", "# type: ignore", "\n", ")", "\n", "\n", "# Restore checkpoint into current model", "\n", "self", ".", "load_state_dict", "(", "restored_model", ".", "state_dict", "(", ")", ",", "strict", "=", "False", ")", "\n", "logging", ".", "info", "(", "f\"Model checkpoint restored from pretrained checkpoint with name : `{model_name}`\"", ")", "\n", "", "elif", "isinstance", "(", "cfg", ".", "init_from_pretrained_model", ",", "dict", ")", ":", "# type: ignore", "\n", "                    ", "pass", "\n", "", "elif", "isinstance", "(", "cfg", ".", "init_from_pretrained_model", ",", "(", "DictConfig", ",", "dict", ")", ")", ":", "# type: ignore", "\n", "                    ", "model_load_dict", "=", "cfg", ".", "init_from_pretrained_model", "# type: ignore", "\n", "for", "model_load_cfg", "in", "model_load_dict", ".", "values", "(", ")", ":", "\n", "                        ", "model_name", "=", "model_load_cfg", ".", "name", "\n", "# Restore model", "\n", "restored_model", "=", "self", ".", "from_pretrained", "(", "\n", "model_name", ",", "map_location", "=", "map_location", ",", "strict", "=", "cfg", ".", "get", "(", "\"init_strict\"", ",", "True", ")", "# type: ignore", "\n", ")", "\n", "\n", "include", "=", "model_load_cfg", ".", "pop", "(", "\"include\"", ",", "[", "\"\"", "]", ")", "\n", "exclude", "=", "model_load_cfg", ".", "pop", "(", "\"exclude\"", ",", "[", "]", ")", "\n", "\n", "self", ".", "load_part_of_state_dict", "(", "\n", "restored_model", ".", "state_dict", "(", ")", ",", "\n", "include", ",", "\n", "exclude", ",", "\n", "f\"pretrained checkpoint with name `{model_name}`\"", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "                    ", "raise", "TypeError", "(", "\"Invalid type: init_from_pretrained_model is not a string or a dict!\"", ")", "\n", "\n", "", "", "", "if", "\"init_from_ptl_ckpt\"", "in", "cfg", "and", "cfg", ".", "init_from_ptl_ckpt", "is", "not", "None", ":", "# type: ignore", "\n", "            ", "with", "open_dict", "(", "cfg", ")", ":", "# type: ignore", "\n", "                ", "if", "isinstance", "(", "cfg", ".", "init_from_ptl_ckpt", ",", "str", ")", ":", "# type: ignore", "\n", "# Restore checkpoint", "\n", "                    ", "ckpt_path", "=", "cfg", ".", "pop", "(", "\"init_from_ptl_ckpt\"", ")", "# type: ignore", "\n", "ckpt", "=", "torch", ".", "load", "(", "ckpt_path", ",", "map_location", "=", "map_location", ")", "\n", "\n", "# Restore checkpoint into current model", "\n", "self", ".", "load_state_dict", "(", "ckpt", "[", "\"state_dict\"", "]", ",", "strict", "=", "False", ")", "\n", "logging", ".", "info", "(", "\n", "f\"Model checkpoint restored from pytorch lightning checkpoint with path : `{ckpt_path}`\"", "\n", ")", "\n", "", "elif", "isinstance", "(", "cfg", ".", "init_from_ptl_ckpt", ",", "(", "DictConfig", ",", "dict", ")", ")", ":", "# type: ignore", "\n", "                    ", "model_load_dict", "=", "cfg", ".", "init_from_ptl_ckpt", "# type: ignore", "\n", "for", "model_load_cfg", "in", "model_load_dict", ".", "values", "(", ")", ":", "\n", "                        ", "ckpt_path", "=", "model_load_cfg", ".", "path", "\n", "# Restore model", "\n", "ckpt", "=", "torch", ".", "load", "(", "ckpt_path", ",", "map_location", "=", "map_location", ")", "\n", "\n", "include", "=", "model_load_cfg", ".", "pop", "(", "\"include\"", ",", "[", "\"\"", "]", ")", "\n", "exclude", "=", "model_load_cfg", ".", "pop", "(", "\"exclude\"", ",", "[", "]", ")", "\n", "\n", "self", ".", "load_part_of_state_dict", "(", "\n", "ckpt", "[", "\"state_dict\"", "]", ",", "include", ",", "exclude", ",", "f\"nemo file with path `{model_path}`\"", "\n", ")", "\n", "", "", "else", ":", "\n", "                    ", "raise", "TypeError", "(", "\"Invalid type: init_from_ptl_ckpt is not a string or a dict!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.teardown": [[988, 994], ["super().teardown", "os.environ.pop"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.teardown"], ["", "", "", "", "def", "teardown", "(", "self", ",", "stage", ":", "str", ")", ":", "\n", "        ", "\"\"\"Called at the end of fit and test.\"\"\"", "\n", "if", "stage", "==", "\"fit\"", "and", "\"PL_TRAINER_GPUS\"", "in", "os", ".", "environ", ":", "\n", "            ", "os", ".", "environ", ".", "pop", "(", "\"PL_TRAINER_GPUS\"", ")", "\n", "\n", "", "super", "(", ")", ".", "teardown", "(", "stage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.extract_state_dict_from": [[995, 1059], ["cls.update_save_restore_connector", "cls._save_restore_connector.extract_state_dict_from", "mridc.core.connectors.save_restore_connector.SaveRestoreConnector", "mridc.core.connectors.save_restore_connector.SaveRestoreConnector", "os.path.exists", "FileExistsError"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.update_save_restore_connector", "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.extract_state_dict_from"], ["", "@", "classmethod", "\n", "def", "extract_state_dict_from", "(", "\n", "cls", ",", "\n", "restore_path", ":", "str", ",", "\n", "save_dir", ":", "str", ",", "\n", "split_by_module", ":", "bool", "=", "False", ",", "\n", "save_restore_connector", ":", "SaveRestoreConnector", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Extract the state dict(s) from a provided .mridc tarfile and save it to a directory.\n\n        Parameters\n        ----------\n        restore_path: path to .mridc file from which state dict(s) should be extracted\n        save_dir: directory in which the saved state dict(s) should be stored\n        split_by_module: bool flag, which determines whether the output checkpoint should be for the entire Model, or\n        the individual module's that comprise the Model\n        save_restore_connector: Can be overridden to add custom save and restore logic.\n\n        Example\n        -------\n        To convert the .mridc tarfile into a single Model level PyTorch checkpoint\n\n        .. code-block::\n\n            state_dict = mridc.collections.asr.models.EncDecCTCModel.extract_state_dict_from('asr.mridc', \\\n            './asr_ckpts')\n\n        To restore a model from a Model level checkpoint\n\n        .. code-block::\n\n            model = mridc.collections.asr.models.EncDecCTCModel(cfg)  # or any other method of restoration\n            model.load_state_dict(torch.load(\"./asr_ckpts/model_weights.ckpt\"))\n\n        To convert the .mridc tarfile into multiple Module level PyTorch checkpoints\n\n        .. code-block::\n\n            state_dict = mridc.collections.asr.models.EncDecCTCModel.extract_state_dict_from('asr.mridc', \\\n            './asr_ckpts', split_by_module=True)\n\n        To restore a module from a Module level checkpoint\n\n        .. code-block::\n\n            model = mridc.collections.asr.models.EncDecCTCModel(cfg)  # or any other method of restoration\n            # load the individual components\n            model.preprocessor.load_state_dict(torch.load(\"./asr_ckpts/preprocessor.ckpt\"))\n            model.encoder.load_state_dict(torch.load(\"./asr_ckpts/encoder.ckpt\"))\n            model.decoder.load_state_dict(torch.load(\"./asr_ckpts/decoder.ckpt\"))\n\n        Returns\n        -------\n        The state dict that was loaded from the original .mridc checkpoint.\n        \"\"\"", "\n", "if", "save_restore_connector", "is", "None", ":", "\n", "            ", "save_restore_connector", "=", "SaveRestoreConnector", "(", ")", "\n", "\n", "", "if", "not", "path", ".", "exists", "(", "restore_path", ")", ":", "\n", "            ", "raise", "FileExistsError", "(", "f\"Can't find {restore_path}\"", ")", "\n", "\n", "", "cls", ".", "update_save_restore_connector", "(", "save_restore_connector", ")", "\n", "return", "cls", ".", "_save_restore_connector", ".", "extract_state_dict_from", "(", "restore_path", ",", "save_dir", ",", "split_by_module", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.prepare_test": [[1060, 1094], ["modelPT.ModelPT.set_trainer", "hasattr", "mridc.utils.logging.info", "mridc.utils.logging.info", "mridc.utils.logging.warning", "mridc.utils.logging.warning"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.set_trainer", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning"], ["", "def", "prepare_test", "(", "self", ",", "trainer", ":", "\"Trainer\"", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Helper method to check whether the model can safely be tested on a dataset after training (or loading a\n        checkpoint).\n\n        .. code-block::\n\n            trainer = Trainer()\n            if model.prepare_test(trainer):\n                trainer.test(model)\n\n        Returns\n        -------\n        Bool which declares the model safe to test. Provides warnings if it has to return False to guide the user.\n        \"\"\"", "\n", "if", "not", "hasattr", "(", "self", ".", "_cfg", ",", "\"test_ds\"", ")", ":", "\n", "            ", "logging", ".", "info", "(", "\"No `test_ds` config found within the manifest.\"", ")", "\n", "return", "False", "\n", "\n", "", "if", "trainer", "is", "not", "None", "and", "trainer", ".", "num_devices", ">", "1", ":", "\n", "# Replace ddp multi-gpu until PTL has a fix", "\n", "            ", "DDP_WARN", "=", "\"\"\"\\n\\nDuring testing, it is currently advisable to construct a new Trainer \"\n                    \"with single GPU and no DDP to obtain accurate results.\n                    \"Following pattern should be used: \"\n                    \"trainer = Trainer(devices=1, accelerator='gpu')\n                    \"if model.prepare_test(trainer):\"\n                    \"  trainer.test(model)\\n\\n\"\"\"", "\n", "\n", "logging", ".", "warning", "(", "DDP_WARN", ")", "\n", "return", "False", "\n", "\n", "# Assign trainer to the model", "\n", "", "self", ".", "set_trainer", "(", "trainer", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.set_trainer": [[1095, 1100], ["modelPT.ModelPT.set_world_size"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.set_world_size"], ["", "def", "set_trainer", "(", "self", ",", "trainer", ":", "Trainer", ")", ":", "\n", "        ", "\"\"\"Set an instance of Trainer object.\"\"\"", "\n", "self", ".", "trainer", "=", "trainer", "\n", "self", ".", "_trainer", "=", "trainer", "\n", "self", ".", "set_world_size", "(", "self", ".", "_trainer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.set_world_size": [[1101, 1113], ["mridc.utils.app_state.AppState", "mridc.utils.app_state.AppState", "isinstance", "mridc.utils.logging.warning", "mridc.utils.logging.warning"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.warning"], ["", "def", "set_world_size", "(", "self", ",", "trainer", ":", "Trainer", ")", ":", "\n", "        ", "\"\"\"Determines the world size from the PyTorch Lightning Trainer and then updates AppState.\"\"\"", "\n", "self", ".", "world_size", "=", "1", "\n", "\n", "if", "trainer", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "trainer", ",", "Trainer", ")", ":", "\n", "                ", "if", "trainer", ".", "num_devices", "and", "trainer", ".", "num_nodes", ":", "\n", "                    ", "self", ".", "world_size", "=", "trainer", ".", "num_devices", "*", "trainer", ".", "num_nodes", "\n", "", "", "else", ":", "\n", "                ", "logging", ".", "warning", "(", "\"World size can only be set by PyTorch Lightning Trainer.\"", ")", "\n", "", "", "app_state", "=", "AppState", "(", ")", "\n", "app_state", ".", "world_size", "=", "self", ".", "world_size", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.summarize": [[1114, 1117], ["pytorch_lightning.utilities.model_summary.summarize"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.summarize"], ["", "def", "summarize", "(", "self", ",", "max_depth", ":", "int", "=", "1", ")", "->", "model_summary", ".", "ModelSummary", ":", "\n", "        ", "\"\"\"Summarize this LightningModule.\"\"\"", "\n", "return", "model_summary", ".", "summarize", "(", "self", ",", "max_depth", "=", "max_depth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._update_dataset_config": [[1118, 1148], ["hasattr", "isinstance", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.set_struct", "omegaconf.OmegaConf.set_struct", "ValueError"], "methods", ["None"], ["", "def", "_update_dataset_config", "(", "self", ",", "dataset_name", ":", "str", ",", "config", ":", "Optional", "[", "Union", "[", "DictConfig", ",", "Dict", "]", "]", ")", ":", "\n", "        ", "\"\"\"\n        Update the config (if not None) of the dataset by given name. Preserves said config after updating.\n\n        Parameters\n        ----------\n        dataset_name: str name of the dataset whose config is being updated. Can be one of `train`, `validation` and\n        `test`.\n        config: Optional DictConfig or dict. If None is passed, this method simply returns. If dict is passed, it is\n        cast into a DictConfig. The internal config is updated with the passed config.\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ",", "\"_multi_dataset_mode\"", ")", "and", "self", ".", "_multi_dataset_mode", "is", "True", ":", "\n", "            ", "return", "\n", "\n", "", "if", "config", "is", "not", "None", ":", "\n", "            ", "if", "not", "isinstance", "(", "config", ",", "DictConfig", ")", ":", "\n", "                ", "config", "=", "OmegaConf", ".", "create", "(", "config", ")", "\n", "\n", "", "if", "dataset_name", "in", "{", "\"train\"", ",", "\"validation\"", ",", "\"test\"", "}", ":", "\n", "                ", "OmegaConf", ".", "set_struct", "(", "self", ".", "cfg", ",", "False", ")", "\n", "\n", "key_name", "=", "f\"{dataset_name}_ds\"", "\n", "self", ".", "cfg", "[", "key_name", "]", "=", "config", "\n", "\n", "OmegaConf", ".", "set_struct", "(", "self", ".", "cfg", ",", "True", ")", "\n", "\n", "# Update hyperparameters by calling property setter", "\n", "self", ".", "cfg", "=", "self", ".", "_cfg", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"`dataset_name` when updating config must be one of [train, validation, test]\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.num_weights": [[1149, 1153], ["sum", "p.numel", "modelPT.ModelPT.parameters"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "num_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Utility property that returns the total number of parameters of the Model.\"\"\"", "\n", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.cfg": [[1165, 1180], ["modelPT.ModelPT._set_hparams", "omegaconf.OmegaConf.create", "hasattr", "omegaconf.OmegaConf.to_object"], "methods", ["None"], ["", "@", "cfg", ".", "setter", "\n", "def", "cfg", "(", "self", ",", "cfg", ")", ":", "\n", "        ", "\"\"\"\n        Property that holds the finalized internal config of the model.\n\n        .. note::\n            Changes to this config are not reflected in the state of the model.\n            Please create a new model using an updated config to properly update the model.\n        \"\"\"", "\n", "self", ".", "_cfg", "=", "cfg", "\n", "self", ".", "_set_hparams", "(", "OmegaConf", ".", "create", "(", "{", "\"cfg\"", ":", "self", ".", "_cfg", "}", ")", ")", "\n", "\n", "# TODO: Remove this when we have a better way to handle this", "\n", "if", "hasattr", "(", "self", ",", "\"_hparams_initial\"", ")", "and", "\"cfg\"", "in", "self", ".", "_hparams_initial", ":", "\n", "            ", "self", ".", "_hparams_initial", "[", "\"cfg\"", "]", "=", "OmegaConf", ".", "to_object", "(", "self", ".", "_cfg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._is_model_being_restored": [[1181, 1186], ["mridc.utils.app_state.AppState", "mridc.utils.app_state.AppState"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_is_model_being_restored", "(", ")", "->", "bool", ":", "\n", "        ", "\"\"\"Checks if the model is being restored from a checkpoint.\"\"\"", "\n", "app_state", "=", "AppState", "(", ")", "\n", "return", "app_state", ".", "is_model_being_restored", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._set_model_restore_state": [[1187, 1193], ["mridc.utils.app_state.AppState", "mridc.utils.app_state.AppState"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_set_model_restore_state", "(", "is_being_restored", ":", "bool", ",", "folder", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"Sets the state of the model to be restored.\"\"\"", "\n", "app_state", "=", "AppState", "(", ")", "\n", "app_state", ".", "is_model_being_restored", "=", "is_being_restored", "\n", "app_state", ".", "mridc_file_folder", "=", "folder", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._set_model_guid": [[1194, 1208], ["hasattr", "mridc.utils.app_state.AppState", "mridc.utils.app_state.AppState", "str", "modelPT.ModelPT._is_model_being_restored", "mridc.utils.app_state.AppState.register_model_guid", "mridc.utils.app_state.AppState.register_model_guid", "uuid.uuid4"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT._is_model_being_restored", "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.register_model_guid", "home.repos.pwc.inspect_result.wdika_mridc.utils.app_state.AppState.register_model_guid"], ["", "def", "_set_model_guid", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets the model guid.\"\"\"", "\n", "if", "not", "hasattr", "(", "self", ",", "\"model_guid\"", ")", ":", "\n", "            ", "appstate", "=", "AppState", "(", ")", "\n", "\n", "# Generate a unique uuid for the instance", "\n", "# also determine if the model is being restored or not, and preserve the path", "\n", "self", ".", "model_guid", "=", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "\n", "if", "self", ".", "_is_model_being_restored", "(", ")", ":", "\n", "                ", "restore_path", "=", "appstate", ".", "model_restore_path", "\n", "", "else", ":", "\n", "                ", "restore_path", "=", "None", "\n", "\n", "", "appstate", ".", "register_model_guid", "(", "self", ".", "model_guid", ",", "restoration_path", "=", "restore_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.modelPT.ModelPT.update_save_restore_connector": [[1209, 1216], ["hasattr", "setattr"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "update_save_restore_connector", "(", "cls", ",", "save_restore_connector", ")", ":", "\n", "        ", "\"\"\"Update the save_restore_connector of the model.\"\"\"", "\n", "if", "hasattr", "(", "cls", ",", "\"_save_restore_connector\"", ")", ":", "\n", "            ", "cls", ".", "_save_restore_connector", "=", "save_restore_connector", "\n", "", "else", ":", "\n", "            ", "setattr", "(", "cls", ",", "\"_save_restore_connector\"", ",", "save_restore_connector", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.num_weights": [[18, 22], ["sum", "p.numel", "module.NeuralModule.parameters"], "methods", ["None"], ["@", "property", "\n", "def", "num_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Utility property that returns the total number of parameters of NeuralModule.\"\"\"", "\n", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "self", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.input_example": [[23, 38], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "input_example", "(", "max_batch", "=", "None", ",", "max_dim", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Override this method if random inputs won't work\n\n        Parameters\n        ----------\n        max_batch: Maximum batch size to generate\n        max_dim: Maximum dimension to generate\n\n        Returns\n        -------\n        A tuple sample of valid input data.\n        \"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.freeze": [[39, 45], ["module.NeuralModule.parameters", "module.NeuralModule.eval"], "methods", ["None"], ["", "def", "freeze", "(", "self", ")", "->", "None", ":", "\n", "        ", "r\"\"\"Freeze all params for inference.\"\"\"", "\n", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "self", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.unfreeze": [[46, 52], ["module.NeuralModule.parameters", "module.NeuralModule.train"], "methods", ["None"], ["", "def", "unfreeze", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Unfreeze all parameters for training.\"\"\"", "\n", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "True", "\n", "\n", "", "self", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.as_frozen": [[53, 72], ["module.NeuralModule.freeze", "module.NeuralModule.named_parameters", "module.NeuralModule.unfreeze", "module.NeuralModule.train", "module.NeuralModule.eval", "module.NeuralModule.named_parameters"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.freeze", "home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.unfreeze"], ["", "@", "contextmanager", "\n", "def", "as_frozen", "(", "self", ")", ":", "\n", "        ", "\"\"\"Context manager which temporarily freezes a module, yields control and finally unfreezes the module.\"\"\"", "\n", "training_mode", "=", "self", ".", "training", "\n", "grad_map", "=", "{", "pname", ":", "param", ".", "requires_grad", "for", "pname", ",", "param", "in", "self", ".", "named_parameters", "(", ")", "}", "\n", "\n", "self", ".", "freeze", "(", ")", "\n", "try", ":", "\n", "            ", "yield", "\n", "", "finally", ":", "\n", "            ", "self", ".", "unfreeze", "(", ")", "\n", "\n", "", "for", "pname", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "grad_map", "[", "pname", "]", "\n", "\n", "", "if", "training_mode", ":", "\n", "            ", "self", ".", "train", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "eval", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.classes.dataset.Dataset._collate_fn": [[19, 26], ["torch.utils.data.dataloader.default_collate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.classes.dataset.Dataset.collate_fn": [[27, 54], ["mridc.core.classes.common.typecheck", "dataset.Dataset._collate_fn", "TypeError"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.dataset.IterableDataset._collate_fn"], ["\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "datasets", ":", "List", "[", "Any", "]", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "sampling_technique", ":", "str", "=", "\"random\"", ",", "\n", "sampling_probabilities", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "global_rank", ":", "int", "=", "0", ",", "\n", "world_size", ":", "int", "=", "1", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "datasets", "=", "datasets", "\n", "self", ".", "iterables", "=", "[", "None", "]", "*", "len", "(", "datasets", ")", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "global_rank", "=", "global_rank", "\n", "self", ".", "world_size", "=", "world_size", "\n", "self", ".", "sampling_kwargs", "=", "{", "}", "\n", "if", "sampling_technique", "==", "\"random\"", ":", "\n", "            ", "self", ".", "index_generator", "=", "ConcatDataset", ".", "random_generator", "\n", "self", ".", "sampling_kwargs", "[", "\"p\"", "]", "=", "sampling_probabilities", "# type: ignore", "\n", "", "elif", "sampling_technique", "==", "\"round-robin\"", ":", "\n", "            ", "self", ".", "index_generator", "=", "ConcatDataset", ".", "round_robin_generator", "\n", "", "else", ":", "\n", "            ", "supported_sampling_techniques", "=", "[", "\"random\"", ",", "\"round-robin\"", "]", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.dataset.IterableDataset._collate_fn": [[62, 69], ["torch.utils.data.dataloader.default_collate"], "methods", ["None"], ["\n", "", "for", "dataset", "in", "datasets", ":", "\n", "            ", "isiterable", "=", "isinstance", "(", "dataset", ",", "pt_data", ".", "IterableDataset", ")", "\n", "if", "isiterable", "and", "self", ".", "kind", "!=", "\"iterable\"", "or", "(", "not", "isiterable", "and", "self", ".", "kind", "==", "\"iterable\"", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"All datasets in ConcatDataset must be of the same kind (Iterable or Map).\"", ")", "\n", "\n", "", "if", "self", ".", "kind", "==", "\"map\"", ":", "\n", "                ", "self", ".", "length", "+=", "np", ".", "floor_divide", "(", "len", "(", "dataset", ")", ",", "world_size", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.dataset.IterableDataset.collate_fn": [[70, 95], ["mridc.core.classes.common.typecheck", "dataset.IterableDataset._collate_fn", "TypeError"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.dataset.IterableDataset._collate_fn"], ["", "else", ":", "\n", "                ", "self", ".", "length", "+=", "len", "(", "dataset", ")", "\n", "\n", "", "", "", "def", "get_iterable", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"Returns an iterable dataset.\"\"\"", "\n", "if", "isinstance", "(", "dataset", ",", "pt_data", ".", "IterableDataset", ")", ":", "\n", "            ", "return", "dataset", ".", "__iter__", "(", ")", "\n", "", "indices", "=", "np", ".", "arange", "(", "len", "(", "dataset", ")", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "indices", ")", "\n", "", "return", "iter", "(", "indices", ")", "\n", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns an iterator over the dataset.\"\"\"", "\n", "worker_info", "=", "pt_data", ".", "get_worker_info", "(", ")", "\n", "if", "worker_info", "is", "None", ":", "\n", "            ", "max_elements", "=", "self", ".", "length", "\n", "wid", "=", "0", "\n", "wnum", "=", "1", "\n", "", "else", ":", "\n", "            ", "wid", "=", "worker_info", ".", "id", "\n", "wnum", "=", "worker_info", ".", "num_workers", "\n", "max_elements", "=", "len", "(", "range", "(", "wid", ",", "self", ".", "length", ",", "wnum", ")", ")", "\n", "\n", "", "if", "self", ".", "kind", "==", "\"map\"", ":", "\n", "            ", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "datasets", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable.input_module": [[32, 35], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "input_module", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable.output_module": [[36, 39], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_module", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable.export": [[40, 172], ["locals().copy", "locals().copy.pop", "export.Exportable.modules", "mridc.utils.export_utils.get_export_format", "isinstance", "mridc.core.classes.common.typecheck.set_typecheck_enabled", "mridc.utils.export_utils.wrap_forward_method", "mridc.core.classes.common.typecheck.set_typecheck_enabled", "export.Exportable._export_teardown", "locals", "exportables.append", "torch.onnx.select_model_mode_for_export", "torch.inference_mode", "torch.jit.optimized_execution", "locals().copy.pop", "locals().copy.pop", "export.Exportable._prepare_for_export", "mridc.utils.export_utils.parse_input_example", "tuple", "export.Exportable.input_module.input_example", "ex._prepare_for_export", "export.Exportable.forward", "export.Exportable.save", "type", "torch.jit.script", "torch.jit.trace_module", "torch.jit.optimize_for_inference", "mridc.utils.logging.info", "torch.onnx.export", "ValueError", "mridc.utils.logging.error", "mridc.core.utils.neural_type_utils.get_dynamic_axes", "mridc.core.utils.neural_type_utils.get_dynamic_axes.update", "mridc.utils.export_utils.verify_runtime", "mridc.core.utils.neural_type_utils.get_dynamic_axes", "tuple", "tuple", "input_dict.values"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable._export_teardown", "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable._prepare_for_export", "home.repos.pwc.inspect_result.wdika_mridc.classes.module.NeuralModule.input_example", "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable._prepare_for_export", "home.repos.pwc.inspect_result.wdika_mridc.losses.ssim.SSIMLoss.forward", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.info", "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable.export", "home.repos.pwc.inspect_result.wdika_mridc.utils.mridc_logging.Logger.error", "home.repos.pwc.inspect_result.wdika_mridc.utils.neural_type_utils.get_dynamic_axes", "home.repos.pwc.inspect_result.wdika_mridc.metrics.global_average_loss_metric.GlobalAverageLossMetric.update", "home.repos.pwc.inspect_result.wdika_mridc.utils.neural_type_utils.get_dynamic_axes"], ["", "def", "export", "(", "\n", "self", ",", "\n", "output", ":", "str", ",", "\n", "input_example", "=", "None", ",", "\n", "verbose", "=", "False", ",", "\n", "export_params", "=", "True", ",", "\n", "do_constant_folding", "=", "True", ",", "\n", "onnx_opset_version", "=", "None", ",", "\n", "try_script", ":", "bool", "=", "False", ",", "\n", "training", "=", "TrainingMode", ".", "EVAL", ",", "\n", "check_trace", ":", "bool", "=", "False", ",", "\n", "use_dynamic_axes", ":", "bool", "=", "True", ",", "\n", "dynamic_axes", "=", "None", ",", "\n", "check_tolerance", "=", "0.01", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Export the module to a file.\n\n        Parameters\n        ----------\n        output: The output file path.\n        input_example: A dictionary of input names and values.\n        verbose: If True, print out the export process.\n        export_params: If True, export the parameters of the module.\n        do_constant_folding: If True, do constant folding.\n        onnx_opset_version: The ONNX opset version to use.\n        try_script: If True, try to export as TorchScript.\n        training: Training mode for the export.\n        check_trace: If True, check the trace of the exported model.\n        use_dynamic_axes: If True, use dynamic axes for the export.\n        dynamic_axes: A dictionary of input names and dynamic axes.\n        check_tolerance: The tolerance for the check_trace.\n        \"\"\"", "\n", "my_args", "=", "locals", "(", ")", ".", "copy", "(", ")", "\n", "my_args", ".", "pop", "(", "\"self\"", ")", "\n", "\n", "exportables", "=", "[", "]", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "# type: ignore", "\n", "            ", "if", "isinstance", "(", "m", ",", "Exportable", ")", ":", "\n", "                ", "exportables", ".", "append", "(", "m", ")", "\n", "\n", "", "", "qual_name", "=", "self", ".", "__module__", "+", "\".\"", "+", "self", ".", "__class__", ".", "__qualname__", "\n", "format", "=", "get_export_format", "(", "output", ")", "\n", "output_descr", "=", "f\"{qual_name} exported to {format}\"", "\n", "\n", "# Pytorch's default for None is too low, can't pass None through", "\n", "if", "onnx_opset_version", "is", "None", ":", "\n", "            ", "onnx_opset_version", "=", "13", "\n", "\n", "", "try", ":", "\n", "# Disable typechecks", "\n", "            ", "typecheck", ".", "set_typecheck_enabled", "(", "enabled", "=", "False", ")", "\n", "\n", "# Allow user to completely override forward method to export", "\n", "forward_method", ",", "old_forward_method", "=", "wrap_forward_method", "(", "self", ")", "\n", "\n", "# Set module mode", "\n", "with", "torch", ".", "onnx", ".", "select_model_mode_for_export", "(", "\n", "self", ",", "training", "\n", ")", ",", "torch", ".", "inference_mode", "(", ")", ",", "torch", ".", "jit", ".", "optimized_execution", "(", "True", ")", ":", "\n", "\n", "                ", "if", "input_example", "is", "None", ":", "\n", "                    ", "input_example", "=", "self", ".", "input_module", ".", "input_example", "(", ")", "\n", "\n", "# Remove i/o examples from args we propagate to enclosed Exportables", "\n", "", "my_args", ".", "pop", "(", "\"output\"", ")", "\n", "my_args", ".", "pop", "(", "\"input_example\"", ")", "\n", "\n", "# Run (possibly overridden) prepare methods before calling forward()", "\n", "for", "ex", "in", "exportables", ":", "\n", "                    ", "ex", ".", "_prepare_for_export", "(", "**", "my_args", ",", "noreplace", "=", "True", ")", "\n", "", "self", ".", "_prepare_for_export", "(", "output", "=", "output", ",", "input_example", "=", "input_example", ",", "**", "my_args", ")", "\n", "\n", "input_list", ",", "input_dict", "=", "parse_input_example", "(", "input_example", ")", "\n", "input_names", "=", "self", ".", "input_names", "\n", "output_names", "=", "self", ".", "output_names", "\n", "output_example", "=", "tuple", "(", "self", ".", "forward", "(", "*", "input_list", ",", "**", "input_dict", ")", ")", "# type: ignore", "\n", "\n", "jitted_model", "=", "None", "\n", "if", "try_script", ":", "\n", "                    ", "try", ":", "\n", "                        ", "jitted_model", "=", "torch", ".", "jit", ".", "script", "(", "self", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                        ", "logging", ".", "error", "(", "f\"jit.script() failed!\\n{e}\"", ")", "\n", "\n", "", "", "if", "format", "==", "ExportFormat", ".", "TORCHSCRIPT", ":", "\n", "                    ", "if", "jitted_model", "is", "None", ":", "\n", "                        ", "jitted_model", "=", "torch", ".", "jit", ".", "trace_module", "(", "\n", "self", ",", "\n", "{", "\"forward\"", ":", "tuple", "(", "input_list", ")", "+", "tuple", "(", "input_dict", ".", "values", "(", ")", ")", "}", ",", "\n", "strict", "=", "True", ",", "\n", "check_trace", "=", "check_trace", ",", "\n", "check_tolerance", "=", "check_tolerance", ",", "\n", ")", "\n", "", "if", "not", "self", ".", "training", ":", "# type: ignore", "\n", "                        ", "jitted_model", "=", "torch", ".", "jit", ".", "optimize_for_inference", "(", "jitted_model", ")", "\n", "", "if", "verbose", ":", "\n", "                        ", "logging", ".", "info", "(", "f\"JIT code:\\n{jitted_model.code}\"", ")", "\n", "", "jitted_model", ".", "save", "(", "output", ")", "\n", "", "elif", "format", "==", "ExportFormat", ".", "ONNX", ":", "\n", "                    ", "if", "jitted_model", "is", "None", ":", "\n", "                        ", "jitted_model", "=", "self", "\n", "\n", "# dynamic axis is a mapping from input/output_name => list of \"dynamic\" indices", "\n", "", "if", "dynamic_axes", "is", "None", "and", "use_dynamic_axes", ":", "\n", "                        ", "dynamic_axes", "=", "get_dynamic_axes", "(", "self", ".", "input_module", ".", "input_types", ",", "input_names", ")", "\n", "dynamic_axes", ".", "update", "(", "get_dynamic_axes", "(", "self", ".", "output_module", ".", "output_types", ",", "output_names", ")", ")", "\n", "\n", "", "torch", ".", "onnx", ".", "export", "(", "\n", "jitted_model", ",", "\n", "input_example", ",", "\n", "output", ",", "\n", "input_names", "=", "input_names", ",", "\n", "output_names", "=", "output_names", ",", "\n", "verbose", "=", "verbose", ",", "\n", "export_params", "=", "export_params", ",", "\n", "do_constant_folding", "=", "do_constant_folding", ",", "\n", "dynamic_axes", "=", "dynamic_axes", ",", "\n", "opset_version", "=", "onnx_opset_version", ",", "\n", ")", "\n", "\n", "if", "check_trace", ":", "\n", "                        ", "verify_runtime", "(", "output", ",", "input_list", ",", "input_dict", ",", "input_names", ",", "output_names", ",", "output_example", ")", "\n", "\n", "", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"Encountered unknown export format {format}.\"", ")", "\n", "", "", "", "finally", ":", "\n", "            ", "typecheck", ".", "set_typecheck_enabled", "(", "enabled", "=", "True", ")", "\n", "if", "forward_method", ":", "\n", "                ", "type", "(", "self", ")", ".", "forward", "=", "old_forward_method", "# type: ignore", "\n", "", "self", ".", "_export_teardown", "(", ")", "\n", "", "return", "[", "output", "]", ",", "[", "output_descr", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable.disabled_deployment_input_names": [[173, 177], ["set"], "methods", ["None"], ["", "@", "property", "\n", "def", "disabled_deployment_input_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"Implement this method to return a set of input names disabled for export\"\"\"", "\n", "return", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable.disabled_deployment_output_names": [[178, 182], ["set"], "methods", ["None"], ["", "@", "property", "\n", "def", "disabled_deployment_output_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"Implement this method to return a set of output names disabled for export\"\"\"", "\n", "return", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable.supported_export_formats": [[183, 187], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "supported_export_formats", "(", "self", ")", ":", "\n", "        ", "\"\"\"Implement this method to return a set of export formats supported. Default is all types.\"\"\"", "\n", "return", "{", "ExportFormat", ".", "ONNX", ",", "ExportFormat", ".", "TORCHSCRIPT", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable._prepare_for_export": [[188, 195], ["mridc.utils.export_utils.replace_for_export"], "methods", ["None"], ["", "def", "_prepare_for_export", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Override this method to prepare module for export. This is in-place operation.\n        Base version does common necessary module replacements (Apex etc)\n        \"\"\"", "\n", "if", "\"noreplace\"", "not", "in", "kwargs", ":", "\n", "            ", "replace_for_export", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable._export_teardown": [[196, 200], ["None"], "methods", ["None"], ["", "", "def", "_export_teardown", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Override this method for any teardown code after export.\n        \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable.input_names": [[201, 205], ["mridc.core.utils.neural_type_utils.get_io_names"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.neural_type_utils.get_io_names"], ["", "@", "property", "\n", "def", "input_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"Implement this method to return a list of input names\"\"\"", "\n", "return", "get_io_names", "(", "self", ".", "input_module", ".", "input_types", ",", "self", ".", "disabled_deployment_input_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.classes.export.Exportable.output_names": [[206, 210], ["mridc.core.utils.neural_type_utils.get_io_names"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.utils.neural_type_utils.get_io_names"], ["", "@", "property", "\n", "def", "output_names", "(", "self", ")", ":", "\n", "        ", "\"\"\"Override this method to return a set of output names disabled for export\"\"\"", "\n", "return", "get_io_names", "(", "self", ".", "output_module", ".", "output_types", ",", "self", ".", "disabled_deployment_output_names", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.conf.schedulers.register_scheduler_params": [[159, 173], ["ValueError"], "function", ["None"], ["", "def", "register_scheduler_params", "(", "name", ":", "str", ",", "scheduler_params", ":", "SchedulerParams", ")", ":", "\n", "    ", "\"\"\"\n    Checks if the scheduler config name exists in the registry, and if it doesn't, adds it.\n    This allows custom schedulers to be added and called by name during instantiation.\n\n    Parameters\n    ----------\n    name: Name of the optimizer. Will be used as key to retrieve the optimizer.\n    scheduler_params: SchedulerParams class\n    \"\"\"", "\n", "if", "name", "in", "AVAILABLE_SCHEDULER_PARAMS", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Cannot override pre-existing optimizers. Conflicting optimizer name = {name}\"", ")", "\n", "\n", "", "AVAILABLE_SCHEDULER_PARAMS", "[", "name", "]", "=", "scheduler_params", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.conf.schedulers.get_scheduler_config": [[175, 195], ["functools.partial", "ValueError", "AVAILABLE_SCHEDULER_PARAMS.keys"], "function", ["None"], ["", "def", "get_scheduler_config", "(", "name", ":", "str", ",", "**", "kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", ")", "->", "partial", ":", "\n", "    ", "\"\"\"\n    Convenience method to obtain a SchedulerParams class and partially instantiate it with optimizer kwargs.\n\n    Parameters\n    ----------\n    name: Name of the SchedulerParams in the registry.\n    kwargs: Optional kwargs of the optimizer used during instantiation.\n\n    Returns\n    -------\n    A partially instantiated SchedulerParams.\n    \"\"\"", "\n", "if", "name", "not", "in", "AVAILABLE_SCHEDULER_PARAMS", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Cannot resolve scheduler parameters '{name}'. Available scheduler parameters are : \"", "\n", "f\"{AVAILABLE_SCHEDULER_PARAMS.keys()}\"", "\n", ")", "\n", "\n", "", "return", "partial", "(", "AVAILABLE_SCHEDULER_PARAMS", "[", "name", "]", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.conf.modelPT.ModelConfigBuilder.__init__": [[73, 136], ["None"], "methods", ["None"], ["app_state", "=", "AppState", "(", ")", "\n", "\n", "# Convert config to a DictConfig", "\n", "cfg", "=", "mridc", ".", "utils", ".", "model_utils", ".", "convert_model_config_to_dict_config", "(", "cfg", ")", "\n", "\n", "# Convert config to support Hydra 1.0+ instantiation", "\n", "cfg", "=", "mridc", ".", "utils", ".", "model_utils", ".", "maybe_update_config_version", "(", "cfg", ")", "\n", "\n", "if", "\"model\"", "in", "cfg", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Creating model config node is forbidden due to collision problem when loading from checkpoint.\"", "\n", ")", "\n", "\n", "", "if", "\"target\"", "not", "in", "cfg", ":", "\n", "# This is for Jarvis service.", "\n", "            ", "OmegaConf", ".", "set_struct", "(", "cfg", ",", "False", ")", "\n", "cfg", ".", "target", "=", "\"{0}.{1}\"", ".", "format", "(", "self", ".", "__class__", ".", "__module__", ",", "self", ".", "__class__", ".", "__name__", ")", "\n", "OmegaConf", ".", "set_struct", "(", "cfg", ",", "True", ")", "\n", "\n", "", "if", "\"mridc_version\"", "not", "in", "cfg", ":", "\n", "            ", "with", "open_dict", "(", "cfg", ")", ":", "\n", "                ", "cfg", ".", "mridc_version", "=", "package_info", ".", "__version__", "\n", "\n", "", "", "self", ".", "_cfg", "=", "cfg", "\n", "\n", "self", ".", "save_hyperparameters", "(", "\"cfg\"", ")", "\n", "self", ".", "_train_dl", "=", "None", "\n", "self", ".", "_validation_dl", "=", "None", "\n", "self", ".", "_test_dl", "=", "None", "\n", "self", ".", "_optimizer_param_groups", "=", "None", "\n", "self", ".", "_optimizer", "=", "None", "\n", "self", ".", "_scheduler", "=", "None", "\n", "self", ".", "trainer", "=", "trainer", "# reference required for self.*_rank", "\n", "self", ".", "_trainer", "=", "self", ".", "trainer", "# alias for backward compatibility", "\n", "self", ".", "_save_restore_connector", "=", "SaveRestoreConnector", "(", ")", "\n", "\n", "self", ".", "_set_model_guid", "(", ")", "\n", "\n", "# Set device_id in AppState", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "torch", ".", "cuda", ".", "current_device", "(", ")", "is", "not", "None", ":", "\n", "            ", "app_state", ".", "device_id", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "\n", "", "if", "self", ".", "_cfg", "is", "not", "None", "and", "not", "self", ".", "_is_model_being_restored", "(", ")", ":", "\n", "            ", "if", "\"train_ds\"", "in", "self", ".", "_cfg", "and", "self", ".", "_cfg", ".", "train_ds", "is", "not", "None", ":", "\n", "                ", "self", ".", "setup_training_data", "(", "self", ".", "_cfg", ".", "train_ds", ")", "\n", "\n", "", "if", "\"validation_ds\"", "in", "self", ".", "_cfg", "and", "self", ".", "_cfg", ".", "validation_ds", "is", "not", "None", ":", "\n", "                ", "self", ".", "setup_multiple_validation_data", "(", "self", ".", "_cfg", ".", "validation_ds", ")", "# type: ignore", "\n", "\n", "", "if", "\"test_ds\"", "in", "self", ".", "_cfg", "and", "self", ".", "_cfg", ".", "test_ds", "is", "not", "None", ":", "\n", "                ", "self", ".", "setup_multiple_test_data", "(", "test_data_config", "=", "None", ")", "# type: ignore", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "\"train_ds\"", "in", "self", ".", "_cfg", "and", "self", ".", "_cfg", ".", "train_ds", "is", "not", "None", ":", "# type: ignore", "\n", "                ", "logging", ".", "warning", "(", "\n", "\"If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() \"", "\n", "\"method and provide a valid configuration file to setup the train data loader.\\n\"", "\n", "f\"Train config : \\n{OmegaConf.to_yaml(self._cfg.train_ds)}\"", "# type: ignore", "\n", ")", "\n", "", "if", "\"validation_ds\"", "in", "self", ".", "_cfg", "and", "self", ".", "_cfg", ".", "validation_ds", "is", "not", "None", ":", "# type: ignore", "\n", "                ", "logging", ".", "warning", "(", "\n", "\"If you intend to do validation, please call the ModelPT.setup_validation_data() or \"", "\n", "\"ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to \"", "\n", "\"setup the validation data loader(s). \\n\"", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.conf.modelPT.ModelConfigBuilder.set_train_ds": [[137, 140], ["None"], "methods", ["None"], ["f\"Validation config : \\n{OmegaConf.to_yaml(self._cfg.validation_ds)}\"", "# type: ignore", "\n", ")", "\n", "", "if", "\"test_ds\"", "in", "self", ".", "_cfg", "and", "self", ".", "_cfg", ".", "test_ds", "is", "not", "None", ":", "# type: ignore", "\n", "                ", "logging", ".", "warning", "(", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.conf.modelPT.ModelConfigBuilder.set_validation_ds": [[141, 144], ["None"], "methods", ["None"], ["\"Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method \"", "\n", "\"and provide a valid configuration file to setup the test data loader(s).\\n\"", "\n", "f\"Test config : \\n{OmegaConf.to_yaml(self._cfg.test_ds)}\"", "# type: ignore", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.conf.modelPT.ModelConfigBuilder.set_test_ds": [[145, 148], ["None"], "methods", ["None"], ["\n", "# ModelPT wrappers over subclass implementations", "\n", "", "", "self", ".", "_training_step", "=", "mridc", ".", "utils", ".", "model_utils", ".", "wrap_training_step", "(", "self", ".", "training_step", ")", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.conf.modelPT.ModelConfigBuilder.set_optim": [[149, 173], ["cfg.__class__.__name__.replace().lower", "WrappedOptimConfig", "sched_cfg.__class__.__name__.replace", "WrappedSchedConfig", "cfg.__class__.__name__.replace", "vars", "vars"], "methods", ["None"], ["", "def", "__init_subclass__", "(", "cls", ")", "->", "None", ":", "\n", "        ", "\"\"\"This method is called when a subclass is created.\"\"\"", "\n", "cls", ".", "_save_restore_connector", "=", "SaveRestoreConnector", "(", ")", "\n", "\n", "", "def", "register_artifact", "(", "self", ",", "config_path", ":", "str", ",", "src", ":", "str", ",", "verify_src_exists", ":", "bool", "=", "True", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.wdika_mridc.conf.modelPT.ModelConfigBuilder._finalize_cfg": [[174, 177], ["NotImplementedError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.conf.modelPT.ModelConfigBuilder.build": [[178, 183], ["modelPT.ModelConfigBuilder._finalize_cfg"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.conf.modelPT.ModelConfigBuilder._finalize_cfg"], ["\n", "if", "src", "is", "None", "or", "not", "src", ":", "\n", "            ", "return", "src", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.conf.hydra_runner.hydra_runner": [[21, 115], ["functools.wraps", "hydra._internal.utils.get_args_parser", "hydra._internal.utils.get_args_parser.parse_args", "overrides.append", "overrides.append", "overrides.append", "hydra._internal.utils._run_hydra", "task_function", "hydra.core.config_store.ConfigStore.instance", "ConfigStore.instance.store", "os.path.split", "_argparse_wrapper", "sys.stderr.write", "sys.exit"], "function", ["None"], ["def", "hydra_runner", "(", "\n", "config_path", ":", "Optional", "[", "str", "]", "=", "\".\"", ",", "config_name", ":", "Optional", "[", "str", "]", "=", "None", ",", "schema", ":", "Optional", "[", "Any", "]", "=", "None", "\n", ")", "->", "Callable", "[", "[", "TaskFunction", "]", ",", "Any", "]", ":", "\n", "    ", "\"\"\"\n    Decorator used for passing the Config paths to main function.\n    Optionally registers a schema used for validation/providing default values.\n\n    Parameters\n    ----------\n    config_path: Path to the config file.\n    config_name: Name of the config file.\n    schema: Schema used for validation/providing default values.\n\n    Returns\n    -------\n    A decorator that passes the config paths to the main function.\n    \"\"\"", "\n", "\n", "def", "decorator", "(", "task_function", ":", "TaskFunction", ")", "->", "Callable", "[", "[", "]", ",", "None", "]", ":", "\n", "        ", "\"\"\"Decorator that passes the config paths to the main function.\"\"\"", "\n", "\n", "@", "functools", ".", "wraps", "(", "task_function", ")", "\n", "def", "wrapper", "(", "cfg_passthrough", ":", "Optional", "[", "DictConfig", "]", "=", "None", ")", "->", "Any", ":", "\n", "            ", "\"\"\"Wrapper that passes the config paths to the main function.\"\"\"", "\n", "# Check it config was passed.", "\n", "if", "cfg_passthrough", "is", "not", "None", ":", "\n", "                ", "return", "task_function", "(", "cfg_passthrough", ")", "\n", "", "args", "=", "get_args_parser", "(", ")", "\n", "\n", "# Parse arguments in order to retrieve overrides", "\n", "parsed_args", ":", "Namespace", "=", "args", ".", "parse_args", "(", ")", "\n", "\n", "# Get overriding args in dot string format", "\n", "overrides", "=", "parsed_args", ".", "overrides", "# type: list", "\n", "\n", "# Disable the creation of .hydra subdir", "\n", "# https://hydra.cc/docs/tutorials/basic/running_your_app/working_directory", "\n", "overrides", ".", "append", "(", "\"hydra.output_subdir=null\"", ")", "\n", "# Hydra logging outputs only to stdout (no log file).", "\n", "# https://hydra.cc/docs/configure_hydra/logging", "\n", "overrides", ".", "append", "(", "\"hydra/job_logging=stdout\"", ")", "\n", "\n", "# Set run.dir ONLY for ExpManager \"compatibility\" - to be removed.", "\n", "overrides", ".", "append", "(", "\"hydra.run.dir=.\"", ")", "\n", "\n", "# Check if user set the schema.", "\n", "if", "schema", "is", "not", "None", ":", "\n", "# Create config store.", "\n", "                ", "cs", "=", "ConfigStore", ".", "instance", "(", ")", "\n", "\n", "# Get the correct ConfigStore \"path name\" to \"inject\" the schema.", "\n", "if", "parsed_args", ".", "config_name", "is", "not", "None", ":", "\n", "                    ", "path", ",", "name", "=", "os", ".", "path", ".", "split", "(", "parsed_args", ".", "config_name", ")", "\n", "# Make sure the path is not set - as this will disable validation scheme.", "\n", "if", "path", "!=", "\"\"", ":", "\n", "                        ", "sys", ".", "stderr", ".", "write", "(", "\n", "\"ERROR Cannot set config file path using `--config-name` when \"", "\n", "\"using schema. Please set path using `--config-path` and file name using \"", "\n", "\"`--config-name` separately.\\n\"", "\n", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "", "else", ":", "\n", "                    ", "name", "=", "config_name", "\n", "\n", "# Register the configuration as a node under the name in the group.", "\n", "", "cs", ".", "store", "(", "name", "=", "name", ",", "node", "=", "schema", ")", "# group=group,", "\n", "\n", "# Wrap a callable object with name `parse_args`", "\n", "# This is to mimic the ArgParser.parse_args() API.", "\n", "", "class", "_argparse_wrapper", ":", "\n", "                ", "\"\"\"Wrapper for ArgParser.parse_args().\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "arg_parser", ")", ":", "\n", "                    ", "self", ".", "arg_parser", "=", "arg_parser", "\n", "self", ".", "_actions", "=", "arg_parser", ".", "_actions", "\n", "\n", "", "@", "staticmethod", "\n", "def", "parse_args", "(", "args", "=", "None", ",", "namespace", "=", "None", ")", ":", "\n", "                    ", "\"\"\"Parse arguments.\"\"\"", "\n", "return", "parsed_args", "\n", "\n", "# no return value from run_hydra() as it may sometime actually run the task_function", "\n", "# multiple times (--multirun)", "\n", "\n", "", "", "_run_hydra", "(", "\n", "args_parser", "=", "_argparse_wrapper", "(", "args", ")", ",", "# type: ignore", "\n", "task_function", "=", "task_function", ",", "\n", "config_path", "=", "config_path", ",", "\n", "config_name", "=", "config_name", ",", "\n", ")", "\n", "\n", "", "return", "wrapper", "\n", "\n", "", "return", "decorator", "\n", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.conf.optimizers.register_optimizer_params": [[214, 228], ["ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.conf.optimizers.get_optimizer_config": [[230, 262], ["functools.partial", "ValueError", "omegaconf.OmegaConf.create", "omegaconf.OmegaConf.merge", "functools.partial.", "AVAILABLE_OPTIMIZER_PARAMS.keys"], "function", ["None"], []], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.elements.ElementType.__str__": [[48, 51], ["None"], "methods", ["None"], ["def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Override this method to provide a human readable representation of the type\"\"\"", "\n", "return", "self", ".", "__doc__", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.elements.ElementType.__repr__": [[52, 55], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Override this method to provide a human readable representation of the type\"\"\"", "\n", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.elements.ElementType.type_parameters": [[56, 65], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "type_parameters", "(", "self", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"\n        Override this property to parametrize your type. For example, you can specify 'storage' type such as float,\n        int, bool with 'dtype' keyword. Another example, is if you want to represent a signal with a particular\n        property (say, sample frequency), then you can put sample_freq->value in there. When two types are compared\n        their type_parameters must match.\"\n        \"\"\"", "\n", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.elements.ElementType.fields": [[66, 75], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "fields", "(", "self", ")", "->", "Optional", "[", "Tuple", "]", ":", "\n", "        ", "\"\"\"\n        This should be used to logically represent tuples/structures. For example, if you want to represent a \\\n        bounding box (x, y, width, height) you can put a tuple with names ('x', y', 'w', 'h') in here. Under the \\\n        hood this should be converted to the last tensor dimension of fixed size = len(fields). When two types are \\\n        compared their fields must match.\n        \"\"\"", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.elements.ElementType.compare": [[76, 107], ["type", "type", "elements.ElementType.type_parameters.items", "issubclass", "set", "set", "issubclass", "elements.ElementType.type_parameters.keys", "second.type_parameters.keys"], "methods", ["None"], ["", "def", "compare", "(", "self", ",", "second", ")", "->", "NeuralTypeComparisonResult", ":", "\n", "        ", "\"\"\"Override this method to provide a comparison between two types.\"\"\"", "\n", "# First, check general compatibility", "\n", "first_t", "=", "type", "(", "self", ")", "\n", "second_t", "=", "type", "(", "second", ")", "\n", "\n", "if", "first_t", "==", "second_t", ":", "\n", "            ", "result", "=", "NeuralTypeComparisonResult", ".", "SAME", "\n", "", "elif", "issubclass", "(", "first_t", ",", "second_t", ")", ":", "\n", "            ", "result", "=", "NeuralTypeComparisonResult", ".", "LESS", "\n", "", "elif", "issubclass", "(", "second_t", ",", "first_t", ")", ":", "\n", "            ", "result", "=", "NeuralTypeComparisonResult", ".", "GREATER", "\n", "", "else", ":", "\n", "            ", "result", "=", "NeuralTypeComparisonResult", ".", "INCOMPATIBLE", "\n", "\n", "", "if", "result", "!=", "NeuralTypeComparisonResult", ".", "SAME", ":", "\n", "            ", "return", "result", "\n", "# now check that all parameters match", "\n", "", "check_params", "=", "set", "(", "self", ".", "type_parameters", ".", "keys", "(", ")", ")", "==", "set", "(", "second", ".", "type_parameters", ".", "keys", "(", ")", ")", "\n", "if", "not", "check_params", ":", "\n", "            ", "return", "NeuralTypeComparisonResult", ".", "SAME_TYPE_INCOMPATIBLE_PARAMS", "\n", "", "for", "k1", ",", "v1", "in", "self", ".", "type_parameters", ".", "items", "(", ")", ":", "\n", "            ", "if", "v1", "is", "None", "or", "second", ".", "type_parameters", "[", "k1", "]", "is", "None", ":", "\n", "# Treat None as Void", "\n", "                ", "continue", "\n", "", "if", "v1", "!=", "second", ".", "type_parameters", "[", "k1", "]", ":", "\n", "                ", "return", "NeuralTypeComparisonResult", ".", "SAME_TYPE_INCOMPATIBLE_PARAMS", "\n", "# check that all fields match", "\n", "", "", "if", "self", ".", "fields", "==", "second", ".", "fields", ":", "\n", "            ", "return", "NeuralTypeComparisonResult", ".", "SAME", "\n", "", "return", "NeuralTypeComparisonResult", ".", "INCOMPATIBLE", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.elements.VoidType.compare": [[115, 118], ["None"], "methods", ["None"], ["def", "compare", "(", "cls", ",", "second", ":", "ABCMeta", ")", "->", "NeuralTypeComparisonResult", ":", "\n", "        ", "\"\"\"Void type is compatible with everything.\"\"\"", "\n", "return", "NeuralTypeComparisonResult", ".", "SAME", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.elements.MRISignal.__init__": [[154, 156], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "freq", ":", "int", "=", "None", ")", ":", "\n", "        ", "self", ".", "_params", "=", "{", "\"freq\"", ":", "freq", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.elements.MRISignal.type_parameters": [[157, 161], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "type_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the type parameters of the element type.\"\"\"", "\n", "return", "self", ".", "_params", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.axes.AxisKind.__repr__": [[39, 42], ["axes.AxisKind.__str__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.__str__"], ["def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns short string representation of the AxisKind\"\"\"", "\n", "return", "self", ".", "__str__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.axes.AxisKind.__str__": [[43, 46], ["str().lower", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns short string representation of the AxisKind\"\"\"", "\n", "return", "str", "(", "self", ".", "name", ")", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.axes.AxisKind.t_with_string": [[47, 50], ["text.startswith", "text.endswith", "axes.AxisKind.__str__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.__str__"], ["", "def", "t_with_string", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"It checks if text is 't_<any string>'\"\"\"", "\n", "return", "text", ".", "startswith", "(", "\"t_\"", ")", "and", "text", ".", "endswith", "(", "\"_\"", ")", "and", "text", "[", "2", ":", "-", "1", "]", "==", "self", ".", "__str__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.axes.AxisKind.from_str": [[51, 74], ["label.lower().strip", "ValueError", "label.lower", "label.lower().strip.startswith", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "from_str", "(", "label", ")", ":", "\n", "        ", "\"\"\"Returns AxisKind instance based on short string representation\"\"\"", "\n", "_label", "=", "label", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "if", "_label", "in", "(", "\"b\"", ",", "\"n\"", ",", "\"batch\"", ")", ":", "\n", "            ", "return", "AxisKind", ".", "Batch", "\n", "", "if", "_label", "==", "\"t\"", "or", "_label", "==", "\"time\"", "or", "(", "len", "(", "_label", ")", ">", "2", "and", "_label", ".", "startswith", "(", "\"t_\"", ")", ")", ":", "\n", "            ", "return", "AxisKind", ".", "Time", "\n", "", "if", "_label", "in", "(", "\"d\"", ",", "\"c\"", ",", "\"channel\"", ")", ":", "\n", "            ", "return", "AxisKind", ".", "Dimension", "\n", "", "if", "_label", "in", "(", "\"w\"", ",", "\"width\"", ")", ":", "\n", "            ", "return", "AxisKind", ".", "Width", "\n", "", "if", "_label", "in", "(", "\"h\"", ",", "\"height\"", ")", ":", "\n", "            ", "return", "AxisKind", ".", "Height", "\n", "", "if", "_label", "in", "(", "\"s\"", ",", "\"singleton\"", ")", ":", "\n", "            ", "return", "AxisKind", ".", "Singleton", "\n", "", "if", "_label", "in", "(", "\"seq\"", ",", "\"sequence\"", ")", ":", "\n", "            ", "return", "AxisKind", ".", "Sequence", "\n", "", "if", "_label", "==", "\"flowgroup\"", ":", "\n", "            ", "return", "AxisKind", ".", "FlowGroup", "\n", "", "if", "_label", "==", "\"any\"", ":", "\n", "            ", "return", "AxisKind", ".", "Any", "\n", "", "raise", "ValueError", "(", "f\"Can't create AxisKind from {label}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.axes.AxisType.__init__": [[90, 96], ["ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "kind", ":", "AxisKindAbstract", ",", "size", ":", "Optional", "[", "int", "]", "=", "None", ",", "is_list", "=", "False", ")", ":", "\n", "        ", "if", "size", "is", "not", "None", "and", "is_list", ":", "\n", "            ", "raise", "ValueError", "(", "\"The axis can't be list and have a fixed size\"", ")", "\n", "", "self", ".", "kind", "=", "kind", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "is_list", "=", "is_list", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.axes.AxisType.__repr__": [[97, 106], ["str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns short string representation of the AxisType\"\"\"", "\n", "if", "self", ".", "size", "is", "None", ":", "\n", "            ", "representation", "=", "str", "(", "self", ".", "kind", ")", "\n", "", "else", ":", "\n", "            ", "representation", "=", "f\"{str(self.kind)}:{self.size}\"", "\n", "", "if", "self", ".", "is_list", ":", "\n", "            ", "representation", "+=", "\"_listdim\"", "\n", "", "return", "representation", "\n", "", "", ""]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.__str__": [[32, 36], ["None"], "methods", ["None"], ["def", "__str__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "axes", "is", "not", "None", ":", "\n", "            ", "return", "f\"axes: {self.axes}; elements_type: {self.elements_type.__class__.__name__}\"", "\n", "", "return", "f\"axes: None; elements_type: {self.elements_type.__class__.__name__}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.__init__": [[37, 58], ["mridc.core.neural_types.elements.VoidType", "isinstance", "ValueError", "neural_type.NeuralType.__check_sanity", "tuple", "isinstance", "axes_list.append", "isinstance", "mridc.core.neural_types.axes.AxisType", "axes_list.append", "ValueError", "mridc.core.neural_types.axes.AxisKind.from_str"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.__check_sanity", "home.repos.pwc.inspect_result.wdika_mridc.neural_types.axes.AxisKind.from_str"], ["", "def", "__init__", "(", "self", ",", "axes", ":", "Optional", "[", "Tuple", "]", "=", "None", ",", "elements_type", ":", "ElementType", "=", "VoidType", "(", ")", ",", "optional", "=", "False", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "elements_type", ",", "ElementType", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"elements_type of NeuralType must be an instance of a class derived from ElementType. \"", "\n", "\"Did you pass a class instead?\"", "\n", ")", "\n", "", "self", ".", "elements_type", "=", "elements_type", "\n", "if", "axes", "is", "not", "None", ":", "\n", "            ", "NeuralType", ".", "__check_sanity", "(", "axes", ")", "\n", "axes_list", "=", "[", "]", "\n", "for", "axis", "in", "axes", ":", "\n", "                ", "if", "isinstance", "(", "axis", ",", "str", ")", ":", "\n", "                    ", "axes_list", ".", "append", "(", "AxisType", "(", "AxisKind", ".", "from_str", "(", "axis", ")", ",", "None", ")", ")", "\n", "", "elif", "isinstance", "(", "axis", ",", "AxisType", ")", ":", "\n", "                    ", "axes_list", ".", "append", "(", "axis", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "\"axis type must be either str or AxisType instance\"", ")", "\n", "", "", "self", ".", "axes", "=", "tuple", "(", "axes_list", ")", "# type: ignore", "\n", "", "else", ":", "\n", "            ", "self", ".", "axes", "=", "None", "# type: ignore", "\n", "", "self", ".", "optional", "=", "optional", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.compare": [[59, 95], ["neural_type.NeuralType.__compare_axes", "neural_type.NeuralType.elements_type.compare", "isinstance", "neural_type.NeuralType.elements_type.compare"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.__compare_axes", "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.compare", "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.compare"], ["", "def", "compare", "(", "self", ",", "second", ")", "->", "NeuralTypeComparisonResult", ":", "\n", "        ", "\"\"\"\n        Performs neural type comparison of self with second. When you chain two modules' inputs/outputs via __call__\n        method, this comparison will be called to ensure neural type compatibility.\n        \"\"\"", "\n", "# First, handle dimensionality", "\n", "axes_a", "=", "self", ".", "axes", "\n", "axes_b", "=", "second", ".", "axes", "\n", "\n", "# \"Big void\" type", "\n", "if", "isinstance", "(", "self", ".", "elements_type", ",", "VoidType", ")", "and", "self", ".", "axes", "is", "None", ":", "\n", "            ", "return", "NeuralTypeComparisonResult", ".", "SAME", "\n", "\n", "", "if", "self", ".", "axes", "is", "None", ":", "\n", "            ", "if", "second", ".", "axes", "is", "None", ":", "\n", "                ", "return", "self", ".", "elements_type", ".", "compare", "(", "second", ".", "elements_type", ")", "\n", "", "return", "NeuralTypeComparisonResult", ".", "INCOMPATIBLE", "\n", "\n", "", "dimensions_pass", "=", "NeuralType", ".", "__compare_axes", "(", "axes_a", ",", "axes_b", ")", "# type: ignore", "\n", "element_comparison_result", "=", "self", ".", "elements_type", ".", "compare", "(", "second", ".", "elements_type", ")", "\n", "\n", "# SAME DIMS", "\n", "if", "dimensions_pass", "==", "0", ":", "\n", "            ", "return", "element_comparison_result", "\n", "# TRANSPOSE_SAME DIMS", "\n", "", "if", "dimensions_pass", "==", "1", "and", "element_comparison_result", "==", "NeuralTypeComparisonResult", ".", "SAME", ":", "\n", "            ", "return", "NeuralTypeComparisonResult", ".", "TRANSPOSE_SAME", "\n", "", "if", "(", "\n", "dimensions_pass", "==", "1", "\n", "or", "dimensions_pass", "==", "2", "\n", "and", "element_comparison_result", "!=", "NeuralTypeComparisonResult", ".", "SAME", "\n", ")", ":", "\n", "            ", "return", "NeuralTypeComparisonResult", ".", "INCOMPATIBLE", "\n", "", "if", "dimensions_pass", "==", "2", ":", "\n", "            ", "return", "NeuralTypeComparisonResult", ".", "DIM_INCOMPATIBLE", "\n", "", "return", "NeuralTypeComparisonResult", ".", "INCOMPATIBLE", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.compare_and_raise_error": [[96, 102], ["neural_type.NeuralType.compare", "neural_type.NeuralPortNmTensorMismatchError", "str", "str"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.compare"], ["", "def", "compare_and_raise_error", "(", "self", ",", "parent_type_name", ",", "port_name", ",", "second_object", ")", ":", "\n", "        ", "\"\"\"Method compares definition of one type with another and raises an error if not compatible.\"\"\"", "\n", "type_compatibility", "=", "self", ".", "compare", "(", "second_object", ")", "\n", "if", "type_compatibility", "not", "in", "(", "NeuralTypeComparisonResult", ".", "SAME", ",", "NeuralTypeComparisonResult", ".", "GREATER", ")", ":", "\n", "            ", "raise", "NeuralPortNmTensorMismatchError", "(", "\n", "parent_type_name", ",", "port_name", ",", "str", "(", "self", ")", ",", "str", "(", "second_object", ".", "ntype", ")", ",", "type_compatibility", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.__eq__": [[104, 107], ["isinstance", "neural_type.NeuralType.compare"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.compare"], ["", "", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\"Checks if two NeuralTypes are equal.\"\"\"", "\n", "return", "self", ".", "compare", "(", "other", ")", "if", "isinstance", "(", "other", ",", "NeuralType", ")", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.__check_sanity": [[108, 129], ["ValueError", "isinstance", "isinstance", "ValueError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "__check_sanity", "(", "axes", ")", ":", "\n", "        ", "\"\"\"Check that list come before any tensor dimension\"\"\"", "\n", "are_strings", "=", "True", "\n", "for", "axis", "in", "axes", ":", "\n", "            ", "if", "not", "isinstance", "(", "axis", ",", "str", ")", ":", "\n", "                ", "are_strings", "=", "False", "\n", "", "if", "isinstance", "(", "axis", ",", "str", ")", "and", "not", "are_strings", ":", "\n", "                ", "raise", "ValueError", "(", "\"Either use full class names or all strings\"", ")", "\n", "", "", "if", "are_strings", ":", "\n", "            ", "return", "\n", "", "checks_passed", "=", "True", "\n", "saw_tensor_dim", "=", "False", "\n", "for", "axis", "in", "axes", ":", "\n", "            ", "if", "not", "axis", ".", "is_list", ":", "\n", "                ", "saw_tensor_dim", "=", "True", "\n", "", "elif", "saw_tensor_dim", ":", "# which is preceded by tensor dim", "\n", "                ", "checks_passed", "=", "False", "\n", "", "", "if", "not", "checks_passed", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"You have list dimension after Tensor dimension. All list dimensions must preceded Tensor dimensions\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.__compare_axes": [[131, 172], ["zip", "len", "len", "kinds_a.keys", "kinds_b.keys", "next", "kinds_a.items"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "__compare_axes", "(", "axes_a", ",", "axes_b", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Compares axes_a and axes_b\n        Args:\n            axes_a: first axes tuple\n            axes_b: second axes tuple\n        Returns:\n            0 - if they are exactly the same\n            1 - if they are \"TRANSPOSE_SAME\"\n            2 - if they are \"DIM_INCOMPATIBLE\"\n            3 - if they are different\n        \"\"\"", "\n", "if", "axes_a", "is", "None", ":", "\n", "            ", "return", "0", "if", "axes_b", "is", "None", "else", "3", "\n", "", "if", "axes_b", "is", "None", ":", "\n", "            ", "return", "3", "\n", "", "if", "len", "(", "axes_a", ")", "!=", "len", "(", "axes_b", ")", ":", "\n", "            ", "return", "3", "\n", "# After these ifs we know that len(axes_a) == len(axes_b)", "\n", "\n", "", "same", "=", "True", "\n", "kinds_a", "=", "{", "}", "\n", "kinds_b", "=", "{", "}", "\n", "for", "axis_a", ",", "axis_b", "in", "zip", "(", "axes_a", ",", "axes_b", ")", ":", "\n", "            ", "kinds_a", "[", "axis_a", ".", "kind", "]", "=", "axis_a", ".", "size", "\n", "kinds_b", "[", "axis_b", ".", "kind", "]", "=", "axis_b", ".", "size", "\n", "if", "axis_a", ".", "kind", "==", "AxisKind", ".", "Any", ":", "\n", "                ", "same", "=", "True", "\n", "", "elif", "(", "\n", "axis_a", ".", "kind", "!=", "axis_b", ".", "kind", "\n", "or", "axis_a", ".", "is_list", "!=", "axis_b", ".", "is_list", "\n", "or", "(", "axis_a", ".", "size", "!=", "axis_b", ".", "size", "and", "axis_a", ".", "size", "is", "not", "None", ")", "\n", ")", ":", "\n", "                ", "same", "=", "False", "\n", "", "", "if", "same", ":", "\n", "            ", "return", "0", "\n", "# can be TRANSPOSE_SAME, DIM_INCOMPATIBLE", "\n", "", "if", "kinds_a", ".", "keys", "(", ")", "==", "kinds_b", ".", "keys", "(", ")", ":", "\n", "            ", "return", "next", "(", "(", "2", "for", "key", ",", "value", "in", "kinds_a", ".", "items", "(", ")", "if", "kinds_b", "[", "key", "]", "!=", "value", ")", ",", "1", ")", "\n", "", "return", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralType.__repr__": [[173, 187], ["str", "repr"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns string representation of NeuralType.\"\"\"", "\n", "axes", "=", "str", "(", "self", ".", "axes", ")", "if", "self", ".", "axes", "is", "not", "None", "else", "\"None\"", "\n", "if", "self", ".", "elements_type", "is", "not", "None", ":", "\n", "            ", "element_type", "=", "repr", "(", "self", ".", "elements_type", ")", "\n", "", "else", ":", "\n", "            ", "element_type", "=", "\"None\"", "\n", "\n", "", "data", "=", "f\"axis={axes}, element_type={element_type}\"", "\n", "\n", "if", "self", ".", "optional", ":", "\n", "            ", "data", "=", "f\"{data}, optional={self.optional}\"", "\n", "\n", "", "return", "f\"{self.__class__.__name__}({data})\"", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNameMismatchError.__init__": [[196, 199], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "input_port_name", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "message", "=", "\"Wrong input port name: {0}\"", ".", "format", "(", "input_port_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__": [[204, 211], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.wdika_mridc.neural_types.neural_type.NeuralPortNmTensorMismatchError.__init__"], ["def", "__init__", "(", "self", ",", "class_name", ",", "port_name", ",", "first_type", ",", "second_type", ",", "type_compatibility", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "message", "=", "\"\\nIn {}. \\nPort: {} and a NmTensor it was fed are \\n\"", ".", "format", "(", "\n", "class_name", ",", "port_name", "\n", ")", "+", "\"of incompatible neural types:\\n\\n{} \\n\\n and \\n\\n{}\"", ".", "format", "(", "first_type", ",", "second_type", ")", "\n", "\n", "self", ".", "message", "+=", "\"\\n\\nType comparison result: {}\"", ".", "format", "(", "type_compatibility", ")", "\n", "", "", ""]]}