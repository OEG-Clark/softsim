{"home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.SlotIntentDataset.__init__": [[15, 18], ["basic_data_reader.SlotIntentDataset.read_seqtag_data_with_class"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.FewShotSlotIntentDataset_in_HIT_form.read_seqtag_data_with_class"], ["    ", "def", "__init__", "(", "self", ",", "data_file", ",", "lowercase", "=", "False", ",", "separator", "=", "':'", ",", "lattice_used", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "all_data_samples", "=", "self", ".", "read_seqtag_data_with_class", "(", "data_file", ",", "lowercase", "=", "lowercase", ",", "separator", "=", "separator", ",", "lattice_used", "=", "lattice_used", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.SlotIntentDataset.read_seqtag_data_with_class": [[19, 45], ["open", "enumerate", "line.strip().split", "slot_tag_line.split", "all_data_samples.append", "item.split", "in_seq.append", "tag_seq.append", "line.strip", "len", "separator.join", "word.lower.lower.lower", "lattice_used.get_lattice_inputs"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "read_seqtag_data_with_class", "(", "self", ",", "data_file", ",", "lowercase", "=", "False", ",", "separator", "=", "':'", ",", "lattice_used", "=", "None", ")", ":", "\n", "        ", "all_data_samples", "=", "[", "]", "\n", "with", "open", "(", "data_file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "ind", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "slot_tag_line", ",", "class_name", "=", "line", ".", "strip", "(", "'\\n\\r'", ")", ".", "split", "(", "' <=> '", ")", "\n", "if", "slot_tag_line", "==", "\"\"", ":", "\n", "                    ", "continue", "\n", "", "in_seq", ",", "tag_seq", "=", "[", "]", ",", "[", "]", "\n", "for", "item", "in", "slot_tag_line", ".", "split", "(", "' '", ")", ":", "\n", "                    ", "tmp", "=", "item", ".", "split", "(", "separator", ")", "\n", "assert", "len", "(", "tmp", ")", ">=", "2", "\n", "word", ",", "tag", "=", "separator", ".", "join", "(", "tmp", "[", ":", "-", "1", "]", ")", ",", "tmp", "[", "-", "1", "]", "\n", "if", "lowercase", ":", "\n", "                        ", "word", "=", "word", ".", "lower", "(", ")", "\n", "", "in_seq", ".", "append", "(", "word", ")", "\n", "tag_seq", ".", "append", "(", "tag", ")", "\n", "\n", "", "all_data_samples", ".", "append", "(", "[", "\n", "ind", ",", "\n", "in_seq", ",", "\n", "tag_seq", ",", "\n", "class_name", ",", "\n", "lattice_used", ".", "get_lattice_inputs", "(", "in_seq", ")", "if", "lattice_used", "else", "None", "\n", "]", ")", "\n", "", "", "return", "all_data_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.SlotIntentDataset.__len__": [[46, 48], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "all_data_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.SlotIntentDataset.__getitem__": [[49, 51], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "all_data_samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.collate_fn_do_nothing": [[52, 54], ["None"], "function", ["None"], ["", "", "def", "collate_fn_do_nothing", "(", "batch", ")", ":", "\n", "    ", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.convert_examples_to_features_for_word_input": [[55, 131], ["tokenizer.convert_tokens_to_ids", "slot_tags_vocab.convert_tokens_to_ids", "sorted", "max", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "len", "batch_tokens.append", "batch_tags.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor.append", "torch.tensor", "torch.tensor", "len", "intent.split", "batch_intents.append", "intents_vocab.convert_tokens_to_ids", "torch.tensor.append", "intent.split", "batch_intents.append", "torch.tensor.append", "len", "tokenizer.convert_tokens_to_ids", "slot_tags_vocab.convert_tokens_to_ids", "intents_vocab.get_vocab_size", "intents_vocab.convert_tokens_to_ids"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.get_vocab_size", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids"], ["", "def", "convert_examples_to_features_for_word_input", "(", "examples", ",", "tokenizer", ",", "slot_tags_vocab", ",", "intents_vocab", ",", "bos_eos", "=", "False", ",", "intent_multi_class", "=", "False", ",", "intent_separator", "=", "';'", ",", "slot_tag_enc_dec", "=", "False", ",", "mask_padding_with_zero", "=", "True", ",", "device", "=", "None", ")", ":", "\n", "    ", "if", "bos_eos", ":", "\n", "        ", "bos_token", "=", "tokenizer", ".", "bos_token", "\n", "eos_token", "=", "tokenizer", ".", "eos_token", "\n", "bos_tag", "=", "slot_tags_vocab", ".", "bos_token", "\n", "eos_tag", "=", "slot_tags_vocab", ".", "eos_token", "\n", "", "if", "slot_tag_enc_dec", ":", "\n", "        ", "bos_tag", "=", "slot_tags_vocab", ".", "bos_token", "\n", "", "pad_token_id", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "pad_token", ")", "\n", "pad_tag_id", "=", "slot_tags_vocab", ".", "convert_tokens_to_ids", "(", "slot_tags_vocab", ".", "pad_token", ")", "\n", "\n", "# sort the batch in increasing order of sentence", "\n", "examples", "=", "sorted", "(", "examples", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "1", "]", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "line_nums", "=", "[", "example", "[", "0", "]", "for", "example", "in", "examples", "]", "\n", "\n", "lengths", "=", "[", "len", "(", "example", "[", "1", "]", ")", "for", "example", "in", "examples", "]", "\n", "max_len", "=", "max", "(", "lengths", ")", "\n", "padding_lengths", "=", "[", "max_len", "-", "l", "for", "l", "in", "lengths", "]", "\n", "\n", "input_ids", "=", "[", "]", "\n", "tag_ids", "=", "[", "]", "\n", "intent_ids", "=", "[", "]", "\n", "input_mask", "=", "[", "]", "\n", "batch_tokens", ",", "batch_tags", ",", "batch_intents", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "example_index", ",", "example", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "tokens", "=", "example", "[", "1", "]", "\n", "tags", "=", "example", "[", "2", "]", "\n", "intent", "=", "example", "[", "3", "]", "\n", "if", "bos_eos", ":", "\n", "            ", "tokens", "=", "[", "bos_token", "]", "+", "tokens", "+", "[", "eos_token", "]", "\n", "tags", "=", "[", "bos_tag", "]", "+", "tags", "+", "[", "eos_tag", "]", "\n", "lengths", "[", "example_index", "]", "+=", "2", "\n", "", "mask_vector", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "tokens", ")", "\n", "batch_tokens", ".", "append", "(", "tokens", ")", "\n", "batch_tags", ".", "append", "(", "tags", ")", "\n", "\n", "input_ids", ".", "append", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "+", "[", "pad_token_id", "]", "*", "padding_lengths", "[", "example_index", "]", ")", "\n", "if", "slot_tag_enc_dec", ":", "\n", "# used for training", "\n", "            ", "tags", "=", "[", "bos_tag", "]", "+", "tags", "\n", "", "tag_ids", ".", "append", "(", "slot_tags_vocab", ".", "convert_tokens_to_ids", "(", "tags", ")", "+", "[", "pad_tag_id", "]", "*", "padding_lengths", "[", "example_index", "]", ")", "\n", "\n", "if", "intent_multi_class", ":", "\n", "            ", "intents", "=", "intent", ".", "split", "(", "intent_separator", ")", "\n", "batch_intents", ".", "append", "(", "intents", ")", "\n", "intents_vector", "=", "[", "0", "]", "*", "intents_vocab", ".", "get_vocab_size", "(", ")", "\n", "for", "intent_id", "in", "intents_vocab", ".", "convert_tokens_to_ids", "(", "intents", ")", ":", "\n", "                ", "intents_vector", "[", "intent_id", "]", "=", "1", "\n", "", "intent_ids", ".", "append", "(", "intents_vector", ")", "\n", "", "else", ":", "\n", "            ", "intents", "=", "intent", ".", "split", "(", "intent_separator", ")", "\n", "batch_intents", ".", "append", "(", "intents", ")", "\n", "intent_ids", ".", "append", "(", "intents_vocab", ".", "convert_tokens_to_ids", "(", "intents", "[", "0", "]", ")", ")", "# we use the first intent to train a softmax classifier", "\n", "\n", "", "mask_vector", "+=", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_lengths", "[", "example_index", "]", "\n", "input_mask", ".", "append", "(", "mask_vector", ")", "\n", "\n", "", "input_ids", "=", "torch", ".", "tensor", "(", "input_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "tag_ids", "=", "torch", ".", "tensor", "(", "tag_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "if", "intent_multi_class", ":", "\n", "        ", "intent_ids", "=", "torch", ".", "tensor", "(", "intent_ids", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "        ", "intent_ids", "=", "torch", ".", "tensor", "(", "intent_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "", "input_mask", "=", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "\n", "return", "{", "\n", "\"line_nums\"", ":", "line_nums", ",", "\n", "\"tokens\"", ":", "batch_tokens", ",", "\n", "\"tags\"", ":", "batch_tags", ",", "\n", "\"intents\"", ":", "batch_intents", ",", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"tag_ids\"", ":", "tag_ids", ",", "\n", "\"intent_ids\"", ":", "intent_ids", ",", "\n", "\"input_mask\"", ":", "input_mask", ",", "\n", "\"lengths\"", ":", "lengths", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader._get_intent_vector": [[133, 143], ["intent.split", "intents_vocab.convert_tokens_to_ids", "intent.split", "intents_vocab.get_vocab_size", "intents_vocab.convert_tokens_to_ids"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.get_vocab_size", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids"], ["", "def", "_get_intent_vector", "(", "intent", ",", "intents_vocab", ",", "intent_multi_class", "=", "False", ",", "intent_separator", "=", "';'", ")", ":", "\n", "    ", "if", "intent_multi_class", ":", "\n", "        ", "intents", "=", "intent", ".", "split", "(", "intent_separator", ")", "\n", "intents_vector", "=", "[", "0", "]", "*", "intents_vocab", ".", "get_vocab_size", "(", ")", "\n", "for", "intent_id", "in", "intents_vocab", ".", "convert_tokens_to_ids", "(", "intents", ")", ":", "\n", "            ", "intents_vector", "[", "intent_id", "]", "=", "1", "\n", "", "return", "intents", ",", "intents_vector", "\n", "", "else", ":", "\n", "        ", "intents", "=", "intent", ".", "split", "(", "intent_separator", ")", "\n", "return", "intents", ",", "intents_vocab", ".", "convert_tokens_to_ids", "(", "intents", "[", "0", "]", ")", "# we use the first intent to train a softmax classifier", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.get_char_features": [[144, 175], ["char_tokenizer.convert_tokens_to_ids", "enumerate", "sorted", "enumerate", "torch.tensor", "max", "torch.tensor", "char_tokenizer.convert_tokens_to_ids", "char_tokenizer.convert_tokens_to_ids", "char_tokenizer.convert_tokens_to_ids", "enumerate", "len", "len", "tuple", "char_ids.append", "char_tokenizer.convert_tokens_to_ids", "len", "len"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids"], ["", "", "def", "get_char_features", "(", "sorted_examples", ",", "char_tokenizer", ",", "padding_lengths", ",", "bos_eos", "=", "False", ",", "device", "=", "None", ",", "feed_transformer", "=", "False", ")", ":", "\n", "    ", "if", "bos_eos", ":", "\n", "        ", "bos_char_id", "=", "char_tokenizer", ".", "convert_tokens_to_ids", "(", "char_tokenizer", ".", "bos_token", ")", "\n", "eos_char_id", "=", "char_tokenizer", ".", "convert_tokens_to_ids", "(", "char_tokenizer", ".", "eos_token", ")", "\n", "", "if", "feed_transformer", ":", "\n", "        ", "cls_char_id", "=", "char_tokenizer", ".", "convert_tokens_to_ids", "(", "char_tokenizer", ".", "cls_token", ")", "\n", "", "pad_char_id", "=", "char_tokenizer", ".", "convert_tokens_to_ids", "(", "char_tokenizer", ".", "pad_token", ")", "\n", "input_char_ids", "=", "[", "]", "\n", "for", "example_index", ",", "example", "in", "enumerate", "(", "sorted_examples", ")", ":", "\n", "        ", "tokens", "=", "example", "[", "1", "]", "\n", "char_ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "chars", "=", "tuple", "(", "token", ")", "\n", "char_ids", ".", "append", "(", "char_tokenizer", ".", "convert_tokens_to_ids", "(", "chars", ")", ")", "\n", "", "if", "bos_eos", ":", "\n", "            ", "char_ids_of_this_sentence", "=", "[", "[", "bos_char_id", "]", "]", "+", "char_ids", "+", "[", "[", "eos_char_id", "]", "]", "+", "[", "[", "pad_char_id", "]", "]", "*", "padding_lengths", "[", "example_index", "]", "\n", "", "else", ":", "\n", "            ", "char_ids_of_this_sentence", "=", "char_ids", "+", "[", "[", "pad_char_id", "]", "]", "*", "padding_lengths", "[", "example_index", "]", "\n", "", "if", "feed_transformer", ":", "\n", "            ", "char_ids_of_this_sentence", "=", "[", "[", "cls_char_id", "]", "]", "+", "char_ids_of_this_sentence", "\n", "", "input_char_ids", "+=", "char_ids_of_this_sentence", "\n", "", "tmp", "=", "sorted", "(", "enumerate", "(", "input_char_ids", ")", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "1", "]", ")", ",", "reverse", "=", "True", ")", "\n", "reverse_index", "=", "[", "0", "]", "*", "len", "(", "tmp", ")", "\n", "for", "idx", ",", "x", "in", "enumerate", "(", "tmp", ")", ":", "\n", "        ", "reverse_index", "[", "x", "[", "0", "]", "]", "=", "idx", "\n", "", "reverse_index", "=", "torch", ".", "tensor", "(", "reverse_index", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "len_word_chars", "=", "[", "len", "(", "char_ids", ")", "for", "_", ",", "char_ids", "in", "tmp", "]", "\n", "max_len_word_chars", "=", "max", "(", "len_word_chars", ")", "\n", "input_char_ids", "=", "[", "char_ids", "+", "[", "pad_char_id", "]", "*", "(", "max_len_word_chars", "-", "len", "(", "char_ids", ")", ")", "for", "_", ",", "char_ids", "in", "tmp", "]", "\n", "input_char_ids", "=", "torch", ".", "tensor", "(", "input_char_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "return", "input_char_ids", ",", "reverse_index", ",", "len_word_chars", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.prepare_inputs_for_bert_xlnet": [[176, 255], ["enumerate", "max", "max", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "word_lengths.append", "tokens.append", "segment_ids.append", "selected_indexes.append", "len", "list", "list", "len", "tokenizer.tokenize", "len", "len", "enumerate", "itertools.chain.from_iterable", "itertools.chain.from_iterable", "selected_index.append", "selected_index.append", "enumerate", "tokenizer.convert_tokens_to_ids", "enumerate", "enumerate", "enumerate", "enumerate", "tokenizer.convert_tokens_to_ids", "enumerate", "enumerate", "enumerate", "range", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUCharTokenizer.tokenize", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids"], ["", "def", "prepare_inputs_for_bert_xlnet", "(", "sorted_examples", ",", "tokenizer", ",", "bos_eos", "=", "False", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "pad_token", "=", "0", ",", "sequence_a_segment_id", "=", "0", ",", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "device", "=", "None", ",", "feed_transformer", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    TODO: if feed_transformer == True, select CLS output as the first embedding of cls_token\n    \"\"\"", "\n", "\"\"\" Loads a data file into a list of `InputBatch`s\n        `cls_token_at_end` define the location of the CLS token:\n            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n    \"\"\"", "\n", "\"\"\" output: {\n        'tokens': tokens_tensor,        # input_ids\n        'segments': segments_tensor,    # token_type_ids\n        'mask': input_mask,             # attention_mask\n        'selects': selects_tensor,      # original_word_to_token_position\n        'copies': copies_tensor         # original_word_position\n        }\n    \"\"\"", "\n", "## sentences are sorted by sentence length", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", "# [CLS]", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", "# [SEP]", "\n", "if", "bos_eos", ":", "\n", "        ", "bos_token", "=", "tokenizer", ".", "bos_token", "\n", "eos_token", "=", "tokenizer", ".", "eos_token", "\n", "\n", "", "word_lengths", "=", "[", "]", "\n", "tokens", "=", "[", "]", "\n", "segment_ids", "=", "[", "]", "\n", "selected_indexes", "=", "[", "]", "\n", "start_pos", "=", "0", "\n", "for", "example_index", ",", "example", "in", "enumerate", "(", "sorted_examples", ")", ":", "\n", "        ", "words", "=", "example", "[", "1", "]", "\n", "if", "bos_eos", ":", "\n", "            ", "words", "=", "[", "bos_token", "]", "+", "words", "+", "[", "eos_token", "]", "\n", "", "word_lengths", ".", "append", "(", "len", "(", "words", ")", ")", "\n", "selected_index", "=", "[", "]", "\n", "ts", "=", "[", "]", "\n", "for", "w", "in", "words", ":", "\n", "            ", "if", "cls_token_at_end", ":", "\n", "                ", "selected_index", ".", "append", "(", "len", "(", "ts", ")", ")", "\n", "", "else", ":", "\n", "                ", "selected_index", ".", "append", "(", "len", "(", "ts", ")", "+", "1", ")", "\n", "", "ts", "+=", "tokenizer", ".", "tokenize", "(", "w", ")", "\n", "", "ts", "+=", "[", "sep_token", "]", "\n", "si", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "ts", ")", "\n", "if", "cls_token_at_end", ":", "\n", "            ", "ts", "=", "ts", "+", "[", "cls_token", "]", "\n", "si", "=", "si", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "ts", "=", "[", "cls_token", "]", "+", "ts", "\n", "si", "=", "[", "cls_token_segment_id", "]", "+", "si", "\n", "", "tokens", ".", "append", "(", "ts", ")", "\n", "segment_ids", ".", "append", "(", "si", ")", "\n", "selected_indexes", ".", "append", "(", "selected_index", ")", "\n", "", "lengths_of_tokens", "=", "[", "len", "(", "tokenized_text", ")", "for", "tokenized_text", "in", "tokens", "]", "\n", "max_length_of_tokens", "=", "max", "(", "lengths_of_tokens", ")", "\n", "#if not cls_token_at_end: # bert", "\n", "#    assert max_length_of_tokens <= model_bert.config.max_position_embeddings", "\n", "padding_lengths", "=", "[", "max_length_of_tokens", "-", "len", "(", "tokenized_text", ")", "for", "tokenized_text", "in", "tokens", "]", "\n", "if", "pad_on_left", ":", "\n", "        ", "input_mask", "=", "[", "[", "0", "]", "*", "padding_lengths", "[", "idx", "]", "+", "[", "1", "]", "*", "len", "(", "tokenized_text", ")", "for", "idx", ",", "tokenized_text", "in", "enumerate", "(", "tokens", ")", "]", "\n", "indexed_tokens", "=", "[", "[", "pad_token", "]", "*", "padding_lengths", "[", "idx", "]", "+", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "for", "idx", ",", "tokenized_text", "in", "enumerate", "(", "tokens", ")", "]", "\n", "segments_ids", "=", "[", "[", "pad_token_segment_id", "]", "*", "padding_lengths", "[", "idx", "]", "+", "si", "for", "idx", ",", "si", "in", "enumerate", "(", "segment_ids", ")", "]", "\n", "selected_indexes", "=", "[", "[", "padding_lengths", "[", "idx", "]", "+", "i", "+", "idx", "*", "max_length_of_tokens", "for", "i", "in", "selected_index", "]", "for", "idx", ",", "selected_index", "in", "enumerate", "(", "selected_indexes", ")", "]", "\n", "", "else", ":", "\n", "        ", "input_mask", "=", "[", "[", "1", "]", "*", "len", "(", "tokenized_text", ")", "+", "[", "0", "]", "*", "padding_lengths", "[", "idx", "]", "for", "idx", ",", "tokenized_text", "in", "enumerate", "(", "tokens", ")", "]", "\n", "indexed_tokens", "=", "[", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "+", "[", "pad_token", "]", "*", "padding_lengths", "[", "idx", "]", "for", "idx", ",", "tokenized_text", "in", "enumerate", "(", "tokens", ")", "]", "\n", "segments_ids", "=", "[", "si", "+", "[", "pad_token_segment_id", "]", "*", "padding_lengths", "[", "idx", "]", "for", "idx", ",", "si", "in", "enumerate", "(", "segment_ids", ")", "]", "\n", "selected_indexes", "=", "[", "[", "0", "+", "i", "+", "idx", "*", "max_length_of_tokens", "for", "i", "in", "selected_index", "]", "for", "idx", ",", "selected_index", "in", "enumerate", "(", "selected_indexes", ")", "]", "\n", "", "max_length_of_sentences", "=", "max", "(", "word_lengths", ")", "# the length is already +2 when bos_eos is True.", "\n", "copied_indexes", "=", "[", "[", "i", "+", "idx", "*", "max_length_of_sentences", "for", "i", "in", "range", "(", "length", ")", "]", "for", "idx", ",", "length", "in", "enumerate", "(", "word_lengths", ")", "]", "\n", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "indexed_tokens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "segments_tensor", "=", "torch", ".", "tensor", "(", "segments_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "selects_tensor", "=", "torch", ".", "tensor", "(", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "selected_indexes", ")", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "copies_tensor", "=", "torch", ".", "tensor", "(", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "copied_indexes", ")", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "#return {'tokens': tokens_tensor, 'segments': segments_tensor, 'selects': selects_tensor, 'copies': copies_tensor, 'mask': input_mask}", "\n", "return", "tokens_tensor", ",", "segments_tensor", ",", "input_mask", ",", "selects_tensor", ",", "copies_tensor", ",", "lengths_of_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.convert_examples_to_features": [[256, 358], ["sorted", "max", "slot_tags_vocab.convert_tokens_to_ids", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "len", "word_tokenizer.convert_tokens_to_ids", "torch.tensor.append", "batch_tokens.append", "batch_tags.append", "torch.tensor.append", "basic_data_reader._get_intent_vector", "batch_intents.append", "torch.tensor.append", "basic_data_reader.get_char_features", "basic_data_reader.prepare_inputs_for_bert_xlnet", "torch.tensor", "torch.tensor", "torch.tensor.append", "lattice_used.get_lattice_batch", "len", "slot_tags_vocab.convert_tokens_to_ids", "len", "len", "max", "word_tokenizer.convert_tokens_to_ids"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader._get_intent_vector", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.get_char_features", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.pretrained_transformer.prepare_inputs_for_bert_xlnet", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids"], ["", "def", "convert_examples_to_features", "(", "examples", ",", "word_tokenizer", "=", "None", ",", "char_tokenizer", "=", "None", ",", "tf_tokenizer", "=", "None", ",", "tf_input_args", "=", "{", "}", ",", "slot_tags_vocab", "=", "None", ",", "intents_vocab", "=", "None", ",", "bos_eos", "=", "False", ",", "intent_multi_class", "=", "False", ",", "intent_separator", "=", "';'", ",", "slot_tag_enc_dec", "=", "False", ",", "mask_padding_with_zero", "=", "True", ",", "device", "=", "None", ",", "feed_transformer", "=", "False", ",", "lattice_used", "=", "None", ")", ":", "\n", "# sort the batch in increasing order of sentence", "\n", "    ", "examples", "=", "sorted", "(", "examples", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "1", "]", ")", ",", "reverse", "=", "True", ")", "\n", "line_nums", "=", "[", "example", "[", "0", "]", "for", "example", "in", "examples", "]", "\n", "lengths", "=", "[", "len", "(", "example", "[", "1", "]", ")", "for", "example", "in", "examples", "]", "\n", "max_len", "=", "max", "(", "lengths", ")", "\n", "padding_lengths", "=", "[", "max_len", "-", "l", "for", "l", "in", "lengths", "]", "\n", "\n", "if", "bos_eos", ":", "\n", "        ", "if", "word_tokenizer", "is", "not", "None", ":", "\n", "            ", "bos_token", "=", "word_tokenizer", ".", "bos_token", "\n", "eos_token", "=", "word_tokenizer", ".", "eos_token", "\n", "", "bos_tag", "=", "slot_tags_vocab", ".", "bos_token", "\n", "eos_tag", "=", "slot_tags_vocab", ".", "eos_token", "\n", "", "if", "slot_tag_enc_dec", ":", "\n", "        ", "bos_tag", "=", "slot_tags_vocab", ".", "bos_token", "\n", "", "if", "word_tokenizer", "is", "not", "None", ":", "\n", "        ", "pad_token_id", "=", "word_tokenizer", ".", "convert_tokens_to_ids", "(", "word_tokenizer", ".", "pad_token", ")", "\n", "", "pad_tag_id", "=", "slot_tags_vocab", ".", "convert_tokens_to_ids", "(", "slot_tags_vocab", ".", "pad_token", ")", "\n", "\n", "input_word_ids", "=", "[", "]", "\n", "tag_ids", "=", "[", "]", "\n", "intent_ids", "=", "[", "]", "\n", "input_mask", "=", "[", "]", "\n", "batch_tokens", ",", "batch_tags", ",", "batch_intents", "=", "[", "]", ",", "[", "]", ",", "[", "]", "# used for evaluation", "\n", "for", "example_index", ",", "example", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "tokens", "=", "example", "[", "1", "]", "\n", "tags", "=", "example", "[", "2", "]", "\n", "intent", "=", "example", "[", "3", "]", "\n", "if", "bos_eos", ":", "\n", "            ", "if", "word_tokenizer", "is", "not", "None", ":", "\n", "                ", "tokens", "=", "[", "bos_token", "]", "+", "tokens", "+", "[", "eos_token", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "[", "'<s>'", "]", "+", "tokens", "+", "[", "'</s>'", "]", "\n", "", "tags", "=", "[", "bos_tag", "]", "+", "tags", "+", "[", "eos_tag", "]", "\n", "lengths", "[", "example_index", "]", "+=", "2", "\n", "", "if", "feed_transformer", "==", "True", ":", "\n", "            ", "tokens", "=", "[", "'<cls>'", "]", "+", "tokens", "\n", "lengths", "[", "example_index", "]", "+=", "1", "\n", "", "mask_vector", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "lengths", "[", "example_index", "]", "\n", "mask_vector", "+=", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_lengths", "[", "example_index", "]", "\n", "input_mask", ".", "append", "(", "mask_vector", ")", "\n", "\n", "if", "word_tokenizer", "is", "not", "None", ":", "\n", "            ", "input_word_ids", ".", "append", "(", "word_tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "+", "[", "pad_token_id", "]", "*", "padding_lengths", "[", "example_index", "]", ")", "\n", "", "batch_tokens", ".", "append", "(", "tokens", ")", "\n", "\n", "batch_tags", ".", "append", "(", "tags", ")", "\n", "if", "slot_tag_enc_dec", ":", "\n", "# used for training", "\n", "            ", "tags", "=", "[", "bos_tag", "]", "+", "tags", "\n", "", "tag_ids", ".", "append", "(", "slot_tags_vocab", ".", "convert_tokens_to_ids", "(", "tags", ")", "+", "[", "pad_tag_id", "]", "*", "padding_lengths", "[", "example_index", "]", ")", "\n", "\n", "intents", ",", "intent_vector_or_id", "=", "_get_intent_vector", "(", "intent", ",", "intents_vocab", ",", "intent_multi_class", "=", "intent_multi_class", ",", "intent_separator", "=", "intent_separator", ")", "\n", "batch_intents", ".", "append", "(", "intents", ")", "\n", "intent_ids", ".", "append", "(", "intent_vector_or_id", ")", "\n", "\n", "", "input_word_ids", "=", "torch", ".", "tensor", "(", "input_word_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "if", "char_tokenizer", "is", "not", "None", ":", "\n", "        ", "input_char_ids", ",", "reverse_index", ",", "len_word_chars", "=", "get_char_features", "(", "examples", ",", "char_tokenizer", ",", "padding_lengths", ",", "bos_eos", "=", "bos_eos", ",", "device", "=", "device", ",", "feed_transformer", "=", "feed_transformer", ")", "\n", "", "else", ":", "\n", "        ", "input_char_ids", ",", "len_word_chars", ",", "reverse_index", "=", "None", ",", "None", ",", "None", "\n", "", "if", "tf_tokenizer", "is", "not", "None", ":", "\n", "        ", "input_tf_ids", ",", "tf_segment_ids", ",", "tf_attention_mask", ",", "tf_output_selects", ",", "tf_output_copies", ",", "lengths_of_tokens", "=", "prepare_inputs_for_bert_xlnet", "(", "examples", ",", "tf_tokenizer", ",", "bos_eos", "=", "bos_eos", ",", "device", "=", "device", ",", "feed_transformer", "=", "feed_transformer", ",", "**", "tf_input_args", ")", "\n", "", "else", ":", "\n", "        ", "input_tf_ids", ",", "tf_segment_ids", ",", "tf_attention_mask", ",", "tf_output_selects", ",", "tf_output_copies", ",", "lengths_of_tokens", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "", "input_mask", "=", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "tag_ids", "=", "torch", ".", "tensor", "(", "tag_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "if", "intent_multi_class", ":", "\n", "        ", "intent_ids", "=", "torch", ".", "tensor", "(", "intent_ids", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "        ", "intent_ids", "=", "torch", ".", "tensor", "(", "intent_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "", "return", "{", "\n", "\"line_nums\"", ":", "line_nums", ",", "\n", "\"tokens\"", ":", "batch_tokens", ",", "\n", "\"tags\"", ":", "batch_tags", ",", "\n", "\"intents\"", ":", "batch_intents", ",", "\n", "\"inputs\"", ":", "{", "\n", "\"input_word\"", ":", "input_word_ids", ",", "\n", "\"input_char\"", ":", "{", "\n", "\"input_char_ids\"", ":", "input_char_ids", ",", "\n", "\"lengths\"", ":", "len_word_chars", ",", "\n", "\"inverse_mapping_index\"", ":", "reverse_index", ",", "\n", "\"batch_size\"", ":", "len", "(", "lengths", ")", "\n", "}", ",", "\n", "\"input_tf\"", ":", "{", "\n", "\"input_ids\"", ":", "input_tf_ids", ",", "\n", "\"segment_ids\"", ":", "tf_segment_ids", ",", "\n", "\"attention_mask\"", ":", "tf_attention_mask", ",", "\n", "\"selects\"", ":", "tf_output_selects", ",", "\n", "\"copies\"", ":", "tf_output_copies", ",", "\n", "\"batch_size\"", ":", "len", "(", "lengths", ")", ",", "\n", "\"lengths\"", ":", "lengths_of_tokens", ",", "\n", "\"max_word_length\"", ":", "max", "(", "lengths", ")", "\n", "}", "\n", "}", ",", "\n", "\"input_mask\"", ":", "input_mask", ",", "\n", "\"tag_ids\"", ":", "tag_ids", ",", "\n", "\"intent_ids\"", ":", "intent_ids", ",", "\n", "\"lengths\"", ":", "lengths", ",", "\n", "\"lattice\"", ":", "lattice_used", ".", "get_lattice_batch", "(", "[", "ex", "[", "-", "1", "]", "for", "ex", "in", "examples", "]", ",", "device", "=", "device", ")", "if", "lattice_used", "else", "None", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.prepare_inputs_of_word_sequences_for_bert_xlnet": [[360, 415], ["enumerate", "max", "torch.tensor", "torch.tensor", "torch.tensor", "tokens.append", "segment_ids.append", "tokenizer.tokenize", "len", "len", "len", "enumerate", "tokenizer.convert_tokens_to_ids", "enumerate", "enumerate", "enumerate", "tokenizer.convert_tokens_to_ids", "enumerate", "enumerate", "len", "len"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUCharTokenizer.tokenize", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids"], ["", "def", "prepare_inputs_of_word_sequences_for_bert_xlnet", "(", "word_sequences", ",", "tokenizer", ",", "bos_eos", "=", "False", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "pad_token", "=", "0", ",", "sequence_a_segment_id", "=", "0", ",", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "device", "=", "None", ")", ":", "\n", "    ", "\"\"\" Loads a data file into a list of `InputBatch`s\n        `cls_token_at_end` define the location of the CLS token:\n            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n    \"\"\"", "\n", "\"\"\" output: {\n        'tokens': tokens_tensor,        # input_ids\n        'segments': segments_tensor,    # token_type_ids\n        'mask': input_mask,             # attention_mask\n        }\n    \"\"\"", "\n", "## sentences are sorted by sentence length", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", "# [CLS]", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", "# [SEP]", "\n", "if", "bos_eos", ":", "\n", "        ", "bos_token", "=", "tokenizer", ".", "bos_token", "\n", "eos_token", "=", "tokenizer", ".", "eos_token", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "segment_ids", "=", "[", "]", "\n", "for", "example_index", ",", "words", "in", "enumerate", "(", "word_sequences", ")", ":", "\n", "        ", "if", "bos_eos", ":", "\n", "            ", "words", "=", "[", "bos_token", "]", "+", "words", "+", "[", "eos_token", "]", "\n", "", "ts", "=", "[", "]", "\n", "for", "w", "in", "words", ":", "\n", "            ", "ts", "+=", "tokenizer", ".", "tokenize", "(", "w", ")", "\n", "", "ts", "+=", "[", "sep_token", "]", "\n", "si", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "ts", ")", "\n", "if", "cls_token_at_end", ":", "\n", "            ", "ts", "=", "ts", "+", "[", "cls_token", "]", "\n", "si", "=", "si", "+", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "ts", "=", "[", "cls_token", "]", "+", "ts", "\n", "si", "=", "[", "cls_token_segment_id", "]", "+", "si", "\n", "", "tokens", ".", "append", "(", "ts", ")", "\n", "segment_ids", ".", "append", "(", "si", ")", "\n", "", "max_length_of_tokens", "=", "max", "(", "[", "len", "(", "tokenized_text", ")", "for", "tokenized_text", "in", "tokens", "]", ")", "\n", "#if not cls_token_at_end: # bert", "\n", "#    assert max_length_of_tokens <= model_bert.config.max_position_embeddings", "\n", "padding_lengths", "=", "[", "max_length_of_tokens", "-", "len", "(", "tokenized_text", ")", "for", "tokenized_text", "in", "tokens", "]", "\n", "if", "pad_on_left", ":", "\n", "        ", "input_mask", "=", "[", "[", "0", "]", "*", "padding_lengths", "[", "idx", "]", "+", "[", "1", "]", "*", "len", "(", "tokenized_text", ")", "for", "idx", ",", "tokenized_text", "in", "enumerate", "(", "tokens", ")", "]", "\n", "indexed_tokens", "=", "[", "[", "pad_token", "]", "*", "padding_lengths", "[", "idx", "]", "+", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "for", "idx", ",", "tokenized_text", "in", "enumerate", "(", "tokens", ")", "]", "\n", "segments_ids", "=", "[", "[", "pad_token_segment_id", "]", "*", "padding_lengths", "[", "idx", "]", "+", "si", "for", "idx", ",", "si", "in", "enumerate", "(", "segment_ids", ")", "]", "\n", "", "else", ":", "\n", "        ", "input_mask", "=", "[", "[", "1", "]", "*", "len", "(", "tokenized_text", ")", "+", "[", "0", "]", "*", "padding_lengths", "[", "idx", "]", "for", "idx", ",", "tokenized_text", "in", "enumerate", "(", "tokens", ")", "]", "\n", "indexed_tokens", "=", "[", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "+", "[", "pad_token", "]", "*", "padding_lengths", "[", "idx", "]", "for", "idx", ",", "tokenized_text", "in", "enumerate", "(", "tokens", ")", "]", "\n", "segments_ids", "=", "[", "si", "+", "[", "pad_token_segment_id", "]", "*", "padding_lengths", "[", "idx", "]", "for", "idx", ",", "si", "in", "enumerate", "(", "segment_ids", ")", "]", "\n", "\n", "", "input_mask", "=", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "indexed_tokens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "segments_tensor", "=", "torch", ".", "tensor", "(", "segments_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "return", "{", "'input_ids'", ":", "tokens_tensor", ",", "'token_type_ids'", ":", "segments_tensor", ",", "'attention_mask'", ":", "input_mask", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.prepare_inputs_of_word_sequences_for_rnn": [[416, 472], ["sorted", "max", "enumerate", "torch.tensor", "torch.tensor", "len", "word_tokenizer.convert_tokens_to_ids", "torch.tensor.append", "batch_tokens.append", "torch.tensor.append", "len", "word_tokenizer.convert_tokens_to_ids"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids"], ["", "def", "prepare_inputs_of_word_sequences_for_rnn", "(", "sentences", ",", "word_tokenizer", "=", "None", ",", "char_tokenizer", "=", "None", ",", "tf_tokenizer", "=", "None", ",", "tf_input_args", "=", "{", "}", ",", "slot_tags_vocab", "=", "None", ",", "intents_vocab", "=", "None", ",", "bos_eos", "=", "False", ",", "intent_multi_class", "=", "False", ",", "intent_separator", "=", "';'", ",", "slot_tag_enc_dec", "=", "False", ",", "mask_padding_with_zero", "=", "True", ",", "device", "=", "None", ",", "feed_transformer", "=", "False", ")", ":", "\n", "# sort the batch in increasing order of sentence", "\n", "    ", "sentences", "=", "sorted", "(", "sentences", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ",", "reverse", "=", "True", ")", "\n", "lengths", "=", "[", "len", "(", "snt", ")", "for", "snt", "in", "sentences", "]", "\n", "max_len", "=", "max", "(", "lengths", ")", "\n", "padding_lengths", "=", "[", "max_len", "-", "l", "for", "l", "in", "lengths", "]", "\n", "\n", "if", "bos_eos", ":", "\n", "        ", "if", "word_tokenizer", "is", "not", "None", ":", "\n", "            ", "bos_token", "=", "word_tokenizer", ".", "bos_token", "\n", "eos_token", "=", "word_tokenizer", ".", "eos_token", "\n", "", "", "if", "word_tokenizer", "is", "not", "None", ":", "\n", "        ", "pad_token_id", "=", "word_tokenizer", ".", "convert_tokens_to_ids", "(", "word_tokenizer", ".", "pad_token", ")", "\n", "\n", "", "input_word_ids", "=", "[", "]", "\n", "input_mask", "=", "[", "]", "\n", "batch_tokens", "=", "[", "]", "# used for evaluation", "\n", "for", "example_index", ",", "example", "in", "enumerate", "(", "sentences", ")", ":", "\n", "        ", "tokens", "=", "example", "\n", "if", "bos_eos", ":", "\n", "            ", "if", "word_tokenizer", "is", "not", "None", ":", "\n", "                ", "tokens", "=", "[", "bos_token", "]", "+", "tokens", "+", "[", "eos_token", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "[", "'<s>'", "]", "+", "tokens", "+", "[", "'</s>'", "]", "\n", "", "lengths", "[", "example_index", "]", "+=", "2", "\n", "", "if", "feed_transformer", "==", "True", ":", "\n", "            ", "tokens", "=", "[", "'<cls>'", "]", "+", "tokens", "\n", "lengths", "[", "example_index", "]", "+=", "1", "\n", "", "mask_vector", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "lengths", "[", "example_index", "]", "\n", "mask_vector", "+=", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_lengths", "[", "example_index", "]", "\n", "input_mask", ".", "append", "(", "mask_vector", ")", "\n", "\n", "if", "word_tokenizer", "is", "not", "None", ":", "\n", "            ", "input_word_ids", ".", "append", "(", "word_tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "+", "[", "pad_token_id", "]", "*", "padding_lengths", "[", "example_index", "]", ")", "\n", "", "batch_tokens", ".", "append", "(", "tokens", ")", "\n", "\n", "", "input_word_ids", "=", "torch", ".", "tensor", "(", "input_word_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "'''\n    if char_tokenizer is not None:\n        input_char_ids, reverse_index, len_word_chars = get_char_features(examples, char_tokenizer, padding_lengths, bos_eos=bos_eos, device=device, feed_transformer=feed_transformer)\n    else:\n        input_char_ids, len_word_chars, reverse_index = None, None, None\n    if tf_tokenizer is not None:\n        input_tf_ids, tf_segment_ids, tf_attention_mask, tf_output_selects, tf_output_copies, lengths_of_tokens = prepare_inputs_for_bert_xlnet(examples, tf_tokenizer, bos_eos=bos_eos, device=device, feed_transformer=feed_transformer, **tf_input_args)\n    else:\n        input_tf_ids, tf_segment_ids, tf_attention_mask, tf_output_selects, tf_output_copies, lengths_of_tokens = None, None, None, None, None, None\n    '''", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "\n", "return", "{", "\n", "#\"tokens\": batch_tokens,", "\n", "\"inputs\"", ":", "{", "\n", "\"input_word\"", ":", "input_word_ids", ",", "\n", "}", ",", "\n", "\"input_mask\"", ":", "input_mask", ",", "\n", "\"lengths\"", ":", "lengths", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric_HIT.compute_fscore": [[4, 19], ["None"], "function", ["None"], ["def", "compute_fscore", "(", "TP", ",", "FP", ",", "FN", ")", ":", "\n", "    ", "metrics", "=", "{", "'p'", ":", "0", ",", "'r'", ":", "0", ",", "'f'", ":", "0", "}", "\n", "if", "TP", "+", "FP", "==", "0", ":", "\n", "        ", "metrics", "[", "'p'", "]", "=", "'Nan'", "\n", "", "else", ":", "\n", "        ", "metrics", "[", "'p'", "]", "=", "100", "*", "TP", "/", "(", "TP", "+", "FP", ")", "\n", "", "if", "TP", "+", "FN", "==", "0", ":", "\n", "        ", "metrics", "[", "'r'", "]", "=", "'Nan'", "\n", "", "else", ":", "\n", "        ", "metrics", "[", "'r'", "]", "=", "100", "*", "TP", "/", "(", "TP", "+", "FN", ")", "\n", "", "if", "2", "*", "TP", "+", "FP", "+", "FN", "==", "0", ":", "\n", "        ", "metrics", "[", "'f'", "]", "=", "'Nan'", "\n", "", "else", ":", "\n", "        ", "metrics", "[", "'f'", "]", "=", "100", "*", "2", "*", "TP", "/", "(", "2", "*", "TP", "+", "FP", "+", "FN", ")", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric_HIT.analysis_fscore": [[20, 35], ["None"], "function", ["None"], ["", "def", "analysis_fscore", "(", "pred_items", ",", "label_items", ")", ":", "\n", "    ", "\"\"\"\n    pred_items: a set\n    label_items: a set\n    \"\"\"", "\n", "TP", ",", "FP", ",", "FN", "=", "0", ",", "0", ",", "0", "\n", "for", "pred_item", "in", "pred_items", ":", "\n", "        ", "if", "pred_item", "in", "label_items", ":", "\n", "            ", "TP", "+=", "1", "\n", "", "else", ":", "\n", "            ", "FP", "+=", "1", "\n", "", "", "for", "label_item", "in", "label_items", ":", "\n", "        ", "if", "label_item", "not", "in", "pred_items", ":", "\n", "            ", "FN", "+=", "1", "\n", "", "", "return", "TP", ",", "FP", ",", "FN", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric_HIT.get_tuples_of_slot_and_intent": [[36, 49], ["set", "set.add", "intent.split", "len", "set.add", "set.add", "tuple", "value.replace"], "function", ["None"], ["", "def", "get_tuples_of_slot_and_intent", "(", "words", ",", "chunks", ",", "intents", ")", ":", "\n", "    ", "tuples", "=", "set", "(", ")", "\n", "for", "start_idx", ",", "end_idx", ",", "slot_name", "in", "chunks", ":", "\n", "        ", "tuples", ".", "add", "(", "(", "slot_name", ",", "''", ".", "join", "(", "words", "[", "start_idx", "-", "1", ":", "end_idx", "]", ")", ".", "replace", "(", "' '", ",", "''", ")", ")", ")", "\n", "", "for", "intent", "in", "intents", ":", "\n", "        ", "if", "intent", "not", "in", "{", "'<pad>'", ",", "'<unk>'", ",", "'<EMPTY>'", "}", ":", "\n", "            ", "items", "=", "intent", ".", "split", "(", "'-'", ")", "\n", "if", "len", "(", "items", ")", "<", "3", ":", "\n", "                ", "tuples", ".", "add", "(", "tuple", "(", "items", ")", ")", "\n", "", "else", ":", "\n", "                ", "act", ",", "slot", ",", "value", "=", "items", "\n", "tuples", ".", "add", "(", "(", "act", "+", "'-'", "+", "slot", ",", "value", ".", "replace", "(", "' '", ",", "''", ")", ")", ")", "\n", "", "", "", "return", "tuples", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric_HIT.get_chunks": [[50, 89], ["range", "len", "chunks.append"], "function", ["None"], ["", "def", "get_chunks", "(", "labels", ")", ":", "\n", "    ", "\"\"\"\n        It supports IOB2 or IOBES tagging scheme.\n        You may also want to try https://github.com/sighsmile/conlleval.\n    \"\"\"", "\n", "chunks", "=", "[", "]", "\n", "start_idx", ",", "end_idx", "=", "0", ",", "0", "\n", "for", "idx", "in", "range", "(", "1", ",", "len", "(", "labels", ")", "-", "1", ")", ":", "\n", "        ", "chunkStart", ",", "chunkEnd", "=", "False", ",", "False", "\n", "if", "labels", "[", "idx", "-", "1", "]", "not", "in", "(", "'O'", ",", "'<pad>'", ",", "'<unk>'", ",", "'<s>'", ",", "'</s>'", ",", "'<STOP>'", ",", "'<START>'", ")", ":", "\n", "            ", "prevTag", ",", "prevType", "=", "labels", "[", "idx", "-", "1", "]", "[", ":", "1", "]", ",", "labels", "[", "idx", "-", "1", "]", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "prevTag", ",", "prevType", "=", "'O'", ",", "'O'", "\n", "", "if", "labels", "[", "idx", "]", "not", "in", "(", "'O'", ",", "'<pad>'", ",", "'<unk>'", ",", "'<s>'", ",", "'</s>'", ",", "'<STOP>'", ",", "'<START>'", ")", ":", "\n", "            ", "Tag", ",", "Type", "=", "labels", "[", "idx", "]", "[", ":", "1", "]", ",", "labels", "[", "idx", "]", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "Tag", ",", "Type", "=", "'O'", ",", "'O'", "\n", "", "if", "labels", "[", "idx", "+", "1", "]", "not", "in", "(", "'O'", ",", "'<pad>'", ",", "'<unk>'", ",", "'<s>'", ",", "'</s>'", ",", "'<STOP>'", ",", "'<START>'", ")", ":", "\n", "            ", "nextTag", ",", "nextType", "=", "labels", "[", "idx", "+", "1", "]", "[", ":", "1", "]", ",", "labels", "[", "idx", "+", "1", "]", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "nextTag", ",", "nextType", "=", "'O'", ",", "'O'", "\n", "\n", "", "if", "Tag", "==", "'B'", "or", "Tag", "==", "'S'", "or", "(", "prevTag", ",", "Tag", ")", "in", "{", "(", "'O'", ",", "'I'", ")", ",", "(", "'O'", ",", "'E'", ")", ",", "(", "'E'", ",", "'I'", ")", ",", "(", "'E'", ",", "'E'", ")", ",", "(", "'S'", ",", "'I'", ")", ",", "(", "'S'", ",", "'E'", ")", "}", ":", "\n", "            ", "chunkStart", "=", "True", "\n", "", "if", "Tag", "!=", "'O'", "and", "prevType", "!=", "Type", ":", "\n", "            ", "chunkStart", "=", "True", "\n", "\n", "", "if", "Tag", "==", "'E'", "or", "Tag", "==", "'S'", "or", "(", "Tag", ",", "nextTag", ")", "in", "{", "(", "'B'", ",", "'B'", ")", ",", "(", "'B'", ",", "'O'", ")", ",", "(", "'B'", ",", "'S'", ")", ",", "(", "'I'", ",", "'B'", ")", ",", "(", "'I'", ",", "'O'", ")", ",", "(", "'I'", ",", "'S'", ")", "}", ":", "\n", "            ", "chunkEnd", "=", "True", "\n", "", "if", "Tag", "!=", "'O'", "and", "Type", "!=", "nextType", ":", "\n", "            ", "chunkEnd", "=", "True", "\n", "\n", "", "if", "chunkStart", ":", "\n", "            ", "start_idx", "=", "idx", "\n", "", "if", "chunkEnd", ":", "\n", "            ", "end_idx", "=", "idx", "\n", "chunks", ".", "append", "(", "(", "start_idx", ",", "end_idx", ",", "Type", ")", ")", "\n", "start_idx", ",", "end_idx", "=", "0", ",", "0", "\n", "", "", "return", "chunks", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.__init__": [[89, 101], ["kwargs.items", "isinstance", "setattr"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_pad_token", "=", "None", "\n", "self", ".", "_unk_token", "=", "None", "\n", "self", ".", "_bos_token", "=", "None", "\n", "self", ".", "_eos_token", "=", "None", "\n", "self", ".", "_seq_token", "=", "None", "\n", "self", ".", "_cls_token", "=", "None", "\n", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", ":", "\n", "                ", "assert", "isinstance", "(", "value", ",", "str", ")", "\n", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.pad_token": [[138, 141], ["None"], "methods", ["None"], ["", "@", "pad_token", ".", "setter", "\n", "def", "pad_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_pad_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.unk_token": [[142, 145], ["None"], "methods", ["None"], ["", "@", "unk_token", ".", "setter", "\n", "def", "unk_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_unk_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.bos_token": [[146, 149], ["None"], "methods", ["None"], ["", "@", "bos_token", ".", "setter", "\n", "def", "bos_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_bos_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.eos_token": [[150, 153], ["None"], "methods", ["None"], ["", "@", "eos_token", ".", "setter", "\n", "def", "eos_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_eos_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.seq_token": [[154, 157], ["None"], "methods", ["None"], ["", "@", "seq_token", ".", "setter", "\n", "def", "seq_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_seq_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.cls_token": [[158, 161], ["None"], "methods", ["None"], ["", "@", "cls_token", ".", "setter", "\n", "def", "cls_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_cls_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids": [[162, 172], ["isinstance", "basic_vocab_reader.Tokenizer._convert_token_to_id", "ids.append", "basic_vocab_reader.Tokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab._convert_token_to_id", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab._convert_token_to_id"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a single token, or a sequence of tokens, (str/unicode) in a single integer id\n            (resp. a sequence of ids), using the vocabulary.\n        \"\"\"", "\n", "if", "isinstance", "(", "tokens", ",", "str", ")", ":", "\n", "            ", "return", "self", ".", "_convert_token_to_id", "(", "tokens", ")", "\n", "", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "ids", ".", "append", "(", "self", ".", "_convert_token_to_id", "(", "token", ")", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer._convert_token_to_id": [[173, 175], ["None"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_ids_to_tokens": [[176, 186], ["isinstance", "basic_vocab_reader.Tokenizer._convert_id_to_token", "tokens.append", "basic_vocab_reader.Tokenizer._convert_id_to_token"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab._convert_id_to_token", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab._convert_id_to_token"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ")", ":", "\n", "        ", "\"\"\" Converts a single index or a sequence of indices (integers) in a token \"\n            (resp.) a sequence of tokens (str/unicode), using the vocabulary and added tokens.\n        \"\"\"", "\n", "if", "isinstance", "(", "ids", ",", "int", ")", ":", "\n", "            ", "return", "self", ".", "_convert_id_to_token", "(", "ids", ")", "\n", "", "tokens", "=", "[", "]", "\n", "for", "index", "in", "ids", ":", "\n", "            ", "tokens", ".", "append", "(", "self", ".", "_convert_id_to_token", "(", "index", ")", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer._convert_id_to_token": [[187, 189], ["None"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUWordTokenizer.__init__": [[195, 208], ["basic_vocab_reader.Tokenizer.__init__", "collections.OrderedDict", "set", "basic_vocab_reader.SLUWordTokenizer.special_tokens.add"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "bos_eos", "=", "False", ",", "lowercase", "=", "False", ",", "bos_token", "=", "'<s>'", ",", "eos_token", "=", "'</s>'", ",", "unk_token", "=", "'<unk>'", ",", "pad_token", "=", "'<pad>'", ",", "seq_token", "=", "'<seq>'", ",", "cls_token", "=", "'<cls>'", ")", ":", "\n", "        ", "super", "(", "SLUWordTokenizer", ",", "self", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "pad_token", "=", "pad_token", ",", "seq_token", "=", "seq_token", ",", "cls_token", "=", "cls_token", ")", "\n", "\n", "self", ".", "lowercase", "=", "lowercase", "\n", "\n", "self", ".", "vocab_size", "=", "0", "\n", "self", ".", "token_to_id", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "#self.id_to_token = collections.OrderedDict()", "\n", "self", ".", "special_tokens", "=", "set", "(", ")", "\n", "for", "token", "in", "(", "self", ".", "pad_token", ",", "self", ".", "unk_token", ",", "self", ".", "bos_token", ",", "self", ".", "eos_token", ",", "self", ".", "seq_token", ",", "self", ".", "cls_token", ")", ":", "\n", "            ", "self", ".", "token_to_id", "[", "token", "]", "=", "self", ".", "vocab_size", "\n", "self", ".", "vocab_size", "+=", "1", "\n", "self", ".", "special_tokens", ".", "add", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUWordTokenizer.get_vocab_size": [[209, 211], ["None"], "methods", ["None"], ["", "", "def", "get_vocab_size", "(", "self", ",", ")", ":", "\n", "        ", "return", "self", ".", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUWordTokenizer.read_word2vec_inText": [[212, 256], ["collections.OrderedDict", "torch.tensor", "collections.OrderedDict", "collections.OrderedDict", "open", "f.readline().strip", "len", "len", "torch.tensor", "len", "int", "line.strip.strip.strip", "line.strip.strip.split", "f.readline", "f.readline().strip.split", "word.lower.lower.lower", "float", "basic_vocab_reader.SLUWordTokenizer.token_to_id.items", "len", "torch.tensor.append"], "methods", ["None"], ["", "def", "read_word2vec_inText", "(", "self", ",", "w2v_file", ",", "device", "=", "None", ")", ":", "\n", "        ", "'''be careful when setting lowercase=True'''", "\n", "special_token_embeddings", "=", "{", "}", "\n", "normal_tokens", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "normal_token_embeddings", "=", "[", "]", "\n", "with", "open", "(", "w2v_file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "head", "=", "f", ".", "readline", "(", ")", ".", "strip", "(", ")", "\n", "word_num", ",", "emb_dim", "=", "[", "int", "(", "value", ")", "for", "value", "in", "head", ".", "split", "(", "' '", ")", "]", "\n", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", "'\\n\\r'", ")", "\n", "items", "=", "line", ".", "split", "(", "' '", ")", "\n", "word", "=", "items", "[", "0", "]", "\n", "if", "self", ".", "lowercase", ":", "\n", "                    ", "word", "=", "word", ".", "lower", "(", ")", "\n", "", "vector", "=", "[", "float", "(", "value", ")", "for", "value", "in", "items", "[", "1", ":", "]", "if", "value", "!=", "\"\"", "]", "\n", "if", "word", "in", "self", ".", "special_tokens", ":", "\n", "                    ", "special_token_embeddings", "[", "word", "]", "=", "vector", "\n", "", "elif", "word", "not", "in", "normal_tokens", ":", "\n", "                    ", "idx", "=", "len", "(", "normal_tokens", ")", "\n", "normal_tokens", "[", "word", "]", "=", "idx", "\n", "normal_token_embeddings", ".", "append", "(", "vector", ")", "\n", "", "", "", "assert", "len", "(", "normal_tokens", ")", "==", "len", "(", "normal_token_embeddings", ")", "\n", "normal_token_embeddings", "=", "torch", ".", "tensor", "(", "normal_token_embeddings", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "\n", "new_token_to_id", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "vocab_size", "=", "0", "\n", "token_out_of_pretrained_emb_num", "=", "0", "\n", "for", "token", "in", "self", ".", "token_to_id", ":", "\n", "            ", "if", "token", "not", "in", "normal_tokens", ":", "\n", "                ", "new_token_to_id", "[", "token", "]", "=", "self", ".", "vocab_size", "\n", "self", ".", "vocab_size", "+=", "1", "\n", "token_out_of_pretrained_emb_num", "+=", "1", "\n", "", "", "for", "token", "in", "normal_tokens", ":", "\n", "            ", "new_token_to_id", "[", "token", "]", "=", "self", ".", "vocab_size", "\n", "self", ".", "vocab_size", "+=", "1", "\n", "\n", "", "self", ".", "token_to_id", "=", "new_token_to_id", "\n", "self", ".", "id_to_token", "=", "collections", ".", "OrderedDict", "(", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "token_to_id", ".", "items", "(", ")", "]", ")", "\n", "\n", "new_special_token_embeddings", "=", "{", "}", "\n", "for", "token", "in", "special_token_embeddings", ":", "\n", "            ", "new_special_token_embeddings", "[", "self", ".", "token_to_id", "[", "token", "]", "]", "=", "torch", ".", "tensor", "(", "special_token_embeddings", "[", "token", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "\n", "", "return", "new_special_token_embeddings", ",", "len", "(", "normal_tokens", ")", ",", "normal_token_embeddings", ",", "token_out_of_pretrained_emb_num", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUWordTokenizer.save_vocab": [[257, 259], ["basic_vocab_reader.save_vocab_file"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.save_vocab_file"], ["", "def", "save_vocab", "(", "self", ",", "vocab_file", ")", ":", "\n", "        ", "save_vocab_file", "(", "self", ".", "token_to_id", ",", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUWordTokenizer.read_vocab": [[260, 267], ["basic_vocab_reader.read_vocab_file", "collections.OrderedDict", "basic_vocab_reader.SLUWordTokenizer.token_to_id.items"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.read_vocab_file"], ["", "def", "read_vocab", "(", "self", ",", "vocab_file", ")", ":", "\n", "        ", "vocab", "=", "read_vocab_file", "(", "vocab_file", ")", "\n", "for", "token", "in", "vocab", ":", "\n", "            ", "if", "token", "not", "in", "self", ".", "token_to_id", ":", "\n", "                ", "self", ".", "token_to_id", "[", "token", "]", "=", "self", ".", "vocab_size", "\n", "self", ".", "vocab_size", "+=", "1", "\n", "", "", "self", ".", "id_to_token", "=", "collections", ".", "OrderedDict", "(", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "token_to_id", ".", "items", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUWordTokenizer._convert_token_to_id": [[268, 271], ["basic_vocab_reader.SLUWordTokenizer.token_to_id.get", "basic_vocab_reader.SLUWordTokenizer.token_to_id.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "token_to_id", ".", "get", "(", "token", ",", "self", ".", "token_to_id", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUWordTokenizer._convert_id_to_token": [[272, 275], ["basic_vocab_reader.SLUWordTokenizer.id_to_token.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "id_to_token", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUWordTokenizer.tokenize": [[276, 283], ["basic_vocab_reader.whitespace_tokenize"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.whitespace_tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"\n        For example:\n            input = \"unaffable\"\n            output = [\"unaffable\"]\n        \"\"\"", "\n", "return", "whitespace_tokenize", "(", "text", ",", "lowercase", "=", "self", ".", "lowercase", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUCharTokenizer.__init__": [[289, 302], ["basic_vocab_reader.Tokenizer.__init__", "collections.OrderedDict", "set", "basic_vocab_reader.SLUCharTokenizer.special_tokens.add"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "bos_eos", "=", "False", ",", "lowercase", "=", "False", ",", "bos_token", "=", "'<s>'", ",", "eos_token", "=", "'</s>'", ",", "unk_token", "=", "'<unk>'", ",", "pad_token", "=", "'<pad>'", ",", "seq_token", "=", "'<seq>'", ",", "cls_token", "=", "'<cls>'", ")", ":", "\n", "        ", "super", "(", "SLUCharTokenizer", ",", "self", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "pad_token", "=", "pad_token", ",", "seq_token", "=", "seq_token", ",", "cls_token", "=", "cls_token", ")", "\n", "\n", "self", ".", "lowercase", "=", "lowercase", "\n", "\n", "self", ".", "vocab_size", "=", "0", "\n", "self", ".", "token_to_id", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "#self.id_to_token = collections.OrderedDict()", "\n", "self", ".", "special_tokens", "=", "set", "(", ")", "\n", "for", "token", "in", "(", "self", ".", "pad_token", ",", "self", ".", "unk_token", ",", "self", ".", "bos_token", ",", "self", ".", "eos_token", ",", "self", ".", "seq_token", ",", "self", ".", "cls_token", ")", ":", "\n", "            ", "self", ".", "token_to_id", "[", "token", "]", "=", "self", ".", "vocab_size", "\n", "self", ".", "vocab_size", "+=", "1", "\n", "self", ".", "special_tokens", ".", "add", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUCharTokenizer.get_vocab_size": [[303, 305], ["None"], "methods", ["None"], ["", "", "def", "get_vocab_size", "(", "self", ",", ")", ":", "\n", "        ", "return", "self", ".", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUCharTokenizer.save_vocab": [[306, 308], ["basic_vocab_reader.save_vocab_file"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.save_vocab_file"], ["", "def", "save_vocab", "(", "self", ",", "vocab_file", ")", ":", "\n", "        ", "save_vocab_file", "(", "self", ".", "token_to_id", ",", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUCharTokenizer.read_vocab": [[309, 316], ["basic_vocab_reader.read_vocab_file", "collections.OrderedDict", "basic_vocab_reader.SLUCharTokenizer.token_to_id.items"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.read_vocab_file"], ["", "def", "read_vocab", "(", "self", ",", "vocab_file", ")", ":", "\n", "        ", "vocab", "=", "read_vocab_file", "(", "vocab_file", ")", "\n", "for", "token", "in", "vocab", ":", "\n", "            ", "if", "token", "not", "in", "self", ".", "token_to_id", ":", "\n", "                ", "self", ".", "token_to_id", "[", "token", "]", "=", "self", ".", "vocab_size", "\n", "self", ".", "vocab_size", "+=", "1", "\n", "", "", "self", ".", "id_to_token", "=", "collections", ".", "OrderedDict", "(", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "token_to_id", ".", "items", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUCharTokenizer._convert_token_to_id": [[317, 320], ["basic_vocab_reader.SLUCharTokenizer.token_to_id.get", "basic_vocab_reader.SLUCharTokenizer.token_to_id.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "token_to_id", ".", "get", "(", "token", ",", "self", ".", "token_to_id", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUCharTokenizer._convert_id_to_token": [[321, 324], ["basic_vocab_reader.SLUCharTokenizer.id_to_token.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "id_to_token", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUCharTokenizer.tokenize": [[325, 335], ["basic_vocab_reader.whitespace_tokenize", "output.append", "tuple"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.whitespace_tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"\n        For example:\n            input = \"unaffable\"\n            output = ['u', 'n', 'a', 'f', 'f', 'a', 'b', 'l', 'e']\n        \"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "word", "in", "whitespace_tokenize", "(", "text", ",", "lowercase", "=", "self", ".", "lowercase", ")", ":", "\n", "            ", "output", ".", "append", "(", "tuple", "(", "word", ")", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUOutputVocab.__init__": [[338, 366], ["basic_vocab_reader.Tokenizer.__init__", "collections.OrderedDict", "collections.OrderedDict", "type", "type", "basic_vocab_reader.read_vocab_file", "basic_vocab_reader.SLUOutputVocab.label_to_id.items"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.read_vocab_file"], ["    ", "def", "__init__", "(", "self", ",", "vocab_data_storage", ",", "no_special_labels", "=", "False", ",", "bos_eos", "=", "False", ",", "bos_token", "=", "'<s>'", ",", "eos_token", "=", "'</s>'", ",", "unk_token", "=", "'<unk>'", ",", "pad_token", "=", "'<pad>'", ")", ":", "\n", "        ", "super", "(", "SLUOutputVocab", ",", "self", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "pad_token", "=", "pad_token", ")", "\n", "\n", "self", ".", "label_to_id", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "special_labels", "=", "{", "self", ".", "pad_token", ",", "self", ".", "unk_token", ",", "self", ".", "bos_token", ",", "self", ".", "eos_token", "}", "\n", "if", "no_special_labels", ":", "\n", "            ", "self", ".", "vocab_size", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "label_to_id", "[", "self", ".", "pad_token", "]", "=", "0", "\n", "self", ".", "label_to_id", "[", "self", ".", "unk_token", "]", "=", "1", "\n", "if", "bos_eos", ":", "\n", "                ", "self", ".", "label_to_id", "[", "self", ".", "bos_token", "]", "=", "2", "\n", "self", ".", "label_to_id", "[", "self", ".", "eos_token", "]", "=", "3", "\n", "self", ".", "vocab_size", "=", "4", "\n", "", "else", ":", "\n", "                ", "self", ".", "vocab_size", "=", "2", "\n", "\n", "", "", "assert", "type", "(", "vocab_data_storage", ")", "in", "{", "str", ",", "list", ",", "tuple", ",", "dict", ",", "set", "}", "\n", "if", "type", "(", "vocab_data_storage", ")", "is", "str", ":", "\n", "            ", "vocab", "=", "read_vocab_file", "(", "vocab_data_storage", ")", "\n", "", "else", ":", "\n", "            ", "vocab", "=", "vocab_data_storage", "\n", "", "for", "label", "in", "vocab", ":", "\n", "            ", "if", "label", "not", "in", "self", ".", "label_to_id", ":", "\n", "                ", "self", ".", "label_to_id", "[", "label", "]", "=", "self", ".", "vocab_size", "\n", "self", ".", "vocab_size", "+=", "1", "\n", "\n", "", "", "self", ".", "id_to_label", "=", "collections", ".", "OrderedDict", "(", "[", "(", "ids", ",", "lab", ")", "for", "lab", ",", "ids", "in", "self", ".", "label_to_id", ".", "items", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUOutputVocab.get_vocab_size": [[367, 369], ["None"], "methods", ["None"], ["", "def", "get_vocab_size", "(", "self", ",", ")", ":", "\n", "        ", "return", "self", ".", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUOutputVocab.save_vocab": [[370, 372], ["basic_vocab_reader.save_vocab_file"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.save_vocab_file"], ["", "def", "save_vocab", "(", "self", ",", "vocab_file", ")", ":", "\n", "        ", "save_vocab_file", "(", "self", ".", "label_to_id", ",", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUOutputVocab._convert_token_to_id": [[373, 376], ["basic_vocab_reader.SLUOutputVocab.label_to_id.get", "basic_vocab_reader.SLUOutputVocab.label_to_id.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "label_to_id", ".", "get", "(", "token", ",", "self", ".", "label_to_id", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUOutputVocab._convert_id_to_token": [[377, 380], ["basic_vocab_reader.SLUOutputVocab.id_to_label.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "id_to_label", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.BIOTagVocab.__init__": [[382, 414], ["basic_vocab_reader.SLUOutputVocab.__init__", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "basic_vocab_reader.BIOTagVocab.bio_of_labels.append", "basic_vocab_reader.BIOTagVocab.name_of_labels.append", "len", "lab.split", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab_file", ",", "no_special_labels", "=", "False", ",", "bos_eos", "=", "False", ",", "bos_token", "=", "'<s>'", ",", "eos_token", "=", "'</s>'", ",", "unk_token", "=", "'<unk>'", ",", "pad_token", "=", "'<pad>'", ")", ":", "\n", "        ", "super", "(", "BIOTagVocab", ",", "self", ")", ".", "__init__", "(", "vocab_file", ",", "no_special_labels", "=", "no_special_labels", ",", "bos_eos", "=", "bos_eos", ",", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "pad_token", "=", "pad_token", ")", "\n", "\n", "self", ".", "label_id_to_bio_and_name_ids", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "bio_to_id", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "special_name_to_id", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "normal_name_to_id", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "bio_of_labels", "=", "[", "]", "\n", "self", ".", "name_of_labels", "=", "[", "]", "\n", "for", "lab", "in", "self", ".", "label_to_id", ":", "\n", "            ", "label_id", "=", "self", ".", "label_to_id", "[", "lab", "]", "\n", "if", "lab", "in", "{", "bos_token", ",", "eos_token", ",", "unk_token", ",", "pad_token", "}", ":", "\n", "                ", "bio", ",", "name", "=", "'O'", ",", "lab", "\n", "", "elif", "lab", "==", "'O'", ":", "\n", "                ", "bio", ",", "name", "=", "'O'", ",", "'<O>'", "\n", "", "else", ":", "\n", "                ", "bio", ",", "name", "=", "lab", ".", "split", "(", "'-'", ",", "1", ")", "\n", "", "if", "bio", "not", "in", "self", ".", "bio_to_id", ":", "\n", "                ", "self", ".", "bio_to_id", "[", "bio", "]", "=", "len", "(", "self", ".", "bio_to_id", ")", "\n", "", "if", "name", "in", "{", "bos_token", ",", "eos_token", ",", "unk_token", ",", "pad_token", ",", "'<O>'", "}", ":", "\n", "                ", "if", "name", "not", "in", "self", ".", "special_name_to_id", ":", "\n", "                    ", "self", ".", "special_name_to_id", "[", "name", "]", "=", "len", "(", "self", ".", "special_name_to_id", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "name", "not", "in", "self", ".", "normal_name_to_id", ":", "\n", "                    ", "self", ".", "normal_name_to_id", "[", "name", "]", "=", "len", "(", "self", ".", "normal_name_to_id", ")", "\n", "", "", "self", ".", "bio_of_labels", ".", "append", "(", "self", ".", "bio_to_id", "[", "bio", "]", ")", "\n", "self", ".", "name_of_labels", ".", "append", "(", "name", ")", "\n", "", "for", "idx", ",", "name", "in", "enumerate", "(", "self", ".", "name_of_labels", ")", ":", "\n", "            ", "if", "name", "in", "{", "bos_token", ",", "eos_token", ",", "unk_token", ",", "pad_token", ",", "'<O>'", "}", ":", "\n", "                ", "self", ".", "name_of_labels", "[", "idx", "]", "=", "self", ".", "special_name_to_id", "[", "name", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "name_of_labels", "[", "idx", "]", "=", "len", "(", "self", ".", "special_name_to_id", ")", "+", "self", ".", "normal_name_to_id", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.BIOTagVocab.save_vocab": [[415, 420], ["basic_vocab_reader.save_vocab_file", "basic_vocab_reader.save_vocab_file", "basic_vocab_reader.save_vocab_file", "basic_vocab_reader.save_vocab_file"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.save_vocab_file", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.save_vocab_file", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.save_vocab_file", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.save_vocab_file"], ["", "", "", "def", "save_vocab", "(", "self", ",", "vocab_file", ",", "bio_vocab_file", ",", "special_name_vocab_file", ",", "normal_name_vocab_file", ")", ":", "\n", "        ", "save_vocab_file", "(", "self", ".", "label_to_id", ",", "vocab_file", ")", "\n", "save_vocab_file", "(", "self", ".", "bio_to_id", ",", "bio_vocab_file", ")", "\n", "save_vocab_file", "(", "self", ".", "special_name_to_id", ",", "special_name_vocab_file", ")", "\n", "save_vocab_file", "(", "self", ".", "normal_name_to_id", ",", "normal_name_vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.BIOTagVocab.get_bio_tensor_and_selected_slot_indexes": [[421, 427], ["torch.eye", "torch.index_select", "bio_tensor.to.to.to", "torch.tensor", "len", "torch.tensor"], "methods", ["None"], ["", "def", "get_bio_tensor_and_selected_slot_indexes", "(", "self", ",", "device", "=", "None", ")", ":", "\n", "        ", "bio_one_hot", "=", "torch", ".", "eye", "(", "len", "(", "self", ".", "bio_to_id", ")", ")", "\n", "bio_tensor", "=", "torch", ".", "index_select", "(", "bio_one_hot", ",", "0", ",", "torch", ".", "tensor", "(", "self", ".", "bio_of_labels", ")", ")", "\n", "bio_tensor", "=", "bio_tensor", ".", "to", "(", "device", "=", "device", ")", "\n", "selected_slot_indexes", "=", "torch", ".", "tensor", "(", "self", ".", "name_of_labels", ",", "device", "=", "device", ")", "\n", "return", "bio_tensor", ",", "selected_slot_indexes", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.read_vocab_file": [[12, 21], ["collections.OrderedDict", "enumerate", "open", "reader.readlines", "token.rstrip.rstrip"], "function", ["None"], ["def", "read_vocab_file", "(", "vocab_file", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ")", "as", "reader", ":", "\n", "        ", "tokens", "=", "reader", ".", "readlines", "(", ")", "\n", "", "for", "index", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "token", "=", "token", ".", "rstrip", "(", "'\\n'", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.save_vocab_file": [[22, 32], ["open", "sorted", "token_to_id.items", "writer.write", "print"], "function", ["None"], ["", "def", "save_vocab_file", "(", "token_to_id", ",", "vocab_file", ")", ":", "\n", "    ", "index", "=", "0", "\n", "with", "open", "(", "vocab_file", ",", "'w'", ")", "as", "writer", ":", "\n", "        ", "for", "token", ",", "token_index", "in", "sorted", "(", "token_to_id", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "            ", "if", "index", "!=", "token_index", ":", "\n", "                ", "print", "(", "\"Saving vocabulary to {}: vocabulary indices are not consecutive.\"", "\n", "\" Please check that the vocabulary is not corrupted!\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "token", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.read_input_vocab_from_data_file": [[33, 76], ["print", "open", "sorted", "collections.OrderedDict", "collections.OrderedDict", "slot_tag_line.split", "all_tokens.items", "line.strip().split", "item.split", "word.lower.lower", "word_tokenizer.token_to_id.items", "char_tokenizer.token_to_id.items", "line.strip", "len", "separator.join"], "function", ["None"], ["", "", "", "def", "read_input_vocab_from_data_file", "(", "file_name", ",", "word_tokenizer", "=", "None", ",", "char_tokenizer", "=", "None", ",", "lowercase", "=", "False", ",", "mini_word_freq", "=", "1", ",", "with_tag", "=", "True", ",", "separator", "=", "':'", ")", ":", "\n", "    ", "\"\"\"\n    data_line: I:O want:O to:O fly:O to:O Shanghai:B-to_city <=> find_flight\n    \"\"\"", "\n", "assert", "word_tokenizer", "is", "not", "None", "or", "char_tokenizer", "is", "not", "None", "\n", "print", "(", "'Constructing input vocabulary from '", ",", "file_name", ",", "' ...'", ")", "\n", "all_tokens", "=", "{", "}", "\n", "with", "open", "(", "file_name", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "slot_tag_line", "=", "line", ".", "strip", "(", "'\\n\\r'", ")", ".", "split", "(", "' <=> '", ")", "[", "0", "]", "\n", "if", "slot_tag_line", "==", "\"\"", ":", "\n", "                ", "continue", "\n", "", "for", "item", "in", "slot_tag_line", ".", "split", "(", "' '", ")", ":", "\n", "                ", "if", "with_tag", ":", "\n", "                    ", "tmp", "=", "item", ".", "split", "(", "separator", ")", "\n", "assert", "len", "(", "tmp", ")", ">=", "2", "\n", "word", ",", "tag", "=", "separator", ".", "join", "(", "tmp", "[", ":", "-", "1", "]", ")", ",", "tmp", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "word", "=", "item", "\n", "", "if", "lowercase", ":", "\n", "                    ", "word", "=", "word", ".", "lower", "(", ")", "\n", "\n", "", "if", "word", "not", "in", "all_tokens", ":", "\n", "                    ", "all_tokens", "[", "word", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "all_tokens", "[", "word", "]", "+=", "1", "\n", "\n", "", "", "", "", "if", "word_tokenizer", "is", "not", "None", ":", "\n", "        ", "sorted_all_tokens", "=", "sorted", "(", "all_tokens", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "selected_tokens", "=", "[", "x", "[", "0", "]", "for", "x", "in", "sorted_all_tokens", "if", "x", "[", "1", "]", ">=", "mini_word_freq", "]", "\n", "for", "token", "in", "selected_tokens", ":", "\n", "            ", "if", "token", "not", "in", "word_tokenizer", ".", "token_to_id", ":", "\n", "                ", "word_tokenizer", ".", "token_to_id", "[", "token", "]", "=", "word_tokenizer", ".", "vocab_size", "\n", "word_tokenizer", ".", "vocab_size", "+=", "1", "\n", "", "", "word_tokenizer", ".", "id_to_token", "=", "collections", ".", "OrderedDict", "(", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "word_tokenizer", ".", "token_to_id", ".", "items", "(", ")", "]", ")", "\n", "\n", "", "if", "char_tokenizer", "is", "not", "None", ":", "\n", "        ", "for", "word", "in", "all_tokens", ":", "\n", "            ", "for", "char", "in", "word", ":", "\n", "                ", "if", "char", "not", "in", "char_tokenizer", ".", "token_to_id", ":", "\n", "                    ", "char_tokenizer", ".", "token_to_id", "[", "char", "]", "=", "char_tokenizer", ".", "vocab_size", "\n", "char_tokenizer", ".", "vocab_size", "+=", "1", "\n", "", "", "", "char_tokenizer", ".", "id_to_token", "=", "collections", ".", "OrderedDict", "(", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "char_tokenizer", ".", "token_to_id", ".", "items", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.whitespace_tokenize": [[77, 84], ["text.strip.strip", "token.lower", "text.strip.split"], "function", ["None"], ["", "", "def", "whitespace_tokenize", "(", "text", ",", "lowercase", "=", "False", ")", ":", "\n", "    ", "\"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "        ", "return", "[", "]", "\n", "", "tokens", "=", "[", "token", ".", "lower", "(", ")", "if", "lowercase", "else", "token", "for", "token", "in", "text", ".", "split", "(", ")", "]", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.pretrained_transformer.load_pretrained_transformer": [[19, 30], ["tokenizer_class.from_pretrained", "print", "pretrained_model_class.from_pretrained", "pretrained_model_class.from_pretrained.apply", "print"], "function", ["None"], ["def", "load_pretrained_transformer", "(", "model_type", ",", "model_name", ")", ":", "\n", "    ", "pretrained_model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "model_type", "]", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "model_name", ")", "\n", "print", "(", "'tokenizer.basic_tokenizer.do_lower_case:'", ",", "tokenizer", ".", "basic_tokenizer", ".", "do_lower_case", ")", "\n", "#pretrained_model = pretrained_model_class.from_pretrained(model_name, output_hidden_states = True)", "\n", "pretrained_model", "=", "pretrained_model_class", ".", "from_pretrained", "(", "model_name", ")", "\n", "def", "add_no_init_flag", "(", "module", ")", ":", "\n", "        ", "module", ".", "sz128__no_init_flag", "=", "True", "\n", "", "pretrained_model", ".", "apply", "(", "add_no_init_flag", ")", "\n", "print", "(", "'pretrained_model.config:'", ",", "pretrained_model", ".", "config", ")", "\n", "return", "tokenizer", ",", "pretrained_model", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.pretrained_transformer.load_pretrained_transformer_full": [[31, 48], ["tokenizer_class.from_pretrained", "print", "pretrained_model_class.from_pretrained", "pretrained_model_class.from_pretrained.apply", "print", "bool", "bool"], "function", ["None"], ["", "def", "load_pretrained_transformer_full", "(", "model_type", ",", "model_name", ")", ":", "\n", "    ", "pretrained_model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "model_type", "]", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "model_name", ")", "\n", "print", "(", "'tokenizer.basic_tokenizer.do_lower_case:'", ",", "tokenizer", ".", "basic_tokenizer", ".", "do_lower_case", ")", "\n", "#pretrained_model = pretrained_model_class.from_pretrained(model_name, output_hidden_states = True)", "\n", "pretrained_model", "=", "pretrained_model_class", ".", "from_pretrained", "(", "model_name", ")", "\n", "def", "add_no_init_flag", "(", "module", ")", ":", "\n", "        ", "module", ".", "sz128__no_init_flag", "=", "True", "\n", "", "pretrained_model", ".", "apply", "(", "add_no_init_flag", ")", "\n", "print", "(", "'pretrained_model.config:'", ",", "pretrained_model", ".", "config", ")", "\n", "tf_input_args", "=", "{", "\n", "'cls_token_at_end'", ":", "bool", "(", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "'cls_token_segment_id'", ":", "2", "if", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "'pad_on_left'", ":", "bool", "(", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "'pad_token_segment_id'", ":", "4", "if", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "}", "\n", "return", "tokenizer", ",", "pretrained_model", ",", "tf_input_args", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.pretrained_transformer.transformer_forward_by_ignoring_suffix": [[49, 65], ["transformer", "pretrained_top_hiddens.view().index_select", "torch.zeros", "embeds.index_copy_().view.index_copy_().view", "pretrained_top_hiddens.size", "pretrained_top_hiddens.size", "pretrained_top_hiddens.size", "pretrained_top_hiddens.view", "embeds.index_copy_().view.index_copy_"], "function", ["None"], ["", "def", "transformer_forward_by_ignoring_suffix", "(", "transformer", ",", "batch_size", ",", "max_word_length", ",", "input_ids", ",", "segment_ids", ",", "selects", ",", "copies", ",", "attention_mask", ",", "device", "=", "None", ",", "get_pooled_output", "=", "False", ")", ":", "\n", "    ", "'''\n    Ignore hidden states of all suffixes: [CLS] from ... to de ##n ##ver [SEP] => from ... to de\n    '''", "\n", "outputs", "=", "transformer", "(", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "pretrained_top_hiddens", "=", "outputs", "[", "0", "]", "\n", "if", "get_pooled_output", ":", "\n", "        ", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "", "batch_size", ",", "pretrained_seq_length", ",", "hidden_size", "=", "pretrained_top_hiddens", ".", "size", "(", "0", ")", ",", "pretrained_top_hiddens", ".", "size", "(", "1", ")", ",", "pretrained_top_hiddens", ".", "size", "(", "2", ")", "\n", "chosen_encoder_hiddens", "=", "pretrained_top_hiddens", ".", "view", "(", "-", "1", ",", "hidden_size", ")", ".", "index_select", "(", "0", ",", "selects", ")", "\n", "embeds", "=", "torch", ".", "zeros", "(", "batch_size", "*", "max_word_length", ",", "hidden_size", ",", "device", "=", "device", ")", "\n", "embeds", "=", "embeds", ".", "index_copy_", "(", "0", ",", "copies", ",", "chosen_encoder_hiddens", ")", ".", "view", "(", "batch_size", ",", "max_word_length", ",", "-", "1", ")", "\n", "if", "get_pooled_output", ":", "\n", "        ", "return", "embeds", ",", "pooled_output", "\n", "", "else", ":", "\n", "        ", "return", "embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.pretrained_transformer.prepare_inputs_for_bert_xlnet": [[66, 211], ["enumerate", "max", "max", "torch.tensor", "torch.tensor", "torch.tensor", "word_lengths.append", "enumerate", "tokens.append", "segment_ids.append", "len", "len", "torch.tensor", "len", "tokenizer.tokenize", "output_tokens.append", "len", "selected_indexes.append", "len", "torch.tensor", "torch.tensor", "torch.tensor", "output_tokens.append", "torch.tensor.append", "torch.tensor.append", "enumerate", "tokenizer.convert_tokens_to_ids", "enumerate", "enumerate", "enumerate", "tokenizer.convert_tokens_to_ids", "enumerate", "enumerate", "enumerate", "enumerate", "torch.tensor", "selected_index.append", "selected_index.append", "aggregated_count.append", "torch.tensor.append", "torch.tensor.append", "len", "enumerate", "len", "enumerate", "len", "len", "len", "list", "torch.tensor.append", "torch.tensor.append", "enumerate", "enumerate", "len", "range", "list", "range", "range", "len", "range", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUCharTokenizer.tokenize", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids"], ["", "", "def", "prepare_inputs_for_bert_xlnet", "(", "input_sentences", ",", "tokenizer", ",", "bos_eos", "=", "False", ",", "cls_token_at_end", "=", "False", ",", "pad_on_left", "=", "False", ",", "pad_token", "=", "0", ",", "sequence_a_segment_id", "=", "0", ",", "cls_token_segment_id", "=", "1", ",", "pad_token_segment_id", "=", "0", ",", "device", "=", "None", ",", "feed_transformer", "=", "False", ",", "alignment", "=", "'first'", ")", ":", "\n", "    ", "\"\"\"\n    NOTE: If you want to feed bert/xlnet embeddings into RNN/GRU/LSTM by using pack_padded_sequence, you'd better sort input sentences in advance.\n    \"\"\"", "\n", "\"\"\"\n    TODO: if feed_transformer == True, select CLS output as the first embedding of cls_token\n    \"\"\"", "\n", "\"\"\" Loads a data file into a list of `InputBatch`s\n        `cls_token_at_end` define the location of the CLS token:\n            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n    \"\"\"", "\n", "\"\"\" output: {\n        'tokens': tokens_tensor,        # input_ids\n        'segments': segments_tensor,    # token_type_ids\n        'mask': input_mask,             # attention_mask\n        'gather_index': gather_index,      # gather_index\n        }\n    \"\"\"", "\n", "## sentences are sorted by sentence length", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", "# [CLS]", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", "# [SEP]", "\n", "if", "bos_eos", ":", "\n", "        ", "bos_token", "=", "tokenizer", ".", "bos_token", "\n", "eos_token", "=", "tokenizer", ".", "eos_token", "\n", "\n", "", "word_lengths", "=", "[", "]", "\n", "tokens", "=", "[", "]", "\n", "segment_ids", "=", "[", "]", "\n", "if", "alignment", "==", "'first'", ":", "\n", "        ", "selected_indexes", "=", "[", "]", "\n", "", "elif", "alignment", "==", "'avg'", ":", "\n", "        ", "remove_cls_seq_gather_indexes", "=", "[", "]", "# for aggregation; first, remove cls and seq", "\n", "aggregated_indexes", "=", "[", "]", "# for aggregation; after removing cls and seq", "\n", "aggregated_counts", "=", "[", "]", "# for aggregation; after removing cls and seq", "\n", "", "elif", "alignment", "==", "'ori'", ":", "\n", "        ", "remove_cls_seq_gather_indexes", "=", "[", "]", "# remove cls and seq", "\n", "", "output_tokens", "=", "[", "]", "\n", "start_pos", "=", "0", "\n", "for", "snt_idx", ",", "words", "in", "enumerate", "(", "input_sentences", ")", ":", "\n", "        ", "if", "bos_eos", ":", "\n", "            ", "words", "=", "[", "bos_token", "]", "+", "words", "+", "[", "eos_token", "]", "\n", "", "word_lengths", ".", "append", "(", "len", "(", "words", ")", ")", "\n", "if", "alignment", "==", "'first'", ":", "\n", "            ", "selected_index", "=", "[", "]", "\n", "", "elif", "alignment", "==", "'avg'", ":", "\n", "            ", "aggregated_index", "=", "[", "]", "\n", "aggregated_count", "=", "[", "]", "\n", "", "ts_1", "=", "[", "]", "\n", "for", "w_idx", ",", "w", "in", "enumerate", "(", "words", ")", ":", "\n", "            ", "_toks", "=", "tokenizer", ".", "tokenize", "(", "w", ")", "\n", "if", "alignment", "==", "'first'", ":", "\n", "                ", "if", "cls_token_at_end", ":", "\n", "                    ", "selected_index", ".", "append", "(", "len", "(", "ts_1", ")", ")", "\n", "", "else", ":", "\n", "                    ", "selected_index", ".", "append", "(", "len", "(", "ts_1", ")", "+", "1", ")", "\n", "", "", "elif", "alignment", "==", "'avg'", ":", "\n", "                ", "aggregated_index", "+=", "[", "w_idx", "]", "*", "len", "(", "_toks", ")", "\n", "aggregated_count", ".", "append", "(", "len", "(", "_toks", ")", ")", "\n", "", "ts_1", "+=", "_toks", "\n", "", "if", "alignment", "in", "{", "'first'", ",", "'avg'", "}", ":", "\n", "            ", "output_tokens", ".", "append", "(", "words", ")", "\n", "", "elif", "alignment", "==", "'ori'", ":", "\n", "            ", "output_tokens", ".", "append", "(", "ts_1", ")", "\n", "", "si", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "ts_1", ")", "\n", "if", "cls_token_at_end", ":", "\n", "            ", "ts", "=", "ts_1", "+", "[", "sep_token", ",", "cls_token", "]", "\n", "si", "=", "si", "+", "[", "sequence_a_segment_id", ",", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "ts", "=", "[", "cls_token", "]", "+", "ts_1", "+", "[", "sep_token", "]", "\n", "si", "=", "[", "cls_token_segment_id", "]", "+", "si", "+", "[", "sequence_a_segment_id", "]", "\n", "", "tokens", ".", "append", "(", "ts", ")", "\n", "#print(ts)", "\n", "segment_ids", ".", "append", "(", "si", ")", "\n", "if", "alignment", "==", "'first'", ":", "\n", "            ", "selected_indexes", ".", "append", "(", "selected_index", ")", "\n", "", "elif", "alignment", "==", "'avg'", ":", "\n", "            ", "if", "cls_token_at_end", ":", "\n", "                ", "remove_cls_seq_gather_indexes", ".", "append", "(", "list", "(", "range", "(", "len", "(", "ts", ")", "-", "2", ")", ")", ")", "# ..... [SEP] [CLS]", "\n", "", "else", ":", "\n", "                ", "remove_cls_seq_gather_indexes", ".", "append", "(", "[", "i", "+", "1", "for", "i", "in", "range", "(", "len", "(", "ts", ")", "-", "2", ")", "]", ")", "# [CLS] ..... [SEP]", "\n", "", "aggregated_indexes", ".", "append", "(", "aggregated_index", ")", "\n", "aggregated_counts", ".", "append", "(", "aggregated_count", ")", "\n", "", "elif", "alignment", "==", "'ori'", ":", "\n", "            ", "if", "cls_token_at_end", ":", "\n", "                ", "remove_cls_seq_gather_indexes", ".", "append", "(", "list", "(", "range", "(", "len", "(", "ts", ")", "-", "2", ")", ")", ")", "# ..... [SEP] [CLS]", "\n", "", "else", ":", "\n", "                ", "remove_cls_seq_gather_indexes", ".", "append", "(", "[", "i", "+", "1", "for", "i", "in", "range", "(", "len", "(", "ts", ")", "-", "2", ")", "]", ")", "# [CLS] ..... [SEP]", "\n", "\n", "", "", "", "max_length_of_sentences", "=", "max", "(", "word_lengths", ")", "# the length is already +2 when bos_eos is True.", "\n", "token_lengths", "=", "[", "len", "(", "tokenized_text", ")", "for", "tokenized_text", "in", "tokens", "]", "\n", "max_length_of_tokens", "=", "max", "(", "token_lengths", ")", "\n", "#if not cls_token_at_end: # bert", "\n", "#    assert max_length_of_tokens <= model_bert.config.max_position_embeddings", "\n", "padding_lengths", "=", "[", "max_length_of_tokens", "-", "len", "(", "tokenized_text", ")", "for", "tokenized_text", "in", "tokens", "]", "\n", "if", "pad_on_left", ":", "\n", "        ", "input_mask", "=", "[", "[", "0", "]", "*", "padding_lengths", "[", "idx", "]", "+", "[", "1", "]", "*", "len", "(", "tokenized_text", ")", "for", "idx", ",", "tokenized_text", "in", "enumerate", "(", "tokens", ")", "]", "\n", "indexed_tokens", "=", "[", "[", "pad_token", "]", "*", "padding_lengths", "[", "idx", "]", "+", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "for", "idx", ",", "tokenized_text", "in", "enumerate", "(", "tokens", ")", "]", "\n", "segments_ids", "=", "[", "[", "pad_token_segment_id", "]", "*", "padding_lengths", "[", "idx", "]", "+", "si", "for", "idx", ",", "si", "in", "enumerate", "(", "segment_ids", ")", "]", "\n", "## word embeddings will always pad on the right size!", "\n", "if", "alignment", "==", "'first'", ":", "\n", "#gather_indexes = [[0] * (max_length_of_sentences - word_lengths[idx]) + [padding_lengths[idx] + i for i in selected_index] for idx,selected_index in enumerate(selected_indexes)]", "\n", "            ", "gather_indexes", "=", "[", "[", "padding_lengths", "[", "idx", "]", "+", "i", "for", "i", "in", "selected_index", "]", "+", "[", "0", "]", "*", "(", "max_length_of_sentences", "-", "word_lengths", "[", "idx", "]", ")", "for", "idx", ",", "selected_index", "in", "enumerate", "(", "selected_indexes", ")", "]", "\n", "", "elif", "alignment", "in", "{", "'ori'", ",", "'avg'", "}", ":", "\n", "#remove_cls_seq_gather_indexes = [[0] * padding_lengths[idx] + [padding_lengths[idx] + i for i in remove_cls_seq_index] for idx,remove_cls_seq_index in enumerate(remove_cls_seq_gather_indexes)]", "\n", "            ", "remove_cls_seq_gather_indexes", "=", "[", "[", "padding_lengths", "[", "idx", "]", "+", "i", "for", "i", "in", "remove_cls_seq_index", "]", "+", "[", "0", "]", "*", "padding_lengths", "[", "idx", "]", "for", "idx", ",", "remove_cls_seq_index", "in", "enumerate", "(", "remove_cls_seq_gather_indexes", ")", "]", "\n", "", "", "else", ":", "\n", "        ", "input_mask", "=", "[", "[", "1", "]", "*", "len", "(", "tokenized_text", ")", "+", "[", "0", "]", "*", "padding_lengths", "[", "idx", "]", "for", "idx", ",", "tokenized_text", "in", "enumerate", "(", "tokens", ")", "]", "\n", "indexed_tokens", "=", "[", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenized_text", ")", "+", "[", "pad_token", "]", "*", "padding_lengths", "[", "idx", "]", "for", "idx", ",", "tokenized_text", "in", "enumerate", "(", "tokens", ")", "]", "\n", "segments_ids", "=", "[", "si", "+", "[", "pad_token_segment_id", "]", "*", "padding_lengths", "[", "idx", "]", "for", "idx", ",", "si", "in", "enumerate", "(", "segment_ids", ")", "]", "\n", "if", "alignment", "==", "'first'", ":", "\n", "            ", "gather_indexes", "=", "[", "selected_index", "+", "[", "max_length_of_tokens", "-", "1", "]", "*", "(", "max_length_of_sentences", "-", "word_lengths", "[", "idx", "]", ")", "for", "idx", ",", "selected_index", "in", "enumerate", "(", "selected_indexes", ")", "]", "\n", "", "elif", "alignment", "in", "{", "'ori'", ",", "'avg'", "}", ":", "\n", "            ", "remove_cls_seq_gather_indexes", "=", "[", "remove_cls_seq_index", "+", "[", "max_length_of_tokens", "-", "1", "]", "*", "padding_lengths", "[", "idx", "]", "for", "idx", ",", "remove_cls_seq_index", "in", "enumerate", "(", "remove_cls_seq_gather_indexes", ")", "]", "\n", "", "", "if", "alignment", "==", "'avg'", ":", "\n", "## output of hiddens should be masked to zero in positions of padding", "\n", "        ", "aggregated_indexes", "=", "[", "aggregated_index", "+", "[", "aggregated_index", "[", "-", "1", "]", "]", "*", "padding_lengths", "[", "idx", "]", "for", "idx", ",", "aggregated_index", "in", "enumerate", "(", "aggregated_indexes", ")", "]", "\n", "aggregated_counts", "=", "[", "aggregated_count", "+", "[", "1", "]", "*", "(", "max_length_of_sentences", "-", "word_lengths", "[", "idx", "]", ")", "for", "idx", ",", "aggregated_count", "in", "enumerate", "(", "aggregated_counts", ")", "]", "\n", "\n", "", "input_mask", "=", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "tokens_tensor", "=", "torch", ".", "tensor", "(", "indexed_tokens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "segments_tensor", "=", "torch", ".", "tensor", "(", "segments_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "output", "=", "{", "\n", "\"input_ids\"", ":", "tokens_tensor", ",", "\n", "\"segment_ids\"", ":", "segments_tensor", ",", "\n", "\"attention_mask\"", ":", "input_mask", "\n", "}", "\n", "output", "[", "\"lengths\"", "]", "=", "[", "len", "(", "seq", ")", "for", "seq", "in", "output_tokens", "]", "\n", "if", "alignment", "==", "'first'", ":", "\n", "        ", "gather_indexes", "=", "torch", ".", "tensor", "(", "gather_indexes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "output", "[", "\"gather_index\"", "]", "=", "gather_indexes", "\n", "", "elif", "alignment", "==", "'avg'", ":", "\n", "        ", "remove_cls_seq_gather_indexes", "=", "torch", ".", "tensor", "(", "remove_cls_seq_gather_indexes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "aggregated_indexes", "=", "torch", ".", "tensor", "(", "aggregated_indexes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "aggregated_counts", "=", "torch", ".", "tensor", "(", "aggregated_counts", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "output", "[", "\"remove_cls_seq_gather_index\"", "]", "=", "remove_cls_seq_gather_indexes", "\n", "output", "[", "\"aggregated_index\"", "]", "=", "aggregated_indexes", "\n", "output", "[", "\"aggregated_count\"", "]", "=", "aggregated_counts", "\n", "output", "[", "\"max_word_seq_length\"", "]", "=", "max_length_of_sentences", "\n", "", "elif", "alignment", "==", "'ori'", ":", "\n", "        ", "remove_cls_seq_gather_indexes", "=", "torch", ".", "tensor", "(", "remove_cls_seq_gather_indexes", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "output", "[", "\"remove_cls_seq_gather_index\"", "]", "=", "remove_cls_seq_gather_indexes", "\n", "\n", "", "return", "output", "#, tokens, output_tokens, [len(seq) for seq in output_to]", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.pretrained_transformer.transformer_forward_by_ignoring_suffix_2": [[212, 242], ["transformer", "pretrained_top_hiddens.masked_fill_", "torch.gather", "gather_index[].expand", "torch.gather", "torch.zeros", "torch.zeros.scatter_add_", "remove_cls_seq_gather_index[].expand", "aggregated_index[].expand", "torch.gather", "remove_cls_seq_gather_index[].expand"], "function", ["None"], ["", "def", "transformer_forward_by_ignoring_suffix_2", "(", "transformer", ",", "input_ids", ",", "segment_ids", ",", "attention_mask", ",", "gather_index", "=", "None", ",", "remove_cls_seq_gather_index", "=", "None", ",", "aggregated_index", "=", "None", ",", "aggregated_count", "=", "None", ",", "max_word_seq_length", "=", "None", ",", "device", "=", "None", ",", "alignment", "=", "'first'", ")", ":", "\n", "    ", "'''\n    ['first', 'avg']: Ignore hidden states of all suffixes: [CLS] from ... to de ##n ##ver [SEP] => from ... to de\n    ['ori']: Ignore hidden states of [CLS] and [SEP]: [CLS] from ... to de ##n ##ver [SEP] => from ... to de ##n ##ver\n    !!! and padding on the right side !!!\n    '''", "\n", "\n", "#assert alignment in {'ori', 'first', 'avg', None}", "\n", "\n", "outputs", "=", "transformer", "(", "input_ids", ",", "token_type_ids", "=", "segment_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "pretrained_top_hiddens", "=", "outputs", "[", "0", "]", "\n", "#print(pretrained_top_hiddens[-1])", "\n", "batch_size", ",", "token_seq_length", ",", "hidden_size", "=", "pretrained_top_hiddens", ".", "shape", "\n", "pretrained_top_hiddens", ".", "masked_fill_", "(", "(", "1", "-", "attention_mask", ")", ".", "to", "(", "torch", ".", "bool", ")", "[", ":", ",", ":", ",", "None", "]", ",", "0", ")", "\n", "\n", "if", "alignment", "==", "'first'", ":", "\n", "        ", "embeds", "=", "torch", ".", "gather", "(", "pretrained_top_hiddens", ",", "1", ",", "gather_index", "[", ":", ",", ":", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hidden_size", ")", ")", "# expand does not allocate new memory", "\n", "", "elif", "alignment", "==", "'avg'", ":", "\n", "        ", "pretrained_top_hiddens_without_cls_seq", "=", "torch", ".", "gather", "(", "pretrained_top_hiddens", ",", "1", ",", "remove_cls_seq_gather_index", "[", ":", ",", ":", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hidden_size", ")", ")", "\n", "\n", "aggregated_embeds", "=", "torch", ".", "zeros", "(", "batch_size", ",", "max_word_seq_length", ",", "hidden_size", ",", "device", "=", "device", ")", "\n", "aggregated_embeds", ".", "scatter_add_", "(", "1", ",", "aggregated_index", "[", ":", ",", ":", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hidden_size", ")", ",", "pretrained_top_hiddens_without_cls_seq", ")", "\n", "embeds", "=", "aggregated_embeds", "/", "aggregated_count", "[", ":", ",", ":", ",", "None", "]", "\n", "", "elif", "alignment", "==", "'ori'", ":", "\n", "        ", "pretrained_top_hiddens_without_cls_seq", "=", "torch", ".", "gather", "(", "pretrained_top_hiddens", ",", "1", ",", "remove_cls_seq_gather_index", "[", ":", ",", ":", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hidden_size", ")", ")", "\n", "embeds", "=", "pretrained_top_hiddens_without_cls_seq", "\n", "", "else", ":", "\n", "        ", "embeds", "=", "pretrained_top_hiddens", "\n", "#print(embeds[-1])", "\n", "", "return", "embeds", "\n", "", ""]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.__init__": [[58, 116], ["Tokenizer.__init__", "collections.OrderedDict", "torch.tensor", "collections.OrderedDict", "list", "len", "type", "type", "read_vocab_file", "vocab_reader.FewShotSlotVocab.get_bio_tensor_and_selected_slot_indexes", "vocab_reader.FewShotSlotVocab.other_labels.append", "vocab_reader.FewShotSlotVocab.label_to_id.items"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.read_vocab_file", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.get_bio_tensor_and_selected_slot_indexes"], ["    ", "def", "__init__", "(", "self", ",", "vocab_data_storage", ",", "slot_embedding_type", "=", "'with_BIO'", ",", "no_special_labels", "=", "False", ",", "bos_eos", "=", "False", ",", "bos_token", "=", "'<s>'", ",", "eos_token", "=", "'</s>'", ",", "unk_token", "=", "'<unk>'", ",", "pad_token", "=", "'<pad>'", ")", ":", "\n", "        ", "'''\n        slot_embedding_type:\n          1. with_BIO : all slot-tag embeddings are calculated from support set;\n          2. with_BI : except that 'O' is ranomly initilized as an embedding vector with the same dimension;\n          3. without_BIO : all slot embeddings are calculated from support set except for 'O', and 'B/I' are ranomly initilized as embedding vectors which will be added into slot embeddings to represent slot-tags.\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "pad_token", "=", "pad_token", ")", "\n", "\n", "self", ".", "label_to_id", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "self", ".", "special_labels", "=", "{", "self", ".", "pad_token", ",", "self", ".", "unk_token", ",", "self", ".", "bos_token", ",", "self", ".", "eos_token", "}", "\n", "if", "no_special_labels", ":", "\n", "            ", "self", ".", "vocab_size", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "label_to_id", "[", "self", ".", "pad_token", "]", "=", "0", "\n", "self", ".", "label_to_id", "[", "self", ".", "unk_token", "]", "=", "1", "\n", "if", "bos_eos", ":", "\n", "                ", "self", ".", "label_to_id", "[", "self", ".", "bos_token", "]", "=", "2", "\n", "self", ".", "label_to_id", "[", "self", ".", "eos_token", "]", "=", "3", "\n", "self", ".", "vocab_size", "=", "4", "\n", "", "else", ":", "\n", "                ", "self", ".", "vocab_size", "=", "2", "\n", "\n", "", "", "self", ".", "init_token_to_id", "=", "{", "}", "\n", "for", "tok", "in", "list", "(", "self", ".", "label_to_id", ")", "+", "[", "'B'", ",", "'I'", ",", "'O'", "]", ":", "\n", "            ", "self", ".", "init_token_to_id", "[", "tok", "]", "=", "len", "(", "self", ".", "init_token_to_id", ")", "\n", "", "assert", "slot_embedding_type", "in", "{", "'with_BIO'", ",", "'with_BI'", ",", "'without_BIO'", "}", "\n", "self", ".", "slot_embedding_type", "=", "slot_embedding_type", "\n", "if", "self", ".", "slot_embedding_type", "==", "'with_BIO'", ":", "\n", "            ", "self", ".", "head_labels_token_ids", "=", "[", "self", ".", "init_token_to_id", "[", "tok", "]", "for", "tok", "in", "self", ".", "label_to_id", "]", "\n", "self", ".", "other_labels", "=", "[", "'O'", "]", "\n", "## NOTE: 'O' is put in the head", "\n", "self", ".", "label_to_id", "[", "'O'", "]", "=", "self", ".", "vocab_size", "\n", "self", ".", "vocab_size", "+=", "1", "\n", "", "else", ":", "\n", "## NOTE: 'O' is put in the head", "\n", "            ", "self", ".", "label_to_id", "[", "'O'", "]", "=", "self", ".", "vocab_size", "\n", "self", ".", "vocab_size", "+=", "1", "\n", "self", ".", "head_labels_token_ids", "=", "[", "self", ".", "init_token_to_id", "[", "tok", "]", "for", "tok", "in", "self", ".", "label_to_id", "]", "\n", "self", ".", "other_labels", "=", "[", "]", "\n", "#self.other_labels_seg_ids =", "\n", "\n", "", "assert", "type", "(", "vocab_data_storage", ")", "in", "{", "str", ",", "list", ",", "tuple", ",", "dict", "}", "# set is not deterministic", "\n", "if", "type", "(", "vocab_data_storage", ")", "is", "str", ":", "\n", "            ", "vocab", "=", "read_vocab_file", "(", "vocab_data_storage", ")", "\n", "", "else", ":", "\n", "            ", "vocab", "=", "vocab_data_storage", "\n", "", "for", "label", "in", "vocab", ":", "\n", "            ", "if", "label", "not", "in", "self", ".", "label_to_id", ":", "\n", "                ", "self", ".", "label_to_id", "[", "label", "]", "=", "self", ".", "vocab_size", "\n", "self", ".", "vocab_size", "+=", "1", "\n", "self", ".", "other_labels", ".", "append", "(", "label", ")", "\n", "\n", "", "", "self", ".", "head_labels_token_ids", "=", "torch", ".", "tensor", "(", "self", ".", "head_labels_token_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "slot_embedding_type", "==", "'without_BIO'", ":", "\n", "            ", "self", ".", "get_bio_tensor_and_selected_slot_indexes", "(", ")", "\n", "\n", "", "self", ".", "id_to_label", "=", "collections", ".", "OrderedDict", "(", "[", "(", "ids", ",", "lab", ")", "for", "lab", ",", "ids", "in", "self", ".", "label_to_id", ".", "items", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.get_bio_tensor_and_selected_slot_indexes": [[117, 130], ["torch.tensor", "torch.tensor", "label.split", "vocab_reader.FewShotSlotVocab.other_labels_seg_ids.append", "vocab_reader.FewShotSlotVocab.other_labels_selected_slot_ids.append", "vocab_reader.FewShotSlotVocab.other_labels_slot_names.append", "len", "len"], "methods", ["None"], ["", "def", "get_bio_tensor_and_selected_slot_indexes", "(", "self", ")", ":", "\n", "        ", "self", ".", "other_labels_seg_ids", "=", "[", "]", "\n", "self", ".", "other_labels_slot_names", "=", "[", "]", "\n", "self", ".", "other_labels_selected_slot_ids", "=", "[", "]", "\n", "for", "label", "in", "self", ".", "other_labels", ":", "\n", "            ", "bio", ",", "slot_name", "=", "label", ".", "split", "(", "'-'", ",", "1", ")", "\n", "self", ".", "other_labels_seg_ids", ".", "append", "(", "self", ".", "init_token_to_id", "[", "bio", "]", ")", "\n", "if", "len", "(", "self", ".", "other_labels_slot_names", ")", "==", "0", "or", "slot_name", "!=", "self", ".", "other_labels_slot_names", "[", "-", "1", "]", ":", "\n", "                ", "self", ".", "other_labels_slot_names", ".", "append", "(", "slot_name", ")", "\n", "", "self", ".", "other_labels_selected_slot_ids", ".", "append", "(", "len", "(", "self", ".", "other_labels_slot_names", ")", "-", "1", ")", "\n", "\n", "", "self", ".", "other_labels_seg_ids", "=", "torch", ".", "tensor", "(", "self", ".", "other_labels_seg_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "self", ".", "other_labels_selected_slot_ids", "=", "torch", ".", "tensor", "(", "self", ".", "other_labels_selected_slot_ids", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.get_elements_used_in_label_embeddings": [[131, 140], ["vocab_reader.FewShotSlotVocab.head_labels_token_ids.to", "vocab_reader.FewShotSlotVocab.other_labels_seg_ids.to", "vocab_reader.FewShotSlotVocab.other_labels_selected_slot_ids.to"], "methods", ["None"], ["", "def", "get_elements_used_in_label_embeddings", "(", "self", ",", "device", "=", "None", ")", ":", "\n", "        ", "head_labels_token_ids", "=", "self", ".", "head_labels_token_ids", ".", "to", "(", "device", "=", "device", ")", "\n", "if", "self", ".", "slot_embedding_type", "==", "'without_BIO'", ":", "\n", "            ", "other_labels_seg_ids", "=", "self", ".", "other_labels_seg_ids", ".", "to", "(", "device", "=", "device", ")", "\n", "other_labels_selected_slot_ids", "=", "self", ".", "other_labels_selected_slot_ids", ".", "to", "(", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "            ", "other_labels_seg_ids", "=", "None", "\n", "other_labels_selected_slot_ids", "=", "None", "\n", "", "return", "head_labels_token_ids", ",", "other_labels_seg_ids", ",", "other_labels_selected_slot_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.get_label_description_for_HIT_data": [[141, 163], ["label_descriptions.append", "label.split", "exit"], "methods", ["None"], ["", "def", "get_label_description_for_HIT_data", "(", "self", ",", "slot_to_desc", ")", ":", "\n", "        ", "label_descriptions", "=", "[", "]", "\n", "for", "label", "in", "self", ".", "other_labels", ":", "\n", "            ", "if", "label", "==", "'O'", ":", "\n", "                ", "words", "=", "[", "'ordinary'", ",", "'-'", "]", "\n", "", "else", ":", "\n", "                ", "bio", ",", "slot", "=", "label", ".", "split", "(", "'-'", ",", "1", ")", "\n", "if", "bio", "==", "'B'", ":", "\n", "                    ", "bio", "=", "'begin'", "\n", "", "elif", "bio", "==", "'I'", ":", "\n", "                    ", "bio", "=", "'inner'", "\n", "", "elif", "bio", "==", "'S'", ":", "\n", "                    ", "bio", "=", "'single'", "\n", "", "elif", "bio", "==", "'M'", ":", "\n", "                    ", "bio", "=", "'middle'", "\n", "", "elif", "bio", "==", "'E'", ":", "\n", "                    ", "bio", "=", "'end'", "\n", "", "else", ":", "\n", "                    ", "exit", "(", ")", "\n", "", "words", "=", "[", "bio", ",", "'-'", "]", "+", "slot_to_desc", "[", "slot", "]", "\n", "", "label_descriptions", ".", "append", "(", "words", ")", "\n", "", "return", "label_descriptions", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.get_vocab_size": [[164, 166], ["None"], "methods", ["None"], ["", "def", "get_vocab_size", "(", "self", ",", ")", ":", "\n", "        ", "return", "self", ".", "vocab_size", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.save_vocab": [[167, 169], ["save_vocab_file"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.save_vocab_file"], ["", "def", "save_vocab", "(", "self", ",", "vocab_file", ")", ":", "\n", "        ", "save_vocab_file", "(", "self", ".", "label_to_id", ",", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab._convert_token_to_id": [[170, 173], ["vocab_reader.FewShotSlotVocab.label_to_id.get", "vocab_reader.FewShotSlotVocab.label_to_id.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "label_to_id", ".", "get", "(", "token", ",", "self", ".", "label_to_id", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab._convert_id_to_token": [[174, 177], ["vocab_reader.FewShotSlotVocab.id_to_label.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "id_to_label", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.read_input_vocab_from_data_file_in_HIT_form": [[15, 55], ["print", "open", "json.load", "sorted", "collections.OrderedDict", "collections.OrderedDict", "all_tokens.items", "word_tokenizer.token_to_id.items", "char_tokenizer.token_to_id.items", "word.lower.lower"], "function", ["None"], ["def", "read_input_vocab_from_data_file_in_HIT_form", "(", "file_name", ",", "word_tokenizer", "=", "None", ",", "char_tokenizer", "=", "None", ",", "lowercase", "=", "False", ",", "mini_word_freq", "=", "1", ",", "with_tag", "=", "True", ",", "separator", "=", "':'", ")", ":", "\n", "    ", "\"\"\"\n    json file\n    \"\"\"", "\n", "assert", "word_tokenizer", "is", "not", "None", "or", "char_tokenizer", "is", "not", "None", "\n", "print", "(", "'Constructing input vocabulary from '", ",", "file_name", ",", "' ...'", ")", "\n", "all_tokens", "=", "{", "}", "\n", "with", "open", "(", "file_name", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "for", "domain_name", "in", "data", ":", "\n", "            ", "for", "batch", "in", "data", "[", "domain_name", "]", ":", "\n", "#print(list(batch['support'])) # ['seq_ins', 'labels', 'seq_outs', 'word_piece_marks', 'tokenized_texts', 'word_piece_labels']", "\n", "#print(list(batch['batch'])) # ['seq_ins', 'labels', 'seq_outs', 'word_piece_marks', 'tokenized_texts', 'word_piece_labels']", "\n", "                ", "for", "data_type", "in", "[", "'support'", ",", "'batch'", "]", ":", "\n", "                    ", "for", "words", "in", "batch", "[", "data_type", "]", "[", "'seq_ins'", "]", ":", "\n", "                        ", "for", "word", "in", "words", ":", "\n", "                            ", "if", "lowercase", ":", "\n", "                                ", "word", "=", "word", ".", "lower", "(", ")", "\n", "\n", "", "if", "word", "not", "in", "all_tokens", ":", "\n", "                                ", "all_tokens", "[", "word", "]", "=", "1", "\n", "", "else", ":", "\n", "                                ", "all_tokens", "[", "word", "]", "+=", "1", "\n", "\n", "", "", "", "", "", "", "", "if", "word_tokenizer", "is", "not", "None", ":", "\n", "        ", "sorted_all_tokens", "=", "sorted", "(", "all_tokens", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "selected_tokens", "=", "[", "x", "[", "0", "]", "for", "x", "in", "sorted_all_tokens", "if", "x", "[", "1", "]", ">=", "mini_word_freq", "]", "\n", "for", "token", "in", "selected_tokens", ":", "\n", "            ", "if", "token", "not", "in", "word_tokenizer", ".", "token_to_id", ":", "\n", "                ", "word_tokenizer", ".", "token_to_id", "[", "token", "]", "=", "word_tokenizer", ".", "vocab_size", "\n", "word_tokenizer", ".", "vocab_size", "+=", "1", "\n", "", "", "word_tokenizer", ".", "id_to_token", "=", "collections", ".", "OrderedDict", "(", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "word_tokenizer", ".", "token_to_id", ".", "items", "(", ")", "]", ")", "\n", "\n", "", "if", "char_tokenizer", "is", "not", "None", ":", "\n", "        ", "for", "word", "in", "all_tokens", ":", "\n", "            ", "for", "char", "in", "word", ":", "\n", "                ", "if", "char", "not", "in", "char_tokenizer", ".", "token_to_id", ":", "\n", "                    ", "char_tokenizer", ".", "token_to_id", "[", "char", "]", "=", "char_tokenizer", ".", "vocab_size", "\n", "char_tokenizer", ".", "vocab_size", "+=", "1", "\n", "", "", "", "char_tokenizer", ".", "id_to_token", "=", "collections", ".", "OrderedDict", "(", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "char_tokenizer", ".", "token_to_id", ".", "items", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.compute_fscore": [[3, 18], ["None"], "function", ["None"], ["def", "compute_fscore", "(", "TP", ",", "FP", ",", "FN", ")", ":", "\n", "    ", "metrics", "=", "{", "'p'", ":", "0", ",", "'r'", ":", "0", ",", "'f'", ":", "0", "}", "\n", "if", "TP", "+", "FP", "==", "0", ":", "\n", "        ", "metrics", "[", "'p'", "]", "=", "'Nan'", "\n", "", "else", ":", "\n", "        ", "metrics", "[", "'p'", "]", "=", "100", "*", "TP", "/", "(", "TP", "+", "FP", ")", "\n", "", "if", "TP", "+", "FN", "==", "0", ":", "\n", "        ", "metrics", "[", "'r'", "]", "=", "'Nan'", "\n", "", "else", ":", "\n", "        ", "metrics", "[", "'r'", "]", "=", "100", "*", "TP", "/", "(", "TP", "+", "FN", ")", "\n", "", "if", "2", "*", "TP", "+", "FP", "+", "FN", "==", "0", ":", "\n", "        ", "metrics", "[", "'f'", "]", "=", "'Nan'", "\n", "", "else", ":", "\n", "        ", "metrics", "[", "'f'", "]", "=", "100", "*", "2", "*", "TP", "/", "(", "2", "*", "TP", "+", "FP", "+", "FN", ")", "\n", "", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.analysis_fscore": [[19, 34], ["None"], "function", ["None"], ["", "def", "analysis_fscore", "(", "pred_items", ",", "label_items", ")", ":", "\n", "    ", "\"\"\"\n    pred_items: a set\n    label_items: a set\n    \"\"\"", "\n", "TP", ",", "FP", ",", "FN", "=", "0", ",", "0", ",", "0", "\n", "for", "pred_item", "in", "pred_items", ":", "\n", "        ", "if", "pred_item", "in", "label_items", ":", "\n", "            ", "TP", "+=", "1", "\n", "", "else", ":", "\n", "            ", "FP", "+=", "1", "\n", "", "", "for", "label_item", "in", "label_items", ":", "\n", "        ", "if", "label_item", "not", "in", "pred_items", ":", "\n", "            ", "FN", "+=", "1", "\n", "", "", "return", "TP", ",", "FP", ",", "FN", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.get_tuples_of_slot_and_intent": [[35, 48], ["set", "set.add", "intent.split", "len", "set.add", "set.add", "tuple", "value.replace"], "function", ["None"], ["", "def", "get_tuples_of_slot_and_intent", "(", "words", ",", "chunks", ",", "intents", ")", ":", "\n", "    ", "tuples", "=", "set", "(", ")", "\n", "for", "start_idx", ",", "end_idx", ",", "slot_name", "in", "chunks", ":", "\n", "        ", "tuples", ".", "add", "(", "(", "slot_name", ",", "''", ".", "join", "(", "words", "[", "start_idx", "-", "1", ":", "end_idx", "]", ")", ".", "replace", "(", "' '", ",", "''", ")", ")", ")", "\n", "", "for", "intent", "in", "intents", ":", "\n", "        ", "if", "intent", "not", "in", "{", "'<pad>'", ",", "'<unk>'", ",", "'<EMPTY>'", "}", ":", "\n", "            ", "items", "=", "intent", ".", "split", "(", "'-'", ")", "\n", "if", "len", "(", "items", ")", "<", "3", ":", "\n", "                ", "tuples", ".", "add", "(", "tuple", "(", "items", ")", ")", "\n", "", "else", ":", "\n", "                ", "act", ",", "slot", ",", "value", "=", "items", "\n", "tuples", ".", "add", "(", "(", "act", "+", "'-'", "+", "slot", ",", "value", ".", "replace", "(", "' '", ",", "''", ")", ")", ")", "\n", "", "", "", "return", "tuples", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.get_chunks": [[49, 88], ["range", "len", "chunks.append"], "function", ["None"], ["", "def", "get_chunks", "(", "labels", ")", ":", "\n", "    ", "\"\"\"\n        It supports IOB2 or IOBES tagging scheme.\n        You may also want to try https://github.com/sighsmile/conlleval.\n    \"\"\"", "\n", "chunks", "=", "[", "]", "\n", "start_idx", ",", "end_idx", "=", "0", ",", "0", "\n", "for", "idx", "in", "range", "(", "1", ",", "len", "(", "labels", ")", "-", "1", ")", ":", "\n", "        ", "chunkStart", ",", "chunkEnd", "=", "False", ",", "False", "\n", "if", "labels", "[", "idx", "-", "1", "]", "not", "in", "(", "'O'", ",", "'<pad>'", ",", "'<unk>'", ",", "'<s>'", ",", "'</s>'", ",", "'<STOP>'", ",", "'<START>'", ")", ":", "\n", "            ", "prevTag", ",", "prevType", "=", "labels", "[", "idx", "-", "1", "]", "[", ":", "1", "]", ",", "labels", "[", "idx", "-", "1", "]", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "prevTag", ",", "prevType", "=", "'O'", ",", "'O'", "\n", "", "if", "labels", "[", "idx", "]", "not", "in", "(", "'O'", ",", "'<pad>'", ",", "'<unk>'", ",", "'<s>'", ",", "'</s>'", ",", "'<STOP>'", ",", "'<START>'", ")", ":", "\n", "            ", "Tag", ",", "Type", "=", "labels", "[", "idx", "]", "[", ":", "1", "]", ",", "labels", "[", "idx", "]", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "Tag", ",", "Type", "=", "'O'", ",", "'O'", "\n", "", "if", "labels", "[", "idx", "+", "1", "]", "not", "in", "(", "'O'", ",", "'<pad>'", ",", "'<unk>'", ",", "'<s>'", ",", "'</s>'", ",", "'<STOP>'", ",", "'<START>'", ")", ":", "\n", "            ", "nextTag", ",", "nextType", "=", "labels", "[", "idx", "+", "1", "]", "[", ":", "1", "]", ",", "labels", "[", "idx", "+", "1", "]", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "nextTag", ",", "nextType", "=", "'O'", ",", "'O'", "\n", "\n", "", "if", "Tag", "==", "'B'", "or", "Tag", "==", "'S'", "or", "(", "prevTag", ",", "Tag", ")", "in", "{", "(", "'O'", ",", "'I'", ")", ",", "(", "'O'", ",", "'E'", ")", ",", "(", "'E'", ",", "'I'", ")", ",", "(", "'E'", ",", "'E'", ")", ",", "(", "'S'", ",", "'I'", ")", ",", "(", "'S'", ",", "'E'", ")", "}", ":", "\n", "            ", "chunkStart", "=", "True", "\n", "", "if", "Tag", "!=", "'O'", "and", "prevType", "!=", "Type", ":", "\n", "            ", "chunkStart", "=", "True", "\n", "\n", "", "if", "Tag", "==", "'E'", "or", "Tag", "==", "'S'", "or", "(", "Tag", ",", "nextTag", ")", "in", "{", "(", "'B'", ",", "'B'", ")", ",", "(", "'B'", ",", "'O'", ")", ",", "(", "'B'", ",", "'S'", ")", ",", "(", "'I'", ",", "'B'", ")", ",", "(", "'I'", ",", "'O'", ")", ",", "(", "'I'", ",", "'S'", ")", "}", ":", "\n", "            ", "chunkEnd", "=", "True", "\n", "", "if", "Tag", "!=", "'O'", "and", "Type", "!=", "nextType", ":", "\n", "            ", "chunkEnd", "=", "True", "\n", "\n", "", "if", "chunkStart", ":", "\n", "            ", "start_idx", "=", "idx", "\n", "", "if", "chunkEnd", ":", "\n", "            ", "end_idx", "=", "idx", "\n", "chunks", ".", "append", "(", "(", "start_idx", ",", "end_idx", ",", "Type", ")", ")", "\n", "start_idx", ",", "end_idx", "=", "0", ",", "0", "\n", "", "", "return", "chunks", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.util.set_logger": [[6, 43], ["logging.Formatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "logging.root.removeHandler", "logging.FileHandler", "logging.FileHandler", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "time.asctime", "print", "time.localtime", "time.time"], "function", ["None"], ["def", "set_logger", "(", "args", ",", "exp_path", ")", ":", "\n", "    ", "try", ":", "\n", "# FIXME(https://github.com/abseil/abseil-py/issues/99)", "\n", "# FIXME(https://github.com/abseil/abseil-py/issues/102)", "\n", "# Unfortunately, many libraries that include absl (including Tensorflow)", "\n", "# will get bitten by double-logging due to absl's incorrect use of", "\n", "# the python logging library:", "\n", "#   2019-07-19 23:47:38,829 my_logger   779 : test", "\n", "#   I0719 23:47:38.829330 139904865122112 foo.py:63] test", "\n", "#   2019-07-19 23:47:38,829 my_logger   779 : test", "\n", "#   I0719 23:47:38.829469 139904865122112 foo.py:63] test", "\n", "# The code below fixes this double-logging.  FMI see:", "\n", "#   https://github.com/tensorflow/tensorflow/issues/26691#issuecomment-500369493", "\n", "        ", "import", "absl", ".", "logging", "\n", "logging", ".", "root", ".", "removeHandler", "(", "absl", ".", "logging", ".", "_absl_handler", ")", "\n", "absl", ".", "logging", ".", "_warn_preinit_stderr", "=", "False", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"Failed to fix absl logging bug\"", ",", "e", ")", "\n", "pass", "\n", "\n", "", "logFormatter", "=", "logging", ".", "Formatter", "(", "'%(message)s'", ")", "#('%(asctime)s - %(levelname)s - %(message)s')", "\n", "logger", "=", "logging", ".", "getLogger", "(", "'mylogger'", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "if", "args", ".", "testing", ":", "\n", "        ", "fileHandler", "=", "logging", ".", "FileHandler", "(", "'%s/log_test.txt'", "%", "(", "exp_path", ")", ",", "mode", "=", "'w'", ")", "\n", "", "else", ":", "\n", "        ", "fileHandler", "=", "logging", ".", "FileHandler", "(", "'%s/log_train.txt'", "%", "(", "exp_path", ")", ",", "mode", "=", "'w'", ")", "\n", "", "fileHandler", ".", "setFormatter", "(", "logFormatter", ")", "\n", "logger", ".", "addHandler", "(", "fileHandler", ")", "\n", "if", "not", "args", ".", "noStdout", ":", "\n", "        ", "consoleHandler", "=", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "\n", "consoleHandler", ".", "setFormatter", "(", "logFormatter", ")", "\n", "logger", ".", "addHandler", "(", "consoleHandler", ")", "\n", "", "logger", ".", "info", "(", "args", ")", "\n", "logger", ".", "info", "(", "\"Experiment path: %s\"", "%", "(", "exp_path", ")", ")", "\n", "logger", ".", "info", "(", "time", ".", "asctime", "(", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ")", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.util.setup_device": [[44, 52], ["torch.cuda.set_device", "torch.device", "logger.info", "torch.device"], "function", ["None"], ["", "def", "setup_device", "(", "deviceId", ",", "logger", ")", ":", "\n", "    ", "if", "deviceId", ">=", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "deviceId", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "# is equivalent to torch.device('cuda:X') where X is the result of torch.cuda.current_device()", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"CPU is used.\"", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "return", "device", "\n", "", ""]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.SlotIntentDataset_in_HIT_form.__init__": [[24, 27], ["data_reader_HIT.SlotIntentDataset_in_HIT_form.read_seqtag_data_with_class"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.FewShotSlotIntentDataset_in_HIT_form.read_seqtag_data_with_class"], ["def", "__init__", "(", "self", ",", "data_file", ",", "slot_tags_vocab", ",", "intents_vocab", ",", "MTL_vocab_share_type", ",", "lowercase", "=", "False", ",", "separator", "=", "':'", ")", ":", "\n", "\n", "        ", "self", ".", "all_data_samples", "=", "self", ".", "read_seqtag_data_with_class", "(", "data_file", ",", "slot_tags_vocab", ",", "intents_vocab", ",", "MTL_vocab_share_type", ",", "lowercase", "=", "lowercase", ",", "separator", "=", "separator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.SlotIntentDataset_in_HIT_form.read_seqtag_data_with_class": [[28, 90], ["open", "json.load", "set", "set", "torch.tensor", "torch.tensor", "all_data_samples.append", "set", "len", "range", "data_batch_support_query.append", "torch.tensor.append", "torch.tensor.append", "data_batch.append", "in_seq.append", "tag_seq.append", "word.lower.lower.lower"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "read_seqtag_data_with_class", "(", "self", ",", "data_file", ",", "slot_tags_vocab", ",", "intents_vocab", ",", "MTL_vocab_share_type", ",", "lowercase", "=", "False", ",", "separator", "=", "':'", ")", ":", "\n", "        ", "all_data_samples", "=", "[", "]", "\n", "with", "open", "(", "data_file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "ind", "=", "0", "\n", "for", "domain_name", "in", "data", ":", "\n", "                ", "for", "batch", "in", "data", "[", "domain_name", "]", ":", "\n", "#print(list(batch['support'])) # ['seq_ins', 'labels', 'seq_outs', 'word_piece_marks', 'tokenized_texts', 'word_piece_labels']", "\n", "#print(list(batch['batch'])) # ['seq_ins', 'labels', 'seq_outs', 'word_piece_marks', 'tokenized_texts', 'word_piece_labels']", "\n", "                    ", "supported_slot_tags", "=", "set", "(", ")", "\n", "for", "slots", "in", "batch", "[", "'support'", "]", "[", "'seq_outs'", "]", ":", "\n", "                        ", "supported_slot_tags", "|=", "set", "(", "slots", ")", "\n", "", "supported_intents", "=", "set", "(", "batch", "[", "'support'", "]", "[", "'labels'", "]", ")", "\n", "if", "MTL_vocab_share_type", "==", "'just_O'", ":", "\n", "                        ", "supported_slot_tags", "=", "{", "slot", "+", "'__'", "+", "domain_name", "if", "slot", "!=", "'O'", "else", "'O'", "for", "slot", "in", "supported_slot_tags", "}", "\n", "", "elif", "MTL_vocab_share_type", "==", "'no'", ":", "\n", "                        ", "supported_slot_tags", "=", "{", "slot", "+", "'__'", "+", "domain_name", "for", "slot", "in", "supported_slot_tags", "}", "\n", "", "if", "MTL_vocab_share_type", "in", "{", "'just_O'", ",", "'no'", "}", ":", "\n", "                        ", "supported_intents", "=", "{", "intent", "+", "'__'", "+", "domain_name", "for", "intent", "in", "supported_intents", "}", "\n", "", "masked_slot_tags", "=", "[", "]", "\n", "for", "idx", "in", "slot_tags_vocab", ".", "id_to_label", ":", "\n", "                        ", "label", "=", "slot_tags_vocab", ".", "id_to_label", "[", "idx", "]", "\n", "if", "label", "in", "slot_tags_vocab", ".", "special_labels", "or", "label", "in", "supported_slot_tags", ":", "\n", "                            ", "pass", "\n", "", "else", ":", "\n", "                            ", "masked_slot_tags", ".", "append", "(", "idx", ")", "\n", "", "", "masked_slot_tags", "=", "torch", ".", "tensor", "(", "masked_slot_tags", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "masked_intents", "=", "[", "]", "\n", "for", "idx", "in", "intents_vocab", ".", "id_to_label", ":", "\n", "                        ", "label", "=", "intents_vocab", ".", "id_to_label", "[", "idx", "]", "\n", "if", "label", "in", "intents_vocab", ".", "special_labels", "or", "label", "in", "supported_intents", ":", "\n", "                            ", "pass", "\n", "", "else", ":", "\n", "                            ", "masked_intents", ".", "append", "(", "idx", ")", "\n", "", "", "masked_intents", "=", "torch", ".", "tensor", "(", "masked_intents", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "data_batch_support_query", "=", "[", "]", "\n", "for", "data_type", "in", "[", "'support'", ",", "'batch'", "]", ":", "\n", "                        ", "data_batch", "=", "[", "]", "\n", "batch_size", "=", "len", "(", "batch", "[", "data_type", "]", "[", "'seq_ins'", "]", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                            ", "in_seq", "=", "[", "]", "\n", "for", "word", "in", "batch", "[", "data_type", "]", "[", "'seq_ins'", "]", "[", "i", "]", ":", "\n", "                                ", "if", "lowercase", ":", "\n", "                                    ", "word", "=", "word", ".", "lower", "(", ")", "\n", "", "in_seq", ".", "append", "(", "word", ")", "\n", "", "tag_seq", "=", "[", "]", "\n", "for", "slot", "in", "batch", "[", "data_type", "]", "[", "'seq_outs'", "]", "[", "i", "]", ":", "\n", "                                ", "if", "MTL_vocab_share_type", "==", "'just_O'", ":", "\n", "                                    ", "slot", "=", "slot", "+", "'__'", "+", "domain_name", "if", "slot", "!=", "'O'", "else", "'O'", "\n", "", "elif", "MTL_vocab_share_type", "==", "'no'", ":", "\n", "                                    ", "slot", "=", "slot", "+", "'__'", "+", "domain_name", "\n", "", "tag_seq", ".", "append", "(", "slot", ")", "\n", "", "class_name", "=", "batch", "[", "data_type", "]", "[", "'labels'", "]", "[", "i", "]", "\n", "if", "MTL_vocab_share_type", "in", "{", "'just_O'", ",", "'no'", "}", ":", "\n", "                                ", "class_name", "=", "class_name", "+", "'__'", "+", "domain_name", "\n", "", "data_batch", ".", "append", "(", "[", "ind", ",", "in_seq", ",", "tag_seq", ",", "class_name", "]", ")", "\n", "ind", "+=", "1", "\n", "", "data_batch_support_query", ".", "append", "(", "data_batch", ")", "\n", "", "all_data_samples", ".", "append", "(", "data_batch_support_query", "+", "[", "masked_slot_tags", ",", "masked_intents", "]", ")", "\n", "\n", "", "", "", "return", "all_data_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.SlotIntentDataset_in_HIT_form.__len__": [[91, 93], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "all_data_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.SlotIntentDataset_in_HIT_form.__getitem__": [[94, 96], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "all_data_samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.FewShotSlotIntentDataset_in_HIT_form.__init__": [[99, 102], ["data_reader_HIT.FewShotSlotIntentDataset_in_HIT_form.read_seqtag_data_with_class"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.FewShotSlotIntentDataset_in_HIT_form.read_seqtag_data_with_class"], ["def", "__init__", "(", "self", ",", "data_file", ",", "slot_desc_file", ",", "slot_embedding_type", "=", "'with_BIO'", ",", "bert_tokenized", "=", "False", ",", "lowercase", "=", "False", ",", "separator", "=", "':'", ",", "input_bos_eos", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "all_data_samples", "=", "self", ".", "read_seqtag_data_with_class", "(", "data_file", ",", "slot_desc_file", ",", "slot_embedding_type", "=", "slot_embedding_type", ",", "bert_tokenized", "=", "bert_tokenized", ",", "lowercase", "=", "lowercase", ",", "separator", "=", "separator", ",", "input_bos_eos", "=", "input_bos_eos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.FewShotSlotIntentDataset_in_HIT_form.read_seqtag_data_with_class": [[103, 155], ["open", "open", "json.load", "desc.split", "line.strip().split", "set", "set", "sorted", "sorted", "utils.vocab_reader.FewShotSlotVocab", "utils.basic_vocab_reader.SLUOutputVocab", "utils.vocab_reader.FewShotSlotVocab.get_label_description_for_HIT_data", "all_data_samples.append", "set", "list", "list", "len", "range", "data_batch_support_query.append", "line.strip", "data_batch.append", "in_seq.append", "tag_seq.append", "word.lower.lower.lower"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.get_label_description_for_HIT_data"], ["", "@", "classmethod", "\n", "def", "read_seqtag_data_with_class", "(", "self", ",", "data_file", ",", "slot_desc_file", ",", "slot_embedding_type", "=", "'with_BIO'", ",", "bert_tokenized", "=", "False", ",", "lowercase", "=", "False", ",", "separator", "=", "':'", ",", "input_bos_eos", "=", "False", ")", ":", "\n", "        ", "slot_to_desc", "=", "{", "}", "\n", "with", "open", "(", "slot_desc_file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "slot", ",", "desc", "=", "line", ".", "strip", "(", "'\\n\\r\\t '", ")", ".", "split", "(", "' : '", ")", "[", ":", "2", "]", "\n", "slot_to_desc", "[", "slot", "]", "=", "desc", ".", "split", "(", "' '", ")", "\n", "", "", "all_data_samples", "=", "[", "]", "\n", "with", "open", "(", "data_file", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "ind", "=", "0", "\n", "for", "domain_name", "in", "data", ":", "\n", "                ", "for", "batch", "in", "data", "[", "domain_name", "]", ":", "\n", "#print(list(batch['support'])) # ['seq_ins', 'labels', 'seq_outs', 'word_piece_marks', 'tokenized_texts', 'word_piece_labels']", "\n", "#print(list(batch['batch'])) # ['seq_ins', 'labels', 'seq_outs', 'word_piece_marks', 'tokenized_texts', 'word_piece_labels']", "\n", "                    ", "if", "not", "bert_tokenized", ":", "\n", "                        ", "seq_ins_tag", "=", "'seq_ins'", "\n", "seq_out_tag", "=", "'seq_outs'", "\n", "", "else", ":", "\n", "                        ", "seq_ins_tag", "=", "'tokenized_texts'", "\n", "seq_out_tag", "=", "'word_piece_labels'", "\n", "## get vocabulary", "\n", "", "supported_slot_tags", "=", "set", "(", ")", "\n", "for", "slots", "in", "batch", "[", "'support'", "]", "[", "seq_out_tag", "]", ":", "\n", "                        ", "supported_slot_tags", "|=", "set", "(", "slots", ")", "\n", "", "supported_intents", "=", "set", "(", "batch", "[", "'support'", "]", "[", "'labels'", "]", ")", "\n", "supported_slot_tags", "=", "sorted", "(", "list", "(", "supported_slot_tags", ")", ")", "\n", "supported_intents", "=", "sorted", "(", "list", "(", "supported_intents", ")", ")", "\n", "slot_tags_vocab", "=", "FewShotSlotVocab", "(", "supported_slot_tags", ",", "slot_embedding_type", "=", "slot_embedding_type", ",", "bos_eos", "=", "input_bos_eos", ")", "\n", "intents_vocab", "=", "SLUOutputVocab", "(", "supported_intents", ",", "no_special_labels", "=", "True", ")", "\n", "slot_desc_in_words", "=", "slot_tags_vocab", ".", "get_label_description_for_HIT_data", "(", "slot_to_desc", ")", "\n", "## get data", "\n", "data_batch_support_query", "=", "[", "]", "\n", "for", "data_type", "in", "[", "'support'", ",", "'batch'", "]", ":", "\n", "                        ", "data_batch", "=", "[", "]", "\n", "batch_size", "=", "len", "(", "batch", "[", "data_type", "]", "[", "seq_ins_tag", "]", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                            ", "in_seq", "=", "[", "]", "\n", "for", "word", "in", "batch", "[", "data_type", "]", "[", "seq_ins_tag", "]", "[", "i", "]", ":", "\n", "                                ", "if", "lowercase", ":", "\n", "                                    ", "word", "=", "word", ".", "lower", "(", ")", "\n", "", "in_seq", ".", "append", "(", "word", ")", "\n", "", "tag_seq", "=", "[", "]", "\n", "for", "slot", "in", "batch", "[", "data_type", "]", "[", "seq_out_tag", "]", "[", "i", "]", ":", "\n", "                                ", "tag_seq", ".", "append", "(", "slot", ")", "\n", "", "class_name", "=", "batch", "[", "data_type", "]", "[", "'labels'", "]", "[", "i", "]", "\n", "data_batch", ".", "append", "(", "[", "ind", ",", "in_seq", ",", "tag_seq", ",", "class_name", "]", ")", "\n", "ind", "+=", "1", "\n", "", "data_batch_support_query", ".", "append", "(", "data_batch", ")", "\n", "", "all_data_samples", ".", "append", "(", "data_batch_support_query", "+", "[", "slot_tags_vocab", ",", "intents_vocab", ",", "slot_desc_in_words", "]", ")", "\n", "\n", "", "", "", "return", "all_data_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.FewShotSlotIntentDataset_in_HIT_form.__len__": [[156, 158], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "all_data_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.FewShotSlotIntentDataset_in_HIT_form.__getitem__": [[159, 161], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "all_data_samples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.read_label_indicator_of_support_set": [[162, 219], ["len", "max", "len", "torch.tensor", "torch.tensor", "torch.tensor", "range", "torch.tensor.append", "torch.tensor.sum", "range", "torch.tensor.append", "torch.tensor.sum", "range", "torch.tensor.append", "torch.tensor.sum", "enumerate", "utils.metric.get_chunks", "type", "range"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.get_chunks"], ["", "", "def", "read_label_indicator_of_support_set", "(", "slot_tags_vocab", ",", "intents_vocab", ",", "support_tags", ",", "support_intents", ",", "indicator_type", "=", "'PN'", ",", "slot_embedding_type", "=", "'with_BIO'", ",", "device", "=", "None", ")", ":", "\n", "    ", "'''\n    indicator_type: (different ways to compute similarities between a hidden vector and each label embedding)\n      1. PN (prototypical network);\n      2. MN (matching network)\n      3. NMN (normalized matching network)\n    slot_embedding_type:\n      1. with_BIO : all slot-tag embeddings are calculated from support set;\n      2. with_BI : except that 'O' is ranomly initilized as an embedding vector with the same dimension;\n      3. without_BIO : all slot embeddings are calculated from support set except for 'O', and 'B/I' are ranomly initilized as embedding vectors which will be added into slot embeddings to represent slot-tags.\n    '''", "\n", "batch_size", "=", "len", "(", "support_tags", ")", "\n", "lengths", "=", "[", "len", "(", "seq", ")", "for", "seq", "in", "support_tags", "]", "\n", "max_length", "=", "max", "(", "lengths", ")", "\n", "if", "indicator_type", "==", "'PN'", ":", "\n", "        ", "if", "slot_embedding_type", "==", "'with_BIO'", "or", "slot_embedding_type", "==", "'with_BI'", ":", "\n", "            ", "slot_label_indicator", "=", "[", "]", "\n", "for", "tag", "in", "slot_tags_vocab", ".", "other_labels", ":", "\n", "                ", "weights", "=", "[", "0.0", "]", "*", "(", "batch_size", "*", "max_length", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "for", "j", ",", "tag_2", "in", "enumerate", "(", "support_tags", "[", "i", "]", ")", ":", "\n", "                        ", "if", "tag_2", "==", "tag", ":", "\n", "                            ", "weights", "[", "max_length", "*", "i", "+", "j", "]", "=", "1.0", "\n", "", "", "", "slot_label_indicator", ".", "append", "(", "weights", ")", "\n", "", "slot_label_indicator", "=", "torch", ".", "tensor", "(", "slot_label_indicator", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "slot_label_indicator", "=", "slot_label_indicator", "/", "slot_label_indicator", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "slot_label_indicator", "=", "[", "]", "\n", "for", "slot", "in", "slot_tags_vocab", ".", "other_labels_slot_names", ":", "\n", "                ", "weights", "=", "[", "0.0", "]", "*", "(", "batch_size", "*", "max_length", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "chunks", "=", "get_chunks", "(", "[", "'O'", "]", "+", "support_tags", "[", "i", "]", "+", "[", "'O'", "]", ")", "\n", "for", "(", "start", ",", "end", ",", "slot_2", ")", "in", "chunks", ":", "\n", "                        ", "start", "-=", "1", "\n", "if", "slot_2", "==", "slot", ":", "\n", "                            ", "for", "j", "in", "range", "(", "start", ",", "end", ")", ":", "\n", "                                ", "weights", "[", "max_length", "*", "i", "+", "j", "]", "=", "1.0", "/", "(", "end", "-", "start", ")", "\n", "", "", "", "", "slot_label_indicator", ".", "append", "(", "weights", ")", "\n", "", "slot_label_indicator", "=", "torch", ".", "tensor", "(", "slot_label_indicator", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "slot_label_indicator", "=", "slot_label_indicator", "/", "slot_label_indicator", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "## for intent", "\n", "", "intent_label_indicator", "=", "[", "]", "\n", "for", "intent", "in", "intents_vocab", ".", "label_to_id", ":", "\n", "            ", "weights", "=", "[", "0.0", "]", "*", "batch_size", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "if", "type", "(", "support_intents", "[", "i", "]", ")", "==", "str", ":", "\n", "                    ", "if", "support_intents", "[", "i", "]", "==", "intent", ":", "\n", "                        ", "weights", "[", "i", "]", "=", "1.0", "\n", "", "", "elif", "intent", "in", "support_intents", "[", "i", "]", ":", "\n", "                    ", "weights", "[", "i", "]", "=", "1.0", "\n", "", "", "intent_label_indicator", ".", "append", "(", "weights", ")", "\n", "", "intent_label_indicator", "=", "torch", ".", "tensor", "(", "intent_label_indicator", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "intent_label_indicator", "=", "intent_label_indicator", "/", "intent_label_indicator", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "slot_label_indicator", ",", "intent_label_indicator", "\n", "", "else", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.convert_examples_to_features": [[220, 284], ["sorted", "max", "slot_tags_vocab.convert_tokens_to_ids", "enumerate", "utils.pretrained_transformer.prepare_inputs_for_bert_xlnet", "torch.tensor", "torch.tensor", "len", "torch.tensor.append", "batch_tokens.append", "batch_tags.append", "torch.tensor.append", "utils.basic_data_reader._get_intent_vector", "batch_intents.append", "torch.tensor.append", "torch.tensor", "torch.tensor", "len", "slot_tags_vocab.convert_tokens_to_ids"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.pretrained_transformer.prepare_inputs_for_bert_xlnet", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader._get_intent_vector", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.Tokenizer.convert_tokens_to_ids"], ["", "", "def", "convert_examples_to_features", "(", "examples", ",", "tf_tokenizer", ",", "tf_input_args", "=", "{", "}", ",", "slot_tags_vocab", "=", "None", ",", "intents_vocab", "=", "None", ",", "bos_eos", "=", "False", ",", "intent_multi_class", "=", "False", ",", "intent_separator", "=", "';'", ",", "slot_tag_enc_dec", "=", "False", ",", "mask_padding_with_zero", "=", "True", ",", "device", "=", "None", ")", ":", "\n", "# sort the batch in increasing order of sentence", "\n", "    ", "examples", "=", "sorted", "(", "examples", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "1", "]", ")", ",", "reverse", "=", "True", ")", "\n", "line_nums", "=", "[", "example", "[", "0", "]", "for", "example", "in", "examples", "]", "\n", "lengths", "=", "[", "len", "(", "example", "[", "1", "]", ")", "for", "example", "in", "examples", "]", "\n", "max_len", "=", "max", "(", "lengths", ")", "\n", "padding_lengths", "=", "[", "max_len", "-", "l", "for", "l", "in", "lengths", "]", "\n", "\n", "if", "bos_eos", ":", "\n", "        ", "bos_tag", "=", "slot_tags_vocab", ".", "bos_token", "\n", "eos_tag", "=", "slot_tags_vocab", ".", "eos_token", "\n", "", "if", "slot_tag_enc_dec", ":", "\n", "        ", "bos_tag", "=", "slot_tags_vocab", ".", "bos_token", "\n", "", "pad_tag_id", "=", "slot_tags_vocab", ".", "convert_tokens_to_ids", "(", "slot_tags_vocab", ".", "pad_token", ")", "\n", "\n", "input_word_ids", "=", "[", "]", "\n", "tag_ids", "=", "[", "]", "\n", "intent_ids", "=", "[", "]", "\n", "input_mask", "=", "[", "]", "\n", "batch_tokens", ",", "batch_tags", ",", "batch_intents", "=", "[", "]", ",", "[", "]", ",", "[", "]", "# used for evaluation", "\n", "for", "example_index", ",", "example", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "tokens", "=", "example", "[", "1", "]", "\n", "tags", "=", "example", "[", "2", "]", "\n", "intent", "=", "example", "[", "3", "]", "\n", "if", "bos_eos", ":", "\n", "            ", "tokens", "=", "[", "'<s>'", "]", "+", "tokens", "+", "[", "'</s>'", "]", "\n", "tags", "=", "[", "bos_tag", "]", "+", "tags", "+", "[", "eos_tag", "]", "\n", "lengths", "[", "example_index", "]", "+=", "2", "\n", "", "mask_vector", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "lengths", "[", "example_index", "]", "\n", "mask_vector", "+=", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_lengths", "[", "example_index", "]", "\n", "input_mask", ".", "append", "(", "mask_vector", ")", "\n", "\n", "batch_tokens", ".", "append", "(", "tokens", ")", "\n", "batch_tags", ".", "append", "(", "tags", ")", "\n", "if", "slot_tag_enc_dec", ":", "\n", "# used for training", "\n", "            ", "tags", "=", "[", "bos_tag", "]", "+", "tags", "\n", "", "tag_ids", ".", "append", "(", "slot_tags_vocab", ".", "convert_tokens_to_ids", "(", "tags", ")", "+", "[", "pad_tag_id", "]", "*", "padding_lengths", "[", "example_index", "]", ")", "\n", "\n", "intents", ",", "intent_vector_or_id", "=", "_get_intent_vector", "(", "intent", ",", "intents_vocab", ",", "intent_multi_class", "=", "intent_multi_class", ",", "intent_separator", "=", "intent_separator", ")", "\n", "batch_intents", ".", "append", "(", "intents", ")", "\n", "intent_ids", ".", "append", "(", "intent_vector_or_id", ")", "\n", "\n", "", "sentences", "=", "[", "example", "[", "1", "]", "for", "example", "in", "examples", "]", "\n", "input_tf", "=", "prepare_inputs_for_bert_xlnet", "(", "sentences", ",", "tf_tokenizer", ",", "bos_eos", "=", "bos_eos", ",", "device", "=", "device", ",", "**", "tf_input_args", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "input_mask", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "tag_ids", "=", "torch", ".", "tensor", "(", "tag_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "if", "intent_multi_class", ":", "\n", "        ", "intent_ids", "=", "torch", ".", "tensor", "(", "intent_ids", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "        ", "intent_ids", "=", "torch", ".", "tensor", "(", "intent_ids", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "", "return", "{", "\n", "\"line_nums\"", ":", "line_nums", ",", "\n", "\"tokens\"", ":", "batch_tokens", ",", "\n", "\"tags\"", ":", "batch_tags", ",", "\n", "\"intents\"", ":", "batch_intents", ",", "\n", "\"inputs\"", ":", "{", "\n", "\"input_tf\"", ":", "input_tf", "\n", "}", ",", "\n", "\"input_mask\"", ":", "input_mask", ",", "\n", "\"tag_ids\"", ":", "tag_ids", ",", "\n", "\"intent_ids\"", ":", "intent_ids", ",", "\n", "\"lengths\"", ":", "lengths", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.concat_query_and_support_samples_for_pari_wise_embeddings": [[286, 327], ["query_input_ids.size", "support_input_ids.size", "torch.cat", "torch.tensor", "[].expand", "[].expand", "torch.tensor", "support_pos_ids.reshape.reshape", "torch.cat", "torch.cat", "query_input_ids[].expand().reshape", "support_input_ids[].expand().reshape", "query_attention_mask[].repeat().view", "support_attention_mask[].repeat().view", "torch.arange", "torch.arange", "query_input_ids[].expand", "support_input_ids[].expand", "query_attention_mask[].repeat", "support_attention_mask[].repeat"], "function", ["None"], ["", "def", "concat_query_and_support_samples_for_pari_wise_embeddings", "(", "query_inputs", ",", "support_inputs", ",", "device", "=", "None", ")", ":", "\n", "    ", "query_input_ids", "=", "query_inputs", "[", "\"inputs\"", "]", "[", "\"input_tf\"", "]", "[", "\"input_ids\"", "]", "\n", "support_input_ids", "=", "support_inputs", "[", "\"inputs\"", "]", "[", "\"input_tf\"", "]", "[", "\"input_ids\"", "]", "[", ":", ",", "1", ":", "]", "# no CLS", "\n", "query_attention_mask", "=", "query_inputs", "[", "\"inputs\"", "]", "[", "\"input_tf\"", "]", "[", "\"attention_mask\"", "]", "\n", "support_attention_mask", "=", "support_inputs", "[", "\"inputs\"", "]", "[", "\"input_tf\"", "]", "[", "\"attention_mask\"", "]", "[", ":", ",", "1", ":", "]", "# no CLS", "\n", "query_lengths_of_tokens", "=", "query_inputs", "[", "\"inputs\"", "]", "[", "\"input_tf\"", "]", "[", "\"lengths\"", "]", "\n", "#for x in (query_input_ids, support_input_ids, query_attention_mask, support_attention_mask):", "\n", "#    print(x, x.size())", "\n", "#print(query_lengths_of_tokens)", "\n", "B1", ",", "L1", "=", "query_input_ids", ".", "size", "(", ")", "\n", "B2", ",", "L2", "=", "support_input_ids", ".", "size", "(", ")", "\n", "concat_input_ids", "=", "torch", ".", "cat", "(", "(", "query_input_ids", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "-", "1", ",", "B2", ",", "-", "1", ")", ".", "reshape", "(", "B1", "*", "B2", ",", "L1", ")", ",", "support_input_ids", "[", "None", ",", ":", ",", ":", "]", ".", "expand", "(", "B1", ",", "-", "1", ",", "-", "1", ")", ".", "reshape", "(", "B1", "*", "B2", ",", "L2", ")", ")", ",", "dim", "=", "1", ")", "\n", "concat_segment_ids", "=", "torch", ".", "tensor", "(", "[", "[", "0", "]", "*", "L1", "+", "[", "1", "]", "*", "L2", "]", "*", "(", "B1", "*", "B2", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "query_pos_ids", "=", "torch", ".", "arange", "(", "L1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "[", "None", ",", ":", "]", ".", "expand", "(", "B1", "*", "B2", ",", "-", "1", ")", "\n", "support_pos_ids", "=", "torch", ".", "arange", "(", "L2", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "[", "None", ",", "None", ",", ":", "]", ".", "expand", "(", "B1", ",", "B2", ",", "-", "1", ")", "\n", "support_start_pos", "=", "torch", ".", "tensor", "(", "query_lengths_of_tokens", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "support_pos_ids", "=", "support_start_pos", "[", ":", ",", "None", ",", "None", "]", "+", "support_pos_ids", "\n", "support_pos_ids", "=", "support_pos_ids", ".", "reshape", "(", "B1", "*", "B2", ",", "-", "1", ")", "\n", "concat_position_ids", "=", "torch", ".", "cat", "(", "(", "query_pos_ids", ",", "support_pos_ids", ")", ",", "dim", "=", "1", ")", "\n", "concat_attention_mask", "=", "torch", ".", "cat", "(", "(", "query_attention_mask", "[", ":", ",", "None", ",", ":", "]", ".", "repeat", "(", "1", ",", "B2", ",", "1", ")", ".", "view", "(", "B1", "*", "B2", ",", "L1", ")", ",", "support_attention_mask", "[", "None", ",", ":", ",", ":", "]", ".", "repeat", "(", "B1", ",", "1", ",", "1", ")", ".", "view", "(", "B1", "*", "B2", ",", "L2", ")", ")", ",", "dim", "=", "1", ")", "\n", "ret", "=", "{", "\n", "\"B1\"", ":", "B1", ",", "\n", "\"B2\"", ":", "B2", ",", "\n", "\"L1\"", ":", "L1", ",", "\n", "\"L2\"", ":", "L2", ",", "\n", "\"input_ids\"", ":", "concat_input_ids", ",", "\n", "\"segment_ids\"", ":", "concat_segment_ids", ",", "\n", "\"position_ids\"", ":", "concat_position_ids", ",", "\n", "\"attention_mask\"", ":", "concat_attention_mask", ",", "\n", "\"query\"", ":", "{", "\n", "\"attention_mask\"", ":", "query_inputs", "[", "\"inputs\"", "]", "[", "\"input_tf\"", "]", "[", "\"attention_mask\"", "]", ",", "\n", "\"gather_index\"", ":", "query_inputs", "[", "\"inputs\"", "]", "[", "\"input_tf\"", "]", "[", "\"gather_index\"", "]", "\n", "}", ",", "\n", "\"support\"", ":", "{", "\n", "\"attention_mask\"", ":", "support_inputs", "[", "\"inputs\"", "]", "[", "\"input_tf\"", "]", "[", "\"attention_mask\"", "]", ",", "\n", "\"gather_index\"", ":", "support_inputs", "[", "\"inputs\"", "]", "[", "\"input_tf\"", "]", "[", "\"gather_index\"", "]", "\n", "}", "\n", "}", "\n", "return", "{", "\n", "\"inputs\"", ":", "{", "\n", "\"input_tf\"", ":", "ret", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.__init__": [[21, 29], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''\n\t\tself.finetuning_task = kwargs.pop('finetuning_task', None)\n        self.num_labels = kwargs.pop('num_labels', 2)\n        self.output_attentions = kwargs.pop('output_attentions', False)\n        self.output_hidden_states = kwargs.pop('output_hidden_states', False)\n        self.torchscript = kwargs.pop('torchscript', False)\n\t\t'''", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.save_pretrained": [[30, 40], ["os.path.isdir", "os.path.join", "config.ModelConfig.to_json_file"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.to_json_file"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a configuration object to the directory `save_directory`, so that it\n            can be re-loaded using the :func:`~transformers.PretrainedConfig.from_pretrained` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "CONFIG_NAME", ")", "\n", "\n", "self", ".", "to_json_file", "(", "output_config_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.from_dict": [[41, 48], ["cls", "json_object.items"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `Config` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "cls", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.from_json_file": [[49, 55], ["cls.from_dict", "open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.from_argparse": [[56, 59], ["cls.from_dict", "copy.deepcopy"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_argparse", "(", "cls", ",", "parsed_args", ")", ":", "\n", "        ", "return", "cls", ".", "from_dict", "(", "copy", ".", "deepcopy", "(", "parsed_args", ".", "__dict__", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.__eq__": [[60, 62], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.__repr__": [[63, 65], ["str", "config.ModelConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.to_dict": [[66, 70], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.to_json_string": [[71, 74], ["json.dumps", "config.ModelConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.to_json_file": [[75, 79], ["open", "writer.write", "config.ModelConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.to_json_string"], ["", "def", "to_json_file", "(", "self", ",", "json_file_path", ")", ":", "\n", "        ", "\"\"\" Save this instance to a json file.\"\"\"", "\n", "with", "open", "(", "json_file_path", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SimilarityNet.__init__": [[20, 33], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "label_embedding_dim", ",", "similarity_fc", "=", "'multiply'", ",", "normalized", "=", "False", ")", ":", "\n", "        ", "'''\n        similarity_fc : cosine / multiply / ff (feed forward)\n        '''", "\n", "super", "(", "SimilarityNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "label_embedding_dim", "=", "label_embedding_dim", "\n", "self", ".", "similarity_fc", "=", "similarity_fc", "\n", "self", ".", "normalized", "=", "normalized", "\n", "if", "self", ".", "similarity_fc", "==", "'ff'", ":", "\n", "            ", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "label_embedding_dim", ",", "label_embedding_dim", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "label_embedding_dim", ",", "label_embedding_dim", ")", "\n", "self", ".", "w_3", "=", "nn", ".", "Linear", "(", "label_embedding_dim", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SimilarityNet.forward": [[34, 66], ["len", "torch.normalize.unsqueeze", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "torch.normalize", "basic_modules.SimilarityNet.squeeze", "torch.normalize.size", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.normalize.transpose", "torch.normalize.transpose", "basic_modules.SimilarityNet.w_1", "basic_modules.SimilarityNet.w_2", "torch.tanh.transpose", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "basic_modules.SimilarityNet.w_3().squeeze", "math.sqrt", "basic_modules.SimilarityNet.unsqueeze", "basic_modules.SimilarityNet.transpose().unsqueeze", "basic_modules.SimilarityNet.w_3", "basic_modules.SimilarityNet.transpose"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_embeddings", ",", "label_embeddings", ")", ":", "\n", "        ", "'''\n        input_embeddings : B * H or B * L * H\n        label_embeddings : O * H or B * O * H\n        '''", "\n", "if", "len", "(", "input_embeddings", ".", "size", "(", ")", ")", "==", "2", ":", "\n", "            ", "squeeze", "=", "True", "\n", "input_embeddings", "=", "input_embeddings", ".", "unsqueeze", "(", "1", ")", "# B * 1 * H", "\n", "", "else", ":", "\n", "            ", "squeeze", "=", "False", "\n", "", "if", "self", ".", "similarity_fc", "==", "'cosine'", ":", "\n", "# cosine \u7684\u7ed3\u679c\u5f88\u5dee\uff0c\u5373\u540c\u65f6\u5bf9\u4e24\u4e2avector\u505a\u5355\u4f4d\u5316\u6839\u672c\u8bad\u7ec3\u4e0d\u52a8\uff1b\u4f46\u662f\u4ec5\u4ec5\u53ea\u5bf9\u5176\u4e2d\u4efb\u4f55\u4e00\u4e2a\u5411\u91cf\u505a\u5355\u4f4d\u5316\uff0c\u5219\u8bad\u7ec3\u6b63\u5e38\uff1b", "\n", "            ", "input_embeddings", "=", "F", ".", "normalize", "(", "input_embeddings", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "label_embeddings", "=", "F", ".", "normalize", "(", "label_embeddings", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "scores", "=", "torch", ".", "matmul", "(", "input_embeddings", ",", "label_embeddings", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "*", "10", "# \u56e0\u4e3acosine\u7684\u503c\u57df\u662f[-1, 1]\uff0c \u800csoftmax\u7684\u8f93\u5165\u503c\u57df\u662f(-inf, +inf)\uff0c\u6240\u4ee5\u9700\u8981\u6269\u5927\u6570\u503c\u8303\u56f4", "\n", "", "elif", "self", ".", "similarity_fc", "==", "'multiply'", ":", "\n", "            ", "scores", "=", "torch", ".", "matmul", "(", "input_embeddings", ",", "label_embeddings", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "#scores = 2 * torch.matmul(input_embeddings, label_embeddings.transpose(-1, -2))", "\n", "#scores = 2 * torch.matmul(input_embeddings, label_embeddings.transpose(-1, -2)) - torch.norm(label_embeddings, p=2, dim=1) ** 2", "\n", "if", "self", ".", "normalized", ":", "\n", "                ", "scores", "=", "scores", "/", "math", ".", "sqrt", "(", "self", ".", "label_embedding_dim", ")", "\n", "", "", "elif", "self", ".", "similarity_fc", "==", "'ff'", ":", "\n", "# \u6548\u679c\u4e0d\u662f\u5f88\u7406\u60f3", "\n", "            ", "h1", "=", "self", ".", "w_1", "(", "input_embeddings", ")", "# B * L * H or B * 1 * H", "\n", "h2", "=", "self", ".", "w_2", "(", "label_embeddings", ")", "# O * H or B * O * H", "\n", "h", "=", "h1", ".", "unsqueeze", "(", "-", "1", ")", "+", "h2", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ".", "unsqueeze", "(", "-", "3", ")", "# B * L * H * 1 + B * 1 * H * O or 1 * H * O => B * L * H * O", "\n", "h", "=", "h", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "h", "=", "F", ".", "tanh", "(", "h", ")", "\n", "scores", "=", "self", ".", "w_3", "(", "h", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "squeeze", ":", "\n", "            ", "scores", "=", "scores", ".", "squeeze", "(", "1", ")", "# B * 1 * O => B * O", "\n", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceTaggingFNNDecoder_withLabelEmbedding.__init__": [[69, 81], ["torch.Module.__init__", "basic_modules.SimilarityNet", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "encoder_output_dim", ",", "label_embedding_dim", ",", "bilinear", "=", "False", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "SequenceTaggingFNNDecoder_withLabelEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "bilinear", ":", "\n", "            ", "self", ".", "hidden2emb", "=", "nn", ".", "Linear", "(", "encoder_output_dim", ",", "label_embedding_dim", ",", "bias", "=", "bias", ")", "\n", "#init_transitions_param = torch.rand(encoder_output_dim)", "\n", "#self.hidden2emb = nn.Parameter(init_transitions_param)", "\n", "", "else", ":", "\n", "            ", "assert", "encoder_output_dim", "==", "label_embedding_dim", "\n", "self", ".", "hidden2emb", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "label_embedding_dim", "=", "label_embedding_dim", "\n", "\n", "self", ".", "compute_similarity", "=", "SimilarityNet", "(", "config", ",", "label_embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceTaggingFNNDecoder_withLabelEmbedding.forward": [[82, 94], ["basic_modules.SequenceTaggingFNNDecoder_withLabelEmbedding.hidden2emb", "basic_modules.SequenceTaggingFNNDecoder_withLabelEmbedding.compute_similarity", "tag_logits.index_fill_.index_fill_.index_fill_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoder_hiddens", ",", "label_embeddings", ",", "masked_output", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        encoder_hiddens : B * L * H\n        label_embeddings : O * H'\n        \"\"\"", "\n", "hidden_emb", "=", "self", ".", "hidden2emb", "(", "encoder_hiddens", ")", "\n", "#hidden_emb = encoder_hiddens * self.hidden2emb", "\n", "tag_logits", "=", "self", ".", "compute_similarity", "(", "hidden_emb", ",", "label_embeddings", ")", "\n", "if", "masked_output", "is", "not", "None", ":", "\n", "            ", "tag_logits", "=", "tag_logits", ".", "index_fill_", "(", "-", "1", ",", "masked_output", ",", "MIN_NUMBER", ")", "\n", "\n", "", "return", "tag_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceEmbedding_Pooling.__init__": [[106, 110], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "encoder_output_dim", ",", "pooling", "=", "'mean'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pooling", "=", "pooling", "\n", "assert", "self", ".", "pooling", "in", "(", "'max'", ",", "'mean'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceEmbedding_Pooling.forward": [[111, 126], ["pooling_mask.sum().squeeze", "rnn_out.sum", "pooling_mask.unsqueeze", "pooling_mask.sum", "masked_rnn_out.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "rnn_out", ",", "pooling_mask", ")", ":", "\n", "        ", "\"\"\"\n        rnn_out : bsize x seqlen x hsize\n        pooling_mask : bsize x seqlen\n        \"\"\"", "\n", "if", "self", ".", "pooling", "==", "'mean'", ":", "\n", "            ", "lengths", "=", "pooling_mask", ".", "sum", "(", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "rnn_out_pool", "=", "rnn_out", ".", "sum", "(", "1", ")", "/", "lengths", "\n", "", "elif", "self", ".", "pooling", "==", "'max'", ":", "\n", "            ", "extended_pooling_mask", "=", "pooling_mask", ".", "unsqueeze", "(", "2", ")", "\n", "extended_pooling_mask", "=", "(", "1.0", "-", "extended_pooling_mask", ")", "*", "MIN_NUMBER", "\n", "masked_rnn_out", "=", "rnn_out", "+", "extended_pooling_mask", "\n", "rnn_out_pool", "=", "masked_rnn_out", ".", "max", "(", "1", ")", "[", "0", "]", "\n", "\n", "", "return", "rnn_out_pool", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceEmbedding_CNN.__init__": [[129, 137], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "encoder_output_dim", ",", "kernel_size", "=", "3", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "dropout_layer", "=", "nn", ".", "Dropout", "(", "config", ".", "arch_dropout", ")", "\n", "self", ".", "batchnorm", "=", "nn", ".", "BatchNorm1d", "(", "encoder_output_dim", ")", "\n", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv1d", "(", "encoder_output_dim", ",", "encoder_output_dim", ",", "self", ".", "kernel_size", ",", "padding", "=", "1", ")", ",", "#, padding=self.kernel_size//2),", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "#nn.Dropout(p=self.dropout),", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceEmbedding_CNN.forward": [[142, 152], ["rnn_out.transpose", "basic_modules.SequenceEmbedding_CNN.cnn", "basic_modules.SequenceEmbedding_CNN.batchnorm", "basic_modules.SequenceEmbedding_CNN.dropout_layer", "basic_modules.SequenceEmbedding_CNN.max"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "rnn_out", ")", ":", "\n", "        ", "\"\"\"\n        rnn_out : bsize x seqlen x hsize\n        \"\"\"", "\n", "hiddens", "=", "rnn_out", ".", "transpose", "(", "1", ",", "2", ")", "\n", "conv_hiddens", "=", "self", ".", "cnn", "(", "hiddens", ")", "\n", "conv_hiddens_pool", "=", "conv_hiddens", ".", "max", "(", "2", ")", "[", "0", "]", "\n", "conv_hiddens_pool", "=", "self", ".", "batchnorm", "(", "conv_hiddens_pool", ")", "\n", "conv_hiddens_pool", "=", "self", ".", "dropout_layer", "(", "conv_hiddens_pool", ")", "\n", "return", "conv_hiddens_pool", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceEmbedding_Attention.__init__": [[155, 161], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "encoder_output_dim", ",", "query_vector_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout_layer", "=", "nn", ".", "Dropout", "(", "config", ".", "arch_dropout", ")", "\n", "self", ".", "Wa", "=", "nn", ".", "Linear", "(", "query_vector_dim", ",", "query_vector_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "Ua", "=", "nn", ".", "Conv1d", "(", "encoder_output_dim", ",", "query_vector_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "Va", "=", "nn", ".", "Conv1d", "(", "query_vector_dim", ",", "1", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceEmbedding_Attention.forward": [[162, 184], ["rnn_out.transpose", "reversed_top_h_t.squeeze.squeeze.squeeze", "basic_modules.SequenceEmbedding_Attention.Wa", "basic_modules.SequenceEmbedding_Attention.Ua", "basic_modules.SequenceEmbedding_Attention.unsqueeze().repeat", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "basic_modules.SequenceEmbedding_Attention.Va().squeeze", "basic_modules.SequenceEmbedding_Attention.masked_fill_", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "basic_modules.SequenceEmbedding_Attention.dropout_layer", "rnn_out.size", "basic_modules.SequenceEmbedding_Attention.unsqueeze", "basic_modules.SequenceEmbedding_Attention.Va", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "rnn_out", ",", "reversed_top_h_t", ",", "attention_mask", ")", ":", "\n", "        ", "'''\n        rnn_out : bsize x seqlen x hsize\n        reversed_top_h_t : bsize x hsize/2\n        attention_mask : bsize x seqlen\n        '''", "\n", "hiddens", "=", "rnn_out", ".", "transpose", "(", "1", ",", "2", ")", "\n", "reversed_top_h_t", "=", "reversed_top_h_t", ".", "squeeze", "(", "0", ")", "\n", "c1", "=", "self", ".", "Wa", "(", "reversed_top_h_t", ")", "\n", "c2", "=", "self", ".", "Ua", "(", "hiddens", ")", "\n", "\n", "c3", "=", "c1", ".", "unsqueeze", "(", "2", ")", ".", "repeat", "(", "1", ",", "1", ",", "rnn_out", ".", "size", "(", "1", ")", ")", "\n", "c4", "=", "torch", ".", "tanh", "(", "c3", "+", "c2", ")", "\n", "\n", "e", "=", "self", ".", "Va", "(", "c4", ")", ".", "squeeze", "(", "1", ")", "\n", "mask", "=", "(", "1", "-", "attention_mask", ")", ".", "to", "(", "dtype", "=", "torch", ".", "bool", ")", "\n", "e", ".", "masked_fill_", "(", "mask", ",", "MIN_NUMBER", ")", "\n", "a", "=", "F", ".", "softmax", "(", "e", ",", "dim", "=", "1", ")", "\n", "\n", "context_hidden", "=", "torch", ".", "bmm", "(", "hiddens", ",", "a", ".", "unsqueeze", "(", "2", ")", ")", ".", "squeeze", "(", "2", ")", "\n", "context_hidden", "=", "self", ".", "dropout_layer", "(", "context_hidden", ")", "\n", "return", "context_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceClassifier_withLabelEmbedding.__init__": [[186, 196], ["torch.Module.__init__", "basic_modules.SimilarityNet", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "encoder_output_dim", ",", "label_embedding_dim", ",", "bilinear", "=", "False", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "SequenceClassifier_withLabelEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "bilinear", ":", "\n", "            ", "self", ".", "hidden2emb", "=", "nn", ".", "Linear", "(", "encoder_output_dim", ",", "label_embedding_dim", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "            ", "assert", "encoder_output_dim", "==", "label_embedding_dim", "\n", "self", ".", "hidden2emb", "=", "nn", ".", "Identity", "(", ")", "\n", "", "self", ".", "label_embedding_dim", "=", "label_embedding_dim", "\n", "\n", "self", ".", "compute_similarity", "=", "SimilarityNet", "(", "config", ",", "label_embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceClassifier_withLabelEmbedding.forward": [[197, 203], ["basic_modules.SequenceClassifier_withLabelEmbedding.hidden2emb", "basic_modules.SequenceClassifier_withLabelEmbedding.compute_similarity", "class_logits.index_fill_.index_fill_.index_fill_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoder_hiddens", ",", "label_embeddings", ",", "masked_output", "=", "None", ")", ":", "\n", "        ", "hidden_emb", "=", "self", ".", "hidden2emb", "(", "encoder_hiddens", ")", "\n", "class_logits", "=", "self", ".", "compute_similarity", "(", "hidden_emb", ",", "label_embeddings", ")", "\n", "if", "masked_output", "is", "not", "None", ":", "\n", "            ", "class_logits", "=", "class_logits", ".", "index_fill_", "(", "1", ",", "masked_output", ",", "MIN_NUMBER", ")", "\n", "", "return", "class_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceClassifier_TwoTails_withLabelEmbedding.__init__": [[206, 208], ["basic_modules.SequenceClassifier_withLabelEmbedding.__init__"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "encoder_output_dim", ",", "label_embedding_dim", ",", "bilinear", "=", "False", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ",", "encoder_output_dim", ",", "label_embedding_dim", ",", "bilinear", "=", "bilinear", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceClassifier_Pooling_withLabelEmbedding.__init__": [[211, 214], ["basic_modules.SequenceClassifier_withLabelEmbedding.__init__", "basic_modules.SequenceEmbedding_Pooling"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "encoder_output_dim", ",", "label_embedding_dim", ",", "bilinear", "=", "False", ",", "bias", "=", "True", ",", "pooling", "=", "'mean'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ",", "encoder_output_dim", ",", "label_embedding_dim", ",", "bilinear", "=", "bilinear", ",", "bias", "=", "bias", ")", "\n", "self", ".", "sequence_embeddings", "=", "SequenceEmbedding_Pooling", "(", "config", ",", "encoder_output_dim", ",", "pooling", "=", "pooling", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceClassifier_Pooling_withLabelEmbedding.forward": [[215, 226], ["basic_modules.SequenceClassifier_Pooling_withLabelEmbedding.sequence_embeddings", "basic_modules.SequenceClassifier_Pooling_withLabelEmbedding.hidden2emb", "basic_modules.SequenceClassifier_Pooling_withLabelEmbedding.compute_similarity", "class_logits.index_fill_.index_fill_.index_fill_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "rnn_out", ",", "pooling_mask", ",", "label_embeddings", ",", "masked_output", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        rnn_out : bsize x seqlen x hsize\n        pooling_mask : bsize x seqlen\n        \"\"\"", "\n", "rnn_out_pool", "=", "self", ".", "sequence_embeddings", "(", "rnn_out", ",", "pooling_mask", ")", "\n", "hidden_emb", "=", "self", ".", "hidden2emb", "(", "rnn_out_pool", ")", "\n", "class_logits", "=", "self", ".", "compute_similarity", "(", "hidden_emb", ",", "label_embeddings", ")", "\n", "if", "masked_output", "is", "not", "None", ":", "\n", "            ", "class_logits", "=", "class_logits", ".", "index_fill_", "(", "1", ",", "masked_output", ",", "MIN_NUMBER", ")", "\n", "", "return", "class_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceClassifier_CNN_withLabelEmbedding.__init__": [[229, 232], ["basic_modules.SequenceClassifier_withLabelEmbedding.__init__", "basic_modules.SequenceEmbedding_CNN"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "encoder_output_dim", ",", "label_embedding_dim", ",", "bilinear", "=", "False", ",", "bias", "=", "True", ",", "kernel_size", "=", "3", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ",", "encoder_output_dim", ",", "label_embedding_dim", ",", "bilinear", "=", "bilinear", ",", "bias", "=", "bias", ")", "\n", "self", ".", "sequence_embeddings", "=", "SequenceEmbedding_CNN", "(", "config", ",", "encoder_output_dim", ",", "kernel_size", "=", "kernel_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceClassifier_CNN_withLabelEmbedding.forward": [[233, 243], ["basic_modules.SequenceClassifier_CNN_withLabelEmbedding.sequence_embeddings", "basic_modules.SequenceClassifier_CNN_withLabelEmbedding.hidden2emb", "basic_modules.SequenceClassifier_CNN_withLabelEmbedding.compute_similarity", "class_logits.index_fill_.index_fill_.index_fill_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "rnn_out", ",", "label_embeddings", ",", "masked_output", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        rnn_out : bsize x seqlen x hsize\n        \"\"\"", "\n", "conv_hiddens_pool", "=", "self", ".", "sequence_embeddings", "(", "rnn_out", ")", "\n", "hidden_emb", "=", "self", ".", "hidden2emb", "(", "conv_hiddens_pool", ")", "\n", "class_logits", "=", "self", ".", "compute_similarity", "(", "hidden_emb", ",", "label_embeddings", ")", "\n", "if", "masked_output", "is", "not", "None", ":", "\n", "            ", "class_logits", "=", "class_logits", ".", "index_fill_", "(", "1", ",", "masked_output", ",", "MIN_NUMBER", ")", "\n", "", "return", "class_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceClassifier_Attention_withLabelEmbedding.__init__": [[246, 249], ["basic_modules.SequenceClassifier_withLabelEmbedding.__init__", "basic_modules.SequenceEmbedding_Attention"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "encoder_output_dim", ",", "query_vector_dim", ",", "label_embedding_dim", ",", "bilinear", "=", "False", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ",", "encoder_output_dim", ",", "label_embedding_dim", ",", "bilinear", "=", "bilinear", ",", "bias", "=", "bias", ")", "\n", "self", ".", "sequence_embeddings", "=", "SequenceEmbedding_Attention", "(", "config", ",", "encoder_output_dim", ",", "query_vector_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_modules.SequenceClassifier_Attention_withLabelEmbedding.forward": [[250, 262], ["basic_modules.SequenceClassifier_Attention_withLabelEmbedding.sequence_embeddings", "basic_modules.SequenceClassifier_Attention_withLabelEmbedding.hidden2emb", "basic_modules.SequenceClassifier_Attention_withLabelEmbedding.compute_similarity", "class_logits.index_fill_.index_fill_.index_fill_"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "rnn_out", ",", "reversed_top_h_t", ",", "attention_mask", ",", "label_embeddings", ",", "masked_output", "=", "None", ")", ":", "\n", "        ", "'''\n        rnn_out : bsize x seqlen x hsize\n        reversed_top_h_t : bsize x hsize/2\n        attention_mask : bsize x seqlen\n        '''", "\n", "context_hidden", "=", "self", ".", "sequence_embeddings", "(", "rnn_out", ",", "reversed_top_h_t", ",", "attention_mask", ")", "\n", "hidden_emb", "=", "self", ".", "hidden2emb", "(", "context_hidden", ")", "\n", "class_logits", "=", "self", ".", "compute_similarity", "(", "hidden_emb", ",", "label_embeddings", ")", "\n", "if", "masked_output", "is", "not", "None", ":", "\n", "            ", "class_logits", "=", "class_logits", ".", "index_fill_", "(", "1", ",", "masked_output", ",", "MIN_NUMBER", ")", "\n", "", "return", "class_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.GeneralTransitionLayer.__init__": [[8, 12], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "transitions.data.clone"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "transitions", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "transitions", "=", "nn", ".", "Parameter", "(", "transitions", ".", "data", ".", "clone", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.GeneralTransitionLayer.forward": [[13, 15], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "return", "self", ".", "transitions", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.AbstractTransitionLayer.__init__": [[24, 39], ["torch.Module.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Parameter", "torch.Parameter", "torch.Parameter"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "device", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "init_transitions_param", "=", "torch", ".", "zeros", "(", "3", ",", "5", ")", "\n", "self", ".", "crf_transitions_model", "=", "nn", ".", "Parameter", "(", "init_transitions_param", ")", "\n", "#nn.init.uniform_(self.crf_transitions_model, -0.01, 0.01)", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "ids_map", "=", "{", "\n", "'O'", ":", "{", "'O'", ":", "0", ",", "'sB'", ":", "1", ",", "'dB'", ":", "2", ",", "'sI'", ":", "3", ",", "'dI'", ":", "4", "}", ",", "\n", "'B'", ":", "{", "'O'", ":", "5", ",", "'sB'", ":", "6", ",", "'dB'", ":", "7", ",", "'sI'", ":", "8", ",", "'dI'", ":", "9", "}", ",", "\n", "'I'", ":", "{", "'O'", ":", "10", ",", "'sB'", ":", "11", ",", "'dB'", ":", "12", ",", "'sI'", ":", "13", ",", "'dI'", ":", "14", "}", "\n", "}", "\n", "self", ".", "last_memory_label_to_id", "=", "None", "\n", "self", ".", "last_memory_selected_ids", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.AbstractTransitionLayer.forward": [[40, 46], ["crf.AbstractTransitionLayer.get_selected_ids_from_label_list", "crf.AbstractTransitionLayer.size", "crf.AbstractTransitionLayer.crf_transitions_model.view().index_select", "transitions_matrix.view.view.view", "crf.AbstractTransitionLayer.view", "crf.AbstractTransitionLayer.crf_transitions_model.view"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.AbstractTransitionLayer.get_selected_ids_from_label_list"], ["", "def", "forward", "(", "self", ",", "label_to_id", ")", ":", "\n", "        ", "selected_ids", "=", "self", ".", "get_selected_ids_from_label_list", "(", "label_to_id", ")", "\n", "label_size", "=", "selected_ids", ".", "size", "(", "0", ")", "\n", "transitions_matrix", "=", "self", ".", "crf_transitions_model", ".", "view", "(", "-", "1", ")", ".", "index_select", "(", "0", ",", "selected_ids", ".", "view", "(", "-", "1", ")", ")", "\n", "transitions_matrix", "=", "transitions_matrix", ".", "view", "(", "label_size", ",", "label_size", ")", "\n", "return", "transitions_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.AbstractTransitionLayer.get_selected_ids_from_label_list": [[47, 83], ["len", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "selected_ids.to.to.to", "range", "label.split"], "methods", ["None"], ["", "def", "get_selected_ids_from_label_list", "(", "self", ",", "label_to_id", ")", ":", "\n", "        ", "if", "self", ".", "last_memory_label_to_id", "==", "label_to_id", ":", "\n", "            ", "return", "self", ".", "last_memory_selected_ids", "\n", "", "else", ":", "\n", "            ", "label_size", "=", "len", "(", "label_to_id", ")", "\n", "labels", "=", "{", "}", "\n", "for", "label", "in", "label_to_id", ":", "\n", "                ", "if", "'-'", "in", "label", ":", "\n", "                    ", "bio", ",", "name", "=", "label", ".", "split", "(", "'-'", ",", "1", ")", "\n", "", "elif", "label", "==", "'O'", ":", "\n", "                    ", "bio", ",", "name", "=", "'O'", ",", "'O'", "\n", "", "else", ":", "\n", "                    ", "bio", ",", "name", "=", "label", ",", "None", "\n", "", "labels", "[", "label_to_id", "[", "label", "]", "]", "=", "(", "bio", ",", "name", ")", "\n", "", "selected_ids", "=", "torch", ".", "zeros", "(", "label_size", ",", "label_size", ")", "\n", "for", "i", "in", "range", "(", "label_size", ")", ":", "\n", "                ", "bio_1", ",", "name_1", "=", "labels", "[", "i", "]", "\n", "for", "j", "in", "range", "(", "label_size", ")", ":", "\n", "                    ", "bio_2", ",", "name_2", "=", "labels", "[", "j", "]", "\n", "if", "name_1", "==", "None", "or", "name_2", "==", "None", ":", "\n", "                        ", "selected_ids", "[", "i", "]", "[", "j", "]", "=", "self", ".", "ids_map", "[", "'O'", "]", "[", "'dB'", "]", "# O->sI, invalid", "\n", "", "elif", "name_1", "==", "'O'", "and", "name_2", "==", "'O'", ":", "\n", "                        ", "selected_ids", "[", "i", "]", "[", "j", "]", "=", "self", ".", "ids_map", "[", "bio_1", "]", "[", "bio_2", "]", "\n", "", "elif", "name_1", "==", "'O'", "and", "name_2", "!=", "'O'", ":", "\n", "                        ", "selected_ids", "[", "i", "]", "[", "j", "]", "=", "self", ".", "ids_map", "[", "bio_1", "]", "[", "'s'", "+", "bio_2", "]", "\n", "", "elif", "name_1", "!=", "'O'", "and", "name_2", "==", "'O'", ":", "\n", "                        ", "selected_ids", "[", "i", "]", "[", "j", "]", "=", "self", ".", "ids_map", "[", "bio_1", "]", "[", "bio_2", "]", "\n", "", "elif", "name_1", "==", "name_2", ":", "\n", "                        ", "selected_ids", "[", "i", "]", "[", "j", "]", "=", "self", ".", "ids_map", "[", "bio_1", "]", "[", "'s'", "+", "bio_2", "]", "\n", "", "else", ":", "\n", "                        ", "selected_ids", "[", "i", "]", "[", "j", "]", "=", "self", ".", "ids_map", "[", "bio_1", "]", "[", "'d'", "+", "bio_2", "]", "\n", "\n", "", "", "", "selected_ids", "=", "selected_ids", ".", "to", "(", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "last_memory_label_to_id", "=", "label_to_id", "\n", "self", ".", "last_memory_selected_ids", "=", "selected_ids", "\n", "return", "selected_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.TransitionLayer_v1.__init__": [[86, 91], ["torch.Module.__init__", "torch.Bilinear", "torch.Bilinear", "torch.Bilinear", "crf.TransitionLayer_v1.crf_transitions_model.weight.data.zero_"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "label_embedding_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "crf_transitions_model", "=", "nn", ".", "Bilinear", "(", "label_embedding_dim", ",", "label_embedding_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "crf_transitions_model", ".", "weight", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.TransitionLayer_v1.forward": [[92, 103], ["label_embeddings.size", "label_embeddings[].expand().contiguous", "label_embeddings[].expand().contiguous", "crf.TransitionLayer_v1.crf_transitions_model().squeeze", "label_embeddings[].expand", "label_embeddings[].expand", "crf.TransitionLayer_v1.crf_transitions_model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "label_embeddings", ")", ":", "\n", "        ", "\"\"\"\n        label_embeddings : O * H\n        \"\"\"", "\n", "label_set_size", "=", "label_embeddings", ".", "size", "(", "0", ")", "\n", "left", "=", "label_embeddings", "[", "None", ",", ":", ",", ":", "]", ".", "expand", "(", "label_set_size", ",", "-", "1", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "right", "=", "label_embeddings", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "-", "1", ",", "label_set_size", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "# # transitions (f_tag_size, t_tag_size), transition value from f_tag to t_tag", "\n", "transitions_matrix", "=", "self", ".", "crf_transitions_model", "(", "left", ",", "right", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "return", "transitions_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.TransitionLayer.__init__": [[106, 113], ["torch.Module.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Parameter", "torch.Parameter", "torch.Parameter"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "label_embedding_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "init_transitions_param", "=", "torch", ".", "zeros", "(", "label_embedding_dim", ",", "label_embedding_dim", ")", "\n", "#init_transitions_param = torch.zeros(label_embedding_dim, 1)", "\n", "self", ".", "crf_transitions_model", "=", "nn", ".", "Parameter", "(", "init_transitions_param", ")", "\n", "self", ".", "label_embedding_dim", "=", "label_embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.TransitionLayer.forward": [[114, 129], ["label_embeddings.size", "label_embeddings.transpose", "len", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "label_embeddings", ")", ":", "\n", "        ", "\"\"\"\n        label_embeddings : O * H or B * O * H\n        \"\"\"", "\n", "label_set_size", "=", "label_embeddings", ".", "size", "(", "0", ")", "\n", "left", "=", "label_embeddings", "\n", "right", "=", "label_embeddings", ".", "transpose", "(", "0", ",", "1", ")", "#.contiguous()", "\n", "# # transitions (f_tag_size, t_tag_size), transition value from f_tag to t_tag", "\n", "if", "len", "(", "label_embeddings", ".", "shape", ")", "==", "2", ":", "\n", "            ", "transitions_matrix", "=", "torch", ".", "matmul", "(", "torch", ".", "matmul", "(", "left", ",", "self", ".", "crf_transitions_model", ")", ",", "right", ")", "#/ math.sqrt(self.label_embedding_dim)", "\n", "", "else", ":", "\n", "            ", "transitions_matrix", "=", "torch", ".", "matmul", "(", "torch", ".", "matmul", "(", "left", ",", "self", ".", "crf_transitions_model", "[", "None", ",", ":", ",", ":", "]", ")", ",", "right", ")", "#/ math.sqrt(self.label_embedding_dim)", "\n", "#transitions_matrix = torch.matmul(torch.matmul(left, self.crf_transitions_model.expand(-1, self.label_embedding_dim)), right)", "\n", "\n", "", "return", "transitions_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.CRFLoss.__init__": [[132, 144], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "trainable_balance_weight", "=", "False", ",", "device", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# # transitions (f_tag_size, t_tag_size), transition value from f_tag to t_tag", "\n", "#init_transitions = torch.zeros(self.tagset_size, self.tagset_size)", "\n", "#self.transitions = nn.Parameter(init_transitions)", "\n", "if", "trainable_balance_weight", ":", "\n", "            ", "self", ".", "scaling_feats", "=", "nn", ".", "Parameter", "(", "torch", ".", "rand", "(", "1", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", ")", "#a uniform distribution on the interval [0, 1)[0,1)", "\n", "", "else", ":", "\n", "            ", "self", ".", "scaling_feats", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.CRFLoss._calculate_alg": [[145, 180], ["feats.size", "feats.size", "feats.size", "transitions.size", "mask.transpose().contiguous.transpose().contiguous.transpose().contiguous", "mask[].all", "torch.logsumexp.sum", "torch.logsumexp.sum", "torch.logsumexp.sum", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "transitions.view", "range", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "mask.transpose().contiguous.transpose().contiguous.transpose", "partition.contiguous().view.contiguous().view.contiguous().view", "mask[].view", "cur_partition.masked_select", "mask_idx.contiguous().view.contiguous().view.contiguous().view", "partition.contiguous().view.contiguous().view.masked_scatter_", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "partition.contiguous().view.contiguous().view.contiguous", "mask_idx.contiguous().view.contiguous().view.contiguous"], "methods", ["None"], ["", "", "def", "_calculate_alg", "(", "self", ",", "transitions", ",", "feats", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n            input:\n                feats: (batch, seq_len, self.tag_size)\n                masks: (batch, seq_len)\n        \"\"\"", "\n", "batch_size", "=", "feats", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "feats", ".", "size", "(", "1", ")", "\n", "tag_size", "=", "feats", ".", "size", "(", "2", ")", "\n", "tagset_size", "=", "transitions", ".", "size", "(", "0", ")", "\n", "assert", "(", "tag_size", "==", "tagset_size", ")", "\n", "mask", "=", "mask", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "assert", "mask", "[", "0", "]", ".", "all", "(", ")", "## minimal length is >= 1", "\n", "\n", "first_input", "=", "feats", "[", ":", ",", "0", ",", ":", "]", "\n", "if", "seq_len", "==", "1", ":", "\n", "            ", "final_partition", "=", "torch", ".", "logsumexp", "(", "first_input", ",", "1", ")", "# bat_size * to_target", "\n", "", "else", ":", "\n", "# This matrix is expanded into a [1, num_tags, num_tags] in preparation for the broadcast summation", "\n", "            ", "partition", "=", "first_input", "\n", "transitions_expand", "=", "transitions", ".", "view", "(", "1", ",", "tag_size", ",", "tag_size", ")", "\n", "for", "idx", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "                ", "partition", "=", "partition", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", "#.expand(batch_size, tag_size, tag_size)", "\n", "transition_scores", "=", "partition", "+", "transitions_expand", "\n", "cur_partition", "=", "feats", "[", ":", ",", "idx", ",", ":", "]", "+", "torch", ".", "logsumexp", "(", "transition_scores", ",", "1", ")", "# bat_size * to_target", "\n", "\n", "mask_idx", "=", "mask", "[", "idx", ",", ":", "]", ".", "view", "(", "batch_size", ",", "1", ")", "#.expand(batch_size, tag_size)", "\n", "masked_cur_partition", "=", "cur_partition", ".", "masked_select", "(", "mask_idx", ")", "\n", "## let mask_idx broadcastable, to disable warning", "\n", "mask_idx", "=", "mask_idx", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", "\n", "\n", "## replace the partition where the maskvalue=1, other partition value keeps the same", "\n", "partition", ".", "masked_scatter_", "(", "mask_idx", ",", "masked_cur_partition", ")", "\n", "", "final_partition", "=", "torch", ".", "logsumexp", "(", "partition", ",", "1", ")", "\n", "", "return", "final_partition", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.CRFLoss._viterbi_decode": [[181, 242], ["feats.size", "feats.size", "feats.size", "transitions.size", "mask.transpose().contiguous.transpose().contiguous.transpose().contiguous", "mask[].all", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "path_score.squeeze.squeeze.squeeze", "list", "list", "torch.cat().view.append", "torch.cat().view.append", "torch.cat().view.append", "transitions.view", "range", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.sum().view().long", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.gather().squeeze.contiguous().view().expand", "torch.gather().squeeze.contiguous().view().expand", "torch.gather().squeeze.contiguous().view().expand", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.cat().view.append", "torch.cat().view.append", "torch.cat().view.append", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view.scatter_", "torch.cat().view.scatter_", "torch.cat().view.scatter_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "mask.transpose().contiguous.transpose().contiguous.transpose", "partition.contiguous().view.contiguous().view.contiguous().view", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.cat().view.append", "torch.cat().view.append", "torch.cat().view.append", "cur_backpointers.masked_fill_", "torch.cat().view.append", "torch.cat().view.append", "torch.cat().view.append", "torch.sum().view().long.view().expand", "torch.sum().view().long.view().expand", "torch.sum().view().long.view().expand", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze.data.view", "torch.gather().squeeze.data.view", "torch.gather().squeeze.data.view", "mask_reverse[].view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.sum().view", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather().squeeze.contiguous().view", "torch.gather().squeeze.contiguous().view", "torch.gather().squeeze.contiguous().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().view.size", "torch.cat().view.size", "torch.cat().view.size", "mask.transpose().contiguous.transpose().contiguous.long", "partition.contiguous().view.contiguous().view.contiguous", "torch.sum().view().long.view", "torch.sum().view().long.view", "torch.sum().view().long.view", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.gather().squeeze.contiguous", "torch.gather().squeeze.contiguous", "torch.gather().squeeze.contiguous", "torch.gather().squeeze.contiguous().view", "torch.gather().squeeze.contiguous().view", "torch.gather().squeeze.contiguous().view", "mask.transpose().contiguous.transpose().contiguous.transpose", "torch.gather().squeeze.contiguous", "torch.gather().squeeze.contiguous", "torch.gather().squeeze.contiguous"], "methods", ["None"], ["", "def", "_viterbi_decode", "(", "self", ",", "transitions", ",", "feats", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n            input:\n                feats: (batch, seq_len, tag_size)\n                mask: (batch, seq_len)\n            output:\n                decode_idx: (batch, seq_len) decoded sequence\n                path_score: (batch, 1) corresponding score for each sequence (to be implementated)\n        \"\"\"", "\n", "batch_size", "=", "feats", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "feats", ".", "size", "(", "1", ")", "\n", "tag_size", "=", "feats", ".", "size", "(", "2", ")", "\n", "tagset_size", "=", "transitions", ".", "size", "(", "0", ")", "\n", "assert", "(", "tag_size", "==", "tagset_size", ")", "\n", "mask", "=", "mask", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "assert", "mask", "[", "0", "]", ".", "all", "(", ")", "## minimal length is >= 1", "\n", "\n", "if", "seq_len", "==", "1", ":", "\n", "            ", "path_score", ",", "decode_idx", "=", "torch", ".", "max", "(", "feats", ",", "dim", "=", "2", ")", "\n", "path_score", "=", "path_score", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "back_points", "=", "list", "(", ")", "\n", "partition_history", "=", "list", "(", ")", "\n", "mask_reverse", "=", "(", "1", "-", "mask", ".", "long", "(", ")", ")", ".", "bool", "(", ")", "\n", "\n", "first_input", "=", "feats", "[", ":", ",", "0", ",", ":", "]", "# bat_size * to_target", "\n", "# This matrix is expanded into a [1, num_tags, num_tags] in preparation for the broadcast summation", "\n", "partition", "=", "first_input", "\n", "partition_history", ".", "append", "(", "partition", ")", "\n", "#back_points.append(partition)", "\n", "transitions_expand", "=", "transitions", ".", "view", "(", "1", ",", "tag_size", ",", "tag_size", ")", "\n", "for", "idx", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "                ", "partition", "=", "partition", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "tag_size", ",", "1", ")", "#.expand(batch_size, tag_size, tag_size)", "\n", "transition_scores", "=", "partition", "+", "transitions_expand", "\n", "cur_scores", ",", "cur_backpointers", "=", "torch", ".", "max", "(", "transition_scores", ",", "1", ")", "# bat_size * to_target", "\n", "partition", "=", "feats", "[", ":", ",", "idx", ",", ":", "]", "+", "cur_scores", "\n", "partition_history", ".", "append", "(", "partition", ")", "\n", "\n", "## cur_bp: (batch_size, tag_size) max source score position in current tag", "\n", "## set padded label as 0, which will be filtered in post processing", "\n", "cur_backpointers", ".", "masked_fill_", "(", "mask_reverse", "[", "idx", ",", ":", "]", ".", "view", "(", "batch_size", ",", "1", ")", ",", "0", ")", "\n", "back_points", ".", "append", "(", "cur_backpointers", ")", "\n", "", "partition_history", "=", "torch", ".", "cat", "(", "partition_history", ",", "dim", "=", "1", ")", ".", "view", "(", "batch_size", ",", "seq_len", ",", "tag_size", ")", "\n", "length_mask", "=", "torch", ".", "sum", "(", "mask", ".", "transpose", "(", "1", ",", "0", ")", ",", "dim", "=", "1", ")", ".", "view", "(", "batch_size", ",", "1", ")", ".", "long", "(", ")", "\n", "last_position", "=", "length_mask", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "tag_size", ")", "-", "1", "\n", "last_partition", "=", "torch", ".", "gather", "(", "partition_history", ",", "1", ",", "last_position", ")", ".", "view", "(", "batch_size", ",", "tag_size", ")", "\n", "## best score and last tags", "\n", "path_score", ",", "pointer", "=", "torch", ".", "max", "(", "last_partition", ",", "1", ")", "\n", "## move the end ids(expand to tag_size) to the corresponding position of back_points to replace the 0 values", "\n", "insert_last", "=", "pointer", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "tag_size", ")", "\n", "pad_zero", "=", "torch", ".", "zeros", "(", "batch_size", ",", "tag_size", ")", ".", "to", "(", "self", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "back_points", ".", "append", "(", "pad_zero", ")", "# \u8003\u8651 len == max_len \u7684\u90a3\u4e9b\u53e5\u5b50", "\n", "back_points", "=", "torch", ".", "cat", "(", "back_points", ",", "dim", "=", "1", ")", ".", "view", "(", "batch_size", ",", "seq_len", ",", "tag_size", ")", "\n", "back_points", ".", "scatter_", "(", "1", ",", "last_position", ",", "insert_last", ")", "\n", "## decode from the end, padded position ids are 0, which will be filtered if following evaluation", "\n", "decode_idx", "=", "torch", ".", "zeros", "(", "batch_size", ",", "seq_len", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "decode_idx", "[", ":", ",", "-", "1", "]", "=", "pointer", ".", "data", "\n", "for", "idx", "in", "range", "(", "back_points", ".", "size", "(", "1", ")", "-", "2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "                ", "pointer", "=", "torch", ".", "gather", "(", "back_points", "[", ":", ",", "idx", ",", ":", "]", ",", "1", ",", "pointer", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "decode_idx", "[", ":", ",", "idx", "]", "=", "pointer", ".", "data", ".", "view", "(", "batch_size", ")", "\n", "", "", "return", "path_score", ",", "decode_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.CRFLoss.viterbi_decode": [[243, 247], ["crf.CRFLoss._viterbi_decode"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.CRFLoss._viterbi_decode"], ["", "def", "viterbi_decode", "(", "self", ",", "transitions", ",", "feats", ",", "mask", ")", ":", "\n", "        ", "feats", "*=", "self", ".", "scaling_feats", "\n", "path_score", ",", "best_path", "=", "self", ".", "_viterbi_decode", "(", "transitions", ",", "feats", ",", "mask", ")", "\n", "return", "path_score", ",", "best_path", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.CRFLoss._score_sentence": [[248, 275], ["feats.size", "feats.size", "feats.size", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "unary_scores.masked_select.masked_select.masked_select", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "binary_scores.masked_select.masked_select.masked_select", "transitions.view", "flattened_transition_indices.view", "mask[].contiguous().view", "unary_scores.masked_select.masked_select.sum", "binary_scores.masked_select.masked_select.sum", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "tags.view", "mask[].contiguous"], "methods", ["None"], ["", "def", "_score_sentence", "(", "self", ",", "transitions", ",", "feats", ",", "mask", ",", "tags", ")", ":", "\n", "        ", "\"\"\"\n            input:\n                feats: (batch, seq_len, tag_size)\n                mask: (batch, seq_len)\n                tags: tensor  (batch, seq_len)\n            output:\n                score: sum of score for gold sequences within whole batch\n        \"\"\"", "\n", "# Gives the score of a provided tag sequence", "\n", "batch_size", "=", "feats", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "feats", ".", "size", "(", "1", ")", "\n", "tag_size", "=", "feats", ".", "size", "(", "2", ")", "\n", "\n", "## crf_unary_score(tag_indices, sequence_lengths, inputs)", "\n", "unary_scores", "=", "torch", ".", "gather", "(", "feats", ",", "2", ",", "tags", ".", "view", "(", "batch_size", ",", "seq_len", ",", "1", ")", ")", ".", "squeeze", "(", "2", ")", "# batch_size * seq_len", "\n", "unary_scores", "=", "unary_scores", ".", "masked_select", "(", "mask", ")", "\n", "\n", "## crf_binary_score(tag_indices, sequence_lengths, transition_params)", "\n", "start_tag_indices", "=", "tags", "[", ":", ",", ":", "-", "1", "]", "\n", "end_tag_indices", "=", "tags", "[", ":", ",", "1", ":", "]", "\n", "flattened_transition_indices", "=", "start_tag_indices", "*", "tag_size", "+", "end_tag_indices", "\n", "binary_scores", "=", "torch", ".", "gather", "(", "transitions", ".", "view", "(", "-", "1", ")", ",", "0", ",", "flattened_transition_indices", ".", "view", "(", "-", "1", ")", ")", "\n", "binary_scores", "=", "binary_scores", ".", "masked_select", "(", "mask", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "gold_score", "=", "unary_scores", ".", "sum", "(", ")", "+", "binary_scores", ".", "sum", "(", ")", "\n", "return", "gold_score", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.CRFLoss.neg_log_likelihood_loss": [[276, 282], ["crf.CRFLoss._calculate_alg", "crf.CRFLoss._score_sentence"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.CRFLoss._calculate_alg", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.CRFLoss._score_sentence"], ["", "def", "neg_log_likelihood_loss", "(", "self", ",", "transitions", ",", "feats", ",", "mask", ",", "tags", ")", ":", "\n", "# nonegative log likelihood", "\n", "        ", "feats", "*=", "self", ".", "scaling_feats", "\n", "forward_score", "=", "self", ".", "_calculate_alg", "(", "transitions", ",", "feats", ",", "mask", ")", "\n", "gold_score", "=", "self", ".", "_score_sentence", "(", "transitions", ",", "feats", ",", "mask", ",", "tags", ")", "\n", "return", "forward_score", "-", "gold_score", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert._LRSchedule.__init__": [[38, 52], ["ABC.__init__", "max", "logger.warning", "ValueError", "float", "float"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "warmup", "=", "0.002", ",", "t_total", "=", "-", "1", ",", "**", "kw", ")", ":", "\n", "        ", "\"\"\"\n        :param warmup:  what fraction of t_total steps will be used for linear warmup\n        :param t_total: how many training steps (updates) are planned\n        :param kw:\n        \"\"\"", "\n", "super", "(", "_LRSchedule", ",", "self", ")", ".", "__init__", "(", "**", "kw", ")", "\n", "if", "t_total", "<", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "\"t_total value of {} results in schedule not being applied\"", ".", "format", "(", "t_total", ")", ")", "\n", "", "if", "not", "0.0", "<=", "warmup", "<", "1.0", "and", "not", "warmup", "==", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "warmup", "=", "max", "(", "warmup", ",", "0.", ")", "\n", "self", ".", "warmup", ",", "self", ".", "t_total", "=", "float", "(", "warmup", ")", ",", "float", "(", "t_total", ")", "\n", "self", ".", "warned_for_t_total_at_progress", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert._LRSchedule.get_lr": [[53, 71], ["optim_bert._LRSchedule.get_lr_", "float", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.WarmupLinearSchedule.get_lr_"], ["", "def", "get_lr", "(", "self", ",", "step", ",", "nowarn", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param step:    which of t_total steps we're on\n        :param nowarn:  set to True to suppress warning regarding training beyond specified 't_total' steps\n        :return:        learning rate multiplier for current update\n        \"\"\"", "\n", "if", "self", ".", "t_total", "<", "0", ":", "\n", "            ", "return", "1.", "\n", "", "progress", "=", "float", "(", "step", ")", "/", "self", ".", "t_total", "\n", "ret", "=", "self", ".", "get_lr_", "(", "progress", ")", "\n", "# warning for exceeding t_total (only active with warmup_linear", "\n", "if", "not", "nowarn", "and", "self", ".", "warn_t_total", "and", "progress", ">", "1.", "and", "progress", ">", "self", ".", "warned_for_t_total_at_progress", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Training beyond specified 't_total'. Learning rate multiplier set to {}. Please set 't_total' of {} correctly.\"", "\n", ".", "format", "(", "ret", ",", "self", ".", "__class__", ".", "__name__", ")", ")", "\n", "self", ".", "warned_for_t_total_at_progress", "=", "progress", "\n", "# end warning", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert._LRSchedule.get_lr_": [[72, 79], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "get_lr_", "(", "self", ",", "progress", ")", ":", "\n", "        ", "\"\"\"\n        :param progress:    value between 0 and 1 (unless going beyond t_total steps) specifying training progress\n        :return:            learning rate multiplier for current update\n        \"\"\"", "\n", "return", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.ConstantLR.get_lr_": [[82, 84], ["None"], "methods", ["None"], ["    ", "def", "get_lr_", "(", "self", ",", "progress", ")", ":", "\n", "        ", "return", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.WarmupCosineSchedule.__init__": [[93, 102], ["optim_bert._LRSchedule.__init__"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "warmup", "=", "0.002", ",", "t_total", "=", "-", "1", ",", "cycles", "=", ".5", ",", "**", "kw", ")", ":", "\n", "        ", "\"\"\"\n        :param warmup:      see LRSchedule\n        :param t_total:     see LRSchedule\n        :param cycles:      number of cycles. Default: 0.5, corresponding to cosine decay from 1. at progress==warmup and 0 at progress==1.\n        :param kw:\n        \"\"\"", "\n", "super", "(", "WarmupCosineSchedule", ",", "self", ")", ".", "__init__", "(", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "**", "kw", ")", "\n", "self", ".", "cycles", "=", "cycles", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.WarmupCosineSchedule.get_lr_": [[103, 109], ["math.cos"], "methods", ["None"], ["", "def", "get_lr_", "(", "self", ",", "progress", ")", ":", "\n", "        ", "if", "progress", "<", "self", ".", "warmup", ":", "\n", "            ", "return", "progress", "/", "self", ".", "warmup", "\n", "", "else", ":", "\n", "            ", "progress", "=", "(", "progress", "-", "self", ".", "warmup", ")", "/", "(", "1", "-", "self", ".", "warmup", ")", "# progress after warmup", "\n", "return", "0.5", "*", "(", "1.", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "self", ".", "cycles", "*", "2", "*", "progress", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.WarmupCosineWithHardRestartsSchedule.__init__": [[117, 120], ["optim_bert.WarmupCosineSchedule.__init__"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "warmup", "=", "0.002", ",", "t_total", "=", "-", "1", ",", "cycles", "=", "1.", ",", "**", "kw", ")", ":", "\n", "        ", "super", "(", "WarmupCosineWithHardRestartsSchedule", ",", "self", ")", ".", "__init__", "(", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "cycles", "=", "cycles", ",", "**", "kw", ")", "\n", "assert", "(", "cycles", ">=", "1.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.WarmupCosineWithHardRestartsSchedule.get_lr_": [[121, 128], ["math.cos"], "methods", ["None"], ["", "def", "get_lr_", "(", "self", ",", "progress", ")", ":", "\n", "        ", "if", "progress", "<", "self", ".", "warmup", ":", "\n", "            ", "return", "progress", "/", "self", ".", "warmup", "\n", "", "else", ":", "\n", "            ", "progress", "=", "(", "progress", "-", "self", ".", "warmup", ")", "/", "(", "1", "-", "self", ".", "warmup", ")", "# progress after warmup", "\n", "ret", "=", "0.5", "*", "(", "1.", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "(", "(", "self", ".", "cycles", "*", "progress", ")", "%", "1", ")", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.WarmupCosineWithWarmupRestartsSchedule.__init__": [[136, 140], ["optim_bert.WarmupCosineWithHardRestartsSchedule.__init__"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "warmup", "=", "0.002", ",", "t_total", "=", "-", "1", ",", "cycles", "=", "1.", ",", "**", "kw", ")", ":", "\n", "        ", "assert", "(", "warmup", "*", "cycles", "<", "1.", ")", "\n", "warmup", "=", "warmup", "*", "cycles", "if", "warmup", ">=", "0", "else", "warmup", "\n", "super", "(", "WarmupCosineWithWarmupRestartsSchedule", ",", "self", ")", ".", "__init__", "(", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "cycles", "=", "cycles", ",", "**", "kw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.WarmupCosineWithWarmupRestartsSchedule.get_lr_": [[141, 149], ["math.cos"], "methods", ["None"], ["", "def", "get_lr_", "(", "self", ",", "progress", ")", ":", "\n", "        ", "progress", "=", "progress", "*", "self", ".", "cycles", "%", "1.", "\n", "if", "progress", "<", "self", ".", "warmup", ":", "\n", "            ", "return", "progress", "/", "self", ".", "warmup", "\n", "", "else", ":", "\n", "            ", "progress", "=", "(", "progress", "-", "self", ".", "warmup", ")", "/", "(", "1", "-", "self", ".", "warmup", ")", "# progress after warmup", "\n", "ret", "=", "0.5", "*", "(", "1.", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "progress", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.WarmupConstantSchedule.get_lr_": [[156, 160], ["None"], "methods", ["None"], ["def", "get_lr_", "(", "self", ",", "progress", ")", ":", "\n", "        ", "if", "progress", "<", "self", ".", "warmup", ":", "\n", "            ", "return", "progress", "/", "self", ".", "warmup", "\n", "", "return", "1.", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.WarmupLinearSchedule.get_lr_": [[168, 172], ["max"], "methods", ["None"], ["def", "get_lr_", "(", "self", ",", "progress", ")", ":", "\n", "        ", "if", "progress", "<", "self", ".", "warmup", ":", "\n", "            ", "return", "progress", "/", "self", ".", "warmup", "\n", "", "return", "max", "(", "(", "progress", "-", "1.", ")", "/", "(", "self", ".", "warmup", "-", "1.", ")", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.BertAdam.__init__": [[200, 224], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "isinstance", "schedule_type", "isinstance", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "required", ",", "warmup", "=", "-", "1", ",", "t_total", "=", "-", "1", ",", "schedule", "=", "'warmup_linear'", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-6", ",", "weight_decay", "=", "0.01", ",", "max_grad_norm", "=", "1.0", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "lr", "is", "not", "required", "and", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "isinstance", "(", "schedule", ",", "_LRSchedule", ")", "and", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "e", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "e", ")", ")", "\n", "# initialize schedule object", "\n", "", "if", "not", "isinstance", "(", "schedule", ",", "_LRSchedule", ")", ":", "\n", "            ", "schedule_type", "=", "SCHEDULES", "[", "schedule", "]", "\n", "schedule", "=", "schedule_type", "(", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ")", "\n", "", "else", ":", "\n", "            ", "if", "warmup", "!=", "-", "1", "or", "t_total", "!=", "-", "1", ":", "\n", "                ", "logger", ".", "warning", "(", "\"warmup and t_total on the optimizer are ineffective when _LRSchedule object is provided as schedule. \"", "\n", "\"Please specify custom warmup and t_total in _LRSchedule object.\"", ")", "\n", "", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "weight_decay", "=", "weight_decay", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "BertAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.BertAdam.get_lr": [[225, 236], ["group[].get_lr", "lr.append", "len"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.BertAdam.get_lr"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "[", "]", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "return", "[", "0", "]", "\n", "", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "lr_scheduled", "*=", "group", "[", "'schedule'", "]", ".", "get_lr", "(", "state", "[", "'step'", "]", ")", "\n", "lr", ".", "append", "(", "lr_scheduled", ")", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.BertAdam.step": [[237, 303], ["closure", "next_m.mul_().add_", "next_v.mul_().addcmul_", "group[].get_lr", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "next_m.mul_", "next_v.mul_", "next_v.sqrt"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.BertAdam.get_lr"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'next_m'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'next_v'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "next_m", ",", "next_v", "=", "state", "[", "'next_m'", "]", ",", "state", "[", "'next_v'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "", "next_m", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "next_v", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "update", "=", "next_m", "/", "(", "next_v", ".", "sqrt", "(", ")", "+", "group", "[", "'e'", "]", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "if", "group", "[", "'weight_decay'", "]", ">", "0.0", ":", "\n", "                    ", "update", "+=", "group", "[", "'weight_decay'", "]", "*", "p", ".", "data", "\n", "\n", "", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "lr_scheduled", "*=", "group", "[", "'schedule'", "]", ".", "get_lr", "(", "state", "[", "'step'", "]", ")", "\n", "\n", "update_with_lr", "=", "lr_scheduled", "*", "update", "\n", "p", ".", "data", ".", "add_", "(", "-", "update_with_lr", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1", "\n", "# No bias correction", "\n", "# bias_correction1 = 1 - beta1 ** state['step']", "\n", "# bias_correction2 = 1 - beta2 ** state['step']", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_model.BasicModel.__init__": [[14, 16], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "BasicModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_model.BasicModel.load_model": [[17, 22], ["basic_model.BasicModel.load_state_dict", "basic_model.BasicModel.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "open", "open"], "methods", ["None"], ["", "def", "load_model", "(", "self", ",", "load_dir", ")", ":", "\n", "        ", "if", "self", ".", "device", ".", "type", "==", "'cuda'", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "open", "(", "load_dir", ",", "'rb'", ")", ",", "map_location", "=", "'cuda:0'", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "open", "(", "load_dir", ",", "'rb'", ")", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_model.BasicModel.save_model": [[23, 25], ["torch.save", "torch.save", "torch.save", "torch.save", "basic_model.BasicModel.state_dict", "open"], "methods", ["None"], ["", "", "def", "save_model", "(", "self", ",", "save_dir", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "open", "(", "save_dir", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_model.BasicModel.init_weights": [[26, 30], ["basic_model.BasicModel.apply"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initialize and prunes weights if needed. \"\"\"", "\n", "# Initialize weights", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_model.BasicModel._init_weights": [[31, 56], ["isinstance", "hasattr", "module.weight.data.uniform_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_", "isinstance", "isinstance", "isinstance", "module.named_parameters", "print", "type", "param.data.uniform_", "param.data.zero_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights \"\"\"", "\n", "'''\n        nn.Parameter will not be included.\n        '''", "\n", "if", "hasattr", "(", "module", ",", "'sz128__no_init_flag'", ")", "and", "module", ".", "sz128__no_init_flag", ":", "\n", "#print(\"Module skips the initialization:\", type(module), module.__class__.__name__)", "\n", "            ", "return", "1", "\n", "", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "nn", ".", "Conv1d", ")", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "0.2", ",", "0.2", ")", "\n", "#module.weight.data.normal_(mean=0.0, std=0.02)", "\n", "", "elif", "isinstance", "(", "module", ",", "(", "nn", ".", "LayerNorm", ",", "nn", ".", "BatchNorm1d", ")", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "GRU", ")", "or", "isinstance", "(", "module", ",", "nn", ".", "LSTM", ")", "or", "isinstance", "(", "module", ",", "nn", ".", "RNN", ")", ":", "\n", "            ", "for", "name", ",", "param", "in", "module", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'weight_ih'", "in", "name", "or", "'weight_hh'", "in", "name", ":", "\n", "                    ", "param", ".", "data", ".", "uniform_", "(", "-", "0.2", ",", "0.2", ")", "\n", "#param.data.normal_(mean=0.0, std=0.02)", "\n", "", "elif", "'bias'", "in", "name", ":", "\n", "                    ", "param", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "", "else", ":", "\n", "            ", "print", "(", "\"Module skips the initialization:\"", ",", "type", "(", "module", ")", ")", "\n", "", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Conv1d", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.data_utils.data_statistic.get_vocab": [[17, 46], ["open", "json.load", "print", "print", "list", "set", "set", "print", "len", "len", "len", "len", "len", "set", "set.add", "slot.split"], "function", ["None"], ["def", "get_vocab", "(", "file_path", ",", "tag_name", ")", ":", "\n", "    ", "slot_vocab", "=", "{", "}", "\n", "intent_vocab", "=", "{", "}", "\n", "with", "open", "(", "file_path", ")", "as", "in_file", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "in_file", ")", "\n", "print", "(", "tag_name", ",", "':'", ")", "\n", "print", "(", "'\\t'", ",", "list", "(", "data", ")", ")", "\n", "for", "domain_name", "in", "data", ":", "\n", "            ", "support_sample_number", "=", "0", "\n", "query_sample_number", "=", "0", "\n", "domain_label_vocab_for_slot_tagging", "=", "set", "(", ")", "\n", "domain_slot_vocab", "=", "set", "(", ")", "\n", "for", "batch", "in", "data", "[", "domain_name", "]", ":", "\n", "#print(list(batch['support'])) # ['seq_ins', 'labels', 'seq_outs', 'word_piece_marks', 'tokenized_texts', 'word_piece_labels']", "\n", "#print(list(batch['batch'])) # ['seq_ins', 'labels', 'seq_outs', 'word_piece_marks', 'tokenized_texts', 'word_piece_labels']", "\n", "                ", "support_sample_number", "+=", "len", "(", "batch", "[", "'support'", "]", "[", "'labels'", "]", ")", "\n", "query_sample_number", "+=", "len", "(", "batch", "[", "'batch'", "]", "[", "'labels'", "]", ")", "\n", "for", "data_type", "in", "[", "'support'", ",", "'batch'", "]", ":", "\n", "                    ", "for", "slots", "in", "batch", "[", "data_type", "]", "[", "'seq_outs'", "]", ":", "\n", "                        ", "for", "slot", "in", "slots", ":", "\n", "                            ", "if", "slot", "!=", "'O'", ":", "\n", "                                ", "slot", "=", "slot", ".", "split", "(", "'-'", ",", "1", ")", "[", "1", "]", "\n", "", "slot_vocab", "[", "slot", "]", "=", "1", "\n", "domain_slot_vocab", ".", "add", "(", "slot", ")", "\n", "", "domain_label_vocab_for_slot_tagging", "|=", "set", "(", "slots", ")", "\n", "", "for", "intent", "in", "batch", "[", "data_type", "]", "[", "'labels'", "]", ":", "\n", "                        ", "intent_vocab", "[", "intent", "]", "=", "1", "\n", "", "", "", "print", "(", "'\\t'", ",", "domain_name", ",", "len", "(", "data", "[", "domain_name", "]", ")", ",", "support_sample_number", ",", "query_sample_number", ",", "len", "(", "domain_label_vocab_for_slot_tagging", ")", ",", "len", "(", "domain_slot_vocab", ")", ")", "\n", "", "", "return", "slot_vocab", ",", "intent_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.data_utils.download.loadData": [[14, 26], ["os.path.exists", "os.makedirs", "os.path.exists", "print", "urllib.request.urlopen", "zipfile.ZipFile", "zipfile.ZipFile.extractall", "zipfile.ZipFile.close", "io.BytesIO", "urllib.request.urlopen.read"], "function", ["None"], ["def", "loadData", "(", ")", ":", "\n", "    ", "data_url", "=", "\"data/ACL2020data\"", "\n", "dataset_url", "=", "\"https://atmahou.github.io/attachments/ACL2020data.zip\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "\"data\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "\"data\"", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "data_url", ")", ":", "\n", "        ", "print", "(", "\"Downloading and unzipping the ACL2020 dataset\"", ")", "\n", "resp", "=", "urllib", ".", "request", ".", "urlopen", "(", "dataset_url", ")", "\n", "zip_ref", "=", "ZipFile", "(", "BytesIO", "(", "resp", ".", "read", "(", ")", ")", ")", "\n", "zip_ref", ".", "extractall", "(", "\"data\"", ")", "\n", "zip_ref", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.get_hyperparam_string": [[36, 59], ["None"], "function", ["None"], ["def", "get_hyperparam_string", "(", "args", ")", ":", "\n", "    ", "\"\"\"Hyerparam string.\"\"\"", "\n", "task_path", "=", "'model_%s'", "%", "(", "args", ".", "task", ")", "\n", "dataset_path", "=", "'data_%s'", "%", "(", "args", ".", "dataset_name", ")", "\n", "\n", "exp_name", "=", "'preTF-%s'", "%", "(", "args", ".", "input_pretrained_transformer_model_name", ")", "\n", "exp_name", "+=", "'_bs-%s'", "%", "(", "args", ".", "tr_batchSize", ")", "\n", "exp_name", "+=", "'_dp-%s'", "%", "(", "args", ".", "arch_dropout", ")", "\n", "exp_name", "+=", "'_optim-%s'", "%", "(", "args", ".", "tr_optim", ")", "\n", "exp_name", "+=", "'_lr-%s'", "%", "(", "args", ".", "tr_lr", ")", "\n", "exp_name", "+=", "'_layer_decay-%s'", "%", "(", "args", ".", "tf_layerwise_lr_decay", ")", "\n", "exp_name", "+=", "'__lr_np_%s'", "%", "(", "args", ".", "tr_lr_np", ")", "\n", "exp_name", "+=", "'_mn-%s'", "%", "(", "args", ".", "tr_max_norm", ")", "\n", "exp_name", "+=", "'_me-%s'", "%", "(", "args", ".", "tr_max_epoch", ")", "\n", "exp_name", "+=", "'_seed-%s'", "%", "(", "args", ".", "random_seed", ")", "\n", "\n", "if", "args", ".", "input_word_lowercase", ":", "\n", "        ", "exp_name", "+=", "'_uncased'", "\n", "", "else", ":", "\n", "        ", "exp_name", "+=", "'_cased'", "\n", "", "exp_name", "+=", "'_%s'", "%", "(", "args", ".", "input_embedding_type", ")", "\n", "\n", "return", "task_path", ",", "dataset_path", ",", "exp_name", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.set_exp_path": [[60, 73], ["slot_tagging_with_prototypical_network_with_pure_bert.get_hyperparam_string", "os.path.join"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.get_hyperparam_string"], ["", "def", "set_exp_path", "(", "args", ",", "exp_path_tag", ")", ":", "\n", "    ", "args", ".", "task", "=", "args", ".", "task_st", "+", "'__and__'", "+", "args", ".", "task_sc", "+", "'__'", "+", "args", ".", "task_sc_type", "\n", "task_path", ",", "dataset_path", ",", "exp_name", "=", "get_hyperparam_string", "(", "args", ")", "\n", "if", "args", ".", "task_sc", ":", "\n", "        ", "exp_name", "+=", "'__alpha_%s'", "%", "(", "args", ".", "tr_st_weight", ")", "\n", "", "exp_name", "+=", "'__slot_emb_%s'", "%", "(", "args", ".", "slot_embedding_type", ")", "\n", "exp_name", "+=", "'__match_sim_%s'", "%", "(", "args", ".", "matching_similarity_type", ")", "\n", "exp_name", "+=", "'_y_%s_f_%s'", "%", "(", "args", ".", "matching_similarity_y", ",", "args", ".", "matching_similarity_function", ")", "\n", "exp_name", "+=", "'__QEnc_on_LE_%s'", "%", "(", "args", ".", "slot_embedding_dependent_query_encoding", ")", "\n", "if", "args", ".", "test_finetune", ":", "\n", "        ", "exp_name", "+=", "'__finetune'", "\n", "", "exp_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "tr_exp_path", ",", "exp_path_tag", ",", "task_path", ",", "dataset_path", ",", "exp_name", ")", "\n", "return", "exp_path", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.set_seed": [[74, 85], ["random.seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.is_available", "numpy.random.seed", "print", "torch.cuda.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "random_seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "random_seed", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "if", "args", ".", "device", ".", "type", "!=", "'cuda'", ":", "\n", "            ", "print", "(", "\"WARNING: You have a CUDA device, so you should probably run with --deviceId [1|2|3]\"", ")", "\n", "", "else", ":", "\n", "            ", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "random_seed", ")", "\n", "#if args.n_gpu > 0:", "\n", "#    torch.cuda.manual_seed_all(args.random_seed)", "\n", "", "", "np", ".", "random", ".", "seed", "(", "args", ".", "random_seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.decode_simBERT": [[86, 140], ["torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "model_ori.eval", "numpy.mean", "utils.compute_fscore", "args.logger.info", "open", "torch.no_grad", "torch.no_grad", "enumerate", "args.dataset_name.startswith", "utils.basic_data_reader.convert_examples_to_features", "model_ori.decode_by_similarity_of_BERT", "losses.append", "enumerate", "marco_f1_scores.append", "utils.basic_data_reader.convert_examples_to_features", "utils.get_chunks", "utils.get_chunks", "utils.analysis_fscore", "len", "len", "len", "writer.write", "writer.write", "len", "slot_tags_vocab._convert_id_to_token", "range", "sum", "str"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.compute_fscore", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.convert_examples_to_features", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.decode_by_similarity_of_BERT", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.convert_examples_to_features", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.get_chunks", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.get_chunks", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.analysis_fscore", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab._convert_id_to_token"], ["", "def", "decode_simBERT", "(", "args", ",", "model_ori", ",", "eval_dataset", ",", "output_path", ")", ":", "\n", "    ", "word_tokenizer", "=", "args", ".", "word_tokenizer", "\n", "char_tokenizer", "=", "args", ".", "char_tokenizer", "\n", "tf_tokenizer", "=", "args", ".", "tf_tokenizer", "\n", "tf_input_args", "=", "args", ".", "tf_input_args", "\n", "eval_sampler", "=", "RandomSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "test_batchSize", ",", "collate_fn", "=", "collate_fn_do_nothing", ")", "\n", "\n", "model_ori", ".", "eval", "(", ")", "\n", "losses", "=", "[", "]", "\n", "TP", ",", "FP", ",", "FN", ",", "TN", "=", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "\n", "marco_f1_scores", "=", "[", "]", "\n", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "writer", ",", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "eval_dataloader", ")", ":", "\n", "            ", "if", "args", ".", "dataset_name", ".", "startswith", "(", "\"HIT_\"", ")", ":", "\n", "                ", "support_batch", ",", "query_batch", "=", "batch", "[", "0", "]", "[", "0", "]", ",", "batch", "[", "0", "]", "[", "1", "]", "\n", "slot_tags_vocab", ",", "intents_vocab", "=", "batch", "[", "0", "]", "[", "2", "]", ",", "batch", "[", "0", "]", "[", "3", "]", "\n", "support_batch_inputs", "=", "convert_examples_to_features", "(", "support_batch", ",", "word_tokenizer", "=", "word_tokenizer", ",", "char_tokenizer", "=", "char_tokenizer", ",", "tf_tokenizer", "=", "tf_tokenizer", ",", "tf_input_args", "=", "tf_input_args", ",", "slot_tags_vocab", "=", "slot_tags_vocab", ",", "intents_vocab", "=", "intents_vocab", ",", "bos_eos", "=", "args", ".", "input_bos_eos", ",", "intent_multi_class", "=", "args", ".", "intent_multi_class", ",", "slot_tag_enc_dec", "=", "args", ".", "enc_dec", ",", "device", "=", "args", ".", "device", ")", "\n", "", "query_batch_inputs", "=", "convert_examples_to_features", "(", "query_batch", ",", "word_tokenizer", "=", "word_tokenizer", ",", "char_tokenizer", "=", "char_tokenizer", ",", "tf_tokenizer", "=", "tf_tokenizer", ",", "tf_input_args", "=", "tf_input_args", ",", "slot_tags_vocab", "=", "slot_tags_vocab", ",", "intents_vocab", "=", "intents_vocab", ",", "bos_eos", "=", "args", ".", "input_bos_eos", ",", "intent_multi_class", "=", "args", ".", "intent_multi_class", ",", "slot_tag_enc_dec", "=", "args", ".", "enc_dec", ",", "device", "=", "args", ".", "device", ")", "\n", "top_pred_tags", "=", "model_ori", ".", "decode_by_similarity_of_BERT", "(", "support_batch_inputs", "[", "\"inputs\"", "]", ",", "support_batch_inputs", "[", "\"input_mask\"", "]", ",", "support_batch_inputs", "[", "\"tag_ids\"", "]", ",", "support_batch_inputs", "[", "\"intent_ids\"", "]", ",", "query_batch_inputs", "[", "\"inputs\"", "]", ")", "\n", "\n", "losses", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "\n", "line_nums", "=", "query_batch_inputs", "[", "\"line_nums\"", "]", "\n", "lengths", "=", "query_batch_inputs", "[", "\"lengths\"", "]", "\n", "inner_TP", ",", "inner_FP", ",", "inner_FN", "=", "0", ",", "0", ",", "0", "\n", "for", "idx", ",", "length", "in", "enumerate", "(", "lengths", ")", ":", "\n", "                ", "pred_tag_seq", "=", "[", "slot_tags_vocab", ".", "_convert_id_to_token", "(", "index", ")", "for", "index", "in", "top_pred_tags", "[", "idx", "]", "]", "[", ":", "length", "]", "\n", "lab_tag_seq", "=", "query_batch_inputs", "[", "\"tags\"", "]", "[", "idx", "]", "\n", "assert", "len", "(", "lab_tag_seq", ")", "==", "length", "\n", "pred_slot_chunks", "=", "metric", ".", "get_chunks", "(", "[", "'O'", "]", "+", "pred_tag_seq", "+", "[", "'O'", "]", ")", "\n", "label_slot_chunks", "=", "metric", ".", "get_chunks", "(", "[", "'O'", "]", "+", "lab_tag_seq", "+", "[", "'O'", "]", ")", "\n", "TP_1", ",", "FP_1", ",", "FN_1", "=", "metric", ".", "analysis_fscore", "(", "pred_slot_chunks", ",", "label_slot_chunks", ")", "\n", "TP", "+=", "TP_1", "\n", "FP", "+=", "FP_1", "\n", "FN", "+=", "FN_1", "\n", "\n", "inner_TP", "+=", "TP_1", "\n", "inner_FP", "+=", "FP_1", "\n", "inner_FN", "+=", "FN_1", "\n", "\n", "tokens", "=", "query_batch_inputs", "[", "\"tokens\"", "]", "[", "idx", "]", "\n", "assert", "len", "(", "tokens", ")", "==", "length", "\n", "token_tag_list", "=", "[", "':'", ".", "join", "(", "(", "tokens", "[", "_idx", "]", ",", "pred_tag_seq", "[", "_idx", "]", ",", "lab_tag_seq", "[", "_idx", "]", ")", ")", "for", "_idx", "in", "range", "(", "length", ")", "]", "\n", "\n", "if", "args", ".", "testing", ":", "\n", "                    ", "writer", ".", "write", "(", "str", "(", "line_nums", "[", "idx", "]", ")", "+", "' : '", "+", "' '", ".", "join", "(", "token_tag_list", ")", "+", "'\\n'", ")", "\n", "", "else", ":", "\n", "                    ", "writer", ".", "write", "(", "' '", ".", "join", "(", "token_tag_list", ")", "+", "'\\n'", ")", "\n", "", "", "marco_f1_scores", ".", "append", "(", "2", "*", "inner_TP", "/", "(", "2", "*", "inner_TP", "+", "inner_FP", "+", "inner_FN", ")", "if", "2", "*", "inner_TP", "+", "inner_FP", "+", "inner_FN", "!=", "0", "else", "0", ")", "\n", "\n", "", "", "mean_losses", "=", "np", ".", "mean", "(", "losses", ",", "axis", "=", "0", ")", "\n", "slot_metrics", "=", "metric", ".", "compute_fscore", "(", "TP", ",", "FP", ",", "FN", ")", "\n", "args", ".", "logger", ".", "info", "(", "'mirco f1 = %.2f;\\tepisode number = %d;\\taveraged mirco f1 = %.2f'", "%", "(", "slot_metrics", "[", "'f'", "]", ",", "len", "(", "marco_f1_scores", ")", ",", "100", "*", "sum", "(", "marco_f1_scores", ")", "/", "len", "(", "marco_f1_scores", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.decode": [[141, 298], ["torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "model_ori.eval", "numpy.mean", "utils.compute_fscore", "utils.compute_fscore", "args.logger.info", "open", "enumerate", "args.dataset_name.startswith", "losses.append", "enumerate", "marco_f1_scores.append", "slot_tags_vocab.get_elements_used_in_label_embeddings", "utils.basic_data_reader.convert_examples_to_features", "utils.data_reader_HIT.read_label_indicator_of_support_set", "utils.basic_data_reader.prepare_inputs_of_word_sequences_for_bert_xlnet", "model_ori.load_model", "model_ori.train", "range", "gc.collect", "model_ori.eval", "torch.no_grad", "torch.no_grad", "model.get_label_embeddings_from_support_set", "utils.basic_data_reader.convert_examples_to_features", "model", "model.decode_top_hyp_for_enc_dec", "model.decode_top_hyp", "utils.get_chunks", "utils.get_chunks", "utils.analysis_fscore", "len", "len", "list", "list", "torch.Adam", "models.utils.optim_bert.BertAdam.zero_grad", "len", "range", "models.utils.optim_bert.BertAdam.step", "len", "len", "isinstance", "utils.analysis_fscore", "intents_vocab._convert_id_to_token", "isinstance", "writer.write", "writer.write", "len", "sum", "model_ori.named_parameters", "filter", "models.utils.optim_bert.BertAdam", "model_ori.get_label_embeddings_from_support_set", "utils.basic_data_reader.convert_examples_to_features", "model_ori", "total_loss.backward", "tag_loss.item", "sum", "intent_loss.item", "len", "slot_tags_vocab._convert_id_to_token", "range", "intents_vocab._convert_id_to_token", "set", "set", "sum", "any", "optimizer_grouped_parameters.append", "enumerate", "model_ori.parameters", "any", "any", "any", "any", "int", "any", "any", "any", "re.search().group", "str", "re.search"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.compute_fscore", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.compute_fscore", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.get_elements_used_in_label_embeddings", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.convert_examples_to_features", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.read_label_indicator_of_support_set", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.prepare_inputs_of_word_sequences_for_bert_xlnet", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_model.BasicModel.load_model", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.get_label_embeddings_from_support_set", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.convert_examples_to_features", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.decode_top_hyp", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.get_chunks", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.get_chunks", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.analysis_fscore", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.BertAdam.step", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.metric.analysis_fscore", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab._convert_id_to_token", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.get_label_embeddings_from_support_set", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.convert_examples_to_features", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab._convert_id_to_token", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab._convert_id_to_token"], ["", "def", "decode", "(", "args", ",", "model_ori", ",", "eval_dataset", ",", "output_path", ",", "test_finetune_step", "=", "0", ",", "model_ori_saved_path", "=", "None", ",", "lr", "=", "0.001", ",", "optim_name", "=", "'adam'", ",", "lr_np", "=", "1e-3", ")", ":", "\n", "    ", "word_tokenizer", "=", "args", ".", "word_tokenizer", "\n", "char_tokenizer", "=", "args", ".", "char_tokenizer", "\n", "tf_tokenizer", "=", "args", ".", "tf_tokenizer", "\n", "tf_input_args", "=", "args", ".", "tf_input_args", "\n", "eval_sampler", "=", "RandomSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "test_batchSize", ",", "collate_fn", "=", "collate_fn_do_nothing", ")", "\n", "\n", "model_ori", ".", "eval", "(", ")", "\n", "losses", "=", "[", "]", "\n", "TP", ",", "FP", ",", "FN", ",", "TN", "=", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "\n", "TP2", ",", "FP2", ",", "FN2", ",", "TN2", "=", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "\n", "marco_f1_scores", "=", "[", "]", "\n", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "writer", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "eval_dataloader", ")", ":", "\n", "            ", "if", "args", ".", "dataset_name", ".", "startswith", "(", "\"HIT_\"", ")", ":", "\n", "                ", "support_batch", ",", "query_batch", "=", "batch", "[", "0", "]", "[", "0", "]", ",", "batch", "[", "0", "]", "[", "1", "]", "\n", "slot_tags_vocab", ",", "intents_vocab", "=", "batch", "[", "0", "]", "[", "2", "]", ",", "batch", "[", "0", "]", "[", "3", "]", "\n", "slot_desc_in_words", "=", "batch", "[", "0", "]", "[", "4", "]", "\n", "slot_head_labels_token_ids", ",", "slot_other_labels_seg_ids", ",", "slot_other_labels_selected_slot_ids", "=", "slot_tags_vocab", ".", "get_elements_used_in_label_embeddings", "(", "device", "=", "args", ".", "device", ")", "\n", "support_batch_inputs", "=", "convert_examples_to_features", "(", "support_batch", ",", "word_tokenizer", "=", "word_tokenizer", ",", "char_tokenizer", "=", "char_tokenizer", ",", "tf_tokenizer", "=", "tf_tokenizer", ",", "tf_input_args", "=", "tf_input_args", ",", "slot_tags_vocab", "=", "slot_tags_vocab", ",", "intents_vocab", "=", "intents_vocab", ",", "bos_eos", "=", "args", ".", "input_bos_eos", ",", "intent_multi_class", "=", "args", ".", "intent_multi_class", ",", "slot_tag_enc_dec", "=", "args", ".", "enc_dec", ",", "device", "=", "args", ".", "device", ")", "\n", "slot_label_indicator", ",", "intent_label_indicator", "=", "read_label_indicator_of_support_set", "(", "slot_tags_vocab", ",", "intents_vocab", ",", "support_batch_inputs", "[", "\"tags\"", "]", ",", "support_batch_inputs", "[", "\"intents\"", "]", ",", "indicator_type", "=", "'PN'", ",", "slot_embedding_type", "=", "args", ".", "slot_embedding_type", ",", "device", "=", "args", ".", "device", ")", "\n", "label_desc_inputs", "=", "prepare_inputs_of_word_sequences_for_bert_xlnet", "(", "slot_desc_in_words", ",", "tf_tokenizer", ",", "bos_eos", "=", "args", ".", "input_bos_eos", ",", "device", "=", "args", ".", "device", ",", "**", "tf_input_args", ")", "\n", "", "if", "test_finetune_step", ">", "0", ":", "\n", "                ", "model_ori", ".", "load_model", "(", "model_ori_saved_path", ")", "# load original model parameters for different episodes", "\n", "#for param in model_ori.input_embeddings.parameters():", "\n", "#    param.requires_grad = False", "\n", "#for param in model_ori.sentence_encoder.parameters():", "\n", "#    param.requires_grad = False", "\n", "if", "args", ".", "input_embedding_type", "in", "{", "'tf_emb'", ",", "'word_tf_emb'", ",", "'char_tf_emb'", ",", "'word_char_tf_emb'", "}", ":", "\n", "                    ", "named_params", "=", "list", "(", "model_ori", ".", "named_parameters", "(", ")", ")", "\n", "named_params", "=", "list", "(", "filter", "(", "lambda", "p", ":", "p", "[", "1", "]", ".", "requires_grad", ",", "named_params", ")", ")", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "large_lr", "=", "[", "'crf'", "]", "\n", "if", "args", ".", "tf_layerwise_lr_decay", ">=", "1.0", ":", "\n", "                        ", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "named_params", "if", "(", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", ")", "and", "(", "not", "any", "(", "ll", "in", "n", "for", "ll", "in", "large_lr", ")", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "# 0.01", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "named_params", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "(", "not", "any", "(", "ll", "in", "n", "for", "ll", "in", "large_lr", ")", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "named_params", "if", "any", "(", "ll", "in", "n", "for", "ll", "in", "large_lr", ")", "]", ",", "'weight_decay'", ":", "0.0", ",", "'lr'", ":", "lr_np", "}", "#1e-3", "\n", "]", "\n", "", "else", ":", "\n", "                        ", "optimizer_grouped_parameters", "=", "[", "]", "\n", "for", "n", ",", "p", "in", "named_params", ":", "\n", "                            ", "params_group", "=", "{", "}", "\n", "params_group", "[", "'params'", "]", "=", "p", "\n", "params_group", "[", "'weight_decay'", "]", "=", "0.01", "if", "(", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", ")", "and", "(", "not", "any", "(", "ll", "in", "n", "for", "ll", "in", "large_lr", ")", ")", "else", "0.0", "\n", "if", "any", "(", "ll", "in", "n", "for", "ll", "in", "large_lr", ")", ":", "\n", "                                ", "params_group", "[", "'lr'", "]", "=", "lr_np", "\n", "", "else", ":", "\n", "                                ", "if", "'tf_model.embeddings'", "in", "n", ":", "\n", "                                    ", "depth", "=", "0", "\n", "", "elif", "'tf_model.encoder.layer'", "in", "n", ":", "\n", "                                    ", "depth", "=", "int", "(", "re", ".", "search", "(", "r'tf_model.encoder.layer.(\\d+)'", ",", "n", ")", ".", "group", "(", "1", ")", ")", "+", "1", "\n", "", "else", ":", "\n", "                                    ", "depth", "=", "args", ".", "tf_model", ".", "config", ".", "num_hidden_layers", "\n", "", "params_group", "[", "'lr'", "]", "=", "lr", "*", "(", "args", ".", "tf_layerwise_lr_decay", "**", "(", "args", ".", "tf_model", ".", "config", ".", "num_hidden_layers", "-", "depth", ")", ")", "\n", "", "optimizer_grouped_parameters", ".", "append", "(", "params_group", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "optimizer_grouped_parameters", "=", "[", "{", "'params'", ":", "[", "param", "for", "param", "in", "model_ori", ".", "parameters", "(", ")", "if", "param", ".", "requires_grad", "]", "}", "]", "\n", "", "if", "optim_name", "==", "'adam'", ":", "\n", "                    ", "optimizer", "=", "optim", ".", "Adam", "(", "optimizer_grouped_parameters", ",", "lr", "=", "lr", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ")", "# (beta1, beta2)", "\n", "", "elif", "optim_name", "==", "'bertadam'", ":", "\n", "                    ", "num_train_optimization_steps", "=", "1", "*", "test_finetune_step", "\n", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "lr", "=", "lr", ",", "warmup", "=", "0.1", ",", "t_total", "=", "num_train_optimization_steps", ",", "max_grad_norm", "=", "1", ")", "\n", "", "model_ori", ".", "train", "(", ")", "\n", "for", "i", "in", "range", "(", "test_finetune_step", ")", ":", "\n", "                    ", "optimizer", ".", "zero_grad", "(", ")", "\n", "support_batch_size", "=", "len", "(", "support_batch", ")", "\n", "if", "args", ".", "test_finetune_accumulate_grad_batchSize", "==", "0", ":", "\n", "                        ", "accum_batch_size", "=", "support_batch_size", "\n", "", "else", ":", "\n", "                        ", "accum_batch_size", "=", "args", ".", "test_finetune_accumulate_grad_batchSize", "# 15, 20", "\n", "", "for", "j", "in", "range", "(", "0", ",", "support_batch_size", ",", "accum_batch_size", ")", ":", "\n", "                        ", "slot_tag_embeds", ",", "intent_embeds", "=", "model_ori", ".", "get_label_embeddings_from_support_set", "(", "support_batch_inputs", "[", "\"inputs\"", "]", ",", "support_batch_inputs", "[", "\"lengths\"", "]", ",", "support_batch_inputs", "[", "\"input_mask\"", "]", ",", "slot_label_indicator", ",", "intent_label_indicator", ",", "slot_head_labels_token_ids", ",", "slot_other_labels_seg_ids", "=", "slot_other_labels_seg_ids", ",", "slot_other_labels_selected_slot_ids", "=", "slot_other_labels_selected_slot_ids", ",", "label_desc_inputs", "=", "label_desc_inputs", ")", "\n", "accum_batch", "=", "support_batch", "[", "j", ":", "j", "+", "accum_batch_size", "]", "\n", "inputs", "=", "convert_examples_to_features", "(", "accum_batch", ",", "word_tokenizer", "=", "word_tokenizer", ",", "char_tokenizer", "=", "char_tokenizer", ",", "tf_tokenizer", "=", "tf_tokenizer", ",", "tf_input_args", "=", "tf_input_args", ",", "slot_tags_vocab", "=", "slot_tags_vocab", ",", "intents_vocab", "=", "intents_vocab", ",", "bos_eos", "=", "args", ".", "input_bos_eos", ",", "intent_multi_class", "=", "args", ".", "intent_multi_class", ",", "slot_tag_enc_dec", "=", "args", ".", "enc_dec", ",", "device", "=", "args", ".", "device", ")", "\n", "outputs", "=", "model_ori", "(", "slot_tag_embeds", ",", "intent_embeds", ",", "inputs", "[", "\"inputs\"", "]", ",", "inputs", "[", "\"lengths\"", "]", ",", "inputs", "[", "\"input_mask\"", "]", ",", "slot_tags", "=", "inputs", "[", "\"tag_ids\"", "]", ",", "intents", "=", "inputs", "[", "\"intent_ids\"", "]", ",", "slot_tag_masked_output", "=", "None", ",", "intent_masked_output", "=", "None", ",", "slot_tag_to_id", "=", "slot_tags_vocab", ".", "label_to_id", ")", "\n", "tag_loss", ",", "intent_loss", "=", "outputs", "[", ":", "2", "]", "\n", "total_loss", "=", "args", ".", "tr_st_weight", "*", "tag_loss", "+", "(", "1", "-", "args", ".", "tr_st_weight", ")", "*", "intent_loss", "\n", "total_loss", ".", "backward", "(", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "", "gc", ".", "collect", "(", ")", "\n", "model_ori", ".", "eval", "(", ")", "\n", "model", "=", "model_ori", "\n", "", "else", ":", "\n", "                ", "model", "=", "model_ori", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "slot_tag_embeds", ",", "intent_embeds", "=", "model", ".", "get_label_embeddings_from_support_set", "(", "support_batch_inputs", "[", "\"inputs\"", "]", ",", "support_batch_inputs", "[", "\"lengths\"", "]", ",", "support_batch_inputs", "[", "\"input_mask\"", "]", ",", "slot_label_indicator", ",", "intent_label_indicator", ",", "slot_head_labels_token_ids", ",", "slot_other_labels_seg_ids", "=", "slot_other_labels_seg_ids", ",", "slot_other_labels_selected_slot_ids", "=", "slot_other_labels_selected_slot_ids", ",", "label_desc_inputs", "=", "label_desc_inputs", ")", "\n", "inputs", "=", "convert_examples_to_features", "(", "query_batch", ",", "word_tokenizer", "=", "word_tokenizer", ",", "char_tokenizer", "=", "char_tokenizer", ",", "tf_tokenizer", "=", "tf_tokenizer", ",", "tf_input_args", "=", "tf_input_args", ",", "slot_tags_vocab", "=", "slot_tags_vocab", ",", "intents_vocab", "=", "intents_vocab", ",", "bos_eos", "=", "args", ".", "input_bos_eos", ",", "intent_multi_class", "=", "args", ".", "intent_multi_class", ",", "slot_tag_enc_dec", "=", "args", ".", "enc_dec", ",", "device", "=", "args", ".", "device", ")", "\n", "outputs", "=", "model", "(", "slot_tag_embeds", ",", "intent_embeds", ",", "inputs", "[", "\"inputs\"", "]", ",", "inputs", "[", "\"lengths\"", "]", ",", "inputs", "[", "\"input_mask\"", "]", ",", "slot_tags", "=", "inputs", "[", "\"tag_ids\"", "]", ",", "intents", "=", "inputs", "[", "\"intent_ids\"", "]", ",", "slot_tag_masked_output", "=", "None", ",", "intent_masked_output", "=", "None", ",", "slot_tag_to_id", "=", "slot_tags_vocab", ".", "label_to_id", ")", "\n", "", "tag_loss", ",", "intent_loss", ",", "tag_logits", ",", "intent_logits", "=", "outputs", "[", ":", "4", "]", "\n", "if", "args", ".", "enc_dec", ":", "\n", "                ", "rnn_out", ",", "reversed_h_t_c_t", "=", "outputs", "[", "4", ":", "]", "\n", "top_pred_tags", ",", "top_pred_intents", "=", "model", ".", "decode_top_hyp_for_enc_dec", "(", "slot_tag_embeds", ",", "intent_logits", ",", "rnn_out", ",", "inputs", "[", "\"input_mask\"", "]", ",", "reversed_h_t_c_t", ",", "inputs", "[", "\"tag_ids\"", "]", "[", ":", ",", "0", ":", "1", "]", ",", "inputs", "[", "\"lengths\"", "]", ",", "slot_tags_vocab", ")", "\n", "", "else", ":", "\n", "                ", "top_pred_tags", ",", "top_pred_intents", "=", "model", ".", "decode_top_hyp", "(", "slot_tag_embeds", ",", "tag_logits", ",", "intent_logits", ",", "inputs", "[", "\"input_mask\"", "]", ",", "slot_tag_to_id", "=", "slot_tags_vocab", ".", "label_to_id", ")", "\n", "\n", "", "losses", ".", "append", "(", "[", "tag_loss", ".", "item", "(", ")", "/", "sum", "(", "inputs", "[", "\"lengths\"", "]", ")", ",", "intent_loss", ".", "item", "(", ")", "/", "len", "(", "inputs", "[", "\"lengths\"", "]", ")", "]", ")", "\n", "\n", "line_nums", "=", "inputs", "[", "\"line_nums\"", "]", "\n", "lengths", "=", "inputs", "[", "\"lengths\"", "]", "\n", "inner_TP", ",", "inner_FP", ",", "inner_FN", "=", "0", ",", "0", ",", "0", "\n", "for", "idx", ",", "length", "in", "enumerate", "(", "lengths", ")", ":", "\n", "                ", "pred_tag_seq", "=", "[", "slot_tags_vocab", ".", "_convert_id_to_token", "(", "index", ")", "for", "index", "in", "top_pred_tags", "[", "idx", "]", "]", "[", ":", "length", "]", "\n", "lab_tag_seq", "=", "inputs", "[", "\"tags\"", "]", "[", "idx", "]", "\n", "assert", "len", "(", "lab_tag_seq", ")", "==", "length", "\n", "pred_slot_chunks", "=", "metric", ".", "get_chunks", "(", "[", "'O'", "]", "+", "pred_tag_seq", "+", "[", "'O'", "]", ")", "\n", "label_slot_chunks", "=", "metric", ".", "get_chunks", "(", "[", "'O'", "]", "+", "lab_tag_seq", "+", "[", "'O'", "]", ")", "\n", "TP_1", ",", "FP_1", ",", "FN_1", "=", "metric", ".", "analysis_fscore", "(", "pred_slot_chunks", ",", "label_slot_chunks", ")", "\n", "TP", "+=", "TP_1", "\n", "FP", "+=", "FP_1", "\n", "FN", "+=", "FN_1", "\n", "\n", "inner_TP", "+=", "TP_1", "\n", "inner_FP", "+=", "FP_1", "\n", "inner_FN", "+=", "FN_1", "\n", "\n", "tokens", "=", "inputs", "[", "\"tokens\"", "]", "[", "idx", "]", "\n", "assert", "len", "(", "tokens", ")", "==", "length", "\n", "token_tag_list", "=", "[", "':'", ".", "join", "(", "(", "tokens", "[", "_idx", "]", ",", "pred_tag_seq", "[", "_idx", "]", ",", "lab_tag_seq", "[", "_idx", "]", ")", ")", "for", "_idx", "in", "range", "(", "length", ")", "]", "\n", "\n", "label_intents", "=", "inputs", "[", "\"intents\"", "]", "[", "idx", "]", "\n", "if", "args", ".", "intent_multi_class", ":", "\n", "                    ", "assert", "isinstance", "(", "label_intents", ",", "list", ")", "\n", "pred_intents", "=", "[", "intents_vocab", ".", "_convert_id_to_token", "(", "i", ")", "for", "i", ",", "p", "in", "enumerate", "(", "top_pred_intents", "[", "idx", "]", ")", "if", "p", ">", "0.5", "]", "\n", "TP_FP_FN", "=", "metric", ".", "analysis_fscore", "(", "set", "(", "pred_intents", ")", ",", "set", "(", "label_intents", ")", ")", "\n", "TP2", "+=", "TP_FP_FN", "[", "0", "]", "\n", "FP2", "+=", "TP_FP_FN", "[", "1", "]", "\n", "FN2", "+=", "TP_FP_FN", "[", "2", "]", "\n", "pred_intents_str", "=", "';'", ".", "join", "(", "pred_intents", ")", "\n", "", "else", ":", "\n", "                    ", "pred_intent", "=", "intents_vocab", ".", "_convert_id_to_token", "(", "top_pred_intents", "[", "idx", "]", ")", "\n", "if", "isinstance", "(", "label_intents", ",", "str", ")", ":", "\n", "                        ", "label_intents", "=", "[", "label_intents", "]", "\n", "", "if", "pred_intent", "in", "label_intents", ":", "\n", "                        ", "TP2", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "FP2", "+=", "1", "\n", "FN2", "+=", "1", "\n", "", "pred_intents_str", "=", "pred_intent", "\n", "", "label_intents_str", "=", "';'", ".", "join", "(", "label_intents", ")", "\n", "\n", "if", "args", ".", "testing", ":", "\n", "                    ", "writer", ".", "write", "(", "str", "(", "line_nums", "[", "idx", "]", ")", "+", "' : '", "+", "' '", ".", "join", "(", "token_tag_list", ")", "+", "' <=> '", "+", "label_intents_str", "+", "' <=> '", "+", "pred_intents_str", "+", "'\\n'", ")", "\n", "", "else", ":", "\n", "                    ", "writer", ".", "write", "(", "' '", ".", "join", "(", "token_tag_list", ")", "+", "' <=> '", "+", "label_intents_str", "+", "' <=> '", "+", "pred_intents_str", "+", "'\\n'", ")", "\n", "\n", "", "", "marco_f1_scores", ".", "append", "(", "2", "*", "inner_TP", "/", "(", "2", "*", "inner_TP", "+", "inner_FP", "+", "inner_FN", ")", "if", "2", "*", "inner_TP", "+", "inner_FP", "+", "inner_FN", "!=", "0", "else", "0", ")", "\n", "\n", "", "", "mean_losses", "=", "np", ".", "mean", "(", "losses", ",", "axis", "=", "0", ")", "\n", "slot_metrics", "=", "metric", ".", "compute_fscore", "(", "TP", ",", "FP", ",", "FN", ")", "\n", "intent_metrics", "=", "metric", ".", "compute_fscore", "(", "TP2", ",", "FN2", ",", "FP2", ")", "\n", "args", ".", "logger", ".", "info", "(", "'episode number = %d;\\taveraged mirco f1 = %.2f'", "%", "(", "len", "(", "marco_f1_scores", ")", ",", "100", "*", "sum", "(", "marco_f1_scores", ")", "/", "len", "(", "marco_f1_scores", ")", ")", ")", "\n", "\n", "#return mean_losses, slot_metrics, intent_metrics", "\n", "return", "mean_losses", ",", "{", "'f'", ":", "100", "*", "sum", "(", "marco_f1_scores", ")", "/", "len", "(", "marco_f1_scores", ")", "}", ",", "intent_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.main": [[299, 675], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "models.utils.config.ModelConfig.from_argparse", "print", "parser.parse_args.dataset_name.startswith", "utils.util.set_logger", "utils.util.setup_device", "slot_tagging_with_prototypical_network_with_pure_bert.set_seed", "parser.parse_args.dataset_name.startswith", "utils.vocab_reader.FewShotSlotVocab", "utils.vocab_reader.FewShotSlotVocab._convert_token_to_id", "utils.util.set_logger.info", "parser.parse_args.dataset_name.startswith", "models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet", "print", "models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.to", "bool", "bool", "bool", "slot_tagging_with_prototypical_network_with_pure_bert.set_exp_path", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "utils.vocab_reader.SLUWordTokenizer", "utils.vocab_reader.SLUCharTokenizer", "utils.util.set_logger.info", "utils.pretrained_transformer.load_pretrained_transformer", "utils.vocab_reader.SLUWordTokenizer.get_vocab_size", "utils.vocab_reader.SLUCharTokenizer.get_vocab_size", "utils.data_reader_HIT.FewShotSlotIntentDataset_in_HIT_form", "utils.data_reader_HIT.FewShotSlotIntentDataset_in_HIT_form", "FewShotSlotIntentDataset", "FewShotSlotIntentDataset", "len", "models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.load_model", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "len", "utils.util.set_logger.info", "utils.util.set_logger.info", "utils.util.set_logger.info", "utils.util.set_logger.info", "slot_tagging_with_prototypical_network_with_pure_bert.decode_simBERT", "slot_tagging_with_prototypical_network_with_pure_bert.decode_simBERT", "range", "utils.util.set_logger.info", "utils.util.set_logger.info", "time.time", "slot_tagging_with_prototypical_network_with_pure_bert.decode", "utils.util.set_logger.info", "time.time", "slot_tagging_with_prototypical_network_with_pure_bert.decode", "utils.util.set_logger.info", "hasattr", "bool", "bool", "parser.parse_args.dataset_name.startswith", "utils.vocab_reader.SLUWordTokenizer.read_word2vec_inText", "utils.util.set_logger.info", "utils.vocab_reader.SLUWordTokenizer.save_vocab", "utils.vocab_reader.SLUCharTokenizer.save_vocab", "utils.vocab_reader.SLUWordTokenizer.read_vocab", "utils.vocab_reader.SLUCharTokenizer.read_vocab", "utils.data_reader_HIT.FewShotSlotIntentDataset_in_HIT_form", "FewShotSlotIntentDataset", "models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.input_embeddings.load_pretrained_word_embeddings", "len", "list", "list", "parser.parse_args.tr_optim.lower", "torch.SGD", "os.path.join", "os.path.join", "time.time", "models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.train", "enumerate", "print", "numpy.mean", "utils.util.set_logger.info", "gc.collect", "hasattr", "time.time", "slot_tagging_with_prototypical_network_with_pure_bert.decode", "utils.util.set_logger.info", "time.time", "slot_tagging_with_prototypical_network_with_pure_bert.decode", "utils.util.set_logger.info", "os.path.join", "os.path.join", "utils.util.set_logger.info", "time.time", "utils.vocab_reader.read_input_vocab_from_data_file_in_HIT_form", "utils.vocab_reader.read_input_vocab_from_data_file", "os.path.join", "os.path.join", "models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.input_embeddings.fix_word_embeddings", "time.asctime", "models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.named_parameters", "filter", "parser.parse_args.tr_optim.lower", "torch.Adam", "int", "parser.parse_args.dataset_name.startswith", "utils.util.set_logger.info", "utils.util.set_logger.info", "os.path.join", "os.path.join", "models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.save_model", "utils.util.set_logger.info", "os.path.join", "utils.util.set_logger.info", "os.remove", "print", "time.asctime", "utils.util.set_logger.info", "time.time", "slot_tagging_with_prototypical_network_with_pure_bert.decode", "utils.util.set_logger.info", "time.localtime", "any", "optimizer_grouped_parameters.append", "parser.parse_args.tr_optim.lower", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "str", "str", "int", "slot_tags_vocab.get_elements_used_in_label_embeddings", "utils.basic_data_reader.convert_examples_to_features", "utils.data_reader_HIT.read_label_indicator_of_support_set", "utils.basic_data_reader.prepare_inputs_of_word_sequences_for_bert_xlnet", "models.utils.optim_bert.BertAdam.zero_grad", "models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.get_label_embeddings_from_support_set", "utils.basic_data_reader.convert_examples_to_features", "models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.", "losses.append", "total_loss.backward", "models.utils.optim_bert.BertAdam.step", "print", "sys.stdout.flush", "os.path.join", "utils.util.set_logger.info", "time.time", "slot_tagging_with_prototypical_network_with_pure_bert.decode", "utils.util.set_logger.info", "time.time", "slot_tagging_with_prototypical_network_with_pure_bert.decode", "utils.util.set_logger.info", "str", "os.path.join", "time.localtime", "os.path.join", "time.time", "parser.parse_args.tr_optim.lower", "models.utils.optim_bert.BertAdam", "exit", "parser.parse_args.tr_optim.lower", "transformers.get_linear_schedule_with_warmup.step", "str", "str", "os.path.join", "os.path.join", "time.time", "time.time", "time.time", "models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.parameters", "int", "parser.parse_args.tr_optim.lower", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "time.time", "time.time", "time.time", "str", "any", "any", "any", "tag_loss.item", "sum", "intent_loss.item", "len", "time.time", "str", "str", "time.time", "any", "int", "time.time", "time.time", "any", "any", "any", "re.search().group", "re.search"], "function", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.config.ModelConfig.from_argparse", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.util.set_logger", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.util.setup_device", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.set_seed", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab._convert_token_to_id", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.set_exp_path", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.pretrained_transformer.load_pretrained_transformer", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.get_vocab_size", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.get_vocab_size", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_model.BasicModel.load_model", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.decode_simBERT", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.decode_simBERT", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.decode", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.decode", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUWordTokenizer.read_word2vec_inText", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.save_vocab", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.save_vocab", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUCharTokenizer.read_vocab", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.SLUCharTokenizer.read_vocab", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.decode", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.decode", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.read_input_vocab_from_data_file_in_HIT_form", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_vocab_reader.read_input_vocab_from_data_file", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_model.BasicModel.save_model", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.decode", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.vocab_reader.FewShotSlotVocab.get_elements_used_in_label_embeddings", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.convert_examples_to_features", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.read_label_indicator_of_support_set", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_data_reader.prepare_inputs_of_word_sequences_for_bert_xlnet", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.get_label_embeddings_from_support_set", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.data_reader_HIT.convert_examples_to_features", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.BertAdam.step", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.decode", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.scripts.slot_tagging_with_prototypical_network_with_pure_bert.decode", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.optim_bert.BertAdam.step"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--task_st'", ",", "required", "=", "True", ",", "help", "=", "'slot_tagger | slot_tagger_with_focus | slot_tagger_with_crf | slot_tagger_with_adaptive_crf | slot_tagger_with_abstract_crf | slot_tagger_with_attention_decoder | slot_tagger_with_focus_and_attention_decoder'", ")", "\n", "parser", ".", "add_argument", "(", "'--task_sc'", ",", "required", "=", "True", ",", "help", "=", "'2tails | maxPooling | hiddenCNN | hiddenAttention'", ")", "\n", "parser", ".", "add_argument", "(", "'--task_sc_type'", ",", "required", "=", "True", ",", "help", "=", "'single_cls_CE | multi_cls_BCE'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--slot_embedding_type'", ",", "required", "=", "True", ",", "help", "=", "'with_BIO | with_BI | without_BIO'", ")", "\n", "parser", ".", "add_argument", "(", "'--matching_similarity_type'", ",", "required", "=", "True", ",", "help", "=", "'xy | xy1 | x1y | x1y1 | rxy'", ")", "\n", "parser", ".", "add_argument", "(", "'--matching_similarity_y'", ",", "required", "=", "True", ",", "help", "=", "'ctx | desc | ctx_desc'", ")", "\n", "parser", ".", "add_argument", "(", "'--matching_similarity_function'", ",", "required", "=", "True", ",", "help", "=", "'dot | euclidean'", ")", "\n", "parser", ".", "add_argument", "(", "'--slot_embedding_dependent_query_encoding'", ",", "required", "=", "True", ",", "help", "=", "'none | ctx | desc'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--dataset_name'", ",", "required", "=", "True", ",", "help", "=", "'HIT_NER_shot_1_xval_1 | SJTU_shot_1_xval_1'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_path'", ",", "required", "=", "True", ",", "help", "=", "'path to dataset'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--input_mini_word_freq'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'mini_word_freq in the training data used in building input vocabulary when pretrained transformer is not used'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_word_lowercase'", ",", "action", "=", "'store_true'", ",", "help", "=", "'word lowercase'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_bos_eos'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Whether to add <s> and </s> to the input sentence (default is not)'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_save_vocab'", ",", "default", "=", "'vocab'", ",", "help", "=", "'save vocab to this file'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_embedding_type'", ",", "default", "=", "\"word_emb\"", ",", "help", "=", "'word_emb, char_emb, word_char_emb, tf_emb, word_tf_emb, char_tf_emb, word_char_tf_emb'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_pretrained_wordEmb'", ",", "required", "=", "False", ",", "help", "=", "'read word embedding from word2vec file'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_pretrained_wordEmb_fixed'", ",", "action", "=", "'store_true'", ",", "help", "=", "'pre-trained word embeddings are fixed'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_pretrained_transformer_model_type'", ",", "required", "=", "False", ",", "help", "=", "'bert, xlnet'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_pretrained_transformer_model_name'", ",", "required", "=", "False", ",", "help", "=", "'bert-base-uncased, bert-base-cased, bert-large-uncased, bert-large-cased, bert-base-multilingual-cased, bert-base-chinese; xlnet-base-cased, xlnet-large-cased'", ")", "\n", "#parser.add_argument('--input_pretrained_transformer_model_fixed', action='store_true', help='fix pretrained (bert/xlnet) model')", "\n", "\n", "parser", ".", "add_argument", "(", "'--model_save_path'", ",", "default", "=", "'model'", ",", "help", "=", "'save model to this file'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_removed'", ",", "default", "=", "'no'", ",", "help", "=", "'yes | no; (not to save model finally)'", ")", "\n", "#parser.add_argument('--arch_word_emb_size', type=int, default=100, help='word embedding dimension')", "\n", "#parser.add_argument('--arch_char_emb_size', type=int, default=25, help='char embedding dimension')", "\n", "#parser.add_argument('--arch_char_hidden_size', type=int, default=25, help='char-level RNN hidden dimension')", "\n", "#parser.add_argument('--arch_tag_emb_size', type=int, default=100, help='tag embedding dimension')", "\n", "#parser.add_argument('--arch_hidden_size', type=int, default=100, help='hidden layer dimension')", "\n", "#parser.add_argument('--arch_num_layers', type=int, default=0, help='number of hidden layers')", "\n", "#parser.add_argument('--arch_rnn_cell', default='lstm', help='type of RNN cell: rnn, gru, lstm')", "\n", "#parser.add_argument('--arch_bidirectional', action='store_true', help='Whether to use bidirectional RNN (default is unidirectional)')", "\n", "#parser.add_argument('--arch_decoder_tied', action='store_true', help='To tie the output layer and input embedding in decoder')", "\n", "parser", ".", "add_argument", "(", "'--arch_dropout'", ",", "type", "=", "float", ",", "default", "=", "0.", ",", "help", "=", "'dropout rate at each non-recurrent layer'", ")", "\n", "parser", ".", "add_argument", "(", "'--arch_init_weight'", ",", "type", "=", "float", ",", "default", "=", "0.2", ",", "help", "=", "'all weights will be set to [-init_weight, init_weight] during initialization'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--tr_lr'", ",", "type", "=", "float", ",", "default", "=", "1e-5", ",", "help", "=", "'learning rate for finetuning BERT'", ")", "\n", "parser", ".", "add_argument", "(", "'--tf_layerwise_lr_decay'", ",", "type", "=", "float", ",", "default", "=", "1.0", ",", "help", "=", "'layerwise lr decay for finetuning BERT'", ")", "\n", "parser", ".", "add_argument", "(", "'--tr_lr_np'", ",", "type", "=", "float", ",", "default", "=", "1e-3", ",", "help", "=", "'learning rate for newly initialized paramters'", ")", "\n", "parser", ".", "add_argument", "(", "'--tr_lr_warmup_proportion'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'Linear warmup over warmup_proportion of total steps.'", ")", "\n", "parser", ".", "add_argument", "(", "'--tr_batchSize'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'input batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--tr_max_norm'", ",", "type", "=", "float", ",", "default", "=", "5", ",", "help", "=", "\"threshold of gradient clipping (2-norm)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--tr_max_epoch'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'max number of epochs to train for'", ")", "\n", "parser", ".", "add_argument", "(", "'--tr_exp_path'", ",", "default", "=", "'exp'", ",", "help", "=", "'Where to store samples and models'", ")", "\n", "parser", ".", "add_argument", "(", "'--tr_optim'", ",", "default", "=", "'adam'", ",", "help", "=", "'choose an optimizer: sgd, adam, adamW'", ")", "\n", "parser", ".", "add_argument", "(", "'--tr_st_weight'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'loss weight for slot tagging task, ranging from 0 to 1.'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batchSize'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'input batch size in decoding'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_finetune'", ",", "action", "=", "'store_true'", ",", "help", "=", "'finetune with support set on the test set'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_finetune_accumulate_grad_batchSize'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'test_finetune_accumulate_grad_batchSize: 0 means not accumulating gradients'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--deviceId'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "'train model on ith gpu. -1:cpu, 0:auto_select'", ")", "\n", "parser", ".", "add_argument", "(", "'--random_seed'", ",", "type", "=", "int", ",", "default", "=", "999", ",", "help", "=", "'set initial random seed'", ")", "\n", "parser", ".", "add_argument", "(", "'--noStdout'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Only log to a file; no stdout'", ")", "\n", "parser", ".", "add_argument", "(", "'--testing'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Only test your model (default is training && testing)'", ")", "\n", "parser", ".", "add_argument", "(", "'--testing_output_path'", ",", "required", "=", "False", ",", "help", "=", "'Online test: output path'", ")", "\n", "parser", ".", "add_argument", "(", "'--testing_model_read_path'", ",", "required", "=", "False", ",", "help", "=", "'Online test: read model from this file'", ")", "\n", "parser", ".", "add_argument", "(", "'--testing_input_read_vocab'", ",", "required", "=", "False", ",", "help", "=", "'Online test: read input vocab from this file'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "config", "=", "ModelConfig", ".", "from_argparse", "(", "args", ")", "\n", "print", "(", "config", ")", "\n", "\n", "assert", "args", ".", "task_st", "in", "{", "'slot_tagger'", ",", "'slot_tagger_with_adaptive_crf'", ",", "'slot_tagger_with_abstract_crf'", ",", "'slot_tagger_with_focus'", "}", "#, 'slot_tagger_with_crf', 'slot_tagger_with_attention_decoder', 'slot_tagger_with_focus_and_attention_decoder'}", "\n", "assert", "args", ".", "task_sc", "in", "{", "'2tails'", ",", "'maxPooling'", ",", "'hiddenCNN'", ",", "'hiddenAttention'", "}", "\n", "assert", "args", ".", "task_sc_type", "in", "{", "'single_cls_CE'", ",", "'multi_cls_BCE'", "}", "\n", "args", ".", "intent_multi_class", "=", "(", "args", ".", "task_sc_type", "==", "\"multi_cls_BCE\"", ")", "\n", "if", "args", ".", "task_st", "in", "{", "'slot_tagger_with_focus'", ",", "'slot_tagger_with_attention_decoder'", ",", "'slot_tagger_with_focus_and_attention_decoder'", "}", ":", "\n", "        ", "args", ".", "enc_dec", "=", "True", "\n", "", "else", ":", "\n", "        ", "args", ".", "enc_dec", "=", "False", "\n", "", "assert", "0", "<", "args", ".", "tr_st_weight", "<=", "1", "\n", "assert", "args", ".", "slot_embedding_type", "in", "{", "'with_BIO'", ",", "'with_BI'", ",", "'without_BIO'", "}", "\n", "assert", "args", ".", "matching_similarity_type", "in", "{", "'xy'", ",", "'x1y'", ",", "'xy1'", ",", "'x1y1'", ",", "'rxy'", "}", "\n", "assert", "args", ".", "matching_similarity_y", "in", "{", "'ctx'", ",", "'ctx_desc'", ",", "'desc'", "}", "\n", "assert", "args", ".", "matching_similarity_function", "in", "{", "'dot'", ",", "'euclidean'", ",", "'euclidean2'", ",", "'euclidean3'", "}", "\n", "assert", "args", ".", "slot_embedding_dependent_query_encoding", "in", "{", "'none'", ",", "'ctx'", ",", "'desc'", "}", "\n", "#assert args.input_embedding_type in {'word_emb', 'char_emb', 'word_char_emb', 'tf_emb', 'word_tf_emb', 'char_tf_emb', 'word_char_tf_emb'}", "\n", "assert", "args", ".", "input_embedding_type", "==", "'tf_emb'", "\n", "assert", "args", ".", "testing", "==", "bool", "(", "args", ".", "testing_output_path", ")", "==", "bool", "(", "args", ".", "testing_model_read_path", ")", "==", "bool", "(", "args", ".", "testing_input_read_vocab", ")", "\n", "if", "args", ".", "test_batchSize", "==", "0", ":", "\n", "        ", "args", ".", "test_batchSize", "=", "args", ".", "tr_batchSize", "\n", "", "if", "args", ".", "dataset_name", ".", "startswith", "(", "\"HIT_\"", ")", ":", "\n", "        ", "args", ".", "tr_batchSize", "=", "1", "\n", "args", ".", "test_batchSize", "=", "1", "\n", "", "assert", "0", "<", "args", ".", "tf_layerwise_lr_decay", "<=", "1.0", "\n", "assert", "args", ".", "model_removed", "in", "{", "'yes'", ",", "'no'", "}", "\n", "\n", "if", "not", "args", ".", "testing", ":", "\n", "        ", "exp_path", "=", "set_exp_path", "(", "args", ",", "'few_shot_slot_intent/prototypical_network_with_pure_bert'", ")", "\n", "", "else", ":", "\n", "        ", "exp_path", "=", "args", ".", "testing_output_path", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "exp_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "exp_path", ")", "\n", "", "logger", "=", "set_logger", "(", "args", ",", "exp_path", ")", "\n", "args", ".", "logger", "=", "logger", "\n", "args", ".", "device", "=", "setup_device", "(", "args", ".", "deviceId", ",", "logger", ")", "\n", "set_seed", "(", "args", ")", "\n", "\n", "## read vocab && dataset", "\n", "dataroot", "=", "args", ".", "dataset_path", "\n", "if", "args", ".", "dataset_name", ".", "startswith", "(", "\"HIT_\"", ")", ":", "\n", "        ", "train_data_path", "=", "os", ".", "path", ".", "join", "(", "dataroot", ",", "'train.json'", ")", "\n", "valid_data_path", "=", "os", ".", "path", ".", "join", "(", "dataroot", ",", "'valid.json'", ")", "\n", "test_data_path", "=", "os", ".", "path", ".", "join", "(", "dataroot", ",", "'test.json'", ")", "\n", "slot_desc_data_path", "=", "os", ".", "path", ".", "join", "(", "dataroot", ",", "'slot_description'", ")", "\n", "", "else", ":", "\n", "# not ready", "\n", "        ", "train_data_path", "=", "os", ".", "path", ".", "join", "(", "dataroot", ",", "'train'", ")", "\n", "valid_data_path", "=", "os", ".", "path", ".", "join", "(", "dataroot", ",", "'valid'", ")", "\n", "test_data_path", "=", "os", ".", "path", ".", "join", "(", "dataroot", ",", "'test'", ")", "\n", "\n", "### build vocab", "\n", "#### complex input embeddings", "\n", "", "if", "args", ".", "input_embedding_type", "in", "{", "'word_emb'", ",", "'word_char_emb'", ",", "'word_tf_emb'", ",", "'word_char_tf_emb'", "}", ":", "\n", "        ", "word_tokenizer", "=", "SLUWordTokenizer", "(", "bos_eos", "=", "args", ".", "input_bos_eos", ",", "lowercase", "=", "args", ".", "input_word_lowercase", ")", "\n", "", "else", ":", "\n", "        ", "word_tokenizer", "=", "None", "\n", "", "if", "args", ".", "input_embedding_type", "in", "{", "'char_emb'", ",", "'word_char_emb'", ",", "'char_tf_emb'", ",", "'word_char_tf_emb'", "}", ":", "\n", "        ", "char_tokenizer", "=", "SLUCharTokenizer", "(", "bos_eos", "=", "args", ".", "input_bos_eos", ",", "lowercase", "=", "args", ".", "input_word_lowercase", ")", "\n", "", "else", ":", "\n", "        ", "char_tokenizer", "=", "None", "\n", "", "if", "args", ".", "input_embedding_type", "in", "{", "'tf_emb'", ",", "'word_tf_emb'", ",", "'char_tf_emb'", ",", "'word_char_tf_emb'", "}", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading pretrained %s model with %s\"", "%", "(", "args", ".", "input_pretrained_transformer_model_type", ",", "args", ".", "input_pretrained_transformer_model_name", ")", ")", "\n", "tf_tokenizer", ",", "tf_model", "=", "load_pretrained_transformer", "(", "args", ".", "input_pretrained_transformer_model_type", ",", "args", ".", "input_pretrained_transformer_model_name", ")", "\n", "tf_input_args", "=", "{", "\n", "'cls_token_at_end'", ":", "bool", "(", "args", ".", "input_pretrained_transformer_model_type", "in", "[", "'xlnet'", "]", ")", ",", "# xlnet has a cls token at the end", "\n", "'cls_token_segment_id'", ":", "2", "if", "args", ".", "input_pretrained_transformer_model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "'pad_on_left'", ":", "bool", "(", "args", ".", "input_pretrained_transformer_model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "'pad_token_segment_id'", ":", "4", "if", "args", ".", "input_pretrained_transformer_model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", "}", "\n", "", "else", ":", "\n", "        ", "tf_tokenizer", ",", "tf_model", "=", "None", ",", "None", "\n", "tf_input_args", "=", "{", "}", "\n", "", "assert", "word_tokenizer", "is", "not", "None", "or", "char_tokenizer", "is", "not", "None", "or", "tf_tokenizer", "is", "not", "None", "\n", "if", "not", "args", ".", "testing", ":", "\n", "        ", "if", "word_tokenizer", "is", "not", "None", "or", "char_tokenizer", "is", "not", "None", ":", "\n", "            ", "if", "args", ".", "dataset_name", ".", "startswith", "(", "\"HIT_\"", ")", ":", "\n", "                ", "read_input_vocab_from_data_file_in_HIT_form", "(", "train_data_path", ",", "word_tokenizer", "=", "word_tokenizer", ",", "char_tokenizer", "=", "char_tokenizer", ",", "lowercase", "=", "args", ".", "input_word_lowercase", ",", "mini_word_freq", "=", "args", ".", "input_mini_word_freq", ")", "\n", "", "else", ":", "\n", "                ", "read_input_vocab_from_data_file", "(", "train_data_path", ",", "word_tokenizer", "=", "word_tokenizer", ",", "char_tokenizer", "=", "char_tokenizer", ",", "lowercase", "=", "args", ".", "input_word_lowercase", ",", "mini_word_freq", "=", "args", ".", "input_mini_word_freq", ")", "\n", "", "", "if", "word_tokenizer", "is", "not", "None", "and", "args", ".", "input_pretrained_wordEmb", ":", "\n", "# pretrained-embedding initialization for training", "\n", "            ", "special_token_embeddings", ",", "pretrained_normal_token_num", ",", "pretrained_normal_token_embeddings", ",", "token_out_of_pretrained_emb_num", "=", "word_tokenizer", ".", "read_word2vec_inText", "(", "args", ".", "input_pretrained_wordEmb", ",", "device", "=", "args", ".", "device", ")", "\n", "logger", ".", "info", "(", "\"%s token(s) is/are out of pretrained word embeddings!\"", "%", "(", "token_out_of_pretrained_emb_num", ")", ")", "\n", "", "if", "word_tokenizer", "is", "not", "None", ":", "\n", "            ", "word_tokenizer", ".", "save_vocab", "(", "os", ".", "path", ".", "join", "(", "exp_path", ",", "args", ".", "input_save_vocab", "+", "'.input_word'", ")", ")", "\n", "", "if", "char_tokenizer", "is", "not", "None", ":", "\n", "            ", "char_tokenizer", ".", "save_vocab", "(", "os", ".", "path", ".", "join", "(", "exp_path", ",", "args", ".", "input_save_vocab", "+", "'.input_char'", ")", ")", "\n", "", "if", "tf_tokenizer", "is", "not", "None", ":", "\n", "            ", "xxxx", "=", "0", "\n", "#tf_tokenizer.save_vocab(os.path.join(exp_path, args.input_save_vocab+'.input_tf'))", "\n", "", "", "else", ":", "\n", "        ", "if", "word_tokenizer", "is", "not", "None", ":", "\n", "            ", "word_tokenizer", ".", "read_vocab", "(", "args", ".", "testing_input_read_vocab", "+", "'.input_word'", ")", "\n", "", "if", "char_tokenizer", "is", "not", "None", ":", "\n", "            ", "char_tokenizer", ".", "read_vocab", "(", "args", ".", "testing_input_read_vocab", "+", "'.input_char'", ")", "\n", "", "if", "tf_tokenizer", "is", "not", "None", ":", "\n", "            ", "xxxx", "=", "0", "\n", "#tf_tokenizer.read_vocab(args.testing_input_read_vocab+'.input_tf')", "\n", "", "", "config", ".", "input_word_vocab_size", "=", "word_tokenizer", ".", "get_vocab_size", "(", ")", "if", "word_tokenizer", "is", "not", "None", "else", "None", "\n", "config", ".", "input_char_vocab_size", "=", "char_tokenizer", ".", "get_vocab_size", "(", ")", "if", "char_tokenizer", "is", "not", "None", "else", "None", "\n", "config", ".", "input_tf_vocab_size", "=", "tf_tokenizer", ".", "vocab_size", "if", "tf_tokenizer", "is", "not", "None", "else", "None", "\n", "args", ".", "word_tokenizer", "=", "word_tokenizer", "\n", "args", ".", "char_tokenizer", "=", "char_tokenizer", "\n", "args", ".", "tf_tokenizer", "=", "tf_tokenizer", "\n", "args", ".", "tf_input_args", "=", "tf_input_args", "\n", "args", ".", "tf_model", "=", "tf_model", "\n", "#### output vocab", "\n", "basic_slot_tags_vocab", "=", "FewShotSlotVocab", "(", "[", "]", ",", "slot_embedding_type", "=", "args", ".", "slot_embedding_type", ",", "bos_eos", "=", "args", ".", "input_bos_eos", ")", "\n", "config", ".", "output_tag_pad_id", "=", "basic_slot_tags_vocab", ".", "_convert_token_to_id", "(", "basic_slot_tags_vocab", ".", "pad_token", ")", "\n", "config", ".", "input_additional_feature_dim", "=", "None", "\n", "logger", ".", "info", "(", "\"Vocab size: input tokens (word-%s, char-%s, tf-%s)\"", "%", "(", "config", ".", "input_word_vocab_size", ",", "config", ".", "input_char_vocab_size", ",", "config", ".", "input_tf_vocab_size", ")", ")", "\n", "\n", "### read data", "\n", "if", "args", ".", "dataset_name", ".", "startswith", "(", "\"HIT_\"", ")", ":", "\n", "        ", "if", "not", "args", ".", "testing", ":", "\n", "            ", "train_dataset", "=", "FewShotSlotIntentDataset_in_HIT_form", "(", "train_data_path", ",", "slot_desc_data_path", ",", "slot_embedding_type", "=", "args", ".", "slot_embedding_type", ",", "bert_tokenized", "=", "False", ",", "lowercase", "=", "args", ".", "input_word_lowercase", ",", "input_bos_eos", "=", "args", ".", "input_bos_eos", ")", "\n", "", "valid_dataset", "=", "FewShotSlotIntentDataset_in_HIT_form", "(", "valid_data_path", ",", "slot_desc_data_path", ",", "slot_embedding_type", "=", "args", ".", "slot_embedding_type", ",", "bert_tokenized", "=", "False", ",", "lowercase", "=", "args", ".", "input_word_lowercase", ",", "input_bos_eos", "=", "args", ".", "input_bos_eos", ")", "\n", "test_dataset", "=", "FewShotSlotIntentDataset_in_HIT_form", "(", "test_data_path", ",", "slot_desc_data_path", ",", "slot_embedding_type", "=", "args", ".", "slot_embedding_type", ",", "bert_tokenized", "=", "False", ",", "lowercase", "=", "args", ".", "input_word_lowercase", ",", "input_bos_eos", "=", "args", ".", "input_bos_eos", ")", "\n", "", "else", ":", "\n", "        ", "if", "not", "args", ".", "testing", ":", "\n", "            ", "train_dataset", "=", "FewShotSlotIntentDataset", "(", "train_data_path", ",", "lowercase", "=", "args", ".", "input_word_lowercase", ",", "input_bos_eos", "=", "args", ".", "input_bos_eos", ")", "\n", "", "valid_dataset", "=", "FewShotSlotIntentDataset", "(", "valid_data_path", ",", "lowercase", "=", "args", ".", "input_word_lowercase", ",", "input_bos_eos", "=", "args", ".", "input_bos_eos", ")", "\n", "test_dataset", "=", "FewShotSlotIntentDataset", "(", "test_data_path", ",", "lowercase", "=", "args", ".", "input_word_lowercase", ",", "input_bos_eos", "=", "args", ".", "input_bos_eos", ")", "\n", "\n", "## init model architecture", "\n", "", "model", "=", "FewShotIntentSlot_ProtoNet", "(", "config", ",", "len", "(", "basic_slot_tags_vocab", ".", "init_token_to_id", ")", ",", "slot_embedding_type", "=", "args", ".", "slot_embedding_type", ",", "matching_similarity_type", "=", "args", ".", "matching_similarity_type", ",", "slot_embedding_dependent_query_encoding", "=", "args", ".", "slot_embedding_dependent_query_encoding", ",", "matching_similarity_y", "=", "args", ".", "matching_similarity_y", ",", "matching_similarity_function", "=", "args", ".", "matching_similarity_function", ",", "device", "=", "args", ".", "device", ",", "pretrained_tf_model", "=", "tf_model", ")", "\n", "print", "(", "model", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "not", "args", ".", "testing", ":", "\n", "# pretrained-embedding initialization for training", "\n", "        ", "if", "word_tokenizer", "is", "not", "None", "and", "args", ".", "input_pretrained_wordEmb", ":", "\n", "            ", "model", ".", "input_embeddings", ".", "load_pretrained_word_embeddings", "(", "special_token_embeddings", ",", "pretrained_normal_token_num", ",", "pretrained_normal_token_embeddings", ")", "\n", "if", "args", ".", "input_pretrained_wordEmb_fixed", ":", "\n", "                ", "model", ".", "input_embeddings", ".", "fix_word_embeddings", "(", ")", "\n", "", "", "", "else", ":", "\n", "# read pretrained model for evaluation", "\n", "        ", "model", ".", "load_model", "(", "args", ".", "testing_model_read_path", ")", "\n", "\n", "## training or testing", "\n", "", "if", "not", "args", ".", "testing", ":", "\n", "        ", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "tr_batchSize", ",", "collate_fn", "=", "collate_fn_do_nothing", ")", "\n", "batch_number", "=", "len", "(", "train_dataloader", ")", "\n", "#print(len(train_dataset), args.tr_batchSize, batch_number, len(train_dataloader))", "\n", "\n", "logger", ".", "info", "(", "\"***** Training starts at %s *****\"", "%", "(", "time", ".", "asctime", "(", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num batches = %d\"", ",", "batch_number", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "tr_max_epoch", ")", "\n", "\n", "# optimizer", "\n", "if", "args", ".", "input_embedding_type", "in", "{", "'tf_emb'", ",", "'word_tf_emb'", ",", "'char_tf_emb'", ",", "'word_char_tf_emb'", "}", ":", "\n", "            ", "named_params", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "named_params", "=", "list", "(", "filter", "(", "lambda", "p", ":", "p", "[", "1", "]", ".", "requires_grad", ",", "named_params", ")", ")", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "large_lr", "=", "[", "'crf'", "]", "\n", "if", "args", ".", "tf_layerwise_lr_decay", ">=", "1.0", ":", "\n", "                ", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "named_params", "if", "(", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", ")", "and", "(", "not", "any", "(", "ll", "in", "n", "for", "ll", "in", "large_lr", ")", ")", "]", ",", "'weight_decay'", ":", "0.01", "}", ",", "# 0.01", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "named_params", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "and", "(", "not", "any", "(", "ll", "in", "n", "for", "ll", "in", "large_lr", ")", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "named_params", "if", "any", "(", "ll", "in", "n", "for", "ll", "in", "large_lr", ")", "]", ",", "'weight_decay'", ":", "0.0", ",", "'lr'", ":", "args", ".", "tr_lr_np", "}", "#1e-3", "\n", "]", "\n", "", "else", ":", "\n", "                ", "optimizer_grouped_parameters", "=", "[", "]", "\n", "for", "n", ",", "p", "in", "named_params", ":", "\n", "                    ", "params_group", "=", "{", "}", "\n", "params_group", "[", "'params'", "]", "=", "p", "\n", "params_group", "[", "'weight_decay'", "]", "=", "0.01", "if", "(", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", ")", "and", "(", "not", "any", "(", "ll", "in", "n", "for", "ll", "in", "large_lr", ")", ")", "else", "0.0", "\n", "if", "any", "(", "ll", "in", "n", "for", "ll", "in", "large_lr", ")", ":", "\n", "                        ", "params_group", "[", "'lr'", "]", "=", "args", ".", "tr_lr_np", "\n", "", "else", ":", "\n", "                        ", "if", "'tf_model.embeddings'", "in", "n", ":", "\n", "                            ", "depth", "=", "0", "\n", "", "elif", "'tf_model.encoder.layer'", "in", "n", ":", "\n", "                            ", "depth", "=", "int", "(", "re", ".", "search", "(", "r'tf_model.encoder.layer.(\\d+)'", ",", "n", ")", ".", "group", "(", "1", ")", ")", "+", "1", "\n", "", "else", ":", "\n", "                            ", "depth", "=", "args", ".", "tf_model", ".", "config", ".", "num_hidden_layers", "\n", "", "params_group", "[", "'lr'", "]", "=", "args", ".", "tr_lr", "*", "(", "args", ".", "tf_layerwise_lr_decay", "**", "(", "args", ".", "tf_model", ".", "config", ".", "num_hidden_layers", "-", "depth", ")", ")", "\n", "", "optimizer_grouped_parameters", ".", "append", "(", "params_group", ")", "\n", "", "", "", "else", ":", "\n", "            ", "optimizer_grouped_parameters", "=", "[", "{", "'params'", ":", "[", "param", "for", "param", "in", "model", ".", "parameters", "(", ")", "if", "param", ".", "requires_grad", "]", "}", "]", "\n", "", "if", "args", ".", "tr_optim", ".", "lower", "(", ")", "==", "'sgd'", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "tr_lr", ")", "\n", "", "elif", "args", ".", "tr_optim", ".", "lower", "(", ")", "==", "'adam'", ":", "\n", "            ", "optimizer", "=", "optim", ".", "Adam", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "tr_lr", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ")", "# (beta1, beta2)", "\n", "", "elif", "args", ".", "tr_optim", ".", "lower", "(", ")", "==", "'adamw'", ":", "\n", "            ", "num_train_optimization_steps", "=", "batch_number", "*", "args", ".", "tr_max_epoch", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "tr_lr", ",", "eps", "=", "1e-8", ",", "correct_bias", "=", "False", ")", "# To reproduce BertAdam specific behavior set correct_bias=False", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "int", "(", "args", ".", "tr_lr_warmup_proportion", "*", "num_train_optimization_steps", ")", ",", "num_training_steps", "=", "num_train_optimization_steps", ")", "# PyTorch scheduler", "\n", "", "elif", "args", ".", "tr_optim", ".", "lower", "(", ")", "==", "'bertadam'", ":", "\n", "            ", "num_train_optimization_steps", "=", "batch_number", "*", "args", ".", "tr_max_epoch", "\n", "optimizer", "=", "BertAdam", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "tr_lr", ",", "warmup", "=", "args", ".", "tr_lr_warmup_proportion", ",", "t_total", "=", "num_train_optimization_steps", ",", "max_grad_norm", "=", "args", ".", "tr_max_norm", ")", "\n", "", "else", ":", "\n", "            ", "exit", "(", ")", "\n", "\n", "", "decode_simBERT", "(", "args", ",", "model", ",", "valid_dataset", ",", "os", ".", "path", ".", "join", "(", "exp_path", ",", "'valid.iter'", "+", "str", "(", "-", "1", ")", ")", ")", "\n", "decode_simBERT", "(", "args", ",", "model", ",", "test_dataset", ",", "os", ".", "path", ".", "join", "(", "exp_path", ",", "'test.iter'", "+", "str", "(", "-", "1", ")", ")", ")", "\n", "best_f1", ",", "best_result", "=", "-", "1", ",", "{", "}", "\n", "for", "i", "in", "range", "(", "args", ".", "tr_max_epoch", ")", ":", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "losses", "=", "[", "]", "\n", "model", ".", "train", "(", ")", "\n", "\n", "piece_steps", "=", "1", "if", "int", "(", "batch_number", "*", "0.1", ")", "==", "0", "else", "int", "(", "batch_number", "*", "0.1", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "                ", "if", "args", ".", "dataset_name", ".", "startswith", "(", "\"HIT_\"", ")", ":", "\n", "                    ", "support_batch", ",", "query_batch", "=", "batch", "[", "0", "]", "[", "0", "]", ",", "batch", "[", "0", "]", "[", "1", "]", "\n", "slot_tags_vocab", ",", "intents_vocab", "=", "batch", "[", "0", "]", "[", "2", "]", ",", "batch", "[", "0", "]", "[", "3", "]", "\n", "slot_desc_in_words", "=", "batch", "[", "0", "]", "[", "4", "]", "\n", "slot_head_labels_token_ids", ",", "slot_other_labels_seg_ids", ",", "slot_other_labels_selected_slot_ids", "=", "slot_tags_vocab", ".", "get_elements_used_in_label_embeddings", "(", "device", "=", "args", ".", "device", ")", "\n", "support_batch_inputs", "=", "convert_examples_to_features", "(", "support_batch", ",", "word_tokenizer", "=", "word_tokenizer", ",", "char_tokenizer", "=", "char_tokenizer", ",", "tf_tokenizer", "=", "tf_tokenizer", ",", "tf_input_args", "=", "tf_input_args", ",", "slot_tags_vocab", "=", "slot_tags_vocab", ",", "intents_vocab", "=", "intents_vocab", ",", "bos_eos", "=", "args", ".", "input_bos_eos", ",", "intent_multi_class", "=", "args", ".", "intent_multi_class", ",", "slot_tag_enc_dec", "=", "args", ".", "enc_dec", ",", "device", "=", "args", ".", "device", ")", "\n", "slot_label_indicator", ",", "intent_label_indicator", "=", "read_label_indicator_of_support_set", "(", "slot_tags_vocab", ",", "intents_vocab", ",", "support_batch_inputs", "[", "\"tags\"", "]", ",", "support_batch_inputs", "[", "\"intents\"", "]", ",", "indicator_type", "=", "'PN'", ",", "slot_embedding_type", "=", "args", ".", "slot_embedding_type", ",", "device", "=", "args", ".", "device", ")", "\n", "label_desc_inputs", "=", "prepare_inputs_of_word_sequences_for_bert_xlnet", "(", "slot_desc_in_words", ",", "tf_tokenizer", ",", "bos_eos", "=", "args", ".", "input_bos_eos", ",", "device", "=", "args", ".", "device", ",", "**", "tf_input_args", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "slot_tag_embeds", ",", "intent_embeds", "=", "model", ".", "get_label_embeddings_from_support_set", "(", "support_batch_inputs", "[", "\"inputs\"", "]", ",", "support_batch_inputs", "[", "\"lengths\"", "]", ",", "support_batch_inputs", "[", "\"input_mask\"", "]", ",", "slot_label_indicator", ",", "intent_label_indicator", ",", "slot_head_labels_token_ids", ",", "slot_other_labels_seg_ids", "=", "slot_other_labels_seg_ids", ",", "slot_other_labels_selected_slot_ids", "=", "slot_other_labels_selected_slot_ids", ",", "label_desc_inputs", "=", "label_desc_inputs", ")", "\n", "inputs", "=", "convert_examples_to_features", "(", "query_batch", ",", "word_tokenizer", "=", "word_tokenizer", ",", "char_tokenizer", "=", "char_tokenizer", ",", "tf_tokenizer", "=", "tf_tokenizer", ",", "tf_input_args", "=", "tf_input_args", ",", "slot_tags_vocab", "=", "slot_tags_vocab", ",", "intents_vocab", "=", "intents_vocab", ",", "bos_eos", "=", "args", ".", "input_bos_eos", ",", "intent_multi_class", "=", "args", ".", "intent_multi_class", ",", "slot_tag_enc_dec", "=", "args", ".", "enc_dec", ",", "device", "=", "args", ".", "device", ")", "\n", "outputs", "=", "model", "(", "slot_tag_embeds", ",", "intent_embeds", ",", "inputs", "[", "\"inputs\"", "]", ",", "inputs", "[", "\"lengths\"", "]", ",", "inputs", "[", "\"input_mask\"", "]", ",", "slot_tags", "=", "inputs", "[", "\"tag_ids\"", "]", ",", "intents", "=", "inputs", "[", "\"intent_ids\"", "]", ",", "slot_tag_masked_output", "=", "None", ",", "intent_masked_output", "=", "None", ",", "slot_tag_to_id", "=", "slot_tags_vocab", ".", "label_to_id", ")", "\n", "tag_loss", ",", "intent_loss", "=", "outputs", "[", ":", "2", "]", "\n", "losses", ".", "append", "(", "[", "tag_loss", ".", "item", "(", ")", "/", "sum", "(", "inputs", "[", "\"lengths\"", "]", ")", ",", "intent_loss", ".", "item", "(", ")", "/", "len", "(", "inputs", "[", "\"lengths\"", "]", ")", "]", ")", "\n", "total_loss", "=", "args", ".", "tr_st_weight", "*", "tag_loss", "+", "(", "1", "-", "args", ".", "tr_st_weight", ")", "*", "intent_loss", "\n", "\n", "total_loss", ".", "backward", "(", ")", "\n", "# Clips gradient norm of an iterable of parameters.", "\n", "if", "args", ".", "tr_optim", ".", "lower", "(", ")", "!=", "'bertadam'", "and", "args", ".", "tr_max_norm", ">", "0", ":", "\n", "                        ", "for", "group", "in", "optimizer_grouped_parameters", ":", "\n", "                            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "group", "[", "'params'", "]", ",", "args", ".", "tr_max_norm", ")", "\n", "", "", "if", "args", ".", "tr_optim", ".", "lower", "(", ")", "==", "'adamw'", ":", "\n", "                        ", "scheduler", ".", "step", "(", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "if", "step", "%", "piece_steps", "==", "0", ":", "\n", "                    ", "print", "(", "'[learning] epoch %i >> %2.2f%%'", "%", "(", "i", ",", "(", "step", "+", "1", ")", "*", "100.", "/", "batch_number", ")", ",", "'completed in %.2f (sec) <<\\r'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", ",", "end", "=", "''", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "", "print", "(", "''", ")", "\n", "mean_loss", "=", "np", ".", "mean", "(", "losses", ",", "axis", "=", "0", ")", "\n", "logger", ".", "info", "(", "'Training:\\tEpoch : %d\\tTime : %.4fs\\tLoss of tag : %.4f\\tLoss of class : %.4f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "mean_loss", "[", "0", "]", ",", "mean_loss", "[", "1", "]", ")", ")", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "if", "hasattr", "(", "model", ",", "'crf_transition_layer'", ")", ":", "\n", "                ", "logger", ".", "info", "(", "model", ".", "crf", ".", "scaling_feats", ")", "\n", "logger", ".", "info", "(", "model", ".", "crf_transition_layer", ".", "crf_transitions_model", ")", "\n", "# Validation & Evaluation", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "loss_val", ",", "slot_metrics_val", ",", "intent_metrics_val", "=", "decode", "(", "args", ",", "model", ",", "valid_dataset", ",", "os", ".", "path", ".", "join", "(", "exp_path", ",", "'valid.iter'", "+", "str", "(", "i", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Validation:\\tEpoch : %d\\tTime : %.4fs\\tLoss : (%.2f, %.2f)\\tFscore : %.2f\\tcls-F1 : %.2f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "loss_val", "[", "0", "]", ",", "loss_val", "[", "1", "]", ",", "slot_metrics_val", "[", "'f'", "]", ",", "intent_metrics_val", "[", "'f'", "]", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "loss_te", ",", "slot_metrics_te", ",", "intent_metrics_te", "=", "decode", "(", "args", ",", "model", ",", "test_dataset", ",", "os", ".", "path", ".", "join", "(", "exp_path", ",", "'test.iter'", "+", "str", "(", "i", ")", ")", ")", "\n", "logger", ".", "info", "(", "'Evaluation:\\tEpoch : %d\\tTime : %.4fs\\tLoss : (%.2f, %.2f)\\tFscore : %.2f\\tcls-F1 : %.2f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "loss_te", "[", "0", "]", ",", "loss_te", "[", "1", "]", ",", "slot_metrics_te", "[", "'f'", "]", ",", "intent_metrics_te", "[", "'f'", "]", ")", ")", "\n", "\n", "if", "args", ".", "task_sc", ":", "\n", "                ", "val_f1_score", "=", "(", "args", ".", "tr_st_weight", "*", "slot_metrics_val", "[", "'f'", "]", "+", "(", "1", "-", "args", ".", "tr_st_weight", ")", "*", "intent_metrics_val", "[", "'f'", "]", ")", "\n", "", "else", ":", "\n", "                ", "val_f1_score", "=", "slot_metrics_val", "[", "'f'", "]", "\n", "", "if", "best_f1", "<", "val_f1_score", ":", "\n", "                ", "model", ".", "save_model", "(", "os", ".", "path", ".", "join", "(", "exp_path", ",", "args", ".", "model_save_path", ")", ")", "\n", "best_f1", "=", "val_f1_score", "\n", "logger", ".", "info", "(", "'NEW BEST:\\tEpoch : %d\\tbest valid F1 : %.2f, cls-F1 : %.2f;\\ttest F1 : %.2f, cls-F1 : %.2f'", "%", "(", "i", ",", "slot_metrics_val", "[", "'f'", "]", ",", "intent_metrics_val", "[", "'f'", "]", ",", "slot_metrics_te", "[", "'f'", "]", ",", "intent_metrics_te", "[", "'f'", "]", ")", ")", "\n", "best_result", "[", "'epoch'", "]", "=", "i", "\n", "best_result", "[", "'vf1'", "]", ",", "best_result", "[", "'vcf1'", "]", ",", "best_result", "[", "'vce'", "]", "=", "slot_metrics_val", "[", "'f'", "]", ",", "intent_metrics_val", "[", "'f'", "]", ",", "loss_val", "\n", "best_result", "[", "'tf1'", "]", ",", "best_result", "[", "'tcf1'", "]", ",", "best_result", "[", "'tce'", "]", "=", "slot_metrics_te", "[", "'f'", "]", ",", "intent_metrics_te", "[", "'f'", "]", ",", "loss_te", "\n", "", "", "logger", ".", "info", "(", "'BEST RESULT: \\tEpoch : %d\\tbest valid (Loss: (%.2f, %.2f) F1 : %.2f cls-F1 : %.2f)\\tbest test (Loss: (%.2f, %.2f) F1 : %.2f cls-F1 : %.2f)'", "%", "(", "best_result", "[", "'epoch'", "]", ",", "best_result", "[", "'vce'", "]", "[", "0", "]", ",", "best_result", "[", "'vce'", "]", "[", "1", "]", ",", "best_result", "[", "'vf1'", "]", ",", "best_result", "[", "'vcf1'", "]", ",", "best_result", "[", "'tce'", "]", "[", "0", "]", ",", "best_result", "[", "'tce'", "]", "[", "1", "]", ",", "best_result", "[", "'tf1'", "]", ",", "best_result", "[", "'tcf1'", "]", ")", ")", "\n", "# finetune  # Validation & Evaluation", "\n", "del", "optimizer", "\n", "try", ":", "\n", "            ", "if", "args", ".", "test_finetune", ":", "\n", "                ", "model_saved_path", "=", "os", ".", "path", ".", "join", "(", "exp_path", ",", "args", ".", "model_save_path", ")", "\n", "#optim_name, lr, finetune_steps ='bertadam', 4e-5, (5, 10) ## it performs worse than the adam for finetuning", "\n", "optim_name", ",", "lr", ",", "lr_np", ",", "finetune_steps", "=", "'adam'", ",", "1e-5", ",", "1e-3", ",", "(", "1", ",", "3", ",", "5", ")", "## (5, 10)", "\n", "if", "args", ".", "matching_similarity_y", "==", "'desc'", ":", "\n", "                    ", "finetune_steps", "=", "(", "5", ",", "10", ")", "\n", "", "for", "test_finetune_step", "in", "finetune_steps", ":", "\n", "                    ", "logger", ".", "info", "(", "'----------optim_name=%s, step=%d, lr=%f, lr_np=%f'", "%", "(", "optim_name", ",", "test_finetune_step", ",", "lr", ",", "lr_np", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "loss_val", ",", "slot_metrics_val", ",", "intent_metrics_val", "=", "decode", "(", "args", ",", "model", ",", "valid_dataset", ",", "os", ".", "path", ".", "join", "(", "exp_path", ",", "'valid.final.iter'", "+", "str", "(", "test_finetune_step", ")", ")", ",", "test_finetune_step", "=", "test_finetune_step", ",", "model_ori_saved_path", "=", "model_saved_path", ",", "lr", "=", "lr", ",", "optim_name", "=", "optim_name", ",", "lr_np", "=", "lr_np", ")", "\n", "logger", ".", "info", "(", "'Validation:\\tEpoch : %d\\tTime : %.4fs\\tLoss : (%.2f, %.2f)\\tFscore : %.2f\\tcls-F1 : %.2f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "loss_val", "[", "0", "]", ",", "loss_val", "[", "1", "]", ",", "slot_metrics_val", "[", "'f'", "]", ",", "intent_metrics_val", "[", "'f'", "]", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "loss_te", ",", "slot_metrics_te", ",", "intent_metrics_te", "=", "decode", "(", "args", ",", "model", ",", "test_dataset", ",", "os", ".", "path", ".", "join", "(", "exp_path", ",", "'test.final.iter'", "+", "str", "(", "test_finetune_step", ")", ")", ",", "test_finetune_step", "=", "test_finetune_step", ",", "model_ori_saved_path", "=", "model_saved_path", ",", "lr", "=", "lr", ",", "optim_name", "=", "optim_name", ",", "lr_np", "=", "lr_np", ")", "\n", "logger", ".", "info", "(", "'Evaluation:\\tEpoch : %d\\tTime : %.4fs\\tLoss : (%.2f, %.2f)\\tFscore : %.2f\\tcls-F1 : %.2f'", "%", "(", "i", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "loss_te", "[", "0", "]", ",", "loss_te", "[", "1", "]", ",", "slot_metrics_te", "[", "'f'", "]", ",", "intent_metrics_te", "[", "'f'", "]", ")", ")", "\n", "", "", "", "except", "Exception", "as", "error", ":", "\n", "            ", "logger", ".", "info", "(", "str", "(", "error", ")", ")", "\n", "", "finally", ":", "\n", "            ", "if", "args", ".", "model_removed", "==", "'yes'", ":", "\n", "                ", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "exp_path", ",", "args", ".", "model_save_path", ")", ")", "\n", "print", "(", "\"Model is removed!\"", ")", "\n", "", "", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Testing starts at %s\"", "%", "(", "time", ".", "asctime", "(", "time", ".", "localtime", "(", "time", ".", "time", "(", ")", ")", ")", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "loss_val", ",", "slot_metrics_val", ",", "intent_metrics_val", "=", "decode", "(", "args", ",", "model", ",", "valid_dataset", ",", "os", ".", "path", ".", "join", "(", "exp_path", ",", "'valid.eval'", ")", ")", "\n", "logger", ".", "info", "(", "'Validation:\\tTime : %.4fs\\tLoss : (%.2f, %.2f)\\tFscore : %.2f\\tcls-F1 : %.2f'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ",", "loss_val", "[", "0", "]", ",", "loss_val", "[", "1", "]", ",", "slot_metrics_val", "[", "'f'", "]", ",", "intent_metrics_val", "[", "'f'", "]", ")", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "loss_te", ",", "slot_metrics_te", ",", "intent_metrics_te", "=", "decode", "(", "args", ",", "model", ",", "test_dataset", ",", "os", ".", "path", ".", "join", "(", "exp_path", ",", "'test.eval'", ")", ")", "\n", "logger", ".", "info", "(", "'Evaluation:\\tTime : %.4fs\\tLoss : (%.2f, %.2f)\\tFscore : %.2f\\tcls-F1 : %.2f'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ",", "loss_te", "[", "0", "]", ",", "loss_te", "[", "1", "]", ",", "slot_metrics_te", "[", "'f'", "]", ",", "intent_metrics_te", "[", "'f'", "]", ")", ")", "\n", "if", "hasattr", "(", "model", ",", "'crf_transition_layer'", ")", ":", "\n", "            ", "logger", ".", "info", "(", "model", ".", "crf_transition_layer", ".", "crf_transitions_model", ")", "\n", "# finetune  # Validation & Evaluation", "\n", "", "if", "args", ".", "test_finetune", ":", "\n", "            ", "start_time", "=", "time", ".", "time", "(", ")", "\n", "#optim_name, lr, finetune_steps ='bertadam', 4e-5, (5, 10) ## it performs worse than the adam for finetuning", "\n", "optim_name", ",", "lr", ",", "lr_np", ",", "finetune_steps", "=", "'adam'", ",", "1e-5", ",", "1e-3", ",", "(", "1", ",", "3", ",", "5", ",", "10", ")", "\n", "for", "test_finetune_step", "in", "finetune_steps", ":", "\n", "                ", "logger", ".", "info", "(", "'----------optim_name=%s, step=%d, lr=%f, lr_np=%f'", "%", "(", "optim_name", ",", "test_finetune_step", ",", "lr", ",", "lr_np", ")", ")", "\n", "#start_time = time.time()", "\n", "#loss_val, slot_metrics_val, intent_metrics_val = decode(args, model, valid_dataset, os.path.join(exp_path, 'valid.eval.iter'+str(test_finetune_step)), test_finetune_step=test_finetune_step, model_ori_saved_path=args.testing_model_read_path, lr=lr, optim_name=optim_name, lr_np=lr_np)", "\n", "#logger.info('Validation:\\tTime : %.4fs\\tLoss : (%.2f, %.2f)\\tFscore : %.2f\\tcls-F1 : %.2f' % (time.time() - start_time, loss_val[0], loss_val[1], slot_metrics_val['f'], intent_metrics_val['f']))", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "loss_te", ",", "slot_metrics_te", ",", "intent_metrics_te", "=", "decode", "(", "args", ",", "model", ",", "test_dataset", ",", "os", ".", "path", ".", "join", "(", "exp_path", ",", "'test.eval.iter'", "+", "str", "(", "test_finetune_step", ")", ")", ",", "test_finetune_step", "=", "test_finetune_step", ",", "model_ori_saved_path", "=", "args", ".", "testing_model_read_path", ",", "lr", "=", "lr", ",", "optim_name", "=", "optim_name", ",", "lr_np", "=", "lr_np", ")", "\n", "logger", ".", "info", "(", "'Evaluation:\\tTime : %.4fs\\tLoss : (%.2f, %.2f)\\tFscore : %.2f\\tcls-F1 : %.2f'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time", ",", "loss_te", "[", "0", "]", ",", "loss_te", "[", "1", "]", ",", "slot_metrics_te", "[", "'f'", "]", ",", "intent_metrics_te", "[", "'f'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.__init__": [[45, 57], ["models.utils.basic_model.BasicModel.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "pretrained_tf_model", ",", "device", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "tf_model", "=", "pretrained_tf_model", "\n", "\n", "#self.embeddings = self.tf_model.embeddings # NOTE: reference of nn.module is not appropriate for reproducing", "\n", "#self.encoder = self.tf_model.encoder", "\n", "#self.pooler = self.tf_model.pooler", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n", "self", ".", "dropout_layer", "=", "nn", ".", "Dropout", "(", "config", ".", "arch_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.get_output_dim": [[58, 60], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tf_model", ".", "config", ".", "hidden_size", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.get_bert_output_in_encoder_part": [[62, 96], ["extended_attention_mask.to.to.to", "slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.tf_model.encoder", "hasattr", "embedding_output.size", "attention_mask.dim", "attention_mask.dim", "ValueError", "next", "slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.parameters"], "methods", ["None"], ["", "def", "get_bert_output_in_encoder_part", "(", "self", ",", "embedding_output", ",", "attention_mask", ")", ":", "\n", "        ", "input_shape", "=", "embedding_output", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "if", "attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\"", ".", "format", "(", "\n", "input_shape", ",", "attention_mask", ".", "shape", "\n", ")", "\n", ")", "\n", "", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "1e16", "#-10000.0", "\n", "\n", "head_mask", "=", "[", "None", "]", "*", "self", ".", "tf_model", ".", "config", ".", "num_hidden_layers", "\n", "\n", "encoder_outputs", "=", "self", ".", "tf_model", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "if", "hasattr", "(", "self", ".", "tf_model", ",", "'pooler'", ")", ":", "# bert", "\n", "            ", "pooled_output", "=", "sequence_output", "[", ":", ",", "0", "]", "#self.tf_model.pooler(sequence_output)", "\n", "", "else", ":", "# electra", "\n", "            ", "pooled_output", "=", "sequence_output", "[", ":", ",", "0", "]", "\n", "\n", "", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "\n", "1", ":", "\n", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.forward_ori_bert": [[97, 101], ["slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.tf_model"], "methods", ["None"], ["", "def", "forward_ori_bert", "(", "self", ",", "input_ids", ",", "token_type_ids", ",", "attention_mask", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "tf_model", "(", "input_ids", "=", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "return", "sequence_output", ",", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.forward": [[102, 140], ["slot_intent_with_prototypical_network_and_pure_bert.transformer_forward_by_ignoring_suffix", "slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.tf_model.embeddings", "slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.get_bert_output_in_encoder_part", "slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.tf_model.embeddings", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.tf_model.embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.get_bert_output_in_encoder_part", "slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.dropout_layer", "slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.dropout_layer", "input_ids.size", "slot_embeddings.size"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.transformer_forward_by_ignoring_suffix", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.get_bert_output_in_encoder_part", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.get_bert_output_in_encoder_part"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "slot_embeddings", "=", "None", ",", "lattice", "=", "None", ")", ":", "\n", "#slot_embeddings: O * H", "\n", "        ", "input_ids", "=", "inputs", "[", "\"input_tf\"", "]", "[", "\"input_ids\"", "]", "\n", "position_ids", "=", "None", "# default", "\n", "token_type_ids", "=", "inputs", "[", "\"input_tf\"", "]", "[", "\"segment_ids\"", "]", "\n", "attention_mask", "=", "inputs", "[", "\"input_tf\"", "]", "[", "\"attention_mask\"", "]", "\n", "batch_size", "=", "inputs", "[", "\"input_tf\"", "]", "[", "\"batch_size\"", "]", "\n", "max_word_length", "=", "inputs", "[", "\"input_tf\"", "]", "[", "\"max_word_length\"", "]", "\n", "selects", "=", "inputs", "[", "\"input_tf\"", "]", "[", "\"selects\"", "]", "\n", "copies", "=", "inputs", "[", "\"input_tf\"", "]", "[", "\"copies\"", "]", "\n", "if", "slot_embeddings", "is", "None", ":", "\n", "            ", "token_embeds", "=", "self", ".", "tf_model", ".", "embeddings", "(", "input_ids", "=", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "\n", "bert_outputs", "=", "self", ".", "get_bert_output_in_encoder_part", "(", "token_embeds", ",", "attention_mask", ")", "\n", "bert_top_hiddens", ",", "bert_pooled_output", "=", "bert_outputs", "[", "0", ":", "2", "]", "\n", "", "else", ":", "\n", "            ", "max_token_length", "=", "input_ids", ".", "size", "(", ")", "[", "1", "]", "\n", "slot_number", "=", "slot_embeddings", ".", "size", "(", ")", "[", "0", "]", "\n", "token_embeds", "=", "self", ".", "tf_model", ".", "embeddings", "(", "input_ids", "=", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "\n", "extended_slot_embeddings", "=", "slot_embeddings", "[", "None", ",", ":", ",", ":", "]", "#.repeat(batch_size, 1, 1)", "\n", "slot_nodes_position_ids", "=", "torch", ".", "zeros", "(", "batch_size", ",", "slot_number", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "# pos all 0", "\n", "slot_nodes_type_ids", "=", "torch", ".", "ones", "(", "batch_size", ",", "slot_number", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "# seg id = 1", "\n", "extended_slot_embeds", "=", "self", ".", "tf_model", ".", "embeddings", "(", "input_ids", "=", "None", ",", "position_ids", "=", "slot_nodes_position_ids", ",", "token_type_ids", "=", "slot_nodes_type_ids", ",", "inputs_embeds", "=", "extended_slot_embeddings", ")", "\n", "combined_input_embeds", "=", "torch", ".", "cat", "(", "(", "token_embeds", ",", "extended_slot_embeds", ")", ",", "dim", "=", "1", ")", "\n", "\n", "slot_attention_mask", "=", "torch", ".", "ones", "(", "batch_size", ",", "slot_number", ",", "dtype", "=", "attention_mask", ".", "dtype", ",", "device", "=", "self", ".", "device", ")", "\n", "combined_attention_mask", "=", "torch", ".", "cat", "(", "(", "attention_mask", ",", "slot_attention_mask", ")", ",", "dim", "=", "1", ")", "\n", "\n", "combined_bert_outputs", "=", "self", ".", "get_bert_output_in_encoder_part", "(", "combined_input_embeds", ",", "combined_attention_mask", ")", "\n", "combined_bert_top_hiddens", ",", "bert_pooled_output", "=", "combined_bert_outputs", "[", "0", ":", "2", "]", "\n", "bert_top_hiddens", "=", "combined_bert_top_hiddens", "[", ":", ",", ":", "max_token_length", ",", ":", "]", "#.contiguous()", "\n", "query_aware_slot_embeddings", "=", "combined_bert_top_hiddens", "[", ":", ",", "max_token_length", ":", ",", ":", "]", "\n", "", "word_embeds", "=", "transformer_forward_by_ignoring_suffix", "(", "bert_top_hiddens", ",", "batch_size", ",", "max_word_length", ",", "selects", ",", "copies", ",", "device", "=", "self", ".", "device", ")", "\n", "word_embeds", ",", "bert_pooled_output", "=", "self", ".", "dropout_layer", "(", "word_embeds", ")", ",", "self", ".", "dropout_layer", "(", "bert_pooled_output", ")", "\n", "\n", "if", "slot_embeddings", "is", "None", ":", "\n", "            ", "return", "word_embeds", ",", "bert_pooled_output", "\n", "", "else", ":", "\n", "            ", "return", "word_embeds", ",", "bert_pooled_output", ",", "query_aware_slot_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.__init__": [[143, 203], ["models.utils.basic_model.BasicModel.__init__", "slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.query_sentence_encoder.get_output_dim", "torch.Embedding", "torch.Embedding", "torch.Embedding", "models.predictor.Projection", "models.predictor.MatchingClassifier", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.slot_tagger_projection_y.get_output_dim", "models.predictor.MatchingClassifier", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.init_weights", "slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "models.utils.crf.TransitionLayer", "models.utils.crf.CRFLoss", "models.utils.crf.AbstractTransitionLayer", "models.utils.crf.CRFLoss", "exit"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.Projection.get_output_dim", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.Projection.get_output_dim", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.basic_model.BasicModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "special_slot_label_number", ",", "slot_embedding_type", "=", "'with_BIO'", ",", "matching_similarity_type", "=", "'xy1'", ",", "sentence_encoder_shared", "=", "True", ",", "slot_embedding_dependent_query_encoding", "=", "'none'", ",", "matching_similarity_y", "=", "'ctx'", ",", "matching_similarity_function", "=", "'dot'", ",", "task_adaptive_projection", "=", "'none'", ",", "pretrained_tf_model", "=", "None", ",", "device", "=", "None", ")", ":", "\n", "        ", "'''\n        slot_embedding_type: with_BIO, with_BI, without_BIO\n        matching_similarity_type: xy, x1y, xy1, x1y1, rxy\n        slot_embedding_dependent_query_encoding: none, ctx, desc\n        matching_similarity_y: ctx, desc, ctx_desc\n        task_adaptive_projection: none, LSM, adaptive_finetune, LEN\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "special_slot_label_number", "=", "special_slot_label_number", "\n", "self", ".", "slot_embedding_type", "=", "slot_embedding_type", "\n", "self", ".", "matching_similarity_type", "=", "matching_similarity_type", "\n", "self", ".", "matching_similarity_y", "=", "matching_similarity_y", "\n", "\n", "#sentence_encoder_shared = True #default 'True'; False", "\n", "bilinear", "=", "False", "#default 'False'; True, False", "\n", "crf_trainable_balance_weight", "=", "False", "# default 'False'; False", "\n", "if", "self", ".", "matching_similarity_type", "==", "'rxy'", ":", "\n", "            ", "crf_trainable_balance_weight", "=", "True", "\n", "\n", "#slot_embedding_dependent_query_encoding = True # True, False", "\n", "", "self", ".", "slot_embedding_dependent_query_encoding", "=", "slot_embedding_dependent_query_encoding", "\n", "\n", "# token embedding layer (shared between query and support sets)", "\n", "self", ".", "query_sentence_encoder", "=", "SequenceEncoder_with_pure_bert", "(", "config", ",", "pretrained_tf_model", ",", "device", "=", "self", ".", "device", ")", "\n", "if", "sentence_encoder_shared", ":", "\n", "            ", "self", ".", "support_sentence_encoder", "=", "self", ".", "query_sentence_encoder", "\n", "", "else", ":", "\n", "            ", "self", ".", "support_sentence_encoder", "=", "SequenceEncoder_with_pure_bert", "(", "config", ",", "pretrained_tf_model", ",", "device", "=", "self", ".", "device", ")", "\n", "", "encoder_output_dim", "=", "self", ".", "query_sentence_encoder", ".", "get_output_dim", "(", ")", "\n", "self", ".", "special_slot_label_embeddings", "=", "nn", ".", "Embedding", "(", "special_slot_label_number", ",", "encoder_output_dim", ")", "\n", "\n", "self", ".", "slot_tagger_projection_x", "=", "Projection", "(", "config", ",", "encoder_output_dim", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "slot_tagger_projection_y", "=", "self", ".", "slot_tagger_projection_x", "\n", "self", ".", "slot_tagger", "=", "MatchingClassifier", "(", "config", ",", "matching_similarity_function", "=", "matching_similarity_function", ")", "\n", "projected_tag_embedding_dim", "=", "self", ".", "slot_tagger_projection_y", ".", "get_output_dim", "(", ")", "\n", "if", "config", ".", "task_st", "==", "\"slot_tagger\"", ":", "\n", "            ", "self", ".", "slot_tag_loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "config", ".", "output_tag_pad_id", ",", "size_average", "=", "False", ")", "\n", "", "elif", "config", ".", "task_st", "==", "\"slot_tagger_with_adaptive_crf\"", ":", "\n", "            ", "self", ".", "crf_transition_layer", "=", "TransitionLayer", "(", "projected_tag_embedding_dim", ")", "\n", "self", ".", "crf", "=", "CRFLoss", "(", "trainable_balance_weight", "=", "crf_trainable_balance_weight", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "slot_tag_loss_fct", "=", "self", ".", "crf", ".", "neg_log_likelihood_loss", "\n", "", "elif", "config", ".", "task_st", "==", "\"slot_tagger_with_abstract_crf\"", ":", "\n", "            ", "self", ".", "crf_transition_layer", "=", "AbstractTransitionLayer", "(", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "crf", "=", "CRFLoss", "(", "trainable_balance_weight", "=", "crf_trainable_balance_weight", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "slot_tag_loss_fct", "=", "self", ".", "crf", ".", "neg_log_likelihood_loss", "\n", "", "else", ":", "\n", "            ", "exit", "(", ")", "\n", "\n", "", "self", ".", "intent_multi_class", "=", "(", "config", ".", "task_sc_type", "==", "\"multi_cls_BCE\"", ")", "\n", "self", ".", "intent_classifier", "=", "MatchingClassifier", "(", "config", ",", "matching_similarity_function", "=", "matching_similarity_function", ")", "\n", "if", "self", ".", "intent_multi_class", ":", "\n", "            ", "self", ".", "intent_loss_fct", "=", "BCELoss", "(", "size_average", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "intent_loss_fct", "=", "CrossEntropyLoss", "(", "size_average", "=", "False", ")", "\n", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet._init_weights": [[204, 225], ["isinstance", "hasattr", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_", "isinstance", "isinstance", "isinstance", "module.named_parameters", "param.data.normal_", "param.data.zero_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights \"\"\"", "\n", "if", "hasattr", "(", "module", ",", "'sz128__no_init_flag'", ")", "and", "module", ".", "sz128__no_init_flag", ":", "\n", "#print(\"Module skips the initialization:\", type(module), module.__class__.__name__)", "\n", "            ", "return", "1", "\n", "", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "(", "nn", ".", "LayerNorm", ",", "nn", ".", "BatchNorm1d", ")", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "GRU", ")", "or", "isinstance", "(", "module", ",", "nn", ".", "LSTM", ")", "or", "isinstance", "(", "module", ",", "nn", ".", "RNN", ")", ":", "\n", "            ", "for", "name", ",", "param", "in", "module", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "'weight_ih'", "in", "name", "or", "'weight_hh'", "in", "name", ":", "\n", "#param.data.uniform_(-0.2, 0.2)", "\n", "                    ", "param", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "", "elif", "'bias'", "in", "name", ":", "\n", "                    ", "param", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.get_contextual_label_embeddings_from_support_set": [[226, 247], ["slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.support_sentence_encoder", "tf_out.size", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.special_slot_label_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.special_slot_label_embeddings", "tf_out.reshape", "tf_out.reshape"], "methods", ["None"], ["", "", "def", "get_contextual_label_embeddings_from_support_set", "(", "self", ",", "inputs", ",", "lengths", ",", "\n", "sentence_mask", ",", "slot_label_indicator", ",", "intent_label_indicator", ",", "\n", "slot_head_labels_token_ids", ",", "slot_other_labels_seg_ids", "=", "None", ",", "\n", "slot_other_labels_selected_slot_ids", "=", "None", ",", "addtional_features", "=", "None", ",", "\n", "lattice", "=", "None", ")", ":", "\n", "        ", "tf_out", ",", "snt_vector", "=", "self", ".", "support_sentence_encoder", "(", "inputs", ",", "lattice", "=", "lattice", ")", "\n", "batch_size", ",", "max_length", ",", "hidden_size", "=", "tf_out", ".", "size", "(", ")", "\n", "\n", "if", "self", ".", "slot_embedding_type", "==", "'with_BIO'", "or", "self", ".", "slot_embedding_type", "==", "'with_BI'", ":", "\n", "            ", "other_slot_tag_embeds", "=", "torch", ".", "matmul", "(", "slot_label_indicator", ",", "tf_out", ".", "reshape", "(", "(", "batch_size", "*", "max_length", ",", "hidden_size", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "other_slot_embeds", "=", "torch", ".", "matmul", "(", "slot_label_indicator", ",", "tf_out", ".", "reshape", "(", "(", "batch_size", "*", "max_length", ",", "hidden_size", ")", ")", ")", "\n", "other_slot_tag_name_embeds", "=", "torch", ".", "index_select", "(", "other_slot_embeds", ",", "0", ",", "slot_other_labels_selected_slot_ids", ")", "\n", "other_slot_tag_seg_embeds", "=", "self", ".", "special_slot_label_embeddings", "(", "slot_other_labels_seg_ids", ")", "\n", "other_slot_tag_embeds", "=", "other_slot_tag_seg_embeds", "+", "other_slot_tag_name_embeds", "\n", "", "head_slot_tag_embeds", "=", "self", ".", "special_slot_label_embeddings", "(", "slot_head_labels_token_ids", ")", "\n", "slot_tag_embeds", "=", "torch", ".", "cat", "(", "(", "head_slot_tag_embeds", ",", "other_slot_tag_embeds", ")", ",", "dim", "=", "0", ")", "\n", "\n", "intent_embeds", "=", "torch", ".", "matmul", "(", "intent_label_indicator", ",", "snt_vector", ")", "\n", "\n", "return", "(", "other_slot_tag_embeds", ",", "slot_tag_embeds", ")", ",", "intent_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.get_description_based_label_embeddings_from_support_set": [[248, 255], ["slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.support_sentence_encoder.forward_ori_bert", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.special_slot_label_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.SequenceEncoder_with_pure_bert.forward_ori_bert"], ["", "def", "get_description_based_label_embeddings_from_support_set", "(", "self", ",", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "slot_head_labels_token_ids", ")", ":", "\n", "        ", "tf_out", ",", "snt_vector", "=", "self", ".", "support_sentence_encoder", ".", "forward_ori_bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ")", "\n", "other_slot_tag_embeds", "=", "snt_vector", "\n", "head_slot_tag_embeds", "=", "self", ".", "special_slot_label_embeddings", "(", "slot_head_labels_token_ids", ")", "\n", "slot_tag_embeds", "=", "torch", ".", "cat", "(", "(", "head_slot_tag_embeds", ",", "other_slot_tag_embeds", ")", ",", "dim", "=", "0", ")", "\n", "\n", "return", "(", "other_slot_tag_embeds", ",", "slot_tag_embeds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.get_label_embeddings_from_support_set": [[256, 306], ["slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.get_description_based_label_embeddings_from_support_set", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.get_contextual_label_embeddings_from_support_set", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.slot_tagger_projection_y", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.slot_tagger_projection_y", "slot_intent_with_prototypical_network_and_pure_bert.get_unit_vectors", "slot_intent_with_prototypical_network_and_pure_bert.get_unit_vectors", "slot_intent_with_prototypical_network_and_pure_bert.get_unit_vectors"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.get_description_based_label_embeddings_from_support_set", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.get_contextual_label_embeddings_from_support_set", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors"], ["", "def", "get_label_embeddings_from_support_set", "(", "self", ",", "inputs", ",", "lengths", ",", "\n", "sentence_mask", ",", "slot_label_indicator", ",", "intent_label_indicator", ",", "\n", "slot_head_labels_token_ids", ",", "slot_other_labels_seg_ids", "=", "None", ",", "\n", "slot_other_labels_selected_slot_ids", "=", "None", ",", "addtional_features", "=", "None", ",", "\n", "label_desc_inputs", "=", "None", ",", "lattice", "=", "None", ")", ":", "\n", "        ", "if", "label_desc_inputs", "is", "None", ":", "\n", "            ", "assert", "self", ".", "matching_similarity_y", "==", "'ctx'", "\n", "desc_other_slot_tag_embeds", ",", "desc_slot_tag_embeds", "=", "None", ",", "None", "\n", "", "else", ":", "\n", "            ", "desc_other_slot_tag_embeds", ",", "desc_slot_tag_embeds", "=", "self", ".", "get_description_based_label_embeddings_from_support_set", "(", "**", "label_desc_inputs", ",", "slot_head_labels_token_ids", "=", "slot_head_labels_token_ids", ")", "\n", "H", "=", "desc_slot_tag_embeds", ".", "shape", "[", "-", "1", "]", "\n", "", "if", "self", ".", "matching_similarity_y", "!=", "'desc'", ":", "\n", "            ", "(", "ctx_other_slot_tag_embeds", ",", "ctx_slot_tag_embeds", ")", ",", "intent_embeds", "=", "self", ".", "get_contextual_label_embeddings_from_support_set", "(", "inputs", ",", "\n", "lengths", ",", "sentence_mask", ",", "slot_label_indicator", ",", "\n", "intent_label_indicator", ",", "slot_head_labels_token_ids", ",", "\n", "slot_other_labels_seg_ids", "=", "slot_other_labels_seg_ids", ",", "\n", "slot_other_labels_selected_slot_ids", "=", "slot_other_labels_selected_slot_ids", ",", "\n", "addtional_features", "=", "addtional_features", ",", "lattice", "=", "lattice", ")", "\n", "", "else", ":", "\n", "            ", "intent_embeds", "=", "torch", ".", "ones", "(", "intent_label_indicator", ".", "shape", "[", "0", "]", ",", "H", ",", "device", "=", "self", ".", "device", ")", "# not ready for intent", "\n", "\n", "## maybe you should build slot_tagger_projection first", "\n", "## ...", "\n", "", "if", "self", ".", "matching_similarity_y", "!=", "'desc'", ":", "\n", "            ", "ctx_slot_tag_embeds", "=", "self", ".", "slot_tagger_projection_y", "(", "ctx_slot_tag_embeds", ")", "# M(l)", "\n", "", "if", "not", "(", "label_desc_inputs", "is", "None", ")", ":", "\n", "            ", "desc_slot_tag_embeds", "=", "self", ".", "slot_tagger_projection_y", "(", "desc_slot_tag_embeds", ")", "# M(l)", "\n", "", "if", "self", ".", "matching_similarity_type", "in", "{", "'xy1'", ",", "'x1y1'", "}", ":", "\n", "            ", "if", "self", ".", "matching_similarity_y", "!=", "'desc'", ":", "\n", "                ", "ctx_slot_tag_embeds", "=", "get_unit_vectors", "(", "ctx_slot_tag_embeds", ",", "eps", "=", "0", ")", "\n", "", "intent_embeds", "=", "get_unit_vectors", "(", "intent_embeds", ",", "eps", "=", "0", ")", "\n", "if", "not", "(", "label_desc_inputs", "is", "None", ")", ":", "\n", "                ", "desc_slot_tag_embeds", "=", "get_unit_vectors", "(", "desc_slot_tag_embeds", ",", "eps", "=", "0", ")", "\n", "\n", "", "", "if", "self", ".", "matching_similarity_y", "==", "'ctx'", ":", "\n", "            ", "slot_tag_embeds", "=", "ctx_slot_tag_embeds", "\n", "", "elif", "self", ".", "matching_similarity_y", "==", "'desc'", ":", "\n", "            ", "slot_tag_embeds", "=", "desc_slot_tag_embeds", "\n", "", "elif", "self", ".", "matching_similarity_y", "==", "'ctx_desc'", ":", "\n", "            ", "lambda_", "=", "0.9", "\n", "slot_tag_embeds", "=", "lambda_", "*", "ctx_slot_tag_embeds", "+", "(", "1", "-", "lambda_", ")", "*", "desc_slot_tag_embeds", "\n", "\n", "", "if", "self", ".", "slot_embedding_dependent_query_encoding", "==", "'ctx'", ":", "\n", "            ", "other_slot_tag_embeds", "=", "ctx_other_slot_tag_embeds", "\n", "", "elif", "self", ".", "slot_embedding_dependent_query_encoding", "==", "'desc'", ":", "\n", "            ", "other_slot_tag_embeds", "=", "desc_other_slot_tag_embeds", "\n", "", "elif", "self", ".", "slot_embedding_dependent_query_encoding", "==", "'none'", ":", "\n", "            ", "other_slot_tag_embeds", "=", "None", "\n", "\n", "", "return", "(", "other_slot_tag_embeds", ",", "slot_tag_embeds", ")", ",", "intent_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.get_feature_representations_for_query_set": [[307, 317], ["slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.query_sentence_encoder", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.query_sentence_encoder"], "methods", ["None"], ["", "def", "get_feature_representations_for_query_set", "(", "self", ",", "slot_tag_embeds", ",", "\n", "intent_embeds", ",", "inputs", ",", "lattice", "=", "None", ")", ":", "\n", "        ", "other_slot_tag_embeds", ",", "slot_tag_embeds", "=", "slot_tag_embeds", "\n", "if", "self", ".", "slot_embedding_dependent_query_encoding", "!=", "'none'", ":", "\n", "            ", "tf_out", ",", "snt_vector", ",", "query_aware_slot_tag_embeds", "=", "self", ".", "query_sentence_encoder", "(", "inputs", ",", "slot_embeddings", "=", "other_slot_tag_embeds", ",", "lattice", "=", "lattice", ")", "\n", "#slot_tag_embeds = query_aware_slot_tag_embeds # NOTE", "\n", "", "else", ":", "\n", "            ", "tf_out", ",", "snt_vector", "=", "self", ".", "query_sentence_encoder", "(", "inputs", ",", "lattice", "=", "lattice", ")", "\n", "\n", "", "return", "tf_out", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.forward": [[318, 366], ["slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.slot_tagger_projection_x", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.slot_tagger", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.intent_classifier", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.query_sentence_encoder", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.query_sentence_encoder", "slot_tag_embeds.detach", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.detach", "snt_vector.detach", "slot_intent_with_prototypical_network_and_pure_bert.get_unit_vectors", "slot_intent_with_prototypical_network_and_pure_bert.get_unit_vectors", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.slot_tag_loss_fct", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.intent_loss_fct", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.intent_loss_fct", "other_slot_tag_embeds.detach", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.transpose", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.crf_transition_layer", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.slot_tag_loss_fct", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "slot_intent_with_prototypical_network_and_pure_bert.get_unit_vectors", "sentence_mask.bool", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.crf_transition_layer", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.slot_tag_loss_fct", "sentence_mask.bool"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors"], ["", "def", "forward", "(", "self", ",", "slot_tag_embeds", ",", "intent_embeds", ",", "inputs", ",", "lengths", ",", "sentence_mask", ",", "\n", "addtional_features", "=", "None", ",", "slot_tag_masked_output", "=", "None", ",", "\n", "intent_masked_output", "=", "None", ",", "slot_tags", "=", "None", ",", "intents", "=", "None", ",", "\n", "slot_tag_to_id", "=", "None", ",", "detach", "=", "False", ",", "lattice", "=", "None", ")", ":", "\n", "\n", "        ", "other_slot_tag_embeds", ",", "slot_tag_embeds", "=", "slot_tag_embeds", "\n", "if", "detach", ":", "\n", "            ", "other_slot_tag_embeds", ",", "slot_tag_embeds", "=", "other_slot_tag_embeds", ".", "detach", "(", ")", "if", "other_slot_tag_embeds", "is", "not", "None", "else", "None", ",", "slot_tag_embeds", ".", "detach", "(", ")", "\n", "", "if", "self", ".", "slot_embedding_dependent_query_encoding", "!=", "'none'", ":", "\n", "            ", "tf_out", ",", "snt_vector", ",", "query_aware_slot_tag_embeds", "=", "self", ".", "query_sentence_encoder", "(", "inputs", ",", "slot_embeddings", "=", "other_slot_tag_embeds", ",", "lattice", "=", "lattice", ")", "\n", "#slot_tag_embeds = query_aware_slot_tag_embeds # NOTE", "\n", "", "else", ":", "\n", "            ", "tf_out", ",", "snt_vector", "=", "self", ".", "query_sentence_encoder", "(", "inputs", ",", "lattice", "=", "lattice", ")", "\n", "", "if", "detach", ":", "\n", "            ", "tf_out", ",", "snt_vector", "=", "tf_out", ".", "detach", "(", ")", ",", "snt_vector", ".", "detach", "(", ")", "\n", "\n", "", "tf_out", "=", "self", ".", "slot_tagger_projection_x", "(", "tf_out", ")", "## M(f(x))", "\n", "if", "self", ".", "matching_similarity_type", "in", "{", "'x1y'", ",", "'x1y1'", "}", ":", "\n", "            ", "tf_out", ",", "snt_vector", "=", "get_unit_vectors", "(", "tf_out", ")", ",", "get_unit_vectors", "(", "snt_vector", ")", "\n", "\n", "", "slot_tag_logits", "=", "self", ".", "slot_tagger", "(", "tf_out", ",", "slot_tag_embeds", ",", "masked_output", "=", "slot_tag_masked_output", ")", "\n", "intent_logits", "=", "self", ".", "intent_classifier", "(", "snt_vector", ",", "intent_embeds", ",", "masked_output", "=", "intent_masked_output", ")", "\n", "\n", "outputs", "=", "(", "slot_tag_logits", ",", "intent_logits", ",", "tf_out", ",", "snt_vector", ")", "\n", "if", "slot_tags", "is", "not", "None", "and", "intents", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "config", ".", "task_st", "==", "\"slot_tagger\"", ":", "\n", "                ", "slot_tag_loss", "=", "self", ".", "slot_tag_loss_fct", "(", "slot_tag_logits", ".", "transpose", "(", "1", ",", "2", ")", ",", "slot_tags", ")", "# B * C * L, B * L", "\n", "", "elif", "self", ".", "config", ".", "task_st", "==", "\"slot_tagger_with_adaptive_crf\"", ":", "\n", "                ", "if", "self", ".", "matching_similarity_type", "in", "{", "'xy1'", ",", "'x1y1'", "}", ":", "\n", "                    ", "slot_tag_embeds_tmp", "=", "slot_tag_embeds", "\n", "", "else", ":", "\n", "                    ", "slot_tag_embeds_tmp", "=", "get_unit_vectors", "(", "slot_tag_embeds", ",", "eps", "=", "0", ")", "\n", "", "transitions", "=", "self", ".", "crf_transition_layer", "(", "slot_tag_embeds_tmp", ")", "\n", "slot_tag_loss", "=", "self", ".", "slot_tag_loss_fct", "(", "transitions", ",", "slot_tag_logits", ",", "sentence_mask", ".", "bool", "(", ")", ",", "slot_tags", ")", "\n", "", "elif", "self", ".", "config", ".", "task_st", "==", "\"slot_tagger_with_abstract_crf\"", ":", "\n", "                ", "transitions", "=", "self", ".", "crf_transition_layer", "(", "slot_tag_to_id", ")", "\n", "slot_tag_loss", "=", "self", ".", "slot_tag_loss_fct", "(", "transitions", ",", "slot_tag_logits", ",", "sentence_mask", ".", "bool", "(", ")", ",", "slot_tags", ")", "\n", "", "else", ":", "\n", "                ", "pass", "\n", "\n", "", "if", "self", ".", "intent_multi_class", ":", "\n", "                ", "intent_loss", "=", "self", ".", "intent_loss_fct", "(", "torch", ".", "sigmoid", "(", "intent_logits", ")", ",", "intents", ")", "\n", "", "else", ":", "\n", "                ", "intent_loss", "=", "self", ".", "intent_loss_fct", "(", "intent_logits", ",", "intents", ")", "\n", "\n", "", "outputs", "=", "(", "slot_tag_loss", ",", "intent_loss", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.decode_top_hyp": [[367, 392], ["slot_tag_logits.data.cpu().numpy().argmax", "torch.sigmoid().data.cpu().numpy", "torch.sigmoid().data.cpu().numpy", "torch.sigmoid().data.cpu().numpy", "torch.sigmoid().data.cpu().numpy", "torch.sigmoid().data.cpu().numpy", "torch.sigmoid().data.cpu().numpy", "torch.sigmoid().data.cpu().numpy", "torch.sigmoid().data.cpu().numpy", "torch.sigmoid().data.cpu().numpy", "intent_logits.data.cpu().numpy().argmax", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.crf_transition_layer", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.crf.viterbi_decode", "tag_path_top_hyp.data.cpu().numpy", "slot_tag_logits.data.cpu().numpy", "slot_intent_with_prototypical_network_and_pure_bert.get_unit_vectors", "sentence_mask.bool", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.crf_transition_layer", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.crf.viterbi_decode", "tag_path_top_hyp.data.cpu().numpy", "torch.sigmoid().data.cpu", "torch.sigmoid().data.cpu", "torch.sigmoid().data.cpu", "torch.sigmoid().data.cpu", "torch.sigmoid().data.cpu", "torch.sigmoid().data.cpu", "torch.sigmoid().data.cpu", "torch.sigmoid().data.cpu", "torch.sigmoid().data.cpu", "intent_logits.data.cpu().numpy", "tag_path_top_hyp.data.cpu", "sentence_mask.bool", "slot_tag_logits.data.cpu", "tag_path_top_hyp.data.cpu", "intent_logits.data.cpu", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.CRFLoss.viterbi_decode", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.utils.crf.CRFLoss.viterbi_decode"], ["", "def", "decode_top_hyp", "(", "self", ",", "slot_tag_embeds", ",", "slot_tag_logits", ",", "intent_logits", ",", "sentence_mask", ",", "slot_tag_to_id", "=", "None", ")", ":", "\n", "        ", "other_slot_tag_embeds", ",", "slot_tag_embeds", "=", "slot_tag_embeds", "# for slot_tagger_with_adaptive_crf", "\n", "if", "self", ".", "config", ".", "task_st", "==", "\"slot_tagger\"", ":", "\n", "            ", "slot_tag_top_hyp", "=", "slot_tag_logits", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "-", "1", ")", "\n", "", "elif", "self", ".", "config", ".", "task_st", "==", "\"slot_tagger_with_adaptive_crf\"", ":", "\n", "            ", "if", "self", ".", "matching_similarity_type", "in", "{", "'xy1'", ",", "'x1y1'", "}", ":", "\n", "                ", "slot_tag_embeds_tmp", "=", "slot_tag_embeds", "\n", "", "else", ":", "\n", "                ", "slot_tag_embeds_tmp", "=", "get_unit_vectors", "(", "slot_tag_embeds", ",", "eps", "=", "0", ")", "\n", "", "transitions", "=", "self", ".", "crf_transition_layer", "(", "slot_tag_embeds_tmp", ")", "\n", "tag_path_scores_top_hyp", ",", "tag_path_top_hyp", "=", "self", ".", "crf", ".", "viterbi_decode", "(", "transitions", ",", "slot_tag_logits", ",", "sentence_mask", ".", "bool", "(", ")", ")", "\n", "slot_tag_top_hyp", "=", "tag_path_top_hyp", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "elif", "self", ".", "config", ".", "task_st", "==", "\"slot_tagger_with_abstract_crf\"", ":", "\n", "            ", "transitions", "=", "self", ".", "crf_transition_layer", "(", "slot_tag_to_id", ")", "\n", "tag_path_scores_top_hyp", ",", "tag_path_top_hyp", "=", "self", ".", "crf", ".", "viterbi_decode", "(", "transitions", ",", "slot_tag_logits", ",", "sentence_mask", ".", "bool", "(", ")", ")", "\n", "slot_tag_top_hyp", "=", "tag_path_top_hyp", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "\n", "", "if", "self", ".", "intent_multi_class", ":", "\n", "            ", "intent_top_hyp", "=", "torch", ".", "sigmoid", "(", "intent_logits", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "intent_top_hyp", "=", "intent_logits", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "argmax", "(", "axis", "=", "-", "1", ")", "\n", "\n", "", "return", "slot_tag_top_hyp", ",", "intent_top_hyp", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.decode_by_similarity_of_BERT": [[393, 416], ["slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.support_sentence_encoder", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.query_sentence_encoder", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "torch.index_select().view", "slot_tag_top_hyp.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "slot_intent_with_prototypical_network_and_pure_bert.get_unit_vectors", "slot_intent_with_prototypical_network_and_pure_bert.get_unit_vectors", "s_tf_out.size", "s_tf_out.size", "tf_out.size", "tf_out.size", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "intent_top_hyp.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "s_tf_out.contiguous().view().transpose", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "slot_tag_top_hyp.data.cpu().numpy.data.cpu().numpy.data.cpu", "s_snt_vector.transpose", "support_intents.view", "torch.argmax.view", "torch.argmax.view", "torch.argmax.view", "support_sentence_mask.view", "support_slot_tags.view", "torch.argmax.view", "torch.argmax.view", "torch.argmax.view", "intent_top_hyp.data.cpu().numpy.data.cpu().numpy.data.cpu", "s_tf_out.contiguous().view", "s_tf_out.contiguous"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors"], ["", "def", "decode_by_similarity_of_BERT", "(", "self", ",", "support_inputs", ",", "\n", "support_sentence_mask", ",", "support_slot_tags", ",", "support_intents", ",", "\n", "query_inputs", ",", "pred_intent", "=", "False", ",", "support_lattice", "=", "None", ",", "query_lattice", "=", "None", ")", ":", "\n", "        ", "s_tf_out", ",", "s_snt_vector", "=", "self", ".", "support_sentence_encoder", "(", "support_inputs", ",", "lattice", "=", "support_lattice", ")", "\n", "s_tf_out", ",", "s_snt_vector", "=", "get_unit_vectors", "(", "s_tf_out", ")", ",", "get_unit_vectors", "(", "s_snt_vector", ")", "\n", "s_batch_size", ",", "s_length", "=", "s_tf_out", ".", "size", "(", "0", ")", ",", "s_tf_out", ".", "size", "(", "1", ")", "\n", "tf_out", ",", "snt_vector", "=", "self", ".", "query_sentence_encoder", "(", "query_inputs", ",", "lattice", "=", "query_lattice", ")", "\n", "q_batch_size", ",", "q_length", "=", "tf_out", ".", "size", "(", "0", ")", ",", "tf_out", ".", "size", "(", "1", ")", "\n", "\n", "output_mask", "=", "(", "(", "1.0", "-", "support_sentence_mask", ".", "view", "(", "-", "1", ")", ")", "*", "(", "-", "1e16", ")", ")", "[", "None", ",", "None", ",", ":", "]", "\n", "slot_tag_logits", "=", "torch", ".", "matmul", "(", "tf_out", ",", "s_tf_out", ".", "contiguous", "(", ")", ".", "view", "(", "s_batch_size", "*", "s_length", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ")", "+", "output_mask", "\n", "slot_tag_top_hyp_ids", "=", "torch", ".", "argmax", "(", "slot_tag_logits", ",", "dim", "=", "-", "1", ")", "\n", "slot_tag_top_hyp", "=", "torch", ".", "index_select", "(", "support_slot_tags", ".", "view", "(", "-", "1", ")", ",", "0", ",", "slot_tag_top_hyp_ids", ".", "view", "(", "-", "1", ")", ")", ".", "view", "(", "q_batch_size", ",", "q_length", ")", "\n", "slot_tag_top_hyp", "=", "slot_tag_top_hyp", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "not", "pred_intent", ":", "\n", "            ", "return", "slot_tag_top_hyp", "\n", "", "else", ":", "\n", "            ", "intent_logits", "=", "torch", ".", "matmul", "(", "snt_vector", ",", "s_snt_vector", ".", "transpose", "(", "0", ",", "1", ")", ")", "\n", "intent_top_hyp_ids", "=", "torch", ".", "argmax", "(", "intent_logits", ",", "dim", "=", "-", "1", ")", "\n", "intent_top_hyp", "=", "torch", ".", "index_select", "(", "support_intents", ".", "view", "(", "-", "1", ")", ",", "0", ",", "intent_top_hyp_ids", ".", "view", "(", "-", "1", ")", ")", "\n", "intent_top_hyp", "=", "intent_top_hyp", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "return", "slot_tag_top_hyp", ",", "intent_top_hyp", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.decompress_CRF_transitions": [[417, 421], ["slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.crf_transition_layer", "models.utils.crf.GeneralTransitionLayer"], "methods", ["None"], ["", "", "def", "decompress_CRF_transitions", "(", "self", ",", "slot_tag_to_id", ")", ":", "\n", "        ", "assert", "self", ".", "config", ".", "task_st", "==", "\"slot_tagger_with_abstract_crf\"", "\n", "transitions", "=", "self", ".", "crf_transition_layer", "(", "slot_tag_to_id", ")", "\n", "self", ".", "crf_transition_layer", "=", "GeneralTransitionLayer", "(", "transitions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.compress_CRF_transitions": [[422, 425], ["models.utils.crf.AbstractTransitionLayer", "slot_intent_with_prototypical_network_and_pure_bert.FewShotIntentSlot_ProtoNet.crf_transition_layer.to"], "methods", ["None"], ["", "def", "compress_CRF_transitions", "(", "self", ")", ":", "\n", "        ", "self", ".", "crf_transition_layer", "=", "AbstractTransitionLayer", "(", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "crf_transition_layer", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.get_unit_vectors": [[26, 31], ["x.div.div", "torch.norm", "torch.norm", "torch.norm", "x_l2_norm.expand_as"], "function", ["None"], ["def", "get_unit_vectors", "(", "x", ",", "eps", "=", "EPS", ")", ":", "\n", "    ", "\"\"\" x : B * L * H or B * H \"\"\"", "\n", "x_l2_norm", "=", "torch", ".", "norm", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "+", "eps", "\n", "x", "=", "x", ".", "div", "(", "x_l2_norm", ".", "expand_as", "(", "x", ")", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.slot_intent_with_prototypical_network_and_pure_bert.transformer_forward_by_ignoring_suffix": [[32, 42], ["pretrained_top_hiddens.reshape().index_select", "torch.zeros", "torch.zeros", "torch.zeros", "embeds.index_copy_().view.index_copy_().view", "pretrained_top_hiddens.size", "pretrained_top_hiddens.size", "pretrained_top_hiddens.size", "pretrained_top_hiddens.reshape", "embeds.index_copy_().view.index_copy_"], "function", ["None"], ["", "def", "transformer_forward_by_ignoring_suffix", "(", "pretrained_top_hiddens", ",", "batch_size", ",", "max_word_length", ",", "selects", ",", "copies", ",", "device", "=", "None", ")", ":", "\n", "    ", "'''\n    Ignore hidden states of all suffixes: [CLS] from ... to de ##n ##ver [SEP] => from ... to de\n    '''", "\n", "batch_size", ",", "pretrained_seq_length", ",", "hidden_size", "=", "pretrained_top_hiddens", ".", "size", "(", "0", ")", ",", "pretrained_top_hiddens", ".", "size", "(", "1", ")", ",", "pretrained_top_hiddens", ".", "size", "(", "2", ")", "\n", "#chosen_encoder_hiddens = pretrained_top_hiddens.view(-1, hidden_size).index_select(0, selects)", "\n", "chosen_encoder_hiddens", "=", "pretrained_top_hiddens", ".", "reshape", "(", "-", "1", ",", "hidden_size", ")", ".", "index_select", "(", "0", ",", "selects", ")", "\n", "embeds", "=", "torch", ".", "zeros", "(", "batch_size", "*", "max_word_length", ",", "hidden_size", ",", "device", "=", "device", ")", "\n", "embeds", "=", "embeds", ".", "index_copy_", "(", "0", ",", "copies", ",", "chosen_encoder_hiddens", ")", ".", "view", "(", "batch_size", ",", "max_word_length", ",", "-", "1", ")", "\n", "return", "embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.Projection.__init__": [[26, 53], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "exit"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "input_embedding_size", ",", "projection", "=", "None", ",", "projection_dim", "=", "0", ",", "device", "=", "None", ")", ":", "\n", "        ", "'''\n        projection: \n            adaptive_finetune\n            LSM (least squares method)\n            LEN (linear error nulling)\n        '''", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "input_embedding_size", "=", "input_embedding_size", "\n", "self", ".", "projection", "=", "projection", "\n", "self", ".", "projection_dim", "=", "projection_dim", "\n", "if", "self", ".", "projection_dim", "==", "0", "or", "projection", "is", "None", ":", "\n", "            ", "self", ".", "projection_dim", "=", "input_embedding_size", "\n", "\n", "", "if", "self", ".", "projection", "==", "'learnable'", ":", "\n", "            ", "self", ".", "M", "=", "nn", ".", "Linear", "(", "input_embedding_size", ",", "self", ".", "projection_dim", ",", "bias", "=", "False", ")", "\n", "", "elif", "self", ".", "projection", "==", "None", ":", "\n", "            ", "self", ".", "M", "=", "nn", ".", "Identity", "(", ")", "\n", "", "elif", "self", ".", "projection", "==", "'adaptive_finetune'", "or", "self", ".", "projection", "==", "'LSM'", ":", "\n", "            ", "self", ".", "M", "=", "nn", ".", "Linear", "(", "input_embedding_size", ",", "self", ".", "projection_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "M", ".", "weight", ".", "requires_grad", "=", "False", "\n", "", "elif", "self", ".", "projection", "==", "'LEN'", ":", "\n", "            ", "self", ".", "M", "=", "None", "\n", "", "else", ":", "\n", "            ", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.Projection.reset": [[54, 56], ["predictor.Projection.M.weight.data.normal_"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "M", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "0.02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.Projection.get_output_dim": [[57, 59], ["None"], "methods", ["None"], ["", "def", "get_output_dim", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "projection_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.Projection.construction_of_projection_M_LSM": [[60, 82], ["C.size", "torch.mm.inverse", "torch.mm.inverse", "torch.mm.inverse", "torch.mm.inverse", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm.inverse", "torch.mm.inverse", "torch.mm.inverse", "torch.mm.inverse", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.eye().index_select", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "X.size", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "X.t", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "X.t", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "C.t", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye"], "methods", ["None"], ["", "def", "construction_of_projection_M_LSM", "(", "self", ",", "C", ",", "X", ",", "Y", ")", ":", "\n", "        ", "'''\n        C : M * H, per-class average of the embedded features\n        X : N * H\n        Y : N\n        '''", "\n", "#assert self.projection == 'LSM'", "\n", "lambda_", "=", "1e-2", "\n", "m", ",", "h", "=", "C", ".", "size", "(", ")", "\n", "n", "=", "X", ".", "size", "(", ")", "[", "0", "]", "\n", "left", "=", "torch", ".", "mm", "(", "X", ".", "t", "(", ")", ",", "X", ")", "+", "lambda_", "*", "torch", ".", "eye", "(", "h", ",", "device", "=", "self", ".", "device", ")", "\n", "left", "=", "left", ".", "inverse", "(", ")", "\n", "left", "=", "torch", ".", "mm", "(", "left", ",", "X", ".", "t", "(", ")", ")", "\n", "right", "=", "torch", ".", "mm", "(", "C", ".", "t", "(", ")", ",", "C", ")", "+", "lambda_", "*", "torch", ".", "eye", "(", "h", ",", "device", "=", "self", ".", "device", ")", "\n", "right", "=", "right", ".", "inverse", "(", ")", "\n", "right", "=", "torch", ".", "mm", "(", "C", ",", "right", ")", "\n", "Y", "=", "torch", ".", "eye", "(", "m", ",", "device", "=", "self", ".", "device", ")", ".", "index_select", "(", "0", ",", "Y", ")", "\n", "Y", "-=", "0.5", "\n", "Y", "*=", "2", "\n", "M", "=", "torch", ".", "mm", "(", "left", ",", "Y", ")", "\n", "M", "=", "torch", ".", "mm", "(", "M", ",", "right", ")", "\n", "self", ".", "M", ".", "weight", ".", "data", "=", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.Projection.construction_of_projection_M_LEN": [[83, 117], ["len", "Phi.sum", "predictor.get_unit_vectors", "predictor.get_unit_vectors", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "vh[].t", "Phi.sum", "predictor.get_unit_vectors", "predictor.get_unit_vectors", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "torch.svd", "vh[].transpose"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors", "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors"], ["", "def", "construction_of_projection_M_LEN", "(", "self", ",", "Phi", ",", "C", ")", ":", "\n", "        ", "'''\n        Phi : n * p\n        C : n * p, b * n * p, per-class average of the embedded features\n        '''", "\n", "eps", "=", "1e-6", "\n", "c_shape", "=", "C", ".", "shape", "\n", "if", "len", "(", "c_shape", ")", "==", "2", ":", "\n", "            ", "n", ",", "p", "=", "c_shape", "\n", "Phi_sum", "=", "Phi", ".", "sum", "(", "dim", "=", "0", ")", "\n", "mod_Phi", "=", "(", "n", "*", "Phi", "-", "Phi_sum", "[", "None", ",", ":", "]", ")", "/", "(", "n", "-", "1", ")", "\n", "mod_Phi", "=", "get_unit_vectors", "(", "mod_Phi", ",", "eps", "=", "eps", ")", "\n", "C", "=", "get_unit_vectors", "(", "C", ",", "eps", "=", "eps", ")", "\n", "null", "=", "mod_Phi", "-", "C", "\n", "\n", "tol", "=", "1e-13", "\n", "u", ",", "s", ",", "vh", "=", "torch", ".", "svd", "(", "null", ",", "some", "=", "False", ")", "\n", "d", "=", "(", "s", ">=", "tol", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "#d = min(p - n, d)", "\n", "#M = vh[d:].conj()", "\n", "M", "=", "vh", "[", "d", ":", "]", ".", "t", "(", ")", "\n", "", "else", ":", "\n", "            ", "b", ",", "n", ",", "p", "=", "c_shape", "\n", "Phi_sum", "=", "Phi", ".", "sum", "(", "dim", "=", "0", ")", "\n", "mod_Phi", "=", "(", "n", "*", "Phi", "-", "Phi_sum", "[", "None", ",", ":", "]", ")", "/", "(", "n", "-", "1", ")", "\n", "mod_Phi", "=", "get_unit_vectors", "(", "mod_Phi", ",", "eps", "=", "eps", ")", "\n", "C", "=", "get_unit_vectors", "(", "C", ",", "eps", "=", "eps", ")", "\n", "null", "=", "mod_Phi", "[", "None", ",", ":", ",", ":", "]", "-", "C", "\n", "\n", "tol", "=", "1e-13", "\n", "u", ",", "s", ",", "vh", "=", "torch", ".", "svd", "(", "null", ",", "some", "=", "False", ")", "\n", "d", "=", "n", "\n", "M", "=", "vh", "[", ":", ",", "d", ":", ",", ":", "]", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "", "self", ".", "M", "=", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.Projection.forward": [[118, 136], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "predictor.Projection.M", "len", "X.squeeze.squeeze.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"\n        X : \n            1. B * L * H or B * H or O * H  x  H * H'\n            1. B * L * H or B * H or B * O * H  x  B * H * H'\n        \"\"\"", "\n", "if", "self", ".", "projection", "==", "'LEN'", ":", "\n", "            ", "if", "len", "(", "X", ".", "shape", ")", "==", "2", ":", "\n", "                ", "X", "=", "X", "[", ":", ",", "None", ",", ":", "]", "\n", "squeeze", "=", "True", "\n", "", "else", ":", "\n", "                ", "squeeze", "=", "False", "\n", "", "X", "=", "torch", ".", "matmul", "(", "X", ",", "self", ".", "M", ")", "\n", "if", "squeeze", ":", "\n", "                ", "X", "=", "X", ".", "squeeze", "(", "1", ")", "# B * 1 * H' => B * H'", "\n", "", "", "else", ":", "\n", "            ", "X", "=", "self", ".", "M", "(", "X", ")", "\n", "", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__": [[139, 143], ["torch.Module.__init__", "matching_similarity_function.lower"], "methods", ["home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "matching_similarity_function", "=", "'dot'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "matching_similarity_function", "=", "matching_similarity_function", ".", "lower", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.MatchingClassifier.forward": [[144, 191], ["len", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "logits.index_fill_.index_fill_.squeeze", "logits.index_fill_.index_fill_.index_fill_", "y.transpose", "len", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "len", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "exit", "y.transpose", "y.transpose", "norm_y[].expand_as", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "norm_y[].expand_as", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "len", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "unit_y.transpose", "unit_y.transpose", "norm_y[].expand_as", "norm_y[].expand_as", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "unit_y.transpose", "unit_y.transpose", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "encoder_hiddens", ",", "label_embeddings", ",", "masked_output", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        encoder_hiddens : B * L * H or B * H\n        label_embeddings : O * H or B * O * H\n        \"\"\"", "\n", "x", "=", "encoder_hiddens", "\n", "y", "=", "label_embeddings", "\n", "\n", "if", "len", "(", "x", ".", "shape", ")", "==", "2", ":", "\n", "            ", "x", "=", "x", "[", ":", ",", "None", ",", ":", "]", "\n", "squeeze", "=", "True", "\n", "", "else", ":", "\n", "            ", "squeeze", "=", "False", "\n", "\n", "# dot product", "\n", "", "if", "self", ".", "matching_similarity_function", "==", "'dot'", ":", "\n", "            ", "logits", "=", "torch", ".", "matmul", "(", "x", ",", "y", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "", "elif", "self", ".", "matching_similarity_function", "==", "'euclidean'", ":", "\n", "            ", "if", "len", "(", "y", ".", "shape", ")", "==", "3", ":", "\n", "                ", "logits", "=", "torch", ".", "matmul", "(", "x", ",", "y", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "-", "(", "torch", ".", "norm", "(", "y", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "**", "2", ")", "[", ":", ",", "None", ",", ":", "]", "/", "2", "\n", "", "else", ":", "\n", "                ", "logits", "=", "torch", ".", "matmul", "(", "x", ",", "y", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "-", "(", "torch", ".", "norm", "(", "y", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "**", "2", ")", "/", "2", "\n", "", "", "elif", "self", ".", "matching_similarity_function", "==", "'euclidean2'", ":", "\n", "            ", "norm_y", "=", "torch", ".", "norm", "(", "y", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "if", "len", "(", "y", ".", "shape", ")", "==", "3", ":", "\n", "                ", "unit_y", "=", "y", "/", "norm_y", "[", ":", ",", ":", ",", "None", "]", ".", "expand_as", "(", "y", ")", "\n", "logits", "=", "torch", ".", "matmul", "(", "x", ",", "unit_y", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "-", "norm_y", "[", ":", ",", "None", ",", ":", "]", "/", "2", "\n", "", "else", ":", "\n", "                ", "unit_y", "=", "y", "/", "norm_y", "[", ":", ",", "None", "]", ".", "expand_as", "(", "y", ")", "\n", "logits", "=", "torch", ".", "matmul", "(", "x", ",", "unit_y", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "-", "norm_y", "/", "2", "\n", "", "", "elif", "self", ".", "matching_similarity_function", "==", "'euclidean3'", ":", "\n", "            ", "norm_y", "=", "torch", ".", "norm", "(", "y", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "if", "len", "(", "y", ".", "shape", ")", "==", "3", ":", "\n", "                ", "unit_y", "=", "y", "/", "norm_y", "[", ":", ",", ":", ",", "None", "]", ".", "expand_as", "(", "y", ")", "\n", "logits", "=", "torch", ".", "matmul", "(", "x", ",", "unit_y", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "-", "norm_y", "[", ":", ",", "None", ",", ":", "]", "/", "2", "-", "(", "torch", ".", "norm", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "**", "2", ")", "[", ":", ",", ":", ",", "None", "]", "/", "norm_y", "[", ":", ",", "None", ",", ":", "]", "/", "2", "\n", "", "else", ":", "\n", "                ", "unit_y", "=", "y", "/", "norm_y", "[", ":", ",", "None", "]", ".", "expand_as", "(", "y", ")", "\n", "logits", "=", "torch", ".", "matmul", "(", "x", ",", "unit_y", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "-", "norm_y", "/", "2", "-", "(", "torch", ".", "norm", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "**", "2", ")", "[", ":", ",", ":", ",", "None", "]", "/", "norm_y", "[", "None", ",", "None", ",", ":", "]", "/", "2", "\n", "", "", "else", ":", "\n", "            ", "exit", "(", ")", "\n", "\n", "", "if", "squeeze", ":", "\n", "            ", "logits", "=", "logits", ".", "squeeze", "(", "1", ")", "# B * 1 * O => B * O", "\n", "", "if", "masked_output", "is", "not", "None", ":", "\n", "            ", "logits", "=", "logits", ".", "index_fill_", "(", "-", "1", ",", "masked_output", ",", "MIN_NUMBER", ")", "\n", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.sz128_few_shot_slot_tagging_and_NER.models.predictor.get_unit_vectors": [[18, 23], ["x.div.div", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "x_l2_norm.expand_as"], "function", ["None"], ["def", "get_unit_vectors", "(", "x", ",", "eps", "=", "EPS", ")", ":", "\n", "    ", "\"\"\" x : B * L * H or B * H \"\"\"", "\n", "x_l2_norm", "=", "torch", ".", "norm", "(", "x", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "+", "eps", "\n", "x", "=", "x", ".", "div", "(", "x_l2_norm", ".", "expand_as", "(", "x", ")", ")", "\n", "return", "x", "\n", "\n"]]}