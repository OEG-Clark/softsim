{"home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Perturbation._add_noise_to_tensor": [[13, 23], ["torch.randn_like", "tens.std"], "methods", ["None"], ["@", "classmethod", "\n", "def", "_add_noise_to_tensor", "(", "cls", ",", "tens", ":", "torch", ".", "Tensor", ",", "over_dim", ":", "int", "=", "0", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Adds noise to a tensor sampled from N(0, tens.std()).\n        :param tens:\n        :param over_dim: over what dim to calculate the std. 0 for features over batch,  1 for over sample.\n        :return: noisy tensor in the same shape as input\n        \"\"\"", "\n", "\n", "return", "tens", "+", "torch", ".", "randn_like", "(", "tens", ")", "*", "tens", ".", "std", "(", "dim", "=", "over_dim", ")", "\n", "# return tens + torch.randn_like(tens)", "\n"]], "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Perturbation.perturb_tensor": [[25, 51], ["list", "cls._add_noise_to_tensor.view", "cls._add_noise_to_tensor.repeat", "cls._add_noise_to_tensor.view", "cls._add_noise_to_tensor.view", "cls._add_noise_to_tensor.requires_grad_", "cls._add_noise_to_tensor"], "methods", ["home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Perturbation._add_noise_to_tensor"], ["", "@", "classmethod", "\n", "def", "perturb_tensor", "(", "cls", ",", "tens", ":", "torch", ".", "Tensor", ",", "n_samples", ":", "int", ",", "perturbation", ":", "bool", "=", "True", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Flatting the tensor, expanding it, perturbing and reconstructing to the original shape.\n        Note, this function assumes that the batch is the first dimension.\n        :param tens:\n        :param n_samples: times to perturb\n        :param perturbation: False - only duplicating the tensor\n        :return: tensor in the shape of [batch, samples * num_eval_samples]\n        \"\"\"", "\n", "tens_dim", "=", "list", "(", "tens", ".", "shape", ")", "\n", "\n", "tens", "=", "tens", ".", "view", "(", "tens", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "tens", "=", "tens", ".", "repeat", "(", "1", ",", "n_samples", ")", "\n", "\n", "tens", "=", "tens", ".", "view", "(", "tens", ".", "shape", "[", "0", "]", "*", "n_samples", ",", "-", "1", ")", "\n", "\n", "if", "perturbation", ":", "\n", "            ", "tens", "=", "cls", ".", "_add_noise_to_tensor", "(", "tens", ")", "\n", "\n", "", "tens_dim", "[", "0", "]", "*=", "n_samples", "\n", "\n", "tens", "=", "tens", ".", "view", "(", "*", "tens_dim", ")", "\n", "tens", ".", "requires_grad_", "(", ")", "\n", "\n", "return", "tens", "\n", "\n"]], "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Perturbation.get_expanded_logits": [[52, 66], ["torch.nn.functional.softmax.repeat", "torch.nn.functional.softmax.repeat.view", "torch.nn.functional.softmax"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_expanded_logits", "(", "cls", ",", "logits", ":", "torch", ".", "Tensor", ",", "n_samples", ":", "int", ",", "logits_flg", ":", "bool", "=", "True", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Perform Softmax and then expand the logits depends on the num_eval_samples\n        :param logits_flg: whether the input is logits or softmax\n        :param logits: tensor holds logits outputs from the model\n        :param n_samples: times to duplicate\n        :return:\n        \"\"\"", "\n", "if", "logits_flg", ":", "\n", "            ", "logits", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "", "expanded_logits", "=", "logits", ".", "repeat", "(", "1", ",", "n_samples", ")", "\n", "\n", "return", "expanded_logits", ".", "view", "(", "expanded_logits", ".", "shape", "[", "0", "]", "*", "n_samples", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization._get_variance": [[72, 81], ["torch.var"], "methods", ["None"], ["@", "classmethod", "\n", "def", "_get_variance", "(", "cls", ",", "loss", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes the variance along samples for the first dimension in a tensor\n        :param loss: [batch, number of evaluate samples]\n        :return: variance of a given batch of loss values\n        \"\"\"", "\n", "\n", "return", "torch", ".", "var", "(", "loss", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization._get_differential_entropy": [[82, 91], ["torch.sum", "loss.log"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_get_differential_entropy", "(", "cls", ",", "loss", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes differential entropy: -E[flogf]\n        :param loss:\n        :return: a tensor holds the differential entropy for a batch\n        \"\"\"", "\n", "\n", "return", "-", "1", "*", "torch", ".", "sum", "(", "loss", "*", "loss", ".", "log", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization._get_functional_entropy": [[92, 103], ["torch.nn.functional.normalize", "torch.mean", "torch.mean", "torch.mean().log", "torch.nn.functional.normalize.log", "torch.mean"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_get_functional_entropy", "(", "cls", ",", "loss", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes functional entropy: E[flogf] - E[f]logE[f]\n        :param loss:\n        :return: a tensor holds the functional entropy for a batch\n        \"\"\"", "\n", "loss", "=", "torch", ".", "nn", ".", "functional", ".", "normalize", "(", "loss", ",", "p", "=", "1", ",", "dim", "=", "1", ")", "\n", "loss", "=", "torch", ".", "mean", "(", "loss", "*", "loss", ".", "log", "(", ")", ")", "-", "(", "torch", ".", "mean", "(", "loss", ")", "*", "torch", ".", "mean", "(", "loss", ")", ".", "log", "(", ")", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization.get_batch_statistics": [[104, 126], ["loss.reshape.reshape.reshape", "torch.mean", "cls._get_variance", "torch.abs", "cls._get_functional_entropy", "cls._get_differential_entropy", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization._get_variance", "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization._get_functional_entropy", "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization._get_differential_entropy"], ["", "@", "classmethod", "\n", "def", "get_batch_statistics", "(", "cls", ",", "loss", ":", "torch", ".", "Tensor", ",", "n_samples", ":", "int", ",", "estimation", ":", "str", "=", "'ent'", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Calculate the expectation of the batch gradient\n        :param n_samples:\n        :param loss:\n        :param estimation:\n        :return: Influence expectation\n        \"\"\"", "\n", "loss", "=", "loss", ".", "reshape", "(", "-", "1", ",", "n_samples", ")", "\n", "\n", "if", "estimation", "==", "'var'", ":", "\n", "            ", "batch_statistics", "=", "cls", ".", "_get_variance", "(", "loss", ")", "\n", "batch_statistics", "=", "torch", ".", "abs", "(", "batch_statistics", ")", "\n", "", "elif", "estimation", "==", "'ent'", ":", "\n", "            ", "batch_statistics", "=", "cls", ".", "_get_functional_entropy", "(", "loss", ")", "\n", "", "elif", "estimation", "==", "'dif_ent'", ":", "\n", "            ", "batch_statistics", "=", "cls", ".", "_get_differential_entropy", "(", "loss", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f'{estimation} is unknown regularization, please use \"var\" or \"ent\".'", ")", "\n", "\n", "", "return", "torch", ".", "mean", "(", "batch_statistics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization.get_batch_norm": [[127, 143], ["torch.norm", "torch.pow", "torch.mean"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "get_batch_norm", "(", "cls", ",", "grad", ":", "torch", ".", "Tensor", ",", "loss", ":", "torch", ".", "Tensor", "=", "None", ",", "estimation", ":", "str", "=", "'ent'", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Calculate the expectation of the batch gradient\n        :param loss:\n        :param estimation:\n        :param grad: tensor holds the gradient batch\n        :return: approximation of the required expectation\n        \"\"\"", "\n", "batch_grad_norm", "=", "torch", ".", "norm", "(", "grad", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "batch_grad_norm", "=", "torch", ".", "pow", "(", "batch_grad_norm", ",", "2", ")", "\n", "\n", "if", "estimation", "==", "'ent'", ":", "\n", "            ", "batch_grad_norm", "=", "batch_grad_norm", "/", "loss", "\n", "\n", "", "return", "torch", ".", "mean", "(", "batch_grad_norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization._get_batch_norm": [[144, 160], ["torch.norm", "torch.pow"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_get_batch_norm", "(", "cls", ",", "grad", ":", "torch", ".", "Tensor", ",", "loss", ":", "torch", ".", "Tensor", "=", "None", ",", "estimation", ":", "str", "=", "'ent'", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Calculate the expectation of the batch gradient\n        :param loss:\n        :param estimation:\n        :param grad: tensor holds the gradient batch\n        :return: approximation of the required expectation\n        \"\"\"", "\n", "batch_grad_norm", "=", "torch", ".", "norm", "(", "grad", ",", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "batch_grad_norm", "=", "torch", ".", "pow", "(", "batch_grad_norm", ",", "2", ")", "\n", "\n", "if", "estimation", "==", "'ent'", ":", "\n", "            ", "batch_grad_norm", "=", "batch_grad_norm", "/", "loss", "\n", "\n", "", "return", "batch_grad_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization._get_max_ent": [[161, 170], ["torch.norm", "torch.div"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_get_max_ent", "(", "cls", ",", "inf_scores", ":", "torch", ".", "Tensor", ",", "norm", ":", "float", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Calculate the norm of 1 divided by the information\n        :param inf_scores: tensor holding batch information scores\n        :param norm: which norm to use\n        :return:\n        \"\"\"", "\n", "return", "torch", ".", "norm", "(", "torch", ".", "div", "(", "1", ",", "inf_scores", ")", ",", "p", "=", "norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization._get_max_ent_minus": [[171, 180], ["torch.norm"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_get_max_ent_minus", "(", "cls", ",", "inf_scores", ":", "torch", ".", "Tensor", ",", "norm", ":", "float", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Calculate -1 * the norm of the information\n        :param inf_scores: tensor holding batch information scores\n        :param norm: which norm to use\n        :return:\n        \"\"\"", "\n", "return", "-", "1", "*", "torch", ".", "norm", "(", "inf_scores", ",", "p", "=", "norm", ")", "+", "0.1", "\n", "\n"]], "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization.get_regularization_term": [[181, 201], ["NotImplementedError", "cls._get_max_ent", "torch.norm", "cls._get_max_ent_minus"], "methods", ["home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization._get_max_ent", "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.Regularization._get_max_ent_minus"], ["", "@", "classmethod", "\n", "def", "get_regularization_term", "(", "cls", ",", "inf_scores", ":", "torch", ".", "Tensor", ",", "norm", ":", "float", "=", "2.0", ",", "\n", "optim_method", ":", "str", "=", "'max_ent'", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Compute the regularization term given a batch of information scores\n        :param inf_scores: tensor holding a batch of information scores\n        :param norm: defines which norm to use (1 or 2)\n        :param optim_method: Define optimization method (possible methods: \"min_ent\", \"max_ent\", \"max_ent_minus\",\n         \"normalized\")\n        :return:\n        \"\"\"", "\n", "\n", "if", "optim_method", "==", "'max_ent'", ":", "\n", "            ", "return", "cls", ".", "_get_max_ent", "(", "inf_scores", ",", "norm", ")", "\n", "", "elif", "optim_method", "==", "'min_ent'", ":", "\n", "            ", "return", "torch", ".", "norm", "(", "inf_scores", ",", "p", "=", "norm", ")", "\n", "", "elif", "optim_method", "==", "'max_ent_minus'", ":", "\n", "            ", "return", "cls", ".", "_get_max_ent_minus", "(", "inf_scores", ",", "norm", ")", "\n", "\n", "", "raise", "NotImplementedError", "(", "f'\"{optim_method}\" is unknown'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.itaigat_removing-bias-in-multi-modal-classifiers.None.regularization.RegParameters.__init__": [[207, 215], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "lambda_", ":", "float", "=", "1e-10", ",", "norm", ":", "float", "=", "2.0", ",", "estimation", ":", "str", "=", "'ent'", ",", "\n", "optim_method", ":", "str", "=", "'max_ent'", ",", "n_samples", ":", "int", "=", "10", ",", "grad", ":", "bool", "=", "True", ")", ":", "\n", "        ", "self", ".", "lambda_", "=", "lambda_", "\n", "self", ".", "norm", "=", "norm", "\n", "self", ".", "estimation", "=", "estimation", "\n", "self", ".", "optim_method", "=", "optim_method", "\n", "self", ".", "n_samples", "=", "n_samples", "\n", "self", ".", "grad", "=", "grad", "\n", "", "", ""]]}