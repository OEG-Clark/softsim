{"home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.None.main.main": [[26, 184], ["configuration.config.base_parser", "logging.config.fileConfig", "logging.config.fileConfig", "logging.getLogger", "logging.getLogger", "os.makedirs", "logging.FileHandler", "logging.FileHandler", "logging.Formatter", "logging.Formatter", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "torch.utils.tensorboard.SummaryWriter", "logging.getLogger.info", "torch.manual_seed", "numpy.random.seed", "random.seed", "logging.getLogger.info", "torch.nn.CrossEntropyLoss", "utils.method_manager.select_method", "logging.getLogger.info", "collections.defaultdict", "time.time", "range", "numpy.save", "numpy.mean", "numpy.array", "np.array.reshape().mean().reshape", "range", "numpy.mean", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "logging.getLogger.info", "torch.utils.tensorboard.SummaryWriter.close", "torch.cuda.is_available", "torch.device", "torch.device", "print", "print", "print", "logging.getLogger.info", "dict", "utils.data_loader.get_train_datalist", "utils.data_loader.get_test_datalist", "logging.getLogger.info", "utils.method_manager.select_method.set_current_dataset", "logging.getLogger.info", "logging.getLogger.info", "utils.method_manager.select_method.after_task", "task_records[].append", "task_records[].append", "logging.getLogger.info", "torch.utils.tensorboard.SummaryWriter.add_scalar", "time.time", "range", "task_records[].append", "random.shuffle", "random.shuffle", "utils.method_manager.select_method.before_task", "utils.method_manager.select_method.before_task", "utils.method_manager.select_method.train", "task_records[].append", "np.array.reshape().mean", "logging.getLogger.info", "logging.getLogger.info", "utils.method_manager.select_method.train", "utils.method_manager.select_method.update_memory", "utils.method_manager.select_method.set_current_dataset", "logging.getLogger.info", "utils.method_manager.select_method.train", "utils.method_manager.select_method.after_task", "numpy.mean", "forget_k.append", "forget_k.append", "numpy.mean", "numpy.std", "np.array.reshape", "cls_acc[].max", "range", "len"], "function", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.configuration.config.base_parser", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.method_manager.select_method", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.get_train_datalist", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.get_test_datalist", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.set_current_dataset", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.joint.Joint.after_task", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.joint.Joint.before_task", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.joint.Joint.before_task", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.joint.Joint.update_memory", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.set_current_dataset", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.joint.Joint.after_task"], ["def", "main", "(", ")", ":", "\n", "    ", "args", "=", "config", ".", "base_parser", "(", ")", "\n", "\n", "# args.debug = True # For debug mode", "\n", "if", "args", ".", "debug", ":", "\n", "        ", "args", ".", "n_epoch", "=", "1", "\n", "\n", "# Save file name", "\n", "", "tr_names", "=", "\"\"", "\n", "for", "trans", "in", "args", ".", "transforms", ":", "# multiple choices: cutmix, cutout, randaug, autoaug", "\n", "        ", "tr_names", "+=", "\"_\"", "+", "trans", "\n", "", "save_path", "=", "f\"{args.dataset}/{args.mode}_cls{args.n_cls_a_task}_{args.mem_manage}_{args.stream_env}_epoch{args.n_epoch}_lr{args.lr}\"", "f\"_msz{args.memory_size}_rnd{args.rnd_seed}{tr_names} \"", "\n", "logging", ".", "config", ".", "fileConfig", "(", "\"./configuration/logging.conf\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "os", ".", "makedirs", "(", "f\"logs/{args.dataset}\"", ",", "exist_ok", "=", "True", ")", "\n", "fileHandler", "=", "logging", ".", "FileHandler", "(", "\"logs/{}.log\"", ".", "format", "(", "save_path", ")", ",", "mode", "=", "\"w\"", ")", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "\n", "\"[%(levelname)s] %(filename)s:%(lineno)d > %(message)s\"", "\n", ")", "\n", "fileHandler", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "fileHandler", ")", "\n", "\n", "writer", "=", "SummaryWriter", "(", "\"tensorboard\"", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "args", ".", "debug", "is", "False", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "", "logger", ".", "info", "(", "f\"Set the device ({device})\"", ")", "\n", "\n", "# Fix the random seeds", "\n", "# https://hoya012.github.io/blog/reproducible_pytorch/", "\n", "torch", ".", "manual_seed", "(", "args", ".", "rnd_seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "rnd_seed", ")", "\n", "random", ".", "seed", "(", "args", ".", "rnd_seed", ")", "\n", "\n", "logger", ".", "info", "(", "f\"[1] Select a CIL method ({args.mode})\"", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "\"mean\"", ")", "\n", "n_classes", "=", "30", "\n", "method", "=", "select_method", "(", "\n", "args", ",", "criterion", ",", "device", ",", "n_classes", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "f\"[2] Incrementally training {args.n_tasks} tasks\"", ")", "\n", "task_records", "=", "defaultdict", "(", "list", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "# start to train each tasks", "\n", "for", "cur_iter", "in", "range", "(", "args", ".", "n_tasks", ")", ":", "\n", "        ", "if", "args", ".", "mode", "==", "\"joint\"", "and", "cur_iter", ">", "0", ":", "\n", "            ", "return", "\n", "", "print", "(", "\"\\n\"", "+", "\"#\"", "*", "50", ")", "\n", "print", "(", "f\"# Task {cur_iter} iteration\"", ")", "\n", "print", "(", "\"#\"", "*", "50", "+", "\"\\n\"", ")", "\n", "\n", "logger", ".", "info", "(", "\"[2-1] Prepare a datalist for the current task\"", ")", "\n", "task_acc", "=", "0.0", "\n", "eval_dict", "=", "dict", "(", ")", "\n", "\n", "# get datalist", "\n", "cur_train_datalist", "=", "get_train_datalist", "(", "args", ",", "cur_iter", ")", "\n", "cur_test_datalist", "=", "get_test_datalist", "(", "args", ",", "args", ".", "exp_name", ",", "cur_iter", ")", "\n", "# Reduce datalist in Debug mode", "\n", "if", "args", ".", "debug", ":", "\n", "            ", "random", ".", "shuffle", "(", "cur_train_datalist", ")", "\n", "random", ".", "shuffle", "(", "cur_test_datalist", ")", "\n", "cur_train_datalist", "=", "cur_train_datalist", "[", ":", "2560", "]", "\n", "cur_test_datalist", "=", "cur_test_datalist", "[", ":", "2560", "]", "\n", "\n", "", "logger", ".", "info", "(", "\"[2-2] Set environment for the current task\"", ")", "\n", "method", ".", "set_current_dataset", "(", "cur_train_datalist", ",", "cur_test_datalist", ")", "\n", "# Increment known class for current task iteration.", "\n", "if", "args", ".", "mode", "==", "\"bic\"", "or", "args", ".", "mode", "==", "\"gdumb\"", ":", "\n", "            ", "method", ".", "before_task", "(", "datalist", "=", "cur_train_datalist", ",", "init_model", "=", "False", ",", "init_opt", "=", "True", ",", "cur_iter", "=", "cur_iter", ")", "\n", "", "else", ":", "\n", "            ", "method", ".", "before_task", "(", "datalist", "=", "cur_train_datalist", ",", "init_model", "=", "False", ",", "init_opt", "=", "True", ")", "\n", "\n", "# The way to handle streamed samles", "\n", "", "logger", ".", "info", "(", "f\"[2-3] Start to train under {args.stream_env}\"", ")", "\n", "if", "args", ".", "stream_env", "==", "\"offline\"", ":", "\n", "# Offline Train", "\n", "            ", "task_acc", ",", "eval_dict", "=", "method", ".", "train", "(", "\n", "cur_iter", "=", "cur_iter", ",", "\n", "n_epoch", "=", "args", ".", "n_epoch", ",", "\n", "batch_size", "=", "args", ".", "batchsize", ",", "\n", "n_worker", "=", "args", ".", "n_worker", ",", "\n", ")", "\n", "if", "args", ".", "mode", "==", "\"joint\"", ":", "\n", "                ", "logger", ".", "info", "(", "f\"joint accuracy: {task_acc}\"", ")", "\n", "", "", "elif", "args", ".", "stream_env", "==", "\"online\"", ":", "\n", "# Online Train", "\n", "            ", "logger", ".", "info", "(", "\"Train over streamed data once\"", ")", "\n", "method", ".", "train", "(", "\n", "cur_iter", "=", "cur_iter", ",", "\n", "n_epoch", "=", "1", ",", "\n", "batch_size", "=", "args", ".", "batchsize", ",", "\n", "n_worker", "=", "args", ".", "n_worker", ",", "\n", ")", "\n", "\n", "method", ".", "update_memory", "(", "cur_iter", ")", "\n", "\n", "# No stremed training data, train with only memory_list", "\n", "method", ".", "set_current_dataset", "(", "[", "]", ",", "cur_test_datalist", ")", "\n", "\n", "logger", ".", "info", "(", "\"Train over memory\"", ")", "\n", "task_acc", ",", "eval_dict", "=", "method", ".", "train", "(", "\n", "cur_iter", "=", "cur_iter", ",", "\n", "n_epoch", "=", "args", ".", "n_epoch", ",", "\n", "batch_size", "=", "args", ".", "batchsize", ",", "\n", "n_worker", "=", "args", ".", "n_worker", ",", "\n", ")", "\n", "\n", "method", ".", "after_task", "(", "cur_iter", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"[2-4] Update the information for the current task\"", ")", "\n", "method", ".", "after_task", "(", "cur_iter", ")", "\n", "task_records", "[", "\"task_acc\"", "]", ".", "append", "(", "task_acc", ")", "\n", "# task_records['cls_acc'][k][j] = break down j-class accuracy from 'task_acc'", "\n", "task_records", "[", "\"cls_acc\"", "]", ".", "append", "(", "eval_dict", "[", "\"cls_acc\"", "]", ")", "\n", "if", "cur_iter", ">", "0", ":", "\n", "            ", "task_records", "[", "\"bwt_list\"", "]", ".", "append", "(", "np", ".", "mean", "(", "\n", "[", "task_records", "[", "\"task_acc\"", "]", "[", "i", "+", "1", "]", "-", "task_records", "[", "\"task_acc\"", "]", "[", "i", "]", "for", "i", "in", "\n", "range", "(", "len", "(", "task_records", "[", "\"task_acc\"", "]", ")", "-", "1", ")", "]", ")", ")", "\n", "# Notify to NSML", "\n", "", "logger", ".", "info", "(", "\"[2-5] Report task result\"", ")", "\n", "writer", ".", "add_scalar", "(", "\"Metrics/TaskAcc\"", ",", "task_acc", ",", "cur_iter", ")", "\n", "", "np", ".", "save", "(", "f\"results/{save_path}.npy\"", ",", "task_records", "[", "\"task_acc\"", "]", ")", "\n", "# Total time (T)", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "# Accuracy (A)", "\n", "A_avg", "=", "np", ".", "mean", "(", "task_records", "[", "\"task_acc\"", "]", ")", "\n", "A_last", "=", "task_records", "[", "\"task_acc\"", "]", "[", "args", ".", "n_tasks", "-", "1", "]", "\n", "\n", "# Forgetting (F)", "\n", "acc_arr", "=", "np", ".", "array", "(", "task_records", "[", "\"cls_acc\"", "]", ")", "\n", "# cls_acc = (k, j), acc for j at k", "\n", "cls_acc", "=", "acc_arr", ".", "reshape", "(", "-", "1", ",", "args", ".", "n_cls_a_task", ")", ".", "mean", "(", "1", ")", ".", "reshape", "(", "args", ".", "n_tasks", ",", "-", "1", ")", "\n", "for", "k", "in", "range", "(", "args", ".", "n_tasks", ")", ":", "\n", "        ", "forget_k", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "args", ".", "n_tasks", ")", ":", "\n", "            ", "if", "j", "<", "k", ":", "\n", "                ", "forget_k", ".", "append", "(", "cls_acc", "[", ":", "k", ",", "j", "]", ".", "max", "(", ")", "-", "cls_acc", "[", "k", ",", "j", "]", ")", "\n", "", "else", ":", "\n", "                ", "forget_k", ".", "append", "(", "None", ")", "\n", "", "", "task_records", "[", "\"forget\"", "]", ".", "append", "(", "forget_k", ")", "\n", "", "F_last", "=", "np", ".", "mean", "(", "task_records", "[", "\"forget\"", "]", "[", "-", "1", "]", "[", ":", "-", "1", "]", ")", "\n", "\n", "# Intrasigence (I)", "\n", "I_last", "=", "args", ".", "joint_acc", "-", "A_last", "\n", "\n", "logger", ".", "info", "(", "f\"======== Summary =======\"", ")", "\n", "logger", ".", "info", "(", "f\"Total time {duration}, Avg: {duration / args.n_tasks}s\"", ")", "\n", "logger", ".", "info", "(", "f'BWT: {np.mean(task_records[\"bwt_list\"])}, std: {np.std(task_records[\"bwt_list\"])}'", ")", "\n", "logger", ".", "info", "(", "f\"A_last {A_last} | A_avg {A_avg} | F_last {F_last} | I_last {I_last}\"", ")", "\n", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.kd_manager.KdManager.__init__": [[23, 25], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "teacher_model", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.kd_manager.KdManager.update_teacher": [[26, 28], ["copy.deepcopy"], "methods", ["None"], ["", "def", "update_teacher", "(", "self", ",", "model", ")", ":", "\n", "        ", "self", ".", "teacher_model", "=", "copy", ".", "deepcopy", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.kd_manager.KdManager.get_kd_loss": [[29, 37], ["kd_manager.loss_fn_kd", "torch.no_grad", "kd_manager.KdManager.teacher_model.forward", "kd_manager.KdManager.size"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.kd_manager.loss_fn_kd", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrectionLayer.forward"], ["", "def", "get_kd_loss", "(", "self", ",", "cur_model_logits", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "teacher_model", "is", "not", "None", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "prev_model_logits", "=", "self", ".", "teacher_model", ".", "forward", "(", "x", ")", "\n", "", "dist_loss", "=", "loss_fn_kd", "(", "cur_model_logits", "[", ":", ",", ":", "prev_model_logits", ".", "size", "(", "1", ")", "]", ",", "prev_model_logits", ")", "\n", "", "else", ":", "\n", "            ", "dist_loss", "=", "0", "\n", "", "return", "dist_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.kd_manager.loss_fn_kd": [[14, 20], ["torch.nn.functional.log_softmax", "torch.nn.functional.softmax"], "function", ["None"], ["def", "loss_fn_kd", "(", "scores", ",", "target_scores", ",", "T", "=", "2.", ")", ":", "\n", "    ", "log_scores_norm", "=", "F", ".", "log_softmax", "(", "scores", "/", "T", ",", "dim", "=", "1", ")", "\n", "targets_norm", "=", "F", ".", "softmax", "(", "target_scores", "/", "T", ",", "dim", "=", "1", ")", "\n", "# Calculate distillation loss (see e.g., Li and Hoiem, 2017)", "\n", "kd_loss", "=", "(", "-", "1", "*", "targets_norm", "*", "log_scores_norm", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "mean", "(", ")", "*", "T", "**", "2", "\n", "return", "kd_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.method_manager.select_method": [[20, 92], ["vars", "logger.info", "print", "print", "print", "print", "methods.finetune.Finetune", "methods.finetune.Finetune", "methods.rainbow_keywords.RK", "methods.icarl.ICaRL", "methods.regularization.EWC", "methods.regularization.RWalk", "methods.joint.Joint", "methods.bic.BiasCorrection", "NotImplementedError"], "function", ["None"], ["def", "select_method", "(", "args", ",", "criterion", ",", "device", ",", "n_classes", ")", ":", "\n", "    ", "kwargs", "=", "vars", "(", "args", ")", "\n", "if", "args", ".", "mode", "==", "\"finetune\"", ":", "\n", "        ", "method", "=", "Finetune", "(", "\n", "criterion", "=", "criterion", ",", "\n", "device", "=", "device", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"native_rehearsal\"", ":", "\n", "        ", "method", "=", "Finetune", "(", "\n", "criterion", "=", "criterion", ",", "\n", "device", "=", "device", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"rainbow_keywords\"", ":", "\n", "        ", "method", "=", "RK", "(", "\n", "criterion", "=", "criterion", ",", "\n", "device", "=", "device", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "**", "kwargs", "\n", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"icarl\"", ":", "\n", "        ", "method", "=", "ICaRL", "(", "\n", "criterion", "=", "criterion", ",", "\n", "device", "=", "device", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "**", "kwargs", "\n", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"ewc\"", ":", "\n", "        ", "method", "=", "EWC", "(", "\n", "criterion", "=", "criterion", ",", "\n", "device", "=", "device", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "\n", "", "elif", "args", ".", "mode", "==", "\"rwalk\"", ":", "\n", "        ", "method", "=", "RWalk", "(", "\n", "criterion", "=", "criterion", ",", "\n", "device", "=", "device", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"joint\"", ":", "\n", "        ", "method", "=", "Joint", "(", "\n", "criterion", "=", "criterion", ",", "\n", "device", "=", "device", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "", "elif", "args", ".", "mode", "==", "\"bic\"", ":", "\n", "        ", "method", "=", "BiasCorrection", "(", "\n", "criterion", "=", "criterion", ",", "\n", "device", "=", "device", ",", "\n", "n_classes", "=", "n_classes", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "\"Choose the args.mode in \"", "\n", "\"[finetune, native_rehearsal, icarl, rainbow_keywords, ewc, rwalk, bic, joint,gdumb]\"", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"CIL Scenario: {args.mode}\"", ")", "\n", "print", "(", "f\"n_tasks: {args.n_tasks}\"", ")", "\n", "print", "(", "f\"n_init_cls: {args.n_init_cls}\"", ")", "\n", "print", "(", "f\"n_cls_a_task: {args.n_cls_a_task}\"", ")", "\n", "print", "(", "f\"total cls: {args.n_tasks * args.n_cls_a_task}\"", ")", "\n", "\n", "return", "method", "\n", "", ""]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.SpeechDataset.__init__": [[27, 45], ["torch.utils.data.Dataset.__init__", "warnings.catch_warnings", "warnings.simplefilter", "torchaudio.transforms.MFCC"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_frame", ":", "pd", ".", "DataFrame", ",", "dataset", ":", "str", ",", "is_training", "=", "True", ",", "transform", "=", "None", ")", ":", "\n", "        ", "super", "(", "SpeechDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\"\"\"\n        Args:\n            data_frame: pd.DataFrame\n            filename: train_filename or valid_filename\n            is_training: True or False\n        \"\"\"", "\n", "self", ".", "data_frame", "=", "data_frame", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "sampling_rate", "=", "16000", "\n", "self", ".", "sample_length", "=", "16000", "\n", "self", ".", "is_training", "=", "is_training", "\n", "self", ".", "bins", "=", "40", "\n", "with", "warnings", ".", "catch_warnings", "(", ")", ":", "\n", "            ", "warnings", ".", "simplefilter", "(", "\"ignore\"", ")", "\n", "self", ".", "mfcc", "=", "MFCC", "(", "sample_rate", "=", "self", ".", "sampling_rate", ",", "n_mfcc", "=", "self", ".", "bins", ",", "log_mels", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.SpeechDataset.__len__": [[46, 48], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data_frame", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.SpeechDataset.load_audio": [[49, 61], ["torchaudio.load", "torch.pad", "torch.pad", "int", "torch.pad", "torch.pad", "torch.randint().item", "torch.randint().item", "torch.randint().item", "torch.randint().item", "waveform.narrow.narrow.narrow", "torch.randint", "torch.randint", "torch.randint", "torch.randint"], "methods", ["None"], ["", "def", "load_audio", "(", "self", ",", "speech_path", ")", ":", "\n", "        ", "waveform", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "speech_path", ")", "\n", "if", "waveform", ".", "shape", "[", "1", "]", "<", "self", ".", "sample_length", ":", "\n", "# padding if the audio length is smaller than samping length.", "\n", "            ", "waveform", "=", "F", ".", "pad", "(", "waveform", ",", "[", "0", ",", "self", ".", "sample_length", "-", "waveform", ".", "shape", "[", "1", "]", "]", ")", "\n", "\n", "", "if", "self", ".", "is_training", ":", "\n", "            ", "pad_length", "=", "int", "(", "waveform", ".", "shape", "[", "1", "]", "*", "0.1", ")", "\n", "waveform", "=", "F", ".", "pad", "(", "waveform", ",", "[", "pad_length", ",", "pad_length", "]", ")", "\n", "offset", "=", "torch", ".", "randint", "(", "0", ",", "waveform", ".", "shape", "[", "1", "]", "-", "self", ".", "sample_length", "+", "1", ",", "size", "=", "(", "1", ",", ")", ")", ".", "item", "(", ")", "\n", "waveform", "=", "waveform", ".", "narrow", "(", "1", ",", "offset", ",", "self", ".", "sample_length", ")", "\n", "", "return", "waveform", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.SpeechDataset.__getitem__": [[62, 83], ["dict", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "torch.is_tensor", "data_loader.SpeechDataset.data_frame.iloc[].get", "os.path.join", "data_loader.SpeechDataset.load_audio", "data_loader.SpeechDataset.mfcc", "idx.tolist.tolist.tolist", "data_loader.SpeechDataset.transform", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "utils.data_augmentation.spec_augmentation"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.SpeechDataset.load_audio", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_augmentation.spec_augmentation"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "sample", "=", "dict", "(", ")", "\n", "if", "torch", ".", "is_tensor", "(", "idx", ")", ":", "\n", "            ", "idx", "=", "idx", ".", "tolist", "(", ")", "\n", "\n", "", "file_name", "=", "self", ".", "data_frame", ".", "iloc", "[", "idx", "]", "[", "\"file_name\"", "]", "\n", "label", "=", "self", ".", "data_frame", ".", "iloc", "[", "idx", "]", ".", "get", "(", "\"label\"", ",", "-", "1", ")", "\n", "\n", "audio_path", "=", "os", ".", "path", ".", "join", "(", "\"/home/xiaoyang/Dev/kws-efficient-cl/dataset/data\"", ",", "file_name", ")", "\n", "waveform", "=", "self", ".", "load_audio", "(", "audio_path", ")", "\n", "if", "self", ".", "transform", "and", "not", "self", ".", "is_training", ":", "\n", "            ", "waveform", "=", "self", ".", "transform", "(", "samples", "=", "waveform", ",", "sample_rate", "=", "self", ".", "sampling_rate", ")", "\n", "waveform", "=", "torch", ".", "as_tensor", "(", "waveform", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "", "waveform", "=", "self", ".", "mfcc", "(", "waveform", ")", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "if", "self", ".", "is_training", "and", "\"specaug\"", "in", "self", ".", "transform", ":", "\n", "                ", "waveform", "=", "spec_augmentation", "(", "waveform", ")", "\n", "", "", "sample", "[", "\"waveform\"", "]", "=", "waveform", "\n", "sample", "[", "\"label\"", "]", "=", "label", "\n", "sample", "[", "\"file_name\"", "]", "=", "file_name", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.SpeechDataset.get_audio_class": [[84, 86], ["None"], "methods", ["None"], ["", "def", "get_audio_class", "(", "self", ",", "y", ")", ":", "\n", "        ", "return", "self", ".", "data_frame", "[", "self", ".", "data_frame", "[", "\"label\"", "]", "==", "y", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.TimeMask.__init__": [[150, 153], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "min_band_part", "=", "0.0", ",", "max_band_part", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "min_band_part", "=", "min_band_part", "\n", "self", ".", "max_band_part", "=", "max_band_part", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.TimeMask.__call__": [[154, 167], ["random.randint", "random.randint", "samples.clone", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "int", "int"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "samples", ",", "sample_rate", ")", ":", "\n", "        ", "num_samples", "=", "samples", ".", "shape", "[", "-", "1", "]", "\n", "t", "=", "random", ".", "randint", "(", "\n", "int", "(", "num_samples", "*", "self", ".", "min_band_part", ")", ",", "\n", "int", "(", "num_samples", "*", "self", ".", "max_band_part", ")", ",", "\n", ")", "\n", "t0", "=", "random", ".", "randint", "(", "\n", "0", ",", "num_samples", "-", "t", "\n", ")", "\n", "new_samples", "=", "samples", ".", "clone", "(", ")", "\n", "mask", "=", "torch", ".", "zeros", "(", "t", ")", "\n", "new_samples", "[", "...", ",", "t0", ":", "t0", "+", "t", "]", "*=", "mask", "\n", "return", "new_samples", "\n", "", "", ""]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.get_train_datalist": [[88, 117], ["range", "data_loader.get_train_collection_name", "pandas.read_json().to_dict", "logger.info", "data_loader.get_train_collection_name", "pandas.read_json().to_dict", "logger.info", "pandas.read_json", "pandas.read_json", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.get_train_collection_name", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.get_train_collection_name"], ["", "", "def", "get_train_datalist", "(", "args", ",", "cur_iter", ":", "int", ")", "->", "List", ":", "\n", "    ", "if", "args", ".", "mode", "==", "\"joint\"", ":", "\n", "        ", "datalist", "=", "[", "]", "\n", "for", "cur_iter_", "in", "range", "(", "args", ".", "n_tasks", ")", ":", "\n", "            ", "collection_name", "=", "get_train_collection_name", "(", "\n", "dataset", "=", "args", ".", "dataset", ",", "\n", "exp", "=", "args", ".", "exp_name", ",", "\n", "rnd", "=", "args", ".", "rnd_seed", ",", "\n", "n_cls", "=", "args", ".", "n_cls_a_task", ",", "\n", "iter", "=", "cur_iter_", ",", "\n", ")", "\n", "datalist", "+=", "pd", ".", "read_json", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "data_root", ",", "f\"{collection_name}.json\"", ")", "\n", ")", ".", "to_dict", "(", "orient", "=", "\"records\"", ")", "\n", "logger", ".", "info", "(", "f\"[Train] Get datalist from {collection_name}.json\"", ")", "\n", "", "", "else", ":", "\n", "        ", "collection_name", "=", "get_train_collection_name", "(", "\n", "dataset", "=", "args", ".", "dataset", ",", "\n", "exp", "=", "args", ".", "exp_name", ",", "\n", "rnd", "=", "args", ".", "rnd_seed", ",", "\n", "n_cls", "=", "args", ".", "n_cls_a_task", ",", "\n", "iter", "=", "cur_iter", ",", "\n", ")", "\n", "\n", "datalist", "=", "pd", ".", "read_json", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_root", ",", "f\"{collection_name}.json\"", ")", "\n", ")", ".", "to_dict", "(", "orient", "=", "\"records\"", ")", "\n", "logger", ".", "info", "(", "f\"[Train] Get datalist from {collection_name}.json\"", ")", "\n", "\n", "", "return", "datalist", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.get_train_collection_name": [[119, 124], ["None"], "function", ["None"], ["", "def", "get_train_collection_name", "(", "dataset", ",", "exp", ",", "rnd", ",", "n_cls", ",", "iter", ")", ":", "\n", "    ", "collection_name", "=", "\"{dataset}_train_{exp}_rand{rnd}_cls{n_cls}_task{iter}\"", ".", "format", "(", "\n", "dataset", "=", "dataset", ",", "exp", "=", "exp", ",", "rnd", "=", "rnd", ",", "n_cls", "=", "n_cls", ",", "iter", "=", "iter", "\n", ")", "\n", "return", "collection_name", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_loader.get_test_datalist": [[126, 147], ["list", "pandas.read_json().to_dict", "logger.info", "range", "pandas.read_json", "os.path.join"], "function", ["None"], ["", "def", "get_test_datalist", "(", "args", ",", "exp_name", ":", "str", ",", "cur_iter", ":", "int", ")", "->", "List", ":", "\n", "    ", "if", "exp_name", "is", "None", ":", "\n", "        ", "exp_name", "=", "args", ".", "exp_name", "\n", "\n", "", "if", "exp_name", "==", "\"disjoint\"", ":", "\n", "# merge current and all previous tasks", "\n", "        ", "tasks", "=", "list", "(", "range", "(", "cur_iter", "+", "1", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "datalist", "=", "[", "]", "\n", "for", "iter_", "in", "tasks", ":", "\n", "        ", "collection_name", "=", "\"{dataset}_test_rand{rnd}_cls{n_cls}_task{iter}\"", ".", "format", "(", "\n", "dataset", "=", "args", ".", "dataset", ",", "rnd", "=", "args", ".", "rnd_seed", ",", "n_cls", "=", "args", ".", "n_cls_a_task", ",", "iter", "=", "iter_", "\n", ")", "\n", "datalist", "+=", "pd", ".", "read_json", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "data_root", ",", "f\"{collection_name}.json\"", ")", "\n", ")", ".", "to_dict", "(", "orient", "=", "\"records\"", ")", "\n", "logger", ".", "info", "(", "f\"[Test ] Get datalist from {collection_name}.json\"", ")", "\n", "\n", "", "return", "datalist", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_augmentation.mixup_data": [[14, 30], ["numpy.random.beta", "x.size", "torch.randperm().cuda", "torch.randperm", "torch.randperm"], "function", ["None"], ["def", "mixup_data", "(", "x", ",", "y", ",", "alpha", "=", "1.0", ",", "use_cuda", "=", "True", ")", ":", "\n", "    ", "'''Returns mixed inputs, pairs of targets, and lambda'''", "\n", "if", "alpha", ">", "0", ":", "\n", "        ", "lam", "=", "np", ".", "random", ".", "beta", "(", "alpha", ",", "alpha", ")", "\n", "", "else", ":", "\n", "        ", "lam", "=", "1", "\n", "\n", "", "batch_size", "=", "x", ".", "size", "(", ")", "[", "0", "]", "\n", "if", "use_cuda", ":", "\n", "        ", "index", "=", "torch", ".", "randperm", "(", "batch_size", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "torch", ".", "randperm", "(", "batch_size", ")", "\n", "\n", "", "mixed_x", "=", "lam", "*", "x", "+", "(", "1", "-", "lam", ")", "*", "x", "[", "index", ",", ":", "]", "\n", "y_a", ",", "y_b", "=", "y", ",", "y", "[", "index", "]", "\n", "return", "mixed_x", ",", "y_a", ",", "y_b", ",", "lam", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_augmentation.spec_augmentation": [[32, 64], ["x.size", "range", "range", "random.randint", "random.randint", "min", "random.randint", "random.randint", "min"], "function", ["None"], ["", "def", "spec_augmentation", "(", "x", ",", "\n", "num_time_mask", "=", "2", ",", "\n", "num_freq_mask", "=", "2", ",", "\n", "max_time", "=", "10", ",", "\n", "max_freq", "=", "12", ")", ":", "\n", "    ", "\"\"\"perform spec augmentation\n    Args:\n        x: input feature, T * F 2D\n        num_t_mask: number of time mask to apply\n        num_f_mask: number of freq mask to apply\n        max_t: max width of time mask\n        max_f: max width of freq mask\n    Returns:\n        augmented feature\n    \"\"\"", "\n", "_", ",", "max_freq_channel", ",", "max_frames", "=", "x", ".", "size", "(", ")", "\n", "\n", "# time mask", "\n", "for", "i", "in", "range", "(", "num_time_mask", ")", ":", "\n", "        ", "start", "=", "random", ".", "randint", "(", "0", ",", "max_frames", "-", "1", ")", "\n", "length", "=", "random", ".", "randint", "(", "1", ",", "max_time", ")", "\n", "end", "=", "min", "(", "max_frames", ",", "start", "+", "length", ")", "\n", "x", "[", ":", ",", ":", ",", "start", ":", "end", "]", "=", "0", "\n", "\n", "# freq mask", "\n", "", "for", "i", "in", "range", "(", "num_freq_mask", ")", ":", "\n", "        ", "start", "=", "random", ".", "randint", "(", "0", ",", "max_freq_channel", "-", "1", ")", "\n", "length", "=", "random", ".", "randint", "(", "1", ",", "max_freq", ")", "\n", "end", "=", "min", "(", "max_freq_channel", ",", "start", "+", "length", ")", "\n", "x", "[", ":", ",", "start", ":", "end", ",", ":", "]", "=", "0", "\n", "\n", "", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.train_utils.select_optimizer": [[13, 41], ["torch.optim.Adam", "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts", "model.parameters", "torch_optimizer.RAdam", "torch.optim.lr_scheduler.ExponentialLR", "model.parameters", "torch.optim.SGD", "NotImplementedError", "torch.optim.lr_scheduler.MultiStepLR", "NotImplementedError", "model.parameters"], "function", ["None"], ["def", "select_optimizer", "(", "opt_name", ",", "lr", ",", "model", ",", "sched_name", "=", "\"cos\"", ")", ":", "\n", "    ", "if", "opt_name", "==", "\"adam\"", ":", "\n", "        ", "opt", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "weight_decay", "=", "1e-6", ")", "\n", "", "elif", "opt_name", "==", "\"radam\"", ":", "\n", "        ", "opt", "=", "torch_optimizer", ".", "RAdam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "weight_decay", "=", "0.00001", ")", "\n", "", "elif", "opt_name", "==", "\"sgd\"", ":", "\n", "        ", "opt", "=", "optim", ".", "SGD", "(", "\n", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "momentum", "=", "0.9", ",", "nesterov", "=", "True", ",", "weight_decay", "=", "1e-4", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Please select the opt_name [adam, sgd]\"", ")", "\n", "\n", "", "if", "sched_name", "==", "\"cos\"", ":", "\n", "        ", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "CosineAnnealingWarmRestarts", "(", "\n", "opt", ",", "T_0", "=", "1", ",", "T_mult", "=", "2", ",", "eta_min", "=", "lr", "*", "0.01", "\n", ")", "\n", "", "elif", "sched_name", "==", "\"anneal\"", ":", "\n", "        ", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "ExponentialLR", "(", "opt", ",", "1", "/", "1.1", ",", "last_epoch", "=", "-", "1", ")", "\n", "", "elif", "sched_name", "==", "\"multistep\"", ":", "\n", "        ", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "\n", "opt", ",", "milestones", "=", "[", "30", ",", "60", ",", "80", ",", "90", "]", ",", "gamma", "=", "0.1", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "\"Please select the sched_name [cos, anneal, multistep]\"", "\n", ")", "\n", "\n", "", "return", "opt", ",", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.train_utils.select_model": [[43, 60], ["model.MFCC_TCResnet", "model.MFCC_TCResnet"], "function", ["None"], ["", "def", "select_model", "(", "model_name", ",", "total_class_num", "=", "None", ")", ":", "\n", "# load the model.", "\n", "    ", "config", "=", "{", "\n", "\"tcresnet8\"", ":", "[", "16", ",", "24", ",", "32", ",", "48", "]", ",", "\n", "\"tcresnet14\"", ":", "[", "16", ",", "24", ",", "24", ",", "32", ",", "32", ",", "48", ",", "48", "]", "\n", "}", "\n", "\n", "if", "model_name", "==", "\"tcresnet8\"", ":", "\n", "        ", "model", "=", "MFCC_TCResnet", "(", "bins", "=", "40", ",", "channels", "=", "config", "[", "model_name", "]", ",", "channel_scale", "=", "1", ",", "\n", "num_classes", "=", "total_class_num", ")", "\n", "", "elif", "model_name", "==", "\"tcresnet14\"", ":", "\n", "        ", "model", "=", "MFCC_TCResnet", "(", "bins", "=", "40", ",", "channels", "=", "config", "[", "model_name", "]", ",", "channel_scale", "=", "1", ",", "\n", "num_classes", "=", "total_class_num", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "None", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.test.test_bic.bias_forward": [[13, 34], ["round", "range", "torch.cat", "print", "out.append", "torch.cat.size", "input.size", "torch.cat.size", "input.size", "input.size", "input.size"], "function", ["None"], ["def", "bias_forward", "(", "input", ")", ":", "\n", "    ", "\"\"\"\n    forward bias correction layer.\n    input: the output of classification model\n    \"\"\"", "\n", "n_new_cls", "=", "3", "\n", "n_split", "=", "round", "(", "(", "input", ".", "size", "(", "1", ")", "-", "12", ")", "/", "n_new_cls", ")", "# TODO: as the task 0 is 12 classes more than the other tasks", "\n", "out", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_split", ")", ":", "\n", "        ", "sub_out", "=", "input", "[", ":", ",", "i", "*", "n_new_cls", "+", "12", ":", "(", "i", "+", "1", ")", "*", "n_new_cls", "+", "12", "]", "\n", "# Only for new classes", "\n", "if", "i", "==", "n_split", "-", "1", ":", "\n", "            ", "sub_out", "=", "input", "[", ":", ",", "i", "*", "n_new_cls", "+", "12", ":", "(", "i", "+", "1", ")", "*", "n_new_cls", "+", "12", "]", "\n", "", "assert", "n_split", "<", "6", "\n", "print", "(", "f\"i is {i}, n_split is {n_split}, input_size() is {input.size()}\"", ")", "\n", "if", "i", "==", "0", ":", "\n", "            ", "sub_out", "=", "input", "[", ":", ",", "0", ":", "(", "i", "+", "1", ")", "*", "n_new_cls", "+", "12", "]", "\n", "", "out", ".", "append", "(", "sub_out", ")", "\n", "", "ret", "=", "torch", ".", "cat", "(", "out", ",", "dim", "=", "1", ")", "\n", "assert", "ret", ".", "size", "(", "1", ")", "==", "input", ".", "size", "(", "1", ")", ",", "f\"final out: {ret.size()}, input size: {input.size()}\"", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.generate_json.readlines": [[14, 18], ["open", "f.read().splitlines", "f.read"], "function", ["None"], ["def", "readlines", "(", "datapath", ")", ":", "\n", "    ", "with", "open", "(", "datapath", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.generate_json.main": [[20, 84], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "generate_json.readlines", "generate_json.readlines", "random.seed", "random.shuffle", "range", "print", "range", "len", "open", "print", "print", "open.write", "open.close", "range", "total_list.append", "range", "total_list.append", "os.path.join.split", "json.dumps", "t_list.append", "t_list.append", "enumerate", "os.path.join", "dataset_list.append", "len", "class_encoding.get"], "function", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.generate_json.readlines", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.generate_json.readlines"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Input optional guidance for training\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dpath\"", ",", "default", "=", "\"./\"", ",", "type", "=", "str", ",", "help", "=", "\"The path of dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "\"Random seed number.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "\"gsc\"", ",", "help", "=", "\"[gsc]\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_tasks\"", ",", "type", "=", "int", ",", "default", "=", "6", ",", "help", "=", "\"The number of tasks\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_cls_a_task\"", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "\"The number of class of each task\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_init_cls\"", ",", "type", "=", "int", ",", "default", "=", "15", ",", "help", "=", "\"The number of classes of initial task\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--exp_name\"", ",", "type", "=", "str", ",", "default", "=", "\"disjoint\"", ",", "help", "=", "\"[disjoint, blurry]\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mode\"", ",", "type", "=", "str", ",", "default", "=", "\"train\"", ",", "help", "=", "\"[train, test]\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "data_path", "=", "args", ".", "dpath", "\n", "class_list_0", "=", "[", "\"four\"", ",", "\"marvin\"", ",", "\"on\"", ",", "\"sheila\"", ",", "\"cat\"", ",", "\"five\"", "]", "\n", "class_list_1", "=", "[", "\"three\"", ",", "\"stop\"", ",", "\"go\"", ",", "\"dog\"", ",", "\"one\"", ",", "\"eight\"", "]", "\n", "class_list_2", "=", "[", "\"down\"", ",", "\"no\"", ",", "\"nine\"", ",", "\"bed\"", ",", "\"wow\"", ",", "\"happy\"", "]", "\n", "class_list_3", "=", "[", "\"yes\"", ",", "\"up\"", ",", "\"tree\"", ",", "\"seven\"", ",", "\"six\"", ",", "\"two\"", "]", "\n", "class_list_4", "=", "[", "\"off\"", ",", "\"house\"", ",", "\"zero\"", ",", "\"left\"", ",", "\"right\"", ",", "\"bird\"", "]", "\n", "class_list", "=", "class_list_0", "+", "class_list_1", "+", "class_list_2", "+", "class_list_3", "+", "class_list_4", "\n", "train_filename", "=", "readlines", "(", "f\"{data_path}/splits/train.txt\"", ")", "\n", "valid_filename", "=", "readlines", "(", "f\"{data_path}/splits/valid.txt\"", ")", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "random", ".", "shuffle", "(", "class_list", ")", "\n", "total_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "args", ".", "n_tasks", ")", ":", "\n", "        ", "if", "i", "==", "0", ":", "\n", "            ", "t_list", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "args", ".", "n_init_cls", ")", ":", "\n", "                ", "t_list", ".", "append", "(", "class_list", "[", "j", "]", ")", "\n", "", "total_list", ".", "append", "(", "t_list", ")", "\n", "", "else", ":", "\n", "            ", "t_list", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "args", ".", "n_cls_a_task", ")", ":", "\n", "                ", "t_list", ".", "append", "(", "(", "class_list", "[", "j", "+", "args", ".", "n_init_cls", "+", "(", "i", "-", "1", ")", "*", "args", ".", "n_cls_a_task", "]", ")", ")", "\n", "", "total_list", ".", "append", "(", "t_list", ")", "\n", "\n", "", "", "print", "(", "total_list", ")", "\n", "label_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "total_list", ")", ")", ":", "\n", "        ", "class_list", "=", "total_list", "[", "i", "]", "\n", "label_list", "=", "label_list", "+", "class_list", "\n", "if", "args", ".", "mode", "==", "'train'", ":", "\n", "            ", "collection_name", "=", "\"collection/{dataset}_{mode}_{exp}_rand{rnd}_cls{n_cls}_task{iter}.json\"", ".", "format", "(", "\n", "dataset", "=", "args", ".", "dataset", ",", "mode", "=", "'train'", ",", "exp", "=", "args", ".", "exp_name", ",", "rnd", "=", "args", ".", "seed", ",", "n_cls", "=", "args", ".", "n_cls_a_task", ",", "iter", "=", "i", "\n", ")", "\n", "filename", "=", "train_filename", "\n", "", "else", ":", "\n", "            ", "collection_name", "=", "\"collection/{dataset}_test_rand{rnd}_cls{n_cls}_task{iter}.json\"", ".", "format", "(", "\n", "dataset", "=", "args", ".", "dataset", ",", "rnd", "=", "args", ".", "seed", ",", "n_cls", "=", "args", ".", "n_cls_a_task", ",", "iter", "=", "i", "\n", ")", "\n", "filename", "=", "valid_filename", "\n", "", "f", "=", "open", "(", "collection_name", ",", "'w'", ")", "\n", "class_encoding", "=", "{", "category", ":", "index", "for", "index", ",", "category", "in", "enumerate", "(", "label_list", ")", "}", "\n", "dataset_list", "=", "[", "]", "\n", "for", "path", "in", "filename", ":", "\n", "            ", "category", ",", "wave_name", "=", "path", ".", "split", "(", "\"/\"", ")", "\n", "if", "category", "in", "class_list", ":", "\n", "                ", "path", "=", "os", ".", "path", ".", "join", "(", "category", ",", "wave_name", ")", "\n", "dataset_list", ".", "append", "(", "[", "path", ",", "category", ",", "class_encoding", ".", "get", "(", "category", ")", "]", ")", "\n", "", "", "res", "=", "[", "{", "\"klass\"", ":", "item", "[", "1", "]", ",", "\"file_name\"", ":", "item", "[", "0", "]", ",", "\"label\"", ":", "item", "[", "2", "]", "}", "for", "item", "in", "dataset_list", "]", "\n", "\n", "print", "(", "\"Task ID is {}\"", ".", "format", "(", "i", ")", ")", "\n", "print", "(", "\"Total samples are {}\"", ".", "format", "(", "len", "(", "res", ")", ")", ")", "\n", "f", ".", "write", "(", "json", ".", "dumps", "(", "res", ")", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.check_path_existence": [[12, 14], ["path.exists"], "function", ["None"], ["def", "check_path_existence", "(", "path", ",", "name", ")", ":", "\n", "    ", "assert", "path", ".", "exists", "(", ")", ",", "(", "f\"{name} ({path}) does not exist!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.parse_arguments": [[16, 43], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "gsc.check_path_existence", "gsc.check_path_existence", "gsc.check_path_existence", "gsc.check_path_existence", "parser.parse_args.output_dir.exists", "len", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path", "parser.parse_args.output_dir.iterdir"], "function", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.check_path_existence", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.check_path_existence", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.check_path_existence", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.check_path_existence"], ["", "def", "parse_arguments", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "__doc__", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--input_dir\"", ",", "type", "=", "lambda", "p", ":", "Path", "(", "p", ")", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Directory as the result of `tar -zxvf <xxx.tar.gz>`.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_list_fullpath\"", ",", "type", "=", "lambda", "p", ":", "Path", "(", "p", ")", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Textfile which contains name of test wave files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--valid_list_fullpath\"", ",", "type", "=", "lambda", "p", ":", "Path", "(", "p", ")", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Textfile which contains name of validation wave files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_list_fullpath\"", ",", "type", "=", "lambda", "p", ":", "Path", "(", "p", ")", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Textfile which contains name of train wave files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "type", "=", "lambda", "p", ":", "Path", "(", "p", ")", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Directory which will contain the result dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--wanted_words\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Comma seperated words to be categorized as foreground. Default '' means take all.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# validation check", "\n", "check_path_existence", "(", "args", ".", "input_dir", ",", "\"Input directory\"", ")", "\n", "check_path_existence", "(", "args", ".", "test_list_fullpath", ",", "\"`test_list_fullpath`\"", ")", "\n", "check_path_existence", "(", "args", ".", "valid_list_fullpath", ",", "\"`valid_list_fullpath`\"", ")", "\n", "check_path_existence", "(", "args", ".", "train_list_fullpath", ",", "\"`valid_list_fullpath`\"", ")", "\n", "assert", "not", "args", ".", "output_dir", ".", "exists", "(", ")", "or", "len", "(", "[", "p", "for", "p", "in", "args", ".", "output_dir", ".", "iterdir", "(", ")", "]", ")", "==", "0", ",", "(", "\n", "f\"Output directory ({args.output_dir}) should be empty!\"", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.get_label_and_filename": [[45, 49], ["None"], "function", ["None"], ["", "def", "get_label_and_filename", "(", "p", ")", ":", "\n", "    ", "parts", "=", "p", ".", "parts", "\n", "label", ",", "filename", "=", "parts", "[", "-", "2", "]", ",", "parts", "[", "-", "1", "]", "\n", "return", "label", ",", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.is_valid_label": [[51, 58], ["None"], "function", ["None"], ["", "def", "is_valid_label", "(", "label", ",", "valid_labels", ")", ":", "\n", "    ", "if", "valid_labels", ":", "\n", "        ", "is_valid", "=", "label", "in", "valid_labels", "\n", "", "else", ":", "\n", "        ", "is_valid", "=", "True", "\n", "\n", "", "return", "is_valid", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.is_noise_label": [[60, 62], ["None"], "function", ["None"], ["", "def", "is_noise_label", "(", "label", ")", ":", "\n", "    ", "return", "label", "==", "BACKGROUND_NOISE_DIR_NAME", "or", "label", "==", "BACKGROUND_NOISE_LABEL", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.process_files": [[64, 139], ["list", "input_dir.iterdir", "set", "print", "data.items", "len", "set", "len", "len", "len", "output_dir.exists", "output_dir.mkdir", "base_dir.mkdir", "print", "target_noise_dir.symlink_to", "list_fullpath[].open", "fr.readlines", "wanted_words.split", "p.is_dir", "gsc.is_valid_label", "list.append", "set", "len", "len", "len", "len", "list", "label_dir.mkdir", "gsc.is_noise_label", "gsc.get_label_and_filename", "data[].append", "gsc.is_noise_label", "set", "target_path.symlink_to", "pathlib.Path", "gsc.is_valid_label", "row.strip"], "function", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.generate_json.readlines", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.is_valid_label", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.is_noise_label", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.get_label_and_filename", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.is_noise_label", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.dataset.gsc.is_valid_label"], ["", "def", "process_files", "(", "input_dir", ",", "train_list_fullpath", ",", "valid_list_fullpath", ",", "test_list_fullpath", ",", "wanted_words", ",", "output_dir", ")", ":", "\n", "# load split list", "\n", "    ", "data", "=", "{", "\n", "\"train\"", ":", "[", "]", ",", "\n", "\"valid\"", ":", "[", "]", ",", "\n", "\"test\"", ":", "[", "]", ",", "\n", "}", "\n", "\n", "list_fullpath", "=", "{", "\n", "\"train\"", ":", "train_list_fullpath", ",", "\n", "\"valid\"", ":", "valid_list_fullpath", ",", "\n", "\"test\"", ":", "test_list_fullpath", ",", "\n", "}", "\n", "\n", "for", "split", "in", "data", ":", "\n", "        ", "with", "list_fullpath", "[", "split", "]", ".", "open", "(", "\"r\"", ")", "as", "fr", ":", "\n", "            ", "for", "row", "in", "fr", ".", "readlines", "(", ")", ":", "\n", "                ", "label", ",", "filename", "=", "get_label_and_filename", "(", "Path", "(", "row", ".", "strip", "(", ")", ")", ")", "\n", "data", "[", "split", "]", ".", "append", "(", "(", "label", ",", "filename", ")", ")", "\n", "\n", "# set labels", "\n", "", "", "", "if", "len", "(", "wanted_words", ")", ">", "0", ":", "\n", "        ", "valid_labels", "=", "set", "(", "wanted_words", ".", "split", "(", "\",\"", ")", ")", "\n", "", "else", ":", "\n", "        ", "valid_labels", "=", "None", "\n", "\n", "", "labels", "=", "list", "(", ")", "\n", "for", "p", "in", "input_dir", ".", "iterdir", "(", ")", ":", "\n", "        ", "if", "p", ".", "is_dir", "(", ")", "and", "is_valid_label", "(", "p", ".", "name", ",", "valid_labels", ")", "and", "not", "is_noise_label", "(", "p", ".", "name", ")", ":", "\n", "            ", "labels", ".", "append", "(", "p", ".", "name", ")", "\n", "", "", "assert", "len", "(", "set", "(", "labels", ")", ")", "==", "len", "(", "labels", ")", ",", "f\"{len(set(labels))} == {len(labels)}\"", "\n", "\n", "# update valid_labels", "\n", "if", "len", "(", "wanted_words", ")", ">", "0", ":", "\n", "        ", "len", "(", "valid_labels", ")", "==", "len", "(", "labels", ")", "\n", "", "valid_labels", "=", "set", "(", "labels", ")", "\n", "print", "(", "f\"Valid Labels: {valid_labels}\"", ")", "\n", "\n", "# make dataset!", "\n", "# make output_dir", "\n", "if", "not", "output_dir", ".", "exists", "(", ")", ":", "\n", "        ", "output_dir", ".", "mkdir", "(", "parents", "=", "True", ")", "\n", "\n", "", "for", "split", ",", "lst", "in", "data", ".", "items", "(", ")", ":", "\n", "# for each split", "\n", "        ", "base_dir", "=", "output_dir", "/", "split", "\n", "base_dir", ".", "mkdir", "(", ")", "\n", "\n", "# make labels for valid + unknown", "\n", "for", "label", "in", "list", "(", "valid_labels", ")", "+", "[", "UNKNOWN_WORD_LABEL", "]", ":", "\n", "            ", "label_dir", "=", "base_dir", "/", "label", "\n", "label_dir", ".", "mkdir", "(", ")", "\n", "\n", "# link files", "\n", "", "noise_count", "=", "0", "\n", "for", "label", ",", "filename", "in", "lst", ":", "\n", "            ", "source_path", "=", "input_dir", "/", "label", "/", "filename", "\n", "\n", "if", "is_noise_label", "(", "label", ")", ":", "\n", "                ", "noise_count", "+=", "1", "\n", "", "else", ":", "\n", "                ", "if", "not", "is_valid_label", "(", "label", ",", "valid_labels", ")", ":", "\n", "                    ", "filename", "=", "f\"{label}_{filename}\"", "\n", "label", "=", "UNKNOWN_WORD_LABEL", "\n", "\n", "", "target_path", "=", "base_dir", "/", "label", "/", "filename", "\n", "target_path", ".", "symlink_to", "(", "source_path", ")", "\n", "\n", "# report number of noise", "\n", "", "", "print", "(", "f\"[{split}] Num of silences: {noise_count}\"", ")", "\n", "\n", "# link noise", "\n", "source_noise_dir", "=", "input_dir", "/", "BACKGROUND_NOISE_DIR_NAME", "\n", "target_noise_dir", "=", "base_dir", "/", "BACKGROUND_NOISE_DIR_NAME", "\n", "target_noise_dir", ".", "symlink_to", "(", "source_noise_dir", ",", "target_is_directory", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.model.model.Residual.__init__": [[17, 41], ["torch.Module.__init__", "torch.BatchNorm2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ")", ":", "\n", "        ", "super", "(", "Residual", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "in_channels", "!=", "out_channels", ":", "\n", "            ", "stride", "=", "2", "\n", "self", ".", "residual", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "stride", "=", "1", "\n", "self", ".", "residual", "=", "nn", ".", "Sequential", "(", ")", "\n", "\n", "", "if", "in_channels", "!=", "out_channels", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "(", "1", ",", "9", ")", ",", "stride", "=", "stride", ",", "padding", "=", "(", "0", ",", "4", ")", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "(", "1", ",", "9", ")", ",", "stride", "=", "stride", ",", "padding", "=", "(", "0", ",", "4", ")", ",", "bias", "=", "False", ")", "\n", "", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "\n", "out_channels", ",", "out_channels", ",", "kernel_size", "=", "(", "1", ",", "9", ")", ",", "stride", "=", "1", ",", "padding", "=", "(", "0", ",", "4", ")", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.model.model.Residual.forward": [[42, 51], ["model.Residual.conv1", "model.Residual.bn1", "model.Residual.relu", "model.Residual.conv2", "model.Residual.bn2", "model.Residual.residual", "model.Residual.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "inputs", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "res", "=", "self", ".", "residual", "(", "inputs", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", "+", "res", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.model.model.TCResNet.__init__": [[54, 69], ["torch.Module.__init__", "torch.Conv2d", "zip", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.Linear", "layers.append", "model.Residual"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bins", ",", "n_channels", ",", "n_class", ")", ":", "\n", "        ", "super", "(", "TCResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\"\"\"\n        Args:\n            bin: frequency bin or feature bin\n        \"\"\"", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "bins", ",", "n_channels", "[", "0", "]", ",", "kernel_size", "=", "(", "1", ",", "3", ")", ",", "padding", "=", "(", "0", ",", "1", ")", ",", "bias", "=", "False", ")", "\n", "self", ".", "channels", "=", "n_channels", "\n", "self", ".", "out_features", "=", "n_class", "\n", "layers", "=", "[", "]", "\n", "for", "in_channels", ",", "out_channels", "in", "zip", "(", "n_channels", "[", "0", ":", "-", "1", "]", ",", "n_channels", "[", "1", ":", "]", ")", ":", "\n", "            ", "layers", ".", "append", "(", "Residual", "(", "in_channels", ",", "out_channels", ")", ")", "\n", "", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "self", ".", "pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "n_channels", "[", "-", "1", "]", ",", "n_class", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.model.model.TCResNet.forward": [[71, 86], ["einops.rearrange", "model.TCResNet.conv", "model.TCResNet.layers", "model.TCResNet.pool", "model.TCResNet.view", "model.TCResNet.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input\n            [B, 1, F, T] ~ [B, 1, freq, time]\n            reshape -> [B, freq, 1, time]\n        \"\"\"", "\n", "B", ",", "C", ",", "F", ",", "T", "=", "inputs", ".", "shape", "\n", "inputs", "=", "rearrange", "(", "inputs", ",", "\"b c f t -> b f c t\"", ",", "c", "=", "C", ",", "f", "=", "F", ")", "\n", "out", "=", "self", ".", "conv", "(", "inputs", ")", "\n", "out", "=", "self", ".", "layers", "(", "out", ")", "\n", "out", "=", "self", ".", "pool", "(", "out", ")", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "linear", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.model.model.MFCC_TCResnet.__init__": [[89, 98], ["torch.Module.__init__", "model.TCResNet", "int"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bins", ":", "int", ",", "channels", ",", "channel_scale", ":", "int", ",", "num_classes", "=", "12", ")", ":", "\n", "        ", "super", "(", "MFCC_TCResnet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sampling_rate", "=", "16000", "\n", "self", ".", "bins", "=", "bins", "\n", "self", ".", "channels", "=", "channels", "\n", "self", ".", "channel_scale", "=", "channel_scale", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "tc_resnet", "=", "TCResNet", "(", "self", ".", "bins", ",", "[", "int", "(", "cha", "*", "self", ".", "channel_scale", ")", "for", "cha", "in", "self", ".", "channels", "]", ",", "self", ".", "num_classes", ")", "\n", "self", ".", "data_augment", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.model.model.MFCC_TCResnet.forward": [[99, 102], ["model.MFCC_TCResnet.tc_resnet"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "waveform", ")", ":", "\n", "        ", "logits", "=", "self", ".", "tc_resnet", "(", "waveform", ")", "\n", "return", "logits", "\n", "", "", ""]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.spectrogram.plot_spectrogram": [[20, 46], ["len", "print", "int", "print", "librosa.feature.melspectrogram", "librosa.power_to_db", "librosa.display.specshow", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.title", "matplotlib.savefig", "matplotlib.show", "max"], "function", ["None"], ["def", "plot_spectrogram", "(", "data", ",", "fs", ",", "name", ")", ":", "\n", "    ", "L", "=", "len", "(", "data", ")", "\n", "print", "(", "'Time:'", ",", "L", "/", "fs", ")", "\n", "\n", "# \u5f52\u4e00\u5316", "\n", "data", "=", "data", "*", "1.0", "/", "max", "(", "data", ")", "\n", "\n", "# 0.025s", "\n", "framelength", "=", "0.025", "\n", "# NFFT\u70b9\u6570=0.025*fs", "\n", "framesize", "=", "int", "(", "framelength", "*", "fs", ")", "\n", "print", "(", "\"NFFT:\"", ",", "framesize", ")", "\n", "\n", "# \u63d0\u53d6mel\u7279\u5f81", "\n", "mel_spect", "=", "librosa", ".", "feature", ".", "melspectrogram", "(", "data", ",", "sr", "=", "fs", ",", "n_fft", "=", "framesize", ")", "\n", "# \u8f6c\u5316\u4e3alog\u5f62\u5f0f", "\n", "mel_spect", "=", "librosa", ".", "power_to_db", "(", "mel_spect", ",", "ref", "=", "np", ".", "max", ")", "\n", "\n", "# \u753bmel\u8c31\u56fe", "\n", "# set_style()", "\n", "librosa", ".", "display", ".", "specshow", "(", "mel_spect", ",", "sr", "=", "fs", ",", "x_axis", "=", "'time'", ",", "y_axis", "=", "'mel'", ")", "\n", "plt", ".", "ylabel", "(", "'Mel Frequency'", ")", "\n", "plt", ".", "xlabel", "(", "'Time(s)'", ")", "\n", "plt", ".", "title", "(", "'Mel Spectrogram'", ")", "\n", "plt", ".", "savefig", "(", "name", "+", "\".pdf\"", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.util.set_size": [[15, 46], ["None"], "function", ["None"], ["def", "set_size", "(", "width", ",", "fraction", "=", "1", ")", ":", "\n", "    ", "\"\"\" Set aesthetic figure dimensions to avoid scaling in latex.\n    Parameters\n    ----------\n    width: float\n            Width in pts\n    fraction: float\n            Fraction of the width which you wish the figure to occupy\n    Returns\n    -------\n    fig_dim: tuple\n            Dimensions of figure in inches\n    \"\"\"", "\n", "# Width of figure", "\n", "fig_width_pt", "=", "width", "*", "fraction", "\n", "\n", "# Convert from pt to inches", "\n", "inches_per_pt", "=", "1", "/", "72.27", "\n", "\n", "# Golden ratio to set aesthetic figure height", "\n", "golden_ratio", "=", "(", "5", "**", ".5", "-", "1", ")", "/", "1.5", "\n", "\n", "# Figure width in inches", "\n", "fig_width_in", "=", "fig_width_pt", "*", "inches_per_pt", "\n", "# Figure height in inches", "\n", "fig_height_in", "=", "fig_width_in", "*", "golden_ratio", "\n", "\n", "fig_dim", "=", "(", "fig_width_in", ",", "fig_height_in", ")", "\n", "#     fig_dim = (2*fig_width_in, fig_height_in)", "\n", "\n", "return", "fig_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.util.set_style": [[48, 65], ["matplotlib.style.use", "matplotlib.rcParams.update"], "function", ["None"], ["", "def", "set_style", "(", ")", ":", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'classic'", ")", "\n", "\n", "nice_fonts", "=", "{", "\n", "# Use LaTeX to write all text", "\n", "\"text.usetex\"", ":", "True", ",", "\n", "\"font.family\"", ":", "\"serif\"", ",", "\n", "# Use 10pt font in plots, to match 10pt font in document", "\n", "\"axes.labelsize\"", ":", "19", ",", "\n", "\"font.size\"", ":", "16", ",", "\n", "# Make the legend/label fonts a little smaller", "\n", "\"legend.fontsize\"", ":", "12", ",", "\n", "\"xtick.labelsize\"", ":", "16", ",", "\n", "\"ytick.labelsize\"", ":", "16", ",", "\n", "}", "\n", "\n", "mpl", ".", "rcParams", ".", "update", "(", "nice_fonts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.util.load_json": [[67, 76], ["open", "json.load"], "function", ["None"], ["", "def", "load_json", "(", "path", ")", ":", "\n", "    ", "'''\n    Load a JSON local file as a dict()\n    :param path: input path\n    :return: JSON dict()\n    '''", "\n", "with", "open", "(", "path", ")", "as", "f", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "data", "\n", "", ""]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.figures.plot_keyword_heatmap": [[8, 18], ["matplotlib.subplots", "numpy.array", "numpy.isnan", "seaborn.heatmap", "axes[].set_ylabel", "axes[].set_xlabel", "matplotlib.show", "range", "range"], "function", ["None"], ["def", "plot_keyword_heatmap", "(", "accs_sets", ")", ":", "\n", "    ", "fig", ",", "axes", "=", "plt", ".", "subplots", "(", "1", ",", "4", ",", "figsize", "=", "(", "20", ",", "5", ")", ")", "\n", "accs_fine_grid", "=", "np", ".", "array", "(", "accs_sets", ")", "\n", "nan_mask", "=", "np", ".", "isnan", "(", "accs_sets", ")", "\n", "sns", ".", "heatmap", "(", "accs_sets", ",", "vmin", "=", "0", ",", "vmax", "=", "4", ",", "mask", "=", "nan_mask", ",", "annot", "=", "True", ",", "fmt", "=", "'g'", ",", "\n", "yticklabels", "=", "range", "(", "1", ",", "6", ")", ",", "xticklabels", "=", "range", "(", "1", ",", "6", ")", ",", "ax", "=", "axes", "[", "0", "]", ",", "cbar", "=", "True", ")", "\n", "\n", "axes", "[", "0", "]", ".", "set_ylabel", "(", "'Tested on Task'", ")", "\n", "axes", "[", "0", "]", ".", "set_xlabel", "(", "'Naive'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.figures.plot_avg_acc": [[20, 68], ["matplotlib.subplots", "range", "numpy.arange", "ax.plot", "ax.plot", "ax.plot", "ax.plot", "ax.plot", "ax.plot", "ax.plot", "ax.plot", "matplotlib.margins", "ax.set_xlabel", "ax.set_ylabel", "ax.set_ylim", "ax.tick_params", "ax.set_xticks", "ax.set_xticklabels", "ax.yaxis.get_major_ticks", "yticks[].label1.set_visible", "yticks[].label1.set_visible", "ax.set_yticklabels", "ax.legend", "matplotlib.savefig", "len", "len", "figure.util.set_size"], "function", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.util.set_size"], ["", "def", "plot_avg_acc", "(", ")", ":", "\n", "    ", "\"\"\"\n    Plot the average accuracy after learning each new task.\n    \"\"\"", "\n", "si_acc_list", "=", "[", "96.2", ",", "87.7", ",", "54.1", ",", "43.8", ",", "29.9", ",", "25.6", "]", "\n", "gem_acc_list", "=", "[", "96.2", ",", "79.1", ",", "74.2", ",", "71.3", ",", "62.4", ",", "52.9", "]", "\n", "# nr_acc_list = [96.2, 91.7, 92.5, 89.4, 90.1, 88.9] # 100%", "\n", "nr_05_acc_list", "=", "[", "96.2", ",", "81.2", ",", "80.4", ",", "77.2", ",", "79.3", ",", "78.9", "]", "\n", "nr_075_acc_list", "=", "[", "96.2", ",", "84.2", ",", "85.5", ",", "80.0", ",", "85.1", ",", "81.4", "]", "\n", "ewc_acc_list", "=", "[", "96.2", ",", "49.6", ",", "32.8", ",", "27.5", ",", "20", ",", "17.1", "]", "\n", "tune_acc_list", "=", "[", "96.2", ",", "51.2", ",", "30.0", ",", "24.1", ",", "19.9", ",", "18.4", "]", "\n", "tcpnn_acc_list", "=", "[", "96.2", ",", "86.1", ",", "91.8", ",", "87.6", ",", "94.2", ",", "86.5", "]", "\n", "single_acc_list", "=", "[", "96.2", ",", "95.0", ",", "98.2", ",", "95.4", ",", "96.6", ",", "97.6", "]", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "set_size", "(", "WIDTH", ")", ")", "\n", "label", "=", "range", "(", "len", "(", "si_acc_list", ")", ")", "\n", "index", "=", "np", ".", "arange", "(", "len", "(", "label", ")", ")", "\n", "\n", "line_width", "=", "2.5", "\n", "ax", ".", "plot", "(", "index", ",", "si_acc_list", ",", "color", "=", "COLOR_LIST", "[", "8", "]", ",", "ms", "=", "10", ",", "linewidth", "=", "line_width", ",", "label", "=", "'SI'", ")", "\n", "ax", ".", "plot", "(", "index", ",", "ewc_acc_list", ",", "color", "=", "COLOR_LIST", "[", "5", "]", ",", "ms", "=", "10", ",", "linewidth", "=", "line_width", ",", "label", "=", "'EWC'", ")", "\n", "ax", ".", "plot", "(", "index", ",", "nr_05_acc_list", ",", "color", "=", "COLOR_LIST", "[", "3", "]", ",", "ms", "=", "10", ",", "linewidth", "=", "line_width", ",", "label", "=", "'NR-0.5'", ")", "\n", "ax", ".", "plot", "(", "index", ",", "nr_075_acc_list", ",", "color", "=", "COLOR_LIST", "[", "6", "]", ",", "ms", "=", "10", ",", "linewidth", "=", "line_width", ",", "label", "=", "'NR-0.75'", ")", "\n", "ax", ".", "plot", "(", "index", ",", "gem_acc_list", ",", "color", "=", "COLOR_LIST", "[", "4", "]", ",", "ms", "=", "10", ",", "linewidth", "=", "line_width", ",", "label", "=", "'GEM-128'", ")", "\n", "ax", ".", "plot", "(", "index", ",", "tcpnn_acc_list", ",", "color", "=", "COLOR_LIST", "[", "2", "]", ",", "ms", "=", "10", ",", "linewidth", "=", "line_width", ",", "label", "=", "'PCL-KWS'", ")", "\n", "ax", ".", "plot", "(", "index", ",", "single_acc_list", ",", "color", "=", "COLOR_LIST", "[", "0", "]", ",", "ms", "=", "10", ",", "linestyle", "=", "'dashed'", ",", "linewidth", "=", "line_width", ",", "\n", "label", "=", "'Stand-alone'", ")", "\n", "ax", ".", "plot", "(", "index", ",", "tune_acc_list", ",", "color", "=", "COLOR_LIST", "[", "1", "]", ",", "ms", "=", "10", ",", "linestyle", "=", "'dashed'", ",", "linewidth", "=", "line_width", ",", "\n", "label", "=", "'Fine-tune'", ")", "\n", "\n", "plt", ".", "margins", "(", "x", "=", "0.08", ")", "\n", "\n", "ax", ".", "set_xlabel", "(", "'Task Number'", ",", "fontsize", "=", "16", ")", "\n", "ax", ".", "set_ylabel", "(", "'ACC (%)'", ",", "fontsize", "=", "16", ")", "\n", "ax", ".", "set_ylim", "(", "[", "-", "39", ",", "110", "]", ")", "\n", "\n", "ax", ".", "tick_params", "(", "axis", "=", "'x'", ",", "rotation", "=", "0", ")", "\n", "ax", ".", "set_xticks", "(", "index", ")", "\n", "ax", ".", "set_xticklabels", "(", "label", ",", "fontsize", "=", "14", ")", "\n", "\n", "yticks", "=", "ax", ".", "yaxis", ".", "get_major_ticks", "(", ")", "\n", "yticks", "[", "0", "]", ".", "label1", ".", "set_visible", "(", "False", ")", "\n", "yticks", "[", "1", "]", ".", "label1", ".", "set_visible", "(", "False", ")", "\n", "\n", "ax", ".", "set_yticklabels", "(", "[", "-", "20", ",", "0", ",", "0", ",", "20", ",", "40", ",", "60", ",", "80", ",", "100", "]", ")", "\n", "\n", "ax", ".", "legend", "(", "loc", "=", "'lower left'", ",", "fontsize", "=", "13", ",", "ncol", "=", "3", ")", "\n", "plt", ".", "savefig", "(", "f'./task_avg_acc.pdf'", ",", "format", "=", "'pdf'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.figures.toK": [[70, 72], ["None"], "function", ["None"], ["", "def", "toK", "(", "input_list", ")", ":", "\n", "    ", "return", "[", "x", "/", "1000", "for", "x", "in", "input_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.figures.plot_param": [[74, 110], ["matplotlib.subplots", "numpy.arange", "ax.plot", "ax.plot", "ax.plot", "matplotlib.text", "matplotlib.axhline", "matplotlib.margins", "ax.set_xlabel", "ax.set_ylabel", "ax.tick_params", "ax.set_xticks", "ax.set_xticklabels", "ax.set_yticklabels", "ax.legend", "matplotlib.savefig", "len", "figures.toK", "figures.toK", "figures.toK", "figure.util.set_size"], "function", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.figures.toK", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.figures.toK", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.figures.toK", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.util.set_size"], ["", "def", "plot_param", "(", ")", ":", "\n", "    ", "\"\"\"\n    Plot the Extra Parameters after learning each new task.\n    \"\"\"", "\n", "sl_list", "=", "[", "0", ",", "67", ",", "67", "*", "2", ",", "67", "*", "4", ",", "67", "*", "8", ",", "67", "*", "16", ",", "67", "*", "32", ",", "67", "*", "64", ",", "67", "*", "128", ",", "67", "*", "256", "]", "\n", "tcpnn_fix_list", "=", "[", "0", ",", "34", ",", "69", ",", "137", ",", "276", ",", "558", ",", "1141", ",", "2380", ",", "5152", ",", "11872", "]", "\n", "tcpnn_list", "=", "[", "0", ",", "3", ",", "6", ",", "13", ",", "27", ",", "56", ",", "119", ",", "265", ",", "634", ",", "1684", "]", "\n", "labels", "=", "[", "0", ",", "1", ",", "2", ",", "4", ",", "8", ",", "16", ",", "32", ",", "64", ",", "128", ",", "256", "]", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "set_size", "(", "WIDTH", ")", ")", "\n", "index", "=", "np", ".", "arange", "(", "len", "(", "labels", ")", ")", "\n", "\n", "line_width", "=", "4", "\n", "ax", ".", "plot", "(", "index", ",", "toK", "(", "sl_list", ")", ",", "color", "=", "COLOR_LIST", "[", "3", "]", ",", "ms", "=", "10", ",", "linestyle", "=", "'dashed'", ",", "linewidth", "=", "line_width", ",", "\n", "label", "=", "'Stand-alone'", ")", "\n", "ax", ".", "plot", "(", "index", ",", "toK", "(", "tcpnn_fix_list", ")", ",", "color", "=", "COLOR_LIST", "[", "4", "]", ",", "ms", "=", "10", ",", "linewidth", "=", "line_width", ",", "label", "=", "'PCL-KWS (fix)'", ")", "\n", "ax", ".", "plot", "(", "index", ",", "toK", "(", "tcpnn_list", ")", ",", "color", "=", "COLOR_LIST", "[", "2", "]", ",", "ms", "=", "10", ",", "linewidth", "=", "line_width", ",", "label", "=", "'PCL-KWS'", ")", "\n", "plt", ".", "text", "(", "x", "=", "-", "0.4", ",", "y", "=", "32", "*", "128", "/", "1000", "+", "0.5", ",", "s", "=", "\"Buffer size of GEM-128\"", ",", "fontsize", "=", "22", ",", "color", "=", "\"#A52A2A\"", ")", "\n", "plt", ".", "axhline", "(", "y", "=", "32", "*", "128", "/", "1000", ",", "color", "=", "COLOR_LIST", "[", "0", "]", ",", "linestyle", "=", "'dashed'", ",", "linewidth", "=", "line_width", ",", "xmin", "=", "0", ")", "\n", "# plt.text(x=0, y=32*512/1000 + 0.1, s=\"GEM-512 buffer size\", fontsize=13, color=\"#A52A2A\")", "\n", "# plt.axhline(y=32*512/1000, color=COLOR_LIST[0], linewidth=2, xmin=0)", "\n", "\n", "plt", ".", "margins", "(", "x", "=", "0.08", ")", "\n", "\n", "ax", ".", "set_xlabel", "(", "'Task Number'", ",", "fontsize", "=", "22", ")", "\n", "ax", ".", "set_ylabel", "(", "'Sub-network Param (M)'", ",", "fontsize", "=", "22", ")", "\n", "# ax.set_ylim([-19, 110])", "\n", "\n", "ax", ".", "tick_params", "(", "axis", "=", "'x'", ",", "rotation", "=", "0", ")", "\n", "ax", ".", "set_xticks", "(", "index", ")", "\n", "ax", ".", "set_xticklabels", "(", "labels", ")", "\n", "ax", ".", "set_yticklabels", "(", "[", "0", ",", "2", ",", "4", ",", "6", ",", "8", ",", "10", ",", "12", ",", "14", ",", "16", ",", "18", "]", ")", "\n", "# ax.tick_params(axis='x', which='major', labelsize=18)", "\n", "# ax.tick_params(axis='y', which='major', labelsize=18)", "\n", "ax", ".", "legend", "(", "loc", "=", "'upper left'", ",", "fontsize", "=", "22", ")", "\n", "plt", ".", "savefig", "(", "f'./task_param.pdf'", ",", "format", "=", "'pdf'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.figures.plot_param_acc": [[112, 143], ["matplotlib.subplots", "ax.plot", "ax.plot", "matplotlib.margins", "ax.set_xlabel", "ax.set_ylabel", "ax.set_ylim", "ax.tick_params", "ax.xaxis.set_ticks", "ax.set_xticklabels", "ax.set_yticklabels", "ax.xaxis.get_major_ticks", "xticks[].label1.set_visible", "xticks[].label1.set_visible", "ax.legend", "matplotlib.savefig", "figure.util.set_size"], "function", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.figure.util.set_size"], ["", "def", "plot_param_acc", "(", ")", ":", "\n", "    ", "\"\"\"\n    Plot the Extra Parameters and Corresponding ACC of TC-PNN.\n    \"\"\"", "\n", "parm_list", "=", "[", "0.9", ",", "3.3", ",", "10", ",", "20", ",", "30", ",", "50", ",", "70", "]", "\n", "acc_3_list", "=", "[", "72.3", ",", "87.4", ",", "95.7", ",", "96.6", ",", "96.9", ",", "97.0", ",", "97.1", "]", "\n", "acc_15_list", "=", "[", "53.8", ",", "71.6", ",", "80.0", ",", "83.1", ",", "84.9", ",", "85.1", ",", "86.4", "]", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "set_size", "(", "WIDTH", ")", ")", "\n", "\n", "line_width", "=", "4", "\n", "ax", ".", "plot", "(", "parm_list", ",", "acc_3_list", ",", "color", "=", "COLOR_LIST", "[", "3", "]", ",", "ms", "=", "10", ",", "linewidth", "=", "line_width", ",", "label", "=", "'3-keyword spotting'", ")", "\n", "ax", ".", "plot", "(", "parm_list", ",", "acc_15_list", ",", "color", "=", "COLOR_LIST", "[", "5", "]", ",", "ms", "=", "10", ",", "linewidth", "=", "line_width", ",", "label", "=", "'15-keyword spotting'", ")", "\n", "\n", "plt", ".", "margins", "(", "x", "=", "0.08", ")", "\n", "\n", "ax", ".", "set_xlabel", "(", "'Extra Parameter (K)'", ",", "fontsize", "=", "22", ")", "\n", "ax", ".", "set_ylabel", "(", "'ACC (%)'", ",", "fontsize", "=", "22", ")", "\n", "ax", ".", "set_ylim", "(", "[", "50", ",", "100", "]", ")", "\n", "\n", "ax", ".", "tick_params", "(", "axis", "=", "'x'", ",", "rotation", "=", "0", ")", "\n", "ax", ".", "xaxis", ".", "set_ticks", "(", "parm_list", ")", "\n", "ax", ".", "set_xticklabels", "(", "parm_list", ")", "\n", "ax", ".", "set_yticklabels", "(", "[", "50", ",", "60", ",", "70", ",", "80", ",", "90", ",", "100", "]", ")", "\n", "xticks", "=", "ax", ".", "xaxis", ".", "get_major_ticks", "(", ")", "\n", "xticks", "[", "0", "]", ".", "label1", ".", "set_visible", "(", "False", ")", "\n", "xticks", "[", "1", "]", ".", "label1", ".", "set_visible", "(", "False", ")", "\n", "# ax.tick_params(axis='x', which='major', labelsize=18)", "\n", "# ax.tick_params(axis='y', which='major', labelsize=18)", "\n", "ax", ".", "legend", "(", "loc", "=", "'lower right'", ",", "fontsize", "=", "22", ")", "\n", "plt", ".", "savefig", "(", "f'./task_param_acc.pdf'", ",", "format", "=", "'pdf'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.configuration.config.base_parser": [[12, 150], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "base_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Class Incremental Learning Research\"", ")", "\n", "# Data root.", "\n", "parser", ".", "add_argument", "(", "\"--data_root\"", ",", "type", "=", "str", ",", "default", "=", "'/home/xiaoyang/Dev/kws-efficient-cl/dataset/collection'", ")", "\n", "# Mode and Exp. Settings.", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mode\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"rainbow_keywords\"", ",", "\n", "help", "=", "\"CIL methods [finetune ,native_rehearsal,joint, rwalk, icarl, rainbow_keywords, ewc, bic, gdumb]\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mem_manage\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'default'", ",", "\n", "help", "=", "\"memory management [default, random, uncertainty, reservoir, prototype]\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"gsc\"", ",", "\n", "help", "=", "\"[gsc]\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_tasks\"", ",", "type", "=", "int", ",", "default", "=", "6", ",", "help", "=", "\"The number of tasks\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--n_cls_a_task\"", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "\"The number of class of each task\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--n_init_cls\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "15", ",", "\n", "help", "=", "\"The number of classes of initial task\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--rnd_seed\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"Random seed number.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--memory_size\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Episodic memory size\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--stream_env\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"online\"", ",", "\n", "choices", "=", "[", "\"offline\"", ",", "\"online\"", "]", ",", "\n", "help", "=", "\"the restriction whether to keep streamed data or not\"", ",", "\n", ")", "\n", "\n", "# Dataset", "\n", "parser", ".", "add_argument", "(", "\n", "\"--log_path\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"results\"", ",", "\n", "help", "=", "\"The path logs are saved. Only for local-machine\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--neptune\"", ",", "default", "=", "True", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"record the experiment into web neptune.ai\"", "\n", ")", "\n", "# Model", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name\"", ",", "type", "=", "str", ",", "default", "=", "\"tcresnet8\"", ",", "help", "=", "\"[tcresnet8, tcresnet14]\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--pretrain\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"pretrain model or not\"", ")", "\n", "\n", "# Train", "\n", "parser", ".", "add_argument", "(", "\"--opt_name\"", ",", "type", "=", "str", ",", "default", "=", "\"adam\"", ",", "help", "=", "\"[adam, sgd]\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sched_name\"", ",", "type", "=", "str", ",", "default", "=", "\"cos\"", ",", "help", "=", "\"[cos, anneal]\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batchsize\"", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "\"batch size\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_epoch\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Epoch\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--n_worker\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"The number of workers\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "\"learning rate\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--init_model\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Initilize model parameters for every iterations\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--init_opt\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Initilize optimizer states for every iterations\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--topk\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"set k when we want to set top k accuracy\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--joint_acc\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.940", ",", "\n", "help", "=", "\"Accuracy when training all the tasks at once\"", ",", "\n", ")", "\n", "# Transforms", "\n", "parser", ".", "add_argument", "(", "\n", "\"--transforms\"", ",", "\n", "nargs", "=", "\"*\"", ",", "\n", "default", "=", "[", "\"specaugment mixup\"", "]", ",", "\n", "help", "=", "\"Additional train transforms [mixup, specaugment]\"", ",", "\n", ")", "\n", "\n", "# Benchmark", "\n", "parser", ".", "add_argument", "(", "\"--exp_name\"", ",", "type", "=", "str", ",", "default", "=", "\"disjoint\"", ",", "help", "=", "\"[disjoint, blurry]\"", ")", "\n", "\n", "# ICARL", "\n", "parser", ".", "add_argument", "(", "\n", "\"--feature_size\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "256", ",", "\n", "help", "=", "\"Feature size when embedding a sample\"", ",", "\n", ")", "\n", "\n", "# BiC", "\n", "parser", ".", "add_argument", "(", "\n", "\"--distilling\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"use distilling loss with classification\"", ",", "\n", ")", "\n", "\n", "# Regularization", "\n", "parser", ".", "add_argument", "(", "\n", "\"--reg_coef\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "0.1", ",", "\n", "help", "=", "\"weighting for the regularization loss term\"", ",", "\n", ")", "\n", "\n", "# Uncertain", "\n", "parser", ".", "add_argument", "(", "\n", "\"--uncert_metric\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"vr\"", ",", "\n", "choices", "=", "[", "\"vr\"", ",", "\"vr1\"", ",", "\"vr_randaug\"", ",", "\"loss\"", "]", ",", "\n", "help", "=", "\"A type of uncertainty metric\"", ",", "\n", ")", "\n", "\n", "# Debug", "\n", "parser", ".", "add_argument", "(", "\"--debug\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Turn on Debug mode\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "", ""]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.ICaRLNet.__init__": [[36, 42], ["torch.Module.__init__", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "feature_size", ",", "n_class", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "feature_size", ",", "momentum", "=", "0.01", ")", "\n", "self", ".", "ReLU", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "feature_size", ",", "n_class", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.ICaRLNet.forward": [[43, 49], ["base.ICaRLNet.model", "base.ICaRLNet.bn", "base.ICaRLNet.ReLU", "base.ICaRLNet.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "model", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "x", "=", "self", ".", "ReLU", "(", "x", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.__init__": [[52, 106], ["base.BaseMethod.criterion.to", "utils.train_utils.select_model", "base.BaseMethod.model.to", "torchaudio.transforms.MFCC", "str", "logger.info", "logger.info", "logger.info"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.train_utils.select_model"], ["    ", "def", "__init__", "(", "\n", "self", ",", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", "\n", ")", ":", "\n", "# Parameters for Dataloader", "\n", "        ", "self", ".", "num_learned_class", "=", "0", "\n", "self", ".", "num_learning_class", "=", "kwargs", "[", "\"n_init_cls\"", "]", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "self", ".", "learned_classes", "=", "[", "]", "\n", "self", ".", "class_mean", "=", "[", "None", "]", "*", "n_classes", "\n", "self", ".", "exposed_classes", "=", "[", "]", "\n", "self", ".", "seen", "=", "0", "\n", "self", ".", "topk", "=", "kwargs", "[", "\"topk\"", "]", "\n", "self", ".", "dataset", "=", "kwargs", "[", "\"dataset\"", "]", "\n", "\n", "# Parameters for Trainer", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "criterion", "=", "criterion", "\n", "self", ".", "opt_name", "=", "kwargs", "[", "\"opt_name\"", "]", "\n", "self", ".", "sched_name", "=", "kwargs", "[", "\"sched_name\"", "]", "\n", "self", ".", "lr", "=", "kwargs", "[", "\"lr\"", "]", "\n", "self", ".", "optimizer", ",", "self", ".", "scheduler", "=", "None", ",", "None", "\n", "self", ".", "criterion", "=", "self", ".", "criterion", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Parameters for Model", "\n", "self", ".", "model_name", "=", "kwargs", "[", "\"model_name\"", "]", "\n", "self", ".", "model", "=", "select_model", "(", "self", ".", "model_name", ",", "kwargs", "[", "\"n_init_cls\"", "]", ")", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Parameters for Prototype Sampler", "\n", "self", ".", "feature_size", "=", "kwargs", "[", "\"feature_size\"", "]", "\n", "self", ".", "feature_extractor", "=", "None", "\n", "self", ".", "mfcc", "=", "MFCC", "(", "sample_rate", "=", "16000", ",", "n_mfcc", "=", "40", ",", "log_mels", "=", "True", ")", "\n", "self", ".", "sample_length", "=", "16000", "\n", "\n", "# Parameters for Augmentation", "\n", "self", ".", "transform", "=", "str", "(", "kwargs", "[", "\"transforms\"", "]", ")", "\n", "self", ".", "mix", "=", "\"mixup\"", "in", "self", ".", "transform", "\n", "logger", ".", "info", "(", "f\"Take the transforms from {self.transform}\"", ")", "\n", "logger", ".", "info", "(", "f\"mix:{self.mix}\"", ")", "\n", "self", ".", "spec", "=", "\"specaug\"", "in", "self", ".", "transform", "\n", "logger", ".", "info", "(", "f\"specaug:{self.spec}\"", ")", "\n", "\n", "# Parameters for Memory Updating", "\n", "self", ".", "prev_streamed_list", "=", "[", "]", "\n", "self", ".", "streamed_list", "=", "[", "]", "\n", "self", ".", "test_list", "=", "[", "]", "\n", "self", ".", "memory_list", "=", "[", "]", "\n", "self", ".", "memory_size", "=", "kwargs", "[", "\"memory_size\"", "]", "\n", "self", ".", "mem_manage", "=", "kwargs", "[", "\"mem_manage\"", "]", "\n", "if", "kwargs", "[", "\"mem_manage\"", "]", "==", "\"default\"", ":", "\n", "            ", "self", ".", "mem_manage", "=", "\"random\"", "\n", "", "self", ".", "already_mem_update", "=", "False", "\n", "self", ".", "mode", "=", "kwargs", "[", "\"mode\"", "]", "\n", "self", ".", "uncert_metric", "=", "kwargs", "[", "\"uncert_metric\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.set_current_dataset": [[107, 112], ["random.shuffle"], "methods", ["None"], ["", "def", "set_current_dataset", "(", "self", ",", "train_datalist", ",", "test_datalist", ")", ":", "\n", "        ", "random", ".", "shuffle", "(", "train_datalist", ")", "\n", "self", ".", "prev_streamed_list", "=", "self", ".", "streamed_list", "\n", "self", ".", "streamed_list", "=", "train_datalist", "\n", "self", ".", "test_list", "=", "test_datalist", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.before_task": [[113, 148], ["logger.info", "[].unique().tolist", "list", "max", "max", "base.BaseMethod.model.to", "logger.info", "set", "len", "torch.Linear", "torch.Linear", "torch.Linear", "base.ICaRLNet", "logger.info", "utils.train_utils.select_model", "torch.Linear", "torch.Linear", "torch.Linear", "logger.info", "utils.train_utils.select_optimizer", "[].unique", "pandas.DataFrame"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.train_utils.select_model", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.train_utils.select_optimizer"], ["", "def", "before_task", "(", "self", ",", "datalist", ",", "init_model", "=", "False", ",", "init_opt", "=", "True", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Apply before_task\"", ")", "\n", "# Confirm incoming classes", "\n", "incoming_classes", "=", "pd", ".", "DataFrame", "(", "datalist", ")", "[", "\"klass\"", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "exposed_classes", "=", "list", "(", "set", "(", "self", ".", "learned_classes", "+", "incoming_classes", ")", ")", "\n", "self", ".", "num_learning_class", "=", "max", "(", "\n", "len", "(", "self", ".", "exposed_classes", ")", ",", "self", ".", "num_learning_class", "\n", ")", "\n", "if", "self", ".", "mem_manage", "==", "\"prototype\"", ":", "\n", "            ", "self", ".", "model", ".", "tc_resnet", ".", "linear", "=", "nn", ".", "Linear", "(", "self", ".", "model", ".", "tc_resnet", ".", "channels", "[", "-", "1", "]", ",", "self", ".", "feature_size", ")", "\n", "self", ".", "feature_extractor", "=", "self", ".", "model", "\n", "self", ".", "model", "=", "ICaRLNet", "(", "\n", "self", ".", "feature_extractor", ",", "self", ".", "feature_size", ",", "self", ".", "num_learning_class", "\n", ")", "\n", "", "in_features", "=", "self", ".", "model", ".", "tc_resnet", ".", "channels", "[", "-", "1", "]", "\n", "out_features", "=", "self", ".", "model", ".", "tc_resnet", ".", "out_features", "\n", "# To care the case of decreasing head", "\n", "new_out_features", "=", "max", "(", "out_features", ",", "self", ".", "num_learning_class", ")", "\n", "if", "init_model", ":", "\n", "# init model parameters in every iteration", "\n", "            ", "logger", ".", "info", "(", "\"Reset model parameters\"", ")", "\n", "self", ".", "model", "=", "select_model", "(", "self", ".", "model_name", ",", "new_out_features", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "tc_resnet", ".", "linear", "=", "nn", ".", "Linear", "(", "in_features", ",", "new_out_features", ")", "\n", "", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "init_opt", ":", "\n", "# reinitialize the optimizer and scheduler", "\n", "            ", "logger", ".", "info", "(", "\"Reset the optimizer and scheduler states\"", ")", "\n", "self", ".", "optimizer", ",", "self", ".", "scheduler", "=", "select_optimizer", "(", "\n", "self", ".", "opt_name", ",", "self", ".", "lr", ",", "self", ".", "model", ",", "self", ".", "sched_name", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"Increasing the head of fc {out_features} -> {new_out_features}\"", ")", "\n", "\n", "self", ".", "already_mem_update", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.after_task": [[149, 154], ["logger.info", "base.BaseMethod.update_memory"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.joint.Joint.update_memory"], ["", "def", "after_task", "(", "self", ",", "cur_iter", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Apply after_task\"", ")", "\n", "self", ".", "learned_classes", "=", "self", ".", "exposed_classes", "\n", "self", ".", "num_learned_class", "=", "self", ".", "num_learning_class", "\n", "self", ".", "update_memory", "(", "cur_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.update_memory": [[155, 200], ["logger.info", "logger.info", "pandas.DataFrame", "logger.warning", "len", "len", "logger.warning", "len", "len", "logger.info", "base.BaseMethod.rnd_sampling", "base.BaseMethod.reservoir_sampling", "base.BaseMethod.mean_feature_sampling", "pandas.DataFrame.klass.value_counts", "logger.error", "base.BaseMethod.equal_class_sampling", "base.BaseMethod.uncertainty_sampling"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.rnd_sampling", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.reservoir_sampling", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.mean_feature_sampling", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.equal_class_sampling", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.uncertainty_sampling"], ["", "def", "update_memory", "(", "self", ",", "cur_iter", ",", "num_class", "=", "None", ")", ":", "\n", "        ", "if", "num_class", "is", "None", ":", "\n", "            ", "num_class", "=", "self", ".", "num_learning_class", "\n", "\n", "", "if", "not", "self", ".", "already_mem_update", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Update memory over {num_class} classes by {self.mem_manage}\"", ")", "\n", "candidates", "=", "self", ".", "streamed_list", "+", "self", ".", "memory_list", "\n", "if", "len", "(", "candidates", ")", "<=", "self", ".", "memory_size", ":", "\n", "                ", "self", ".", "memory_list", "=", "candidates", "\n", "self", ".", "seen", "=", "len", "(", "candidates", ")", "\n", "logger", ".", "warning", "(", "\"Candidates < Memory size\"", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "mem_manage", "==", "\"random\"", ":", "\n", "                    ", "self", ".", "memory_list", "=", "self", ".", "rnd_sampling", "(", "candidates", ")", "\n", "", "elif", "self", ".", "mem_manage", "==", "\"reservoir\"", ":", "\n", "                    ", "self", ".", "reservoir_sampling", "(", "self", ".", "streamed_list", ")", "\n", "", "elif", "self", ".", "mem_manage", "==", "\"prototype\"", ":", "\n", "                    ", "self", ".", "memory_list", "=", "self", ".", "mean_feature_sampling", "(", "\n", "exemplars", "=", "self", ".", "memory_list", ",", "\n", "samples", "=", "self", ".", "streamed_list", ",", "\n", "num_class", "=", "num_class", ",", "\n", ")", "\n", "", "elif", "self", ".", "mem_manage", "==", "\"uncertainty\"", ":", "\n", "                    ", "if", "cur_iter", "==", "0", ":", "\n", "                        ", "self", ".", "memory_list", "=", "self", ".", "equal_class_sampling", "(", "\n", "candidates", ",", "num_class", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "memory_list", "=", "self", ".", "uncertainty_sampling", "(", "\n", "candidates", ",", "\n", "num_class", "=", "num_class", ",", "\n", ")", "\n", "", "", "else", ":", "\n", "                    ", "logger", ".", "error", "(", "\"Not implemented memory management\"", ")", "\n", "raise", "NotImplementedError", "\n", "\n", "", "", "assert", "len", "(", "self", ".", "memory_list", ")", "<=", "self", ".", "memory_size", "\n", "logger", ".", "info", "(", "\"Memory statistic\"", ")", "\n", "memory_df", "=", "pd", ".", "DataFrame", "(", "self", ".", "memory_list", ")", "\n", "if", "len", "(", "self", ".", "memory_list", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "f\"\\n{memory_df.klass.value_counts(sort=True)}\"", ")", "\n", "# memory update happens only once per task iteratin.", "\n", "", "self", ".", "already_mem_update", "=", "True", "\n", "", "else", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Already updated the memory during this iter ({cur_iter})\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.get_dataloader": [[201, 231], ["utils.data_loader.SpeechDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "utils.data_loader.SpeechDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "pandas.DataFrame", "pandas.DataFrame"], "methods", ["None"], ["", "", "def", "get_dataloader", "(", "self", ",", "batch_size", ",", "n_worker", ",", "train_list", ",", "test_list", ")", ":", "\n", "# Loader", "\n", "        ", "train_loader", "=", "None", "\n", "test_loader", "=", "None", "\n", "if", "train_list", "is", "not", "None", "and", "len", "(", "train_list", ")", ">", "0", ":", "\n", "            ", "train_dataset", "=", "SpeechDataset", "(", "\n", "pd", ".", "DataFrame", "(", "train_list", ")", ",", "\n", "dataset", "=", "self", ".", "dataset", ",", "\n", "is_training", "=", "True", "\n", ")", "\n", "# drop last becasue of BatchNorm1D in IcarlNet", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "n_worker", ",", "\n", "drop_last", "=", "True", ",", "\n", ")", "\n", "\n", "", "if", "test_list", "is", "not", "None", ":", "\n", "            ", "test_dataset", "=", "SpeechDataset", "(", "\n", "pd", ".", "DataFrame", "(", "test_list", ")", ",", "\n", "dataset", "=", "self", ".", "dataset", ",", "\n", "is_training", "=", "False", "\n", ")", "\n", "test_loader", "=", "DataLoader", "(", "\n", "test_dataset", ",", "shuffle", "=", "False", ",", "batch_size", "=", "batch_size", ",", "num_workers", "=", "n_worker", "\n", ")", "\n", "\n", "", "return", "train_loader", ",", "test_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.train": [[232, 291], ["random.shuffle", "base.BaseMethod.get_dataloader", "logger.info", "logger.info", "logger.info", "logger.info", "dict", "range", "base.BaseMethod._train", "base.BaseMethod.evaluation", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "logger.info", "max", "len", "len", "len", "len", "base.BaseMethod.scheduler.step"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.get_dataloader", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk._train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.evaluation"], ["", "def", "train", "(", "self", ",", "cur_iter", ",", "n_epoch", ",", "batch_size", ",", "n_worker", ",", "n_passes", "=", "1", ")", ":", "\n", "\n", "        ", "train_list", "=", "self", ".", "streamed_list", "+", "self", ".", "memory_list", "\n", "random", ".", "shuffle", "(", "train_list", ")", "\n", "test_list", "=", "self", ".", "test_list", "\n", "train_loader", ",", "test_loader", "=", "self", ".", "get_dataloader", "(", "\n", "batch_size", ",", "n_worker", ",", "train_list", ",", "test_list", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Streamed samples: {len(self.streamed_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"In-memory samples: {len(self.memory_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"Train samples: {len(train_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"Test samples: {len(test_list)}\"", ")", "\n", "\n", "# TRAIN", "\n", "best_acc", "=", "0.0", "\n", "eval_dict", "=", "dict", "(", ")", "\n", "for", "epoch", "in", "range", "(", "n_epoch", ")", ":", "\n", "# https://github.com/drimpossible/GDumb/blob/master/src/main.py", "\n", "# initialize for each task", "\n", "            ", "if", "epoch", "<=", "0", ":", "# Warm start of 1 epoch", "\n", "                ", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "\"lr\"", "]", "=", "self", ".", "lr", "*", "0.1", "\n", "", "", "elif", "epoch", "==", "1", ":", "# Then set to max lr", "\n", "                ", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "\"lr\"", "]", "=", "self", ".", "lr", "\n", "", "", "else", ":", "# And go!", "\n", "                ", "self", ".", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "train_loss", ",", "train_acc", "=", "self", ".", "_train", "(", "\n", "train_loader", "=", "train_loader", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ",", "\n", "criterion", "=", "self", ".", "criterion", ",", "\n", "epoch", "=", "epoch", ",", "\n", "total_epochs", "=", "n_epoch", ",", "\n", "n_passes", "=", "n_passes", ",", "\n", ")", "\n", "\n", "eval_dict", "=", "self", ".", "evaluation", "(", "\n", "test_loader", "=", "test_loader", ",", "criterion", "=", "self", ".", "criterion", "\n", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/train/loss\"", ",", "train_loss", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/train/acc\"", ",", "train_acc", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/test/loss\"", ",", "eval_dict", "[", "\"avg_loss\"", "]", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/test/acc\"", ",", "eval_dict", "[", "\"avg_acc\"", "]", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "f\"task{cur_iter}/train/lr\"", ",", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "epoch", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "f\"Task {cur_iter} | Epoch {epoch + 1}/{n_epoch} | train_loss {train_loss:.4f} | train_acc {train_acc:.4f} | \"", "\n", "f\"test_loss {eval_dict['avg_loss']:.4f} | test_acc {eval_dict['avg_acc']:.4f} | \"", "\n", "f\"lr {self.optimizer.param_groups[0]['lr']:.4f}\"", "\n", ")", "\n", "\n", "best_acc", "=", "max", "(", "best_acc", ",", "eval_dict", "[", "\"avg_acc\"", "]", ")", "\n", "\n", "", "return", "best_acc", ",", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod._train": [[292, 326], ["base.BaseMethod.model.train", "enumerate", "len", "range", "x.to.to.to", "y.to.to.to", "optimizer.zero_grad", "base.BaseMethod.topk", "criterion.backward", "optimizer.step", "criterion.item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "y.to.to.size", "utils.data_augmentation.mixup_data", "base.BaseMethod.model", "base.BaseMethod.model", "criterion", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "criterion", "criterion", "y.to.to.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_augmentation.mixup_data"], ["", "def", "_train", "(", "\n", "self", ",", "train_loader", ",", "optimizer", ",", "criterion", ",", "epoch", ",", "total_epochs", ",", "n_passes", "=", "1", "\n", ")", ":", "\n", "        ", "total_loss", ",", "correct", ",", "num_data", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "for", "pass_", "in", "range", "(", "n_passes", ")", ":", "\n", "                ", "x", "=", "data", "[", "\"waveform\"", "]", "\n", "y", "=", "data", "[", "\"label\"", "]", "\n", "x", "=", "x", ".", "to", "(", "self", ".", "device", ")", "\n", "y", "=", "y", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "self", ".", "mix", ":", "\n", "                    ", "x", ",", "labels_a", ",", "labels_b", ",", "lam", "=", "mixup_data", "(", "x", "=", "x", ",", "y", "=", "y", ",", "alpha", "=", "0.5", ")", "\n", "logit", "=", "self", ".", "model", "(", "x", ")", "\n", "loss", "=", "lam", "*", "criterion", "(", "logit", ",", "labels_a", ")", "+", "(", "1", "-", "lam", ")", "*", "criterion", "(", "\n", "logit", ",", "labels_b", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "logit", "=", "self", ".", "model", "(", "x", ")", "\n", "loss", "=", "criterion", "(", "logit", ",", "y", ")", "\n", "", "_", ",", "preds", "=", "logit", ".", "topk", "(", "self", ".", "topk", ",", "1", ",", "True", ",", "True", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "correct", "+=", "torch", ".", "sum", "(", "preds", "==", "y", ".", "unsqueeze", "(", "1", ")", ")", ".", "item", "(", ")", "\n", "num_data", "+=", "y", ".", "size", "(", "0", ")", "\n", "\n", "", "", "n_batches", "=", "len", "(", "train_loader", ")", "\n", "\n", "return", "total_loss", "/", "n_batches", ",", "correct", "/", "num_data", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.evaluation_ext": [[327, 340], ["utils.data_loader.SpeechDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "base.BaseMethod.evaluation", "pandas.DataFrame"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.evaluation"], ["", "def", "evaluation_ext", "(", "self", ",", "test_list", ")", ":", "\n", "# evaluation from out of class", "\n", "        ", "test_dataset", "=", "SpeechDataset", "(", "\n", "pd", ".", "DataFrame", "(", "test_list", ")", ",", "\n", "dataset", "=", "self", ".", "dataset", ",", "\n", "is_training", "=", "False", "\n", ")", "\n", "test_loader", "=", "DataLoader", "(", "\n", "test_dataset", ",", "shuffle", "=", "False", ",", "batch_size", "=", "32", ",", "num_workers", "=", "2", "\n", ")", "\n", "eval_dict", "=", "self", ".", "evaluation", "(", "test_loader", ",", "self", ".", "criterion", ")", "\n", "\n", "return", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.evaluation": [[341, 376], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "base.BaseMethod.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "len", "x.to.to.to", "y.to.to.to", "base.BaseMethod.model", "criterion", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "base.BaseMethod.topk", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "y.to.to.size", "base.BaseMethod._interpret_pred", "correct_xlabel_cnt.detach().cpu", "xlabel_cnt.detach().cpu", "criterion.item", "y.to.to.tolist", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "correct_xlabel_cnt.detach", "xlabel_cnt.detach", "y.to.to.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRL._interpret_pred"], ["", "def", "evaluation", "(", "self", ",", "test_loader", ",", "criterion", ")", ":", "\n", "        ", "total_correct", ",", "total_num_data", ",", "total_loss", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "correct_l", "=", "torch", ".", "zeros", "(", "self", ".", "n_classes", ")", "\n", "num_data_l", "=", "torch", ".", "zeros", "(", "self", ".", "n_classes", ")", "\n", "label", "=", "[", "]", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", ",", "data", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "                ", "x", "=", "data", "[", "\"waveform\"", "]", "\n", "y", "=", "data", "[", "\"label\"", "]", "\n", "x", "=", "x", ".", "to", "(", "self", ".", "device", ")", "\n", "y", "=", "y", ".", "to", "(", "self", ".", "device", ")", "\n", "logit", "=", "self", ".", "model", "(", "x", ")", "\n", "\n", "loss", "=", "criterion", "(", "logit", ",", "y", ")", "\n", "pred", "=", "torch", ".", "argmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "_", ",", "preds", "=", "logit", ".", "topk", "(", "self", ".", "topk", ",", "1", ",", "True", ",", "True", ")", "\n", "\n", "total_correct", "+=", "torch", ".", "sum", "(", "preds", "==", "y", ".", "unsqueeze", "(", "1", ")", ")", ".", "item", "(", ")", "\n", "total_num_data", "+=", "y", ".", "size", "(", "0", ")", "\n", "\n", "xlabel_cnt", ",", "correct_xlabel_cnt", "=", "self", ".", "_interpret_pred", "(", "y", ",", "pred", ")", "\n", "correct_l", "+=", "correct_xlabel_cnt", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "num_data_l", "+=", "xlabel_cnt", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "label", "+=", "y", ".", "tolist", "(", ")", "\n", "\n", "", "", "avg_acc", "=", "total_correct", "/", "total_num_data", "\n", "avg_loss", "=", "total_loss", "/", "len", "(", "test_loader", ")", "\n", "cls_acc", "=", "(", "correct_l", "/", "(", "num_data_l", "+", "1e-5", ")", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "ret", "=", "{", "\"avg_loss\"", ":", "avg_loss", ",", "\"avg_acc\"", ":", "avg_acc", ",", "\"cls_acc\"", ":", "cls_acc", "}", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod._interpret_pred": [[377, 392], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "y.unique", "zip", "y.masked_select", "y.masked_select.unique", "zip"], "methods", ["None"], ["", "def", "_interpret_pred", "(", "self", ",", "y", ",", "pred", ")", ":", "\n", "# xlable is batch", "\n", "        ", "ret_num_data", "=", "torch", ".", "zeros", "(", "self", ".", "n_classes", ")", "\n", "ret_corrects", "=", "torch", ".", "zeros", "(", "self", ".", "n_classes", ")", "\n", "\n", "xlabel_cls", ",", "xlabel_cnt", "=", "y", ".", "unique", "(", "return_counts", "=", "True", ")", "\n", "for", "cls_idx", ",", "cnt", "in", "zip", "(", "xlabel_cls", ",", "xlabel_cnt", ")", ":", "\n", "            ", "ret_num_data", "[", "cls_idx", "]", "=", "cnt", "\n", "\n", "", "correct_xlabel", "=", "y", ".", "masked_select", "(", "y", "==", "pred", ")", "\n", "correct_cls", ",", "correct_cnt", "=", "correct_xlabel", ".", "unique", "(", "return_counts", "=", "True", ")", "\n", "for", "cls_idx", ",", "cnt", "in", "zip", "(", "correct_cls", ",", "correct_cnt", ")", ":", "\n", "            ", "ret_corrects", "[", "cls_idx", "]", "=", "cnt", "\n", "\n", "", "return", "ret_num_data", ",", "ret_corrects", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.rnd_sampling": [[393, 396], ["random.shuffle"], "methods", ["None"], ["", "def", "rnd_sampling", "(", "self", ",", "samples", ")", ":", "\n", "        ", "random", ".", "shuffle", "(", "samples", ")", "\n", "return", "samples", "[", ":", "self", ".", "memory_size", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.reservoir_sampling": [[397, 406], ["len", "numpy.random.randint"], "methods", ["None"], ["", "def", "reservoir_sampling", "(", "self", ",", "samples", ")", ":", "\n", "        ", "for", "sample", "in", "samples", ":", "\n", "            ", "if", "len", "(", "self", ".", "memory_list", ")", "<", "self", ".", "memory_size", ":", "\n", "                ", "self", ".", "memory_list", "+=", "[", "sample", "]", "\n", "", "else", ":", "\n", "                ", "j", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "seen", ")", "\n", "if", "j", "<", "self", ".", "memory_size", ":", "\n", "                    ", "self", ".", "memory_list", "[", "j", "]", "=", "sample", "\n", "", "", "self", ".", "seen", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.mean_feature_sampling": [[407, 514], ["base.BaseMethod.mean_feature_sampling._reduce_exemplar_sets"], "methods", ["None"], ["", "", "def", "mean_feature_sampling", "(", "self", ",", "exemplars", ",", "samples", ",", "num_class", ")", ":", "\n", "        ", "\"\"\"Prototype sampling\n\n        Args:\n            features ([Tensor]): [features corresponding to the samples]\n            samples ([Datalist]): [datalist for a class]\n\n        Returns:\n            [type]: [Sampled datalist]\n        \"\"\"", "\n", "\n", "def", "_reduce_exemplar_sets", "(", "exemplars", ",", "mem_per_cls", ")", ":", "\n", "            ", "if", "len", "(", "exemplars", ")", "==", "0", ":", "\n", "                ", "return", "exemplars", "\n", "\n", "", "exemplar_df", "=", "pd", ".", "DataFrame", "(", "exemplars", ")", "\n", "ret", "=", "[", "]", "\n", "for", "y", "in", "range", "(", "self", ".", "num_learned_class", ")", ":", "\n", "                ", "cls_df", "=", "exemplar_df", "[", "exemplar_df", "[", "\"label\"", "]", "==", "y", "]", "\n", "ret", "+=", "cls_df", ".", "sample", "(", "n", "=", "min", "(", "mem_per_cls", ",", "len", "(", "cls_df", ")", ")", ")", ".", "to_dict", "(", "\n", "orient", "=", "\"records\"", "\n", ")", "\n", "\n", "", "num_dups", "=", "pd", ".", "DataFrame", "(", "ret", ")", ".", "duplicated", "(", ")", ".", "sum", "(", ")", "\n", "if", "num_dups", ">", "0", ":", "\n", "                ", "logger", ".", "warning", "(", "f\"Duplicated samples in memory: {num_dups}\"", ")", "\n", "\n", "", "return", "ret", "\n", "\n", "", "mem_per_cls", "=", "self", ".", "memory_size", "//", "num_class", "\n", "exemplars", "=", "_reduce_exemplar_sets", "(", "exemplars", ",", "mem_per_cls", ")", "\n", "old_exemplar_df", "=", "pd", ".", "DataFrame", "(", "exemplars", ")", "\n", "\n", "new_exemplar_set", "=", "[", "]", "\n", "sample_df", "=", "pd", ".", "DataFrame", "(", "samples", ")", "\n", "for", "y", "in", "range", "(", "self", ".", "num_learning_class", ")", ":", "\n", "            ", "cls_samples", "=", "[", "]", "\n", "cls_exemplars", "=", "[", "]", "\n", "if", "len", "(", "sample_df", ")", "!=", "0", ":", "\n", "                ", "cls_samples", "=", "sample_df", "[", "sample_df", "[", "\"label\"", "]", "==", "y", "]", ".", "to_dict", "(", "\n", "orient", "=", "\"records\"", "\n", ")", "\n", "", "if", "len", "(", "old_exemplar_df", ")", "!=", "0", ":", "\n", "                ", "cls_exemplars", "=", "old_exemplar_df", "[", "old_exemplar_df", "[", "\"label\"", "]", "==", "y", "]", ".", "to_dict", "(", "\n", "orient", "=", "\"records\"", "\n", ")", "\n", "\n", "", "if", "len", "(", "cls_exemplars", ")", ">=", "mem_per_cls", ":", "\n", "                ", "new_exemplar_set", "+=", "cls_exemplars", "\n", "continue", "\n", "\n", "# Assign old exemplars to the samples", "\n", "", "cls_samples", "+=", "cls_exemplars", "\n", "if", "len", "(", "cls_samples", ")", "<=", "mem_per_cls", ":", "\n", "                ", "new_exemplar_set", "+=", "cls_samples", "\n", "continue", "\n", "\n", "", "features", "=", "[", "]", "\n", "self", ".", "feature_extractor", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "data", "in", "cls_samples", ":", "\n", "                    ", "audio_path", "=", "os", ".", "path", ".", "join", "(", "\"/home/xiaoyang/Dev/kws-efficient-cl/dataset/data\"", ",", "data", "[", "\"file_name\"", "]", ")", "\n", "waveform", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "audio_path", ")", "\n", "if", "waveform", ".", "shape", "[", "1", "]", "<", "self", ".", "sample_length", ":", "\n", "# padding if the audio length is smaller than samping length.", "\n", "                        ", "waveform", "=", "F", ".", "pad", "(", "waveform", ",", "[", "0", ",", "self", ".", "sample_length", "-", "waveform", ".", "shape", "[", "1", "]", "]", ")", "\n", "", "waveform", "=", "self", ".", "mfcc", "(", "waveform", ")", "\n", "waveform", "=", "waveform", ".", "to", "(", "self", ".", "device", ")", "\n", "feature", "=", "(", "\n", "self", ".", "feature_extractor", "(", "waveform", ".", "unsqueeze", "(", "0", ")", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", ")", "\n", "feature", "=", "feature", "/", "np", ".", "linalg", ".", "norm", "(", "feature", ",", "axis", "=", "1", ")", "# Normalize", "\n", "features", ".", "append", "(", "feature", ".", "squeeze", "(", ")", ")", "\n", "\n", "", "", "features", "=", "np", ".", "array", "(", "features", ")", "\n", "logger", ".", "debug", "(", "f\"[Prototype] features: {features.shape}\"", ")", "\n", "\n", "# do not replace the existing class mean", "\n", "if", "self", ".", "class_mean", "[", "y", "]", "is", "None", ":", "\n", "                ", "cls_mean", "=", "np", ".", "mean", "(", "features", ",", "axis", "=", "0", ")", "\n", "cls_mean", "/=", "np", ".", "linalg", ".", "norm", "(", "cls_mean", ")", "\n", "self", ".", "class_mean", "[", "y", "]", "=", "cls_mean", "\n", "", "else", ":", "\n", "                ", "cls_mean", "=", "self", ".", "class_mean", "[", "y", "]", "\n", "", "assert", "cls_mean", ".", "ndim", "==", "1", "\n", "\n", "phi", "=", "features", "\n", "mu", "=", "cls_mean", "\n", "# select exemplars from the scratch", "\n", "exemplar_features", "=", "[", "]", "\n", "num_exemplars", "=", "min", "(", "mem_per_cls", ",", "len", "(", "cls_samples", ")", ")", "\n", "for", "j", "in", "range", "(", "num_exemplars", ")", ":", "\n", "                ", "S", "=", "np", ".", "sum", "(", "exemplar_features", ",", "axis", "=", "0", ")", "\n", "mu_p", "=", "1.0", "/", "(", "j", "+", "1", ")", "*", "(", "phi", "+", "S", ")", "\n", "mu_p", "=", "mu_p", "/", "np", ".", "linalg", ".", "norm", "(", "mu_p", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "(", "mu", "-", "mu_p", ")", "**", "2", ",", "axis", "=", "1", ")", ")", "\n", "i", "=", "np", ".", "argmin", "(", "dist", ")", "\n", "\n", "new_exemplar_set", ".", "append", "(", "cls_samples", "[", "i", "]", ")", "\n", "exemplar_features", ".", "append", "(", "phi", "[", "i", "]", ")", "\n", "\n", "# Avoid to sample the duplicated one.", "\n", "del", "cls_samples", "[", "i", "]", "\n", "phi", "=", "np", ".", "delete", "(", "phi", ",", "i", ",", "0", ")", "\n", "\n", "", "", "return", "new_exemplar_set", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.uncertainty_sampling": [[515, 553], ["base.BaseMethod.montecarlo", "pandas.DataFrame", "range", "pandas.DataFrame().file_name.duplicated().sum", "len", "logger.warning", "sample_df[].sample().to_dict", "logger.warning", "len", "cls_df.to_dict", "uncertain_samples[].to_dict", "pandas.DataFrame().file_name.duplicated", "len", "cls_df.sort_values", "sample_df[].sample", "pandas.DataFrame", "pandas.DataFrame.file_name.isin", "pandas.DataFrame"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.montecarlo"], ["", "def", "uncertainty_sampling", "(", "self", ",", "samples", ",", "num_class", ")", ":", "\n", "        ", "\"\"\"uncertainty based sampling\n\n        Args:\n            samples ([list]): [training_list + memory_list]\n        \"\"\"", "\n", "self", ".", "montecarlo", "(", "samples", ",", "uncert_metric", "=", "self", ".", "uncert_metric", ")", "\n", "\n", "sample_df", "=", "pd", ".", "DataFrame", "(", "samples", ")", "\n", "mem_per_cls", "=", "self", ".", "memory_size", "//", "num_class", "# kc: the number of the samples of each class", "\n", "\n", "ret", "=", "[", "]", "\n", "\"\"\"\n        Sampling class by class\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "num_class", ")", ":", "\n", "            ", "cls_df", "=", "sample_df", "[", "sample_df", "[", "\"label\"", "]", "==", "i", "]", "\n", "if", "len", "(", "cls_df", ")", "<=", "mem_per_cls", ":", "\n", "                ", "ret", "+=", "cls_df", ".", "to_dict", "(", "orient", "=", "\"records\"", ")", "\n", "", "else", ":", "\n", "                ", "jump_idx", "=", "len", "(", "cls_df", ")", "//", "mem_per_cls", "\n", "uncertain_samples", "=", "cls_df", ".", "sort_values", "(", "by", "=", "\"uncertainty\"", ")", "[", ":", ":", "jump_idx", "]", "\n", "ret", "+=", "uncertain_samples", "[", ":", "mem_per_cls", "]", ".", "to_dict", "(", "orient", "=", "\"records\"", ")", "\n", "\n", "", "", "num_rest_slots", "=", "self", ".", "memory_size", "-", "len", "(", "ret", ")", "\n", "if", "num_rest_slots", ">", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Fill the unused slots by breaking the equilibrium.\"", ")", "\n", "ret", "+=", "(", "\n", "sample_df", "[", "~", "sample_df", ".", "file_name", ".", "isin", "(", "pd", ".", "DataFrame", "(", "ret", ")", ".", "file_name", ")", "]", "\n", ".", "sample", "(", "n", "=", "num_rest_slots", ")", "\n", ".", "to_dict", "(", "orient", "=", "\"records\"", ")", "\n", ")", "\n", "\n", "", "num_dups", "=", "pd", ".", "DataFrame", "(", "ret", ")", ".", "file_name", ".", "duplicated", "(", ")", ".", "sum", "(", ")", "\n", "if", "num_dups", ">", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Duplicated samples in memory: {num_dups}\"", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod._compute_uncert": [[554, 575], ["pandas.DataFrame", "utils.data_loader.SpeechDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "base.BaseMethod.model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "x.to.to.to", "base.BaseMethod.model", "logit.detach().cpu.detach().cpu.detach().cpu", "enumerate", "logit.detach().cpu.detach().cpu.detach"], "methods", ["None"], ["", "def", "_compute_uncert", "(", "self", ",", "infer_list", ",", "infer_transform", ",", "uncert_name", ")", ":", "\n", "        ", "batch_size", "=", "128", "\n", "infer_df", "=", "pd", ".", "DataFrame", "(", "infer_list", ")", "\n", "infer_dataset", "=", "SpeechDataset", "(", "\n", "infer_df", ",", "dataset", "=", "self", ".", "dataset", ",", "transform", "=", "infer_transform", ",", "is_training", "=", "False", "\n", ")", "\n", "infer_loader", "=", "DataLoader", "(", "\n", "infer_dataset", ",", "shuffle", "=", "False", ",", "batch_size", "=", "batch_size", ",", "num_workers", "=", "8", "\n", ")", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "n_batch", ",", "data", "in", "enumerate", "(", "infer_loader", ")", ":", "\n", "                ", "x", "=", "data", "[", "\"waveform\"", "]", "\n", "x", "=", "x", ".", "to", "(", "self", ".", "device", ")", "\n", "logit", "=", "self", ".", "model", "(", "x", ")", "\n", "logit", "=", "logit", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "for", "i", ",", "cert_value", "in", "enumerate", "(", "logit", ")", ":", "\n", "                    ", "sample", "=", "infer_list", "[", "batch_size", "*", "n_batch", "+", "i", "]", "\n", "sample", "[", "uncert_name", "]", "=", "1", "-", "cert_value", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.montecarlo": [[576, 599], ["logger.info", "len", "enumerate", "audiomentations.Compose", "base.BaseMethod._compute_uncert", "base.BaseMethod.variance_ratio", "audiomentations.AddGaussianNoise", "audiomentations.PitchShift", "audiomentations.Shift", "utils.data_loader.TimeMask", "audiomentations.FrequencyMask", "audiomentations.ClippingDistortion", "utils.data_loader.TimeMask", "str"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod._compute_uncert", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.variance_ratio"], ["", "", "", "", "def", "montecarlo", "(", "self", ",", "candidates", ",", "uncert_metric", "=", "\"vr\"", ")", ":", "\n", "        ", "transform_cands", "=", "[", "]", "\n", "logger", ".", "info", "(", "f\"Compute uncertainty by {uncert_metric}!\"", ")", "\n", "if", "uncert_metric", "==", "\"vr\"", ":", "\n", "            ", "transform_cands", "=", "[", "\n", "AddGaussianNoise", "(", "min_amplitude", "=", "0.001", ",", "max_amplitude", "=", "0.015", ",", "p", "=", "1", ")", ",", "\n", "PitchShift", "(", "min_semitones", "=", "-", "4", ",", "max_semitones", "=", "4", ",", "p", "=", "1", ")", ",", "\n", "Shift", "(", "min_fraction", "=", "-", "0.5", ",", "max_fraction", "=", "0.5", ",", "p", "=", "1", ")", ",", "\n", "TimeMask", "(", "min_band_part", "=", "0", ",", "max_band_part", "=", "0.1", ")", ",", "\n", "FrequencyMask", "(", "min_frequency_band", "=", "0", ",", "max_frequency_band", "=", "0.1", ",", "p", "=", "1", ")", ",", "\n", "ClippingDistortion", "(", "min_percentile_threshold", "=", "0", ",", "max_percentile_threshold", "=", "10", ",", "p", "=", "1", ")", "\n", "]", "\n", "", "elif", "uncert_metric", "==", "\"vr_timemask\"", ":", "\n", "            ", "transform_cands", "=", "[", "TimeMask", "(", "min_band_part", "=", "0", ",", "max_band_part", "=", "0.1", ")", "]", "*", "12", "\n", "\n", "", "n_transforms", "=", "len", "(", "transform_cands", ")", "\n", "\n", "for", "idx", ",", "tr", "in", "enumerate", "(", "transform_cands", ")", ":", "\n", "            ", "_tr", "=", "Compose", "(", "[", "tr", "]", ")", "\n", "self", ".", "_compute_uncert", "(", "candidates", ",", "_tr", ",", "uncert_name", "=", "f\"uncert_{str(idx)}\"", ")", "\n", "\n", "", "for", "sample", "in", "candidates", ":", "\n", "            ", "self", ".", "variance_ratio", "(", "sample", ",", "n_transforms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.variance_ratio": [[600, 607], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "sample[].size", "int", "torch.zeros.sum", "torch.zeros.sum", "torch.zeros.sum", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.zeros.max", "torch.zeros.max", "torch.zeros.max"], "methods", ["None"], ["", "", "def", "variance_ratio", "(", "self", ",", "sample", ",", "cand_length", ")", ":", "\n", "        ", "vote_counter", "=", "torch", ".", "zeros", "(", "sample", "[", "\"uncert_0\"", "]", ".", "size", "(", "0", ")", ")", "\n", "for", "i", "in", "range", "(", "cand_length", ")", ":", "\n", "            ", "top_class", "=", "int", "(", "torch", ".", "argmin", "(", "sample", "[", "f\"uncert_{i}\"", "]", ")", ")", "# uncert argmin.", "\n", "vote_counter", "[", "top_class", "]", "+=", "1", "\n", "", "assert", "vote_counter", ".", "sum", "(", ")", "==", "cand_length", "\n", "sample", "[", "\"uncertainty\"", "]", "=", "(", "1", "-", "vote_counter", ".", "max", "(", ")", "/", "cand_length", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.equal_class_sampling": [[608, 633], ["pandas.DataFrame", "range", "pandas.DataFrame().file_name.duplicated().sum", "cls_df.sample().to_dict", "len", "logger.warning", "sample_df[].sample().to_dict", "logger.warning", "pandas.DataFrame().file_name.duplicated", "cls_df.sample", "sample_df[].sample", "min", "pandas.DataFrame", "len", "pandas.DataFrame.file_name.isin", "pandas.DataFrame"], "methods", ["None"], ["", "def", "equal_class_sampling", "(", "self", ",", "samples", ",", "num_class", ")", ":", "\n", "        ", "mem_per_cls", "=", "self", ".", "memory_size", "//", "num_class", "\n", "sample_df", "=", "pd", ".", "DataFrame", "(", "samples", ")", "\n", "# Warning: assuming the classes were ordered following task number.", "\n", "ret", "=", "[", "]", "\n", "for", "y", "in", "range", "(", "self", ".", "num_learning_class", ")", ":", "\n", "            ", "cls_df", "=", "sample_df", "[", "sample_df", "[", "\"label\"", "]", "==", "y", "]", "\n", "ret", "+=", "cls_df", ".", "sample", "(", "n", "=", "min", "(", "mem_per_cls", ",", "len", "(", "cls_df", ")", ")", ")", ".", "to_dict", "(", "\n", "orient", "=", "\"records\"", "\n", ")", "\n", "\n", "", "num_rest_slots", "=", "self", ".", "memory_size", "-", "len", "(", "ret", ")", "\n", "if", "num_rest_slots", ">", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Fill the unused slots by breaking the equilibrium.\"", ")", "\n", "ret", "+=", "(", "\n", "sample_df", "[", "~", "sample_df", ".", "file_name", ".", "isin", "(", "pd", ".", "DataFrame", "(", "ret", ")", ".", "file_name", ")", "]", "\n", ".", "sample", "(", "n", "=", "num_rest_slots", ")", "\n", ".", "to_dict", "(", "orient", "=", "\"records\"", ")", "\n", ")", "\n", "\n", "", "num_dups", "=", "pd", ".", "DataFrame", "(", "ret", ")", ".", "file_name", ".", "duplicated", "(", ")", ".", "sum", "(", ")", "\n", "if", "num_dups", ">", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "f\"Duplicated samples in memory: {num_dups}\"", ")", "\n", "\n", "", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRLNet.__init__": [[32, 38], ["torch.nn.Module.__init__", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", ",", "feature_size", ",", "n_class", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "feature_size", ",", "momentum", "=", "0.01", ")", "\n", "self", ".", "ReLU", "=", "nn", ".", "ReLU", "(", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "feature_size", ",", "n_class", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRLNet.forward": [[39, 45], ["icarl.ICaRLNet.model", "icarl.ICaRLNet.bn", "icarl.ICaRLNet.ReLU", "icarl.ICaRLNet.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "model", "(", "x", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "x", "=", "self", ".", "ReLU", "(", "x", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRL.__init__": [[48, 71], ["methods.base.BaseMethod.__init__", "torch.nn.Linear", "torch.nn.Linear", "icarl.ICaRL.feature_extractor.to", "icarl.ICaRLNet", "icarl.ICaRL.icarlnet.to", "torch.nn.BCELoss", "torch.nn.BCELoss"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["    ", "def", "__init__", "(", "self", ",", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", ")", "\n", "self", ".", "batch_size", "=", "kwargs", "[", "\"batchsize\"", "]", "\n", "self", ".", "n_worker", "=", "kwargs", "[", "\"n_worker\"", "]", "\n", "self", ".", "exp_env", "=", "kwargs", "[", "\"stream_env\"", "]", "\n", "self", ".", "model", ".", "tc_resnet", ".", "linear", "=", "nn", ".", "Linear", "(", "self", ".", "model", ".", "tc_resnet", ".", "channels", "[", "-", "1", "]", ",", "self", ".", "feature_size", ")", "\n", "self", ".", "feature_extractor", "=", "self", ".", "model", "\n", "self", ".", "feature_extractor", "=", "self", ".", "feature_extractor", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "icarlnet", "=", "ICaRLNet", "(", "\n", "self", ".", "feature_extractor", ",", "self", ".", "feature_size", ",", "kwargs", "[", "\"n_init_cls\"", "]", "\n", ")", "\n", "self", ".", "icarlnet", "=", "self", ".", "icarlnet", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Learning method", "\n", "self", ".", "dist_loss", "=", "nn", ".", "BCELoss", "(", ")", "\n", "\n", "# Means of exemplars", "\n", "self", ".", "compute_means", "=", "True", "\n", "self", ".", "exemplar_means", "=", "[", "]", "\n", "\n", "if", "kwargs", "[", "\"mem_manage\"", "]", "==", "\"default\"", ":", "\n", "            ", "self", ".", "mem_manage", "=", "\"prototype\"", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRL.before_task": [[72, 119], ["pandas.DataFrame", "datalist_df[].unique().tolist", "list", "max", "icarl.ICaRL.feature_extractor.to", "icarl.ICaRL.icarlnet.to", "logger.info", "set", "torch.nn.Linear", "torch.nn.Linear", "icarl.ICaRLNet", "torch.nn.Linear", "torch.nn.Linear", "logger.info", "utils.train_utils.select_optimizer", "datalist_df[].unique", "datalist_df[].max"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.train_utils.select_optimizer"], ["", "", "def", "before_task", "(", "self", ",", "datalist", ",", "init_model", "=", "False", ",", "init_opt", "=", "True", ")", ":", "\n", "        ", "datalist_df", "=", "pd", ".", "DataFrame", "(", "datalist", ")", "\n", "incoming_classes", "=", "datalist_df", "[", "\"klass\"", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "exposed_classes", "=", "list", "(", "set", "(", "self", ".", "learned_classes", "+", "incoming_classes", ")", ")", "\n", "\n", "# learning_class increase monotonically", "\n", "self", ".", "num_learning_class", "=", "max", "(", "\n", "datalist_df", "[", "\"label\"", "]", ".", "max", "(", ")", "+", "1", ",", "self", ".", "num_learning_class", "\n", ")", "\n", "\n", "in_features", "=", "self", ".", "icarlnet", ".", "fc", ".", "in_features", "\n", "out_features", "=", "self", ".", "icarlnet", ".", "fc", ".", "out_features", "\n", "weight", "=", "self", ".", "icarlnet", ".", "fc", ".", "weight", ".", "data", "\n", "\n", "if", "init_model", ":", "\n", "# init model parameters in every iteration", "\n", "            ", "self", ".", "model", ".", "tc_resnet", ".", "linear", "=", "nn", ".", "Linear", "(", "\n", "self", ".", "model", ".", "tc_resnet", ".", "channels", "[", "-", "1", "]", ",", "self", ".", "feature_size", "\n", ")", "\n", "self", ".", "feature_extractor", "=", "self", ".", "model", "\n", "\n", "self", ".", "icarlnet", "=", "ICaRLNet", "(", "\n", "self", ".", "feature_extractor", ",", "self", ".", "feature_size", ",", "self", ".", "num_learning_class", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "icarlnet", ".", "fc", "=", "nn", ".", "Linear", "(", "\n", "in_features", ",", "self", ".", "num_learning_class", ",", "bias", "=", "False", "\n", ")", "\n", "\n", "# keep weights for the old classes", "\n", "", "self", ".", "icarlnet", ".", "fc", ".", "weight", ".", "data", "[", ":", "out_features", "]", "=", "weight", "\n", "\n", "self", ".", "feature_extractor", "=", "self", ".", "feature_extractor", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "icarlnet", "=", "self", ".", "icarlnet", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "if", "init_opt", ":", "\n", "# reinitialize the optimizer and scheduler", "\n", "            ", "logger", ".", "info", "(", "\"Reset the optimizer and scheduler states\"", ")", "\n", "self", ".", "optimizer", ",", "self", ".", "scheduler", "=", "select_optimizer", "(", "\n", "self", ".", "opt_name", ",", "self", ".", "lr", ",", "self", ".", "model", ",", "self", ".", "sched_name", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "\n", "f\"Increasing heads of fc layer {out_features} --> {self.num_learning_class})\"", "\n", ")", "\n", "\n", "self", ".", "already_mem_update", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRL.classify": [[120, 142], ["x.size", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "means.transpose.transpose.transpose", "icarl.ICaRL.feature_extractor.eval", "icarl.ICaRL.feature_extractor", "range", "feature.expand_as.expand_as.unsqueeze", "feature.expand_as.expand_as.expand_as", "dists.topk", "feature.expand_as.expand_as.size", "feature.expand_as.expand_as.data[].norm"], "methods", ["None"], ["", "def", "classify", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"Classify audios by nearest-means-of-exemplars\n        Args:\n            x: input audio batch\n        Returns:\n            pred: Tensor of size (batch_size,)\n        \"\"\"", "\n", "batch_size", "=", "x", ".", "size", "(", "0", ")", "\n", "means", "=", "torch", ".", "stack", "(", "self", ".", "exemplar_means", ")", "\n", "means", "=", "torch", ".", "stack", "(", "[", "means", "]", "*", "batch_size", ")", "\n", "means", "=", "means", ".", "transpose", "(", "1", ",", "2", ")", "\n", "self", ".", "feature_extractor", ".", "eval", "(", ")", "\n", "feature", "=", "self", ".", "feature_extractor", "(", "x", ")", "\n", "for", "i", "in", "range", "(", "feature", ".", "size", "(", "0", ")", ")", ":", "# Normalize", "\n", "            ", "feature", ".", "data", "[", "i", "]", "=", "feature", ".", "data", "[", "i", "]", "/", "feature", ".", "data", "[", "i", "]", ".", "norm", "(", ")", "\n", "", "feature", "=", "feature", ".", "unsqueeze", "(", "2", ")", "\n", "# (batch_size, feature_size, n_classes)", "\n", "feature", "=", "feature", ".", "expand_as", "(", "means", ")", "\n", "# (batch_size, n_classes)", "\n", "dists", "=", "(", "feature", "-", "means", ")", ".", "pow", "(", "2", ")", ".", "sum", "(", "1", ")", ".", "squeeze", "(", ")", "\n", "_", ",", "pred", "=", "dists", ".", "topk", "(", "k", "=", "self", ".", "topk", ",", "dim", "=", "1", ",", "largest", "=", "False", ",", "sorted", "=", "True", ")", "\n", "return", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRL.train": [[143, 286], ["random.shuffle", "icarl.ICaRL.get_dataloader", "logger.info", "logger.info", "logger.info", "logger.info", "dict", "icarl.ICaRL.icarlnet.train", "range", "icarl.ICaRL.update_memory", "icarl.ICaRL.icarl_evaluation", "max", "icarl.ICaRL.get_dataloader", "enumerate", "len", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "logger.info", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "icarl.ICaRL.icarlnet.eval", "data[].to", "data[].to", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "torch.nonzero().squeeze", "icarl.ICaRL.optimizer.zero_grad", "icarl.ICaRL.icarlnet", "loss.item", "loss.backward", "icarl.ICaRL.optimizer.step", "len", "len", "len", "len", "data[].to", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "enumerate", "icarl.ICaRL.scheduler.step", "torch.nonzero().squeeze.unsqueeze", "torch.nonzero().squeeze.unsqueeze", "torch.nonzero().squeeze.unsqueeze", "torch.nonzero().squeeze.unsqueeze", "data[].to.size", "torch.nonzero().squeeze.size", "torch.nonzero().squeeze.size", "cls_loss.item", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "range", "dist_loss.item", "icarl.ICaRL.icarlnet", "g[].detach", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero().squeeze.dim", "torch.nonzero().squeeze.dim", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero().squeeze.dim", "torch.nonzero().squeeze.dim", "torch.nonzero().squeeze.size", "torch.nonzero().squeeze.size", "torch.nonzero().squeeze.size", "torch.nonzero().squeeze.size", "utils.data_augmentation.mixup_data", "icarl.ICaRL.icarlnet", "icarl.ICaRL.criterion", "torch.nonzero().squeeze.size", "torch.nonzero().squeeze.size", "torch.stack.append", "torch.stack.append", "icarl.ICaRL.dist_loss", "icarl.ICaRL.criterion", "icarl.ICaRL.criterion"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.get_dataloader", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.joint.Joint.update_memory", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRL.icarl_evaluation", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.get_dataloader", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_augmentation.mixup_data"], ["", "def", "train", "(", "self", ",", "cur_iter", ",", "n_epoch", ",", "batch_size", ",", "n_worker", ")", ":", "\n", "        ", "train_list", "=", "self", ".", "streamed_list", "+", "self", ".", "memory_list", "\n", "random", ".", "shuffle", "(", "train_list", ")", "\n", "test_list", "=", "self", ".", "test_list", "\n", "train_loader", ",", "test_loader", "=", "self", ".", "get_dataloader", "(", "\n", "batch_size", ",", "n_worker", ",", "train_list", ",", "test_list", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Streamed samples: {len(self.streamed_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"In-memory samples: {len(self.memory_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"Train samples: {len(train_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"Test samples: {len(test_list)}\"", ")", "\n", "\n", "q", "=", "dict", "(", ")", "\n", "if", "self", ".", "num_learned_class", ">", "0", ":", "\n", "            ", "old_class_list", "=", "[", "\n", "sample", "\n", "for", "sample", "in", "train_list", "\n", "if", "sample", "[", "\"label\"", "]", "<", "self", ".", "num_learned_class", "\n", "]", "\n", "_", ",", "old_class_loader", "=", "self", ".", "get_dataloader", "(", "\n", "batch_size", ",", "n_worker", ",", "None", ",", "old_class_list", "\n", ")", "\n", "# Store network outputs with pre-update parameters", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "icarlnet", ".", "eval", "(", ")", "\n", "for", "data", "in", "old_class_loader", ":", "\n", "                    ", "waveforms", "=", "data", "[", "\"waveform\"", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "file_names", "=", "data", "[", "\"file_name\"", "]", "\n", "g", "=", "torch", ".", "sigmoid", "(", "self", ".", "icarlnet", "(", "waveforms", ")", ")", "\n", "for", "i", ",", "file_name", "in", "enumerate", "(", "file_names", ")", ":", "\n", "                        ", "q", "[", "file_name", "]", "=", "g", "[", "i", "]", ".", "detach", "(", ")", "\n", "\n", "# TRAIN", "\n", "", "", "", "", "best_acc", "=", "0.0", "\n", "self", ".", "icarlnet", ".", "train", "(", ")", "\n", "for", "epoch", "in", "range", "(", "n_epoch", ")", ":", "\n", "            ", "total_loss", ",", "total_cls_loss", ",", "total_dist_loss", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "\n", "if", "epoch", "<=", "0", ":", "# Warm start of 1 epoch", "\n", "                ", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "\"lr\"", "]", "=", "self", ".", "lr", "*", "0.1", "\n", "", "", "elif", "epoch", "==", "1", ":", "# Then set to max lr", "\n", "                ", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "\"lr\"", "]", "=", "self", ".", "lr", "\n", "", "", "else", ":", "# And go!", "\n", "                ", "self", ".", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "for", "i", ",", "data", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "                ", "x", "=", "data", "[", "\"waveform\"", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "y", "=", "data", "[", "\"label\"", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "file_names", "=", "data", "[", "\"file_name\"", "]", "\n", "\n", "old_cls_index", "=", "torch", ".", "nonzero", "(", "\n", "y", "<", "self", ".", "num_learned_class", ",", "as_tuple", "=", "False", "\n", ")", ".", "squeeze", "(", ")", "\n", "old_cls_index", "=", "(", "\n", "old_cls_index", ".", "unsqueeze", "(", "0", ")", "\n", "if", "old_cls_index", ".", "dim", "(", ")", "==", "0", "\n", "else", "old_cls_index", "\n", ")", "\n", "new_cls_index", "=", "torch", ".", "nonzero", "(", "\n", "y", ">=", "self", ".", "num_learned_class", ",", "as_tuple", "=", "False", "\n", ")", ".", "squeeze", "(", ")", "\n", "new_cls_index", "=", "(", "\n", "new_cls_index", ".", "unsqueeze", "(", "0", ")", "\n", "if", "new_cls_index", ".", "dim", "(", ")", "==", "0", "\n", "else", "new_cls_index", "\n", ")", "\n", "assert", "old_cls_index", ".", "size", "(", "0", ")", "+", "new_cls_index", ".", "size", "(", "0", ")", "==", "y", ".", "size", "(", "0", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "g", "=", "self", ".", "icarlnet", "(", "x", ")", "\n", "\n", "# Classification loss for new classes", "\n", "cls_loss", "=", "0", "\n", "if", "new_cls_index", ".", "size", "(", "0", ")", ">", "0", ":", "\n", "                    ", "if", "self", ".", "mix", ":", "\n", "                        ", "x", "=", "x", "[", "new_cls_index", "]", "\n", "y", "=", "y", "[", "new_cls_index", "]", "\n", "x", ",", "labels_a", ",", "labels_b", ",", "lam", "=", "mixup_data", "(", "x", "=", "x", ",", "y", "=", "y", ",", "alpha", "=", "0.5", ")", "\n", "g_", "=", "self", ".", "icarlnet", "(", "x", ")", "\n", "cls_loss", "+=", "lam", "*", "self", ".", "criterion", "(", "g_", ",", "labels_a", ")", "+", "(", "\n", "1", "-", "lam", "\n", ")", "*", "self", ".", "criterion", "(", "g_", ",", "labels_b", ")", "\n", "", "else", ":", "\n", "                        ", "cls_loss", "+=", "self", ".", "criterion", "(", "g", "[", "new_cls_index", "]", ",", "y", "[", "new_cls_index", "]", ")", "\n", "", "total_cls_loss", "+=", "cls_loss", ".", "item", "(", ")", "\n", "\n", "# Distillation loss for old classes", "\n", "", "dist_loss", "=", "0", "\n", "if", "self", ".", "num_learned_class", ">", "0", "and", "old_cls_index", ".", "size", "(", "0", ")", ">", "0", ":", "\n", "                    ", "g", "=", "torch", ".", "sigmoid", "(", "g", ")", "\n", "q_i", "=", "[", "]", "\n", "for", "idx", "in", "old_cls_index", ":", "\n", "                        ", "name", "=", "file_names", "[", "idx", "]", "\n", "q_i", ".", "append", "(", "q", "[", "name", "]", ")", "\n", "", "q_i", "=", "torch", ".", "stack", "(", "q_i", ",", "dim", "=", "0", ")", "\n", "\n", "for", "y", "in", "range", "(", "self", ".", "num_learned_class", ")", ":", "\n", "                        ", "dist_loss", "+=", "self", ".", "dist_loss", "(", "g", "[", "old_cls_index", ",", "y", "]", ",", "q_i", "[", ":", ",", "y", "]", ")", "\n", "\n", "", "total_dist_loss", "+=", "dist_loss", ".", "item", "(", ")", "\n", "\n", "", "loss", "=", "cls_loss", "+", "dist_loss", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "num_batches", "=", "len", "(", "train_loader", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "\n", "f\"task{cur_iter}/train/loss\"", ",", "total_loss", "/", "num_batches", ",", "epoch", "\n", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "f\"task{cur_iter}/train/cls_loss\"", ",", "total_cls_loss", "/", "num_batches", ",", "epoch", "\n", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "f\"task{cur_iter}/train/distilling\"", ",", "total_dist_loss", "/", "num_batches", ",", "epoch", "\n", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "f\"task{cur_iter}/train/lr\"", ",", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "epoch", "\n", ")", "\n", "\n", "train_loss", "=", "total_loss", "/", "num_batches", "\n", "train_cls_loss", "=", "total_cls_loss", "/", "num_batches", "\n", "train_dist_loss", "=", "total_dist_loss", "/", "num_batches", "\n", "\n", "logger", ".", "info", "(", "\n", "f\"Task {cur_iter} | Epoch {epoch + 1}/{n_epoch} | train_loss {train_loss:.4f} | \"", "\n", "f\"train_cls_loss {train_cls_loss:.4f} | train_distill_loss: {train_dist_loss:.4f} | \"", "\n", "f\"train_lr {self.optimizer.param_groups[0]['lr']:.4f}\"", "\n", ")", "\n", "\n", "# Icarl requires feature update(=compute exemplars) before the evaluation", "\n", "", "self", ".", "compute_means", "=", "True", "\n", "self", ".", "update_memory", "(", "cur_iter", ",", "self", ".", "num_learning_class", ")", "\n", "eval_dict", "=", "self", ".", "icarl_evaluation", "(", "test_loader", ")", "\n", "best_acc", "=", "max", "(", "best_acc", ",", "eval_dict", "[", "\"avg_acc\"", "]", ")", "\n", "\n", "return", "best_acc", ",", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRL._interpret_pred": [[287, 304], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "y.unique", "zip", "mask.sum().bool.sum().bool.sum().bool", "y.masked_select", "y.masked_select.unique", "zip", "y.unsqueeze", "mask.sum().bool.sum().bool.sum"], "methods", ["None"], ["", "def", "_interpret_pred", "(", "self", ",", "y", ",", "pred", ")", ":", "\n", "# xlable is batch", "\n", "        ", "ret_num_data", "=", "torch", ".", "zeros", "(", "self", ".", "n_classes", ")", "\n", "ret_corrects", "=", "torch", ".", "zeros", "(", "self", ".", "n_classes", ")", "\n", "\n", "xlabel_cls", ",", "xlabel_cnt", "=", "y", ".", "unique", "(", "return_counts", "=", "True", ")", "\n", "for", "cls_idx", ",", "cnt", "in", "zip", "(", "xlabel_cls", ",", "xlabel_cnt", ")", ":", "\n", "            ", "ret_num_data", "[", "cls_idx", "]", "=", "cnt", "\n", "\n", "", "mask", "=", "pred", "==", "y", ".", "unsqueeze", "(", "1", ")", "\n", "mask", "=", "mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "bool", "(", ")", "\n", "correct_xlabel", "=", "y", ".", "masked_select", "(", "mask", ")", "\n", "correct_cls", ",", "correct_cnt", "=", "correct_xlabel", ".", "unique", "(", "return_counts", "=", "True", ")", "\n", "for", "cls_idx", ",", "cnt", "in", "zip", "(", "correct_cls", ",", "correct_cnt", ")", ":", "\n", "            ", "ret_corrects", "[", "cls_idx", "]", "=", "cnt", "\n", "\n", "", "return", "ret_num_data", ",", "ret_corrects", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRL.icarl_evaluation": [[305, 366], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "icarl.ICaRL.feature_extractor.eval", "logger.info", "logger.info", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "pandas.DataFrame", "range", "data[].to", "icarl.ICaRL.classify", "y.size", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "icarl.ICaRL._interpret_pred", "cls_df.to_dict", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack.mean().squeeze", "torch.stack.mean().squeeze", "exemplar_means.append", "y.detach().cpu", "icarl.ICaRL.detach().cpu", "len", "logger.warning", "exemplar_means.append", "os.path.join", "torchaudio.load", "icarl.ICaRL.mfcc", "torch.pad.to", "icarl.ICaRL.feature_extractor", "feature.squeeze.squeeze.squeeze", "torch.stack.append", "torch.stack.append", "torch.stack.mean().squeeze.norm", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.pad", "torch.pad", "torch.pad.unsqueeze", "feature.squeeze.squeeze.data.norm", "torch.stack.mean", "torch.stack.mean", "y.detach", "icarl.ICaRL.detach", "icarl.ICaRL.detach().cpu", "y.unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "icarl.ICaRL.detach"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRL.classify", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRL._interpret_pred"], ["", "def", "icarl_evaluation", "(", "self", ",", "eval_loader", ")", ":", "\n", "        ", "correct_l", "=", "torch", ".", "zeros", "(", "self", ".", "n_classes", ")", "\n", "num_data_l", "=", "torch", ".", "zeros", "(", "self", ".", "n_classes", ")", "\n", "\n", "self", ".", "feature_extractor", ".", "eval", "(", ")", "\n", "if", "self", ".", "compute_means", ":", "\n", "            ", "logger", ".", "info", "(", "\"Computing mean of classes for classification\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "mem_df", "=", "pd", ".", "DataFrame", "(", "self", ".", "memory_list", ")", "\n", "exemplar_means", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_learning_class", ")", ":", "\n", "                    ", "cls_df", "=", "mem_df", "[", "mem_df", "[", "\"label\"", "]", "==", "i", "]", "\n", "cls_data", "=", "cls_df", ".", "to_dict", "(", "orient", "=", "\"records\"", ")", "\n", "\n", "if", "len", "(", "cls_data", ")", "==", "0", ":", "\n", "                        ", "logger", ".", "warning", "(", "f\"No samples for a class {i}\"", ")", "\n", "exemplar_means", ".", "append", "(", "\n", "torch", ".", "zeros", "(", "self", ".", "feature_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", ")", "\n", "continue", "\n", "\n", "", "features", "=", "[", "]", "\n", "for", "data", "in", "cls_data", ":", "\n", "                        ", "audio_path", "=", "os", ".", "path", ".", "join", "(", "\"/home/xiaoyang/Dev/kws-efficient-cl/dataset/data\"", ",", "data", "[", "\"file_name\"", "]", ")", "\n", "waveform", ",", "sample_rate", "=", "torchaudio", ".", "load", "(", "audio_path", ")", "\n", "if", "waveform", ".", "shape", "[", "1", "]", "<", "self", ".", "sample_length", ":", "\n", "# padding if the audio length is smaller than samping length.", "\n", "                            ", "waveform", "=", "F", ".", "pad", "(", "waveform", ",", "[", "0", ",", "self", ".", "sample_length", "-", "waveform", ".", "shape", "[", "1", "]", "]", ")", "\n", "", "waveform", "=", "self", ".", "mfcc", "(", "waveform", ")", "\n", "waveform", "=", "waveform", ".", "to", "(", "self", ".", "device", ")", "\n", "feature", "=", "self", ".", "feature_extractor", "(", "waveform", ".", "unsqueeze", "(", "0", ")", ")", "\n", "feature", "=", "feature", ".", "squeeze", "(", ")", "\n", "feature", ".", "data", "=", "feature", ".", "data", "/", "feature", ".", "data", ".", "norm", "(", ")", "# Normalize", "\n", "features", ".", "append", "(", "feature", ")", "\n", "", "features", "=", "torch", ".", "stack", "(", "features", ")", "\n", "mu_y", "=", "features", ".", "mean", "(", "0", ")", ".", "squeeze", "(", ")", "\n", "mu_y", "=", "mu_y", "/", "mu_y", ".", "norm", "(", ")", "# Normalize", "\n", "exemplar_means", ".", "append", "(", "mu_y", ")", "\n", "", "self", ".", "exemplar_means", "=", "exemplar_means", "\n", "self", ".", "compute_means", "=", "False", "\n", "\n", "", "", "total_num_data", ",", "total_correct", "=", "0.0", ",", "0.0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "data", "in", "eval_loader", ":", "\n", "                ", "x", "=", "data", "[", "\"waveform\"", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "y", "=", "data", "[", "\"label\"", "]", "\n", "pred", "=", "self", ".", "classify", "(", "x", ")", "\n", "total_num_data", "+=", "y", ".", "size", "(", "0", ")", "\n", "total_correct", "+=", "torch", ".", "sum", "(", "pred", ".", "detach", "(", ")", ".", "cpu", "(", ")", "==", "y", ".", "unsqueeze", "(", "1", ")", ")", ".", "item", "(", ")", "\n", "\n", "xlabel_cnt", ",", "correct_xlabel_cnt", "=", "self", ".", "_interpret_pred", "(", "\n", "y", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "pred", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", ")", "\n", "correct_l", "+=", "correct_xlabel_cnt", "\n", "num_data_l", "+=", "xlabel_cnt", "\n", "", "", "avg_acc", "=", "total_correct", "/", "total_num_data", "\n", "logger", ".", "info", "(", "\"[icarl_eval] test acc: {acc:.4f}\"", ".", "format", "(", "acc", "=", "avg_acc", ")", ")", "\n", "cls_acc", "=", "(", "correct_l", "/", "(", "num_data_l", "+", "1e-5", ")", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "ret", "=", "{", "\"avg_acc\"", ":", "avg_acc", ",", "\"cls_acc\"", ":", "cls_acc", "}", "\n", "\n", "return", "ret", "\n", "", "", ""]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrectionLayer.__init__": [[28, 33], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "bic.BiasCorrectionLayer.linear.weight.data.fill_", "bic.BiasCorrectionLayer.linear.bias.data.fill_"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "1", ",", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "linear", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "self", ".", "linear", ".", "bias", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrectionLayer.forward": [[34, 38], ["bic.BiasCorrectionLayer.linear", "correction.squeeze.squeeze.squeeze", "x.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "correction", "=", "self", ".", "linear", "(", "x", ".", "unsqueeze", "(", "dim", "=", "2", ")", ")", "\n", "correction", "=", "correction", ".", "squeeze", "(", "dim", "=", "2", ")", "\n", "return", "correction", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.__init__": [[41, 67], ["methods.base.BaseMethod.__init__", "round", "range", "bic.BiasCorrection.feature_extractor.to", "BiasCorrectionLayer().to", "bic.BiasCorrection.bias_layer_list.append", "bic.BiasCorrectionLayer"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["    ", "def", "__init__", "(", "self", ",", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        self.valid_list: valid set which is used for training bias correction layer.\n        self.memory_list: training set only including old classes. As already mentioned in the paper,\n        memory list and valid list are exclusive.\n        self.bias_layer_list - the list of bias correction layers. The index of the list means the task number.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", ")", "\n", "self", ".", "bias_layer", "=", "None", "\n", "self", ".", "valid_list", "=", "[", "]", "\n", "if", "kwargs", "[", "\"mem_manage\"", "]", "==", "\"default\"", ":", "\n", "            ", "self", ".", "mem_manage", "=", "\"prototype\"", "\n", "", "self", ".", "stream_env", "=", "kwargs", "[", "\"stream_env\"", "]", "\n", "\n", "self", ".", "valid_size", "=", "round", "(", "self", ".", "memory_size", "*", "0.1", ")", "\n", "self", ".", "memory_size", "=", "self", ".", "memory_size", "-", "self", ".", "valid_size", "\n", "self", ".", "n_tasks", "=", "kwargs", "[", "\"n_tasks\"", "]", "\n", "self", ".", "bias_layer_list", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "n_tasks", ")", ":", "\n", "            ", "bias_layer", "=", "BiasCorrectionLayer", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "bias_layer_list", ".", "append", "(", "bias_layer", ")", "\n", "", "self", ".", "init_cls", "=", "kwargs", "[", "\"n_init_cls\"", "]", "\n", "self", ".", "n_class_a_task", "=", "kwargs", "[", "\"n_cls_a_task\"", "]", "\n", "self", ".", "distilling", "=", "kwargs", "[", "\"distilling\"", "]", "\n", "self", ".", "feature_extractor", "=", "self", ".", "model", "\n", "self", ".", "feature_extractor", "=", "self", ".", "feature_extractor", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.distillation_loss": [[68, 76], ["torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "new_logit.size", "old_logit.size"], "methods", ["None"], ["", "def", "distillation_loss", "(", "self", ",", "old_logit", ",", "new_logit", ")", ":", "\n", "# new_logit should have same dimension with old_logit.(dimension = n)", "\n", "        ", "assert", "new_logit", ".", "size", "(", "1", ")", "==", "old_logit", ".", "size", "(", "1", ")", "\n", "T", "=", "2", "\n", "old_softmax", "=", "torch", ".", "softmax", "(", "old_logit", "/", "T", ",", "dim", "=", "1", ")", "\n", "new_log_softmax", "=", "torch", ".", "log_softmax", "(", "new_logit", "/", "T", ",", "dim", "=", "1", ")", "\n", "loss", "=", "-", "(", "old_softmax", "*", "new_log_softmax", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.bias_forward": [[77, 109], ["round", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "out.append", "torch.cat.size", "torch.cat.size", "input.size", "torch.cat.size", "torch.cat.size", "input.size", "input.size"], "methods", ["None"], ["", "def", "bias_forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "\"\"\"\n        forward bias correction layer.\n        input: the output of classification model\n        \"\"\"", "\n", "n_new_cls", "=", "self", ".", "n_class_a_task", "\n", "n_split", "=", "round", "(", "(", "input", ".", "size", "(", "1", ")", "-", "(", "\n", "self", ".", "init_cls", "-", "n_new_cls", ")", ")", "/", "n_new_cls", ")", "\n", "out", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_split", ")", ":", "\n", "            ", "sub_out", "=", "input", "[", ":", ",", "\n", "i", "*", "n_new_cls", "+", "(", "self", ".", "init_cls", "-", "n_new_cls", ")", ":", "(", "i", "+", "1", ")", "*", "n_new_cls", "+", "(", "self", ".", "init_cls", "-", "n_new_cls", ")", "]", "\n", "# Only for new classes", "\n", "if", "i", "==", "n_split", "-", "1", ":", "\n", "                ", "if", "i", "==", "0", ":", "\n", "                    ", "sub_out", "=", "self", ".", "bias_layer_list", "[", "i", "]", "(", "\n", "input", "[", ":", ",", "0", ":", "(", "i", "+", "1", ")", "*", "n_new_cls", "+", "(", "self", ".", "init_cls", "-", "n_new_cls", ")", "]", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "sub_out", "=", "self", ".", "bias_layer_list", "[", "i", "]", "(", "\n", "input", "[", ":", ",", "\n", "i", "*", "n_new_cls", "+", "(", "self", ".", "init_cls", "-", "n_new_cls", ")", ":", "(", "i", "+", "1", ")", "*", "n_new_cls", "+", "(", "self", ".", "init_cls", "-", "n_new_cls", ")", "]", "\n", ")", "\n", "", "", "if", "i", "==", "0", ":", "\n", "                ", "sub_out", "=", "input", "[", ":", ",", "\n", "0", ":", "(", "i", "+", "1", ")", "*", "n_new_cls", "+", "(", "\n", "self", ".", "init_cls", "-", "n_new_cls", ")", "]", "\n", "# logger.info(f\"i is {i}, n_split is {n_split}, input_size() is {input.size()}\")", "\n", "", "out", ".", "append", "(", "sub_out", ")", "\n", "", "ret", "=", "torch", ".", "cat", "(", "out", ",", "dim", "=", "1", ")", "\n", "assert", "ret", ".", "size", "(", "1", ")", "==", "input", ".", "size", "(", "1", ")", ",", "f\"final out: {ret.size()}, input size: {input.size()}\"", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.before_task": [[110, 145], ["logger.info", "[].unique().tolist", "list", "max", "max", "bic.BiasCorrection.model.to", "logger.info", "set", "len", "logger.info", "utils.train_utils.select_model", "torch.Linear", "torch.Linear", "logger.info", "utils.train_utils.select_optimizer", "logger.info", "bic.BiasCorrection.reduce_correction_examplers", "[].unique", "len", "pandas.DataFrame"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.train_utils.select_model", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.train_utils.select_optimizer", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.reduce_correction_examplers"], ["", "def", "before_task", "(", "self", ",", "datalist", ",", "init_model", "=", "False", ",", "init_opt", "=", "True", ",", "cur_iter", "=", "None", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Apply before_task\"", ")", "\n", "incoming_classes", "=", "pd", ".", "DataFrame", "(", "datalist", ")", "[", "\"klass\"", "]", ".", "unique", "(", ")", ".", "tolist", "(", ")", "\n", "self", ".", "exposed_classes", "=", "list", "(", "set", "(", "self", ".", "learned_classes", "+", "incoming_classes", ")", ")", "\n", "self", ".", "num_learning_class", "=", "max", "(", "\n", "len", "(", "self", ".", "exposed_classes", ")", ",", "self", ".", "num_learning_class", "\n", ")", "\n", "\n", "in_features", "=", "self", ".", "model", ".", "tc_resnet", ".", "channels", "[", "-", "1", "]", "\n", "out_features", "=", "self", ".", "model", ".", "tc_resnet", ".", "out_features", "\n", "# To care the case of decreasing head", "\n", "new_out_features", "=", "max", "(", "out_features", ",", "self", ".", "num_learning_class", ")", "\n", "if", "init_model", ":", "\n", "# init model parameters in every iteration", "\n", "            ", "logger", ".", "info", "(", "\"Reset model parameters\"", ")", "\n", "self", ".", "model", "=", "select_model", "(", "self", ".", "model_name", ",", "incoming_classes", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "tc_resnet", ".", "linear", "=", "nn", ".", "Linear", "(", "in_features", ",", "new_out_features", ")", "\n", "", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "init_opt", ":", "\n", "# reinitialize the optimizer and scheduler", "\n", "            ", "logger", ".", "info", "(", "\"Reset the optimizer and scheduler states\"", ")", "\n", "self", ".", "optimizer", ",", "self", ".", "scheduler", "=", "select_optimizer", "(", "\n", "self", ".", "opt_name", ",", "self", ".", "lr", ",", "self", ".", "model", ",", "self", ".", "sched_name", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"Increasing the head of fc {out_features} -> {new_out_features}\"", ")", "\n", "\n", "self", ".", "already_mem_update", "=", "False", "\n", "self", ".", "bias_layer", "=", "self", ".", "bias_layer_list", "[", "cur_iter", "]", "\n", "# When task num > 0, the correction list needs to reduce.", "\n", "if", "cur_iter", "!=", "0", ":", "\n", "            ", "n_sample", "=", "self", ".", "valid_size", "//", "len", "(", "self", ".", "learned_classes", ")", "\n", "logger", ".", "info", "(", "f\"[task {cur_iter}] n_sample: {n_sample} in valid_list\"", ")", "\n", "self", ".", "reduce_correction_examplers", "(", "num_sample", "=", "n_sample", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.reduce_correction_examplers": [[146, 155], ["pandas.DataFrame", "correction_df[].unique", "correction_df[].sample", "correction_df[].sample.to_dict"], "methods", ["None"], ["", "", "def", "reduce_correction_examplers", "(", "self", ",", "num_sample", ")", ":", "\n", "        ", "correction_df", "=", "pd", ".", "DataFrame", "(", "self", ".", "valid_list", ")", "\n", "valid_list", "=", "[", "]", "\n", "for", "label", "in", "correction_df", "[", "\"label\"", "]", ".", "unique", "(", ")", ":", "\n", "            ", "prev_correction_df", "=", "correction_df", "[", "correction_df", ".", "label", "==", "label", "]", ".", "sample", "(", "\n", "n", "=", "num_sample", "\n", ")", "\n", "valid_list", "+=", "prev_correction_df", ".", "to_dict", "(", "orient", "=", "\"records\"", ")", "\n", "", "self", ".", "valid_list", "=", "valid_list", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.construct_correction_examplers": [[156, 174], ["pandas.DataFrame", "sample_df[].unique", "len", "pandas.DataFrame", "len", "logger.warning", "sample_df[].sample", "sample_df[].sample.to_dict", "logger.warning"], "methods", ["None"], ["", "def", "construct_correction_examplers", "(", "self", ",", "num_sample", ")", ":", "\n", "        ", "sample_df", "=", "pd", ".", "DataFrame", "(", "self", ".", "streamed_list", ")", "\n", "if", "len", "(", "sample_df", ")", "==", "0", ":", "\n", "            ", "sample_df", "=", "pd", ".", "DataFrame", "(", "self", ".", "prev_streamed_list", ")", "\n", "\n", "", "if", "len", "(", "sample_df", ")", "==", "0", ":", "\n", "            ", "logger", ".", "warning", "(", "\"No candidates for validset from current dataset\"", ")", "\n", "return", "False", "\n", "\n", "", "for", "label", "in", "sample_df", "[", "\"label\"", "]", ".", "unique", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "new_correction_df", "=", "sample_df", "[", "sample_df", ".", "label", "==", "label", "]", ".", "sample", "(", "\n", "n", "=", "num_sample", "\n", ")", "\n", "self", ".", "valid_list", "+=", "new_correction_df", ".", "to_dict", "(", "orient", "=", "\"records\"", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "f\"Not available samples for bias_removal against label-{label}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.train": [[176, 266], ["logger.info", "logger.info", "logger.info", "random.shuffle", "logger.info", "bic.BiasCorrection.get_dataloader", "bic.BiasCorrection.model.to", "range", "bic.BiasCorrection.evaluation", "bic.BiasCorrection._train", "bic.BiasCorrection.evaluation", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "logger.info", "logger.info", "bic.BiasCorrection.construct_correction_examplers", "logger.info", "bic.BiasCorrection.construct_correction_examplers", "pandas.DataFrame", "utils.data_loader.SpeechDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "bic.BiasCorrection.bias_correction", "copy.deepcopy", "len", "len", "len", "len", "len", "len", "bic.BiasCorrection.scheduler.step"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.get_dataloader", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.evaluation", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk._train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.evaluation", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.construct_correction_examplers", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.construct_correction_examplers", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.bias_correction"], ["", "", "", "def", "train", "(", "self", ",", "cur_iter", ",", "n_epoch", ",", "batch_size", ",", "n_worker", ",", "n_passes", "=", "1", ")", ":", "\n", "\n", "        ", "logger", ".", "info", "(", "f\"Streamed samples: {len(self.streamed_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"In-memory samples: {len(self.memory_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"Test samples: {len(self.test_list)}\"", ")", "\n", "\n", "random", ".", "shuffle", "(", "self", ".", "streamed_list", ")", "\n", "\n", "test_list", "=", "self", ".", "test_list", "\n", "train_list", "=", "self", ".", "streamed_list", "+", "self", ".", "memory_list", "\n", "logger", ".", "info", "(", "\n", "\"[Task {}] self.training_list length: {}\"", ".", "format", "(", "cur_iter", ",", "len", "(", "train_list", ")", ")", "\n", ")", "\n", "\n", "train_loader", ",", "test_loader", "=", "self", ".", "get_dataloader", "(", "\n", "batch_size", ",", "n_worker", ",", "train_list", ",", "test_list", "\n", ")", "\n", "\n", "# TRAIN", "\n", "best_acc", "=", "0.0", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "epoch", "in", "range", "(", "n_epoch", ")", ":", "\n", "# https://github.com/drimpossible/GDumb/blob/master/src/main.py", "\n", "# initialize for each task", "\n", "            ", "if", "epoch", "<=", "0", ":", "# Warm start of 1 epoch", "\n", "                ", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "\"lr\"", "]", "=", "self", ".", "lr", "*", "0.1", "\n", "", "", "elif", "epoch", "==", "1", ":", "# Then set to maxlr", "\n", "                ", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "\"lr\"", "]", "=", "self", ".", "lr", "\n", "", "", "else", ":", "# Aand go!", "\n", "                ", "self", ".", "scheduler", ".", "step", "(", ")", "\n", "\n", "", "train_loss", "=", "self", ".", "_train", "(", "\n", "train_loader", "=", "train_loader", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ",", "\n", "criterion", "=", "self", ".", "criterion", ",", "\n", "epoch", "=", "epoch", ",", "\n", "total_epochs", "=", "n_epoch", ",", "\n", "cur_iter", "=", "cur_iter", ",", "\n", "n_passes", "=", "n_passes", ",", "\n", ")", "\n", "eval_dict", "=", "self", ".", "evaluation", "(", "\n", "test_loader", "=", "test_loader", ",", "criterion", "=", "self", ".", "criterion", "\n", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/train/loss\"", ",", "train_loss", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "f\"task{cur_iter}/train/lr\"", ",", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "epoch", "\n", ")", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/test/acc\"", ",", "eval_dict", "[", "\"avg_acc\"", "]", ",", "epoch", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "f\"Task {cur_iter} | Epoch {epoch + 1}/{n_epoch} | train_loss {train_loss:.4f} | \"", "\n", "f\"test_acc {eval_dict['avg_acc']:.4f} | train_lr {self.optimizer.param_groups[0]['lr']:.4f}\"", "\n", ")", "\n", "\n", "", "if", "cur_iter", "==", "0", ":", "\n", "            ", "n_sample", "=", "self", ".", "valid_size", "//", "len", "(", "self", ".", "exposed_classes", ")", "\n", "logger", ".", "info", "(", "\n", "f\"[task {cur_iter}] num samples for bias correction : {n_sample}\"", "\n", ")", "\n", "self", ".", "construct_correction_examplers", "(", "num_sample", "=", "n_sample", ")", "\n", "\n", "", "else", ":", "\n", "            ", "n_sample", "=", "self", ".", "valid_size", "//", "len", "(", "self", ".", "learned_classes", ")", "\n", "logger", ".", "info", "(", "\n", "f\"[task {cur_iter}] num samples for bias correction : {n_sample}\"", "\n", ")", "\n", "self", ".", "construct_correction_examplers", "(", "num_sample", "=", "n_sample", ")", "\n", "\n", "correction_df", "=", "pd", ".", "DataFrame", "(", "self", ".", "valid_list", ")", "\n", "correction_dataset", "=", "SpeechDataset", "(", "\n", "correction_df", ",", "dataset", "=", "self", ".", "dataset", ",", "is_training", "=", "False", "\n", ")", "\n", "correction_loader", "=", "DataLoader", "(", "\n", "correction_dataset", ",", "shuffle", "=", "True", ",", "batch_size", "=", "100", ",", "num_workers", "=", "2", "\n", ")", "\n", "self", ".", "bias_correction", "(", "\n", "bias_loader", "=", "correction_loader", ",", "\n", "test_loader", "=", "test_loader", ",", "\n", "criterion", "=", "self", ".", "criterion", ",", "\n", "n_epoch", "=", "n_epoch", ",", "\n", ")", "\n", "\n", "", "eval_dict", "=", "self", ".", "evaluation", "(", "test_loader", "=", "test_loader", ",", "criterion", "=", "self", ".", "criterion", ")", "\n", "if", "best_acc", "<", "eval_dict", "[", "\"avg_acc\"", "]", ":", "\n", "            ", "best_acc", "=", "eval_dict", "[", "\"avg_acc\"", "]", "\n", "self", ".", "prev_model", "=", "deepcopy", "(", "self", ".", "model", ")", "\n", "", "return", "best_acc", ",", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection._train": [[267, 325], ["bic.BiasCorrection.model.train", "enumerate", "len", "logger.debug", "x.to.to.to", "xlabel.to.to.to", "range", "bic.BiasCorrection.prev_model.eval", "optimizer.zero_grad", "bic.BiasCorrection.model", "bic.BiasCorrection.bias_forward", "criterion", "loss.backward", "optimizer.step", "loss.item", "bic.BiasCorrection.item", "criterion.item", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "bic.BiasCorrection.prev_model", "bic.BiasCorrection.bias_forward", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "bic.BiasCorrection.distillation_loss", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "bic.BiasCorrection.size"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.bias_forward", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.bias_forward", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.distillation_loss"], ["", "def", "_train", "(", "\n", "self", ",", "\n", "train_loader", ",", "\n", "optimizer", ",", "\n", "criterion", ",", "\n", "epoch", ",", "\n", "total_epochs", ",", "\n", "cur_iter", ",", "\n", "n_passes", "=", "1", ",", "\n", ")", ":", "\n", "        ", "total_loss", ",", "distill_loss", ",", "classify_loss", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "x", "=", "data", "[", "\"waveform\"", "]", "\n", "xlabel", "=", "data", "[", "\"label\"", "]", "\n", "x", "=", "x", ".", "to", "(", "self", ".", "device", ")", "\n", "xlabel", "=", "xlabel", ".", "to", "(", "self", ".", "device", ")", "\n", "if", "cur_iter", "!=", "0", ":", "\n", "                ", "self", ".", "prev_model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "logit_old", "=", "self", ".", "prev_model", "(", "x", ")", "\n", "logit_old", "=", "self", ".", "bias_forward", "(", "logit_old", ")", "\n", "\n", "", "", "for", "pass_", "in", "range", "(", "n_passes", ")", ":", "\n", "                ", "optimizer", ".", "zero_grad", "(", ")", "\n", "logit_new", "=", "self", ".", "model", "(", "x", ")", "\n", "logit_new", "=", "self", ".", "bias_forward", "(", "logit_new", ")", "\n", "loss_c", "=", "criterion", "(", "logit_new", ",", "xlabel", ")", "\n", "if", "cur_iter", "==", "0", ":", "\n", "                    ", "loss_d", "=", "torch", ".", "tensor", "(", "0.0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "                    ", "loss_d", "=", "self", ".", "distillation_loss", "(", "\n", "logit_old", ",", "logit_new", "[", ":", ",", ":", "logit_old", ".", "size", "(", "1", ")", "]", "\n", ")", "\n", "\n", "", "lam", "=", "len", "(", "self", ".", "learned_classes", ")", "/", "len", "(", "self", ".", "exposed_classes", ")", "\n", "if", "self", ".", "distilling", ":", "\n", "                    ", "loss", "=", "lam", "*", "loss_d", "+", "(", "1", "-", "lam", ")", "*", "loss_c", "\n", "", "else", ":", "\n", "                    ", "loss", "=", "loss_c", "\n", "", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "distill_loss", "+=", "loss_d", ".", "item", "(", ")", "\n", "classify_loss", "+=", "loss_c", ".", "item", "(", ")", "\n", "\n", "", "", "n_batches", "=", "len", "(", "train_loader", ")", "\n", "logger", ".", "debug", "(", "\n", "\"Stage 1 | Epoch {}/{} | loss: {:.4f} | distill_loss: {:.4f} | classify_loss:{:.4f}\"", ".", "format", "(", "\n", "epoch", "+", "1", ",", "\n", "total_epochs", ",", "\n", "total_loss", "/", "n_batches", ",", "\n", "distill_loss", "/", "n_batches", ",", "\n", "classify_loss", "/", "n_batches", ",", "\n", ")", "\n", ")", "\n", "return", "total_loss", "/", "n_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.bias_correction": [[326, 371], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "bic.BiasCorrection.model.eval", "range", "bic.BiasCorrection.print_bias_layer_parameters", "bic.BiasCorrection.bias_layer.train", "enumerate", "logger.info", "bic.BiasCorrection.bias_layer.parameters", "x.to.to.to", "xlabel.to.to.to", "bic.BiasCorrection.model", "bic.BiasCorrection.bias_forward", "criterion", "torch.optim.Adam.zero_grad", "torch.optim.Adam.zero_grad", "criterion.backward", "torch.optim.Adam.step", "torch.optim.Adam.step", "criterion.item", "bic.BiasCorrection.evaluation", "bic.BiasCorrection.bias_layer.linear.weight.item", "bic.BiasCorrection.bias_layer.linear.bias.item"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.print_bias_layer_parameters", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.bias_forward", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.evaluation"], ["", "def", "bias_correction", "(", "self", ",", "bias_loader", ",", "test_loader", ",", "criterion", ",", "n_epoch", ")", ":", "\n", "        ", "\"\"\"\n        Train the bias correction layer with bias_loader. (Linear Regression)\n\n        :param bias_loader: data loader from valid list.\n\n        \"\"\"", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "params", "=", "self", ".", "bias_layer", ".", "parameters", "(", ")", ",", "lr", "=", "0.001", ")", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "None", "\n", "# Get the logit from the STAGE 1", "\n", "for", "iteration", "in", "range", "(", "n_epoch", ")", ":", "\n", "            ", "self", ".", "bias_layer", ".", "train", "(", ")", "\n", "total_loss", "=", "0.0", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "bias_loader", ")", ":", "\n", "                ", "x", "=", "data", "[", "\"waveform\"", "]", "\n", "xlabel", "=", "data", "[", "\"label\"", "]", "\n", "x", "=", "x", ".", "to", "(", "self", ".", "device", ")", "\n", "xlabel", "=", "xlabel", ".", "to", "(", "self", ".", "device", ")", "\n", "out", "=", "self", ".", "model", "(", "x", ")", "\n", "logit", "=", "self", ".", "bias_forward", "(", "out", ")", "\n", "\n", "loss", "=", "criterion", "(", "logit", ",", "xlabel", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "\n", "\"[Stage 2] [{}/{}]\\tloss: {:.4f}\\talpha: {:.4f}\\tbeta: {:.4f}\"", ".", "format", "(", "\n", "iteration", "+", "1", ",", "\n", "n_epoch", ",", "\n", "total_loss", ",", "\n", "self", ".", "bias_layer", ".", "linear", ".", "weight", ".", "item", "(", ")", ",", "\n", "self", ".", "bias_layer", ".", "linear", ".", "bias", ".", "item", "(", ")", ",", "\n", ")", "\n", ")", "\n", "if", "iteration", "%", "50", "==", "0", ":", "\n", "                ", "self", ".", "evaluation", "(", "test_loader", "=", "test_loader", ",", "criterion", "=", "criterion", ")", "\n", "\n", "", "", "assert", "total_loss", "is", "not", "None", "\n", "\n", "self", ".", "print_bias_layer_parameters", "(", ")", "\n", "return", "total_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.evaluation_ext": [[372, 385], ["utils.data_loader.SpeechDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "bic.BiasCorrection.evaluation", "pandas.DataFrame"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.evaluation"], ["", "def", "evaluation_ext", "(", "self", ",", "test_list", ")", ":", "\n", "# evaluation from out of class", "\n", "        ", "test_dataset", "=", "SpeechDataset", "(", "\n", "pd", ".", "DataFrame", "(", "test_list", ")", ",", "\n", "dataset", "=", "self", ".", "dataset", ",", "\n", "is_training", "=", "False", "\n", ")", "\n", "test_loader", "=", "DataLoader", "(", "\n", "test_dataset", ",", "shuffle", "=", "False", ",", "batch_size", "=", "32", ",", "num_workers", "=", "2", "\n", ")", "\n", "eval_dict", "=", "self", ".", "evaluation", "(", "test_loader", ",", "self", ".", "criterion", ")", "\n", "\n", "return", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.evaluation": [[386, 427], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "bic.BiasCorrection.model.eval", "bic.BiasCorrection.bias_layer.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "len", "x.to.to.to", "bic.BiasCorrection.model", "bic.BiasCorrection.bias_forward", "logit.detach().cpu.detach().cpu.detach().cpu", "criterion", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "logit.detach().cpu.detach().cpu.topk", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "xlabel.size", "bic.BiasCorrection._interpret_pred", "correct_xlabel_cnt.detach().cpu", "xlabel_cnt.detach().cpu", "criterion.item", "xlabel.tolist", "logit.detach().cpu.detach().cpu.detach", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "correct_xlabel_cnt.detach", "xlabel_cnt.detach", "xlabel.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.bias_forward", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.icarl.ICaRL._interpret_pred"], ["", "def", "evaluation", "(", "self", ",", "test_loader", ",", "criterion", ")", ":", "\n", "        ", "total_correct", ",", "total_num_data", ",", "total_loss", "=", "(", "\n", "0.0", ",", "\n", "0.0", ",", "\n", "0.0", ",", "\n", ")", "\n", "correct_l", "=", "torch", ".", "zeros", "(", "self", ".", "n_classes", ")", "\n", "num_data_l", "=", "torch", ".", "zeros", "(", "self", ".", "n_classes", ")", "\n", "label", "=", "[", "]", "\n", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "bias_layer", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", ",", "data", "in", "enumerate", "(", "test_loader", ")", ":", "\n", "                ", "x", "=", "data", "[", "\"waveform\"", "]", "\n", "xlabel", "=", "data", "[", "\"label\"", "]", "\n", "x", "=", "x", ".", "to", "(", "self", ".", "device", ")", "\n", "logit", "=", "self", ".", "model", "(", "x", ")", "\n", "logit", "=", "self", ".", "bias_forward", "(", "logit", ")", "\n", "logit", "=", "logit", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "loss", "=", "criterion", "(", "logit", ",", "xlabel", ")", "\n", "pred", "=", "torch", ".", "argmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "_", ",", "preds", "=", "logit", ".", "topk", "(", "self", ".", "topk", ",", "1", ",", "True", ",", "True", ")", "\n", "total_correct", "+=", "torch", ".", "sum", "(", "preds", "==", "xlabel", ".", "unsqueeze", "(", "1", ")", ")", ".", "item", "(", ")", "\n", "total_num_data", "+=", "xlabel", ".", "size", "(", "0", ")", "\n", "\n", "xlabel_cnt", ",", "correct_xlabel_cnt", "=", "self", ".", "_interpret_pred", "(", "xlabel", ",", "pred", ")", "\n", "correct_l", "+=", "correct_xlabel_cnt", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "num_data_l", "+=", "xlabel_cnt", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "label", "+=", "xlabel", ".", "tolist", "(", ")", "\n", "\n", "", "", "avg_acc", "=", "total_correct", "/", "total_num_data", "\n", "avg_loss", "=", "total_loss", "/", "len", "(", "test_loader", ")", "\n", "\n", "cls_acc", "=", "(", "correct_l", "/", "(", "num_data_l", "+", "1e-5", ")", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", "\n", "ret", "=", "{", "\"avg_loss\"", ":", "avg_loss", ",", "\"avg_acc\"", ":", "avg_acc", ",", "\"cls_acc\"", ":", "cls_acc", "}", "\n", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.print_bias_layer_parameters": [[428, 433], ["enumerate", "logger.info", "layer.linear.weight.item", "layer.linear.bias.item"], "methods", ["None"], ["", "def", "print_bias_layer_parameters", "(", "self", ")", ":", "\n", "        ", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "bias_layer_list", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"[{}] alpha: {:.4f}, beta: {:.4f}\"", ".", "format", "(", "\n", "i", ",", "layer", ".", "linear", ".", "weight", ".", "item", "(", ")", ",", "layer", ".", "linear", ".", "bias", ".", "item", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.rainbow_keywords.RK.__init__": [[36, 46], ["methods.base.BaseMethod.__init__", "utils.kd_manager.KdManager"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["    ", "def", "__init__", "(", "self", ",", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", ")", "\n", "self", ".", "batch_size", "=", "kwargs", "[", "\"batchsize\"", "]", "\n", "self", ".", "n_worker", "=", "kwargs", "[", "\"n_worker\"", "]", "\n", "self", ".", "exp_env", "=", "kwargs", "[", "\"stream_env\"", "]", "\n", "if", "kwargs", "[", "\"mem_manage\"", "]", "==", "\"default\"", ":", "\n", "            ", "self", ".", "mem_manage", "=", "\"uncertainty\"", "\n", "", "self", ".", "task_seen", "=", "None", "\n", "self", ".", "kd_manager", "=", "KdManager", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.rainbow_keywords.RK.train": [[47, 117], ["random.shuffle", "rainbow_keywords.RK.get_dataloader", "logger.info", "logger.info", "logger.info", "logger.info", "dict", "rainbow_keywords.RK.model.to", "range", "len", "utils.data_loader.SpeechDataset", "torch.utils.data.DataLoader", "rainbow_keywords.RK._train", "rainbow_keywords.RK.evaluation", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "logger.info", "max", "pandas.DataFrame", "len", "len", "len", "rainbow_keywords.RK.scheduler.step", "len", "len"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.get_dataloader", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk._train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.evaluation"], ["", "def", "train", "(", "self", ",", "cur_iter", ",", "n_epoch", ",", "batch_size", ",", "n_worker", ",", "n_passes", "=", "0", ")", ":", "\n", "        ", "self", ".", "task_seen", "=", "cur_iter", "\n", "if", "len", "(", "self", ".", "memory_list", ")", ">", "0", ":", "\n", "            ", "mem_dataset", "=", "SpeechDataset", "(", "\n", "pd", ".", "DataFrame", "(", "self", ".", "memory_list", ")", ",", "\n", "dataset", "=", "self", ".", "dataset", ",", "\n", "is_training", "=", "True", ",", "\n", "transform", "=", "self", ".", "transform", "\n", ")", "\n", "memory_loader", "=", "DataLoader", "(", "\n", "mem_dataset", ",", "\n", "shuffle", "=", "True", ",", "\n", "batch_size", "=", "(", "batch_size", "//", "2", ")", ",", "\n", "num_workers", "=", "n_worker", ",", "\n", ")", "\n", "stream_batch_size", "=", "batch_size", "-", "batch_size", "//", "2", "\n", "", "else", ":", "\n", "            ", "memory_loader", "=", "None", "\n", "stream_batch_size", "=", "batch_size", "\n", "\n", "# train_list == streamed_list in RM", "\n", "", "train_list", "=", "self", ".", "streamed_list", "\n", "test_list", "=", "self", ".", "test_list", "\n", "random", ".", "shuffle", "(", "train_list", ")", "\n", "# Configuring a batch with streamed and memory data equally.", "\n", "train_loader", ",", "test_loader", "=", "self", ".", "get_dataloader", "(", "\n", "stream_batch_size", ",", "n_worker", ",", "train_list", ",", "test_list", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Streamed samples: {len(self.streamed_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"In-memory samples: {len(self.memory_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"Train samples: {len(train_list) + len(self.memory_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"Test samples: {len(test_list)}\"", ")", "\n", "\n", "# TRAIN", "\n", "best_acc", "=", "0.0", "\n", "eval_dict", "=", "dict", "(", ")", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "epoch", "in", "range", "(", "n_epoch", ")", ":", "\n", "# initialize for each task", "\n", "            ", "if", "epoch", "<=", "0", ":", "# Warm start of 1 epoch", "\n", "                ", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "\"lr\"", "]", "=", "self", ".", "lr", "*", "0.1", "\n", "", "", "elif", "epoch", "==", "1", ":", "# Then set to maxlr", "\n", "                ", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "\"lr\"", "]", "=", "self", ".", "lr", "\n", "", "", "else", ":", "# Aand go!", "\n", "                ", "self", ".", "scheduler", ".", "step", "(", ")", "\n", "", "train_loss", ",", "train_acc", "=", "self", ".", "_train", "(", "train_loader", "=", "train_loader", ",", "memory_loader", "=", "memory_loader", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ",", "criterion", "=", "self", ".", "criterion", ")", "\n", "eval_dict", "=", "self", ".", "evaluation", "(", "\n", "test_loader", "=", "test_loader", ",", "criterion", "=", "self", ".", "criterion", "\n", ")", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/train/loss\"", ",", "train_loss", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/train/acc\"", ",", "train_acc", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/test/loss\"", ",", "eval_dict", "[", "\"avg_loss\"", "]", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/test/acc\"", ",", "eval_dict", "[", "\"avg_acc\"", "]", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "f\"task{cur_iter}/train/lr\"", ",", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "epoch", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "f\"Task {cur_iter} | Epoch {epoch + 1}/{n_epoch} | train_loss {train_loss:.4f} | train_acc {train_acc:.4f} | \"", "\n", "f\"test_loss {eval_dict['avg_loss']:.4f} | test_acc {eval_dict['avg_acc']:.4f} | \"", "\n", "f\"lr {self.optimizer.param_groups[0]['lr']:.4f}\"", "\n", ")", "\n", "\n", "best_acc", "=", "max", "(", "best_acc", ",", "eval_dict", "[", "\"avg_acc\"", "]", ")", "\n", "\n", "", "return", "best_acc", ",", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.rainbow_keywords.RK.update_model": [[118, 137], ["optimizer.zero_grad", "rainbow_keywords.RK.topk", "criterion.backward", "optimizer.step", "utils.data_augmentation.mixup_data", "rainbow_keywords.RK.model", "rainbow_keywords.RK.model", "criterion", "criterion.item", "torch.sum().item", "y.size", "rainbow_keywords.RK.kd_manager.get_kd_loss", "criterion", "criterion", "torch.sum", "y.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_augmentation.mixup_data", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.kd_manager.KdManager.get_kd_loss"], ["", "def", "update_model", "(", "self", ",", "x", ",", "y", ",", "criterion", ",", "optimizer", ")", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "mix", ":", "\n", "            ", "x", ",", "labels_a", ",", "labels_b", ",", "lam", "=", "mixup_data", "(", "x", "=", "x", ",", "y", "=", "y", ",", "alpha", "=", "0.5", ")", "\n", "logit", "=", "self", ".", "model", "(", "x", ")", "\n", "loss", "=", "lam", "*", "criterion", "(", "logit", ",", "labels_a", ")", "+", "(", "1", "-", "lam", ")", "*", "criterion", "(", "\n", "logit", ",", "labels_b", "\n", ")", "\n", "", "else", ":", "\n", "            ", "logit", "=", "self", ".", "model", "(", "x", ")", "\n", "loss", "=", "criterion", "(", "logit", ",", "y", ")", "\n", "# use knowledge distillation loss", "\n", "", "loss", "=", "1", "/", "(", "(", "self", ".", "task_seen", "+", "1", ")", "**", "0.5", ")", "*", "loss", "+", "(", "1", "-", "1", "/", "(", "(", "self", ".", "task_seen", "+", "1", ")", "**", "0.5", ")", ")", "*", "self", ".", "kd_manager", ".", "get_kd_loss", "(", "logit", ",", "x", ")", "\n", "_", ",", "preds", "=", "logit", ".", "topk", "(", "self", ".", "topk", ",", "1", ",", "True", ",", "True", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "return", "loss", ".", "item", "(", ")", ",", "torch", ".", "sum", "(", "preds", "==", "y", ".", "unsqueeze", "(", "1", ")", ")", ".", "item", "(", ")", ",", "y", ".", "size", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.rainbow_keywords.RK._train": [[138, 176], ["rainbow_keywords.RK.model.train", "zip", "torch.cat.to", "torch.cat.to", "rainbow_keywords.RK.update_model", "len", "len", "rainbow_keywords.cycle", "len", "torch.cat", "torch.cat", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.update_model", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.rainbow_keywords.cycle"], ["", "def", "_train", "(", "\n", "self", ",", "train_loader", ",", "memory_loader", ",", "optimizer", ",", "criterion", "\n", ")", ":", "\n", "        ", "total_loss", ",", "correct", ",", "num_data", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "if", "memory_loader", "is", "not", "None", "and", "train_loader", "is", "not", "None", ":", "\n", "            ", "data_iterator", "=", "zip", "(", "train_loader", ",", "cycle", "(", "memory_loader", ")", ")", "\n", "", "elif", "memory_loader", "is", "not", "None", ":", "\n", "            ", "data_iterator", "=", "memory_loader", "\n", "", "elif", "train_loader", "is", "not", "None", ":", "\n", "            ", "data_iterator", "=", "train_loader", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"None of dataloder is valid\"", ")", "\n", "\n", "", "for", "data", "in", "data_iterator", ":", "\n", "            ", "if", "len", "(", "data", ")", "==", "2", ":", "\n", "                ", "stream_data", ",", "mem_data", "=", "data", "\n", "x", "=", "torch", ".", "cat", "(", "[", "stream_data", "[", "\"waveform\"", "]", ",", "mem_data", "[", "\"waveform\"", "]", "]", ")", "\n", "y", "=", "torch", ".", "cat", "(", "[", "stream_data", "[", "\"label\"", "]", ",", "mem_data", "[", "\"label\"", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "data", "[", "\"waveform\"", "]", "\n", "y", "=", "data", "[", "\"label\"", "]", "\n", "\n", "", "x", "=", "x", ".", "to", "(", "self", ".", "device", ")", "\n", "y", "=", "y", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "l", ",", "c", ",", "d", "=", "self", ".", "update_model", "(", "x", ",", "y", ",", "criterion", ",", "optimizer", ")", "\n", "total_loss", "+=", "l", "\n", "correct", "+=", "c", "\n", "num_data", "+=", "d", "\n", "\n", "", "if", "train_loader", "is", "not", "None", ":", "\n", "            ", "n_batches", "=", "len", "(", "train_loader", ")", "\n", "", "else", ":", "\n", "            ", "n_batches", "=", "len", "(", "memory_loader", ")", "\n", "\n", "", "return", "total_loss", "/", "n_batches", ",", "correct", "/", "num_data", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.rainbow_keywords.RK.allocate_batch_size": [[177, 183], ["int"], "methods", ["None"], ["", "def", "allocate_batch_size", "(", "self", ",", "n_old_class", ",", "n_new_class", ")", ":", "\n", "        ", "new_batch_size", "=", "int", "(", "\n", "self", ".", "batch_size", "*", "n_new_class", "/", "(", "n_old_class", "+", "n_new_class", ")", "\n", ")", "\n", "old_batch_size", "=", "self", ".", "batch_size", "-", "new_batch_size", "\n", "return", "new_batch_size", ",", "old_batch_size", "\n", "", "", ""]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.rainbow_keywords.cycle": [[28, 33], ["None"], "function", ["None"], ["def", "cycle", "(", "iterable", ")", ":", "\n", "# iterate with shuffling", "\n", "    ", "while", "True", ":", "\n", "        ", "for", "i", "in", "iterable", ":", "\n", "            ", "yield", "i", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.finetune.Finetune.__init__": [[12, 21], ["methods.base.BaseMethod.__init__", "Exception"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["    ", "def", "__init__", "(", "self", ",", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", ")", "\n", "if", "self", ".", "mode", "==", "\"finetune\"", ":", "\n", "            ", "self", ".", "memory_size", "=", "0", "\n", "if", "kwargs", "[", "\"stream_env\"", "]", "==", "\"online\"", ":", "\n", "                ", "raise", "Exception", "(", "\"Finetune method with online environment will have 0 samples for training, please set \"", "\n", "\"offline environment\"", ")", "\n", "", "", "if", "self", ".", "mode", "==", "\"native_rehearsal\"", "and", "self", ".", "mem_manage", "==", "\"default\"", ":", "\n", "            ", "self", ".", "mem_manage", "=", "\"random\"", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.joint.Joint.__init__": [[19, 29], ["methods.base.BaseMethod.__init__", "utils.train_utils.select_model", "utils.train_utils.select_optimizer", "joint.Joint.model.to", "joint.Joint.criterion.to"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.train_utils.select_model", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.train_utils.select_optimizer"], ["    ", "def", "__init__", "(", "self", ",", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", ")", "\n", "self", ".", "model", "=", "select_model", "(", "self", ".", "model_name", ",", "n_classes", ")", "\n", "self", ".", "optimizer", ",", "self", ".", "scheduler", "=", "select_optimizer", "(", "\n", "kwargs", "[", "\"opt_name\"", "]", ",", "kwargs", "[", "\"lr\"", "]", ",", "self", ".", "model", "\n", ")", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "criterion", "=", "self", ".", "criterion", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "num_learning_class", "=", "n_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.joint.Joint.before_task": [[31, 33], ["None"], "methods", ["None"], ["", "def", "before_task", "(", "self", ",", "datalist", ",", "init_model", ",", "init_opt", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.joint.Joint.after_task": [[34, 36], ["None"], "methods", ["None"], ["", "def", "after_task", "(", "self", ",", "cur_iter", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.joint.Joint.update_memory": [[37, 39], ["None"], "methods", ["None"], ["", "def", "update_memory", "(", "self", ",", "cur_iter", ",", "num_class", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.__init__": [[28, 42], ["methods.base.BaseMethod.__init__", "list", "regularization.Regularization.model.named_parameters"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["def", "__init__", "(", "self", ",", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", ")", "\n", "# except for last layers.", "\n", "self", ".", "params", "=", "{", "\n", "n", ":", "p", "for", "n", ",", "p", "in", "list", "(", "self", ".", "model", ".", "named_parameters", "(", ")", ")", "[", ":", "-", "2", "]", "if", "p", ".", "requires_grad", "\n", "}", "# For convenience", "\n", "self", ".", "regularization_terms", "=", "{", "}", "\n", "self", ".", "task_count", "=", "0", "\n", "self", ".", "reg_coef", "=", "kwargs", "[", "\"reg_coef\"", "]", "\n", "if", "self", ".", "mode", "==", "\"rwalk\"", ":", "\n", "            ", "self", ".", "reg_coef", "=", "100", "\n", "", "if", "kwargs", "[", "\"mem_manage\"", "]", "==", "\"default\"", ":", "\n", "            ", "self", ".", "mem_manage", "=", "\"reservoir\"", "\n", "", "self", ".", "online_reg", "=", "\"online\"", "in", "kwargs", "[", "\"stream_env\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.calculate_importance": [[43, 49], ["regularization.Regularization.params.items", "p.clone().detach().fill_", "p.clone().detach", "p.clone"], "methods", ["None"], ["", "def", "calculate_importance", "(", "self", ",", "dataloader", ")", ":", "\n", "# Use an identity importance so it is an L2 regularization.", "\n", "        ", "importance", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "importance", "[", "n", "]", "=", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "fill_", "(", "1", ")", "# Identity", "\n", "", "return", "importance", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.update_model": [[50, 57], ["regularization.Regularization.model", "regularization.Regularization.regularization_loss", "optimizer.zero_grad", "regularization.Regularization.backward", "optimizer.step", "regularization.Regularization.detach"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.regularization_loss"], ["", "def", "update_model", "(", "self", ",", "inputs", ",", "targets", ",", "optimizer", ")", ":", "\n", "        ", "out", "=", "self", ".", "model", "(", "inputs", ")", "\n", "loss", "=", "self", ".", "regularization_loss", "(", "out", ",", "targets", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "return", "loss", ".", "detach", "(", ")", ",", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.train": [[58, 140], ["random.shuffle", "regularization.Regularization.get_dataloader", "logger.info", "logger.info", "logger.info", "logger.info", "dict", "range", "regularization.Regularization.params.items", "regularization.Regularization.calculate_importance", "logger.debug", "regularization.Regularization._train", "regularization.Regularization.evaluation", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "writer.add_scalar", "logger.info", "p.clone().detach", "len", "len", "len", "len", "len", "regularization.Regularization.scheduler.step", "p.clone", "len"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.base.BaseMethod.get_dataloader", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.calculate_importance", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk._train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.bic.BiasCorrection.evaluation"], ["", "def", "train", "(", "self", ",", "cur_iter", ",", "n_epoch", ",", "batch_size", ",", "n_worker", ")", ":", "\n", "# Loader", "\n", "        ", "train_list", "=", "self", ".", "streamed_list", "+", "self", ".", "memory_list", "\n", "random", ".", "shuffle", "(", "train_list", ")", "\n", "test_list", "=", "self", ".", "test_list", "\n", "train_loader", ",", "test_loader", "=", "self", ".", "get_dataloader", "(", "\n", "batch_size", ",", "n_worker", ",", "train_list", ",", "test_list", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Streamed samples: {len(self.streamed_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"In-memory samples: {len(self.memory_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"Train samples: {len(train_list)}\"", ")", "\n", "logger", ".", "info", "(", "f\"Test samples: {len(test_list)}\"", ")", "\n", "\n", "# TRAIN", "\n", "best_acc", "=", "0.0", "\n", "eval_dict", "=", "dict", "(", ")", "\n", "for", "epoch", "in", "range", "(", "n_epoch", ")", ":", "\n", "# learning rate scheduling from", "\n", "# https://github.com/drimpossible/GDumb/blob/master/src/main.py", "\n", "# initialize for each task", "\n", "            ", "if", "epoch", "<=", "0", ":", "# Warm start of 1 epoch", "\n", "                ", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "\"lr\"", "]", "=", "self", ".", "lr", "*", "0.1", "\n", "", "", "elif", "epoch", "==", "1", ":", "# Then set to maxlr", "\n", "                ", "for", "param_group", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "\"lr\"", "]", "=", "self", ".", "lr", "\n", "", "", "else", ":", "# Aand go!", "\n", "                ", "self", ".", "scheduler", ".", "step", "(", ")", "\n", "", "train_loss", ",", "train_acc", "=", "self", ".", "_train", "(", "\n", "train_loader", "=", "train_loader", ",", "\n", "optimizer", "=", "self", ".", "optimizer", ",", "\n", "epoch", "=", "epoch", ",", "\n", "total_epochs", "=", "n_epoch", ",", "\n", ")", "\n", "eval_dict", "=", "self", ".", "evaluation", "(", "\n", "test_loader", "=", "test_loader", ",", "criterion", "=", "self", ".", "criterion", "\n", ")", "\n", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/train/loss\"", ",", "train_loss", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/train/acc\"", ",", "train_acc", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/test/loss\"", ",", "eval_dict", "[", "\"avg_loss\"", "]", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "f\"task{cur_iter}/test/acc\"", ",", "eval_dict", "[", "\"avg_acc\"", "]", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "\n", "f\"task{cur_iter}/train/lr\"", ",", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", ",", "epoch", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "f\"Task {cur_iter} | Epoch {epoch + 1}/{n_epoch} | train_loss {train_loss:.4f} | train_acc {train_acc:.4f} | \"", "\n", "f\"test_loss {eval_dict['avg_loss']:.4f} | test_acc {eval_dict['avg_acc']:.4f} | \"", "\n", "f\"lr {self.optimizer.param_groups[0]['lr']:.4f}\"", "\n", ")", "\n", "\n", "if", "best_acc", "<", "eval_dict", "[", "\"avg_acc\"", "]", ":", "\n", "                ", "best_acc", "=", "eval_dict", "[", "\"avg_acc\"", "]", "\n", "\n", "# 2.Backup the weight of current task", "\n", "", "", "task_param", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "task_param", "[", "n", "]", "=", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "\n", "# 3.Calculate the importance of weights for current task", "\n", "", "importance", "=", "self", ".", "calculate_importance", "(", "train_loader", ")", "\n", "\n", "# Save the weight and importance of weights of current task", "\n", "self", ".", "task_count", "+=", "1", "\n", "\n", "# Use a new slot to store the task-specific information", "\n", "if", "self", ".", "online_reg", "and", "len", "(", "self", ".", "regularization_terms", ")", ">", "0", ":", "\n", "# Always use only one slot in self.regularization_terms", "\n", "            ", "self", ".", "regularization_terms", "[", "1", "]", "=", "{", "\n", "\"importance\"", ":", "importance", ",", "\n", "\"task_param\"", ":", "task_param", ",", "\n", "}", "\n", "", "else", ":", "\n", "# Use a new slot to store the task-specific information", "\n", "            ", "self", ".", "regularization_terms", "[", "self", ".", "task_count", "]", "=", "{", "\n", "\"importance\"", ":", "importance", ",", "\n", "\"task_param\"", ":", "task_param", ",", "\n", "}", "\n", "", "logger", ".", "debug", "(", "f\"# of reg_terms: {len(self.regularization_terms)}\"", ")", "\n", "\n", "return", "best_acc", ",", "eval_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization._train": [[141, 175], ["regularization.Regularization.model.train", "enumerate", "len", "x.to.to.to", "y.to.to.to", "optimizer.zero_grad", "regularization.Regularization.regularization_loss", "regularization.Regularization.backward", "optimizer.step", "regularization.Regularization.topk", "regularization.Regularization.item", "torch.sum().item", "y.to.to.size", "utils.data_augmentation.mixup_data", "regularization.Regularization.model", "regularization.Regularization.model", "regularization.Regularization.criterion", "torch.sum", "regularization.Regularization.criterion", "regularization.Regularization.criterion", "y.to.to.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.regularization_loss", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_augmentation.mixup_data"], ["", "def", "_train", "(", "self", ",", "train_loader", ",", "optimizer", ",", "epoch", ",", "total_epochs", ")", ":", "\n", "        ", "total_loss", ",", "correct", ",", "num_data", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "x", "=", "data", "[", "\"waveform\"", "]", "\n", "y", "=", "data", "[", "\"label\"", "]", "\n", "x", "=", "x", ".", "to", "(", "self", ".", "device", ")", "\n", "y", "=", "y", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "self", ".", "mix", ":", "\n", "                ", "x", ",", "labels_a", ",", "labels_b", ",", "lam", "=", "mixup_data", "(", "x", "=", "x", ",", "y", "=", "y", ",", "alpha", "=", "0.5", ")", "\n", "logit", "=", "self", ".", "model", "(", "x", ")", "\n", "loss", "=", "lam", "*", "self", ".", "criterion", "(", "logit", ",", "labels_a", ")", "+", "(", "\n", "1", "-", "lam", "\n", ")", "*", "self", ".", "criterion", "(", "logit", ",", "labels_b", ")", "\n", "", "else", ":", "\n", "                ", "logit", "=", "self", ".", "model", "(", "x", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "logit", ",", "y", ")", "\n", "\n", "", "reg_loss", "=", "self", ".", "regularization_loss", "(", ")", "\n", "\n", "loss", "+=", "reg_loss", "\n", "loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "_", ",", "preds", "=", "logit", ".", "topk", "(", "self", ".", "topk", ",", "1", ",", "True", ",", "True", ")", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "correct", "+=", "torch", ".", "sum", "(", "preds", "==", "y", ".", "unsqueeze", "(", "1", ")", ")", ".", "item", "(", ")", "\n", "num_data", "+=", "y", ".", "size", "(", "0", ")", "\n", "\n", "", "n_batches", "=", "len", "(", "train_loader", ")", "\n", "return", "total_loss", "/", "n_batches", ",", "correct", "/", "num_data", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.regularization_loss": [[176, 205], ["len", "regularization.Regularization.regularization_terms.items", "regularization.Regularization.params.items", "regularization.Regularization.params.items", "max", "max", "logger.warning", "importance[].max"], "methods", ["None"], ["", "def", "regularization_loss", "(", "\n", "self", ",", "\n", ")", ":", "\n", "        ", "reg_loss", "=", "0", "\n", "if", "len", "(", "self", ".", "regularization_terms", ")", ">", "0", ":", "\n", "# Calculate the reg_loss only when the regularization_terms exists", "\n", "            ", "for", "_", ",", "reg_term", "in", "self", ".", "regularization_terms", ".", "items", "(", ")", ":", "\n", "                ", "task_reg_loss", "=", "0", "\n", "importance", "=", "reg_term", "[", "\"importance\"", "]", "\n", "task_param", "=", "reg_term", "[", "\"task_param\"", "]", "\n", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "                    ", "task_reg_loss", "+=", "(", "importance", "[", "n", "]", "*", "(", "p", "-", "task_param", "[", "n", "]", ")", "**", "2", ")", ".", "sum", "(", ")", "\n", "\n", "", "max_importance", "=", "0", "\n", "max_param_change", "=", "0", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "                    ", "max_importance", "=", "max", "(", "max_importance", ",", "importance", "[", "n", "]", ".", "max", "(", ")", ")", "\n", "max_param_change", "=", "max", "(", "\n", "max_param_change", ",", "(", "(", "p", "-", "task_param", "[", "n", "]", ")", "**", "2", ")", ".", "max", "(", ")", "\n", ")", "\n", "", "if", "reg_loss", ">", "1000", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "f\"max_importance:{max_importance}, max_param_change:{max_param_change}\"", "\n", ")", "\n", "", "reg_loss", "+=", "task_reg_loss", "\n", "", "reg_loss", "=", "self", ".", "reg_coef", "*", "reg_loss", "\n", "\n", "", "return", "reg_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.EWC.__init__": [[218, 227], ["regularization.Regularization.__init__"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["def", "__init__", "(", "\n", "self", ",", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", "\n", ")", "\n", "\n", "self", ".", "n_fisher_sample", "=", "None", "\n", "self", ".", "empFI", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.EWC.calculate_importance": [[228, 278], ["logger.info", "regularization.EWC.params.items", "regularization.EWC.model.eval", "p.clone().detach().fill_", "min", "logger.info", "random.sample", "torch.utils.data.Subset", "torch.utils.data.DataLoader", "x.to.to.to", "y.to.to.to", "regularization.EWC.model", "torch.argmax", "regularization.EWC.criterion", "regularization.EWC.regularization_loss", "regularization.EWC.model.zero_grad", "regularization.EWC.backward", "importance.items", "len", "list", "p.clone().detach", "range", "len", "len", "p.clone", "len"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.regularization_loss"], ["", "def", "calculate_importance", "(", "self", ",", "dataloader", ")", ":", "\n", "# Update the diag fisher information", "\n", "# There are several ways to estimate the F matrix.", "\n", "# We keep the implementation as simple as possible while maintaining a similar performance to the literature.", "\n", "        ", "logger", ".", "info", "(", "\"Computing EWC\"", ")", "\n", "\n", "# Initialize the importance matrix", "\n", "importance", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "importance", "[", "n", "]", "=", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "fill_", "(", "0", ")", "# zero initialized", "\n", "\n", "# Sample a subset (n_fisher_sample) of data to estimate the fisher information (batch_size=1)", "\n", "# Otherwise it uses mini-batches for the estimation. This speeds up the process a lot with similar performance.", "\n", "", "if", "self", ".", "n_fisher_sample", "is", "not", "None", ":", "\n", "            ", "n_sample", "=", "min", "(", "self", ".", "n_fisher_sample", ",", "len", "(", "dataloader", ".", "dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"Sample\"", ",", "self", ".", "n_fisher_sample", ",", "\"for estimating the F matrix.\"", ")", "\n", "rand_ind", "=", "random", ".", "sample", "(", "list", "(", "range", "(", "len", "(", "dataloader", ".", "dataset", ")", ")", ")", ",", "n_sample", ")", "\n", "subdata", "=", "torch", ".", "utils", ".", "data", ".", "Subset", "(", "dataloader", ".", "dataset", ",", "rand_ind", ")", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "subdata", ",", "shuffle", "=", "True", ",", "num_workers", "=", "2", ",", "batch_size", "=", "1", "\n", ")", "\n", "\n", "", "self", ".", "model", ".", "eval", "(", ")", "\n", "# Accumulate the square of gradients", "\n", "for", "data", "in", "dataloader", ":", "\n", "            ", "x", "=", "data", "[", "\"waveform\"", "]", "\n", "y", "=", "data", "[", "\"label\"", "]", "\n", "\n", "x", "=", "x", ".", "to", "(", "self", ".", "device", ")", "\n", "y", "=", "y", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "logit", "=", "self", ".", "model", "(", "x", ")", "\n", "\n", "pred", "=", "torch", ".", "argmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "if", "self", ".", "empFI", ":", "# Use groundtruth label (default is without this)", "\n", "                ", "pred", "=", "y", "\n", "\n", "", "loss", "=", "self", ".", "criterion", "(", "logit", ",", "pred", ")", "\n", "reg_loss", "=", "self", ".", "regularization_loss", "(", ")", "\n", "loss", "+=", "reg_loss", "\n", "\n", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "for", "n", ",", "p", "in", "importance", ".", "items", "(", ")", ":", "\n", "# Some heads can have no grad if no loss applied on them.", "\n", "                ", "if", "self", ".", "params", "[", "n", "]", ".", "grad", "is", "not", "None", ":", "\n", "                    ", "p", "+=", "(", "self", ".", "params", "[", "n", "]", ".", "grad", "**", "2", ")", "*", "len", "(", "x", ")", "/", "len", "(", "dataloader", ".", "dataset", ")", "\n", "\n", "", "", "", "return", "importance", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__": [[281, 301], ["regularization.Regularization.__init__", "regularization.RWalk.params.items", "p.clone().detach().fill_().to", "p.clone().detach().fill_().to", "p.clone().detach().fill_", "p.clone().detach().fill_", "p.clone().detach", "p.clone().detach", "p.clone", "p.clone"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "criterion", ",", "device", ",", "n_classes", ",", "**", "kwargs", "\n", ")", "\n", "\n", "self", ".", "score", "=", "[", "]", "\n", "self", ".", "fisher", "=", "[", "]", "\n", "self", ".", "n_fisher_sample", "=", "None", "\n", "self", ".", "empFI", "=", "False", "\n", "self", ".", "alpha", "=", "0.5", "\n", "self", ".", "epoch_score", "=", "{", "}", "\n", "self", ".", "epoch_fisher", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "epoch_score", "[", "n", "]", "=", "(", "\n", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "fill_", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", ")", "# zero initialized", "\n", "self", ".", "epoch_fisher", "[", "n", "]", "=", "(", "\n", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "fill_", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", ")", "# zero initialized", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.update_fisher_and_score": [[303, 328], ["regularization.RWalk.params.items", "regularization.RWalk.epoch_score[].max", "logger.debug"], "methods", ["None"], ["", "", "def", "update_fisher_and_score", "(", "\n", "self", ",", "new_params", ",", "old_params", ",", "new_grads", ",", "old_grads", ",", "epsilon", "=", "0.001", "\n", ")", ":", "\n", "        ", "for", "n", ",", "_", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "if", "n", "in", "old_grads", ":", "\n", "                ", "new_p", "=", "new_params", "[", "n", "]", "\n", "old_p", "=", "old_params", "[", "n", "]", "\n", "new_grad", "=", "new_grads", "[", "n", "]", "\n", "old_grad", "=", "old_grads", "[", "n", "]", "\n", "self", ".", "epoch_score", "[", "n", "]", "+=", "(", "new_grad", "-", "old_grad", ")", "/", "(", "\n", "0.5", "*", "self", ".", "epoch_fisher", "[", "n", "]", "*", "(", "new_p", "-", "old_p", ")", "**", "2", "+", "epsilon", "\n", ")", "\n", "if", "self", ".", "epoch_score", "[", "n", "]", ".", "max", "(", ")", ">", "1000", ":", "\n", "                    ", "logger", ".", "debug", "(", "\n", "\"Too large score {} / {}\"", ".", "format", "(", "\n", "new_grad", "-", "old_grad", ",", "\n", "0.5", "*", "self", ".", "epoch_fisher", "[", "n", "]", "*", "(", "new_p", "-", "old_p", ")", "**", "2", "+", "epsilon", ",", "\n", ")", "\n", ")", "\n", "", "if", "(", "self", ".", "epoch_fisher", "[", "n", "]", "==", "0", ")", ".", "all", "(", ")", ":", "# First time", "\n", "                    ", "self", ".", "epoch_fisher", "[", "n", "]", "=", "new_grad", "**", "2", "\n", "", "else", ":", "\n", "                    ", "self", ".", "epoch_fisher", "[", "n", "]", "=", "(", "1", "-", "self", ".", "alpha", ")", "*", "self", ".", "epoch_fisher", "[", "\n", "n", "\n", "]", "+", "self", ".", "alpha", "*", "new_grad", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk._train": [[329, 376], ["regularization.RWalk.model.train", "enumerate", "len", "x.to.to.to", "y.to.to.to", "optimizer.zero_grad", "regularization.RWalk.regularization_loss", "regularization.RWalk.backward", "optimizer.step", "regularization.RWalk.update_fisher_and_score", "regularization.RWalk.topk", "regularization.RWalk.item", "torch.sum().item", "y.to.to.size", "p.detach", "p.grad.detach", "utils.data_augmentation.mixup_data", "regularization.RWalk.model", "regularization.RWalk.model", "regularization.RWalk.criterion", "p.detach", "p.grad.detach", "regularization.RWalk.params.items", "regularization.RWalk.params.items", "regularization.RWalk.params.items", "regularization.RWalk.params.items", "torch.sum", "regularization.RWalk.criterion", "regularization.RWalk.criterion", "y.to.to.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.train", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.Regularization.regularization_loss", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.update_fisher_and_score", "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.utils.data_augmentation.mixup_data"], ["", "", "", "", "def", "_train", "(", "self", ",", "train_loader", ",", "optimizer", ",", "epoch", ",", "total_epochs", ")", ":", "\n", "        ", "total_loss", ",", "correct", ",", "num_data", "=", "0.0", ",", "0.0", ",", "0.0", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "i", ",", "data", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "            ", "x", "=", "data", "[", "\"waveform\"", "]", "\n", "y", "=", "data", "[", "\"label\"", "]", "\n", "x", "=", "x", ".", "to", "(", "self", ".", "device", ")", "\n", "y", "=", "y", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "old_params", "=", "{", "n", ":", "p", ".", "detach", "(", ")", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", "}", "\n", "old_grads", "=", "{", "\n", "n", ":", "p", ".", "grad", ".", "detach", "(", ")", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", "if", "p", ".", "grad", "is", "not", "None", "\n", "}", "\n", "\n", "# do_cutmix = self.cutmix and np.random.rand(1) < 0.5", "\n", "do_cutmix", "=", "False", "\n", "if", "do_cutmix", ":", "\n", "                ", "x", ",", "labels_a", ",", "labels_b", ",", "lam", "=", "mixup_data", "(", "x", "=", "x", ",", "y", "=", "y", ",", "alpha", "=", "1.0", ")", "\n", "logit", "=", "self", ".", "model", "(", "x", ")", "\n", "loss", "=", "lam", "*", "self", ".", "criterion", "(", "logit", ",", "labels_a", ")", "+", "(", "\n", "1", "-", "lam", "\n", ")", "*", "self", ".", "criterion", "(", "logit", ",", "labels_b", ")", "\n", "", "else", ":", "\n", "                ", "logit", "=", "self", ".", "model", "(", "x", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "logit", ",", "y", ")", "\n", "\n", "", "reg_loss", "=", "self", ".", "regularization_loss", "(", ")", "\n", "loss", "+=", "reg_loss", "\n", "loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "new_params", "=", "{", "n", ":", "p", ".", "detach", "(", ")", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", "}", "\n", "new_grads", "=", "{", "\n", "n", ":", "p", ".", "grad", ".", "detach", "(", ")", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", "if", "p", ".", "grad", "is", "not", "None", "\n", "}", "\n", "\n", "self", ".", "update_fisher_and_score", "(", "new_params", ",", "old_params", ",", "new_grads", ",", "old_grads", ")", "\n", "\n", "_", ",", "preds", "=", "logit", ".", "topk", "(", "self", ".", "topk", ",", "1", ",", "True", ",", "True", ")", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "correct", "+=", "torch", ".", "sum", "(", "preds", "==", "y", ".", "unsqueeze", "(", "1", ")", ")", ".", "item", "(", ")", "\n", "num_data", "+=", "y", ".", "size", "(", "0", ")", "\n", "", "n_batches", "=", "len", "(", "train_loader", ")", "\n", "\n", "return", "total_loss", "/", "n_batches", ",", "correct", "/", "num_data", "\n", "\n"]], "home.repos.pwc.inspect_result.swagshaw_rainbow-keywords.methods.regularization.RWalk.calculate_importance": [[377, 392], ["regularization.RWalk.fisher.append", "regularization.RWalk.params.items", "regularization.RWalk.score.append", "regularization.RWalk.params.items", "regularization.RWalk.score.append", "regularization.RWalk.params[].clone().detach().fill_", "regularization.RWalk.params[].clone().detach", "regularization.RWalk.params[].clone"], "methods", ["None"], ["", "def", "calculate_importance", "(", "self", ",", "dataloader", ")", ":", "\n", "        ", "importance", "=", "{", "}", "\n", "self", ".", "fisher", ".", "append", "(", "self", ".", "epoch_fisher", ")", "\n", "if", "self", ".", "task_count", "==", "0", ":", "\n", "            ", "self", ".", "score", ".", "append", "(", "self", ".", "epoch_score", ")", "\n", "", "else", ":", "\n", "            ", "score", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "                ", "score", "[", "n", "]", "=", "0.5", "*", "self", ".", "score", "[", "-", "1", "]", "[", "n", "]", "+", "0.5", "*", "self", ".", "epoch_score", "[", "n", "]", "\n", "", "self", ".", "score", ".", "append", "(", "score", ")", "\n", "\n", "", "for", "n", ",", "p", "in", "self", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "importance", "[", "n", "]", "=", "self", ".", "fisher", "[", "-", "1", "]", "[", "n", "]", "+", "self", ".", "score", "[", "-", "1", "]", "[", "n", "]", "\n", "self", ".", "epoch_score", "[", "n", "]", "=", "self", ".", "params", "[", "n", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", ".", "fill_", "(", "0", ")", "\n", "", "return", "importance", "\n", "", "", ""]]}