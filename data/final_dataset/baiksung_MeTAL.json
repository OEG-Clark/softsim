{"home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaMaxResLayerReLU.__init__": [[42, 76], ["torch.Module.__init__", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "meta_neural_network_architectures.MetaMaxResLayerReLU.build_block"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaNormLayerConvReLU.build_block"], ["    ", "def", "__init__", "(", "self", ",", "input_shape", ",", "num_filters", ",", "kernel_size", ",", "stride", ",", "padding", ",", "use_bias", ",", "args", ",", "normalization", "=", "True", ",", "\n", "meta_layer", "=", "True", ",", "no_bn_learnable_params", "=", "False", ",", "device", "=", "None", ",", "downsample", "=", "None", ",", "max_padding", "=", "0", ",", "maxpool", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n           Initializes a BatchNorm->Conv->ReLU layer which applies those operation in that order.\n           :param args: A named tuple containing the system's hyperparameters.\n           :param device: The device to run the layer on.\n           :param normalization: The type of normalization to use 'batch_norm' or 'layer_norm'\n           :param meta_layer: Whether this layer will require meta-layer capabilities such as meta-batch norm,\n           meta-conv etc.\n           :param input_shape: The image input shape in the form (b, c, h, w)\n           :param num_filters: number of filters for convolutional layer\n           :param kernel_size: the kernel size of the convolutional layer\n           :param stride: the stride of the convolutional layer\n           :param padding: the bias of the convolutional layer\n           :param use_bias: whether the convolutional layer utilizes a bias\n        \"\"\"", "\n", "super", "(", "MetaMaxResLayerReLU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "normalization", "=", "normalization", "\n", "self", ".", "use_per_step_bn_statistics", "=", "args", ".", "per_step_bn_statistics", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "num_filters", "=", "num_filters", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "meta_layer", "=", "meta_layer", "\n", "self", ".", "no_bn_learnable_params", "=", "no_bn_learnable_params", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "layer_dict", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "max_padding", "=", "max_padding", "\n", "self", ".", "maxpool", "=", "maxpool", "\n", "self", ".", "build_block", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaMaxResLayerReLU.build_block": [[77, 146], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "meta_neural_network_architectures.MetaConvNormLayerSwish", "meta_neural_network_architectures.MetaMaxResLayerReLU.conv1", "meta_neural_network_architectures.MetaConvNormLayerSwish", "meta_neural_network_architectures.MetaMaxResLayerReLU.conv2", "meta_neural_network_architectures.MetaConv2dLayer", "meta_neural_network_architectures.MetaMaxResLayerReLU.conv3", "meta_neural_network_architectures.MetaBatchNormLayer", "meta_neural_network_architectures.MetaMaxResLayerReLU.norm_layer", "meta_neural_network_architectures.MetaConv2dLayer", "meta_neural_network_architectures.MetaBatchNormLayer", "meta_neural_network_architectures.MetaMaxResLayerReLU.shortcut_conv", "meta_neural_network_architectures.MetaMaxResLayerReLU.shortcut_norm_layer", "torch.relu_", "torch.relu_", "torch.relu_", "print", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d"], "methods", ["None"], ["", "def", "build_block", "(", "self", ")", ":", "\n", "\n", "        ", "x", "=", "torch", ".", "zeros", "(", "self", ".", "input_shape", ")", "\n", "\n", "identity", "=", "x", "\n", "out", "=", "x", "\n", "\n", "self", ".", "conv1", "=", "MetaConvNormLayerSwish", "(", "input_shape", "=", "out", ".", "shape", ",", "\n", "num_filters", "=", "self", ".", "num_filters", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "self", ".", "stride", ",", "\n", "padding", "=", "1", ",", "\n", "use_bias", "=", "self", ".", "use_bias", ",", "args", "=", "self", ".", "args", ",", "\n", "normalization", "=", "True", ",", "\n", "meta_layer", "=", "self", ".", "meta_layer", ",", "\n", "no_bn_learnable_params", "=", "False", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "out", "=", "self", ".", "conv1", "(", "out", ",", "training", "=", "True", ",", "num_step", "=", "0", ")", "\n", "\n", "self", ".", "conv2", "=", "MetaConvNormLayerSwish", "(", "input_shape", "=", "out", ".", "shape", ",", "\n", "num_filters", "=", "self", ".", "num_filters", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "self", ".", "stride", ",", "\n", "padding", "=", "1", ",", "\n", "use_bias", "=", "self", ".", "use_bias", ",", "args", "=", "self", ".", "args", ",", "\n", "normalization", "=", "True", ",", "\n", "meta_layer", "=", "self", ".", "meta_layer", ",", "\n", "no_bn_learnable_params", "=", "False", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "out", "=", "self", ".", "conv2", "(", "out", ",", "training", "=", "True", ",", "num_step", "=", "0", ")", "\n", "\n", "self", ".", "conv3", "=", "MetaConv2dLayer", "(", "in_channels", "=", "out", ".", "shape", "[", "1", "]", ",", "out_channels", "=", "out", ".", "shape", "[", "1", "]", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "1", ",", "padding", "=", "self", ".", "padding", ",", "use_bias", "=", "self", ".", "use_bias", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "\n", "self", ".", "norm_layer", "=", "MetaBatchNormLayer", "(", "out", ".", "shape", "[", "1", "]", ",", "track_running_stats", "=", "True", ",", "\n", "meta_batch_norm", "=", "self", ".", "meta_layer", ",", "\n", "no_learnable_params", "=", "self", ".", "no_bn_learnable_params", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "use_per_step_bn_statistics", "=", "self", ".", "use_per_step_bn_statistics", ",", "\n", "args", "=", "self", ".", "args", ")", "\n", "\n", "out", "=", "self", ".", "norm_layer", "(", "out", ",", "num_step", "=", "0", ")", "\n", "\n", "self", ".", "shortcut_conv", "=", "MetaConv2dLayer", "(", "in_channels", "=", "identity", ".", "shape", "[", "1", "]", ",", "out_channels", "=", "out", ".", "shape", "[", "1", "]", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "1", ",", "padding", "=", "0", ",", "use_bias", "=", "self", ".", "use_bias", ")", "\n", "\n", "self", ".", "shortcut_norm_layer", "=", "MetaBatchNormLayer", "(", "out", ".", "shape", "[", "1", "]", ",", "track_running_stats", "=", "True", ",", "\n", "meta_batch_norm", "=", "self", ".", "meta_layer", ",", "\n", "no_learnable_params", "=", "self", ".", "no_bn_learnable_params", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "use_per_step_bn_statistics", "=", "self", ".", "use_per_step_bn_statistics", ",", "\n", "args", "=", "self", ".", "args", ")", "\n", "\n", "identity", "=", "self", ".", "shortcut_conv", "(", "identity", ")", "\n", "identity", "=", "self", ".", "shortcut_norm_layer", "(", "identity", ",", "num_step", "=", "0", ")", "\n", "\n", "out", "+=", "identity", "\n", "\n", "#out = F.relu(out)", "\n", "#", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "\n", "if", "self", ".", "maxpool", ":", "\n", "            ", "out", "=", "F", ".", "max_pool2d", "(", "input", "=", "out", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "2", ",", "padding", "=", "self", ".", "max_padding", ")", "\n", "\n", "\n", "", "print", "(", "out", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaMaxResLayerReLU.forward": [[147, 216], ["meta_neural_network_architectures.MetaMaxResLayerReLU.conv1", "meta_neural_network_architectures.MetaMaxResLayerReLU.conv2", "meta_neural_network_architectures.MetaMaxResLayerReLU.conv3", "meta_neural_network_architectures.MetaMaxResLayerReLU.norm_layer.forward", "meta_neural_network_architectures.MetaMaxResLayerReLU.shortcut_conv", "meta_neural_network_architectures.MetaMaxResLayerReLU.shortcut_norm_layer.forward", "torch.relu_", "torch.relu_", "torch.relu_", "meta_neural_network_architectures.extract_top_level_dict", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict"], ["", "def", "forward", "(", "self", ",", "x", ",", "num_step", ",", "params", "=", "None", ",", "training", "=", "False", ",", "backup_running_statistics", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            Forward propagates by applying the function. If params are none then internal params are used.\n            Otherwise passed params will be used to execute the function.\n            :param input: input data batch, size either can be any.\n            :param num_step: The current inner loop step being taken. This is used when we are learning per step params and\n             collecting per step batch statistics. It indexes the correct object to use for the current time-step\n            :param params: A dictionary containing 'weight' and 'bias'.\n            :param training: Whether this is currently the training or evaluation phase.\n            :param backup_running_statistics: Whether to backup the running statistics. This is used\n            at evaluation time, when after the pass is complete we want to throw away the collected validation stats.\n            :return: The result of the batch norm operation.\n        \"\"\"", "\n", "conv_params_1", "=", "None", "\n", "conv_params_2", "=", "None", "\n", "conv_params_3", "=", "None", "\n", "conv_params_shortcut", "=", "None", "\n", "norm_params", "=", "None", "\n", "norm_params_shortcut", "=", "None", "\n", "activation_function_pre_params", "=", "None", "\n", "\n", "if", "params", "is", "not", "None", ":", "\n", "            ", "params", "=", "extract_top_level_dict", "(", "current_dict", "=", "params", ")", "\n", "\n", "if", "self", ".", "normalization", ":", "\n", "                ", "if", "'activation_function_pre'", "in", "params", ":", "\n", "                    ", "activation_function_pre_params", "=", "params", "[", "'activation_function_pre'", "]", "\n", "\n", "", "", "conv_params_1", "=", "params", "[", "'conv1'", "]", "\n", "conv_params_2", "=", "params", "[", "'conv2'", "]", "\n", "conv_params_3", "=", "params", "[", "'conv3'", "]", "\n", "conv_params_shortcut", "=", "params", "[", "'shortcut_conv'", "]", "\n", "\n", "if", "'norm_layer'", "in", "params", ":", "\n", "                ", "norm_params", "=", "params", "[", "'norm_layer'", "]", "\n", "norm_params_shortcut", "=", "params", "[", "'shortcut_norm_layer'", "]", "\n", "\n", "", "", "out", "=", "x", "\n", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "out", ",", "params", "=", "conv_params_1", ",", "training", "=", "training", ",", "\n", "backup_running_statistics", "=", "backup_running_statistics", ",", "\n", "num_step", "=", "num_step", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ",", "params", "=", "conv_params_2", ",", "training", "=", "training", ",", "\n", "backup_running_statistics", "=", "backup_running_statistics", ",", "\n", "num_step", "=", "num_step", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ",", "params", "=", "conv_params_3", ")", "\n", "\n", "out", "=", "self", ".", "norm_layer", ".", "forward", "(", "out", ",", "num_step", "=", "num_step", ",", "\n", "params", "=", "norm_params", ",", "training", "=", "training", ",", "\n", "backup_running_statistics", "=", "backup_running_statistics", ")", "\n", "\n", "\n", "\n", "identity", "=", "self", ".", "shortcut_conv", "(", "identity", ",", "params", "=", "conv_params_shortcut", ")", "\n", "identity", "=", "self", ".", "shortcut_norm_layer", ".", "forward", "(", "identity", ",", "num_step", "=", "num_step", ",", "\n", "params", "=", "norm_params_shortcut", ",", "training", "=", "training", ",", "\n", "backup_running_statistics", "=", "backup_running_statistics", ")", "\n", "out", "+=", "identity", "\n", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "\n", "if", "self", ".", "maxpool", ":", "\n", "            ", "out", "=", "F", ".", "max_pool2d", "(", "input", "=", "out", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "2", ",", "padding", "=", "self", ".", "max_padding", ")", "\n", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaMaxResLayerReLU.restore_backup_stats": [[217, 225], ["meta_neural_network_architectures.MetaMaxResLayerReLU.conv1.restore_backup_stats", "meta_neural_network_architectures.MetaMaxResLayerReLU.conv2.restore_backup_stats", "meta_neural_network_architectures.MetaMaxResLayerReLU.norm_layer.restore_backup_stats", "meta_neural_network_architectures.MetaMaxResLayerReLU.shortcut_norm_layer.restore_backup_stats"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats"], ["", "def", "restore_backup_stats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Restore stored statistics from the backup, replacing the current ones.\n        \"\"\"", "\n", "self", ".", "conv1", ".", "restore_backup_stats", "(", ")", "\n", "self", ".", "conv2", ".", "restore_backup_stats", "(", ")", "\n", "self", ".", "norm_layer", ".", "restore_backup_stats", "(", ")", "\n", "self", ".", "shortcut_norm_layer", ".", "restore_backup_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaConvNormLayerSwish.__init__": [[228, 259], ["torch.Module.__init__", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "meta_neural_network_architectures.MetaConvNormLayerSwish.build_block"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaNormLayerConvReLU.build_block"], ["    ", "def", "__init__", "(", "self", ",", "input_shape", ",", "num_filters", ",", "kernel_size", ",", "stride", ",", "padding", ",", "use_bias", ",", "args", ",", "normalization", "=", "True", ",", "\n", "meta_layer", "=", "True", ",", "no_bn_learnable_params", "=", "False", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n           Initializes a BatchNorm->Conv->ReLU layer which applies those operation in that order.\n           :param args: A named tuple containing the system's hyperparameters.\n           :param device: The device to run the layer on.\n           :param normalization: The type of normalization to use 'batch_norm' or 'layer_norm'\n           :param meta_layer: Whether this layer will require meta-layer capabilities such as meta-batch norm,\n           meta-conv etc.\n           :param input_shape: The image input shape in the form (b, c, h, w)\n           :param num_filters: number of filters for convolutional layer\n           :param kernel_size: the kernel size of the convolutional layer\n           :param stride: the stride of the convolutional layer\n           :param padding: the bias of the convolutional layer\n           :param use_bias: whether the convolutional layer utilizes a bias\n        \"\"\"", "\n", "super", "(", "MetaConvNormLayerSwish", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "normalization", "=", "normalization", "\n", "self", ".", "use_per_step_bn_statistics", "=", "args", ".", "per_step_bn_statistics", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "num_filters", "=", "num_filters", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "meta_layer", "=", "meta_layer", "\n", "self", ".", "no_bn_learnable_params", "=", "no_bn_learnable_params", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "layer_dict", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "build_block", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaConvNormLayerSwish.build_block": [[260, 291], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "meta_neural_network_architectures.MetaConv2dLayer", "meta_neural_network_architectures.MetaConvNormLayerSwish.conv", "torch.relu_", "torch.relu_", "torch.relu_", "print", "meta_neural_network_architectures.MetaConvNormLayerSwish.norm_layer", "meta_neural_network_architectures.MetaBatchNormLayer", "meta_neural_network_architectures.MetaLayerNormLayer"], "methods", ["None"], ["", "def", "build_block", "(", "self", ")", ":", "\n", "\n", "        ", "x", "=", "torch", ".", "zeros", "(", "self", ".", "input_shape", ")", "\n", "\n", "out", "=", "x", "\n", "\n", "self", ".", "conv", "=", "MetaConv2dLayer", "(", "in_channels", "=", "out", ".", "shape", "[", "1", "]", ",", "out_channels", "=", "self", ".", "num_filters", ",", "\n", "kernel_size", "=", "self", ".", "kernel_size", ",", "\n", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", ",", "use_bias", "=", "self", ".", "use_bias", ")", "\n", "\n", "\n", "\n", "out", "=", "self", ".", "conv", "(", "out", ")", "\n", "\n", "if", "self", ".", "normalization", ":", "\n", "            ", "if", "self", ".", "args", ".", "norm_layer", "==", "\"batch_norm\"", ":", "\n", "                ", "self", ".", "norm_layer", "=", "MetaBatchNormLayer", "(", "out", ".", "shape", "[", "1", "]", ",", "track_running_stats", "=", "True", ",", "\n", "meta_batch_norm", "=", "self", ".", "meta_layer", ",", "\n", "no_learnable_params", "=", "self", ".", "no_bn_learnable_params", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "use_per_step_bn_statistics", "=", "self", ".", "use_per_step_bn_statistics", ",", "\n", "args", "=", "self", ".", "args", ")", "\n", "\n", "", "elif", "self", ".", "args", ".", "norm_layer", "==", "\"layer_norm\"", ":", "\n", "                ", "self", ".", "norm_layer", "=", "MetaLayerNormLayer", "(", "input_feature_shape", "=", "out", ".", "shape", "[", "1", ":", "]", ")", "\n", "\n", "", "out", "=", "self", ".", "norm_layer", "(", "out", ",", "num_step", "=", "0", ")", "\n", "\n", "", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "\n", "print", "(", "out", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaConvNormLayerSwish.forward": [[292, 334], ["meta_neural_network_architectures.MetaConvNormLayerSwish.conv", "torch.relu_", "torch.relu_", "torch.relu_", "meta_neural_network_architectures.extract_top_level_dict", "meta_neural_network_architectures.MetaConvNormLayerSwish.norm_layer.forward"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward"], ["", "def", "forward", "(", "self", ",", "x", ",", "num_step", ",", "params", "=", "None", ",", "training", "=", "False", ",", "backup_running_statistics", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            Forward propagates by applying the function. If params are none then internal params are used.\n            Otherwise passed params will be used to execute the function.\n            :param input: input data batch, size either can be any.\n            :param num_step: The current inner loop step being taken. This is used when we are learning per step params and\n             collecting per step batch statistics. It indexes the correct object to use for the current time-step\n            :param params: A dictionary containing 'weight' and 'bias'.\n            :param training: Whether this is currently the training or evaluation phase.\n            :param backup_running_statistics: Whether to backup the running statistics. This is used\n            at evaluation time, when after the pass is complete we want to throw away the collected validation stats.\n            :return: The result of the batch norm operation.\n        \"\"\"", "\n", "batch_norm_params", "=", "None", "\n", "conv_params", "=", "None", "\n", "activation_function_pre_params", "=", "None", "\n", "\n", "if", "params", "is", "not", "None", ":", "\n", "            ", "params", "=", "extract_top_level_dict", "(", "current_dict", "=", "params", ")", "\n", "\n", "if", "self", ".", "normalization", ":", "\n", "                ", "if", "'norm_layer'", "in", "params", ":", "\n", "                    ", "batch_norm_params", "=", "params", "[", "'norm_layer'", "]", "\n", "\n", "", "if", "'activation_function_pre'", "in", "params", ":", "\n", "                    ", "activation_function_pre_params", "=", "params", "[", "'activation_function_pre'", "]", "\n", "\n", "", "", "conv_params", "=", "params", "[", "'conv'", "]", "\n", "\n", "", "out", "=", "x", "\n", "\n", "\n", "out", "=", "self", ".", "conv", "(", "out", ",", "params", "=", "conv_params", ")", "\n", "\n", "if", "self", ".", "normalization", ":", "\n", "            ", "out", "=", "self", ".", "norm_layer", ".", "forward", "(", "out", ",", "num_step", "=", "num_step", ",", "\n", "params", "=", "batch_norm_params", ",", "training", "=", "training", ",", "\n", "backup_running_statistics", "=", "backup_running_statistics", ")", "\n", "\n", "", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaConvNormLayerSwish.restore_backup_stats": [[335, 341], ["meta_neural_network_architectures.MetaConvNormLayerSwish.norm_layer.restore_backup_stats"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats"], ["", "def", "restore_backup_stats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Restore stored statistics from the backup, replacing the current ones.\n        \"\"\"", "\n", "if", "self", ".", "normalization", ":", "\n", "            ", "self", ".", "norm_layer", ".", "restore_backup_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaConv2dLayer.__init__": [[344, 369], ["torch.Module.__init__", "int", "int", "int", "int", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "padding", ",", "use_bias", ",", "groups", "=", "1", ",", "dilation_rate", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        A MetaConv2D layer. Applies the same functionality of a standard Conv2D layer with the added functionality of\n        being able to receive a parameter dictionary at the forward pass which allows the convolution to use external\n        weights instead of the internal ones stored in the conv layer. Useful for inner loop optimization in the meta\n        learning setting.\n        :param in_channels: Number of input channels\n        :param out_channels: Number of output channels\n        :param kernel_size: Convolutional kernel size\n        :param stride: Convolutional stride\n        :param padding: Convolution padding\n        :param use_bias: Boolean indicating whether to use a bias or not.\n        \"\"\"", "\n", "super", "(", "MetaConv2dLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "num_filters", "=", "out_channels", "\n", "self", ".", "stride", "=", "int", "(", "stride", ")", "\n", "self", ".", "padding", "=", "int", "(", "padding", ")", "\n", "self", ".", "dilation_rate", "=", "int", "(", "dilation_rate", ")", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "groups", "=", "int", "(", "groups", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "empty", "(", "num_filters", ",", "in_channels", ",", "kernel_size", ",", "kernel_size", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weight", ")", "\n", "\n", "if", "self", ".", "use_bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_filters", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaConv2dLayer.forward": [[370, 396], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "meta_neural_network_architectures.extract_top_level_dict"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "params", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Applies a conv2D forward pass. If params are not None will use the passed params as the conv weights and biases\n        :param x: Input image batch.\n        :param params: If none, then conv layer will use the stored self.weights and self.bias, if they are not none\n        then the conv layer will use the passed params as its parameters.\n        :return: The output of a convolutional function.\n        \"\"\"", "\n", "if", "params", "is", "not", "None", ":", "\n", "            ", "params", "=", "extract_top_level_dict", "(", "current_dict", "=", "params", ")", "\n", "if", "self", ".", "use_bias", ":", "\n", "                ", "(", "weight", ",", "bias", ")", "=", "params", "[", "\"weight\"", "]", ",", "params", "[", "\"bias\"", "]", "\n", "", "else", ":", "\n", "                ", "(", "weight", ")", "=", "params", "[", "\"weight\"", "]", "\n", "bias", "=", "None", "\n", "", "", "else", ":", "\n", "#print(\"No inner loop params\")", "\n", "            ", "if", "self", ".", "use_bias", ":", "\n", "                ", "weight", ",", "bias", "=", "self", ".", "weight", ",", "self", ".", "bias", "\n", "", "else", ":", "\n", "                ", "weight", "=", "self", ".", "weight", "\n", "bias", "=", "None", "\n", "\n", "", "", "out", "=", "F", ".", "conv2d", "(", "input", "=", "x", ",", "weight", "=", "weight", ",", "bias", "=", "bias", ",", "stride", "=", "self", ".", "stride", ",", "\n", "padding", "=", "self", ".", "padding", ",", "dilation", "=", "self", ".", "dilation_rate", ",", "groups", "=", "self", ".", "groups", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLinearLayer.__init__": [[399, 417], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_shape", ",", "num_filters", ",", "use_bias", ")", ":", "\n", "        ", "\"\"\"\n        A MetaLinear layer. Applies the same functionality of a standard linearlayer with the added functionality of\n        being able to receive a parameter dictionary at the forward pass which allows the convolution to use external\n        weights instead of the internal ones stored in the linear layer. Useful for inner loop optimization in the meta\n        learning setting.\n        :param input_shape: The shape of the input data, in the form (b, f)\n        :param num_filters: Number of output filters\n        :param use_bias: Whether to use biases or not.\n        \"\"\"", "\n", "super", "(", "MetaLinearLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "b", ",", "c", "=", "input_shape", "\n", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "weights", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_filters", ",", "c", ")", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "weights", ")", "\n", "if", "self", ".", "use_bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_filters", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLinearLayer.forward": [[418, 446], ["torch.linear", "torch.linear", "torch.linear", "meta_neural_network_architectures.extract_top_level_dict"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "params", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Forward propagates by applying a linear function (Wx + b). If params are none then internal params are used.\n        Otherwise passed params will be used to execute the function.\n        :param x: Input data batch, in the form (b, f)\n        :param params: A dictionary containing 'weights' and 'bias'. If params are none then internal params are used.\n        Otherwise the external are used.\n        :return: The result of the linear function.\n        \"\"\"", "\n", "if", "params", "is", "not", "None", ":", "\n", "            ", "params", "=", "extract_top_level_dict", "(", "current_dict", "=", "params", ")", "\n", "if", "self", ".", "use_bias", ":", "\n", "                ", "(", "weight", ",", "bias", ")", "=", "params", "[", "\"weights\"", "]", ",", "params", "[", "\"bias\"", "]", "\n", "", "else", ":", "\n", "                ", "(", "weight", ")", "=", "params", "[", "\"weights\"", "]", "\n", "bias", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "pass", "\n", "#print('no inner loop params', self)", "\n", "\n", "if", "self", ".", "use_bias", ":", "\n", "                ", "weight", ",", "bias", "=", "self", ".", "weights", ",", "self", ".", "bias", "\n", "", "else", ":", "\n", "                ", "weight", "=", "self", ".", "weights", "\n", "bias", "=", "None", "\n", "# print(x.shape)", "\n", "", "", "out", "=", "F", ".", "linear", "(", "input", "=", "x", ",", "weight", "=", "weight", ",", "bias", "=", "bias", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaBatchNormLayer.__init__": [[449, 509], ["torch.Module.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_features", ",", "device", ",", "args", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ",", "affine", "=", "True", ",", "\n", "track_running_stats", "=", "True", ",", "meta_batch_norm", "=", "True", ",", "no_learnable_params", "=", "False", ",", "\n", "use_per_step_bn_statistics", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        A MetaBatchNorm layer. Applies the same functionality of a standard BatchNorm layer with the added functionality of\n        being able to receive a parameter dictionary at the forward pass which allows the convolution to use external\n        weights instead of the internal ones stored in the conv layer. Useful for inner loop optimization in the meta\n        learning setting. Also has the additional functionality of being able to store per step running stats and per step beta and gamma.\n        :param num_features:\n        :param device:\n        :param args:\n        :param eps:\n        :param momentum:\n        :param affine:\n        :param track_running_stats:\n        :param meta_batch_norm:\n        :param no_learnable_params:\n        :param use_per_step_bn_statistics:\n        \"\"\"", "\n", "super", "(", "MetaBatchNormLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "eps", "=", "eps", "\n", "\n", "self", ".", "affine", "=", "affine", "\n", "self", ".", "track_running_stats", "=", "track_running_stats", "\n", "self", ".", "meta_batch_norm", "=", "meta_batch_norm", "\n", "self", ".", "num_features", "=", "num_features", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "use_per_step_bn_statistics", "=", "use_per_step_bn_statistics", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "learnable_gamma", "=", "self", ".", "args", ".", "learnable_bn_gamma", "\n", "self", ".", "learnable_beta", "=", "self", ".", "args", ".", "learnable_bn_beta", "\n", "\n", "if", "use_per_step_bn_statistics", ":", "\n", "            ", "self", ".", "running_mean", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "args", ".", "number_of_training_steps_per_iter", ",", "num_features", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "self", ".", "running_var", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "args", ".", "number_of_training_steps_per_iter", ",", "num_features", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "args", ".", "number_of_training_steps_per_iter", ",", "num_features", ")", ",", "\n", "requires_grad", "=", "self", ".", "learnable_beta", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "args", ".", "number_of_training_steps_per_iter", ",", "num_features", ")", ",", "\n", "requires_grad", "=", "self", ".", "learnable_gamma", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "running_mean", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "running_var", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ",", "\n", "requires_grad", "=", "self", ".", "learnable_beta", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ",", "\n", "requires_grad", "=", "self", ".", "learnable_gamma", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "enable_inner_loop_optimizable_bn_params", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "num_features", ")", ",", "\n", "requires_grad", "=", "self", ".", "learnable_beta", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "num_features", ")", ",", "\n", "requires_grad", "=", "self", ".", "learnable_gamma", ")", "\n", "\n", "", "self", ".", "backup_running_mean", "=", "torch", ".", "zeros", "(", "self", ".", "running_mean", ".", "shape", ")", "\n", "self", ".", "backup_running_var", "=", "torch", ".", "ones", "(", "self", ".", "running_var", ".", "shape", ")", "\n", "\n", "self", ".", "momentum", "=", "momentum", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaBatchNormLayer.forward": [[510, 553], ["torch.batch_norm", "torch.batch_norm", "torch.batch_norm", "meta_neural_network_architectures.extract_top_level_dict", "copy.copy.copy", "copy.copy.copy"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict"], ["", "def", "forward", "(", "self", ",", "input", ",", "num_step", ",", "params", "=", "None", ",", "training", "=", "False", ",", "backup_running_statistics", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Forward propagates by applying a bach norm function. If params are none then internal params are used.\n        Otherwise passed params will be used to execute the function.\n        :param input: input data batch, size either can be any.\n        :param num_step: The current inner loop step being taken. This is used when we are learning per step params and\n         collecting per step batch statistics. It indexes the correct object to use for the current time-step\n        :param params: A dictionary containing 'weight' and 'bias'.\n        :param training: Whether this is currently the training or evaluation phase.\n        :param backup_running_statistics: Whether to backup the running statistics. This is used\n        at evaluation time, when after the pass is complete we want to throw away the collected validation stats.\n        :return: The result of the batch norm operation.\n        \"\"\"", "\n", "if", "params", "is", "not", "None", ":", "\n", "            ", "params", "=", "extract_top_level_dict", "(", "current_dict", "=", "params", ")", "\n", "(", "weight", ",", "bias", ")", "=", "params", "[", "\"weight\"", "]", ",", "params", "[", "\"bias\"", "]", "\n", "#print(num_step, params['weight'])", "\n", "", "else", ":", "\n", "#print(num_step, \"no params\")", "\n", "            ", "weight", ",", "bias", "=", "self", ".", "weight", ",", "self", ".", "bias", "\n", "\n", "", "if", "self", ".", "use_per_step_bn_statistics", ":", "\n", "            ", "running_mean", "=", "self", ".", "running_mean", "[", "num_step", "]", "\n", "running_var", "=", "self", ".", "running_var", "[", "num_step", "]", "\n", "if", "params", "is", "None", ":", "\n", "                ", "if", "not", "self", ".", "args", ".", "enable_inner_loop_optimizable_bn_params", ":", "\n", "                    ", "bias", "=", "self", ".", "bias", "[", "num_step", "]", "\n", "weight", "=", "self", ".", "weight", "[", "num_step", "]", "\n", "", "", "", "else", ":", "\n", "            ", "running_mean", "=", "None", "\n", "running_var", "=", "None", "\n", "\n", "\n", "", "if", "backup_running_statistics", "and", "self", ".", "use_per_step_bn_statistics", ":", "\n", "            ", "self", ".", "backup_running_mean", ".", "data", "=", "copy", "(", "self", ".", "running_mean", ".", "data", ")", "\n", "self", ".", "backup_running_var", ".", "data", "=", "copy", "(", "self", ".", "running_var", ".", "data", ")", "\n", "\n", "", "momentum", "=", "self", ".", "momentum", "\n", "\n", "output", "=", "F", ".", "batch_norm", "(", "input", ",", "running_mean", ",", "running_var", ",", "weight", ",", "bias", ",", "\n", "training", "=", "True", ",", "momentum", "=", "momentum", ",", "eps", "=", "self", ".", "eps", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaBatchNormLayer.restore_backup_stats": [[554, 561], ["torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "meta_neural_network_architectures.MetaBatchNormLayer.backup_running_mean.to", "meta_neural_network_architectures.MetaBatchNormLayer.backup_running_var.to"], "methods", ["None"], ["", "def", "restore_backup_stats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Resets batch statistics to their backup values which are collected after each forward pass.\n        \"\"\"", "\n", "if", "self", ".", "use_per_step_bn_statistics", ":", "\n", "            ", "self", ".", "running_mean", "=", "nn", ".", "Parameter", "(", "self", ".", "backup_running_mean", ".", "to", "(", "device", "=", "self", ".", "device", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "running_var", "=", "nn", ".", "Parameter", "(", "self", ".", "backup_running_var", ".", "to", "(", "device", "=", "self", ".", "device", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaBatchNormLayer.extra_repr": [[562, 565], ["None"], "methods", ["None"], ["", "", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "'{num_features}, eps={eps}, momentum={momentum}, affine={affine}, '", "'track_running_stats={track_running_stats}'", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLayerNormLayer.__init__": [[568, 591], ["torch.Module.__init__", "isinstance", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "meta_neural_network_architectures.MetaLayerNormLayer.reset_parameters", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "meta_neural_network_architectures.MetaLayerNormLayer.register_parameter", "meta_neural_network_architectures.MetaLayerNormLayer.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLayerNormLayer.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "input_feature_shape", ",", "eps", "=", "1e-5", ",", "elementwise_affine", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        A MetaLayerNorm layer. A layer that applies the same functionality as a layer norm layer with the added\n        capability of being able to receive params at inference time to use instead of the internal ones. As well as\n        being able to use its own internal weights.\n        :param input_feature_shape: The input shape without the batch dimension, e.g. c, h, w\n        :param eps: Epsilon to use for protection against overflows\n        :param elementwise_affine: Whether to learn a multiplicative interaction parameter 'w' in addition to\n        the biases.\n        \"\"\"", "\n", "super", "(", "MetaLayerNormLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "isinstance", "(", "input_feature_shape", ",", "numbers", ".", "Integral", ")", ":", "\n", "            ", "input_feature_shape", "=", "(", "input_feature_shape", ",", ")", "\n", "", "self", ".", "normalized_shape", "=", "torch", ".", "Size", "(", "input_feature_shape", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "elementwise_affine", "=", "elementwise_affine", "\n", "if", "self", ".", "elementwise_affine", ":", "\n", "            ", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "input_feature_shape", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "*", "input_feature_shape", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'weight'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLayerNormLayer.reset_parameters": [[592, 599], ["meta_neural_network_architectures.MetaLayerNormLayer.weight.data.fill_", "meta_neural_network_architectures.MetaLayerNormLayer.bias.data.zero_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset parameters to their initialization values.\n        \"\"\"", "\n", "if", "self", ".", "elementwise_affine", ":", "\n", "            ", "self", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "self", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLayerNormLayer.forward": [[600, 622], ["torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "meta_neural_network_architectures.extract_top_level_dict"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict"], ["", "", "def", "forward", "(", "self", ",", "input", ",", "num_step", ",", "params", "=", "None", ",", "training", "=", "False", ",", "backup_running_statistics", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            Forward propagates by applying a layer norm function. If params are none then internal params are used.\n            Otherwise passed params will be used to execute the function.\n            :param input: input data batch, size either can be any.\n            :param num_step: The current inner loop step being taken. This is used when we are learning per step params and\n             collecting per step batch statistics. It indexes the correct object to use for the current time-step\n            :param params: A dictionary containing 'weight' and 'bias'.\n            :param training: Whether this is currently the training or evaluation phase.\n            :param backup_running_statistics: Whether to backup the running statistics. This is used\n            at evaluation time, when after the pass is complete we want to throw away the collected validation stats.\n            :return: The result of the batch norm operation.\n        \"\"\"", "\n", "if", "params", "is", "not", "None", ":", "\n", "            ", "params", "=", "extract_top_level_dict", "(", "current_dict", "=", "params", ")", "\n", "bias", "=", "params", "[", "\"bias\"", "]", "\n", "", "else", ":", "\n", "            ", "bias", "=", "self", ".", "bias", "\n", "#print('no inner loop params', self)", "\n", "\n", "", "return", "F", ".", "layer_norm", "(", "\n", "input", ",", "self", ".", "normalized_shape", ",", "self", ".", "weight", ",", "bias", ",", "self", ".", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLayerNormLayer.restore_backup_stats": [[623, 625], ["None"], "methods", ["None"], ["", "def", "restore_backup_stats", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLayerNormLayer.extra_repr": [[626, 629], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "'{normalized_shape}, eps={eps}, '", "'elementwise_affine={elementwise_affine}'", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaConvNormLayerReLU.__init__": [[632, 663], ["torch.Module.__init__", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "meta_neural_network_architectures.MetaConvNormLayerReLU.build_block"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaNormLayerConvReLU.build_block"], ["    ", "def", "__init__", "(", "self", ",", "input_shape", ",", "num_filters", ",", "kernel_size", ",", "stride", ",", "padding", ",", "use_bias", ",", "args", ",", "normalization", "=", "True", ",", "\n", "meta_layer", "=", "True", ",", "no_bn_learnable_params", "=", "False", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n           Initializes a BatchNorm->Conv->ReLU layer which applies those operation in that order.\n           :param args: A named tuple containing the system's hyperparameters.\n           :param device: The device to run the layer on.\n           :param normalization: The type of normalization to use 'batch_norm' or 'layer_norm'\n           :param meta_layer: Whether this layer will require meta-layer capabilities such as meta-batch norm,\n           meta-conv etc.\n           :param input_shape: The image input shape in the form (b, c, h, w)\n           :param num_filters: number of filters for convolutional layer\n           :param kernel_size: the kernel size of the convolutional layer\n           :param stride: the stride of the convolutional layer\n           :param padding: the bias of the convolutional layer\n           :param use_bias: whether the convolutional layer utilizes a bias\n        \"\"\"", "\n", "super", "(", "MetaConvNormLayerReLU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "normalization", "=", "normalization", "\n", "self", ".", "use_per_step_bn_statistics", "=", "args", ".", "per_step_bn_statistics", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "num_filters", "=", "num_filters", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "meta_layer", "=", "meta_layer", "\n", "self", ".", "no_bn_learnable_params", "=", "no_bn_learnable_params", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "layer_dict", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "build_block", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaConvNormLayerReLU.build_block": [[664, 692], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "meta_neural_network_architectures.MetaConv2dLayer", "meta_neural_network_architectures.MetaConvNormLayerReLU.conv", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "print", "meta_neural_network_architectures.MetaConvNormLayerReLU.norm_layer", "meta_neural_network_architectures.MetaBatchNormLayer", "meta_neural_network_architectures.MetaLayerNormLayer"], "methods", ["None"], ["", "def", "build_block", "(", "self", ")", ":", "\n", "\n", "        ", "x", "=", "torch", ".", "zeros", "(", "self", ".", "input_shape", ")", "\n", "\n", "out", "=", "x", "\n", "\n", "self", ".", "conv", "=", "MetaConv2dLayer", "(", "in_channels", "=", "out", ".", "shape", "[", "1", "]", ",", "out_channels", "=", "self", ".", "num_filters", ",", "\n", "kernel_size", "=", "self", ".", "kernel_size", ",", "\n", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", ",", "use_bias", "=", "self", ".", "use_bias", ")", "\n", "\n", "out", "=", "self", ".", "conv", "(", "out", ")", "\n", "\n", "if", "self", ".", "normalization", ":", "\n", "            ", "if", "self", ".", "args", ".", "norm_layer", "==", "\"batch_norm\"", ":", "\n", "                ", "self", ".", "norm_layer", "=", "MetaBatchNormLayer", "(", "out", ".", "shape", "[", "1", "]", ",", "track_running_stats", "=", "True", ",", "\n", "meta_batch_norm", "=", "self", ".", "meta_layer", ",", "\n", "no_learnable_params", "=", "self", ".", "no_bn_learnable_params", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "use_per_step_bn_statistics", "=", "self", ".", "use_per_step_bn_statistics", ",", "\n", "args", "=", "self", ".", "args", ")", "\n", "", "elif", "self", ".", "args", ".", "norm_layer", "==", "\"layer_norm\"", ":", "\n", "                ", "self", ".", "norm_layer", "=", "MetaLayerNormLayer", "(", "input_feature_shape", "=", "out", ".", "shape", "[", "1", ":", "]", ")", "\n", "\n", "", "out", "=", "self", ".", "norm_layer", "(", "out", ",", "num_step", "=", "0", ")", "\n", "\n", "", "out", "=", "F", ".", "leaky_relu", "(", "out", ")", "\n", "\n", "print", "(", "out", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaConvNormLayerReLU.forward": [[693, 735], ["meta_neural_network_architectures.MetaConvNormLayerReLU.conv", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu", "meta_neural_network_architectures.extract_top_level_dict", "meta_neural_network_architectures.MetaConvNormLayerReLU.norm_layer.forward"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward"], ["", "def", "forward", "(", "self", ",", "x", ",", "num_step", ",", "params", "=", "None", ",", "training", "=", "False", ",", "backup_running_statistics", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            Forward propagates by applying the function. If params are none then internal params are used.\n            Otherwise passed params will be used to execute the function.\n            :param input: input data batch, size either can be any.\n            :param num_step: The current inner loop step being taken. This is used when we are learning per step params and\n             collecting per step batch statistics. It indexes the correct object to use for the current time-step\n            :param params: A dictionary containing 'weight' and 'bias'.\n            :param training: Whether this is currently the training or evaluation phase.\n            :param backup_running_statistics: Whether to backup the running statistics. This is used\n            at evaluation time, when after the pass is complete we want to throw away the collected validation stats.\n            :return: The result of the batch norm operation.\n        \"\"\"", "\n", "batch_norm_params", "=", "None", "\n", "conv_params", "=", "None", "\n", "activation_function_pre_params", "=", "None", "\n", "\n", "if", "params", "is", "not", "None", ":", "\n", "            ", "params", "=", "extract_top_level_dict", "(", "current_dict", "=", "params", ")", "\n", "\n", "if", "self", ".", "normalization", ":", "\n", "                ", "if", "'norm_layer'", "in", "params", ":", "\n", "                    ", "batch_norm_params", "=", "params", "[", "'norm_layer'", "]", "\n", "\n", "", "if", "'activation_function_pre'", "in", "params", ":", "\n", "                    ", "activation_function_pre_params", "=", "params", "[", "'activation_function_pre'", "]", "\n", "\n", "", "", "conv_params", "=", "params", "[", "'conv'", "]", "\n", "\n", "", "out", "=", "x", "\n", "\n", "\n", "out", "=", "self", ".", "conv", "(", "out", ",", "params", "=", "conv_params", ")", "\n", "\n", "if", "self", ".", "normalization", ":", "\n", "            ", "out", "=", "self", ".", "norm_layer", ".", "forward", "(", "out", ",", "num_step", "=", "num_step", ",", "\n", "params", "=", "batch_norm_params", ",", "training", "=", "training", ",", "\n", "backup_running_statistics", "=", "backup_running_statistics", ")", "\n", "\n", "", "out", "=", "F", ".", "leaky_relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaConvNormLayerReLU.restore_backup_stats": [[736, 742], ["meta_neural_network_architectures.MetaConvNormLayerReLU.norm_layer.restore_backup_stats"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats"], ["", "def", "restore_backup_stats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Restore stored statistics from the backup, replacing the current ones.\n        \"\"\"", "\n", "if", "self", ".", "normalization", ":", "\n", "            ", "self", ".", "norm_layer", ".", "restore_backup_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaNormLayerConvReLU.__init__": [[745, 776], ["torch.Module.__init__", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "meta_neural_network_architectures.MetaNormLayerConvReLU.build_block"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaNormLayerConvReLU.build_block"], ["    ", "def", "__init__", "(", "self", ",", "input_shape", ",", "num_filters", ",", "kernel_size", ",", "stride", ",", "padding", ",", "use_bias", ",", "args", ",", "normalization", "=", "True", ",", "\n", "meta_layer", "=", "True", ",", "no_bn_learnable_params", "=", "False", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n           Initializes a BatchNorm->Conv->ReLU layer which applies those operation in that order.\n           :param args: A named tuple containing the system's hyperparameters.\n           :param device: The device to run the layer on.\n           :param normalization: The type of normalization to use 'batch_norm' or 'layer_norm'\n           :param meta_layer: Whether this layer will require meta-layer capabilities such as meta-batch norm,\n           meta-conv etc.\n           :param input_shape: The image input shape in the form (b, c, h, w)\n           :param num_filters: number of filters for convolutional layer\n           :param kernel_size: the kernel size of the convolutional layer\n           :param stride: the stride of the convolutional layer\n           :param padding: the bias of the convolutional layer\n           :param use_bias: whether the convolutional layer utilizes a bias\n        \"\"\"", "\n", "super", "(", "MetaNormLayerConvReLU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "normalization", "=", "normalization", "\n", "self", ".", "use_per_step_bn_statistics", "=", "args", ".", "per_step_bn_statistics", "\n", "self", ".", "input_shape", "=", "input_shape", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "num_filters", "=", "num_filters", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "meta_layer", "=", "meta_layer", "\n", "self", ".", "no_bn_learnable_params", "=", "no_bn_learnable_params", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "layer_dict", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "build_block", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaNormLayerConvReLU.build_block": [[777, 804], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "meta_neural_network_architectures.MetaConv2dLayer", "torch.LeakyReLU", "torch.LeakyReLU", "torch.LeakyReLU", "meta_neural_network_architectures.MetaNormLayerConvReLU.layer_dict[].forward", "print", "meta_neural_network_architectures.MetaNormLayerConvReLU.norm_layer.forward", "meta_neural_network_architectures.MetaNormLayerConvReLU.conv.forward", "meta_neural_network_architectures.MetaBatchNormLayer", "meta_neural_network_architectures.MetaLayerNormLayer"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward"], ["", "def", "build_block", "(", "self", ")", ":", "\n", "\n", "        ", "x", "=", "torch", ".", "zeros", "(", "self", ".", "input_shape", ")", "\n", "\n", "out", "=", "x", "\n", "if", "self", ".", "normalization", ":", "\n", "            ", "if", "self", ".", "args", ".", "norm_layer", "==", "\"batch_norm\"", ":", "\n", "                ", "self", ".", "norm_layer", "=", "MetaBatchNormLayer", "(", "self", ".", "input_shape", "[", "1", "]", ",", "track_running_stats", "=", "True", ",", "\n", "meta_batch_norm", "=", "self", ".", "meta_layer", ",", "\n", "no_learnable_params", "=", "self", ".", "no_bn_learnable_params", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "use_per_step_bn_statistics", "=", "self", ".", "use_per_step_bn_statistics", ",", "\n", "args", "=", "self", ".", "args", ")", "\n", "", "elif", "self", ".", "args", ".", "norm_layer", "==", "\"layer_norm\"", ":", "\n", "                ", "self", ".", "norm_layer", "=", "MetaLayerNormLayer", "(", "input_feature_shape", "=", "out", ".", "shape", "[", "1", ":", "]", ")", "\n", "\n", "", "out", "=", "self", ".", "norm_layer", ".", "forward", "(", "out", ",", "num_step", "=", "0", ")", "\n", "", "self", ".", "conv", "=", "MetaConv2dLayer", "(", "in_channels", "=", "out", ".", "shape", "[", "1", "]", ",", "out_channels", "=", "self", ".", "num_filters", ",", "\n", "kernel_size", "=", "self", ".", "kernel_size", ",", "\n", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", ",", "use_bias", "=", "self", ".", "use_bias", ")", "\n", "\n", "\n", "self", ".", "layer_dict", "[", "'activation_function_pre'", "]", "=", "nn", ".", "LeakyReLU", "(", ")", "\n", "\n", "\n", "out", "=", "self", ".", "layer_dict", "[", "'activation_function_pre'", "]", ".", "forward", "(", "self", ".", "conv", ".", "forward", "(", "out", ")", ")", "\n", "print", "(", "out", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaNormLayerConvReLU.forward": [[805, 843], ["meta_neural_network_architectures.MetaNormLayerConvReLU.conv.forward", "meta_neural_network_architectures.MetaNormLayerConvReLU.layer_dict[].forward", "meta_neural_network_architectures.extract_top_level_dict", "meta_neural_network_architectures.MetaNormLayerConvReLU.norm_layer.forward"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward"], ["", "def", "forward", "(", "self", ",", "x", ",", "num_step", ",", "params", "=", "None", ",", "training", "=", "False", ",", "backup_running_statistics", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            Forward propagates by applying the function. If params are none then internal params are used.\n            Otherwise passed params will be used to execute the function.\n            :param input: input data batch, size either can be any.\n            :param num_step: The current inner loop step being taken. This is used when we are learning per step params and\n             collecting per step batch statistics. It indexes the correct object to use for the current time-step\n            :param params: A dictionary containing 'weight' and 'bias'.\n            :param training: Whether this is currently the training or evaluation phase.\n            :param backup_running_statistics: Whether to backup the running statistics. This is used\n            at evaluation time, when after the pass is complete we want to throw away the collected validation stats.\n            :return: The result of the batch norm operation.\n        \"\"\"", "\n", "batch_norm_params", "=", "None", "\n", "\n", "if", "params", "is", "not", "None", ":", "\n", "            ", "params", "=", "extract_top_level_dict", "(", "current_dict", "=", "params", ")", "\n", "\n", "if", "self", ".", "normalization", ":", "\n", "                ", "if", "'norm_layer'", "in", "params", ":", "\n", "                    ", "batch_norm_params", "=", "params", "[", "'norm_layer'", "]", "\n", "\n", "", "", "conv_params", "=", "params", "[", "'conv'", "]", "\n", "", "else", ":", "\n", "            ", "conv_params", "=", "None", "\n", "#print('no inner loop params', self)", "\n", "\n", "", "out", "=", "x", "\n", "\n", "if", "self", ".", "normalization", ":", "\n", "            ", "out", "=", "self", ".", "norm_layer", ".", "forward", "(", "out", ",", "num_step", "=", "num_step", ",", "\n", "params", "=", "batch_norm_params", ",", "training", "=", "training", ",", "\n", "backup_running_statistics", "=", "backup_running_statistics", ")", "\n", "\n", "", "out", "=", "self", ".", "conv", ".", "forward", "(", "out", ",", "params", "=", "conv_params", ")", "\n", "out", "=", "self", ".", "layer_dict", "[", "'activation_function_pre'", "]", ".", "forward", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaNormLayerConvReLU.restore_backup_stats": [[844, 850], ["meta_neural_network_architectures.MetaNormLayerConvReLU.norm_layer.restore_backup_stats"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats"], ["", "def", "restore_backup_stats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Restore stored statistics from the backup, replacing the current ones.\n        \"\"\"", "\n", "if", "self", ".", "normalization", ":", "\n", "            ", "self", ".", "norm_layer", ".", "restore_backup_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.VGGReLUNormNetwork.__init__": [[853, 887], ["torch.Module.__init__", "list", "meta_neural_network_architectures.VGGReLUNormNetwork.build_network", "print", "meta_neural_network_architectures.VGGReLUNormNetwork.named_parameters", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.build_network"], ["    ", "def", "__init__", "(", "self", ",", "im_shape", ",", "num_output_classes", ",", "args", ",", "device", ",", "meta_classifier", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Builds a multilayer convolutional network. It also provides functionality for passing external parameters to be\n        used at inference time. Enables inner loop optimization readily.\n        :param im_shape: The input image batch shape.\n        :param num_output_classes: The number of output classes of the network.\n        :param args: A named tuple containing the system's hyperparameters.\n        :param device: The device to run this on.\n        :param meta_classifier: A flag indicating whether the system's meta-learning (inner-loop) functionalities should\n        be enabled.\n        \"\"\"", "\n", "super", "(", "VGGReLUNormNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "b", ",", "c", ",", "self", ".", "h", ",", "self", ".", "w", "=", "im_shape", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "total_layers", "=", "0", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "upscale_shapes", "=", "[", "]", "\n", "self", ".", "cnn_filters", "=", "args", ".", "cnn_num_filters", "\n", "self", ".", "input_shape", "=", "list", "(", "im_shape", ")", "\n", "self", ".", "num_stages", "=", "args", ".", "num_stages", "\n", "self", ".", "num_output_classes", "=", "num_output_classes", "\n", "\n", "if", "args", ".", "max_pooling", ":", "\n", "            ", "print", "(", "\"Using max pooling\"", ")", "\n", "self", ".", "conv_stride", "=", "1", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Using strided convolutions\"", ")", "\n", "self", ".", "conv_stride", "=", "2", "\n", "", "self", ".", "meta_classifier", "=", "meta_classifier", "\n", "\n", "self", ".", "build_network", "(", ")", "\n", "print", "(", "\"meta network params\"", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "print", "(", "name", ",", "param", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.VGGReLUNormNetwork.build_network": [[888, 926], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "meta_neural_network_architectures.VGGReLUNormNetwork.upscale_shapes.append", "range", "list", "torch.max_pool2d.view", "meta_neural_network_architectures.MetaLinearLayer", "print", "meta_neural_network_architectures.MetaConvNormLayerReLU", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "numpy.prod"], "methods", ["None"], ["", "", "def", "build_network", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Builds the network before inference is required by creating some dummy inputs with the same input as the\n        self.im_shape tuple. Then passes that through the network and dynamically computes input shapes and\n        sets output shapes for each layer.\n        \"\"\"", "\n", "x", "=", "torch", ".", "zeros", "(", "self", ".", "input_shape", ")", "\n", "out", "=", "x", "\n", "self", ".", "layer_dict", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "upscale_shapes", ".", "append", "(", "x", ".", "shape", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_stages", ")", ":", "\n", "            ", "self", ".", "layer_dict", "[", "'conv{}'", ".", "format", "(", "i", ")", "]", "=", "MetaConvNormLayerReLU", "(", "input_shape", "=", "out", ".", "shape", ",", "\n", "num_filters", "=", "self", ".", "cnn_filters", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "self", ".", "conv_stride", ",", "\n", "padding", "=", "self", ".", "args", ".", "conv_padding", ",", "\n", "use_bias", "=", "True", ",", "args", "=", "self", ".", "args", ",", "\n", "normalization", "=", "True", ",", "\n", "meta_layer", "=", "self", ".", "meta_classifier", ",", "\n", "no_bn_learnable_params", "=", "False", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "out", "=", "self", ".", "layer_dict", "[", "'conv{}'", ".", "format", "(", "i", ")", "]", "(", "out", ",", "training", "=", "True", ",", "num_step", "=", "0", ")", "\n", "\n", "if", "self", ".", "args", ".", "max_pooling", ":", "\n", "                ", "out", "=", "F", ".", "max_pool2d", "(", "input", "=", "out", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "not", "self", ".", "args", ".", "max_pooling", ":", "\n", "            ", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "out", ".", "shape", "[", "2", "]", ")", "\n", "\n", "", "self", ".", "encoder_features_shape", "=", "list", "(", "out", ".", "shape", ")", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "self", ".", "layer_dict", "[", "'linear'", "]", "=", "MetaLinearLayer", "(", "input_shape", "=", "(", "out", ".", "shape", "[", "0", "]", ",", "np", ".", "prod", "(", "out", ".", "shape", "[", "1", ":", "]", ")", ")", ",", "\n", "num_filters", "=", "self", ".", "num_output_classes", ",", "use_bias", "=", "True", ")", "\n", "\n", "out", "=", "self", ".", "layer_dict", "[", "'linear'", "]", "(", "out", ")", "\n", "print", "(", "\"VGGNetwork build\"", ",", "out", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.VGGReLUNormNetwork.forward": [[927, 968], ["dict", "meta_neural_network_architectures.VGGReLUNormNetwork.layer_dict.named_parameters", "range", "torch.max_pool2d.view", "meta_neural_network_architectures.extract_top_level_dict", "name.split", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.max_pool2d.size", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "params.items"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict"], ["", "def", "forward", "(", "self", ",", "x", ",", "num_step", ",", "params", "=", "None", ",", "training", "=", "False", ",", "backup_running_statistics", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Forward propages through the network. If any params are passed then they are used instead of stored params.\n        :param x: Input image batch.\n        :param num_step: The current inner loop step number\n        :param params: If params are None then internal parameters are used. If params are a dictionary with keys the\n         same as the layer names then they will be used instead.\n        :param training: Whether this is training (True) or eval time.\n        :param backup_running_statistics: Whether to backup the running statistics in their backup store. Which is\n        then used to reset the stats back to a previous state (usually after an eval loop, when we want to throw away stored statistics)\n        :return: Logits of shape b, num_output_classes.\n        \"\"\"", "\n", "param_dict", "=", "dict", "(", ")", "\n", "\n", "if", "params", "is", "not", "None", ":", "\n", "            ", "params", "=", "{", "key", ":", "value", "[", "0", "]", "for", "key", ",", "value", "in", "params", ".", "items", "(", ")", "}", "\n", "param_dict", "=", "extract_top_level_dict", "(", "current_dict", "=", "params", ")", "\n", "\n", "# print('top network', param_dict.keys())", "\n", "", "for", "name", ",", "param", "in", "self", ".", "layer_dict", ".", "named_parameters", "(", ")", ":", "\n", "            ", "path_bits", "=", "name", ".", "split", "(", "\".\"", ")", "\n", "layer_name", "=", "path_bits", "[", "0", "]", "\n", "if", "layer_name", "not", "in", "param_dict", ":", "\n", "                ", "param_dict", "[", "layer_name", "]", "=", "None", "\n", "\n", "", "", "out", "=", "x", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_stages", ")", ":", "\n", "            ", "out", "=", "self", ".", "layer_dict", "[", "'conv{}'", ".", "format", "(", "i", ")", "]", "(", "out", ",", "params", "=", "param_dict", "[", "'conv{}'", ".", "format", "(", "i", ")", "]", ",", "training", "=", "training", ",", "\n", "backup_running_statistics", "=", "backup_running_statistics", ",", "\n", "num_step", "=", "num_step", ")", "\n", "if", "self", ".", "args", ".", "max_pooling", ":", "\n", "                ", "out", "=", "F", ".", "max_pool2d", "(", "input", "=", "out", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "2", ",", "padding", "=", "0", ")", "\n", "\n", "", "", "if", "not", "self", ".", "args", ".", "max_pooling", ":", "\n", "            ", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "out", ".", "shape", "[", "2", "]", ")", "\n", "\n", "", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "layer_dict", "[", "'linear'", "]", "(", "out", ",", "param_dict", "[", "'linear'", "]", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.VGGReLUNormNetwork.re_init": [[969, 974], ["meta_neural_network_architectures.VGGReLUNormNetwork.named_parameters", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["None"], ["", "def", "re_init", "(", "self", ")", ":", "\n", "#for param in self.parameters():", "\n", "        ", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", "and", "'weight'", "in", "name", "and", "'norm'", "not", "in", "name", ":", "\n", "                ", "nn", ".", "init", ".", "xavier_uniform_", "(", "param", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.VGGReLUNormNetwork.zero_grad": [[975, 991], ["meta_neural_network_architectures.VGGReLUNormNetwork.parameters", "params.items", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "param.grad.zero_", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "param.grad.zero_"], "methods", ["None"], ["", "", "", "def", "zero_grad", "(", "self", ",", "params", "=", "None", ")", ":", "\n", "        ", "if", "params", "is", "None", ":", "\n", "            ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", "==", "True", ":", "\n", "                    ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "if", "torch", ".", "sum", "(", "param", ".", "grad", ")", ">", "0", ":", "\n", "                            ", "print", "(", "param", ".", "grad", ")", "\n", "param", ".", "grad", ".", "zero_", "(", ")", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "for", "name", ",", "param", "in", "params", ".", "items", "(", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", "==", "True", ":", "\n", "                    ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "if", "torch", ".", "sum", "(", "param", ".", "grad", ")", ">", "0", ":", "\n", "                            ", "print", "(", "param", ".", "grad", ")", "\n", "param", ".", "grad", ".", "zero_", "(", ")", "\n", "params", "[", "name", "]", ".", "grad", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.VGGReLUNormNetwork.restore_backup_stats": [[992, 998], ["range", "meta_neural_network_architectures.VGGReLUNormNetwork.layer_dict[].restore_backup_stats"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats"], ["", "", "", "", "", "", "def", "restore_backup_stats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset stored batch statistics from the stored backup.\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "num_stages", ")", ":", "\n", "            ", "self", ".", "layer_dict", "[", "'conv{}'", ".", "format", "(", "i", ")", "]", ".", "restore_backup_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.ResNet12.__init__": [[1001, 1035], ["torch.Module.__init__", "list", "meta_neural_network_architectures.ResNet12.build_network", "print", "meta_neural_network_architectures.ResNet12.named_parameters", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.build_network"], ["    ", "def", "__init__", "(", "self", ",", "im_shape", ",", "num_output_classes", ",", "args", ",", "device", ",", "meta_classifier", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Builds a multilayer convolutional network. It also provides functionality for passing external parameters to be\n        used at inference time. Enables inner loop optimization readily.\n        :param im_shape: The input image batch shape.\n        :param num_output_classes: The number of output classes of the network.\n        :param args: A named tuple containing the system's hyperparameters.\n        :param device: The device to run this on.\n        :param meta_classifier: A flag indicating whether the system's meta-learning (inner-loop) functionalities should\n        be enabled.\n        \"\"\"", "\n", "super", "(", "ResNet12", ",", "self", ")", ".", "__init__", "(", ")", "\n", "b", ",", "c", ",", "self", ".", "h", ",", "self", ".", "w", "=", "im_shape", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "total_layers", "=", "0", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "upscale_shapes", "=", "[", "]", "\n", "self", ".", "cnn_filters", "=", "args", ".", "cnn_num_filters", "\n", "self", ".", "input_shape", "=", "list", "(", "im_shape", ")", "\n", "self", ".", "num_stages", "=", "args", ".", "num_stages", "\n", "self", ".", "num_output_classes", "=", "num_output_classes", "\n", "\n", "if", "args", ".", "max_pooling", ":", "\n", "            ", "print", "(", "\"Using max pooling\"", ")", "\n", "self", ".", "conv_stride", "=", "1", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Using strided convolutions\"", ")", "\n", "self", ".", "conv_stride", "=", "2", "\n", "", "self", ".", "meta_classifier", "=", "meta_classifier", "\n", "\n", "self", ".", "build_network", "(", ")", "\n", "print", "(", "\"meta network params\"", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "print", "(", "name", ",", "param", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.ResNet12.build_network": [[1036, 1075], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "meta_neural_network_architectures.ResNet12.upscale_shapes.append", "range", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "out.view.view.view", "meta_neural_network_architectures.MetaLinearLayer", "print", "len", "meta_neural_network_architectures.MetaMaxResLayerReLU", "numpy.prod"], "methods", ["None"], ["", "", "def", "build_network", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Builds the network before inference is required by creating some dummy inputs with the same input as the\n        self.im_shape tuple. Then passes that through the network and dynamically computes input shapes and\n        sets output shapes for each layer.\n        \"\"\"", "\n", "x", "=", "torch", ".", "zeros", "(", "self", ".", "input_shape", ")", "\n", "out", "=", "x", "\n", "self", ".", "layer_dict", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "upscale_shapes", ".", "append", "(", "x", ".", "shape", ")", "\n", "\n", "num_chn", "=", "[", "64", ",", "128", ",", "256", ",", "512", "]", "\n", "max_padding", "=", "[", "0", ",", "0", ",", "1", ",", "1", "]", "\n", "maxpool", "=", "[", "True", ",", "True", ",", "True", ",", "False", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "num_chn", ")", ")", ":", "\n", "            ", "self", ".", "layer_dict", "[", "'layer{}'", ".", "format", "(", "i", ")", "]", "=", "MetaMaxResLayerReLU", "(", "input_shape", "=", "out", ".", "shape", ",", "\n", "num_filters", "=", "num_chn", "[", "i", "]", ",", "\n", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "1", ",", "\n", "use_bias", "=", "False", ",", "args", "=", "self", ".", "args", ",", "\n", "#use_bias=True, args=self.args,", "\n", "normalization", "=", "True", ",", "\n", "meta_layer", "=", "self", ".", "meta_classifier", ",", "\n", "no_bn_learnable_params", "=", "False", ",", "\n", "device", "=", "self", ".", "device", ",", "\n", "downsample", "=", "False", ",", "\n", "max_padding", "=", "max_padding", "[", "i", "]", ",", "\n", "maxpool", "=", "maxpool", "[", "i", "]", ")", "\n", "out", "=", "self", ".", "layer_dict", "[", "'layer{}'", ".", "format", "(", "i", ")", "]", "(", "out", ",", "training", "=", "True", ",", "num_step", "=", "0", ")", "\n", "\n", "", "out", "=", "F", ".", "adaptive_avg_pool2d", "(", "out", ",", "(", "1", ",", "1", ")", ")", "\n", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "self", ".", "layer_dict", "[", "'linear'", "]", "=", "MetaLinearLayer", "(", "input_shape", "=", "(", "out", ".", "shape", "[", "0", "]", ",", "np", ".", "prod", "(", "out", ".", "shape", "[", "1", ":", "]", ")", ")", ",", "\n", "num_filters", "=", "self", ".", "num_output_classes", ",", "use_bias", "=", "True", ")", "\n", "\n", "out", "=", "self", ".", "layer_dict", "[", "'linear'", "]", "(", "out", ")", "\n", "print", "(", "\"ResNet12 build\"", ",", "out", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.ResNet12.forward": [[1076, 1115], ["dict", "meta_neural_network_architectures.ResNet12.layer_dict.named_parameters", "range", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "out.view.view.view", "meta_neural_network_architectures.extract_top_level_dict", "name.split", "out.view.view.size", "params.items"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict"], ["", "def", "forward", "(", "self", ",", "x", ",", "num_step", ",", "params", "=", "None", ",", "training", "=", "False", ",", "backup_running_statistics", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Forward propages through the network. If any params are passed then they are used instead of stored params.\n        :param x: Input image batch.\n        :param num_step: The current inner loop step number\n        :param params: If params are None then internal parameters are used. If params are a dictionary with keys the\n         same as the layer names then they will be used instead.\n        :param training: Whether this is training (True) or eval time.\n        :param backup_running_statistics: Whether to backup the running statistics in their backup store. Which is\n        then used to reset the stats back to a previous state (usually after an eval loop, when we want to throw away stored statistics)\n        :return: Logits of shape b, num_output_classes.\n        \"\"\"", "\n", "param_dict", "=", "dict", "(", ")", "\n", "\n", "if", "params", "is", "not", "None", ":", "\n", "#param_dict = parallel_extract_top_level_dict(current_dict=params)", "\n", "\n", "            ", "params", "=", "{", "key", ":", "value", "[", "0", "]", "for", "key", ",", "value", "in", "params", ".", "items", "(", ")", "}", "\n", "param_dict", "=", "extract_top_level_dict", "(", "current_dict", "=", "params", ")", "\n", "\n", "# print('top network', param_dict.keys())", "\n", "", "for", "name", ",", "param", "in", "self", ".", "layer_dict", ".", "named_parameters", "(", ")", ":", "\n", "            ", "path_bits", "=", "name", ".", "split", "(", "\".\"", ")", "\n", "layer_name", "=", "path_bits", "[", "0", "]", "\n", "if", "layer_name", "not", "in", "param_dict", ":", "\n", "                ", "param_dict", "[", "layer_name", "]", "=", "None", "\n", "\n", "", "", "out", "=", "x", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_stages", ")", ":", "\n", "            ", "out", "=", "self", ".", "layer_dict", "[", "'layer{}'", ".", "format", "(", "i", ")", "]", "(", "out", ",", "params", "=", "param_dict", "[", "'layer{}'", ".", "format", "(", "i", ")", "]", ",", "training", "=", "training", ",", "\n", "backup_running_statistics", "=", "backup_running_statistics", ",", "\n", "num_step", "=", "num_step", ")", "\n", "\n", "", "out", "=", "F", ".", "adaptive_avg_pool2d", "(", "out", ",", "(", "1", ",", "1", ")", ")", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "layer_dict", "[", "'linear'", "]", "(", "out", ",", "param_dict", "[", "'linear'", "]", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.ResNet12.zero_grad": [[1116, 1132], ["meta_neural_network_architectures.ResNet12.parameters", "params.items", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "param.grad.zero_", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "param.grad.zero_"], "methods", ["None"], ["", "def", "zero_grad", "(", "self", ",", "params", "=", "None", ")", ":", "\n", "        ", "if", "params", "is", "None", ":", "\n", "            ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", "==", "True", ":", "\n", "                    ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "if", "torch", ".", "sum", "(", "param", ".", "grad", ")", ">", "0", ":", "\n", "                            ", "print", "(", "param", ".", "grad", ")", "\n", "param", ".", "grad", ".", "zero_", "(", ")", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "for", "name", ",", "param", "in", "params", ".", "items", "(", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", "==", "True", ":", "\n", "                    ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "if", "torch", ".", "sum", "(", "param", ".", "grad", ")", ">", "0", ":", "\n", "                            ", "print", "(", "param", ".", "grad", ")", "\n", "param", ".", "grad", ".", "zero_", "(", ")", "\n", "params", "[", "name", "]", ".", "grad", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.ResNet12.restore_backup_stats": [[1133, 1140], ["range", "meta_neural_network_architectures.ResNet12.layer_dict[].restore_backup_stats"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats"], ["", "", "", "", "", "", "def", "restore_backup_stats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset stored batch statistics from the stored backup.\n        \"\"\"", "\n", "#self.layer_dict['conv0'].restore_backup_stats()", "\n", "for", "i", "in", "range", "(", "self", ".", "num_stages", ")", ":", "\n", "            ", "self", ".", "layer_dict", "[", "'layer{}'", ".", "format", "(", "i", ")", "]", ".", "restore_backup_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaStepLossNetwork.__init__": [[1142, 1154], ["torch.Module.__init__", "meta_neural_network_architectures.MetaStepLossNetwork.build_network", "print", "meta_neural_network_architectures.MetaStepLossNetwork.named_parameters", "print"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.build_network"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "args", ",", "device", ")", ":", "\n", "        ", "super", "(", "MetaStepLossNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "input_shape", "=", "(", "1", ",", "input_dim", ")", "\n", "\n", "self", ".", "build_network", "(", ")", "\n", "print", "(", "\"meta network params\"", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "print", "(", "name", ",", "param", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaStepLossNetwork.build_network": [[1155, 1174], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "meta_neural_network_architectures.MetaLinearLayer", "meta_neural_network_architectures.MetaLinearLayer", "meta_neural_network_architectures.MetaStepLossNetwork.linear1", "torch.relu_", "torch.relu_", "torch.relu_", "meta_neural_network_architectures.MetaStepLossNetwork.linear2"], "methods", ["None"], ["", "", "def", "build_network", "(", "self", ")", ":", "\n", "        ", "\"\"\" \n        Builds the network before inference is required by creating some dummy inputs with the same input as the\n        self.im_shape tuple. Then passes that through the network and dynamically computes input shapes and\n        sets output shapes for each layer.\n        \"\"\"", "\n", "x", "=", "torch", ".", "zeros", "(", "self", ".", "input_shape", ")", "\n", "out", "=", "x", "\n", "\n", "self", ".", "linear1", "=", "MetaLinearLayer", "(", "input_shape", "=", "self", ".", "input_shape", ",", "\n", "num_filters", "=", "self", ".", "input_dim", ",", "use_bias", "=", "True", ")", "\n", "\n", "self", ".", "linear2", "=", "MetaLinearLayer", "(", "input_shape", "=", "(", "1", ",", "self", ".", "input_dim", ")", ",", "\n", "num_filters", "=", "1", ",", "use_bias", "=", "True", ")", "\n", "\n", "\n", "out", "=", "self", ".", "linear1", "(", "out", ")", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "out", "=", "self", ".", "linear2", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaStepLossNetwork.forward": [[1175, 1204], ["meta_neural_network_architectures.MetaStepLossNetwork.linear1", "torch.relu_", "torch.relu_", "torch.relu_", "meta_neural_network_architectures.MetaStepLossNetwork.linear2", "meta_neural_network_architectures.extract_top_level_dict"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict"], ["", "def", "forward", "(", "self", ",", "x", ",", "params", "=", "None", ")", ":", "\n", "        ", "\"\"\"                                  \n        Forward propages through the network. If any params are passed then they are used instead of stored params.\n        :param x: Input image batch.\n        :param num_step: The current inner loop step number\n        :param params: If params are None then internal parameters are used. If params are a dictionary with keys the\n         same as the layer names then they will be used instead.\n        :param training: Whether this is training (True) or eval time.\n        :param backup_running_statistics: Whether to backup the running statistics in their backup store. Which is\n        then used to reset the stats back to a previous state (usually after an eval loop, when we want to throw away stored statistics)\n        :return: Logits of shape b, num_output_classes.\n        \"\"\"", "\n", "\n", "linear1_params", "=", "None", "\n", "linear2_params", "=", "None", "\n", "\n", "if", "params", "is", "not", "None", ":", "\n", "            ", "params", "=", "extract_top_level_dict", "(", "current_dict", "=", "params", ")", "\n", "\n", "linear1_params", "=", "params", "[", "'linear1'", "]", "\n", "linear2_params", "=", "params", "[", "'linear2'", "]", "\n", "\n", "", "out", "=", "x", "\n", "\n", "out", "=", "self", ".", "linear1", "(", "out", ",", "linear1_params", ")", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "out", "=", "self", ".", "linear2", "(", "out", ",", "linear2_params", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaStepLossNetwork.zero_grad": [[1205, 1221], ["meta_neural_network_architectures.MetaStepLossNetwork.parameters", "params.items", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "param.grad.zero_", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "param.grad.zero_"], "methods", ["None"], ["", "def", "zero_grad", "(", "self", ",", "params", "=", "None", ")", ":", "\n", "        ", "if", "params", "is", "None", ":", "\n", "            ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", "==", "True", ":", "\n", "                    ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "if", "torch", ".", "sum", "(", "param", ".", "grad", ")", ">", "0", ":", "\n", "                            ", "print", "(", "param", ".", "grad", ")", "\n", "param", ".", "grad", ".", "zero_", "(", ")", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "for", "name", ",", "param", "in", "params", ".", "items", "(", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", "==", "True", ":", "\n", "                    ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "if", "torch", ".", "sum", "(", "param", ".", "grad", ")", ">", "0", ":", "\n", "                            ", "print", "(", "param", ".", "grad", ")", "\n", "param", ".", "grad", ".", "zero_", "(", ")", "\n", "params", "[", "name", "]", ".", "grad", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaStepLossNetwork.restore_backup_stats": [[1222, 1228], ["range", "meta_neural_network_architectures.MetaStepLossNetwork.layer_dict[].restore_backup_stats"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats"], ["", "", "", "", "", "", "def", "restore_backup_stats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset stored batch statistics from the stored backup.\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "num_stages", ")", ":", "\n", "            ", "self", ".", "layer_dict", "[", "'conv{}'", ".", "format", "(", "i", ")", "]", ".", "restore_backup_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.__init__": [[1231, 1255], ["torch.Module.__init__", "meta_neural_network_architectures.MetaLossNetwork.build_network", "print", "meta_neural_network_architectures.MetaLossNetwork.named_parameters", "print"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.build_network"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "args", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        Builds a multilayer convolutional network. It also provides functionality for passing external parameters to be\n        used at inference time. Enables inner loop optimization readily.\n        :param im_shape: The input image batch shape.\n        :param num_output_classes: The number of output classes of the network.\n        :param args: A named tuple containing the system's hyperparameters.\n        :param device: The device to run this on.\n        :param meta_classifier: A flag indicating whether the system's meta-learning (inner-loop) functionalities should\n        be enabled. \n        \"\"\"", "\n", "super", "(", "MetaLossNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "input_shape", "=", "(", "1", ",", "input_dim", ")", "\n", "\n", "self", ".", "num_steps", "=", "args", ".", "number_of_training_steps_per_iter", "# number of inner-loop steps", "\n", "\n", "self", ".", "build_network", "(", ")", "\n", "print", "(", "\"meta network params\"", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "print", "(", "name", ",", "param", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.build_network": [[1256, 1269], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "range", "meta_neural_network_architectures.MetaStepLossNetwork"], "methods", ["None"], ["", "", "def", "build_network", "(", "self", ")", ":", "\n", "        ", "\"\"\" \n        Builds the network before inference is required by creating some dummy inputs with the same input as the\n        self.im_shape tuple. Then passes that through the network and dynamically computes input shapes and\n        sets output shapes for each layer.\n        \"\"\"", "\n", "x", "=", "torch", ".", "zeros", "(", "self", ".", "input_shape", ")", "\n", "self", ".", "layer_dict", "=", "nn", ".", "ModuleDict", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "self", ".", "layer_dict", "[", "'step{}'", ".", "format", "(", "i", ")", "]", "=", "MetaStepLossNetwork", "(", "self", ".", "input_dim", ",", "args", "=", "self", ".", "args", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "out", "=", "self", ".", "layer_dict", "[", "'step{}'", ".", "format", "(", "i", ")", "]", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.forward": [[1270, 1300], ["dict", "meta_neural_network_architectures.MetaLossNetwork.layer_dict.named_parameters", "meta_neural_network_architectures.extract_top_level_dict", "name.split", "params.items"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "num_step", ",", "params", "=", "None", ")", ":", "\n", "        ", "\"\"\"                                  \n        Forward propages through the network. If any params are passed then they are used instead of stored params.\n        :param x: Input image batch.\n        :param num_step: The current inner loop step number\n        :param params: If params are None then internal parameters are used. If params are a dictionary with keys the\n         same as the layer names then they will be used instead.\n        :param training: Whether this is training (True) or eval time.\n        :param backup_running_statistics: Whether to backup the running statistics in their backup store. Which is\n        then used to reset the stats back to a previous state (usually after an eval loop, when we want to throw away stored statistics)\n        :return: Logits of shape b, num_output_classes.\n        \"\"\"", "\n", "param_dict", "=", "dict", "(", ")", "\n", "\n", "if", "params", "is", "not", "None", ":", "\n", "            ", "params", "=", "{", "key", ":", "value", "[", "0", "]", "for", "key", ",", "value", "in", "params", ".", "items", "(", ")", "}", "\n", "param_dict", "=", "extract_top_level_dict", "(", "current_dict", "=", "params", ")", "\n", "\n", "", "for", "name", ",", "param", "in", "self", ".", "layer_dict", ".", "named_parameters", "(", ")", ":", "\n", "            ", "path_bits", "=", "name", ".", "split", "(", "\".\"", ")", "\n", "layer_name", "=", "path_bits", "[", "0", "]", "\n", "if", "layer_name", "not", "in", "param_dict", ":", "\n", "                ", "param_dict", "[", "layer_name", "]", "=", "None", "\n", "\n", "\n", "", "", "out", "=", "x", "\n", "\n", "out", "=", "self", ".", "layer_dict", "[", "'step{}'", ".", "format", "(", "num_step", ")", "]", "(", "out", ",", "param_dict", "[", "'step{}'", ".", "format", "(", "num_step", ")", "]", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.zero_grad": [[1301, 1317], ["meta_neural_network_architectures.MetaLossNetwork.parameters", "params.items", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "param.grad.zero_", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "param.grad.zero_"], "methods", ["None"], ["", "def", "zero_grad", "(", "self", ",", "params", "=", "None", ")", ":", "\n", "        ", "if", "params", "is", "None", ":", "\n", "            ", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", "==", "True", ":", "\n", "                    ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "if", "torch", ".", "sum", "(", "param", ".", "grad", ")", ">", "0", ":", "\n", "                            ", "print", "(", "param", ".", "grad", ")", "\n", "param", ".", "grad", ".", "zero_", "(", ")", "\n", "", "", "", "", "", "else", ":", "\n", "            ", "for", "name", ",", "param", "in", "params", ".", "items", "(", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", "==", "True", ":", "\n", "                    ", "if", "param", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "if", "torch", ".", "sum", "(", "param", ".", "grad", ")", ">", "0", ":", "\n", "                            ", "print", "(", "param", ".", "grad", ")", "\n", "param", ".", "grad", ".", "zero_", "(", ")", "\n", "params", "[", "name", "]", ".", "grad", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats": [[1318, 1324], ["range", "meta_neural_network_architectures.MetaLossNetwork.layer_dict[].restore_backup_stats"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats"], ["", "", "", "", "", "", "def", "restore_backup_stats", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset stored batch statistics from the stored backup.\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "num_stages", ")", ":", "\n", "            ", "self", ".", "layer_dict", "[", "'conv{}'", ".", "format", "(", "i", ")", "]", ".", "restore_backup_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.StepLossAdapter.__init__": [[1327, 1340], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "num_loss_net_layers", ",", "args", ",", "device", ")", ":", "\n", "        ", "super", "(", "StepLossAdapter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "args", "=", "args", "\n", "output_dim", "=", "num_loss_net_layers", "*", "2", "*", "2", "# 2 for weight and bias, another 2 for multiplier and offset", "\n", "\n", "self", ".", "linear1", "=", "nn", ".", "Linear", "(", "input_dim", ",", "input_dim", ")", "\n", "self", ".", "activation", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "linear2", "=", "nn", ".", "Linear", "(", "input_dim", ",", "output_dim", ")", "\n", "\n", "self", ".", "multiplier_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "output_dim", "//", "2", ")", ")", "\n", "self", ".", "offset_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "output_dim", "//", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.StepLossAdapter.forward": [[1341, 1358], ["meta_neural_network_architectures.StepLossAdapter.linear1", "torch.relu_", "torch.relu_", "torch.relu_", "meta_neural_network_architectures.StepLossAdapter.linear2", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "dict", "loss_params.items"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "task_state", ",", "num_step", ",", "loss_params", ")", ":", "\n", "\n", "        ", "out", "=", "self", ".", "linear1", "(", "task_state", ")", "\n", "out", "=", "F", ".", "relu_", "(", "out", ")", "\n", "out", "=", "self", ".", "linear2", "(", "out", ")", "\n", "\n", "generated_multiplier", ",", "generated_offset", "=", "torch", ".", "chunk", "(", "out", ",", "chunks", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n", "i", "=", "0", "\n", "updated_loss_weights", "=", "dict", "(", ")", "\n", "for", "key", ",", "val", "in", "loss_params", ".", "items", "(", ")", ":", "\n", "            ", "if", "'step{}'", ".", "format", "(", "num_step", ")", "in", "key", ":", "\n", "                ", "updated_loss_weights", "[", "key", "]", "=", "(", "1", "+", "self", ".", "multiplier_bias", "[", "i", "]", "*", "generated_multiplier", "[", "i", "]", ")", "*", "val", "+", "self", ".", "offset_bias", "[", "i", "]", "*", "generated_offset", "[", "i", "]", "\n", "i", "+=", "1", "\n", "\n", "", "", "return", "updated_loss_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.LossAdapter.__init__": [[1361, 1372], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "meta_neural_network_architectures.LossAdapter.loss_adapter.append", "meta_neural_network_architectures.StepLossAdapter"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "num_loss_net_layers", ",", "args", ",", "device", ")", ":", "\n", "        ", "super", "(", "LossAdapter", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "args", "=", "args", "\n", "\n", "self", ".", "num_steps", "=", "args", ".", "number_of_training_steps_per_iter", "# number of inner-loop steps", "\n", "\n", "self", ".", "loss_adapter", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_steps", ")", ":", "\n", "            ", "self", ".", "loss_adapter", ".", "append", "(", "StepLossAdapter", "(", "input_dim", ",", "num_loss_net_layers", ",", "args", "=", "args", ",", "device", "=", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.LossAdapter.forward": [[1373, 1375], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "task_state", ",", "num_step", ",", "loss_params", ")", ":", "\n", "        ", "return", "self", ".", "loss_adapter", "[", "num_step", "]", "(", "task_state", ",", "num_step", ",", "loss_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.extract_top_level_dict": [[11, 40], ["dict", "current_dict.keys", "key.replace", "name.replace.replace", "name.replace.replace", "name.replace.replace", "name.replace.split", "name.replace.split", "output_dict[].items"], "function", ["None"], ["def", "extract_top_level_dict", "(", "current_dict", ")", ":", "\n", "    ", "\"\"\"\n    Builds a graph dictionary from the passed depth_keys, value pair. Useful for dynamically passing external params\n    :param depth_keys: A list of strings making up the name of a variable. Used to make a graph for that params tree.\n    :param value: Param value\n    :param key_exists: If none then assume new dict, else load existing dict and add new key->value pairs to it.\n    :return: A dictionary graph of the params already added to the graph.\n    \"\"\"", "\n", "output_dict", "=", "dict", "(", ")", "\n", "for", "key", "in", "current_dict", ".", "keys", "(", ")", ":", "\n", "        ", "name", "=", "key", ".", "replace", "(", "\"layer_dict.\"", ",", "\"\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"layer_dict.\"", ",", "\"\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"block_dict.\"", ",", "\"\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"module-\"", ",", "\"\"", ")", "\n", "top_level", "=", "name", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "sub_level", "=", "\".\"", ".", "join", "(", "name", ".", "split", "(", "\".\"", ")", "[", "1", ":", "]", ")", "\n", "\n", "if", "top_level", "not", "in", "output_dict", ":", "\n", "            ", "if", "sub_level", "==", "\"\"", ":", "\n", "                ", "output_dict", "[", "top_level", "]", "=", "current_dict", "[", "key", "]", "\n", "", "else", ":", "\n", "                ", "output_dict", "[", "top_level", "]", "=", "{", "sub_level", ":", "current_dict", "[", "key", "]", "}", "\n", "", "", "else", ":", "\n", "            ", "new_item", "=", "{", "key", ":", "value", "for", "key", ",", "value", "in", "output_dict", "[", "top_level", "]", ".", "items", "(", ")", "}", "\n", "new_item", "[", "sub_level", "]", "=", "current_dict", "[", "key", "]", "\n", "output_dict", "[", "top_level", "]", "=", "new_item", "\n", "\n", "#print(current_dict.keys(), output_dict.keys())", "\n", "", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.__init__": [[27, 122], ["torch.Module.__init__", "few_shot_learning_system.set_torch_seed", "inner_loop_optimizers.LSLRGradientDescentLearningRule", "few_shot_learning_system.MAMLFewShotClassifier.get_inner_loop_parameter_dict", "few_shot_learning_system.MAMLFewShotClassifier.inner_loop_optimizer.initialise", "print", "few_shot_learning_system.MAMLFewShotClassifier.inner_loop_optimizer.named_parameters", "few_shot_learning_system.MAMLFewShotClassifier.to", "print", "few_shot_learning_system.MAMLFewShotClassifier.named_parameters", "list", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.lr_scheduler.CosineAnnealingLR", "torch.lr_scheduler.CosineAnnealingLR", "torch.lr_scheduler.CosineAnnealingLR", "torch.lr_scheduler.CosineAnnealingLR", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "meta_neural_network_architectures.ResNet12().to", "meta_neural_network_architectures.VGGReLUNormNetwork().to", "few_shot_learning_system.MAMLFewShotClassifier.classifier.named_parameters", "len", "meta_neural_network_architectures.MetaLossNetwork().to", "meta_neural_network_architectures.MetaLossNetwork().to", "meta_neural_network_architectures.LossAdapter().to", "meta_neural_network_architectures.LossAdapter().to", "print", "len", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "few_shot_learning_system.MAMLFewShotClassifier.trainable_parameters", "print", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "print", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "few_shot_learning_system.MAMLFewShotClassifier.to", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "few_shot_learning_system.MAMLFewShotClassifier.to", "meta_neural_network_architectures.ResNet12", "meta_neural_network_architectures.VGGReLUNormNetwork", "meta_neural_network_architectures.MetaLossNetwork", "meta_neural_network_architectures.MetaLossNetwork", "meta_neural_network_architectures.LossAdapter", "meta_neural_network_architectures.LossAdapter", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.cuda.current_device", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.set_torch_seed", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.get_inner_loop_parameter_dict", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.inner_loop_optimizers.LSLRGradientDescentLearningRule.initialise", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.trainable_parameters"], ["    ", "def", "__init__", "(", "self", ",", "im_shape", ",", "device", ",", "args", ")", ":", "\n", "        ", "\"\"\"\n        Initializes a MAML few shot learning system\n        :param im_shape: The images input size, in batch, c, h, w shape\n        :param device: The device to use to use the model on.\n        :param args: A namedtuple of arguments specifying various hyperparameters.\n        \"\"\"", "\n", "super", "(", "MAMLFewShotClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "self", ".", "use_cuda", "=", "args", ".", "use_cuda", "\n", "self", ".", "im_shape", "=", "im_shape", "\n", "self", ".", "current_epoch", "=", "0", "\n", "\n", "self", ".", "rng", "=", "set_torch_seed", "(", "seed", "=", "args", ".", "seed", ")", "\n", "\n", "if", "self", ".", "args", ".", "backbone", "==", "'ResNet12'", ":", "\n", "            ", "self", ".", "classifier", "=", "ResNet12", "(", "im_shape", "=", "self", ".", "im_shape", ",", "num_output_classes", "=", "self", ".", "args", ".", "\n", "num_classes_per_set", ",", "\n", "args", "=", "args", ",", "device", "=", "device", ",", "meta_classifier", "=", "True", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "VGGReLUNormNetwork", "(", "im_shape", "=", "self", ".", "im_shape", ",", "num_output_classes", "=", "self", ".", "args", ".", "\n", "num_classes_per_set", ",", "\n", "args", "=", "args", ",", "device", "=", "device", ",", "meta_classifier", "=", "True", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n", "", "self", ".", "task_learning_rate", "=", "args", ".", "init_inner_loop_learning_rate", "\n", "\n", "self", ".", "inner_loop_optimizer", "=", "LSLRGradientDescentLearningRule", "(", "device", "=", "device", ",", "\n", "init_learning_rate", "=", "self", ".", "task_learning_rate", ",", "\n", "init_weight_decay", "=", "args", ".", "init_inner_loop_weight_decay", ",", "\n", "total_num_inner_loop_steps", "=", "self", ".", "args", ".", "number_of_training_steps_per_iter", ",", "\n", "use_learnable_weight_decay", "=", "self", ".", "args", ".", "alfa", ",", "\n", "use_learnable_learning_rates", "=", "(", "self", ".", "args", ".", "learnable_per_layer_per_step_inner_loop_learning_rate", "or", "self", ".", "args", ".", "alfa", ")", ",", "\n", "alfa", "=", "self", ".", "args", ".", "alfa", ",", "random_init", "=", "self", ".", "args", ".", "random_init", ")", "\n", "\n", "names_weights_copy", "=", "self", ".", "get_inner_loop_parameter_dict", "(", "self", ".", "classifier", ".", "named_parameters", "(", ")", ")", "\n", "\n", "if", "self", ".", "args", ".", "meta_loss", ":", "\n", "\n", "            ", "base_learner_num_layers", "=", "len", "(", "names_weights_copy", ")", "\n", "\n", "support_meta_loss_num_dim", "=", "base_learner_num_layers", "+", "2", "*", "self", ".", "args", ".", "num_classes_per_set", "+", "1", "\n", "support_adapter_num_dim", "=", "base_learner_num_layers", "+", "1", "\n", "query_num_dim", "=", "base_learner_num_layers", "+", "1", "+", "self", ".", "args", ".", "num_classes_per_set", "\n", "\n", "self", ".", "meta_loss", "=", "MetaLossNetwork", "(", "support_meta_loss_num_dim", ",", "args", "=", "args", ",", "device", "=", "device", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "meta_query_loss", "=", "MetaLossNetwork", "(", "query_num_dim", ",", "args", "=", "args", ",", "device", "=", "device", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n", "\n", "self", ".", "meta_loss_adapter", "=", "LossAdapter", "(", "support_adapter_num_dim", ",", "num_loss_net_layers", "=", "2", ",", "args", "=", "args", ",", "device", "=", "device", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "meta_query_loss_adapter", "=", "LossAdapter", "(", "query_num_dim", ",", "num_loss_net_layers", "=", "2", ",", "args", "=", "args", ",", "device", "=", "device", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n", "", "self", ".", "inner_loop_optimizer", ".", "initialise", "(", "\n", "names_weights_dict", "=", "names_weights_copy", ")", "\n", "print", "(", "\"Inner Loop parameters\"", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "inner_loop_optimizer", ".", "named_parameters", "(", ")", ":", "\n", "            ", "print", "(", "key", ",", "value", ".", "shape", ")", "\n", "\n", "", "self", ".", "use_cuda", "=", "args", ".", "use_cuda", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "to", "(", "device", ")", "\n", "print", "(", "\"Outer Loop parameters\"", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", ":", "\n", "                ", "print", "(", "name", ",", "param", ".", "shape", ",", "param", ".", "device", ",", "param", ".", "requires_grad", ")", "\n", "\n", "# ALFA", "\n", "", "", "if", "self", ".", "args", ".", "alfa", ":", "\n", "            ", "num_layers", "=", "len", "(", "names_weights_copy", ")", "\n", "input_dim", "=", "num_layers", "*", "2", "\n", "self", ".", "update_rule_learner", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "input_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "input_dim", ",", "input_dim", ")", "\n", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n", "", "learnable_params", "=", "list", "(", ")", "\n", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "trainable_parameters", "(", ")", ",", "lr", "=", "args", ".", "meta_learning_rate", ",", "amsgrad", "=", "False", ")", "\n", "\n", "self", ".", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "optimizer", "=", "self", ".", "optimizer", ",", "T_max", "=", "self", ".", "args", ".", "total_epochs", ",", "\n", "eta_min", "=", "self", ".", "args", ".", "min_learning_rate", ")", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "print", "(", "torch", ".", "cuda", ".", "device_count", "(", ")", ")", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "                ", "self", ".", "to", "(", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "DataParallel", "(", "module", "=", "self", ".", "classifier", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "to", "(", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", "\n", "\n", "", "self", ".", "device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.get_per_step_loss_importance_vector": [[123, 144], ["range", "numpy.minimum", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "numpy.ones", "numpy.maximum", "len", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "", "def", "get_per_step_loss_importance_vector", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generates a tensor of dimensionality (num_inner_loop_steps) indicating the importance of each step's target\n        loss towards the optimization loss.\n        :return: A tensor to be used to compute the weighted average of the loss, useful for\n        the MSL (Multi Step Loss) mechanism.\n        \"\"\"", "\n", "loss_weights", "=", "np", ".", "ones", "(", "shape", "=", "(", "self", ".", "args", ".", "number_of_training_steps_per_iter", ")", ")", "*", "(", "\n", "1.0", "/", "self", ".", "args", ".", "number_of_training_steps_per_iter", ")", "\n", "decay_rate", "=", "1.0", "/", "self", ".", "args", ".", "number_of_training_steps_per_iter", "/", "self", ".", "args", ".", "multi_step_loss_num_epochs", "\n", "min_value_for_non_final_losses", "=", "0.03", "/", "self", ".", "args", ".", "number_of_training_steps_per_iter", "\n", "for", "i", "in", "range", "(", "len", "(", "loss_weights", ")", "-", "1", ")", ":", "\n", "            ", "curr_value", "=", "np", ".", "maximum", "(", "loss_weights", "[", "i", "]", "-", "(", "self", ".", "current_epoch", "*", "decay_rate", ")", ",", "min_value_for_non_final_losses", ")", "\n", "loss_weights", "[", "i", "]", "=", "curr_value", "\n", "\n", "", "curr_value", "=", "np", ".", "minimum", "(", "\n", "loss_weights", "[", "-", "1", "]", "+", "(", "self", ".", "current_epoch", "*", "(", "self", ".", "args", ".", "number_of_training_steps_per_iter", "-", "1", ")", "*", "decay_rate", ")", ",", "\n", "1.0", "-", "(", "(", "self", ".", "args", ".", "number_of_training_steps_per_iter", "-", "1", ")", "*", "min_value_for_non_final_losses", ")", ")", "\n", "loss_weights", "[", "-", "1", "]", "=", "curr_value", "\n", "loss_weights", "=", "torch", ".", "Tensor", "(", "loss_weights", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "return", "loss_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.get_inner_loop_parameter_dict": [[145, 161], ["dict", "param.to", "param.to"], "methods", ["None"], ["", "def", "get_inner_loop_parameter_dict", "(", "self", ",", "params", ")", ":", "\n", "        ", "\"\"\"\n        Returns a dictionary with the parameters to use for inner loop updates.\n        :param params: A dictionary of the network's parameters.\n        :return: A dictionary of the parameters to use for the inner loop optimization process.\n        \"\"\"", "\n", "param_dict", "=", "dict", "(", ")", "\n", "for", "name", ",", "param", "in", "params", ":", "\n", "            ", "if", "param", ".", "requires_grad", ":", "\n", "                ", "if", "self", ".", "args", ".", "enable_inner_loop_optimizable_bn_params", ":", "\n", "                    ", "param_dict", "[", "name", "]", "=", "param", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "", "else", ":", "\n", "                    ", "if", "\"norm_layer\"", "not", "in", "name", ":", "\n", "                        ", "param_dict", "[", "name", "]", "=", "param", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n", "", "", "", "", "return", "param_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.apply_inner_loop_update": [[162, 206], ["torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "dict", "dict.items", "few_shot_learning_system.MAMLFewShotClassifier.inner_loop_optimizer.update_params", "few_shot_learning_system.MAMLFewShotClassifier.classifier.module.zero_grad", "few_shot_learning_system.MAMLFewShotClassifier.classifier.zero_grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "zip", "names_grads_copy[].sum", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "name.replace", "value.unsqueeze().repeat", "few_shot_learning_system.MAMLFewShotClassifier.values", "few_shot_learning_system.MAMLFewShotClassifier.keys", "few_shot_learning_system.MAMLFewShotClassifier.items", "print", "few_shot_learning_system.MAMLFewShotClassifier.items", "value.unsqueeze", "range", "len"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.inner_loop_optimizers.LSLRGradientDescentLearningRule.update_params", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.zero_grad", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.zero_grad"], ["", "def", "apply_inner_loop_update", "(", "self", ",", "loss", ",", "names_weights_copy", ",", "generated_alpha_params", ",", "generated_beta_params", ",", "use_second_order", ",", "current_step_idx", ",", "grads", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Applies an inner loop update given current step's loss, the weights to update, a flag indicating whether to use\n        second order derivatives and the current step's index.\n        :param loss: Current step's loss with respect to the support set.\n        :param names_weights_copy: A dictionary with names to parameters to update.\n        :param use_second_order: A boolean flag of whether to use second order derivatives.\n        :param current_step_idx: Current step's index.\n        :return: A dictionary with the updated weights (name, param)\n        \"\"\"", "\n", "num_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "if", "num_gpus", ">", "1", ":", "\n", "            ", "self", ".", "classifier", ".", "module", ".", "zero_grad", "(", "params", "=", "names_weights_copy", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "classifier", ".", "zero_grad", "(", "params", "=", "names_weights_copy", ")", "\n", "\n", "", "if", "grads", "is", "None", ":", "\n", "            ", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "names_weights_copy", ".", "values", "(", ")", ",", "\n", "create_graph", "=", "use_second_order", ",", "allow_unused", "=", "True", ")", "\n", "\n", "", "names_grads_copy", "=", "dict", "(", "zip", "(", "names_weights_copy", ".", "keys", "(", ")", ",", "grads", ")", ")", "\n", "\n", "names_weights_copy", "=", "{", "key", ":", "value", "[", "0", "]", "for", "key", ",", "value", "in", "names_weights_copy", ".", "items", "(", ")", "}", "\n", "\n", "for", "key", ",", "grad", "in", "names_grads_copy", ".", "items", "(", ")", ":", "\n", "            ", "if", "grad", "is", "None", ":", "\n", "                ", "print", "(", "'Grads not found for inner loop parameter'", ",", "key", ")", "\n", "", "names_grads_copy", "[", "key", "]", "=", "names_grads_copy", "[", "key", "]", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n", "\n", "", "names_weights_copy", "=", "self", ".", "inner_loop_optimizer", ".", "update_params", "(", "names_weights_dict", "=", "names_weights_copy", ",", "\n", "names_grads_wrt_params_dict", "=", "names_grads_copy", ",", "\n", "generated_alpha_params", "=", "generated_alpha_params", ",", "\n", "generated_beta_params", "=", "generated_beta_params", ",", "\n", "num_step", "=", "current_step_idx", ")", "\n", "\n", "num_devices", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "1", "\n", "names_weights_copy", "=", "{", "\n", "name", ".", "replace", "(", "'module.'", ",", "''", ")", ":", "value", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "\n", "[", "num_devices", "]", "+", "[", "1", "for", "i", "in", "range", "(", "len", "(", "value", ".", "shape", ")", ")", "]", ")", "for", "\n", "name", ",", "value", "in", "names_weights_copy", ".", "items", "(", ")", "}", "\n", "\n", "\n", "return", "names_weights_copy", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.get_across_task_loss_metrics": [[207, 214], ["dict", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "get_across_task_loss_metrics", "(", "self", ",", "total_losses", ",", "total_accuracies", ")", ":", "\n", "        ", "losses", "=", "dict", "(", ")", "\n", "\n", "losses", "[", "'loss'", "]", "=", "torch", ".", "stack", "(", "total_losses", ")", "\n", "losses", "[", "'accuracy'", "]", "=", "total_accuracies", "\n", "\n", "return", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward": [[215, 368], ["enumerate", "few_shot_learning_system.MAMLFewShotClassifier.get_across_task_loss_metrics", "enumerate", "zip", "few_shot_learning_system.MAMLFewShotClassifier.get_per_step_loss_importance_vector", "few_shot_learning_system.MAMLFewShotClassifier.get_inner_loop_parameter_dict", "few_shot_learning_system.MAMLFewShotClassifier.get_inner_loop_parameter_dict", "few_shot_learning_system.MAMLFewShotClassifier.get_inner_loop_parameter_dict", "x_support_set_task.view.view.view", "y_support_set_task.view.view.view", "x_target_set_task.view.view.view", "y_target_set_task.view.view.view", "range", "target_preds.detach().cpu().numpy", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "predicted.float().eq().cpu().float", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "total_losses.append", "total_accuracies.extend", "item.detach().cpu().numpy", "range", "range", "range", "few_shot_learning_system.MAMLFewShotClassifier.classifier.named_parameters", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "name.replace", "value.unsqueeze().repeat", "few_shot_learning_system.MAMLFewShotClassifier.meta_loss.named_parameters", "few_shot_learning_system.MAMLFewShotClassifier.meta_query_loss.named_parameters", "name.replace", "value.unsqueeze().repeat", "name.replace", "value.unsqueeze().repeat", "few_shot_learning_system.MAMLFewShotClassifier.net_forward", "few_shot_learning_system.MAMLFewShotClassifier.apply_inner_loop_update", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "len", "few_shot_learning_system.MAMLFewShotClassifier.items", "few_shot_learning_system.MAMLFewShotClassifier.items", "few_shot_learning_system.MAMLFewShotClassifier.items", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "few_shot_learning_system.MAMLFewShotClassifier.items", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "few_shot_learning_system.MAMLFewShotClassifier.update_rule_learner", "len", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "few_shot_learning_system.MAMLFewShotClassifier.keys", "few_shot_learning_system.MAMLFewShotClassifier.net_forward", "torch.sum.append", "torch.sum.append", "torch.sum.append", "torch.sum.append", "target_preds.detach().cpu", "predicted.float().eq().cpu", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "few_shot_learning_system.MAMLFewShotClassifier.classifier.module.restore_backup_stats", "few_shot_learning_system.MAMLFewShotClassifier.classifier.restore_backup_stats", "item.detach().cpu", "value.unsqueeze", "value.unsqueeze", "value.unsqueeze", "few_shot_learning_system.MAMLFewShotClassifier.values", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "len", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "few_shot_learning_system.MAMLFewShotClassifier.net_forward", "torch.sum.append", "torch.sum.append", "torch.sum.append", "torch.sum.append", "v.mean", "loss_grads[].mean", "target_preds.detach", "predicted.float().eq", "item.detach", "range", "range", "range", "y_target_set_task.view.view.data.float", "len", "len", "len", "predicted.float"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.get_across_task_loss_metrics", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.get_per_step_loss_importance_vector", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.get_inner_loop_parameter_dict", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.get_inner_loop_parameter_dict", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.get_inner_loop_parameter_dict", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.net_forward", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.apply_inner_loop_update", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.net_forward", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.restore_backup_stats", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.net_forward"], ["", "def", "forward", "(", "self", ",", "data_batch", ",", "epoch", ",", "use_second_order", ",", "use_multi_step_loss_optimization", ",", "num_steps", ",", "training_phase", ")", ":", "\n", "        ", "\"\"\"\n        Runs a forward outer loop pass on the batch of tasks using the MAML/++ framework.\n        :param data_batch: A data batch containing the support and target sets.\n        :param epoch: Current epoch's index\n        :param use_second_order: A boolean saying whether to use second order derivatives.\n        :param use_multi_step_loss_optimization: Whether to optimize on the outer loop using just the last step's\n        target loss (True) or whether to use multi step loss which improves the stability of the system (False)\n        :param num_steps: Number of inner loop steps.\n        :param training_phase: Whether this is a training phase (True) or an evaluation phase (False)\n        :return: A dictionary with the collected losses of the current outer forward propagation.\n        \"\"\"", "\n", "\n", "x_support_set", ",", "x_target_set", ",", "y_support_set", ",", "y_target_set", "=", "data_batch", "\n", "\n", "[", "b", ",", "ncs", ",", "spc", "]", "=", "y_support_set", ".", "shape", "\n", "\n", "self", ".", "num_classes_per_set", "=", "ncs", "\n", "\n", "total_losses", "=", "[", "]", "\n", "total_accuracies", "=", "[", "]", "\n", "total_support_accuracies", "=", "[", "[", "]", "for", "i", "in", "range", "(", "num_steps", ")", "]", "\n", "total_target_accuracies", "=", "[", "[", "]", "for", "i", "in", "range", "(", "num_steps", ")", "]", "\n", "per_task_target_preds", "=", "[", "[", "]", "for", "i", "in", "range", "(", "len", "(", "x_target_set", ")", ")", "]", "\n", "\n", "for", "task_id", ",", "(", "x_support_set_task", ",", "y_support_set_task", ",", "x_target_set_task", ",", "y_target_set_task", ")", "in", "enumerate", "(", "zip", "(", "x_support_set", ",", "\n", "y_support_set", ",", "\n", "x_target_set", ",", "\n", "y_target_set", ")", ")", ":", "\n", "            ", "task_losses", "=", "[", "]", "\n", "task_accuracies", "=", "[", "]", "\n", "per_step_support_accuracy", "=", "[", "]", "\n", "per_step_target_accuracy", "=", "[", "]", "\n", "per_step_loss_importance_vectors", "=", "self", ".", "get_per_step_loss_importance_vector", "(", ")", "\n", "names_weights_copy", "=", "self", ".", "get_inner_loop_parameter_dict", "(", "self", ".", "classifier", ".", "named_parameters", "(", ")", ")", "\n", "\n", "num_devices", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "1", "\n", "\n", "names_weights_copy", "=", "{", "\n", "name", ".", "replace", "(", "'module.'", ",", "''", ")", ":", "value", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "\n", "[", "num_devices", "]", "+", "[", "1", "for", "i", "in", "range", "(", "len", "(", "value", ".", "shape", ")", ")", "]", ")", "for", "\n", "name", ",", "value", "in", "names_weights_copy", ".", "items", "(", ")", "}", "\n", "\n", "names_loss_weights_copy_list", "=", "[", "]", "\n", "names_query_loss_weights_copy_list", "=", "[", "]", "\n", "names_loss_weights_copy", "=", "self", ".", "get_inner_loop_parameter_dict", "(", "self", ".", "meta_loss", ".", "named_parameters", "(", ")", ")", "\n", "names_query_loss_weights_copy", "=", "self", ".", "get_inner_loop_parameter_dict", "(", "self", ".", "meta_query_loss", ".", "named_parameters", "(", ")", ")", "\n", "\n", "names_loss_weights_copy", "=", "{", "\n", "name", ".", "replace", "(", "'module.'", ",", "''", ")", ":", "value", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "\n", "[", "num_devices", "]", "+", "[", "1", "for", "i", "in", "range", "(", "len", "(", "value", ".", "shape", ")", ")", "]", ")", "for", "\n", "name", ",", "value", "in", "names_loss_weights_copy", ".", "items", "(", ")", "}", "\n", "\n", "names_query_loss_weights_copy", "=", "{", "\n", "name", ".", "replace", "(", "'module.'", ",", "''", ")", ":", "value", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "\n", "[", "num_devices", "]", "+", "[", "1", "for", "i", "in", "range", "(", "len", "(", "value", ".", "shape", ")", ")", "]", ")", "for", "\n", "name", ",", "value", "in", "names_query_loss_weights_copy", ".", "items", "(", ")", "}", "\n", "\n", "n", ",", "s", ",", "c", ",", "h", ",", "w", "=", "x_target_set_task", ".", "shape", "\n", "\n", "x_support_set_task", "=", "x_support_set_task", ".", "view", "(", "-", "1", ",", "c", ",", "h", ",", "w", ")", "\n", "y_support_set_task", "=", "y_support_set_task", ".", "view", "(", "-", "1", ")", "\n", "x_target_set_task", "=", "x_target_set_task", ".", "view", "(", "-", "1", ",", "c", ",", "h", ",", "w", ")", "\n", "y_target_set_task", "=", "y_target_set_task", ".", "view", "(", "-", "1", ")", "\n", "\n", "for", "num_step", "in", "range", "(", "num_steps", ")", ":", "\n", "\n", "                ", "meta_loss", ",", "support_preds", ",", "support_loss", "=", "self", ".", "net_forward", "(", "x", "=", "x_support_set_task", ",", "\n", "y", "=", "y_support_set_task", ",", "\n", "weights", "=", "names_weights_copy", ",", "\n", "backup_running_statistics", "=", "\n", "True", "if", "(", "num_step", "==", "0", ")", "else", "False", ",", "\n", "training", "=", "True", ",", "num_step", "=", "num_step", ",", "\n", "x_t", "=", "x_target_set_task", ",", "\n", "meta_loss_weights", "=", "names_loss_weights_copy", ",", "\n", "meta_query_loss_weights", "=", "names_query_loss_weights_copy", ")", "\n", "generated_alpha_params", "=", "{", "}", "\n", "generated_beta_params", "=", "{", "}", "\n", "\n", "loss_grads", "=", "None", "\n", "\n", "if", "self", ".", "args", ".", "alfa", ":", "\n", "\n", "                    ", "loss_grads", "=", "torch", ".", "autograd", ".", "grad", "(", "meta_loss", ",", "names_weights_copy", ".", "values", "(", ")", ",", "create_graph", "=", "use_second_order", ")", "\n", "per_step_task_embedding", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "names_weights_copy", ".", "items", "(", ")", ":", "\n", "                        ", "per_step_task_embedding", ".", "append", "(", "v", ".", "mean", "(", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "len", "(", "loss_grads", ")", ")", ":", "\n", "                        ", "per_step_task_embedding", ".", "append", "(", "loss_grads", "[", "i", "]", ".", "mean", "(", ")", ")", "\n", "\n", "", "per_step_task_embedding", "=", "torch", ".", "stack", "(", "per_step_task_embedding", ")", "\n", "\n", "generated_params", "=", "self", ".", "update_rule_learner", "(", "per_step_task_embedding", ")", "\n", "num_layers", "=", "len", "(", "names_weights_copy", ")", "\n", "\n", "generated_alpha", ",", "generated_beta", "=", "torch", ".", "split", "(", "generated_params", ",", "split_size_or_sections", "=", "num_layers", ")", "\n", "g", "=", "0", "\n", "for", "key", "in", "names_weights_copy", ".", "keys", "(", ")", ":", "\n", "                        ", "generated_alpha_params", "[", "key", "]", "=", "generated_alpha", "[", "g", "]", "\n", "generated_beta_params", "[", "key", "]", "=", "generated_beta", "[", "g", "]", "\n", "g", "+=", "1", "\n", "\n", "", "", "names_weights_copy", "=", "self", ".", "apply_inner_loop_update", "(", "loss", "=", "meta_loss", ",", "\n", "names_weights_copy", "=", "names_weights_copy", ",", "\n", "generated_beta_params", "=", "generated_beta_params", ",", "\n", "generated_alpha_params", "=", "generated_alpha_params", ",", "\n", "use_second_order", "=", "use_second_order", ",", "\n", "current_step_idx", "=", "num_step", ",", "\n", "grads", "=", "loss_grads", ")", "\n", "\n", "if", "use_multi_step_loss_optimization", "and", "training_phase", "and", "epoch", "<", "self", ".", "args", ".", "multi_step_loss_num_epochs", ":", "\n", "                    ", "target_loss", ",", "target_preds", ",", "_", "=", "self", ".", "net_forward", "(", "x", "=", "x_support_set_task", ",", "\n", "y", "=", "y_support_set_task", ",", "weights", "=", "names_weights_copy", ",", "\n", "backup_running_statistics", "=", "False", ",", "training", "=", "True", ",", "\n", "num_step", "=", "num_step", ",", "\n", "x_t", "=", "x_target_set_task", ",", "\n", "y_t", "=", "y_target_set_task", ")", "\n", "\n", "task_losses", ".", "append", "(", "per_step_loss_importance_vectors", "[", "num_step", "]", "*", "target_loss", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "if", "num_step", "==", "(", "self", ".", "args", ".", "number_of_training_steps_per_iter", "-", "1", ")", ":", "\n", "                        ", "target_loss", ",", "target_preds", ",", "_", "=", "self", ".", "net_forward", "(", "x", "=", "x_support_set_task", ",", "\n", "y", "=", "y_support_set_task", ",", "weights", "=", "names_weights_copy", ",", "\n", "backup_running_statistics", "=", "False", ",", "training", "=", "True", ",", "\n", "num_step", "=", "num_step", ",", "\n", "x_t", "=", "x_target_set_task", ",", "\n", "y_t", "=", "y_target_set_task", ")", "\n", "task_losses", ".", "append", "(", "target_loss", ")", "\n", "\n", "", "", "", "per_task_target_preds", "[", "task_id", "]", "=", "target_preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "_", ",", "predicted", "=", "torch", ".", "max", "(", "target_preds", ".", "data", ",", "1", ")", "\n", "\n", "accuracy", "=", "predicted", ".", "float", "(", ")", ".", "eq", "(", "y_target_set_task", ".", "data", ".", "float", "(", ")", ")", ".", "cpu", "(", ")", ".", "float", "(", ")", "\n", "task_losses", "=", "torch", ".", "sum", "(", "torch", ".", "stack", "(", "task_losses", ")", ")", "\n", "total_losses", ".", "append", "(", "task_losses", ")", "\n", "total_accuracies", ".", "extend", "(", "accuracy", ")", "\n", "\n", "if", "not", "training_phase", ":", "\n", "                ", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "                    ", "self", ".", "classifier", ".", "module", ".", "restore_backup_stats", "(", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "classifier", ".", "restore_backup_stats", "(", ")", "\n", "\n", "", "", "", "losses", "=", "self", ".", "get_across_task_loss_metrics", "(", "total_losses", "=", "total_losses", ",", "\n", "total_accuracies", "=", "total_accuracies", ")", "\n", "\n", "for", "idx", ",", "item", "in", "enumerate", "(", "per_step_loss_importance_vectors", ")", ":", "\n", "            ", "losses", "[", "'loss_importance_vector_{}'", ".", "format", "(", "idx", ")", "]", "=", "item", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "return", "losses", ",", "per_task_target_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.net_forward": [[369, 442], ["few_shot_learning_system.MAMLFewShotClassifier.classifier.forward", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "weights.values", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "few_shot_learning_system.MAMLFewShotClassifier.meta_loss_adapter", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "few_shot_learning_system.MAMLFewShotClassifier.meta_loss().mean().squeeze", "weights.values", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "few_shot_learning_system.MAMLFewShotClassifier.meta_query_loss_adapter", "few_shot_learning_system.MAMLFewShotClassifier.meta_query_loss().mean().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.mean", "torch.cat.mean", "torch.cat.mean", "torch.cat.mean", "x_t.size", "x_t.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "v.mean", "torch.cat.mean", "torch.cat.mean", "torch.cat.mean", "torch.cat.mean", "torch.cat.std", "torch.cat.std", "torch.cat.std", "torch.cat.std", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat.view().expand", "torch.cat.view().expand", "torch.cat.view().expand", "torch.cat.view().expand", "torch.cat.mean", "torch.cat.mean", "torch.cat.mean", "torch.cat.mean", "torch.cat.std", "torch.cat.std", "torch.cat.std", "torch.cat.std", "few_shot_learning_system.MAMLFewShotClassifier.meta_loss().mean", "v.mean", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat.view().expand", "torch.cat.view().expand", "torch.cat.view().expand", "torch.cat.view().expand", "torch.sum.view", "torch.sum.view", "torch.sum.view", "torch.sum.view", "torch.cat.mean", "torch.cat.mean", "torch.cat.mean", "torch.cat.mean", "torch.cat.std", "torch.cat.std", "torch.cat.std", "torch.cat.std", "few_shot_learning_system.MAMLFewShotClassifier.meta_query_loss().mean", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "support_preds.size", "torch.sum.size", "torch.sum.size", "torch.sum.size", "torch.sum.size", "torch.zeros().to.size", "torch.zeros().to.size", "torch.zeros().to.size", "torch.zeros().to.size", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "few_shot_learning_system.MAMLFewShotClassifier.meta_loss", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat.view", "few_shot_learning_system.MAMLFewShotClassifier.meta_query_loss"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward"], ["", "def", "net_forward", "(", "self", ",", "x", ",", "y", ",", "weights", ",", "backup_running_statistics", ",", "training", ",", "num_step", ",", "meta_loss_weights", "=", "None", ",", "x_t", "=", "None", ",", "y_t", "=", "None", ",", "meta_query_loss_weights", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        A base model forward pass on some data points x. Using the parameters in the weights dictionary. Also requires\n        boolean flags indicating whether to reset the running statistics at the end of the run (if at evaluation phase).\n        A flag indicating whether this is the training session and an int indicating the current step's number in the\n        inner loop.\n        :param x: A data batch of shape b, c, h, w\n        :param y: A data targets batch of shape b, n_classes\n        :param weights: A dictionary containing the weights to pass to the network.\n        :param backup_running_statistics: A flag indicating whether to reset the batch norm running statistics to their\n         previous values after the run (only for evaluation)\n        :param training: A flag indicating whether the current process phase is a training or evaluation.\n        :param num_step: An integer indicating the number of the step in the inner loop.\n        :return: the crossentropy losses with respect to the given y, the predictions of the base model.\n        \"\"\"", "\n", "tmp_preds", "=", "self", ".", "classifier", ".", "forward", "(", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "x_t", ")", ",", "0", ")", ",", "params", "=", "weights", ",", "\n", "training", "=", "training", ",", "\n", "backup_running_statistics", "=", "backup_running_statistics", ",", "num_step", "=", "num_step", ")", "\n", "support_preds", "=", "tmp_preds", "[", ":", "-", "x_t", ".", "size", "(", "0", ")", "]", "\n", "query_preds", "=", "tmp_preds", "[", "-", "x_t", ".", "size", "(", "0", ")", ":", "]", "\n", "\n", "if", "meta_loss_weights", "is", "None", ":", "\n", "            ", "loss", "=", "F", ".", "cross_entropy", "(", "input", "=", "tmp_preds", ",", "target", "=", "torch", ".", "cat", "(", "(", "y", ",", "y_t", ")", ",", "0", ")", ")", "\n", "preds", "=", "query_preds", "\n", "support_loss", "=", "loss", "\n", "\n", "", "else", ":", "\n", "            ", "support_task_state", "=", "[", "]", "\n", "\n", "support_loss", "=", "F", ".", "cross_entropy", "(", "input", "=", "support_preds", ",", "target", "=", "y", ")", "\n", "support_task_state", ".", "append", "(", "support_loss", ")", "\n", "\n", "for", "v", "in", "weights", ".", "values", "(", ")", ":", "\n", "                ", "support_task_state", ".", "append", "(", "v", ".", "mean", "(", ")", ")", "\n", "\n", "", "support_task_state", "=", "torch", ".", "stack", "(", "support_task_state", ")", "\n", "adapt_support_task_state", "=", "(", "support_task_state", "-", "support_task_state", ".", "mean", "(", ")", ")", "/", "(", "support_task_state", ".", "std", "(", ")", "+", "1e-12", ")", "\n", "\n", "updated_meta_loss_weights", "=", "self", ".", "meta_loss_adapter", "(", "adapt_support_task_state", ",", "num_step", ",", "meta_loss_weights", ")", "\n", "\n", "support_y", "=", "torch", ".", "zeros", "(", "support_preds", ".", "shape", ")", ".", "to", "(", "support_preds", ".", "device", ")", "\n", "support_y", "[", "torch", ".", "arange", "(", "support_y", ".", "size", "(", "0", ")", ")", ",", "y", "]", "=", "1", "\n", "support_task_state", "=", "torch", ".", "cat", "(", "(", "\n", "support_task_state", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand", "(", "support_preds", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "\n", "support_preds", ",", "\n", "support_y", "\n", ")", ",", "-", "1", ")", "\n", "\n", "support_task_state", "=", "(", "support_task_state", "-", "support_task_state", ".", "mean", "(", ")", ")", "/", "(", "support_task_state", ".", "std", "(", ")", "+", "1e-12", ")", "\n", "meta_support_loss", "=", "self", ".", "meta_loss", "(", "support_task_state", ",", "num_step", ",", "params", "=", "updated_meta_loss_weights", ")", ".", "mean", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "query_task_state", "=", "[", "]", "\n", "for", "v", "in", "weights", ".", "values", "(", ")", ":", "\n", "                ", "query_task_state", ".", "append", "(", "v", ".", "mean", "(", ")", ")", "\n", "", "out_prob", "=", "F", ".", "log_softmax", "(", "query_preds", ")", "\n", "instance_entropy", "=", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "out_prob", ")", "*", "out_prob", ",", "dim", "=", "-", "1", ")", "\n", "query_task_state", "=", "torch", ".", "stack", "(", "query_task_state", ")", "\n", "query_task_state", "=", "torch", ".", "cat", "(", "(", "\n", "query_task_state", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand", "(", "instance_entropy", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "\n", "query_preds", ",", "\n", "instance_entropy", ".", "view", "(", "-", "1", ",", "1", ")", "\n", ")", ",", "-", "1", ")", "\n", "\n", "query_task_state", "=", "(", "query_task_state", "-", "query_task_state", ".", "mean", "(", ")", ")", "/", "(", "query_task_state", ".", "std", "(", ")", "+", "1e-12", ")", "\n", "updated_meta_query_loss_weights", "=", "self", ".", "meta_query_loss_adapter", "(", "query_task_state", ".", "mean", "(", "0", ")", ",", "num_step", ",", "meta_query_loss_weights", ")", "\n", "\n", "meta_query_loss", "=", "self", ".", "meta_query_loss", "(", "query_task_state", ",", "num_step", ",", "params", "=", "updated_meta_query_loss_weights", ")", ".", "mean", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "loss", "=", "support_loss", "+", "meta_query_loss", "+", "meta_support_loss", "\n", "\n", "preds", "=", "support_preds", "\n", "\n", "", "return", "loss", ",", "preds", ",", "support_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.trainable_parameters": [[443, 450], ["few_shot_learning_system.MAMLFewShotClassifier.parameters"], "methods", ["None"], ["", "def", "trainable_parameters", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns an iterator over the trainable parameters of the model.\n        \"\"\"", "\n", "for", "param", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", ":", "\n", "                ", "yield", "param", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.train_forward_prop": [[451, 465], ["few_shot_learning_system.MAMLFewShotClassifier.forward"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward"], ["", "", "", "def", "train_forward_prop", "(", "self", ",", "data_batch", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Runs an outer loop forward prop using the meta-model and base-model.\n        :param data_batch: A data batch containing the support set and the target set input, output pairs.\n        :param epoch: The index of the currrent epoch.\n        :return: A dictionary of losses for the current step.\n        \"\"\"", "\n", "losses", ",", "per_task_target_preds", "=", "self", ".", "forward", "(", "data_batch", "=", "data_batch", ",", "epoch", "=", "epoch", ",", "\n", "use_second_order", "=", "self", ".", "args", ".", "second_order", "and", "\n", "epoch", ">", "self", ".", "args", ".", "first_order_to_second_order_epoch", ",", "\n", "use_multi_step_loss_optimization", "=", "self", ".", "args", ".", "use_multi_step_loss_optimization", ",", "\n", "num_steps", "=", "self", ".", "args", ".", "number_of_training_steps_per_iter", ",", "\n", "training_phase", "=", "True", ")", "\n", "return", "losses", ",", "per_task_target_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.evaluation_forward_prop": [[466, 479], ["few_shot_learning_system.MAMLFewShotClassifier.forward"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.forward"], ["", "def", "evaluation_forward_prop", "(", "self", ",", "data_batch", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Runs an outer loop evaluation forward prop using the meta-model and base-model.\n        :param data_batch: A data batch containing the support set and the target set input, output pairs.\n        :param epoch: The index of the currrent epoch.\n        :return: A dictionary of losses for the current step.\n        \"\"\"", "\n", "losses", ",", "per_task_target_preds", "=", "self", ".", "forward", "(", "data_batch", "=", "data_batch", ",", "epoch", "=", "epoch", ",", "use_second_order", "=", "False", ",", "\n", "use_multi_step_loss_optimization", "=", "True", ",", "\n", "num_steps", "=", "self", ".", "args", ".", "number_of_evaluation_steps_per_iter", ",", "\n", "training_phase", "=", "False", ")", "\n", "\n", "return", "losses", ",", "per_task_target_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.meta_update": [[480, 489], ["loss.backward", "few_shot_learning_system.MAMLFewShotClassifier.optimizer.step"], "methods", ["None"], ["", "def", "meta_update", "(", "self", ",", "loss", ",", "task_idx", ")", ":", "\n", "        ", "\"\"\"\n        Applies an outer loop update on the meta-parameters of the model.\n        :param loss: The current crossentropy loss.\n        \"\"\"", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "task_idx", "==", "self", ".", "args", ".", "batch_size", "-", "1", ":", "\n", "            ", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.run_train_iter": [[490, 543], ["int", "few_shot_learning_system.MAMLFewShotClassifier.scheduler.step", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "few_shot_learning_system.MAMLFewShotClassifier.optimizer.zero_grad", "range", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "numpy.mean", "few_shot_learning_system.MAMLFewShotClassifier.optimizer.zero_grad", "few_shot_learning_system.MAMLFewShotClassifier.zero_grad", "few_shot_learning_system.MAMLFewShotClassifier.train", "few_shot_learning_system.MAMLFewShotClassifier.train_forward_prop", "few_shot_learning_system.MAMLFewShotClassifier.meta_update", "few_shot_learning_system.MAMLFewShotClassifier.scheduler.get_lr", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "losses[].detach", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.concatenate", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "losses[].detach"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.zero_grad", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.zero_grad", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.meta_neural_network_architectures.MetaLossNetwork.zero_grad", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.train_forward_prop", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.meta_update"], ["", "", "def", "run_train_iter", "(", "self", ",", "data_batch", ",", "epoch", ")", ":", "\n", "        ", "\"\"\"\n        Runs an outer loop update step on the meta-model's parameters.\n        :param data_batch: input data batch containing the support set and target set input, output pairs\n        :param epoch: the index of the current epoch\n        :return: The losses of the ran iteration.\n        \"\"\"", "\n", "epoch", "=", "int", "(", "epoch", ")", "\n", "self", ".", "scheduler", ".", "step", "(", "epoch", "=", "epoch", ")", "\n", "if", "self", ".", "current_epoch", "!=", "epoch", ":", "\n", "            ", "self", ".", "current_epoch", "=", "epoch", "\n", "\n", "", "if", "not", "self", ".", "training", ":", "\n", "            ", "self", ".", "train", "(", ")", "\n", "\n", "", "x_support_set", ",", "x_target_set", ",", "y_support_set", ",", "y_target_set", "=", "data_batch", "\n", "\n", "x_support_set", "=", "torch", ".", "Tensor", "(", "x_support_set", ")", ".", "float", "(", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "x_target_set", "=", "torch", ".", "Tensor", "(", "x_target_set", ")", ".", "float", "(", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "y_support_set", "=", "torch", ".", "Tensor", "(", "y_support_set", ")", ".", "long", "(", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "y_target_set", "=", "torch", ".", "Tensor", "(", "y_target_set", ")", ".", "long", "(", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "\n", "stacked_loss", "=", "None", "\n", "stacked_acc", "=", "None", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "for", "nt", "in", "range", "(", "self", ".", "args", ".", "batch_size", ")", ":", "\n", "            ", "x_support_set_t", "=", "x_support_set", "[", "nt", ":", "nt", "+", "1", "]", "\n", "y_support_set_t", "=", "y_support_set", "[", "nt", ":", "nt", "+", "1", "]", "\n", "x_target_set_t", "=", "x_target_set", "[", "nt", ":", "nt", "+", "1", "]", "\n", "y_target_set_t", "=", "y_target_set", "[", "nt", ":", "nt", "+", "1", "]", "\n", "\n", "data_batch", "=", "(", "x_support_set_t", ",", "x_target_set_t", ",", "y_support_set_t", ",", "y_target_set_t", ")", "\n", "\n", "losses", ",", "per_task_target_preds", "=", "self", ".", "train_forward_prop", "(", "data_batch", "=", "data_batch", ",", "epoch", "=", "epoch", ")", "\n", "self", ".", "meta_update", "(", "loss", "=", "losses", "[", "'loss'", "]", "/", "self", ".", "args", ".", "batch_size", ",", "task_idx", "=", "nt", ")", "\n", "\n", "if", "stacked_loss", "is", "None", ":", "\n", "                ", "stacked_loss", "=", "losses", "[", "'loss'", "]", ".", "detach", "(", ")", "\n", "stacked_acc", "=", "losses", "[", "'accuracy'", "]", "\n", "", "else", ":", "\n", "                ", "stacked_loss", "=", "torch", ".", "cat", "(", "(", "stacked_loss", ",", "losses", "[", "'loss'", "]", ".", "detach", "(", ")", ")", ",", "0", ")", "\n", "stacked_acc", "=", "np", ".", "concatenate", "(", "(", "stacked_acc", ",", "losses", "[", "'accuracy'", "]", ")", ",", "0", ")", "\n", "\n", "", "", "losses", "[", "'loss'", "]", "=", "torch", ".", "mean", "(", "stacked_loss", ")", ".", "item", "(", ")", "\n", "losses", "[", "'accuracy'", "]", "=", "np", ".", "mean", "(", "stacked_acc", ")", "\n", "\n", "losses", "[", "'learning_rate'", "]", "=", "self", ".", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "zero_grad", "(", ")", "\n", "\n", "return", "losses", ",", "per_task_target_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.run_validation_iter": [[544, 568], ["torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().float().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "torch.Tensor().long().to", "few_shot_learning_system.MAMLFewShotClassifier.evaluation_forward_prop", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "torch.mean().item", "numpy.mean", "few_shot_learning_system.MAMLFewShotClassifier.eval", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().float", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.Tensor().long", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.evaluation_forward_prop"], ["", "def", "run_validation_iter", "(", "self", ",", "data_batch", ")", ":", "\n", "        ", "\"\"\"\n        Runs an outer loop evaluation step on the meta-model's parameters.\n        :param data_batch: input data batch containing the support set and target set input, output pairs\n        :param epoch: the index of the current epoch\n        :return: The losses of the ran iteration.\n        \"\"\"", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "eval", "(", ")", "\n", "\n", "", "x_support_set", ",", "x_target_set", ",", "y_support_set", ",", "y_target_set", "=", "data_batch", "\n", "\n", "x_support_set", "=", "torch", ".", "Tensor", "(", "x_support_set", ")", ".", "float", "(", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "x_target_set", "=", "torch", ".", "Tensor", "(", "x_target_set", ")", ".", "float", "(", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "y_support_set", "=", "torch", ".", "Tensor", "(", "y_support_set", ")", ".", "long", "(", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "y_target_set", "=", "torch", ".", "Tensor", "(", "y_target_set", ")", ".", "long", "(", ")", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "data_batch", "=", "(", "x_support_set", ",", "x_target_set", ",", "y_support_set", ",", "y_target_set", ")", "\n", "\n", "losses", ",", "per_task_target_preds", "=", "self", ".", "evaluation_forward_prop", "(", "data_batch", "=", "data_batch", ",", "epoch", "=", "self", ".", "current_epoch", ")", "\n", "losses", "[", "'loss'", "]", "=", "torch", ".", "mean", "(", "losses", "[", "'loss'", "]", ")", ".", "item", "(", ")", "\n", "losses", "[", "'accuracy'", "]", "=", "np", ".", "mean", "(", "losses", "[", "'accuracy'", "]", ")", "\n", "\n", "return", "losses", ",", "per_task_target_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.save_model": [[569, 578], ["few_shot_learning_system.MAMLFewShotClassifier.state_dict", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "model_save_dir", ",", "state", ")", ":", "\n", "        ", "\"\"\"\n        Save the network parameter state and experiment state dictionary.\n        :param model_save_dir: The directory to store the state at.\n        :param state: The state containing the experiment state and the network. It's in the form of a dictionary\n        object.\n        \"\"\"", "\n", "state", "[", "'network'", "]", "=", "self", ".", "state_dict", "(", ")", "\n", "torch", ".", "save", "(", "state", ",", "f", "=", "model_save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.load_model": [[579, 593], ["os.path.join", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "few_shot_learning_system.MAMLFewShotClassifier.load_state_dict"], "methods", ["None"], ["", "def", "load_model", "(", "self", ",", "model_save_dir", ",", "model_name", ",", "model_idx", ")", ":", "\n", "        ", "\"\"\"\n        Load checkpoint and return the state dictionary containing the network state params and experiment state.\n        :param model_save_dir: The directory from which to load the files.\n        :param model_name: The model_name to be loaded from the direcotry.\n        :param model_idx: The index of the model (i.e. epoch number or 'latest' for the latest saved model of the current\n        experiment)\n        :return: A dictionary containing the experiment state and the saved model parameters.\n        \"\"\"", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "model_save_dir", ",", "\"{}_{}\"", ".", "format", "(", "model_name", ",", "model_idx", ")", ")", "\n", "state", "=", "torch", ".", "load", "(", "filepath", ")", "\n", "state_dict_loaded", "=", "state", "[", "'network'", "]", "\n", "self", ".", "load_state_dict", "(", "state_dict", "=", "state_dict_loaded", ")", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.set_torch_seed": [[13, 24], ["numpy.random.RandomState", "np.random.RandomState.randint", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["def", "set_torch_seed", "(", "seed", ")", ":", "\n", "    ", "\"\"\"\n    Sets the pytorch seeds for current experiment run\n    :param seed: The seed (int)\n    :return: A random number generator to use\n    \"\"\"", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "seed", ")", "\n", "torch_seed", "=", "rng", ".", "randint", "(", "0", ",", "999999", ")", "\n", "torch", ".", "manual_seed", "(", "seed", "=", "torch_seed", ")", "\n", "\n", "return", "rng", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.inner_loop_optimizers.GradientDescentLearningRule.__init__": [[26, 38], ["torch.Module.__init__", "inner_loop_optimizers.GradientDescentLearningRule.learning_rate.to", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__"], ["def", "__init__", "(", "self", ",", "device", ",", "learning_rate", "=", "1e-3", ")", ":", "\n", "        ", "\"\"\"Creates a new learning rule object.\n        Args:\n            learning_rate: A postive scalar to scale gradient updates to the\n                parameters by. This needs to be carefully set - if too large\n                the learning dynamic will be unstable and may diverge, while\n                if set too small learning will proceed very slowly.\n        \"\"\"", "\n", "super", "(", "GradientDescentLearningRule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "learning_rate", ">", "0.", ",", "'learning_rate should be positive.'", "\n", "self", ".", "learning_rate", "=", "torch", ".", "ones", "(", "1", ")", "*", "learning_rate", "\n", "self", ".", "learning_rate", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.inner_loop_optimizers.GradientDescentLearningRule.update_params": [[39, 55], ["dict", "names_weights_dict.keys"], "methods", ["None"], ["", "def", "update_params", "(", "self", ",", "names_weights_dict", ",", "names_grads_wrt_params_dict", ",", "num_step", ",", "tau", "=", "0.9", ")", ":", "\n", "        ", "\"\"\"Applies a single gradient descent update to all parameters.\n        All parameter updates are performed using in-place operations and so\n        nothing is returned.\n        Args:\n            grads_wrt_params: A list of gradients of the scalar loss function\n                with respect to each of the parameters passed to `initialise`\n                previously, with this list expected to be in the same order.\n        \"\"\"", "\n", "updated_names_weights_dict", "=", "dict", "(", ")", "\n", "for", "key", "in", "names_weights_dict", ".", "keys", "(", ")", ":", "\n", "            ", "updated_names_weights_dict", "[", "key", "]", "=", "names_weights_dict", "[", "key", "]", "-", "self", ".", "learning_rate", "*", "names_grads_wrt_params_dict", "[", "\n", "key", "]", "\n", "\n", "", "return", "updated_names_weights_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.inner_loop_optimizers.LSLRGradientDescentLearningRule.__init__": [[71, 99], ["torch.Module.__init__", "print", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "inner_loop_optimizers.LSLRGradientDescentLearningRule.init_pspl_weight_decay.to", "inner_loop_optimizers.LSLRGradientDescentLearningRule.init_learning_rate.to", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__"], ["def", "__init__", "(", "self", ",", "device", ",", "total_num_inner_loop_steps", ",", "use_learnable_learning_rates", ",", "use_learnable_weight_decay", ",", "alfa", ",", "random_init", ",", "init_learning_rate", "=", "1e-3", ",", "init_weight_decay", "=", "5e-4", ")", ":", "\n", "        ", "\"\"\"Creates a new learning rule object.\n        Args:\n            init_learning_rate: A postive scalar to scale gradient updates to the\n                parameters by. This needs to be carefully set - if too large\n                the learning dynamic will be unstable and may diverge, while\n                if set too small learning will proceed very slowly.\n        \"\"\"", "\n", "super", "(", "LSLRGradientDescentLearningRule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "print", "(", "init_learning_rate", ")", "\n", "assert", "init_learning_rate", ">", "0.", ",", "'learning_rate should be positive.'", "\n", "\n", "self", ".", "alfa", "=", "alfa", "\n", "self", ".", "random_init", "=", "random_init", "\n", "\n", "self", ".", "init_lr_val", "=", "init_learning_rate", "\n", "self", ".", "init_wd_val", "=", "init_weight_decay", "\n", "\n", "self", ".", "init_pspl_weight_decay", "=", "torch", ".", "ones", "(", "1", ")", "\n", "self", ".", "init_pspl_weight_decay", ".", "to", "(", "device", ")", "\n", "\n", "self", ".", "init_learning_rate", "=", "torch", ".", "ones", "(", "1", ")", "*", "init_learning_rate", "\n", "self", ".", "init_learning_rate", ".", "to", "(", "device", ")", "\n", "self", ".", "total_num_inner_loop_steps", "=", "total_num_inner_loop_steps", "\n", "self", ".", "use_learnable_learning_rates", "=", "use_learnable_learning_rates", "\n", "self", ".", "use_learnable_weight_decay", "=", "use_learnable_weight_decay", "\n", "self", ".", "init_weight_decay", "=", "torch", ".", "ones", "(", "1", ")", "*", "init_weight_decay", "\n", "self", ".", "init_bias_decay", "=", "torch", ".", "ones", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.inner_loop_optimizers.LSLRGradientDescentLearningRule.initialise": [[100, 135], ["torch.ParameterDict", "torch.ParameterDict", "torch.ParameterDict", "torch.ParameterDict", "torch.ParameterDict", "torch.ParameterDict", "torch.ParameterDict", "torch.ParameterDict", "enumerate", "torch.ParameterDict", "torch.ParameterDict", "torch.ParameterDict", "torch.ParameterDict", "enumerate", "torch.ParameterDict", "torch.ParameterDict", "torch.ParameterDict", "torch.ParameterDict", "names_weights_dict.items", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "names_weights_dict.items", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "key.replace", "key.replace", "key.replace", "key.replace", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "key.replace", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "initialise", "(", "self", ",", "names_weights_dict", ")", ":", "\n", "        ", "if", "self", ".", "alfa", ":", "\n", "            ", "if", "self", ".", "random_init", ":", "\n", "                ", "self", ".", "names_beta_dict_per_param", "=", "nn", ".", "ParameterDict", "(", ")", "\n", "\n", "", "self", ".", "names_alpha_dict", "=", "nn", ".", "ParameterDict", "(", ")", "\n", "self", ".", "names_beta_dict", "=", "nn", ".", "ParameterDict", "(", ")", "\n", "\n", "for", "idx", ",", "(", "key", ",", "param", ")", "in", "enumerate", "(", "names_weights_dict", ".", "items", "(", ")", ")", ":", "\n", "\n", "                ", "if", "self", ".", "random_init", ":", "\n", "# per-param weight decay for random init", "\n", "                    ", "self", ".", "names_beta_dict_per_param", "[", "key", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "]", "=", "nn", ".", "Parameter", "(", "\n", "data", "=", "torch", ".", "ones", "(", "param", ".", "shape", ")", "*", "self", ".", "init_weight_decay", "*", "self", ".", "init_learning_rate", ",", "\n", "requires_grad", "=", "self", ".", "use_learnable_learning_rates", ")", "\n", "\n", "self", ".", "names_beta_dict", "[", "key", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "]", "=", "nn", ".", "Parameter", "(", "\n", "data", "=", "torch", ".", "ones", "(", "self", ".", "total_num_inner_loop_steps", "+", "1", ")", ",", "\n", "requires_grad", "=", "self", ".", "use_learnable_learning_rates", ")", "\n", "", "else", ":", "\n", "# per-step per-layer meta-learnable weight decay bias term (for more stable training and better performance by 2~3%)", "\n", "                    ", "self", ".", "names_beta_dict", "[", "key", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "]", "=", "nn", ".", "Parameter", "(", "\n", "data", "=", "torch", ".", "ones", "(", "self", ".", "total_num_inner_loop_steps", "+", "1", ")", "*", "self", ".", "init_weight_decay", "*", "self", ".", "init_learning_rate", ",", "\n", "requires_grad", "=", "self", ".", "use_learnable_learning_rates", ")", "\n", "\n", "# per-step per-layer meta-learnable learning rate bias term (for more stable training and better performance by 2~3%)", "\n", "", "self", ".", "names_alpha_dict", "[", "key", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "]", "=", "nn", ".", "Parameter", "(", "\n", "data", "=", "torch", ".", "ones", "(", "self", ".", "total_num_inner_loop_steps", "+", "1", ")", "*", "self", ".", "init_learning_rate", ",", "\n", "requires_grad", "=", "self", ".", "use_learnable_learning_rates", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "names_learning_rates_dict", "=", "nn", ".", "ParameterDict", "(", ")", "\n", "for", "idx", ",", "(", "key", ",", "param", ")", "in", "enumerate", "(", "names_weights_dict", ".", "items", "(", ")", ")", ":", "\n", "                ", "self", ".", "names_learning_rates_dict", "[", "key", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "]", "=", "nn", ".", "Parameter", "(", "\n", "data", "=", "torch", ".", "ones", "(", "self", ".", "total_num_inner_loop_steps", "+", "1", ")", "*", "self", ".", "init_learning_rate", ",", "\n", "requires_grad", "=", "self", ".", "use_learnable_learning_rates", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.inner_loop_optimizers.LSLRGradientDescentLearningRule.update_params": [[137, 165], ["dict", "names_grads_wrt_params_dict.keys", "names_grads_wrt_params_dict.keys", "key.replace", "key.replace", "key.replace", "key.replace", "key.replace", "key.replace"], "methods", ["None"], ["", "", "", "def", "update_params", "(", "self", ",", "names_weights_dict", ",", "names_grads_wrt_params_dict", ",", "generated_alpha_params", ",", "generated_beta_params", ",", "num_step", ",", "tau", "=", "0.1", ")", ":", "\n", "        ", "\"\"\"Applies a single gradient descent update to all parameters.\n        All parameter updates are performed using in-place operations and so\n        nothing is returned.\n        Args:\n            grads_wrt_params: A list of gradients of the scalar loss function\n                with respect to each of the parameters passed to `initialise`\n                previously, with this list expected to be in the same order.\n        \"\"\"", "\n", "updated_names_weights_dict", "=", "dict", "(", ")", "\n", "\n", "for", "key", "in", "names_grads_wrt_params_dict", ".", "keys", "(", ")", ":", "\n", "# beta = (1 - generated_beta * meta-learned per-step-per-layer bias term)", "\n", "# alpha = generated_alpha * meta-learned per-step-per-layer bias term)", "\n", "            ", "if", "self", ".", "alfa", ":", "\n", "                ", "if", "self", ".", "random_init", ":", "\n", "                    ", "updated_names_weights_dict", "[", "key", "]", "=", "(", "1", "-", "self", ".", "names_beta_dict_per_param", "[", "key", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "]", "*", "generated_beta_params", "[", "key", "]", "*", "self", ".", "names_beta_dict", "[", "key", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "]", "[", "num_step", "]", ")", "*", "names_weights_dict", "[", "key", "]", "-", "generated_alpha_params", "[", "key", "]", "*", "self", ".", "names_alpha_dict", "[", "key", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "]", "[", "num_step", "]", "*", "names_grads_wrt_params_dict", "[", "key", "]", "\n", "", "else", ":", "\n", "                    ", "updated_names_weights_dict", "[", "key", "]", "=", "(", "1", "-", "generated_beta_params", "[", "key", "]", "*", "self", ".", "names_beta_dict", "[", "key", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "]", "[", "num_step", "]", ")", "*", "names_weights_dict", "[", "key", "]", "-", "generated_alpha_params", "[", "key", "]", "*", "self", ".", "names_alpha_dict", "[", "key", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "]", "[", "num_step", "]", "*", "names_grads_wrt_params_dict", "[", "key", "]", "\n", "", "", "else", ":", "\n", "#updated_names_weights_dict[key] = names_weights_dict[key] - self.init_lr_val * names_grads_wrt_params_dict[key]", "\n", "                ", "for", "key", "in", "names_grads_wrt_params_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "updated_names_weights_dict", "[", "key", "]", "=", "names_weights_dict", "[", "key", "]", "-", "self", ".", "names_learning_rates_dict", "[", "key", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "]", "[", "num_step", "]", "*", "names_grads_wrt_params_dict", "[", "key", "]", "\n", "\n", "\n", "\n", "", "", "", "return", "updated_names_weights_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.rotate_image.__init__": [[19, 22], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "k", ",", "channels", ")", ":", "\n", "        ", "self", ".", "k", "=", "k", "\n", "self", ".", "channels", "=", "channels", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.rotate_image.__call__": [[23, 34], ["numpy.rot90().copy", "numpy.expand_dims", "len", "numpy.expand_dims", "numpy.rot90", "len"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "image", ")", ":", "\n", "        ", "if", "self", ".", "channels", "==", "1", "and", "len", "(", "image", ".", "shape", ")", "==", "3", ":", "\n", "            ", "image", "=", "image", "[", ":", ",", ":", ",", "0", "]", "\n", "image", "=", "np", ".", "expand_dims", "(", "image", ",", "axis", "=", "2", ")", "\n", "\n", "", "elif", "self", ".", "channels", "==", "1", "and", "len", "(", "image", ".", "shape", ")", "==", "4", ":", "\n", "            ", "image", "=", "image", "[", ":", ",", ":", ",", ":", ",", "0", "]", "\n", "image", "=", "np", ".", "expand_dims", "(", "image", ",", "axis", "=", "3", ")", "\n", "\n", "", "image", "=", "np", ".", "rot90", "(", "image", ",", "k", "=", "self", ".", "k", ")", ".", "copy", "(", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.torch_rotate_image.__init__": [[38, 41], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "k", ",", "channels", ")", ":", "\n", "        ", "self", ".", "k", "=", "k", "\n", "self", ".", "channels", "=", "channels", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.torch_rotate_image.__call__": [[42, 52], ["torchvision.transforms.RandomRotation", "PIL.Image.fromarray", "torchvision.transforms.RandomRotation.", "numpy.array", "len", "numpy.expand_dims"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "image", ")", ":", "\n", "        ", "rotate", "=", "transforms", ".", "RandomRotation", "(", "degrees", "=", "self", ".", "k", "*", "90", ")", "\n", "if", "image", ".", "shape", "[", "-", "1", "]", "==", "1", ":", "\n", "            ", "image", "=", "image", "[", ":", ",", ":", ",", "0", "]", "\n", "", "image", "=", "Image", ".", "fromarray", "(", "image", ")", "\n", "image", "=", "rotate", "(", "image", ")", "\n", "image", "=", "np", ".", "array", "(", "image", ")", "\n", "if", "len", "(", "image", ".", "shape", ")", "==", "2", ":", "\n", "            ", "image", "=", "np", ".", "expand_dims", "(", "image", ",", "axis", "=", "2", ")", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.__init__": [[117, 173], ["numpy.random.RandomState", "numpy.random.RandomState.randint", "numpy.random.RandomState", "numpy.random.RandomState.randint", "numpy.random.RandomState", "numpy.random.RandomState.randint", "numpy.random.RandomState", "data.FewShotLearningDatasetParallel.load_dataset", "data.FewShotLearningDatasetParallel.get_label_set", "print", "numpy.sum", "len", "len", "len", "data.FewShotLearningDatasetParallel.datasets.keys", "list", "list", "list", "len", "data.FewShotLearningDatasetParallel.datasets[].keys", "data.FewShotLearningDatasetParallel.datasets[].keys", "data.FewShotLearningDatasetParallel.datasets[].keys"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_dataset", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.get_label_set"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "\"\"\"\n        A data provider class inheriting from Pytorch's Dataset class. It takes care of creating task sets for\n        our few-shot learning model training and evaluation\n        :param args: Arguments in the form of a Bunch object. Includes all hyperparameters necessary for the\n        data-provider. For transparency and readability reasons to explicitly set as self.object_name all arguments\n        required for the data provider, such that the reader knows exactly what is necessary for the data provider/\n        \"\"\"", "\n", "self", ".", "data_path", "=", "args", ".", "dataset_path", "\n", "self", ".", "dataset_name", "=", "args", ".", "dataset_name", "\n", "self", ".", "data_loaded_in_memory", "=", "False", "\n", "self", ".", "image_height", ",", "self", ".", "image_width", ",", "self", ".", "image_channel", "=", "args", ".", "image_height", ",", "args", ".", "image_width", ",", "args", ".", "image_channels", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "indexes_of_folders_indicating_class", "=", "args", ".", "indexes_of_folders_indicating_class", "\n", "self", ".", "reverse_channels", "=", "args", ".", "reverse_channels", "\n", "self", ".", "labels_as_int", "=", "args", ".", "labels_as_int", "\n", "self", ".", "train_val_test_split", "=", "args", ".", "train_val_test_split", "\n", "self", ".", "current_set_name", "=", "\"train\"", "\n", "self", ".", "num_target_samples", "=", "args", ".", "num_target_samples", "\n", "self", ".", "reset_stored_filepaths", "=", "args", ".", "reset_stored_filepaths", "\n", "val_rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "args", ".", "val_seed", ")", "\n", "val_seed", "=", "val_rng", ".", "randint", "(", "1", ",", "999999", ")", "\n", "train_rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "args", ".", "train_seed", ")", "\n", "train_seed", "=", "train_rng", ".", "randint", "(", "1", ",", "999999", ")", "\n", "test_rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "args", ".", "val_seed", ")", "\n", "test_seed", "=", "test_rng", ".", "randint", "(", "1", ",", "999999", ")", "\n", "args", ".", "val_seed", "=", "val_seed", "\n", "args", ".", "train_seed", "=", "train_seed", "\n", "args", ".", "test_seed", "=", "test_seed", "\n", "self", ".", "init_seed", "=", "{", "\"train\"", ":", "args", ".", "train_seed", ",", "\"val\"", ":", "args", ".", "val_seed", ",", "'test'", ":", "args", ".", "val_seed", "}", "\n", "self", ".", "seed", "=", "{", "\"train\"", ":", "args", ".", "train_seed", ",", "\"val\"", ":", "args", ".", "val_seed", ",", "'test'", ":", "args", ".", "val_seed", "}", "\n", "self", ".", "num_of_gpus", "=", "args", ".", "num_of_gpus", "\n", "self", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "\n", "self", ".", "train_index", "=", "0", "\n", "self", ".", "val_index", "=", "0", "\n", "self", ".", "test_index", "=", "0", "\n", "\n", "self", ".", "augment_images", "=", "False", "\n", "self", ".", "num_samples_per_class", "=", "args", ".", "num_samples_per_class", "\n", "self", ".", "num_classes_per_set", "=", "args", ".", "num_classes_per_set", "\n", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "self", ".", "seed", "[", "'val'", "]", ")", "\n", "self", ".", "datasets", "=", "self", ".", "load_dataset", "(", ")", "\n", "\n", "self", ".", "indexes", "=", "{", "\"train\"", ":", "0", ",", "\"val\"", ":", "0", ",", "'test'", ":", "0", "}", "\n", "self", ".", "dataset_size_dict", "=", "{", "\n", "\"train\"", ":", "{", "key", ":", "len", "(", "self", ".", "datasets", "[", "'train'", "]", "[", "key", "]", ")", "for", "key", "in", "list", "(", "self", ".", "datasets", "[", "'train'", "]", ".", "keys", "(", ")", ")", "}", ",", "\n", "\"val\"", ":", "{", "key", ":", "len", "(", "self", ".", "datasets", "[", "'val'", "]", "[", "key", "]", ")", "for", "key", "in", "list", "(", "self", ".", "datasets", "[", "'val'", "]", ".", "keys", "(", ")", ")", "}", ",", "\n", "'test'", ":", "{", "key", ":", "len", "(", "self", ".", "datasets", "[", "'test'", "]", "[", "key", "]", ")", "for", "key", "in", "list", "(", "self", ".", "datasets", "[", "'test'", "]", ".", "keys", "(", ")", ")", "}", "}", "\n", "self", ".", "label_set", "=", "self", ".", "get_label_set", "(", ")", "\n", "self", ".", "data_length", "=", "{", "name", ":", "np", ".", "sum", "(", "[", "len", "(", "self", ".", "datasets", "[", "name", "]", "[", "key", "]", ")", "\n", "for", "key", "in", "self", ".", "datasets", "[", "name", "]", "]", ")", "for", "name", "in", "self", ".", "datasets", ".", "keys", "(", ")", "}", "\n", "\n", "print", "(", "\"data\"", ",", "self", ".", "data_length", ")", "\n", "self", ".", "observed_seed_set", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_dataset": [[174, 238], ["numpy.random.RandomState", "data.FewShotLearningDatasetParallel.load_datapaths", "dict", "dict.items", "data.FewShotLearningDatasetParallel.load_datapaths", "len", "numpy.arange", "numpy.random.RandomState.shuffle", "list", "list", "dict", "print", "print", "dict.items", "data.FewShotLearningDatasetParallel.get_label_from_index", "data.FewShotLearningDatasetParallel.split", "len", "dict.keys", "dict.values", "zip", "int", "int", "int", "print", "dict.keys", "numpy.zeros", "tqdm.tqdm", "numpy.sum", "list", "list", "list", "len", "set_value.items", "concurrent.futures.ProcessPoolExecutor", "executor.map", "dict.keys", "dict.keys", "dict.keys", "len", "set_value.items", "pbar_memory_load.update"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_datapaths", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_datapaths", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.shuffle", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.get_label_from_index"], ["", "def", "load_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Loads a dataset's dictionary files and splits the data according to the train_val_test_split variable stored\n        in the args object.\n        :return: Three sets, the training set, validation set and test sets (referred to as the meta-train,\n        meta-val and meta-test in the paper)\n        \"\"\"", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "self", ".", "seed", "[", "'val'", "]", ")", "\n", "\n", "if", "self", ".", "args", ".", "sets_are_pre_split", "==", "True", ":", "\n", "            ", "data_image_paths", ",", "index_to_label_name_dict_file", ",", "label_to_index", "=", "self", ".", "load_datapaths", "(", ")", "\n", "dataset_splits", "=", "dict", "(", ")", "\n", "for", "key", ",", "value", "in", "data_image_paths", ".", "items", "(", ")", ":", "\n", "                ", "key", "=", "self", ".", "get_label_from_index", "(", "index", "=", "key", ")", "\n", "bits", "=", "key", ".", "split", "(", "\"/\"", ")", "\n", "set_name", "=", "bits", "[", "0", "]", "\n", "class_label", "=", "bits", "[", "1", "]", "\n", "if", "set_name", "not", "in", "dataset_splits", ":", "\n", "                    ", "dataset_splits", "[", "set_name", "]", "=", "{", "class_label", ":", "value", "}", "\n", "", "else", ":", "\n", "                    ", "dataset_splits", "[", "set_name", "]", "[", "class_label", "]", "=", "value", "\n", "", "", "", "else", ":", "\n", "            ", "data_image_paths", ",", "index_to_label_name_dict_file", ",", "label_to_index", "=", "self", ".", "load_datapaths", "(", ")", "\n", "total_label_types", "=", "len", "(", "data_image_paths", ")", "\n", "num_classes_idx", "=", "np", ".", "arange", "(", "len", "(", "data_image_paths", ".", "keys", "(", ")", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "rng", ".", "shuffle", "(", "num_classes_idx", ")", "\n", "keys", "=", "list", "(", "data_image_paths", ".", "keys", "(", ")", ")", "\n", "values", "=", "list", "(", "data_image_paths", ".", "values", "(", ")", ")", "\n", "new_keys", "=", "[", "keys", "[", "idx", "]", "for", "idx", "in", "num_classes_idx", "]", "\n", "new_values", "=", "[", "values", "[", "idx", "]", "for", "idx", "in", "num_classes_idx", "]", "\n", "data_image_paths", "=", "dict", "(", "zip", "(", "new_keys", ",", "new_values", ")", ")", "\n", "# data_image_paths = self.shuffle(data_image_paths)", "\n", "x_train_id", ",", "x_val_id", ",", "x_test_id", "=", "int", "(", "self", ".", "train_val_test_split", "[", "0", "]", "*", "total_label_types", ")", ",", "int", "(", "np", ".", "sum", "(", "self", ".", "train_val_test_split", "[", ":", "2", "]", ")", "*", "total_label_types", ")", ",", "int", "(", "total_label_types", ")", "\n", "print", "(", "x_train_id", ",", "x_val_id", ",", "x_test_id", ")", "\n", "x_train_classes", "=", "(", "class_key", "for", "class_key", "in", "list", "(", "data_image_paths", ".", "keys", "(", ")", ")", "[", ":", "x_train_id", "]", ")", "\n", "x_val_classes", "=", "(", "class_key", "for", "class_key", "in", "list", "(", "data_image_paths", ".", "keys", "(", ")", ")", "[", "x_train_id", ":", "x_val_id", "]", ")", "\n", "x_test_classes", "=", "(", "class_key", "for", "class_key", "in", "list", "(", "data_image_paths", ".", "keys", "(", ")", ")", "[", "x_val_id", ":", "x_test_id", "]", ")", "\n", "x_train", ",", "x_val", ",", "x_test", "=", "{", "class_key", ":", "data_image_paths", "[", "class_key", "]", "for", "class_key", "in", "x_train_classes", "}", ",", "{", "class_key", ":", "data_image_paths", "[", "class_key", "]", "for", "class_key", "in", "x_val_classes", "}", ",", "{", "class_key", ":", "data_image_paths", "[", "class_key", "]", "for", "class_key", "in", "x_test_classes", "}", ",", "\n", "dataset_splits", "=", "{", "\"train\"", ":", "x_train", ",", "\"val\"", ":", "x_val", ",", "\"test\"", ":", "x_test", "}", "\n", "\n", "", "if", "self", ".", "args", ".", "load_into_memory", "is", "True", ":", "\n", "\n", "            ", "print", "(", "\"Loading data into RAM\"", ")", "\n", "x_loaded", "=", "{", "\"train\"", ":", "[", "]", ",", "\"val\"", ":", "[", "]", ",", "\"test\"", ":", "[", "]", "}", "\n", "\n", "for", "set_key", ",", "set_value", "in", "dataset_splits", ".", "items", "(", ")", ":", "\n", "                ", "print", "(", "\"Currently loading into memory the {} set\"", ".", "format", "(", "set_key", ")", ")", "\n", "x_loaded", "[", "set_key", "]", "=", "{", "key", ":", "np", ".", "zeros", "(", "len", "(", "value", ")", ",", ")", "for", "key", ",", "value", "in", "set_value", ".", "items", "(", ")", "}", "\n", "# for class_key, class_value in set_value.items():", "\n", "with", "tqdm", ".", "tqdm", "(", "total", "=", "len", "(", "set_value", ")", ")", "as", "pbar_memory_load", ":", "\n", "                    ", "with", "concurrent", ".", "futures", ".", "ProcessPoolExecutor", "(", "max_workers", "=", "4", ")", "as", "executor", ":", "\n", "# Process the list of files, but split the work across the process pool to use all CPUs!", "\n", "                        ", "for", "(", "class_label", ",", "class_images_loaded", ")", "in", "executor", ".", "map", "(", "self", ".", "load_parallel_batch", ",", "(", "set_value", ".", "items", "(", ")", ")", ")", ":", "\n", "                            ", "x_loaded", "[", "set_key", "]", "[", "class_label", "]", "=", "class_images_loaded", "\n", "pbar_memory_load", ".", "update", "(", "1", ")", "\n", "\n", "", "", "", "", "dataset_splits", "=", "x_loaded", "\n", "self", ".", "data_loaded_in_memory", "=", "True", "\n", "\n", "", "return", "dataset_splits", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_datapaths": [[239, 274], ["os.path.exists", "os.path.exists", "data.FewShotLearningDatasetParallel.load_from_json", "data.FewShotLearningDatasetParallel.load_from_json", "data.FewShotLearningDatasetParallel.load_from_json", "os.remove", "print", "data.FewShotLearningDatasetParallel.get_data_paths", "data.FewShotLearningDatasetParallel.save_to_json", "data.FewShotLearningDatasetParallel.save_to_json", "data.FewShotLearningDatasetParallel.save_to_json", "data.FewShotLearningDatasetParallel.load_datapaths"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.load_from_json", "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.load_from_json", "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.load_from_json", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.get_data_paths", "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.save_to_json", "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.save_to_json", "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.save_to_json", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_datapaths"], ["", "def", "load_datapaths", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        If saved json dictionaries of the data are available, then this method loads the dictionaries such that the\n        data is ready to be read. If the json dictionaries do not exist, then this method calls get_data_paths()\n        which will build the json dictionary containing the class to filepath samples, and then store them.\n        :return: data_image_paths: dict containing class to filepath list pairs.\n                 index_to_label_name_dict_file: dict containing numerical indexes mapped to the human understandable\n                 string-names of the class\n                 label_to_index: dictionary containing human understandable string mapped to numerical indexes\n        \"\"\"", "\n", "dataset_dir", "=", "os", ".", "environ", "[", "'DATASET_DIR'", "]", "\n", "data_path_file", "=", "\"{}/{}.json\"", ".", "format", "(", "dataset_dir", ",", "self", ".", "dataset_name", ")", "\n", "self", ".", "index_to_label_name_dict_file", "=", "\"{}/map_to_label_name_{}.json\"", ".", "format", "(", "dataset_dir", ",", "self", ".", "dataset_name", ")", "\n", "self", ".", "label_name_to_map_dict_file", "=", "\"{}/label_name_to_map_{}.json\"", ".", "format", "(", "dataset_dir", ",", "self", ".", "dataset_name", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "data_path_file", ")", ":", "\n", "            ", "self", ".", "reset_stored_filepaths", "=", "True", "\n", "\n", "", "if", "self", ".", "reset_stored_filepaths", "==", "True", ":", "\n", "            ", "if", "os", ".", "path", ".", "exists", "(", "data_path_file", ")", ":", "\n", "                ", "os", ".", "remove", "(", "data_path_file", ")", "\n", "", "self", ".", "reset_stored_filepaths", "=", "False", "\n", "\n", "", "try", ":", "\n", "            ", "data_image_paths", "=", "self", ".", "load_from_json", "(", "filename", "=", "data_path_file", ")", "\n", "label_to_index", "=", "self", ".", "load_from_json", "(", "filename", "=", "self", ".", "label_name_to_map_dict_file", ")", "\n", "index_to_label_name_dict_file", "=", "self", ".", "load_from_json", "(", "filename", "=", "self", ".", "index_to_label_name_dict_file", ")", "\n", "return", "data_image_paths", ",", "index_to_label_name_dict_file", ",", "label_to_index", "\n", "", "except", ":", "\n", "            ", "print", "(", "\"Mapped data paths can't be found, remapping paths..\"", ")", "\n", "data_image_paths", ",", "code_to_label_name", ",", "label_name_to_code", "=", "self", ".", "get_data_paths", "(", ")", "\n", "self", ".", "save_to_json", "(", "dict_to_store", "=", "data_image_paths", ",", "filename", "=", "data_path_file", ")", "\n", "self", ".", "save_to_json", "(", "dict_to_store", "=", "code_to_label_name", ",", "filename", "=", "self", ".", "index_to_label_name_dict_file", ")", "\n", "self", ".", "save_to_json", "(", "dict_to_store", "=", "label_name_to_code", ",", "filename", "=", "self", ".", "label_name_to_map_dict_file", ")", "\n", "return", "self", ".", "load_datapaths", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.save_to_json": [[275, 278], ["open", "json.dump", "os.path.abspath"], "methods", ["None"], ["", "", "def", "save_to_json", "(", "self", ",", "filename", ",", "dict_to_store", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "abspath", "(", "filename", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "dict_to_store", ",", "fp", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_from_json": [[279, 284], ["open", "json.load"], "methods", ["None"], ["", "", "def", "load_from_json", "(", "self", ",", "filename", ")", ":", "\n", "        ", "with", "open", "(", "filename", ",", "mode", "=", "\"r\"", ")", "as", "f", ":", "\n", "            ", "load_dict", "=", "json", ".", "load", "(", "fp", "=", "f", ")", "\n", "\n", "", "return", "load_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_test_image": [[285, 306], ["PIL.Image.open", "os.system", "print", "PIL.Image.open", "print"], "methods", ["None"], ["", "def", "load_test_image", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "\"\"\"\n        Tests whether a target filepath contains an uncorrupted image. If image is corrupted, attempt to fix.\n        :param filepath: Filepath of image to be tested\n        :return: Return filepath of image if image exists and is uncorrupted (or attempt to fix has succeeded),\n        else return None\n        \"\"\"", "\n", "image", "=", "None", "\n", "try", ":", "\n", "            ", "image", "=", "Image", ".", "open", "(", "filepath", ")", "\n", "", "except", "RuntimeWarning", ":", "\n", "            ", "os", ".", "system", "(", "\"convert {} -strip {}\"", ".", "format", "(", "filepath", ",", "filepath", ")", ")", "\n", "print", "(", "\"converting\"", ")", "\n", "image", "=", "Image", ".", "open", "(", "filepath", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "\"Broken image\"", ")", "\n", "\n", "", "if", "image", "is", "not", "None", ":", "\n", "            ", "return", "filepath", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.get_data_paths": [[307, 340], ["print", "set", "os.walk", "sorted", "tqdm.tqdm", "enumerate", "enumerate", "list", "concurrent.futures.ProcessPoolExecutor", "executor.map", "os.path.abspath", "data.FewShotLearningDatasetParallel.get_label_from_path", "data_image_path_list_raw.append", "sorted.add", "idx_to_label_name.keys", "len", "pbar_error.update", "file.lower", "file.lower", "file.lower", "os.path.join", "data.FewShotLearningDatasetParallel.get_label_from_path", "data_image_path_dict[].append"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.get_label_from_path", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.get_label_from_path"], ["", "", "def", "get_data_paths", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Method that scans the dataset directory and generates class to image-filepath list dictionaries.\n        :return: data_image_paths: dict containing class to filepath list pairs.\n                 index_to_label_name_dict_file: dict containing numerical indexes mapped to the human understandable\n                 string-names of the class\n                 label_to_index: dictionary containing human understandable string mapped to numerical indexes\n        \"\"\"", "\n", "print", "(", "\"Get images from\"", ",", "self", ".", "data_path", ")", "\n", "data_image_path_list_raw", "=", "[", "]", "\n", "labels", "=", "set", "(", ")", "\n", "for", "subdir", ",", "dir", ",", "files", "in", "os", ".", "walk", "(", "self", ".", "data_path", ")", ":", "\n", "            ", "for", "file", "in", "files", ":", "\n", "                ", "if", "(", "\".jpeg\"", ")", "in", "file", ".", "lower", "(", ")", "or", "(", "\".png\"", ")", "in", "file", ".", "lower", "(", ")", "or", "(", "\".jpg\"", ")", "in", "file", ".", "lower", "(", ")", ":", "\n", "                    ", "filepath", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "subdir", ",", "file", ")", ")", "\n", "label", "=", "self", ".", "get_label_from_path", "(", "filepath", ")", "\n", "data_image_path_list_raw", ".", "append", "(", "filepath", ")", "\n", "labels", ".", "add", "(", "label", ")", "\n", "\n", "", "", "", "labels", "=", "sorted", "(", "labels", ")", "\n", "idx_to_label_name", "=", "{", "idx", ":", "label", "for", "idx", ",", "label", "in", "enumerate", "(", "labels", ")", "}", "\n", "label_name_to_idx", "=", "{", "label", ":", "idx", "for", "idx", ",", "label", "in", "enumerate", "(", "labels", ")", "}", "\n", "data_image_path_dict", "=", "{", "idx", ":", "[", "]", "for", "idx", "in", "list", "(", "idx_to_label_name", ".", "keys", "(", ")", ")", "}", "\n", "with", "tqdm", ".", "tqdm", "(", "total", "=", "len", "(", "data_image_path_list_raw", ")", ")", "as", "pbar_error", ":", "\n", "            ", "with", "concurrent", ".", "futures", ".", "ProcessPoolExecutor", "(", "max_workers", "=", "4", ")", "as", "executor", ":", "\n", "# Process the list of files, but split the work across the process pool to use all CPUs!", "\n", "                ", "for", "image_file", "in", "executor", ".", "map", "(", "self", ".", "load_test_image", ",", "(", "data_image_path_list_raw", ")", ")", ":", "\n", "                    ", "pbar_error", ".", "update", "(", "1", ")", "\n", "if", "image_file", "is", "not", "None", ":", "\n", "                        ", "label", "=", "self", ".", "get_label_from_path", "(", "image_file", ")", "\n", "data_image_path_dict", "[", "label_name_to_idx", "[", "label", "]", "]", ".", "append", "(", "image_file", ")", "\n", "\n", "", "", "", "", "return", "data_image_path_dict", ",", "idx_to_label_name", ",", "label_name_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.get_label_set": [[341, 348], ["data.FewShotLearningDatasetParallel.load_from_json", "set", "list", "data.FewShotLearningDatasetParallel.keys"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.load_from_json"], ["", "def", "get_label_set", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generates a set containing all class numerical indexes\n        :return: A set containing all class numerical indexes\n        \"\"\"", "\n", "index_to_label_name_dict_file", "=", "self", ".", "load_from_json", "(", "filename", "=", "self", ".", "index_to_label_name_dict_file", ")", "\n", "return", "set", "(", "list", "(", "index_to_label_name_dict_file", ".", "keys", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.get_index_from_label": [[349, 357], ["data.FewShotLearningDatasetParallel.load_from_json"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.load_from_json"], ["", "def", "get_index_from_label", "(", "self", ",", "label", ")", ":", "\n", "        ", "\"\"\"\n        Given a class's (human understandable) string, returns the numerical index of that class\n        :param label: A string of a human understandable class contained in the dataset\n        :return: An int containing the numerical index of the given class-string\n        \"\"\"", "\n", "label_to_index", "=", "self", ".", "load_from_json", "(", "filename", "=", "self", ".", "label_name_to_map_dict_file", ")", "\n", "return", "label_to_index", "[", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.get_label_from_index": [[358, 366], ["data.FewShotLearningDatasetParallel.load_from_json"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.load_from_json"], ["", "def", "get_label_from_index", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Given an index return the human understandable label mapping to it.\n        :param index: A numerical index (int)\n        :return: A human understandable label (str)\n        \"\"\"", "\n", "index_to_label_name", "=", "self", ".", "load_from_json", "(", "filename", "=", "self", ".", "index_to_label_name_dict_file", ")", "\n", "return", "index_to_label_name", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.get_label_from_path": [[367, 378], ["filepath.split", "int"], "methods", ["None"], ["", "def", "get_label_from_path", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "\"\"\"\n        Given a path of an image generate the human understandable label for that image.\n        :param filepath: The image's filepath\n        :return: A human understandable label.\n        \"\"\"", "\n", "label_bits", "=", "filepath", ".", "split", "(", "\"/\"", ")", "\n", "label", "=", "\"/\"", ".", "join", "(", "[", "label_bits", "[", "idx", "]", "for", "idx", "in", "self", ".", "indexes_of_folders_indicating_class", "]", ")", "\n", "if", "self", ".", "labels_as_int", ":", "\n", "            ", "label", "=", "int", "(", "label", ")", "\n", "", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_image": [[379, 401], ["PIL.Image.open", "numpy.expand_dims.resize", "numpy.array", "numpy.expand_dims.resize().convert", "numpy.array", "numpy.expand_dims", "numpy.expand_dims.resize"], "methods", ["None"], ["", "def", "load_image", "(", "self", ",", "image_path", ",", "channels", ")", ":", "\n", "        ", "\"\"\"\n        Given an image filepath and the number of channels to keep, load an image and keep the specified channels\n        :param image_path: The image's filepath\n        :param channels: The number of channels to keep\n        :return: An image array of shape (h, w, channels), whose values range between 0.0 and 1.0.\n        \"\"\"", "\n", "if", "not", "self", ".", "data_loaded_in_memory", ":", "\n", "            ", "image", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "if", "'omniglot'", "in", "self", ".", "dataset_name", ":", "\n", "                ", "image", "=", "image", ".", "resize", "(", "(", "self", ".", "image_height", ",", "self", ".", "image_width", ")", ",", "resample", "=", "Image", ".", "LANCZOS", ")", "\n", "image", "=", "np", ".", "array", "(", "image", ",", "np", ".", "float32", ")", "\n", "if", "channels", "==", "1", ":", "\n", "                    ", "image", "=", "np", ".", "expand_dims", "(", "image", ",", "axis", "=", "2", ")", "\n", "", "", "else", ":", "\n", "                ", "image", "=", "image", ".", "resize", "(", "(", "self", ".", "image_height", ",", "self", ".", "image_width", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "image", "=", "np", ".", "array", "(", "image", ",", "np", ".", "float32", ")", "\n", "image", "=", "image", "/", "255.0", "\n", "", "", "else", ":", "\n", "            ", "image", "=", "image_path", "\n", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_batch": [[402, 422], ["numpy.array", "numpy.array", "data.FewShotLearningDatasetParallel.preprocess_data", "data.FewShotLearningDatasetParallel.append", "data.FewShotLearningDatasetParallel.load_image"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.preprocess_data", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_image"], ["", "def", "load_batch", "(", "self", ",", "batch_image_paths", ")", ":", "\n", "        ", "\"\"\"\n        Load a batch of images, given a list of filepaths\n        :param batch_image_paths: A list of filepaths\n        :return: A numpy array of images of shape batch, height, width, channels\n        \"\"\"", "\n", "image_batch", "=", "[", "]", "\n", "\n", "if", "self", ".", "data_loaded_in_memory", ":", "\n", "            ", "for", "image_path", "in", "batch_image_paths", ":", "\n", "                ", "image_batch", ".", "append", "(", "image_path", ")", "\n", "", "image_batch", "=", "np", ".", "array", "(", "image_batch", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "#print(image_batch.shape)", "\n", "", "else", ":", "\n", "            ", "image_batch", "=", "[", "self", ".", "load_image", "(", "image_path", "=", "image_path", ",", "channels", "=", "self", ".", "image_channel", ")", "\n", "for", "image_path", "in", "batch_image_paths", "]", "\n", "image_batch", "=", "np", ".", "array", "(", "image_batch", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "image_batch", "=", "self", ".", "preprocess_data", "(", "image_batch", ")", "\n", "\n", "", "return", "image_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_parallel_batch": [[423, 446], ["numpy.array", "numpy.array", "data.FewShotLearningDatasetParallel.preprocess_data", "data.FewShotLearningDatasetParallel.append", "data.FewShotLearningDatasetParallel.load_image", "numpy.copy"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.preprocess_data", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_image"], ["", "def", "load_parallel_batch", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Load a batch of images, given a list of filepaths\n        :param batch_image_paths: A list of filepaths\n        :return: A numpy array of images of shape batch, height, width, channels\n        \"\"\"", "\n", "class_label", ",", "batch_image_paths", "=", "inputs", "\n", "image_batch", "=", "[", "]", "\n", "\n", "if", "self", ".", "data_loaded_in_memory", ":", "\n", "            ", "for", "image_path", "in", "batch_image_paths", ":", "\n", "                ", "image_batch", ".", "append", "(", "np", ".", "copy", "(", "image_path", ")", ")", "\n", "", "image_batch", "=", "np", ".", "array", "(", "image_batch", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "#with tqdm.tqdm(total=1) as load_pbar:", "\n", "            ", "image_batch", "=", "[", "self", ".", "load_image", "(", "image_path", "=", "image_path", ",", "channels", "=", "self", ".", "image_channel", ")", "\n", "for", "image_path", "in", "batch_image_paths", "]", "\n", "#load_pbar.update(1)", "\n", "\n", "image_batch", "=", "np", ".", "array", "(", "image_batch", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "image_batch", "=", "self", ".", "preprocess_data", "(", "image_batch", ")", "\n", "\n", "", "return", "class_label", ",", "image_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.preprocess_data": [[447, 462], ["numpy.reshape", "x.reshape.reshape.reshape", "numpy.ones", "range"], "methods", ["None"], ["", "def", "preprocess_data", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Preprocesses data such that their shapes match the specified structures\n        :param x: A data batch to preprocess\n        :return: A preprocessed data batch\n        \"\"\"", "\n", "x_shape", "=", "x", ".", "shape", "\n", "x", "=", "np", ".", "reshape", "(", "x", ",", "(", "-", "1", ",", "x_shape", "[", "-", "3", "]", ",", "x_shape", "[", "-", "2", "]", ",", "x_shape", "[", "-", "1", "]", ")", ")", "\n", "if", "self", ".", "reverse_channels", "is", "True", ":", "\n", "            ", "reverse_photos", "=", "np", ".", "ones", "(", "shape", "=", "x", ".", "shape", ")", "\n", "for", "channel", "in", "range", "(", "x", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "                ", "reverse_photos", "[", ":", ",", ":", ",", ":", ",", "x", ".", "shape", "[", "-", "1", "]", "-", "1", "-", "channel", "]", "=", "x", "[", ":", ",", ":", ",", ":", ",", "channel", "]", "\n", "", "x", "=", "reverse_photos", "\n", "", "x", "=", "x", ".", "reshape", "(", "x_shape", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.reconstruct_original": [[463, 471], ["None"], "methods", ["None"], ["", "def", "reconstruct_original", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Applies the reverse operations that preprocess_data() applies such that the data returns to their original form\n        :param x: A batch of data to reconstruct\n        :return: A reconstructed batch of data\n        \"\"\"", "\n", "x", "=", "x", "*", "255.0", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.shuffle": [[472, 482], ["numpy.arange", "rng.shuffle", "len"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.shuffle"], ["", "def", "shuffle", "(", "self", ",", "x", ",", "rng", ")", ":", "\n", "        ", "\"\"\"\n        Shuffles the data batch along it's first axis\n        :param x: A data batch\n        :return: A shuffled data batch\n        \"\"\"", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "x", ")", ")", "\n", "rng", ".", "shuffle", "(", "indices", ")", "\n", "x", "=", "x", "[", "indices", "]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.get_set": [[483, 530], ["numpy.random.RandomState", "numpy.random.RandomState.choice", "numpy.random.RandomState.shuffle", "numpy.random.RandomState.randint", "torch.stack", "numpy.array", "list", "numpy.random.RandomState.choice", "torch.stack", "torch.stack.append", "numpy.array.append", "data.FewShotLearningDatasetParallel.dataset_size_dict[].keys", "zip", "range", "zip", "data.augment_image", "torch.stack.append", "class_labels.append", "data.FewShotLearningDatasetParallel.load_batch", "int"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.shuffle", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.augment_image", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.load_batch"], ["", "def", "get_set", "(", "self", ",", "dataset_name", ",", "seed", ",", "augment_images", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Generates a task-set to be used for training or evaluation\n        :param set_name: The name of the set to use, e.g. \"train\", \"val\" etc.\n        :return: A task-set containing an image and label support set, and an image and label target set.\n        \"\"\"", "\n", "#seed = seed % self.args.total_unique_tasks", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "seed", ")", "\n", "selected_classes", "=", "rng", ".", "choice", "(", "list", "(", "self", ".", "dataset_size_dict", "[", "dataset_name", "]", ".", "keys", "(", ")", ")", ",", "\n", "size", "=", "self", ".", "num_classes_per_set", ",", "replace", "=", "False", ")", "\n", "rng", ".", "shuffle", "(", "selected_classes", ")", "\n", "k_list", "=", "rng", ".", "randint", "(", "0", ",", "4", ",", "size", "=", "self", ".", "num_classes_per_set", ")", "\n", "k_dict", "=", "{", "selected_class", ":", "k_item", "for", "(", "selected_class", ",", "k_item", ")", "in", "zip", "(", "selected_classes", ",", "k_list", ")", "}", "\n", "episode_labels", "=", "[", "i", "for", "i", "in", "range", "(", "self", ".", "num_classes_per_set", ")", "]", "\n", "class_to_episode_label", "=", "{", "selected_class", ":", "episode_label", "for", "(", "selected_class", ",", "episode_label", ")", "in", "\n", "zip", "(", "selected_classes", ",", "episode_labels", ")", "}", "\n", "\n", "x_images", "=", "[", "]", "\n", "y_labels", "=", "[", "]", "\n", "\n", "for", "class_entry", "in", "selected_classes", ":", "\n", "            ", "choose_samples_list", "=", "rng", ".", "choice", "(", "self", ".", "dataset_size_dict", "[", "dataset_name", "]", "[", "class_entry", "]", ",", "\n", "size", "=", "self", ".", "num_samples_per_class", "+", "self", ".", "num_target_samples", ",", "replace", "=", "False", ")", "\n", "class_image_samples", "=", "[", "]", "\n", "class_labels", "=", "[", "]", "\n", "for", "sample", "in", "choose_samples_list", ":", "\n", "                ", "choose_samples", "=", "self", ".", "datasets", "[", "dataset_name", "]", "[", "class_entry", "]", "[", "sample", "]", "\n", "x_class_data", "=", "self", ".", "load_batch", "(", "[", "choose_samples", "]", ")", "[", "0", "]", "\n", "k", "=", "k_dict", "[", "class_entry", "]", "\n", "x_class_data", "=", "augment_image", "(", "image", "=", "x_class_data", ",", "k", "=", "k", ",", "\n", "channels", "=", "self", ".", "image_channel", ",", "augment_bool", "=", "augment_images", ",", "\n", "dataset_name", "=", "self", ".", "dataset_name", ",", "args", "=", "self", ".", "args", ")", "\n", "class_image_samples", ".", "append", "(", "x_class_data", ")", "\n", "class_labels", ".", "append", "(", "int", "(", "class_to_episode_label", "[", "class_entry", "]", ")", ")", "\n", "", "class_image_samples", "=", "torch", ".", "stack", "(", "class_image_samples", ")", "\n", "x_images", ".", "append", "(", "class_image_samples", ")", "\n", "y_labels", ".", "append", "(", "class_labels", ")", "\n", "\n", "", "x_images", "=", "torch", ".", "stack", "(", "x_images", ")", "\n", "y_labels", "=", "np", ".", "array", "(", "y_labels", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "support_set_images", "=", "x_images", "[", ":", ",", ":", "self", ".", "num_samples_per_class", "]", "\n", "support_set_labels", "=", "y_labels", "[", ":", ",", ":", "self", ".", "num_samples_per_class", "]", "\n", "target_set_images", "=", "x_images", "[", ":", ",", "self", ".", "num_samples_per_class", ":", "]", "\n", "target_set_labels", "=", "y_labels", "[", ":", ",", "self", ".", "num_samples_per_class", ":", "]", "\n", "\n", "return", "support_set_images", ",", "target_set_images", ",", "support_set_labels", ",", "target_set_labels", ",", "seed", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.__len__": [[531, 534], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "total_samples", "=", "self", ".", "data_length", "[", "self", ".", "current_set_name", "]", "\n", "return", "total_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.length": [[535, 538], ["data.FewShotLearningDatasetParallel.switch_set", "len"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.switch_set"], ["", "def", "length", "(", "self", ",", "set_name", ")", ":", "\n", "        ", "self", ".", "switch_set", "(", "set_name", "=", "set_name", ")", "\n", "return", "len", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.set_augmentation": [[539, 541], ["None"], "methods", ["None"], ["", "def", "set_augmentation", "(", "self", ",", "augment_images", ")", ":", "\n", "        ", "self", ".", "augment_images", "=", "augment_images", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.switch_set": [[542, 546], ["data.FewShotLearningDatasetParallel.update_seed"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.update_seed"], ["", "def", "switch_set", "(", "self", ",", "set_name", ",", "current_iter", "=", "None", ")", ":", "\n", "        ", "self", ".", "current_set_name", "=", "set_name", "\n", "if", "set_name", "==", "\"train\"", ":", "\n", "            ", "self", ".", "update_seed", "(", "dataset_name", "=", "set_name", ",", "seed", "=", "self", ".", "init_seed", "[", "set_name", "]", "+", "current_iter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.update_seed": [[547, 549], ["None"], "methods", ["None"], ["", "", "def", "update_seed", "(", "self", ",", "dataset_name", ",", "seed", "=", "100", ")", ":", "\n", "        ", "self", ".", "seed", "[", "dataset_name", "]", "=", "seed", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.__getitem__": [[550, 556], ["data.FewShotLearningDatasetParallel.get_set"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.get_set"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "support_set_images", ",", "target_set_image", ",", "support_set_labels", ",", "target_set_label", ",", "seed", "=", "self", ".", "get_set", "(", "self", ".", "current_set_name", ",", "seed", "=", "self", ".", "seed", "[", "self", ".", "current_set_name", "]", "+", "idx", ",", "\n", "augment_images", "=", "self", ".", "augment_images", ")", "\n", "\n", "return", "support_set_images", ",", "target_set_image", ",", "support_set_labels", ",", "target_set_label", ",", "seed", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.reset_seed": [[557, 559], ["None"], "methods", ["None"], ["", "def", "reset_seed", "(", "self", ")", ":", "\n", "        ", "self", ".", "seed", "=", "self", ".", "init_seed", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.__init__": [[562, 580], ["data.FewShotLearningDatasetParallel", "data.MetaLearningSystemDataLoader.continue_from_iter"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.continue_from_iter"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "current_iter", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        Initializes a meta learning system dataloader. The data loader uses the Pytorch DataLoader class to parallelize\n        batch sampling and preprocessing.\n        :param args: An arguments NamedTuple containing all the required arguments.\n        :param current_iter: Current iter of experiment. Is used to make sure the data loader continues where it left\n        of previously.\n        \"\"\"", "\n", "self", ".", "num_of_gpus", "=", "args", ".", "num_of_gpus", "\n", "self", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "self", ".", "samples_per_iter", "=", "args", ".", "samples_per_iter", "\n", "self", ".", "num_workers", "=", "args", ".", "num_dataprovider_workers", "\n", "self", ".", "total_train_iters_produced", "=", "0", "\n", "self", ".", "dataset", "=", "FewShotLearningDatasetParallel", "(", "args", "=", "args", ")", "\n", "self", ".", "batches_per_iter", "=", "args", ".", "samples_per_iter", "\n", "self", ".", "full_data_length", "=", "self", ".", "dataset", ".", "data_length", "\n", "self", ".", "continue_from_iter", "(", "current_iter", "=", "current_iter", ")", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.get_dataloader": [[581, 588], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "get_dataloader", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns a data loader with the correct set (train, val or test), continuing from the current iter.\n        :return:\n        \"\"\"", "\n", "return", "DataLoader", "(", "self", ".", "dataset", ",", "batch_size", "=", "(", "self", ".", "num_of_gpus", "*", "self", ".", "batch_size", "*", "self", ".", "samples_per_iter", ")", ",", "\n", "shuffle", "=", "False", ",", "num_workers", "=", "self", ".", "num_workers", ",", "drop_last", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.continue_from_iter": [[589, 595], ["None"], "methods", ["None"], ["", "def", "continue_from_iter", "(", "self", ",", "current_iter", ")", ":", "\n", "        ", "\"\"\"\n        Makes sure the data provider is aware of where we are in terms of training iterations in the experiment.\n        :param current_iter:\n        \"\"\"", "\n", "self", ".", "total_train_iters_produced", "+=", "(", "current_iter", "*", "(", "self", ".", "num_of_gpus", "*", "self", ".", "batch_size", "*", "self", ".", "samples_per_iter", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.get_train_batches": [[596, 611], ["data.MetaLearningSystemDataLoader.dataset.switch_set", "data.MetaLearningSystemDataLoader.dataset.set_augmentation", "enumerate", "data.MetaLearningSystemDataLoader.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.switch_set", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.set_augmentation", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.get_dataloader"], ["", "def", "get_train_batches", "(", "self", ",", "total_batches", "=", "-", "1", ",", "augment_images", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Returns a training batches data_loader\n        :param total_batches: The number of batches we want the data loader to sample\n        :param augment_images: Whether we want the images to be augmented.\n        \"\"\"", "\n", "if", "total_batches", "==", "-", "1", ":", "\n", "            ", "self", ".", "dataset", ".", "data_length", "=", "self", ".", "full_data_length", "\n", "", "else", ":", "\n", "            ", "self", ".", "dataset", ".", "data_length", "[", "\"train\"", "]", "=", "total_batches", "*", "self", ".", "dataset", ".", "batch_size", "\n", "", "self", ".", "dataset", ".", "switch_set", "(", "set_name", "=", "\"train\"", ",", "current_iter", "=", "self", ".", "total_train_iters_produced", ")", "\n", "self", ".", "dataset", ".", "set_augmentation", "(", "augment_images", "=", "augment_images", ")", "\n", "self", ".", "total_train_iters_produced", "+=", "(", "self", ".", "num_of_gpus", "*", "self", ".", "batch_size", "*", "self", ".", "samples_per_iter", ")", "\n", "for", "sample_id", ",", "sample_batched", "in", "enumerate", "(", "self", ".", "get_dataloader", "(", ")", ")", ":", "\n", "            ", "yield", "sample_batched", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.get_val_batches": [[613, 627], ["data.MetaLearningSystemDataLoader.dataset.switch_set", "data.MetaLearningSystemDataLoader.dataset.set_augmentation", "enumerate", "data.MetaLearningSystemDataLoader.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.switch_set", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.set_augmentation", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.get_dataloader"], ["", "", "def", "get_val_batches", "(", "self", ",", "total_batches", "=", "-", "1", ",", "augment_images", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Returns a validation batches data_loader\n        :param total_batches: The number of batches we want the data loader to sample\n        :param augment_images: Whether we want the images to be augmented.\n        \"\"\"", "\n", "if", "total_batches", "==", "-", "1", ":", "\n", "            ", "self", ".", "dataset", ".", "data_length", "=", "self", ".", "full_data_length", "\n", "", "else", ":", "\n", "            ", "self", ".", "dataset", ".", "data_length", "[", "'val'", "]", "=", "total_batches", "*", "self", ".", "dataset", ".", "batch_size", "\n", "", "self", ".", "dataset", ".", "switch_set", "(", "set_name", "=", "\"val\"", ")", "\n", "self", ".", "dataset", ".", "set_augmentation", "(", "augment_images", "=", "augment_images", ")", "\n", "for", "sample_id", ",", "sample_batched", "in", "enumerate", "(", "self", ".", "get_dataloader", "(", ")", ")", ":", "\n", "            ", "yield", "sample_batched", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.get_test_batches": [[629, 643], ["data.MetaLearningSystemDataLoader.dataset.switch_set", "data.MetaLearningSystemDataLoader.dataset.set_augmentation", "enumerate", "data.MetaLearningSystemDataLoader.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.switch_set", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.FewShotLearningDatasetParallel.set_augmentation", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.get_dataloader"], ["", "", "def", "get_test_batches", "(", "self", ",", "total_batches", "=", "-", "1", ",", "augment_images", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Returns a testing batches data_loader\n        :param total_batches: The number of batches we want the data loader to sample\n        :param augment_images: Whether we want the images to be augmented.\n        \"\"\"", "\n", "if", "total_batches", "==", "-", "1", ":", "\n", "            ", "self", ".", "dataset", ".", "data_length", "=", "self", ".", "full_data_length", "\n", "", "else", ":", "\n", "            ", "self", ".", "dataset", ".", "data_length", "[", "'test'", "]", "=", "total_batches", "*", "self", ".", "dataset", ".", "batch_size", "\n", "", "self", ".", "dataset", ".", "switch_set", "(", "set_name", "=", "'test'", ")", "\n", "self", ".", "dataset", ".", "set_augmentation", "(", "augment_images", "=", "augment_images", ")", "\n", "for", "sample_id", ",", "sample_batched", "in", "enumerate", "(", "self", ".", "get_dataloader", "(", ")", ")", ":", "\n", "            ", "yield", "sample_batched", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.augment_image": [[54, 78], ["data.get_transforms_for_dataset", "len", "torch.stack", "output_images.append", "transform_current", "transform_current", "transform_current", "transform_current"], "function", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.get_transforms_for_dataset"], ["", "", "def", "augment_image", "(", "image", ",", "k", ",", "channels", ",", "augment_bool", ",", "args", ",", "dataset_name", ")", ":", "\n", "    ", "transform_train", ",", "transform_evaluation", "=", "get_transforms_for_dataset", "(", "dataset_name", "=", "dataset_name", ",", "\n", "args", "=", "args", ",", "k", "=", "k", ")", "\n", "if", "len", "(", "image", ".", "shape", ")", ">", "3", ":", "\n", "        ", "images", "=", "[", "item", "for", "item", "in", "image", "]", "\n", "output_images", "=", "[", "]", "\n", "for", "image", "in", "images", ":", "\n", "            ", "if", "augment_bool", "is", "True", ":", "\n", "                ", "for", "transform_current", "in", "transform_train", ":", "\n", "                    ", "image", "=", "transform_current", "(", "image", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "transform_current", "in", "transform_evaluation", ":", "\n", "                    ", "image", "=", "transform_current", "(", "image", ")", "\n", "", "", "output_images", ".", "append", "(", "image", ")", "\n", "", "image", "=", "torch", ".", "stack", "(", "output_images", ")", "\n", "", "else", ":", "\n", "        ", "if", "augment_bool", "is", "True", ":", "\n", "# meanstd transformation", "\n", "            ", "for", "transform_current", "in", "transform_train", ":", "\n", "                ", "image", "=", "transform_current", "(", "image", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "transform_current", "in", "transform_evaluation", ":", "\n", "                ", "image", "=", "transform_current", "(", "image", ")", "\n", "", "", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.get_transforms_for_dataset": [[80, 114], ["torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "data.rotate_image", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["None"], ["", "def", "get_transforms_for_dataset", "(", "dataset_name", ",", "args", ",", "k", ")", ":", "\n", "    ", "if", "\"cifar10\"", "in", "dataset_name", "or", "\"cifar100\"", "in", "dataset_name", "or", "\"FC100\"", "in", "dataset_name", ":", "\n", "        ", "transform_train", "=", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5071", ",", "0.4847", ",", "0.4408", ")", ",", "(", "0.2675", ",", "0.2565", ",", "0.2761", ")", ")", "]", "\n", "\n", "#transforms.RandomCrop(32, padding=4),", "\n", "#transforms.RandomHorizontalFlip(),", "\n", "#transforms.ToTensor(),", "\n", "#transforms.Normalize(args.classification_mean, args.classification_std)]", "\n", "\n", "transform_evaluate", "=", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5071", ",", "0.4847", ",", "0.4408", ")", ",", "(", "0.2675", ",", "0.2565", ",", "0.2761", ")", ")", "]", "\n", "#transforms.ToTensor(),", "\n", "#transforms.Normalize(args.classification_mean, args.classification_std)]", "\n", "\n", "", "elif", "'omniglot'", "in", "dataset_name", ":", "\n", "\n", "        ", "transform_train", "=", "[", "rotate_image", "(", "k", "=", "k", ",", "channels", "=", "args", ".", "image_channels", ")", ",", "transforms", ".", "ToTensor", "(", ")", "]", "\n", "transform_evaluate", "=", "[", "transforms", ".", "ToTensor", "(", ")", "]", "\n", "\n", "\n", "", "elif", "'imagenet'", "in", "dataset_name", ":", "\n", "\n", "        ", "transform_train", "=", "[", "transforms", ".", "Compose", "(", "[", "\n", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "(", "0.229", ",", "0.224", ",", "0.225", ")", ")", "]", ")", "]", "\n", "\n", "transform_evaluate", "=", "[", "transforms", ".", "Compose", "(", "[", "\n", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "(", "0.485", ",", "0.456", ",", "0.406", ")", ",", "(", "0.229", ",", "0.224", ",", "0.225", ")", ")", "]", ")", "]", "\n", "\n", "", "return", "transform_train", ",", "transform_evaluate", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.__init__": [[11, 76], ["utils.storage.build_experiment_folder", "dict", "dict", "os.path.abspath", "os.makedirs", "os.path.join", "print", "data", "print", "int", "int", "time.time", "print", "os.path.abspath.split", "int", "os.path.join", "print", "os.path.exists", "experiment_builder.ExperimentBuilder.args.dataset_name.lower", "experiment_builder.ExperimentBuilder.model.load_model", "int", "int", "experiment_builder.ExperimentBuilder.model.load_model", "int"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.build_experiment_folder", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.load_model", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.load_model"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "data", ",", "model", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        Initializes an experiment builder using a named tuple (args), a data provider (data), a meta learning system\n        (model) and a device (e.g. gpu/cpu/n)\n        :param args: A namedtuple containing all experiment hyperparameters\n        :param data: A data provider of instance MetaLearningSystemDataLoader\n        :param model: A meta learning system instance\n        :param device: Device/s to use for the experiment\n        \"\"\"", "\n", "self", ".", "args", ",", "self", ".", "device", "=", "args", ",", "device", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "saved_models_filepath", ",", "self", ".", "logs_filepath", ",", "self", ".", "samples_filepath", "=", "build_experiment_folder", "(", "\n", "experiment_name", "=", "self", ".", "args", ".", "experiment_name", ")", "\n", "\n", "self", ".", "total_losses", "=", "dict", "(", ")", "\n", "self", ".", "state", "=", "dict", "(", ")", "\n", "self", ".", "state", "[", "'best_val_acc'", "]", "=", "0.", "\n", "self", ".", "state", "[", "'best_val_iter'", "]", "=", "0", "\n", "self", ".", "state", "[", "'current_iter'", "]", "=", "0", "\n", "self", ".", "state", "[", "'current_iter'", "]", "=", "0", "\n", "self", ".", "start_epoch", "=", "0", "\n", "self", ".", "max_models_to_save", "=", "self", ".", "args", ".", "max_models_to_save", "\n", "self", ".", "create_summary_csv", "=", "False", "\n", "\n", "experiment_path", "=", "os", ".", "path", ".", "abspath", "(", "self", ".", "args", ".", "experiment_name", ")", "\n", "exp_name", "=", "experiment_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "log_base_dir", "=", "'logs'", "\n", "os", ".", "makedirs", "(", "log_base_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "log_dir", "=", "os", ".", "path", ".", "join", "(", "log_base_dir", ",", "exp_name", ")", "\n", "print", "(", "log_dir", ")", "\n", "\n", "if", "self", ".", "args", ".", "continue_from_epoch", "==", "'from_scratch'", ":", "\n", "            ", "self", ".", "create_summary_csv", "=", "True", "\n", "\n", "", "elif", "self", ".", "args", ".", "continue_from_epoch", "==", "'latest'", ":", "\n", "            ", "checkpoint", "=", "os", ".", "path", ".", "join", "(", "self", ".", "saved_models_filepath", ",", "\"train_model_latest\"", ")", "\n", "print", "(", "\"attempting to find existing checkpoint\"", ",", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "checkpoint", ")", ":", "\n", "                ", "self", ".", "state", "=", "self", ".", "model", ".", "load_model", "(", "model_save_dir", "=", "self", ".", "saved_models_filepath", ",", "model_name", "=", "\"train_model\"", ",", "\n", "model_idx", "=", "'latest'", ")", "\n", "self", ".", "start_epoch", "=", "int", "(", "self", ".", "state", "[", "'current_iter'", "]", "/", "self", ".", "args", ".", "total_iter_per_epoch", ")", "\n", "\n", "", "else", ":", "\n", "                ", "self", ".", "args", ".", "continue_from_epoch", "=", "'from_scratch'", "\n", "self", ".", "create_summary_csv", "=", "True", "\n", "", "", "elif", "int", "(", "self", ".", "args", ".", "continue_from_epoch", ")", ">=", "0", ":", "\n", "            ", "self", ".", "state", "=", "self", ".", "model", ".", "load_model", "(", "model_save_dir", "=", "self", ".", "saved_models_filepath", ",", "model_name", "=", "\"train_model\"", ",", "\n", "model_idx", "=", "self", ".", "args", ".", "continue_from_epoch", ")", "\n", "self", ".", "start_epoch", "=", "int", "(", "self", ".", "state", "[", "'current_iter'", "]", "/", "self", ".", "args", ".", "total_iter_per_epoch", ")", "\n", "\n", "", "self", ".", "data", "=", "data", "(", "args", "=", "args", ",", "current_iter", "=", "self", ".", "state", "[", "'current_iter'", "]", ")", "\n", "\n", "print", "(", "\"train_seed {}, val_seed: {}, at start time\"", ".", "format", "(", "self", ".", "data", ".", "dataset", ".", "seed", "[", "\"train\"", "]", ",", "\n", "self", ".", "data", ".", "dataset", ".", "seed", "[", "\"val\"", "]", ")", ")", "\n", "self", ".", "total_epochs_before_pause", "=", "self", ".", "args", ".", "total_epochs_before_pause", "\n", "self", ".", "state", "[", "'best_epoch'", "]", "=", "int", "(", "self", ".", "state", "[", "'best_val_iter'", "]", "/", "self", ".", "args", ".", "total_iter_per_epoch", ")", "\n", "self", ".", "epoch", "=", "int", "(", "self", ".", "state", "[", "'current_iter'", "]", "/", "self", ".", "args", ".", "total_iter_per_epoch", ")", "\n", "self", ".", "augment_flag", "=", "True", "if", "'omniglot'", "in", "self", ".", "args", ".", "dataset_name", ".", "lower", "(", ")", "else", "False", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "epochs_done_in_this_run", "=", "0", "\n", "print", "(", "self", ".", "state", "[", "'current_iter'", "]", ",", "int", "(", "self", ".", "args", ".", "total_iter_per_epoch", "*", "self", ".", "args", ".", "total_epochs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.build_summary_dict": [[77, 93], ["dict", "numpy.mean", "numpy.std"], "methods", ["None"], ["", "def", "build_summary_dict", "(", "self", ",", "total_losses", ",", "phase", ",", "summary_losses", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Builds/Updates a summary dict directly from the metric dict of the current iteration.\n        :param total_losses: Current dict with total losses (not aggregations) from experiment\n        :param phase: Current training phase\n        :param summary_losses: Current summarised (aggregated/summarised) losses stats means, stdv etc.\n        :return: A new summary dict with the updated summary statistics information.\n        \"\"\"", "\n", "if", "summary_losses", "is", "None", ":", "\n", "            ", "summary_losses", "=", "dict", "(", ")", "\n", "\n", "", "for", "key", "in", "total_losses", ":", "\n", "            ", "summary_losses", "[", "\"{}_{}_mean\"", ".", "format", "(", "phase", ",", "key", ")", "]", "=", "np", ".", "mean", "(", "total_losses", "[", "key", "]", ")", "\n", "summary_losses", "[", "\"{}_{}_std\"", ".", "format", "(", "phase", ",", "key", ")", "]", "=", "np", ".", "std", "(", "total_losses", "[", "key", "]", ")", "\n", "\n", "", "return", "summary_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.build_loss_summary_string": [[94, 107], ["zip", "list", "list", "summary_losses.keys", "summary_losses.values", "float"], "methods", ["None"], ["", "def", "build_loss_summary_string", "(", "self", ",", "summary_losses", ")", ":", "\n", "        ", "\"\"\"\n        Builds a progress bar summary string given current summary losses dictionary\n        :param summary_losses: Current summary statistics\n        :return: A summary string ready to be shown to humans.\n        \"\"\"", "\n", "output_update", "=", "\"\"", "\n", "for", "key", ",", "value", "in", "zip", "(", "list", "(", "summary_losses", ".", "keys", "(", ")", ")", ",", "list", "(", "summary_losses", ".", "values", "(", ")", ")", ")", ":", "\n", "            ", "if", "\"loss\"", "in", "key", "or", "\"accuracy\"", "in", "key", ":", "\n", "                ", "value", "=", "float", "(", "value", ")", "\n", "output_update", "+=", "\"{}: {:.4f}, \"", ".", "format", "(", "key", ",", "value", ")", "\n", "\n", "", "", "return", "output_update", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.merge_two_dicts": [[108, 113], ["first_dict.copy", "first_dict.copy.update"], "methods", ["None"], ["", "def", "merge_two_dicts", "(", "self", ",", "first_dict", ",", "second_dict", ")", ":", "\n", "        ", "\"\"\"Given two dicts, merge them into a new dict as a shallow copy.\"\"\"", "\n", "z", "=", "first_dict", ".", "copy", "(", ")", "\n", "z", ".", "update", "(", "second_dict", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.train_iteration": [[114, 149], ["experiment_builder.ExperimentBuilder.model.run_train_iter", "zip", "experiment_builder.ExperimentBuilder.build_summary_dict", "experiment_builder.ExperimentBuilder.build_loss_summary_string", "pbar_train.update", "pbar_train.set_description", "print", "list", "list", "losses.keys", "losses.values", "total_losses[].append", "float", "float"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.run_train_iter", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.build_summary_dict", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.build_loss_summary_string"], ["", "def", "train_iteration", "(", "self", ",", "train_sample", ",", "sample_idx", ",", "epoch_idx", ",", "total_losses", ",", "current_iter", ",", "pbar_train", ")", ":", "\n", "        ", "\"\"\"\n        Runs a training iteration, updates the progress bar and returns the total and current epoch train losses.\n        :param train_sample: A sample from the data provider\n        :param sample_idx: The index of the incoming sample, in relation to the current training run.\n        :param epoch_idx: The epoch index.\n        :param total_losses: The current total losses dictionary to be updated.\n        :param current_iter: The current training iteration in relation to the whole experiment.\n        :param pbar_train: The progress bar of the training.\n        :return: Updates total_losses, train_losses, current_iter\n        \"\"\"", "\n", "x_support_set", ",", "x_target_set", ",", "y_support_set", ",", "y_target_set", ",", "seed", "=", "train_sample", "\n", "data_batch", "=", "(", "x_support_set", ",", "x_target_set", ",", "y_support_set", ",", "y_target_set", ")", "\n", "\n", "if", "sample_idx", "==", "0", ":", "\n", "            ", "print", "(", "\"shape of data\"", ",", "x_support_set", ".", "shape", ",", "x_target_set", ".", "shape", ",", "y_support_set", ".", "shape", ",", "\n", "y_target_set", ".", "shape", ")", "\n", "\n", "", "losses", ",", "_", "=", "self", ".", "model", ".", "run_train_iter", "(", "data_batch", "=", "data_batch", ",", "epoch", "=", "epoch_idx", ")", "\n", "\n", "for", "key", ",", "value", "in", "zip", "(", "list", "(", "losses", ".", "keys", "(", ")", ")", ",", "list", "(", "losses", ".", "values", "(", ")", ")", ")", ":", "\n", "            ", "if", "key", "not", "in", "total_losses", ":", "\n", "                ", "total_losses", "[", "key", "]", "=", "[", "float", "(", "value", ")", "]", "\n", "", "else", ":", "\n", "                ", "total_losses", "[", "key", "]", ".", "append", "(", "float", "(", "value", ")", ")", "\n", "\n", "", "", "train_losses", "=", "self", ".", "build_summary_dict", "(", "total_losses", "=", "total_losses", ",", "phase", "=", "\"train\"", ")", "\n", "train_output_update", "=", "self", ".", "build_loss_summary_string", "(", "losses", ")", "\n", "\n", "pbar_train", ".", "update", "(", "1", ")", "\n", "pbar_train", ".", "set_description", "(", "\"training phase {} -> {}\"", ".", "format", "(", "self", ".", "epoch", ",", "train_output_update", ")", ")", "\n", "\n", "current_iter", "+=", "1", "\n", "\n", "return", "train_losses", ",", "total_losses", ",", "current_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.evaluation_iteration": [[150, 177], ["experiment_builder.ExperimentBuilder.model.run_validation_iter", "zip", "experiment_builder.ExperimentBuilder.build_summary_dict", "experiment_builder.ExperimentBuilder.build_loss_summary_string", "pbar_val.update", "pbar_val.set_description", "list", "list", "losses.keys", "losses.values", "total_losses[].append", "float", "float"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.run_validation_iter", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.build_summary_dict", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.build_loss_summary_string"], ["", "def", "evaluation_iteration", "(", "self", ",", "val_sample", ",", "total_losses", ",", "pbar_val", ",", "phase", ")", ":", "\n", "        ", "\"\"\"\n        Runs a validation iteration, updates the progress bar and returns the total and current epoch val losses.\n        :param val_sample: A sample from the data provider\n        :param total_losses: The current total losses dictionary to be updated.\n        :param pbar_val: The progress bar of the val stage.\n        :return: The updated val_losses, total_losses\n        \"\"\"", "\n", "x_support_set", ",", "x_target_set", ",", "y_support_set", ",", "y_target_set", ",", "seed", "=", "val_sample", "\n", "data_batch", "=", "(", "\n", "x_support_set", ",", "x_target_set", ",", "y_support_set", ",", "y_target_set", ")", "\n", "\n", "losses", ",", "_", "=", "self", ".", "model", ".", "run_validation_iter", "(", "data_batch", "=", "data_batch", ")", "\n", "for", "key", ",", "value", "in", "zip", "(", "list", "(", "losses", ".", "keys", "(", ")", ")", ",", "list", "(", "losses", ".", "values", "(", ")", ")", ")", ":", "\n", "            ", "if", "key", "not", "in", "total_losses", ":", "\n", "                ", "total_losses", "[", "key", "]", "=", "[", "float", "(", "value", ")", "]", "\n", "", "else", ":", "\n", "                ", "total_losses", "[", "key", "]", ".", "append", "(", "float", "(", "value", ")", ")", "\n", "\n", "", "", "val_losses", "=", "self", ".", "build_summary_dict", "(", "total_losses", "=", "total_losses", ",", "phase", "=", "phase", ")", "\n", "val_output_update", "=", "self", ".", "build_loss_summary_string", "(", "losses", ")", "\n", "\n", "pbar_val", ".", "update", "(", "1", ")", "\n", "pbar_val", ".", "set_description", "(", "\n", "\"val_phase {} -> {}\"", ".", "format", "(", "self", ".", "epoch", ",", "val_output_update", ")", ")", "\n", "\n", "return", "val_losses", ",", "total_losses", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.test_evaluation_iteration": [[178, 201], ["experiment_builder.ExperimentBuilder.model.run_validation_iter", "per_model_per_batch_preds[].extend", "experiment_builder.ExperimentBuilder.build_loss_summary_string", "pbar_test.update", "pbar_test.set_description", "list"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.run_validation_iter", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.build_loss_summary_string"], ["", "def", "test_evaluation_iteration", "(", "self", ",", "val_sample", ",", "model_idx", ",", "sample_idx", ",", "per_model_per_batch_preds", ",", "pbar_test", ")", ":", "\n", "        ", "\"\"\"\n        Runs a validation iteration, updates the progress bar and returns the total and current epoch val losses.\n        :param val_sample: A sample from the data provider\n        :param total_losses: The current total losses dictionary to be updated.\n        :param pbar_test: The progress bar of the val stage.\n        :return: The updated val_losses, total_losses\n        \"\"\"", "\n", "x_support_set", ",", "x_target_set", ",", "y_support_set", ",", "y_target_set", ",", "seed", "=", "val_sample", "\n", "data_batch", "=", "(", "\n", "x_support_set", ",", "x_target_set", ",", "y_support_set", ",", "y_target_set", ")", "\n", "\n", "losses", ",", "per_task_preds", "=", "self", ".", "model", ".", "run_validation_iter", "(", "data_batch", "=", "data_batch", ")", "\n", "\n", "per_model_per_batch_preds", "[", "model_idx", "]", ".", "extend", "(", "list", "(", "per_task_preds", ")", ")", "\n", "\n", "test_output_update", "=", "self", ".", "build_loss_summary_string", "(", "losses", ")", "\n", "\n", "pbar_test", ".", "update", "(", "1", ")", "\n", "pbar_test", ".", "set_description", "(", "\n", "\"test_phase {} -> {}\"", ".", "format", "(", "self", ".", "epoch", ",", "test_output_update", ")", ")", "\n", "\n", "return", "per_model_per_batch_preds", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.save_models": [[202, 219], ["model.save_model", "model.save_model", "print", "os.path.join", "os.path.join", "int"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.save_model", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.save_model"], ["", "def", "save_models", "(", "self", ",", "model", ",", "epoch", ",", "state", ")", ":", "\n", "        ", "\"\"\"\n        Saves two separate instances of the current model. One to be kept for history and reloading later and another\n        one marked as \"latest\" to be used by the system for the next epoch training. Useful when the training/val\n        process is interrupted or stopped. Leads to fault tolerant training and validation systems that can continue\n        from where they left off before.\n        :param model: Current meta learning model of any instance within the few_shot_learning_system.py\n        :param epoch: Current epoch\n        :param state: Current model and experiment state dict.\n        \"\"\"", "\n", "model", ".", "save_model", "(", "model_save_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "saved_models_filepath", ",", "\"train_model_{}\"", ".", "format", "(", "int", "(", "epoch", ")", ")", ")", ",", "\n", "state", "=", "state", ")", "\n", "\n", "model", ".", "save_model", "(", "model_save_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "saved_models_filepath", ",", "\"train_model_latest\"", ")", ",", "\n", "state", "=", "state", ")", "\n", "\n", "print", "(", "\"saved models to\"", ",", "self", ".", "saved_models_filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.pack_and_save_metrics": [[220, 258], ["experiment_builder.ExperimentBuilder.merge_two_dicts", "experiment_builder.ExperimentBuilder.items", "experiment_builder.ExperimentBuilder.build_loss_summary_string", "time.time", "print", "utils.storage.save_statistics", "dict", "time.time", "utils.storage.save_statistics", "list", "[].append", "list", "experiment_builder.ExperimentBuilder.values", "experiment_builder.ExperimentBuilder.keys"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.merge_two_dicts", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.build_loss_summary_string", "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.save_statistics", "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.save_statistics"], ["", "def", "pack_and_save_metrics", "(", "self", ",", "start_time", ",", "create_summary_csv", ",", "train_losses", ",", "val_losses", ",", "state", ")", ":", "\n", "        ", "\"\"\"\n        Given current epochs start_time, train losses, val losses and whether to create a new stats csv file, pack stats\n        and save into a statistics csv file. Return a new start time for the new epoch.\n        :param start_time: The start time of the current epoch\n        :param create_summary_csv: A boolean variable indicating whether to create a new statistics file or\n        append results to existing one\n        :param train_losses: A dictionary with the current train losses\n        :param val_losses: A dictionary with the currrent val loss\n        :return: The current time, to be used for the next epoch.\n        \"\"\"", "\n", "epoch_summary_losses", "=", "self", ".", "merge_two_dicts", "(", "first_dict", "=", "train_losses", ",", "second_dict", "=", "val_losses", ")", "\n", "\n", "if", "'per_epoch_statistics'", "not", "in", "state", ":", "\n", "            ", "state", "[", "'per_epoch_statistics'", "]", "=", "dict", "(", ")", "\n", "\n", "", "for", "key", ",", "value", "in", "epoch_summary_losses", ".", "items", "(", ")", ":", "\n", "\n", "            ", "if", "key", "not", "in", "state", "[", "'per_epoch_statistics'", "]", ":", "\n", "                ", "state", "[", "'per_epoch_statistics'", "]", "[", "key", "]", "=", "[", "value", "]", "\n", "", "else", ":", "\n", "                ", "state", "[", "'per_epoch_statistics'", "]", "[", "key", "]", ".", "append", "(", "value", ")", "\n", "\n", "", "", "epoch_summary_string", "=", "self", ".", "build_loss_summary_string", "(", "epoch_summary_losses", ")", "\n", "epoch_summary_losses", "[", "\"epoch\"", "]", "=", "self", ".", "epoch", "\n", "epoch_summary_losses", "[", "'epoch_run_time'", "]", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "if", "create_summary_csv", ":", "\n", "            ", "self", ".", "summary_statistics_filepath", "=", "save_statistics", "(", "self", ".", "logs_filepath", ",", "list", "(", "epoch_summary_losses", ".", "keys", "(", ")", ")", ",", "\n", "create", "=", "True", ")", "\n", "self", ".", "create_summary_csv", "=", "False", "\n", "\n", "", "start_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"epoch {} -> {}\"", ".", "format", "(", "epoch_summary_losses", "[", "\"epoch\"", "]", ",", "epoch_summary_string", ")", ")", "\n", "\n", "self", ".", "summary_statistics_filepath", "=", "save_statistics", "(", "self", ".", "logs_filepath", ",", "\n", "list", "(", "epoch_summary_losses", ".", "values", "(", ")", ")", ")", "\n", "return", "start_time", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.evaluated_test_set_using_the_best_models": [[259, 313], ["numpy.copy", "numpy.array", "print", "print", "enumerate", "numpy.mean", "numpy.argmax", "numpy.array().reshape", "numpy.mean", "numpy.std", "utils.storage.save_statistics", "utils.storage.save_statistics", "print", "print", "dict", "experiment_builder.ExperimentBuilder.model.load_model", "numpy.equal", "numpy.equal", "list", "list", "numpy.argsort().astype", "range", "range", "range", "tqdm.tqdm", "enumerate", "numpy.array", "test_losses.keys", "test_losses.values", "range", "experiment_builder.ExperimentBuilder.data.get_test_batches", "per_model_per_batch_targets[].extend", "experiment_builder.ExperimentBuilder.test_evaluation_iteration", "len", "numpy.argsort", "int", "numpy.array", "int"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.save_statistics", "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.save_statistics", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.few_shot_learning_system.MAMLFewShotClassifier.load_model", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.get_test_batches", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.test_evaluation_iteration"], ["", "def", "evaluated_test_set_using_the_best_models", "(", "self", ",", "top_n_models", ")", ":", "\n", "        ", "per_epoch_statistics", "=", "self", ".", "state", "[", "'per_epoch_statistics'", "]", "\n", "val_acc", "=", "np", ".", "copy", "(", "per_epoch_statistics", "[", "'val_accuracy_mean'", "]", ")", "\n", "val_idx", "=", "np", ".", "array", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "val_acc", ")", ")", "]", ")", "\n", "sorted_idx", "=", "np", ".", "argsort", "(", "val_acc", ",", "axis", "=", "0", ")", ".", "astype", "(", "dtype", "=", "np", ".", "int32", ")", "[", ":", ":", "-", "1", "]", "[", ":", "top_n_models", "]", "\n", "\n", "sorted_val_acc", "=", "val_acc", "[", "sorted_idx", "]", "\n", "val_idx", "=", "val_idx", "[", "sorted_idx", "]", "\n", "print", "(", "sorted_idx", ")", "\n", "print", "(", "sorted_val_acc", ")", "\n", "\n", "top_n_idx", "=", "val_idx", "[", ":", "top_n_models", "]", "\n", "per_model_per_batch_preds", "=", "[", "[", "]", "for", "i", "in", "range", "(", "top_n_models", ")", "]", "\n", "per_model_per_batch_targets", "=", "[", "[", "]", "for", "i", "in", "range", "(", "top_n_models", ")", "]", "\n", "test_losses", "=", "[", "dict", "(", ")", "for", "i", "in", "range", "(", "top_n_models", ")", "]", "\n", "for", "idx", ",", "model_idx", "in", "enumerate", "(", "top_n_idx", ")", ":", "\n", "            ", "self", ".", "state", "=", "self", ".", "model", ".", "load_model", "(", "model_save_dir", "=", "self", ".", "saved_models_filepath", ",", "model_name", "=", "\"train_model\"", ",", "\n", "model_idx", "=", "model_idx", "+", "1", ")", "\n", "with", "tqdm", ".", "tqdm", "(", "total", "=", "int", "(", "self", ".", "args", ".", "num_evaluation_tasks", "/", "self", ".", "args", ".", "batch_size", ")", ")", "as", "pbar_test", ":", "\n", "                ", "for", "sample_idx", ",", "test_sample", "in", "enumerate", "(", "\n", "self", ".", "data", ".", "get_test_batches", "(", "total_batches", "=", "int", "(", "self", ".", "args", ".", "num_evaluation_tasks", "/", "self", ".", "args", ".", "batch_size", ")", ",", "\n", "augment_images", "=", "False", ")", ")", ":", "\n", "#print(test_sample[4])", "\n", "                    ", "per_model_per_batch_targets", "[", "idx", "]", ".", "extend", "(", "np", ".", "array", "(", "test_sample", "[", "3", "]", ")", ")", "\n", "per_model_per_batch_preds", "=", "self", ".", "test_evaluation_iteration", "(", "val_sample", "=", "test_sample", ",", "\n", "sample_idx", "=", "sample_idx", ",", "\n", "model_idx", "=", "idx", ",", "\n", "per_model_per_batch_preds", "=", "per_model_per_batch_preds", ",", "\n", "pbar_test", "=", "pbar_test", ")", "\n", "# for i in range(top_n_models):", "\n", "#     print(\"test assertion\", 0)", "\n", "#     print(per_model_per_batch_targets[0], per_model_per_batch_targets[i])", "\n", "#     assert np.equal(np.array(per_model_per_batch_targets[0]), np.array(per_model_per_batch_targets[i]))", "\n", "\n", "", "", "", "per_batch_preds", "=", "np", ".", "mean", "(", "per_model_per_batch_preds", ",", "axis", "=", "0", ")", "\n", "#print(per_batch_preds.shape)", "\n", "per_batch_max", "=", "np", ".", "argmax", "(", "per_batch_preds", ",", "axis", "=", "2", ")", "\n", "per_batch_targets", "=", "np", ".", "array", "(", "per_model_per_batch_targets", "[", "0", "]", ")", ".", "reshape", "(", "per_batch_max", ".", "shape", ")", "\n", "#print(per_batch_max)", "\n", "accuracy", "=", "np", ".", "mean", "(", "np", ".", "equal", "(", "per_batch_targets", ",", "per_batch_max", ")", ")", "\n", "accuracy_std", "=", "np", ".", "std", "(", "np", ".", "equal", "(", "per_batch_targets", ",", "per_batch_max", ")", ")", "\n", "\n", "test_losses", "=", "{", "\"test_accuracy_mean\"", ":", "accuracy", ",", "\"test_accuracy_std\"", ":", "accuracy_std", "}", "\n", "\n", "_", "=", "save_statistics", "(", "self", ".", "logs_filepath", ",", "\n", "list", "(", "test_losses", ".", "keys", "(", ")", ")", ",", "\n", "create", "=", "True", ",", "filename", "=", "\"test_summary.csv\"", ")", "\n", "\n", "summary_statistics_filepath", "=", "save_statistics", "(", "self", ".", "logs_filepath", ",", "\n", "list", "(", "test_losses", ".", "values", "(", ")", ")", ",", "\n", "create", "=", "False", ",", "filename", "=", "\"test_summary.csv\"", ")", "\n", "print", "(", "test_losses", ")", "\n", "print", "(", "\"saved test performance at\"", ",", "summary_statistics_filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.run_experiment": [[314, 384], ["tqdm.tqdm", "experiment_builder.ExperimentBuilder.evaluated_test_set_using_the_best_models", "enumerate", "int", "experiment_builder.ExperimentBuilder.data.get_train_batches", "experiment_builder.ExperimentBuilder.train_iteration", "dict", "dict", "experiment_builder.ExperimentBuilder.merge_two_dicts", "experiment_builder.ExperimentBuilder.save_models", "experiment_builder.ExperimentBuilder.pack_and_save_metrics", "dict", "utils.storage.save_to_json", "tqdm.tqdm", "enumerate", "print", "sys.exit", "int", "experiment_builder.ExperimentBuilder.data.get_val_batches", "experiment_builder.ExperimentBuilder.evaluation_iteration", "print", "int", "experiment_builder.ExperimentBuilder.merge_two_dicts", "os.path.join", "int", "int"], "methods", ["home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.evaluated_test_set_using_the_best_models", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.get_train_batches", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.train_iteration", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.merge_two_dicts", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.save_models", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.pack_and_save_metrics", "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.save_to_json", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.data.MetaLearningSystemDataLoader.get_val_batches", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.evaluation_iteration", "home.repos.pwc.inspect_result.baiksung_MeTAL.None.experiment_builder.ExperimentBuilder.merge_two_dicts"], ["", "def", "run_experiment", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Runs a full training experiment with evaluations of the model on the val set at every epoch. Furthermore,\n        will return the test set evaluation results on the best performing validation model.\n        \"\"\"", "\n", "with", "tqdm", ".", "tqdm", "(", "initial", "=", "self", ".", "state", "[", "'current_iter'", "]", ",", "\n", "total", "=", "int", "(", "self", ".", "args", ".", "total_iter_per_epoch", "*", "self", ".", "args", ".", "total_epochs", ")", ")", "as", "pbar_train", ":", "\n", "\n", "            ", "while", "(", "self", ".", "state", "[", "'current_iter'", "]", "<", "(", "self", ".", "args", ".", "total_epochs", "*", "self", ".", "args", ".", "total_iter_per_epoch", ")", ")", "and", "(", "self", ".", "args", ".", "evaluate_on_test_set_only", "==", "False", ")", ":", "\n", "\n", "                ", "for", "train_sample_idx", ",", "train_sample", "in", "enumerate", "(", "\n", "self", ".", "data", ".", "get_train_batches", "(", "total_batches", "=", "int", "(", "self", ".", "args", ".", "total_iter_per_epoch", "*", "\n", "self", ".", "args", ".", "total_epochs", ")", "-", "self", ".", "state", "[", "\n", "'current_iter'", "]", ",", "\n", "augment_images", "=", "self", ".", "augment_flag", ")", ")", ":", "\n", "# print(self.state['current_iter'], (self.args.total_epochs * self.args.total_iter_per_epoch))", "\n", "                    ", "train_losses", ",", "total_losses", ",", "self", ".", "state", "[", "'current_iter'", "]", "=", "self", ".", "train_iteration", "(", "\n", "train_sample", "=", "train_sample", ",", "\n", "total_losses", "=", "self", ".", "total_losses", ",", "\n", "epoch_idx", "=", "(", "self", ".", "state", "[", "'current_iter'", "]", "/", "\n", "self", ".", "args", ".", "total_iter_per_epoch", ")", ",", "\n", "pbar_train", "=", "pbar_train", ",", "\n", "current_iter", "=", "self", ".", "state", "[", "'current_iter'", "]", ",", "\n", "sample_idx", "=", "self", ".", "state", "[", "'current_iter'", "]", ")", "\n", "\n", "if", "self", ".", "state", "[", "'current_iter'", "]", "%", "self", ".", "args", ".", "total_iter_per_epoch", "==", "0", ":", "\n", "\n", "                        ", "total_losses", "=", "dict", "(", ")", "\n", "val_losses", "=", "dict", "(", ")", "\n", "with", "tqdm", ".", "tqdm", "(", "total", "=", "int", "(", "self", ".", "args", ".", "num_evaluation_tasks", "/", "self", ".", "args", ".", "batch_size", ")", ")", "as", "pbar_val", ":", "\n", "                            ", "for", "_", ",", "val_sample", "in", "enumerate", "(", "\n", "self", ".", "data", ".", "get_val_batches", "(", "total_batches", "=", "int", "(", "self", ".", "args", ".", "num_evaluation_tasks", "/", "self", ".", "args", ".", "batch_size", ")", ",", "\n", "augment_images", "=", "False", ")", ")", ":", "\n", "                                ", "val_losses", ",", "total_losses", "=", "self", ".", "evaluation_iteration", "(", "val_sample", "=", "val_sample", ",", "\n", "total_losses", "=", "total_losses", ",", "\n", "pbar_val", "=", "pbar_val", ",", "phase", "=", "'val'", ")", "\n", "\n", "", "if", "val_losses", "[", "\"val_accuracy_mean\"", "]", ">", "self", ".", "state", "[", "'best_val_acc'", "]", ":", "\n", "                                ", "print", "(", "\"Best validation accuracy\"", ",", "val_losses", "[", "\"val_accuracy_mean\"", "]", ")", "\n", "self", ".", "state", "[", "'best_val_acc'", "]", "=", "val_losses", "[", "\"val_accuracy_mean\"", "]", "\n", "self", ".", "state", "[", "'best_val_iter'", "]", "=", "self", ".", "state", "[", "'current_iter'", "]", "\n", "self", ".", "state", "[", "'best_epoch'", "]", "=", "int", "(", "\n", "self", ".", "state", "[", "'best_val_iter'", "]", "/", "self", ".", "args", ".", "total_iter_per_epoch", ")", "\n", "\n", "\n", "", "", "self", ".", "epoch", "+=", "1", "\n", "self", ".", "state", "=", "self", ".", "merge_two_dicts", "(", "first_dict", "=", "self", ".", "merge_two_dicts", "(", "first_dict", "=", "self", ".", "state", ",", "\n", "second_dict", "=", "train_losses", ")", ",", "\n", "second_dict", "=", "val_losses", ")", "\n", "\n", "self", ".", "save_models", "(", "model", "=", "self", ".", "model", ",", "epoch", "=", "self", ".", "epoch", ",", "state", "=", "self", ".", "state", ")", "\n", "\n", "self", ".", "start_time", ",", "self", ".", "state", "=", "self", ".", "pack_and_save_metrics", "(", "start_time", "=", "self", ".", "start_time", ",", "\n", "create_summary_csv", "=", "self", ".", "create_summary_csv", ",", "\n", "train_losses", "=", "train_losses", ",", "\n", "val_losses", "=", "val_losses", ",", "\n", "state", "=", "self", ".", "state", ")", "\n", "\n", "self", ".", "total_losses", "=", "dict", "(", ")", "\n", "\n", "self", ".", "epochs_done_in_this_run", "+=", "1", "\n", "\n", "save_to_json", "(", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "logs_filepath", ",", "\"summary_statistics.json\"", ")", ",", "\n", "dict_to_store", "=", "self", ".", "state", "[", "'per_epoch_statistics'", "]", ")", "\n", "\n", "if", "self", ".", "epochs_done_in_this_run", ">=", "self", ".", "total_epochs_before_pause", ":", "\n", "                            ", "print", "(", "\"train_seed {}, val_seed: {}, at pause time\"", ".", "format", "(", "self", ".", "data", ".", "dataset", ".", "seed", "[", "\"train\"", "]", ",", "\n", "self", ".", "data", ".", "dataset", ".", "seed", "[", "\"val\"", "]", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "", "", "self", ".", "evaluated_test_set_using_the_best_models", "(", "top_n_models", "=", "5", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.dataset_tools.maybe_unzip_dataset": [[4, 48], ["enumerate", "dataset_path.endswith", "print", "os.walk", "print", "os.path.exists", "print", "os.path.exists", "print", "dataset_tools.unzip_file", "print", "shutil.rmtree", "dataset_tools.maybe_unzip_dataset", "os.path.join", "os.path.abspath", "os.path.abspath", "print", "os.path.join", "file.lower().endswith", "file.lower().endswith", "file.lower().endswith", "file.lower().endswith", "file.lower", "file.lower", "file.lower", "file.lower"], "function", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.dataset_tools.unzip_file", "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.dataset_tools.maybe_unzip_dataset"], ["def", "maybe_unzip_dataset", "(", "args", ")", ":", "\n", "\n", "    ", "datasets", "=", "[", "args", ".", "dataset_name", "]", "\n", "dataset_paths", "=", "[", "args", ".", "dataset_path", "]", "\n", "done", "=", "False", "\n", "\n", "for", "dataset_idx", ",", "dataset_path", "in", "enumerate", "(", "dataset_paths", ")", ":", "\n", "        ", "if", "dataset_path", ".", "endswith", "(", "'/'", ")", ":", "\n", "            ", "dataset_path", "=", "dataset_path", "[", ":", "-", "1", "]", "\n", "", "print", "(", "dataset_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "dataset_path", ")", ":", "\n", "            ", "print", "(", "\"Not found dataset folder structure.. searching for .tar.bz2 file\"", ")", "\n", "zip_directory", "=", "\"{}.tar.bz2\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "'DATASET_DIR'", "]", ",", "datasets", "[", "dataset_idx", "]", ")", ")", "\n", "\n", "assert", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "abspath", "(", "zip_directory", ")", ")", ",", "\"{} dataset zip file not found\"", "\"place dataset in datasets folder as explained in README\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "zip_directory", ")", ")", "\n", "print", "(", "\"Found zip file, unpacking\"", ")", "\n", "\n", "unzip_file", "(", "filepath_pack", "=", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "'DATASET_DIR'", "]", ",", "\"{}.tar.bz2\"", ".", "format", "(", "datasets", "[", "dataset_idx", "]", ")", ")", ",", "\n", "filepath_to_store", "=", "os", ".", "environ", "[", "'DATASET_DIR'", "]", ")", "\n", "\n", "\n", "\n", "args", ".", "reset_stored_filepaths", "=", "True", "\n", "\n", "", "total_files", "=", "0", "\n", "for", "subdir", ",", "dir", ",", "files", "in", "os", ".", "walk", "(", "dataset_path", ")", ":", "\n", "            ", "for", "file", "in", "files", ":", "\n", "                ", "if", "file", ".", "lower", "(", ")", ".", "endswith", "(", "\".jpeg\"", ")", "or", "file", ".", "lower", "(", ")", ".", "endswith", "(", "\".jpg\"", ")", "or", "file", ".", "lower", "(", ")", ".", "endswith", "(", "\n", "\".png\"", ")", "or", "file", ".", "lower", "(", ")", ".", "endswith", "(", "\".pkl\"", ")", ":", "\n", "                    ", "total_files", "+=", "1", "\n", "", "", "", "print", "(", "\"count stuff________________________________________\"", ",", "total_files", ")", "\n", "if", "(", "total_files", "==", "1623", "*", "20", "and", "datasets", "[", "dataset_idx", "]", "==", "'omniglot_dataset'", ")", "or", "(", "\n", "total_files", "==", "100", "*", "600", "and", "'mini_imagenet'", "in", "datasets", "[", "dataset_idx", "]", ")", "or", "(", "\n", "total_files", "==", "3", "and", "'mini_imagenet_pkl'", "in", "datasets", "[", "dataset_idx", "]", ")", ":", "\n", "            ", "print", "(", "\"file count is correct\"", ")", "\n", "done", "=", "True", "\n", "", "elif", "datasets", "[", "dataset_idx", "]", "!=", "'omniglot_dataset'", "and", "datasets", "[", "dataset_idx", "]", "!=", "'mini_imagenet'", "and", "datasets", "[", "dataset_idx", "]", "!=", "'mini_imagenet_pkl'", ":", "\n", "            ", "done", "=", "True", "\n", "print", "(", "\"using new dataset\"", ")", "\n", "\n", "", "if", "not", "done", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "dataset_path", ",", "ignore_errors", "=", "True", ")", "\n", "maybe_unzip_dataset", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.dataset_tools.unzip_file": [[50, 53], ["os.system"], "function", ["None"], ["", "", "", "def", "unzip_file", "(", "filepath_pack", ",", "filepath_to_store", ")", ":", "\n", "    ", "command_to_run", "=", "\"tar -I pbzip2 -xf {} -C {}\"", ".", "format", "(", "filepath_pack", ",", "filepath_to_store", ")", "\n", "os", ".", "system", "(", "command_to_run", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.Bunch.__init__": [[105, 107], ["parser_utils.Bunch.__dict__.update"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "adict", ")", ":", "\n", "    ", "self", ".", "__dict__", ".", "update", "(", "adict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.get_args": [[4, 101], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "vars", "list", "parser_utils.Bunch", "torch.cuda.is_available", "torch.cuda.is_available", "parser_utils.extract_args_from_json", "extract_args_from_json.keys", "print", "torch.cuda.current_device", "print", "print", "print", "torch.device", "str().lower", "os.path.join", "print", "type", "str().lower", "os.path.join", "torch.cuda.current_device", "str", "str"], "function", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.extract_args_from_json"], ["def", "get_args", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "import", "os", "\n", "import", "torch", "\n", "import", "json", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Welcome to the L2F training and inference system'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "nargs", "=", "\"?\"", ",", "type", "=", "int", ",", "default", "=", "32", ",", "help", "=", "'Batch_size for experiment'", ")", "\n", "parser", ".", "add_argument", "(", "'--image_height'", ",", "nargs", "=", "\"?\"", ",", "type", "=", "int", ",", "default", "=", "28", ")", "\n", "parser", ".", "add_argument", "(", "'--image_width'", ",", "nargs", "=", "\"?\"", ",", "type", "=", "int", ",", "default", "=", "28", ")", "\n", "parser", ".", "add_argument", "(", "'--image_channels'", ",", "nargs", "=", "\"?\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--reset_stored_filepaths'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ")", "\n", "parser", ".", "add_argument", "(", "'--reverse_channels'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_of_gpus'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--indexes_of_folders_indicating_class'", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "-", "2", ",", "-", "3", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--train_val_test_split'", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "0.73982737361", ",", "0.26", ",", "0.13008631319", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--samples_per_iter'", ",", "nargs", "=", "\"?\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--labels_as_int'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "104", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--gpu_to_use'", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--num_dataprovider_workers'", ",", "nargs", "=", "\"?\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "'--max_models_to_save'", ",", "nargs", "=", "\"?\"", ",", "type", "=", "int", ",", "default", "=", "5", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_name'", ",", "type", "=", "str", ",", "default", "=", "\"omniglot_dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_path'", ",", "type", "=", "str", ",", "default", "=", "\"datasets/omniglot_dataset\"", ")", "\n", "parser", ".", "add_argument", "(", "'--reset_stored_paths'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ")", "\n", "parser", ".", "add_argument", "(", "'--experiment_name'", ",", "nargs", "=", "\"?\"", ",", "type", "=", "str", ",", ")", "\n", "parser", ".", "add_argument", "(", "'--architecture_name'", ",", "nargs", "=", "\"?\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--continue_from_epoch'", ",", "nargs", "=", "\"?\"", ",", "type", "=", "str", ",", "default", "=", "'latest'", ",", "help", "=", "'Continue from checkpoint of epoch'", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout_rate_value'", ",", "type", "=", "float", ",", "default", "=", "0.3", ",", "help", "=", "'Dropout_rate_value'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_target_samples'", ",", "type", "=", "int", ",", "default", "=", "15", ",", "help", "=", "'Dropout_rate_value'", ")", "\n", "parser", ".", "add_argument", "(", "'--second_order'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "help", "=", "'Dropout_rate_value'", ")", "\n", "parser", ".", "add_argument", "(", "'--total_epochs'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "'Number of epochs per experiment'", ")", "\n", "parser", ".", "add_argument", "(", "'--total_iter_per_epoch'", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "'Number of iters per epoch'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.00001", ",", "help", "=", "'Min learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'Learning rate of overall MAML system'", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_opt_bn'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ")", "\n", "parser", ".", "add_argument", "(", "'--task_learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'Learning rate per task gradient step'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--norm_layer'", ",", "type", "=", "str", ",", "default", "=", "\"batch_norm\"", ")", "\n", "parser", ".", "add_argument", "(", "'--max_pooling'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ")", "\n", "parser", ".", "add_argument", "(", "'--per_step_bn_statistics'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_classes_per_set'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "'Number of classes to sample per set'", ")", "\n", "parser", ".", "add_argument", "(", "'--cnn_num_blocks'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Number of classes to sample per set'", ")", "\n", "parser", ".", "add_argument", "(", "'--number_of_training_steps_per_iter'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Number of classes to sample per set'", ")", "\n", "parser", ".", "add_argument", "(", "'--number_of_evaluation_steps_per_iter'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Number of classes to sample per set'", ")", "\n", "parser", ".", "add_argument", "(", "'--cnn_num_filters'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'Number of classes to sample per set'", ")", "\n", "parser", ".", "add_argument", "(", "'--cnn_blocks_per_stage'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'Number of classes to sample per set'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_samples_per_class'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'Number of samples per set to sample'", ")", "\n", "parser", ".", "add_argument", "(", "'--name_of_args_json_file'", ",", "type", "=", "str", ",", "default", "=", "\"None\"", ")", "\n", "\n", "# Architecture Backbone", "\n", "parser", ".", "add_argument", "(", "'--backbone'", ",", "type", "=", "str", ",", "default", "=", "\"4-CONV\"", ",", "help", "=", "'Base learner architecture backbone'", ")", "\n", "\n", "# L2F", "\n", "parser", ".", "add_argument", "(", "'--attenuate'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "help", "=", "'Whether to attenuate the initialization (for L2F)'", ")", "\n", "\n", "# ALFA", "\n", "parser", ".", "add_argument", "(", "'--alfa'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "help", "=", "'Whether to perform adaptive inner-loop optimization'", ")", "\n", "parser", ".", "add_argument", "(", "'--random_init'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "help", "=", "'Whether to use random initialization'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--meta_loss'", ",", "type", "=", "str", ",", "default", "=", "\"False\"", ",", "help", "=", "'Whether to use meta loss'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args_dict", "=", "vars", "(", "args", ")", "\n", "if", "args", ".", "name_of_args_json_file", "is", "not", "\"None\"", ":", "\n", "        ", "args_dict", "=", "extract_args_from_json", "(", "args", ".", "name_of_args_json_file", ",", "args_dict", ")", "\n", "\n", "", "for", "key", "in", "list", "(", "args_dict", ".", "keys", "(", ")", ")", ":", "\n", "\n", "        ", "if", "str", "(", "args_dict", "[", "key", "]", ")", ".", "lower", "(", ")", "==", "\"true\"", ":", "\n", "            ", "args_dict", "[", "key", "]", "=", "True", "\n", "", "elif", "str", "(", "args_dict", "[", "key", "]", ")", ".", "lower", "(", ")", "==", "\"false\"", ":", "\n", "            ", "args_dict", "[", "key", "]", "=", "False", "\n", "", "if", "key", "==", "\"dataset_path\"", ":", "\n", "            ", "args_dict", "[", "key", "]", "=", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "'DATASET_DIR'", "]", ",", "args_dict", "[", "key", "]", ")", "\n", "print", "(", "key", ",", "os", ".", "path", ".", "join", "(", "os", ".", "environ", "[", "'DATASET_DIR'", "]", ",", "args_dict", "[", "key", "]", ")", ")", "\n", "\n", "", "print", "(", "key", ",", "args_dict", "[", "key", "]", ",", "type", "(", "args_dict", "[", "key", "]", ")", ")", "\n", "\n", "", "args", "=", "Bunch", "(", "args_dict", ")", "\n", "\n", "\n", "args", ".", "use_cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "# checks whether a cuda gpu is available and whether the gpu flag is True", "\n", "        ", "device", "=", "torch", ".", "cuda", ".", "current_device", "(", ")", "\n", "\n", "print", "(", "\"use GPU\"", ",", "device", ")", "\n", "print", "(", "\"GPU ID {}\"", ".", "format", "(", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"use CPU\"", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "# sets the device to be CPU", "\n", "\n", "\n", "", "return", "args", ",", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.parser_utils.extract_args_from_json": [[108, 123], ["json.load.keys", "open", "json.load"], "function", ["None"], ["", "", "def", "extract_args_from_json", "(", "json_file_path", ",", "args_dict", ")", ":", "\n", "    ", "import", "json", "\n", "summary_filename", "=", "json_file_path", "\n", "with", "open", "(", "summary_filename", ")", "as", "f", ":", "\n", "        ", "summary_dict", "=", "json", ".", "load", "(", "fp", "=", "f", ")", "\n", "\n", "", "for", "key", "in", "summary_dict", ".", "keys", "(", ")", ":", "\n", "        ", "if", "\"continue_from\"", "in", "key", ":", "\n", "            ", "pass", "\n", "", "elif", "\"gpu_to_use\"", "in", "key", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "args_dict", "[", "key", "]", "=", "summary_dict", "[", "key", "]", "\n", "\n", "", "", "return", "args_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.save_to_json": [[8, 11], ["open", "json.dump", "os.path.abspath"], "function", ["None"], ["def", "save_to_json", "(", "filename", ",", "dict_to_store", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "abspath", "(", "filename", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "dict_to_store", ",", "fp", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.load_from_json": [[12, 17], ["open", "json.load"], "function", ["None"], ["", "", "def", "load_from_json", "(", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "mode", "=", "\"r\"", ")", "as", "f", ":", "\n", "        ", "load_dict", "=", "json", ".", "load", "(", "fp", "=", "f", ")", "\n", "\n", "", "return", "load_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.save_statistics": [[18, 30], ["open", "csv.writer", "csv.writer.writerow", "open", "csv.writer", "csv.writer.writerow"], "function", ["None"], ["", "def", "save_statistics", "(", "experiment_name", ",", "line_to_add", ",", "filename", "=", "\"summary_statistics.csv\"", ",", "create", "=", "False", ")", ":", "\n", "    ", "summary_filename", "=", "\"{}/{}\"", ".", "format", "(", "experiment_name", ",", "filename", ")", "\n", "if", "create", ":", "\n", "        ", "with", "open", "(", "summary_filename", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "line_to_add", ")", "\n", "", "", "else", ":", "\n", "        ", "with", "open", "(", "summary_filename", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "line_to_add", ")", "\n", "\n", "", "", "return", "summary_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.load_statistics": [[31, 47], ["dict", "open", "f.readlines", "lines[].replace().split", "line.replace().split", "zip", "lines[].replace", "data_dict[].append", "line.replace"], "function", ["None"], ["", "def", "load_statistics", "(", "experiment_name", ",", "filename", "=", "\"summary_statistics.csv\"", ")", ":", "\n", "    ", "data_dict", "=", "dict", "(", ")", "\n", "summary_filename", "=", "\"{}/{}\"", ".", "format", "(", "experiment_name", ",", "filename", ")", "\n", "with", "open", "(", "summary_filename", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "data_labels", "=", "lines", "[", "0", "]", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "split", "(", "\",\"", ")", "\n", "del", "lines", "[", "0", "]", "\n", "\n", "for", "label", "in", "data_labels", ":", "\n", "            ", "data_dict", "[", "label", "]", "=", "[", "]", "\n", "\n", "", "for", "line", "in", "lines", ":", "\n", "            ", "data", "=", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "split", "(", "\",\"", ")", "\n", "for", "key", ",", "item", "in", "zip", "(", "data_labels", ",", "data", ")", ":", "\n", "                ", "data_dict", "[", "key", "]", ".", "append", "(", "item", ")", "\n", "", "", "", "return", "data_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.build_experiment_folder": [[49, 67], ["os.path.abspath", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.abspath"], "function", ["None"], ["", "def", "build_experiment_folder", "(", "experiment_name", ")", ":", "\n", "    ", "experiment_path", "=", "os", ".", "path", ".", "abspath", "(", "experiment_name", ")", "\n", "saved_models_filepath", "=", "\"{}/{}\"", ".", "format", "(", "experiment_path", ",", "\"saved_models\"", ")", "\n", "logs_filepath", "=", "\"{}/{}\"", ".", "format", "(", "experiment_path", ",", "\"logs\"", ")", "\n", "samples_filepath", "=", "\"{}/{}\"", ".", "format", "(", "experiment_path", ",", "\"visual_outputs\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "experiment_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "experiment_path", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "logs_filepath", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "logs_filepath", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "samples_filepath", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "samples_filepath", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "saved_models_filepath", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "saved_models_filepath", ")", "\n", "\n", "", "outputs", "=", "(", "saved_models_filepath", ",", "logs_filepath", ",", "samples_filepath", ")", "\n", "outputs", "=", "(", "os", ".", "path", ".", "abspath", "(", "item", ")", "for", "item", "in", "outputs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.get_best_validation_model_statistics": [[68, 81], ["storage.load_statistics", "numpy.array", "numpy.min", "numpy.argmin"], "function", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.load_statistics"], ["", "def", "get_best_validation_model_statistics", "(", "experiment_name", ",", "filename", "=", "\"summary_statistics.csv\"", ")", ":", "\n", "    ", "\"\"\"\n    Returns the best val epoch and val accuracy from a log csv file\n    :param log_dir: The log directory the file is saved in\n    :param statistics_file_name: The log file name\n    :return: The best validation accuracy and the epoch at which it is produced\n    \"\"\"", "\n", "log_file_dict", "=", "load_statistics", "(", "filename", "=", "filename", ",", "experiment_name", "=", "experiment_name", ")", "\n", "d_val_loss", "=", "np", ".", "array", "(", "log_file_dict", "[", "'total_d_val_loss_mean'", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "best_d_val_loss", "=", "np", ".", "min", "(", "d_val_loss", ")", "\n", "best_d_val_epoch", "=", "np", ".", "argmin", "(", "d_val_loss", ")", "\n", "\n", "return", "best_d_val_loss", ",", "best_d_val_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.create_json_experiment_log": [[82, 96], ["dict", "vars().items", "dict", "datetime.datetime.now().timestamp", "open", "json.dump", "vars", "datetime.datetime.now", "os.path.abspath"], "function", ["None"], ["", "def", "create_json_experiment_log", "(", "experiment_log_dir", ",", "args", ",", "log_name", "=", "\"experiment_log.json\"", ")", ":", "\n", "    ", "summary_filename", "=", "\"{}/{}\"", ".", "format", "(", "experiment_log_dir", ",", "log_name", ")", "\n", "\n", "experiment_summary_dict", "=", "dict", "(", ")", "\n", "\n", "for", "key", ",", "value", "in", "vars", "(", "args", ")", ".", "items", "(", ")", ":", "\n", "        ", "experiment_summary_dict", "[", "key", "]", "=", "value", "\n", "\n", "", "experiment_summary_dict", "[", "\"epoch_stats\"", "]", "=", "dict", "(", ")", "\n", "timestamp", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "timestamp", "(", ")", "\n", "experiment_summary_dict", "[", "\"experiment_status\"", "]", "=", "[", "(", "timestamp", ",", "\"initialization\"", ")", "]", "\n", "experiment_summary_dict", "[", "\"experiment_initialization_time\"", "]", "=", "timestamp", "\n", "with", "open", "(", "os", ".", "path", ".", "abspath", "(", "summary_filename", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "experiment_summary_dict", ",", "fp", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.update_json_experiment_log_dict": [[97, 106], ["summary_dict[].append", "open", "json.load", "open", "json.dump"], "function", ["None"], ["", "", "def", "update_json_experiment_log_dict", "(", "key", ",", "value", ",", "experiment_log_dir", ",", "log_name", "=", "\"experiment_log.json\"", ")", ":", "\n", "    ", "summary_filename", "=", "\"{}/{}\"", ".", "format", "(", "experiment_log_dir", ",", "log_name", ")", "\n", "with", "open", "(", "summary_filename", ")", "as", "f", ":", "\n", "        ", "summary_dict", "=", "json", ".", "load", "(", "fp", "=", "f", ")", "\n", "\n", "", "summary_dict", "[", "key", "]", ".", "append", "(", "value", ")", "\n", "\n", "with", "open", "(", "summary_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "summary_dict", ",", "fp", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.change_json_log_experiment_status": [[107, 112], ["datetime.datetime.now().timestamp", "storage.update_json_experiment_log_dict", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.update_json_experiment_log_dict"], ["", "", "def", "change_json_log_experiment_status", "(", "experiment_status", ",", "experiment_log_dir", ",", "log_name", "=", "\"experiment_log.json\"", ")", ":", "\n", "    ", "timestamp", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "timestamp", "(", ")", "\n", "experiment_status", "=", "(", "timestamp", ",", "experiment_status", ")", "\n", "update_json_experiment_log_dict", "(", "key", "=", "\"experiment_status\"", ",", "value", "=", "experiment_status", ",", "\n", "experiment_log_dir", "=", "experiment_log_dir", ",", "log_name", "=", "log_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baiksung_MeTAL.utils.storage.update_json_experiment_log_epoch_stats": [[113, 132], ["epoch_stats.keys", "open", "json.load", "float", "open", "json.dump", "epoch_stats_dict[].append"], "function", ["None"], ["", "def", "update_json_experiment_log_epoch_stats", "(", "epoch_stats", ",", "experiment_log_dir", ",", "log_name", "=", "\"experiment_log.json\"", ")", ":", "\n", "    ", "summary_filename", "=", "\"{}/{}\"", ".", "format", "(", "experiment_log_dir", ",", "log_name", ")", "\n", "with", "open", "(", "summary_filename", ")", "as", "f", ":", "\n", "        ", "summary_dict", "=", "json", ".", "load", "(", "fp", "=", "f", ")", "\n", "\n", "", "epoch_stats_dict", "=", "summary_dict", "[", "\"epoch_stats\"", "]", "\n", "\n", "for", "key", "in", "epoch_stats", ".", "keys", "(", ")", ":", "\n", "        ", "entry", "=", "float", "(", "epoch_stats", "[", "key", "]", ")", "\n", "if", "key", "in", "epoch_stats_dict", ":", "\n", "            ", "epoch_stats_dict", "[", "key", "]", ".", "append", "(", "entry", ")", "\n", "", "else", ":", "\n", "            ", "epoch_stats_dict", "[", "key", "]", "=", "[", "entry", "]", "\n", "\n", "", "", "summary_dict", "[", "'epoch_stats'", "]", "=", "epoch_stats_dict", "\n", "\n", "with", "open", "(", "summary_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "summary_dict", ",", "fp", "=", "f", ")", "\n", "", "return", "summary_filename", "\n", "", ""]]}