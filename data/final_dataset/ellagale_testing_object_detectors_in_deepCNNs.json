{"home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.IM_test_zhou_vgg_places365.ICLRPaperTest": [[73, 136], ["grab_points_for_a_cluster", "find_zhou_precision", "print", "sum", "print", "print", "print", "print", "numpy.mean", "numpy.std", "print", "numpy.mean", "numpy.std", "print", "print", "egg.append", "sum.append", "numpy.sqrt", "len", "numpy.sqrt", "len", "max", "classA.append", "range", "classnotA.append", "len", "len", "len", "len", "len", "len", "max", "class_name.split"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_zhou_precision"], ["def", "ICLRPaperTest", "(", "classAindices", ",", "\n", "current_neuron_index", ",", "\n", "x_data", ",", "\n", "acts", ",", "\n", "cluster_list", ")", ":", "\n", "    ", "from", "h5_analysis_jitterer", "import", "grab_points_for_a_cluster", ",", "find_zhou_precision", "\n", "\"\"\"Does a suite of tests on the data \"\"\"", "\n", "# this bit does tge zhou precisison", "\n", "local_list", ",", "selected_activations", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "max", "(", "x_data", ")", "/", "4", ",", "\n", "max_selected_x_data", "=", "max", "(", "x_data", ")", ",", "\n", "x_data", "=", "x_data", ",", "\n", "acts", "=", "acts", ",", "\n", "verbose", "=", "True", ")", "\n", "local_list", "=", "local_list", "[", "-", "101", ":", "-", "1", "]", "\n", "selected_activations", "=", "selected_activations", "[", "-", "101", ":", "-", "1", "]", "\n", "zhou_precs_class", ",", "zhou_precs", ",", "zhou_no_of_classes", ",", "zhou", "=", "find_zhou_precision", "(", "number_of_points", "=", "100", ",", "\n", "local_list", "=", "local_list", ")", "\n", "egg", "=", "[", "]", "\n", "for", "class_name", "in", "r", ".", "labels", "[", "bus_indices", "]", ":", "\n", "        ", "egg", ".", "append", "(", "class_name", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "\n", "#", "\n", "", "print", "(", "'Warning, this is hacky, and assumes the .h5 file name so do doublecheck if this answer is 0'", ")", "\n", "count", "=", "[", "]", "\n", "for", "key_start", "in", "egg", ":", "\n", "        ", "key", "=", "key_start", "+", "'_'", "+", "r", ".", "blob_list", "[", "0", "]", "+", "'_max'", "\n", "count", ".", "append", "(", "zhou", "[", "key", "]", ")", "\n", "#", "\n", "", "count", "=", "sum", "(", "count", ")", "\n", "zhou_precs", "=", "count", "/", "100.0", "\n", "print", "(", "'Zhou:{}'", ".", "format", "(", "zhou", ")", ")", "\n", "print", "(", "'Zhou precision class: {}\\nZhou precision:{}\\nZhou no. of class:{}\\n'", ".", "format", "(", "egg", ",", "zhou_precs", ",", "\n", "zhou_no_of_classes", ")", ")", "\n", "#", "\n", "#", "\n", "classA", "=", "[", "]", "\n", "for", "index", "in", "classAindices", ":", "\n", "        ", "for", "item", "in", "cluster_list", "[", "index", "]", ":", "\n", "            ", "classA", ".", "append", "(", "item", ")", "\n", "#", "\n", "", "", "classnotA", "=", "[", "]", "\n", "for", "index", "in", "[", "x", "for", "x", "in", "range", "(", "1000", ")", "if", "x", "not", "in", "classAindices", "]", ":", "\n", "        ", "for", "item", "in", "cluster_list", "[", "index", "]", ":", "\n", "            ", "classnotA", ".", "append", "(", "item", ")", "\n", "#", "\n", "", "", "print", "(", "'Representative stats'", ")", "\n", "print", "(", "'Class A is {} items\\t class not A is {} items'", ".", "format", "(", "len", "(", "classA", ")", ",", "len", "(", "classnotA", ")", ")", ")", "\n", "muA", "=", "np", ".", "mean", "(", "classA", ")", "\n", "stdA", "=", "np", ".", "std", "(", "classA", ")", "\n", "meA", "=", "stdA", "/", "np", ".", "sqrt", "(", "len", "(", "classA", ")", ")", "\n", "pc_nonzeroA", "=", "100", "*", "len", "(", "[", "x", "for", "x", "in", "classA", "if", "x", ">", "0.0", "]", ")", "/", "len", "(", "classA", ")", "\n", "print", "(", "'mean (A): {}+/-{}\\nstd (A): {}\\n%A that is nonzero: {}'", "\n", ".", "format", "(", "muA", ",", "meA", ",", "stdA", ",", "pc_nonzeroA", ")", ")", "\n", "munotA", "=", "np", ".", "mean", "(", "classnotA", ")", "\n", "stdnotA", "=", "np", ".", "std", "(", "classnotA", ")", "\n", "menotA", "=", "stdnotA", "/", "np", ".", "sqrt", "(", "len", "(", "classnotA", ")", ")", "\n", "pc_nonzeronotA", "=", "100", "*", "len", "(", "[", "x", "for", "x", "in", "classnotA", "if", "x", ">", "0.0", "]", ")", "/", "len", "(", "classnotA", ")", "\n", "print", "(", "'mean (NOT A): {}+/-{}\\nstd (NOT A): {}\\n%NOT A that is nonzero: {}'", "\n", ".", "format", "(", "munotA", ",", "menotA", ",", "stdnotA", ",", "pc_nonzeronotA", ")", ")", "\n", "CCMAS", "=", "(", "muA", "-", "munotA", ")", "/", "(", "muA", "+", "munotA", ")", "\n", "print", "(", "'CCMAS(A):{}\\n'", ".", "format", "(", "CCMAS", ")", ")", "\n", "#", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.calculate_mean_average_precision": [[48, 88], ["acts.get_activations_for_neuron", "h5_analysis_jitterer.grab_points_for_a_cluster", "len", "range", "max", "print", "print", "abs", "abs"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster"], ["def", "calculate_mean_average_precision", "(", "class_name", "=", "''", ",", "current_neuron_index", "=", "current_neuron_index", ",", "acts", "=", "acts", ",", "verbose", "=", "verbose", ",", "minx", "=", "0.000000001", ")", ":", "\n", "    ", "\"\"\"Counts down using -1 to min list length+1 indexing and calculates the mean average precision\n    given by: M.A.P. = sum over j of no. of A so far found at position j divided by the position in the list\n     Note that we are counting backwards, the formula expects a 1-indexed list and j counts position over a 1-indexed list\n     Note, we assume if no class name is given you want the class for the highest activation\n     minx = the minimum activation to consider, this must be above 0.0 as these all have the same value\"\"\"", "\n", "#", "\n", "current_neuron", "=", "acts", ".", "get_activations_for_neuron", "(", "current_neuron_index", ")", "# get the neuron's data", "\n", "x_data", "=", "current_neuron", ".", "vector", "# get the activations without classes", "\n", "# grab your list of points", "\n", "local_list", ",", "selected_activations", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "minx", ",", "\n", "max_selected_x_data", "=", "max", "(", "x_data", ")", ",", "\n", "acts", "=", "acts", ",", "\n", "x_data", "=", "x_data", ",", "\n", "verbose", "=", "verbose", ")", "\n", "Q", "=", "len", "(", "local_list", ")", "# total length of list", "\n", "# get the test class (this is the correct class or 'A')", "\n", "if", "class_name", "==", "''", ":", "\n", "        ", "test_class", "=", "local_list", "[", "-", "1", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "test_class", "=", "class_name", "\n", "# set up counters", "\n", "", "MAP", "=", "0", "# mean average precision", "\n", "count_of_test_class", "=", "0", "\n", "# loop backwards through the list, abs j is the position in a 1-indexed list", "\n", "for", "i", "in", "range", "(", "Q", "+", "1", ")", ":", "\n", "        ", "j", "=", "-", "(", "i", "+", "1", ")", "# 1 indexed", "\n", "current_class", "=", "local_list", "[", "j", "]", "[", "0", "]", "# current class", "\n", "if", "j", "==", "-", "Q", ":", "\n", "# if the whole of local_list is the same class (this accounts for zero indexing)", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "current_class", ")", "\n", "print", "(", "'{}/{}'", ".", "format", "(", "count_of_test_class", ",", "abs", "(", "j", ")", ")", ")", "\n", "", "j", "=", "j", "-", "1", "# really this is here so we can check j", "\n", "break", "\n", "", "if", "(", "current_class", "==", "test_class", ")", ":", "\n", "            ", "count_of_test_class", "=", "count_of_test_class", "+", "1", "\n", "MAP", "=", "MAP", "+", "count_of_test_class", "/", "(", "abs", "(", "j", ")", ")", "# N.b. this is the sum, we divide by j on the output", "\n", "", "", "return", "MAP", "/", "Q", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.calculate_average_precision_top_classes": [[90, 136], ["precision_calulator.find_zhou_precision", "precision_calulator.calculate_ave_precs_general", "Ave_prec_x_list.append", "precs_x_list.append", "recall_x_list.append", "print", "list_of_top_classes.most_common"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_zhou_precision", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.calculate_ave_precs_general"], ["", "def", "calculate_average_precision_top_classes", "(", "local_list", "=", "local_list", ",", "\n", "class_names", "=", "''", ",", "\n", "no_files_in_label", "=", "no_files_in_label", ",", "\n", "Q_stop", "=", "''", ",", "\n", "no_of_points_for_zhou_precs", "=", "100", ",", "\n", "verbose", "=", "verbose", ")", ":", "\n", "    ", "\"\"\"Calcs ave precsision for all classes in top 100 activations\n    Counts down using -1 to min list length+1 indexing and calculates the mean average precision\n    given by: M.A.P. = sum over j of no. of A so far found at position j divided by the position in the list\n     Note that we are counting backwards, the formula expects a 1-indexed list and j counts position over a 1-indexed list\n     Note, we assume if no class name is given you want the class for the highest activation\n     minx = the minimum activation to consider, this must be above 0.0 as these all have the same value\n     Q_stop = no. of points back from the end to consider, i.e. 100 does the last 100, not this overrides xmin\n     no_of_points = the number of points at the top of hte activation range to consider \"\"\"", "\n", "#", "\n", "# get the test class (this is the correct class or 'A')", "\n", "if", "class_names", "==", "''", ":", "\n", "        ", "top_mode_class", ",", "precs_of_tmc", ",", "no_of_classes_in_top_x", ",", "list_of_top_classes", "=", "find_zhou_precision", "(", "\n", "number_of_points", "=", "no_of_points_for_zhou_precs", ",", "local_list", "=", "local_list", ")", "\n", "# n.b.list_of_top_classes is not sorted on magnitude of items", "\n", "# test_class_list is sorted that way", "\n", "test_class_list", "=", "[", "x", "[", "0", "]", "for", "x", "in", "list_of_top_classes", ".", "most_common", "(", ")", "]", "\n", "", "else", ":", "\n", "        ", "if", "class_names", "==", "str", ":", "\n", "            ", "print", "(", "'Input test_class is not a list of classes! You probably wanted to use the function\\n'", "\n", "'calculate_average_precision, not calculate_average_precision_top_class!\\n'", ")", "\n", "", "else", ":", "\n", "            ", "test_class_list", "=", "class_name", "\n", "top_mode_class", ",", "precs_of_tmc", ",", "no_of_classes_in_top_x", ",", "list_of_top_classes", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "", "", "Ave_prec_x_list", "=", "[", "]", "\n", "precs_x_list", "=", "[", "]", "\n", "recall_x_list", "=", "[", "]", "\n", "for", "test_class", "in", "test_class_list", ":", "\n", "        ", "Ave_precs_x", ",", "precs_x", ",", "recall_x", "=", "calculate_ave_precs_general", "(", "test_class", "=", "test_class", ",", "\n", "local_list", "=", "local_list", ",", "\n", "Q_stop", "=", "Q_stop", ",", "\n", "no_files_in_label", "=", "no_files_in_label", ",", "\n", "verbose", "=", "verbose", ")", "\n", "# have done all Q points now", "\n", "Ave_prec_x_list", ".", "append", "(", "Ave_precs_x", ")", "\n", "precs_x_list", ".", "append", "(", "precs_x", ")", "\n", "recall_x_list", ".", "append", "(", "recall_x", ")", "\n", "", "out", "=", "(", "top_mode_class", ",", "precs_of_tmc", ",", "no_of_classes_in_top_x", ",", "\n", "list_of_top_classes", ",", "Ave_prec_x_list", ",", "precs_x_list", ",", "\n", "recall_x_list", ",", "test_class_list", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.find_extent_of_top_class": [[137, 153], ["range", "len", "len"], "function", ["None"], ["", "def", "find_extent_of_top_class", "(", "local_list", "=", "local_list", ")", ":", "\n", "    ", "\"\"\"starts at the highest index and counts down until the classes no longer match\"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "local_list", ")", "+", "1", ")", ":", "\n", "        ", "j", "=", "-", "(", "i", "+", "1", ")", "# 1 indexed", "\n", "if", "j", "==", "-", "1", ":", "\n", "            ", "test_class", "=", "local_list", "[", "j", "]", "[", "0", "]", "\n", "", "current_class", "=", "local_list", "[", "j", "]", "[", "0", "]", "\n", "if", "j", "==", "-", "len", "(", "local_list", ")", ":", "\n", "# if the whole of local_list is the same class 9(this accounts for zero indexing)", "\n", "            ", "j", "=", "j", "-", "1", "\n", "break", "\n", "", "if", "not", "(", "current_class", "==", "test_class", ")", ":", "\n", "#print(j)", "\n", "            ", "break", "\n", "", "", "no_of_members_of_test_class", "=", "-", "j", "-", "1", "\n", "return", "no_of_members_of_test_class", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.get_local_list_for_neuron": [[154, 179], ["acts.get_activations_for_neuron", "h5_analysis_jitterer.grab_points_for_a_cluster", "min", "max", "min"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster"], ["", "def", "get_local_list_for_neuron", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "minx", "=", "''", ",", "\n", "maxx", "=", "''", ",", "\n", "acts", "=", "acts", ")", ":", "\n", "    ", "\"\"\"Little function to get the local_list and selected activations from minx x to max_x for a neuron\n    N.B. use minx=0 if you want the points ABOVE 0.0\n    use minx=0.0 if you want the points equal to and above 0.0\"\"\"", "\n", "current_neuron", "=", "acts", ".", "get_activations_for_neuron", "(", "current_neuron_index", ")", "# get the neuron's data", "\n", "x_data", "=", "current_neuron", ".", "vector", "# get the activations without classes", "\n", "if", "minx", "==", "''", ":", "\n", "        ", "minx", "=", "min", "(", "x_data", ")", "# this grabs all the points", "\n", "", "elif", "minx", "==", "0", ":", "\n", "        ", "minx", "=", "min", "(", "[", "x", "for", "x", "in", "x_data", "if", "x", ">", "0.0", "]", ")", "\n", "# grab everything above 0 - special case, we don't include 0", "\n", "# this changed grab_points_for_cluster from x >= 0 to x > 0", "\n", "", "if", "maxx", "==", "''", ":", "\n", "        ", "maxx", "=", "max", "(", "x_data", ")", "\n", "# grab your list of points", "\n", "", "local_list", ",", "selected_activations", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "minx", ",", "\n", "max_selected_x_data", "=", "maxx", ",", "\n", "acts", "=", "acts", ",", "\n", "x_data", "=", "x_data", ",", "\n", "verbose", "=", "verbose", ")", "\n", "return", "local_list", ",", "selected_activations", ",", "x_data", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.calculate_average_precision": [[180, 246], ["acts.get_activations_for_neuron", "h5_analysis_jitterer.grab_points_for_a_cluster", "range", "min", "len", "max", "abs", "print", "print", "print", "print", "abs", "abs"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster"], ["", "def", "calculate_average_precision", "(", "class_name", "=", "''", ",", "current_neuron_index", "=", "current_neuron_index", ",", "acts", "=", "acts", ",", "\n", "no_files_in_label", "=", "no_files_in_label", ",", "verbose", "=", "verbose", ",", "minx", "=", "''", ",", "Q_stop", "=", "''", ")", ":", "\n", "    ", "\"\"\"Counts down using -1 to min list length+1 indexing and calculates the mean average precision\n    given by: M.A.P. = sum over j of no. of A so far found at position j divided by the position in the list\n     Note that we are counting backwards, the formula expects a 1-indexed list and j counts position over a 1-indexed list\n     Note, we assume if no class name is given you want the class for the highest activation\n     minx = the minimum activation to consider, this must be above 0.0 as these all have the same value\n     Q_stop = no. of points back from the end to consider, i.e. 100 does the last 100, not this overrides xmin\"\"\"", "\n", "#", "\n", "current_neuron", "=", "acts", ".", "get_activations_for_neuron", "(", "current_neuron_index", ")", "# get the neuron's data", "\n", "x_data", "=", "current_neuron", ".", "vector", "# get the activations without classes", "\n", "if", "minx", "==", "''", ":", "\n", "        ", "minx", "=", "min", "(", "x_data", ")", "# this grabs all the points", "\n", "# grab your list of points", "\n", "", "local_list", ",", "selected_activations", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "minx", ",", "\n", "max_selected_x_data", "=", "max", "(", "x_data", ")", ",", "\n", "acts", "=", "acts", ",", "\n", "x_data", "=", "x_data", ",", "\n", "verbose", "=", "verbose", ")", "\n", "if", "not", "Q_stop", "==", "''", ":", "\n", "        ", "Q", "=", "Q_stop", "\n", "", "else", ":", "\n", "        ", "Q", "=", "len", "(", "local_list", ")", "# total length of list", "\n", "# get the test class (this is the correct class or 'A')", "\n", "", "if", "class_name", "==", "''", ":", "\n", "        ", "test_class", "=", "local_list", "[", "-", "1", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "test_class", "=", "class_name", "\n", "", "N_test", "=", "no_files_in_label", "[", "test_class", "]", "# no of items in class A", "\n", "# set up counters", "\n", "AP", "=", "0", "# average precision", "\n", "count_of_test_class", "=", "0", "\n", "# loop backwards through the list, abs j is the position in a 1-indexed list", "\n", "# values for i == -1", "\n", "#    current_class = local_list[-1][0]", "\n", "#    if (current_class == test_class):", "\n", "#        count_of_test_class = count_of_test_class + 1 # we found A", "\n", "#    precs_x = count_of_test_class /1", "\n", "recall_x", "=", "0", "\n", "Ave_precs_x", "=", "0", "\n", "for", "i", "in", "range", "(", "Q", ")", ":", "\n", "        ", "j", "=", "-", "(", "i", "+", "1", ")", "# 1 indexed", "\n", "recall_x_minus_1", "=", "recall_x", "\n", "current_class", "=", "local_list", "[", "j", "]", "[", "0", "]", "# current class", "\n", "if", "j", "==", "-", "Q", ":", "\n", "# if the whole of local_list is the same class (this accounts for zero indexing)", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "current_class", ")", "\n", "print", "(", "'{}/{}'", ".", "format", "(", "count_of_test_class", ",", "abs", "(", "j", ")", ")", ")", "\n", "", "j", "=", "j", "-", "1", "# really this is here so we can check j", "\n", "#break", "\n", "", "if", "count_of_test_class", "==", "N_test", ":", "\n", "#we've found them all", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'found all {} of {}, stopping...'", ".", "format", "(", "N_test", ",", "current_class", ")", ")", "\n", "print", "(", "'{}/{}'", ".", "format", "(", "count_of_test_class", ",", "abs", "(", "j", ")", ")", ")", "\n", "", "break", "\n", "", "if", "(", "current_class", "==", "test_class", ")", ":", "\n", "            ", "count_of_test_class", "=", "count_of_test_class", "+", "1", "#n A", "\n", "", "precs_x", "=", "count_of_test_class", "/", "(", "abs", "(", "j", ")", ")", "# N.b. this is the sum, we divide by j on the output", "\n", "recall_x", "=", "count_of_test_class", "/", "N_test", "\n", "delta_recall_x", "=", "recall_x", "-", "recall_x_minus_1", "# difference in recall between this point nd the next", "\n", "weight_precs_x", "=", "precs_x", "*", "delta_recall_x", "# weighted precsion at point x (we do average via weighted sum)", "\n", "Ave_precs_x", "=", "Ave_precs_x", "+", "weight_precs_x", "# average_precision evaluated at point x", "\n", "", "return", "Ave_precs_x", ",", "precs_x", ",", "recall_x", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.calculate_ave_precs_general": [[248, 299], ["range", "len", "len", "len", "print", "print", "print", "print", "abs", "print", "print", "len", "abs"], "function", ["None"], ["", "def", "calculate_ave_precs_general", "(", "test_class", "=", "test_class", ",", "\n", "local_list", "=", "local_list", ",", "\n", "Q_stop", "=", "''", ",", "\n", "no_files_in_label", "=", "no_files_in_label", ",", "\n", "verbose", "=", "verbose", ")", ":", "\n", "    ", "\"\"\"Internal function to calculate the average precision of a local_list\n    current_class = name of the class we're taking as A\n    local_list = sorted list of tuples containing the class and index of each point\n    Q_stop = number at which to stop evaluating the ave precs\n    no_files_in_label = cell array of labels to number of items in that label\n    verbose = whether to print data to screen\"\"\"", "\n", "if", "not", "Q_stop", "==", "''", ":", "\n", "        ", "Q", "=", "Q_stop", "\n", "", "else", ":", "\n", "        ", "Q", "=", "len", "(", "local_list", ")", "\n", "# does all points", "\n", "", "if", "Q", ">", "len", "(", "local_list", ")", ":", "\n", "        ", "Q", "=", "len", "(", "local_list", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'The number of points to check (Q) {} is more than the number of points above minx {}'", ".", "format", "(", "Q", ",", "len", "(", "local_list", ")", ")", ")", "\n", "print", "(", "'Setting Q to len(local_list), you may wish to change your settings'", ")", "\n", "", "", "N_test", "=", "no_files_in_label", "[", "test_class", "]", "# no of items in class A", "\n", "# set up counters", "\n", "AP", "=", "0", "# average precision", "\n", "count_of_test_class", "=", "0", "\n", "# loop backwards through the list, abs j is the position in a 1-indexed list", "\n", "recall_x", "=", "0", "\n", "Ave_precs_x", "=", "0", "\n", "for", "i", "in", "range", "(", "Q", ")", ":", "\n", "        ", "j", "=", "-", "(", "i", "+", "1", ")", "# 1 indexed", "\n", "recall_x_minus_1", "=", "recall_x", "\n", "current_class", "=", "local_list", "[", "j", "]", "[", "0", "]", "\n", "#j = j - 1  # really this is here so we can check j", "\n", "# break", "\n", "if", "count_of_test_class", "==", "N_test", ":", "\n", "# we've found them all", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'found all {} of {}, stopping...'", ".", "format", "(", "N_test", ",", "current_class", ")", ")", "\n", "print", "(", "'{}/{}'", ".", "format", "(", "count_of_test_class", ",", "abs", "(", "j", ")", ")", ")", "\n", "", "break", "\n", "", "if", "(", "current_class", "==", "test_class", ")", ":", "\n", "            ", "count_of_test_class", "=", "count_of_test_class", "+", "1", "# n A", "\n", "", "precs_x", "=", "count_of_test_class", "/", "(", "abs", "(", "j", ")", ")", "# N.b. this is the sum, we divide by j on the output", "\n", "recall_x", "=", "count_of_test_class", "/", "N_test", "\n", "delta_recall_x", "=", "recall_x", "-", "recall_x_minus_1", "# difference in recall between this point nd the next", "\n", "weight_precs_x", "=", "precs_x", "*", "delta_recall_x", "# weighted precsion at point x (we do average via weighted sum)", "\n", "Ave_precs_x", "=", "Ave_precs_x", "+", "weight_precs_x", "# average_precision evaluated at point x", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'Class {}, evaluated at Q={}:, found {}'", ".", "format", "(", "test_class", ",", "Q", ",", "count_of_test_class", ")", ")", "\n", "print", "(", "'Average precision={}; precision={}; recall={}'", ".", "format", "(", "Ave_precs_x", ",", "precs_x", ",", "recall_x", ")", ")", "\n", "", "return", "Ave_precs_x", ",", "precs_x", ",", "recall_x", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.calculate_many_precs_recall_stats": [[301, 395], ["range", "len", "len", "len", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "abs", "abs", "abs", "print", "print", "abs", "len", "abs"], "function", ["None"], ["", "def", "calculate_many_precs_recall_stats", "(", "test_class", "=", "test_class", ",", "\n", "local_list", "=", "local_list", ",", "\n", "Q_stop", "=", "''", ",", "\n", "no_files_in_label", "=", "no_files_in_label", ",", "\n", "no_of_images", "=", "no_of_images", ",", "\n", "verbose", "=", "verbose", ")", ":", "\n", "    ", "\"\"\"Function to calculate the average precision of a local_list\n    current_class = name of the class we're taking as A\n    local_list = sorted list of tuples containing the class and index of each point\n    Q_stop = number at which to stop evaluating the ave precs\n    no_files_in_label = cell array of labels to number of items in that label\n    verbose = whether to print data to screen\"\"\"", "\n", "if", "not", "Q_stop", "==", "''", ":", "\n", "        ", "Q", "=", "Q_stop", "\n", "", "else", ":", "\n", "        ", "Q", "=", "len", "(", "local_list", ")", "\n", "# does all points", "\n", "", "if", "Q", ">", "len", "(", "local_list", ")", ":", "\n", "        ", "Q", "=", "len", "(", "local_list", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'The number of points to check (Q) {} is more than the number of points above minx {}'", ".", "format", "(", "Q", ",", "len", "(", "local_list", ")", ")", ")", "\n", "print", "(", "'Setting Q to len(local_list), you may wish to change your settings'", ")", "\n", "", "", "N_test", "=", "no_files_in_label", "[", "test_class", "]", "# no of items in class A", "\n", "N_not_test", "=", "no_of_images", "-", "N_test", "# i.e. set not-A", "\n", "# set up counters", "\n", "AP", "=", "0", "# average precision", "\n", "found_recall_precs_p95", "=", "False", "\n", "recall_p95", "=", "0.0", "\n", "count_of_test_class", "=", "0", "\n", "# loop backwards through the list, abs j is the position in a 1-indexed list", "\n", "recall_x", "=", "0", "# n.b. this is also sensitivity", "\n", "Ave_precs_x", "=", "0", "\n", "specificity_x", "=", "0", "\n", "count_of_false_positives", "=", "0", "# number of not-A on misidentified", "\n", "max_informedness", "=", "0", "\n", "x_for_max_informedness", "=", "0", "\n", "max_f1_stat", "=", "0", "\n", "x_for_max_f1", "=", "0", "\n", "recall_for_max_informedness", "=", "0", "\n", "specificity_for_max_informedness", "=", "0", "\n", "for", "i", "in", "range", "(", "Q", ")", ":", "\n", "        ", "j", "=", "-", "(", "i", "+", "1", ")", "# 1 indexed", "\n", "recall_x_minus_1", "=", "recall_x", "\n", "current_class", "=", "local_list", "[", "j", "]", "[", "0", "]", "\n", "#j = j - 1  # really this is here so we can check j", "\n", "# break", "\n", "if", "count_of_test_class", "==", "N_test", ":", "\n", "# we've found them all", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'found all {} of {}, stopping...'", ".", "format", "(", "N_test", ",", "current_class", ")", ")", "\n", "print", "(", "'{}/{}'", ".", "format", "(", "count_of_test_class", ",", "abs", "(", "j", ")", ")", ")", "\n", "", "break", "\n", "", "if", "(", "current_class", "==", "test_class", ")", ":", "\n", "            ", "count_of_test_class", "=", "count_of_test_class", "+", "1", "# n A", "\n", "", "else", ":", "\n", "            ", "count_of_false_positives", "=", "count_of_false_positives", "+", "1", "\n", "", "precs_x", "=", "count_of_test_class", "/", "(", "abs", "(", "j", ")", ")", "# N.b. this is the sum, we divide by j on the output", "\n", "recall_x", "=", "count_of_test_class", "/", "N_test", "\n", "false_pos_rate", "=", "count_of_false_positives", "/", "no_of_images", "\n", "specificity_x", "=", "1", "-", "false_pos_rate", "\n", "if", "(", "precs_x", "<=", ".95", ")", "and", "(", "found_recall_precs_p95", "is", "False", ")", ":", "\n", "# thingy to grab the recall when precision drops below .95 (if ever)", "\n", "            ", "recall_p95", "=", "recall_x", "\n", "found_recall_precs_p95", "=", "True", "\n", "", "delta_recall_x", "=", "recall_x", "-", "recall_x_minus_1", "# difference in recall between this point nd the next", "\n", "weight_precs_x", "=", "precs_x", "*", "delta_recall_x", "# weighted precsion at point x (we do average via weighted sum)", "\n", "Ave_precs_x", "=", "Ave_precs_x", "+", "weight_precs_x", "# average_precision evaluated at point x", "\n", "informedness_x", "=", "recall_x", "+", "specificity_x", "-", "1", "\n", "if", "informedness_x", ">", "max_informedness", ":", "\n", "            ", "max_informedness", "=", "informedness_x", "\n", "x_for_max_informedness", "=", "abs", "(", "j", ")", "\n", "recall_for_max_informedness", "=", "recall_x", "\n", "specificity_for_max_informedness", "=", "specificity_x", "\n", "", "if", "(", "precs_x", ">", "0", "and", "recall_x", ">", "0", ")", ":", "\n", "            ", "f1_x", "=", "2", "*", "(", "precs_x", "*", "recall_x", ")", "/", "(", "precs_x", "+", "recall_x", ")", "\n", "", "else", ":", "\n", "            ", "f1_x", "=", "0", "\n", "", "if", "f1_x", ">", "max_f1_stat", ":", "\n", "            ", "max_f1_stat", "=", "f1_x", "\n", "x_for_max_f1", "=", "abs", "(", "j", ")", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'Class {}, evaluated at Q={}:, found {}'", ".", "format", "(", "test_class", ",", "Q", ",", "count_of_test_class", ")", ")", "\n", "print", "(", "'Average precision={}; precision={}; recall={}'", ".", "format", "(", "Ave_precs_x", ",", "precs_x", ",", "recall_x", ")", ")", "\n", "print", "(", "'Recall at precision .95 threashold is {}'", ".", "format", "(", "recall_p95", ")", ")", "\n", "print", "(", "'specificity = {}'", ".", "format", "(", "specificity_x", ")", ")", "\n", "print", "(", "'informedness = {}'", ".", "format", "(", "informedness_x", ")", ")", "\n", "print", "(", "'Max informedness was {}, seen at x {}'", ".", "format", "(", "max_informedness", ",", "x_for_max_informedness", ")", ")", "\n", "print", "(", "'F1 at x={} is {}'", ".", "format", "(", "abs", "(", "j", ")", ",", "f1_x", ")", ")", "\n", "print", "(", "'Max F1 was {}, seen at x = {}'", ".", "format", "(", "max_f1_stat", ",", "x_for_max_f1", ")", ")", "\n", "", "out", "=", "(", "Ave_precs_x", ",", "precs_x", ",", "recall_x", ",", "recall_p95", ",", "\n", "specificity_x", ",", "informedness_x", ",", "max_informedness", ",", "x_for_max_informedness", ",", "\n", "max_f1_stat", ",", "x_for_max_f1", ",", "\n", "recall_for_max_informedness", ",", "specificity_for_max_informedness", ",", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.calculate_average_precision_incl_zeros": [[400, 429], ["len", "len", "precision_calulator.calculate_ave_precs_general", "precision_calulator.get_local_list_for_neuron", "print", "print", "print", "min"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.calculate_ave_precs_general", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.get_local_list_for_neuron"], ["", "def", "calculate_average_precision_incl_zeros", "(", "test_class", ",", "local_list", "=", "''", ",", "x_data", "=", "''", ",", "selected_activations", "=", "''", ",", "\n", "current_neuron_index", "=", "current_neuron_index", ",", "acts", "=", "acts", ",", "verbose", "=", "verbose", ")", ":", "\n", "    ", "\"\"\"Wrapper function to calculate the average precision when we have lots of zeros\"\"\"", "\n", "if", "local_list", "==", "''", ":", "\n", "# if you don't pass it in, get the data", "\n", "        ", "local_list", ",", "selected_activations", ",", "x_data", "=", "get_local_list_for_neuron", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "minx", "=", "0", ",", "\n", "acts", "=", "acts", ")", "\n", "", "total_no_of_points", "=", "len", "(", "x_data", ")", "\n", "no_of_points_selected", "=", "len", "(", "local_list", ")", "\n", "# grabs all points above 0 (special case)", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Taking all points above 0.0, minimum is {}'", ".", "format", "(", "min", "(", "selected_activations", ")", ")", ")", "\n", "", "Ave_precs_x", ",", "precs_x", ",", "recall_x", "=", "calculate_ave_precs_general", "(", "\n", "test_class", "=", "test_class", ",", "\n", "local_list", "=", "local_list", ",", "\n", "Q_stop", "=", "''", ",", "\n", "no_files_in_label", "=", "no_files_in_label", ",", "\n", "verbose", "=", "verbose", ")", "\n", "# this gives the values just above zero", "\n", "precs_all", "=", "no_files_in_label", "[", "test_class", "]", "/", "total_no_of_points", "#  a largely pointless measure", "\n", "recall_all", "=", "1.0", "\n", "delta_recall_all", "=", "recall_all", "-", "recall_x", "# difference in recall between this point nd the next", "\n", "weight_precs_all", "=", "precs_all", "*", "delta_recall_all", "# weighted precsion at point x (we do average via weighted sum)", "\n", "Ave_precs_all", "=", "Ave_precs_x", "+", "weight_precs_all", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Class {}, evaluated at Q={}:, found {}'", ".", "format", "(", "test_class", ",", "total_no_of_points", ",", "no_files_in_label", "[", "test_class", "]", ")", ")", "\n", "print", "(", "'Average precision={}; precision={}; recall={}'", ".", "format", "(", "Ave_precs_all", ",", "precs_all", ",", "recall_all", ")", ")", "\n", "", "return", "Ave_precs_all", ",", "precs_all", ",", "recall_all", ",", "Ave_precs_x", ",", "precs_x", ",", "recall_x", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.test_ave_precsision": [[431, 477], ["range", "print", "print", "print", "abs", "print", "print", "print", "print", "abs", "abs"], "function", ["None"], ["", "def", "test_ave_precsision", "(", "class_name", ",", "local_list", "=", "local_list", ")", ":", "\n", "#N_test = no_files_in_label[test_class] # no of items in class A", "\n", "# set up counters", "\n", "    ", "AP", "=", "0", "# average precision", "\n", "count_of_test_class", "=", "0", "\n", "# loop backwards through the list, abs j is the position in a 1-indexed list", "\n", "# values for i == -1", "\n", "#    current_class = local_list[-1][0]", "\n", "#    if (current_class == test_class):", "\n", "#        count_of_test_class = count_of_test_class + 1 # we found A", "\n", "#    precs_x = count_of_test_class /1", "\n", "egg", "=", "{", "'1'", ":", "6396", ",", "'7'", ":", "5964", ",", "'0'", ":", "5823", ",", "'6'", ":", "5636", ",", "'9'", ":", "5595", ",", "'3'", ":", "5396", ",", "'2'", ":", "5242", ",", "'8'", ":", "5219", ",", "'4'", ":", "5213", ",", "'5'", ":", "5030", "}", "\n", "N_test", "=", "egg", "[", "class_name", "]", "\n", "test_class", "=", "class_name", "\n", "verbose", "=", "True", "\n", "Q", "=", "55514", "\n", "recall_x", "=", "0", "\n", "Ave_precs_x", "=", "0", "\n", "for", "i", "in", "range", "(", "Q", ")", ":", "\n", "        ", "j", "=", "-", "(", "i", "+", "1", ")", "# 1 indexed", "\n", "recall_x_minus_1", "=", "recall_x", "\n", "current_class", "=", "local_list", "[", "j", "]", "[", "0", "]", "# current class", "\n", "if", "j", "==", "-", "Q", ":", "\n", "# if the whole of local_list is the same class (this accounts for zero indexing)", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "current_class", ")", "\n", "print", "(", "'{}/{}'", ".", "format", "(", "count_of_test_class", ",", "abs", "(", "j", ")", ")", ")", "\n", "", "j", "=", "j", "-", "1", "# really this is here so we can check j", "\n", "#break", "\n", "", "if", "count_of_test_class", "==", "N_test", ":", "\n", "#we've found them all", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'found all {} of {}, stopping...'", ".", "format", "(", "N_test", ",", "test_class", ")", ")", "\n", "print", "(", "'{}/{}'", ".", "format", "(", "count_of_test_class", ",", "abs", "(", "j", ")", ")", ")", "\n", "", "break", "\n", "", "if", "(", "current_class", "==", "test_class", ")", ":", "\n", "            ", "count_of_test_class", "=", "count_of_test_class", "+", "1", "#n A", "\n", "", "precs_x", "=", "count_of_test_class", "/", "(", "abs", "(", "j", ")", ")", "# N.b. this is the sum, we divide by j on the output", "\n", "recall_x", "=", "count_of_test_class", "/", "N_test", "\n", "delta_recall_x", "=", "recall_x", "-", "recall_x_minus_1", "# difference in recall between this point nd the next", "\n", "weight_precs_x", "=", "precs_x", "*", "delta_recall_x", "# weighted precsion at point x (we do average via weighted sum)", "\n", "Ave_precs_x", "=", "Ave_precs_x", "+", "weight_precs_x", "# average_precision evaluated at point x", "\n", "", "print", "(", "'precsionn = {}'", ".", "format", "(", "precs_x", ")", ")", "\n", "print", "(", "'recall = {}'", ".", "format", "(", "recall_x", ")", ")", "\n", "print", "(", "'average precsion = {}'", ".", "format", "(", "Ave_precs_x", ")", ")", "\n", "return", "Ave_precs_x", ",", "precs_x", ",", "recall_x", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.find_zhou_precision": [[478, 486], ["collections.Counter", "len", "range", "collections.Counter.most_common", "collections.Counter.most_common"], "function", ["None"], ["", "def", "find_zhou_precision", "(", "number_of_points", "=", "100", ",", "local_list", "=", "local_list", ")", ":", "\n", "    ", "\"\"\"Finds the maximally occuring (top mode) class in the top number_of_points and counts it\"\"\"", "\n", "classes_in_top_100", "=", "[", "local_list", "[", "x", "]", "[", "0", "]", "for", "x", "in", "range", "(", "-", "number_of_points", ",", "0", ")", "]", "\n", "zhou", "=", "Counter", "(", "classes_in_top_100", ")", "\n", "zhou_precs_class", "=", "zhou", ".", "most_common", "(", "1", ")", "[", "0", "]", "[", "0", "]", "# the class name", "\n", "zhou_precs", "=", "zhou", ".", "most_common", "(", "1", ")", "[", "0", "]", "[", "1", "]", "/", "number_of_points", "# the precision", "\n", "zhou_no_of_classes", "=", "len", "(", "zhou", ")", "\n", "return", "zhou_precs_class", ",", "zhou_precs", ",", "zhou_no_of_classes", ",", "zhou", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.get_max_index_of_list": [[487, 494], ["isinstance", "numpy.argmax", "isinstance", "a_list.index", "max"], "function", ["None"], ["", "def", "get_max_index_of_list", "(", "a_list", ")", ":", "\n", "    ", "\"\"\"I keep forgetting how to do this\"\"\"", "\n", "if", "isinstance", "(", "a_list", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "idx", "=", "np", ".", "argmax", "(", "a_list", ")", "\n", "", "elif", "isinstance", "(", "a_list", ",", "list", ")", ":", "\n", "        ", "idx", "=", "a_list", ".", "index", "(", "max", "(", "a_list", ")", ")", "\n", "", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.get_max_ave_precs": [[495, 510], ["precision_calulator.get_max_index_of_list", "precision_calulator.get_max_index_of_list", "len", "range", "range", "len", "len"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.get_max_index_of_list", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.get_max_index_of_list"], ["", "def", "get_max_ave_precs", "(", "class_list", "=", "test_class_list", ",", "output_precs_data", "=", "output_precs_data", ")", ":", "\n", "    ", "\"\"\"grabs the max class names and 2nd max class names\n    test_class_list = list of class names in the correct order\n    output_precs_data = list of values to get the max and second max of\"\"\"", "\n", "apL", "=", "[", "x", "[", "0", "]", "for", "x", "in", "output_precs_data", "]", "\n", "idx", "=", "get_max_index_of_list", "(", "apL", ")", "\n", "MaxApLClass", "=", "class_list", "[", "idx", "]", "\n", "if", "not", "len", "(", "class_list", ")", "==", "1", ":", "\n", "        ", "apL2", "=", "[", "apL", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "apL", ")", ")", "if", "not", "i", "==", "idx", "]", "\n", "class_list2", "=", "[", "class_list", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "class_list", ")", ")", "if", "not", "i", "==", "idx", "]", "\n", "idx", "=", "get_max_index_of_list", "(", "apL2", ")", "\n", "MaxApLClass2", "=", "class_list2", "[", "idx", "]", "\n", "", "else", ":", "\n", "        ", "MaxApLClass2", "=", "''", "\n", "", "return", "MaxApLClass", ",", "MaxApLClass2", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.count_zeros": [[511, 535], ["len", "sorted", "sorted", "min", "print", "len", "float", "nzeros_dict.items", "pzeros_dict.items", "operator.itemgetter", "operator.itemgetter"], "function", ["None"], ["", "def", "count_zeros", "(", "local_list", "=", "local_list", ",", "x_data", "=", "x_data", ",", "class_labels", "=", "class_labels", ",", "topx", "=", "10", ",", "verbose", "=", "verbose", ")", ":", "\n", "    ", "\"\"\"counts the zeros in a local_list\n    topx is the number of results to return, assuming the top-10\n    nzeros is the number of zeros\n    pzeros is the percentage of a class that is zero\n    \"\"\"", "\n", "# now do the zeros", "\n", "minx", ",", "maxx", ",", "nzeros_dict", ",", "pzeros_dict", "=", "min", "(", "x_data", ")", ",", "0.0", ",", "{", "}", ",", "{", "}", "\n", "# this gets all the zeros", "\n", "num_zeros", "=", "len", "(", "local_list", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Working on counting the zeros for all classes (slow!)'", ")", "\n", "", "for", "test_class", "in", "class_labels", ":", "\n", "# counts the number of zeros and percentage of zeros for each class", "\n", "        ", "nzero", "=", "len", "(", "[", "x", "for", "x", "in", "local_list", "if", "x", "[", "0", "]", "==", "test_class", "]", ")", "\n", "nzeros_dict", "[", "test_class", "]", "=", "nzero", "\n", "pzeros_dict", "[", "test_class", "]", "=", "float", "(", "nzero", "/", "no_files_in_label", "[", "test_class", "]", ")", "\n", "# sorts the lists so the classes with the least zeros are first", "\n", "", "nzeros", "=", "sorted", "(", "nzeros_dict", ".", "items", "(", ")", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ")", "\n", "pzeros", "=", "sorted", "(", "pzeros_dict", ".", "items", "(", ")", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ")", "\n", "# grab the top 10", "\n", "nzeros", "=", "nzeros", "[", "0", ":", "topx", "]", "\n", "pzeros", "=", "pzeros", "[", "0", ":", "topx", "]", "\n", "return", "num_zeros", ",", "nzeros", ",", "pzeros", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.main": [[542, 1424], ["Make_activation.main", "h5_analysis_jitterer.make_class_to_line_number_look_up_table", "sys.stdout.write", "sys.stdout.flush", "h5_analysis_jitterer.build_label_dict", "sys.stdout.write", "sys.stdout.flush", "acts.get_image_count", "print", "len", "print", "precision_calulator.get_max_ave_precs", "precision_calulator.get_max_ave_precs", "precision_calulator.get_max_ave_precs", "open", "csv.reader", "open", "csv.DictWriter", "csv.DictWriter.writeheader", "acts.get_activation", "len", "test_class_list.append", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "len", "test_class_list.append", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "len", "test_class_list.append", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "open", "csv.DictWriter", "csv.DictWriter.writeheader", "print", "current_range.append", "print", "open", "csv.DictWriter", "csv.DictWriter.writeheader", "int", "open", "csv.DictWriter", "csv.DictWriter.writeheader", "precision_calulator.get_local_list_for_neuron", "h5_analysis_jitterer.grab_points_for_a_cluster", "precision_calulator.find_zhou_precision", "precision_calulator.find_zhou_precision", "range", "precision_calulator.count_zeros", "precision_calulator.main.row1_outputter"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.main", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.make_class_to_line_number_look_up_table", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.build_label_dict", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_image_count", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.get_max_ave_precs", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.get_max_ave_precs", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.get_max_ave_precs", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.get_local_list_for_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_zhou_precision", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_zhou_precision", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calulator.count_zeros"], ["", "def", "main", "(", ")", ":", "\n", "\n", "\n", "\n", "    ", "m", ".", "main", "(", ")", "\n", "acts", "=", "m", ".", "acts", "\n", "class_labels", "=", "m", ".", "class_labels", "\n", "\n", "\n", "\n", "out_filename", "=", "'precs_data.csv'", "\n", "out_filename2", "=", "'precs_data_nonzero.csv'", "\n", "out_filename3", "=", "'precs_data_all.csv'", "\n", "out_filename4", "=", "'precs_data_zeros.csv'", "\n", "out_filename5", "=", "'precs_summary.csv'", "\n", "\n", "class_dict", "=", "h", ".", "make_class_to_line_number_look_up_table", "(", "class_labels", "=", "class_labels", ",", "verbose", "=", "False", ")", "\n", "# this builds the look-up table between points and the class they are in", "\n", "## This bit is sslow, it loads the label data for all acts", "\n", "sys", ".", "stdout", ".", "write", "(", "'About to build the label dict (slow)'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "label_dict", ",", "found_labels", ",", "no_files_in_label", "=", "h", ".", "build_label_dict", "(", "acts", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "'Built the label dict'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "no_of_images", "=", "acts", ".", "get_image_count", "(", ")", "\n", "print", "(", "'Found {} images'", ".", "format", "(", "no_of_images", ")", ")", "\n", "\n", "no_of_neurons", "=", "len", "(", "acts", ".", "get_activation", "(", "0", ")", ".", "vector", ")", "\n", "print", "(", "'{} neurons found'", ".", "format", "(", "no_of_neurons", ")", ")", "\n", "\n", "current_range", "=", "[", "]", "\n", "\n", "\n", "\n", "fieldnames", "=", "[", "'Neuron no.'", ",", "# neuron index", "\n", "'top_mode_class_name'", ",", "# class name for top mode class (class with highest number in top 100)", "\n", "'max_ave_precs_100_class'", ",", "\n", "'second_max_ave_precs_100_class'", ",", "\n", "'zhou_precs60'", ",", "# Zhou precision for the most common class in top 60", "\n", "'zhou_precs_class60'", ",", "# class for ZP60", "\n", "'zhou_no_of_classes100'", ",", "# no fo classes in top 100", "\n", "'1_class'", ",", "\n", "'1_Ave_precs_100'", ",", "#", "\n", "'1_precs_100'", ",", "\n", "'1_recall_100'", ",", "\n", "'1_recall_p95_100'", ",", "\n", "'1_specificity_100'", ",", "\n", "'1_informedness_100'", ",", "\n", "'1_max_informedness_100'", ",", "\n", "'1_x_for_max_informedness_100'", ",", "\n", "'1_max_f1_stat_100'", ",", "\n", "'1_x_for_max_f1_100'", ",", "\n", "'2_class'", ",", "\n", "'2_Ave_precs_100'", ",", "# start of x = 100 data for top 10 classes", "\n", "'2_precs_100'", ",", "\n", "'2_recall_100'", ",", "\n", "'2_recall_p95_100'", ",", "\n", "'2_specificity_100'", ",", "\n", "'2_informedness_100'", ",", "\n", "'2_max_informedness_100'", ",", "\n", "'2_x_for_max_informedness_100'", ",", "\n", "'2_max_f1_stat_100'", ",", "\n", "'2_x_for_max_f1_100'", ",", "\n", "'3_class'", ",", "\n", "'3_Ave_precs_100'", ",", "# start of x = 100 data for top 10 classes", "\n", "'3_precs_100'", ",", "\n", "'3_recall_100'", ",", "\n", "'3_recall_p95_100'", ",", "\n", "'3_specificity_100'", ",", "\n", "'3_informedness_100'", ",", "\n", "'3_max_informedness_100'", ",", "\n", "'3_x_for_max_informedness_100'", ",", "\n", "'3_max_f1_stat_100'", ",", "\n", "'3_x_for_max_f1_100'", ",", "\n", "'4_class'", ",", "\n", "'4_Ave_precs_100'", ",", "# start of x = 100 data for top 10 classes", "\n", "'4_precs_100'", ",", "\n", "'4_recall_100'", ",", "\n", "'4_recall_p95_100'", ",", "\n", "'4_specificity_100'", ",", "\n", "'4_informedness_100'", ",", "\n", "'4_max_informedness_100'", ",", "\n", "'4_x_for_max_informedness_100'", ",", "\n", "'4_max_f1_stat_100'", ",", "\n", "'4_x_for_max_f1_100'", ",", "\n", "'5_class'", ",", "\n", "'5_Ave_precs_100'", ",", "# start of x = 100 data for top 10 classes", "\n", "'5_precs_100'", ",", "\n", "'5_recall_100'", ",", "\n", "'5_recall_p95_100'", ",", "\n", "'5_specificity_100'", ",", "\n", "'5_informedness_100'", ",", "\n", "'5_max_informedness_100'", ",", "\n", "'5_x_for_max_informedness_100'", ",", "\n", "'5_max_f1_stat_100'", ",", "\n", "'5_x_for_max_f1_100'", ",", "\n", "'6_class'", ",", "\n", "'6_Ave_precs_100'", ",", "# start of x = 100 data for top 10 classes", "\n", "'6_precs_100'", ",", "\n", "'6_recall_100'", ",", "\n", "'6_recall_p95_100'", ",", "\n", "'6_specificity_100'", ",", "\n", "'6_informedness_100'", ",", "\n", "'6_max_informedness_100'", ",", "\n", "'6_x_for_max_informedness_100'", ",", "\n", "'6_max_f1_stat_100'", ",", "\n", "'6_x_for_max_f1_100'", ",", "\n", "'7_class'", ",", "\n", "'7_Ave_precs_100'", ",", "# start of x = 100 data for top 10 classes", "\n", "'7_precs_100'", ",", "\n", "'7_recall_100'", ",", "\n", "'7_recall_p95_100'", ",", "\n", "'7_specificity_100'", ",", "\n", "'7_informedness_100'", ",", "\n", "'7_max_informedness_100'", ",", "\n", "'7_x_for_max_informedness_100'", ",", "\n", "'7_max_f1_stat_100'", ",", "\n", "'7_x_for_max_f1_100'", ",", "\n", "'8_class'", ",", "\n", "'8_Ave_precs_100'", ",", "# start of x = 100 data for top 10 classes", "\n", "'8_precs_100'", ",", "\n", "'8_recall_100'", ",", "\n", "'8_recall_p95_100'", ",", "\n", "'8_specificity_100'", ",", "\n", "'8_informedness_100'", ",", "\n", "'8_max_informedness_100'", ",", "\n", "'8_x_for_max_informedness_100'", ",", "\n", "'8_max_f1_stat_100'", ",", "\n", "'8_x_for_max_f1_100'", ",", "\n", "'9_class'", ",", "\n", "'9_Ave_precs_100'", ",", "# start of x = 100 data for top 10 classes", "\n", "'9_precs_100'", ",", "\n", "'9_recall_100'", ",", "\n", "'9_recall_p95_100'", ",", "\n", "'9_specificity_100'", ",", "\n", "'9_informedness_100'", ",", "\n", "'9_max_informedness_100'", ",", "\n", "'9_x_for_max_informedness_100'", ",", "\n", "'9_max_f1_stat_100'", ",", "\n", "'9_x_for_max_f1_100'", ",", "\n", "'10_class'", ",", "\n", "'10_Ave_precs_100'", ",", "# start of x = 100 data for top 10 classes", "\n", "'10_precs_100'", ",", "\n", "'10_recall_100'", ",", "\n", "'10_recall_p95_100'", ",", "\n", "'10_specificity_100'", ",", "\n", "'10_informedness_100'", ",", "\n", "'10_max_informedness_100'", ",", "\n", "'10_x_for_max_informedness_100'", ",", "\n", "'10_max_f1_stat_100'", ",", "\n", "'10_x_for_max_f1_100'", "\n", "]", "\n", "\n", "\n", "fieldnames2", "=", "[", "'Neuron no.'", ",", "# neuron index", "\n", "'max_ave_precs_nonzero_class'", ",", "\n", "'second_max_ave_precs_nonzero_class'", ",", "\n", "'1_class'", ",", "\n", "'1_Ave_precs_nonzero'", ",", "#", "\n", "'1_precs_nonzero'", ",", "\n", "'1_recall_nonzero'", ",", "\n", "'1_recall_p95_nonzero'", ",", "\n", "'1_specificity_nonzero'", ",", "\n", "'1_informedness_nonzero'", ",", "\n", "'1_max_informedness_nonzero'", ",", "\n", "'1_x_for_max_informedness_nonzero'", ",", "\n", "'1_recall_for_max_informedness'", ",", "\n", "'1_specificity_for_max_informedness'", ",", "\n", "'1_max_f1_stat_nonzero'", ",", "\n", "'1_x_for_max_f1_nonzero'", ",", "\n", "'2_class'", ",", "\n", "'2_Ave_precs_nonzero'", ",", "# start of x = 100 data for top 10 classes", "\n", "'2_precs_nonzero'", ",", "\n", "'2_recall_nonzero'", ",", "\n", "'2_recall_p95_nonzero'", ",", "\n", "'2_specificity_nonzero'", ",", "\n", "'2_informedness_nonzero'", ",", "\n", "'2_max_informedness_nonzero'", ",", "\n", "'2_x_for_max_informedness_nonzero'", ",", "\n", "'2_recall_for_max_informedness'", ",", "\n", "'2_specificity_for_max_informedness'", ",", "\n", "'2_max_f1_stat_nonzero'", ",", "\n", "'2_x_for_max_f1_nonzero'", ",", "\n", "'3_class'", ",", "\n", "'3_Ave_precs_nonzero'", ",", "# start of x = 100 data for top 10 classes", "\n", "'3_precs_nonzero'", ",", "\n", "'3_recall_nonzero'", ",", "\n", "'3_recall_p95_nonzero'", ",", "\n", "'3_specificity_nonzero'", ",", "\n", "'3_informedness_nonzero'", ",", "\n", "'3_max_informedness_nonzero'", ",", "\n", "'3_x_for_max_informedness_nonzero'", ",", "\n", "'3_recall_for_max_informedness'", ",", "\n", "'3_specificity_for_max_informedness'", ",", "\n", "'3_max_f1_stat_nonzero'", ",", "\n", "'3_x_for_max_f1_nonzero'", ",", "\n", "'4_class'", ",", "\n", "'4_Ave_precs_nonzero'", ",", "# start of x = 100 data for top 10 classes", "\n", "'4_precs_nonzero'", ",", "\n", "'4_recall_nonzero'", ",", "\n", "'4_recall_p95_nonzero'", ",", "\n", "'4_specificity_nonzero'", ",", "\n", "'4_informedness_nonzero'", ",", "\n", "'4_max_informedness_nonzero'", ",", "\n", "'4_x_for_max_informedness_nonzero'", ",", "\n", "'4_recall_for_max_informedness'", ",", "\n", "'4_specificity_for_max_informedness'", ",", "\n", "'4_max_f1_stat_nonzero'", ",", "\n", "'4_x_for_max_f1_nonzero'", ",", "\n", "'5_class'", ",", "\n", "'5_Ave_precs_nonzero'", ",", "# start of x = 100 data for top 10 classes", "\n", "'5_precs_nonzero'", ",", "\n", "'5_recall_nonzero'", ",", "\n", "'5_recall_p95_nonzero'", ",", "\n", "'5_specificity_nonzero'", ",", "\n", "'5_informedness_nonzero'", ",", "\n", "'5_max_informedness_nonzero'", ",", "\n", "'5_x_for_max_informedness_nonzero'", ",", "\n", "'5_recall_for_max_informedness'", ",", "\n", "'5_specificity_for_max_informedness'", ",", "\n", "'5_max_f1_stat_nonzero'", ",", "\n", "'5_x_for_max_f1_nonzero'", ",", "\n", "'6_class'", ",", "\n", "'6_Ave_precs_nonzero'", ",", "# start of x = 100 data for top 10 classes", "\n", "'6_precs_nonzero'", ",", "\n", "'6_recall_nonzero'", ",", "\n", "'6_recall_p95_nonzero'", ",", "\n", "'6_specificity_nonzero'", ",", "\n", "'6_informedness_nonzero'", ",", "\n", "'6_max_informedness_nonzero'", ",", "\n", "'6_x_for_max_informedness_nonzero'", ",", "\n", "'6_recall_for_max_informedness'", ",", "\n", "'6_specificity_for_max_informedness'", ",", "\n", "'6_max_f1_stat_nonzero'", ",", "\n", "'6_x_for_max_f1_nonzero'", ",", "\n", "'7_class'", ",", "\n", "'7_Ave_precs_nonzero'", ",", "# start of x = 100 data for top 10 classes", "\n", "'7_precs_nonzero'", ",", "\n", "'7_recall_nonzero'", ",", "\n", "'7_recall_p95_nonzero'", ",", "\n", "'7_specificity_nonzero'", ",", "\n", "'7_informedness_nonzero'", ",", "\n", "'7_max_informedness_nonzero'", ",", "\n", "'7_x_for_max_informedness_nonzero'", ",", "\n", "'7_recall_for_max_informedness'", ",", "\n", "'7_specificity_for_max_informedness'", ",", "\n", "'7_max_f1_stat_nonzero'", ",", "\n", "'7_x_for_max_f1_nonzero'", ",", "\n", "'8_class'", ",", "\n", "'8_Ave_precs_nonzero'", ",", "# start of x = 100 data for top 10 classes", "\n", "'8_precs_nonzero'", ",", "\n", "'8_recall_nonzero'", ",", "\n", "'8_recall_p95_nonzero'", ",", "\n", "'8_specificity_nonzero'", ",", "\n", "'8_informedness_nonzero'", ",", "\n", "'8_max_informedness_nonzero'", ",", "\n", "'8_x_for_max_informedness_nonzero'", ",", "\n", "'8_recall_for_max_informedness'", ",", "\n", "'8_specificity_for_max_informedness'", ",", "\n", "'8_max_f1_stat_nonzero'", ",", "\n", "'8_x_for_max_f1_nonzero'", ",", "\n", "'9_class'", ",", "\n", "'9_Ave_precs_nonzero'", ",", "# start of x = 100 data for top 10 classes", "\n", "'9_precs_nonzero'", ",", "\n", "'9_recall_nonzero'", ",", "\n", "'9_recall_p95_nonzero'", ",", "\n", "'9_specificity_nonzero'", ",", "\n", "'9_informedness_nonzero'", ",", "\n", "'9_max_informedness_nonzero'", ",", "\n", "'9_x_for_max_informedness_nonzero'", ",", "\n", "'9_recall_for_max_informedness'", ",", "\n", "'9_specificity_for_max_informedness'", ",", "\n", "'9_max_f1_stat_nonzero'", ",", "\n", "'9_x_for_max_f1_nonzero'", ",", "\n", "'10_class'", ",", "\n", "'10_Ave_precs_nonzero'", ",", "# start of x = 100 data for top 10 classes", "\n", "'10_precs_nonzero'", ",", "\n", "'10_recall_nonzero'", ",", "\n", "'10_recall_p95_nonzero'", ",", "\n", "'10_specificity_nonzero'", ",", "\n", "'10_informedness_nonzero'", ",", "\n", "'10_max_informedness_nonzero'", ",", "\n", "'10_x_for_max_informedness_nonzero'", ",", "\n", "'10_recall_for_max_informedness'", ",", "\n", "'10_specificity_for_max_informedness'", ",", "\n", "'10_max_f1_stat_nonzero'", ",", "\n", "'10_x_for_max_f1_nonzero'", "\n", "]", "\n", "\n", "fieldnames3", "=", "[", "'Neuron no.'", ",", "# neuron index", "\n", "'max_ave_precs_all_class'", ",", "\n", "'second_max_ave_precs_all_class'", ",", "\n", "'1_class'", ",", "\n", "'1_Ave_precs_all'", ",", "# start of x = 100 data for top 10 classes", "\n", "'1_precs_all'", ",", "\n", "'1_recall_all'", ",", "\n", "'2_class'", ",", "\n", "'2_Ave_precs_all'", ",", "# start of x = 100 data for top 10 classes", "\n", "'2_precs_all'", ",", "\n", "'2_recall_all'", ",", "\n", "'3_class'", ",", "\n", "'3_Ave_precs_all'", ",", "# start of x = 100 data for top 10 classes", "\n", "'3_precs_all'", ",", "\n", "'3_recall_all'", ",", "\n", "'4_class'", ",", "\n", "'4_Ave_precs_all'", ",", "# start of x = 100 data for top 10 classes", "\n", "'4_precs_all'", ",", "\n", "'4_recall_all'", ",", "\n", "'5_class'", ",", "\n", "'5_Ave_precs_all'", ",", "# start of x = 100 data for top 10 classes", "\n", "'5_precs_all'", ",", "\n", "'5_recall_all'", ",", "\n", "'6_class'", ",", "\n", "'6_Ave_precs_all'", ",", "# start of x = 100 data for top 10 classes", "\n", "'6_precs_all'", ",", "\n", "'6_recall_all'", ",", "\n", "'7_class'", ",", "\n", "'7_Ave_precs_all'", ",", "# start of x = 100 data for top 10 classes", "\n", "'7_precs_all'", ",", "\n", "'7_recall_all'", ",", "\n", "'8_class'", ",", "\n", "'8_Ave_precs_all'", ",", "# start of x = 100 data for top 10 classes", "\n", "'8_precs_all'", ",", "\n", "'8_recall_all'", ",", "\n", "'9_class'", ",", "\n", "'9_Ave_precs_all'", ",", "# start of x = 100 data for top 10 classes", "\n", "'9_precs_all'", ",", "\n", "'9_recall_all'", ",", "\n", "'10_class'", ",", "\n", "'10_Ave_precs_all'", ",", "# start of x = 100 data for top 10 classes", "\n", "'10_precs_all'", ",", "\n", "'10_recall_all'", "\n", "]", "\n", "\n", "fieldnames4", "=", "[", "'Neuron no.'", ",", "# neuron index", "\n", "'num_zeros'", ",", "\n", "'1_least_zero_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'1_least_zero_num'", ",", "\n", "'2_least_zero_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'2_least_zero_num'", ",", "\n", "'3_least_zero_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'3_least_zero_num'", ",", "\n", "'4_least_zero_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'4_least_zero_num'", ",", "\n", "'5_least_zero_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'5_least_zero_num'", ",", "\n", "'6_least_zero_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'6_least_zero_num'", ",", "\n", "'7_least_zero_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'7_least_zero_num'", ",", "\n", "'8_least_zero_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'8_least_zero_num'", ",", "\n", "'9_least_zero_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'9_least_zero_num'", ",", "\n", "'10_least_zero_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'10_least_zero_num'", ",", "\n", "'1_least_zero_prop_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'1_least_zero_prop_num'", ",", "\n", "'2_least_zero_prop_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'2_least_zero_prop_num'", ",", "\n", "'3_least_zero_prop_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'3_least_zero_prop_num'", ",", "\n", "'4_least_zero_prop_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'4_least_zero_prop_num'", ",", "\n", "'5_least_zero_prop_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'5_least_zero_prop_num'", ",", "\n", "'6_least_zero_prop_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'6_least_zero_prop_num'", ",", "\n", "'7_least_zero_prop_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'7_least_zero_prop_num'", ",", "\n", "'8_least_zero_prop_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'8_least_zero_prop_num'", ",", "\n", "'9_least_zero_prop_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'9_least_zero_prop_num'", ",", "\n", "'10_least_zero_prop_class'", ",", "# start of x = 100 data for top 10 classes", "\n", "'10_least_zero_prop_num'", "\n", "]", "\n", "\n", "def", "row1_outputter", "(", "current_neuron_index", "=", "current_neuron_index", ",", "top_mode_class", "=", "top_mode_class", ",", "zhou_precs60", "=", "zhou_precs60", ",", "\n", "zhou_precs_class60", "=", "zhou_precs_class60", ",", "zhou_no_of_classes100", "=", "zhou_no_of_classes100", ",", "\n", "output_precs_data", "=", "output_precs_data", ",", "test_class_list", "=", "test_class_list", ")", ":", "\n", "        ", "\"\"\"Little wrapper function to write out the row\n        this is the stats over the top 100 activations!\"\"\"", "\n", "max_ave_precs_100_class", ",", "second_max_ave_precs_100_class", "=", "get_max_ave_precs", "(", "class_list", "=", "test_class_list", ",", "output_precs_data", "=", "output_precs_data", ")", "\n", "while", "len", "(", "test_class_list", ")", "<", "10", ":", "\n", "            ", "test_class_list", ".", "append", "(", "''", ")", "\n", "", "row", "=", "{", "'Neuron no.'", ":", "str", "(", "current_neuron_index", ")", ",", "# neuron index", "\n", "'top_mode_class_name'", ":", "str", "(", "top_mode_class", ")", ",", "# class name for top mode class (class with highest number in top 100)", "\n", "'max_ave_precs_100_class'", ":", "str", "(", "max_ave_precs_100_class", ")", ",", "\n", "'second_max_ave_precs_100_class'", ":", "str", "(", "second_max_ave_precs_100_class", ")", ",", "\n", "'zhou_precs60'", ":", "str", "(", "zhou_precs60", ")", ",", "# Zhou precision for the most common class in top 60", "\n", "'zhou_precs_class60'", ":", "str", "(", "zhou_precs_class60", ")", ",", "# class for ZP60", "\n", "'zhou_no_of_classes100'", ":", "str", "(", "zhou_no_of_classes100", ")", ",", "# no fo classes in top 100,", "\n", "'1_class'", ":", "str", "(", "test_class_list", "[", "0", "]", ")", ",", "\n", "'1_Ave_precs_100'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'1_precs_100'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "1", "]", ")", ",", "\n", "'1_recall_100'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "2", "]", ")", ",", "\n", "'1_recall_p95_100'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "3", "]", ")", ",", "\n", "'1_specificity_100'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "4", "]", ")", ",", "\n", "'1_informedness_100'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "5", "]", ")", ",", "\n", "'1_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "6", "]", ")", ",", "\n", "'1_x_for_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "7", "]", ")", ",", "\n", "'1_max_f1_stat_100'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "8", "]", ")", ",", "\n", "'1_x_for_max_f1_100'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "9", "]", ")", ",", "\n", "'2_class'", ":", "str", "(", "test_class_list", "[", "1", "]", ")", ",", "\n", "'2_Ave_precs_100'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'2_precs_100'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "1", "]", ")", ",", "\n", "'2_recall_100'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "2", "]", ")", ",", "\n", "'2_recall_p95_100'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "3", "]", ")", ",", "\n", "'2_specificity_100'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "4", "]", ")", ",", "\n", "'2_informedness_100'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "5", "]", ")", ",", "\n", "'2_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "6", "]", ")", ",", "\n", "'2_x_for_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "7", "]", ")", ",", "\n", "'2_max_f1_stat_100'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "8", "]", ")", ",", "\n", "'2_x_for_max_f1_100'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "9", "]", ")", ",", "\n", "'3_class'", ":", "str", "(", "test_class_list", "[", "2", "]", ")", ",", "\n", "'3_Ave_precs_100'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'3_precs_100'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "1", "]", ")", ",", "\n", "'3_recall_100'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "2", "]", ")", ",", "\n", "'3_recall_p95_100'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "3", "]", ")", ",", "\n", "'3_specificity_100'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "4", "]", ")", ",", "\n", "'3_informedness_100'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "5", "]", ")", ",", "\n", "'3_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "6", "]", ")", ",", "\n", "'3_x_for_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "7", "]", ")", ",", "\n", "'3_max_f1_stat_100'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "8", "]", ")", ",", "\n", "'3_x_for_max_f1_100'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "9", "]", ")", ",", "\n", "'4_class'", ":", "str", "(", "test_class_list", "[", "3", "]", ")", ",", "\n", "'4_Ave_precs_100'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'4_precs_100'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "1", "]", ")", ",", "\n", "'4_recall_100'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "2", "]", ")", ",", "\n", "'4_recall_p95_100'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "3", "]", ")", ",", "\n", "'4_specificity_100'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "4", "]", ")", ",", "\n", "'4_informedness_100'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "5", "]", ")", ",", "\n", "'4_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "6", "]", ")", ",", "\n", "'4_x_for_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "7", "]", ")", ",", "\n", "'4_max_f1_stat_100'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "8", "]", ")", ",", "\n", "'4_x_for_max_f1_100'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "9", "]", ")", ",", "\n", "'5_class'", ":", "str", "(", "test_class_list", "[", "4", "]", ")", ",", "\n", "'5_Ave_precs_100'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'5_precs_100'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "1", "]", ")", ",", "\n", "'5_recall_100'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "2", "]", ")", ",", "\n", "'5_recall_p95_100'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "3", "]", ")", ",", "\n", "'5_specificity_100'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "4", "]", ")", ",", "\n", "'5_informedness_100'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "5", "]", ")", ",", "\n", "'5_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "6", "]", ")", ",", "\n", "'5_x_for_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "7", "]", ")", ",", "\n", "'5_max_f1_stat_100'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "8", "]", ")", ",", "\n", "'5_x_for_max_f1_100'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "9", "]", ")", ",", "\n", "'6_class'", ":", "str", "(", "test_class_list", "[", "5", "]", ")", ",", "\n", "'6_Ave_precs_100'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'6_precs_100'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "1", "]", ")", ",", "\n", "'6_recall_100'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "2", "]", ")", ",", "\n", "'6_recall_p95_100'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "3", "]", ")", ",", "\n", "'6_specificity_100'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "4", "]", ")", ",", "\n", "'6_informedness_100'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "5", "]", ")", ",", "\n", "'6_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "6", "]", ")", ",", "\n", "'6_x_for_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "7", "]", ")", ",", "\n", "'6_max_f1_stat_100'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "8", "]", ")", ",", "\n", "'6_x_for_max_f1_100'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "9", "]", ")", ",", "\n", "'7_class'", ":", "str", "(", "test_class_list", "[", "6", "]", ")", ",", "\n", "'7_Ave_precs_100'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'7_precs_100'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "1", "]", ")", ",", "\n", "'7_recall_100'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "2", "]", ")", ",", "\n", "'7_recall_p95_100'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "3", "]", ")", ",", "\n", "'7_specificity_100'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "4", "]", ")", ",", "\n", "'7_informedness_100'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "5", "]", ")", ",", "\n", "'7_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "6", "]", ")", ",", "\n", "'7_x_for_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "7", "]", ")", ",", "\n", "'7_max_f1_stat_100'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "8", "]", ")", ",", "\n", "'7_x_for_max_f1_100'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "9", "]", ")", ",", "\n", "'8_class'", ":", "str", "(", "test_class_list", "[", "7", "]", ")", ",", "\n", "'8_Ave_precs_100'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'8_precs_100'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "1", "]", ")", ",", "\n", "'8_recall_100'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "2", "]", ")", ",", "\n", "'8_recall_p95_100'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "3", "]", ")", ",", "\n", "'8_specificity_100'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "4", "]", ")", ",", "\n", "'8_informedness_100'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "5", "]", ")", ",", "\n", "'8_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "6", "]", ")", ",", "\n", "'8_x_for_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "7", "]", ")", ",", "\n", "'8_max_f1_stat_100'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "8", "]", ")", ",", "\n", "'8_x_for_max_f1_100'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "9", "]", ")", ",", "\n", "'9_class'", ":", "str", "(", "test_class_list", "[", "8", "]", ")", ",", "\n", "'9_Ave_precs_100'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'9_precs_100'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "1", "]", ")", ",", "\n", "'9_recall_100'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "2", "]", ")", ",", "\n", "'9_recall_p95_100'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "3", "]", ")", ",", "\n", "'9_specificity_100'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "4", "]", ")", ",", "\n", "'9_informedness_100'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "5", "]", ")", ",", "\n", "'9_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "6", "]", ")", ",", "\n", "'9_x_for_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "7", "]", ")", ",", "\n", "'9_max_f1_stat_100'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "8", "]", ")", ",", "\n", "'9_x_for_max_f1_100'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "9", "]", ")", ",", "\n", "'10_class'", ":", "str", "(", "test_class_list", "[", "9", "]", ")", ",", "\n", "'10_Ave_precs_100'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'10_precs_100'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "1", "]", ")", ",", "\n", "'10_recall_100'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "2", "]", ")", ",", "\n", "'10_recall_p95_100'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "3", "]", ")", ",", "\n", "'10_specificity_100'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "4", "]", ")", ",", "\n", "'10_informedness_100'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "5", "]", ")", ",", "\n", "'10_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "6", "]", ")", ",", "\n", "'10_x_for_max_informedness_100'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "7", "]", ")", ",", "\n", "'10_max_f1_stat_100'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "8", "]", ")", ",", "\n", "'10_x_for_max_f1_100'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "9", "]", ")", "\n", "}", "\n", "return", "row", "\n", "\n", "", "def", "row2_outputter", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "output_precs_data", "=", "output_precs_data", ",", "test_class_list", "=", "test_class_list", ")", ":", "\n", "        ", "max_ave_precs_nonzero_class", ",", "second_max_ave_precs_nonzero_class", "=", "get_max_ave_precs", "(", "class_list", "=", "test_class_list", ",", "output_precs_data", "=", "output_precs_data", ")", "\n", "while", "len", "(", "test_class_list", ")", "<", "10", ":", "\n", "            ", "test_class_list", ".", "append", "(", "''", ")", "\n", "", "row", "=", "{", "'Neuron no.'", ":", "str", "(", "current_neuron_index", ")", ",", "# neuron index", "\n", "'max_ave_precs_nonzero_class'", ":", "str", "(", "max_ave_precs_nonzero_class", ")", ",", "\n", "'second_max_ave_precs_nonzero_class'", ":", "str", "(", "second_max_ave_precs_nonzero_class", ")", ",", "\n", "'1_class'", ":", "str", "(", "test_class_list", "[", "0", "]", ")", ",", "\n", "'1_Ave_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'1_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "1", "]", ")", ",", "\n", "'1_recall_nonzero'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "2", "]", ")", ",", "\n", "'1_recall_p95_nonzero'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "3", "]", ")", ",", "\n", "'1_specificity_nonzero'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "4", "]", ")", ",", "\n", "'1_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "5", "]", ")", ",", "\n", "'1_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "6", "]", ")", ",", "\n", "'1_x_for_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "7", "]", ")", ",", "\n", "'1_max_f1_stat_nonzero'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "8", "]", ")", ",", "\n", "'1_x_for_max_f1_nonzero'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "9", "]", ")", ",", "\n", "'1_recall_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "10", "]", ")", ",", "\n", "'1_specificity_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "11", "]", ")", ",", "\n", "'2_class'", ":", "str", "(", "test_class_list", "[", "1", "]", ")", ",", "\n", "'2_Ave_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'2_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "1", "]", ")", ",", "\n", "'2_recall_nonzero'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "2", "]", ")", ",", "\n", "'2_recall_p95_nonzero'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "3", "]", ")", ",", "\n", "'2_specificity_nonzero'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "4", "]", ")", ",", "\n", "'2_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "5", "]", ")", ",", "\n", "'2_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "6", "]", ")", ",", "\n", "'2_x_for_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "7", "]", ")", ",", "\n", "'2_max_f1_stat_nonzero'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "8", "]", ")", ",", "\n", "'2_x_for_max_f1_nonzero'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "9", "]", ")", ",", "\n", "'2_recall_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "10", "]", ")", ",", "\n", "'2_specificity_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "11", "]", ")", ",", "\n", "'3_class'", ":", "str", "(", "test_class_list", "[", "2", "]", ")", ",", "\n", "'3_Ave_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'3_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "1", "]", ")", ",", "\n", "'3_recall_nonzero'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "2", "]", ")", ",", "\n", "'3_recall_p95_nonzero'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "3", "]", ")", ",", "\n", "'3_specificity_nonzero'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "4", "]", ")", ",", "\n", "'3_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "5", "]", ")", ",", "\n", "'3_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "6", "]", ")", ",", "\n", "'3_x_for_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "7", "]", ")", ",", "\n", "'3_max_f1_stat_nonzero'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "8", "]", ")", ",", "\n", "'3_x_for_max_f1_nonzero'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "9", "]", ")", ",", "\n", "'3_recall_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "10", "]", ")", ",", "\n", "'3_specificity_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "11", "]", ")", ",", "\n", "'4_class'", ":", "str", "(", "test_class_list", "[", "3", "]", ")", ",", "\n", "'4_Ave_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'4_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "1", "]", ")", ",", "\n", "'4_recall_nonzero'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "2", "]", ")", ",", "\n", "'4_recall_p95_nonzero'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "3", "]", ")", ",", "\n", "'4_specificity_nonzero'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "4", "]", ")", ",", "\n", "'4_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "5", "]", ")", ",", "\n", "'4_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "6", "]", ")", ",", "\n", "'4_x_for_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "7", "]", ")", ",", "\n", "'4_max_f1_stat_nonzero'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "8", "]", ")", ",", "\n", "'4_x_for_max_f1_nonzero'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "9", "]", ")", ",", "\n", "'4_recall_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "10", "]", ")", ",", "\n", "'4_specificity_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "11", "]", ")", ",", "\n", "'5_class'", ":", "str", "(", "test_class_list", "[", "4", "]", ")", ",", "\n", "'5_Ave_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'5_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "1", "]", ")", ",", "\n", "'5_recall_nonzero'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "2", "]", ")", ",", "\n", "'5_recall_p95_nonzero'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "3", "]", ")", ",", "\n", "'5_specificity_nonzero'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "4", "]", ")", ",", "\n", "'5_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "5", "]", ")", ",", "\n", "'5_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "6", "]", ")", ",", "\n", "'5_x_for_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "7", "]", ")", ",", "\n", "'5_max_f1_stat_nonzero'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "8", "]", ")", ",", "\n", "'5_x_for_max_f1_nonzero'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "9", "]", ")", ",", "\n", "'5_recall_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "10", "]", ")", ",", "\n", "'5_specificity_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "11", "]", ")", ",", "\n", "'6_class'", ":", "str", "(", "test_class_list", "[", "5", "]", ")", ",", "\n", "'6_Ave_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'6_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "1", "]", ")", ",", "\n", "'6_recall_nonzero'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "2", "]", ")", ",", "\n", "'6_recall_p95_nonzero'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "3", "]", ")", ",", "\n", "'6_specificity_nonzero'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "4", "]", ")", ",", "\n", "'6_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "5", "]", ")", ",", "\n", "'6_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "6", "]", ")", ",", "\n", "'6_x_for_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "7", "]", ")", ",", "\n", "'6_max_f1_stat_nonzero'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "8", "]", ")", ",", "\n", "'6_x_for_max_f1_nonzero'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "9", "]", ")", ",", "\n", "'6_recall_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "10", "]", ")", ",", "\n", "'6_specificity_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "11", "]", ")", ",", "\n", "'7_class'", ":", "str", "(", "test_class_list", "[", "6", "]", ")", ",", "\n", "'7_Ave_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'7_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "1", "]", ")", ",", "\n", "'7_recall_nonzero'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "2", "]", ")", ",", "\n", "'7_recall_p95_nonzero'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "3", "]", ")", ",", "\n", "'7_specificity_nonzero'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "4", "]", ")", ",", "\n", "'7_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "5", "]", ")", ",", "\n", "'7_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "6", "]", ")", ",", "\n", "'7_x_for_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "7", "]", ")", ",", "\n", "'7_max_f1_stat_nonzero'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "8", "]", ")", ",", "\n", "'7_x_for_max_f1_nonzero'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "9", "]", ")", ",", "\n", "'7_recall_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "10", "]", ")", ",", "\n", "'7_specificity_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "11", "]", ")", ",", "\n", "'8_class'", ":", "str", "(", "test_class_list", "[", "7", "]", ")", ",", "\n", "'8_Ave_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'8_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "1", "]", ")", ",", "\n", "'8_recall_nonzero'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "2", "]", ")", ",", "\n", "'8_recall_p95_nonzero'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "3", "]", ")", ",", "\n", "'8_specificity_nonzero'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "4", "]", ")", ",", "\n", "'8_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "5", "]", ")", ",", "\n", "'8_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "6", "]", ")", ",", "\n", "'8_x_for_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "7", "]", ")", ",", "\n", "'8_max_f1_stat_nonzero'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "8", "]", ")", ",", "\n", "'8_x_for_max_f1_nonzero'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "9", "]", ")", ",", "\n", "'8_recall_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "10", "]", ")", ",", "\n", "'8_specificity_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "11", "]", ")", ",", "\n", "'9_class'", ":", "str", "(", "test_class_list", "[", "8", "]", ")", ",", "\n", "'9_Ave_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'9_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "1", "]", ")", ",", "\n", "'9_recall_nonzero'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "2", "]", ")", ",", "\n", "'9_recall_p95_nonzero'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "3", "]", ")", ",", "\n", "'9_specificity_nonzero'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "4", "]", ")", ",", "\n", "'9_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "5", "]", ")", ",", "\n", "'9_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "6", "]", ")", ",", "\n", "'9_x_for_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "7", "]", ")", ",", "\n", "'9_max_f1_stat_nonzero'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "8", "]", ")", ",", "\n", "'9_x_for_max_f1_nonzero'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "9", "]", ")", ",", "\n", "'9_recall_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "10", "]", ")", ",", "\n", "'9_specificity_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "11", "]", ")", ",", "\n", "'10_class'", ":", "str", "(", "test_class_list", "[", "9", "]", ")", ",", "\n", "'10_Ave_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'10_precs_nonzero'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "1", "]", ")", ",", "\n", "'10_recall_nonzero'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "2", "]", ")", ",", "\n", "'10_recall_p95_nonzero'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "3", "]", ")", ",", "\n", "'10_specificity_nonzero'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "4", "]", ")", ",", "\n", "'10_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "5", "]", ")", ",", "\n", "'10_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "6", "]", ")", ",", "\n", "'10_x_for_max_informedness_nonzero'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "7", "]", ")", ",", "\n", "'10_max_f1_stat_nonzero'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "8", "]", ")", ",", "\n", "'10_x_for_max_f1_nonzero'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "9", "]", ")", ",", "\n", "'10_recall_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "10", "]", ")", ",", "\n", "'10_specificity_for_max_informedness'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "11", "]", ")", "\n", "}", "\n", "return", "row", "\n", "\n", "\n", "", "def", "row3_outputter", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "output_precs_data", "=", "output_precs_data", ",", "test_class_list", "=", "test_class_list", ")", ":", "\n", "        ", "max_ave_precs_all_class", ",", "second_max_ave_precs_all_class", "=", "get_max_ave_precs", "(", "class_list", "=", "test_class_list", ",", "output_precs_data", "=", "output_precs_data", ")", "\n", "while", "len", "(", "test_class_list", ")", "<", "10", ":", "\n", "            ", "test_class_list", ".", "append", "(", "''", ")", "\n", "", "row", "=", "{", "'Neuron no.'", ":", "str", "(", "current_neuron_index", ")", ",", "# neuron index", "\n", "'max_ave_precs_all_class'", ":", "str", "(", "max_ave_precs_all_class", ")", ",", "\n", "'second_max_ave_precs_all_class'", ":", "str", "(", "second_max_ave_precs_all_class", ")", ",", "\n", "'1_class'", ":", "str", "(", "test_class_list", "[", "0", "]", ")", ",", "\n", "'1_Ave_precs_all'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'1_precs_all'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "1", "]", ")", ",", "\n", "'1_recall_all'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "2", "]", ")", ",", "\n", "'2_class'", ":", "str", "(", "test_class_list", "[", "1", "]", ")", ",", "\n", "'2_Ave_precs_all'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'2_precs_all'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "1", "]", ")", ",", "\n", "'2_recall_all'", ":", "str", "(", "output_precs_data", "[", "1", "]", "[", "2", "]", ")", ",", "\n", "'3_class'", ":", "str", "(", "test_class_list", "[", "2", "]", ")", ",", "\n", "'3_Ave_precs_all'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'3_precs_all'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "1", "]", ")", ",", "\n", "'3_recall_all'", ":", "str", "(", "output_precs_data", "[", "2", "]", "[", "2", "]", ")", ",", "\n", "'4_class'", ":", "str", "(", "test_class_list", "[", "3", "]", ")", ",", "\n", "'4_Ave_precs_all'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'4_precs_all'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "1", "]", ")", ",", "\n", "'4_recall_all'", ":", "str", "(", "output_precs_data", "[", "3", "]", "[", "2", "]", ")", ",", "\n", "'5_class'", ":", "str", "(", "test_class_list", "[", "4", "]", ")", ",", "\n", "'5_Ave_precs_all'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'5_precs_all'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "1", "]", ")", ",", "\n", "'5_recall_all'", ":", "str", "(", "output_precs_data", "[", "4", "]", "[", "2", "]", ")", ",", "\n", "'6_class'", ":", "str", "(", "test_class_list", "[", "5", "]", ")", ",", "\n", "'6_Ave_precs_all'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'6_precs_all'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "1", "]", ")", ",", "\n", "'6_recall_all'", ":", "str", "(", "output_precs_data", "[", "5", "]", "[", "2", "]", ")", ",", "\n", "'7_class'", ":", "str", "(", "test_class_list", "[", "6", "]", ")", ",", "\n", "'7_Ave_precs_all'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'7_precs_all'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "1", "]", ")", ",", "\n", "'7_recall_all'", ":", "str", "(", "output_precs_data", "[", "6", "]", "[", "2", "]", ")", ",", "\n", "'8_class'", ":", "str", "(", "test_class_list", "[", "7", "]", ")", ",", "\n", "'8_Ave_precs_all'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'8_precs_all'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "1", "]", ")", ",", "\n", "'8_recall_all'", ":", "str", "(", "output_precs_data", "[", "7", "]", "[", "2", "]", ")", ",", "\n", "'9_class'", ":", "str", "(", "test_class_list", "[", "8", "]", ")", ",", "\n", "'9_Ave_precs_all'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'9_precs_all'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "1", "]", ")", ",", "\n", "'9_recall_all'", ":", "str", "(", "output_precs_data", "[", "8", "]", "[", "2", "]", ")", ",", "\n", "'10_class'", ":", "str", "(", "test_class_list", "[", "9", "]", ")", ",", "\n", "'10_Ave_precs_all'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'10_precs_all'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "1", "]", ")", ",", "\n", "'10_recall_all'", ":", "str", "(", "output_precs_data", "[", "9", "]", "[", "2", "]", ")", ",", "\n", "}", "\n", "return", "row", "\n", "\n", "", "def", "row4_outputter", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "nzeros", "=", "nzeros", ",", "pzeros", "=", "pzeros", ",", "num_zeros", "=", "num_zeros", ")", ":", "\n", "        ", "row", "=", "{", "'Neuron no.'", ":", "str", "(", "current_neuron_index", ")", ",", "# neuron index", "\n", "'num_zeros'", ":", "str", "(", "num_zeros", ")", ",", "\n", "'1_least_zero_class'", ":", "str", "(", "nzeros", "[", "0", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'1_least_zero_num'", ":", "str", "(", "nzeros", "[", "0", "]", "[", "1", "]", ")", ",", "\n", "'2_least_zero_class'", ":", "str", "(", "nzeros", "[", "1", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'2_least_zero_num'", ":", "str", "(", "nzeros", "[", "1", "]", "[", "1", "]", ")", ",", "\n", "'3_least_zero_class'", ":", "str", "(", "nzeros", "[", "2", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'3_least_zero_num'", ":", "str", "(", "nzeros", "[", "2", "]", "[", "1", "]", ")", ",", "\n", "'4_least_zero_class'", ":", "str", "(", "nzeros", "[", "3", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'4_least_zero_num'", ":", "str", "(", "nzeros", "[", "3", "]", "[", "1", "]", ")", ",", "\n", "'5_least_zero_class'", ":", "str", "(", "nzeros", "[", "4", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'5_least_zero_num'", ":", "str", "(", "nzeros", "[", "4", "]", "[", "1", "]", ")", ",", "\n", "'6_least_zero_class'", ":", "str", "(", "nzeros", "[", "5", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'6_least_zero_num'", ":", "str", "(", "nzeros", "[", "5", "]", "[", "1", "]", ")", ",", "\n", "'7_least_zero_class'", ":", "str", "(", "nzeros", "[", "6", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'7_least_zero_num'", ":", "str", "(", "nzeros", "[", "6", "]", "[", "1", "]", ")", ",", "\n", "'8_least_zero_class'", ":", "str", "(", "nzeros", "[", "7", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'8_least_zero_num'", ":", "str", "(", "nzeros", "[", "7", "]", "[", "1", "]", ")", ",", "\n", "'9_least_zero_class'", ":", "str", "(", "nzeros", "[", "8", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'9_least_zero_num'", ":", "str", "(", "nzeros", "[", "8", "]", "[", "1", "]", ")", ",", "\n", "'10_least_zero_class'", ":", "str", "(", "nzeros", "[", "9", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'10_least_zero_num'", ":", "str", "(", "nzeros", "[", "9", "]", "[", "1", "]", ")", ",", "\n", "'1_least_zero_prop_class'", ":", "str", "(", "pzeros", "[", "0", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'1_least_zero_prop_num'", ":", "str", "(", "pzeros", "[", "0", "]", "[", "1", "]", ")", ",", "\n", "'2_least_zero_prop_class'", ":", "str", "(", "pzeros", "[", "1", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'2_least_zero_prop_num'", ":", "str", "(", "pzeros", "[", "1", "]", "[", "1", "]", ")", ",", "\n", "'3_least_zero_prop_class'", ":", "str", "(", "pzeros", "[", "2", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'3_least_zero_prop_num'", ":", "str", "(", "pzeros", "[", "2", "]", "[", "1", "]", ")", ",", "\n", "'4_least_zero_prop_class'", ":", "str", "(", "pzeros", "[", "3", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'4_least_zero_prop_num'", ":", "str", "(", "pzeros", "[", "3", "]", "[", "1", "]", ")", ",", "\n", "'5_least_zero_prop_class'", ":", "str", "(", "pzeros", "[", "4", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'5_least_zero_prop_num'", ":", "str", "(", "pzeros", "[", "4", "]", "[", "1", "]", ")", ",", "\n", "'6_least_zero_prop_class'", ":", "str", "(", "pzeros", "[", "5", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'6_least_zero_prop_num'", ":", "str", "(", "pzeros", "[", "5", "]", "[", "1", "]", ")", ",", "\n", "'7_least_zero_prop_class'", ":", "str", "(", "pzeros", "[", "6", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'7_least_zero_prop_num'", ":", "str", "(", "pzeros", "[", "6", "]", "[", "1", "]", ")", ",", "\n", "'8_least_zero_prop_class'", ":", "str", "(", "pzeros", "[", "7", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'8_least_zero_prop_num'", ":", "str", "(", "pzeros", "[", "7", "]", "[", "1", "]", ")", ",", "\n", "'9_least_zero_prop_class'", ":", "str", "(", "pzeros", "[", "8", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'9_least_zero_prop_num'", ":", "str", "(", "pzeros", "[", "8", "]", "[", "1", "]", ")", ",", "\n", "'10_least_zero_prop_class'", ":", "str", "(", "pzeros", "[", "9", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'10_least_zero_prop_num'", ":", "str", "(", "pzeros", "[", "9", "]", "[", "1", "]", ")", "\n", "}", "\n", "return", "row", "\n", "\n", "\n", "", "current_range", "=", "[", "0", "]", "\n", "\n", "with", "open", "(", "filelistfile", ",", "'r'", ")", "as", "infile", ":", "\n", "        ", "csv_reader", "=", "csv", ".", "reader", "(", "infile", ",", "delimiter", "=", "','", ")", "\n", "line_count", "=", "0", "\n", "for", "row", "in", "csv_reader", ":", "\n", "            ", "if", "line_count", "==", "0", ":", "\n", "                ", "print", "(", "'Column names are {\", \".join(row)}'", ")", "\n", "line_count", "+=", "1", "\n", "", "else", ":", "\n", "                ", "current_range", ".", "append", "(", "int", "(", "row", "[", "0", "]", ")", ")", "\n", "line_count", "+=", "1", "\n", "print", "(", "'Processed {} lines.'", ".", "format", "(", "line_count", ")", ")", "\n", "\n", "\n", "", "", "", "with", "open", "(", "out_filename", ",", "'w'", ")", "as", "csvfile", ":", "\n", "# fieldnames=out_list", "\n", "        ", "writer", "=", "csv", ".", "DictWriter", "(", "csvfile", ",", "delimiter", "=", "','", ",", "fieldnames", "=", "fieldnames", ")", "\n", "writer", ".", "writeheader", "(", ")", "\n", "with", "open", "(", "out_filename2", ",", "'w'", ")", "as", "csvfile2", ":", "\n", "            ", "writer2", "=", "csv", ".", "DictWriter", "(", "csvfile2", ",", "delimiter", "=", "','", ",", "fieldnames", "=", "fieldnames2", ")", "\n", "writer2", ".", "writeheader", "(", ")", "\n", "with", "open", "(", "out_filename3", ",", "'w'", ")", "as", "csvfile3", ":", "\n", "                ", "writer3", "=", "csv", ".", "DictWriter", "(", "csvfile3", ",", "delimiter", "=", "','", ",", "fieldnames", "=", "fieldnames3", ")", "\n", "writer3", ".", "writeheader", "(", ")", "\n", "with", "open", "(", "out_filename4", ",", "'w'", ")", "as", "csvfile4", ":", "\n", "                    ", "writer4", "=", "csv", ".", "DictWriter", "(", "csvfile4", ",", "delimiter", "=", "','", ",", "fieldnames", "=", "fieldnames4", ")", "\n", "writer4", ".", "writeheader", "(", ")", "\n", "# calculations go in here!", "\n", "for", "current_neuron_index", "in", "current_range", ":", "\n", "                        ", "if", "verbose", ":", "\n", "                            ", "print", "(", "'Grabbing the points for neuron {}'", ".", "format", "(", "current_neuron_index", ")", ")", "\n", "# # this grabs all the points - note that this gets the data out of acts and is slow so we don;twant to do this twice", "\n", "", "local_list", ",", "selected_activations", ",", "x_data", "=", "get_local_list_for_neuron", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "minx", "=", "''", ",", "\n", "maxx", "=", "''", ",", "\n", "acts", "=", "acts", ")", "\n", "# this grabs all the zeros from x_data", "\n", "local_list0", ",", "selected_activations0", "=", "h", ".", "grab_points_for_a_cluster", "(", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "min", "(", "x_data", ")", ",", "\n", "max_selected_x_data", "=", "0.0", ",", "\n", "acts", "=", "acts", ",", "\n", "x_data", "=", "x_data", ",", "\n", "verbose", "=", "verbose", ")", "\n", "# this gets the zhou precision over the top 60 activations", "\n", "zhou_precs_class60", ",", "zhou_precs60", ",", "zhou_no_of_classes60", ",", "zhou60", "=", "find_zhou_precision", "(", "\n", "number_of_points", "=", "60", ",", "local_list", "=", "local_list", ")", "\n", "# grab the classes in the top 100 and find the top mode class", "\n", "top_mode_class", ",", "zhou_precs100", ",", "zhou_no_of_classes100", ",", "zhou100", "=", "find_zhou_precision", "(", "\n", "number_of_points", "=", "100", ",", "local_list", "=", "local_list", ")", "\n", "# now we set up some counters", "\n", "output_precs_data", "=", "[", "]", "\n", "output_precs_data2", "=", "[", "]", "\n", "output_precs_data3", "=", "[", "]", "\n", "test_class_list", "=", "[", "x", "for", "x", "in", "zhou100", "]", "\n", "if", "len", "(", "test_class_list", ")", ">", "10", ":", "\n", "                            ", "test_class_list", "=", "test_class_list", "[", "0", ":", "10", "]", "# we always take the top 10 classes, but these may not all be in the top 100", "\n", "", "placeholder", "=", "(", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ")", "\n", "# max_f1_stat, x_for_max_f1)", "\n", "#       # now we loop over all 10 classes found by Zhou", "\n", "for", "idx", "in", "range", "(", "10", ")", ":", "\n", "                            ", "if", "idx", "+", "1", "<=", "len", "(", "test_class_list", ")", ":", "\n", "# there is a class do stuff", "\n", "# egg = (Ave_precs_x, precs_x, recall_x, recall_p95,", "\n", "# specificity_x, informedness_x, max_informedness, x_for_max_informedness,", "\n", "# max_f1_stat, x_for_max_f1)", "\n", "                                ", "test_class", "=", "test_class_list", "[", "idx", "]", "\n", "# this calculates recall stats over the top 100", "\n", "egg", "=", "calculate_many_precs_recall_stats", "(", "test_class", "=", "test_class", ",", "\n", "local_list", "=", "local_list", ",", "\n", "Q_stop", "=", "100", ",", "\n", "no_files_in_label", "=", "no_files_in_label", ",", "\n", "no_of_images", "=", "no_of_images", ",", "\n", "verbose", "=", "verbose", ")", "\n", "# this does recall stats over all / or all nonzero points", "\n", "egg2", "=", "calculate_many_precs_recall_stats", "(", "test_class", "=", "test_class", ",", "\n", "local_list", "=", "local_list", ",", "\n", "Q_stop", "=", "''", ",", "\n", "no_files_in_label", "=", "no_files_in_label", ",", "\n", "no_of_images", "=", "no_of_images", ",", "\n", "verbose", "=", "verbose", ")", "\n", "# this calcs the correct precisions for all points", "\n", "Ave_precs_all", ",", "precs_all", ",", "recall_all", ",", "_", ",", "_", ",", "_", "=", "calculate_average_precision_incl_zeros", "(", "test_class", ",", "\n", "local_list", "=", "local_list", ",", "\n", "x_data", "=", "x_data", ",", "\n", "selected_activations", "=", "selected_activations", ",", "\n", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "acts", "=", "acts", ",", "\n", "verbose", "=", "verbose", ")", "\n", "egg3", "=", "(", "Ave_precs_all", ",", "precs_all", ",", "recall_all", ")", "\n", "#### output buts", "\n", "output_precs_data", ".", "append", "(", "egg", ")", "# output this", "\n", "output_precs_data2", ".", "append", "(", "egg2", ")", "# output this", "\n", "output_precs_data3", ".", "append", "(", "egg3", ")", "\n", "", "else", ":", "\n", "                                ", "output_precs_data", ".", "append", "(", "placeholder", ")", "\n", "output_precs_data2", ".", "append", "(", "placeholder", ")", "\n", "output_precs_data3", ".", "append", "(", "(", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ")", ")", "\n", "# find the max and second max ave precs of our 10 selected testclasses over this range", "\n", "", "", "if", "verbose", ":", "\n", "                            ", "print", "(", "'Nearly finished analysing unit {}'", ".", "format", "(", "current_neuron_index", ")", ")", "\n", "", "num_zeros", ",", "nzeros", ",", "pzeros", "=", "count_zeros", "(", "local_list", "=", "local_list0", ",", "x_data", "=", "x_data", ",", "class_labels", "=", "class_labels", ",", "\n", "topx", "=", "10", ",", "verbose", "=", "verbose", ")", "\n", "# NOW OUTPUT  the results for this neuron", "\n", "# for the top 100", "\n", "row", "=", "row1_outputter", "(", "current_neuron_index", "=", "current_neuron_index", ",", "top_mode_class", "=", "top_mode_class", ",", "\n", "zhou_precs60", "=", "zhou_precs60", ",", "\n", "zhou_precs_class60", "=", "zhou_precs_class60", ",", "zhou_no_of_classes100", "=", "zhou_no_of_classes100", ",", "\n", "output_precs_data", "=", "output_precs_data", ",", "\n", "test_class_list", "=", "test_class_list", "\n", ")", "\n", "sorted_row", "=", "OrderedDict", "(", "sorted", "(", "row", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "fieldnames", ".", "index", "(", "item", "[", "0", "]", ")", ")", ")", "\n", "writer", ".", "writerow", "(", "sorted_row", ")", "\n", "# for all nonzero data", "\n", "row2", "=", "row2_outputter", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "output_precs_data", "=", "output_precs_data2", ",", "\n", "test_class_list", "=", "test_class_list", ")", "\n", "sorted_row2", "=", "OrderedDict", "(", "sorted", "(", "row2", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "fieldnames2", ".", "index", "(", "item", "[", "0", "]", ")", ")", ")", "\n", "writer2", ".", "writerow", "(", "sorted_row2", ")", "\n", "# for the data adjusted to include the 0.0 points", "\n", "row3", "=", "row3_outputter", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "output_precs_data", "=", "output_precs_data3", ",", "\n", "test_class_list", "=", "test_class_list", ")", "\n", "sorted_row3", "=", "OrderedDict", "(", "sorted", "(", "row3", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "fieldnames3", ".", "index", "(", "item", "[", "0", "]", ")", ")", ")", "\n", "writer3", ".", "writerow", "(", "sorted_row3", ")", "\n", "# data to do with teh number of zeros for classes", "\n", "row4", "=", "row4_outputter", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "nzeros", "=", "nzeros", ",", "pzeros", "=", "pzeros", ",", "num_zeros", "=", "num_zeros", ")", "\n", "sorted_row4", "=", "OrderedDict", "(", "sorted", "(", "row4", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "fieldnames4", ".", "index", "(", "item", "[", "0", "]", ")", ")", ")", "\n", "writer4", ".", "writerow", "(", "sorted_row4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.IM_test_zhou_alexnet.print_test_acts": [[60, 72], ["print", "acts.get_activation", "print", "print", "acts.get_all_point_indices", "len", "len", "acts.get_all_point_indices"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices"], ["def", "print_test_acts", "(", "acts", ")", ":", "\n", "    ", "\"\"\"\n    :param acts:\n    prints out example data\n    :return:\n    \"\"\"", "\n", "print", "(", "'{} files in table'", ".", "format", "(", "len", "(", "acts", ".", "get_all_point_indices", "(", ")", ")", ")", ")", "\n", "egg", "=", "acts", ".", "get_all_point_indices", "(", ")", "[", "0", "]", "\n", "point", "=", "acts", ".", "get_activation", "(", "egg", ")", "\n", "print", "(", "'Example file: {}, vectors are {}-dimensional'", ".", "format", "(", "point", ",", "len", "(", "point", ".", "vector", ")", ")", ")", "\n", "print", "(", "'Example labels: {}'", ".", "format", "(", "point", ".", "labels", ")", ")", "\n", "return", "point", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.IM_test_zhou_alexnet.build_label_dict": [[74, 175], ["sys.stdout.write", "sys.stdout.flush", "acts.get_loaded_files", "len", "acts.get_all_point_indices", "range", "acts.get_loaded_files", "len", "acts.get_all_point_indices", "set", "sys.stdout.write", "sys.stdout.flush", "big_list.append", "h5_analysis_jitterer.filename_to_label", "found_labels.append", "print", "isinstance", "h5_analysis_jitterer.filename_to_label", "enumerate", "print", "print", "range", "len", "len", "big_list.append", "h5_analysis_jitterer.filename_to_label", "found_labels.append", "print", "isinstance", "acts.get_activation().labels[].decode", "print", "acts.get_activation().labels.decode", "acts.get_activation().labels[].decode", "h5_analysis_jitterer.filename_to_label", "len", "len", "len", "print", "acts.get_activation().labels.decode", "acts.get_activation().labels[].decode", "print", "file_name.split", "acts.get_activation", "big_list[].append", "file_name.split", "acts.get_activation", "big_dict.values", "big_dict.items", "file_name.split", "len", "len", "acts.get_activation", "acts.get_activation", "acts.get_activation", "acts.get_activation", "acts.get_activation"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_loaded_files", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_loaded_files", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation"], ["", "def", "build_label_dict", "(", "acts", ",", "use_loaded_files", "=", "True", ",", "verbose", "=", "True", ",", "doMean", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Builds a dictionary of labels to points in local format\n    Gives out a dictionary and a list of found labels\n    acts: activation table object\n    use_loaded_files: whether to assume one file per label (current default)\n    This version can deal with the filenames and labels being different\n    \"\"\"", "\n", "sys", ".", "stdout", ".", "write", "(", "'About to build the label dict (slow)'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "if", "use_loaded_files", "==", "True", ":", "\n", "# we use the filenames as the labels", "\n", "        ", "files", "=", "acts", ".", "get_loaded_files", "(", ")", "\n", "big_list", "=", "[", "]", "\n", "no_of_files", "=", "len", "(", "files", ")", "\n", "found_labels", "=", "[", "]", "\n", "label_dict", "=", "{", "}", "\n", "no_files_in_label", "=", "{", "}", "\n", "for", "file_name", "in", "files", ":", "\n", "            ", "big_list", ".", "append", "(", "[", "]", ")", "\n", "label", "=", "filename_to_label", "(", "file_name", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "found_labels", ".", "append", "(", "label", ")", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'Found {} files in activation table object'", ".", "format", "(", "no_of_files", ")", ")", "\n", "#print('Be patient, I found {} points'.format(len(acts.get_all_activation_indices())))", "\n", "", "for", "current_point", "in", "acts", ".", "get_all_point_indices", "(", ")", ":", "\n", "# TODO:: Make this work with multiple labels", "\n", "            ", "if", "isinstance", "(", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", ",", "(", "bytes", ",", "bytearray", ",", "str", ")", ")", ":", "\n", "# old style, the labels are a numpy byte string", "\n", "                ", "assigned_label", "=", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", ".", "decode", "(", "'UTF-8'", ")", "\n", "", "else", ":", "\n", "# new style, labels are a list", "\n", "                ", "assigned_label", "=", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", "[", "0", "]", ".", "decode", "(", "'UTF-8'", ")", "\n", "", "assigned_label", "=", "filename_to_label", "(", "assigned_label", ")", "\n", "# except AttributeError:", "\n", "#     assigned_label = acts.get_activation(current_point).labels.decode('UTF-8')", "\n", "# except ValueError:", "\n", "#     import pdb; pdb.set_trace()", "\n", "for", "f_no", ",", "file_name", "in", "enumerate", "(", "files", ")", ":", "\n", "                ", "label", "=", "filename_to_label", "(", "file_name", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "if", "assigned_label", "==", "label", ":", "\n", "                    ", "big_list", "[", "f_no", "]", ".", "append", "(", "current_point", ")", "\n", "break", "\n", "", "", "", "if", "not", "len", "(", "found_labels", ")", "==", "len", "(", "files", ")", ":", "\n", "            ", "print", "(", "'The number of found labels does not match the number of files in activation table'", ")", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'Found label: \\t No. of points'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "found_labels", ")", ")", ":", "\n", "                ", "print", "(", "'{}: \\t {}'", ".", "format", "(", "found_labels", "[", "i", "]", ",", "len", "(", "big_list", "[", "i", "]", ")", ")", ")", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "found_labels", ")", ")", ":", "\n", "#print(i, found_labels[i])", "\n", "            ", "label_dict", "[", "found_labels", "[", "i", "]", "]", "=", "big_list", "[", "i", "]", "\n", "no_files_in_label", "[", "found_labels", "[", "i", "]", "]", "=", "len", "(", "big_list", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "# we assume acts already has the labels", "\n", "        ", "files", "=", "acts", ".", "get_loaded_files", "(", ")", "\n", "big_list", "=", "[", "]", "\n", "no_of_files", "=", "len", "(", "files", ")", "\n", "found_labels", "=", "[", "]", "\n", "big_dict", "=", "{", "}", "\n", "label_dict", "=", "{", "}", "\n", "no_files_in_label", "=", "{", "}", "\n", "for", "file_name", "in", "files", ":", "\n", "            ", "big_list", ".", "append", "(", "[", "]", ")", "\n", "label", "=", "filename_to_label", "(", "file_name", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "found_labels", ".", "append", "(", "label", ")", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'Found {} files in activation table object'", ".", "format", "(", "no_of_files", ")", ")", "\n", "#print('Be patient, I found {} points'.format(len(acts.get_all_activation_indices())))", "\n", "", "for", "current_point", "in", "acts", ".", "get_all_point_indices", "(", ")", ":", "\n", "# TODO:: Make this work with multiple labels", "\n", "            ", "if", "isinstance", "(", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", ",", "(", "bytes", ",", "bytearray", ",", "str", ")", ")", ":", "\n", "# old style, the labels are a numpy byte string", "\n", "                ", "assigned_label", "=", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", ".", "decode", "(", "'UTF-8'", ")", "\n", "", "else", ":", "\n", "# new style, labels are a list", "\n", "                ", "assigned_label", "=", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", "[", "0", "]", ".", "decode", "(", "'UTF-8'", ")", "\n", "#assigned_label = filename_to_label(assigned_label)", "\n", "# except AttributeError:", "\n", "#     assigned_label = acts.get_activation(current_point).labels.decode('UTF-8')", "\n", "# except ValueError:", "\n", "#     import pdb; pdb.set_trace()", "\n", "", "big_dict", "[", "current_point", "]", "=", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", "[", "0", "]", ".", "decode", "(", "'UTF-8'", ")", "\n", "# we've got all the points", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'Found label: \\t No. of points'", ")", "\n", "", "unique_values", "=", "set", "(", "val", "for", "dic", "in", "big_dict", "for", "val", "in", "big_dict", ".", "values", "(", ")", ")", "\n", "found_labels", "=", "[", "x", "for", "x", "in", "unique_values", "]", "\n", "for", "f_label", "in", "found_labels", ":", "\n", "            ", "list_of_tuples", "=", "[", "x", "[", "0", "]", "for", "x", "in", "big_dict", ".", "items", "(", ")", "if", "x", "[", "1", "]", "==", "f_label", "]", "\n", "label_dict", "[", "f_label", "]", "=", "list_of_tuples", "\n", "# for f_no, file_name in enumerate(files):", "\n", "#     label=filename_to_label(file_name.split('_')[0])", "\n", "#     if assigned_label == label:", "\n", "#         big_list[f_no].append(current_point)", "\n", "#         break", "\n", "if", "verbose", ":", "\n", "                ", "print", "(", "'{}: \\t {}'", ".", "format", "(", "f_label", ",", "len", "(", "list_of_tuples", ")", ")", ")", "\n", "", "", "sys", ".", "stdout", ".", "write", "(", "'Built the label dict'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "return", "label_dict", ",", "found_labels", ",", "no_files_in_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.test_zhou_resnet.make_synset_files": [[47, 76], ["open", "open", "fh.close", "line.strip().split", "print", "line.strip().split", "print", "open", "image_list.append", "labels_list.append", "fh.writelines", "line.strip", "line.strip"], "function", ["None"], ["def", "make_synset_files", "(", "index_into_index_file", ",", "index_file", ",", "category_file", ",", "out_file_name", ")", ":", "\n", "    ", "\"\"\"Function to get Broden into the correct formats\n    index_into_index_file is which column of index file to take\n    index_file is the files with the images and associated categories\n    category file is the file c_oject,txt etc with the human readable labels\"\"\"", "\"\"", "\n", "## Get a list of images which have associated objects and we'll take those as classes", "\n", "image_list", "=", "[", "]", "\n", "correct_class_list", "=", "[", "]", "\n", "file", "=", "open", "(", "index_file", ",", "'r'", ")", "\n", "for", "line", "in", "file", ":", "\n", "        ", "line_list", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "print", "(", "line_list", ")", "\n", "if", "not", "line_list", "[", "index_into_index_file", "]", "==", "''", ":", "\n", "            ", "image_list", ".", "append", "(", "[", "line_list", "[", "0", "]", ",", "line_list", "[", "index_into_index_file", "]", "]", ")", "\n", "# this the original image name and an image which masks the object", "\n", "# gets the human readable lbels from the file", "\n", "", "", "labels_list", "=", "[", "]", "\n", "file2", "=", "open", "(", "category_file", ",", "'r'", ")", "\n", "for", "line", "in", "file2", ":", "\n", "        ", "line_list", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "print", "(", "line_list", ")", "\n", "if", "not", "line_list", "[", "1", "]", "==", "'number'", ":", "\n", "            ", "labels_list", ".", "append", "(", "[", "line_list", "[", "1", "]", ",", "line_list", "[", "2", "]", "]", ")", "\n", "# write it out in the correct format", "\n", "", "", "with", "open", "(", "out_file_name", ",", "\"w\"", ")", "as", "fh", ":", "\n", "        ", "for", "line", "in", "labels_list", ":", "\n", "            ", "fh", ".", "writelines", "(", "' '", ".", "join", "(", "line", ")", "+", "'\\n'", ")", "\n", "", "", "fh", ".", "close", "(", ")", "\n", "return", "image_list", ",", "labels_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.test_zhou_resnet.get_class_details_broden": [[201, 209], ["short_labels.index", "class_name.split", "x.split"], "function", ["None"], ["def", "get_class_details_broden", "(", "classname", ",", "labels", ",", "short_labels", ")", ":", "\n", "    ", "\"\"\"grabs cat number for a unit\n    classname is the word name of the class\n    labels is our list\"\"\"", "\n", "class_name", "=", "[", "x", "for", "x", "in", "labels", "if", "x", ".", "split", "(", "' '", ")", "[", "1", "]", "==", "classname", "]", "[", "0", "]", "\n", "class_name", "=", "class_name", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "class_pos", "=", "short_labels", ".", "index", "(", "class_name", ")", "\n", "return", "class_name", ",", "class_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.merger.merge": [[8, 30], ["h5py.File", "h5py.File.close", "print", "h5py.File.create_group", "h5py.File", "output_file.create_group.create_group", "group.create_group.create_dataset", "h5py.File.close", "os.path.basename().split", "output_file.create_group.create_dataset", "os.path.basename"], "function", ["None"], ["def", "merge", "(", "input_filenames", ",", "output_filename", ")", ":", "\n", "    ", "''' create a single h5 file from several input ones.\n    '''", "\n", "output_file", "=", "h5py", ".", "File", "(", "output_filename", ")", "\n", "for", "input_filename", "in", "input_filenames", ":", "\n", "        ", "print", "(", "input_filename", ")", "\n", "group_name", "=", "os", ".", "path", ".", "basename", "(", "input_filename", ")", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "group", "=", "output_file", ".", "create_group", "(", "group_name", ")", "\n", "input_file", "=", "h5py", ".", "File", "(", "input_filename", ",", "'r'", ")", "\n", "for", "key", "in", "DATA_ITEMS", ":", "\n", "            ", "group", ".", "create_dataset", "(", "key", ",", "data", "=", "input_file", "[", "key", "]", ")", "\n", "", "for", "key", "in", "input_file", "[", "u'activations'", "]", ".", "attrs", ":", "\n", "            ", "group", "[", "u'activations'", "]", ".", "attrs", "[", "key", "]", "=", "input_file", "[", "u'activations'", "]", ".", "attrs", "[", "key", "]", "\n", "# activation_labels is an odd one", "\n", "", "label_group", "=", "group", ".", "create_group", "(", "'activation_labels'", ")", "\n", "# There _should_ only be a single field value for this file.", "\n", "# There _should_ only be a single field value for this file", "\n", "# assert len(input_file['activation_labels']) == 1", "\n", "field_name", "=", "[", "x", "for", "x", "in", "input_file", "[", "'activation_labels'", "]", "]", "[", "0", "]", "\n", "label_group", ".", "create_dataset", "(", "group_name", ",", "data", "=", "input_file", "[", "'activation_labels/{}'", ".", "format", "(", "field_name", ")", "]", ")", "\n", "input_file", ".", "close", "(", ")", "\n", "", "output_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.merger.merge_layer": [[32, 43], ["glob.glob", "os.path.join", "print", "merger.merge", "os.path.join"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.merger.merge"], ["", "def", "merge_layer", "(", "directory", ",", "layer_name", ",", "name_leader", "=", "'AN_merged_all'", ",", "suffix", "=", "''", ",", "input_filenames", "=", "'n*_fc8_max.h5'", ",", "\n", "isimagenet", "=", "True", ")", ":", "\n", "    ", "''' look in directory for all h5s for a layer and merge them. '''", "\n", "# input_filenames = glob.glob(os.path.join(directory, name_leader+'n*_{}.h5'.format(layer_name)))", "\n", "input_filenames", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "input_filenames", ")", ")", "\n", "# output_filename = os.path.join(directory, name_leader+'merged_{}.h5'.format(layer_name))", "\n", "# input_filenames = glob.glob(os.path.join(directory, 'n*_{}{}.h5'.format(layer_name, suffix)))", "\n", "output_filename", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "'{}_{}{}.h5'", ".", "format", "(", "name_leader", ",", "layer_name", ",", "suffix", ")", ")", "\n", "print", "(", "input_filenames", ")", "\n", "merge", "(", "input_filenames", ",", "output_filename", ")", "\n", "return", "output_filename", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.merger.main": [[45, 50], ["merger.merge_layer", "os.getcwd"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.merger.merge_layer"], ["", "def", "main", "(", ")", ":", "\n", "# merge(['n02096051_fc6.h5','n02129604_fc6.h5','n02640242_fc6.h5'], 'fc6.h5')", "\n", "# merge_layer(os.getcwd(), 'prob')", "\n", "# merge_layer(os.getcwd(), 'fc7')", "\n", "    ", "merge_layer", "(", "os", ".", "getcwd", "(", ")", ",", "'fc8'", ",", "''", ",", "'all'", ")", "\n", "# merge_layer(os.getcwd(), 'conv5')", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.IM_test_zhou_googlenet.ICLRPaperTest": [[71, 135], ["h5_analysis_jitterer.grab_points_for_a_cluster", "h5_analysis_jitterer.find_zhou_precision", "print", "sum", "print", "print", "print", "print", "numpy.mean", "numpy.std", "print", "numpy.mean", "numpy.std", "print", "print", "print", "egg.append", "sum.append", "numpy.sqrt", "len", "numpy.sqrt", "len", "max", "classA.append", "range", "classnotA.append", "len", "len", "len", "len", "len", "len", "max", "class_name.split"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_zhou_precision"], ["def", "ICLRPaperTest", "(", "classAindices", ",", "\n", "current_neuron_index", ",", "\n", "x_data", ",", "\n", "acts", ",", "\n", "cluster_list", ")", ":", "\n", "    ", "from", "h5_analysis_jitterer", "import", "grab_points_for_a_cluster", ",", "find_zhou_precision", "\n", "\"\"\"Does a suite of tests on the data \"\"\"", "\n", "# this bit does tge zhou precisison", "\n", "local_list", ",", "selected_activations", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "max", "(", "x_data", ")", "/", "4", ",", "\n", "max_selected_x_data", "=", "max", "(", "x_data", ")", ",", "\n", "x_data", "=", "x_data", ",", "\n", "acts", "=", "acts", ",", "\n", "verbose", "=", "True", ")", "\n", "local_list", "=", "local_list", "[", "-", "101", ":", "-", "1", "]", "\n", "selected_activations", "=", "selected_activations", "[", "-", "101", ":", "-", "1", "]", "\n", "zhou_precs_class", ",", "zhou_precs", ",", "zhou_no_of_classes", ",", "zhou", "=", "find_zhou_precision", "(", "number_of_points", "=", "100", ",", "\n", "local_list", "=", "local_list", ")", "\n", "egg", "=", "[", "]", "\n", "for", "class_name", "in", "r", ".", "labels", "[", "bus_indices", "]", ":", "\n", "        ", "egg", ".", "append", "(", "class_name", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "\n", "#", "\n", "", "print", "(", "'Warning, this is hacky, and assumes the .h5 file name so do doublecheck if this answer is 0'", ")", "\n", "count", "=", "[", "]", "\n", "for", "key_start", "in", "egg", ":", "\n", "        ", "key", "=", "key_start", "+", "'_'", "+", "'inception_4e_output'", "+", "'_max'", "\n", "count", ".", "append", "(", "zhou", "[", "key", "]", ")", "\n", "#", "\n", "", "count", "=", "sum", "(", "count", ")", "\n", "zhou_precs", "=", "count", "/", "100.0", "\n", "print", "(", "'Zhou:{}'", ".", "format", "(", "zhou", ")", ")", "\n", "print", "(", "'Zhou precision class: {}\\nZhou precision:{}\\nZhou no. of class:{}\\n'", ".", "format", "(", "egg", ",", "zhou_precs", ",", "\n", "zhou_no_of_classes", ")", ")", "\n", "#", "\n", "#", "\n", "classA", "=", "[", "]", "\n", "for", "index", "in", "classAindices", ":", "\n", "        ", "for", "item", "in", "cluster_list", "[", "index", "]", ":", "\n", "            ", "classA", ".", "append", "(", "item", ")", "\n", "#", "\n", "", "", "classnotA", "=", "[", "]", "\n", "for", "index", "in", "[", "x", "for", "x", "in", "range", "(", "1000", ")", "if", "x", "not", "in", "classAindices", "]", ":", "\n", "        ", "for", "item", "in", "cluster_list", "[", "index", "]", ":", "\n", "            ", "classnotA", ".", "append", "(", "item", ")", "\n", "#", "\n", "", "", "print", "(", "'Representative stats'", ")", "\n", "print", "(", "'Class A is {} items\\t class not A is {} items'", ".", "format", "(", "len", "(", "classA", ")", ",", "len", "(", "classnotA", ")", ")", ")", "\n", "muA", "=", "np", ".", "mean", "(", "classA", ")", "\n", "stdA", "=", "np", ".", "std", "(", "classA", ")", "\n", "meA", "=", "stdA", "/", "np", ".", "sqrt", "(", "len", "(", "classA", ")", ")", "\n", "pc_nonzeroA", "=", "100", "*", "len", "(", "[", "x", "for", "x", "in", "classA", "if", "x", ">", "0.0", "]", ")", "/", "len", "(", "classA", ")", "\n", "print", "(", "'mean (A): {}+/-{}\\nstd (A): {}\\n%A that is nonzero: {}'", "\n", ".", "format", "(", "muA", ",", "meA", ",", "stdA", ",", "pc_nonzeroA", ")", ")", "\n", "munotA", "=", "np", ".", "mean", "(", "classnotA", ")", "\n", "stdnotA", "=", "np", ".", "std", "(", "classnotA", ")", "\n", "menotA", "=", "stdnotA", "/", "np", ".", "sqrt", "(", "len", "(", "classnotA", ")", ")", "\n", "pc_nonzeronotA", "=", "100", "*", "len", "(", "[", "x", "for", "x", "in", "classnotA", "if", "x", ">", "0.0", "]", ")", "/", "len", "(", "classnotA", ")", "\n", "print", "(", "'mean (NOT A): {}+/-{}\\nstd (NOT A): {}\\n%NOT A that is nonzero: {}'", "\n", ".", "format", "(", "munotA", ",", "menotA", ",", "stdnotA", ",", "pc_nonzeronotA", ")", ")", "\n", "CCMAS", "=", "(", "muA", "-", "munotA", ")", "/", "(", "muA", "+", "munotA", ")", "\n", "print", "(", "'CCMAS(A):{}\\n'", ".", "format", "(", "CCMAS", ")", ")", "\n", "print", "(", "'{} & {} & {} & {} & {} & {}'", ".", "format", "(", "pc_nonzeroA", ",", "pc_nonzeronotA", ",", "muA", ",", "munotA", ",", "zhou_precs", ",", "CCMAS", ")", ")", "\n", "#", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.IM_test_zhou_googlenet.find_zhou_precision": [[258, 266], ["collections.Counter", "len", "range", "collections.Counter.most_common", "collections.Counter.most_common"], "function", ["None"], ["def", "find_zhou_precision", "(", "number_of_points", "=", "100", ",", "local_list", "=", "local_list", ")", ":", "\n", "    ", "\"\"\"Finds the maximally occuring class in the top number_of_points and counts it\"\"\"", "\n", "classes_in_top_100", "=", "[", "local_list", "[", "x", "]", "[", "0", "]", "for", "x", "in", "range", "(", "-", "number_of_points", ",", "0", ")", "]", "\n", "zhou", "=", "Counter", "(", "classes_in_top_100", ")", "\n", "zhou_precs_class", "=", "zhou", ".", "most_common", "(", "1", ")", "[", "0", "]", "[", "0", "]", "# the class name", "\n", "zhou_precs", "=", "zhou", ".", "most_common", "(", "1", ")", "[", "0", "]", "[", "1", "]", "/", "number_of_points", "# the precision", "\n", "zhou_no_of_classes", "=", "len", "(", "zhou", ")", "\n", "return", "zhou_precs_class", ",", "zhou_precs", ",", "zhou_no_of_classes", ",", "zhou", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.test_zhou_vgg.make_synset_files": [[50, 79], ["open", "open", "fh.close", "line.strip().split", "print", "line.strip().split", "print", "open", "image_list.append", "labels_list.append", "fh.writelines", "line.strip", "line.strip"], "function", ["None"], ["def", "make_synset_files", "(", "index_into_index_file", ",", "index_file", ",", "category_file", ",", "out_file_name", ")", ":", "\n", "    ", "\"\"\"Function to get Broden into the correct formats\n    index_into_index_file is which column of index file to take\n    index_file is the files with the images and associated categories\n    category file is the file c_oject,txt etc with the human readable labels\"\"\"", "\"\"", "\n", "## Get a list of images which have associated objects and we'll take those as classes", "\n", "image_list", "=", "[", "]", "\n", "correct_class_list", "=", "[", "]", "\n", "file", "=", "open", "(", "index_file", ",", "'r'", ")", "\n", "for", "line", "in", "file", ":", "\n", "        ", "line_list", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "print", "(", "line_list", ")", "\n", "if", "not", "line_list", "[", "index_into_index_file", "]", "==", "''", ":", "\n", "            ", "image_list", ".", "append", "(", "[", "line_list", "[", "0", "]", ",", "line_list", "[", "index_into_index_file", "]", "]", ")", "\n", "# this the original image name and an image which masks the object", "\n", "# gets the human readable lbels from the file", "\n", "", "", "labels_list", "=", "[", "]", "\n", "file2", "=", "open", "(", "category_file", ",", "'r'", ")", "\n", "for", "line", "in", "file2", ":", "\n", "        ", "line_list", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "print", "(", "line_list", ")", "\n", "if", "not", "line_list", "[", "1", "]", "==", "'number'", ":", "\n", "            ", "labels_list", ".", "append", "(", "[", "line_list", "[", "1", "]", ",", "line_list", "[", "2", "]", "]", ")", "\n", "# write it out in the correct format", "\n", "", "", "with", "open", "(", "out_file_name", ",", "\"w\"", ")", "as", "fh", ":", "\n", "        ", "for", "line", "in", "labels_list", ":", "\n", "            ", "fh", ".", "writelines", "(", "' '", ".", "join", "(", "line", ")", "+", "'\\n'", ")", "\n", "", "", "fh", ".", "close", "(", ")", "\n", "return", "image_list", ",", "labels_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.test_zhou_vgg.get_class_details_broden": [[203, 211], ["short_labels.index", "class_name.split", "x.split"], "function", ["None"], ["def", "get_class_details_broden", "(", "classname", ",", "labels", ",", "short_labels", ")", ":", "\n", "    ", "\"\"\"grabs cat number for a unit\n    classname is the word name of the class\n    labels is our list\"\"\"", "\n", "class_name", "=", "[", "x", "for", "x", "in", "labels", "if", "x", ".", "split", "(", "' '", ")", "[", "1", "]", "==", "classname", "]", "[", "0", "]", "\n", "class_name", "=", "class_name", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "class_pos", "=", "short_labels", ".", "index", "(", "class_name", ")", "\n", "return", "class_name", ",", "class_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.test_zhou_vgg.make_collage_new": [[284, 341], ["range", "append_images", "acts.get_file_name().decode", "selected_image_list.append", "len", "len", "int", "rows.append", "append_images.save", "print", "crop_to_square().resize", "append_images", "print", "print", "acts.get_file_name", "x.resize", "map", "len", "append_images.save", "crop_to_square", "crop_to_square", "print"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.append_images", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.save", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.append_images", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_file_name", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.save", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.crop_to_square", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.crop_to_square"], ["def", "make_collage_new", "(", "out_file", "=", "'temp.jpg'", ",", "local_list", "=", "local_list", ",", "shrink", "=", "True", ",", "do_square", "=", "True", ",", "no_of_cols", "=", "5", ",", "\n", "acts", "=", "acts", ",", "class_dict", "=", "class_dict", ",", "class_labels", "=", "class_labels", ",", "\n", "verbose", "=", "verbose", ",", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ")", ":", "\n", "    ", "\"\"\"Function to get the selected images and collage them\n    local_list: list of points in act to find pictures for\n    shrink: whether to shrink images\n    do_square: whether to squarify the images\n    no_of_cols: how many colums in the collage\n    returns an image object\"\"\"", "\n", "selected_image_list", "=", "[", "]", "\n", "found_classes", "=", "[", "]", "\n", "for", "selected_point", "in", "local_list", ":", "\n", "# grab filename", "\n", "        ", "selected_file", "=", "acts", ".", "get_file_name", "(", "selected_point", ")", ".", "decode", "(", "'UTF-8'", ")", "\n", "if", "verbose", ":", "\n", "            ", "pass", "\n", "#print(selected_file)", "\n", "# we've assumed files are in folders labelled by class!", "\n", "#class_dir_label = filename_to_label(selected_file.split('_')[0])", "\n", "", "selected_image_list", ".", "append", "(", "imagenet_root", "+", "'ade20K'", "+", "'/'", "+", "selected_file", ")", "\n", "#class_no = class_dict[class_dir_label]", "\n", "#if not class_no in found_classes:", "\n", "#    found_classes.append(class_no)", "\n", "", "if", "shrink", "and", "do_square", ":", "\n", "        ", "images", "=", "[", "crop_to_square", "(", "x", ")", ".", "resize", "(", "(", "277", ",", "277", ")", ")", "for", "x", "in", "selected_image_list", "]", "\n", "", "elif", "shrink", ":", "\n", "# this option may not work so do not use it!", "\n", "        ", "images", "=", "[", "Image", ".", "open", "for", "x", "in", "selected_image_list", "]", "\n", "images", "=", "[", "x", ".", "resize", "(", "(", "277", ",", "277", ")", ")", "for", "x", "in", "images", "]", "\n", "", "elif", "do_square", ":", "\n", "        ", "images", "=", "[", "crop_to_square", "(", "x", ")", "for", "x", "in", "selected_image_list", "]", "\n", "", "else", ":", "\n", "        ", "images", "=", "map", "(", "Image", ".", "open", ",", "selected_image_list", ")", "\n", "", "rows", "=", "[", "]", "\n", "# make row images", "\n", "if", "len", "(", "images", ")", "<", "10", ":", "\n", "        ", "no_of_cols", "=", "len", "(", "images", ")", "\n", "", "for", "row_no", "in", "range", "(", "int", "(", "len", "(", "images", ")", "/", "no_of_cols", ")", ")", ":", "\n", "        ", "rows", ".", "append", "(", "\n", "append_images", "(", "images", "[", "0", "+", "no_of_cols", "*", "row_no", ":", "no_of_cols", "+", "no_of_cols", "*", "row_no", "]", ",", "direction", "=", "'horizontal'", ")", ")", "\n", "# stack row images", "\n", "", "combined_image", "=", "append_images", "(", "rows", ",", "direction", "=", "'vertical'", ")", "\n", "try", ":", "\n", "      ", "combined_image", ".", "save", "(", "out_file", ")", "\n", "", "except", "IOError", ":", "\n", "      ", "print", "(", "\"Failed to write {}, trying as png\"", ".", "format", "(", "out_file", ")", ")", "\n", "try", ":", "\n", "        ", "out_file_png", "=", "\"{}.png\"", ".", "format", "(", "out_file", ")", "\n", "combined_image", ".", "save", "(", "out_file_png", ")", "\n", "", "except", "IOError", ":", "\n", "        ", "print", "(", "\"Failed to write {} as png\"", ".", "format", "(", "out_file_png", ")", ")", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'Found the following classes:'", ")", "\n", "for", "class_no", "in", "found_classes", ":", "\n", "            ", "print", "(", "'{}'", ".", "format", "(", "class_labels", "[", "class_no", "]", ")", ")", "\n", "# if you want to see it do combined_image.show()", "\n", "", "", "return", "combined_image", ",", "found_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_directory.handle_args": [[20, 66], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "len", "print", "quit", "os.getcwd"], "function", ["None"], ["def", "handle_args", "(", ")", ":", "\n", "    ", "\"\"\" Parse cli arguments\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--image_dir'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "os", ".", "getcwd", "(", ")", ",", "\n", "help", "=", "'where the image directory is'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--image'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "''", ",", "\n", "help", "=", "'image file name'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_of_guesses'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "5", ",", "\n", "help", "=", "'number of probabilities to return'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--verbose'", ",", "\n", "default", "=", "True", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'more verbose logging.'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--class_list'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "'correct_classes.txt'", ",", "\n", "help", "=", "'file with list of file names and maybe also the correct classes in'", "\n", ")", "\n", "#parser.add_argument(", "\n", "#    '--model',", "\n", "#    type=str,", "\n", "#    default='',", "\n", "#    help='model file flag--see settings in Caffe_AlexNet.py'", "\n", "#)", "\n", "\n", "flags", ",", "unparsed", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "if", "len", "(", "unparsed", ")", ">", "0", ":", "\n", "        ", "print", "(", "'Unrecognised flags: {}'", ".", "format", "(", "unparsed", ")", ")", "\n", "quit", "(", "1", ")", "\n", "", "return", "flags", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_directory.what_am_I_from_image": [[76, 121], ["transformer.preprocess", "net.forward", "range", "print", "print", "out_list.append", "probabilities.argmax", "probabilities.argsort", "print", "type", "type", "true_class.decode", "h5_analysis_jitterer.class_lineno_to_name", "print", "print", "probabilities.argmax"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.class_lineno_to_name"], ["def", "what_am_I_from_image", "(", "image", "=", "image", ",", "net", "=", "net", ",", "transformer", "=", "transformer", ",", "verbose", "=", "True", ",", "true_class", "=", "''", ",", "found_labels", "=", "[", "]", ",", "class_labels", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Function to classify based on 'prob'ability layer inputs\n    probabilities: a vector of input probabilities\n    no_of_guesses: how many of the top probabilities do you want?\n    true_class: the real class name if known\n    outputs are in order: probability, label, human readable name\n    \"\"\"", "\n", "#TODO: This has not yet been properly tested!!!!!!", "\n", "transformed_image", "=", "transformer", ".", "preprocess", "(", "'data'", ",", "image", ")", "\n", "# copy the image data into the memory allocated for the net", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "transformed_image", "\n", "### perform classification", "\n", "output", "=", "net", ".", "forward", "(", ")", "\n", "probabilities", "=", "output", "[", "'prob'", "]", "[", "0", "]", "# the output probability vector for the first image in the batch", "\n", "is_correct", "=", "2", "# lets use trinary, where 2 means indeterminate! :)", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'predicted class is:'", ",", "probabilities", ".", "argmax", "(", ")", ")", "\n", "print", "(", "'output label:{}'", ".", "format", "(", "found_labels", "[", "probabilities", ".", "argmax", "(", ")", "]", ")", ")", "\n", "", "top_inds", "=", "probabilities", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", ":", "no_of_guesses", "]", "# reverse sort and take five largest items", "\n", "sorted_out_list", "=", "[", "(", "probabilities", "[", "x", "]", ",", "found_labels", "[", "x", "]", ")", "for", "x", "in", "top_inds", "]", "\n", "out_list", "=", "[", "]", "\n", "for", "guess", "in", "range", "(", "no_of_guesses", ")", ":", "\n", "        ", "a_label", "=", "' '", ".", "join", "(", "h", ".", "class_lineno_to_name", "(", "line_no", "=", "top_inds", "[", "guess", "]", ",", "class_labels", "=", "class_labels", ")", "[", "2", "]", ")", "\n", "if", "guess", "==", "0", ":", "\n", "            ", "best_guess", "=", "a_label", "\n", "", "out_list", ".", "append", "(", "(", "sorted_out_list", "[", "guess", "]", "[", "0", "]", "*", "100", ",", "sorted_out_list", "[", "guess", "]", "[", "1", "]", ",", "a_label", ")", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'{:.2f}%: {}: {} '", ".", "format", "(", "sorted_out_list", "[", "guess", "]", "[", "0", "]", "*", "100", ",", "sorted_out_list", "[", "guess", "]", "[", "1", "]", ",", "a_label", ")", ")", "\n", "", "", "if", "not", "true_class", "==", "''", ":", "\n", "# we can test if it is correct", "\n", "        ", "if", "type", "(", "true_class", ")", "==", "type", "(", "''", ")", ":", "\n", "            ", "ground_truth", "=", "true_class", "\n", "", "else", ":", "\n", "# assume byte array", "\n", "            ", "ground_truth", "=", "true_class", ".", "decode", "(", ")", "\n", "", "if", "found_labels", "[", "top_inds", "[", "0", "]", "]", "==", "ground_truth", ":", "\n", "# is correct", "\n", "            ", "is_correct", "=", "True", "\n", "if", "verbose", ":", "\n", "                ", "print", "(", "'Image is correctly classified'", ")", "\n", "", "", "else", ":", "\n", "            ", "is_correct", "=", "False", "\n", "if", "verbose", ":", "\n", "                ", "print", "(", "'Image is incorrectly classified'", ")", "\n", "", "", "", "return", "out_list", ",", "is_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_directory.main": [[126, 273], ["set_up_caffe_net.main", "open", "print", "line.strip().split", "image_list.append", "open", "csv.DictWriter", "csv.DictWriter.writeheader", "range", "label.split", "len", "correct_class_list.append", "len", "Caffe_AlexNet.caffe.io.load_image", "collections.OrderedDict", "csv.DictWriter.writerow", "len", "line.strip", "Test_AlexNet_on_directory.what_am_I_from_image", "Test_AlexNet_on_directory.what_am_I_from_image", "correct_top_1.append", "str", "str", "str", "str", "str", "str", "sorted", "row.items", "int", "class_labels[].split", "fieldnames.index", "int"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.main", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.what_am_I_from_image", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.what_am_I_from_image"], ["", "def", "main", "(", ")", ":", "\n", "    ", "global", "acts", ",", "class_labels", ",", "h5_list", ",", "caffe_settings", "\n", "\n", "image_directory", "=", "FLAGS", ".", "image_dir", "\n", "image_filename", "=", "FLAGS", ".", "image", "\n", "verbose", "=", "FLAGS", ".", "verbose", "\n", "correct_class_filename", "=", "FLAGS", ".", "class_list", "\n", "#model_file_flag = FLAGS.model_file", "\n", "#model_file = Get_Model_File(model_file_flag)", "\n", "#model_file = Get_Model_File('AlexNet_standard')", "\n", "image_directory", "=", "FLAGS", ".", "image_dir", "\n", "caffe_settings", "=", "s", ".", "main", "(", ")", "\n", "# caffe_root = s.caffe_root", "\n", "#image_directory = caffe_settings.image_directory", "\n", "labels_file", "=", "caffe_settings", ".", "labels_file", "\n", "model_def", "=", "caffe_settings", ".", "model_def", "\n", "model_weights", "=", "caffe_settings", ".", "model_weights", "\n", "dir_list", "=", "caffe_settings", ".", "dir_list", "\n", "labels", "=", "caffe_settings", ".", "labels", "\n", "net", "=", "caffe_settings", ".", "net", "\n", "transformer", "=", "caffe_settings", ".", "transformer", "\n", "short_labels", "=", "caffe_settings", ".", "short_labels", "\n", "model_file", "=", "caffe_settings", ".", "model_file", "\n", "this_one_file_name", "=", "caffe_settings", ".", "this_one_file_name", "\n", "blob", "=", "caffe_settings", ".", "blob", "\n", "file_root", "=", "caffe_settings", ".", "file_root", "\n", "#model_file = Get_Model_File('L1_AlexNet')", "\n", "#model_file = Get_Model_File('no_reg_AlexNet')", "\n", "# first we grab the network", "\n", "# if usingDocker:", "\n", "#     # new set-up with safer deployment for use on all machines", "\n", "#     caffe_root, image_directory, labels_file, model_def, model_weights, dir_list, labels = set_up_caffe(", "\n", "#         image_directory=image_directory,", "\n", "#         model_file=model_file)", "\n", "#     net, transformer = Caffe_NN_setup(imangenet_mean_image='python/caffe/imagenet/ilsvrc_2012_mean.npy',", "\n", "#                                       batch_size=50, model_def=model_def, model_weights=model_weights,", "\n", "#                                       verbose=True,root_dir=caffe_root)", "\n", "# else:", "\n", "#     # old set-up with hardcoded links and old-style unsafe deployment", "\n", "#     caffe_root, image_directory, labels_file, model_def, model_weights, dir_list, labels = \\", "\n", "#         C.set_up_caffe(image_directory=image_directory,", "\n", "#                      model_file=model_file,", "\n", "#                      label_file_address='data/ilsvrc12/synset_words.txt',", "\n", "#                      dir_file='/storage/data/imagenet_2012_class_list.txt',", "\n", "#                      root_dir='/home/eg16993/src/caffe', verbose=True)", "\n", "#     net, transformer = C.Caffe_NN_setup(imangenet_mean_image='/home/eg16993/src/caffe/python/caffe/imagenet/ilsvrc_2012_mean.npy',", "\n", "#                                   batch_size=1, model_def=model_def, model_weights=model_weights,", "\n", "#                                   verbose=True,root_dir=caffe_root)", "\n", "# why did i changethe names? argh", "\n", "class_labels", "=", "labels", "# this is the readin text file", "\n", "found_labels", "=", "[", "label", ".", "split", "(", "' '", ")", "[", "0", "]", "for", "label", "in", "labels", "]", "# this is the list of the class codes", "\n", "\n", "# this chunk grabs the filenames and", "\n", "image_list", "=", "[", "]", "\n", "correct_class_list", "=", "[", "]", "\n", "file", "=", "open", "(", "correct_class_filename", ",", "'r'", ")", "\n", "for", "line", "in", "file", ":", "\n", "        ", "line_list", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "image_list", ".", "append", "(", "line_list", "[", "0", "]", ")", "\n", "if", "len", "(", "line_list", ")", "==", "2", ":", "\n", "# we have been given classes", "\n", "            ", "correct_class_list", ".", "append", "(", "line_list", "[", "1", "]", ")", "\n", "check_classes", "=", "True", "\n", "", "else", ":", "\n", "# no classes :(", "\n", "            ", "check_classes", "=", "False", "\n", "\n", "", "", "fieldnames", "=", "[", "'image_name'", ",", "# image name", "\n", "'true_class'", ",", "# true class if known", "\n", "'true_class_name'", ",", "# true class name if known", "\n", "'is_correct'", ",", "# did AlexNet get it correct?", "\n", "'top_1_prob'", ",", "# probabilty (certainty) of the top class (top 1)", "\n", "'top_1_prob_class'", ",", "# top_class code", "\n", "'top_1_prob_name'", ",", "# top class human readable name", "\n", "'top_2_prob'", ",", "\n", "'top_2_prob_class'", ",", "\n", "'top_2_prob_name'", ",", "\n", "'top_3_prob'", ",", "\n", "'top_3_prob_class'", ",", "\n", "'top_3_prob_name'", ",", "\n", "'top_4_prob'", ",", "\n", "'top_4_prob_class'", ",", "\n", "'top_4_prob_name'", ",", "\n", "'top_5_prob'", ",", "\n", "'top_5_prob_class'", ",", "\n", "'top_5_prob_name'", "\n", "]", "\n", "\n", "correct_top_1", "=", "[", "]", "\n", "out_filename", "=", "'results.csv'", "\n", "with", "open", "(", "out_filename", ",", "'w'", ")", "as", "csvfile", ":", "\n", "        ", "writer", "=", "csv", ".", "DictWriter", "(", "csvfile", ",", "delimiter", "=", "','", ",", "fieldnames", "=", "fieldnames", ")", "\n", "writer", ".", "writeheader", "(", ")", "\n", "# now we process all the images", "\n", "# TODO: I am sure there is a batch way to do this that would be faster...", "\n", "for", "image_no", "in", "range", "(", "len", "(", "image_list", ")", ")", ":", "\n", "            ", "image_name", "=", "image_list", "[", "image_no", "]", "\n", "image", "=", "C", ".", "caffe", ".", "io", ".", "load_image", "(", "image_directory", "+", "'/'", "+", "image_name", ")", "\n", "if", "check_classes", ":", "\n", "                ", "true_class", "=", "found_labels", "[", "int", "(", "correct_class_list", "[", "image_no", "]", ")", "]", "\n", "true_class_name", "=", "' '", ".", "join", "(", "class_labels", "[", "int", "(", "correct_class_list", "[", "image_no", "]", ")", "]", ".", "split", "(", "' '", ")", "[", "1", ":", "]", ")", "\n", "out_list", ",", "is_correct", "=", "what_am_I_from_image", "(", "\n", "image", "=", "image", ",", "\n", "net", "=", "net", ",", "\n", "transformer", "=", "transformer", ",", "\n", "verbose", "=", "verbose", ",", "\n", "found_labels", "=", "found_labels", ",", "\n", "class_labels", "=", "class_labels", ",", "\n", "true_class", "=", "true_class", "\n", ")", "\n", "", "else", ":", "\n", "                ", "out_list", ",", "is_correct", "=", "what_am_I_from_image", "(", "\n", "image", "=", "image", ",", "\n", "net", "=", "net", ",", "\n", "transformer", "=", "transformer", ",", "\n", "verbose", "=", "verbose", ",", "\n", "found_labels", "=", "found_labels", ",", "\n", "class_labels", "=", "class_labels", ",", "\n", "true_class", "=", "''", "\n", ")", "\n", "true_class", "=", "'null'", "\n", "true_class_name", "=", "'unknown'", "\n", "", "if", "check_classes", "and", "is_correct", ":", "\n", "                ", "correct_top_1", ".", "append", "(", "image_name", ")", "\n", "", "row", "=", "{", "'image_name'", ":", "image_name", ",", "# image name", "\n", "'true_class'", ":", "true_class", ",", "# true class if known", "\n", "'true_class_name'", ":", "true_class_name", ",", "# true class name if known", "\n", "'is_correct'", ":", "str", "(", "is_correct", ")", ",", "# did AlexNet get it correct?", "\n", "'top_1_prob'", ":", "str", "(", "out_list", "[", "0", "]", "[", "0", "]", ")", ",", "# probabilty (certainty) of the top class (top 1)", "\n", "'top_1_prob_class'", ":", "out_list", "[", "0", "]", "[", "1", "]", ",", "# top_class code", "\n", "'top_1_prob_name'", ":", "out_list", "[", "0", "]", "[", "2", "]", ",", "# top class human readable name", "\n", "'top_2_prob'", ":", "str", "(", "out_list", "[", "1", "]", "[", "0", "]", ")", ",", "\n", "'top_2_prob_class'", ":", "out_list", "[", "1", "]", "[", "1", "]", ",", "\n", "'top_2_prob_name'", ":", "out_list", "[", "1", "]", "[", "2", "]", ",", "\n", "'top_3_prob'", ":", "str", "(", "out_list", "[", "2", "]", "[", "0", "]", ")", ",", "\n", "'top_3_prob_class'", ":", "out_list", "[", "2", "]", "[", "1", "]", ",", "\n", "'top_3_prob_name'", ":", "out_list", "[", "2", "]", "[", "2", "]", ",", "\n", "'top_4_prob'", ":", "str", "(", "out_list", "[", "3", "]", "[", "0", "]", ")", ",", "\n", "'top_4_prob_class'", ":", "out_list", "[", "3", "]", "[", "1", "]", ",", "\n", "'top_4_prob_name'", ":", "out_list", "[", "3", "]", "[", "2", "]", ",", "\n", "'top_5_prob'", ":", "str", "(", "out_list", "[", "4", "]", "[", "0", "]", ")", ",", "\n", "'top_5_prob_class'", ":", "out_list", "[", "4", "]", "[", "1", "]", ",", "\n", "'top_5_prob_name'", ":", "out_list", "[", "4", "]", "[", "2", "]", "\n", "}", "\n", "sorted_row", "=", "OrderedDict", "(", "sorted", "(", "row", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "fieldnames", ".", "index", "(", "item", "[", "0", "]", ")", ")", ")", "\n", "writer", ".", "writerow", "(", "sorted_row", ")", "\n", "", "", "print", "(", "'No. of correct (top 1): {}'", ".", "format", "(", "len", "(", "correct_top_1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_activation.combine_h5_files_in_activation_table": [[58, 88], ["os.path.join", "numpy.loadtxt", "kmeans.test_activation_table.TestActivationTable", "kmeans.test_activation_table.TestActivationTable", "kmeans.activation_table.ActivationTable", "kmeans.activation_table.ActivationTable", "kmeans.activation_table.ActivationTable.add_file", "print", "print", "os.path.join"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_file"], ["", "def", "combine_h5_files_in_activation_table", "(", "h5_file_location", "=", "'/storage/data/Temp_ImageNet_Test/'", ",", "\n", "h5_list_filename", "=", "'h5_list.txt'", ",", "h5_list", "=", "None", ",", "useFile", "=", "True", ",", "verbose", "=", "True", ",", "\n", "test", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Combines several h5 files into a single activation table for the win\n    h5_file_location: folder containing the h5 files\n    h5_list_filename: the filename of a list of h5 files to analyse\n    useFile: whether to use a file full of h5 names -- could expand to include h5 list as an input\n    h5List: feed this in if you dont want to make files\n    \"\"\"", "\n", "# TO-DO possibly sort the h5_list_filename bit so it reads in the h5 files instead or perahps as a switch", "\n", "if", "useFile", ":", "\n", "        ", "h5_list_file", "=", "os", ".", "path", ".", "join", "(", "h5_file_location", ",", "h5_list_filename", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'Using directories from {}'", ".", "format", "(", "h5_list_file", ")", ")", "\n", "", "h5_list", "=", "np", ".", "loadtxt", "(", "h5_list_file", ",", "str", ",", "delimiter", "=", "'\\t'", ")", "\n", "", "else", ":", "\n", "# I think you could feed in the h5_list instead", "\n", "        ", "pass", "\n", "# this chunk loads the acitvations into an acativation table", "\n", "", "if", "test", ":", "\n", "        ", "acts", "=", "kmeans", ".", "test_activation_table", ".", "TestActivationTable", "(", "mean", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "acts", "=", "kmeans", ".", "activation_table", ".", "ActivationTable", "(", "mean", "=", "False", ")", "\n", "", "for", "file", "in", "h5_list", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "'adding file {}'", ".", "format", "(", "file", ")", ")", "\n", "", "acts", ".", "add_file", "(", "os", ".", "path", ".", "join", "(", "h5_file_location", ",", "file", ")", ")", "\n", "# training_files = [os.path.join(image_directory, '{}_fc8.h5'.format(x)) for x in class_list]", "\n", "", "return", "acts", ",", "h5_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_activation.check_labels": [[117, 136], ["print", "acts.get_all_activation_indices", "acts.get_activation", "print", "print", "acts.get_activation.index[].split", "print", "acts.get_activation", "acts.get_activation"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationObject.get_all_activation_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation"], ["", "def", "check_labels", "(", "acts", ",", "class_labels", ")", ":", "\n", "# this checks that our labels are assigned properly", "\n", "# this only makes sense if the folders were labelled", "\n", "        ", "print", "(", "'point: \\t assigned label'", ")", "\n", "for", "current_point", "in", "acts", ".", "get_all_activation_indices", "(", ")", ":", "\n", "# this code assumes that te points are put in in files named by the class!", "\n", "#assigned_label = class_labels[acts.get_activation(current_point).label].split(' ')[0]", "\n", "            ", "point", "=", "acts", ".", "get_activation", "(", "current_point", ")", "\n", "assigned_label", "=", "point", ".", "label", "\n", "label_from_h5", "=", "point", ".", "index", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "count", "=", "0", "\n", "if", "not", "assigned_label", "==", "label_from_h5", ":", "\n", "                ", "print", "(", "'{}, \\t {}'", ".", "format", "(", "acts", ".", "get_activation", "(", "current_point", ")", ",", "\n", "class_labels", "[", "acts", ".", "get_activation", "(", "current_point", ")", ".", "label", "]", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "", "", "if", "count", "==", "0", ":", "\n", "            ", "print", "(", "'Labels are correct: check passed!'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Check failed: {} labels are incorrect'", ".", "format", "(", "count", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_activation.main": [[138, 219], ["print", "set_up_caffe_net.main", "print", "print", "print", "Make_activation.combine_h5_files_in_activation_table", "Make_activation.check_labels", "Make_activation.combine_h5_files_in_activation_table", "Make_activation.combine_h5_files_in_activation_table", "Make_activation.combine_h5_files_in_activation_table", "Make_activation.combine_h5_files_in_activation_table", "kmeans.activation_table.ActivationTable", "kmeans.activation_table.ActivationTable", "kmeans.activation_table.ActivationTable.add_merged_file", "kmeans.activation_table.ActivationTable.add_merged_file", "kmeans.activation_table.ActivationTable.add_merged_file", "kmeans.activation_table.ActivationTable.add_merged_file", "kmeans.activation_table.ActivationTable.add_merged_file", "kmeans.activation_table.ActivationTable.add_merged_file", "kmeans.activation_table.ActivationTable.add_merged_file"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.main", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_activation.combine_h5_files_in_activation_table", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_activation.check_labels", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_activation.combine_h5_files_in_activation_table", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_activation.combine_h5_files_in_activation_table", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_activation.combine_h5_files_in_activation_table", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_activation.combine_h5_files_in_activation_table", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_merged_file", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_merged_file", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_merged_file", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_merged_file", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_merged_file", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_merged_file", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_merged_file"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "print", "(", "'Make_activation'", ")", "\n", "global", "acts", ",", "class_labels", ",", "h5_list", ",", "caffe_settings", "\n", "# class_labels is the imagenet labels for 2012, both human readable and n909402394", "\n", "image_directory", "=", "'/storage/data/imagenet_2012'", "#'/storage/data/0602_L1_reg_top_1_imagenet_2012'", "\n", "# set up caffe default", "\n", "#image_directory = '/storage/data/top_1_imagenet_2012/'", "\n", "\n", "\n", "# this is hte bit that sets up the caffe networks ------------------------------------------------------------------", "\n", "caffe_settings", "=", "s", ".", "main", "(", ")", "\n", "# caffe_root = s.caffe_root", "\n", "image_directory", "=", "caffe_settings", ".", "image_directory", "\n", "labels_file", "=", "caffe_settings", ".", "labels_file", "\n", "model_def", "=", "caffe_settings", ".", "model_def", "\n", "model_weights", "=", "caffe_settings", ".", "model_weights", "\n", "dir_list", "=", "caffe_settings", ".", "dir_list", "\n", "labels", "=", "caffe_settings", ".", "labels", "\n", "net", "=", "caffe_settings", ".", "net", "\n", "transformer", "=", "caffe_settings", ".", "transformer", "\n", "short_labels", "=", "caffe_settings", ".", "short_labels", "\n", "model_file", "=", "caffe_settings", ".", "model_file", "\n", "this_one_file_name", "=", "caffe_settings", ".", "this_one_file_name", "\n", "blob", "=", "caffe_settings", ".", "blob", "\n", "file_root", "=", "caffe_settings", ".", "file_root", "\n", "class_labels", "=", "short_labels", "\n", "# end of the bit tha sets up the caffe netwroks --------------------------------------------------------------------", "\n", "print", "(", "'I am using the following merged h5 file: {}'", ".", "format", "(", "this_one_file_name", ")", ")", "\n", "print", "(", "'Which I expect to be located at: {}'", ".", "format", "(", "file_root", ")", ")", "\n", "\n", "h5_list_filename", "=", "''", "\n", "# #/storage/data/imagenet_2012/test_class_list.txt", "\n", "option", "=", "'merged'", "#'doAllClasses'#'merged'#doAllClasses'#'merged' # 'merged'#''doFewClasses'#'doTwoClasses'#'doFewClasses'#'doAllClasses'", "\n", "layer_option", "=", "'this_one'", "\n", "h5_list_filename", "=", "'h5_list.txt'", "\n", "if", "option", "==", "'doTwoClasses'", ":", "\n", "        ", "acts", ",", "h5_list", "=", "combine_h5_files_in_activation_table", "(", "h5_file_location", "=", "'/storage/data/Temp_ImageNet_Test/'", ",", "\n", "h5_list_filename", "=", "'h5_small_list.txt'", ",", "h5_list", "=", "[", "]", ",", "\n", "useFile", "=", "True", ",", "verbose", "=", "True", ")", "\n", "", "elif", "option", "==", "'doFewClasses'", ":", "\n", "        ", "acts", ",", "h5_list", "=", "combine_h5_files_in_activation_table", "(", "h5_file_location", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "h5_list_filename", "=", "'few_classes_h5_list.txt'", ",", "h5_list", "=", "[", "]", ",", "useFile", "=", "True", ",", "\n", "verbose", "=", "True", ")", "\n", "", "elif", "option", "==", "'doAllClasses'", ":", "\n", "# actually does 993 calsses", "\n", "        ", "acts", ",", "h5_list", "=", "combine_h5_files_in_activation_table", "(", "h5_file_location", "=", "file_root", ",", "\n", "h5_list_filename", "=", "h5_list_filename", ",", "h5_list", "=", "[", "]", ",", "useFile", "=", "True", ",", "\n", "verbose", "=", "True", ")", "\n", "", "elif", "option", "==", "'prob'", ":", "\n", "# actually does classes", "\n", "        ", "acts", ",", "h5_list", "=", "combine_h5_files_in_activation_table", "(", "h5_file_location", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "h5_list_filename", "=", "'prob.txt'", ",", "h5_list", "=", "[", "]", ",", "useFile", "=", "True", ",", "\n", "verbose", "=", "True", ")", "\n", "", "elif", "option", "==", "'few_prob'", ":", "\n", "# actually does 20 classes", "\n", "        ", "acts", ",", "h5_list", "=", "combine_h5_files_in_activation_table", "(", "h5_file_location", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "h5_list_filename", "=", "'few_prob.txt'", ",", "h5_list", "=", "[", "]", ",", "useFile", "=", "True", ",", "\n", "verbose", "=", "True", ")", "\n", "", "elif", "option", "==", "'merged'", ":", "\n", "        ", "acts", "=", "kmeans", ".", "activation_table", ".", "ActivationTable", "(", "mean", "=", "False", ")", "\n", "if", "layer_option", "==", "'fc6_softmaxed'", ":", "\n", "            ", "acts", ".", "add_merged_file", "(", "'/storage/data/imagenet_2012/h5_files/merged_fc7_softmax.h5'", ")", "\n", "", "elif", "layer_option", "==", "'this_one'", ":", "\n", "                ", "acts", ".", "add_merged_file", "(", "file_root", "+", "this_one_file_name", ")", "\n", "", "elif", "layer_option", "==", "'fc6'", ":", "\n", "            ", "acts", ".", "add_merged_file", "(", "'/storage/data/imagenet_2012/h5_files/L1_merged_fc6.h5'", ")", "\n", "", "elif", "layer_option", "==", "'fc8'", ":", "\n", "            ", "acts", ".", "add_merged_file", "(", "'/storage/data/imagenet_2012/h5_files/0905_AN_merged_fc8.h5'", ")", "\n", "", "elif", "layer_option", "==", "'fc8_softmaxed'", ":", "\n", "            ", "acts", ".", "add_merged_file", "(", "'/storage/data/imagenet_2012/h5_files/merged_fc8_softmax.h5'", ")", "\n", "", "elif", "layer_option", "==", "'homemade_prob'", ":", "\n", "            ", "acts", ".", "add_merged_file", "(", "'/storage/data/imagenet_2012/h5_files/merged_fc8_prob.h5'", ")", "\n", "", "elif", "layer_option", "==", "'prob'", ":", "\n", "            ", "acts", ".", "add_merged_file", "(", "file_root", "+", "'AlexNet_merged_prob.h5'", ")", "\n", "\n", "", "", "h5_out_location", "=", "'/storage/data/'", "\n", "h5_out_filename", "=", "'test.h5'", "\n", "\n", "print", "(", "'File loaded options: {}, {}'", ".", "format", "(", "option", ",", "layer_option", ")", ")", "\n", "if", "do_check", ":", "\n", "        ", "check_labels", "(", "acts", ",", "class_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.set_up_caffe": [[83, 129], ["sys.path.insert", "os.path.isfile", "os.path.join", "numpy.loadtxt", "numpy.loadtxt", "caffe.set_device", "caffe.set_mode_gpu", "os.path.join", "os.path.join", "os.path.join", "print", "print", "os.path.exists", "print", "print", "print", "print", "print", "model_file.split"], "function", ["None"], ["def", "set_up_caffe", "(", "image_directory", "=", "'/storage/data/imagenet_2012'", ",", "\n", "model_file", "=", "'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'", ",", "\n", "label_file_address", "=", "'/storage/data/ilsvrc12/synset_words.txt'", ",", "\n", "dir_file", "=", "'/storage/data/imagenet_2012_class_list.txt'", ",", "\n", "root_dir", "=", "''", ",", "\n", "verbose", "=", "True", ",", "\n", "deploy_file", "=", "'deploy.prototxt'", ")", ":", "\n", "    ", "\"\"\"stupid little function that sets up all the addresses that you will need with sensible defaults\n    run this to get caffe working withuot having to think\n    image_directory: root dir for folders of images eg imagenet/\n    model_file: .caffemodel file\n    label_file_address: .txt of the label names\n    dir_file: .txt file of the subdirectories for the class you wish to run\n    \"\"\"", "\n", "if", "root_dir", "==", "''", ":", "\n", "        ", "caffe_root", "=", "os", ".", "environ", "[", "'CAFFE_ROOT'", "]", "\n", "", "else", ":", "\n", "        ", "caffe_root", "=", "root_dir", "\n", "", "sys", ".", "path", ".", "insert", "(", "0", ",", "caffe_root", "+", "'python'", ")", "\n", "# If you get \"No module named _caffe\", either you have not built pycaffe or you have the wrong path.", "\n", "# loads caffee and checks there is a model", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "caffe_root", ",", "model_file", ")", ")", ":", "\n", "        ", "print", "(", "'CaffeNet found.'", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Model not found!'", ")", "\n", "# load ImageNet labels", "\n", "", "labels_file", "=", "os", ".", "path", ".", "join", "(", "caffe_root", ",", "label_file_address", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "labels_file", ")", ":", "\n", "        ", "print", "(", "'You need to run get_ilsvrc_aux.sh'", ")", "\n", "print", "(", "'Look here ---> / data / ilsvrc12 / get_ilsvrc_aux.sh'", ")", "\n", "# !../ data / ilsvrc12 / get_ilsvrc_aux.sh", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'Using directories from {}'", ".", "format", "(", "dir_file", ")", ")", "\n", "", "dir_list", "=", "np", ".", "loadtxt", "(", "dir_file", ",", "str", ",", "delimiter", "=", "'\\t'", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Using labels from {}'", ".", "format", "(", "labels_file", ")", ")", "\n", "", "labels", "=", "np", ".", "loadtxt", "(", "labels_file", ",", "str", ",", "delimiter", "=", "'\\t'", ")", "\n", "caffe", ".", "set_device", "(", "0", ")", "# if we have multiple GPUs, pick the first one", "\n", "caffe", ".", "set_mode_gpu", "(", ")", "\n", "# caffe.set_mode_cpu()", "\n", "model_dir", "=", "'/'", ".", "join", "(", "model_file", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "model_def", "=", "os", ".", "path", ".", "join", "(", "caffe_root", ",", "model_dir", ",", "deploy_file", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Using {} as model def'", ".", "format", "(", "model_def", ")", ")", "\n", "", "model_weights", "=", "os", ".", "path", ".", "join", "(", "caffe_root", ",", "model_file", ")", "\n", "return", "caffe_root", ",", "image_directory", ",", "labels_file", ",", "model_def", ",", "model_weights", ",", "dir_list", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.Caffe_NN_setup": [[131, 187], ["print", "caffe.Net", "numpy.load", "mu.mean().mean.mean().mean", "print", "caffe.io.Transformer", "caffe.io.Transformer.set_transpose", "caffe.io.Transformer.set_mean", "caffe.io.Transformer.set_raw_scale", "caffe.io.Transformer.set_channel_swap", "caffe.Net.blobs[].reshape", "caffe.Net.blobs.items", "caffe.Net.params.items", "os.path.join", "mu.mean().mean.mean", "str", "str", "pdb.set_trace", "str"], "function", ["None"], ["", "def", "Caffe_NN_setup", "(", "model_def", ",", "\n", "model_weights", ",", "\n", "imangenet_mean_image", "=", "'python/caffe/imagenet/ilsvrc_2012_mean.npy'", ",", "\n", "batch_size", "=", "50", ",", "\n", "verbose", "=", "False", ",", "\n", "root_dir", "=", "''", ",", "\n", "img_size", "=", "227", "\n", ")", ":", "\n", "    ", "\"\"\"\n    function to set up a standard Caffe_NN_setup and do imagenet\n    imagenet_mean_image: address of npy array of means to subtract\n    batch_size=50: batchsize for the nnw\n    \"\"\"", "\n", "if", "root_dir", "==", "''", ":", "\n", "        ", "caffe_root", "=", "os", ".", "environ", "[", "'CAFFE_ROOT'", "]", "\n", "", "else", ":", "\n", "        ", "caffe_root", "=", "root_dir", "\n", "", "print", "(", "'Setting up NN'", ")", "\n", "## this sets up the NN", "\n", "net", "=", "caffe", ".", "Net", "(", "model_def", ",", "# defines the structure of the model", "\n", "model_weights", ",", "# contains the trained weights", "\n", "caffe", ".", "TEST", ")", "# use test mode (e.g., don't perform dropout)", "\n", "if", "verbose", ":", "\n", "# for each layer, show the output shape", "\n", "        ", "for", "layer_name", ",", "blob", "in", "net", ".", "blobs", ".", "items", "(", ")", ":", "\n", "            ", "print", "\n", "layer_name", "+", "'\\t'", "+", "str", "(", "blob", ".", "data", ".", "shape", ")", "\n", "", "for", "layer_name", ",", "param", "in", "net", ".", "params", ".", "items", "(", ")", ":", "\n", "            ", "print", "\n", "try", ":", "\n", "                ", "layer_name", "+", "'\\t'", "+", "str", "(", "param", "[", "0", "]", ".", "data", ".", "shape", ")", ",", "str", "(", "param", "[", "1", "]", ".", "data", ".", "shape", ")", "\n", "", "except", "IndexError", ":", "\n", "                ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "# Set up input preprocessing. (We'll use Caffe's caffe.io.Transformer to do this,", "\n", "## but this step is independent of other parts of Caffe, so any custom preprocessing code may be used).", "\n", "# Our default CaffeNet is configured to take images in BGR format. Values are expected to start in the range [0, 255]", "\n", "## and then have the mean ImageNet pixel value subtracted from them. In addition, the channel dimension is expected", "\n", "## as the first (outermost) dimension.", "\n", "# As matplotlib will load images with values in the range [0, 1] in RGB format with the channel as the", "\n", "# innermost dimension, we are arranging for the needed transformations here.", "\n", "# load the mean ImageNet image (as distributed with Caffe) for subtraction", "\n", "", "", "", "mu", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "caffe_root", ",", "imangenet_mean_image", ")", ")", "\n", "mu", "=", "mu", ".", "mean", "(", "1", ")", ".", "mean", "(", "1", ")", "# average over pixels to obtain the mean (BGR) pixel values", "\n", "print", "(", "'{}'", ".", "format", "(", "mu", ")", ")", "\n", "# print('mean-subtracted values:{}', zip('BGR', mu))", "\n", "# create transformer for the input called 'data'", "\n", "transformer", "=", "caffe", ".", "io", ".", "Transformer", "(", "{", "'data'", ":", "net", ".", "blobs", "[", "'data'", "]", ".", "data", ".", "shape", "}", ")", "\n", "transformer", ".", "set_transpose", "(", "'data'", ",", "(", "2", ",", "0", ",", "1", ")", ")", "# move image channels to outermost dimension", "\n", "transformer", ".", "set_mean", "(", "'data'", ",", "mu", ")", "# subtract the dataset-mean value in each channel", "\n", "transformer", ".", "set_raw_scale", "(", "'data'", ",", "255", ")", "# rescale from [0, 1] to [0, 255]", "\n", "transformer", ".", "set_channel_swap", "(", "'data'", ",", "(", "2", ",", "1", ",", "0", ")", ")", "# swap channels from RGB to BGR", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "reshape", "(", "batch_size", ",", "# batch size", "\n", "3", ",", "# 3-channel (BGR) images", "\n", "img_size", ",", "img_size", ")", "# image size is 227x227", "\n", "return", "net", ",", "transformer", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.Get_Model_File": [[189, 203], ["print", "print", "print"], "function", ["None"], ["", "def", "Get_Model_File", "(", "Flag", "=", "''", ")", ":", "\n", "    ", "\"\"\"Stupid little function to make sure you got the correct settings\"\"\"", "\n", "if", "Flag", "==", "'AlexNet_standard'", ":", "\n", "        ", "model_file", "=", "'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'", "# standard (L2 reg)", "\n", "", "elif", "Flag", "==", "'L1_AlexNet'", ":", "\n", "        ", "model_file", "=", "'/storage/models/L1/0602_caffenet_train_iter_733955.caffemodel'", "# L1 reg", "\n", "", "elif", "Flag", "==", "'no_reg_AlexNet'", ":", "\n", "        ", "model_file", "=", "'/storage/models/no_reg/0702_no_ref_caffenet_train_iter_508100.caffemodel'", "# no reg", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Error! You must define a model file'", ")", "\n", "print", "(", "'setting AlexNet default'", ")", "\n", "model_file", "=", "'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'", "\n", "", "print", "(", "'Using model file: {}'", ".", "format", "(", "model_file", ")", ")", "\n", "return", "model_file", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.set_settings": [[205, 246], ["set_up_caffe_net.Get_Model_File", "set_up_caffe_net.Get_Model_File", "set_up_caffe_net.Get_Model_File"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.Get_Model_File", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.Get_Model_File", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.Get_Model_File"], ["", "def", "set_settings", "(", "setting", ",", "blob", ")", ":", "\n", "    ", "\"\"\"wrapper function\"\"\"", "\n", "model_file", "=", "''", "\n", "this_one_file_name", "=", "''", "\n", "if", "setting", "==", "'AN'", ":", "\n", "        ", "model_file", "=", "Get_Model_File", "(", "'AlexNet_standard'", ")", "\n", "", "elif", "setting", "==", "'L1'", ":", "\n", "        ", "model_file", "=", "Get_Model_File", "(", "'L1_AlexNet'", ")", "\n", "", "elif", "setting", "==", "'NR'", ":", "\n", "        ", "model_file", "=", "Get_Model_File", "(", "'no_reg_AlexNet'", ")", "\n", "## now set hte merged filename", "\n", "", "if", "setting", "==", "'AN'", ":", "\n", "        ", "if", "blob", "==", "'fc6'", ":", "\n", "            ", "this_one_file_name", "=", "'AN_merged_fc6_max.h5'", "\n", "", "elif", "blob", "==", "'fc7'", ":", "\n", "            ", "this_one_file_name", "=", "'AN_merged_fc7_max.h5'", "\n", "", "elif", "blob", "==", "'fc8'", ":", "\n", "            ", "this_one_file_name", "=", "'AN_merged_fc8_max.h5'", "\n", "", "elif", "blob", "==", "'prob'", ":", "\n", "            ", "this_one_file_name", "=", "'AN_merged_prob_max.h5'", "\n", "", "elif", "blob", "==", "'conv5'", ":", "\n", "            ", "this_one_file_name", "=", "'AN_merged_conv5_max.h5'", "\n", "", "", "elif", "setting", "==", "'L1'", ":", "\n", "        ", "if", "blob", "==", "'fc6'", ":", "\n", "            ", "this_one_file_name", "=", "'L1_merged_fc6L1.h5'", "\n", "", "elif", "blob", "==", "'fc7'", ":", "\n", "            ", "this_one_file_name", "=", "'0602_L1_reg_merged_fc7.h5'", "\n", "", "elif", "blob", "==", "'fc8'", ":", "\n", "            ", "this_one_file_name", "=", "'0602_L1_reg_merged_fc8.h5'", "\n", "", "elif", "blob", "==", "'prob'", ":", "\n", "            ", "this_one_file_name", "=", "'0602_L1_reg_merged_prob.h5'", "\n", "", "", "elif", "setting", "==", "'NR'", ":", "\n", "        ", "if", "blob", "==", "'fc6'", ":", "\n", "            ", "this_one_file_name", "=", "'0702_no_reg_mergedfc6.h5'", "\n", "", "elif", "blob", "==", "'fc7'", ":", "\n", "            ", "this_one_file_name", "=", "'0702_no_reg_mergedfc7.h5'", "\n", "", "elif", "blob", "==", "'fc8'", ":", "\n", "            ", "this_one_file_name", "=", "'0702_no_reg_mergedfc8.h5'", "\n", "", "elif", "blob", "==", "'prob'", ":", "\n", "            ", "this_one_file_name", "=", "'0702_no_reg_mergedprob.h5'", "\n", "", "", "return", "model_file", ",", "this_one_file_name", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.main": [[258, 325], ["set_up_caffe_net.CaffeSettings", "set_up_caffe_net.Get_Model_File", "print", "print", "print", "set_up_caffe_net.Get_Model_File", "set_up_caffe_net.set_settings", "set_up_caffe_net.set_up_caffe", "set_up_caffe_net.Caffe_NN_setup", "set_up_caffe_net.set_up_caffe", "set_up_caffe_net.Caffe_NN_setup", "label.split"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.Get_Model_File", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.Get_Model_File", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.set_settings", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.set_up_caffe", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.Caffe_NN_setup", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.set_up_caffe", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.Caffe_NN_setup"], ["", "def", "main", "(", ")", ":", "\n", "####################################################################################################################", "\n", "# all SETTINGS! CHANGE THIS BIT!", "\n", "####################################################################################################################", "\n", "# set-up with 2012 defaults", "\n", "# if using docker, you want the defaults if not use:`", "\n", "# model_file = '/storage/models/L1/0602_caffenet_train_iter_733955.caffemodel' # L1 reg", "\n", "# model_file = '/storage/models/no_reg/0702_no_ref_caffenet_train_iter_508100.caffemodel' # no reg", "\n", "# model_file = 'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel' # standard (L2 reg) AlexNet_standard", "\n", "# r.image_directory='/storage/data/top_1_imagenet_2012'", "\n", "    ", "r", "=", "CaffeSettings", "(", ")", "\n", "# r.image_directory = '/storage/data/0602_L1_reg_top_1_imagenet_2012'", "\n", "# r.image_directory = '/storage/data/0702_no_reg_top_1_imagenet_2012'#'/storage/data/imagenet_2012'", "\n", "r", ".", "image_directory", "=", "'/storage/data/AN_top_1_imagenet_2012'", "# '/storage/data/imagenet_2012'", "\n", "r", ".", "image_directory", "=", "'/storage/data/imagenet_2012'", "\n", "model_file", "=", "Get_Model_File", "(", "'AlexNet_standard'", ")", "\n", "# model_file = Get_Model_File('L1_AlexNet')", "\n", "do_by_hand", "=", "True", "\n", "if", "do_by_hand", ":", "\n", "# we're not using a standard model file or standard", "\n", "        ", "print", "(", "'running do_by_hand in set_up_caffe'", ")", "\n", "r", ".", "model_file", "=", "Get_Model_File", "(", "'AlexNet_standard'", ")", "\n", "# r.this_one_file_name = '0702_no_reg_mergedfc8.h5'", "\n", "# r.model_file=Get_Model_File('AlexNet_standard')", "\n", "# r.this_one_file_name= '0905_AN_merged_fc8.h5's", "\n", "# r.this_one_file_name= 'AN_merged_conv5_max.h5'", "\n", "# r.this_one_file_name = 'L1_merged_fc6L1.h5'", "\n", "r", ".", "this_one_file_name", "=", "'AN_merged_fc8_max.h5'", "# 'AN_merged_conv5_max.h5'#'AN_merged_fc6_max.h5'#'AN_merged_fc8_all.h5'", "\n", "# r.this_one_file_name = '/storage/data/0602_L1_reg_top_1_imagenet_2012'", "\n", "# r.model_file=Get_Model_File('L1_AlexNet')", "\n", "# r.this_one_file_name = '0702_no_reg_merged_oliprob.h5'", "\n", "", "else", ":", "\n", "        ", "r", ".", "setting", "=", "'AN'", "# AN for AlexNet, NR for no reg, L1 for L1", "\n", "r", ".", "blob", "=", "'fc6'", "\n", "r", ".", "model_file", ",", "r", ".", "this_one_file_name", "=", "set_settings", "(", "setting", ",", "blob", ")", "\n", "# this hte address of the merged.h5 if you have it", "\n", "", "r", ".", "file_root", "=", "'/storage/data/AlexNet_Merged/'", "\n", "# r.file_root = '/storage/data/imagenet_2012/'", "\n", "\n", "####################################################################################################################", "\n", "\n", "if", "usingDocker", ":", "\n", "# new set-up with safer deployment for use on all machines", "\n", "        ", "r", ".", "caffe_root", ",", "r", ".", "image_directory", ",", "r", ".", "labels_file", ",", "r", ".", "model_def", ",", "r", ".", "model_weights", ",", "r", ".", "dir_list", ",", "r", ".", "labels", "=", "set_up_caffe", "(", "\n", "image_directory", "=", "r", ".", "image_directory", ",", "\n", "model_file", "=", "r", ".", "model_file", "\n", ")", "\n", "r", ".", "net", ",", "r", ".", "transformer", "=", "Caffe_NN_setup", "(", "imangenet_mean_image", "=", "'python/caffe/imagenet/ilsvrc_2012_mean.npy'", ",", "\n", "batch_size", "=", "50", ",", "model_def", "=", "r", ".", "model_def", ",", "model_weights", "=", "r", ".", "model_weights", ",", "\n", "verbose", "=", "True", ",", "root_dir", "=", "r", ".", "caffe_root", ",", "img_size", "=", "r", ".", "img_size", ")", "\n", "", "else", ":", "\n", "# old set-up with hardcoded links and old-style unsafe deployment", "\n", "        ", "r", ".", "caffe_root", ",", "r", ".", "image_directory", ",", "r", ".", "labels_file", ",", "r", ".", "model_def", ",", "r", ".", "model_weights", ",", "r", ".", "dir_list", ",", "r", ".", "labels", "=", "set_up_caffe", "(", "image_directory", "=", "r", ".", "image_directory", ",", "\n", "model_file", "=", "r", ".", "model_file", ",", "\n", "label_file_address", "=", "'data/ilsvrc12/synset_words.txt'", ",", "\n", "dir_file", "=", "'/storage/data/imagenet_2012_class_list.txt'", ",", "\n", "root_dir", "=", "'/home/eg16993/src/caffe'", ",", "verbose", "=", "True", ")", "\n", "r", ".", "net", ",", "r", ".", "transformer", "=", "Caffe_NN_setup", "(", "\n", "imangenet_mean_image", "=", "'/home/eg16993/src/caffe/python/caffe/imagenet/ilsvrc_2012_mean.npy'", ",", "\n", "batch_size", "=", "50", ",", "model_def", "=", "r", ".", "model_def", ",", "model_weights", "=", "r", ".", "model_weights", ",", "\n", "verbose", "=", "True", ",", "root_dir", "=", "r", ".", "caffe_root", ")", "\n", "", "r", ".", "short_labels", "=", "[", "label", ".", "split", "(", "' '", ")", "[", "0", "]", "for", "label", "in", "r", ".", "labels", "]", "\n", "\n", "print", "(", "'Running in image_directory: {}'", ".", "format", "(", "r", ".", "image_directory", ")", ")", "\n", "print", "(", "'Using this model file: {}'", ".", "format", "(", "r", ".", "model_file", ")", ")", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.analysis.ThreadedRunner.__init__": [[20, 29], ["threading.Thread"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tasks", ",", "maxparallel", "=", "8", ")", ":", "\n", "        ", "\"\"\"\n        tasks: an array of tuples of the form (function,arguments) to call\n        maxparallel: the maximum number of threads to be running at once\n        \"\"\"", "\n", "self", ".", "threads", "=", "[", "threading", ".", "Thread", "(", "target", "=", "f", ",", "kwargs", "=", "k", ")", "for", "(", "f", ",", "k", ")", "in", "tasks", "]", "\n", "# TODO: spin up seperate thread managers to maximise throughput", "\n", "self", ".", "maxparallel", "=", "8", "\n", "self", ".", "next_thread", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.analysis.ThreadedRunner.run": [[30, 62], ["len", "min", "imp.lock_held", "imp.release_lock", "thread.start", "imp.acquire_lock", "len", "len"], "methods", ["None"], ["", "def", "run", "(", "self", ",", "threadrunlimit", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        threadrunlimit: only run this many threads at most total,\n                        if None (default) then run all threads\n        \"\"\"", "\n", "runcount", "=", "len", "(", "self", ".", "threads", "[", "self", ".", "next_thread", ":", "]", ")", "\n", "if", "threadrunlimit", "is", "not", "None", ":", "\n", "            ", "runcount", "=", "min", "(", "runcount", ",", "threadrunlimit", ")", "\n", "\n", "", "next_thread", "=", "0", "\n", "while", "runcount", ">", "0", ":", "\n", "            ", "batch", "=", "self", ".", "threads", "[", "next_thread", ":", "next_thread", "+", "self", ".", "maxparallel", "]", "\n", "\n", "# cannot start threads while imp lock is held.", "\n", "toLock", "=", "imp", ".", "lock_held", "(", ")", "\n", "if", "toLock", ":", "\n", "                ", "imp", ".", "release_lock", "(", ")", "\n", "\n", "# Start all threads in this batch", "\n", "", "for", "thread", "in", "batch", ":", "\n", "                ", "thread", ".", "start", "(", ")", "\n", "\n", "# Wait for them all to finish", "\n", "", "for", "thread", "in", "batch", ":", "\n", "                ", "thread", ".", "join", "\n", "\n", "# rest lock state", "\n", "", "if", "toLock", ":", "\n", "                ", "imp", ".", "acquire_lock", "(", ")", "\n", "\n", "", "runcount", "=", "runcount", "-", "len", "(", "batch", ")", "\n", "next_thread", "=", "next_thread", "+", "len", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.analysis.fk_plotter": [[64, 107], ["range", "matplotlib.figure", "itertools.cycle", "range", "matplotlib.xlim", "matplotlib.legend().draggable", "matplotlib.plot", "len", "numpy.array", "len", "matplotlib.plot", "matplotlib.axhline", "matplotlib.axhline", "matplotlib.title", "matplotlib.title", "matplotlib.xlabel", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.ylabel", "matplotlib.show", "plt.figure.savefig", "range", "matplotlib.legend", "str", "itertools.cycle.next", "min", "max", "str", "str"], "function", ["None"], ["", "", "", "def", "fk_plotter", "(", "dks", ",", "noOfK", ",", "lRange", "=", "None", ",", "error", "=", "0.15", ",", "xaxis", "=", "1", ",", "title", "=", "None", ",", "xlabel", "=", "None", ",", "ylabel", "=", "None", ",", "showPlots", "=", "1", ",", "\n", "savePlots", "=", "0", ")", ":", "\n", "    ", "\"\"\"Produces F(k) plots for each layer of neurons\"\"\"", "\n", "\"lRange = range of layers to plot\"", "\n", "\"error = error below 1 which we consider significant\"", "\n", "\"xaxis = where to draw the xaxis line\"", "\n", "if", "lRange", "==", "None", ":", "\n", "        ", "lRange", "=", "range", "(", "len", "(", "dks", ")", ")", "\n", "", "for", "l", "in", "lRange", ":", "\n", "# l is the number of layers -- send a smaller dks if you don't want them all!", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "l", ")", "\n", "x_data", "=", "np", ".", "array", "(", "range", "(", "noOfK", ")", ")", "+", "1", "\n", "marker", "=", "itertools", ".", "cycle", "(", "[", "'o'", ",", "'>'", ",", "'<'", ",", "'v'", ",", "'8'", ",", "'d'", ",", "'s'", ",", "'p'", ",", "'*'", "]", ")", "\n", "for", "n", "in", "range", "(", "len", "(", "dks", "[", "l", "]", ")", ")", ":", "\n", "# n is the number neurons in a layer", "\n", "            ", "y_data", "=", "dks", "[", "l", "]", "[", "n", "]", ".", "fs", "\n", "plt", ".", "plot", "(", "x_data", ",", "y_data", ",", "label", "=", "str", "(", "n", ")", ",", "marker", "=", "marker", ".", "next", "(", ")", ",", "alpha", "=", "1", ")", "\n", "", "if", "not", "xaxis", "==", "None", ":", "\n", "# note, if you don't want an xaxis, set xaxis='off'", "\n", "            ", "plt", ".", "axhline", "(", "xaxis", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "axhline", "(", "0", ")", "\n", "", "plt", ".", "xlim", "(", "[", "min", "(", "x_data", ")", "-", "0.25", ",", "max", "(", "x_data", ")", "+", "1", "]", ")", "\n", "# plt.legend()", "\n", "plt", ".", "legend", "(", "bbox_to_anchor", "=", "(", "0.9", ",", "1.1", ")", ",", "loc", "=", "'best'", ",", "ncol", "=", "2", ",", "framealpha", "=", "0.5", ")", ".", "draggable", "(", ")", "\n", "# ax.legend().draggable()", "\n", "plt", ".", "plot", "(", "[", "0.", ",", "noOfK", "]", ",", "[", "1", "-", "error", ",", "1", "-", "error", "]", ")", "\n", "if", "title", "==", "None", ":", "\n", "            ", "plt", ".", "title", "(", "'Layer '", "+", "str", "(", "l", "+", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "title", "(", "title", ")", "\n", "", "if", "xlabel", "==", "None", ":", "\n", "            ", "plt", ".", "xlabel", "(", "'K'", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "xlabel", "(", "xlabel", ")", "\n", "", "if", "ylabel", "==", "None", ":", "\n", "            ", "plt", ".", "ylabel", "(", "'f(K)'", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "ylabel", "(", "ylabel", ")", "\n", "", "if", "showPlots", "==", "1", ":", "\n", "            ", "plt", ".", "show", "(", ")", "\n", "", "if", "savePlots", "==", "1", ":", "\n", "            ", "fig", ".", "savefig", "(", "'Fk'", "+", "str", "(", "l", ")", "+", "'.png'", ",", "dpi", "=", "fig", ".", "dpi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.analysis.jitterer": [[109, 122], ["numpy.ones", "range", "range", "numpy.random.uniform"], "function", ["None"], ["", "", "", "def", "jitterer", "(", "out", ",", "z", ")", ":", "\n", "    ", "\"\"\"This function jitters the x axis\n    1: matrix of layer activations of the form:\n    2. which layer number to do\n    outputs a transposed matrix of no of neurons rows and no of data columns\"\"\"", "\n", "Jx", "=", "np", ".", "ones", "(", "out", "[", "z", "]", ".", "T", ".", "shape", ")", "\n", "\n", "for", "i", "in", "range", "(", "out", "[", "z", "]", ".", "T", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "'this is the number of neurons'", "\n", "for", "j", "in", "range", "(", "out", "[", "z", "]", ".", "T", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "'this is the number of data'", "\n", "Jx", "[", "i", ",", "j", "]", "=", "i", "+", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "\n", "", "", "return", "Jx", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.analysis.normalise_to_zero_one_interval": [[124, 128], ["TypeError"], "function", ["None"], ["", "def", "normalise_to_zero_one_interval", "(", "y", ",", "ymin", ",", "ymax", ")", ":", "\n", "    ", "\"\"\"Because I always forget the formula\"\"\"", "\n", "if", "ymin", ">", "ymax", ":", "raise", "TypeError", "(", "'min and max values the wrong way round!'", ")", "\n", "return", "(", "y", "-", "ymin", ")", "/", "(", "ymax", "-", "ymin", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.analysis.plotter": [[130, 157], ["matplotlib.figure", "matplotlib.axis", "matplotlib.ylabel", "matplotlib.xlabel", "max", "min", "max", "min", "range", "range", "matplotlib.axhline", "matplotlib.axhline", "matplotlib.legend", "matplotlib.show", "plt.figure.savefig", "y.flatten", "y.flatten", "len", "matplotlib.plot", "len", "matplotlib.plot", "min", "max", "min", "max", "x.flatten", "x.flatten", "y.flatten", "y.flatten", "str"], "function", ["None"], ["", "def", "plotter", "(", "x", ",", "y", ",", "labels", "=", "[", "'x'", ",", "'y'", "]", ",", "legend", "=", "None", ",", "linestyle", "=", "[", "'o-'", ",", "'+-'", ",", "'*.-'", "]", ",", "xaxis", "=", "None", ",", "showPlots", "=", "1", ",", "savePlots", "=", "0", ")", ":", "\n", "    ", "\"\"\"Make nice plots automatically\"\"\"", "\n", "fig", "=", "plt", ".", "figure", "(", "1", ")", "\n", "xrange", "=", "max", "(", "x", ")", "-", "min", "(", "x", ")", "\n", "yrange", "=", "max", "(", "y", ".", "flatten", "(", ")", ")", "-", "min", "(", "y", ".", "flatten", "(", ")", ")", "\n", "if", "not", "legend", "==", "None", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "y", ")", ")", ":", "\n", "            ", "plt", ".", "plot", "(", "x", ",", "y", "[", "i", "]", ",", "linestyle", "[", "i", "/", "3", "]", ",", "label", "=", "legend", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "y", ")", ")", ":", "\n", "            ", "plt", ".", "plot", "(", "x", ",", "y", "[", "i", "]", ",", "linestyle", "[", "i", "/", "3", "]", ")", "\n", "", "", "if", "not", "xaxis", "==", "None", ":", "\n", "# note, if you don't want an xaxis, set xaxis='off'", "\n", "        ", "plt", ".", "axhline", "(", "xaxis", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "axhline", "(", "0", ")", "\n", "\n", "", "plt", ".", "axis", "(", "[", "min", "(", "x", ".", "flatten", "(", ")", ")", "-", "0.1", "*", "xrange", ",", "max", "(", "x", ".", "flatten", "(", ")", ")", "+", "0.1", "*", "xrange", ",", "\n", "min", "(", "y", ".", "flatten", "(", ")", ")", "-", "0.1", "*", "yrange", ",", "max", "(", "y", ".", "flatten", "(", ")", ")", "+", "0.1", "*", "yrange", "]", ")", "\n", "plt", ".", "ylabel", "(", "labels", "[", "1", "]", ")", "\n", "plt", ".", "xlabel", "(", "labels", "[", "0", "]", ")", "\n", "if", "not", "legend", "==", "None", ":", "\n", "        ", "plt", ".", "legend", "(", "framealpha", "=", "0.5", ")", "\n", "", "if", "showPlots", "==", "1", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "", "if", "savePlots", "==", "1", ":", "\n", "        ", "fig", ".", "savefig", "(", "'Hk'", "+", "str", "(", "x", "[", "0", "]", ")", "+", "'.png'", ",", "dpi", "=", "fig", ".", "dpi", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.analysis.hinton": [[173, 198], ["ax.patch.set_facecolor", "ax.set_aspect", "ax.xaxis.set_major_locator", "ax.yaxis.set_major_locator", "numpy.ndenumerate", "ax.autoscale_view", "ax.invert_yaxis", "matplotlib.gca", "matplotlib.NullLocator", "matplotlib.NullLocator", "numpy.sqrt", "matplotlib.Rectangle", "ax.add_patch", "analysis.hinton", "matplotlib.show", "numpy.ceil", "numpy.abs", "numpy.random.rand", "numpy.log", "numpy.log", "numpy.abs().max", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.analysis.hinton"], ["def", "hinton", "(", "matrix", ",", "max_weight", "=", "None", ",", "ax", "=", "None", ")", ":", "\n", "    ", "\"\"\"Draw Hinton diagram for visualizing a weight matrix.\"\"\"", "\n", "ax", "=", "ax", "if", "ax", "is", "not", "None", "else", "plt", ".", "gca", "(", ")", "\n", "\n", "if", "not", "max_weight", ":", "\n", "        ", "max_weight", "=", "2", "**", "np", ".", "ceil", "(", "np", ".", "log", "(", "np", ".", "abs", "(", "matrix", ")", ".", "max", "(", ")", ")", "/", "np", ".", "log", "(", "2", ")", ")", "\n", "\n", "", "ax", ".", "patch", ".", "set_facecolor", "(", "'gray'", ")", "\n", "ax", ".", "set_aspect", "(", "'equal'", ",", "'box'", ")", "\n", "ax", ".", "xaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "\n", "ax", ".", "yaxis", ".", "set_major_locator", "(", "plt", ".", "NullLocator", "(", ")", ")", "\n", "\n", "for", "(", "x", ",", "y", ")", ",", "w", "in", "np", ".", "ndenumerate", "(", "matrix", ")", ":", "\n", "        ", "color", "=", "'white'", "if", "w", ">", "0", "else", "'black'", "\n", "size", "=", "np", ".", "sqrt", "(", "np", ".", "abs", "(", "w", ")", "/", "max_weight", ")", "\n", "rect", "=", "plt", ".", "Rectangle", "(", "[", "x", "-", "size", "/", "2", ",", "y", "-", "size", "/", "2", "]", ",", "size", ",", "size", ",", "\n", "facecolor", "=", "color", ",", "edgecolor", "=", "color", ")", "\n", "ax", ".", "add_patch", "(", "rect", ")", "\n", "\n", "", "ax", ".", "autoscale_view", "(", ")", "\n", "ax", ".", "invert_yaxis", "(", ")", "\n", "\n", "if", "__name__", "==", "'__main__'", ":", "\n", "        ", "hinton", "(", "np", ".", "random", ".", "rand", "(", "20", ",", "20", ")", "-", "0.5", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.test_zhou_densenet.make_synset_files": [[49, 78], ["open", "open", "fh.close", "line.strip().split", "print", "line.strip().split", "print", "open", "image_list.append", "labels_list.append", "fh.writelines", "line.strip", "line.strip"], "function", ["None"], ["def", "make_synset_files", "(", "index_into_index_file", ",", "index_file", ",", "category_file", ",", "out_file_name", ")", ":", "\n", "    ", "\"\"\"Function to get Broden into the correct formats\n    index_into_index_file is which column of index file to take\n    index_file is the files with the images and associated categories\n    category file is the file c_oject,txt etc with the human readable labels\"\"\"", "\"\"", "\n", "## Get a list of images which have associated objects and we'll take those as classes", "\n", "image_list", "=", "[", "]", "\n", "correct_class_list", "=", "[", "]", "\n", "file", "=", "open", "(", "index_file", ",", "'r'", ")", "\n", "for", "line", "in", "file", ":", "\n", "        ", "line_list", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "print", "(", "line_list", ")", "\n", "if", "not", "line_list", "[", "index_into_index_file", "]", "==", "''", ":", "\n", "            ", "image_list", ".", "append", "(", "[", "line_list", "[", "0", "]", ",", "line_list", "[", "index_into_index_file", "]", "]", ")", "\n", "# this the original image name and an image which masks the object", "\n", "# gets the human readable lbels from the file", "\n", "", "", "labels_list", "=", "[", "]", "\n", "file2", "=", "open", "(", "category_file", ",", "'r'", ")", "\n", "for", "line", "in", "file2", ":", "\n", "        ", "line_list", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "print", "(", "line_list", ")", "\n", "if", "not", "line_list", "[", "1", "]", "==", "'number'", ":", "\n", "            ", "labels_list", ".", "append", "(", "[", "line_list", "[", "1", "]", ",", "line_list", "[", "2", "]", "]", ")", "\n", "# write it out in the correct format", "\n", "", "", "with", "open", "(", "out_file_name", ",", "\"w\"", ")", "as", "fh", ":", "\n", "        ", "for", "line", "in", "labels_list", ":", "\n", "            ", "fh", ".", "writelines", "(", "' '", ".", "join", "(", "line", ")", "+", "'\\n'", ")", "\n", "", "", "fh", ".", "close", "(", ")", "\n", "return", "image_list", ",", "labels_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.test_zhou_densenet.get_class_details_broden": [[199, 207], ["short_labels.index", "class_name.split", "x.split"], "function", ["None"], ["def", "get_class_details_broden", "(", "classname", ",", "labels", ",", "short_labels", ")", ":", "\n", "    ", "\"\"\"grabs cat number for a unit\n    classname is the word name of the class\n    labels is our list\"\"\"", "\n", "class_name", "=", "[", "x", "for", "x", "in", "labels", "if", "x", ".", "split", "(", "' '", ")", "[", "1", "]", "==", "classname", "]", "[", "0", "]", "\n", "class_name", "=", "class_name", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "class_pos", "=", "short_labels", ".", "index", "(", "class_name", ")", "\n", "return", "class_name", ",", "class_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet2.Batch.__init__": [[61, 75], ["numpy.copy", "numpy.copy", "blobs.items"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "images", ",", "blobs", ",", "probabilities", ",", "label", ")", ":", "\n", "        ", "''' create a base batch object.\n            size: the numeber of images in this batch\n            images: [] of images in the batch\n            blobs: {layer -> data}\n            probabilties: label guesses.\n            label: the actual label of the batch\n        '''", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "images", "=", "images", "\n", "## THIS IS VERY IMPORTANT< THIS COPYS THE VALueS AND NOT A POINTER! AVOIdS THE AWFuL ERROR OF DOOM", "\n", "self", ".", "blobs", "=", "{", "key", ":", "np", ".", "copy", "(", "value", ")", "for", "key", ",", "value", "in", "blobs", ".", "items", "(", ")", "}", "\n", "self", ".", "probabilities", "=", "np", ".", "copy", "(", "probabilities", ")", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet2.info": [[39, 52], ["hasattr", "sys.__excepthook__", "sys.__excepthook__", "traceback.print_exception", "pdb.post_mortem", "sys.stderr.isatty", "sys.stderr.isatty"], "function", ["None"], ["def", "info", "(", "type", ",", "value", ",", "tb", ")", ":", "\n", "    ", "if", "hasattr", "(", "sys", ",", "'ps1'", ")", "or", "not", "sys", ".", "stderr", ".", "isatty", "(", ")", ":", "\n", "# we are in interactive mode or we don't have a tty-like", "\n", "# device, so we call the default hook", "\n", "        ", "sys", ".", "__excepthook__", "(", "type", ",", "value", ",", "tb", ")", "\n", "", "else", ":", "\n", "        ", "import", "traceback", ",", "pdb", "\n", "# we are NOT in interactive mode, print the exception...", "\n", "traceback", ".", "print_exception", "(", "type", ",", "value", ",", "tb", ")", "\n", "print", "\n", "# ...then start the debugger in post-mortem mode.", "\n", "# pdb.pm() # deprecated", "\n", "pdb", ".", "post_mortem", "(", "tb", ")", "# more \"modern\"", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet2.parse_directory": [[131, 196], ["os.getcwd", "os.listdir", "print", "print", "len", "print", "len", "sys.stdout.write", "sys.stdout.write", "sys.stdout.flush", "sys.stdout.flush", "enumerate", "batches_of_activations.append", "print", "transformer.preprocess", "net.forward", "Caffe_AlexNet2.Batch", "caffe.io.load_image", "os.path.join"], "function", ["None"], ["def", "parse_directory", "(", "net", ",", "transformer", ",", "image_directory", "=", "os", ".", "getcwd", "(", ")", ",", "no_of_images", "=", "None", ",", "batch_size", "=", "50", ",", "verbose", "=", "True", ",", "\n", "blob_list", "=", "blob_list", ",", "label", "=", "None", ")", ":", "\n", "    ", "\"\"\"Function to parse images from a directory into AlexNet and generate a list of classifications\n    image_directory: where to get the images from\n    no_of_images: no. of images to to parse in the directory, default is all\n    batch_size: no. to feed in at a time\n    verbose: whether to spew up meaningless data\n    blob_list: which layers do you want the activations for?\n    \"\"\"", "\n", "image_list", "=", "os", ".", "listdir", "(", "image_directory", ")", "# get a list of images to classify", "\n", "image_list", "=", "[", "x", "for", "x", "in", "image_list", "if", "(", "'JPEG'", "or", "'jpg'", "or", "'PNG'", "or", "'png'", ")", "in", "x", "]", "# nts png functionality not tested", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Using images from {}'", ".", "format", "(", "image_directory", ")", ")", "\n", "", "if", "len", "(", "image_list", ")", "==", "0", ":", "\n", "        ", "print", "(", "'No images found in {}'", ".", "format", "(", "image_directory", ")", ")", "\n", "return", "\n", "", "if", "no_of_images", "==", "None", ":", "\n", "        ", "no_of_images", "=", "len", "(", "image_list", ")", "# per diretory", "\n", "# assert no_of_images >= batch_size", "\n", "", "print", "(", "no_of_images", ")", "\n", "count", "=", "0", "\n", "batches_of_activations", "=", "[", "]", "\n", "# setup loop invariants", "\n", "# how many images are left to process", "\n", "images_to_process", "=", "no_of_images", "\n", "# index of first image in this batch", "\n", "batch_start", "=", "0", "\n", "while", "images_to_process", ">", "0", ":", "\n", "# feed in and transform the images", "\n", "# deal with last case", "\n", "        ", "if", "images_to_process", ">", "batch_size", ":", "\n", "            ", "images_to_process", "-=", "batch_size", "\n", "", "else", ":", "\n", "# handle final batch (may be < batch_size)", "\n", "            ", "batch_size", "=", "images_to_process", "\n", "images_to_process", "=", "0", "\n", "", "sys", ".", "stdout", ".", "write", "(", "'{}-{} '", ".", "format", "(", "batch_start", ",", "batch_start", "+", "batch_size", ")", ")", "\n", "batch_images", "=", "image_list", "[", "batch_start", ":", "batch_start", "+", "batch_size", "]", "\n", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "for", "batch_image_index", ",", "batch_image", "in", "enumerate", "(", "batch_images", ")", ":", "\n", "# this feeds in a batches worth of picture data", "\n", "            ", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "batch_image_index", ",", "...", "]", "=", "transformer", ".", "preprocess", "(", "'data'", ",", "\n", "caffe", ".", "io", ".", "load_image", "(", "\n", "os", ".", "path", ".", "join", "(", "image_directory", ",", "\n", "batch_image", ")", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "# if i==0 and verbose:", "\n", "#    # spew out a picture if you want", "\n", "#    image = caffe.io.load_image(os.path.join(image_directory, image_list[i]))", "\n", "#    plt.imshow(image)", "\n", "#    plt.savefig(\"example_image.png\")", "\n", "### perform classification on a batch", "\n", "", "probabilities", "=", "net", ".", "forward", "(", ")", "[", "'prob'", "]", "\n", "temp", "=", "{", "}", "\n", "for", "blob_name", "in", "blob_list", ":", "\n", "            ", "temp", "[", "blob_name", "]", "=", "net", ".", "blobs", "[", "blob_name", "]", ".", "data", "\n", "", "batches_of_activations", ".", "append", "(", "Batch", "(", "batch_size", ",", "batch_images", ",", "temp", ",", "probabilities", ",", "label", ")", ")", "\n", "# reestablish invariants", "\n", "batch_start", "+=", "batch_size", "\n", "# if verbose:", "\n", "#    output_prob = output[0]['prob'][0]  # the output probability vector for the first image in the batch", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'{} images processed'", ".", "format", "(", "count", ")", ")", "\n", "", "return", "batches_of_activations", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet2.classify_directory": [[198, 269], ["print", "enumerate", "print", "range", "print", "int", "range", "output_prob.argmax", "print", "print", "label.split", "output_prob.argsort", "index_accuracies.append", "index_accuracies.append", "assigned_label_indices.append", "assigned_labels.append", "print", "print", "print", "labels[].split", "labels[].split", "label.split"], "function", ["None"], ["", "def", "classify_directory", "(", "batches", ",", "labels", ",", "check_classification", "=", "False", ",", "\n", "true_class", "=", "None", ",", "no_of_guesses", "=", "1", ",", "\n", "assignIndices", "=", "True", ",", "assignLabels", "=", "False", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"Function to generate a list of classifications from output\n    batches: array of batch objects created by parse_directory\n    check_classification: whether to compare the classification to the known result\n    true_class: what the actual class is (assumes a batch of the same class)\n    no_of_guesses: how many of the top probabilities you want to check for the true_class, default is 1\n    assignIndices: whether to return the assigned indices\n    assignLabels: whether to return the assinged labels\n    \"\"\"", "\n", "# no_of_batches = len(batches)", "\n", "if", "check_classification", "==", "True", ":", "\n", "# verify we are using the correct imagenet", "\n", "        ", "assert", "true_class", "in", "[", "label", ".", "split", "(", "' '", ")", "[", "0", "]", "for", "label", "in", "labels", "]", "\n", "", "if", "check_classification", "==", "True", ":", "\n", "        ", "assert", "true_class", "is", "not", "None", "\n", "", "if", "true_class", "is", "not", "None", ":", "\n", "        ", "assert", "check_classification", "==", "True", "\n", "# correct_indices = []", "\n", "# incorrect_indices =[]", "\n", "", "print", "(", "'classify'", ")", "\n", "for", "batch_no", ",", "batch", "in", "enumerate", "(", "batches", ")", ":", "\n", "# if batch_no==26:", "\n", "#     import pdb;", "\n", "#     pdb.set_trace()", "\n", "        ", "print", "(", "'{}:{}'", ".", "format", "(", "batch_no", ",", "batch", ")", ")", "\n", "# assign labels", "\n", "index_accuracies", "=", "[", "]", "\n", "assigned_label_indices", "=", "[", "]", "\n", "assigned_labels", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "batch", ".", "size", ")", ":", "\n", "            ", "print", "(", "'{}'", ".", "format", "(", "index", ")", ")", "\n", "output_prob", "=", "batch", ".", "probabilities", "[", "index", "]", "\n", "assigned_label_index", "=", "int", "(", "output_prob", ".", "argmax", "(", ")", ")", "# this is the int line number in labels", "\n", "if", "verbose", ":", "\n", "                ", "print", "(", "'predicted class is: {}: {}, {}'", "\n", ".", "format", "(", "assigned_label_index", ",", "\n", "labels", "[", "assigned_label_index", "]", ".", "split", "(", "' '", ")", "[", "0", "]", ",", "\n", "labels", "[", "assigned_label_index", "]", ".", "split", "(", "' '", ")", "[", "1", "]", ")", ")", "\n", "# sort top five predictions from softmax output", "\n", "# top_inds = output_prob.argsort()[::-1][:no_of_guesses]  # reverse sort and take five largest items", "\n", "", "top_inds", "=", "output_prob", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", ":", "no_of_guesses", "]", "# reverse sort and take five largest items", "\n", "top_labels", "=", "[", "labels", "[", "x", "]", "for", "x", "in", "top_inds", "]", "\n", "sorted_out_list", "=", "[", "(", "output_prob", "[", "x", "]", ",", "labels", "[", "x", "]", ")", "for", "x", "in", "top_inds", "]", "\n", "# sorted_out_list = zip(output_prob[top_inds], labels[top_inds])", "\n", "for", "guess", "in", "range", "(", "no_of_guesses", ")", ":", "\n", "                ", "print", "(", "'{}'", ".", "format", "(", "sorted_out_list", "[", "guess", "]", ")", ")", "\n", "", "if", "check_classification", ":", "\n", "                ", "if", "true_class", "in", "[", "label", ".", "split", "(", "' '", ")", "[", "0", "]", "for", "label", "in", "top_labels", "]", ":", "\n", "# ! can change this later so loop over the whole list to see if it is in the top five or not", "\n", "# currently only checks the first position", "\n", "                    ", "if", "verbose", ":", "\n", "                        ", "print", "(", "'{} in {}'", ".", "format", "(", "true_class", ",", "sorted_out_list", ")", ")", "\n", "print", "(", "'correct!'", ")", "\n", "", "index_accuracies", ".", "append", "(", "True", ")", "\n", "", "else", ":", "\n", "                    ", "if", "verbose", ":", "\n", "                        ", "print", "(", "'incorrect'", ")", "\n", "", "index_accuracies", ".", "append", "(", "False", ")", "\n", "", "if", "assignIndices", "==", "True", ":", "\n", "                    ", "assigned_label_indices", ".", "append", "(", "top_inds", "[", "0", "]", ")", "\n", "", "if", "assignLabels", "==", "True", ":", "\n", "                    ", "assigned_labels", ".", "append", "(", "labels", "[", "top_inds", "]", "[", "0", "]", ")", "\n", "", "", "batch", ".", "index_accuracies", "=", "index_accuracies", "\n", "batch", ".", "assigned_labels", "=", "assigned_labels", "\n", "batch", ".", "assigned_label_indices", "=", "assigned_label_indices", "\n", "# if verbose and check_classification:", "\n", "#     print('{} correct for this class out of {}, {}%'.format(len(correct_indices), count,", "\n", "#           100*float(len(correct_indices))/count))", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet2.convert_alexnet_to_h5_max": [[271, 312], ["sum", "kmeans.activation_table.ActivationTable", "kmeans.activation_table.ActivationTable.add_direct", "activation_table.add_direct.save_to_hdf5", "print", "print", "Caffe_AlexNet2.convert_alexnet_to_h5_new", "range", "sum", "numpy.amax", "numpy.resize", "activation_table.add_direct.add_activation", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_direct", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.save_to_hdf5", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_new", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.add_activation"], ["", "def", "convert_alexnet_to_h5_max", "(", "batches", ",", "blob_name", ",", "h5_out_filename", ",", "net", ",", "labels", ")", ":", "\n", "    ", "''' Parse the alexnet results and output the maximum activation for each correct match\n    '''", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Writing out {}'", ".", "format", "(", "h5_out_filename", ")", ")", "\n", "", "image_count", "=", "sum", "(", "[", "sum", "(", "batch", ".", "index_accuracies", ")", "for", "batch", "in", "batches", "]", ")", "\n", "layer", "=", "net", ".", "blobs", "[", "blob_name", "]", "\n", "if", "layer", ".", "width", "==", "1", "and", "layer", ".", "height", "==", "1", ":", "\n", "        ", "print", "(", "\"Asking to take maximum of single value?\"", ")", "\n", "# Switch to single neuron code path", "\n", "return", "convert_alexnet_to_h5_new", "(", "batches", ",", "blob_name", ",", "h5_out_filename", ",", "net", ",", "labels", ")", "\n", "\n", "# makea new activation table", "\n", "", "activation_table", "=", "ActivationTable", "(", ")", "\n", "# add in all the activations", "\n", "activation_handle", "=", "activation_table", ".", "add_direct", "(", "identifier", "=", "blob_name", ",", "\n", "image_count", "=", "image_count", ",", "\n", "neuron_count", "=", "layer", ".", "channels", ",", "\n", "labels", "=", "labels", ",", "\n", "neuron_x_count", "=", "1", ",", "\n", "neuron_y_count", "=", "1", ")", "\n", "# now add in all the activations", "\n", "for", "batch", "in", "batches", ":", "\n", "        ", "activations", "=", "batch", ".", "blobs", "[", "blob_name", "]", "\n", "for", "index", "in", "range", "(", "batch", ".", "size", ")", ":", "\n", "            ", "if", "not", "batch", ".", "index_accuracies", "[", "index", "]", ":", "\n", "# It got it wrong :(", "\n", "                ", "continue", "\n", "", "activation_label", "=", "caffe_settings", ".", "short_labels", "[", "batch", ".", "assigned_label_indices", "[", "index", "]", "]", "\n", "if", "activation_label", "!=", "batch", ".", "label", ":", "\n", "# IF WE HIT HERE, it is broken", "\n", "                ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "assert", "(", "activation_label", "==", "batch", ".", "label", ")", "\n", "activation_values", "=", "np", ".", "amax", "(", "activations", "[", "index", "]", ",", "(", "1", ",", "2", ")", ")", "\n", "activation_values", "=", "np", ".", "resize", "(", "activation_values", ",", "(", "activation_values", ".", "size", ",", "1", ",", "1", ")", ")", "\n", "activation_handle", ".", "add_activation", "(", "activation_values", ",", "\n", "batch", ".", "images", "[", "index", "]", ",", "\n", "activation_label", ")", "\n", "# write out a nice h5 file", "\n", "", "", "activation_handle", ".", "save_to_hdf5", "(", "h5_out_filename", ",", "regenerate_labels", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet2.convert_alexnet_to_h5_new": [[314, 347], ["sum", "kmeans.activation_table.ActivationTable", "kmeans.activation_table.ActivationTable.add_direct", "activation_table.add_direct.save_to_hdf5", "print", "range", "sum", "activation_table.add_direct.add_activation", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_direct", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.save_to_hdf5", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.add_activation"], ["", "def", "convert_alexnet_to_h5_new", "(", "batches", ",", "blob_name", ",", "h5_out_filename", ",", "net", ",", "labels", ")", ":", "\n", "    ", "''' Currently only adds correct ones '''", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Writing out {}'", ".", "format", "(", "h5_out_filename", ")", ")", "\n", "", "image_count", "=", "sum", "(", "[", "sum", "(", "batch", ".", "index_accuracies", ")", "for", "batch", "in", "batches", "]", ")", "\n", "layer", "=", "net", ".", "blobs", "[", "blob_name", "]", "\n", "# makea new activation table", "\n", "activation_table", "=", "ActivationTable", "(", ")", "\n", "# add in all the activations", "\n", "activation_handle", "=", "activation_table", ".", "add_direct", "(", "identifier", "=", "blob_name", ",", "\n", "image_count", "=", "image_count", ",", "\n", "neuron_count", "=", "layer", ".", "channels", ",", "\n", "labels", "=", "labels", ",", "\n", "neuron_x_count", "=", "layer", ".", "width", ",", "\n", "neuron_y_count", "=", "layer", ".", "height", ")", "\n", "# now add in all the activations", "\n", "for", "batch", "in", "batches", ":", "\n", "        ", "activations", "=", "batch", ".", "blobs", "[", "blob_name", "]", "\n", "for", "index", "in", "range", "(", "batch", ".", "size", ")", ":", "\n", "            ", "if", "not", "batch", ".", "index_accuracies", "[", "index", "]", ":", "\n", "# It got it wrong :(", "\n", "                ", "continue", "\n", "", "activation_label", "=", "caffe_settings", ".", "short_labels", "[", "batch", ".", "assigned_label_indices", "[", "index", "]", "]", "\n", "if", "activation_label", "!=", "batch", ".", "label", ":", "\n", "# IF WE HIT HERE, it is broken", "\n", "                ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "assert", "(", "activation_label", "==", "batch", ".", "label", ")", "\n", "activation_handle", ".", "add_activation", "(", "activations", "[", "index", "]", ",", "\n", "batch", ".", "images", "[", "index", "]", ",", "\n", "activation_label", ")", "\n", "# write out a nice h5 file", "\n", "", "", "activation_handle", ".", "save_to_hdf5", "(", "h5_out_filename", ",", "regenerate_labels", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet2.convert_alexnet_to_h5_all": [[349, 381], ["sum", "kmeans.activation_table.ActivationTable", "kmeans.activation_table.ActivationTable.add_direct", "activation_table.add_direct.save_to_hdf5", "print", "range", "sum", "activation_table.add_direct.add_activation"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_direct", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.save_to_hdf5", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.add_activation"], ["", "def", "convert_alexnet_to_h5_all", "(", "batches", ",", "blob_name", ",", "h5_out_filename", ",", "net", ",", "labels", ")", ":", "\n", "    ", "''' adds all images!'''", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Writing out {}'", ".", "format", "(", "h5_out_filename", ")", ")", "\n", "", "image_count", "=", "sum", "(", "[", "sum", "(", "batch", ".", "index_accuracies", ")", "for", "batch", "in", "batches", "]", ")", "\n", "layer", "=", "net", ".", "blobs", "[", "blob_name", "]", "\n", "# makea new activation table", "\n", "activation_table", "=", "kmeans", ".", "activation_table", ".", "ActivationTable", "(", ")", "\n", "# add in all the activations", "\n", "activation_handle", "=", "activation_table", ".", "add_direct", "(", "identifier", "=", "blob_name", ",", "\n", "image_count", "=", "image_count", ",", "\n", "neuron_count", "=", "layer", ".", "channels", ",", "\n", "labels", "=", "labels", ",", "\n", "neuron_x_count", "=", "layer", ".", "width", ",", "\n", "neuron_y_count", "=", "layer", ".", "height", ")", "\n", "# now add in all the activations", "\n", "for", "batch", "in", "batches", ":", "\n", "        ", "activations", "=", "batch", ".", "blobs", "[", "blob_name", "]", "\n", "for", "index", "in", "range", "(", "batch", ".", "size", ")", ":", "\n", "# if not batch.index_accuracies[index]:", "\n", "# It got it wrong :(", "\n", "#    continue", "\n", "            ", "activation_label", "=", "labels", "[", "batch", ".", "assigned_label_indices", "[", "index", "]", "]", "\n", "# if activation_label != batch.label:", "\n", "#    import pdb", "\n", "#    pdb.set_trace()", "\n", "# assert(activation_label==batch.label)", "\n", "activation_handle", ".", "add_activation", "(", "activations", "[", "index", "]", ",", "\n", "batch", ".", "images", "[", "index", "]", ",", "\n", "activation_label", ")", "\n", "# write out a nice h5 file", "\n", "", "", "activation_handle", ".", "save_to_hdf5", "(", "h5_out_filename", ",", "regenerate_labels", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet2.convert_alexnet_to_h5": [[383, 422], ["len", "len", "kmeans.ActivationTable", "kmeans.ActivationTable.add_direct", "activation_table.add_direct.save_to_hdf5", "print", "divmod", "activation_table.add_direct.add_activation"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_direct", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.save_to_hdf5", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.add_activation"], ["", "def", "convert_alexnet_to_h5", "(", "image_list", ",", "blob_name", ",", "assigned_labels", ",", "indices_list", ",", "activations", ",", "h5_out_filename", ",", "net", ")", ":", "\n", "    ", "\"\"\"Takes in alexnet and picture directories\n    image_list: list of image names\n    assigned_labels: labels to label each point with\n    h5_out_filename:  filename to write out to\n    blob_name: name of layer to write activations for\n    indices_list: list of indicies to write to file - should relate to imagenet\n    \"\"\"", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Writing out {}'", ".", "format", "(", "h5_out_filename", ")", ")", "\n", "", "image_count", "=", "len", "(", "image_list", ")", "\n", "layer", "=", "net", ".", "blobs", "[", "blob_name", "]", "\n", "batch_size", "=", "len", "(", "activations", "[", "0", "]", "[", "blob_name", "]", ")", "\n", "# makea new activation table", "\n", "activation_table", "=", "kmeans", ".", "ActivationTable", "(", ")", "\n", "# add in all the activations", "\n", "activation_handle", "=", "activation_table", ".", "add_direct", "(", "identifier", "=", "blob_name", ",", "\n", "image_count", "=", "image_count", ",", "\n", "neuron_count", "=", "layer", ".", "channels", ",", "\n", "labels", "=", "assigned_labels", ",", "\n", "neuron_x_count", "=", "layer", ".", "width", ",", "\n", "neuron_y_count", "=", "layer", ".", "height", ")", "\n", "count", "=", "0", "\n", "# now add in all the activations", "\n", "for", "index", "in", "indices_list", ":", "\n", "        ", "if", "index", ">=", "image_count", ":", "\n", "# caused by the fact we've got an incomplete block at the end which will have odd values.", "\n", "            ", "continue", "\n", "# this is the index of a picture we've analysed", "\n", "", "batch_increment", ",", "remainder", "=", "divmod", "(", "index", ",", "batch_size", ")", "# modulo aritmatic FTW!", "\n", "\n", "activation_handle", ".", "add_activation", "(", "activations", "[", "batch_increment", "]", "[", "blob_name", "]", "[", "remainder", "]", ",", "\n", "image_list", "[", "index", "]", ",", "assigned_labels", "[", "index", "]", ")", "\n", "# activation_handle.add_activation(batch[i]", "\n", "# net.blobs[blob_name].data[i], h5_out_filename, assigned_labels[i])", "\n", "# write out a nice h5 file", "\n", "", "activation_handle", ".", "save_to_hdf5", "(", "h5_out_filename", ")", "\n", "# h5_out_filename.close()", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet2.main": [[466, 560], ["set_up_caffe_net.main", "enumerate", "os.path.join", "print", "os.path.exists", "Caffe_AlexNet2.classify_directory", "range", "os.path.join", "os.path.join", "print", "Caffe_AlexNet2.parse_directory", "len", "len", "print", "print", "Caffe_AlexNet2.convert_alexnet_to_h5_all", "Caffe_AlexNet2.convert_alexnet_to_h5_max", "Caffe_AlexNet2.convert_alexnet_to_h5_new", "NotImplemented"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.main", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.classify_directory", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.parse_directory", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_all", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_max", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_new"], ["", "def", "main", "(", ")", ":", "\n", "####################################################################################################################", "\n", "#       Set-up netowkr iwth defaukts from imagent 2012", "\n", "\n", "# this is hte bit that sets up the caffe networks ------------------------------------------------------------------", "\n", "    ", "global", "caffe_settings", "\n", "caffe_settings", "=", "s", ".", "main", "(", ")", "\n", "# caffe_root = s.caffe_root", "\n", "image_directory", "=", "caffe_settings", ".", "image_directory", "\n", "labels_file", "=", "caffe_settings", ".", "labels_file", "\n", "model_def", "=", "caffe_settings", ".", "model_def", "\n", "model_weights", "=", "caffe_settings", ".", "model_weights", "\n", "dir_list", "=", "caffe_settings", ".", "dir_list", "\n", "labels", "=", "caffe_settings", ".", "labels", "\n", "net", "=", "caffe_settings", ".", "net", "\n", "transformer", "=", "caffe_settings", ".", "transformer", "\n", "short_labels", "=", "caffe_settings", ".", "short_labels", "\n", "# end of the bit tha sets up the caffe netwroks ---------", "\n", "# ###### Change this to select either the correct answers (good only) and take the maximum only", "\n", "do_good_only", "=", "True", "\n", "take_maximum_only", "=", "True", "\n", "# build the net", "\n", "\n", "####################################################################################################################", "\n", "#       The main loop that does evreything -- this now just runs the stuff to generate the n***.h5 files!", "\n", "####################################################################################################################", "\n", "# dir_list = dir_list[27:]", "\n", "\n", "import", "pdb", "\n", "for", "current_index", ",", "current_class", "in", "enumerate", "(", "dir_list", ")", ":", "\n", "        ", "current_image_directory", "=", "os", ".", "path", ".", "join", "(", "image_directory", ",", "current_class", ")", "\n", "print", "(", "'Running in {} ({}/{})'", ".", "format", "(", "current_image_directory", ",", "current_index", ",", "len", "(", "dir_list", ")", ")", ")", "\n", "true_class", "=", "current_class", "\n", "h5_filename_list", "=", "[", "os", ".", "path", ".", "join", "(", "image_directory", ",", "'{}_{}_max.h5'", ".", "format", "(", "current_class", ",", "blob", ")", ")", "for", "blob", "in", "\n", "blob_list", "]", "\n", "h5_filename_list", "=", "[", "os", ".", "path", ".", "join", "(", "image_directory", ",", "'{}.h5'", ".", "format", "(", "current_class", ",", "blob", ")", ")", "for", "blob", "in", "\n", "blob_list", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "h5_filename_list", "[", "0", "]", ")", ":", "\n", "            ", "print", "(", "\"WARNING: {} already exists, skipping {}\"", ".", "format", "(", "h5_filename_list", "[", "0", "]", ",", "current_class", ")", ")", "\n", "continue", "\n", "", "try", ":", "\n", "            ", "batches_of_activations", "=", "parse_directory", "(", "net", "=", "net", ",", "\n", "transformer", "=", "transformer", ",", "\n", "image_directory", "=", "current_image_directory", ",", "\n", "no_of_images", "=", "None", ",", "\n", "batch_size", "=", "50", ",", "\n", "verbose", "=", "False", ",", "\n", "blob_list", "=", "blob_list", ",", "\n", "label", "=", "true_class", ")", "\n", "", "except", "Exception", "as", "exception", ":", "\n", "            ", "print", "(", "'true class = {}'", ".", "format", "(", "true_class", ")", ")", "\n", "print", "(", "\"ERROR: unable to parse directory {}: {}\"", ".", "format", "(", "current_class", ",", "exception", ")", ")", "\n", "import", "traceback", ",", "pdb", "\n", "# we are NOT in interactive mode, print the exception...", "\n", "# traceback.print_exception(type, value, tb)", "\n", "# ...then start the debugger in post-mortem mode.", "\n", "# pdb.pm() # deprecated", "\n", "# pdb.post_mortem(tb) # more \"modern\"", "\n", "continue", "\n", "\n", "", "classify_directory", "(", "batches", "=", "batches_of_activations", ",", "\n", "labels", "=", "labels", ",", "\n", "check_classification", "=", "True", ",", "\n", "true_class", "=", "current_class", ",", "\n", "no_of_guesses", "=", "caffe_settings", ".", "no_of_guesses", ",", "\n", "assignIndices", "=", "True", ",", "\n", "assignLabels", "=", "False", ",", "\n", "verbose", "=", "False", ")", "\n", "\n", "# image_list = good_image_lis", "\n", "### !!! N.B. only correct images are written out!", "\n", "\n", "for", "blob_no", "in", "range", "(", "len", "(", "blob_list", ")", ")", ":", "# t", "\n", "            ", "if", "do_good_only", ":", "\n", "                ", "if", "take_maximum_only", ":", "\n", "                    ", "convert_alexnet_to_h5_max", "(", "batches", "=", "batches_of_activations", ",", "\n", "blob_name", "=", "blob_list", "[", "blob_no", "]", ",", "\n", "h5_out_filename", "=", "h5_filename_list", "[", "blob_no", "]", ",", "\n", "net", "=", "net", ",", "\n", "labels", "=", "labels", ")", "\n", "", "else", ":", "\n", "                    ", "convert_alexnet_to_h5_new", "(", "batches", "=", "batches_of_activations", ",", "\n", "blob_name", "=", "blob_list", "[", "blob_no", "]", ",", "\n", "h5_out_filename", "=", "h5_filename_list", "[", "blob_no", "]", ",", "\n", "net", "=", "net", ",", "\n", "labels", "=", "labels", ")", "\n", "", "", "if", "not", "do_good_only", ":", "\n", "                ", "if", "take_maximum_only", ":", "\n", "                    ", "raise", "NotImplemented", "(", "\"Not written this yet!\"", ")", "\n", "", "convert_alexnet_to_h5_all", "(", "batches", "=", "batches_of_activations", ",", "\n", "blob_name", "=", "blob_list", "[", "blob_no", "]", ",", "\n", "h5_out_filename", "=", "h5_filename_list", "[", "blob_no", "]", ",", "\n", "net", "=", "net", ",", "\n", "labels", "=", "short_labels", ")", "\n", "# convert_alexnet_to_h5(image_list=image_list, blob_name=blob_list[blob_no], assigned_labels=assigned_label_indices,", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.print_test_acts": [[14, 26], ["print", "acts.get_activation", "print", "print", "acts.get_all_point_indices", "len", "len", "acts.get_all_point_indices"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices"], ["def", "print_test_acts", "(", "acts", ")", ":", "\n", "    ", "\"\"\"\n    :param acts:\n    prints out example data\n    :return:\n    \"\"\"", "\n", "print", "(", "'{} files in table'", ".", "format", "(", "len", "(", "acts", ".", "get_all_point_indices", "(", ")", ")", ")", ")", "\n", "egg", "=", "acts", ".", "get_all_point_indices", "(", ")", "[", "0", "]", "\n", "point", "=", "acts", ".", "get_activation", "(", "egg", ")", "\n", "print", "(", "'Example file: {}, vectors are {}-dimensional'", ".", "format", "(", "point", ",", "len", "(", "point", ".", "vector", ")", ")", ")", "\n", "print", "(", "'Example labels: {}'", ".", "format", "(", "point", ".", "labels", ")", ")", "\n", "return", "point", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.make_synset_files": [[284, 313], ["open", "open", "fh.close", "line.strip().split", "print", "line.strip().split", "print", "open", "image_list.append", "labels_list.append", "fh.writelines", "line.strip", "line.strip"], "function", ["None"], ["", "def", "make_synset_files", "(", "index_into_index_file", ",", "index_file", ",", "category_file", ",", "out_file_name", ")", ":", "\n", "    ", "\"\"\"Function to get Broden into the correct formats\n    index_into_index_file is which column of index file to take\n    index_file is the files with the images and associated categories\n    category file is the file c_oject,txt etc with the human readable labels\"\"\"", "\"\"", "\n", "## Get a list of images which have associated objects and we'll take those as classes", "\n", "image_list", "=", "[", "]", "\n", "correct_class_list", "=", "[", "]", "\n", "file", "=", "open", "(", "index_file", ",", "'r'", ")", "\n", "for", "line", "in", "file", ":", "\n", "        ", "line_list", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "print", "(", "line_list", ")", "\n", "if", "not", "line_list", "[", "index_into_index_file", "]", "==", "''", ":", "\n", "            ", "image_list", ".", "append", "(", "[", "line_list", "[", "0", "]", ",", "line_list", "[", "index_into_index_file", "]", "]", ")", "\n", "# this the original image name and an image which masks the object", "\n", "# gets the human readable lbels from the file", "\n", "", "", "labels_list", "=", "[", "]", "\n", "file2", "=", "open", "(", "category_file", ",", "'r'", ")", "\n", "for", "line", "in", "file2", ":", "\n", "        ", "line_list", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "print", "(", "line_list", ")", "\n", "if", "not", "line_list", "[", "1", "]", "==", "'number'", ":", "\n", "            ", "labels_list", ".", "append", "(", "[", "line_list", "[", "1", "]", ",", "line_list", "[", "2", "]", "]", ")", "\n", "# write it out in the correct format", "\n", "", "", "with", "open", "(", "out_file_name", ",", "\"w\"", ")", "as", "fh", ":", "\n", "        ", "for", "line", "in", "labels_list", ":", "\n", "            ", "fh", ".", "writelines", "(", "' '", ".", "join", "(", "line", ")", "+", "'\\n'", ")", "\n", "", "", "fh", ".", "close", "(", ")", "\n", "return", "image_list", ",", "labels_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.build_label_dict": [[59, 160], ["sys.stdout.write", "sys.stdout.flush", "acts.get_loaded_files", "len", "acts.get_all_point_indices", "range", "acts.get_loaded_files", "len", "acts.get_all_point_indices", "set", "sys.stdout.write", "sys.stdout.flush", "big_list.append", "h5_analysis_jitterer.filename_to_label", "found_labels.append", "print", "isinstance", "h5_analysis_jitterer.filename_to_label", "enumerate", "print", "print", "range", "len", "len", "big_list.append", "h5_analysis_jitterer.filename_to_label", "found_labels.append", "print", "isinstance", "acts.get_activation().labels[].decode", "print", "acts.get_activation().labels.decode", "acts.get_activation().labels[].decode", "h5_analysis_jitterer.filename_to_label", "len", "len", "len", "print", "acts.get_activation().labels.decode", "acts.get_activation().labels[].decode", "print", "file_name.split", "acts.get_activation", "big_list[].append", "file_name.split", "acts.get_activation", "big_dict.values", "big_dict.items", "file_name.split", "len", "len", "acts.get_activation", "acts.get_activation", "acts.get_activation", "acts.get_activation", "acts.get_activation"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_loaded_files", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_loaded_files", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation"], ["", "def", "build_label_dict", "(", "acts", ",", "use_loaded_files", "=", "True", ",", "verbose", "=", "True", ",", "doMean", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Builds a dictionary of labels to points in local format\n    Gives out a dictionary and a list of found labels\n    acts: activation table object\n    use_loaded_files: whether to assume one file per label (current default)\n    This version can deal with the filenames and labels being different\n    \"\"\"", "\n", "sys", ".", "stdout", ".", "write", "(", "'About to build the label dict (slow)'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "if", "use_loaded_files", "==", "True", ":", "\n", "# we use the filenames as the labels", "\n", "        ", "files", "=", "acts", ".", "get_loaded_files", "(", ")", "\n", "big_list", "=", "[", "]", "\n", "no_of_files", "=", "len", "(", "files", ")", "\n", "found_labels", "=", "[", "]", "\n", "label_dict", "=", "{", "}", "\n", "no_files_in_label", "=", "{", "}", "\n", "for", "file_name", "in", "files", ":", "\n", "            ", "big_list", ".", "append", "(", "[", "]", ")", "\n", "label", "=", "filename_to_label", "(", "file_name", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "found_labels", ".", "append", "(", "label", ")", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'Found {} files in activation table object'", ".", "format", "(", "no_of_files", ")", ")", "\n", "# print('Be patient, I found {} points'.format(len(acts.get_all_activation_indices())))", "\n", "", "for", "current_point", "in", "acts", ".", "get_all_point_indices", "(", ")", ":", "\n", "# TODO:: Make this work with multiple labels", "\n", "            ", "if", "isinstance", "(", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", ",", "(", "bytes", ",", "bytearray", ",", "str", ")", ")", ":", "\n", "# old style, the labels are a numpy byte string", "\n", "                ", "assigned_label", "=", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", ".", "decode", "(", "'UTF-8'", ")", "\n", "", "else", ":", "\n", "# new style, labels are a list", "\n", "                ", "assigned_label", "=", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", "[", "0", "]", ".", "decode", "(", "'UTF-8'", ")", "\n", "", "assigned_label", "=", "filename_to_label", "(", "assigned_label", ")", "\n", "# except AttributeError:", "\n", "#     assigned_label = acts.get_activation(current_point).labels.decode('UTF-8')", "\n", "# except ValueError:", "\n", "#     import pdb; pdb.set_trace()", "\n", "for", "f_no", ",", "file_name", "in", "enumerate", "(", "files", ")", ":", "\n", "                ", "label", "=", "filename_to_label", "(", "file_name", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "if", "assigned_label", "==", "label", ":", "\n", "                    ", "big_list", "[", "f_no", "]", ".", "append", "(", "current_point", ")", "\n", "break", "\n", "", "", "", "if", "not", "len", "(", "found_labels", ")", "==", "len", "(", "files", ")", ":", "\n", "            ", "print", "(", "'The number of found labels does not match the number of files in activation table'", ")", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'Found label: \\t No. of points'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "found_labels", ")", ")", ":", "\n", "                ", "print", "(", "'{}: \\t {}'", ".", "format", "(", "found_labels", "[", "i", "]", ",", "len", "(", "big_list", "[", "i", "]", ")", ")", ")", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "found_labels", ")", ")", ":", "\n", "# print(i, found_labels[i])", "\n", "            ", "label_dict", "[", "found_labels", "[", "i", "]", "]", "=", "big_list", "[", "i", "]", "\n", "no_files_in_label", "[", "found_labels", "[", "i", "]", "]", "=", "len", "(", "big_list", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "# we assume acts already has the labels", "\n", "        ", "files", "=", "acts", ".", "get_loaded_files", "(", ")", "\n", "big_list", "=", "[", "]", "\n", "no_of_files", "=", "len", "(", "files", ")", "\n", "found_labels", "=", "[", "]", "\n", "big_dict", "=", "{", "}", "\n", "label_dict", "=", "{", "}", "\n", "no_files_in_label", "=", "{", "}", "\n", "for", "file_name", "in", "files", ":", "\n", "            ", "big_list", ".", "append", "(", "[", "]", ")", "\n", "label", "=", "filename_to_label", "(", "file_name", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "found_labels", ".", "append", "(", "label", ")", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'Found {} files in activation table object'", ".", "format", "(", "no_of_files", ")", ")", "\n", "# print('Be patient, I found {} points'.format(len(acts.get_all_activation_indices())))", "\n", "", "for", "current_point", "in", "acts", ".", "get_all_point_indices", "(", ")", ":", "\n", "# TODO:: Make this work with multiple labels", "\n", "            ", "if", "isinstance", "(", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", ",", "(", "bytes", ",", "bytearray", ",", "str", ")", ")", ":", "\n", "# old style, the labels are a numpy byte string", "\n", "                ", "assigned_label", "=", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", ".", "decode", "(", "'UTF-8'", ")", "\n", "", "else", ":", "\n", "# new style, labels are a list", "\n", "                ", "assigned_label", "=", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", "[", "0", "]", ".", "decode", "(", "'UTF-8'", ")", "\n", "# assigned_label = filename_to_label(assigned_label)", "\n", "# except AttributeError:", "\n", "#     assigned_label = acts.get_activation(current_point).labels.decode('UTF-8')", "\n", "# except ValueError:", "\n", "#     import pdb; pdb.set_trace()", "\n", "", "big_dict", "[", "current_point", "]", "=", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", "[", "0", "]", ".", "decode", "(", "'UTF-8'", ")", "\n", "# we've got all the points", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'Found label: \\t No. of points'", ")", "\n", "", "unique_values", "=", "set", "(", "val", "for", "dic", "in", "big_dict", "for", "val", "in", "big_dict", ".", "values", "(", ")", ")", "\n", "found_labels", "=", "[", "x", "for", "x", "in", "unique_values", "]", "\n", "for", "f_label", "in", "found_labels", ":", "\n", "            ", "list_of_tuples", "=", "[", "x", "[", "0", "]", "for", "x", "in", "big_dict", ".", "items", "(", ")", "if", "x", "[", "1", "]", "==", "f_label", "]", "\n", "label_dict", "[", "f_label", "]", "=", "list_of_tuples", "\n", "# for f_no, file_name in enumerate(files):", "\n", "#     label=filename_to_label(file_name.split('_')[0])", "\n", "#     if assigned_label == label:", "\n", "#         big_list[f_no].append(current_point)", "\n", "#         break", "\n", "if", "verbose", ":", "\n", "                ", "print", "(", "'{}: \\t {}'", ".", "format", "(", "f_label", ",", "len", "(", "list_of_tuples", ")", ")", ")", "\n", "", "", "sys", ".", "stdout", ".", "write", "(", "'Built the label dict'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "return", "label_dict", ",", "found_labels", ",", "no_files_in_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.do_jitter_plot_test": [[162, 190], ["acts.get_activations_for_neuron", "h5_analysis_jitterer.build_cluster_from_class_label", "h5_analysis_jitterer.jitterer", "sys.stdout.write", "sys.stdout.flush", "Automation_experimental_functions.build_label_dict", "sys.stdout.write", "sys.stdout.flush", "str", "str"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.build_cluster_from_class_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.build_label_dict"], ["", "def", "do_jitter_plot_test", "(", "acts", ",", "test_class_index", "=", "0", ",", "current_neuron_index", "=", "0", ",", "label_dict", "=", "''", ",", "found_labels", "=", "''", ",", "\n", "no_files_in_label", "=", "''", ",", "name_leader", "=", "''", ")", ":", "\n", "    ", "\"\"\"Little function to plot a jitterplot and return assigned labesl\n    If your labels are correct, this is useful to doing the selectivity,\n    if not, do one of these to double check there are no odd patterns in the activataions! \"\"\"", "\n", "if", "label_dict", "==", "''", ":", "\n", "# build it", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "'About to build the label dict (slow)'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "label_dict", ",", "found_labels", ",", "no_files_in_label", "=", "build_label_dict", "(", "acts", ",", "use_loaded_files", "=", "False", ",", "verbose", "=", "True", ",", "\n", "doMean", "=", "False", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "'Built the label dict'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "", "current_neuron", "=", "acts", ".", "get_activations_for_neuron", "(", "current_neuron_index", ")", "\n", "cluster_list", ",", "min_list", ",", "max_list", "=", "build_cluster_from_class_label", "(", "acts", "=", "acts", ",", "\n", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "found_labels", "=", "found_labels", ",", "\n", "current_neuron", "=", "current_neuron", ",", "\n", "do_check", "=", "''", ")", "\n", "jitterer", "(", "x_data", "=", "cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "'test_neuron'", "+", "str", "(", "current_neuron_index", ")", "+", "'class'", "+", "str", "(", "\n", "test_class_index", ")", "+", "'cbyc.png'", ",", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "True", ",", "\n", "current_neuron_index", "=", "test_class_index", ")", "\n", "return", "label_dict", ",", "found_labels", ",", "no_files_in_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.get_class_details_broden": [[192, 200], ["short_labels.index", "class_name.split", "x.split"], "function", ["None"], ["", "def", "get_class_details_broden", "(", "classname", ",", "labels", ",", "short_labels", ")", ":", "\n", "    ", "\"\"\"grabs cat number for a unit\n    classname is the word name of the class\n    labels is our list\"\"\"", "\n", "class_name", "=", "[", "x", "for", "x", "in", "labels", "if", "x", ".", "split", "(", "' '", ")", "[", "1", "]", "==", "classname", "]", "[", "0", "]", "\n", "class_name", "=", "class_name", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "class_pos", "=", "short_labels", ".", "index", "(", "class_name", ")", "\n", "return", "class_name", ",", "class_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.guess_n_check_labels": [[204, 249], ["print", "print", "print", "print", "print", "acts.get_test_activation", "len", "len", "print", "len", "len", "[].decode", "x[].decode"], "function", ["None"], ["", "def", "guess_n_check_labels", "(", "acts", ",", "activation_indice_list", ",", "correct_class_list", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"Function to guess labels for known data and compare it to output\n    Bascially this reads the guesses from your activation table\n    acts is activation table of activations should be test activation type\n    activation_indice_list is a list of activations\n    correct_class_list is a list of the correct classes for those points\n    make sure ccl is decoded byte strings\n    do a list of len 1 if they are all the same\n    do a empty list of the label is attached to the point\"\"\"", "\n", "# Test, check that it can correctly assign daisies", "\n", "print", "(", "\"Guessing labels\"", ")", "\n", "# acts.guess_all()", "\n", "if", "correct_class_list", "==", "''", ":", "\n", "# assume correct class list is label", "\n", "        ", "pass", "# we deal with it below", "\n", "", "top_1_count", "=", "0", "\n", "top_5_count", "=", "0", "\n", "\n", "for", "act_index", "in", "activation_indice_list", ":", "\n", "# now use the new code to attempt to guess the labels", "\n", "# fisrt make it guess", "\n", "# But we want the inner details", "\n", "        ", "test_point", "=", "acts", ".", "get_test_activation", "(", "act_index", ",", "True", ")", "\n", "if", "correct_class_list", "==", "''", ":", "\n", "            ", "correct_class_list", "=", "[", "test_point", ".", "label", "]", "# check this!!!!", "\n", "", "elif", "len", "(", "correct_class_list", ")", "==", "1", ":", "\n", "# assume all points are the same class", "\n", "            ", "true_class", "=", "correct_class_list", "[", "0", "]", "\n", "", "else", ":", "\n", "# assume its a list of classes for each point", "\n", "            ", "true_class", "=", "correct_class_list", "[", "act_index", "]", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "\"{}: {}\"", ".", "format", "(", "test_point", ".", "index", ",", "test_point", ".", "guesses", ")", ")", "\n", "", "if", "len", "(", "test_point", ".", "guesses", ")", ">", "0", "and", "test_point", ".", "guesses", "[", "0", "]", "[", "0", "]", ".", "decode", "(", ")", "==", "true_class", ":", "\n", "            ", "top_1_count", "+=", "1", "\n", "", "if", "true_class", "in", "[", "x", "[", "0", "]", ".", "decode", "(", ")", "for", "x", "in", "test_point", ".", "guesses", "]", ":", "\n", "            ", "top_5_count", "+=", "1", "\n", "\n", "", "", "print", "(", "'Top 1 correct = {}'", ".", "format", "(", "top_1_count", ")", ")", "\n", "print", "(", "'Top 5 correct = {}'", ".", "format", "(", "top_5_count", ")", ")", "\n", "pc1", "=", "100", "*", "top_1_count", "/", "len", "(", "activation_indice_list", ")", "\n", "pc5", "=", "100", "*", "top_5_count", "/", "len", "(", "activation_indice_list", ")", "\n", "print", "(", "'Top 1 correct % = {}'", ".", "format", "(", "pc1", ")", ")", "\n", "print", "(", "'Top 5 correct % = {}'", ".", "format", "(", "pc5", ")", ")", "\n", "return", "top_1_count", ",", "top_5_count", ",", "pc1", ",", "pc5", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.get_image_list_from_file": [[251, 268], ["open", "line.strip().split", "image_list.append", "len", "correct_class_list.append", "line.strip", "int"], "function", ["None"], ["", "def", "get_image_list_from_file", "(", "correct_class_filename", ")", ":", "\n", "    ", "\"\"\"Little function to read in images and correct classes fromr a file\n    correct_class_filename = the file to read\"\"\"", "\n", "image_list", "=", "[", "]", "\n", "correct_class_list", "=", "[", "]", "\n", "file", "=", "open", "(", "correct_class_filename", ",", "'r'", ")", "\n", "for", "line", "in", "file", ":", "\n", "        ", "line_list", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "image_list", ".", "append", "(", "line_list", "[", "0", "]", ")", "\n", "if", "len", "(", "line_list", ")", "==", "2", ":", "\n", "# we have been given classes", "\n", "            ", "correct_class_list", ".", "append", "(", "int", "(", "line_list", "[", "1", "]", ")", ")", "\n", "check_classes", "=", "True", "\n", "", "else", ":", "\n", "# no classes :(", "\n", "            ", "check_classes", "=", "False", "\n", "", "", "return", "image_list", ",", "correct_class_list", ",", "check_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.simple_stats_on_vector": [[270, 282], ["collections.Counter", "collections.Counter.most_common", "numpy.mean", "numpy.median", "numpy.std", "numpy.sqrt", "print", "len"], "function", ["None"], ["", "def", "simple_stats_on_vector", "(", "input_vector", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"Simple stats on cluster of activations\"\"\"", "\n", "egg", "=", "Counter", "(", "input_vector", ")", "\n", "modal_activation", "=", "egg", ".", "most_common", "(", ")", "\n", "modal_activation", ",", "count", "=", "modal_activation", "[", "0", "]", "[", "0", "]", ",", "modal_activation", "[", "0", "]", "[", "1", "]", "\n", "mean_activation", "=", "np", ".", "mean", "(", "input_vector", ")", "\n", "median_activation", "=", "np", ".", "median", "(", "input_vector", ")", "\n", "ste", "=", "np", ".", "std", "(", "input_vector", ")", "/", "np", ".", "sqrt", "(", "len", "(", "input_vector", ")", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Mode: {}, count {}, Mean {} +/- {}, Median {}'", ".", "format", "(", "\n", "modal_activation", ",", "count", ",", "mean_activation", ",", "ste", ",", "median_activation", ")", ")", "\n", "", "return", "modal_activation", ",", "count", ",", "mean_activation", ",", "ste", ",", "median_activation", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.build_h5_files": [[315, 327], ["C.main", "merge_layer"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.main", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.merger.merge_layer"], ["", "def", "build_h5_files", "(", "r", ",", "name_leader", "=", "''", ",", "suffix", "=", "''", ",", "input_filenames", "=", "'*.h5'", ")", ":", "\n", "    ", "\"\"\"this will make your .h5 files and merge them\n    r is a caffe_settings object\"\"\"", "\n", "import", "Caffe_AlexNet2", "as", "C", "\n", "C", ".", "main", "(", "r", ")", "# this makes the h5 files", "\n", "from", "merger", "import", "merge_layer", "\n", "merge_layer", "(", "directory", "=", "r", ".", "image_directory", ",", "\n", "layer_name", "=", "r", ".", "blob", ",", "\n", "name_leader", "=", "name_leader", ",", "\n", "suffix", "=", "suffix", ",", "\n", "input_filenames", "=", "input_filenames", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.make_acts": [[329, 351], ["Automation_experimental_functions.print_test_acts", "kmeans.test_activation_table.ActivationTable", "kmeans.test_activation_table.ActivationTable.add_merged_file", "kmeans.test_activation_table.ActivationTable", "kmeans.test_activation_table.ActivationTable.add_normalised_file", "Make_activation.combine_h5_files_in_activation_table"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.print_test_acts", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_merged_file", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_normalised_file", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_activation.combine_h5_files_in_activation_table"], ["", "def", "make_acts", "(", "r", ",", "\n", "use_merged_h5_file", "=", "True", ",", "\n", "use_normalised_h5_file", "=", "False", ",", "\n", "h5_files_directory", "=", "''", ",", "\n", "h5_list_filename", "=", "''", ",", "\n", "h5_list", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Makes an activation table using ActivationTable\"\"\"", "\n", "if", "use_merged_h5_file", "==", "True", ":", "\n", "        ", "acts", "=", "kmeans", ".", "test_activation_table", ".", "ActivationTable", "(", "mean", "=", "False", ")", "\n", "acts", ".", "add_merged_file", "(", "r", ".", "file_root", "+", "r", ".", "this_one_file_name", ")", "\n", "", "elif", "use_normalised_h5_file", ":", "\n", "        ", "acts", "=", "kmeans", ".", "test_activation_table", ".", "ActivationTable", "(", "mean", "=", "False", ")", "\n", "acts", ".", "add_normalised_file", "(", "r", ".", "file_root", "+", "r", ".", "this_one_file_name", ")", "\n", "", "else", ":", "\n", "        ", "acts", ",", "h5_list", "=", "combine_h5_files_in_activation_table", "(", "\n", "h5_file_location", "=", "h5_files_directory", ",", "\n", "h5_list_filename", "=", "h5_list_filename", ",", "\n", "h5_list", "=", "h5_list", ",", "\n", "useFile", "=", "True", ",", "\n", "verbose", "=", "True", ")", "\n", "", "print_test_acts", "(", "acts", ")", "\n", "return", "acts", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.make_test_acts": [[353, 372], ["Automation_experimental_functions.print_test_acts", "kmeans.test_activation_table.TestActivationTable", "kmeans.test_activation_table.TestActivationTable.add_merged_file", "kmeans.test_activation_table.TestActivationTable", "kmeans.test_activation_table.TestActivationTable.add_normalised_file", "Make_activation.combine_h5_files_in_activation_table"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.print_test_acts", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_merged_file", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_normalised_file", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_activation.combine_h5_files_in_activation_table"], ["", "def", "make_test_acts", "(", "r", ",", "use_merged_h5_file", "=", "True", ",", "\n", "use_normalised_h5_file", "=", "False", ",", "\n", "h5_files_directory", "=", "''", ",", "h5_list_filename", "=", "''", ",", "h5_list", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Makes an activation table using TestActivationTable\"\"\"", "\n", "if", "use_merged_h5_file", "==", "True", ":", "\n", "        ", "acts", "=", "kmeans", ".", "test_activation_table", ".", "TestActivationTable", "(", "mean", "=", "False", ")", "\n", "acts", ".", "add_merged_file", "(", "r", ".", "file_root", "+", "r", ".", "this_one_file_name", ")", "\n", "", "elif", "use_normalised_h5_file", ":", "\n", "        ", "acts", "=", "kmeans", ".", "test_activation_table", ".", "TestActivationTable", "(", "mean", "=", "False", ")", "\n", "acts", ".", "add_normalised_file", "(", "r", ".", "file_root", "+", "r", ".", "this_one_file_name", ")", "\n", "", "else", ":", "\n", "        ", "acts", ",", "h5_list", "=", "combine_h5_files_in_activation_table", "(", "\n", "h5_file_location", "=", "h5_files_directory", ",", "\n", "h5_list_filename", "=", "h5_list_filename", ",", "\n", "h5_list", "=", "h5_list", ",", "\n", "useFile", "=", "True", ",", "\n", "verbose", "=", "True", ")", "\n", "", "print_test_acts", "(", "acts", ")", "\n", "return", "acts", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.set_up_acts": [[374, 393], ["Automation_experimental_functions.make_acts", "Automation_experimental_functions.make_acts"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.make_acts", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.make_acts"], ["", "def", "set_up_acts", "(", "r", ",", "h5_files_directory", ",", "h5_file_name", ",", "use_merged_h5_file", "=", "True", ")", ":", "\n", "    ", "\"\"\"Warpper function to set up the activation table for you\"\"\"", "\n", "# make acts & test it", "\n", "if", "use_merged_h5_file", ":", "\n", "# this uses the merged file", "\n", "        ", "acts", "=", "make_acts", "(", "\n", "r", "=", "r", ",", "\n", "use_merged_h5_file", "=", "True", ",", "\n", "h5_files_directory", "=", "''", ",", "\n", "h5_list_filename", "=", "''", ",", "\n", "h5_list", "=", "[", "]", ")", "\n", "", "else", ":", "\n", "        ", "acts", "=", "make_acts", "(", "\n", "r", "=", "''", ",", "\n", "use_merged_h5_file", "=", "False", ",", "\n", "h5_files_directory", "=", "h5_files_directory", ",", "\n", "h5_list_filename", "=", "h5_file_name", ",", "\n", "h5_list", "=", "[", "]", ")", "\n", "", "return", "acts", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Automation_experimental_functions.IM_class_indices": [[395, 409], ["out.append", "out.append", "acts.get_all_point_indices", "acts.get_all_point_indices"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices"], ["", "def", "IM_class_indices", "(", "chosen_classes", ",", "acts", ",", "h5_tail", "=", "'_fc8_max.h5'", ",", "use_merged_h5_file", "=", "True", ",", ")", ":", "\n", "    ", "\"\"\"Wrapper function to grab sets of classes from acts\n    chosen classes is a list of hte imagenet classes in n0090909 format\n    h5_tail is the end of hte .h5 files for non merged files\"\"\"", "\n", "out", "=", "[", "]", "\n", "if", "use_merged_h5_file", ":", "\n", "        ", "for", "chosen_class", "in", "chosen_classes", ":", "\n", "            ", "out", ".", "append", "(", "\n", "[", "(", "f", ",", "i", ")", "for", "(", "f", ",", "i", ")", "in", "acts", ".", "get_all_point_indices", "(", ")", "if", "f", "==", "chosen_class", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "chosen_class", "in", "chosen_classes", ":", "\n", "            ", "out", ".", "append", "(", "\n", "[", "(", "f", ",", "i", ")", "for", "(", "f", ",", "i", ")", "in", "acts", ".", "get_all_point_indices", "(", ")", "if", "f", "==", "[", "chosen_class", "+", "h5_tail", "]", "]", ")", "\n", "", "", "return", "out", "\n", "", ""]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.IM_test_zhou_googlenet_places365.ICLRPaperTest": [[76, 140], ["grab_points_for_a_cluster", "find_zhou_precision", "print", "sum", "print", "print", "print", "print", "numpy.mean", "numpy.std", "print", "numpy.mean", "numpy.std", "print", "print", "print", "egg.append", "sum.append", "numpy.sqrt", "len", "numpy.sqrt", "len", "max", "classA.append", "range", "classnotA.append", "len", "len", "len", "len", "len", "len", "max", "class_name.split"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_zhou_precision"], ["def", "ICLRPaperTest", "(", "classAindices", ",", "\n", "current_neuron_index", ",", "\n", "x_data", ",", "\n", "acts", ",", "\n", "cluster_list", ")", ":", "\n", "    ", "from", "h5_analysis_jitterer", "import", "grab_points_for_a_cluster", ",", "find_zhou_precision", "\n", "\"\"\"Does a suite of tests on the data \"\"\"", "\n", "# this bit does tge zhou precisison", "\n", "local_list", ",", "selected_activations", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "max", "(", "x_data", ")", "/", "4", ",", "\n", "max_selected_x_data", "=", "max", "(", "x_data", ")", ",", "\n", "x_data", "=", "x_data", ",", "\n", "acts", "=", "acts", ",", "\n", "verbose", "=", "True", ")", "\n", "local_list", "=", "local_list", "[", "-", "101", ":", "-", "1", "]", "\n", "selected_activations", "=", "selected_activations", "[", "-", "101", ":", "-", "1", "]", "\n", "zhou_precs_class", ",", "zhou_precs", ",", "zhou_no_of_classes", ",", "zhou", "=", "find_zhou_precision", "(", "number_of_points", "=", "100", ",", "\n", "local_list", "=", "local_list", ")", "\n", "egg", "=", "[", "]", "\n", "for", "class_name", "in", "r", ".", "labels", "[", "bus_indices", "]", ":", "\n", "        ", "egg", ".", "append", "(", "class_name", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "\n", "#", "\n", "", "print", "(", "'Warning, this is hacky, and assumes the .h5 file name so do doublecheck if this answer is 0'", ")", "\n", "count", "=", "[", "]", "\n", "for", "key_start", "in", "egg", ":", "\n", "        ", "key", "=", "key_start", "+", "'_'", "+", "'inception_4e_output'", "+", "'_max'", "\n", "count", ".", "append", "(", "zhou", "[", "key", "]", ")", "\n", "#", "\n", "", "count", "=", "sum", "(", "count", ")", "\n", "zhou_precs", "=", "count", "/", "100.0", "\n", "print", "(", "'Zhou:{}'", ".", "format", "(", "zhou", ")", ")", "\n", "print", "(", "'Zhou precision class: {}\\nZhou precision:{}\\nZhou no. of class:{}\\n'", ".", "format", "(", "egg", ",", "zhou_precs", ",", "\n", "zhou_no_of_classes", ")", ")", "\n", "#", "\n", "#", "\n", "classA", "=", "[", "]", "\n", "for", "index", "in", "classAindices", ":", "\n", "        ", "for", "item", "in", "cluster_list", "[", "index", "]", ":", "\n", "            ", "classA", ".", "append", "(", "item", ")", "\n", "#", "\n", "", "", "classnotA", "=", "[", "]", "\n", "for", "index", "in", "[", "x", "for", "x", "in", "range", "(", "1000", ")", "if", "x", "not", "in", "classAindices", "]", ":", "\n", "        ", "for", "item", "in", "cluster_list", "[", "index", "]", ":", "\n", "            ", "classnotA", ".", "append", "(", "item", ")", "\n", "#", "\n", "", "", "print", "(", "'Representative stats'", ")", "\n", "print", "(", "'Class A is {} items\\t class not A is {} items'", ".", "format", "(", "len", "(", "classA", ")", ",", "len", "(", "classnotA", ")", ")", ")", "\n", "muA", "=", "np", ".", "mean", "(", "classA", ")", "\n", "stdA", "=", "np", ".", "std", "(", "classA", ")", "\n", "meA", "=", "stdA", "/", "np", ".", "sqrt", "(", "len", "(", "classA", ")", ")", "\n", "pc_nonzeroA", "=", "100", "*", "len", "(", "[", "x", "for", "x", "in", "classA", "if", "x", ">", "0.0", "]", ")", "/", "len", "(", "classA", ")", "\n", "print", "(", "'mean (A): {}+/-{}\\nstd (A): {}\\n%A that is nonzero: {}'", "\n", ".", "format", "(", "muA", ",", "meA", ",", "stdA", ",", "pc_nonzeroA", ")", ")", "\n", "munotA", "=", "np", ".", "mean", "(", "classnotA", ")", "\n", "stdnotA", "=", "np", ".", "std", "(", "classnotA", ")", "\n", "menotA", "=", "stdnotA", "/", "np", ".", "sqrt", "(", "len", "(", "classnotA", ")", ")", "\n", "pc_nonzeronotA", "=", "100", "*", "len", "(", "[", "x", "for", "x", "in", "classnotA", "if", "x", ">", "0.0", "]", ")", "/", "len", "(", "classnotA", ")", "\n", "print", "(", "'mean (NOT A): {}+/-{}\\nstd (NOT A): {}\\n%NOT A that is nonzero: {}'", "\n", ".", "format", "(", "munotA", ",", "menotA", ",", "stdnotA", ",", "pc_nonzeronotA", ")", ")", "\n", "CCMAS", "=", "(", "muA", "-", "munotA", ")", "/", "(", "muA", "+", "munotA", ")", "\n", "print", "(", "'CCMAS(A):{}\\n'", ".", "format", "(", "CCMAS", ")", ")", "\n", "print", "(", "'{} & {} & {} & {} & {} & {}'", ".", "format", "(", "pc_nonzeroA", ",", "pc_nonzeronotA", ",", "muA", ",", "munotA", ",", "zhou_precs", ",", "CCMAS", ")", ")", "\n", "#", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calculator2.calculate_missing_precs_recall_stats": [[46, 134], ["range", "len", "len", "len", "print", "print", "abs", "print", "print", "len", "abs"], "function", ["None"], ["def", "calculate_missing_precs_recall_stats", "(", "test_class", "=", "test_class", ",", "\n", "local_list", "=", "local_list", ",", "\n", "Q_stop", "=", "''", ",", "\n", "no_files_in_label", "=", "no_files_in_label", ",", "\n", "no_of_images", "=", "no_of_images", ",", "\n", "verbose", "=", "verbose", ")", ":", "\n", "    ", "\"\"\"Function to calculate the average precision of a local_list\n    current_class = name of the class we're taking as A\n    local_list = sorted list of tuples containing the class and index of each point\n    Q_stop = number at which to stop evaluating the ave precs\n    no_files_in_label = cell array of labels to number of items in that label\n    verbose = whether to print data to screen\"\"\"", "\n", "if", "not", "Q_stop", "==", "''", ":", "\n", "        ", "Q", "=", "Q_stop", "\n", "", "else", ":", "\n", "        ", "Q", "=", "len", "(", "local_list", ")", "\n", "# does all points", "\n", "", "if", "Q", ">", "len", "(", "local_list", ")", ":", "\n", "        ", "Q", "=", "len", "(", "local_list", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'The number of points to check (Q) {} is more than the number of points above minx {}'", ".", "format", "(", "Q", ",", "len", "(", "local_list", ")", ")", ")", "\n", "print", "(", "'Setting Q to len(local_list), you may wish to change your settings'", ")", "\n", "", "", "N_test", "=", "no_files_in_label", "[", "test_class", "]", "# no of items in class A", "\n", "N_not_test", "=", "no_of_images", "-", "N_test", "# i.e. set not-A", "\n", "# set up counters", "\n", "AP", "=", "0", "# average precision", "\n", "found_recall_precs_p95", "=", "False", "\n", "recall_p95", "=", "0.0", "\n", "count_of_test_class", "=", "0", "\n", "recall_p1", "=", "0.0", "\n", "found_recall_precs_p1", "=", "False", "\n", "# loop backwards through the list, abs j is the position in a 1-indexed list", "\n", "recall_x", "=", "0", "# n.b. this is also sensitivity", "\n", "Ave_precs_x", "=", "0", "\n", "specificity_x", "=", "0", "\n", "count_of_false_positives", "=", "0", "# number of not-A on misidentified", "\n", "max_informedness", "=", "0", "\n", "x_for_max_informedness", "=", "0", "\n", "max_f1_stat", "=", "0", "\n", "x_for_max_f1", "=", "0", "\n", "recall_for_max_informedness", "=", "0", "\n", "specificity_for_max_informedness", "=", "0", "\n", "for", "i", "in", "range", "(", "Q", ")", ":", "\n", "        ", "j", "=", "-", "(", "i", "+", "1", ")", "# 1 indexed", "\n", "recall_x_minus_1", "=", "recall_x", "\n", "current_class", "=", "local_list", "[", "j", "]", "[", "0", "]", "\n", "#j = j - 1  # really this is here so we can check j", "\n", "# break", "\n", "if", "count_of_test_class", "==", "N_test", ":", "\n", "# we've found them all", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'found all {} of {}, stopping...'", ".", "format", "(", "N_test", ",", "current_class", ")", ")", "\n", "print", "(", "'{}/{}'", ".", "format", "(", "count_of_test_class", ",", "abs", "(", "j", ")", ")", ")", "\n", "", "break", "\n", "", "if", "(", "current_class", "==", "test_class", ")", ":", "\n", "            ", "count_of_test_class", "=", "count_of_test_class", "+", "1", "# n A", "\n", "", "else", ":", "\n", "            ", "count_of_false_positives", "=", "count_of_false_positives", "+", "1", "\n", "", "precs_x", "=", "count_of_test_class", "/", "(", "abs", "(", "j", ")", ")", "# N.b. this is the sum, we divide by j on the output", "\n", "recall_x", "=", "count_of_test_class", "/", "N_test", "\n", "false_pos_rate", "=", "count_of_false_positives", "/", "no_of_images", "\n", "specificity_x", "=", "1", "-", "false_pos_rate", "\n", "if", "(", "precs_x", "<=", ".95", ")", "and", "(", "found_recall_precs_p95", "is", "False", ")", ":", "\n", "# thingy to grab the recall when precision drops below .95 (if ever)", "\n", "            ", "recall_p95", "=", "recall_x", "\n", "found_recall_precs_p95", "=", "True", "\n", "", "if", "(", "precs_x", "<=", "1", ")", "and", "(", "found_recall_precs_p1", "is", "False", ")", ":", "\n", "# thingy to grab the recall when precision drops below .1 (if ever)", "\n", "            ", "recall_p1", "=", "recall_x", "\n", "found_recall_precs_p1", "=", "True", "\n", "", "delta_recall_x", "=", "recall_x", "-", "recall_x_minus_1", "# difference in recall between this point nd the next", "\n", "weight_precs_x", "=", "precs_x", "*", "delta_recall_x", "# weighted precsion at point x (we do average via weighted sum)", "\n", "Ave_precs_x", "=", "Ave_precs_x", "+", "weight_precs_x", "# average_precision evaluated at point x", "\n", "informedness_x", "=", "recall_x", "+", "specificity_x", "-", "1", "\n", "# if informedness_x > max_informedness:", "\n", "#     max_informedness = informedness_x", "\n", "#     x_for_max_informedness = abs(j)", "\n", "#     recall_for_max_informedness = recall_x", "\n", "#     specificity_for_max_informedness = specificity_x", "\n", "# if (precs_x > 0 and recall_x > 0):", "\n", "#     f1_x = 2*(precs_x*recall_x) / (precs_x + recall_x)", "\n", "# else:", "\n", "#     f1_x = 0", "\n", "# if f1_x > max_f1_stat:", "\n", "#     max_f1_stat = f1_x", "\n", "#     x_for_max_f1 = abs(j)", "\n", "", "out", "=", "(", "recall_p1", ",", "recall_p95", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calculator2.row6_outputter": [[174, 183], ["str", "str", "str", "str"], "function", ["None"], ["def", "row6_outputter", "(", "current_neuron_index", "=", "current_neuron_index", ",", "top_mode_class", "=", "top_mode_class", ",", "\n", "output_precs_data", "=", "output_precs_data", ")", ":", "\n", "    ", "\"\"\"Little wrapper function to write out the row\n    this is the stats over the top 100 activations!\"\"\"", "\n", "row", "=", "{", "'Neuron no.'", ":", "str", "(", "current_neuron_index", ")", ",", "# neuron index", "\n", "'top_mode_class_name'", ":", "str", "(", "top_mode_class", ")", ",", "# class name for top mode class (class with highest number in top 100)", "\n", "'tmc_recall_p1'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'tmc_recall_p095'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "1", "]", ")", "}", "\n", "return", "row", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calculator3.calculate_missing_precs_recall_stats": [[47, 135], ["range", "len", "len", "len", "print", "print", "abs", "print", "print", "len", "abs"], "function", ["None"], ["def", "calculate_missing_precs_recall_stats", "(", "test_class", "=", "test_class", ",", "\n", "local_list", "=", "local_list", ",", "\n", "Q_stop", "=", "''", ",", "\n", "no_files_in_label", "=", "no_files_in_label", ",", "\n", "no_of_images", "=", "no_of_images", ",", "\n", "verbose", "=", "verbose", ")", ":", "\n", "    ", "\"\"\"Function to calculate the average precision of a local_list\n    current_class = name of the class we're taking as A\n    local_list = sorted list of tuples containing the class and index of each point\n    Q_stop = number at which to stop evaluating the ave precs\n    no_files_in_label = cell array of labels to number of items in that label\n    verbose = whether to print data to screen\"\"\"", "\n", "if", "not", "Q_stop", "==", "''", ":", "\n", "        ", "Q", "=", "Q_stop", "\n", "", "else", ":", "\n", "        ", "Q", "=", "len", "(", "local_list", ")", "\n", "# does all points", "\n", "", "if", "Q", ">", "len", "(", "local_list", ")", ":", "\n", "        ", "Q", "=", "len", "(", "local_list", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'The number of points to check (Q) {} is more than the number of points above minx {}'", ".", "format", "(", "Q", ",", "len", "(", "local_list", ")", ")", ")", "\n", "print", "(", "'Setting Q to len(local_list), you may wish to change your settings'", ")", "\n", "", "", "N_test", "=", "no_files_in_label", "[", "test_class", "]", "# no of items in class A", "\n", "N_not_test", "=", "no_of_images", "-", "N_test", "# i.e. set not-A", "\n", "# set up counters", "\n", "AP", "=", "0", "# average precision", "\n", "found_recall_precs_p9", "=", "False", "\n", "recall_p9", "=", "0.0", "\n", "count_of_test_class", "=", "0", "\n", "recall_p1", "=", "0.0", "\n", "found_recall_precs_p1", "=", "False", "\n", "# loop backwards through the list, abs j is the position in a 1-indexed list", "\n", "recall_x", "=", "0", "# n.b. this is also sensitivity", "\n", "Ave_precs_x", "=", "0", "\n", "specificity_x", "=", "0", "\n", "count_of_false_positives", "=", "0", "# number of not-A on misidentified", "\n", "max_informedness", "=", "0", "\n", "x_for_max_informedness", "=", "0", "\n", "max_f1_stat", "=", "0", "\n", "x_for_max_f1", "=", "0", "\n", "recall_for_max_informedness", "=", "0", "\n", "specificity_for_max_informedness", "=", "0", "\n", "for", "i", "in", "range", "(", "Q", ")", ":", "\n", "        ", "j", "=", "-", "(", "i", "+", "1", ")", "# 1 indexed", "\n", "recall_x_minus_1", "=", "recall_x", "\n", "current_class", "=", "local_list", "[", "j", "]", "[", "0", "]", "\n", "#j = j - 1  # really this is here so we can check j", "\n", "# break", "\n", "if", "count_of_test_class", "==", "N_test", ":", "\n", "# we've found them all", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'found all {} of {}, stopping...'", ".", "format", "(", "N_test", ",", "current_class", ")", ")", "\n", "print", "(", "'{}/{}'", ".", "format", "(", "count_of_test_class", ",", "abs", "(", "j", ")", ")", ")", "\n", "", "break", "\n", "", "if", "(", "current_class", "==", "test_class", ")", ":", "\n", "            ", "count_of_test_class", "=", "count_of_test_class", "+", "1", "# n A", "\n", "", "else", ":", "\n", "            ", "count_of_false_positives", "=", "count_of_false_positives", "+", "1", "\n", "", "precs_x", "=", "count_of_test_class", "/", "(", "abs", "(", "j", ")", ")", "# N.b. this is the sum, we divide by j on the output", "\n", "recall_x", "=", "count_of_test_class", "/", "N_test", "\n", "false_pos_rate", "=", "count_of_false_positives", "/", "no_of_images", "\n", "specificity_x", "=", "1", "-", "false_pos_rate", "\n", "if", "(", "precs_x", "<=", ".9", ")", "and", "(", "found_recall_precs_p9", "is", "False", ")", ":", "\n", "# thingy to grab the recall when precision drops below .95 (if ever)", "\n", "            ", "recall_p9", "=", "recall_x", "\n", "found_recall_precs_p9", "=", "True", "\n", "", "if", "(", "precs_x", "<=", "1", ")", "and", "(", "found_recall_precs_p1", "is", "False", ")", ":", "\n", "# thingy to grab the recall when precision drops below .1 (if ever)", "\n", "            ", "recall_p1", "=", "recall_x", "\n", "found_recall_precs_p1", "=", "True", "\n", "", "delta_recall_x", "=", "recall_x", "-", "recall_x_minus_1", "# difference in recall between this point nd the next", "\n", "weight_precs_x", "=", "precs_x", "*", "delta_recall_x", "# weighted precsion at point x (we do average via weighted sum)", "\n", "Ave_precs_x", "=", "Ave_precs_x", "+", "weight_precs_x", "# average_precision evaluated at point x", "\n", "informedness_x", "=", "recall_x", "+", "specificity_x", "-", "1", "\n", "# if informedness_x > max_informedness:", "\n", "#     max_informedness = informedness_x", "\n", "#     x_for_max_informedness = abs(j)", "\n", "#     recall_for_max_informedness = recall_x", "\n", "#     specificity_for_max_informedness = specificity_x", "\n", "# if (precs_x > 0 and recall_x > 0):", "\n", "#     f1_x = 2*(precs_x*recall_x) / (precs_x + recall_x)", "\n", "# else:", "\n", "#     f1_x = 0", "\n", "# if f1_x > max_f1_stat:", "\n", "#     max_f1_stat = f1_x", "\n", "#     x_for_max_f1 = abs(j)", "\n", "", "out", "=", "(", "recall_p1", ",", "recall_p9", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.precision_calculator3.row6_outputter": [[176, 186], ["str", "str", "str", "str", "str"], "function", ["None"], ["def", "row6_outputter", "(", "current_neuron_index", "=", "current_neuron_index", ",", "top_mode_class", "=", "top_mode_class", ",", "\n", "output_precs_data", "=", "output_precs_data", ",", "Zhou", "=", "Zhou", ")", ":", "\n", "    ", "\"\"\"Little wrapper function to write out the row\n    this is the stats over the top 100 activations!\"\"\"", "\n", "row", "=", "{", "'Neuron no.'", ":", "str", "(", "current_neuron_index", ")", ",", "# neuron index", "\n", "'top_mode_class_name'", ":", "str", "(", "top_mode_class", ")", ",", "# class name for top mode class (class with highest number in top 100)", "\n", "'tmc_recall_p1'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "0", "]", ")", ",", "# start of x = 100 data for top 10 classes", "\n", "'tmc_recall_p09'", ":", "str", "(", "output_precs_data", "[", "0", "]", "[", "1", "]", ")", ",", "\n", "'Zhou_no_60'", ":", "str", "(", "Zhou", ")", "}", "\n", "return", "row", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_top_1_set.grab_files": [[26, 52], ["acts.get_file_name().decode", "acts.get_file_name().decode.split", "selected_image_list.append", "selected_image_list.append", "found_classes.append", "acts.get_file_name", "acts.get_file_name().decode.split"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_file_name"], ["def", "grab_files", "(", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "\n", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "\n", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "in_class_sub_dirs", "=", "True", ")", ":", "\n", "    ", "\"\"\"Function to get the selected images and return their addresses\n    in_class_sub_dirs: True if like imagenet, false if like imagenet test set\"\"\"", "\n", "selected_image_list", "=", "[", "]", "\n", "found_classes", "=", "[", "]", "\n", "for", "selected_point", "in", "local_list", ":", "\n", "# grab filename", "\n", "        ", "selected_file", "=", "acts", ".", "get_file_name", "(", "selected_point", ")", ".", "decode", "(", "'UTF-8'", ")", "\n", "if", "verbose", ":", "\n", "            ", "pass", "\n", "#print(selected_file)", "\n", "", "class_dir_label", "=", "selected_file", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "in_class_sub_dirs", ":", "\n", "# we've assumed files are in folders labelled by class!", "\n", "            ", "selected_image_list", ".", "append", "(", "imagenet_root", "+", "class_dir_label", "+", "'/'", "+", "selected_file", ")", "\n", "", "else", ":", "\n", "            ", "selected_image_list", ".", "append", "(", "imagenet_root", "+", "selected_file", ")", "\n", "", "class_no", "=", "class_dict", "[", "selected_file", ".", "split", "(", "'_'", ")", "[", "0", "]", "]", "\n", "if", "not", "class_no", "in", "found_classes", ":", "\n", "            ", "found_classes", ".", "append", "(", "class_no", ")", "\n", "", "", "return", "selected_image_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_top_1_set.check_image_correct": [[53, 105], ["Make_top_1_set.grab_files", "range", "len", "Caffe_AlexNet2.caffe.io.load_image", "Test_AlexNet_on_directory.what_am_I_from_image", "mistake_list_name.append", "mistake_list_no.append", "correct_list_name.append", "correct_list_no.append", "corrected_local_list.append", "print"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_squarified_test_set.grab_files", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.what_am_I_from_image"], ["", "def", "check_image_correct", "(", "true_class", "=", "''", ",", "\n", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "\n", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "\n", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "net", "=", "net", ",", "\n", "transformer", "=", "transformer", ",", "\n", "in_class_sub_dirs", "=", "True", ")", ":", "\n", "    ", "\"\"\"wrapper function to check that a given image is correct in a fresh instantiation of ALexNet\n    ture_class needs to be input\"\"\"", "\n", "selected_image_list", "=", "grab_files", "(", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "imagenet_root", "=", "imagenet_root", ",", "in_class_sub_dirs", "=", "in_class_sub_dirs", ")", "\n", "image_list", "=", "selected_image_list", "\n", "image_directory", "=", "''", "\n", "mistake_list_name", "=", "[", "]", "\n", "mistake_list_no", "=", "[", "]", "\n", "correct_list_name", "=", "[", "]", "\n", "correct_list_no", "=", "[", "]", "\n", "corrected_local_list", "=", "[", "]", "\n", "for", "image_no", "in", "range", "(", "len", "(", "image_list", ")", ")", ":", "\n", "        ", "image_name", "=", "image_list", "[", "image_no", "]", "\n", "try", ":", "\n", "            ", "image", "=", "C", ".", "caffe", ".", "io", ".", "load_image", "(", "image_directory", "+", "image_name", ")", "\n", "good_to_go", "=", "True", "\n", "", "except", ":", "\n", "            ", "good_to_go", "=", "False", "\n", "", "if", "good_to_go", ":", "\n", "            ", "out_list", ",", "is_correct", "=", "what_am_I_from_image", "(", "\n", "image", "=", "image", ",", "\n", "net", "=", "net", ",", "\n", "transformer", "=", "transformer", ",", "\n", "verbose", "=", "verbose", ",", "\n", "found_labels", "=", "found_labels", ",", "\n", "class_labels", "=", "class_labels", ",", "\n", "true_class", "=", "true_class", "\n", ")", "\n", "if", "is_correct", "==", "False", ":", "\n", "                ", "if", "verbose", ":", "\n", "                    ", "print", "(", "'Error: {} is incorrect'", ".", "format", "(", "image_name", ")", ")", "\n", "", "mistake_list_name", ".", "append", "(", "image_name", ")", "\n", "mistake_list_no", ".", "append", "(", "image_no", ")", "\n", "", "else", ":", "\n", "# if its true or the functions doesnot know", "\n", "                ", "correct_list_name", ".", "append", "(", "image_name", ")", "\n", "correct_list_no", ".", "append", "(", "image_no", ")", "\n", "corrected_local_list", ".", "append", "(", "local_list", "[", "image_no", "]", ")", "\n", "#else:", "\n", "#mistake_list_name.append(image_name)", "\n", "#mistake_list_no.append(image_no)", "\n", "", "", "", "return", "corrected_local_list", ",", "correct_list_name", ",", "correct_list_no", ",", "mistake_list_name", ",", "mistake_list_no", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_top_1_set.simple_move_files": [[149, 154], ["range", "len", "shutil.move", "selected_image_list[].split"], "function", ["None"], ["def", "simple_move_files", "(", "selected_image_list", ",", "out_dir", "=", "'/storage/data/top_images_test_set/'", ")", ":", "\n", "    ", "\"\"\"Function to grab files and move them\"\"\"", "\n", "for", "file_no", "in", "range", "(", "len", "(", "selected_image_list", ")", ")", ":", "\n", "        ", "shutil", ".", "move", "(", "selected_image_list", "[", "file_no", "]", ",", "out_dir", "+", "selected_image_list", "[", "file_no", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.Batch.__init__": [[42, 56], ["numpy.copy", "numpy.copy", "blobs.items"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "images", ",", "blobs", ",", "probabilities", ",", "label", ")", ":", "\n", "        ", "''' create a base batch object.\n            size: the numeber of images in this batch\n            images: [] of images in the batch\n            blobs: {layer -> data}\n            probabilties: label guesses.\n            label: the actual label of the batch\n        '''", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "images", "=", "images", "\n", "## THIS IS VERY IMPORTANT< THIS COPYS THE VALueS AND NOT A POINTER! AVOIdS THE AWFuL ERROR OF DOOM", "\n", "self", ".", "blobs", "=", "{", "key", ":", "np", ".", "copy", "(", "value", ")", "for", "key", ",", "value", "in", "blobs", ".", "items", "(", ")", "}", "\n", "self", ".", "probabilities", "=", "np", ".", "copy", "(", "probabilities", ")", "\n", "self", ".", "label", "=", "label", "\n", "", "", "try", ":", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.parse_directory": [[125, 187], ["os.getcwd", "os.listdir", "print", "print", "len", "print", "len", "sys.stdout.write", "sys.stdout.flush", "enumerate", "batches_of_activations.append", "print", "transformer.preprocess", "net.forward", "Caffe_AlexNet.Batch", "caffe.io.load_image", "os.path.join"], "function", ["None"], ["def", "parse_directory", "(", "net", ",", "transformer", ",", "image_directory", "=", "os", ".", "getcwd", "(", ")", ",", "no_of_images", "=", "None", ",", "\n", "batch_size", "=", "50", ",", "verbose", "=", "True", ",", "blob_list", "=", "blob_list", ",", "label", "=", "None", ")", ":", "\n", "    ", "\"\"\"Function to parse images from a directory into AlexNet and generate a list of classifications\n    image_directory: where to get the images from\n    no_of_images: no. of images to to parse in the directory, default is all\n    batch_size: no. to feed in at a time\n    verbose: whether to spew up meaningless data\n    blob_list: which layers do you want the activations for?\n    \"\"\"", "\n", "image_list", "=", "os", ".", "listdir", "(", "image_directory", ")", "# get a list of images to classify", "\n", "image_list", "=", "[", "x", "for", "x", "in", "image_list", "if", "(", "'JPEG'", "in", "x", "or", "'jpg'", "in", "x", "or", "'PNG'", "in", "x", "or", "'png'", "in", "x", ")", "]", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Using images from {}'", ".", "format", "(", "image_directory", ")", ")", "\n", "", "if", "len", "(", "image_list", ")", "==", "0", ":", "\n", "        ", "print", "(", "'No images found in {}'", ".", "format", "(", "image_directory", ")", ")", "\n", "return", "\n", "", "if", "no_of_images", "==", "None", ":", "\n", "        ", "no_of_images", "=", "len", "(", "image_list", ")", "# per diretory", "\n", "#assert no_of_images >= batch_size", "\n", "", "print", "(", "no_of_images", ")", "\n", "count", "=", "0", "\n", "batches_of_activations", "=", "[", "]", "\n", "# setup loop invariants", "\n", "# how many images are left to process", "\n", "images_to_process", "=", "no_of_images", "\n", "# index of first image in this batch", "\n", "batch_start", "=", "0", "\n", "while", "images_to_process", ">", "0", ":", "\n", "# feed in and transform the images", "\n", "# deal with last case", "\n", "        ", "if", "images_to_process", ">", "batch_size", ":", "\n", "            ", "images_to_process", "-=", "batch_size", "\n", "", "else", ":", "\n", "# handle final batch (may be < batch_size)", "\n", "            ", "batch_size", "=", "images_to_process", "\n", "images_to_process", "=", "0", "\n", "", "sys", ".", "stdout", ".", "write", "(", "'{}-{} '", ".", "format", "(", "batch_start", ",", "batch_start", "+", "batch_size", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "batch_images", "=", "image_list", "[", "batch_start", ":", "batch_start", "+", "batch_size", "]", "\n", "for", "batch_image_index", ",", "batch_image", "in", "enumerate", "(", "batch_images", ")", ":", "\n", "# this feeds in a batches worth of picture data", "\n", "            ", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "batch_image_index", ",", "...", "]", "=", "transformer", ".", "preprocess", "(", "'data'", ",", "\n", "caffe", ".", "io", ".", "load_image", "(", "os", ".", "path", ".", "join", "(", "image_directory", ",", "batch_image", ")", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "#if i==0 and verbose:", "\n", "#    # spew out a picture if you want", "\n", "#    image = caffe.io.load_image(os.path.join(image_directory, image_list[i]))", "\n", "#    plt.imshow(image)", "\n", "#    plt.savefig(\"example_image.png\")", "\n", "### perform classification on a batch", "\n", "", "probabilities", "=", "net", ".", "forward", "(", ")", "[", "'prob'", "]", "\n", "temp", "=", "{", "}", "\n", "for", "blob_name", "in", "blob_list", ":", "\n", "            ", "temp", "[", "blob_name", "]", "=", "net", ".", "blobs", "[", "blob_name", "]", ".", "data", "\n", "", "batches_of_activations", ".", "append", "(", "Batch", "(", "batch_size", ",", "batch_images", ",", "temp", ",", "probabilities", ",", "label", ")", ")", "\n", "# reestablish invariants", "\n", "batch_start", "+=", "batch_size", "\n", "#if verbose:", "\n", "#    output_prob = output[0]['prob'][0]  # the output probability vector for the first image in the batch", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'{} images processed'", ".", "format", "(", "count", ")", ")", "\n", "", "return", "batches_of_activations", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.parse_directory_limited": [[189, 257], ["os.getcwd", "os.listdir", "print", "print", "len", "print", "len", "sys.stdout.write", "sys.stdout.flush", "enumerate", "batches_of_activations.append", "print", "transformer.preprocess", "net.forward", "Caffe_AlexNet.Batch", "caffe.io.load_image", "os.path.join"], "function", ["None"], ["", "def", "parse_directory_limited", "(", "net", ",", "transformer", ",", "image_directory", "=", "os", ".", "getcwd", "(", ")", ",", "no_of_images", "=", "None", ",", "\n", "batch_size", "=", "50", ",", "verbose", "=", "True", ",", "blob_list", "=", "blob_list", ",", "label", "=", "None", ",", "no_of_batches_to_process", "=", "10", ")", ":", "\n", "    ", "\"\"\"Function to parse images from a directory into AlexNet and generate a list of classifications\n    Limited as it will only grab a certain number of images\n    image_directory: where to get the images from\n    no_of_images: no. of images to to parse in the directory, default is all\n    batch_size: no. to feed in at a time\n    verbose: whether to spew up meaningless data\n    blob_list: which layers do you want the activations for?\n    how many images tor process?\n    \"\"\"", "\n", "image_list", "=", "os", ".", "listdir", "(", "image_directory", ")", "# get a list of images to classify", "\n", "image_list", "=", "[", "x", "for", "x", "in", "image_list", "if", "(", "'JPEG'", "in", "x", "or", "'jpg'", "in", "x", "or", "'PNG'", "in", "x", "or", "'png'", "in", "x", ")", "]", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Using images from {}'", ".", "format", "(", "image_directory", ")", ")", "\n", "", "if", "len", "(", "image_list", ")", "==", "0", ":", "\n", "        ", "print", "(", "'No images found in {}'", ".", "format", "(", "image_directory", ")", ")", "\n", "return", "\n", "", "if", "no_of_images", "==", "None", ":", "\n", "        ", "no_of_images", "=", "len", "(", "image_list", ")", "# per diretory", "\n", "#assert no_of_images >= batch_size", "\n", "", "print", "(", "no_of_images", ")", "\n", "count", "=", "0", "\n", "batches_of_activations", "=", "[", "]", "\n", "# setup loop invariants", "\n", "# how many images are left to process", "\n", "images_to_process", "=", "no_of_images", "\n", "# index of first image in this batch", "\n", "batch_start", "=", "0", "\n", "while", "images_to_process", ">", "0", ":", "\n", "# feed in and transform the images", "\n", "# deal with last case", "\n", "        ", "if", "images_to_process", ">", "batch_size", ":", "\n", "            ", "images_to_process", "-=", "batch_size", "\n", "", "else", ":", "\n", "# handle final batch (may be < batch_size)", "\n", "            ", "batch_size", "=", "images_to_process", "\n", "images_to_process", "=", "0", "\n", "", "if", "not", "no_of_batches_to_process", "==", "0", ":", "\n", "# we're limiting it", "\n", "            ", "if", "count", ">", "no_of_batches_to_process", ":", "\n", "                ", "continue", "\n", "", "", "sys", ".", "stdout", ".", "write", "(", "'{}-{} '", ".", "format", "(", "batch_start", ",", "batch_start", "+", "batch_size", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "batch_images", "=", "image_list", "[", "batch_start", ":", "batch_start", "+", "batch_size", "]", "\n", "for", "batch_image_index", ",", "batch_image", "in", "enumerate", "(", "batch_images", ")", ":", "\n", "# this feeds in a batches worth of picture data", "\n", "            ", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "batch_image_index", ",", "...", "]", "=", "transformer", ".", "preprocess", "(", "'data'", ",", "\n", "caffe", ".", "io", ".", "load_image", "(", "os", ".", "path", ".", "join", "(", "image_directory", ",", "batch_image", ")", ")", ")", "\n", "count", "=", "count", "+", "1", "\n", "#if i==0 and verbose:", "\n", "#    # spew out a picture if you want", "\n", "#    image = caffe.io.load_image(os.path.join(image_directory, image_list[i]))", "\n", "#    plt.imshow(image)", "\n", "#    plt.savefig(\"example_image.png\")", "\n", "### perform classification on a batch", "\n", "", "probabilities", "=", "net", ".", "forward", "(", ")", "[", "'prob'", "]", "\n", "temp", "=", "{", "}", "\n", "for", "blob_name", "in", "blob_list", ":", "\n", "            ", "temp", "[", "blob_name", "]", "=", "net", ".", "blobs", "[", "blob_name", "]", ".", "data", "\n", "", "batches_of_activations", ".", "append", "(", "Batch", "(", "batch_size", ",", "batch_images", ",", "temp", ",", "probabilities", ",", "label", ")", ")", "\n", "# reestablish invariants", "\n", "batch_start", "+=", "batch_size", "\n", "#if verbose:", "\n", "#    output_prob = output[0]['prob'][0]  # the output probability vector for the first image in the batch", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'{} images processed'", ".", "format", "(", "count", ")", ")", "\n", "", "return", "batches_of_activations", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.classify_directory": [[260, 340], ["print", "enumerate", "print", "range", "print", "int", "range", "output_prob.argmax", "print", "print", "assigned_label_indices.append", "assigned_labels.append", "print", "forced_labels.append", "label.split", "output_prob.argsort", "index_accuracies.append", "index_accuracies.append", "print", "print", "print", "labels[].split", "labels[].split", "label.split"], "function", ["None"], ["", "def", "classify_directory", "(", "batches", ",", "labels", ",", "check_classification", "=", "False", ",", "\n", "true_class", "=", "None", ",", "no_of_guesses", "=", "1", ",", "\n", "assignIndices", "=", "True", ",", "assignLabels", "=", "False", ",", "\n", "forceLabels", "=", "False", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"Function to generate a list of classifications from output\n    batches: array of batch objects created by parse_directory\n    check_classification: whether to compare the classification to the known result\n    true_class: what the actual class is (assumes a batch of the same class)\n    no_of_guesses: how many of the top probabilities you want to check for the true_class, default is 1\n    assignIndices: whether to return the assigned indices\n    assignLabels: whether to return the assinged labels\n    forceLabels: whether to force the assigned label to be the true_class\n    \"\"\"", "\n", "#no_of_batches = len(batches)", "\n", "if", "check_classification", "==", "True", ":", "\n", "#verify we are using the correct imagenet", "\n", "        ", "assert", "true_class", "in", "[", "label", ".", "split", "(", "' '", ")", "[", "0", "]", "for", "label", "in", "labels", "]", "\n", "", "if", "check_classification", "==", "True", ":", "\n", "        ", "assert", "true_class", "is", "not", "None", "\n", "# if true_class is not None:", "\n", "#     assert check_classification == True", "\n", "# correct_indices = []", "\n", "# incorrect_indices =[]", "\n", "", "print", "(", "'classify'", ")", "\n", "for", "batch_no", ",", "batch", "in", "enumerate", "(", "batches", ")", ":", "\n", "# if batch_no==26:", "\n", "#     import pdb;", "\n", "#     pdb.set_trace()", "\n", "        ", "print", "(", "'{}:{}'", ".", "format", "(", "batch_no", ",", "batch", ")", ")", "\n", "# assign labels", "\n", "index_accuracies", "=", "[", "]", "\n", "assigned_label_indices", "=", "[", "]", "\n", "assigned_labels", "=", "[", "]", "\n", "forced_labels", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "batch", ".", "size", ")", ":", "\n", "            ", "print", "(", "'{}'", ".", "format", "(", "index", ")", ")", "\n", "output_prob", "=", "batch", ".", "probabilities", "[", "index", "]", "\n", "assigned_label_index", "=", "int", "(", "output_prob", ".", "argmax", "(", ")", ")", "# this is the int line number in labels", "\n", "if", "verbose", ":", "\n", "                ", "print", "(", "'predicted class is: {}: {}, {}'", "\n", ".", "format", "(", "assigned_label_index", ",", "\n", "labels", "[", "assigned_label_index", "]", ".", "split", "(", "' '", ")", "[", "0", "]", ",", "\n", "labels", "[", "assigned_label_index", "]", ".", "split", "(", "' '", ")", "[", "1", "]", ")", ")", "\n", "# sort top five predictions from softmax output", "\n", "#top_inds = output_prob.argsort()[::-1][:no_of_guesses]  # reverse sort and take five largest items", "\n", "", "top_inds", "=", "output_prob", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", ":", "no_of_guesses", "]", "# reverse sort and take five largest items", "\n", "top_labels", "=", "[", "labels", "[", "x", "]", "for", "x", "in", "top_inds", "]", "\n", "sorted_out_list", "=", "[", "(", "output_prob", "[", "x", "]", ",", "labels", "[", "x", "]", ")", "for", "x", "in", "top_inds", "]", "\n", "#sorted_out_list = zip(output_prob[top_inds], labels[top_inds])", "\n", "for", "guess", "in", "range", "(", "no_of_guesses", ")", ":", "\n", "                ", "print", "(", "'{}'", ".", "format", "(", "sorted_out_list", "[", "guess", "]", ")", ")", "\n", "", "if", "check_classification", ":", "\n", "                ", "if", "true_class", "in", "[", "label", ".", "split", "(", "' '", ")", "[", "0", "]", "for", "label", "in", "top_labels", "]", ":", "\n", "# ! can change this later so loop over the whole list to see if it is in the top five or not", "\n", "# currently only checks the first position", "\n", "                    ", "if", "verbose", ":", "\n", "                        ", "print", "(", "'{} in {}'", ".", "format", "(", "true_class", ",", "sorted_out_list", ")", ")", "\n", "print", "(", "'correct!'", ")", "\n", "", "index_accuracies", ".", "append", "(", "True", ")", "\n", "", "else", ":", "\n", "                    ", "if", "verbose", ":", "\n", "                        ", "print", "(", "'incorrect'", ")", "\n", "", "index_accuracies", ".", "append", "(", "False", ")", "\n", "", "", "if", "assignIndices", "==", "True", ":", "\n", "                ", "assigned_label_indices", ".", "append", "(", "top_inds", ")", "\n", "", "if", "assignLabels", "==", "True", ":", "\n", "                ", "assigned_labels", ".", "append", "(", "top_labels", ")", "\n", "", "if", "forceLabels", "and", "not", "(", "true_class", "==", "None", ")", ":", "\n", "                ", "print", "(", "'forcing label {}'", ".", "format", "(", "true_class", ")", ")", "\n", "forced_labels", ".", "append", "(", "true_class", ")", "\n", "", "", "batch", ".", "index_accuracies", "=", "index_accuracies", "\n", "if", "forceLabels", ":", "\n", "            ", "batch", ".", "assigned_labels", "=", "forced_labels", "\n", "", "else", ":", "\n", "            ", "batch", ".", "assigned_labels", "=", "assigned_labels", "\n", "", "batch", ".", "assigned_label_indices", "=", "assigned_label_indices", "\n", "# if verbose and check_classification:", "\n", "#     print('{} correct for this class out of {}, {}%'.format(len(correct_indices), count,", "\n", "#           100*float(len(correct_indices))/count))", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_max": [[341, 382], ["sum", "kmeans.activation_table.ActivationTable", "kmeans.activation_table.ActivationTable.add_direct", "activation_table.add_direct.save_to_hdf5", "print", "print", "Caffe_AlexNet.convert_alexnet_to_h5_new", "range", "sum", "numpy.amax", "numpy.resize", "activation_table.add_direct.add_activation", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_direct", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.save_to_hdf5", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_new", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.add_activation"], ["", "def", "convert_alexnet_to_h5_max", "(", "batches", ",", "blob_name", ",", "h5_out_filename", ",", "net", ",", "labels", ")", ":", "\n", "    ", "''' Parse the alexnet results and output the maximum activation for each correct match\n    '''", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Writing out {}'", ".", "format", "(", "h5_out_filename", ")", ")", "\n", "", "image_count", "=", "sum", "(", "[", "sum", "(", "batch", ".", "index_accuracies", ")", "for", "batch", "in", "batches", "]", ")", "\n", "layer", "=", "net", ".", "blobs", "[", "blob_name", "]", "\n", "if", "layer", ".", "width", "==", "1", "and", "layer", ".", "height", "==", "1", ":", "\n", "        ", "print", "(", "\"Asking to take maximum of single value?\"", ")", "\n", "# Switch to single neuron code path", "\n", "return", "convert_alexnet_to_h5_new", "(", "batches", ",", "blob_name", ",", "h5_out_filename", ",", "net", ",", "labels", ")", "\n", "\n", "# makea new activation table", "\n", "", "activation_table", "=", "ActivationTable", "(", ")", "\n", "# add in all the activations", "\n", "activation_handle", "=", "activation_table", ".", "add_direct", "(", "identifier", "=", "blob_name", ",", "\n", "image_count", "=", "image_count", ",", "\n", "neuron_count", "=", "layer", ".", "channels", ",", "\n", "labels", "=", "labels", ",", "\n", "neuron_x_count", "=", "1", ",", "\n", "neuron_y_count", "=", "1", ")", "\n", "# now add in all the activations", "\n", "for", "batch", "in", "batches", ":", "\n", "        ", "activations", "=", "batch", ".", "blobs", "[", "blob_name", "]", "\n", "for", "index", "in", "range", "(", "batch", ".", "size", ")", ":", "\n", "            ", "if", "not", "batch", ".", "index_accuracies", "[", "index", "]", ":", "\n", "# It got it wrong :(", "\n", "                ", "continue", "\n", "", "activation_label", "=", "caffe_settings", ".", "short_labels", "[", "batch", ".", "assigned_label_indices", "[", "index", "]", "]", "\n", "if", "activation_label", "!=", "batch", ".", "label", ":", "\n", "# IF WE HIT HERE, it is broken", "\n", "                ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "assert", "(", "activation_label", "==", "batch", ".", "label", ")", "\n", "activation_values", "=", "np", ".", "amax", "(", "activations", "[", "index", "]", ",", "(", "1", ",", "2", ")", ")", "\n", "activation_values", "=", "np", ".", "resize", "(", "activation_values", ",", "(", "activation_values", ".", "size", ",", "1", ",", "1", ")", ")", "\n", "activation_handle", ".", "add_activation", "(", "activation_values", ",", "\n", "batch", ".", "images", "[", "index", "]", ",", "\n", "activation_label", ")", "\n", "# write out a nice h5 file", "\n", "", "", "activation_handle", ".", "save_to_hdf5", "(", "h5_out_filename", ",", "regenerate_labels", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_all_alexnet_to_h5_max": [[383, 424], ["sum", "kmeans.activation_table.ActivationTable", "kmeans.activation_table.ActivationTable.add_direct", "activation_table.add_direct.save_to_hdf5", "print", "print", "Caffe_AlexNet.convert_alexnet_to_h5_new", "range", "sum", "numpy.amax", "numpy.resize", "activation_table.add_direct.add_activation"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_direct", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.save_to_hdf5", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_new", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.add_activation"], ["", "def", "convert_all_alexnet_to_h5_max", "(", "batches", ",", "blob_name", ",", "h5_out_filename", ",", "net", ",", "labels", ")", ":", "\n", "    ", "''' Parse the alexnet results and output the maximum activation for each correct match\n    '''", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Writing out {}'", ".", "format", "(", "h5_out_filename", ")", ")", "\n", "", "image_count", "=", "sum", "(", "[", "sum", "(", "batch", ".", "index_accuracies", ")", "for", "batch", "in", "batches", "]", ")", "\n", "layer", "=", "net", ".", "blobs", "[", "blob_name", "]", "\n", "if", "layer", ".", "width", "==", "1", "and", "layer", ".", "height", "==", "1", ":", "\n", "        ", "print", "(", "\"Asking to take maximum of single value?\"", ")", "\n", "# Switch to single neuron code path", "\n", "return", "convert_alexnet_to_h5_new", "(", "batches", ",", "blob_name", ",", "h5_out_filename", ",", "net", ",", "labels", ")", "\n", "\n", "# makea new activation table", "\n", "", "activation_table", "=", "ActivationTable", "(", ")", "\n", "# add in all the activations", "\n", "activation_handle", "=", "activation_table", ".", "add_direct", "(", "identifier", "=", "blob_name", ",", "\n", "image_count", "=", "image_count", ",", "\n", "neuron_count", "=", "layer", ".", "channels", ",", "\n", "labels", "=", "labels", ",", "\n", "neuron_x_count", "=", "1", ",", "\n", "neuron_y_count", "=", "1", ")", "\n", "# now add in all the activations", "\n", "for", "batch", "in", "batches", ":", "\n", "        ", "activations", "=", "batch", ".", "blobs", "[", "blob_name", "]", "\n", "for", "index", "in", "range", "(", "batch", ".", "size", ")", ":", "\n", "# if not batch.index_accuracies[index]:", "\n", "#     # It got it wrong :(", "\n", "#     continue", "\n", "            ", "activation_label", "=", "caffe_settings", ".", "short_labels", "[", "batch", ".", "assigned_label_indices", "[", "index", "]", "]", "\n", "# if activation_label != batch.label:", "\n", "#     # IF WE HIT HERE, it is broken", "\n", "#     import pdb", "\n", "#     pdb.set_trace()", "\n", "# assert(activation_label==batch.label)", "\n", "activation_values", "=", "np", ".", "amax", "(", "activations", "[", "index", "]", ",", "(", "1", ",", "2", ")", ")", "\n", "activation_values", "=", "np", ".", "resize", "(", "activation_values", ",", "(", "activation_values", ".", "size", ",", "1", ",", "1", ")", ")", "\n", "activation_handle", ".", "add_activation", "(", "activation_values", ",", "\n", "batch", ".", "images", "[", "index", "]", ",", "\n", "activation_label", ")", "\n", "# write out a nice h5 file", "\n", "", "", "activation_handle", ".", "save_to_hdf5", "(", "h5_out_filename", ",", "regenerate_labels", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_new": [[425, 458], ["sum", "kmeans.activation_table.ActivationTable", "kmeans.activation_table.ActivationTable.add_direct", "activation_table.add_direct.save_to_hdf5", "print", "range", "sum", "activation_table.add_direct.add_activation", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_direct", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.save_to_hdf5", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.add_activation"], ["", "def", "convert_alexnet_to_h5_new", "(", "batches", ",", "blob_name", ",", "h5_out_filename", ",", "net", ",", "labels", ")", ":", "\n", "    ", "''' Currently only adds correct ones '''", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Writing out {}'", ".", "format", "(", "h5_out_filename", ")", ")", "\n", "", "image_count", "=", "sum", "(", "[", "sum", "(", "batch", ".", "index_accuracies", ")", "for", "batch", "in", "batches", "]", ")", "\n", "layer", "=", "net", ".", "blobs", "[", "blob_name", "]", "\n", "# makea new activation table", "\n", "activation_table", "=", "ActivationTable", "(", ")", "\n", "# add in all the activations", "\n", "activation_handle", "=", "activation_table", ".", "add_direct", "(", "identifier", "=", "blob_name", ",", "\n", "image_count", "=", "image_count", ",", "\n", "neuron_count", "=", "layer", ".", "channels", ",", "\n", "labels", "=", "labels", ",", "\n", "neuron_x_count", "=", "layer", ".", "width", ",", "\n", "neuron_y_count", "=", "layer", ".", "height", ")", "\n", "# now add in all the activations", "\n", "for", "batch", "in", "batches", ":", "\n", "        ", "activations", "=", "batch", ".", "blobs", "[", "blob_name", "]", "\n", "for", "index", "in", "range", "(", "batch", ".", "size", ")", ":", "\n", "            ", "if", "not", "batch", ".", "index_accuracies", "[", "index", "]", ":", "\n", "# It got it wrong :(", "\n", "                ", "continue", "\n", "", "activation_label", "=", "caffe_settings", ".", "short_labels", "[", "batch", ".", "assigned_label_indices", "[", "index", "]", "]", "\n", "if", "activation_label", "!=", "batch", ".", "label", ":", "\n", "# IF WE HIT HERE, it is broken", "\n", "                ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "assert", "(", "activation_label", "==", "batch", ".", "label", ")", "\n", "activation_handle", ".", "add_activation", "(", "activations", "[", "index", "]", ",", "\n", "batch", ".", "images", "[", "index", "]", ",", "\n", "activation_label", ")", "\n", "# write out a nice h5 file", "\n", "", "", "activation_handle", ".", "save_to_hdf5", "(", "h5_out_filename", ",", "regenerate_labels", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_all": [[459, 508], ["sum", "kmeans.activation_table.ActivationTable", "kmeans.activation_table.ActivationTable.add_direct", "activation_table.add_direct.save_to_hdf5", "print", "range", "len", "print", "print", "activation_table.add_direct.add_activation", "print", "pdb.set_trace"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_direct", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.save_to_hdf5", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.add_activation"], ["", "def", "convert_alexnet_to_h5_all", "(", "batches", ",", "blob_name", ",", "h5_out_filename", ",", "net", ",", "labels", ",", "forceLabels", ")", ":", "\n", "    ", "''' adds all images!'''", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Writing out {}'", ".", "format", "(", "h5_out_filename", ")", ")", "\n", "# don't used accuracies here as we may not have them added!", "\n", "", "image_count", "=", "sum", "(", "[", "len", "(", "batch", ".", "images", ")", "for", "batch", "in", "batches", "]", ")", "\n", "layer", "=", "net", ".", "blobs", "[", "blob_name", "]", "\n", "# makea new activation table", "\n", "activation_table", "=", "kmeans", ".", "activation_table", ".", "ActivationTable", "(", ")", "\n", "# add in all the activations", "\n", "activation_handle", "=", "activation_table", ".", "add_direct", "(", "identifier", "=", "blob_name", ",", "\n", "image_count", "=", "image_count", ",", "\n", "neuron_count", "=", "layer", ".", "channels", ",", "\n", "labels", "=", "labels", ",", "\n", "neuron_x_count", "=", "layer", ".", "width", ",", "\n", "neuron_y_count", "=", "layer", ".", "height", ")", "\n", "# now add in all the activations", "\n", "for", "batch", "in", "batches", ":", "\n", "        ", "activations", "=", "batch", ".", "blobs", "[", "blob_name", "]", "\n", "for", "index", "in", "range", "(", "batch", ".", "size", ")", ":", "\n", "            ", "print", "(", "'index is {}'", ".", "format", "(", "index", ")", ")", "\n", "print", "(", "''", ")", "\n", "#print('{}'.format(batch.assigned_labels))", "\n", "#if not batch.index_accuracies[index]:", "\n", "# It got it wrong :(", "\n", "#    continue", "\n", "if", "forceLabels", ":", "\n", "                ", "activation_labels", "=", "[", "batch", ".", "assigned_labels", "[", "index", "]", "]", "\n", "print", "(", "activation_labels", ")", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "# TODO: handle old code where this is not an array?", "\n", "# activation_label=labels[batch.assigned_label_indices[index]]", "\n", "                  ", "activation_labels", "=", "[", "labels", "[", "x", "]", "for", "x", "in", "batch", ".", "assigned_label_indices", "[", "index", "]", "]", "\n", "", "except", "IndexError", ":", "\n", "                  ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "#if activation_label != batch.label:", "\n", "#    import pdb", "\n", "#    pdb.set_trace()", "\n", "#assert(activation_label==batch.label)", "\n", "# if len(batch.assigned_labels) > 1:", "\n", "#     # hacky hacky hacky lets overwrite activation label with multilables", "\n", "#     activation_label = labels[batch.assigned_labels[index]]", "\n", "", "", "activation_handle", ".", "add_activation", "(", "activations", "[", "index", "]", ",", "\n", "batch", ".", "images", "[", "index", "]", ",", "\n", "activation_labels", ")", "\n", "# write out a nice h5 file", "\n", "", "", "activation_handle", ".", "save_to_hdf5", "(", "h5_out_filename", ",", "regenerate_labels", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_max_all": [[509, 555], ["sum", "kmeans.activation_table.ActivationTable", "kmeans.activation_table.ActivationTable.add_direct", "activation_table.add_direct.save_to_hdf5", "print", "range", "len", "print", "print", "numpy.amax", "numpy.resize", "activation_table.add_direct.add_activation", "code.interact", "locals"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_direct", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.save_to_hdf5", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.add_activation"], ["", "def", "convert_alexnet_to_h5_max_all", "(", "batches", ",", "blob_name", ",", "h5_out_filename", ",", "net", ",", "labels", ")", ":", "\n", "    ", "''' adds all images!'''", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Writing out {}'", ".", "format", "(", "h5_out_filename", ")", ")", "\n", "# don't used accuracies here as we may not have them added!", "\n", "", "image_count", "=", "sum", "(", "[", "len", "(", "batch", ".", "images", ")", "for", "batch", "in", "batches", "]", ")", "\n", "layer", "=", "net", ".", "blobs", "[", "blob_name", "]", "\n", "# makea new activation table", "\n", "activation_table", "=", "kmeans", ".", "activation_table", ".", "ActivationTable", "(", ")", "\n", "# add in all the activations", "\n", "activation_handle", "=", "activation_table", ".", "add_direct", "(", "identifier", "=", "blob_name", ",", "\n", "image_count", "=", "image_count", ",", "\n", "neuron_count", "=", "layer", ".", "channels", ",", "\n", "labels", "=", "labels", ",", "\n", "neuron_x_count", "=", "1", ",", "\n", "neuron_y_count", "=", "1", ")", "\n", "# now add in all the activations", "\n", "for", "batch", "in", "batches", ":", "\n", "        ", "activations", "=", "batch", ".", "blobs", "[", "blob_name", "]", "\n", "for", "index", "in", "range", "(", "batch", ".", "size", ")", ":", "\n", "            ", "print", "(", "'index is {}'", ".", "format", "(", "index", ")", ")", "\n", "print", "(", "''", ")", "\n", "#print('{}'.format(batch.assigned_labels))", "\n", "#if not batch.index_accuracies[index]:", "\n", "# It got it wrong :(", "\n", "#    continue", "\n", "try", ":", "\n", "# TODO: handle old code where this is not an array?", "\n", "# activation_label=labels[batch.assigned_label_indices[index]]", "\n", "              ", "activation_labels", "=", "[", "labels", "[", "x", "]", "for", "x", "in", "batch", ".", "assigned_label_indices", "[", "index", "]", "]", "\n", "", "except", "IndexError", ":", "\n", "                ", "code", ".", "interact", "(", "local", "=", "locals", "(", ")", ")", "\n", "#if activation_label != batch.label:", "\n", "#    import pdb", "\n", "#    pdb.set_trace()", "\n", "#assert(activation_label==batch.label)", "\n", "# if len(batch.assigned_labels) > 1:", "\n", "#     # hacky hacky hacky lets overwrite activation label with multilables", "\n", "#     activation_label = labels[batch.assigned_labels[index]]", "\n", "", "activation_values", "=", "np", ".", "amax", "(", "activations", "[", "index", "]", ",", "(", "1", ",", "2", ")", ")", "\n", "activation_values", "=", "np", ".", "resize", "(", "activation_values", ",", "(", "activation_values", ".", "size", ",", "1", ",", "1", ")", ")", "\n", "activation_handle", ".", "add_activation", "(", "activation_values", ",", "\n", "batch", ".", "images", "[", "index", "]", ",", "\n", "activation_labels", ")", "\n", "# write out a nice h5 file", "\n", "", "", "activation_handle", ".", "save_to_hdf5", "(", "h5_out_filename", ",", "regenerate_labels", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5": [[558, 597], ["len", "len", "kmeans.ActivationTable", "kmeans.ActivationTable.add_direct", "activation_table.add_direct.save_to_hdf5", "print", "divmod", "activation_table.add_direct.add_activation"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_direct", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.save_to_hdf5", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.add_activation"], ["", "def", "convert_alexnet_to_h5", "(", "image_list", ",", "blob_name", ",", "assigned_labels", ",", "indices_list", ",", "activations", ",", "h5_out_filename", ",", "net", ")", ":", "\n", "    ", "\"\"\"Takes in alexnet and picture directories\n    image_list: list of image names\n    assigned_labels: labels to label each point with\n    h5_out_filename:  filename to write out to\n    blob_name: name of layer to write activations for\n    indices_list: list of indicies to write to file - should relate to imagenet\n    \"\"\"", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'Writing out {}'", ".", "format", "(", "h5_out_filename", ")", ")", "\n", "", "image_count", "=", "len", "(", "image_list", ")", "\n", "layer", "=", "net", ".", "blobs", "[", "blob_name", "]", "\n", "batch_size", "=", "len", "(", "activations", "[", "0", "]", "[", "blob_name", "]", ")", "\n", "# makea new activation table", "\n", "activation_table", "=", "kmeans", ".", "ActivationTable", "(", ")", "\n", "# add in all the activations", "\n", "activation_handle", "=", "activation_table", ".", "add_direct", "(", "identifier", "=", "blob_name", ",", "\n", "image_count", "=", "image_count", ",", "\n", "neuron_count", "=", "layer", ".", "channels", ",", "\n", "labels", "=", "assigned_labels", ",", "\n", "neuron_x_count", "=", "layer", ".", "width", ",", "\n", "neuron_y_count", "=", "layer", ".", "height", ")", "\n", "count", "=", "0", "\n", "# now add in all the activations", "\n", "for", "index", "in", "indices_list", ":", "\n", "        ", "if", "index", ">=", "image_count", ":", "\n", "# caused by the fact we've got an incomplete block at the end which will have odd values.", "\n", "            ", "continue", "\n", "# this is the index of a picture we've analysed", "\n", "", "batch_increment", ",", "remainder", "=", "divmod", "(", "index", ",", "batch_size", ")", "# modulo aritmatic FTW!", "\n", "\n", "activation_handle", ".", "add_activation", "(", "activations", "[", "batch_increment", "]", "[", "blob_name", "]", "[", "remainder", "]", ",", "\n", "image_list", "[", "index", "]", ",", "assigned_labels", "[", "index", "]", ")", "\n", "# activation_handle.add_activation(batch[i]", "\n", "# net.blobs[blob_name].data[i], h5_out_filename, assigned_labels[i])", "\n", "# write out a nice h5 file", "\n", "", "activation_handle", ".", "save_to_hdf5", "(", "h5_out_filename", ")", "\n", "#h5_out_filename.close()", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.main": [[646, 797], ["enumerate", "set_up_caffe_net.main", "print", "os.path.join", "print", "os.path.exists", "Caffe_AlexNet.classify_directory", "range", "kmeans.ActivationTable", "kmeans.ActivationTable.add_file", "kmeans.ActivationTable.get_file_name", "divmod", "train_filename.close", "print", "os.path.join", "print", "len", "kmeans.ActivationTable.get_file_name", "len", "Caffe_AlexNet.parse_directory", "Caffe_AlexNet.parse_directory", "print", "print", "print", "numpy.savetxt", "blob.replace", "Caffe_AlexNet.convert_alexnet_to_h5_max", "Caffe_AlexNet.convert_alexnet_to_h5_new", "Caffe_AlexNet.convert_alexnet_to_h5_max_all", "Caffe_AlexNet.convert_alexnet_to_h5_all", "os.path.exists", "image_name.split", "type"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.main", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.classify_directory", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_file", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_file_name", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_file_name", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.parse_directory", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.parse_directory", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_max", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_new", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_max_all", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Caffe_AlexNet.convert_alexnet_to_h5_all"], ["", "def", "main", "(", "override_settings", "=", "None", ")", ":", "\n", "\n", "####################################################################################################################", "\n", "#       Set-up netowkr iwth defaukts from imagent 2012", "\n", "    ", "global", "caffe_settings", "\n", "#Use_standard_set_up = False", "\n", "#if Use_standard_set_up == True:", "\n", "# this is hte bit that sets up the caffe networks ------------------------------------------------------------------", "\n", "if", "override_settings", "is", "None", ":", "\n", "        ", "caffe_settings", "=", "s", ".", "main", "(", ")", "\n", "# caffe_root = s.caffe_root", "\n", "\n", "", "else", ":", "\n", "# i expect this files is called by something tah bypasses set_up caffe", "\n", "        ", "caffe_settings", "=", "override_settings", "\n", "print", "(", "caffe_settings", ".", "dir_list", ")", "\n", "pass", "\n", "", "image_directory", "=", "caffe_settings", ".", "image_directory", "\n", "try", ":", "\n", "        ", "output_directory", "=", "caffe_settings", ".", "output_directory", "\n", "", "except", "AttributeError", ":", "\n", "        ", "print", "(", "\"No output_directory specified, falling back to image directory\"", ")", "\n", "output_directory", "=", "image_directory", "\n", "", "labels_file", "=", "caffe_settings", ".", "labels_file", "\n", "model_def", "=", "caffe_settings", ".", "model_def", "\n", "model_weights", "=", "caffe_settings", ".", "model_weights", "\n", "dir_list", "=", "caffe_settings", ".", "dir_list", "\n", "labels", "=", "caffe_settings", ".", "labels", "\n", "net", "=", "caffe_settings", ".", "net", "\n", "transformer", "=", "caffe_settings", ".", "transformer", "\n", "short_labels", "=", "caffe_settings", ".", "short_labels", "\n", "blob_list", "=", "caffe_settings", ".", "blob_list", "\n", "no_of_guesses", "=", "caffe_settings", ".", "no_of_guesses", "\n", "do_limited", "=", "caffe_settings", ".", "do_limited", "\n", "deploy_file", "=", "caffe_settings", ".", "deploy_file", "\n", "img_size", "=", "caffe_settings", ".", "img_size", "\n", "forceLabels", "=", "caffe_settings", ".", "forceLabels", "\n", "## atm", "\n", "#do_limited = True", "\n", "# end of the bit tha sets up the caffe netwroks --------------------------------------------------------------------", "\n", "\n", "\n", "# build the net", "\n", "\n", "\n", "####################################################################################################################", "\n", "#       The main loop that does evreything -- this now just runs the stuff to generate the n***.h5 files!", "\n", "####################################################################################################################", "\n", "#dir_list = dir_list[27:]", "\n", "\n", "for", "current_index", ",", "current_class", "in", "enumerate", "(", "dir_list", ")", ":", "\n", "        ", "current_image_directory", "=", "os", ".", "path", ".", "join", "(", "image_directory", ",", "current_class", ")", "\n", "print", "(", "'Running in {} ({}/{})'", ".", "format", "(", "current_image_directory", ",", "current_index", ",", "len", "(", "dir_list", ")", ")", ")", "\n", "true_class", "=", "current_class", "\n", "h5_filename_list", "=", "[", "os", ".", "path", ".", "join", "(", "output_directory", ",", "'{}_{}_max.h5'", ".", "format", "(", "current_class", ",", "blob", ".", "replace", "(", "\"/\"", ",", "\"_\"", ")", ")", ")", "for", "blob", "in", "blob_list", "]", "\n", "if", "os", ".", "path", ".", "exists", "(", "h5_filename_list", "[", "0", "]", ")", ":", "\n", "            ", "print", "(", "\"WARNING: {} already exists, skipping {}\"", ".", "format", "(", "h5_filename_list", "[", "0", "]", ",", "current_class", ")", ")", "\n", "continue", "\n", "", "try", ":", "\n", "            ", "if", "do_limited", ":", "\n", "                ", "batches_of_activations", "=", "parse_directory", "(", "net", "=", "net", ",", "\n", "transformer", "=", "transformer", ",", "\n", "image_directory", "=", "current_image_directory", ",", "\n", "no_of_images", "=", "100", ",", "\n", "batch_size", "=", "50", ",", "\n", "verbose", "=", "True", ",", "\n", "blob_list", "=", "blob_list", ",", "\n", "label", "=", "true_class", ")", "\n", "\n", "", "else", ":", "\n", "                ", "batches_of_activations", "=", "parse_directory", "(", "net", "=", "net", ",", "\n", "transformer", "=", "transformer", ",", "\n", "image_directory", "=", "current_image_directory", ",", "\n", "no_of_images", "=", "None", ",", "\n", "batch_size", "=", "50", ",", "\n", "verbose", "=", "True", ",", "\n", "blob_list", "=", "blob_list", ",", "\n", "label", "=", "true_class", ")", "\n", "", "", "except", "Exception", "as", "exception", ":", "\n", "            ", "print", "(", "'true class = {}'", ".", "format", "(", "true_class", ")", ")", "\n", "print", "(", "\"ERROR: unable to parse directory {}: {}\"", ".", "format", "(", "current_class", ",", "exception", ")", ")", "\n", "print", "(", "\"Exception type:{}\"", ".", "format", "(", "type", "(", "exception", ")", ".", "__name__", ")", ")", "\n", "continue", "\n", "\n", "\n", "", "classify_directory", "(", "batches", "=", "batches_of_activations", ",", "\n", "labels", "=", "labels", ",", "\n", "check_classification", "=", "False", ",", "\n", "true_class", "=", "current_class", ",", "\n", "no_of_guesses", "=", "caffe_settings", ".", "no_of_guesses", ",", "\n", "assignIndices", "=", "True", ",", "\n", "assignLabels", "=", "True", ",", "\n", "forceLabels", "=", "forceLabels", ",", "\n", "verbose", "=", "True", ")", "\n", "\n", "#image_list = good_image_lis", "\n", "### !!! N.B. only correct images are written out!", "\n", "do_good_only", "=", "False", "\n", "take_maximum_only", "=", "False", "\n", "for", "blob_no", "in", "range", "(", "len", "(", "blob_list", ")", ")", ":", "# t", "\n", "            ", "if", "do_good_only", ":", "\n", "                ", "if", "take_maximum_only", ":", "\n", "                    ", "convert_alexnet_to_h5_max", "(", "batches", "=", "batches_of_activations", ",", "\n", "blob_name", "=", "blob_list", "[", "blob_no", "]", ",", "\n", "h5_out_filename", "=", "h5_filename_list", "[", "blob_no", "]", ",", "\n", "net", "=", "net", ",", "\n", "labels", "=", "labels", ")", "\n", "", "else", ":", "\n", "                    ", "convert_alexnet_to_h5_new", "(", "batches", "=", "batches_of_activations", ",", "\n", "blob_name", "=", "blob_list", "[", "blob_no", "]", ",", "\n", "h5_out_filename", "=", "h5_filename_list", "[", "blob_no", "]", ",", "\n", "net", "=", "net", ",", "\n", "labels", "=", "labels", ")", "\n", "", "", "if", "not", "do_good_only", ":", "\n", "                ", "if", "take_maximum_only", ":", "\n", "                    ", "convert_alexnet_to_h5_max_all", "(", "batches", "=", "batches_of_activations", ",", "\n", "blob_name", "=", "blob_list", "[", "blob_no", "]", ",", "\n", "h5_out_filename", "=", "h5_filename_list", "[", "blob_no", "]", ",", "\n", "net", "=", "net", ",", "\n", "labels", "=", "short_labels", ")", "\n", "", "else", ":", "\n", "                    ", "convert_alexnet_to_h5_all", "(", "batches", "=", "batches_of_activations", ",", "\n", "blob_name", "=", "blob_list", "[", "blob_no", "]", ",", "\n", "h5_out_filename", "=", "h5_filename_list", "[", "blob_no", "]", ",", "\n", "net", "=", "net", ",", "\n", "labels", "=", "short_labels", ",", "\n", "forceLabels", "=", "forceLabels", ")", "\n", "#convert_alexnet_to_h5(image_list=image_list, blob_name=blob_list[blob_no], assigned_labels=assigned_label_indices,", "\n", "#             indices_list=correct_indices, activations=batches_of_activations,", "\n", "#                     h5_out_filename=h5_filename_list[blob_no], net=net)", "\n", "\n", "", "", "", "do_bottlenecks", "=", "False", "\n", "if", "do_bottlenecks", ":", "\n", "# this writes out bottleneck files, but some for reason as csv column array I dont know why", "\n", "            ", "over_write_bottlenecks", "=", "True", "\n", "bottleneck_filename", "=", "dirname", "+", "'/'", "+", "image_name", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "'.txt'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "bottleneck_filename", ")", "or", "over_write_bottlenecks", ":", "\n", "                ", "np", ".", "savetxt", "(", "bottleneck_filename", ",", "feat_out", ",", "delimiter", "=", "\",\"", ")", "\n", "\n", "\n", "", "", "", "do_check", "=", "0", "\n", "if", "verbose", "and", "do_check", "==", "1", ":", "\n", "# lets do some checking here", "\n", "        ", "train_filename", "=", "'out.h5'", "\n", "reloaded_activation", "=", "kmeans", ".", "ActivationTable", "(", ")", "\n", "reloaded_activation", ".", "add_file", "(", "train_filename", ")", "\n", "reloaded_activation", ".", "get_file_name", "(", "55", ")", "\n", "assert", "reloaded_activation", ".", "get_file_name", "(", "55", ")", "==", "image_list", "[", "correct_indices", "[", "55", "]", "]", "\n", "batch_increment", ",", "remainder", "=", "divmod", "(", "correct_indices", "[", "55", "]", ",", "batch_size", ")", "\n", "#reloaded_activation.get_activation(55).vector == batches_of_activations[batch_increment]['fc6'][remainder]", "\n", "train_filename", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label": [[92, 97], ["filename.endswith"], "function", ["None"], ["def", "filename_to_label", "(", "filename", ")", ":", "\n", "    ", "\"\"\" dewisott \"\"\"", "\n", "if", "filename", ".", "endswith", "(", "\".h5\"", ")", ":", "\n", "        ", "filename", "=", "filename", "[", ":", "-", "3", "]", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.all_same": [[99, 102], ["all"], "function", ["None"], ["", "def", "all_same", "(", "items", ")", ":", "\n", "    ", "\"\"\"Gives true if all items in an array are the same\"\"\"", "\n", "return", "all", "(", "x", "==", "items", "[", "0", "]", "for", "x", "in", "items", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.build_label_dict_from_filenames": [[104, 121], ["acts.get_all_point_indices", "found_labels.append", "label_dict[].append", "activation_filename.split", "filename.split"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices"], ["", "def", "build_label_dict_from_filenames", "(", "acts", ")", ":", "\n", "    ", "\"\"\" Build a dictionary of labels to points in local format\n    Assumes the filename is the correct label.\n    \"\"\"", "\n", "label_dict", "=", "{", "}", "\n", "found_labels", "=", "[", "]", "\n", "no_files_in_label", "=", "{", "}", "\n", "for", "activation_filename", "in", "acts", ".", "activation_files", ":", "\n", "        ", "label", "=", "activation_filename", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "found_labels", ".", "append", "(", "label", ")", "\n", "no_files_in_label", "[", "label", "]", "=", "0", "\n", "label_dict", "[", "label", "]", "=", "[", "]", "\n", "", "for", "filename", ",", "idx", "in", "acts", ".", "get_all_point_indices", "(", ")", ":", "\n", "        ", "label", "=", "filename", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "label_dict", "[", "label", "]", ".", "append", "(", "(", "filename", ",", "idx", ")", ")", "\n", "no_files_in_label", "[", "label", "]", "+=", "1", "\n", "", "return", "label_dict", ",", "found_labels", ",", "no_files_in_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.build_label_dict": [[123, 172], ["acts.get_loaded_files", "len", "acts.get_all_point_indices", "range", "big_list.append", "h5_analysis_jitterer.filename_to_label", "found_labels.append", "print", "isinstance", "h5_analysis_jitterer.filename_to_label", "enumerate", "print", "print", "range", "len", "len", "acts.get_activation().labels.decode", "acts.get_activation().labels[].decode", "h5_analysis_jitterer.filename_to_label", "len", "len", "len", "print", "file_name.split", "acts.get_activation", "big_list[].append", "file_name.split", "len", "acts.get_activation", "acts.get_activation"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_loaded_files", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation"], ["", "def", "build_label_dict", "(", "acts", ",", "use_loaded_files", "=", "True", ",", "verbose", "=", "True", ",", "doMean", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Builds a dictionary of labels to points in local format\n    Gives out a dictionary and a list of found labels\n    acts: activation table object\n    use_loaded_files: whether to assume one file per label (current default)\n    \"\"\"", "\n", "files", "=", "acts", ".", "get_loaded_files", "(", ")", "\n", "big_list", "=", "[", "]", "\n", "no_of_files", "=", "len", "(", "files", ")", "\n", "found_labels", "=", "[", "]", "\n", "label_dict", "=", "{", "}", "\n", "no_files_in_label", "=", "{", "}", "\n", "for", "file_name", "in", "files", ":", "\n", "        ", "big_list", ".", "append", "(", "[", "]", ")", "\n", "label", "=", "filename_to_label", "(", "file_name", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "found_labels", ".", "append", "(", "label", ")", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'Found {} files in activation table object'", ".", "format", "(", "no_of_files", ")", ")", "\n", "# print('Be patient, I found {} points'.format(len(acts.get_all_activation_indices())))", "\n", "", "for", "current_point", "in", "acts", ".", "get_all_point_indices", "(", ")", ":", "\n", "# TODO:: Make this work with multiple labels", "\n", "        ", "if", "isinstance", "(", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", ",", "(", "bytes", ",", "bytearray", ",", "str", ")", ")", ":", "\n", "# old style, the labels are a numpy byte string", "\n", "            ", "assigned_label", "=", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", ".", "decode", "(", "'UTF-8'", ")", "\n", "", "else", ":", "\n", "# new style, labels are a list", "\n", "            ", "assigned_label", "=", "acts", ".", "get_activation", "(", "current_point", ")", ".", "labels", "[", "0", "]", ".", "decode", "(", "'UTF-8'", ")", "\n", "", "assigned_label", "=", "filename_to_label", "(", "assigned_label", ")", "\n", "# except AttributeError:", "\n", "#     assigned_label = acts.get_activation(current_point).labels.decode('UTF-8')", "\n", "# except ValueError:", "\n", "#     import pdb; pdb.set_trace()", "\n", "for", "f_no", ",", "file_name", "in", "enumerate", "(", "files", ")", ":", "\n", "            ", "label", "=", "filename_to_label", "(", "file_name", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "if", "assigned_label", "==", "label", ":", "\n", "                ", "big_list", "[", "f_no", "]", ".", "append", "(", "current_point", ")", "\n", "break", "\n", "", "", "", "if", "not", "len", "(", "found_labels", ")", "==", "len", "(", "files", ")", ":", "\n", "        ", "print", "(", "'The number of found labels does not match the number of files in activation table'", ")", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'Found label: \\t No. of points'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "found_labels", ")", ")", ":", "\n", "            ", "print", "(", "'{}: \\t {}'", ".", "format", "(", "found_labels", "[", "i", "]", ",", "len", "(", "big_list", "[", "i", "]", ")", ")", ")", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "found_labels", ")", ")", ":", "\n", "# print(i, found_labels[i])", "\n", "        ", "label_dict", "[", "found_labels", "[", "i", "]", "]", "=", "big_list", "[", "i", "]", "\n", "no_files_in_label", "[", "found_labels", "[", "i", "]", "]", "=", "len", "(", "big_list", "[", "i", "]", ")", "\n", "", "return", "label_dict", ",", "found_labels", ",", "no_files_in_label", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.build_cluster_from_class_label": [[174, 226], ["range", "acts.get_activations_for_neuron", "len", "acts.from_local_indices", "cluster_list.append", "min_list.append", "max_list.append", "print", "random.sample", "range", "print", "min", "max", "len", "acts.from_local_indices", "acts.get_activation", "acts.get_activation", "acts.get_activations_for_neuron"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.from_local_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.from_local_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron"], ["", "def", "build_cluster_from_class_label", "(", "acts", ",", "current_neuron_index", ",", "label_dict", ",", "found_labels", ",", "current_neuron", "=", "[", "]", ",", "\n", "do_check", "=", "do_check", ",", "no_of_points_to_check", "=", "''", ")", ":", "\n", "    ", "\"\"\"Builds a cluster list from the class labels and activation table\n    This could be expanded to build a list of centroids as well and a detK object or similar\n    acts: activation table object\n    current_neuron_index: which neuron to do this for\n    label_dict: look up table that matches the found_labels to the local coordinates in the activation table object\n    found_labels: list of labels which are keys to label_dict\n    returns a list of lists of points which are members of each category\n    \"\"\"", "\n", "cluster_list", "=", "[", "]", "\n", "min_list", "=", "[", "]", "\n", "max_list", "=", "[", "]", "\n", "# moved this up here as it costs time", "\n", "if", "current_neuron", "==", "[", "]", ":", "\n", "        ", "current_neuron", "=", "acts", ".", "get_activations_for_neuron", "(", "current_neuron_index", ")", "\n", "", "else", ":", "\n", "        ", "pass", "\n", "", "for", "class_index", "in", "range", "(", "len", "(", "label_dict", ")", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "'building cluster based on class labels for label {}'", ".", "format", "(", "found_labels", "[", "class_index", "]", ")", ")", "\n", "# this is the list of points in our current class in the 2-d tuple format", "\n", "", "list_of_points_in_current_class", "=", "label_dict", "[", "found_labels", "[", "class_index", "]", "]", "\n", "# if we decide to only compare a subset...", "\n", "if", "not", "no_of_points_to_check", "==", "''", ":", "\n", "            ", "list_of_points_in_current_class", "=", "random", ".", "sample", "(", "list_of_points_in_current_class", ",", "no_of_points_to_check", ")", "\n", "# this is the list of points in our current class in the 1-d global number format (which corresponds to the vector's dimentions)", "\n", "", "global_list_of_points_in_current_class", "=", "acts", ".", "from_local_indices", "(", "\n", "list_of_points_in_current_class", ")", "# this gives all the points as a list", "\n", "# thus our cluster of points for this class is...", "\n", "# current_cluster = acts.get_activations_for_neuron(current_neuron_index)[0][0][global_list_of_points_in_current_class]", "\n", "current_cluster", "=", "current_neuron", ".", "vector", "[", "global_list_of_points_in_current_class", "]", "\n", "# and cos that was so fucking belaboured, lets check that shit", "\n", "# current_point = list_of_points_in_current_class[point_index]", "\n", "if", "do_check", ":", "\n", "# this checks that acts was built correctly", "\n", "            ", "for", "point_index", "in", "range", "(", "len", "(", "list_of_points_in_current_class", ")", ")", ":", "\n", "                ", "current_point_local", "=", "list_of_points_in_current_class", "[", "point_index", "]", "\n", "current_point_global", "=", "acts", ".", "from_local_indices", "(", "[", "list_of_points_in_current_class", "[", "point_index", "]", "]", ")", "[", "0", "]", "\n", "# the activation for the current neuron in the current point should equal the activation for the current point in the current neuron", "\n", "assert", "acts", ".", "get_activation", "(", "current_point_local", ")", ".", "vector", "[", "current_neuron_index", "]", "==", "acts", ".", "get_activations_for_neuron", "(", "current_neuron_index", ")", "[", "0", "]", "[", "0", "]", "[", "current_point_global", "]", "\n", "# and this checks we've clustered it correctly", "\n", "assert", "acts", ".", "get_activation", "(", "current_point_local", ")", ".", "vector", "[", "current_neuron_index", "]", "==", "current_cluster", "[", "\n", "point_index", "]", "\n", "# phew that was effortful", "\n", "", "print", "(", "'Coordinate transform from local to global check passed :)'", ")", "\n", "", "cluster_list", ".", "append", "(", "current_cluster", ")", "\n", "min_list", ".", "append", "(", "min", "(", "current_cluster", ")", ")", "\n", "max_list", ".", "append", "(", "max", "(", "current_cluster", ")", ")", "\n", "# note this assertion is assuming a 1d vectro", "\n", "", "return", "cluster_list", ",", "min_list", ",", "max_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer_list": [[228, 339], ["matplotlib.figure", "itertools.cycle", "itertools.cycle", "itertools.cycle", "itertools.cycle", "matplotlib.gca", "matplotlib.close", "print", "matplotlib.scatter", "range", "matplotlib.scatter", "matplotlib.xlim", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.ylim", "plt.gca.axes.get_xaxis().set_visible", "plt.gca.axes.get_yaxis().set_visible", "matplotlib.show", "matplotlib.close", "print", "plt.figure.savefig", "matplotlib.close", "numpy.random.uniform", "len", "min", "min", "max", "max", "matplotlib.scatter", "min", "min", "max", "max", "matplotlib.scatter", "min", "max", "min", "max", "plt.gca.axes.get_xaxis", "plt.gca.axes.get_yaxis", "min", "min", "max", "max", "print", "min", "min", "max", "max", "numpy.random.uniform", "range", "next", "numpy.random.uniform", "range", "next", "next", "len", "str", "len", "str"], "function", ["None"], ["", "def", "jitterer_list", "(", "x_data", ",", "colour_flag", "=", "'mono'", ",", "title", "=", "''", ",", "save_label", "=", "'fig'", ",", "show_plots", "=", "False", ",", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "label_dict", "=", "{", "}", ",", "outLayerNeuron", "=", "False", ",", "\n", "current_neuron_indices", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Lightweight plotter to plot jittered plots of x axis data with various options\n    x_data: the x axis data\n    colour_flag: flag for colour style: mono; cluster; random; highlight\n    title: title for the plot\n    save_label: filename if saving\n    show_plots: whether to show plots\n    save_plots: whether to save plots\n    do_x_axis: whether to show the x axis\n    do_y_axis: whether to show the y axis\n    x_range: range to plot x over\n    y_range: range to plot y over\n    label_dict: the dictionary of label names for the classes\n    outLayerNeuron: whether we're operating on 1-hot encoded output layer (it will label the graphs)\n    current_neuron_index: only used with outLayerNeuron to select the current data, alternatively, use ths to select\n                        : a cluster to be coloured black\n    \"\"\"", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "y_data", "=", "[", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "for", "x", "in", "x_data", "]", "\n", "if", "colour_flag", "==", "'mono'", ":", "\n", "        ", "print", "(", "'doing mono'", ")", "\n", "colour_option", "=", "'k'", "\n", "plt", ".", "scatter", "(", "x_data", ",", "y_data", ",", "label", "=", "title", ",", "\n", "color", "=", "colour_option", ",", "marker", "=", "\"o\"", ",", "alpha", "=", "0.25", ",", "s", "=", "1.75", ")", "\n", "# if colour_flag == 'random':", "\n", "#     z = np.random.rand(len(x_data))", "\n", "#     colour_option = z", "\n", "", "multi_colour_list", "=", "itertools", ".", "cycle", "(", "[", "'blue'", ",", "'firebrick'", ",", "'darkgreen'", ",", "'m'", ",", "\n", "'black'", ",", "'red'", ",", "'gold'", ",", "'darkcyan'", ",", "\n", "'olivedrab'", ",", "'dodgerblue'", "]", ")", "\n", "greyscale_list", "=", "itertools", ".", "cycle", "(", "[", "'0.5'", ",", "'0.6'", ",", "'0.7'", ",", "'0.8'", ",", "'0.9'", "]", ")", "\n", "black_list", "=", "itertools", ".", "cycle", "(", "[", "'black'", "]", ")", "\n", "marker_list", "=", "itertools", ".", "cycle", "(", "[", "'s'", ",", "'p'", ",", "'*'", ",", "'8'", ",", "'2'", ",", "'x'", ",", "'D'", ",", "'+'", "]", ")", "\n", "colour_list", "=", "multi_colour_list", "\n", "highlight_list", "=", "black_list", "\n", "if", "colour_flag", "==", "\"multi\"", ":", "\n", "        ", "colour_list", "=", "greyscale_list", "\n", "highlight_list", "=", "multi_colour_list", "\n", "", "if", "colour_flag", "==", "'cluster'", "or", "colour_flag", "==", "\"multi\"", ":", "\n", "# we expect that x_data is actually a list of lists of points, not just a list of points", "\n", "# import code", "\n", "# code.interact(local=locals())", "\n", "        ", "min_of_x", ",", "max_of_x", "=", "x_data", "[", "0", "]", "[", "0", "]", ",", "x_data", "[", "0", "]", "[", "0", "]", "\n", "min_of_y", ",", "max_of_y", "=", "1", ",", "1", "\n", "for", "cn", "in", "range", "(", "len", "(", "x_data", ")", ")", ":", "\n", "            ", "if", "(", "outLayerNeuron", "and", "cn", "not", "in", "current_neuron_indices", ")", "or", "outLayerNeuron", "==", "False", ":", "\n", "# if not outLayerNeuron or cn != current_neuron_index:", "\n", "# If not our selected data, plot it with all teh colours", "\n", "                ", "x_data_subset", "=", "x_data", "[", "cn", "]", "# [x[0] for x in cf[cn]]", "\n", "y_data_subset", "=", "[", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "for", "x", "in", "range", "(", "len", "(", "x_data_subset", ")", ")", "]", "\n", "# we need this stuff to plot the full range nicely", "\n", "min_of_x", "=", "min", "(", "min", "(", "x_data_subset", ")", ",", "min_of_x", ")", "\n", "min_of_y", "=", "min", "(", "min", "(", "y_data_subset", ")", ",", "min_of_y", ")", "\n", "max_of_x", "=", "max", "(", "max", "(", "x_data_subset", ")", ",", "max_of_x", ")", "\n", "max_of_y", "=", "max", "(", "max", "(", "y_data_subset", ")", ",", "max_of_y", ")", "\n", "plt", ".", "scatter", "(", "x_data_subset", ",", "y_data_subset", ",", "label", "=", "'neuron '", "+", "str", "(", "0", ")", ",", "marker", "=", "\"o\"", ",", "alpha", "=", "0.25", ",", "\n", "color", "=", "next", "(", "colour_list", ")", ")", "\n", "", "else", ":", "\n", "                ", "pass", "\n", "# cos we want to plot the last class last so its on the top", "\n", "", "", "if", "outLayerNeuron", ":", "\n", "# now we do the last ones", "\n", "            ", "for", "cn", "in", "current_neuron_indices", ":", "\n", "                ", "if", "verbose", ":", "\n", "                    ", "print", "(", "'Output layer neuron for class no {}'", ".", "format", "(", "cn", ")", ")", "\n", "# If not our selected data, plot it with balck", "\n", "", "x_data_subset", "=", "x_data", "[", "cn", "]", "# [x[0] for x in cf[cn]]", "\n", "y_data_subset", "=", "[", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "for", "x", "in", "range", "(", "len", "(", "x_data_subset", ")", ")", "]", "\n", "# we need this stuff to plot the full range nicely", "\n", "min_of_x", "=", "min", "(", "min", "(", "x_data_subset", ")", ",", "min_of_x", ")", "\n", "min_of_y", "=", "min", "(", "min", "(", "y_data_subset", ")", ",", "min_of_y", ")", "\n", "max_of_x", "=", "max", "(", "max", "(", "x_data_subset", ")", ",", "max_of_x", ")", "\n", "max_of_y", "=", "max", "(", "max", "(", "y_data_subset", ")", ",", "max_of_y", ")", "\n", "plt", ".", "scatter", "(", "x_data_subset", ",", "y_data_subset", ",", "\n", "label", "=", "'neuron '", "+", "str", "(", "0", ")", ",", "\n", "marker", "=", "next", "(", "marker_list", ")", ",", "\n", "alpha", "=", "0.75", ",", "\n", "color", "=", "next", "(", "highlight_list", ")", ")", "\n", "", "", "x_range", "=", "[", "min_of_x", ",", "max_of_x", "+", "0.1", "*", "max_of_x", "]", "\n", "y_range", "=", "[", "min_of_y", ",", "max_of_y", "]", "\n", "", "else", ":", "\n", "        ", "colour_option", "=", "'k'", "\n", "plt", ".", "scatter", "(", "x_data", ",", "y_data", ",", "label", "=", "title", ",", "\n", "color", "=", "colour_option", ",", "marker", "=", "\"o\"", ",", "alpha", "=", "0.25", ",", "s", "=", "1.75", ")", "\n", "## now we have a scatter plot, lets fuck with it", "\n", "", "if", "x_range", "is", "None", ":", "\n", "# figure it out yourself", "\n", "        ", "plt", ".", "xlim", "(", "[", "min", "(", "x_data", ")", ",", "max", "(", "x_data", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "xlim", "(", "x_range", ")", "\n", "", "if", "y_range", "is", "None", ":", "\n", "# figure it out yourself", "\n", "        ", "plt", ".", "ylim", "(", "[", "min", "(", "y_data", ")", ",", "max", "(", "y_data", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "ylim", "(", "y_range", ")", "\n", "", "cur_axes", "=", "plt", ".", "gca", "(", ")", "\n", "if", "not", "do_x_axis", ":", "\n", "        ", "cur_axes", ".", "axes", ".", "get_xaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "", "if", "not", "do_y_axis", ":", "\n", "        ", "cur_axes", ".", "axes", ".", "get_yaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "", "if", "show_plots", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "if", "save_plots", ":", "\n", "        ", "print", "(", "'saving figure {}.'", ".", "format", "(", "save_label", ")", ")", "\n", "fig", ".", "savefig", "(", "save_label", ",", "dpi", "=", "400", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "plt", ".", "close", "(", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.compute_selectivity_neuron": [[341, 388], ["range", "print", "len", "min", "max", "print", "print", "print", "print", "print", "range", "range"], "function", ["None"], ["", "def", "compute_selectivity_neuron", "(", "max_list", ",", "min_list", ",", "found_labels", ",", "verbose", "=", "verbose", ")", ":", "\n", "    ", "\"\"\"\n    computes the selectivity between classes\n    this works on ONE neuron at a time\n    :return:\n    \"\"\"", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"-- compute_selectivity --\"", ")", "\n", "# def brute_force_selectivity", "\n", "", "all_max", "=", "max_list", "\n", "all_min", "=", "min_list", "\n", "isSelective", "=", "False", "\n", "selectivity", "=", "0.0", "\n", "found_class", "=", "''", "\n", "for", "class_no", "in", "range", "(", "len", "(", "all_max", ")", ")", ":", "\n", "        ", "min_match", "=", "all_min", "[", "class_no", "]", "\n", "max_match", "=", "all_max", "[", "class_no", "]", "\n", "min_notmatch", "=", "min", "(", "[", "all_min", "[", "x", "]", "for", "x", "in", "range", "(", "0", ",", "1000", ")", "if", "not", "x", "==", "class_no", "]", ")", "\n", "max_notmatch", "=", "max", "(", "[", "all_max", "[", "x", "]", "for", "x", "in", "range", "(", "0", ",", "1000", ")", "if", "not", "x", "==", "class_no", "]", ")", "\n", "if", "max_match", ">", "min_notmatch", "and", "max_notmatch", ">", "min_match", ":", "\n", "## this is an overlap", "\n", "## dont think we need to know what the overlap is do we?", "\n", "# overlaps[label] = min((max_match - min_notmatch), (max_notmatch - min_match))", "\n", "            ", "continue", "\n", "", "if", "min_notmatch", "<", "max_match", ":", "\n", "# positive selectivity -- On neuron", "\n", "            ", "selectivity", "=", "min_match", "-", "max_notmatch", "\n", "isSelective", "=", "True", "\n", "", "else", ":", "\n", "# negative selectivity", "\n", "            ", "selectivity", "=", "min_notmatch", "-", "max_match", "\n", "isSelective", "=", "True", "\n", "", "if", "max_match", "==", "0.0", "and", "selectivity", "==", "0.0", ":", "\n", "# special case - neuron ignores this and others", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'ignoring 0.0 case'", ")", "\n", "", "isSelective", "=", "False", "\n", "continue", "\n", "", "if", "verbose", ":", "\n", "            ", "print", "(", "'{}: {}-{}\\nothers: {}-{}'", ".", "format", "(", "class_no", ",", "min_match", ",", "max_match", ",", "\n", "min_notmatch", ",", "max_notmatch", ")", ")", "\n", "", "if", "isSelective", ":", "\n", "            ", "print", "(", "'Selecitivy of {} found!'", ".", "format", "(", "selectivity", ")", ")", "\n", "print", "(", "'current_label is: {}'", ".", "format", "(", "found_labels", "[", "class_no", "]", ")", ")", "\n", "print", "(", "'class_no is: {}'", ".", "format", "(", "class_no", ")", ")", "\n", "found_class", "=", "found_labels", "[", "class_no", "]", "\n", "", "", "return", "isSelective", ",", "selectivity", ",", "found_class", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.class_code_to_name": [[390, 395], ["None"], "function", ["None"], ["", "def", "class_code_to_name", "(", "class_name", ",", "class_dict", ",", "class_labels", ")", ":", "\n", "    ", "\"\"\"teeny function to get the name of any class\n    uses class_dict nd class_ables from m\n    class_name = the imagent code\"\"\"", "\n", "return", "class_labels", "[", "class_dict", "[", "class_name", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.class_lineno_to_name": [[397, 406], ["entry.split"], "function", ["None"], ["", "def", "class_lineno_to_name", "(", "line_no", "=", "0", ",", "class_labels", "=", "class_labels", ")", ":", "\n", "    ", "\"\"\"teeny function to get the name of any class\n    uses class_dict nd class_ables from m\n    class_name = the imagent code\"\"\"", "\n", "entry", "=", "class_labels", "[", "line_no", "]", "\n", "meh", "=", "entry", ".", "split", "(", "' '", ")", "\n", "code", "=", "meh", "[", "0", "]", "\n", "name", "=", "meh", "[", "1", ":", "]", "\n", "return", "entry", ",", "code", ",", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_max_per_cluster": [[408, 419], ["max_per_class.append", "max", "max_per_class.append", "print", "numpy.mean"], "function", ["None"], ["", "def", "find_max_per_cluster", "(", "cluster_list", ",", "setting", "=", "'max'", ",", "verbose", "=", "verbose", ")", ":", "\n", "    ", "\"\"\"teeny function, loops over a list of arrays and grabs the max or mean\"\"\"", "\n", "max_per_class", "=", "[", "]", "\n", "for", "c", "in", "cluster_list", ":", "\n", "        ", "if", "setting", "==", "'max'", ":", "\n", "            ", "max_per_class", ".", "append", "(", "max", "(", "c", ")", ")", "\n", "", "elif", "setting", "==", "'mean'", ":", "\n", "            ", "max_per_class", ".", "append", "(", "np", ".", "mean", "(", "c", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'setting should be max or mean'", ")", "\n", "", "", "return", "max_per_class", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.compute_ccma_selectivity_neuron": [[421, 457], ["print", "numpy.mean", "numpy.mean", "h5_analysis_jitterer.find_max_per_cluster", "max", "h5_analysis_jitterer.class_lineno_to_name", "enumerate", "print", "type", "range", "operator.itemgetter", "h5_analysis_jitterer.class_lineno_to_name", "print", "type", "print", "len"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_max_per_cluster", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.class_lineno_to_name", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.class_lineno_to_name"], ["", "def", "compute_ccma_selectivity_neuron", "(", "cluster_list", ",", "found_labels", "=", "''", ",", "class_dict", "=", "class_dict", ",", "class_labels", "=", "class_labels", ",", "\n", "top_class", "=", "''", ",", "verbose", "=", "verbose", ")", ":", "\n", "    ", "\"\"\"\n    computes the class conditional mean activity based selectivity measure\n    this works on ONE neuron at a time\n    cluster_list = values sorted into a cluster\n    found_labels = labels for each cluster\n    top_class = class to do comparison for, if known, if not, I'll calc the top, can be index or label\n    :return:\n    \"\"\"", "\n", "print", "(", "\"-- compute_ccma_selectivity --\"", ")", "\n", "if", "top_class", "==", "''", ":", "\n", "# we figure out which is hte top class", "\n", "        ", "max_list", "=", "find_max_per_cluster", "(", "cluster_list", "=", "cluster_list", ",", "setting", "=", "'mean'", ",", "verbose", "=", "verbose", ")", "\n", "max_index", ",", "max_activation", "=", "max", "(", "enumerate", "(", "max_list", ")", ",", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ")", "\n", "entry", ",", "code", ",", "name", "=", "class_lineno_to_name", "(", "line_no", "=", "max_index", ",", "class_labels", "=", "class_labels", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "entry", ")", "\n", "", "", "elif", "type", "(", "top_class", ")", "==", "int", ":", "\n", "# someones given us an index into cluster_list", "\n", "        ", "max_index", "=", "top_class", "\n", "if", "verbose", ":", "\n", "            ", "entry", ",", "code", ",", "name", "=", "class_lineno_to_name", "(", "line_no", "=", "max_index", ",", "class_labels", "=", "class_labels", ")", "\n", "print", "(", "entry", ")", "\n", "", "", "elif", "type", "(", "top_class", ")", "==", "str", ":", "\n", "        ", "code", "=", "top_class", "\n", "max_index", "=", "class_dict", "[", "code", "]", "\n", "", "else", ":", "\n", "        ", "print", "(", "'top_class needs to be an index or a class code'", ")", "\n", "# now we geht class conditional mean activity for the top_class", "\n", "", "mu_max", "=", "np", ".", "mean", "(", "cluster_list", "[", "max_index", "]", ")", "\n", "not_cluster_list", "=", "[", "cluster_list", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "cluster_list", ")", ")", "if", "not", "i", "==", "max_index", "]", "\n", "flattened_list", "=", "[", "y", "for", "x", "in", "not_cluster_list", "for", "y", "in", "x", "]", "\n", "mu_not_max", "=", "np", ".", "mean", "(", "flattened_list", ")", "\n", "ccma_selectivity", "=", "(", "mu_max", "-", "mu_not_max", ")", "/", "(", "mu_max", "+", "mu_not_max", ")", "\n", "return", "ccma_selectivity", ",", "mu_max", ",", "mu_not_max", ",", "max_index", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.old_build_cluster_from_class_label": [[459, 498], ["range", "len", "acts.from_local_indices", "cluster_list.append", "print", "range", "print", "len", "acts.get_activations_for_neuron", "acts.from_local_indices", "acts.get_activation", "acts.get_activation", "acts.get_activations_for_neuron"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.from_local_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.from_local_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron"], ["", "def", "old_build_cluster_from_class_label", "(", "acts", ",", "current_neuron_index", ",", "label_dict", ",", "found_labels", ",", "do_check", "=", "do_check", ")", ":", "\n", "    ", "\"\"\"Builds a cluster list from the class labels and activation table\n    This could be expanded to build a list of centroids as well and a detK object or similar\n    acts: activation table object\n    current_neuron_index: which neuron to do this for\n    label_dict: look up table that matches the found_labels to the local coordinates in the activation table object\n    found_labels: list of labels which are keys to label_dict\n    returns a list of lists of points which are members of each category\n    \"\"\"", "\n", "cluster_list", "=", "[", "]", "\n", "for", "class_index", "in", "range", "(", "len", "(", "label_dict", ")", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "'building cluster based on class labels for label {}'", ".", "format", "(", "found_labels", "[", "class_index", "]", ")", ")", "\n", "# this is the list of points in our current class in the 2-d tuple format", "\n", "", "list_of_points_in_current_class", "=", "label_dict", "[", "found_labels", "[", "class_index", "]", "]", "\n", "# this is the list of points in our current class in the 1-d global number format (which corresponds to the vector's dimentions)", "\n", "global_list_of_points_in_current_class", "=", "acts", ".", "from_local_indices", "(", "\n", "list_of_points_in_current_class", ")", "# this gives all the points as a list", "\n", "# thus our cluster of points for this class is...", "\n", "current_cluster", "=", "acts", ".", "get_activations_for_neuron", "(", "current_neuron_index", ")", "[", "0", "]", "[", "0", "]", "[", "\n", "global_list_of_points_in_current_class", "]", "\n", "# and cos that was so fucking belaboured, lets check that shit", "\n", "# current_point = list_of_points_in_current_class[point_index]", "\n", "if", "do_check", ":", "\n", "            ", "for", "point_index", "in", "range", "(", "len", "(", "list_of_points_in_current_class", ")", ")", ":", "\n", "                ", "current_point_local", "=", "list_of_points_in_current_class", "[", "point_index", "]", "\n", "current_point_global", "=", "acts", ".", "from_local_indices", "(", "[", "list_of_points_in_current_class", "[", "point_index", "]", "]", ")", "[", "0", "]", "\n", "# the activation for the current neuron in the current point should equal the activation for the current point in the current neuron", "\n", "assert", "acts", ".", "get_activation", "(", "current_point_local", ")", ".", "vector", "[", "current_neuron_index", "]", "==", "acts", ".", "get_activations_for_neuron", "(", "current_neuron_index", ")", "[", "0", "]", "[", "0", "]", "[", "current_point_global", "]", "\n", "# and this checks we've clustered it correctly", "\n", "assert", "acts", ".", "get_activation", "(", "current_point_local", ")", ".", "vector", "[", "current_neuron_index", "]", "==", "current_cluster", "[", "\n", "point_index", "]", "\n", "# phew that was effortful", "\n", "", "print", "(", "'Coordinate transform from local to global check passed :)'", ")", "\n", "", "cluster_list", ".", "append", "(", "current_cluster", ")", "\n", "# note this assertion is assuming a 1d vectro", "\n", "# 9.2300749", "\n", "", "return", "cluster_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.tiger_shark_or_toilet_roll": [[500, 543], ["numpy.where", "acts.get_points", "h5_analysis_jitterer.tiger_shark_or_toilet_roll._inner"], "function", ["None"], ["", "def", "tiger_shark_or_toilet_roll", "(", "label_no", ",", "label_dict", "=", "label_dict", ",", "point_no", "=", "None", ",", "acts", "=", "acts", ",", "\n", "found_labels", "=", "found_labels", ",", "\n", "print_value", "=", "True", ",", "class_labels", "=", "{", "}", ")", ":", "\n", "    ", "\"\"\"Tells you the class of a activation picture by selecting the max activation\n    N.B. this expects that you are using fc8 activations\n    if not, it will return the neuron wit the highest activation\n    point_no: if None, will do all points, else give a list or an integer\n    label_no: which found_label do you want to ivestigate\n    print_value: whether to print out the value\n    \"\"\"", "\n", "tiger_sharks", "=", "[", "]", "\n", "\n", "def", "find_position_of_max_act_in_vector", "(", "vector", ")", ":", "\n", "        ", "\"\"\"lets find that max\"\"\"", "\n", "out", "=", "np", ".", "where", "(", "vector", "==", "vector", ".", "max", "(", ")", ")", "\n", "return", "out", ",", "vector", ".", "max", "(", ")", "\n", "\n", "", "def", "_inner", "(", "print_value", "=", "print_value", ",", "class_labels", "=", "class_labels", ",", "tiger_sharks", "=", "tiger_sharks", ")", ":", "\n", "        ", "for", "current_shark_label", "in", "tiger_sharks", ":", "\n", "            ", "current_shark", "=", "current_shark_label", ".", "vector", "\n", "i", ",", "j", "=", "find_position_of_max_act_in_vector", "(", "current_shark", ")", "\n", "if", "(", "class_labels", "==", "{", "}", ")", ".", "any", "(", ")", "==", "False", ":", "\n", "                ", "label", "=", "class_labels", "[", "i", "[", "0", "]", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                ", "label", "=", "''", "\n", "", "if", "print_value", ":", "\n", "                ", "print", "(", "'Position {}, value {}: {}'", ".", "format", "(", "i", ",", "j", ",", "label", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Position {}: {}'", ".", "format", "(", "i", ",", "label", ")", ")", "\n", "", "", "return", "\n", "\n", "", "if", "point_no", "==", "None", ":", "\n", "# assume you want all points", "\n", "        ", "tiger_sharks", "=", "acts", ".", "get_points", "(", "label_dict", "[", "found_labels", "[", "label_no", "]", "]", ")", "\n", "_inner", "(", "print_value", "=", "print_value", ",", "class_labels", "=", "class_labels", ",", "tiger_sharks", "=", "tiger_sharks", ")", "\n", "", "elif", "type", "(", "point_no", ")", "is", "int", ":", "\n", "        ", "tiger_sharks", "=", "[", "acts", ".", "get_points", "(", "label_dict", "[", "found_labels", "[", "label_no", "]", "]", ")", "[", "point_no", "]", "]", "\n", "_inner", "(", "print_value", "=", "print_value", ",", "class_labels", "=", "class_labels", ",", "tiger_sharks", "=", "tiger_sharks", ")", "\n", "", "elif", "type", "(", "point_no", ")", "is", "list", ":", "\n", "# # assuming a sublist of points", "\n", "        ", "tiger_sharks", "=", "[", "acts", ".", "get_points", "(", "label_dict", "[", "found_labels", "[", "label_no", "]", "]", ")", "[", "i", "]", "for", "i", "in", "point_no", "]", "\n", "_inner", "(", "print_value", "=", "print_value", ",", "class_labels", "=", "class_labels", ",", "tiger_sharks", "=", "tiger_sharks", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer": [[551, 649], ["matplotlib.figure", "matplotlib.gca", "matplotlib.close", "print", "matplotlib.scatter", "itertools.cycle", "range", "matplotlib.scatter", "matplotlib.xlim", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.ylim", "plt.gca.axes.get_xaxis().set_visible", "plt.gca.axes.get_yaxis().set_visible", "matplotlib.show", "matplotlib.close", "print", "plt.figure.savefig", "matplotlib.close", "numpy.random.uniform", "len", "min", "min", "max", "max", "matplotlib.scatter", "min", "min", "max", "max", "matplotlib.scatter", "print", "min", "min", "max", "max", "min", "max", "min", "max", "plt.gca.axes.get_xaxis", "plt.gca.axes.get_yaxis", "min", "min", "max", "max", "numpy.random.uniform", "range", "numpy.random.uniform", "range", "next", "len", "str", "len", "str"], "function", ["None"], ["", "def", "jitterer", "(", "x_data", ",", "colour_flag", "=", "'mono'", ",", "title", "=", "''", ",", "save_label", "=", "'fig'", ",", "show_plots", "=", "False", ",", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "label_dict", "=", "{", "}", ",", "outLayerNeuron", "=", "False", ",", "\n", "current_neuron_index", "=", "0", ")", ":", "\n", "    ", "\"\"\"Lightweight plotter to plot jittered plots of x axis data with various options\n    x_data: the x axis data\n    colour_flag: flag for colour style: mono; cluster; random;\n    title: title for the plot\n    save_label: filename if saving\n    show_plots: whether to show plots\n    save_plots: whether to save plots\n    do_x_axis: whether to show the x axis\n    do_y_axis: whether to show the y axis\n    x_range: range to plot x over\n    y_range: range to plot y over\n    label_dict: the dictionary of label names for the classes\n    outLayerNeuron: whether we're operating on 1-hot encoded output layer (it will label the graphs)\n    current_neuron_index: only used with outLayerNeuron to select the current data, alternatively, use ths to select\n                        : a cluster to be coloured black\n    \"\"\"", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "y_data", "=", "[", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "for", "x", "in", "x_data", "]", "\n", "if", "colour_flag", "==", "'mono'", ":", "\n", "        ", "print", "(", "'doing mono'", ")", "\n", "colour_option", "=", "'k'", "\n", "plt", ".", "scatter", "(", "x_data", ",", "y_data", ",", "label", "=", "title", ",", "\n", "color", "=", "colour_option", ",", "marker", "=", "\"o\"", ",", "alpha", "=", "0.25", ",", "s", "=", "1.75", ")", "\n", "# if colour_flag == 'random':", "\n", "#     z = np.random.rand(len(x_data))", "\n", "#     colour_option = z", "\n", "", "if", "colour_flag", "==", "'cluster'", ":", "\n", "# we expect that x_data is actually a list of lists of points, not just a list of points", "\n", "        ", "colourList", "=", "itertools", ".", "cycle", "(", "[", "'blue'", ",", "'firebrick'", ",", "'gray'", ",", "'darkgreen'", ",", "'m'", ",", "\n", "'darkorange'", ",", "'red'", ",", "'gold'", ",", "'darkcyan'", ",", "\n", "'olivedrab'", ",", "'dodgerblue'", "]", ")", "\n", "min_of_x", ",", "max_of_x", "=", "x_data", "[", "0", "]", "[", "0", "]", ",", "x_data", "[", "0", "]", "[", "0", "]", "\n", "min_of_y", ",", "max_of_y", "=", "1", ",", "1", "\n", "for", "cn", "in", "range", "(", "len", "(", "x_data", ")", ")", ":", "\n", "            ", "if", "(", "(", "outLayerNeuron", "==", "True", ")", "and", "(", "not", "cn", "==", "current_neuron_index", ")", ")", "or", "outLayerNeuron", "==", "False", ":", "\n", "# if not outLayerNeuron or cn != current_neuron_index:", "\n", "# If not our selected data, plot it with all teh colours", "\n", "                ", "x_data_subset", "=", "x_data", "[", "cn", "]", "# [x[0] for x in cf[cn]]", "\n", "y_data_subset", "=", "[", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "for", "x", "in", "range", "(", "len", "(", "x_data_subset", ")", ")", "]", "\n", "# we need this stuff to plot the full range nicely", "\n", "min_of_x", "=", "min", "(", "min", "(", "x_data_subset", ")", ",", "min_of_x", ")", "\n", "min_of_y", "=", "min", "(", "min", "(", "y_data_subset", ")", ",", "min_of_y", ")", "\n", "max_of_x", "=", "max", "(", "max", "(", "x_data_subset", ")", ",", "max_of_x", ")", "\n", "max_of_y", "=", "max", "(", "max", "(", "y_data_subset", ")", ",", "max_of_y", ")", "\n", "plt", ".", "scatter", "(", "x_data_subset", ",", "y_data_subset", ",", "label", "=", "'neuron '", "+", "str", "(", "0", ")", ",", "marker", "=", "\"o\"", ",", "alpha", "=", "0.5", ",", "\n", "color", "=", "next", "(", "colourList", ")", ")", "\n", "", "else", ":", "\n", "                ", "pass", "\n", "# cos we want to plot the last class last so its on the top", "\n", "", "", "if", "outLayerNeuron", "==", "True", ":", "\n", "# now we do that last one", "\n", "            ", "cn", "=", "current_neuron_index", "\n", "if", "verbose", ":", "\n", "                ", "print", "(", "'Output layer neuron for class no {}'", ".", "format", "(", "cn", ")", ")", "\n", "# If not our selected data, plot it with balck", "\n", "", "x_data_subset", "=", "x_data", "[", "cn", "]", "# [x[0] for x in cf[cn]]", "\n", "y_data_subset", "=", "[", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "for", "x", "in", "range", "(", "len", "(", "x_data_subset", ")", ")", "]", "\n", "# we need this stuff to plot the full range nicely", "\n", "min_of_x", "=", "min", "(", "min", "(", "x_data_subset", ")", ",", "min_of_x", ")", "\n", "min_of_y", "=", "min", "(", "min", "(", "y_data_subset", ")", ",", "min_of_y", ")", "\n", "max_of_x", "=", "max", "(", "max", "(", "x_data_subset", ")", ",", "max_of_x", ")", "\n", "max_of_y", "=", "max", "(", "max", "(", "y_data_subset", ")", ",", "max_of_y", ")", "\n", "plt", ".", "scatter", "(", "x_data_subset", ",", "y_data_subset", ",", "label", "=", "'neuron '", "+", "str", "(", "0", ")", ",", "marker", "=", "\"s\"", ",", "alpha", "=", "0.75", ",", "\n", "color", "=", "'k'", ")", "\n", "", "x_range", "=", "[", "min_of_x", ",", "max_of_x", "+", "0.1", "*", "max_of_x", "]", "\n", "y_range", "=", "[", "min_of_y", ",", "max_of_y", "]", "\n", "", "else", ":", "\n", "        ", "colour_option", "=", "'k'", "\n", "plt", ".", "scatter", "(", "x_data", ",", "y_data", ",", "label", "=", "title", ",", "\n", "color", "=", "colour_option", ",", "marker", "=", "\"o\"", ",", "alpha", "=", "0.25", ",", "s", "=", "1.75", ")", "\n", "## now we have a scatter plot, lets fuck with it", "\n", "", "if", "x_range", "==", "None", ":", "\n", "# figure it out yourself", "\n", "        ", "plt", ".", "xlim", "(", "[", "min", "(", "x_data", ")", ",", "max", "(", "x_data", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "xlim", "(", "x_range", ")", "\n", "", "if", "y_range", "==", "None", ":", "\n", "# figure it out yourself", "\n", "        ", "plt", ".", "ylim", "(", "[", "min", "(", "y_data", ")", ",", "max", "(", "y_data", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "plt", ".", "ylim", "(", "y_range", ")", "\n", "", "cur_axes", "=", "plt", ".", "gca", "(", ")", "\n", "if", "do_x_axis", "==", "False", ":", "\n", "        ", "cur_axes", ".", "axes", ".", "get_xaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "", "if", "do_y_axis", "==", "False", ":", "\n", "        ", "cur_axes", ".", "axes", ".", "get_yaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "", "if", "show_plots", ":", "\n", "        ", "plt", ".", "show", "(", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "if", "save_plots", ":", "\n", "        ", "print", "(", "'saving figure {}.'", ".", "format", "(", "save_label", ")", ")", "\n", "fig", ".", "savefig", "(", "save_label", ",", "dpi", "=", "400", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "plt", ".", "close", "(", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.make_class_to_line_number_look_up_table": [[652, 665], ["range", "len", "line.split", "line.split", "print"], "function", ["None"], ["", "def", "make_class_to_line_number_look_up_table", "(", "class_labels", "=", "class_labels", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Function to link the class code with the line number as used in imagenet\n    class_labels: output from reading in the class label file in Make_activation\n    verbose: set to true if you want a print out on-screen of line number ot class\"\"\"", "\n", "class_dict", "=", "{", "}", "\n", "for", "line_no", "in", "range", "(", "len", "(", "class_labels", ")", ")", ":", "\n", "        ", "line", "=", "class_labels", "[", "line_no", "]", "\n", "class_code", "=", "line", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "class_name", "=", "line", ".", "split", "(", "' '", ")", "[", "1", ":", "]", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'class no. {}: class: {}: {}'", ".", "format", "(", "line_no", ",", "class_code", ",", "' '", ".", "join", "(", "class_name", ")", ")", ")", "\n", "", "class_dict", "[", "class_code", "]", "=", "line_no", "\n", "", "return", "class_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.append_images": [[667, 707], ["zip", "PIL.Image.new", "sum", "max", "max", "sum", "Image.new.paste", "Image.new.paste", "int", "int"], "function", ["None"], ["", "def", "append_images", "(", "images", ",", "direction", "=", "'horizontal'", ",", "\n", "bg_color", "=", "(", "255", ",", "255", ",", "255", ")", ",", "aligment", "=", "'center'", ")", ":", "\n", "    ", "\"\"\"\n    Appends images in horizontal/vertical direction.\n    Args:\n        images: List of PIL images\n        direction: direction of concatenation, 'horizontal' or 'vertical'\n        bg_color: Background color (default: white)\n        aligment: alignment mode if images need padding;\n           'left', 'right', 'top', 'bottom', or 'center'\n    Returns:\n        Concatenated image as a new PIL image object.\n    \"\"\"", "\n", "widths", ",", "heights", "=", "zip", "(", "*", "(", "i", ".", "size", "for", "i", "in", "images", ")", ")", "\n", "if", "direction", "==", "'horizontal'", ":", "\n", "        ", "new_width", "=", "sum", "(", "widths", ")", "\n", "new_height", "=", "max", "(", "heights", ")", "\n", "", "else", ":", "\n", "        ", "new_width", "=", "max", "(", "widths", ")", "\n", "new_height", "=", "sum", "(", "heights", ")", "\n", "", "new_im", "=", "Image", ".", "new", "(", "'RGB'", ",", "(", "new_width", ",", "new_height", ")", ",", "color", "=", "bg_color", ")", "\n", "offset", "=", "0", "\n", "for", "im", "in", "images", ":", "\n", "        ", "if", "direction", "==", "'horizontal'", ":", "\n", "            ", "y", "=", "0", "\n", "if", "aligment", "==", "'center'", ":", "\n", "                ", "y", "=", "int", "(", "(", "new_height", "-", "im", ".", "size", "[", "1", "]", ")", "/", "2", ")", "\n", "", "elif", "aligment", "==", "'bottom'", ":", "\n", "                ", "y", "=", "new_height", "-", "im", ".", "size", "[", "1", "]", "\n", "", "new_im", ".", "paste", "(", "im", ",", "(", "offset", ",", "y", ")", ")", "\n", "offset", "+=", "im", ".", "size", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "x", "=", "0", "\n", "if", "aligment", "==", "'center'", ":", "\n", "                ", "x", "=", "int", "(", "(", "new_width", "-", "im", ".", "size", "[", "0", "]", ")", "/", "2", ")", "\n", "", "elif", "aligment", "==", "'right'", ":", "\n", "                ", "x", "=", "new_width", "-", "im", ".", "size", "[", "0", "]", "\n", "", "new_im", ".", "paste", "(", "im", ",", "(", "x", ",", "offset", ")", ")", "\n", "offset", "+=", "im", ".", "size", "[", "1", "]", "\n", "", "", "return", "new_im", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.crop_to_square": [[709, 736], ["PIL.Image.open", "img.crop.crop", "img.crop.crop"], "function", ["None"], ["", "def", "crop_to_square", "(", "image_address", ")", ":", "\n", "    ", "\"\"\"function to crop to open and crop an image to square\n    cos rolleiflex was correct\"\"\"", "\n", "img", "=", "Image", ".", "open", "(", "image_address", ")", "\n", "w", ",", "h", "=", "img", ".", "size", "\n", "half_the_width", "=", "w", "/", "2", "\n", "half_the_height", "=", "h", "/", "2", "\n", "# get square", "\n", "if", "w", "<", "h", ":", "\n", "        ", "img", "=", "img", ".", "crop", "(", "\n", "(", "\n", "half_the_width", "-", "half_the_width", ",", "\n", "half_the_height", "-", "half_the_width", ",", "\n", "half_the_width", "+", "half_the_width", ",", "\n", "half_the_height", "+", "half_the_width", "\n", ")", "\n", ")", "\n", "", "elif", "h", "<", "w", ":", "\n", "        ", "img", "=", "img", ".", "crop", "(", "\n", "(", "\n", "half_the_width", "-", "half_the_height", ",", "\n", "half_the_height", "-", "half_the_height", ",", "\n", "half_the_width", "+", "half_the_height", ",", "\n", "half_the_height", "+", "half_the_height", "\n", ")", "\n", ")", "\n", "", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.make_collage": [[738, 795], ["range", "h5_analysis_jitterer.append_images", "acts.get_file_name().decode", "h5_analysis_jitterer.filename_to_label", "selected_image_list.append", "len", "len", "int", "rows.append", "append_images.save", "print", "found_classes.append", "crop_to_square().resize", "h5_analysis_jitterer.append_images", "print", "print", "acts.get_file_name", "acts.get_file_name().decode.split", "x.resize", "map", "len", "append_images.save", "h5_analysis_jitterer.crop_to_square", "h5_analysis_jitterer.crop_to_square", "print"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.append_images", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.filename_to_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.save", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.append_images", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_file_name", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.save", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.crop_to_square", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.crop_to_square"], ["", "def", "make_collage", "(", "out_file", "=", "'temp.jpg'", ",", "local_list", "=", "local_list", ",", "shrink", "=", "True", ",", "do_square", "=", "True", ",", "no_of_cols", "=", "5", ",", "\n", "acts", "=", "acts", ",", "class_dict", "=", "class_dict", ",", "class_labels", "=", "class_labels", ",", "\n", "verbose", "=", "verbose", ",", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ")", ":", "\n", "    ", "\"\"\"Function to get the selected images and collage them\n    local_list: list of points in act to find pictures for\n    shrink: whether to shrink images\n    do_square: whether to squarify the images\n    no_of_cols: how many colums in the collage\n    returns an image object\"\"\"", "\n", "selected_image_list", "=", "[", "]", "\n", "found_classes", "=", "[", "]", "\n", "for", "selected_point", "in", "local_list", ":", "\n", "# grab filename", "\n", "        ", "selected_file", "=", "acts", ".", "get_file_name", "(", "selected_point", ")", ".", "decode", "(", "'UTF-8'", ")", "\n", "if", "verbose", ":", "\n", "            ", "pass", "\n", "# print(selected_file)", "\n", "# we've assumed files are in folders labelled by class!", "\n", "", "class_dir_label", "=", "filename_to_label", "(", "selected_file", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "selected_image_list", ".", "append", "(", "imagenet_root", "+", "class_dir_label", "+", "'/'", "+", "selected_file", ")", "\n", "class_no", "=", "class_dict", "[", "class_dir_label", "]", "\n", "if", "not", "class_no", "in", "found_classes", ":", "\n", "            ", "found_classes", ".", "append", "(", "class_no", ")", "\n", "", "", "if", "shrink", "and", "do_square", ":", "\n", "        ", "images", "=", "[", "crop_to_square", "(", "x", ")", ".", "resize", "(", "(", "277", ",", "277", ")", ")", "for", "x", "in", "selected_image_list", "]", "\n", "", "elif", "shrink", ":", "\n", "# this option may not work so do not use it!", "\n", "        ", "images", "=", "[", "Image", ".", "open", "for", "x", "in", "selected_image_list", "]", "\n", "images", "=", "[", "x", ".", "resize", "(", "(", "277", ",", "277", ")", ")", "for", "x", "in", "images", "]", "\n", "", "elif", "do_square", ":", "\n", "        ", "images", "=", "[", "crop_to_square", "(", "x", ")", "for", "x", "in", "selected_image_list", "]", "\n", "", "else", ":", "\n", "        ", "images", "=", "map", "(", "Image", ".", "open", ",", "selected_image_list", ")", "\n", "", "rows", "=", "[", "]", "\n", "# make row images", "\n", "if", "len", "(", "images", ")", "<", "10", ":", "\n", "        ", "no_of_cols", "=", "len", "(", "images", ")", "\n", "", "for", "row_no", "in", "range", "(", "int", "(", "len", "(", "images", ")", "/", "no_of_cols", ")", ")", ":", "\n", "        ", "rows", ".", "append", "(", "\n", "append_images", "(", "images", "[", "0", "+", "no_of_cols", "*", "row_no", ":", "no_of_cols", "+", "no_of_cols", "*", "row_no", "]", ",", "direction", "=", "'horizontal'", ")", ")", "\n", "# stack row images", "\n", "", "combined_image", "=", "append_images", "(", "rows", ",", "direction", "=", "'vertical'", ")", "\n", "try", ":", "\n", "        ", "combined_image", ".", "save", "(", "out_file", ")", "\n", "", "except", "IOError", ":", "\n", "        ", "print", "(", "\"Failed to write {}, trying as png\"", ".", "format", "(", "out_file", ")", ")", "\n", "try", ":", "\n", "            ", "out_file_png", "=", "\"{}.png\"", ".", "format", "(", "out_file", ")", "\n", "combined_image", ".", "save", "(", "out_file_png", ")", "\n", "", "except", "IOError", ":", "\n", "            ", "print", "(", "\"Failed to write {} as png\"", ".", "format", "(", "out_file_png", ")", ")", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'Found the following classes:'", ")", "\n", "for", "class_no", "in", "found_classes", ":", "\n", "            ", "print", "(", "'{}'", ".", "format", "(", "class_labels", "[", "class_no", "]", ")", ")", "\n", "# if you want to see it do combined_image.show()", "\n", "", "", "return", "combined_image", ",", "found_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.get_class_clusters_for_neuron": [[797, 815], ["h5_analysis_jitterer.build_cluster_from_class_label", "acts.get_activations_for_neuron"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.build_cluster_from_class_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron"], ["", "def", "get_class_clusters_for_neuron", "(", "current_neuron_index", ",", "x_data", "=", "[", "]", ",", "acts", "=", "acts", ",", "label_dict", "=", "label_dict", ",", "\n", "found_labels", "=", "found_labels", ")", ":", "\n", "    ", "\"\"\"function to generate useful info for a single neuron from acts\n    current_neuron_index: which neuron to investigate\"\"\"", "\n", "# ! TODO: perhaps add in kmeans here to get kmeans generated clusters for a neuron, when it works", "\n", "if", "x_data", "==", "[", "]", ":", "\n", "# this is slow, so only do it if you have to", "\n", "        ", "current_neuron", "=", "acts", ".", "get_activations_for_neuron", "(", "current_neuron_index", ")", "\n", "x_data", "=", "current_neuron", ".", "vector", "\n", "", "else", ":", "\n", "        ", "current_neuron", "=", "[", "]", "\n", "pass", "\n", "", "cluster_list", "=", "build_cluster_from_class_label", "(", "acts", "=", "acts", ",", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "current_neuron", "=", "current_neuron", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "found_labels", "=", "found_labels", ",", "do_check", "=", "do_check", ",", "\n", "verbose", "=", "False", ")", "\n", "return", "x_data", ",", "cluster_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster": [[817, 853], ["numpy.argsort", "len", "acts.to_local_indices", "acts.get_activations_for_neuron", "numpy.where", "print", "print", "numpy.logical_and", "numpy.mean", "numpy.std"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.to_local_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron"], ["", "def", "grab_points_for_a_cluster", "(", "current_neuron_index", ",", "\n", "min_selected_x_data", ",", "\n", "max_selected_x_data", ",", "\n", "x_data", "=", "[", "]", ",", "\n", "acts", "=", "acts", ",", "\n", "verbose", "=", "verbose", ")", ":", "\n", "    ", "\"\"\"Grabs image names and addresses for images that fall within an activation range\n    current_neuron_index: which neuron to use\n    min_selected_x_data: minimum activation to grab (leq)\n    max_selected_x_data: maximum activation to grab (meq)\n    acts: activations\n    returns the list sorted from min to max\n    \"\"\"", "\n", "if", "x_data", "==", "[", "]", ":", "\n", "        ", "current_neuron", "=", "acts", ".", "get_activations_for_neuron", "(", "current_neuron_index", ")", "\n", "x_data", "=", "current_neuron", ".", "vector", "\n", "", "else", ":", "\n", "        ", "pass", "\n", "# we find the activations", "\n", "", "selected_activation_indices", "=", "np", ".", "where", "(", "np", ".", "logical_and", "(", "x_data", ">=", "min_selected_x_data", ",", "x_data", "<=", "max_selected_x_data", ")", ")", "[", "0", "]", "\n", "# we grab the activations", "\n", "selected_activations", "=", "x_data", "[", "selected_activation_indices", "]", "\n", "# we sort them based on value of activation and gt a list", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "selected_activations", ")", "\n", "selected_activations", "=", "x_data", "[", "selected_activation_indices", "[", "sorted_indices", "]", "]", "\n", "selected_activation_indices", "=", "selected_activation_indices", "[", "sorted_indices", "]", "\n", "no_of_selected_activations", "=", "len", "(", "selected_activation_indices", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'No. of selected activations is {}'", ".", "format", "(", "no_of_selected_activations", ")", ")", "\n", "# selected_activations = x_data[selected_activation_indices]", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "'Selected activations are {} on average with a standard deviation of {}'", ".", "format", "(", "\n", "np", ".", "mean", "(", "selected_activations", ")", ",", "np", ".", "std", "(", "selected_activations", ")", ")", ")", "\n", "", "local_list", "=", "acts", ".", "to_local_indices", "(", "selected_activation_indices", ")", "\n", "return", "local_list", ",", "selected_activations", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.single_cluster_analysis": [[887, 926], ["h5_analysis_jitterer.grab_points_for_a_cluster", "h5_analysis_jitterer.make_collage", "str"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.make_collage"], ["", "def", "single_cluster_analysis", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "0", ",", "\n", "max_selected_x_data", "=", "100", ",", "\n", "acts", "=", "acts", ",", "\n", "x_data", "=", "[", "]", ",", "\n", "name_stem", "=", "'collage'", ",", "\n", "class_dict", "=", "class_dict", ",", "\n", "class_labels", "=", "class_labels", ",", "\n", "verbose", "=", "verbose", ",", "\n", "do_pictures", "=", "do_pictures", "\n", ")", ":", "\n", "    ", "\"\"\"wrapper function to analyse a single cluster on a single neuron, this gives out the number of selected activations\n    mean and std, their classes and produces a picture\n    \"\"\"", "\n", "# Todo could tidy this up", "\n", "# # # lets grab some points (currently I bin the activations)", "\n", "local_list", ",", "selected_activations", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "min_selected_x_data", ",", "\n", "max_selected_x_data", "=", "max_selected_x_data", ",", "\n", "x_data", "=", "x_data", ",", "\n", "acts", "=", "acts", ",", "\n", "verbose", "=", "True", ")", "\n", "if", "do_pictures", "==", "True", ":", "\n", "        ", "egg", "=", "make_collage", "(", "out_file", "=", "name_stem", "+", "str", "(", "current_neuron_index", ")", "+", "'.jpg'", ",", "\n", "local_list", "=", "local_list", ",", "\n", "shrink", "=", "True", ",", "\n", "do_square", "=", "True", ",", "\n", "no_of_cols", "=", "10", ",", "\n", "acts", "=", "acts", ",", "\n", "class_dict", "=", "class_dict", ",", "\n", "class_labels", "=", "class_labels", ",", "\n", "verbose", "=", "verbose", ",", "\n", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ")", "\n", "", "else", ":", "\n", "        ", "egg", "=", "''", "\n", "# egg = make_collage(out_file=name_stem + str(current_neuron_index) + '.jpg', local_list=local_list, shrink=True, do_square=True, no_of_cols=10,", "\n", "#             acts=acts, verbose=verbose, imagenet_root='/storage/data/imagenet_2012/')", "\n", "# to see picutre, do egg.show()", "\n", "", "return", "local_list", ",", "selected_activations", ",", "egg", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.spotty_plotter": [[928, 1000], ["range", "matplotlib.figure", "len", "matplotlib.show", "matplotlib.close", "print", "plt.figure.savefig", "matplotlib.close", "range", "range", "matplotlib.subplot", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.gca", "plt.gca.axes.get_yaxis().set_visible", "plt.gca.axes.get_xaxis().set_visible", "itertools.cycle", "range", "matplotlib.scatter", "str", "len", "matplotlib.scatter", "numpy.random.rand", "matplotlib.scatter", "numpy.array", "numpy.array", "matplotlib.scatter", "matplotlib.scatter", "matplotlib.scatter", "numpy.ones", "plt.gca.axes.get_yaxis", "plt.gca.axes.get_xaxis", "len", "numpy.random.uniform", "next", "numpy.random.uniform", "str", "str", "numpy.random.uniform", "str"], "function", ["None"], ["", "def", "spotty_plotter", "(", "dks", ",", "input_flag", "=", "'K'", ",", "doHistogram", "=", "False", ",", "colour", "=", "'random'", ",", "doMu", "=", "True", ",", "show_plots", "=", "0", ",", "save_plots", "=", "1", ",", "\n", "cols", "=", "2", ",", "label", "=", "''", ",", "no_of_layers", "=", "1", ")", ":", "\n", "    ", "\"\"\"Make things that look like neuronal plots\"\"\"", "\n", "\"doMu is whether to plot the centers of K-means centroids (mu)\"", "\n", "\"colour= 'random' or 'centroid', or 'black' or ''\"", "\n", "for", "l", "in", "range", "(", "no_of_layers", ")", ":", "\n", "# figsize is in inches, default is 8,6", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "l", ",", "figsize", "=", "(", "24", ",", "18", ")", ")", "\n", "# t = a.jitterer(out, l)", "\n", "# yrange=max(out[l])-min(out[l])", "\n", "r", "=", "len", "(", "dks", "[", "l", "]", ")", "/", "cols", "\n", "c", "=", "cols", "\n", "n", "=", "1", "\n", "layer_overlaps", "=", "min_overlaps", "[", "l", "]", "\n", "if", "input_flag", "==", "'K'", ":", "\n", "# new style using dks", "\n", "            ", "if", "doHistogram", "==", "True", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "c", ")", ":", "\n", "                        ", "plt", ".", "subplot", "(", "r", ",", "c", ",", "n", ")", "\n", "if", "colour", "==", "'centroid'", ":", "\n", "# z = np.random.rand(576)", "\n", "                            ", "cf", "=", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "clusters", "\n", "colourList", "=", "itertools", ".", "cycle", "(", "[", "'blue'", ",", "'firebrick'", ",", "'gray'", ",", "'darkgreen'", ",", "'m'", ",", "\n", "'darkorange'", ",", "'black'", ",", "'red'", ",", "'gold'", ",", "'darkcyan'", ",", "\n", "'olivedrab'", ",", "'dodgerblue'", "]", ")", "\n", "for", "cn", "in", "range", "(", "len", "(", "cf", ")", ")", ":", "\n", "                                ", "x_data", "=", "[", "x", "[", "0", "]", "for", "x", "in", "cf", "[", "cn", "]", "]", "\n", "y_data", "=", "[", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "for", "x", "in", "cf", "[", "cn", "]", "]", "\n", "plt", ".", "scatter", "(", "x_data", ",", "y_data", ",", "label", "=", "'neuron '", "+", "str", "(", "j", ")", ",", "marker", "=", "\"o\"", ",", "alpha", "=", "0.5", ",", "\n", "color", "=", "next", "(", "colourList", ")", ")", "\n", "", "", "else", ":", "\n", "                            ", "if", "colour", "==", "'random'", ":", "\n", "                                ", "z", "=", "np", ".", "random", ".", "rand", "(", "576", ")", "\n", "x_data", "=", "[", "x", "[", "0", "]", "for", "x", "in", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "X", "]", "\n", "y_data", "=", "[", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "for", "x", "in", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "X", "]", "\n", "plt", ".", "scatter", "(", "x_data", ",", "y_data", ",", "label", "=", "'neuron '", "+", "str", "(", "j", ")", ",", "c", "=", "z", ",", "marker", "=", "\"o\"", ",", "alpha", "=", "0.5", ")", "\n", "", "if", "colour", "==", "'black'", ":", "\n", "                                ", "full_x_data", "=", "np", ".", "array", "(", "[", "x", "[", "0", "]", "for", "x", "in", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "X", "]", ")", "\n", "full_y_data", "=", "np", ".", "array", "(", "[", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "for", "x", "in", "full_x_data", "]", ")", "\n", "plt", ".", "scatter", "(", "full_x_data", ",", "full_y_data", ",", "label", "=", "'neuron '", "+", "str", "(", "j", ")", ",", "color", "=", "'k'", ",", "marker", "=", "\"o\"", ",", "\n", "alpha", "=", "0.25", ",", "s", "=", "0.75", ")", "\n", "das_over_label", ",", "das_under_label", "=", "layer_overlaps", "[", "n", "-", "1", "]", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "plt", ".", "scatter", "(", "full_x_data", "[", "label_dict", "[", "das_over_label", "]", "]", ",", "\n", "full_y_data", "[", "label_dict", "[", "das_over_label", "]", "]", ",", "\n", "label", "=", "'neuron {}({})'", ".", "format", "(", "j", ",", "das_over_label", ")", ",", "color", "=", "'green'", ",", "marker", "=", "\"o\"", ",", "\n", "alpha", "=", "0.75", ",", "s", "=", "1", ")", "\n", "plt", ".", "scatter", "(", "full_x_data", "[", "label_dict", "[", "das_under_label", "]", "]", ",", "\n", "full_y_data", "[", "label_dict", "[", "das_under_label", "]", "]", ",", "\n", "label", "=", "'neuron {}({})'", ".", "format", "(", "j", ",", "das_under_label", ")", ",", "color", "=", "'red'", ",", "marker", "=", "\"o\"", ",", "\n", "alpha", "=", "0.75", ",", "s", "=", "1", ")", "\n", "", "", "if", "doMu", "==", "1", ":", "\n", "                            ", "mu_data", "=", "[", "x", "[", "0", "]", "for", "x", "in", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "mu", "]", "\n", "plt", ".", "scatter", "(", "mu_data", ",", "np", ".", "ones", "(", "len", "(", "mu_data", ")", ")", ",", "\n", "marker", "=", "\"^\"", ",", "facecolors", "=", "'none'", ",", "edgecolors", "=", "'k'", ",", "s", "=", "100", ",", "alpha", "=", "1.0", ")", "\n", "", "n", "=", "n", "+", "1", "\n", "plt", ".", "xlim", "(", "[", "-", "0.05", ",", "1.05", "]", ")", "\n", "plt", ".", "ylim", "(", "[", "0.7", ",", "1.3", "]", ")", "\n", "cur_axes", "=", "plt", ".", "gca", "(", ")", "\n", "cur_axes", ".", "axes", ".", "get_yaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "cur_axes", ".", "axes", ".", "get_xaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "", "", "", "", "if", "show_plots", "==", "1", ":", "\n", "            ", "plt", ".", "show", "(", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "if", "save_plots", "==", "1", ":", "\n", "            ", "print", "(", "'saving figure {}.'", ".", "format", "(", "l", ")", ")", "\n", "fig", ".", "savefig", "(", "'spotty'", "+", "str", "(", "l", ")", "+", "label", "+", "'.png'", ",", "dpi", "=", "fig", ".", "dpi", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.fs_plotter": [[1002, 1023], ["len", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.title", "print", "plt.figure.savefig", "matplotlib.close", "fs.tolist", "str", "range", "range", "str", "str", "len", "len"], "function", ["None"], ["", "", "", "def", "fs_plotter", "(", "fs", ",", "K_list", "=", "[", "]", ",", "layer_name", "=", "''", ",", "current_neuron_index", "=", "current_neuron_index", ",", "do_horizontal", "=", "True", ",", "\n", "horizon", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"Function to plot out fs versus K\n    fs is input\n    K_list is the values of K chosen, we assume usually it goes from 1 to the length of fs\"\"\"", "\n", "no_of_points", "=", "len", "(", "fs", ")", "\n", "if", "do_horizontal", "==", "True", ":", "\n", "        ", "horz", "=", "[", "1.0", "for", "x", "in", "range", "(", "len", "(", "fs", ")", "+", "1", ")", "]", "\n", "", "if", "K_list", "==", "[", "]", ":", "\n", "# assume a 1-indexed values", "\n", "        ", "K_list", "=", "[", "1", "+", "x", "for", "x", "in", "range", "(", "len", "(", "fs", ")", ")", "]", "\n", "", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "plot", "(", "K_list", ",", "fs", ".", "tolist", "(", ")", ",", "'o-'", ")", "\n", "plt", ".", "plot", "(", "horz", ")", "\n", "plt", ".", "xlabel", "(", "'K'", ")", "\n", "plt", ".", "ylabel", "(", "'fs'", ")", "\n", "plt", ".", "title", "(", "layer_name", "+", "str", "(", "current_neuron_index", ")", ")", "\n", "print", "(", "'saving figure {}.'", ".", "format", "(", "layer_name", "+", "str", "(", "current_neuron_index", ")", ")", ")", "\n", "fig", ".", "savefig", "(", "'fs_'", "+", "layer_name", "+", "'_'", "+", "str", "(", "current_neuron_index", ")", "+", "'.png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "close", "(", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.selectivity_grid": [[1025, 1087], ["range", "matplotlib.figure", "len", "matplotlib.show", "matplotlib.close", "plt.figure.savefig", "matplotlib.close", "range", "range", "matplotlib.subplot", "len", "range", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.gca", "plt.gca.axes.get_yaxis().set_visible", "plt.gca.set_axis_bgcolor", "str", "print", "float", "matplotlib.text", "matplotlib.text", "matplotlib.text", "matplotlib.text", "matplotlib.text", "plt.gca.axes.get_yaxis", "min", "max", "min", "max", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["", "def", "selectivity_grid", "(", "dks", ",", "input_flag", "=", "'K'", ",", "doHistogram", "=", "False", ",", "colour", "=", "'random'", ",", "doMu", "=", "True", ",", "show_plots", "=", "0", ",", "save_plots", "=", "1", ",", "no_of_layers", "=", "1", ")", ":", "\n", "    ", "\"\"\"Makes selectivity measures and a grid\"\"\"", "\n", "\"doMu is whether to plot the centers of K-means centroids (mu)\"", "\n", "\"colour= 'random' or 'centroid', or 'black' or ''\"", "\n", "for", "l", "in", "range", "(", "no_of_layers", ")", ":", "\n", "        ", "print", "\n", "l", "\n", "fig", "=", "plt", ".", "figure", "(", "l", ")", "\n", "# t = a.jitterer(out, l)", "\n", "# yrange=max(out[l])-min(out[l])", "\n", "r", "=", "len", "(", "dks", "[", "l", "]", ")", "/", "2", "\n", "c", "=", "2", "\n", "n", "=", "1", "\n", "if", "input_flag", "==", "'K'", ":", "\n", "# new style using dks", "\n", "            ", "if", "doHistogram", "==", "True", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "c", ")", ":", "\n", "                        ", "plt", ".", "subplot", "(", "r", ",", "c", ",", "n", ")", "\n", "cf", "=", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "clusters", "\n", "noOfClusters", "=", "len", "(", "cf", ")", "\n", "for", "cn", "in", "range", "(", "noOfClusters", "-", "1", ")", ":", "\n", "# NTS this is hacky and only works for a list of 2 things", "\n", "                            ", "if", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "mu", "[", "cn", "]", ">", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "mu", "[", "cn", "+", "1", "]", ":", "\n", "                                ", "old_selectivity", "=", "min", "(", "cf", "[", "cn", "]", ")", "-", "max", "(", "cf", "[", "cn", "+", "1", "]", ")", "\n", "", "else", ":", "\n", "                                ", "old_selectivity", "=", "min", "(", "cf", "[", "cn", "+", "1", "]", ")", "-", "max", "(", "cf", "[", "cn", "]", ")", "\n", "", "", "if", "noOfClusters", "==", "2", ":", "\n", "# old school selectivity IS DEFINED, so print it", "\n", "                            ", "print", "(", "'layer {0}, neuron {1}, selectivity = {2}'", ".", "format", "(", "l", ",", "n", ",", "old_selectivity", ")", ")", "\n", "z", "=", "float", "(", "old_selectivity", ")", "\n", "plt", ".", "text", "(", "0.05", ",", "0.95", ",", "'sel ='", "+", "str", "(", "old_selectivity", ")", ",", "fontsize", "=", "14", ",", "\n", "verticalalignment", "=", "'top'", ")", "\n", "if", "z", "<", "0.5", ":", "\n", "                                ", "plt", ".", "text", "(", "0.05", ",", "0.95", ",", "'sel ='", "+", "str", "(", "old_selectivity", ")", ",", "fontsize", "=", "14", ",", "\n", "verticalalignment", "=", "'top'", ",", "color", "=", "'white'", ")", "\n", "", "if", "z", "<", "0", ":", "\n", "                                ", "z", "=", "0", "\n", "", "plt", ".", "text", "(", "0.01", ",", "1.97", ",", "str", "(", "l", ")", "+", "str", "(", "n", ")", ",", "fontsize", "=", "12", ",", "\n", "verticalalignment", "=", "'top'", ")", "\n", "", "else", ":", "\n", "                            ", "z", "=", "0", "\n", "", "if", "z", "<", "0.5", ":", "\n", "                            ", "plt", ".", "text", "(", "0.2", ",", "1.2", ",", "'k = '", "+", "str", "(", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "K", ")", ",", "fontsize", "=", "14", ",", "\n", "verticalalignment", "=", "'top'", ",", "color", "=", "'white'", ")", "\n", "", "else", ":", "\n", "                            ", "plt", ".", "text", "(", "0.2", ",", "1.2", ",", "'k = '", "+", "str", "(", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "K", ")", ",", "fontsize", "=", "14", ",", "\n", "verticalalignment", "=", "'top'", ")", "\n", "", "n", "=", "n", "+", "1", "\n", "plt", ".", "xlim", "(", "[", "-", "0.05", ",", "1.05", "]", ")", "\n", "plt", ".", "ylim", "(", "[", "0.7", ",", "1.3", "]", ")", "\n", "cur_axes", "=", "plt", ".", "gca", "(", ")", "\n", "cur_axes", ".", "axes", ".", "get_yaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "cur_axes", ".", "set_axis_bgcolor", "(", "(", "z", ",", "z", ",", "z", ")", ")", "\n", "", "", "", "", "if", "show_plots", "==", "1", ":", "\n", "            ", "plt", ".", "show", "(", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "if", "save_plots", "==", "1", ":", "\n", "            ", "fig", ".", "savefig", "(", "'spotty'", "+", "str", "(", "l", ")", "+", "'.png'", ",", "dpi", "=", "fig", ".", "dpi", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.new_spotty_plotter": [[1092, 1164], ["range", "matplotlib.figure", "len", "matplotlib.show", "matplotlib.close", "print", "plt.figure.savefig", "matplotlib.close", "range", "range", "matplotlib.subplot", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.gca", "plt.gca.axes.get_yaxis().set_visible", "plt.gca.axes.get_xaxis().set_visible", "itertools.cycle", "range", "matplotlib.scatter", "str", "len", "matplotlib.scatter", "numpy.random.rand", "matplotlib.scatter", "numpy.array", "numpy.array", "matplotlib.scatter", "matplotlib.scatter", "matplotlib.scatter", "numpy.ones", "plt.gca.axes.get_yaxis", "plt.gca.axes.get_xaxis", "len", "numpy.random.uniform", "next", "numpy.random.uniform", "str", "str", "numpy.random.uniform", "str"], "function", ["None"], ["", "", "", "def", "new_spotty_plotter", "(", "dks", ",", "input_flag", "=", "'K'", ",", "doHistogram", "=", "False", ",", "colour", "=", "'random'", ",", "doMu", "=", "True", ",", "show_plots", "=", "0", ",", "save_plots", "=", "1", ",", "\n", "cols", "=", "2", ",", "label", "=", "''", ",", "no_of_layers", "=", "1", ")", ":", "\n", "    ", "\"\"\"Make things that look like neuronal plots\"\"\"", "\n", "\"doMu is whether to plot the centers of K-means centroids (mu)\"", "\n", "\"colour= 'random' or 'centroid', or 'black' or ''\"", "\n", "for", "l", "in", "range", "(", "no_of_layers", ")", ":", "\n", "# figsize is in inches, default is 8,6", "\n", "        ", "fig", "=", "plt", ".", "figure", "(", "l", ",", "figsize", "=", "(", "24", ",", "18", ")", ")", "\n", "# t = a.jitterer(out, l)", "\n", "# yrange=max(out[l])-min(out[l])", "\n", "r", "=", "len", "(", "dks", "[", "l", "]", ")", "/", "cols", "\n", "c", "=", "cols", "\n", "n", "=", "1", "\n", "layer_overlaps", "=", "min_overlaps", "[", "l", "]", "\n", "if", "input_flag", "==", "'K'", ":", "\n", "# new style using dks", "\n", "            ", "if", "doHistogram", "==", "True", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "c", ")", ":", "\n", "                        ", "plt", ".", "subplot", "(", "r", ",", "c", ",", "n", ")", "\n", "if", "colour", "==", "'centroid'", ":", "\n", "# z = np.random.rand(576)", "\n", "                            ", "cf", "=", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "clusters", "\n", "colourList", "=", "itertools", ".", "cycle", "(", "[", "'blue'", ",", "'firebrick'", ",", "'gray'", ",", "'darkgreen'", ",", "'m'", ",", "\n", "'darkorange'", ",", "'black'", ",", "'red'", ",", "'gold'", ",", "'darkcyan'", ",", "\n", "'olivedrab'", ",", "'dodgerblue'", "]", ")", "\n", "for", "cn", "in", "range", "(", "len", "(", "cf", ")", ")", ":", "\n", "                                ", "x_data", "=", "[", "x", "[", "0", "]", "for", "x", "in", "cf", "[", "cn", "]", "]", "\n", "y_data", "=", "[", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "for", "x", "in", "cf", "[", "cn", "]", "]", "\n", "plt", ".", "scatter", "(", "x_data", ",", "y_data", ",", "label", "=", "'neuron '", "+", "str", "(", "j", ")", ",", "marker", "=", "\"o\"", ",", "alpha", "=", "0.5", ",", "\n", "color", "=", "next", "(", "colourList", ")", ")", "\n", "", "", "else", ":", "\n", "                            ", "if", "colour", "==", "'random'", ":", "\n", "                                ", "z", "=", "np", ".", "random", ".", "rand", "(", "576", ")", "\n", "x_data", "=", "[", "x", "[", "0", "]", "for", "x", "in", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "X", "]", "\n", "y_data", "=", "[", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "for", "x", "in", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "X", "]", "\n", "plt", ".", "scatter", "(", "x_data", ",", "y_data", ",", "label", "=", "'neuron '", "+", "str", "(", "j", ")", ",", "c", "=", "z", ",", "marker", "=", "\"o\"", ",", "alpha", "=", "0.5", ")", "\n", "", "if", "colour", "==", "'black'", ":", "\n", "                                ", "full_x_data", "=", "np", ".", "array", "(", "[", "x", "[", "0", "]", "for", "x", "in", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "X", "]", ")", "\n", "full_y_data", "=", "np", ".", "array", "(", "[", "1", "+", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ")", "for", "x", "in", "full_x_data", "]", ")", "\n", "plt", ".", "scatter", "(", "full_x_data", ",", "full_y_data", ",", "label", "=", "'neuron '", "+", "str", "(", "j", ")", ",", "color", "=", "'k'", ",", "marker", "=", "\"o\"", ",", "\n", "alpha", "=", "0.25", ",", "s", "=", "0.75", ")", "\n", "das_over_label", ",", "das_under_label", "=", "layer_overlaps", "[", "n", "-", "1", "]", "\n", "# import pdb", "\n", "# pdb.set_trace()", "\n", "plt", ".", "scatter", "(", "full_x_data", "[", "label_dict", "[", "das_over_label", "]", "]", ",", "\n", "full_y_data", "[", "label_dict", "[", "das_over_label", "]", "]", ",", "\n", "label", "=", "'neuron {}({})'", ".", "format", "(", "j", ",", "das_over_label", ")", ",", "color", "=", "'green'", ",", "marker", "=", "\"o\"", ",", "\n", "alpha", "=", "0.75", ",", "s", "=", "1", ")", "\n", "plt", ".", "scatter", "(", "full_x_data", "[", "label_dict", "[", "das_under_label", "]", "]", ",", "\n", "full_y_data", "[", "label_dict", "[", "das_under_label", "]", "]", ",", "\n", "label", "=", "'neuron {}({})'", ".", "format", "(", "j", ",", "das_under_label", ")", ",", "color", "=", "'red'", ",", "marker", "=", "\"o\"", ",", "\n", "alpha", "=", "0.75", ",", "s", "=", "1", ")", "\n", "", "", "if", "doMu", "==", "1", ":", "\n", "                            ", "mu_data", "=", "[", "x", "[", "0", "]", "for", "x", "in", "dks", "[", "l", "]", "[", "n", "-", "1", "]", ".", "mu", "]", "\n", "plt", ".", "scatter", "(", "mu_data", ",", "np", ".", "ones", "(", "len", "(", "mu_data", ")", ")", ",", "\n", "marker", "=", "\"^\"", ",", "facecolors", "=", "'none'", ",", "edgecolors", "=", "'k'", ",", "s", "=", "100", ",", "alpha", "=", "1.0", ")", "\n", "", "n", "=", "n", "+", "1", "\n", "plt", ".", "xlim", "(", "[", "-", "0.05", ",", "1.05", "]", ")", "\n", "plt", ".", "ylim", "(", "[", "0.7", ",", "1.3", "]", ")", "\n", "cur_axes", "=", "plt", ".", "gca", "(", ")", "\n", "cur_axes", ".", "axes", ".", "get_yaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "cur_axes", ".", "axes", ".", "get_xaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "", "", "", "", "if", "show_plots", "==", "1", ":", "\n", "            ", "plt", ".", "show", "(", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "if", "save_plots", "==", "1", ":", "\n", "            ", "print", "(", "'saving figure {}.'", ".", "format", "(", "l", ")", ")", "\n", "fig", ".", "savefig", "(", "'spotty'", "+", "str", "(", "l", ")", "+", "label", "+", "'.png'", ",", "dpi", "=", "fig", ".", "dpi", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.calculate_mean_average_precision": [[1166, 1207], ["acts.get_activations_for_neuron", "h5_analysis_jitterer.grab_points_for_a_cluster", "len", "range", "max", "print", "print", "abs", "abs"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster"], ["", "", "", "def", "calculate_mean_average_precision", "(", "class_name", "=", "''", ",", "current_neuron_index", "=", "current_neuron_index", ",", "acts", "=", "acts", ",", "\n", "verbose", "=", "verbose", ",", "minx", "=", "0.000000001", ")", ":", "\n", "    ", "\"\"\"Counts down using -1 to min list length+1 indexing and calculates the mean average precision\n    given by: M.A.P. = sum over j of no. of A so far found at position j divided by the position in the list\n     Note that we are counting backwards, the formula expects a 1-indexed list and j counts position over a 1-indexed list\n     Note, we assume if no class name is given you want the class for the highest activation\n     minx = the minimum activation to consider, this must be above 0.0 as these all have the same value\"\"\"", "\n", "#", "\n", "current_neuron", "=", "acts", ".", "get_activations_for_neuron", "(", "current_neuron_index", ")", "# get the neuron's data", "\n", "x_data", "=", "current_neuron", ".", "vector", "# get the activations without classes", "\n", "# grab your list of points", "\n", "local_list", ",", "selected_activations", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "minx", ",", "\n", "max_selected_x_data", "=", "max", "(", "x_data", ")", ",", "\n", "acts", "=", "acts", ",", "\n", "x_data", "=", "x_data", ",", "\n", "verbose", "=", "verbose", ")", "\n", "Q", "=", "len", "(", "local_list", ")", "# total length of list", "\n", "# get the test class (this is the correct class or 'A')", "\n", "if", "class_name", "==", "''", ":", "\n", "        ", "test_class", "=", "local_list", "[", "-", "1", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "test_class", "=", "class_name", "\n", "# set up counters", "\n", "", "MAP", "=", "0", "# mean average precision", "\n", "count_of_test_class", "=", "0", "\n", "# loop backwards through the list, abs j is the position in a 1-indexed list", "\n", "for", "i", "in", "range", "(", "Q", "+", "1", ")", ":", "\n", "        ", "j", "=", "-", "(", "i", "+", "1", ")", "# 1 indexed", "\n", "current_class", "=", "local_list", "[", "j", "]", "[", "0", "]", "# current class", "\n", "if", "j", "==", "-", "Q", ":", "\n", "# if the whole of local_list is the same class (this accounts for zero indexing)", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "current_class", ")", "\n", "print", "(", "'{}/{}'", ".", "format", "(", "count_of_test_class", ",", "abs", "(", "j", ")", ")", ")", "\n", "", "j", "=", "j", "-", "1", "# really this is here so we can check j", "\n", "break", "\n", "", "if", "(", "current_class", "==", "test_class", ")", ":", "\n", "            ", "count_of_test_class", "=", "count_of_test_class", "+", "1", "\n", "MAP", "=", "MAP", "+", "count_of_test_class", "/", "(", "abs", "(", "j", ")", ")", "# N.b. this is the sum, we divide by j on the output", "\n", "", "", "return", "MAP", "/", "Q", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_zhou_precision": [[1209, 1217], ["collections.Counter", "len", "range", "collections.Counter.most_common", "collections.Counter.most_common"], "function", ["None"], ["", "def", "find_zhou_precision", "(", "number_of_points", "=", "100", ",", "local_list", "=", "local_list", ")", ":", "\n", "    ", "\"\"\"Finds the maximally occuring class in the top number_of_points and counts it\"\"\"", "\n", "classes_in_top_100", "=", "[", "local_list", "[", "x", "]", "[", "0", "]", "for", "x", "in", "range", "(", "-", "number_of_points", ",", "0", ")", "]", "\n", "zhou", "=", "Counter", "(", "classes_in_top_100", ")", "\n", "zhou_precs_class", "=", "zhou", ".", "most_common", "(", "1", ")", "[", "0", "]", "[", "0", "]", "# the class name", "\n", "zhou_precs", "=", "zhou", ".", "most_common", "(", "1", ")", "[", "0", "]", "[", "1", "]", "/", "number_of_points", "# the precision", "\n", "zhou_no_of_classes", "=", "len", "(", "zhou", ")", "\n", "return", "zhou_precs_class", ",", "zhou_precs", ",", "zhou_no_of_classes", ",", "zhou", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.test_for_repetition_in_activations": [[1221, 1231], ["print", "h5_analysis_jitterer.all_same", "collections.Counter", "collections.Counter.values", "print", "print", "len", "len", "collections.Counter.values", "collections.Counter.values", "collections.Counter.values"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.all_same"], ["", "def", "test_for_repetition_in_activations", "(", "x_data", ",", "verbose", "=", "verbose", ")", ":", "\n", "    ", "\"\"\"Little function to keep an eye out for some wierd shit\"\"\"", "\n", "if", "verbose", ":", "\n", "        ", "test_1", "=", "Counter", "(", "x_data", ")", "\n", "", "print", "(", "test_1", ")", "\n", "if", "all_same", "(", "test_1", ".", "values", "(", ")", ")", ":", "\n", "        ", "print", "(", "'{} values, each repeated {} times'", ".", "format", "(", "len", "(", "test_1", ".", "values", "(", ")", ")", ",", "test_1", ".", "values", "(", ")", "[", "0", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'{} values'", ".", "format", "(", "len", "(", "test_1", ".", "values", "(", ")", ")", ")", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_position_of_max_act_in_vector": [[1233, 1237], ["numpy.where", "vector.max", "vector.max"], "function", ["None"], ["", "def", "find_position_of_max_act_in_vector", "(", "vector", ")", ":", "\n", "    ", "\"\"\"lets find that max\"\"\"", "\n", "out", "=", "np", ".", "where", "(", "vector", "==", "vector", ".", "max", "(", ")", ")", "\n", "return", "out", ",", "vector", ".", "max", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_gaps_between_clusters": [[1239, 1292], ["len", "range", "h5_analysis_jitterer.find_gaps_between_clusters.code_the_gaps"], "function", ["None"], ["", "def", "find_gaps_between_clusters", "(", "cluster_list", ",", "dict_keys", "=", "[", "]", ",", "invert", "=", "True", ")", ":", "\n", "    ", "\"\"\"Finds the gaps between clusters\n    Takes in cluster_list (from cloud.clusters) and not a detK object so we can use this on anything\n    cluster_list: dictionary of clusters\n    dict_key: list of dictionary keys to loop over - currently assumes numbers in increasing order\n    invert - whether to code the gaps from the highest activations or not\"\"\"", "\n", "K", "=", "len", "(", "cluster_list", ")", "# no of clusters", "\n", "gap_list", "=", "[", "]", "\n", "if", "(", "K", "==", "0", ")", ":", "\n", "        ", "print", "(", "\"WARN:find_gaps_between_clusters called with empty gap list\"", ")", "\n", "return", "\n", "\n", "", "def", "code_the_gaps", "(", "gap_list", ",", "invariant_gap_list", "=", "[", "]", ",", "K", "=", "K", ",", "invert", "=", "invert", ")", ":", "\n", "        ", "\"\"\"mini function as we call this twice\"\"\"", "\n", "do_invariant", "=", "True", "\n", "if", "invariant_gap_list", "==", "[", "]", ":", "\n", "            ", "invariant_gap_list", "=", "gap_list", "\n", "do_invariant", "=", "False", "\n", "", "max_gap_code", ",", "max_gap", "=", "find_position_of_max_act_in_vector", "(", "np", ".", "array", "(", "gap_list", ")", ")", "\n", "if", "do_invariant", ":", "\n", "            ", "max_gap_code", "=", "np", ".", "where", "(", "np", ".", "array", "(", "invariant_gap_list", ")", "==", "max_gap", ")", "\n", "", "if", "invert", "==", "True", ":", "\n", "# There are K - 1 gaps, if invert, we start counting from the highest activation cluster", "\n", "            ", "max_gap_code", "=", "K", "-", "1", "-", "max_gap_code", "[", "0", "]", ".", "tolist", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "max_gap_code", "=", "max_gap_code", "[", "0", "]", ".", "tolist", "(", ")", "[", "0", "]", "\n", "", "return", "max_gap_code", ",", "max_gap", "\n", "\n", "", "if", "dict_keys", "==", "[", "]", ":", "\n", "# assume we know what these keys are, sigh, they are what FAstDetK made", "\n", "        ", "dict_keys", "=", "[", "i", "for", "i", "in", "range", "(", "K", ")", "]", "\n", "", "for", "c", "in", "range", "(", "K", "-", "1", ")", ":", "\n", "        ", "higher", "=", "dict_keys", "[", "c", "+", "1", "]", "\n", "lower", "=", "dict_keys", "[", "c", "]", "\n", "# print('{} - {}'.format(c + 1, c))", "\n", "gap", "=", "min", "(", "cluster_list", "[", "higher", "]", ")", "-", "max", "(", "cluster_list", "[", "lower", "]", ")", "\n", "assert", "min", "(", "cluster_list", "[", "higher", "]", ")", ">", "max", "(", "cluster_list", "[", "lower", "]", ")", "\n", "# print(gap)", "\n", "gap_list", ".", "append", "(", "gap", ")", "\n", "# now we analyse this stuff", "\n", "", "max_gap_code", ",", "max_gap", "=", "code_the_gaps", "(", "gap_list", "=", "gap_list", ")", "\n", "# now to get the 2nd biggest gap", "\n", "new_gap_list", "=", "[", "x", "for", "x", "in", "gap_list", "if", "not", "x", "==", "max_gap", "]", "\n", "assert", "(", "len", "(", "new_gap_list", ")", "+", "1", ")", "==", "len", "(", "gap_list", ")", "\n", "# now do it again", "\n", "if", "len", "(", "new_gap_list", ")", ">", "1", ":", "\n", "        ", "max_2_gap_code", ",", "max_2_gap", "=", "code_the_gaps", "(", "gap_list", "=", "new_gap_list", ",", "invariant_gap_list", "=", "gap_list", ")", "\n", "", "else", ":", "\n", "# we found a neuron which only has two clusters in the top half", "\n", "        ", "print", "(", "'highly selective neuron found'", ")", "\n", "max_2_gap_code", "=", "0", "\n", "max_2_gap", "=", "0", "\n", "", "return", "gap_list", ",", "max_gap", ",", "max_gap_code", ",", "max_2_gap", ",", "max_2_gap_code", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_extent_of_top_class": [[1294, 1310], ["range", "len", "len"], "function", ["None"], ["", "def", "find_extent_of_top_class", "(", "local_list", "=", "local_list", ")", ":", "\n", "    ", "\"\"\"starts at the highest index and counts down until the classes no longer match\"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "local_list", ")", "+", "1", ")", ":", "\n", "        ", "j", "=", "-", "(", "i", "+", "1", ")", "# 1 indexed", "\n", "if", "j", "==", "-", "1", ":", "\n", "            ", "test_class", "=", "local_list", "[", "j", "]", "[", "0", "]", "\n", "", "current_class", "=", "local_list", "[", "j", "]", "[", "0", "]", "\n", "if", "j", "==", "-", "len", "(", "local_list", ")", ":", "\n", "# if the whole of local_list is the same class 9(this accounts for zero indexing)", "\n", "            ", "j", "=", "j", "-", "1", "\n", "break", "\n", "", "if", "not", "(", "current_class", "==", "test_class", ")", ":", "\n", "# print(j)", "\n", "            ", "break", "\n", "", "", "no_of_members_of_test_class", "=", "-", "j", "-", "1", "\n", "return", "no_of_members_of_test_class", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.main": [[1317, 1965], ["set_up_caffe_net.main", "print", "print", "Make_activation.main", "h5_analysis_jitterer.make_class_to_line_number_look_up_table", "sys.stdout.write", "sys.stdout.flush", "h5_analysis_jitterer.build_label_dict", "sys.stdout.write", "sys.stdout.flush", "acts.get_image_count", "print", "range", "range", "sys.stdout.write", "sys.stdout.flush", "print", "range", "Make_activation.check_labels", "acts.get_all_activation_indices", "len", "print", "range", "open", "csv.DictWriter", "csv.DictWriter.writeheader", "len", "print", "range", "temp.append", "h5_analysis_jitterer.all_same", "len", "print", "acts.get_activations_for_neuron", "len", "h5_analysis_jitterer.tiger_shark_or_toilet_roll", "len", "acts.get_activation", "print", "print", "numpy.sort", "len", "len", "max", "kmeans.fast_detk.FastDetK.runFK", "print", "min", "max", "h5_analysis_jitterer.grab_points_for_a_cluster", "len", "h5_analysis_jitterer.class_code_to_name", "set", "len", "h5_analysis_jitterer.grab_points_for_a_cluster", "set", "len", "sum", "h5_analysis_jitterer.find_extent_of_top_class", "sum", "collections.OrderedDict", "csv.DictWriter.writerow", "label_dict.keys", "h5_analysis_jitterer.build_cluster_from_class_label", "h5_analysis_jitterer.compute_selectivity_neuron", "h5_analysis_jitterer.build_cluster_from_class_label", "h5_analysis_jitterer.compute_selectivity_neuron", "max", "min", "print", "kmeans.fast_detk.FastDetK", "print", "kmeans.fast_detk.FastDetK", "print", "set", "print", "h5_analysis_jitterer.jitterer", "h5_analysis_jitterer.single_cluster_analysis", "h5_analysis_jitterer.fs_plotter", "len", "print", "print", "h5_analysis_jitterer.jitterer", "h5_analysis_jitterer.fs_plotter", "h5_analysis_jitterer.find_gaps_between_clusters", "print", "len", "sum", "print", "cluster_list.keys", "kmeans.fast_detk.FastDetK.clusters.keys", "h5_analysis_jitterer.grab_points_for_a_cluster", "set", "len", "sum", "h5_analysis_jitterer.grab_points_for_a_cluster", "h5_analysis_jitterer.find_extent_of_top_class", "h5_analysis_jitterer.build_cluster_from_class_label", "h5_analysis_jitterer.compute_ccma_selectivity_neuron", "h5_analysis_jitterer.class_lineno_to_name", "h5_analysis_jitterer.compute_selectivity_neuron", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "sorted", "acts.get_activation", "foundSelectivityList.append", "foundClassList.append", "foundNeuronList.append", "print", "h5_analysis_jitterer.build_cluster_from_class_label", "h5_analysis_jitterer.compute_selectivity_neuron", "print", "len", "len", "min", "kmeans.fast_detk.FastDetK.runFK", "print", "len", "min", "kmeans.fast_detk.FastDetK.runFK", "print", "h5_analysis_jitterer.find_gaps_between_clusters", "h5_analysis_jitterer.fs_plotter", "h5_analysis_jitterer.jitterer", "print", "print", "h5_analysis_jitterer.compute_ccma_selectivity_neuron", "h5_analysis_jitterer.compute_ccma_selectivity_neuron", "h5_analysis_jitterer.class_lineno_to_name", "max", "min", "max", "min", "max", "min", "foundSelectivityList.append", "foundClassList.append", "foundNeuronList.append", "row.items", "found_labels.index", "print", "h5_analysis_jitterer.grab_points_for_a_cluster", "h5_analysis_jitterer.class_code_to_name", "print", "found_labels.index", "print", "foundSelectivityList.append", "foundClassList.append", "foundNeuronList.append", "min", "max", "kmeans.fast_detk.FastDetK", "set", "kmeans.fast_detk.FastDetK", "set", "print", "kmeans.fast_detk.FastDetK.runFK", "min", "h5_analysis_jitterer.class_code_to_name", "print", "found_labels.index", "print", "h5_analysis_jitterer.jitterer", "h5_analysis_jitterer.jitterer", "h5_analysis_jitterer.jitterer", "h5_analysis_jitterer.jitterer", "found_labels.index", "print", "print", "print", "h5_analysis_jitterer.jitterer", "range", "h5_analysis_jitterer.jitterer", "h5_analysis_jitterer.jitterer", "fieldnames.index", "class_labels[].split", "numpy.mean", "max", "class_labels[].split", "h5_analysis_jitterer.jitterer", "h5_analysis_jitterer.jitterer", "min", "min", "max", "len", "class_labels[].split", "class_labels[].split", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.main", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.main", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.make_class_to_line_number_look_up_table", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.build_label_dict", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_image_count", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_activation.check_labels", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationObject.get_all_activation_indices", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.all_same", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.tiger_shark_or_toilet_roll", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.runFK", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.class_code_to_name", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_extent_of_top_class", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.build_cluster_from_class_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.compute_selectivity_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.build_cluster_from_class_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.compute_selectivity_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.single_cluster_analysis", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.fs_plotter", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.fs_plotter", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_gaps_between_clusters", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_extent_of_top_class", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.build_cluster_from_class_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.compute_ccma_selectivity_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.class_lineno_to_name", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.compute_selectivity_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.build_cluster_from_class_label", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.compute_selectivity_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.runFK", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.runFK", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_gaps_between_clusters", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.fs_plotter", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.compute_ccma_selectivity_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.compute_ccma_selectivity_neuron", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.class_lineno_to_name", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.grab_points_for_a_cluster", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.class_code_to_name", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.runFK", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.class_code_to_name", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.jitterer"], ["", "def", "main", "(", ")", ":", "\n", "    ", "global", "acts", ",", "class_labels", ",", "labels", ",", "h5_list", ",", "caffe_settings", "\n", "isClassSelective", "=", "False", "\n", "# class_labels is the imagenet labels for 2012, both human readable and n909402394", "\n", "# image_directory = '/storage/data/imagenet_2012'", "\n", "# set up caffe default", "\n", "# image_directory = '/storage/data/top_1_imagenet_2012/'", "\n", "\n", "# this is hte bit that sets up the caffe networks ------------------------------------------------------------------", "\n", "caffe_settings", "=", "s", ".", "main", "(", ")", "\n", "# caffe_root = s.caffe_root", "\n", "image_directory", "=", "caffe_settings", ".", "image_directory", "\n", "labels_file", "=", "caffe_settings", ".", "labels_file", "\n", "model_def", "=", "caffe_settings", ".", "model_def", "\n", "model_weights", "=", "caffe_settings", ".", "model_weights", "\n", "dir_list", "=", "caffe_settings", ".", "dir_list", "\n", "labels", "=", "caffe_settings", ".", "labels", "\n", "net", "=", "caffe_settings", ".", "net", "\n", "transformer", "=", "caffe_settings", ".", "transformer", "\n", "short_labels", "=", "caffe_settings", ".", "short_labels", "\n", "model_file", "=", "caffe_settings", ".", "model_file", "\n", "this_one_file_name", "=", "caffe_settings", ".", "this_one_file_name", "\n", "blob", "=", "caffe_settings", ".", "blob", "\n", "file_root", "=", "caffe_settings", ".", "file_root", "\n", "class_labels", "=", "short_labels", "\n", "# end of the bit tha sets up the caffe netwroks --------------------------------------------------------------------", "\n", "print", "(", "'I am using the following merged h5 file: {}'", ".", "format", "(", "this_one_file_name", ")", ")", "\n", "print", "(", "'Which I expect to be located at: {}'", ".", "format", "(", "file_root", ")", ")", "\n", "do_check", "=", "False", "\n", "m", ".", "main", "(", ")", "\n", "acts", "=", "m", ".", "acts", "\n", "class_labels", "=", "m", ".", "class_labels", "\n", "\n", "class_dict", "=", "make_class_to_line_number_look_up_table", "(", "class_labels", "=", "class_labels", ",", "verbose", "=", "False", ")", "\n", "# this builds the look-up table between points and the class they are in", "\n", "## This bit is sslow, it loads the label data for all acts", "\n", "sys", ".", "stdout", ".", "write", "(", "'About to build the label dict (slow)'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "label_dict", ",", "found_labels", ",", "no_files_in_label", "=", "build_label_dict", "(", "acts", ")", "\n", "sys", ".", "stdout", ".", "write", "(", "'Built the label dict'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "# class_to_found_label_dict={}", "\n", "# for", "\n", "\n", "no_of_images", "=", "acts", ".", "get_image_count", "(", ")", "\n", "print", "(", "'Found {} images'", ".", "format", "(", "no_of_images", ")", ")", "\n", "\n", "# whether  to sanity check the created activation table (acts)", "\n", "if", "do_check", "==", "True", ":", "\n", "        ", "m", ".", "check_labels", "(", "acts", ",", "class_labels", ")", "\n", "\n", "## This chunk checks that hte no_of_neurons is correct", "\n", "", "temp", "=", "[", "]", "# this is hte no of neurosn each image has data for, these should all be the same!", "\n", "if", "do_check", ":", "\n", "        ", "for", "current_point", "in", "acts", ".", "get_all_activation_indices", "(", ")", ":", "\n", "            ", "temp", ".", "append", "(", "len", "(", "acts", ".", "get_activation", "(", "current_point", ")", ".", "vector", ")", ")", "\n", "", "assert", "all_same", "(", "temp", ")", "==", "True", "\n", "no_of_neurons", "=", "temp", "[", "0", "]", "\n", "", "else", ":", "\n", "# simply grab the no of neurons from the first batch point", "\n", "# no_of_neurons = len(acts.get_activation(acts.get_batch_indices(2)[0]).vector)", "\n", "        ", "no_of_neurons", "=", "len", "(", "acts", ".", "get_activation", "(", "0", ")", ".", "vector", ")", "\n", "print", "(", "'{} neurons found'", ".", "format", "(", "no_of_neurons", ")", ")", "\n", "\n", "########################################################################################################################", "\n", "#       Das loop", "\n", "########################################################################################################################", "\n", "\n", "## code to get useful info for a specific neuron", "\n", "\n", "\n", "", "if", "do_check", "==", "True", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "label_dict", ")", ")", ":", "\n", "            ", "print", "(", "'i{}: row no {}'", ".", "format", "(", "i", ",", "class_dict", "[", "found_labels", "[", "i", "]", "]", ")", ")", "\n", "\n", "", "", "if", "Test", ":", "\n", "        ", "no_of_neurons", "=", "1", "\n", "", "else", ":", "\n", "# no_of_neurons = 1000", "\n", "        ", "pass", "\n", "\n", "", "out_filename", "=", "'dataRerun.csv'", "\n", "\n", "out_vector", "=", "[", "]", "\n", "# for i in range(len(cluster_list)):", "\n", "#     print('{}: {}'.format(i, max(cluster_list[i])))", "\n", "\n", "fieldnames", "=", "[", "'Neuron no.'", ",", "# neuron index", "\n", "'top_class_name'", ",", "\n", "'all_K'", ",", "# no of K for 'All': whole of (midX to maxX) range", "\n", "'all_No_images'", ",", "# No of images over All", "\n", "'biggest_gap'", ",", "# Size of biggest gap: this defines the start of 'Struct' range", "\n", "'big_gap_code'", ",", "# Coded position of gap: 0 is top cluster, counting down", "\n", "'second_biggest_gap'", ",", "# Second biggest gap size --> could be used as struct start", "\n", "'2_Big_gap_code'", ",", "# Gap position code", "\n", "'top_class'", ",", "# Class with highest activation- could be a list", "\n", "'c_0_no'", ",", "# No. images in cluster 0 (top cluster)", "\n", "'c_0_no_class'", ",", "# No. of classes in top cluster", "\n", "'struct_no'", ",", "# No. of images in structured region", "\n", "'struct_K'", ",", "# No. of clusters in struct range --> this may be after a 2nd kmeans", "\n", "'struct_no_class'", ",", "# No of classes in structured region", "\n", "'No_top_in_cluster_0'", ",", "# No. of top class in top cluster", "\n", "'No_top_class_in_struct'", ",", "# No. of top class in structure", "\n", "'No_top_class_in_half_range'", ",", "# No. of top class in half range", "\n", "'No_top_class'", ",", "# No in the top class overall", "\n", "'pc_top_class_in_top_100'", ",", "# pc of top class in top 100", "\n", "'is_class_selective'", ",", "\n", "'ccma_selectivity_top'", ",", "# ccma_selectivity to top activating class", "\n", "'mu_max_top'", ",", "# average activation of top activating class", "\n", "'ccma_selectivity'", ",", "# ccma_selectivity of highest mean activation class", "\n", "'mu_max'", ",", "# mean of highest mean activatinging class", "\n", "'mean_act_class_name'", ",", "# name of highest mean class", "\n", "'ccma_selectivity_2'", ",", "# ccma_selectivity of 2nd highest mean activation class", "\n", "'mu_max_2'", ",", "# mean of second highest mean activatinging class", "\n", "'mean_act_class_name_2'", ",", "# name of highest mean class", "\n", "'range_top'", ",", "# range of top activating class", "\n", "'range_mean'", ",", "# range of class with highest mean activation", "\n", "'range_2_mean'", ",", "# range of class with second highest mean activation", "\n", "'gap_selectivity'", ",", "# sub-group selectivity on anything above the largest gap", "\n", "'extent_of_top_class'", "# number of top activations before the class changes", "\n", "]", "\n", "\n", "ccma_selectivity_top", "=", "0", "# ccma_selectivity to top activating class", "\n", "mu_max_top", "=", "0", "\n", "ccma_selectivity", "=", "0", "# ccma_selectivity of highest mean activation class", "\n", "mu_max", "=", "0", "# mean of highest mean activatinging class", "\n", "top_mean_class", "=", "0", "# name of highest mean class", "\n", "ccma_selectivity_2", "=", "0", "# ccma_selectivity of 2nd highest mean activation class", "\n", "mu_max_2", "=", "0", "# mean of second highest mean activatinging class", "\n", "top_2_mean_class", "=", "0", "# name of highest mean class", "\n", "range_top", "=", "0", "# range of top activating class", "\n", "range_mean", "=", "0", "# range of class with highest mean activation", "\n", "range_2_mean", "=", "0", "# range of class with second highest mean activation", "\n", "gap_selectivity", "=", "0", "# sub-group selectivity on anything above the largest gap", "\n", "extent_of_top_class", "=", "0", "\n", "normal_range", "=", "range", "(", "0", ",", "40", ",", "2", ")", "\n", "current_range", "=", "[", "14", "]", "# normal_range #range(0, int(no_of_neurons/2))", "\n", "# current_range = [0, 1, 2, 4, 5, 6, 7, 8, 13, 49]", "\n", "test_range", "=", "[", "0", ",", "\n", "11", "]", "\n", "normal_range_for_pictures", "=", "range", "(", "0", ",", "no_of_neurons", ",", "100", ")", "\n", "range_for_pictures", "=", "[", "14", "]", "# test_range + [x for x in normal_range_for_pictures]", "\n", "looking_at_output_layer", "=", "False", "\n", "do_second_Botvinick", "=", "False", "# True", "\n", "do_pictures", "=", "False", "# True", "\n", "do_all_points", "=", "False", "# True", "\n", "# !! DO NOT MOVE THESE VARIABLES UP THE TOP IT BREAKS EVERYTHING!!", "\n", "no_of_weak_grandmas", "=", "0", "# counter for the number of neurons with a single cluster at the top of the range above the biggest gap", "\n", "no_of_sparse_neurons", "=", "0", "# counter for the number of neurosn that have less possible K points for half than the setting for k (i.e. sparse and unclustered)", "\n", "no_of_single_grandma", "=", "0", "# counter for the number of neurons that have only 1 image in top cluster", "\n", "# current_range = [0]", "\n", "sys", ".", "stdout", ".", "write", "(", "'About to start with csvfile'", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "with", "open", "(", "out_filename", ",", "'w'", ")", "as", "csvfile", ":", "\n", "# fieldnames=out_list", "\n", "        ", "writer", "=", "csv", ".", "DictWriter", "(", "csvfile", ",", "delimiter", "=", "','", ",", "fieldnames", "=", "fieldnames", ")", "\n", "writer", ".", "writeheader", "(", ")", "\n", "# row = ['Spam'] * 5 + ['Baked Beans']", "\n", "# writer.writerow(row)", "\n", "for", "current_neuron_index", "in", "current_range", ":", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", "(", "'working on neuron {}'", ".", "format", "(", "current_neuron_index", ")", ")", "\n", "# this grabs the activations as a multidimensional array", "\n", "", "current_neuron", "=", "acts", ".", "get_activations_for_neuron", "(", "current_neuron_index", ")", "\n", "# this takes the last dimension (the only non-singleton for 1-D vectors)", "\n", "# x_data = current_neuron[0][0]jitterer", "\n", "x_data", "=", "current_neuron", ".", "vector", "\n", "if", "cluster_by_class", ":", "\n", "                ", "print", "(", "'hello'", ")", "\n", "# this builds a lists of lists of points by class label", "\n", "if", "do_all_points", ":", "\n", "# this will do a comparison of all points", "\n", "                    ", "cluster_list", ",", "min_list", ",", "max_list", "=", "build_cluster_from_class_label", "(", "acts", "=", "acts", ",", "\n", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "current_neuron", "=", "current_neuron", ",", "\n", "found_labels", "=", "found_labels", ",", "\n", "do_check", "=", "do_check", ")", "\n", "# if cluster_by_kmeans == False and do_ccma_selectivity:", "\n", "#     ccma_selectivity, mu_max, mu_not_max, max_index = \\", "\n", "#         compute_ccma_selectivity_neuron(cluster_list=cluster_list, found_labels='',", "\n", "#                                     top_class=top_class,", "\n", "#                                     verbose=verbose)", "\n", "isSelective", ",", "selectivity", ",", "found_class", "=", "compute_selectivity_neuron", "(", "max_list", ",", "min_list", ",", "found_labels", ")", "\n", "if", "looking_at_output_layer", "==", "True", ":", "\n", "# as cluster_list is build from label_dict, and label_dict is in a shuffled order", "\n", "# we must find out which class we are really on!", "\n", "                        ", "if", "do_true_picture", ":", "\n", "# do it anyway", "\n", "                            ", "actual_class", "=", "found_labels", ".", "index", "(", "class_labels", "[", "current_neuron_index", "]", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "\n", "print", "(", "'actual class {}'", ".", "format", "(", "actual_class", ")", ")", "\n", "if", "do_pictures", ":", "\n", "                                ", "jitterer", "(", "x_data", "=", "cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "str", "(", "current_neuron_index", ")", "+", "'cbyc.png'", ",", "\n", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "True", ",", "\n", "current_neuron_index", "=", "actual_class", ")", "\n", "", "", "", "else", ":", "\n", "# not looking at output layer, lets take the max activation as the output class and plot that!", "\n", "                        ", "if", "do_true_picture", ":", "\n", "# do it anyway", "\n", "                            ", "local_list", ",", "selected_activations", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "np", ".", "mean", "(", "\n", "current_neuron", ".", "vector", ")", ",", "\n", "max_selected_x_data", "=", "max", "(", "\n", "current_neuron", ".", "vector", ")", ",", "\n", "acts", "=", "acts", ",", "\n", "x_data", "=", "x_data", ",", "\n", "verbose", "=", "verbose", ")", "\n", "top_class_code", "=", "local_list", "[", "-", "1", "]", "[", "0", "]", "\n", "top_class", "=", "class_dict", "[", "local_list", "[", "-", "1", "]", "[", "0", "]", "]", "\n", "top_class_name", "=", "class_code_to_name", "(", "class_name", "=", "top_class_code", ",", "class_dict", "=", "class_dict", ",", "\n", "class_labels", "=", "class_labels", ")", "\n", "# actual_class = found_labels.index(class_labels[current_neuron_index].split(' ')[0])", "\n", "print", "(", "'maximally activated class is {}'", ".", "format", "(", "top_class_name", ")", ")", "\n", "if", "do_pictures", ":", "\n", "                                ", "jitterer", "(", "x_data", "=", "cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "str", "(", "current_neuron_index", ")", "+", "'cbycMAX.png'", ",", "\n", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "True", ",", "\n", "current_neuron_index", "=", "top_class", ")", "\n", "", "", "", "if", "isSelective", ":", "\n", "# and if it is selective with all points, plot the graph", "\n", "                        ", "foundSelectivityList", ".", "append", "(", "selectivity", ")", "\n", "foundClassList", ".", "append", "(", "found_class", ")", "\n", "foundNeuronList", ".", "append", "(", "current_neuron_index", ")", "\n", "if", "looking_at_output_layer", "==", "True", ":", "\n", "# as cluster_list is build from label_dict, and label_dict is in a shuffled order", "\n", "# we must find out which class we are really on!", "\n", "                            ", "actual_class", "=", "found_labels", ".", "index", "(", "class_labels", "[", "current_neuron_index", "]", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "\n", "print", "(", "'actual class {}'", ".", "format", "(", "actual_class", ")", ")", "\n", "if", "do_pictures", ":", "\n", "                                ", "jitterer", "(", "x_data", "=", "cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "str", "(", "current_neuron_index", ")", "+", "'cbyc.png'", ",", "\n", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "True", ",", "\n", "current_neuron_index", "=", "actual_class", ")", "\n", "", "", "else", ":", "\n", "                            ", "if", "do_pictures", ":", "\n", "# name_leader = 'fc6_layer_neuron'", "\n", "                                ", "jitterer", "(", "x_data", "=", "cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "str", "(", "current_neuron_index", ")", "+", "'.png'", ",", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "False", ",", "\n", "current_neuron_index", "=", "0", ")", "\n", "", "", "", "", "else", ":", "\n", "                    ", "cluster_list", ",", "min_list", ",", "max_list", "=", "build_cluster_from_class_label", "(", "acts", "=", "acts", ",", "\n", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "found_labels", "=", "found_labels", ",", "\n", "current_neuron", "=", "current_neuron", ",", "\n", "do_check", "=", "do_check", ",", "\n", "no_of_points_to_check", "=", "10", ")", "\n", "isSelective", ",", "selectivity", ",", "found_class", "=", "compute_selectivity_neuron", "(", "max_list", ",", "min_list", ",", "found_labels", ")", "\n", "if", "isSelective", ":", "\n", "                        ", "print", "(", "'Found selectivity with 10,000 points, now checking the whole thing'", ")", "\n", "# it is selective on 10,000 points, probably worth trying the whole thing", "\n", "cluster_list", ",", "min_list", ",", "max_list", "=", "build_cluster_from_class_label", "(", "acts", "=", "acts", ",", "\n", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "found_labels", "=", "found_labels", ",", "\n", "current_neuron", "=", "current_neuron", ",", "\n", "do_check", "=", "do_check", ")", "\n", "isSelective", ",", "selectivity", ",", "found_class", "=", "compute_selectivity_neuron", "(", "max_list", ",", "min_list", ",", "\n", "found_labels", ")", "\n", "if", "isSelective", ":", "\n", "# and if it is selective with all points, plot the graph", "\n", "                            ", "foundSelectivityList", ".", "append", "(", "selectivity", ")", "\n", "foundClassList", ".", "append", "(", "found_class", ")", "\n", "foundNeuronList", ".", "append", "(", "current_neuron_index", ")", "\n", "if", "looking_at_output_layer", "==", "True", ":", "\n", "# as cluster_list is build from label_dict, and label_dict is in a shuffled order", "\n", "# we must find out which class we are really on!", "\n", "                                ", "actual_class", "=", "found_labels", ".", "index", "(", "class_labels", "[", "current_neuron_index", "]", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "\n", "print", "(", "'actual class {}'", ".", "format", "(", "actual_class", ")", ")", "\n", "if", "do_pictures", ":", "\n", "                                    ", "jitterer", "(", "x_data", "=", "cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "str", "(", "current_neuron_index", ")", "+", "'.png'", ",", "\n", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "True", ",", "\n", "current_neuron_index", "=", "actual_class", ")", "\n", "", "", "else", ":", "\n", "                                ", "if", "do_pictures", ":", "\n", "# name_leader = 'fc6_layer_neuron'", "\n", "                                    ", "jitterer", "(", "x_data", "=", "cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "str", "(", "current_neuron_index", ")", "+", "'.png'", ",", "\n", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "False", ",", "\n", "current_neuron_index", "=", "0", ")", "\n", "", "", "", "", "else", ":", "\n", "                        ", "print", "(", "'Neuron {} is not selectivie with 10,000 points'", ".", "format", "(", "current_neuron_index", ")", ")", "\n", "", "", "", "if", "cluster_by_kmeans", ":", "\n", "# this sets up a k_means object", "\n", "                ", "rangemax", "=", "max", "(", "current_neuron", ".", "vector", ")", "-", "min", "(", "current_neuron", ".", "vector", ")", "# actually now the correct range!", "\n", "sorted_x_data", "=", "np", ".", "sort", "(", "x_data", ")", "\n", "numx", "=", "len", "(", "current_neuron", ".", "vector", "[", "current_neuron", ".", "vector", ">", "0.5", "*", "rangemax", "+", "min", "(", "current_neuron", ".", "vector", ")", "]", ")", "\n", "if", "numx", ">", "num_of_points_for_initial_k_means", ":", "\n", "# sometimes we get far too many points, let pick 1500 as a max allowed", "\n", "                    ", "print", "(", "'Too many points ({}) in half-range, drop X or up K...'", ".", "format", "(", "numx", ")", ")", "\n", "# argh, some neurons go negative!!!!!", "\n", "discard_ratio", "=", "(", "sorted_x_data", "[", "-", "num_of_points_for_initial_k_means", "]", "-", "min", "(", "current_neuron", ".", "vector", ")", ")", "/", "rangemax", "# max(x_data)", "\n", "cloud", "=", "FastDetK", "(", "X", "=", "current_neuron", ",", "discard", "=", "discard_ratio", ")", "\n", "print", "(", "'Neuron {}, discarding {}% of data'", ".", "format", "(", "current_neuron_index", ",", "discard_ratio", ")", ")", "\n", "", "else", ":", "\n", "                    ", "cloud", "=", "FastDetK", "(", "X", "=", "current_neuron", ",", "discard", "=", "0.5", ")", "\n", "print", "(", "'Neuron {}, discarding 50% of data range'", ".", "format", "(", "current_neuron_index", ")", ")", "\n", "", "max_possible_K", "=", "len", "(", "set", "(", "cloud", ".", "X", ")", ")", "\n", "max_activation", "=", "max", "(", "cloud", ".", "X", ")", "\n", "K_for_cloud", "=", "max_K_For_half", "\n", "if", "max_possible_K", "<", "max_K_For_half", ":", "\n", "                    ", "no_of_sparse_neurons", "=", "no_of_sparse_neurons", "+", "1", "\n", "print", "(", "'sparse neuron detected! No. so far:{}'", ".", "format", "(", "no_of_sparse_neurons", ")", ")", "\n", "K_for_cloud", "=", "max_possible_K", "\n", "", "cloud", ".", "runFK", "(", "K_for_cloud", ",", "1", ")", "\n", "current_best_K", "=", "cloud", ".", "K", "\n", "print", "(", "'neuron {}: k={}'", ".", "format", "(", "current_neuron_index", ",", "current_best_K", ")", ")", "\n", "cluster_list", "=", "cloud", ".", "clusters", "\n", "if", "do_pictures", "or", "current_neuron_index", "in", "range_for_pictures", ":", "\n", "                    ", "jitterer", "(", "x_data", "=", "cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "str", "(", "current_neuron_index", ")", "+", "'_kmeans'", "+", "'.png'", ",", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "False", ",", "\n", "current_neuron_index", "=", "current_neuron_index", ")", "\n", "", "top_cluster", "=", "cluster_list", "[", "current_best_K", "-", "1", "]", "\n", "min_top_cluster", "=", "min", "(", "top_cluster", ")", "\n", "max_top_cluster", "=", "max", "(", "top_cluster", ")", "\n", "# this is just hte top cluster", "\n", "local_list", ",", "selected_activations", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "min_top_cluster", ",", "\n", "max_selected_x_data", "=", "max_top_cluster", ",", "\n", "acts", "=", "acts", ",", "\n", "x_data", "=", "x_data", ",", "\n", "verbose", "=", "verbose", ")", "\n", "if", "do_pictures", "or", "current_neuron_index", "in", "range_for_pictures", ":", "\n", "                    ", "picture", "=", "single_cluster_analysis", "(", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "min_top_cluster", ",", "\n", "max_selected_x_data", "=", "max_top_cluster", ",", "\n", "acts", "=", "acts", ",", "\n", "x_data", "=", "x_data", ",", "\n", "name_stem", "=", "'collage'", ",", "\n", "class_dict", "=", "class_dict", ",", "\n", "class_labels", "=", "class_labels", ",", "\n", "verbose", "=", "verbose", ")", "\n", "fs_plotter", "(", "fs", "=", "cloud", ".", "fs", ",", "layer_name", "=", "'prob_'", ",", "current_neuron_index", "=", "current_neuron_index", ")", "\n", "# data for output", "\n", "", "c_0_no", "=", "len", "(", "local_list", ")", "\n", "top_class", "=", "local_list", "[", "-", "1", "]", "[", "0", "]", "\n", "top_class_name", "=", "class_code_to_name", "(", "class_name", "=", "top_class", ",", "class_dict", "=", "class_dict", ",", "\n", "class_labels", "=", "class_labels", ")", "\n", "unique_classes_0", "=", "set", "(", "[", "x", "[", "0", "]", "for", "x", "in", "local_list", "]", ")", "\n", "c_0_no_classes", "=", "len", "(", "unique_classes_0", ")", "\n", "# now we do structural", "\n", "# this finds and analyses the gaps", "\n", "if", "len", "(", "cluster_list", ")", "==", "0", ":", "\n", "                    ", "print", "(", "\"ERROR: we have an empty cluster list for {}?\"", ".", "format", "(", "current_neuron_index", ")", ")", "\n", "continue", "\n", "", "if", "current_best_K", "==", "1", ":", "\n", "# uniform distrubtion or a higher value of k needed!", "\n", "                    ", "print", "(", "'Neuron {} has a K of 1, may require further investigation!'", ".", "format", "(", "current_neuron_index", ")", ")", "\n", "jitterer", "(", "x_data", "=", "cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "str", "(", "current_neuron_index", ")", "+", "'_kmeans'", "+", "'.png'", ",", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "False", ",", "\n", "current_neuron_index", "=", "current_neuron_index", ")", "\n", "fs_plotter", "(", "fs", "=", "cloud", ".", "fs", ",", "layer_name", "=", "'prob_'", ",", "current_neuron_index", "=", "current_neuron_index", ")", "\n", "gap_list", ",", "max_gap", ",", "max_gap_code", ",", "max_2_gap", ",", "max_2_gap_code", "=", "[", "]", ",", "0", ",", "'Null'", ",", "0", ",", "'Null'", "\n", "", "else", ":", "\n", "                    ", "gap_list", ",", "max_gap", ",", "max_gap_code", ",", "max_2_gap", ",", "max_2_gap_code", "=", "find_gaps_between_clusters", "(", "cluster_list", ",", "dict_keys", "=", "[", "]", ",", "invert", "=", "True", ")", "\n", "if", "len", "(", "cluster_list", "[", "current_best_K", "-", "1", "]", ")", "==", "1", ":", "\n", "# we found a grandma cell for one picture", "\n", "                        ", "no_of_single_grandma", "=", "no_of_single_grandma", "+", "1", "\n", "# we define the structural range as anything above the biggest gap", "\n", "", "", "if", "max_gap_code", "==", "1", ":", "\n", "# we've found a grandmother cell alike!", "\n", "                    ", "no_of_weak_grandmas", "=", "no_of_weak_grandmas", "+", "1", "\n", "print", "(", "'{} weak grandmas'", ".", "format", "(", "no_of_weak_grandmas", ")", ")", "\n", "No_classes_struct", "=", "len", "(", "unique_classes_0", ")", "\n", "no_of_top_class_in_struct", "=", "sum", "(", "[", "1", "for", "x", "in", "local_list", "if", "x", "[", "0", "]", "==", "top_class", "]", ")", "\n", "struct_no", "=", "c_0_no", "\n", "struct_K", "=", "1", "\n", "", "else", ":", "\n", "# we got a structured layer at the top", "\n", "# lets do another k-means", "\n", "                    ", "struct_K", "=", "max_gap_code", "\n", "# middle of the gap between structured and unstructured", "\n", "if", "not", "current_best_K", "==", "1", ":", "\n", "                        ", "mid_struct_gap", "=", "max", "(", "cluster_list", "[", "current_best_K", "-", "max_gap_code", "-", "1", "]", ")", "+", "0.5", "*", "(", "min", "(", "cluster_list", "[", "current_best_K", "-", "max_gap_code", "]", ")", "-", "max", "(", "\n", "cluster_list", "[", "current_best_K", "-", "max_gap_code", "-", "1", "]", ")", ")", "\n", "total_range", "=", "cloud", ".", "maxX", "-", "cloud", ".", "minX", "\n", "as_pc", "=", "mid_struct_gap", "/", "total_range", "\n", "# numx = len(current_neuron.vector[current_neuron.vector > 0.5 * rangemax])", "\n", "try", ":", "\n", "                            ", "structured", "=", "FastDetK", "(", "X", "=", "current_neuron", ",", "discard", "=", "as_pc", ")", "\n", "", "except", "UserWarning", "as", "e", ":", "\n", "                            ", "print", "(", "\n", "'That weird error where it spits on struct region and fails to find any points, sob :('", ")", "\n", "continue", "\n", "", "max_possible_K", "=", "len", "(", "set", "(", "structured", ".", "X", ")", ")", "# to catch when there are repeated values", "\n", "chosen_max_K", "=", "min", "(", "max_K_For_Structured", ",", "max_possible_K", ")", "\n", "structured", ".", "runFK", "(", "chosen_max_K", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "'Trying a further k-means on Neuron {}, discarding 75% of data'", ".", "format", "(", "\n", "current_neuron_index", ")", ")", "\n", "try", ":", "\n", "                            ", "structured", "=", "FastDetK", "(", "X", "=", "current_neuron", ",", "discard", "=", "75", ")", "\n", "", "except", "UserWarning", "as", "e", ":", "\n", "                            ", "print", "(", "\n", "'That weird error where it spits on struct region and fails to find any points, sob :('", ")", "\n", "continue", "\n", "", "max_possible_K", "=", "len", "(", "set", "(", "structured", ".", "X", ")", ")", "# to catch when there are repeated values", "\n", "chosen_max_K", "=", "min", "(", "max_K_For_Structured", ",", "max_possible_K", ")", "\n", "structured", ".", "runFK", "(", "chosen_max_K", ")", "\n", "print", "(", "'Updated K of {} for neuron {}'", ".", "format", "(", "structured", ".", "K", ",", "current_neuron_index", ")", ")", "\n", "gap_list", ",", "max_gap", ",", "max_gap_code", ",", "max_2_gap", ",", "max_2_gap_code", "=", "find_gaps_between_clusters", "(", "cluster_list", ",", "dict_keys", "=", "[", "]", ",", "invert", "=", "True", ")", "\n", "", "if", "do_pictures", "or", "current_neuron_index", "in", "range_for_pictures", ":", "\n", "                        ", "fs_plotter", "(", "fs", "=", "structured", ".", "fs", ",", "layer_name", "=", "'prob_struct_'", ",", "\n", "current_neuron_index", "=", "current_neuron_index", ")", "\n", "", "if", "(", "structured", ".", "K", "==", "max_possible_K", ")", "and", "(", "not", "max_possible_K", "==", "1", ")", ":", "\n", "                        ", "if", "(", "structured", ".", "fs", "[", "0", ":", "max_possible_K", "-", "1", "]", "<", "allowed_error", ")", ".", "any", "(", ")", ":", "\n", "# one of the smaller numbers of K gives us clusters to within our accuracy", "\n", "# RE RUN K MEANS!", "\n", "                            ", "print", "(", "'K found that is within error range but not optimal'", ")", "\n", "structured", ".", "runFK", "(", "max_possible_K", "-", "1", ")", "\n", "", "", "updated_cluster_list", "=", "{", "}", "\n", "print", "(", "'K of structured layer is {}'", ".", "format", "(", "structured", ".", "K", ")", ")", "\n", "K_below_struct", "=", "current_best_K", "-", "max_gap_code", "\n", "for", "old_key", "in", "cluster_list", ".", "keys", "(", ")", ":", "\n", "                        ", "if", "old_key", "<", "K_below_struct", ":", "\n", "                            ", "updated_cluster_list", "[", "old_key", "]", "=", "cluster_list", "[", "old_key", "]", "\n", "", "", "for", "new_key", "in", "structured", ".", "clusters", ".", "keys", "(", ")", ":", "\n", "                        ", "updated_cluster_list", "[", "new_key", "+", "K_below_struct", "]", "=", "structured", ".", "clusters", "[", "new_key", "]", "\n", "", "if", "do_pictures", "or", "current_neuron_index", "in", "range_for_pictures", ":", "\n", "                        ", "jitterer", "(", "x_data", "=", "updated_cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "str", "(", "current_neuron_index", ")", "+", "'_heir_kmeans'", "+", "'.png'", ",", "\n", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "False", ",", "\n", "current_neuron_index", "=", "current_neuron_index", ")", "\n", "", "local_list_struct", ",", "selected_activations_struct", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "min", "(", "\n", "structured", ".", "X", ")", ",", "\n", "max_selected_x_data", "=", "max_top_cluster", ",", "\n", "acts", "=", "acts", ",", "\n", "x_data", "=", "x_data", ",", "\n", "verbose", "=", "verbose", ")", "\n", "unique_classes_struct", "=", "set", "(", "[", "x", "[", "0", "]", "for", "x", "in", "local_list_struct", "]", ")", "\n", "No_classes_struct", "=", "len", "(", "unique_classes_struct", ")", "\n", "no_of_top_class_in_struct", "=", "sum", "(", "[", "1", "for", "x", "in", "local_list_struct", "if", "x", "[", "0", "]", "==", "top_class", "]", ")", "\n", "struct_no", "=", "structured", ".", "N", "\n", "struct_K", "=", "structured", ".", "K", "\n", "# TODO these stats should be a function, here you're doing the same thing 3 times", "\n", "# did not have time ot write it properly so please fix", "\n", "# To do!", "\n", "# now we do whole (half!) range", "\n", "", "local_list_half", ",", "selected_activations_half", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "cloud", ".", "midX", ",", "\n", "max_selected_x_data", "=", "max_top_cluster", ",", "\n", "acts", "=", "acts", ",", "\n", "x_data", "=", "x_data", ",", "\n", "verbose", "=", "verbose", ")", "\n", "# c_0_no = len(local_list)", "\n", "# top_class = local_list[0][0]", "\n", "unique_classes_half", "=", "set", "(", "[", "x", "[", "0", "]", "for", "x", "in", "local_list_half", "]", ")", "\n", "No_classes_in", "=", "len", "(", "unique_classes_half", ")", "\n", "no_of_top_class_in_all", "=", "sum", "(", "[", "1", "for", "x", "in", "local_list_half", "if", "x", "[", "0", "]", "==", "top_class", "]", ")", "\n", "extent_of_top_class", "=", "find_extent_of_top_class", "(", "local_list", "=", "local_list_half", ")", "\n", "if", "looking_at_output_layer", ":", "\n", "                    ", "local_list", ",", "selected_activations", "=", "grab_points_for_a_cluster", "(", "current_neuron_index", ",", "\n", "min_selected_x_data", "=", "0", ",", "\n", "max_selected_x_data", "=", "max_top_cluster", ",", "\n", "acts", "=", "acts", ",", "\n", "x_data", "=", "x_data", ",", "\n", "verbose", "=", "verbose", ")", "\n", "extent_of_top_class", "=", "find_extent_of_top_class", "(", "local_list", "=", "local_list", ")", "\n", "", "local_list", "=", "local_list_half", "[", "-", "101", ":", "-", "1", "]", "\n", "selected_activations", "=", "selected_activations_half", "[", "-", "101", ":", "-", "1", "]", "\n", "no_of_top_class_in_top_100", "=", "sum", "(", "[", "1", "for", "x", "in", "local_list", "if", "x", "[", "0", "]", "==", "top_class", "]", ")", "\n", "no_of_top_class", "=", "no_files_in_label", "[", "top_class", "]", "\n", "if", "do_ccma_selectivity", "==", "True", ":", "\n", "# this should be bunged up top as well, but for now...", "\n", "# irritiatingly to compute class conditional selectivity, we need to cluster by classes sigh", "\n", "                    ", "class_cluster_list", ",", "min_list", ",", "max_list", "=", "build_cluster_from_class_label", "(", "acts", "=", "acts", ",", "\n", "current_neuron_index", "=", "current_neuron_index", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "current_neuron", "=", "current_neuron", ",", "\n", "found_labels", "=", "found_labels", ",", "\n", "do_check", "=", "do_check", ")", "\n", "# this computes the CCMAS for the highest mean activating class", "\n", "ccma_selectivity", ",", "mu_max", ",", "mu_not_max", ",", "max_index", "=", "compute_ccma_selectivity_neuron", "(", "class_cluster_list", ",", "found_labels", "=", "''", ",", "class_dict", "=", "class_dict", ",", "\n", "class_labels", "=", "class_labels", ",", "top_class", "=", "''", ",", "verbose", "=", "verbose", ")", "\n", "[", "top_mean_class", ",", "top_mean_code", ",", "top_mean_label", "]", "=", "class_lineno_to_name", "(", "line_no", "=", "max_index", ",", "\n", "class_labels", "=", "class_labels", ")", "\n", "if", "not", "top_mean_code", "==", "top_class", ":", "\n", "                        ", "print", "(", "'Class with top activations is not the class with the highest mean activation'", ")", "\n", "print", "(", "'Top class: {}; top mean class: {}'", ".", "format", "(", "top_class_name", ",", "top_mean_class", ")", ")", "\n", "# the class with the highest activation values is not the same as the class with the highest mean activation value!", "\n", "# so d oteh computation for the top-most class", "\n", "ccma_selectivity_top", ",", "mu_max_top", ",", "mu_not_max_top", ",", "max_index_top", "=", "compute_ccma_selectivity_neuron", "(", "class_cluster_list", ",", "found_labels", "=", "''", ",", "class_dict", "=", "class_dict", ",", "\n", "class_labels", "=", "class_labels", ",", "top_class", "=", "top_class", ",", "\n", "verbose", "=", "verbose", ")", "\n", "if", "do_true_picture", ":", "\n", "# do it anyway", "\n", "                            ", "egg", "=", "class_code_to_name", "(", "class_name", "=", "top_mean_class", ",", "class_dict", "=", "class_dict", ",", "\n", "class_labels", "=", "class_labels", ")", "\n", "# actual_class = found_labels.index(class_labels[current_neuron_index].split(' ')[0])", "\n", "print", "(", "'maximally activated class is {}'", ".", "format", "(", "top_class_name", ")", ")", "\n", "if", "do_pictures", ":", "\n", "                                ", "jitterer", "(", "x_data", "=", "class_cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "'class_'", "+", "str", "(", "current_neuron_index", ")", "+", "'cbycMEAN.png'", ",", "\n", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "True", ",", "\n", "current_neuron_index", "=", "max_index", ")", "\n", "", "", "", "else", ":", "\n", "                        ", "ccma_selectivity_top", ",", "mu_max_top", ",", "mu_not_max_top", ",", "max_index_top", "=", "ccma_selectivity", ",", "mu_max", ",", "mu_not_max", ",", "max_index", "\n", "# sigh, now lets check out the second most mean activating class...", "\n", "", "if", "do_second_Botvinick", ":", "\n", "# compare the selectivity of the second most mean activating class", "\n", "                        ", "not_class_cluster_list", "=", "[", "class_cluster_list", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "class_cluster_list", ")", ")", "if", "\n", "not", "i", "==", "max_index", "]", "\n", "ccma_selectivity_2", ",", "mu_max_2", ",", "mu_not_max_2", ",", "max_index_2", "=", "compute_ccma_selectivity_neuron", "(", "not_class_cluster_list", ",", "found_labels", "=", "''", ",", "\n", "class_dict", "=", "class_dict", ",", "\n", "class_labels", "=", "class_labels", ",", "top_class", "=", "''", ",", "verbose", "=", "verbose", ")", "\n", "[", "top_2_mean_class", ",", "_", ",", "_", "]", "=", "class_lineno_to_name", "(", "line_no", "=", "max_index_2", ",", "class_labels", "=", "class_labels", ")", "\n", "", "else", ":", "\n", "                        ", "ccma_selectivity_2", ",", "mu_max_2", ",", "mu_not_max_2", ",", "max_index_2", "=", "0.0", ",", "0.0", ",", "0.0", ",", "max_index", "\n", "top_2_mean_class", "=", "''", "\n", "# do ranges", "\n", "", "range_top", "=", "max", "(", "class_cluster_list", "[", "max_index_top", "]", ")", "-", "min", "(", "class_cluster_list", "[", "max_index_top", "]", ")", "\n", "range_mean", "=", "max", "(", "class_cluster_list", "[", "max_index", "]", ")", "-", "min", "(", "class_cluster_list", "[", "max_index", "]", ")", "\n", "range_2_mean", "=", "max", "(", "class_cluster_list", "[", "max_index_2", "]", ")", "-", "min", "(", "class_cluster_list", "[", "max_index_2", "]", ")", "\n", "isClassSelective", ",", "selectivity", ",", "found_class", "=", "compute_selectivity_neuron", "(", "max_list", ",", "min_list", ",", "\n", "found_labels", ",", "verbose", "=", "False", ")", "\n", "# if the region above the struct were taken as a code, what would the selectivity be?", "\n", "gap_selectivity", "=", "max_gap", "/", "max_activation", "\n", "if", "isClassSelective", ":", "\n", "# and if it is selective with all points, plot the graph", "\n", "                        ", "foundSelectivityList", ".", "append", "(", "selectivity", ")", "\n", "foundClassList", ".", "append", "(", "found_class", ")", "\n", "foundNeuronList", ".", "append", "(", "current_neuron_index", ")", "\n", "if", "looking_at_output_layer", "==", "True", ":", "\n", "# as cluster_list is build from label_dict, and label_dict is in a shuffled order", "\n", "# we must find out which class we are really on!", "\n", "                            ", "actual_class", "=", "found_labels", ".", "index", "(", "class_labels", "[", "current_neuron_index", "]", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "\n", "print", "(", "'actual class {}'", ".", "format", "(", "actual_class", ")", ")", "\n", "if", "do_pictures", ":", "\n", "                                ", "jitterer", "(", "x_data", "=", "cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "str", "(", "current_neuron_index", ")", "+", "'.png'", ",", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "True", ",", "\n", "current_neuron_index", "=", "actual_class", ")", "\n", "", "", "else", ":", "\n", "                            ", "if", "do_pictures", "or", "current_neuron_index", "in", "range_for_pictures", ":", "\n", "# name_leader = 'fc6_layer_neuron'", "\n", "                                ", "jitterer", "(", "x_data", "=", "cluster_list", ",", "colour_flag", "=", "'cluster'", ",", "title", "=", "'Yo'", ",", "\n", "save_label", "=", "name_leader", "+", "str", "(", "current_neuron_index", ")", "+", "'.png'", ",", "show_plots", "=", "False", ",", "\n", "save_plots", "=", "True", ",", "\n", "do_x_axis", "=", "True", ",", "do_y_axis", "=", "False", ",", "x_range", "=", "None", ",", "y_range", "=", "None", ",", "\n", "label_dict", "=", "label_dict", ",", "\n", "outLayerNeuron", "=", "False", ",", "\n", "current_neuron_index", "=", "0", ")", "\n", "", "", "", "", "row", "=", "{", "'Neuron no.'", ":", "str", "(", "current_neuron_index", ")", ",", "# neuron index", "\n", "'top_class_name'", ":", "str", "(", "top_class_name", ")", ",", "\n", "'all_K'", ":", "str", "(", "cloud", ".", "K", ")", ",", "# no of K for 'All': whole of (midX to maxX) range", "\n", "'all_No_images'", ":", "str", "(", "cloud", ".", "N", ")", ",", "# No of images over All", "\n", "'biggest_gap'", ":", "str", "(", "max_gap", ")", ",", "# Size of biggest gap: this defines the start of 'Struct' range", "\n", "'big_gap_code'", ":", "str", "(", "max_gap_code", ")", ",", "# Coded position of gap: 0 is top cluster, counting down", "\n", "'second_biggest_gap'", ":", "str", "(", "max_2_gap", ")", ",", "\n", "# Second biggest gap size --> could be used as struct start", "\n", "'2_Big_gap_code'", ":", "str", "(", "max_2_gap_code", ")", ",", "# Gap position code", "\n", "'top_class'", ":", "str", "(", "top_class", ")", ",", "# Class with highest activation- could be a list", "\n", "'c_0_no'", ":", "str", "(", "c_0_no", ")", ",", "# No. images in cluster 0 (top cluster)", "\n", "'c_0_no_class'", ":", "str", "(", "c_0_no_classes", ")", ",", "# No. of classes in top cluster", "\n", "'struct_no'", ":", "str", "(", "struct_no", ")", ",", "# No. of images in structured region", "\n", "'struct_K'", ":", "str", "(", "struct_K", ")", ",", "# No. of clusters in struct range --> this may be after a 2nd kmeans", "\n", "'struct_no_class'", ":", "str", "(", "No_classes_struct", ")", ",", "# No of classes in structured region", "\n", "'No_top_in_cluster_0'", ":", "str", "(", "c_0_no_classes", ")", ",", "# No. of top class in top cluster", "\n", "'No_top_class_in_struct'", ":", "str", "(", "no_of_top_class_in_struct", ")", ",", "# No. of top class in structure", "\n", "'No_top_class_in_half_range'", ":", "str", "(", "no_of_top_class_in_all", ")", ",", "# No. of top class in half range", "\n", "'No_top_class'", ":", "str", "(", "no_of_top_class", ")", ",", "# No in the top class overall", "\n", "'pc_top_class_in_top_100'", ":", "str", "(", "no_of_top_class_in_top_100", ")", ",", "# pc of top class in top 100", "\n", "'is_class_selective'", ":", "isClassSelective", ",", "\n", "'ccma_selectivity_top'", ":", "str", "(", "ccma_selectivity_top", ")", ",", "# ccma_selectivity to top activating class", "\n", "'mu_max_top'", ":", "str", "(", "mu_max_top", ")", ",", "# average activation of top activating class", "\n", "'ccma_selectivity'", ":", "str", "(", "ccma_selectivity", ")", ",", "# ccma_selectivity of highest mean activation class", "\n", "'mu_max'", ":", "str", "(", "mu_max", ")", ",", "# mean of highest mean activatinging class", "\n", "'mean_act_class_name'", ":", "str", "(", "top_mean_class", ")", ",", "# name of highest mean class", "\n", "'ccma_selectivity_2'", ":", "str", "(", "ccma_selectivity_2", ")", ",", "\n", "# ccma_selectivity of 2nd highest mean activation class", "\n", "'mu_max_2'", ":", "str", "(", "mu_max_2", ")", ",", "# mean of second highest mean activatinging class", "\n", "'mean_act_class_name_2'", ":", "str", "(", "top_2_mean_class", ")", ",", "# name of highest mean class", "\n", "'range_top'", ":", "str", "(", "range_top", ")", ",", "# range of top activating class", "\n", "'range_mean'", ":", "str", "(", "range_mean", ")", ",", "# range of class with highest mean activation", "\n", "'range_2_mean'", ":", "str", "(", "range_2_mean", ")", ",", "# range of class with second highest mean activation", "\n", "'gap_selectivity'", ":", "str", "(", "gap_selectivity", ")", ",", "\n", "# sub-group selectivity on anything above the largest gap", "\n", "'extent_of_top_class'", ":", "str", "(", "extent_of_top_class", ")", "\n", "# number of top activations before the class changes", "\n", "}", "\n", "sorted_row", "=", "OrderedDict", "(", "sorted", "(", "row", ".", "items", "(", ")", ",", "key", "=", "lambda", "item", ":", "fieldnames", ".", "index", "(", "item", "[", "0", "]", ")", ")", ")", "\n", "writer", ".", "writerow", "(", "sorted_row", ")", "\n", "\n", "", "", "", "print", "(", "'Neuron, Selectivity, Class'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "foundSelectivityList", ")", ")", ":", "\n", "        ", "print", "(", "'{0},{1},{2}'", ".", "format", "(", "foundNeuronList", "[", "i", "]", ",", "foundSelectivityList", "[", "i", "]", ",", "foundClassList", "[", "i", "]", ")", ")", "\n", "\n", "# tiger_shark_or_toilet_roll(label_no=1, label_dict = label_dict, point_no = [1,2,7], acts = acts, found_labels = found_labels,", "\n", "#                             print_value=True, class_labels=class_labels)", "\n", "", "if", "do_check", ":", "\n", "        ", "for", "class_key", "in", "range", "(", "len", "(", "label_dict", ".", "keys", "(", ")", ")", ")", ":", "\n", "# check some stuff", "\n", "# This gives hte classification for the first member of each class", "\n", "            ", "tiger_shark_or_toilet_roll", "(", "label_no", "=", "class_key", ",", "label_dict", "=", "label_dict", ",", "point_no", "=", "0", ",", "acts", "=", "acts", ",", "\n", "found_labels", "=", "found_labels", ",", "\n", "print_value", "=", "True", ",", "class_labels", "=", "class_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.test_zhou_googlenet.make_synset_files": [[48, 77], ["open", "open", "fh.close", "line.strip().split", "print", "line.strip().split", "print", "open", "image_list.append", "labels_list.append", "fh.writelines", "line.strip", "line.strip"], "function", ["None"], ["def", "make_synset_files", "(", "index_into_index_file", ",", "index_file", ",", "category_file", ",", "out_file_name", ")", ":", "\n", "    ", "\"\"\"Function to get Broden into the correct formats\n    index_into_index_file is which column of index file to take\n    index_file is the files with the images and associated categories\n    category file is the file c_oject,txt etc with the human readable labels\"\"\"", "\"\"", "\n", "## Get a list of images which have associated objects and we'll take those as classes", "\n", "image_list", "=", "[", "]", "\n", "correct_class_list", "=", "[", "]", "\n", "file", "=", "open", "(", "index_file", ",", "'r'", ")", "\n", "for", "line", "in", "file", ":", "\n", "        ", "line_list", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "print", "(", "line_list", ")", "\n", "if", "not", "line_list", "[", "index_into_index_file", "]", "==", "''", ":", "\n", "            ", "image_list", ".", "append", "(", "[", "line_list", "[", "0", "]", ",", "line_list", "[", "index_into_index_file", "]", "]", ")", "\n", "# this the original image name and an image which masks the object", "\n", "# gets the human readable lbels from the file", "\n", "", "", "labels_list", "=", "[", "]", "\n", "file2", "=", "open", "(", "category_file", ",", "'r'", ")", "\n", "for", "line", "in", "file2", ":", "\n", "        ", "line_list", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "','", ")", "\n", "print", "(", "line_list", ")", "\n", "if", "not", "line_list", "[", "1", "]", "==", "'number'", ":", "\n", "            ", "labels_list", ".", "append", "(", "[", "line_list", "[", "1", "]", ",", "line_list", "[", "2", "]", "]", ")", "\n", "# write it out in the correct format", "\n", "", "", "with", "open", "(", "out_file_name", ",", "\"w\"", ")", "as", "fh", ":", "\n", "        ", "for", "line", "in", "labels_list", ":", "\n", "            ", "fh", ".", "writelines", "(", "' '", ".", "join", "(", "line", ")", "+", "'\\n'", ")", "\n", "", "", "fh", ".", "close", "(", ")", "\n", "return", "image_list", ",", "labels_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.handle_args": [[15, 49], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "len", "print", "quit", "os.getcwd"], "function", ["None"], ["def", "handle_args", "(", ")", ":", "\n", "    ", "\"\"\" Parse cli arguments\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--image_dir'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "os", ".", "getcwd", "(", ")", ",", "\n", "help", "=", "'where the image directory is'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--image'", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "''", ",", "\n", "help", "=", "'image file name'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--no_of_guesses'", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "5", ",", "\n", "help", "=", "'number of probabilities to return'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'--verbose'", ",", "\n", "default", "=", "True", ",", "\n", "action", "=", "'store_true'", ",", "\n", "help", "=", "'more verbose logging.'", "\n", ")", "\n", "\n", "flags", ",", "unparsed", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "if", "len", "(", "unparsed", ")", ">", "0", ":", "\n", "        ", "print", "(", "'Unrecognised flags: {}'", ".", "format", "(", "unparsed", ")", ")", "\n", "quit", "(", "1", ")", "\n", "", "return", "flags", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.what_am_I_from_image": [[59, 95], ["transformer.preprocess", "net.forward", "range", "print", "print", "out_list.append", "probabilities.argmax", "probabilities.argsort", "print", "true_class.decode", "h5_analysis_jitterer.class_lineno_to_name", "probabilities.argmax"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.class_lineno_to_name"], ["def", "what_am_I_from_image", "(", "image", "=", "image", ",", "net", "=", "net", ",", "transformer", "=", "transformer", ",", "verbose", "=", "True", ",", "true_class", "=", "''", ",", "found_labels", "=", "[", "]", ",", "class_labels", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Function to classify based on 'prob'ability layer inputs\n    probabilities: a vector of input probabilities\n    no_of_guesses: how many of the top probabilities do you want?\n    true_class: the real class name if known\n    outputs are in order: probability, label, human readable name\n    \"\"\"", "\n", "#TODO: This has not yet been properly tested!!!!!!", "\n", "transformed_image", "=", "transformer", ".", "preprocess", "(", "'data'", ",", "image", ")", "\n", "# copy the image data into the memory allocated for the net", "\n", "net", ".", "blobs", "[", "'data'", "]", ".", "data", "[", "...", "]", "=", "transformed_image", "\n", "### perform classification", "\n", "output", "=", "net", ".", "forward", "(", ")", "\n", "probabilities", "=", "output", "[", "'prob'", "]", "[", "0", "]", "# the output probability vector for the first image in the batch", "\n", "is_correct", "=", "2", "# lets use trinary, where 2 means indeterminate! :)", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'predicted class is:'", ",", "probabilities", ".", "argmax", "(", ")", ")", "\n", "print", "(", "'output label:{}'", ".", "format", "(", "found_labels", "[", "probabilities", ".", "argmax", "(", ")", "]", ")", ")", "\n", "", "top_inds", "=", "probabilities", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", ":", "no_of_guesses", "]", "# reverse sort and take five largest items", "\n", "sorted_out_list", "=", "[", "(", "probabilities", "[", "x", "]", ",", "found_labels", "[", "x", "]", ")", "for", "x", "in", "top_inds", "]", "\n", "out_list", "=", "[", "]", "\n", "for", "guess", "in", "range", "(", "no_of_guesses", ")", ":", "\n", "        ", "a_label", "=", "' '", ".", "join", "(", "h", ".", "class_lineno_to_name", "(", "line_no", "=", "top_inds", "[", "guess", "]", ",", "class_labels", "=", "class_labels", ")", "[", "2", "]", ")", "\n", "if", "guess", "==", "0", ":", "\n", "            ", "best_guess", "=", "a_label", "\n", "", "out_list", ".", "append", "(", "(", "sorted_out_list", "[", "guess", "]", "[", "0", "]", "*", "100", ",", "sorted_out_list", "[", "guess", "]", "[", "1", "]", ",", "a_label", ")", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'{:.2f}%: {}: {} '", ".", "format", "(", "sorted_out_list", "[", "guess", "]", "[", "0", "]", "*", "100", ",", "sorted_out_list", "[", "guess", "]", "[", "1", "]", ",", "a_label", ")", ")", "\n", "", "", "if", "not", "true_class", "==", "''", ":", "\n", "# we can test if it is correct", "\n", "        ", "if", "found_labels", "[", "top_inds", "[", "0", "]", "]", "==", "true_class", ".", "decode", "(", ")", ":", "\n", "# is correct", "\n", "            ", "is_correct", "=", "True", "\n", "", "else", ":", "\n", "            ", "is_correct", "=", "False", "\n", "", "", "return", "out_list", ",", "is_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.main": [[100, 131], ["Caffe_AlexNet.caffe.io.load_image", "Test_AlexNet_on_anything.what_am_I_from_image", "set_up_caffe", "set_up_caffe_net.Caffe_NN_setup", "Caffe_AlexNet.set_up_caffe", "Caffe_AlexNet.Caffe_NN_setup", "label.split"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.what_am_I_from_image", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.set_up_caffe", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.Caffe_NN_setup", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.set_up_caffe", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.set_up_caffe_net.Caffe_NN_setup"], ["", "def", "main", "(", ")", ":", "\n", "    ", "image_directory", "=", "FLAGS", ".", "image_dir", "\n", "image_filename", "=", "FLAGS", ".", "image", "\n", "verbose", "=", "FLAGS", ".", "verbose", "\n", "if", "usingDocker", ":", "\n", "# new set-up with safer deployment for use on all machines", "\n", "        ", "caffe_root", ",", "image_directory", ",", "labels_file", ",", "model_def", ",", "model_weights", ",", "dir_list", ",", "labels", "=", "set_up_caffe", "(", ")", "\n", "net", ",", "transformer", "=", "Caffe_NN_setup", "(", "imangenet_mean_image", "=", "'python/caffe/imagenet/ilsvrc_2012_mean.npy'", ",", "\n", "batch_size", "=", "50", ",", "model_def", "=", "model_def", ",", "model_weights", "=", "model_weights", ",", "\n", "verbose", "=", "True", ",", "root_dir", "=", "caffe_root", ")", "\n", "", "else", ":", "\n", "# old set-up with hardcoded links and old-style unsafe deployment", "\n", "        ", "caffe_root", ",", "image_directory", ",", "labels_file", ",", "model_def", ",", "model_weights", ",", "dir_list", ",", "labels", "=", "C", ".", "set_up_caffe", "(", "image_directory", "=", "image_directory", ",", "\n", "model_file", "=", "'models/bvlc_reference_caffenet/bvlc_reference_caffenet.caffemodel'", ",", "\n", "label_file_address", "=", "'data/ilsvrc12/synset_words.txt'", ",", "\n", "dir_file", "=", "'/storage/data/imagenet_2012_class_list.txt'", ",", "\n", "root_dir", "=", "'/home/eg16993/src/caffe'", ",", "verbose", "=", "True", ")", "\n", "net", ",", "transformer", "=", "C", ".", "Caffe_NN_setup", "(", "imangenet_mean_image", "=", "'/home/eg16993/src/caffe/python/caffe/imagenet/ilsvrc_2012_mean.npy'", ",", "\n", "batch_size", "=", "50", ",", "model_def", "=", "model_def", ",", "model_weights", "=", "model_weights", ",", "\n", "verbose", "=", "True", ",", "root_dir", "=", "caffe_root", ")", "\n", "\n", "", "class_labels", "=", "labels", "\n", "found_labels", "=", "[", "label", ".", "split", "(", "' '", ")", "[", "0", "]", "for", "label", "in", "labels", "]", "\n", "\n", "image", "=", "C", ".", "caffe", ".", "io", ".", "load_image", "(", "image_directory", "+", "'/'", "+", "image_filename", ")", "\n", "#image = C.caffe.io.load_image(image_directory + '/shark2.png')", "\n", "#image = C.caffe.io.load_image(image_directory + '/n01484850_76.JPEG')", "\n", "#image = C.caffe.io.load_image(image_directory + '/205.jpg')", "\n", "\n", "what_am_I_from_image", "(", "image", "=", "image", ",", "net", "=", "net", ",", "transformer", "=", "transformer", ",", "verbose", "=", "verbose", ",", "found_labels", "=", "found_labels", ",", "class_labels", "=", "class_labels", ")", "\n", "### perform classification", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Grab_top_most_images.what_am_I_from_prob": [[26, 62], ["range", "print", "print", "out_list.append", "probabilities.argmax", "probabilities.argsort", "print", "type", "type", "true_class.decode", "h5_analysis_jitterer.class_lineno_to_name", "print", "print", "probabilities.argmax"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.class_lineno_to_name"], ["def", "what_am_I_from_prob", "(", "probabilities", ",", "no_of_guesses", "=", "5", ",", "true_class", "=", "''", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\"Function to classify based on 'prob'ability layer inputs\n    probabilities: a vector of input probabilities\n    no_of_guesses: how many of the top probabilities do you want?\n    true_class: the real class name if known\n    outputs are in order: probability, label, human readable name\n    \"\"\"", "\n", "is_correct", "=", "2", "# lets use trinary, where 2 means indeterminate! :)", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'predicted class is:'", ",", "probabilities", ".", "argmax", "(", ")", ")", "\n", "print", "(", "'output label:{}'", ".", "format", "(", "found_labels", "[", "probabilities", ".", "argmax", "(", ")", "]", ")", ")", "\n", "", "top_inds", "=", "probabilities", ".", "argsort", "(", ")", "[", ":", ":", "-", "1", "]", "[", ":", "no_of_guesses", "]", "# reverse sort and take five largest items", "\n", "sorted_out_list", "=", "[", "(", "probabilities", "[", "x", "]", ",", "found_labels", "[", "x", "]", ")", "for", "x", "in", "top_inds", "]", "\n", "out_list", "=", "[", "]", "\n", "for", "guess", "in", "range", "(", "no_of_guesses", ")", ":", "\n", "        ", "a_label", "=", "' '", ".", "join", "(", "h", ".", "class_lineno_to_name", "(", "line_no", "=", "top_inds", "[", "guess", "]", ",", "class_labels", "=", "class_labels", ")", "[", "2", "]", ")", "\n", "out_list", ".", "append", "(", "(", "sorted_out_list", "[", "guess", "]", "[", "0", "]", "*", "100", ",", "sorted_out_list", "[", "guess", "]", "[", "1", "]", ",", "a_label", ")", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'{:.2f}%: {}: {} '", ".", "format", "(", "sorted_out_list", "[", "guess", "]", "[", "0", "]", "*", "100", ",", "sorted_out_list", "[", "guess", "]", "[", "1", "]", ",", "a_label", ")", ")", "\n", "", "", "if", "not", "true_class", "==", "''", ":", "\n", "# we can test if it is correct", "\n", "        ", "if", "type", "(", "true_class", ")", "==", "type", "(", "''", ")", ":", "\n", "            ", "ground_truth", "=", "true_class", "\n", "", "else", ":", "\n", "# assume byte array", "\n", "            ", "ground_truth", "=", "true_class", ".", "decode", "(", ")", "\n", "", "if", "found_labels", "[", "top_inds", "[", "0", "]", "]", "==", "ground_truth", ":", "\n", "# is correct", "\n", "            ", "is_correct", "=", "True", "\n", "if", "verbose", ":", "\n", "                ", "print", "(", "'Image is correctly classified'", ")", "\n", "", "", "else", ":", "\n", "            ", "is_correct", "=", "False", "\n", "if", "verbose", ":", "\n", "                ", "print", "(", "'Image is incorrectly classified'", ")", "\n", "", "", "", "return", "out_list", ",", "is_correct", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Grab_top_most_images.grab_files": [[64, 90], ["acts.get_file_name().decode", "acts.get_file_name().decode.split", "selected_image_list.append", "selected_image_list.append", "found_classes.append", "acts.get_file_name", "acts.get_file_name().decode.split"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_file_name"], ["", "def", "grab_files", "(", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "\n", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "\n", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "in_class_sub_dirs", "=", "True", ")", ":", "\n", "    ", "\"\"\"Function to get the selected images and return their addresses\n    in_class_sub_dirs: True if like imagenet, false if like imagenet test set\"\"\"", "\n", "selected_image_list", "=", "[", "]", "\n", "found_classes", "=", "[", "]", "\n", "for", "selected_point", "in", "local_list", ":", "\n", "# grab filename", "\n", "        ", "selected_file", "=", "acts", ".", "get_file_name", "(", "selected_point", ")", ".", "decode", "(", "'UTF-8'", ")", "\n", "if", "verbose", ":", "\n", "            ", "pass", "\n", "# print(selected_file)", "\n", "", "class_dir_label", "=", "selected_file", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "in_class_sub_dirs", ":", "\n", "# we've assumed files are in folders labelled by class!", "\n", "            ", "selected_image_list", ".", "append", "(", "imagenet_root", "+", "class_dir_label", "+", "'/'", "+", "selected_file", ")", "\n", "", "else", ":", "\n", "            ", "selected_image_list", ".", "append", "(", "imagenet_root", "+", "selected_file", ")", "\n", "", "class_no", "=", "class_dict", "[", "selected_file", ".", "split", "(", "'_'", ")", "[", "0", "]", "]", "\n", "if", "not", "class_no", "in", "found_classes", ":", "\n", "            ", "found_classes", ".", "append", "(", "class_no", ")", "\n", "", "", "return", "selected_image_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Grab_top_most_images.move_files": [[92, 104], ["Grab_top_most_images.grab_files", "range", "len", "shutil.copyfile", "selected_image_list[].split"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_squarified_test_set.grab_files"], ["", "def", "move_files", "(", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "out_dir", "=", "'/storage/data/top_images_test_set/'", ")", ":", "\n", "    ", "\"\"\"Function to grab imagenet files and move them\"\"\"", "\n", "selected_image_list", "=", "grab_files", "(", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "in_class_sub_dirs", "=", "True", ")", "\n", "for", "file_no", "in", "range", "(", "len", "(", "selected_image_list", ")", ")", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "selected_image_list", "[", "file_no", "]", ",", "out_dir", "+", "selected_image_list", "[", "file_no", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Grab_top_most_images.move_and_squarify_files": [[106, 118], ["Grab_top_most_images.grab_files", "range", "len", "shutil.copyfile", "selected_image_list[].split"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_squarified_test_set.grab_files"], ["", "def", "move_and_squarify_files", "(", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "out_dir", "=", "'/storage/data/top_images_test_set/'", ")", ":", "\n", "    ", "\"\"\"Function to grab imagenet files and move them\"\"\"", "\n", "selected_image_list", "=", "grab_files", "(", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "in_class_sub_dirs", "=", "True", ")", "\n", "for", "file_no", "in", "range", "(", "len", "(", "selected_image_list", ")", ")", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "selected_image_list", "[", "file_no", "]", ",", "out_dir", "+", "selected_image_list", "[", "file_no", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Grab_top_most_images.find_most_active_in_prob": [[165, 184], ["h5_analysis_jitterer.find_position_of_max_act_in_vector", "certainty_list.append", "acts.get_activation", "Grab_top_most_images.what_am_I_from_prob", "numpy.array", "certainty_list.append", "correct_list.append", "correct_point_list.append", "list"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.h5_analysis_jitterer.find_position_of_max_act_in_vector", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Grab_top_most_images.what_am_I_from_prob"], ["", "def", "find_most_active_in_prob", "(", "class_label", "=", "''", ",", "no_of_guesses", "=", "1", ",", "acts", "=", "acts", ",", "label_dict", "=", "label_dict", ")", ":", "\n", "    ", "\"\"\"wrpper function to grab most certain images in prob layer\n    class_label is the label of the class you are doing at thsi point\n    no_of_guesses: whether to accept top 1 or top 5 acc (top 1 chosen)\"\"\"", "\n", "point_indices", "=", "label_dict", "[", "class_label", "]", "\n", "for", "point", "in", "point_indices", ":", "\n", "        ", "current_activation", "=", "acts", ".", "get_activation", "(", "point", ")", "\n", "probabilities", "=", "current_activation", ".", "vector", "\n", "true_class", "=", "current_activation", ".", "label", "\n", "out_list", ",", "is_correct", "=", "what_am_I_from_prob", "(", "probabilities", ",", "no_of_guesses", "=", "no_of_guesses", ",", "true_class", "=", "true_class", ",", "\n", "verbose", "=", "True", ")", "\n", "if", "is_correct", ":", "\n", "            ", "certainty_list", ".", "append", "(", "out_list", "[", "0", "]", "[", "0", "]", ")", "\n", "correct_list", ".", "append", "(", "is_correct", ")", "\n", "correct_point_list", ".", "append", "(", "point", ")", "\n", "", "", "indices", ",", "certainty", "=", "h", ".", "find_position_of_max_act_in_vector", "(", "np", ".", "array", "(", "certainty_list", ")", ")", "\n", "certainty_list", ".", "append", "(", "certainty", ")", "\n", "local_list", "=", "[", "correct_point_list", "[", "x", "]", "for", "x", "in", "list", "(", "indices", "[", "0", "]", ")", "]", "\n", "return", "local_list", ",", "true_class", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Grab_top_most_images.check_image_correct": [[186, 238], ["Grab_top_most_images.grab_files", "range", "len", "Caffe_AlexNet2.caffe.io.load_image", "Test_AlexNet_on_directory.what_am_I_from_image", "mistake_list_name.append", "mistake_list_no.append", "correct_list_name.append", "correct_list_no.append", "corrected_local_list.append", "print"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_squarified_test_set.grab_files", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.what_am_I_from_image"], ["", "def", "check_image_correct", "(", "true_class", "=", "''", ",", "\n", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "\n", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "\n", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "net", "=", "net", ",", "\n", "transformer", "=", "transformer", ",", "\n", "in_class_sub_dirs", "=", "True", ")", ":", "\n", "    ", "\"\"\"wrapper function to check that a given image is correct in a fresh instantiation of ALexNet\n    ture_class needs to be input\"\"\"", "\n", "selected_image_list", "=", "grab_files", "(", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "imagenet_root", "=", "imagenet_root", ",", "in_class_sub_dirs", "=", "in_class_sub_dirs", ")", "\n", "image_list", "=", "selected_image_list", "\n", "image_directory", "=", "''", "\n", "mistake_list_name", "=", "[", "]", "\n", "mistake_list_no", "=", "[", "]", "\n", "correct_list_name", "=", "[", "]", "\n", "correct_list_no", "=", "[", "]", "\n", "corrected_local_list", "=", "[", "]", "\n", "for", "image_no", "in", "range", "(", "len", "(", "image_list", ")", ")", ":", "\n", "        ", "image_name", "=", "image_list", "[", "image_no", "]", "\n", "try", ":", "\n", "            ", "image", "=", "C", ".", "caffe", ".", "io", ".", "load_image", "(", "image_directory", "+", "image_name", ")", "\n", "good_to_go", "=", "True", "\n", "", "except", ":", "\n", "            ", "good_to_go", "=", "False", "\n", "", "if", "good_to_go", ":", "\n", "            ", "out_list", ",", "is_correct", "=", "what_am_I_from_image", "(", "\n", "image", "=", "image", ",", "\n", "net", "=", "net", ",", "\n", "transformer", "=", "transformer", ",", "\n", "verbose", "=", "verbose", ",", "\n", "found_labels", "=", "found_labels", ",", "\n", "class_labels", "=", "class_labels", ",", "\n", "true_class", "=", "true_class", "\n", ")", "\n", "if", "is_correct", "==", "False", ":", "\n", "                ", "if", "verbose", ":", "\n", "                    ", "print", "(", "'Error: {} is incorrect'", ".", "format", "(", "image_name", ")", ")", "\n", "", "mistake_list_name", ".", "append", "(", "image_name", ")", "\n", "mistake_list_no", ".", "append", "(", "image_no", ")", "\n", "", "else", ":", "\n", "# if its true or the functions doesnot know", "\n", "                ", "correct_list_name", ".", "append", "(", "image_name", ")", "\n", "correct_list_no", ".", "append", "(", "image_no", ")", "\n", "corrected_local_list", ".", "append", "(", "local_list", "[", "image_no", "]", ")", "\n", "# else:", "\n", "# mistake_list_name.append(image_name)", "\n", "# mistake_list_no.append(image_no)", "\n", "", "", "", "return", "corrected_local_list", ",", "correct_list_name", ",", "correct_list_no", ",", "mistake_list_name", ",", "mistake_list_no", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_squarified_test_set.grab_files": [[29, 55], ["acts.get_file_name().decode", "acts.get_file_name().decode.split", "selected_image_list.append", "selected_image_list.append", "found_classes.append", "acts.get_file_name", "acts.get_file_name().decode.split"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_file_name"], ["def", "grab_files", "(", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "\n", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "\n", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "in_class_sub_dirs", "=", "True", ")", ":", "\n", "    ", "\"\"\"Function to get the selected images and return their addresses\n    in_class_sub_dirs: True if like imagenet, false if like imagenet test set\"\"\"", "\n", "selected_image_list", "=", "[", "]", "\n", "found_classes", "=", "[", "]", "\n", "for", "selected_point", "in", "local_list", ":", "\n", "# grab filename", "\n", "        ", "selected_file", "=", "acts", ".", "get_file_name", "(", "selected_point", ")", ".", "decode", "(", "'UTF-8'", ")", "\n", "if", "verbose", ":", "\n", "            ", "pass", "\n", "#print(selected_file)", "\n", "", "class_dir_label", "=", "selected_file", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "if", "in_class_sub_dirs", ":", "\n", "# we've assumed files are in folders labelled by class!", "\n", "            ", "selected_image_list", ".", "append", "(", "imagenet_root", "+", "class_dir_label", "+", "'/'", "+", "selected_file", ")", "\n", "", "else", ":", "\n", "            ", "selected_image_list", ".", "append", "(", "imagenet_root", "+", "selected_file", ")", "\n", "", "class_no", "=", "class_dict", "[", "selected_file", ".", "split", "(", "'_'", ")", "[", "0", "]", "]", "\n", "if", "not", "class_no", "in", "found_classes", ":", "\n", "            ", "found_classes", ".", "append", "(", "class_no", ")", "\n", "", "", "return", "selected_image_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_squarified_test_set.check_image_correct": [[56, 108], ["Make_squarified_test_set.grab_files", "range", "len", "Caffe_AlexNet.caffe.io.load_image", "Test_AlexNet_on_directory.what_am_I_from_image", "mistake_list_name.append", "mistake_list_no.append", "correct_list_name.append", "correct_list_no.append", "corrected_local_list.append", "print"], "function", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_squarified_test_set.grab_files", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Test_AlexNet_on_anything.what_am_I_from_image"], ["", "def", "check_image_correct", "(", "true_class", "=", "''", ",", "\n", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "\n", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "\n", "imagenet_root", "=", "'/storage/data/imagenet_2012/'", ",", "\n", "net", "=", "net", ",", "\n", "transformer", "=", "transformer", ",", "\n", "in_class_sub_dirs", "=", "True", ")", ":", "\n", "    ", "\"\"\"wrapper function to check that a given image is correct in a fresh instantiation of ALexNet\n    ture_class needs to be input\"\"\"", "\n", "selected_image_list", "=", "grab_files", "(", "local_list", "=", "local_list", ",", "\n", "acts", "=", "acts", ",", "class_dict", "=", "class_dict", ",", "\n", "verbose", "=", "verbose", ",", "imagenet_root", "=", "imagenet_root", ",", "in_class_sub_dirs", "=", "in_class_sub_dirs", ")", "\n", "image_list", "=", "selected_image_list", "\n", "image_directory", "=", "''", "\n", "mistake_list_name", "=", "[", "]", "\n", "mistake_list_no", "=", "[", "]", "\n", "correct_list_name", "=", "[", "]", "\n", "correct_list_no", "=", "[", "]", "\n", "corrected_local_list", "=", "[", "]", "\n", "for", "image_no", "in", "range", "(", "len", "(", "image_list", ")", ")", ":", "\n", "        ", "image_name", "=", "image_list", "[", "image_no", "]", "\n", "try", ":", "\n", "            ", "image", "=", "C", ".", "caffe", ".", "io", ".", "load_image", "(", "image_directory", "+", "image_name", ")", "\n", "good_to_go", "=", "True", "\n", "", "except", ":", "\n", "            ", "good_to_go", "=", "False", "\n", "", "if", "good_to_go", ":", "\n", "            ", "out_list", ",", "is_correct", "=", "what_am_I_from_image", "(", "\n", "image", "=", "image", ",", "\n", "net", "=", "net", ",", "\n", "transformer", "=", "transformer", ",", "\n", "verbose", "=", "verbose", ",", "\n", "found_labels", "=", "found_labels", ",", "\n", "class_labels", "=", "class_labels", ",", "\n", "true_class", "=", "true_class", "\n", ")", "\n", "if", "is_correct", "==", "False", ":", "\n", "                ", "if", "verbose", ":", "\n", "                    ", "print", "(", "'Error: {} is incorrect'", ".", "format", "(", "image_name", ")", ")", "\n", "", "mistake_list_name", ".", "append", "(", "image_name", ")", "\n", "mistake_list_no", ".", "append", "(", "image_no", ")", "\n", "", "else", ":", "\n", "# if its true or the functions doesnot know", "\n", "                ", "correct_list_name", ".", "append", "(", "image_name", ")", "\n", "correct_list_no", ".", "append", "(", "image_no", ")", "\n", "corrected_local_list", ".", "append", "(", "local_list", "[", "image_no", "]", ")", "\n", "#else:", "\n", "#mistake_list_name.append(image_name)", "\n", "#mistake_list_no.append(image_no)", "\n", "", "", "", "return", "corrected_local_list", ",", "correct_list_name", ",", "correct_list_no", ",", "mistake_list_name", ",", "mistake_list_no", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.None.Make_squarified_test_set.simple_move_files": [[152, 157], ["range", "len", "shutil.move", "selected_image_list[].split"], "function", ["None"], ["def", "simple_move_files", "(", "selected_image_list", ",", "out_dir", "=", "'/command/results/top_images_test_set/'", ")", ":", "\n", "    ", "\"\"\"Function to grab files and move them\"\"\"", "\n", "for", "file_no", "in", "range", "(", "len", "(", "selected_image_list", ")", ")", ":", "\n", "        ", "shutil", ".", "move", "(", "selected_image_list", "[", "file_no", "]", ",", "out_dir", "+", "selected_image_list", "[", "file_no", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeansplusplus.KMeansPlusPlus.dist_from_centers": [[16, 22], ["numpy.array", "min", "numpy.linalg.norm"], "methods", ["None"], ["def", "dist_from_centers", "(", "self", ",", "mu_count", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Calculates the shortest distance squared between all points and all centroids\n        \"\"\"", "\n", "self", ".", "D2", "=", "np", ".", "array", "(", "\n", "[", "min", "(", "[", "np", ".", "linalg", ".", "norm", "(", "x", "-", "mu", ")", "**", "2", "for", "mu", "in", "self", ".", "mu", "[", "0", ":", "mu_count", "]", "]", ")", "for", "x", "in", "self", ".", "X", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeansplusplus.KMeansPlusPlus._radius": [[23, 26], ["kmeansplusplus.KMeansPlusPlus.dist_from_centers", "max"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeansplusplus.KMeansPlusPlus.dist_from_centers"], ["", "def", "_radius", "(", "self", ")", ":", "\n", "        ", "self", ".", "dist_from_centers", "(", "self", ".", "K", ")", "\n", "self", ".", "r", "=", "max", "(", "self", ".", "D2", ")", "**", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeansplusplus.KMeansPlusPlus._choose_next_center": [[27, 43], ["kmeansplusplus.KMeansPlusPlus.probs.cumsum", "kmeansplusplus.KMeansPlusPlus.D2.sum", "random.random", "print", "print", "print", "print", "print", "print", "numpy.where", "numpy.where"], "methods", ["None"], ["", "def", "_choose_next_center", "(", "self", ")", ":", "\n", "        ", "self", ".", "probs", "=", "self", ".", "D2", "/", "self", ".", "D2", ".", "sum", "(", ")", "\n", "self", ".", "cumprobs", "=", "self", ".", "probs", ".", "cumsum", "(", ")", "\n", "# random.random returns [0-1), we want (0-1]", "\n", "r", "=", "1.0", "-", "random", ".", "random", "(", ")", "\n", "try", ":", "\n", "            ", "idx", "=", "np", ".", "where", "(", "self", ".", "cumprobs", ">=", "r", ")", "[", "0", "]", "[", "0", "]", "\n", "", "except", "IndexError", ":", "\n", "            ", "print", "(", "self", ".", "X", ")", "\n", "print", "(", "self", ".", "mu", ")", "\n", "print", "(", "self", ".", "probs", ")", "\n", "print", "(", "self", ".", "cumprobs", ")", "\n", "print", "(", "r", ")", "\n", "print", "(", "np", ".", "where", "(", "self", ".", "cumprobs", ">=", "r", ")", ")", "\n", "raise", "\n", "", "return", "self", ".", "X", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeansplusplus.KMeansPlusPlus.init_centers": [[44, 53], ["numpy.zeros", "kmeansplusplus.KMeansPlusPlus.dist_from_centers", "kmeansplusplus.KMeansPlusPlus._choose_next_center", "numpy.random.choice"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeansplusplus.KMeansPlusPlus.dist_from_centers", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeansplusplus.KMeansPlusPlus._choose_next_center"], ["", "def", "init_centers", "(", "self", ")", ":", "\n", "        ", "self", ".", "mu", "=", "np", ".", "zeros", "(", "[", "self", ".", "K", ",", "self", ".", "dimensions", "]", ")", "\n", "mu_count", "=", "1", "\n", "self", ".", "mu", "[", "0", ",", "]", "=", "self", ".", "X", "[", "np", ".", "random", ".", "choice", "(", "self", ".", "N", ",", "1", ",", "replace", "=", "False", ")", "]", "\n", "# pick a point, any point", "\n", "while", "mu_count", "<", "self", ".", "K", ":", "\n", "            ", "self", ".", "dist_from_centers", "(", "mu_count", ")", "\n", "self", ".", "mu", "[", "mu_count", ",", "]", "=", "self", ".", "_choose_next_center", "(", ")", "\n", "mu_count", "+=", "1", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.ActivationEncoder.default": [[17, 23], ["isinstance", "json.JSONEncoder.default"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.ActivationEncoder.default"], ["def", "default", "(", "self", ",", "obj", ")", ":", "# pylint: disable=method-hidden", "\n", "        ", "\"\"\" encode \"\"\"", "\n", "if", "not", "isinstance", "(", "obj", ",", "Activation", ")", ":", "\n", "            ", "return", "json", ".", "JSONEncoder", ".", "default", "(", "self", ",", "obj", ")", "\n", "# Don't actually save the values", "\n", "", "return", "{", "'index'", ":", "obj", ".", "index", ",", "'label'", ":", "obj", ".", "label", ",", "'labels'", ":", "obj", ".", "labels", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.from_json": [[37, 45], ["json.loads", "point_source.getPoint"], "methods", ["None"], ["@", "classmethod", "\n", "def", "from_json", "(", "cls", ",", "point_source", ",", "json_text", ")", ":", "\n", "        ", "\"\"\"Given a point source and a json file, recreate the Activation object\"\"\"", "\n", "data", "=", "json", ".", "loads", "(", "json_text", ")", "\n", "point", "=", "point_source", ".", "getPoint", "(", "data", "[", "'index'", "]", ")", "\n", "# Fairly limited amount of verification we can do", "\n", "assert", "point", ".", "label", "==", "data", "[", "'label'", "]", "\n", "return", "point", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.__init__": [[46, 63], ["numpy.array", "isinstance", "len"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "labels", ":", "LabelType", ",", "vector", ":", "np", ".", "array", ",", "\n", "index", ":", "ActivationIndexType", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\" Create a point with vector v and a classification label\n\n        \"\"\"", "\n", "self", ".", "vector", "=", "np", ".", "array", "(", "vector", ")", "\n", "if", "isinstance", "(", "labels", ",", "str", ")", ":", "\n", "            ", "self", ".", "label", "=", "labels", "\n", "self", ".", "labels", "=", "[", "labels", "]", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "labels", ")", ">", "0", ":", "\n", "                ", "self", ".", "label", "=", "labels", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "label", "=", "None", "\n", "", "self", ".", "labels", "=", "labels", "\n", "", "self", ".", "index", "=", "index", "\n", "self", ".", "__array_interface__", "=", "self", ".", "vector", ".", "__array_interface__", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.hydrate": [[64, 70], ["activation_table.get_activation"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation"], ["", "def", "hydrate", "(", "self", ",", "activation_table", ":", "'ActivationTable'", ")", "->", "None", ":", "\n", "        ", "\"\"\" Given a point source, get the vector values.\n        \"\"\"", "\n", "point", "=", "activation_table", ".", "get_activation", "(", "self", ".", "index", ")", "\n", "self", ".", "vector", "=", "point", ".", "vector", "\n", "self", ".", "__array_interface__", "=", "self", ".", "vector", ".", "__array_interface__", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.dessicate": [[71, 75], ["None"], "methods", ["None"], ["", "def", "dessicate", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\" Reduce memory usage by dumping the vector values.\n        \"\"\"", "\n", "self", ".", "vector", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.encode": [[76, 79], ["Activation._encoder.encode"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.encode"], ["", "def", "encode", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\" Get the json encoded form of this point. \"\"\"", "\n", "return", "Activation", ".", "_encoder", ".", "encode", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.dimensionality": [[80, 88], ["len"], "methods", ["None"], ["", "def", "dimensionality", "(", "self", ")", ":", "\n", "        ", "\"\"\" get the number of dimensions to this point. \"\"\"", "\n", "if", "self", ".", "vector", ".", "shape", "is", "(", ")", ":", "\n", "            ", "return", "0", "\n", "", "if", "len", "(", "self", ".", "vector", ".", "shape", ")", "is", "1", ":", "\n", "            ", "return", "1", "\n", "", "_", ",", "dim", "=", "self", ".", "vector", ".", "shape", "\n", "return", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.standardise": [[89, 102], ["activation.Activation.dimensionality", "max", "activation.Activation.vector.astype"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.dimensionality"], ["", "def", "standardise", "(", "self", ")", ":", "\n", "        ", "\"\"\" Scale the space in which the point exists such that the largest value is 1.0.\n        \"\"\"", "\n", "if", "self", ".", "vector", ".", "shape", "is", "(", ")", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "dimensionality", "(", ")", "!=", "1", ":", "\n", "# TODO: implement", "\n", "            ", "raise", "NotImplementedError", "\n", "", "max_value", "=", "1.0", "*", "max", "(", "self", ".", "vector", ")", "\n", "if", "max_value", "==", "0.0", ":", "\n", "# Nothing to do", "\n", "            ", "return", "\n", "", "self", ".", "vector", "=", "self", ".", "vector", ".", "astype", "(", "'float64'", ")", "/", "max_value", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.__repr__": [[103, 106], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\" point representation string. \"\"\"", "\n", "return", "'Activation: {} (idx{})'", ".", "format", "(", "self", ".", "labels", ",", "self", ".", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.__eq__": [[107, 115], ["isinstance", "numpy.all"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\"Override the default Equals behavior\"\"\"", "\n", "if", "isinstance", "(", "other", ",", "self", ".", "__class__", ")", ":", "\n", "            ", "return", "self", ".", "index", "==", "other", ".", "index", "and", "self", ".", "label", "==", "other", ".", "label", "and", "self", ".", "labels", "==", "other", ".", "labels", "and", "np", ".", "all", "(", "self", ".", "vector", "==", "other", ".", "vector", ")", "\n", "", "return", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.__ne__": [[116, 121], ["isinstance", "activation.Activation.__eq__"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.__eq__"], ["", "def", "__ne__", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\"Define a non-equality test\"\"\"", "\n", "if", "isinstance", "(", "other", ",", "self", ".", "__class__", ")", ":", "\n", "            ", "return", "not", "self", ".", "__eq__", "(", "other", ")", "\n", "", "return", "NotImplemented", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.__hash__": [[122, 128], ["hash", "tuple", "tuple"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Override the default hash behavior (that returns the id or the object)\"\"\"", "\n", "return", "hash", "(", "\n", "(", "tuple", "(", "\n", "self", ".", "vector", ")", ",", "self", ".", "index", ",", "tuple", "(", "\n", "self", ".", "labels", ")", ",", "self", ".", "label", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.neuron.Neuron.__init__": [[19, 23], ["kmeans.activation.Activation.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.fast_detk.FastDetK.__init__"], ["def", "__init__", "(", "self", ",", "labels", ":", "LabelType", ",", "vector", ":", "np", ".", "array", ")", "->", "None", ":", "\n", "        ", "if", "vector", "is", "not", "None", "and", "vector", ".", "shape", "is", "not", "(", ")", "and", "vector", ".", "ndim", "is", "not", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Neurons must have 1D vectors\"", ")", "\n", "", "super", "(", "Neuron", ",", "self", ")", ".", "__init__", "(", "labels", ",", "vector", ",", "None", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox.__init__": [[23, 29], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "ll", ":", "np", ".", "array", "=", "None", ",", "ur", ":", "np", ".", "array", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Base constructor. Not that we can't do much until we have a point added.\n        \"\"\"", "\n", "self", ".", "lower_left", "=", "ll", "\n", "self", ".", "upper_right", "=", "ur", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox.expand": [[30, 37], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "expand", "(", "self", ",", "point", ":", "Activation", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Expand the bounding box so that it includes the supplied point\n        :param point: to add\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", "\"Use a subtype\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox.get_centre": [[38, 48], ["numpy.mean"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "get_centre", "(", "self", ")", "->", "np", ".", "array", ":", "\n", "        ", "\"\"\"\n        calculate the centre point of the bounding box\n        :return: a numpy array\n        \"\"\"", "\n", "if", "self", ".", "lower_left", "is", "None", ":", "\n", "# Not yet initialised", "\n", "            ", "return", "None", "\n", "", "return", "np", ".", "mean", "(", "(", "self", ".", "lower_left", ",", "self", ".", "upper_right", ")", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox.contains": [[49, 57], ["NotImplementedError"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "contains", "(", "self", ",", "point", ":", "Activation", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        test whether the given box contains a specific point\n        :param point: the point to add\n        :return: true iff the point is contained within the bounding box\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", "\"Use a subtype\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox.escape_distance_L1": [[58, 77], ["numpy.sum", "numpy.sum", "numpy.where", "numpy.where"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "escape_distance_L1", "(", "self", ",", "point", ":", "Activation", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        calculate an approximation of how far outside the cluster a given point falls.\n        this is defined as the sum of the distance from the closest limit to the point on each axis\n        for all axes where the point falls outside the cluster.\n        L1 distance or block distance (sum of errors)\n        :param point: a point to test\n        :return: the escape distance for the point\n        \"\"\"", "\n", "under", "=", "self", ".", "lower_left", "-", "point", ".", "vector", "\n", "\n", "under_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "under", ">", "0", ",", "under", ",", "0.0", ")", ")", "\n", "\n", "over", "=", "point", ".", "vector", "-", "self", ".", "upper_right", "\n", "\n", "over_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "over", ">", "0", ",", "over", ",", "0.0", ")", ")", "\n", "\n", "return", "under_distance", "+", "over_distance", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox._get_shortest_edge_vector": [[78, 92], ["numpy.minimum", "bounding_box.BoundingBox.contains"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.PartialDataBoundingBox.contains"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "_get_shortest_edge_vector", "(", "self", ",", "point", ":", "Activation", ")", ":", "\n", "        ", "\"\"\"\n        Calculate the shortest vector to the edge of the bounding box from a _contained_ point.\n        :param point:\n        :return: a vector representing the distance, or None\n        \"\"\"", "\n", "if", "not", "self", ".", "contains", "(", "point", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "to_under", "=", "point", ".", "vector", "-", "self", ".", "lower_left", "\n", "to_upper", "=", "self", ".", "upper_right", "-", "point", ".", "vector", "\n", "# As we _know_ the point is contained, all values in to_under and to_upper are >=0", "\n", "return", "np", ".", "minimum", "(", "to_under", ",", "to_upper", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox.internal_distance_L1": [[93, 102], ["bounding_box.BoundingBox._get_shortest_edge_vector", "numpy.sum", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.PartialDataBoundingBox._get_shortest_edge_vector"], ["", "def", "internal_distance_L1", "(", "self", ",", "point", ":", "Activation", ")", "->", "float", ":", "\n", "        ", "\"\"\" Calculates the minimum distance from a _contained_ point to the\n            edge of the bounding box using the L1 mestric\n        \"\"\"", "\n", "closest", "=", "self", ".", "_get_shortest_edge_vector", "(", "point", ")", "\n", "if", "not", "closest", ":", "\n", "            ", "raise", "ValueError", "(", "\"Point must be contained\"", ")", "\n", "\n", "", "return", "np", ".", "sum", "(", "closest", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox.internal_distance_L2": [[103, 112], ["bounding_box.BoundingBox._get_shortest_edge_vector", "numpy.linalg.norm", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.PartialDataBoundingBox._get_shortest_edge_vector"], ["", "def", "internal_distance_L2", "(", "self", ",", "point", ":", "Activation", ")", "->", "float", ":", "\n", "        ", "\"\"\" Calculates the minimum distance from a _contained_ point to the\n            edge of the bounding box using the L2 metric\n        \"\"\"", "\n", "closest", "=", "self", ".", "_get_shortest_edge_vector", "(", "point", ")", "\n", "if", "not", "closest", ":", "\n", "            ", "raise", "ValueError", "(", "\"Point must be contained\"", ")", "\n", "\n", "", "return", "np", ".", "linalg", ".", "norm", "(", "closest", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox.escape_distance_L0": [[113, 132], ["numpy.sum", "numpy.sum", "numpy.where", "numpy.where"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "escape_distance_L0", "(", "self", ",", "point", ":", "Activation", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        calculates on how many dimensions a given point falls outside the cluster.\n        this is defined as the sum of the distance from the closest limit to the point on each axis\n        for all axes where the point falls outside the cluster.\n        L0 distance or no. nonzero errors, equiv. to weight in binary vectors or Hamming distance\n        :param point: a point to test\n        :return: the escape distance for the point\n        \"\"\"", "\n", "under", "=", "self", ".", "lower_left", "-", "point", ".", "vector", "\n", "\n", "under_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "under", ">", "0", ",", "1.0", ",", "0.0", ")", ")", "\n", "\n", "over", "=", "point", ".", "vector", "-", "self", ".", "upper_right", "\n", "\n", "over_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "over", ">", "0", ",", "1.0", ",", "0.0", ")", ")", "\n", "\n", "return", "under_distance", "+", "over_distance", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox.escape_distance_L2": [[133, 152], ["numpy.where", "numpy.where", "numpy.linalg.norm"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "escape_distance_L2", "(", "self", ",", "point", ":", "Activation", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        calculate how far outside the cluster a given point falls.\n        this is defined as the sum of the distance from the closest limit to the point on each axis\n        for all axes where the point falls outside the cluster.\n        L2 distance (sum of errors) pythagorean distance\n        :param point: a point to test\n        :return: the escape distance for the point\n        \"\"\"", "\n", "under", "=", "self", ".", "lower_left", "-", "point", ".", "vector", "\n", "\n", "under_distance", "=", "np", ".", "where", "(", "under", ">", "0", ",", "under", ",", "0.0", ")", "\n", "\n", "over", "=", "point", ".", "vector", "-", "self", ".", "upper_right", "\n", "\n", "over_distance", "=", "np", ".", "where", "(", "over", ">", "0", ",", "over", ",", "0.0", ")", "\n", "\n", "return", "np", ".", "linalg", ".", "norm", "(", "under_distance", "+", "over_distance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox.__eq__": [[153, 163], ["isinstance", "numpy.all", "numpy.all"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\"\n        Equality test\n        :param other: the object to test against\n        :return: true iff the object is considered equal\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "other", ",", "self", ".", "__class__", ")", ":", "\n", "            ", "return", "False", "\n", "", "return", "np", ".", "all", "(", "self", ".", "lower_left", "==", "other", ".", "lower_left", ")", "and", "np", ".", "all", "(", "self", ".", "upper_right", "==", "other", ".", "upper_right", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox.__hash__": [[164, 168], ["hash", "tuple", "tuple"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Hash function for sets\"\"\"", "\n", "return", "hash", "(", "(", "tuple", "(", "self", ".", "upper_right", ")", ",", "\n", "tuple", "(", "self", ".", "lower_left", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.BoundingBox.__repr__": [[169, 173], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\" bounding box representation string\"\"\"", "\n", "return", "'BoundingBox: {} to {}'", ".", "format", "(", "\n", "self", ".", "lower_left", ",", "self", ".", "upper_right", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.__init__": [[182, 192], ["bounding_box.BoundingBox.__init__"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.fast_detk.FastDetK.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\" create an empty bounding box \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "upper_right", "=", "None", "\n", "# an array of all dimensions in which we have seen a non-zero", "\n", "# activations.", "\n", "self", ".", "filter", "=", "None", "\n", "# an array of all dimensions in which we have seen a zero activation.", "\n", "self", ".", "zero_filter", "=", "None", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.expand": [[193, 217], ["numpy.logical_or", "numpy.logical_or", "numpy.min", "numpy.max", "numpy.where", "numpy.where", "numpy.logical_not", "numpy.where", "numpy.where"], "methods", ["None"], ["", "def", "expand", "(", "self", ",", "activation", ":", "Activation", ")", ":", "\n", "        ", "\"\"\" Increase the boundingbox to include the passed activation.\"\"\"", "\n", "self", ".", "count", "+=", "1", "\n", "\n", "if", "self", ".", "lower_left", "is", "None", ":", "\n", "# Make sure that we actually have a box", "\n", "            ", "self", ".", "lower_left", "=", "np", ".", "where", "(", "\n", "activation", ".", "vector", "!=", "0", ",", "activation", ".", "vector", "-", "self", ".", "margin", ",", "0.0", ")", "\n", "self", ".", "upper_right", "=", "np", ".", "where", "(", "\n", "activation", ".", "vector", "!=", "0", ",", "activation", ".", "vector", "+", "self", ".", "margin", ",", "0.0", ")", "\n", "# self.filter = np.logical_or(activation.vector > self.zero_margin, activation.vector < -self.zero_margin)", "\n", "self", ".", "filter", "=", "activation", ".", "vector", "!=", "0", "\n", "\n", "self", ".", "zero_filter", "=", "np", ".", "logical_not", "(", "self", ".", "filter", ")", "\n", "return", "\n", "\n", "# Note: we assume all points have the same dimensionality.", "\n", "", "self", ".", "filter", "=", "np", ".", "logical_or", "(", "self", ".", "filter", ",", "(", "activation", ".", "vector", "!=", "0.0", ")", ")", "\n", "self", ".", "zero_filter", "=", "np", ".", "logical_or", "(", "\n", "self", ".", "zero_filter", ",", "(", "activation", ".", "vector", "==", "0.0", ")", ")", "\n", "self", ".", "lower_left", "=", "np", ".", "min", "(", "(", "self", ".", "lower_left", ",", "np", ".", "where", "(", "\n", "activation", ".", "vector", "!=", "0", ",", "activation", ".", "vector", "-", "self", ".", "margin", ",", "0.0", ")", ")", ",", "axis", "=", "0", ")", "\n", "self", ".", "upper_right", "=", "np", ".", "max", "(", "(", "self", ".", "upper_right", ",", "np", ".", "where", "(", "\n", "activation", ".", "vector", "!=", "0", ",", "activation", ".", "vector", "+", "self", ".", "margin", ",", "0.0", ")", ")", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.get_centre": [[218, 224], ["numpy.where", "numpy.mean"], "methods", ["None"], ["", "def", "get_centre", "(", "self", ")", "->", "np", ".", "array", ":", "\n", "        ", "\"\"\" calculate the point at the centre of the bounding box.\"\"\"", "\n", "if", "self", ".", "lower_left", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "return", "np", ".", "where", "(", "self", ".", "filter", ",", "np", ".", "mean", "(", "\n", "(", "self", ".", "lower_left", ",", "self", ".", "upper_right", ")", ",", "axis", "=", "0", ")", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.contains": [[225, 247], ["numpy.any", "numpy.logical_and", "numpy.logical_and", "numpy.where", "numpy.size", "numpy.sum", "numpy.logical_or", "numpy.where"], "methods", ["None"], ["", "def", "contains", "(", "self", ",", "activation", ":", "Activation", ")", "->", "bool", ":", "\n", "        ", "\"\"\" Determine if a activation lies within the box.\n        Note that a activation on the lower border is considered 'in',\n        while one on the upper border is considered 'out'.\n        \"\"\"", "\n", "# if it has a value on an axis in which we don't exist, skip", "\n", "if", "np", ".", "any", "(", "np", ".", "where", "(", "self", ".", "filter", ",", "0.0", ",", "activation", ".", "vector", ")", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "", "allowed_zeros", "=", "np", ".", "logical_and", "(", "\n", "self", ".", "zero_filter", ",", "activation", ".", "vector", "==", "0.0", ")", "\n", "\n", "# Not that we take containment as inclusive on the lower bound only", "\n", "contain", "=", "np", ".", "logical_and", "(", "\n", "self", ".", "lower_left", "<=", "activation", ".", "vector", ",", "self", ".", "upper_right", ">", "activation", ".", "vector", ")", "\n", "\n", "# ignore filtered overlaps", "\n", "distance", "=", "np", ".", "size", "(", "\n", "self", ".", "filter", ")", "-", "np", ".", "sum", "(", "np", ".", "logical_or", "(", "np", ".", "where", "(", "self", ".", "filter", ",", "contain", ",", "True", ")", ",", "\n", "allowed_zeros", ")", ")", "\n", "\n", "return", "distance", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox._get_shortest_edge_vector": [[248, 261], ["numpy.where", "numpy.where", "numpy.minimum", "bounding_box.LowerDimensionedBoundingBox.contains"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.PartialDataBoundingBox.contains"], ["", "def", "_get_shortest_edge_vector", "(", "self", ",", "point", ":", "Activation", ")", ":", "\n", "        ", "\"\"\"\n        Calculate the shortest vector to the edge of the bounding box from a _contained_ point.\n        :param point:\n        :return: a vector representing the distance, or None\n        \"\"\"", "\n", "if", "not", "self", ".", "contains", "(", "point", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "to_under", "=", "np", ".", "where", "(", "self", ".", "filter", ",", "point", ".", "vector", "-", "self", ".", "lower_left", ",", "0", ")", "\n", "to_upper", "=", "np", ".", "where", "(", "self", ".", "filter", ",", "self", ".", "upper_right", "-", "point", ".", "vector", ",", "0", ")", "\n", "# As we _know_ the point is contained, all values in to_under and to_upper are >=0", "\n", "return", "np", ".", "minimum", "(", "to_under", ",", "to_upper", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.escape_distance_L1": [[262, 276], ["abs", "numpy.where", "numpy.sum", "numpy.where", "numpy.sum", "numpy.sum", "numpy.where", "numpy.where"], "methods", ["None"], ["", "def", "escape_distance_L1", "(", "self", ",", "point", ":", "Activation", ")", "->", "float", ":", "\n", "        ", "\"\"\"L1 Norm\n        \"\"\"", "\n", "outside_distance", "=", "abs", "(", "np", ".", "sum", "(", "point", ".", "vector", "[", "self", ".", "zero_filter", "]", ")", ")", "\n", "\n", "under", "=", "np", ".", "where", "(", "self", ".", "filter", ",", "self", ".", "lower_left", "-", "point", ".", "vector", ",", "0.0", ")", "\n", "\n", "under_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "under", ">", "0", ",", "under", ",", "0.0", ")", ")", "\n", "\n", "over", "=", "np", ".", "where", "(", "self", ".", "filter", ",", "point", ".", "vector", "-", "self", ".", "upper_right", ",", "0.0", ")", "\n", "\n", "over_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "over", ">", "0", ",", "over", ",", "0.0", ")", ")", "\n", "\n", "return", "outside_distance", "+", "under_distance", "+", "over_distance", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.escape_distance_L2": [[277, 296], ["numpy.ones", "numpy.where", "numpy.logical_and", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.linalg.norm", "len"], "methods", ["None"], ["", "def", "escape_distance_L2", "(", "self", ",", "point", ":", "Activation", ")", "->", "float", ":", "\n", "        ", "\"\"\"L2 Norm - pythaogorean distance\n        \"\"\"", "\n", "mask", "=", "np", ".", "ones", "(", "len", "(", "self", ".", "filter", ")", ",", "np", ".", "bool", ")", "\n", "mask", "[", "self", ".", "filter", "]", "=", "False", "\n", "outside_distance", "=", "np", ".", "where", "(", "mask", ",", "point", ".", "vector", ",", "0.0", ")", "\n", "\n", "zero_values", "=", "np", ".", "logical_and", "(", "self", ".", "zero_filter", ",", "point", ".", "vector", ")", "\n", "\n", "under", "=", "np", ".", "where", "(", "zero_values", ",", "0.0", ",", "self", ".", "lower_left", "-", "point", ".", "vector", ")", "\n", "\n", "under_distance", "=", "np", ".", "where", "(", "under", ">", "0", ",", "under", ",", "0.0", ")", "\n", "\n", "over", "=", "np", ".", "where", "(", "self", ".", "filter", ",", "point", ".", "vector", "-", "self", ".", "upper_right", ",", "0.0", ")", "\n", "\n", "over_distance", "=", "np", ".", "where", "(", "over", ">", "0", ",", "over", ",", "0.0", ")", "\n", "\n", "return", "np", ".", "linalg", ".", "norm", "(", "\n", "outside_distance", "+", "under_distance", "+", "over_distance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.escape_distance_L0": [[297, 317], ["numpy.ones", "numpy.sum", "numpy.logical_and", "numpy.where", "numpy.sum", "numpy.where", "numpy.sum", "len", "numpy.where", "numpy.where", "numpy.where"], "methods", ["None"], ["", "def", "escape_distance_L0", "(", "self", ",", "point", ":", "Activation", ")", "->", "int", ":", "\n", "        ", "\"\"\"L0 Norm - no of non zero dimensions\n        \"\"\"", "\n", "mask", "=", "np", ".", "ones", "(", "len", "(", "self", ".", "filter", ")", ",", "np", ".", "bool", ")", "\n", "mask", "[", "self", ".", "filter", "]", "=", "False", "\n", "# vector of dimensions which have always been zero", "\n", "outside_vector", "=", "point", ".", "vector", "[", "mask", "]", "\n", "outside_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "outside_vector", "!=", "0", ",", "1", ",", "0", ")", ")", "\n", "\n", "zero_values", "=", "np", ".", "logical_and", "(", "self", ".", "zero_filter", ",", "point", ".", "vector", ")", "\n", "\n", "under", "=", "np", ".", "where", "(", "zero_values", ",", "0.0", ",", "self", ".", "lower_left", "-", "point", ".", "vector", ")", "\n", "\n", "under_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "under", ">", "0", ",", "1.0", ",", "0.0", ")", ")", "\n", "\n", "over", "=", "np", ".", "where", "(", "self", ".", "filter", ",", "point", ".", "vector", "-", "self", ".", "upper_right", ",", "0.0", ")", "\n", "\n", "over_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "over", ">", "0", ",", "1.0", ",", "0.0", ")", ")", "\n", "\n", "return", "outside_distance", "+", "under_distance", "+", "over_distance", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.escape_distance_zip": [[318, 345], ["zip"], "methods", ["None"], ["", "def", "escape_distance_zip", "(", "self", ",", "point", ")", "->", "int", ":", "\n", "        ", "\"\"\" Determine the total distance by which a point falls outside the bounding box.\n        \"\"\"", "\n", "\n", "distance", "=", "0.0", "\n", "\n", "for", "value", ",", "lower", ",", "upper", ",", "present", ",", "zero_ok", "in", "zip", "(", "point", ".", "vector", ",", "\n", "self", ".", "lower_left", ",", "\n", "self", ".", "upper_right", ",", "\n", "self", ".", "filter", ",", "\n", "self", ".", "zero_filter", ")", ":", "\n", "            ", "if", "value", "<", "lower", ":", "\n", "                ", "if", "zero_ok", "and", "value", "==", "0.0", ":", "\n", "                    ", "continue", "\n", "", "if", "not", "present", ":", "\n", "                    ", "distance", "+=", "value", "\n", "continue", "\n", "", "distance", "+=", "(", "lower", "-", "value", ")", "\n", "\n", "", "if", "value", ">", "upper", ":", "\n", "                ", "distance", "+=", "(", "value", "-", "upper", ")", "\n", "\n", "", "if", "not", "present", ":", "\n", "                ", "distance", "+=", "value", "\n", "continue", "\n", "\n", "", "", "return", "distance", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.escape_count": [[346, 369], ["numpy.logical_and", "numpy.logical_and", "numpy.size", "numpy.sum", "numpy.logical_or", "numpy.where"], "methods", ["None"], ["", "def", "escape_count", "(", "self", ",", "activation", ")", "->", "int", ":", "\n", "        ", "\"\"\" Determine the count of axes in which the given activation falls\n        outside the bounding box.\n        Note that a activation on the lower border is considered 'in',\n        while one on the upper border is considered 'out'.\n        L0 norm\n        \"\"\"", "\n", "# TODO: handle", "\n", "# if it has a value on an axis in which we don't exist, skip", "\n", "\n", "allowed_zeros", "=", "np", ".", "logical_and", "(", "\n", "self", ".", "zero_filter", ",", "activation", ".", "vector", "==", "0.0", ")", "\n", "\n", "# Not that we take containment as inclusive on the lower bound only", "\n", "contain", "=", "np", ".", "logical_and", "(", "\n", "self", ".", "lower_left", "<=", "activation", ".", "vector", ",", "self", ".", "upper_right", ">", "activation", ".", "vector", ")", "\n", "\n", "# ignore filtered overlaps", "\n", "distance", "=", "np", ".", "size", "(", "self", ".", "filter", ")", "-", "np", ".", "sum", "(", "np", ".", "logical_or", "(", "np", ".", "where", "(", "self", ".", "filter", ",", "contain", ",", "True", ")", ",", "\n", "allowed_zeros", ")", ")", "\n", "\n", "return", "distance", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.overlap": [[370, 378], ["numpy.logical_or", "numpy.logical_and", "numpy.any", "numpy.logical_and"], "methods", ["None"], ["", "def", "overlap", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\" Determine if two boxes overlap \"\"\"", "\n", "# Do these boxes overlap in every dimension?", "\n", "# if ah<=bl or bh<=al in every dimension, then no overlap", "\n", "overlaps", "=", "np", ".", "logical_or", "(", "self", ".", "upper_right", "<=", "other", ".", "lower_left", ",", "\n", "other", ".", "upper_right", "<=", "self", ".", "lower_left", ")", "\n", "filters", "=", "np", ".", "logical_and", "(", "self", ".", "filter", ",", "other", ".", "filter", ")", "\n", "return", "not", "np", ".", "any", "(", "np", ".", "logical_and", "(", "overlaps", ",", "filters", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.__eq__": [[379, 385], ["numpy.all", "numpy.all", "numpy.all", "numpy.all"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "\"\"\" test for equality. \"\"\"", "\n", "return", "np", ".", "all", "(", "self", ".", "upper_right", "==", "other", ".", "upper_right", ")", "and", "np", ".", "all", "(", "self", ".", "lower_left", "==", "other", ".", "lower_left", ")", "and", "np", ".", "all", "(", "self", ".", "filter", "==", "other", ".", "filter", ")", "and", "np", ".", "all", "(", "self", ".", "zero_filter", "==", "self", ".", "zero_filter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.LowerDimensionedBoundingBox.__hash__": [[386, 392], ["hash", "tuple", "tuple", "tuple", "tuple"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Hash function for sets\"\"\"", "\n", "return", "hash", "(", "(", "tuple", "(", "self", ".", "upper_right", ")", ",", "\n", "tuple", "(", "self", ".", "lower_left", ")", ",", "\n", "tuple", "(", "self", ".", "filter", ")", ",", "\n", "tuple", "(", "self", ".", "zero_filter", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.PartialDataBoundingBox.get_centre": [[399, 406], ["numpy.zeros", "len"], "methods", ["None"], ["def", "get_centre", "(", "self", ")", "->", "np", ".", "array", ":", "\n", "        ", "result", "=", "np", ".", "zeros", "(", "len", "(", "self", ".", "lower_left", ")", ",", "np", ".", "float", ")", "\n", "result", "+=", "self", ".", "lower_left", "[", "self", ".", "mask", "]", "\n", "result", "+=", "self", ".", "upper_right", "[", "self", ".", "mask", "]", "\n", "result", "/=", "2.0", "\n", "result", "[", "self", ".", "mask", "]", "=", "None", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.PartialDataBoundingBox.contains": [[407, 431], ["bounding_box.PartialDataBoundingBox.mask.copy", "numpy.any", "numpy.any", "numpy.any", "numpy.where"], "methods", ["None"], ["", "def", "contains", "(", "self", ",", "point", ":", "Activation", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "lower_left", "is", "None", ":", "\n", "# Not yet created, so...", "\n", "            ", "return", "False", "\n", "\n", "# Calculate those axes on which both the bounding box and the point", "\n", "# have values", "\n", "", "mask", "=", "self", ".", "mask", ".", "copy", "(", ")", "\n", "mask", "[", "np", ".", "where", "(", "point", ".", "vector", "==", "None", ")", "]", "=", "False", "\n", "\n", "if", "not", "np", ".", "any", "(", "mask", ")", ":", "\n", "# There is no axes of overlap, so assume false", "\n", "            ", "return", "False", "\n", "\n", "", "under", "=", "self", ".", "lower_left", "[", "mask", "]", "-", "point", ".", "vector", "[", "mask", "]", "\n", "if", "np", ".", "any", "(", "under", ">", "0.0", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "", "over", "=", "point", ".", "vector", "[", "mask", "]", "-", "self", ".", "upper_right", "[", "mask", "]", "\n", "if", "np", ".", "any", "(", "over", ">", "0.0", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "# Seems Good.", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.PartialDataBoundingBox._get_shortest_edge_vector": [[432, 445], ["numpy.where", "numpy.where", "numpy.minimum", "bounding_box.PartialDataBoundingBox.contains"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.PartialDataBoundingBox.contains"], ["", "def", "_get_shortest_edge_vector", "(", "self", ",", "point", ":", "Activation", ")", ":", "\n", "        ", "\"\"\"\n        Calculate the shortest vector to the edge of the bounding box from a _contained_ point.\n        :param point:\n        :return: a vector representing the distance, or None\n        \"\"\"", "\n", "if", "not", "self", ".", "contains", "(", "point", ")", ":", "\n", "            ", "return", "None", "\n", "\n", "", "to_under", "=", "np", ".", "where", "(", "self", ".", "mask", ",", "point", ".", "vector", "-", "self", ".", "lower_left", ",", "0", ")", "\n", "to_upper", "=", "np", ".", "where", "(", "self", ".", "mask", ",", "self", ".", "upper_right", "-", "point", ".", "vector", ",", "0", ")", "\n", "# As we _know_ the point is contained, all values in to_under and to_upper are >=0", "\n", "return", "np", ".", "minimum", "(", "to_under", ",", "to_upper", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.PartialDataBoundingBox.escape_distance_L1": [[446, 459], ["bounding_box.PartialDataBoundingBox.mask.copy", "numpy.sum", "numpy.sum", "numpy.where", "numpy.where", "numpy.where"], "methods", ["None"], ["", "def", "escape_distance_L1", "(", "self", ",", "point", ":", "Activation", ")", "->", "float", ":", "\n", "# Calculate those axes on which both the bounding box and the point", "\n", "# have values", "\n", "        ", "mask", "=", "self", ".", "mask", ".", "copy", "(", ")", "\n", "mask", "[", "np", ".", "where", "(", "point", ".", "vector", "==", "None", ")", "]", "=", "False", "\n", "\n", "under", "=", "self", ".", "lower_left", "[", "mask", "]", "-", "point", ".", "vector", "[", "mask", "]", "\n", "under_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "under", ">", "0", ",", "under", ",", "0.0", ")", ")", "\n", "\n", "over", "=", "point", ".", "vector", "[", "mask", "]", "-", "self", ".", "upper_right", "[", "mask", "]", "\n", "over_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "over", ">", "0", ",", "over", ",", "0.0", ")", ")", "\n", "\n", "return", "under_distance", "+", "over_distance", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.PartialDataBoundingBox.escape_distance_L0": [[460, 473], ["bounding_box.PartialDataBoundingBox.mask.copy", "numpy.sum", "numpy.sum", "numpy.where", "numpy.where", "numpy.where"], "methods", ["None"], ["", "def", "escape_distance_L0", "(", "self", ",", "point", ":", "Activation", ")", "->", "int", ":", "\n", "# Calculate those axes on which both the bounding box and the point", "\n", "# have values", "\n", "        ", "mask", "=", "self", ".", "mask", ".", "copy", "(", ")", "\n", "mask", "[", "np", ".", "where", "(", "point", ".", "vector", "==", "None", ")", "]", "=", "False", "\n", "\n", "under", "=", "self", ".", "lower_left", "[", "mask", "]", "-", "point", ".", "vector", "[", "mask", "]", "\n", "under_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "under", ">", "0", ",", "1.0", ",", "0.0", ")", ")", "\n", "\n", "over", "=", "point", ".", "vector", "[", "mask", "]", "-", "self", ".", "upper_right", "[", "mask", "]", "\n", "over_distance", "=", "np", ".", "sum", "(", "np", ".", "where", "(", "over", ">", "0", ",", "1.0", ",", "0.0", ")", ")", "\n", "\n", "return", "under_distance", "+", "over_distance", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.PartialDataBoundingBox.escape_distance_L2": [[474, 487], ["bounding_box.PartialDataBoundingBox.mask.copy", "numpy.where", "numpy.where", "numpy.linalg.norm", "numpy.where"], "methods", ["None"], ["", "def", "escape_distance_L2", "(", "self", ",", "point", ":", "Activation", ")", "->", "float", ":", "\n", "# Calculate those axes on which both the bounding box", "\n", "# and the point have values", "\n", "        ", "mask", "=", "self", ".", "mask", ".", "copy", "(", ")", "\n", "mask", "[", "np", ".", "where", "(", "point", ".", "vector", "==", "None", ")", "]", "=", "False", "\n", "\n", "under", "=", "self", ".", "lower_left", "[", "mask", "]", "-", "point", ".", "vector", "[", "mask", "]", "\n", "under_distance", "=", "np", ".", "where", "(", "under", ">", "0", ",", "under", ",", "0.0", ")", "\n", "\n", "over", "=", "point", ".", "vector", "[", "mask", "]", "-", "self", ".", "upper_right", "[", "mask", "]", "\n", "over_distance", "=", "np", ".", "where", "(", "over", ">", "0", ",", "over", ",", "0.0", ")", "\n", "\n", "return", "np", ".", "linalg", ".", "norm", "(", "under_distance", "+", "over_distance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.bounding_box.PartialDataBoundingBox.expand": [[488, 520], ["bounding_box.PartialDataBoundingBox.mask.copy", "numpy.invert", "bounding_box.PartialDataBoundingBox.mask.copy", "numpy.array", "numpy.array", "point.vector.copy", "point.vector.copy", "numpy.ones", "bounding_box.PartialDataBoundingBox.mask.copy", "len", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "min", "zip", "max", "zip"], "methods", ["None"], ["", "def", "expand", "(", "self", ",", "point", ":", "Activation", ")", ":", "\n", "        ", "if", "self", ".", "lower_left", "is", "None", ":", "\n", "# This is the first point. Use margins so that we actually have a box", "\n", "# Of course, this point may be partial...", "\n", "            ", "self", ".", "lower_left", "=", "point", ".", "vector", ".", "copy", "(", ")", "\n", "self", ".", "upper_right", "=", "point", ".", "vector", ".", "copy", "(", ")", "\n", "self", ".", "mask", "=", "np", ".", "ones", "(", "len", "(", "self", ".", "lower_left", ")", ",", "np", ".", "bool", ")", "\n", "self", ".", "mask", "[", "np", ".", "where", "(", "self", ".", "lower_left", "==", "None", ")", "]", "=", "False", "\n", "self", ".", "lower_left", "[", "self", ".", "mask", "]", "-=", "self", ".", "margin", "\n", "self", ".", "upper_right", "[", "self", ".", "mask", "]", "+=", "self", ".", "margin", "\n", "return", "\n", "# first set the minimum of the intersections", "\n", "# TODO:: Don't go via lists.", "\n", "", "mask", "=", "self", ".", "mask", ".", "copy", "(", ")", "\n", "mask", "[", "np", ".", "where", "(", "point", ".", "vector", "==", "None", ")", "]", "=", "False", "\n", "newmask", "=", "np", ".", "invert", "(", "self", ".", "mask", ".", "copy", "(", ")", ")", "\n", "newmask", "[", "np", ".", "where", "(", "point", ".", "vector", "==", "None", ")", "]", "=", "False", "\n", "oldmask", "=", "self", ".", "mask", ".", "copy", "(", ")", "\n", "oldmask", "[", "np", ".", "where", "(", "point", ".", "vector", "!=", "None", ")", "]", "=", "False", "\n", "\n", "overlap_min", "=", "np", ".", "array", "(", "[", "min", "(", "x", ",", "y", ")", "if", "m", "else", "None", "for", "(", "x", ",", "y", ",", "m", ")", "in", "\n", "zip", "(", "self", ".", "lower_left", ",", "point", ".", "vector", ",", "mask", ")", "]", ")", "\n", "overlap_min", "[", "newmask", "]", "=", "point", ".", "vector", "[", "newmask", "]", "\n", "overlap_min", "[", "oldmask", "]", "=", "self", ".", "lower_left", "[", "oldmask", "]", "\n", "self", ".", "lower_left", "=", "overlap_min", "\n", "\n", "overlap_max", "=", "np", ".", "array", "(", "[", "max", "(", "x", ",", "y", ")", "if", "m", "else", "None", "for", "(", "x", ",", "y", ",", "m", ")", "in", "\n", "zip", "(", "self", ".", "upper_right", ",", "point", ".", "vector", ",", "mask", ")", "]", ")", "\n", "overlap_max", "[", "newmask", "]", "=", "point", ".", "vector", "[", "newmask", "]", "\n", "overlap_max", "[", "oldmask", "]", "=", "self", ".", "upper_right", "[", "oldmask", "]", "\n", "self", ".", "upper_right", "=", "overlap_max", "\n", "self", ".", "mask", "[", "np", ".", "where", "(", "self", ".", "lower_left", "==", "None", ")", "]", "=", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.__init__": [[19, 32], ["kmeans.kmeansplusplus.KMeansPlusPlus.__init__"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.fast_detk.FastDetK.__init__"], ["def", "__init__", "(", "self", ",", "\n", "X", ":", "input_type", "=", "None", ",", "\n", "K", ":", "int", "=", "5", ",", "\n", "filename", ":", "str", "=", "None", ",", "\n", "mu", ":", "List", "[", "np", ".", "array", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        X the data as a list of Points\n        filename - name of file to load from\n        mu is the list of centroids\n        \"\"\"", "\n", "KMeansPlusPlus", ".", "__init__", "(", "self", ",", "X", ",", "K", ",", "filename", ",", "mu", ",", "verbose", ")", "\n", "self", ".", "a_mem", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK._zero": [[33, 39], ["super()._zero"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._zero"], ["", "def", "_zero", "(", "self", ")", ":", "\n", "        ", "\"\"\" wipe this object\n        \"\"\"", "\n", "super", "(", "DetK", ",", "self", ")", ".", "_zero", "(", ")", "\n", "self", ".", "fs", "=", "None", "\n", "self", ".", "fCentroids", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK._build_save_dictionary": [[40, 46], ["super()._build_save_dictionary"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._build_save_dictionary"], ["", "def", "_build_save_dictionary", "(", "self", ")", ":", "\n", "        ", "\"\"\" extend _build_save_dictionary to include the additional stuff needed to save.\n        \"\"\"", "\n", "super", "(", "DetK", ",", "self", ")", ".", "_build_save_dictionary", "(", ")", "\n", "self", ".", "savedic", "[", "'fs'", "]", "=", "self", ".", "fs", "\n", "self", ".", "savedic", "[", "'fCentroids'", "]", "=", "self", ".", "fCentroids", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK._load": [[47, 53], ["super()._load"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._load"], ["", "def", "_load", "(", "self", ",", "filehandle", ")", ":", "\n", "        ", "\"\"\" extend _load to include the new attributes\n        \"\"\"", "\n", "super", "(", "DetK", ",", "self", ")", ".", "_load", "(", "filehandle", ")", "\n", "self", ".", "fs", "=", "filehandle", "[", "'fs'", "]", "\n", "self", ".", "fCentroids", "=", "filehandle", "[", "'fCentroids'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.fK": [[54, 66], ["detk.DetK.find_centers", "sum", "numpy.linalg.norm", "range", "detk.DetK.a"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.find_centers", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.a"], ["", "def", "fK", "(", "self", ",", "Skm1", "=", "0", ")", ":", "\n", "        ", "self", ".", "find_centers", "(", ")", "\n", "mu", ",", "clusters", "=", "self", ".", "mu", ",", "self", ".", "clusters", "\n", "# Sk = sum([np.linalg.norm(m-c)**2 for m in clusters for c in clusters[m]])", "\n", "Sk", "=", "sum", "(", "[", "np", ".", "linalg", ".", "norm", "(", "mu", "[", "i", "]", "-", "c", ")", "**", "2", "\n", "for", "i", "in", "range", "(", "self", ".", "K", ")", "for", "c", "in", "clusters", "[", "i", "]", "]", ")", "\n", "\n", "if", "self", ".", "K", "==", "1", "or", "Skm1", "==", "0", ":", "\n", "            ", "fs", "=", "1.0", "\n", "", "else", ":", "\n", "            ", "fs", "=", "Sk", "/", "(", "self", ".", "a", "(", "self", ".", "K", ",", "self", ".", "dimensions", ")", "*", "Skm1", ")", "\n", "", "return", "fs", ",", "Sk", ",", "mu", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK._bounding_box": [[67, 69], ["numpy.amin", "numpy.amax"], "methods", ["None"], ["", "def", "_bounding_box", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "amin", "(", "self", ".", "X", ",", "axis", "=", "0", ")", ",", "np", ".", "amax", "(", "self", ".", "X", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.gap": [[70, 95], ["detk.DetK._bounding_box", "detk.DetK.init_centers", "detk.DetK.find_centers", "numpy.log", "numpy.zeros", "range", "numpy.sqrt", "sum", "numpy.array", "detk.DetK", "DetK.init_centers", "DetK.find_centers", "numpy.log", "sum", "numpy.array.append", "sum", "sum", "numpy.sqrt", "random.uniform", "range", "float", "numpy.linalg.norm", "len", "range", "numpy.linalg.norm", "len"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK._bounding_box", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.init_centers", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.find_centers", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.init_centers", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.find_centers"], ["", "def", "gap", "(", "self", ")", ":", "\n", "        ", "dataMin", ",", "dataMax", "=", "self", ".", "_bounding_box", "(", ")", "\n", "self", ".", "init_centers", "(", ")", "\n", "self", ".", "find_centers", "(", ")", "\n", "mu", ",", "clusters", "=", "self", ".", "mu", ",", "self", ".", "clusters", "\n", "Wk", "=", "np", ".", "log", "(", "sum", "(", "[", "np", ".", "linalg", ".", "norm", "(", "mu", "[", "i", "]", "-", "c", ")", "**", "2", "/", "(", "2", "*", "len", "(", "c", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "K", ")", "for", "c", "in", "clusters", "[", "i", "]", "]", ")", ")", "\n", "# why 10?", "\n", "B", "=", "10", "\n", "ms", "=", "None", "\n", "BWkbs", "=", "np", ".", "zeros", "(", "B", ")", "\n", "for", "i", "in", "range", "(", "B", ")", ":", "\n", "            ", "Xb", "=", "[", "]", "\n", "for", "n", "in", "self", ".", "X", ":", "\n", "                ", "Xb", ".", "append", "(", "random", ".", "uniform", "(", "dataMin", ",", "dataMax", ")", ")", "\n", "", "Xb", "=", "np", ".", "array", "(", "Xb", ")", "\n", "kb", "=", "DetK", "(", "K", "=", "self", ".", "K", ",", "X", "=", "Xb", ")", "\n", "kb", ".", "init_centers", "(", ")", "\n", "kb", ".", "find_centers", "(", ")", "\n", "ms", ",", "cs", "=", "kb", ".", "mu", ",", "kb", ".", "clusters", "\n", "BWkbs", "[", "i", "]", "=", "np", ".", "log", "(", "sum", "(", "[", "np", ".", "linalg", ".", "norm", "(", "ms", "[", "j", "]", "-", "c", ")", "**", "2", "/", "(", "2", "*", "len", "(", "c", ")", ")", "\n", "for", "j", "in", "range", "(", "self", ".", "K", ")", "for", "c", "in", "cs", "[", "j", "]", "]", ")", ")", "\n", "", "Wkb", "=", "sum", "(", "BWkbs", ")", "/", "B", "\n", "sk", "=", "np", ".", "sqrt", "(", "sum", "(", "(", "BWkbs", "-", "Wkb", ")", "**", "2", "/", "float", "(", "B", ")", ")", "*", "np", ".", "sqrt", "(", "1", "+", "1", "/", "B", ")", ")", "\n", "return", "Wk", ",", "Wkb", ",", "sk", ",", "ms", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.runFK": [[96, 121], ["range", "numpy.zeros", "numpy.argmin", "detk.DetK.cluster_points", "len", "detk.DetK.init_centers", "detk.DetK.fK", "fCentroidList.append", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.cluster_points", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.init_centers", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.fK"], ["", "def", "runFK", "(", "self", ",", "maxK", ",", "minK", "=", "1", ")", ":", "\n", "        ", "\"\"\" Run fK for values in the range 1..maxK,\n        picking the best one in the range minK..MaxK\n        \"\"\"", "\n", "ks", "=", "range", "(", "1", ",", "maxK", "+", "1", ")", "\n", "fs", "=", "np", ".", "zeros", "(", "len", "(", "ks", ")", ")", "\n", "fCentroidList", "=", "[", "]", "\n", "Sk", "=", "0", "\n", "for", "k", "in", "ks", ":", "\n", "# if self.verbose:", "\n", "#    print('k={}'.format(k))", "\n", "            ", "self", ".", "K", "=", "k", "\n", "self", ".", "init_centers", "(", ")", "\n", "fs", "[", "k", "-", "1", "]", ",", "Sk", ",", "centroids", "=", "self", ".", "fK", "(", "Skm1", "=", "Sk", ")", "\n", "fCentroidList", ".", "append", "(", "np", ".", "array", "(", "centroids", ")", ")", "\n", "", "self", ".", "fs", "=", "fs", "\n", "self", ".", "fCentroids", "=", "fCentroidList", "\n", "# Now assign the best K centroids, starting from minK", "\n", "error", "=", "0.15", "\n", "bestF", "=", "np", ".", "argmin", "(", "fs", "[", "minK", "-", "1", ":", "]", ")", "\n", "if", "fs", "[", "bestF", "]", ">", "(", "1", "-", "error", ")", ":", "\n", "            ", "bestF", "=", "minK", "-", "1", "\n", "", "self", ".", "K", "=", "bestF", "+", "1", "\n", "self", ".", "mu", "=", "fCentroidList", "[", "bestF", "]", "\n", "self", ".", "cluster_points", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.runGap": [[122, 138], ["range", "range", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.zeros", "print", "detk.DetK.init_centers", "detk.DetK.gap", "gCentroidList.append", "len", "G.append", "numpy.array", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.init_centers", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.gap"], ["", "def", "runGap", "(", "self", ",", "maxK", ")", ":", "\n", "        ", "ks", "=", "range", "(", "1", ",", "maxK", ")", "\n", "gCentroidList", "=", "[", "]", "\n", "Wks", ",", "Wkbs", ",", "sks", "=", "np", ".", "zeros", "(", "\n", "len", "(", "ks", ")", "+", "1", ")", ",", "np", ".", "zeros", "(", "len", "(", "ks", ")", "+", "1", ")", ",", "np", ".", "zeros", "(", "len", "(", "ks", ")", "+", "1", ")", "\n", "for", "k", "in", "ks", ":", "\n", "            ", "print", "(", "'k={}'", ".", "format", "(", "k", ")", ")", "\n", "self", ".", "K", "=", "k", "\n", "self", ".", "init_centers", "(", ")", "\n", "Wks", "[", "k", "-", "1", "]", ",", "Wkbs", "[", "k", "-", "1", "]", ",", "sks", "[", "k", "-", "1", "]", ",", "centroids", "=", "self", ".", "gap", "(", ")", "\n", "gCentroidList", ".", "append", "(", "np", ".", "array", "(", "centroids", ")", ")", "\n", "", "G", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "ks", ")", ")", ":", "\n", "            ", "G", ".", "append", "(", "(", "Wkbs", "-", "Wks", ")", "[", "i", "]", "-", "(", "(", "Wkbs", "-", "Wks", ")", "[", "i", "+", "1", "]", "-", "sks", "[", "i", "+", "1", "]", ")", ")", "\n", "", "self", ".", "G", "=", "np", ".", "array", "(", "G", ")", "\n", "self", ".", "gCentroids", "=", "gCentroidList", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.run": [[139, 146], ["detk.DetK.runFK", "detk.DetK.runGap"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.runFK", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.runGap"], ["", "def", "run", "(", "self", ",", "maxK", ",", "which", "=", "'both'", ")", ":", "\n", "        ", "doF", "=", "which", "is", "'f'", "or", "which", "is", "'both'", "\n", "doGap", "=", "which", "is", "'gap'", "or", "which", "is", "'both'", "\n", "if", "doF", ":", "\n", "            ", "self", ".", "runFK", "(", "maxK", ")", "\n", "", "if", "doGap", ":", "\n", "            ", "self", ".", "runGap", "(", "maxK", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.a": [[147, 160], ["detk.DetK.a"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.detk.DetK.a"], ["", "", "def", "a", "(", "self", ",", "k", ":", "int", ",", "dimensions", ":", "int", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "self", ".", "a_mem", "[", "(", "k", ",", "dimensions", ")", "]", "\n", "", "except", "KeyError", ":", "\n", "# Not yet calculated this value", "\n", "            ", "result", "=", "None", "\n", "if", "k", "==", "2", ":", "\n", "                ", "result", "=", "1", "-", "3.0", "/", "(", "4.0", "*", "dimensions", ")", "\n", "", "else", ":", "\n", "                ", "previous", "=", "self", ".", "a", "(", "k", "-", "1", ",", "dimensions", ")", "\n", "result", "=", "previous", "+", "(", "1", "-", "previous", ")", "/", "6.0", "\n", "", "self", ".", "a_mem", "[", "(", "k", ",", "dimensions", ")", "]", "=", "result", "\n", "return", "result", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationObject.__init__": [[38, 47], ["numpy.array", "numpy.array"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "index_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "self", ".", "index_name", "=", "index_name", "\n", "self", ".", "image_count", "=", "0", "\n", "self", ".", "neuron_count", "=", "0", "\n", "self", ".", "activations", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "self", ".", "label_mappings", "=", "[", "]", "\n", "self", ".", "labels", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "self", ".", "activation_labels", "=", "{", "}", "\n", "self", ".", "file_names", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationObject.is_valid": [[48, 50], ["None"], "methods", ["None"], ["", "def", "is_valid", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationObject.get_activation": [[51, 89], ["kmeans.activation.Activation", "ValueError", "numpy.mean", "activation_table.ActivationObject.activations[].reshape", "kmeans.activation.Activation.standardise", "numpy.mean", "print", "print"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.standardise"], ["", "def", "get_activation", "(", "\n", "self", ",", "\n", "idx", ":", "int", ",", "\n", "standardise", ":", "bool", "=", "False", ",", "\n", "mean", ":", "bool", "=", "True", ")", "->", "Activation", ":", "\n", "        ", "\"\"\"Get a point by it's index.\n\n        Args:\n            idx (int): the index (from 0) of the activation to get\n            standardise (bool, optional): whether to standardise the activation\n                so that the maximum distance in any dimension is 1.0\n            mean (bool, optional): for multidimensional data, whether to convert\n                it to 1D by averaging the values in dimensions 2+\n        \"\"\"", "\n", "if", "idx", ">=", "self", ".", "image_count", ":", "\n", "            ", "raise", "ValueError", "(", "\"index {} out of bounds.\"", ".", "format", "(", "idx", ")", ")", "\n", "", "if", "mean", ":", "\n", "            ", "vector", "=", "np", ".", "mean", "(", "np", ".", "mean", "(", "self", ".", "activations", "[", "idx", "]", ",", "axis", "=", "0", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "# Note that reshape forces vector to be 1D!", "\n", "            ", "vector", "=", "self", ".", "activations", "[", "idx", "]", ".", "reshape", "(", "-", "1", ")", "\n", "\n", "", "try", ":", "\n", "            ", "labels", "=", "self", ".", "label_mappings", "[", "idx", "]", "\n", "", "except", "IndexError", "as", "e", ":", "\n", "            ", "print", "(", "\"ERROR: Failed to get label mappings for {}\"", ".", "format", "(", "idx", ")", ")", "\n", "print", "(", "\"Availiable mappings: {}\"", ".", "format", "(", "self", ".", "label_mappings", ")", ")", "\n", "raise", "e", "\n", "", "point", "=", "Activation", "(", "\n", "labels", "=", "self", ".", "label_mappings", "[", "idx", "]", ",", "\n", "vector", "=", "vector", ",", "\n", "index", "=", "(", "\n", "self", ".", "index_name", ",", "\n", "idx", ")", ")", "\n", "if", "standardise", ":", "\n", "            ", "point", ".", "standardise", "(", ")", "\n", "\n", "", "return", "point", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationObject.get_activations": [[90, 101], ["activation_table.ActivationObject.get_activation"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation"], ["", "def", "get_activations", "(", "\n", "self", ",", "\n", "indices", ":", "List", "[", "int", "]", ",", "\n", "standardise", ":", "bool", "=", "False", ",", "\n", "mean", ":", "bool", "=", "True", ")", "->", "List", "[", "Activation", "]", ":", "\n", "        ", "\"\"\"Get a list of points, by index.\n\n        Note:\n            parameters as per get_activation\n        \"\"\"", "\n", "return", "[", "self", ".", "get_activation", "(", "idx", ",", "standardise", ",", "mean", ")", "for", "idx", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationObject.get_all_activation_indices": [[102, 106], ["range"], "methods", ["None"], ["", "def", "get_all_activation_indices", "(", "self", ")", "->", "range", ":", "\n", "        ", "\"\"\"Get indices of  points in the table.\n        \"\"\"", "\n", "return", "range", "(", "self", ".", "image_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationObject.get_batch_indices": [[107, 124], ["range", "str"], "methods", ["None"], ["", "def", "get_batch_indices", "(", "self", ",", "batch_size", ":", "int", ",", "offset", ":", "int", "=", "0", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\" get a list of indices of batch_size elements of each label\n            starting from offset*batch_size\n        \"\"\"", "\n", "# TODO: make sure we don't go off the end", "\n", "indices", "=", "[", "]", "\n", "start_offset", "=", "batch_size", "*", "offset", "\n", "# We assume that the label names occur in label order", "\n", "for", "label", "in", "self", ".", "labels", ":", "\n", "            ", "try", ":", "\n", "                ", "start_idx", "=", "self", ".", "activation_labels", "[", "str", "(", "\n", "label", ")", "]", "[", "0", "]", "+", "start_offset", "\n", "indices", "+=", "range", "(", "start_idx", ",", "start_idx", "+", "batch_size", ")", "\n", "", "except", "KeyError", ":", "\n", "# Handle empty directories", "\n", "                ", "pass", "\n", "", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationGroup.__init__": [[132, 155], ["activation_table.ActivationObject.__init__", "pdb.set_trace", "print"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.fast_detk.FastDetK.__init__"], ["def", "__init__", "(", "self", ",", "source", ":", "h5File", ",", "index_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\" Creates the object:\n            source: a h5py file or group object\n            index_name: the name by which the parent activation table refers to this object.\n        \"\"\"", "\n", "ActivationObject", ".", "__init__", "(", "self", ",", "index_name", ")", "\n", "try", ":", "\n", "            ", "self", ".", "activations", "=", "source", "[", "'activations'", "]", "\n", "", "except", "ValueError", ":", "\n", "            ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "self", ".", "labels", "=", "source", "[", "'labels'", "]", "\n", "self", ".", "label_mappings", "=", "source", "[", "'label_mappings'", "]", "\n", "self", ".", "activation_labels", "=", "source", "[", "'activation_labels'", "]", "\n", "try", ":", "\n", "            ", "self", ".", "file_names", "=", "source", "[", "'file_names'", "]", "\n", "", "except", "KeyError", ":", "\n", "# hdf5 made with old version", "\n", "            ", "print", "(", "\"Warning: This hdf5 file lacks file_name mappings\"", ")", "\n", "", "self", ".", "image_count", "=", "self", ".", "activations", ".", "attrs", "[", "'image_count'", "]", "\n", "# TODO: handle multi-dimensional neurons better", "\n", "self", ".", "neuron_count", "=", "self", ".", "activations", ".", "attrs", "[", "'neuron_count'", "]", "\n", "self", ".", "_source", "=", "source", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationFile.__init__": [[163, 167], ["h5py.File", "activation_table.ActivationGroup.__init__"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.fast_detk.FastDetK.__init__"], ["def", "__init__", "(", "self", ",", "filename", ":", "str", ",", "index_name", ":", "str", ")", "->", "None", ":", "\n", "        ", "file_handle", "=", "h5py", ".", "File", "(", "\n", "filename", ",", "'r'", ")", "# pylint: disable=undefined-variable", "\n", "ActivationGroup", ".", "__init__", "(", "self", ",", "file_handle", ",", "index_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.__init__": [[174, 183], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "standardise", ":", "bool", "=", "False", ",", "mean", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "self", ".", "activation_files", "=", "{", "}", "\n", "self", ".", "default_file", "=", "None", "\n", "self", ".", "standardise", "=", "standardise", "\n", "self", ".", "mean", "=", "mean", "\n", "self", ".", "merged_file", "=", "None", "\n", "self", ".", "normalised_file", "=", "None", "\n", "self", ".", "normalisation_min", "=", "None", "\n", "self", ".", "normalisation_max", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_merged_file": [[184, 202], ["h5py.File", "ValueError", "ValueError", "activation_table.ActivationGroup", "list", "pdb.set_trace", "activation_table.ActivationTable.merged_file.keys"], "methods", ["None"], ["", "def", "add_merged_file", "(", "self", ",", "filename", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\" Attempts to open an hdf5 of multiple activation_tables and read the values. \"\"\"", "\n", "if", "self", ".", "merged_file", "is", "not", "None", "or", "self", ".", "normalised_file", "is", "not", "None", ":", "\n", "# Wouldn't be too hard to change this though.", "\n", "            ", "raise", "ValueError", "(", "'Only one merged / normalised file is supported at a time.'", ")", "\n", "", "if", "self", ".", "default_file", "is", "not", "None", ":", "\n", "# Again not that hard to change", "\n", "            ", "raise", "ValueError", "(", "\n", "'Cannot mix merged and unmerged files'", ")", "\n", "", "self", ".", "merged_file", "=", "h5py", ".", "File", "(", "filename", ",", "'r'", ")", "\n", "for", "merged_key", "in", "self", ".", "merged_file", ":", "\n", "            ", "self", ".", "activation_files", "[", "merged_key", "]", "=", "ActivationGroup", "(", "\n", "self", ".", "merged_file", "[", "merged_key", "]", ",", "merged_key", ")", "\n", "", "try", ":", "\n", "            ", "self", ".", "default_file", "=", "list", "(", "self", ".", "merged_file", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "", "except", "IndexError", ":", "\n", "            ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_normalised_file": [[203, 220], ["h5py.File", "ValueError", "ValueError", "activation_table.ActivationGroup", "list", "activation_table.ActivationTable.merged_file.keys"], "methods", ["None"], ["", "", "def", "add_normalised_file", "(", "self", ",", "filename", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\" Attempts to load an hdf5 file of multiple normalised activations and read the values.\"\"\"", "\n", "if", "self", ".", "merged_file", "is", "not", "None", "or", "self", ".", "normalised_file", "is", "not", "None", ":", "\n", "# Wouldn't be too hard to change this though.", "\n", "            ", "raise", "ValueError", "(", "'Only one merged / normalised file is supported at a time.'", ")", "\n", "", "if", "self", ".", "default_file", "is", "not", "None", ":", "\n", "# Again not that hard to change", "\n", "            ", "raise", "ValueError", "(", "\n", "'Cannot mix merged and unmerged files'", ")", "\n", "", "self", ".", "merged_file", "=", "h5py", ".", "File", "(", "filename", ",", "'r'", ")", "\n", "self", ".", "normalisation_min", "=", "self", ".", "merged_file", "[", "'normalisation_min'", "]", "\n", "self", ".", "normalisation_max", "=", "self", ".", "merged_file", "[", "'normalisation_max'", "]", "\n", "\n", "for", "merged_key", "in", "self", ".", "merged_file", "[", "'values'", "]", ":", "\n", "            ", "self", ".", "activation_files", "[", "merged_key", "]", "=", "ActivationGroup", "(", "\n", "self", ".", "merged_file", "[", "'values'", "]", "[", "merged_key", "]", ",", "merged_key", ")", "\n", "", "self", ".", "default_file", "=", "list", "(", "self", ".", "merged_file", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.save_normalised_file": [[221, 254], ["functools.reduce", "functools.reduce", "ValueError", "numpy.min", "numpy.max", "h5py.File", "output.create_group", "output.create_group.create_group", "src_file.copy"], "methods", ["None"], ["", "def", "save_normalised_file", "(", "self", ",", "filename", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\" Attempts to save a new hdf5 file containing a normalised version of this file.\"\"\"", "\n", "if", "self", ".", "normalised_file", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Can't renormalise a file.\"", ")", "\n", "\n", "# First calculate the value range of our activation files.", "\n", "", "min_values", "=", "[", "np", ".", "min", "(", "self", ".", "activation_files", "[", "x", "]", ".", "activations", ",", "axis", "=", "0", ")", "for", "x", "in", "self", ".", "activation_files", "]", "\n", "max_values", "=", "[", "np", ".", "max", "(", "self", ".", "activation_files", "[", "x", "]", ".", "activations", ",", "axis", "=", "0", ")", "for", "x", "in", "self", ".", "activation_files", "]", "\n", "\n", "# Now calculate the value range across them", "\n", "self", ".", "normalisation_min", "=", "functools", ".", "reduce", "(", "np", ".", "minimum", ",", "min_values", ")", "\n", "self", ".", "normalisation_max", "=", "functools", ".", "reduce", "(", "np", ".", "maximum", ",", "max_values", ")", "\n", "norm_vector", "=", "self", ".", "normalisation_max", "-", "self", ".", "normalisation_min", "\n", "\n", "with", "h5py", ".", "File", "(", "filename", ",", "'w'", ")", "as", "output", ":", "\n", "            ", "output", "[", "'normalisation_min'", "]", "=", "self", ".", "normalisation_min", "\n", "output", "[", "'normalisation_max'", "]", "=", "self", ".", "normalisation_max", "\n", "value_grp", "=", "output", ".", "create_group", "(", "'values'", ")", "\n", "for", "afile", "in", "self", ".", "activation_files", ":", "\n", "# try:", "\n", "#     src = self.activation_files[afile]", "\n", "# except:", "\n", "#     src = self.activation_files[afile]", "\n", "                ", "src", "=", "self", ".", "activation_files", "[", "afile", "]", "\n", "src_file", "=", "src", ".", "_source", "\n", "grp", "=", "value_grp", ".", "create_group", "(", "afile", ")", "\n", "for", "field", "in", "src_file", ":", "\n", "                    ", "if", "field", "==", "'activations'", ":", "\n", "                        ", "grp", "[", "'activations'", "]", "=", "(", "src", ".", "activations", "-", "self", ".", "normalisation_min", ")", "/", "norm_vector", "\n", "", "else", ":", "\n", "                        ", "src_file", ".", "copy", "(", "field", ",", "grp", ")", "\n", "", "", "grp", "[", "'activations'", "]", ".", "attrs", "[", "'image_count'", "]", "=", "src", ".", "image_count", "\n", "grp", "[", "'activations'", "]", ".", "attrs", "[", "'neuron_count'", "]", "=", "src", ".", "neuron_count", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_file": [[255, 265], ["os.path.basename", "activation_table.ActivationFile", "ValueError"], "methods", ["None"], ["", "", "", "def", "add_file", "(", "self", ",", "filename", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\" Attempts to open the activation hdf5 file and read the basic values \"\"\"", "\n", "base_filename", "=", "os", ".", "path", ".", "basename", "(", "filename", ")", "\n", "if", "base_filename", "in", "self", ".", "activation_files", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "'hdf5 file {} already loaded.'", ".", "format", "(", "base_filename", ")", ")", "\n", "", "self", ".", "activation_files", "[", "base_filename", "]", "=", "ActivationFile", "(", "\n", "filename", ",", "base_filename", ")", "\n", "if", "self", ".", "default_file", "is", "None", ":", "\n", "            ", "self", ".", "default_file", "=", "base_filename", "\n", "# TODO: maybe validate the file in some way? That the label counts are", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.add_direct": [[268, 291], ["str", "activation_table.ActivationDirect", "ValueError"], "methods", ["None"], ["", "", "def", "add_direct", "(", "self", ",", "identifier", ":", "object", ",", "\n", "image_count", ":", "int", ",", "\n", "neuron_count", ":", "int", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "neuron_x_count", ":", "int", ",", "\n", "neuron_y_count", ":", "int", ")", "->", "'ActivationDirect'", ":", "\n", "        ", "\"\"\" creates an activation object which will hold its data in ram.\n            takes an identifier to describe the object.\n            returns a handle to the object so you can call add_activation\n        \"\"\"", "\n", "ident", "=", "str", "(", "identifier", ")", "\n", "if", "ident", "in", "self", ".", "activation_files", ":", "\n", "            ", "raise", "ValueError", "(", "'identifier {} already in use.'", ".", "format", "(", "ident", ")", ")", "\n", "", "self", ".", "activation_files", "[", "ident", "]", "=", "ActivationDirect", "(", "ident", ",", "\n", "image_count", ",", "\n", "neuron_count", ",", "\n", "labels", ",", "\n", "neuron_x_count", ",", "\n", "neuron_y_count", ")", "\n", "if", "self", ".", "default_file", "is", "None", ":", "\n", "            ", "self", ".", "default_file", "=", "ident", "\n", "\n", "", "return", "self", ".", "activation_files", "[", "ident", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_loaded_files": [[292, 296], ["activation_table.ActivationTable.activation_files.keys"], "methods", ["None"], ["", "def", "get_loaded_files", "(", "self", ")", "->", "KeysView", ":", "\n", "        ", "\"\"\" Return the list of filenames loaded.\n        \"\"\"", "\n", "return", "self", ".", "activation_files", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation": [[297, 302], ["activation_table.ActivationTable._expand_index", "activation_table.ActivationTable.activation_files[].get_activation"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._expand_index", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activation"], ["", "def", "get_activation", "(", "self", ",", "idx", ":", "ActivationImplicitIndex", ")", "->", "Activation", ":", "\n", "        ", "\"\"\"Get a point by index. \"\"\"", "\n", "filename", ",", "index", "=", "self", ".", "_expand_index", "(", "idx", ")", "\n", "return", "self", ".", "activation_files", "[", "filename", "]", ".", "get_activation", "(", "\n", "index", ",", "self", ".", "standardise", ",", "self", ".", "mean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_all_point_indices": [[303, 311], ["activation_table.ActivationTable.activation_files[].get_all_activation_indices"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationObject.get_all_activation_indices"], ["", "def", "get_all_point_indices", "(", "self", ")", "->", "List", "[", "ActivationIndex", "]", ":", "\n", "        ", "\"\"\"Get all points in the table.\n        \"\"\"", "\n", "points", "=", "[", "]", "\n", "for", "act_file", "in", "self", ".", "activation_files", ":", "\n", "            ", "points", "+=", "[", "(", "act_file", ",", "x", ")", "for", "x", "in", "\n", "self", ".", "activation_files", "[", "act_file", "]", ".", "get_all_activation_indices", "(", ")", "]", "\n", "", "return", "points", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_file_name": [[312, 322], ["activation_table.ActivationTable._expand_index"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._expand_index"], ["", "def", "get_file_name", "(", "self", ",", "index", ":", "ActivationIndex", ")", "->", "str", ":", "\n", "        ", "\"\"\" Gets the filename associate with a given index.\n        \"\"\"", "\n", "act_file", ",", "index", "=", "self", ".", "_expand_index", "(", "index", ")", "\n", "\n", "try", ":", "\n", "            ", "return", "self", ".", "activation_files", "[", "act_file", "]", ".", "file_names", "[", "index", "]", "\n", "", "except", "KeyError", ":", "\n", "# some clusters ended up up logged using the file extension for some reason.", "\n", "            ", "return", "self", ".", "activation_files", "[", "act_file", "+", "\".h5\"", "]", ".", "file_names", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_image_count": [[323, 326], ["sum", "activation_table.ActivationTable.activation_files.values"], "methods", ["None"], ["", "", "def", "get_image_count", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\" returns the number of images in the table \"\"\"", "\n", "return", "sum", "(", "[", "x", ".", "image_count", "for", "x", "in", "self", ".", "activation_files", ".", "values", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._global_to_local_index": [[327, 336], ["IndexError", "activation_table._strip_h5"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table._strip_h5"], ["", "def", "_global_to_local_index", "(", "self", ",", "index", ":", "int", ")", "->", "ActivationIndex", ":", "\n", "        ", "\"\"\" convert the given index into a tuple pair as used internally. \"\"\"", "\n", "for", "a_file_key", "in", "self", ".", "activation_files", ":", "\n", "            ", "a_file", "=", "self", ".", "activation_files", "[", "a_file_key", "]", "\n", "if", "index", "<", "a_file", ".", "image_count", ":", "\n", "                ", "return", "_strip_h5", "(", "a_file_key", ")", ",", "index", "\n", "", "index", "-=", "a_file", ".", "image_count", "\n", "# should never get here", "\n", "", "raise", "IndexError", "(", "'index out of range'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._local_to_global_index": [[337, 351], ["activation_table._strip_h5", "KeyError", "activation_table._strip_h5", "pdb.set_trace", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table._strip_h5", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table._strip_h5"], ["", "def", "_local_to_global_index", "(", "self", ",", "index", ":", "ActivationIndex", ")", "->", "int", ":", "\n", "        ", "\"\"\" convert the given index tuple into a global index.\"\"\"", "\n", "local_key_full", ",", "local_index", "=", "index", "\n", "local_key", "=", "_strip_h5", "(", "local_key_full", ")", "\n", "for", "a_file_key", "in", "self", ".", "activation_files", ":", "\n", "            ", "a_base_key", "=", "_strip_h5", "(", "a_file_key", ")", "\n", "if", "len", "(", "local_key", ")", "<", "9", "or", "len", "(", "a_base_key", ")", "<", "9", ":", "\n", "                ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "if", "local_key", "==", "a_base_key", ":", "\n", "                ", "return", "local_index", "\n", "", "local_index", "+=", "self", ".", "activation_files", "[", "a_file_key", "]", ".", "image_count", "\n", "# should never get here", "\n", "", "raise", "KeyError", "(", "'invalid index tuple.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.to_local_indices": [[352, 365], ["activation_table.ActivationTable.get_image_count", "len", "len", "IndexError", "activation_table.ActivationTable._global_to_local_index"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_image_count", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._global_to_local_index"], ["", "def", "to_local_indices", "(", "self", ",", "index_list", ":", "List", "[", "int", "]", ")", "->", "List", "[", "ActivationIndex", "]", ":", "\n", "        ", "\"\"\" convert a given list of indices into local versions suitible for use in getpoint, etc\n        \"\"\"", "\n", "if", "len", "(", "index_list", ")", "==", "0", ":", "\n", "            ", "return", "[", "]", "\n", "\n", "", "image_count", "=", "self", ".", "get_image_count", "(", ")", "\n", "out_of_range", "=", "[", "x", "for", "x", "in", "index_list", "if", "x", ">", "image_count", "]", "\n", "if", "len", "(", "out_of_range", ")", ">", "0", ":", "\n", "            ", "raise", "IndexError", "(", "\n", "'One or more indices were out of range (max is {})'", ".", "format", "(", "image_count", ")", ")", "\n", "\n", "", "return", "[", "self", ".", "_global_to_local_index", "(", "x", ")", "for", "x", "in", "index_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.from_local_indices": [[366, 372], ["activation_table.ActivationTable._local_to_global_index"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._local_to_global_index"], ["", "def", "from_local_indices", "(", "\n", "self", ",", "\n", "index_list", ":", "List", "[", "ActivationIndex", "]", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\" convert a given list of local tuple indices into normal global version.\n        \"\"\"", "\n", "return", "[", "self", ".", "_local_to_global_index", "(", "x", ")", "for", "x", "in", "index_list", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._get_activations_for_neuron_old": [[373, 390], ["numpy.zeros", "activation_table.ActivationTable.activation_files.values", "kmeans.neuron.Neuron", "str", "numpy.squeeze", "activation_table.ActivationTable.get_image_count", "pdb.set_trace", "list", "activation_table.ActivationTable.activation_files.values"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_image_count"], ["", "def", "_get_activations_for_neuron_old", "(", "self", ",", "neuron", ":", "int", ")", "->", "Neuron", ":", "\n", "        ", "\"\"\" Get a list of all the activations for a given neuron, loading from an old file.\n            If your activation tables are not all the same shape, this will probably explode.\n        \"\"\"", "\n", "output_shape", "=", "list", "(", "self", ".", "activation_files", ".", "values", "(", ")", ")", "[", "\n", "0", "]", ".", "activations", ".", "shape", "[", "1", ":", "-", "1", "]", "+", "(", "self", ".", "get_image_count", "(", ")", ",", ")", "\n", "result", "=", "np", ".", "zeros", "(", "output_shape", ",", "dtype", "=", "'f'", ")", "\n", "cur_index", "=", "0", "\n", "for", "a_file", "in", "self", ".", "activation_files", ".", "values", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "result", "[", ":", ",", ":", ",", "cur_index", ":", "cur_index", "+", "\n", "a_file", ".", "image_count", "]", "=", "a_file", ".", "activations", "[", ":", "]", ".", "T", "[", "neuron", ",", ":", ",", ":", ",", ":", "]", "\n", "cur_index", "+=", "a_file", ".", "image_count", "\n", "", "except", "BaseException", ":", "\n", "                ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "return", "Neuron", "(", "str", "(", "neuron", ")", ",", "np", ".", "squeeze", "(", "result", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations_for_neuron": [[391, 414], ["numpy.zeros", "activation_table.ActivationTable.activation_files.values", "kmeans.neuron.Neuron", "print", "activation_table.ActivationTable._get_activations_for_neuron_old", "str", "numpy.squeeze", "activation_table.ActivationTable.get_image_count", "pdb.set_trace", "list", "list", "activation_table.ActivationTable.activation_files.values", "activation_table.ActivationTable.activation_files.values"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._get_activations_for_neuron_old", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_image_count"], ["", "def", "get_activations_for_neuron", "(", "self", ",", "neuron", ":", "int", ")", "->", "Neuron", ":", "\n", "        ", "\"\"\" Get a list of all the activations for a given neuron.\n            If your activation tables are not all the same shape, this will probably explode.\n        \"\"\"", "\n", "# So, the problem is that old activation files are arranged", "\n", "# image,x,y,neron, while newer ones are image,neuron,x,y", "\n", "if", "list", "(", "self", ".", "activation_files", ".", "values", "(", ")", ")", "[", "0", "]", ".", "activations", ".", "shape", "[", "-", "1", "]", ">", "1", ":", "\n", "            ", "print", "(", "\"Loading old seqence neuron\"", ")", "\n", "return", "self", ".", "_get_activations_for_neuron_old", "(", "neuron", ")", "\n", "\n", "", "output_shape", "=", "list", "(", "self", ".", "activation_files", ".", "values", "(", ")", ")", "[", "\n", "0", "]", ".", "activations", ".", "shape", "[", "2", ":", "]", "+", "(", "self", ".", "get_image_count", "(", ")", ",", ")", "\n", "result", "=", "np", ".", "zeros", "(", "output_shape", ",", "dtype", "=", "'f'", ")", "\n", "cur_index", "=", "0", "\n", "for", "a_file", "in", "self", ".", "activation_files", ".", "values", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "result", "[", ":", ",", ":", ",", "cur_index", ":", "cur_index", "+", "\n", "a_file", ".", "image_count", "]", "=", "a_file", ".", "activations", "[", ":", "]", ".", "T", "[", ":", ",", ":", ",", "neuron", ",", ":", "]", "\n", "cur_index", "+=", "a_file", ".", "image_count", "\n", "", "except", "BaseException", ":", "\n", "                ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "return", "Neuron", "(", "str", "(", "neuron", ")", ",", "np", ".", "squeeze", "(", "result", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._expand_index": [[415, 421], ["isinstance"], "methods", ["None"], ["", "def", "_expand_index", "(", "self", ",", "index", ":", "ActivationImplicitIndex", ")", "->", "ActivationIndex", ":", "\n", "        ", "\"\"\" ensures an index is in the correct tuple format. \"\"\"", "\n", "if", "isinstance", "(", "index", ",", "int", ")", ":", "\n", "            ", "return", "self", ".", "default_file", ",", "index", "\n", "\n", "", "return", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._expand_indices": [[422, 433], ["result.append", "result.append"], "methods", ["None"], ["", "def", "_expand_indices", "(", "\n", "self", ",", "\n", "indices", ":", "List", "[", "ActivationImplicitIndex", "]", ")", "->", "List", "[", "ActivationIndex", "]", ":", "\n", "        ", "\"\"\" ensures a list of indices is in the correct tuple format.\"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "index", "in", "indices", ":", "\n", "            ", "try", ":", "\n", "                ", "result", ".", "append", "(", "(", "index", "[", "0", "]", ",", "index", "[", "1", "]", ")", ")", "\n", "", "except", "TypeError", ":", "\n", "                ", "result", ".", "append", "(", "(", "self", ".", "default_file", ",", "index", ")", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._split_indices_by_file": [[434, 446], ["activation_table.ActivationTable._expand_indices", "point_lists[].append"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._expand_indices"], ["", "def", "_split_indices_by_file", "(", "\n", "self", ",", "indices", ":", "List", "[", "ActivationIndex", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", ":", "\n", "        ", "\"\"\" convert a list of (file,index) tuples into a dictionary of {file}->[indices]\n        \"\"\"", "\n", "indices", "=", "self", ".", "_expand_indices", "(", "indices", ")", "\n", "point_lists", "=", "{", "}", "\n", "for", "point_file", ",", "point_idx", "in", "indices", ":", "\n", "            ", "try", ":", "\n", "                ", "point_lists", "[", "point_file", "]", ".", "append", "(", "point_idx", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "point_lists", "[", "point_file", "]", "=", "[", "point_idx", "]", "\n", "", "", "return", "point_lists", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations": [[447, 460], ["activation_table.ActivationTable._split_indices_by_file", "activation_table.ActivationTable.activation_files[].get_activations"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable._split_indices_by_file", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_activations"], ["", "def", "get_activations", "(", "\n", "self", ",", "\n", "indices", ":", "List", "[", "ActivationImplicitIndex", "]", ")", "->", "List", "[", "Activation", "]", ":", "\n", "        ", "\"\"\"Get a list of points, by index.\n           These will either be indices or (filename,index) tuples\n        \"\"\"", "\n", "results", "=", "[", "]", "\n", "point_files", "=", "self", ".", "_split_indices_by_file", "(", "indices", ")", "\n", "for", "point_file", "in", "point_files", ":", "\n", "            ", "results", "+=", "self", ".", "activation_files", "[", "point_file", "]", ".", "get_activations", "(", "\n", "point_files", "[", "point_file", "]", ",", "self", ".", "standardise", ",", "self", ".", "mean", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_batch_indices": [[461, 473], ["activation_table.ActivationTable.activation_files[].get_batch_indices"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTable.get_batch_indices"], ["", "def", "get_batch_indices", "(", "self", ",", "batch_size", ":", "int", ",", "offset", ":", "int", "=", "0", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\" get a list of indices of batch_size elements of each label per activation_file\n            starting from offset*batch_size\n            Offset determines which batch to get.\n            e.g. with batch_size of 20 and offset 1,\n            it will return the 21st through 40th of each batch\n        \"\"\"", "\n", "results", "=", "[", "]", "\n", "for", "act_file", "in", "self", ".", "activation_files", ":", "\n", "            ", "results", "+=", "[", "(", "act_file", ",", "x", ")", "for", "x", "in", "\n", "self", ".", "activation_files", "[", "act_file", "]", ".", "get_batch_indices", "(", "batch_size", ",", "offset", ")", "]", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.__init__": [[480, 504], ["activation_table.ActivationObject.__init__", "numpy.zeros", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.fast_detk.FastDetK.__init__"], ["def", "__init__", "(", "self", ",", "index_name", ":", "str", ",", "\n", "image_count", ":", "int", ",", "\n", "neuron_count", ":", "int", ",", "\n", "labels", ":", "List", "[", "str", "]", ",", "\n", "neuron_x_count", ":", "int", "=", "8", ",", "\n", "neuron_y_count", ":", "int", "=", "8", ")", "->", "None", ":", "\n", "        ", "\"\"\" constructor.\n            image_count: number of images that will be loaded\n            neuron_count: number of neurons in the system.\n            labels: list of label names\n        \"\"\"", "\n", "ActivationObject", ".", "__init__", "(", "self", ",", "index_name", ")", "\n", "self", ".", "neuron_count", "=", "neuron_count", "\n", "self", ".", "neuron_x_count", "=", "neuron_x_count", "\n", "self", ".", "neuron_y_count", "=", "neuron_y_count", "\n", "self", ".", "image_count", "=", "image_count", "\n", "self", ".", "activations", "=", "np", ".", "zeros", "(", "\n", "(", "image_count", ",", "\n", "neuron_count", ",", "\n", "neuron_x_count", ",", "\n", "neuron_y_count", ")", ",", "\n", "dtype", "=", "'f'", ")", "\n", "self", ".", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "self", ".", "_index", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.add_activation": [[505, 538], ["activation_table.ActivationDirect.file_names.append", "isinstance", "activation_table.ActivationDirect.label_mappings.append", "activation_table.ActivationDirect.activation_labels[].append", "pdb.set_trace", "activation_values.reshape", "pdb.set_trace"], "methods", ["None"], ["", "def", "add_activation", "(", "\n", "self", ",", "\n", "activation_values", ":", "np", ".", "array", ",", "\n", "file_name", ":", "str", ",", "\n", "labels", ":", "LabelType", ")", "->", "None", ":", "\n", "        ", "\"\"\" Add a single file's activations to the table. \"\"\"", "\n", "try", ":", "\n", "            ", "self", ".", "activations", "[", "self", ".", "_index", ",", ":", "]", "=", "activation_values", "\n", "", "except", "ValueError", ":", "\n", "            ", "if", "self", ".", "neuron_x_count", "==", "1", "and", "self", ".", "neuron_y_count", "==", "1", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "activations", "[", "self", ".", "_index", ",", ":", "]", "=", "activation_values", ".", "reshape", "(", "\n", "self", ".", "neuron_count", ",", "1", ",", "1", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "import", "pdb", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "", "", "self", ".", "file_names", ".", "append", "(", "file_name", ")", "\n", "if", "isinstance", "(", "labels", ",", "str", ")", ":", "\n", "            ", "labels_list", "=", "[", "labels", "]", "\n", "", "else", ":", "\n", "            ", "labels_list", "=", "labels", "\n", "\n", "", "self", ".", "label_mappings", ".", "append", "(", "labels_list", ")", "\n", "\n", "for", "label", "in", "labels_list", ":", "\n", "            ", "try", ":", "\n", "                ", "self", ".", "activation_labels", "[", "label", "]", ".", "append", "(", "self", ".", "_index", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "self", ".", "activation_labels", "[", "label", "]", "=", "[", "self", ".", "_index", "]", "\n", "", "", "self", ".", "_index", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationDirect.save_to_hdf5": [[539, 567], ["h5_fh.create_dataset.ActivationDirect.activation_labels.keys", "x.encode", "x.encode", "h5py.File", "h5_fh.create_dataset", "h5_fh.create_dataset", "h5_fh.create_dataset", "h5_fh.create_dataset", "l.encode", "h5_fh.create_dataset"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.encode", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.encode", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation.Activation.encode"], ["", "def", "save_to_hdf5", "(", "\n", "self", ",", "\n", "file_name", ":", "str", ",", "\n", "regenerate_labels", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\" Freeze this down into a normal hdf5 file.\n            optionally generate the label list from the added activations\n        \"\"\"", "\n", "if", "regenerate_labels", ":", "\n", "            ", "self", ".", "labels", "=", "self", ".", "activation_labels", ".", "keys", "(", ")", "\n", "\n", "# prevent h5py string encoding issues", "\n", "", "self", ".", "labels", "=", "[", "x", ".", "encode", "(", "'utf8'", ")", "for", "x", "in", "self", ".", "labels", "]", "\n", "self", ".", "label_mappings", "=", "[", "[", "l", ".", "encode", "(", "'utf8'", ")", "for", "l", "in", "ls", "]", "\n", "for", "ls", "in", "self", ".", "label_mappings", "]", "\n", "self", ".", "file_names", "=", "[", "x", ".", "encode", "(", "'utf8'", ")", "for", "x", "in", "self", ".", "file_names", "]", "\n", "\n", "with", "h5py", ".", "File", "(", "file_name", ",", "'w'", ")", "as", "h5_fh", ":", "\n", "            ", "activation_table", "=", "h5_fh", ".", "create_dataset", "(", "\n", "'activations'", ",", "data", "=", "self", ".", "activations", ")", "\n", "activation_table", ".", "attrs", "[", "'image_count'", "]", "=", "self", ".", "image_count", "\n", "activation_table", ".", "attrs", "[", "'neuron_count'", "]", "=", "self", ".", "neuron_count", "\n", "h5_fh", ".", "create_dataset", "(", "'labels'", ",", "data", "=", "self", ".", "labels", ")", "\n", "h5_fh", ".", "create_dataset", "(", "'label_mappings'", ",", "data", "=", "self", ".", "label_mappings", ")", "\n", "h5_fh", ".", "create_dataset", "(", "'file_names'", ",", "data", "=", "self", ".", "file_names", ")", "\n", "for", "label", "in", "self", ".", "activation_labels", ":", "\n", "                ", "h5_fh", ".", "create_dataset", "(", "\n", "'activation_labels/{}'", ".", "format", "(", "label", ")", ",", "\n", "data", "=", "self", ".", "activation_labels", "[", "label", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table.ActivationTableFileSystem.__init__": [[573, 651], ["np.empty.ActivationTable.__init__", "print", "len", "os.walk", "print", "print", "os.listdir", "open().readline", "len", "print", "numpy.empty", "numpy.array", "numpy.empty", "os.walk", "numpy.array", "next", "len", "os.path.join", "print", "filename.endswith", "FileNotFoundError", "numpy.array", "os.walk", "open", "float", "open().readline", "file_names.append", "os.path.join", "open().readline.split", "activation_file.endswith", "float", "root.split", "label_mapping[].append", "print", "x.endswith", "open", "open().readline.split", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.fast_detk.FastDetK.__init__"], ["def", "__init__", "(", "self", ",", "target_directory", ":", "str", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\"\"\" Constructor. \"\"\"", "\n", "dir_list", "=", "next", "(", "os", ".", "walk", "(", "target_directory", ")", ")", "[", "1", "]", "\n", "print", "(", "dir_list", ")", "\n", "label_count", "=", "len", "(", "dir_list", ")", "\n", "\n", "image_count", "=", "0", "\n", "for", "root", ",", "_", ",", "files", "in", "os", ".", "walk", "(", "target_directory", ")", ":", "\n", "            ", "image_count", "+=", "len", "(", "[", "x", "for", "x", "in", "files", "if", "x", ".", "endswith", "(", "'.txt'", ")", "]", ")", "\n", "\n", "", "print", "(", "'image_count:{}'", ".", "format", "(", "image_count", ")", ")", "\n", "\n", "# pick a file, any file", "\n", "print", "(", "'looking for activations'", ")", "\n", "arbitrary_file", "=", "None", "\n", "for", "filename", "in", "os", ".", "listdir", "(", "\n", "os", ".", "path", ".", "join", "(", "\n", "target_directory", ",", "\n", "dir_list", "[", "0", "]", ")", ")", ":", "\n", "            ", "print", "(", "'is it {}?'", ".", "format", "(", "filename", ")", ")", "\n", "if", "filename", ".", "endswith", "(", "'.txt'", ")", ":", "\n", "                ", "arbitrary_file", "=", "filename", "\n", "break", "\n", "\n", "", "", "if", "arbitrary_file", "is", "None", ":", "\n", "            ", "raise", "FileNotFoundError", "(", "\"No files found to parse\"", ")", "\n", "\n", "", "activations", "=", "open", "(", "os", ".", "path", ".", "join", "(", "\n", "target_directory", ",", "dir_list", "[", "0", "]", ",", "arbitrary_file", ")", ")", ".", "readline", "(", ")", "\n", "neuron_count", "=", "len", "(", "[", "float", "(", "x", ")", "for", "x", "in", "activations", ".", "split", "(", "','", ")", "]", ")", "\n", "\n", "print", "(", "\n", "'Found {} images across {} categories activating {} neurons'", ".", "format", "(", "\n", "image_count", ",", "\n", "label_count", ",", "\n", "neuron_count", ")", ")", "\n", "\n", "activation_table", "=", "np", ".", "empty", "(", "(", "image_count", ",", "neuron_count", ")", ",", "dtype", "=", "'f'", ")", "\n", "label_table", "=", "np", ".", "array", "(", "dir_list", ")", "\n", "label_name_table", "=", "np", ".", "empty", "(", "(", "image_count", ",", ")", ",", "dtype", "=", "label_table", ".", "dtype", ")", "\n", "\n", "label_mapping", "=", "{", "}", "\n", "file_names", "=", "[", "]", "\n", "\n", "image_index", "=", "0", "\n", "for", "root", ",", "label", ",", "files", "in", "os", ".", "walk", "(", "target_directory", ")", ":", "\n", "            ", "for", "activation_file", "in", "files", ":", "\n", "                ", "if", "not", "activation_file", ".", "endswith", "(", "'.txt'", ")", ":", "\n", "                    ", "continue", "\n", "", "if", "activation_file", "==", "'labels.txt'", ":", "\n", "                    ", "continue", "\n", "", "activation_list", "=", "open", "(", "os", ".", "path", ".", "join", "(", "\n", "root", ",", "activation_file", ")", ")", ".", "readline", "(", ")", "\n", "activations", "=", "[", "float", "(", "x", ")", "for", "x", "in", "activation_list", ".", "split", "(", "','", ")", "]", "\n", "activation_table", "[", "image_index", ",", ":", "]", "=", "activations", "\n", "label", "=", "root", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "# labels.append(root.split('/')[-1])", "\n", "label_name_table", "[", "image_index", "]", "=", "label", "\n", "try", ":", "\n", "                    ", "label_mapping", "[", "label", "]", ".", "append", "(", "image_index", ")", "\n", "", "except", "KeyError", ":", "\n", "                    ", "label_mapping", "[", "label", "]", "=", "[", "image_index", "]", "\n", "", "file_names", ".", "append", "(", "activation_file", ")", "\n", "image_index", "+=", "1", "\n", "if", "(", "image_index", "%", "100", ")", "==", "0", ":", "\n", "                    ", "print", "(", "'read {} images.'", ".", "format", "(", "image_index", ")", ")", "\n", "\n", "", "", "", "self", ".", "file_names", "=", "np", ".", "array", "(", "file_names", ")", "\n", "self", ".", "activation_labels", "=", "{", "}", "\n", "for", "label", "in", "label_mapping", ":", "\n", "            ", "self", ".", "activation_labels", "[", "label", "]", "=", "np", ".", "array", "(", "label_mapping", "[", "label", "]", ")", "\n", "\n", "", "self", ".", "activations", "=", "activation_table", "\n", "self", ".", "labels", "=", "label_table", "\n", "self", ".", "label_mappings", "=", "label_name_table", "\n", "self", ".", "neuron_count", "=", "neuron_count", "\n", "self", ".", "image_count", "=", "image_count", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.activation_table._strip_h5": [[19, 24], ["value.endswith"], "function", ["None"], ["def", "_strip_h5", "(", "value", ":", "str", ")", "->", "str", ":", "\n", "    ", "\"\"\" remove trailing .h5, if present \"\"\"", "\n", "if", "value", ".", "endswith", "(", "\".h5\"", ")", ":", "\n", "        ", "value", "=", "value", "[", ":", "-", "3", "]", "\n", "", "return", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.__init__": [[28, 62], ["kmeans.KMeans._zero", "print", "kmeans.KMeans._init_from_variable", "kmeans.KMeans._init_mu_from_variable", "len", "UserWarning", "len", "kmeans.KMeans._convert_to_array", "kmeans.KMeans._init_from_file", "ValueError", "len"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._zero", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.fast_detk.FastDetK._init_from_variable", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._init_mu_from_variable", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._convert_to_array", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._init_from_file"], ["def", "__init__", "(", "self", ",", "\n", "X", ":", "input_type", "=", "None", ",", "\n", "K", ":", "int", "=", "None", ",", "\n", "filename", ":", "str", "=", "None", ",", "\n", "mu", ":", "List", "[", "np", ".", "array", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        X the data as a list of Points\n        K the number of centroids to find\n        filename - name of file to load from\n        mu is the list of centroids\n        \"\"\"", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "_zero", "(", ")", "\n", "\n", "if", "X", "is", "not", "None", ":", "\n", "            ", "self", ".", "_init_from_variable", "(", "self", ".", "_convert_to_array", "(", "X", ")", ",", "K", ")", "\n", "", "elif", "filename", "is", "not", "None", ":", "\n", "            ", "self", ".", "_init_from_file", "(", "filename", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'must specify X or filename'", ")", "\n", "\n", "", "if", "mu", "is", "not", "None", ":", "\n", "            ", "self", ".", "_init_mu_from_variable", "(", "mu", ")", "\n", "\n", "", "if", "len", "(", "self", ".", "X", ")", "==", "0", ":", "\n", "            ", "raise", "UserWarning", "(", "\"No Data Found\"", ")", "\n", "", "print", "(", "\"KMeans with {} points\"", ".", "format", "(", "len", "(", "self", ".", "X", ")", ")", ")", "\n", "if", "(", "self", ".", "X", ".", "ndim", "==", "1", ")", ":", "\n", "# X is a 1D array", "\n", "            ", "self", ".", "N", "=", "len", "(", "self", ".", "X", ")", "\n", "self", ".", "dimensions", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "N", ",", "self", ".", "dimensions", "=", "self", ".", "X", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._convert_to_array": [[63, 80], ["isinstance", "TypeError", "isinstance", "isinstance", "numpy.all", "numpy.stack", "type", "isinstance"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_convert_to_array", "(", "input", ":", "input_type", ")", "->", "np", ".", "array", ":", "\n", "        ", "\"\"\"\n        Take any of the input style options and create an appropriate numpy\n        array from them\n        :param input: the passed inputs\n        :return: a numpy array\n        \"\"\"", "\n", "if", "input", "is", "None", "or", "isinstance", "(", "input", ",", "(", "np", ".", "ndarray", ",", "np", ".", "generic", ")", ")", ":", "\n", "            ", "return", "input", "\n", "", "if", "isinstance", "(", "input", ",", "Activation", ")", ":", "\n", "            ", "return", "input", ".", "vector", "\n", "", "if", "isinstance", "(", "input", ",", "list", ")", "and", "np", ".", "all", "(", "[", "isinstance", "(", "x", ",", "Activation", ")", "for", "x", "in", "input", "]", ")", ":", "\n", "            ", "return", "np", ".", "stack", "(", "[", "a", ".", "vector", "for", "a", "in", "input", "]", ",", "0", ")", "\n", "\n", "", "raise", "TypeError", "(", "\"Invalid type {} passed to Kmeans\"", ".", "format", "(", "type", "(", "input", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._zero": [[81, 87], ["None"], "methods", ["None"], ["", "def", "_zero", "(", "self", ")", ":", "\n", "        ", "self", ".", "mu", "=", "None", "\n", "self", ".", "clusters", "=", "None", "\n", "self", ".", "oldmu", "=", "None", "\n", "self", ".", "oldermu", "=", "None", "\n", "self", ".", "method", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._init_from_variable": [[88, 91], ["None"], "methods", ["None"], ["", "def", "_init_from_variable", "(", "self", ",", "X", ",", "K", ")", ":", "\n", "        ", "self", ".", "X", "=", "X", "\n", "self", ".", "K", "=", "K", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._init_from_file": [[92, 100], ["numpy.load", "kmeans.KMeans._load", "handle[].tolist"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._load"], ["", "def", "_init_from_file", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\"\n        filename the name of a previously saved KMeans object\n        \"\"\"", "\n", "# TODO: error handlnig", "\n", "# TODO: Update to work with new class", "\n", "with", "np", ".", "load", "(", "filename", ")", "as", "handle", ":", "\n", "            ", "self", ".", "_load", "(", "handle", "[", "'data'", "]", ".", "tolist", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._init_mu_from_variable": [[101, 103], ["None"], "methods", ["None"], ["", "", "def", "_init_mu_from_variable", "(", "self", ",", "mu", ")", ":", "\n", "        ", "self", ".", "mu", "=", "mu", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._load": [[104, 109], ["None"], "methods", ["None"], ["", "def", "_load", "(", "self", ",", "filehandle", ")", ":", "\n", "        ", "self", ".", "X", "=", "filehandle", "[", "'X'", "]", "\n", "self", ".", "K", "=", "filehandle", "[", "'K'", "]", "\n", "self", ".", "mu", "=", "filehandle", "[", "'mu'", "]", "\n", "self", ".", "clusters", "=", "filehandle", "[", "'clusters'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._get_save_dictionary": [[110, 113], ["kmeans.KMeans._build_save_dictionary"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._build_save_dictionary"], ["", "def", "_get_save_dictionary", "(", "self", ")", ":", "\n", "        ", "self", ".", "_build_save_dictionary", "(", ")", "\n", "return", "self", ".", "savedic", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._build_save_dictionary": [[114, 120], ["None"], "methods", ["None"], ["", "def", "_build_save_dictionary", "(", "self", ")", ":", "\n", "        ", "self", ".", "savedic", "=", "{", "}", "\n", "self", ".", "savedic", "[", "'X'", "]", "=", "self", ".", "X", "\n", "self", ".", "savedic", "[", "'K'", "]", "=", "self", ".", "K", "\n", "self", ".", "savedic", "[", "'mu'", "]", "=", "self", ".", "mu", "\n", "self", ".", "savedic", "[", "'clusters'", "]", "=", "self", ".", "clusters", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.save": [[121, 124], ["kmeans.KMeans._build_save_dictionary", "numpy.savez"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._build_save_dictionary"], ["", "def", "save", "(", "self", ",", "filename", ")", ":", "\n", "        ", "self", ".", "_build_save_dictionary", "(", ")", "\n", "np", ".", "savez", "(", "filename", ",", "data", "=", "self", ".", "savedic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.cluster_points": [[125, 147], ["enumerate", "cluster_to_point_mapping.setdefault().append", "min", "print", "clusters[].append", "numpy.linalg.norm", "enumerate", "cluster_to_point_mapping.setdefault"], "methods", ["None"], ["", "def", "cluster_points", "(", "self", ")", ":", "\n", "# assign all the points of X to their nearest centroid.", "\n", "        ", "clusters", "=", "{", "}", "\n", "for", "i", ",", "_", "in", "enumerate", "(", "self", ".", "mu", ")", ":", "\n", "            ", "clusters", "[", "i", "]", "=", "[", "]", "\n", "\n", "", "count", "=", "0", "\n", "cluster_to_point_mapping", "=", "{", "}", "\n", "for", "x", "in", "self", ".", "X", ":", "\n", "            ", "keys", "=", "[", "(", "idx", ",", "np", ".", "linalg", ".", "norm", "(", "x", "-", "mu", ")", ")", "\n", "for", "idx", ",", "mu", "in", "enumerate", "(", "self", ".", "mu", ")", "]", "\n", "bestmukey", "=", "min", "(", "keys", ",", "key", "=", "lambda", "t", ":", "t", "[", "1", "]", ")", "[", "0", "]", "\n", "cluster_to_point_mapping", ".", "setdefault", "(", "bestmukey", ",", "[", "]", ")", ".", "append", "(", "count", ")", "\n", "if", "self", ".", "verbose", ":", "\n", "                ", "print", "(", "'Count {0}: mu {1}'", ".", "format", "(", "count", ",", "bestmukey", ")", ")", "\n", "", "count", "=", "count", "+", "1", "\n", "try", ":", "\n", "                ", "clusters", "[", "bestmukey", "]", ".", "append", "(", "x", ")", "\n", "", "except", "KeyError", ":", "\n", "                ", "clusters", "[", "bestmukey", "]", "=", "[", "x", "]", "\n", "", "", "self", ".", "clusters", "=", "clusters", "\n", "self", ".", "cluster_to_point_mapping", "=", "cluster_to_point_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._compute_new_centroids": [[148, 151], ["numpy.mean", "kmeans.KMeans.clusters.values"], "methods", ["None"], ["", "def", "_compute_new_centroids", "(", "self", ")", ":", "\n", "        ", "self", ".", "mu", "=", "[", "np", ".", "mean", "(", "x", ",", "axis", "=", "0", ")", "for", "x", "in", "self", ".", "clusters", ".", "values", "(", ")", "]", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._has_converged": [[152, 171], ["numpy.unique", "numpy.all", "len", "print", "kmeans.KMeans.cluster_points", "kmeans.KMeans._compute_new_centroids", "numpy.in1d", "range"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.cluster_points", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._compute_new_centroids"], ["", "def", "_has_converged", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "oldmu", "is", "None", ":", "\n", "# catch first run", "\n", "            ", "return", "False", "\n", "\n", "", "self", ".", "mu", "=", "np", ".", "unique", "(", "self", ".", "mu", ",", "axis", "=", "0", ")", "\n", "# Catch issues with individual MUs converging.", "\n", "if", "len", "(", "self", ".", "mu", ")", "<", "self", ".", "K", ":", "\n", "            ", "print", "(", "\"Two centroids converged! Ending\"", ")", "\n", "# this set of MU is useless. use the previous.", "\n", "self", ".", "mu", "=", "self", ".", "oldmu", "\n", "self", ".", "cluster_points", "(", ")", "\n", "self", ".", "_compute_new_centroids", "(", ")", "\n", "return", "True", "\n", "\n", "# make numpy treat the rows as items", "\n", "", "dtype", "=", "{", "'names'", ":", "[", "'f{}'", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "self", ".", "dimensions", ")", "]", ",", "\n", "'formats'", ":", "self", ".", "N", "*", "[", "self", ".", "mu", ".", "dtype", "]", "}", "\n", "return", "np", ".", "all", "(", "np", ".", "in1d", "(", "self", ".", "oldmu", ",", "self", ".", "mu", ",", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.init_centers": [[172, 175], ["numpy.random.choice"], "methods", ["None"], ["", "def", "init_centers", "(", "self", ")", ":", "\n", "# pick a set of random points to use as the initial K values", "\n", "        ", "self", ".", "mu", "=", "self", ".", "X", "[", "np", ".", "random", ".", "choice", "(", "self", ".", "N", ",", "self", ".", "K", ",", "replace", "=", "False", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.find_centers": [[176, 182], ["kmeans.KMeans.init_centers", "kmeans.KMeans._has_converged", "kmeans.KMeans.cluster_points", "kmeans.KMeans._compute_new_centroids"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.init_centers", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._has_converged", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans.cluster_points", "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.kmeans.KMeans._compute_new_centroids"], ["", "def", "find_centers", "(", "self", ")", ":", "\n", "        ", "self", ".", "init_centers", "(", ")", "\n", "while", "not", "self", ".", "_has_converged", "(", ")", ":", "\n", "            ", "self", ".", "oldmu", "=", "self", ".", "mu", "\n", "self", ".", "cluster_points", "(", ")", "\n", "self", ".", "_compute_new_centroids", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.fast_detk.FastDetK.__init__": [[18, 32], ["kmeans.detk.DetK.__init__"], "methods", ["home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.fast_detk.FastDetK.__init__"], ["def", "__init__", "(", "self", ",", "\n", "X", ":", "input_type", "=", "None", ",", "\n", "filename", ":", "str", "=", "None", ",", "\n", "mu", ":", "List", "[", "np", ".", "array", "]", "=", "None", ",", "\n", "discard", ":", "float", "=", "1", ",", "\n", "verbose", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        X the data as a list of Points\n        filename - name of file to load from\n        mu is the list of centroids\n        discard is the fractional range of X to discard\n        \"\"\"", "\n", "self", ".", "discard", "=", "discard", "\n", "DetK", ".", "__init__", "(", "self", ",", "X", ",", "None", ",", "filename", ",", "mu", ",", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ellagale_testing_object_detectors_in_deepCNNs.kmeans.fast_detk.FastDetK._init_from_variable": [[33, 50], ["max", "min", "compressed_X.sum.sum.sum"], "methods", ["None"], ["", "def", "_init_from_variable", "(", "self", ",", "X", ",", "K", ")", ":", "\n", "        ", "\"\"\"We only take the values of X which are above discard*full range\"\"\"", "\n", "# Need to compress a (potentially multidimensional array down to a 1D", "\n", "# of the size of it", "\n", "remaining_dim", "=", "X", ".", "ndim", "\n", "compressed_X", "=", "X", "\n", "while", "remaining_dim", ">", "1", ":", "\n", "            ", "compressed_X", "=", "compressed_X", ".", "sum", "(", "axis", "=", "-", "1", ")", "\n", "remaining_dim", "-=", "1", "\n", "", "maxX", "=", "max", "(", "compressed_X", ")", "\n", "minX", "=", "min", "(", "compressed_X", ")", "\n", "midX", "=", "minX", "+", "(", "maxX", "-", "minX", ")", "*", "self", ".", "discard", "\n", "self", ".", "maxX", "=", "maxX", "\n", "self", ".", "minX", "=", "minX", "\n", "self", ".", "midX", "=", "midX", "\n", "self", ".", "X", "=", "X", "[", "compressed_X", ">", "midX", "]", "\n", "self", ".", "K", "=", "K", "\n", "# def _convert_to_array(input: input_type):", "\n"]]}