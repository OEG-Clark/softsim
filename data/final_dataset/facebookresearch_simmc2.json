{"home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.disambiguator_evaluation.evaluate_disambiguation": [[28, 62], ["print", "print", "numpy.mean", "predictions.append", "open", "json.dump", "numpy.std", "numpy.sqrt", "len", "len"], "function", ["None"], ["def", "evaluate_disambiguation", "(", "gt_labels", ",", "model_results", ",", "record_instance_results", "=", "None", ")", ":", "\n", "    ", "\"\"\"Evaluates disambiguation using golden labels and model predictions.\n\n    Args:\n        gt_labels: Ground truth labels.\n        model_results: Generated labels.\n        record_instance_results: Path to save instance-level metrics.\n    \"\"\"", "\n", "gt_label_pool", "=", "{", "ii", "[", "\"dialogue_idx\"", "]", ":", "ii", "for", "ii", "in", "gt_labels", "[", "\"dialogue_data\"", "]", "}", "\n", "\n", "predictions", "=", "[", "]", "\n", "num_evaluations", "=", "0", "\n", "for", "model_datum", "in", "model_results", ":", "\n", "        ", "dialog_id", "=", "model_datum", "[", "\"dialog_id\"", "]", "\n", "for", "round_datum", "in", "model_datum", "[", "\"predictions\"", "]", ":", "\n", "            ", "round_id", "=", "round_datum", "[", "\"turn_id\"", "]", "\n", "predicted_label", "=", "round_datum", "[", "\"disambiguation_label\"", "]", "\n", "gt_datum", "=", "gt_label_pool", "[", "dialog_id", "]", "[", "\"dialogue\"", "]", "[", "round_id", "]", "\n", "\n", "assert", "\"disambiguation_label\"", "in", "gt_datum", ",", "\"Turn not to be evaluated!\"", "\n", "gt_label", "=", "gt_datum", "[", "\"disambiguation_label\"", "]", "\n", "predictions", ".", "append", "(", "gt_label", "==", "predicted_label", ")", "\n", "\n", "# Add the result to datum and save it back.", "\n", "if", "record_instance_results", ":", "\n", "                ", "round_datum", "[", "\"disambiguation_accuracy\"", "]", "=", "gt_label", "==", "predicted_label", "\n", "\n", "", "", "", "print", "(", "f\"# Instances evaluated: {len(predictions)}\"", ")", "\n", "# Record and save per instance results.", "\n", "if", "record_instance_results", ":", "\n", "        ", "print", "(", "\"Saving per instance result: {}\"", ".", "format", "(", "record_instance_results", ")", ")", "\n", "with", "open", "(", "record_instance_results", ",", "\"w\"", ")", "as", "file_id", ":", "\n", "            ", "json", ".", "dump", "(", "model_results", ",", "file_id", ")", "\n", "", "", "return", "np", ".", "mean", "(", "predictions", ")", ",", "np", ".", "std", "(", "predictions", ")", "/", "np", ".", "sqrt", "(", "len", "(", "predictions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.disambiguator_evaluation.main": [[64, 83], ["print", "print", "disambiguator_evaluation.evaluate_disambiguation", "print", "open", "json.load", "open", "json.load", "args[].replace"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.disambiguator_evaluation.evaluate_disambiguation"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "print", "(", "\"Reading: {}\"", ".", "format", "(", "args", "[", "\"data_json_path\"", "]", ")", ")", "\n", "with", "open", "(", "args", "[", "\"data_json_path\"", "]", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "        ", "gt_labels", "=", "json", ".", "load", "(", "file_id", ")", "\n", "", "print", "(", "\"Reading: {}\"", ".", "format", "(", "args", "[", "\"model_result_path\"", "]", ")", ")", "\n", "with", "open", "(", "args", "[", "\"model_result_path\"", "]", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "        ", "model_results", "=", "json", ".", "load", "(", "file_id", ")", "\n", "\n", "", "if", "args", "[", "\"record_instance_results\"", "]", ":", "\n", "        ", "instance_results_path", "=", "args", "[", "\"model_result_path\"", "]", ".", "replace", "(", "\n", "\".json\"", ",", "\"_results.json\"", "\n", ")", "\n", "", "else", ":", "\n", "        ", "instance_results_path", "=", "None", "\n", "\n", "", "accuracy", ",", "accuracy_std_err", "=", "evaluate_disambiguation", "(", "\n", "gt_labels", ",", "model_results", ",", "record_instance_results", "=", "instance_results_path", "\n", ")", "\n", "print", "(", "f\"Disambiguation Accuracy: {accuracy:.3f} +- {accuracy_std_err:.3f}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.retrieval_evaluation.evaluate_response_retrieval": [[29, 74], ["numpy.array", "print", "len", "enumerate", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "np.array.append", "numpy.std", "numpy.sqrt", "numpy.std", "numpy.sqrt", "numpy.std", "numpy.sqrt", "numpy.std", "numpy.sqrt", "numpy.std", "numpy.sqrt", "numpy.sum", "numpy.array"], "function", ["None"], ["def", "evaluate_response_retrieval", "(", "gt_responses", ",", "model_scores", ",", "single_round_eval", "=", "False", ")", ":", "\n", "    ", "\"\"\"Evaluates response retrieval using the raw data and model predictions.\n\n    Args:\n        gt_responses: Ground truth responses.\n        model_scores: Scores assigned by the model to the candidates.\n        single_round_eval: Evaluate only for the last turn.\n\n    If in single round evaluation model (mostly for hidden test-std split),\n    use hidden gt_index field. Else, 0th element is the ground truth for other\n    splits.\n    \"\"\"", "\n", "gt_index_pool", "=", "{", "\n", "ii", "[", "\"dialogue_idx\"", "]", ":", "ii", "for", "ii", "in", "gt_responses", "[", "\"retrieval_candidates\"", "]", "\n", "}", "\n", "gt_ranks", "=", "[", "]", "\n", "for", "model_datum", "in", "model_scores", ":", "\n", "        ", "dialog_id", "=", "model_datum", "[", "\"dialog_id\"", "]", "\n", "gt_datum", "=", "gt_index_pool", "[", "dialog_id", "]", "[", "\"retrieval_candidates\"", "]", "\n", "num_gt_rounds", "=", "len", "(", "gt_datum", ")", "\n", "for", "round_id", ",", "round_datum", "in", "enumerate", "(", "model_datum", "[", "\"candidate_scores\"", "]", ")", ":", "\n", "            ", "round_id", "=", "round_datum", "[", "\"turn_id\"", "]", "\n", "# Skip if single_round_eval and this is not the last round.", "\n", "if", "single_round_eval", "and", "round_id", "!=", "num_gt_rounds", "-", "1", ":", "\n", "                ", "continue", "\n", "\n", "", "gt_index", "=", "gt_datum", "[", "round_id", "]", "[", "\"gt_index\"", "]", "\n", "current_turn", "=", "round_datum", "[", "\"turn_id\"", "]", "\n", "round_scores", "=", "round_datum", "[", "\"scores\"", "]", "\n", "gt_score", "=", "round_scores", "[", "gt_index", "]", "\n", "gt_ranks", ".", "append", "(", "np", ".", "sum", "(", "np", ".", "array", "(", "round_scores", ")", ">", "gt_score", ")", "+", "1", ")", "\n", "", "", "gt_ranks", "=", "np", ".", "array", "(", "gt_ranks", ")", "\n", "print", "(", "\"#Instances evaluated retrieval: {}\"", ".", "format", "(", "gt_ranks", ".", "size", ")", ")", "\n", "\n", "return", "{", "\n", "\"r1\"", ":", "np", ".", "mean", "(", "gt_ranks", "<=", "1", ")", ",", "\n", "\"r1_std_err\"", ":", "np", ".", "std", "(", "gt_ranks", "<=", "1", ")", "/", "np", ".", "sqrt", "(", "gt_ranks", ".", "size", ")", ",", "\n", "\"r5\"", ":", "np", ".", "mean", "(", "gt_ranks", "<=", "5", ")", ",", "\n", "\"r5_std_err\"", ":", "np", ".", "std", "(", "gt_ranks", "<=", "5", ")", "/", "np", ".", "sqrt", "(", "gt_ranks", ".", "size", ")", ",", "\n", "\"r10\"", ":", "np", ".", "mean", "(", "gt_ranks", "<=", "10", ")", ",", "\n", "\"r10_std_err\"", ":", "np", ".", "std", "(", "gt_ranks", "<=", "10", ")", "/", "np", ".", "sqrt", "(", "gt_ranks", ".", "size", ")", ",", "\n", "\"mean\"", ":", "np", ".", "mean", "(", "gt_ranks", ")", ",", "\n", "\"mean_std_err\"", ":", "np", ".", "std", "(", "gt_ranks", ")", "/", "np", ".", "sqrt", "(", "gt_ranks", ".", "size", ")", ",", "\n", "\"mrr\"", ":", "np", ".", "mean", "(", "1", "/", "gt_ranks", ")", ",", "\n", "\"mrr_std_err\"", ":", "np", ".", "std", "(", "1", "/", "gt_ranks", ")", "/", "np", ".", "sqrt", "(", "gt_ranks", ".", "size", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.retrieval_evaluation.main": [[77, 88], ["print", "print", "retrieval_evaluation.evaluate_response_retrieval", "print", "open", "json.load", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.retrieval_evaluation.evaluate_response_retrieval"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "print", "(", "\"Reading: {}\"", ".", "format", "(", "args", "[", "\"retrieval_json_path\"", "]", ")", ")", "\n", "with", "open", "(", "args", "[", "\"retrieval_json_path\"", "]", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "        ", "gt_responses", "=", "json", ".", "load", "(", "file_id", ")", "\n", "", "print", "(", "\"Reading: {}\"", ".", "format", "(", "args", "[", "\"model_score_path\"", "]", ")", ")", "\n", "with", "open", "(", "args", "[", "\"model_score_path\"", "]", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "        ", "model_scores", "=", "json", ".", "load", "(", "file_id", ")", "\n", "", "retrieval_metrics", "=", "evaluate_response_retrieval", "(", "\n", "gt_responses", ",", "model_scores", ",", "args", "[", "\"single_round_evaluation\"", "]", "\n", ")", "\n", "print", "(", "retrieval_metrics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.visualize_bboxes.draw_bboxes": [[24, 68], ["PIL.Image.open", "PIL.ImageDraw.Draw", "PIL.ImageFont.load_default", "enumerate", "Image.open.save", "bbox_datum.get", "ImageDraw.Draw.rectangle", "str", "ImageFont.load_default.getsize", "ImageDraw.Draw.rectangle", "ImageDraw.Draw.text", "print", "str"], "function", ["None"], ["def", "draw_bboxes", "(", "bboxes", ",", "load_path", ",", "save_path", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "\"\"\"Draw bounding boxes given the screenpath and list of bboxes.\n\n    Args:\n        bboxes: List of all bounding boxes\n        load_path: Path to load the screenshot\n        save_path: Path to save the screenshot with bounding boxes\n        verbose: Print out status statements\n    \"\"\"", "\n", "# Read images and draw rectangles.", "\n", "image", "=", "Image", ".", "open", "(", "load_path", ")", "\n", "draw", "=", "ImageDraw", ".", "Draw", "(", "image", ")", "\n", "# Get a font.", "\n", "font", "=", "ImageFont", ".", "load_default", "(", ")", "\n", "# font = ImageFont.truetype(\"arial.ttf\", size=20)", "\n", "offset", "=", "2", "\n", "for", "index", ",", "bbox_datum", "in", "enumerate", "(", "bboxes", ")", ":", "\n", "        ", "object_index", "=", "bbox_datum", ".", "get", "(", "\"index\"", ",", "index", ")", "\n", "verts", "=", "bbox_datum", "[", "\"bbox\"", "]", "\n", "draw", ".", "rectangle", "(", "\n", "[", "(", "verts", "[", "0", "]", ",", "verts", "[", "1", "]", ")", ",", "(", "verts", "[", "0", "]", "+", "verts", "[", "3", "]", ",", "verts", "[", "1", "]", "+", "verts", "[", "2", "]", ")", "]", "\n", ")", "\n", "# Draw text with black background.", "\n", "text", "=", "str", "(", "object_index", ")", "\n", "text_width", ",", "text_height", "=", "font", ".", "getsize", "(", "text", ")", "\n", "draw", ".", "rectangle", "(", "\n", "(", "\n", "verts", "[", "0", "]", "+", "offset", ",", "\n", "verts", "[", "1", "]", "+", "offset", ",", "\n", "verts", "[", "0", "]", "+", "2", "*", "offset", "+", "text_width", ",", "\n", "verts", "[", "1", "]", "+", "2", "*", "offset", "+", "text_height", ",", "\n", ")", ",", "\n", "fill", "=", "\"black\"", ",", "\n", ")", "\n", "draw", ".", "text", "(", "\n", "(", "verts", "[", "0", "]", "+", "offset", ",", "verts", "[", "1", "]", "+", "offset", ")", ",", "\n", "str", "(", "object_index", ")", ",", "# str(index)", "\n", "fill", "=", "(", "255", ",", "255", ",", "255", ")", ",", "\n", "font", "=", "font", ",", "\n", ")", "\n", "# Save the image with bbox drawn.", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Saving: {}\"", ".", "format", "(", "save_path", ")", ")", "\n", "", "image", ".", "save", "(", "save_path", ",", "\"PNG\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.visualize_bboxes.get_screenshot_save_path": [[70, 73], ["screenshot_path.rsplit"], "function", ["None"], ["", "def", "get_screenshot_save_path", "(", "screenshot_path", ")", ":", "\n", "    ", "file_name", ",", "extension", "=", "screenshot_path", ".", "rsplit", "(", "\".\"", ",", "1", ")", "\n", "return", "\"{}_bbox_draw.{}\"", ".", "format", "(", "file_name", ",", "extension", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.visualize_bboxes.main": [[75, 108], ["print", "print", "tqdm.tqdm", "list", "list.remove", "os.path.join", "os.path.join", "os.path.join", "visualize_bboxes.draw_bboxes", "set", "os.path.exists", "os.path.join", "os.path.exists", "open", "json.load", "ii.rsplit", "os.listdir"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.visualize_bboxes.draw_bboxes"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "if", "args", "[", "\"scene_names\"", "]", "==", "\"all\"", ":", "\n", "# Get all the scene names in the folder.", "\n", "        ", "scene_names", "=", "[", "\n", "ii", ".", "rsplit", "(", "\"_\"", ",", "1", ")", "[", "0", "]", "for", "ii", "in", "os", ".", "listdir", "(", "args", "[", "\"scene_json_root\"", "]", ")", "\n", "]", "\n", "scene_names", "=", "list", "(", "set", "(", "scene_names", ")", ")", "\n", "# Remove explore.py.", "\n", "scene_names", ".", "remove", "(", "\"explore.py\"", ")", "\n", "", "else", ":", "\n", "        ", "scene_names", "=", "args", "[", "\"scene_names\"", "]", "\n", "\n", "", "print", "(", "f\"\"\"Reading scene JSONS: {args[\"scene_json_root\"]}\"\"\"", ")", "\n", "print", "(", "f\"\"\"Reading scene screenshots: {args[\"screenshot_root\"]}\"\"\"", ")", "\n", "for", "scene", "in", "progressbar", "(", "scene_names", ")", ":", "\n", "        ", "json_path", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"scene_json_root\"", "]", ",", "f\"{scene}_scene.json\"", ")", "\n", "# Check if file exists, else try with \"m_\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "json_path", ")", ":", "\n", "            ", "json_path", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"scene_json_root\"", "]", ",", "f\"m_{scene}_scene.json\"", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "json_path", ")", ",", "f\"{json_path} not found!\"", "\n", "", "with", "open", "(", "json_path", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "            ", "scene_json", "=", "json", ".", "load", "(", "file_id", ")", "\n", "", "object_bboxes", "=", "scene_json", "[", "\"scenes\"", "]", "[", "0", "]", "[", "\"objects\"", "]", "\n", "\n", "# Image load and save paths.", "\n", "trimmed_scene_name", "=", "scene", "[", "2", ":", "]", "if", "scene", "[", ":", "2", "]", "==", "\"m_\"", "else", "scene", "\n", "screenshot_load_path", "=", "os", ".", "path", ".", "join", "(", "\n", "args", "[", "\"screenshot_root\"", "]", ",", "f\"{trimmed_scene_name}.png\"", "\n", ")", "\n", "screenshot_save_path", "=", "os", ".", "path", ".", "join", "(", "\n", "args", "[", "\"save_root\"", "]", ",", "f\"{trimmed_scene_name}_bbox.png\"", "\n", ")", "\n", "draw_bboxes", "(", "object_bboxes", ",", "screenshot_load_path", ",", "screenshot_save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.response_evaluation.normalize_sentence": [[29, 32], ["nltk.tokenize.word_tokenize", "sentence.lower"], "function", ["None"], ["def", "normalize_sentence", "(", "sentence", ")", ":", "\n", "    ", "\"\"\"Normalize the sentences and tokenize.\"\"\"", "\n", "return", "nltk", ".", "tokenize", ".", "word_tokenize", "(", "sentence", ".", "lower", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.response_evaluation.evaluate_response_generation": [[34, 85], ["nltk.translate.bleu_score.SmoothingFunction", "print", "numpy.mean", "len", "print", "numpy.std", "numpy.sqrt", "nltk.translate.bleu_score.sentence_bleu", "bleu_scores.append", "len", "open", "json.dump", "len", "response_evaluation.normalize_sentence", "len", "response_evaluation.normalize_sentence", "response_evaluation.normalize_sentence"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.evaluate_response.normalize_sentence", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.evaluate_response.normalize_sentence", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.evaluate_response.normalize_sentence"], ["", "def", "evaluate_response_generation", "(", "\n", "gt_responses", ",", "\n", "model_responses", ",", "\n", "single_round_eval", "=", "False", ",", "\n", "record_instance_results", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Evaluates response generation using the raw data and model predictions.\n\n    Args:\n        gt_responses: Ground truth responses.\n        model_responses: Generated responses.\n        single_round_eval: Evaluate only for the last turn.\n        record_instance_results: Save path for instance level metrics.\n    \"\"\"", "\n", "gt_responses_pool", "=", "{", "ii", "[", "\"dialogue_idx\"", "]", ":", "ii", "for", "ii", "in", "gt_responses", "[", "\"dialogue_data\"", "]", "}", "\n", "bleu_scores", "=", "[", "]", "\n", "# Smoothing function.", "\n", "chencherry", "=", "nltk", ".", "translate", ".", "bleu_score", ".", "SmoothingFunction", "(", ")", "\n", "num_evaluations", "=", "0", "\n", "for", "model_datum", "in", "model_responses", ":", "\n", "        ", "dialog_id", "=", "model_datum", "[", "\"dialog_id\"", "]", "\n", "num_gt_rounds", "=", "len", "(", "gt_responses_pool", "[", "dialog_id", "]", "[", "\"dialogue\"", "]", ")", "\n", "for", "round_datum", "in", "model_datum", "[", "\"predictions\"", "]", ":", "\n", "            ", "round_id", "=", "round_datum", "[", "\"turn_id\"", "]", "\n", "# Skip if single_round_eval and this is not the last round.", "\n", "if", "single_round_eval", "and", "round_id", "!=", "num_gt_rounds", "-", "1", ":", "\n", "                ", "continue", "\n", "\n", "", "response", "=", "round_datum", "[", "\"response\"", "]", "\n", "gt_datum", "=", "gt_responses_pool", "[", "dialog_id", "]", "[", "\"dialogue\"", "]", "[", "round_id", "]", "\n", "gt_response", "=", "gt_datum", "[", "\"system_transcript\"", "]", "\n", "bleu_score", "=", "nltk", ".", "translate", ".", "bleu_score", ".", "sentence_bleu", "(", "\n", "[", "normalize_sentence", "(", "gt_response", ")", "]", ",", "\n", "normalize_sentence", "(", "response", ")", ",", "\n", "smoothing_function", "=", "chencherry", ".", "method7", ",", "\n", ")", "\n", "bleu_scores", ".", "append", "(", "bleu_score", ")", "\n", "\n", "# Add the result to datum and save it back.", "\n", "if", "record_instance_results", ":", "\n", "                ", "round_datum", "[", "\"bleu\"", "]", "=", "bleu_score", "\n", "round_datum", "[", "\"response_len\"", "]", "=", "len", "(", "normalize_sentence", "(", "gt_response", ")", ")", "\n", "", "", "", "print", "(", "\"#Instances evaluated BLEU: {}\"", ".", "format", "(", "len", "(", "bleu_scores", ")", ")", ")", "\n", "if", "record_instance_results", ":", "\n", "        ", "print", "(", "f\"Saving per instance results: {record_instance_results}\"", ")", "\n", "with", "open", "(", "record_instance_results", ",", "\"w\"", ")", "as", "file_id", ":", "\n", "            ", "json", ".", "dump", "(", "model_responses", ",", "file_id", ")", "\n", "\n", "", "", "bleu_str_mean", "=", "np", ".", "mean", "(", "bleu_scores", ")", "\n", "bleu_str_err", "=", "np", ".", "std", "(", "bleu_scores", ")", "/", "np", ".", "sqrt", "(", "len", "(", "bleu_scores", ")", ")", "\n", "return", "bleu_str_mean", ",", "bleu_str_err", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.response_evaluation.main": [[87, 109], ["print", "print", "response_evaluation.evaluate_response_generation", "print", "open", "json.load", "open", "json.load", "args[].replace"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.response_evaluation.evaluate_response_generation"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "print", "(", "\"Reading: {}\"", ".", "format", "(", "args", "[", "\"data_json_path\"", "]", ")", ")", "\n", "with", "open", "(", "args", "[", "\"data_json_path\"", "]", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "        ", "gt_responses", "=", "json", ".", "load", "(", "file_id", ")", "\n", "", "print", "(", "\"Reading: {}\"", ".", "format", "(", "args", "[", "\"model_response_path\"", "]", ")", ")", "\n", "with", "open", "(", "args", "[", "\"model_response_path\"", "]", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "        ", "model_responses", "=", "json", ".", "load", "(", "file_id", ")", "\n", "\n", "", "if", "args", "[", "\"record_instance_results\"", "]", ":", "\n", "        ", "instance_results_path", "=", "args", "[", "\"model_response_path\"", "]", ".", "replace", "(", "\n", "\".json\"", ",", "\"_results.json\"", "\n", ")", "\n", "", "else", ":", "\n", "        ", "instance_results_path", "=", "None", "\n", "\n", "", "bleu_score", ",", "bleu_std_err", "=", "evaluate_response_generation", "(", "\n", "gt_responses", ",", "\n", "model_responses", ",", "\n", "args", "[", "\"single_round_evaluation\"", "]", ",", "\n", "instance_results_path", ",", "\n", ")", "\n", "print", "(", "f\"BLEU Score: {bleu_score:.4f} +- {bleu_std_err}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.evaluate_from_json": [[19, 72], ["range", "evaluate_dst.evaluate_from_flat_list", "len", "range", "len", "evaluate_dst.reformat_turn", "evaluate_dst.reformat_turn", "d_true_flattened.append", "d_pred_flattened.append"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.evaluate_from_flat_list", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.reformat_turn", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.reformat_turn"], ["def", "evaluate_from_json", "(", "d_true", ",", "d_pred", ")", ":", "\n", "    ", "\"\"\"\n    <list>d_true and <list>d_pred are in the following format:\n    (Equivalent to \"dialogue_data\" field in the input data JSON file)\n    [\n        {\n            \"dialogue\": [\n                {\n                    \"transcript_annotated\":  {\n                        'act': <str>,\n                        'act_attributes': {\n                            'slot_values': {\n                                SLOT_NAME: SLOT_VALUE,\n                                ...\n                            },\n                            'request_slots': [\n                                SLOT_NAME, ...\n                            ],\n                            'objects': [ <int> ],\n                            'disambiguation_candidates': [ <int> ]\n                        }\n                    },\n                    ...\n                }\n                [End of a turn]\n                ...\n            ],\n        }\n        [End of a dialogue]\n        ...\n    ]\n    \"\"\"", "\n", "d_true_flattened", "=", "[", "]", "\n", "d_pred_flattened", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "d_true", ")", ")", ":", "\n", "# Iterate through each dialog", "\n", "        ", "dialog_true", "=", "d_true", "[", "i", "]", "[", "\"dialogue\"", "]", "\n", "dialog_pred", "=", "d_pred", "[", "i", "]", "[", "\"dialogue\"", "]", "\n", "\n", "# ** Assumes dialogue_idx and turn_idx are ordered", "\n", "# exactly the same for `dialog_true` and `dialog_pred`", "\n", "_", "=", "d_true", "[", "i", "]", "[", "\"dialogue_idx\"", "]", "\n", "\n", "for", "j", "in", "range", "(", "len", "(", "dialog_true", ")", ")", ":", "\n", "# Iterate through each turn", "\n", "            ", "turn_true", "=", "reformat_turn", "(", "dialog_true", "[", "j", "]", "[", "\"transcript_annotated\"", "]", ")", "\n", "turn_pred", "=", "reformat_turn", "(", "dialog_pred", "[", "j", "]", "[", "\"transcript_annotated\"", "]", ")", "\n", "\n", "d_true_flattened", ".", "append", "(", "turn_true", ")", "\n", "d_pred_flattened", ".", "append", "(", "turn_pred", ")", "\n", "\n", "", "", "return", "evaluate_from_flat_list", "(", "d_true_flattened", ",", "d_pred_flattened", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.reformat_turn": [[74, 83], ["t.get", "[].items"], "function", ["None"], ["", "def", "reformat_turn", "(", "t", ")", ":", "\n", "    ", "frame", "=", "{", "\n", "'act'", ":", "t", "[", "'act'", "]", ",", "\n", "'slots'", ":", "[", "[", "s", ",", "v", "]", "for", "s", ",", "v", "in", "t", "[", "'act_attributes'", "]", "[", "'slot_values'", "]", ".", "items", "(", ")", "]", ",", "\n", "'request_slots'", ":", "t", "[", "'act_attributes'", "]", "[", "'request_slots'", "]", ",", "\n", "'objects'", ":", "t", "[", "'act_attributes'", "]", "[", "'objects'", "]", ",", "\n", "'disambiguation_candidates'", ":", "t", ".", "get", "(", "'disambiguation_candidates'", ",", "[", "]", ")", "\n", "}", "\n", "return", "[", "frame", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.evaluate_from_flat_list": [[85, 192], ["evaluate_dst.initialize_count_dict", "range", "evaluate_dst.rec_prec_f1", "evaluate_dst.rec_prec_f1", "evaluate_dst.rec_prec_f1", "evaluate_dst.rec_prec_f1", "evaluate_dst.rec_prec_f1", "evaluate_dst.d_f1", "evaluate_dst.d_f1", "evaluate_dst.d_f1", "evaluate_dst.d_f1", "evaluate_dst.d_f1", "len", "evaluate_dst.evaluate_turn", "evaluate_dst.add_dicts"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.initialize_count_dict", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.rec_prec_f1", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.rec_prec_f1", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.rec_prec_f1", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.rec_prec_f1", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.rec_prec_f1", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.d_f1", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.d_f1", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.d_f1", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.d_f1", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.d_f1", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.evaluate_turn", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.add_dicts"], ["", "def", "evaluate_from_flat_list", "(", "d_true", ",", "d_pred", ")", ":", "\n", "    ", "\"\"\"\n    <list>d_true and <list>d_pred are in the following format:\n    (Each element represents a single turn, with (multiple) frames)\n    [\n        [\n            {\n                'act': <str>,\n                'slots': [\n                    [\n                        SLOT_NAME, SLOT_VALUE\n                    ],\n                    ...\n                ],\n                'request_slots': [ SLOT_NAME, ... ],\n                'objects': [ <int> ],\n                'disambiguation_candidates': [ <int> ]\n            },\n            [End of a frame]\n            ...\n        ],\n        [End of a turn]\n        ...\n    ]\n    \"\"\"", "\n", "c", "=", "initialize_count_dict", "(", ")", "\n", "\n", "# Count # corrects & # wrongs", "\n", "for", "i", "in", "range", "(", "len", "(", "d_true", ")", ")", ":", "\n", "        ", "true_turn", "=", "d_true", "[", "i", "]", "\n", "pred_turn", "=", "d_pred", "[", "i", "]", "\n", "turn_evaluation", "=", "evaluate_turn", "(", "true_turn", ",", "pred_turn", ")", "\n", "\n", "c", "=", "add_dicts", "(", "c", ",", "turn_evaluation", ")", "\n", "\n", "# Calculate metrics", "\n", "", "joint_accuracy", "=", "c", "[", "\"n_correct_beliefs\"", "]", "/", "c", "[", "\"n_frames\"", "]", "\n", "\n", "act_rec", ",", "act_prec", ",", "act_f1", "=", "rec_prec_f1", "(", "\n", "n_correct", "=", "c", "[", "\"n_correct_acts\"", "]", ",", "n_true", "=", "c", "[", "\"n_true_acts\"", "]", ",", "n_pred", "=", "c", "[", "\"n_pred_acts\"", "]", "\n", ")", "\n", "\n", "slot_rec", ",", "slot_prec", ",", "slot_f1", "=", "rec_prec_f1", "(", "\n", "n_correct", "=", "c", "[", "\"n_correct_slots\"", "]", ",", "\n", "n_true", "=", "c", "[", "\"n_true_slots\"", "]", ",", "\n", "n_pred", "=", "c", "[", "\"n_pred_slots\"", "]", ",", "\n", ")", "\n", "\n", "request_slot_rec", ",", "request_slot_prec", ",", "request_slot_f1", "=", "rec_prec_f1", "(", "\n", "n_correct", "=", "c", "[", "\"n_correct_request_slots\"", "]", ",", "\n", "n_true", "=", "c", "[", "\"n_true_request_slots\"", "]", ",", "\n", "n_pred", "=", "c", "[", "\"n_pred_request_slots\"", "]", ",", "\n", ")", "\n", "\n", "object_rec", ",", "object_prec", ",", "object_f1", "=", "rec_prec_f1", "(", "\n", "n_correct", "=", "c", "[", "\"n_correct_objects\"", "]", ",", "\n", "n_true", "=", "c", "[", "\"n_true_objects\"", "]", ",", "\n", "n_pred", "=", "c", "[", "\"n_pred_objects\"", "]", ",", "\n", ")", "\n", "\n", "disamb_candidate_rec", ",", "disamb_candidate_prec", ",", "disamb_candidate_f1", "=", "rec_prec_f1", "(", "\n", "n_correct", "=", "c", "[", "\"n_correct_disamb_candidates\"", "]", ",", "\n", "n_true", "=", "c", "[", "\"n_true_disamb_candidates\"", "]", ",", "\n", "n_pred", "=", "c", "[", "\"n_pred_disamb_candidates\"", "]", ",", "\n", ")", "\n", "\n", "# Calculate std err", "\n", "act_f1_stderr", "=", "d_f1", "(", "c", "[", "\"n_true_acts\"", "]", ",", "c", "[", "\"n_pred_acts\"", "]", ",", "c", "[", "\"n_correct_acts\"", "]", ")", "\n", "slot_f1_stderr", "=", "d_f1", "(", "c", "[", "\"n_true_slots\"", "]", ",", "c", "[", "\"n_pred_slots\"", "]", ",", "c", "[", "\"n_correct_slots\"", "]", ")", "\n", "request_slot_f1_stderr", "=", "d_f1", "(", "\n", "c", "[", "\"n_true_request_slots\"", "]", ",", "\n", "c", "[", "\"n_pred_request_slots\"", "]", ",", "\n", "c", "[", "\"n_correct_request_slots\"", "]", ",", "\n", ")", "\n", "object_f1_stderr", "=", "d_f1", "(", "\n", "c", "[", "\"n_true_objects\"", "]", ",", "\n", "c", "[", "\"n_pred_objects\"", "]", ",", "\n", "c", "[", "\"n_correct_objects\"", "]", "\n", ")", "\n", "disamb_candidate_f1_stderr", "=", "d_f1", "(", "\n", "c", "[", "\"n_true_disamb_candidates\"", "]", ",", "\n", "c", "[", "\"n_pred_disamb_candidates\"", "]", ",", "\n", "c", "[", "\"n_correct_disamb_candidates\"", "]", "\n", ")", "\n", "\n", "return", "{", "\n", "\"joint_accuracy\"", ":", "joint_accuracy", ",", "\n", "\"act_rec\"", ":", "act_rec", ",", "\n", "\"act_prec\"", ":", "act_prec", ",", "\n", "\"act_f1\"", ":", "act_f1", ",", "\n", "\"act_f1_stderr\"", ":", "act_f1_stderr", ",", "\n", "\"slot_rec\"", ":", "slot_rec", ",", "\n", "\"slot_prec\"", ":", "slot_prec", ",", "\n", "\"slot_f1\"", ":", "slot_f1", ",", "\n", "\"slot_f1_stderr\"", ":", "slot_f1_stderr", ",", "\n", "\"request_slot_rec\"", ":", "request_slot_rec", ",", "\n", "\"request_slot_prec\"", ":", "request_slot_prec", ",", "\n", "\"request_slot_f1\"", ":", "request_slot_f1", ",", "\n", "\"request_slot_f1_stderr\"", ":", "request_slot_f1_stderr", ",", "\n", "\"object_rec\"", ":", "object_rec", ",", "\n", "\"object_prec\"", ":", "object_prec", ",", "\n", "\"object_f1\"", ":", "object_f1", ",", "\n", "\"object_f1_stderr\"", ":", "object_f1_stderr", ",", "\n", "\"disamb_candidate_rec\"", ":", "disamb_candidate_rec", ",", "\n", "\"disamb_candidate_prec\"", ":", "disamb_candidate_prec", ",", "\n", "\"disamb_candidate_f1\"", ":", "disamb_candidate_f1", ",", "\n", "\"disamb_candidate_f1_stderr\"", ":", "disamb_candidate_f1_stderr", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.evaluate_turn": [[195, 213], ["evaluate_dst.initialize_count_dict", "range", "len", "evaluate_dst.add_dicts", "len", "evaluate_dst.evaluate_frame"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.initialize_count_dict", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.add_dicts", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.evaluate_frame"], ["", "def", "evaluate_turn", "(", "true_turn", ",", "pred_turn", ")", ":", "\n", "\n", "    ", "count_dict", "=", "initialize_count_dict", "(", ")", "\n", "\n", "# Must preserve order in which frames appear.", "\n", "for", "frame_idx", "in", "range", "(", "len", "(", "true_turn", ")", ")", ":", "\n", "# For each frame", "\n", "        ", "true_frame", "=", "true_turn", "[", "frame_idx", "]", "\n", "if", "frame_idx", ">=", "len", "(", "pred_turn", ")", ":", "\n", "            ", "pred_frame", "=", "{", "}", "\n", "", "else", ":", "\n", "            ", "pred_frame", "=", "pred_turn", "[", "frame_idx", "]", "\n", "\n", "", "count_dict", "=", "add_dicts", "(", "\n", "count_dict", ",", "evaluate_frame", "(", "true_frame", ",", "pred_frame", ",", "strict", "=", "False", ")", "\n", ")", "\n", "\n", "", "return", "count_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.evaluate_frame": [[215, 353], ["evaluate_dst.initialize_count_dict", "set", "set", "true_frame.get", "pred_frame.get", "len", "len", "len", "len", "len", "len", "len", "len", "set.add", "set.add", "len", "len", "len", "len", "set", "set", "set.intersection", "true_frame.get", "pred_frame.get", "true_frame_request_slot_values.intersection", "true_frame.get", "pred_frame.get", "true_frame_object_values.intersection", "true_frame.get", "pred_frame.get", "true_frame_disamb_candidate_values.intersection", "type", "type", "list.sort", "type", "type", "list.sort", "list", "list", "list", "list", "eval", "type", "type", "eval", "type", "type"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.initialize_count_dict"], ["", "def", "evaluate_frame", "(", "true_frame", ",", "pred_frame", ",", "strict", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    If strict=True,\n        For each dialog_act (frame), set(slot values) must match.\n        If dialog_act is incorrect, its set(slot values) is considered wrong.\n    \"\"\"", "\n", "count_dict", "=", "initialize_count_dict", "(", ")", "\n", "count_dict", "[", "\"n_frames\"", "]", "+=", "1", "\n", "\n", "# Compare Dialog Actss", "\n", "true_act", "=", "true_frame", "[", "\"act\"", "]", "if", "\"act\"", "in", "true_frame", "else", "None", "\n", "pred_act", "=", "pred_frame", "[", "\"act\"", "]", "if", "\"act\"", "in", "pred_frame", "else", "None", "\n", "b_correct_act", "=", "true_act", "==", "pred_act", "\n", "count_dict", "[", "\"n_correct_acts\"", "]", "+=", "b_correct_act", "\n", "count_dict", "[", "\"n_true_acts\"", "]", "+=", "\"act\"", "in", "true_frame", "\n", "count_dict", "[", "\"n_pred_acts\"", "]", "+=", "\"act\"", "in", "pred_frame", "\n", "\n", "# (1) Compare Slots", "\n", "#true_frame_slot_values = {f\"{k}={v}\" for k, v in true_frame.get(\"slots\", [])}", "\n", "#pred_frame_slot_values = {f\"{k}={v}\" for k, v in pred_frame.get(\"slots\", [])}", "\n", "\n", "true_frame_slot_values", "=", "set", "(", ")", "\n", "pred_frame_slot_values", "=", "set", "(", ")", "\n", "\n", "for", "k", ",", "v", "in", "true_frame", ".", "get", "(", "\"slots\"", ",", "[", "]", ")", ":", "\n", "        ", "if", "k", "in", "set", "(", "[", "'availableSizes'", "]", ")", ":", "\n", "# For availableSizes, we expect that the type is <list>.", "\n", "# Otherwise, try converting it to a <list>.", "\n", "            ", "if", "type", "(", "v", ")", "==", "str", ":", "\n", "                ", "try", ":", "\n", "                    ", "v", "=", "list", "(", "eval", "(", "v", ")", ")", "\n", "", "except", ":", "\n", "                    ", "v", "=", "[", "v", "]", "\n", "\n", "", "", "elif", "type", "(", "v", ")", "==", "tuple", "or", "type", "(", "v", ")", "==", "set", ":", "\n", "                ", "v", "=", "list", "(", "v", ")", "\n", "\n", "# Sort the elements to get consistent ordering.", "\n", "# For slots with a list of elements, all elements must be captured.", "\n", "", "if", "type", "(", "v", ")", "==", "list", ":", "\n", "                ", "v", ".", "sort", "(", ")", "\n", "\n", "", "", "true_frame_slot_values", ".", "add", "(", "f\"{k}={v}\"", ")", "\n", "\n", "", "for", "k", ",", "v", "in", "pred_frame", ".", "get", "(", "\"slots\"", ",", "[", "]", ")", ":", "\n", "        ", "if", "k", "in", "set", "(", "[", "'availableSizes'", "]", ")", ":", "\n", "            ", "if", "type", "(", "v", ")", "==", "str", ":", "\n", "                ", "try", ":", "\n", "                    ", "v", "=", "list", "(", "eval", "(", "v", ")", ")", "\n", "", "except", ":", "\n", "                    ", "v", "=", "[", "v", "]", "\n", "\n", "", "", "elif", "type", "(", "v", ")", "==", "tuple", "or", "type", "(", "v", ")", "==", "set", ":", "\n", "                ", "v", "=", "list", "(", "v", ")", "\n", "", "if", "type", "(", "v", ")", "==", "list", ":", "\n", "                ", "v", ".", "sort", "(", ")", "\n", "\n", "", "", "pred_frame_slot_values", ".", "add", "(", "f\"{k}={v}\"", ")", "\n", "\n", "", "count_dict", "[", "\"n_true_slots\"", "]", "+=", "len", "(", "true_frame_slot_values", ")", "\n", "count_dict", "[", "\"n_pred_slots\"", "]", "+=", "len", "(", "pred_frame_slot_values", ")", "\n", "\n", "if", "strict", "and", "not", "b_correct_act", ":", "\n", "        ", "pass", "\n", "", "else", ":", "\n", "        ", "count_dict", "[", "\"n_correct_slots\"", "]", "+=", "len", "(", "\n", "true_frame_slot_values", ".", "intersection", "(", "pred_frame_slot_values", ")", "\n", ")", "\n", "\n", "# Debug only", "\n", "# if len(true_frame_slot_values.intersection(pred_frame_slot_values)) != len(pred_frame_slot_values):", "\n", "# print(true_frame_slot_values)", "\n", "# print(pred_frame_slot_values)", "\n", "# print(len(true_frame_slot_values.intersection(pred_frame_slot_values)) == len(pred_frame_slot_values))", "\n", "# print('--')", "\n", "\n", "# (2) Compare Request slots", "\n", "", "true_frame_request_slot_values", "=", "{", "rs", "for", "rs", "in", "true_frame", ".", "get", "(", "\"request_slots\"", ",", "[", "]", ")", "}", "\n", "pred_frame_request_slot_values", "=", "{", "rs", "for", "rs", "in", "pred_frame", ".", "get", "(", "\"request_slots\"", ",", "[", "]", ")", "}", "\n", "# print(true_frame_request_slot_values)", "\n", "\n", "count_dict", "[", "\"n_true_request_slots\"", "]", "+=", "len", "(", "true_frame_request_slot_values", ")", "\n", "count_dict", "[", "\"n_pred_request_slots\"", "]", "+=", "len", "(", "pred_frame_request_slot_values", ")", "\n", "\n", "if", "strict", "and", "not", "b_correct_act", ":", "\n", "        ", "pass", "\n", "", "else", ":", "\n", "        ", "count_dict", "[", "\"n_correct_request_slots\"", "]", "+=", "len", "(", "\n", "true_frame_request_slot_values", ".", "intersection", "(", "pred_frame_request_slot_values", ")", "\n", ")", "\n", "\n", "# (3) Compare Objects", "\n", "", "true_frame_object_values", "=", "{", "\n", "object_id", "for", "object_id", "in", "true_frame", ".", "get", "(", "\"objects\"", ",", "[", "]", ")", "\n", "}", "\n", "pred_frame_object_values", "=", "{", "\n", "object_id", "for", "object_id", "in", "pred_frame", ".", "get", "(", "\"objects\"", ",", "[", "]", ")", "\n", "}", "\n", "# print(true_frame_object_values)", "\n", "\n", "count_dict", "[", "\"n_true_objects\"", "]", "+=", "len", "(", "true_frame_object_values", ")", "\n", "count_dict", "[", "\"n_pred_objects\"", "]", "+=", "len", "(", "pred_frame_object_values", ")", "\n", "\n", "if", "strict", "and", "not", "b_correct_act", ":", "\n", "        ", "pass", "\n", "", "else", ":", "\n", "        ", "count_dict", "[", "\"n_correct_objects\"", "]", "+=", "len", "(", "\n", "true_frame_object_values", ".", "intersection", "(", "pred_frame_object_values", ")", "\n", ")", "\n", "\n", "# (4) Compare Disambiguation Objects", "\n", "", "true_frame_disamb_candidate_values", "=", "{", "\n", "disamb_candidate_id", "for", "disamb_candidate_id", "in", "true_frame", ".", "get", "(", "\"disambiguation_candidates\"", ",", "[", "]", ")", "\n", "}", "\n", "pred_frame_disamb_candidate_values", "=", "{", "\n", "disamb_candidate_id", "for", "disamb_candidate_id", "in", "pred_frame", ".", "get", "(", "\"disambiguation_candidates\"", ",", "[", "]", ")", "\n", "}", "\n", "# print(true_frame_disamb_candidate_values)", "\n", "\n", "count_dict", "[", "\"n_true_disamb_candidates\"", "]", "+=", "len", "(", "true_frame_disamb_candidate_values", ")", "\n", "count_dict", "[", "\"n_pred_disamb_candidates\"", "]", "+=", "len", "(", "pred_frame_disamb_candidate_values", ")", "\n", "\n", "if", "strict", "and", "not", "b_correct_act", ":", "\n", "        ", "pass", "\n", "", "else", ":", "\n", "        ", "count_dict", "[", "\"n_correct_disamb_candidates\"", "]", "+=", "len", "(", "\n", "true_frame_disamb_candidate_values", ".", "intersection", "(", "pred_frame_disamb_candidate_values", ")", "\n", ")", "\n", "\n", "# (5) Joint", "\n", "", "count_dict", "[", "\"n_correct_beliefs\"", "]", "+=", "(", "\n", "b_correct_act", "\n", "and", "true_frame_slot_values", "==", "pred_frame_slot_values", "\n", "and", "true_frame_request_slot_values", "==", "pred_frame_request_slot_values", "\n", "and", "true_frame_object_values", "==", "pred_frame_object_values", "\n", ")", "\n", "\n", "return", "count_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.add_dicts": [[355, 357], ["None"], "function", ["None"], ["", "def", "add_dicts", "(", "d1", ",", "d2", ")", ":", "\n", "    ", "return", "{", "k", ":", "d1", "[", "k", "]", "+", "d2", "[", "k", "]", "for", "k", "in", "d1", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.rec_prec_f1": [[359, 365], ["None"], "function", ["None"], ["", "def", "rec_prec_f1", "(", "n_correct", ",", "n_true", ",", "n_pred", ")", ":", "\n", "    ", "rec", "=", "n_correct", "/", "n_true", "if", "n_true", "!=", "0", "else", "0", "\n", "prec", "=", "n_correct", "/", "n_pred", "if", "n_pred", "!=", "0", "else", "0", "\n", "f1", "=", "2", "*", "prec", "*", "rec", "/", "(", "prec", "+", "rec", ")", "if", "(", "prec", "+", "rec", ")", "!=", "0", "else", "0", "\n", "\n", "return", "rec", ",", "prec", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.d_f1": [[367, 380], ["evaluate_dst.b_stderr", "evaluate_dst.b_stderr"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.b_stderr", "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.b_stderr"], ["", "def", "d_f1", "(", "n_true", ",", "n_pred", ",", "n_correct", ")", ":", "\n", "# 1/r + 1/p = 2/F1", "\n", "# dr / r^2 + dp / p^2 = 2dF1 /F1^2", "\n", "# dF1 = 1/2 F1^2 (dr/r^2 + dp/p^2)", "\n", "    ", "dr", "=", "b_stderr", "(", "n_true", ",", "n_correct", ")", "\n", "dp", "=", "b_stderr", "(", "n_pred", ",", "n_correct", ")", "\n", "\n", "r", "=", "n_correct", "/", "n_true", "\n", "p", "=", "n_correct", "/", "n_pred", "\n", "f1", "=", "2", "*", "p", "*", "r", "/", "(", "p", "+", "r", ")", "if", "p", "+", "r", "!=", "0", "else", "0", "\n", "\n", "d_f1", "=", "0.5", "*", "f1", "**", "2", "*", "(", "dr", "/", "r", "**", "2", "+", "dp", "/", "p", "**", "2", ")", "\n", "return", "d_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.b_stderr": [[382, 384], ["numpy.std", "numpy.sqrt", "evaluate_dst.b_arr"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.b_arr"], ["", "def", "b_stderr", "(", "n_total", ",", "n_pos", ")", ":", "\n", "    ", "return", "np", ".", "std", "(", "b_arr", "(", "n_total", ",", "n_pos", ")", ")", "/", "np", ".", "sqrt", "(", "n_total", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.b_arr": [[386, 390], ["numpy.zeros", "int", "int"], "function", ["None"], ["", "def", "b_arr", "(", "n_total", ",", "n_pos", ")", ":", "\n", "    ", "out", "=", "np", ".", "zeros", "(", "int", "(", "n_total", ")", ")", "\n", "out", "[", ":", "int", "(", "n_pos", ")", "]", "=", "1.0", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.evaluate_dst.initialize_count_dict": [[392, 413], ["copy.deepcopy"], "function", ["None"], ["", "def", "initialize_count_dict", "(", ")", ":", "\n", "    ", "c", "=", "{", "\n", "\"n_frames\"", ":", "0.0", ",", "\n", "\"n_true_acts\"", ":", "0.0", ",", "\n", "\"n_pred_acts\"", ":", "0.0", ",", "\n", "\"n_correct_acts\"", ":", "0.0", ",", "\n", "\"n_true_slots\"", ":", "0.0", ",", "\n", "\"n_pred_slots\"", ":", "0.0", ",", "\n", "\"n_correct_slots\"", ":", "0.0", ",", "\n", "\"n_true_request_slots\"", ":", "0.0", ",", "\n", "\"n_pred_request_slots\"", ":", "0.0", ",", "\n", "\"n_correct_request_slots\"", ":", "0.0", ",", "\n", "\"n_true_objects\"", ":", "0.0", ",", "\n", "\"n_pred_objects\"", ":", "0.0", ",", "\n", "\"n_correct_objects\"", ":", "0.0", ",", "\n", "\"n_true_disamb_candidates\"", ":", "0.0", ",", "\n", "\"n_pred_disamb_candidates\"", ":", "0.0", ",", "\n", "\"n_correct_disamb_candidates\"", ":", "0.0", ",", "\n", "\"n_correct_beliefs\"", ":", "0.0", ",", "\n", "}", "\n", "return", "copy", ".", "deepcopy", "(", "c", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.convert.convert_json_to_flattened": [[44, 269], ["enumerate", "os.path.dirname", "os.path.dirname", "open", "set", "enumerate", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "open", "f_predict.write", "os.path.dirname", "os.path.dirname", "json.load", "open", "json.load", "open", "json.load", "additional_special_tokens.append", "additional_special_tokens.append", "additional_special_tokens.extend", "turn.get().replace().strip", "turn.get", "turn.get().replace().strip", "lst_context.append", "open", "f_target.write", "os.path.exists", "os.makedirs", "open", "file_id.write", "os.path.exists", "os.makedirs", "open", "special_tokens[].extend", "json.dump", "belief_state.append", "TEMPLATE_PREDICT.format", "predicts.append", "TEMPLATE_PREDICT_NOBELIEF.format", "predicts.append", "list", "turn.get().replace", "turn.get().replace", "set.add", "turn.get.get().get", "TEMPLATE_TARGET.format", "targets.append", "TEMPLATE_TARGET_NOBELIEF.format", "targets.append", "convert.represent_visual_objects", "turn.get.get().strip", "turn.get.get", "set.add", "TEMPLATE_TARGET_NOBELIEF.format", "retrieval_targets.append", "turn.get", "turn.get", "turn.get.get().get", "turn.get.get", "str", "turn.get.get", "str", "str", "turn.get.get().get().items", "turn.get.get", "turn.get.get().get", "turn.get.get", "k.strip", "str().strip", "turn.get.get().get", "turn.get.get", "str", "turn.get.get"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.convert.represent_visual_objects"], ["def", "convert_json_to_flattened", "(", "\n", "input_path_json", ",", "\n", "output_path_predict", ",", "\n", "output_path_target", ",", "\n", "len_context", "=", "2", ",", "\n", "use_multimodal_contexts", "=", "True", ",", "\n", "use_belief_states", "=", "True", ",", "\n", "output_target", "=", "True", ",", "\n", "input_path_retrieval", "=", "None", ",", "\n", "output_path_retrieval", "=", "None", ",", "\n", "input_path_special_tokens", "=", "\"\"", ",", "\n", "output_path_special_tokens", "=", "\"\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Input: JSON representation of the dialogs\n    Output: line-by-line stringified representation of each turn\n    \"\"\"", "\n", "\n", "with", "open", "(", "input_path_json", ",", "\"r\"", ")", "as", "f_in", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "f_in", ")", "[", "\"dialogue_data\"", "]", "\n", "\n", "# If input_path_retrieval is not None, also encode retrieval options.", "\n", "", "if", "input_path_retrieval", "is", "not", "None", ":", "\n", "        ", "with", "open", "(", "input_path_retrieval", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "            ", "retrieval_options", "=", "json", ".", "load", "(", "file_id", ")", "\n", "", "format_retrieval_options", "=", "True", "\n", "options_pool", "=", "retrieval_options", "[", "\"system_transcript_pool\"", "]", "\n", "options_dict", "=", "{", "\n", "ii", "[", "\"dialogue_idx\"", "]", ":", "ii", "\n", "for", "ii", "in", "retrieval_options", "[", "\"retrieval_candidates\"", "]", "\n", "}", "\n", "retrieval_targets", "=", "[", "]", "\n", "", "else", ":", "\n", "        ", "format_retrieval_options", "=", "False", "\n", "\n", "", "predicts", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "if", "input_path_special_tokens", "!=", "\"\"", ":", "\n", "        ", "with", "open", "(", "input_path_special_tokens", ",", "\"r\"", ")", "as", "f_in", ":", "\n", "            ", "special_tokens", "=", "json", ".", "load", "(", "f_in", ")", "\n", "", "", "else", ":", "\n", "        ", "special_tokens", "=", "{", "\"eos_token\"", ":", "END_OF_SENTENCE", "}", "\n", "additional_special_tokens", "=", "[", "]", "\n", "if", "use_belief_states", ":", "\n", "            ", "additional_special_tokens", ".", "append", "(", "END_OF_BELIEF", ")", "\n", "", "else", ":", "\n", "            ", "additional_special_tokens", ".", "append", "(", "START_OF_RESPONSE", ")", "\n", "", "if", "use_multimodal_contexts", ":", "\n", "            ", "additional_special_tokens", ".", "extend", "(", "\n", "[", "START_OF_MULTIMODAL_CONTEXTS", ",", "END_OF_MULTIMODAL_CONTEXTS", "]", "\n", ")", "\n", "", "special_tokens", "[", "\"additional_special_tokens\"", "]", "=", "additional_special_tokens", "\n", "\n", "", "if", "output_path_special_tokens", "!=", "\"\"", ":", "\n", "# If a new output path for special tokens is given,", "\n", "# we track new OOVs", "\n", "        ", "oov", "=", "set", "(", ")", "\n", "\n", "", "for", "_", ",", "dialog", "in", "enumerate", "(", "data", ")", ":", "\n", "\n", "        ", "domain", "=", "dialog", "[", "\"domain\"", "]", "\n", "dialog_id", "=", "dialog", "[", "\"dialogue_idx\"", "]", "\n", "prev_asst_uttr", "=", "None", "\n", "prev_turn", "=", "None", "\n", "lst_context", "=", "[", "]", "\n", "\n", "for", "turn_id", ",", "turn", "in", "enumerate", "(", "dialog", "[", "FIELDNAME_DIALOG", "]", ")", ":", "\n", "            ", "user_uttr", "=", "turn", ".", "get", "(", "FIELDNAME_USER_UTTR", ",", "\"\"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "user_belief", "=", "turn", ".", "get", "(", "FIELDNAME_BELIEF_STATE", ",", "{", "}", ")", "\n", "asst_uttr", "=", "turn", ".", "get", "(", "FIELDNAME_ASST_UTTR", ",", "\"\"", ")", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "\n", "# Format main input context", "\n", "context", "=", "\"\"", "\n", "if", "prev_asst_uttr", ":", "\n", "                ", "context", "+=", "f\"System : {prev_asst_uttr} \"", "\n", "if", "use_multimodal_contexts", ":", "\n", "# Add multimodal contexts", "\n", "                    ", "visual_objects", "=", "prev_turn", "[", "FIELDNAME_SYSTEM_STATE", "]", "[", "\n", "\"act_attributes\"", "\n", "]", "[", "\"objects\"", "]", "\n", "context", "+=", "represent_visual_objects", "(", "visual_objects", ")", "+", "\" \"", "\n", "\n", "", "", "context", "+=", "f\"User : {user_uttr}\"", "\n", "prev_asst_uttr", "=", "asst_uttr", "\n", "prev_turn", "=", "turn", "\n", "\n", "# Add multimodal contexts -- user shouldn't have access to ground-truth", "\n", "\"\"\"\n            if use_multimodal_contexts:\n                visual_objects = turn[FIELDNAME_BELIEF_STATE]['act_attributes']['objects']\n                context += ' ' + represent_visual_objects(visual_objects)\n            \"\"\"", "\n", "\n", "# Concat with previous contexts", "\n", "lst_context", ".", "append", "(", "context", ")", "\n", "context", "=", "\" \"", ".", "join", "(", "lst_context", "[", "-", "len_context", ":", "]", ")", "\n", "\n", "# Format belief state", "\n", "if", "use_belief_states", ":", "\n", "                ", "belief_state", "=", "[", "]", "\n", "# for bs_per_frame in user_belief:", "\n", "str_belief_state_per_frame", "=", "(", "\n", "\"{act} [ {slot_values} ] ({request_slots}) < {objects} > | {disamb_candidates} |\"", ".", "format", "(", "\n", "act", "=", "user_belief", ".", "get", "(", "\"act\"", ",", "\"\"", ")", ".", "strip", "(", ")", ",", "\n", "slot_values", "=", "\", \"", ".", "join", "(", "\n", "[", "\n", "f\"{k.strip()} = {str(v).strip()}\"", "\n", "for", "k", ",", "v", "in", "user_belief", ".", "get", "(", "\"act_attributes\"", ",", "{", "}", ")", ".", "get", "(", "\n", "\"slot_values\"", ",", "{", "}", "\n", ")", ".", "items", "(", ")", "\n", "]", "\n", ")", ",", "\n", "request_slots", "=", "\", \"", ".", "join", "(", "\n", "user_belief", ".", "get", "(", "\"act_attributes\"", ",", "{", "}", ")", ".", "get", "(", "\"request_slots\"", ",", "[", "]", ")", "\n", ")", ",", "\n", "objects", "=", "\", \"", ".", "join", "(", "\n", "[", "str", "(", "o", ")", "for", "o", "in", "user_belief", ".", "get", "(", "\"act_attributes\"", ",", "{", "}", ")", ".", "get", "(", "\"objects\"", ",", "[", "]", ")", "]", "\n", ")", ",", "\n", "disamb_candidates", "=", "\", \"", ".", "join", "(", "\n", "[", "str", "(", "o", ")", "for", "o", "in", "user_belief", ".", "get", "(", "\"disambiguation_candidates\"", ",", "[", "]", ")", "]", "\n", ")", ",", "\n", ")", "\n", ")", "\n", "belief_state", ".", "append", "(", "str_belief_state_per_frame", ")", "\n", "\n", "# Track OOVs", "\n", "if", "output_path_special_tokens", "!=", "\"\"", ":", "\n", "                    ", "oov", ".", "add", "(", "user_belief", ".", "get", "(", "\"act\"", ",", "\"\"", ")", ")", "\n", "for", "slot_name", "in", "user_belief", ".", "get", "(", "\"act_attributes\"", ",", "{", "}", ")", ".", "get", "(", "\"slot_values\"", ",", "{", "}", ")", ":", "\n", "                        ", "oov", ".", "add", "(", "str", "(", "slot_name", ")", ")", "\n", "# slot_name, slot_value = kv[0].strip(), kv[1].strip()", "\n", "# oov.add(slot_name)", "\n", "# oov.add(slot_value)", "\n", "\n", "", "", "str_belief_state", "=", "\" \"", ".", "join", "(", "belief_state", ")", "\n", "\n", "# Format the main input", "\n", "predict", "=", "TEMPLATE_PREDICT", ".", "format", "(", "\n", "context", "=", "context", ",", "\n", "START_BELIEF_STATE", "=", "START_BELIEF_STATE", ",", "\n", ")", "\n", "predicts", ".", "append", "(", "predict", ")", "\n", "\n", "# Format the main output", "\n", "if", "output_target", ":", "\n", "                    ", "target", "=", "TEMPLATE_TARGET", ".", "format", "(", "\n", "context", "=", "context", ",", "\n", "START_BELIEF_STATE", "=", "START_BELIEF_STATE", ",", "\n", "belief_state", "=", "str_belief_state", ",", "\n", "END_OF_BELIEF", "=", "END_OF_BELIEF", ",", "\n", "response", "=", "asst_uttr", ",", "\n", "END_OF_SENTENCE", "=", "END_OF_SENTENCE", ",", "\n", ")", "\n", "targets", ".", "append", "(", "target", ")", "\n", "\n", "# NOTE: Retrieval options w/ belief states is not implemented.", "\n", "", "", "else", ":", "\n", "# Format the main input", "\n", "                ", "predict", "=", "TEMPLATE_PREDICT_NOBELIEF", ".", "format", "(", "\n", "context", "=", "context", ",", "START_OF_RESPONSE", "=", "START_OF_RESPONSE", "\n", ")", "\n", "predicts", ".", "append", "(", "predict", ")", "\n", "\n", "# Format the main output", "\n", "if", "output_target", ":", "\n", "                    ", "target", "=", "TEMPLATE_TARGET_NOBELIEF", ".", "format", "(", "\n", "context", "=", "context", ",", "\n", "response", "=", "asst_uttr", ",", "\n", "END_OF_SENTENCE", "=", "END_OF_SENTENCE", ",", "\n", "START_OF_RESPONSE", "=", "START_OF_RESPONSE", ",", "\n", ")", "\n", "targets", ".", "append", "(", "target", ")", "\n", "\n", "# Add retrieval options is necessary.", "\n", "", "if", "format_retrieval_options", ":", "\n", "                    ", "turn_options", "=", "(", "\n", "options_dict", "[", "dialog_id", "]", "[", "\"retrieval_candidates\"", "]", "[", "turn_id", "]", "\n", ")", "\n", "for", "option_ind", "in", "turn_options", "[", "\"retrieval_candidates\"", "]", ":", "\n", "                        ", "retrieval_target", "=", "TEMPLATE_TARGET_NOBELIEF", ".", "format", "(", "\n", "context", "=", "context", ",", "\n", "response", "=", "options_pool", "[", "domain", "]", "[", "option_ind", "]", ",", "\n", "END_OF_SENTENCE", "=", "END_OF_SENTENCE", ",", "\n", "START_OF_RESPONSE", "=", "START_OF_RESPONSE", ",", "\n", ")", "\n", "retrieval_targets", ".", "append", "(", "retrieval_target", ")", "\n", "\n", "# Create a directory if it does not exist", "\n", "", "", "", "", "", "directory", "=", "os", ".", "path", ".", "dirname", "(", "output_path_predict", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "directory", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "directory", "=", "os", ".", "path", ".", "dirname", "(", "output_path_target", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "directory", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Output into text files", "\n", "", "with", "open", "(", "output_path_predict", ",", "\"w\"", ")", "as", "f_predict", ":", "\n", "        ", "X", "=", "\"\\n\"", ".", "join", "(", "predicts", ")", "\n", "f_predict", ".", "write", "(", "X", ")", "\n", "\n", "", "if", "output_target", ":", "\n", "        ", "with", "open", "(", "output_path_target", ",", "\"w\"", ")", "as", "f_target", ":", "\n", "            ", "Y", "=", "\"\\n\"", ".", "join", "(", "targets", ")", "\n", "f_target", ".", "write", "(", "Y", ")", "\n", "\n", "# Write retrieval candidates if necessary.", "\n", "", "", "if", "format_retrieval_options", ":", "\n", "# Create a directory if it does not exist", "\n", "        ", "directory", "=", "os", ".", "path", ".", "dirname", "(", "output_path_retrieval", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "directory", ",", "exist_ok", "=", "True", ")", "\n", "", "with", "open", "(", "output_path_retrieval", ",", "\"w\"", ")", "as", "file_id", ":", "\n", "            ", "file_id", ".", "write", "(", "\"\\n\"", ".", "join", "(", "retrieval_targets", ")", ")", "\n", "\n", "", "", "if", "output_path_special_tokens", "!=", "\"\"", ":", "\n", "# Create a directory if it does not exist", "\n", "        ", "directory", "=", "os", ".", "path", ".", "dirname", "(", "output_path_special_tokens", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "directory", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "with", "open", "(", "output_path_special_tokens", ",", "\"w\"", ")", "as", "f_special_tokens", ":", "\n", "# Add oov's (acts and slot names, etc.) to special tokens as well", "\n", "            ", "special_tokens", "[", "\"additional_special_tokens\"", "]", ".", "extend", "(", "list", "(", "oov", ")", ")", "\n", "json", ".", "dump", "(", "special_tokens", ",", "f_special_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.convert.represent_visual_objects": [[271, 292], ["str"], "function", ["None"], ["", "", "", "def", "represent_visual_objects", "(", "object_ids", ")", ":", "\n", "# Stringify visual objects (JSON)", "\n", "    ", "\"\"\"\n    target_attributes = ['pos', 'color', 'type', 'class_name', 'decor_style']\n\n    list_str_objects = []\n    for obj_name, obj in visual_objects.items():\n        s = obj_name + ' :'\n        for target_attribute in target_attributes:\n            if target_attribute in obj:\n                target_value = obj.get(target_attribute)\n                if target_value == '' or target_value == []:\n                    pass\n                else:\n                    s += f' {target_attribute} {str(target_value)}'\n        list_str_objects.append(s)\n\n    str_objects = ' '.join(list_str_objects)\n    \"\"\"", "\n", "str_objects", "=", "\", \"", ".", "join", "(", "[", "str", "(", "o", ")", "for", "o", "in", "object_ids", "]", ")", "\n", "return", "f\"{START_OF_MULTIMODAL_CONTEXTS} {str_objects} {END_OF_MULTIMODAL_CONTEXTS}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.convert.parse_flattened_results_from_file": [[294, 302], ["open", "convert.parse_flattened_result", "results.append"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.convert.parse_flattened_result"], ["", "def", "parse_flattened_results_from_file", "(", "path", ")", ":", "\n", "    ", "results", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f_in", ":", "\n", "        ", "for", "line", "in", "f_in", ":", "\n", "            ", "parsed", "=", "parse_flattened_result", "(", "line", ")", "\n", "results", ".", "append", "(", "parsed", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.utils.convert.parse_flattened_result": [[304, 385], ["re.compile", "re.compile", "re.compile", "re.compile", "re.compile", "splits[].strip.strip().split", "len", "splits[].strip", "splits[].strip.split", "splits[].strip.strip", "len", "splits[].strip", "re.compile.finditer", "re.compile.finditer", "re.compile.finditer", "re.compile.finditer", "re.compile.finditer", "dialog_act.group", "dialog_act.group", "d[].append", "dialog_act.group", "d[].append", "dialog_act.group", "object_id.group().strip", "dialog_act.group", "disamb_candidate_id.group().strip", "belief.append", "request_slot.group().strip", "int", "d[].append", "int", "d[].append", "slot.group().strip", "slot.group().strip", "object_id.group", "disamb_candidate_id.group", "request_slot.group", "slot.group", "slot.group"], "function", ["None"], ["", "def", "parse_flattened_result", "(", "to_parse", ")", ":", "\n", "    ", "\"\"\"\n    Parse out the belief state from the raw text.\n    Return an empty list if the belief state can't be parsed\n\n    Input:\n    - A single <str> of flattened result\n      e.g. 'User: Show me something else => Belief State : DA:REQUEST ...'\n\n    Output:\n    - Parsed result in a JSON format, where the format is:\n        [\n            {\n                'act': <str>  # e.g. 'DA:REQUEST',\n                'slots': [\n                    <str> slot_name,\n                    <str> slot_value\n                ]\n            }, ...  # End of a frame\n        ]  # End of a dialog\n    \"\"\"", "\n", "dialog_act_regex", "=", "re", ".", "compile", "(", "\n", "r'([\\w:?.?]*)  *\\[(.*)\\] *\\(([^\\]]*)\\) *\\<([^\\]]*)\\> *\\|([^\\]]*)\\|'", "\n", ")", "\n", "\n", "slot_regex", "=", "re", ".", "compile", "(", "r\"([A-Za-z0-9_.-:]*)  *= (\\[(.*)\\]|[^,]*)\"", ")", "\n", "request_regex", "=", "re", ".", "compile", "(", "r\"([A-Za-z0-9_.-:]+)\"", ")", "\n", "object_regex", "=", "re", ".", "compile", "(", "r\"([A-Za-z0-9]+)\"", ")", "\n", "disamb_candidate_regex", "=", "re", ".", "compile", "(", "r\"([A-Za-z0-9]+)\"", ")", "\n", "\n", "belief", "=", "[", "]", "\n", "\n", "# Parse", "\n", "splits", "=", "to_parse", ".", "strip", "(", ")", ".", "split", "(", "START_BELIEF_STATE", ")", "\n", "if", "len", "(", "splits", ")", "==", "2", ":", "\n", "        ", "to_parse", "=", "splits", "[", "1", "]", ".", "strip", "(", ")", "\n", "splits", "=", "to_parse", ".", "split", "(", "END_OF_BELIEF", ")", "\n", "\n", "if", "len", "(", "splits", ")", "==", "2", ":", "\n", "# to_parse: 'DIALOG_ACT_1 : [ SLOT_NAME = SLOT_VALUE, ... ] ...'", "\n", "            ", "to_parse", "=", "splits", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "for", "dialog_act", "in", "dialog_act_regex", ".", "finditer", "(", "to_parse", ")", ":", "\n", "                ", "d", "=", "{", "\n", "\"act\"", ":", "dialog_act", ".", "group", "(", "1", ")", ",", "\n", "\"slots\"", ":", "[", "]", ",", "\n", "\"request_slots\"", ":", "[", "]", ",", "\n", "\"objects\"", ":", "[", "]", ",", "\n", "\"disambiguation_candidates\"", ":", "[", "]", ",", "\n", "}", "\n", "\n", "for", "slot", "in", "slot_regex", ".", "finditer", "(", "dialog_act", ".", "group", "(", "2", ")", ")", ":", "\n", "                    ", "d", "[", "\"slots\"", "]", ".", "append", "(", "[", "slot", ".", "group", "(", "1", ")", ".", "strip", "(", ")", ",", "slot", ".", "group", "(", "2", ")", ".", "strip", "(", ")", "]", ")", "\n", "\n", "", "for", "request_slot", "in", "request_regex", ".", "finditer", "(", "dialog_act", ".", "group", "(", "3", ")", ")", ":", "\n", "                    ", "d", "[", "\"request_slots\"", "]", ".", "append", "(", "request_slot", ".", "group", "(", "1", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "for", "object_id", "in", "object_regex", ".", "finditer", "(", "dialog_act", ".", "group", "(", "4", ")", ")", ":", "\n", "                    ", "str_object_id", "=", "object_id", ".", "group", "(", "1", ")", ".", "strip", "(", ")", "\n", "\n", "try", ":", "\n", "# Object ID should always be <int>.", "\n", "                        ", "int_object_id", "=", "int", "(", "str_object_id", ")", "\n", "d", "[", "\"objects\"", "]", ".", "append", "(", "int_object_id", ")", "\n", "", "except", ":", "\n", "                        ", "pass", "\n", "\n", "", "", "for", "disamb_candidate_id", "in", "disamb_candidate_regex", ".", "finditer", "(", "dialog_act", ".", "group", "(", "5", ")", ")", ":", "\n", "                    ", "str_disamb_candidate_id", "=", "disamb_candidate_id", ".", "group", "(", "1", ")", ".", "strip", "(", ")", "\n", "\n", "try", ":", "\n", "# disamb_candidate ID should always be <int>.", "\n", "                        ", "int_disamb_candidate_id", "=", "int", "(", "str_disamb_candidate_id", ")", "\n", "d", "[", "\"disambiguation_candidates\"", "]", ".", "append", "(", "int_disamb_candidate_id", ")", "\n", "", "except", ":", "\n", "                        ", "pass", "\n", "\n", "", "", "if", "d", "!=", "{", "}", ":", "\n", "                    ", "belief", ".", "append", "(", "d", ")", "\n", "\n", "", "", "", "", "return", "belief", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.disambiguator.Disambiguator.__init__": [[22, 46], ["torch.Module.__init__", "disambiguator.Disambiguator.classifier.resize_token_embeddings", "transformers.GPT2ForSequenceClassification.from_pretrained", "len", "disambiguator.Disambiguator.classifier.cuda", "transformers.BertForSequenceClassification.from_pretrained", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.LineByLineTextDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ")", ":", "\n", "        ", "super", "(", "Disambiguator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_args", "=", "args", "\n", "\n", "if", "args", "[", "\"backbone\"", "]", "==", "\"gpt2\"", ":", "\n", "            ", "self", ".", "classifier", "=", "(", "\n", "transformers", ".", "GPT2ForSequenceClassification", ".", "from_pretrained", "(", "\n", "\"gpt2\"", ",", "num_labels", "=", "2", "\n", ")", "\n", ")", "\n", "self", ".", "classifier", ".", "config", ".", "pad_token_id", "=", "self", ".", "classifier", ".", "config", ".", "eos_token_id", "\n", "", "elif", "args", "[", "\"backbone\"", "]", "==", "\"bert\"", ":", "\n", "            ", "self", ".", "classifier", "=", "(", "\n", "transformers", ".", "BertForSequenceClassification", ".", "from_pretrained", "(", "\n", "\"bert-base-uncased\"", ",", "num_labels", "=", "2", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"\"\"Invalid backbone: {args[\"backbone\"]}\"\"\"", ")", "\n", "# Fix model padding token id.", "\n", "", "self", ".", "classifier", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "if", "args", "[", "\"use_gpu\"", "]", ":", "\n", "            ", "self", ".", "classifier", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.disambiguator.Disambiguator.forward": [[47, 50], ["disambiguator.Disambiguator.classifier"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "batch", ")", ":", "\n", "        ", "model_out", "=", "self", ".", "classifier", "(", "**", "batch", "[", "\"text_in\"", "]", ")", "\n", "return", "model_out", "[", "\"logits\"", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.train_model.evaluate_model": [[28, 61], ["collections.defaultdict", "tqdm.tqdm", "loader.get_entire_batch", "model", "torch.argmax", "torch.argmax", "print", "int", "range", "open", "json.dump", "results[].append", "collections.defaultdict.items", "predictions[].cpu().item", "predictions[].cpu"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.dataloader.Dataloader.get_entire_batch"], ["def", "evaluate_model", "(", "model", ",", "loader", ",", "batch_size", ",", "save_path", "=", "None", ",", "hidden_test", "=", "False", ")", ":", "\n", "    ", "num_matches", "=", "0", "\n", "results", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "batch", "in", "progressbar", "(", "loader", ".", "get_entire_batch", "(", "batch_size", ")", ")", ":", "\n", "        ", "output", "=", "model", "(", "batch", ")", "\n", "predictions", "=", "torch", ".", "argmax", "(", "output", ",", "dim", "=", "1", ")", "\n", "if", "not", "hidden_test", ":", "\n", "            ", "num_matches", "+=", "int", "(", "(", "predictions", "==", "batch", "[", "\"gt_label\"", "]", ")", ".", "sum", "(", ")", ")", "\n", "\n", "# Save results if need be.", "\n", "", "if", "save_path", ":", "\n", "            ", "for", "ii", "in", "range", "(", "predictions", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "new_instance", "=", "{", "\n", "\"turn_id\"", ":", "batch", "[", "\"turn_id\"", "]", "[", "ii", "]", ",", "\n", "\"disambiguation_label\"", ":", "predictions", "[", "ii", "]", ".", "cpu", "(", ")", ".", "item", "(", ")", ",", "\n", "}", "\n", "results", "[", "batch", "[", "\"dialog_id\"", "]", "[", "ii", "]", "]", ".", "append", "(", "new_instance", ")", "\n", "\n", "# Restructure results JSON and save.", "\n", "", "", "", "if", "save_path", ":", "\n", "        ", "results", "=", "[", "\n", "{", "\n", "\"dialog_id\"", ":", "dialog_id", ",", "\n", "\"predictions\"", ":", "predictions", ",", "\n", "}", "\n", "for", "dialog_id", ",", "predictions", "in", "results", ".", "items", "(", ")", "\n", "]", "\n", "print", "(", "f\"Saving: {save_path}\"", ")", "\n", "with", "open", "(", "save_path", ",", "\"w\"", ")", "as", "file_id", ":", "\n", "            ", "json", ".", "dump", "(", "results", ",", "file_id", ")", "\n", "\n", "", "", "accuracy", "=", "num_matches", "/", "loader", ".", "num_instances", "*", "100", "\n", "return", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.train_model.main": [[63, 173], ["transformers.BertTokenizer.from_pretrained.add_special_tokens", "dataloader.Dataloader", "dataloader.Dataloader", "dataloader.Dataloader", "dataloader.Dataloader", "disambiguator.Disambiguator", "disambiguator.Disambiguator.train", "torch.CrossEntropyLoss", "transformers.AdamW", "transformers.GPT2Tokenizer.from_pretrained", "transformers.BertTokenizer.from_pretrained", "criterion.cuda.cuda", "disambiguator.Disambiguator.parameters", "int", "disambiguator.Disambiguator.zero_grad", "dataloader.Dataloader.get_random_batch", "disambiguator.Disambiguator.", "criterion.cuda.", "criterion.backward", "transformers.AdamW.step", "float", "int", "criterion.float().item", "print", "disambiguator.Disambiguator.eval", "print", "train_model.evaluate_model", "print", "disambiguator.Disambiguator.train", "float", "print", "train_model.evaluate_model", "print", "print", "int", "criterion.float", "os.path.join", "torch.no_grad", "torch.no_grad", "train_model.evaluate_model", "os.path.join"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.train", "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.dataloader.Dataloader.get_random_batch", "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.train_model.evaluate_model", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.train", "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.train_model.evaluate_model", "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.train_model.evaluate_model"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "if", "args", "[", "\"backbone\"", "]", "==", "\"gpt2\"", ":", "\n", "        ", "tokenizer", "=", "transformers", ".", "GPT2Tokenizer", ".", "from_pretrained", "(", "\"gpt2\"", ")", "\n", "tokenizer", ".", "padding_side", "=", "\"left\"", "\n", "# Define PAD Token = EOS Token = 50256", "\n", "tokenizer", ".", "pad_token", "=", "tokenizer", ".", "eos_token", "\n", "", "else", ":", "\n", "        ", "tokenizer", "=", "transformers", ".", "BertTokenizer", ".", "from_pretrained", "(", "\"bert-base-uncased\"", ")", "\n", "", "num_added_tokens", "=", "tokenizer", ".", "add_special_tokens", "(", "\n", "{", "\"additional_special_tokens\"", ":", "[", "\"<USER>\"", ",", "\"<SYS>\"", "]", "}", "\n", ")", "\n", "# Dataloader.", "\n", "train_loader", "=", "Dataloader", "(", "tokenizer", ",", "args", "[", "\"train_file\"", "]", ",", "args", ")", "\n", "val_loader", "=", "Dataloader", "(", "tokenizer", ",", "args", "[", "\"dev_file\"", "]", ",", "args", ")", "\n", "devtest_loader", "=", "Dataloader", "(", "tokenizer", ",", "args", "[", "\"devtest_file\"", "]", ",", "args", ")", "\n", "teststd_loader", "=", "Dataloader", "(", "\n", "tokenizer", ",", "args", "[", "\"teststd_file\"", "]", ",", "args", ",", "hidden_labels", "=", "True", "\n", ")", "\n", "model", "=", "Disambiguator", "(", "tokenizer", ",", "args", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "# loss function.", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "if", "args", "[", "\"use_gpu\"", "]", ":", "\n", "        ", "criterion", "=", "criterion", ".", "cuda", "(", ")", "\n", "# Prepare optimizer and schedule (linear warmup and decay).", "\n", "", "optimizer", "=", "transformers", ".", "AdamW", "(", "\n", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", "[", "\"learning_rate\"", "]", ",", "eps", "=", "args", "[", "\"adam_epsilon\"", "]", "\n", ")", "\n", "\n", "total_steps", "=", "(", "\n", "int", "(", "train_loader", ".", "num_instances", "/", "args", "[", "\"batch_size\"", "]", "*", "args", "[", "\"num_epochs\"", "]", ")", "+", "1", "\n", ")", "\n", "num_iters_epoch", "=", "train_loader", ".", "num_instances", "//", "args", "[", "\"batch_size\"", "]", "\n", "num_iters_epoch_float", "=", "train_loader", ".", "num_instances", "/", "args", "[", "\"batch_size\"", "]", "\n", "next_eval_iter", "=", "0", "\n", "num_iters", "=", "0", "\n", "best_performance", "=", "{", "\"dev\"", ":", "0.0", "}", "\n", "total_loss", "=", "None", "\n", "while", "True", ":", "\n", "        ", "model", ".", "zero_grad", "(", ")", "\n", "\n", "epoch", "=", "num_iters", "/", "(", "float", "(", "train_loader", ".", "num_instances", ")", "/", "args", "[", "\"batch_size\"", "]", ")", "\n", "batch", "=", "train_loader", ".", "get_random_batch", "(", "args", "[", "\"batch_size\"", "]", ")", "\n", "output", "=", "model", "(", "batch", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "batch", "[", "\"gt_label\"", "]", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "loss_float", "=", "float", "(", "loss", ".", "float", "(", ")", ".", "item", "(", ")", ")", "\n", "if", "total_loss", ":", "\n", "            ", "total_loss", "=", "0.95", "*", "total_loss", "+", "0.05", "*", "loss_float", "\n", "", "else", ":", "\n", "            ", "total_loss", "=", "loss_float", "\n", "\n", "", "if", "num_iters", "%", "100", "==", "0", ":", "\n", "            ", "print", "(", "f\"[Ep: {epoch:.2f}][Loss: {total_loss:.2f}]\"", ")", "\n", "\n", "# Evaluate_model every epoch.", "\n", "", "if", "num_iters", "==", "next_eval_iter", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "print", "(", "\"Evaluating ..\"", ")", "\n", "# Get dev results.", "\n", "accuracy", "=", "evaluate_model", "(", "model", ",", "val_loader", ",", "args", "[", "\"batch_size\"", "]", ")", "\n", "print", "(", "f\"Accuracy [dev]: {accuracy}\"", ")", "\n", "\n", "# Evaluate on devtest and teststd if better dev performance.", "\n", "if", "best_performance", "[", "\"dev\"", "]", "<", "accuracy", ":", "\n", "                ", "best_performance", "[", "\"dev\"", "]", "=", "accuracy", "\n", "best_performance", "[", "\"iter_id\"", "]", "=", "num_iters", "\n", "best_performance", "[", "\"epoch\"", "]", "=", "epoch", "\n", "\n", "# Get devtest results.", "\n", "if", "args", "[", "\"result_save_path\"", "]", ":", "\n", "                    ", "save_path", "=", "os", ".", "path", ".", "join", "(", "\n", "args", "[", "\"result_save_path\"", "]", ",", "f\"results_devtest_{num_iters}.json\"", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "save_path", "=", "None", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "accuracy", "=", "evaluate_model", "(", "\n", "model", ",", "devtest_loader", ",", "args", "[", "\"batch_size\"", "]", ",", "save_path", "\n", ")", "\n", "", "best_performance", "[", "\"devtest\"", "]", "=", "accuracy", "\n", "# Check if performance is the best.", "\n", "print", "(", "f\"Accuracy [devtest]: {accuracy}\"", ")", "\n", "\n", "# Get teststd predictions.", "\n", "if", "args", "[", "\"result_save_path\"", "]", ":", "\n", "                    ", "save_path", "=", "os", ".", "path", ".", "join", "(", "\n", "args", "[", "\"result_save_path\"", "]", ",", "f\"results_teststd_{num_iters}.json\"", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "save_path", "=", "None", "\n", "", "accuracy", "=", "evaluate_model", "(", "\n", "model", ",", "\n", "teststd_loader", ",", "\n", "args", "[", "\"batch_size\"", "]", "*", "5", ",", "\n", "save_path", ",", "\n", "hidden_test", "=", "True", ",", "\n", ")", "\n", "best_performance", "[", "\"teststd\"", "]", "=", "accuracy", "\n", "print", "(", "f\"Accuracy [teststd]: {accuracy}\"", ")", "\n", "print", "(", "f\"Current best performance: {best_performance}\"", ")", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "", "num_iters", "+=", "1", "\n", "next_eval_iter", "=", "int", "(", "int", "(", "epoch", "+", "1", ")", "*", "num_iters_epoch_float", ")", "\n", "if", "epoch", ">", "args", "[", "\"num_epochs\"", "]", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.format_disambiguation_data.main": [[24, 58], ["print", "enumerate", "print", "os.path.join", "print", "open", "json.load", "enumerate", "open", "json.dump", "history.append", "turn_datum.get", "disambiguate_data.append", "history.append", "len", "copy.deepcopy"], "function", ["None"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "for", "split", "in", "SPLITS", ":", "\n", "        ", "read_path", "=", "args", "[", "f\"simmc_{split}_json\"", "]", "\n", "print", "(", "f\"Reading: {read_path}\"", ")", "\n", "with", "open", "(", "read_path", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "            ", "dialogs", "=", "json", ".", "load", "(", "file_id", ")", "\n", "\n", "# Reformat into simple strings with positive and negative labels.", "\n", "# (dialog string, label)", "\n", "", "disambiguate_data", "=", "[", "]", "\n", "for", "dialog_id", ",", "dialog_datum", "in", "enumerate", "(", "dialogs", "[", "\"dialogue_data\"", "]", ")", ":", "\n", "            ", "history", "=", "[", "]", "\n", "for", "turn_ind", ",", "turn_datum", "in", "enumerate", "(", "dialog_datum", "[", "\"dialogue\"", "]", ")", ":", "\n", "                ", "history", ".", "append", "(", "turn_datum", "[", "\"transcript\"", "]", ")", "\n", "\n", "if", "\"disambiguation_label\"", "in", "turn_datum", ":", "\n", "                    ", "label", "=", "turn_datum", "[", "\"disambiguation_label\"", "]", "\n", "new_datum", "=", "{", "\n", "\"dialog_id\"", ":", "dialog_datum", "[", "\"dialogue_idx\"", "]", ",", "\n", "\"turn_id\"", ":", "turn_ind", ",", "\n", "\"input_text\"", ":", "copy", ".", "deepcopy", "(", "history", ")", ",", "\n", "\"disambiguation_label_gt\"", ":", "label", ",", "\n", "}", "\n", "disambiguate_data", ".", "append", "(", "new_datum", ")", "\n", "# Ignore if system_transcript is not found (last round teststd).", "\n", "", "if", "turn_datum", ".", "get", "(", "\"system_transcript\"", ",", "None", ")", ":", "\n", "                    ", "history", ".", "append", "(", "turn_datum", "[", "\"system_transcript\"", "]", ")", "\n", "", "", "", "print", "(", "f\"# instances [{split}]: {len(disambiguate_data)}\"", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "\n", "args", "[", "\"disambiguate_save_path\"", "]", ",", "f\"simmc2_disambiguate_dstc10_{split}.json\"", "\n", ")", "\n", "print", "(", "f\"Saving: {save_path}\"", ")", "\n", "with", "open", "(", "save_path", ",", "\"w\"", ")", "as", "file_id", ":", "\n", "            ", "json", ".", "dump", "(", "disambiguate_data", ",", "file_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.dataloader.Dataloader.__init__": [[22, 33], ["print", "len", "open", "json.load"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "load_path", ",", "args", ",", "hidden_labels", "=", "False", ")", ":", "\n", "        ", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_args", "=", "args", "\n", "self", ".", "_hidden_labels", "=", "hidden_labels", "\n", "print", "(", "\"Loading: {}\"", ".", "format", "(", "load_path", ")", ")", "\n", "with", "open", "(", "load_path", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "            ", "self", ".", "_raw_data", "=", "json", ".", "load", "(", "file_id", ")", "\n", "\n", "", "self", ".", "num_utterances", "=", "2", "*", "args", "[", "\"max_turns\"", "]", "+", "1", "\n", "self", ".", "num_instances", "=", "len", "(", "self", ".", "_raw_data", ")", "\n", "self", ".", "device", "=", "torch", ".", "cuda", "if", "args", "[", "\"use_gpu\"", "]", "else", "torch", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.dataloader.Dataloader.get_random_batch": [[34, 37], ["numpy.random.randint", "dataloader.Dataloader.get_indexed_data"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.dataloader.Dataloader.get_indexed_data"], ["", "def", "get_random_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "indices", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "num_instances", ",", "batch_size", ")", "\n", "return", "self", ".", "get_indexed_data", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.dataloader.Dataloader.get_entire_batch": [[38, 43], ["numpy.arange", "dataloader.Dataloader.get_indexed_data"], "methods", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.dataloader.Dataloader.get_indexed_data"], ["", "def", "get_entire_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "all_indices", "=", "np", ".", "arange", "(", "self", ".", "num_instances", ")", "\n", "for", "start", "in", "all_indices", "[", ":", ":", "batch_size", "]", ":", "\n", "            ", "batch_indices", "=", "all_indices", "[", "start", ":", "start", "+", "batch_size", "]", "\n", "yield", "self", ".", "get_indexed_data", "(", "batch_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.disambiguate.dataloader.Dataloader.get_indexed_data": [[44, 85], ["dataloader.Dataloader._tokenizer", "enumerate", "text_inputs.append", "text_labels.append", "dialog_ids.append", "turn_ids.append", "val.detach", "dataloader.Dataloader.device.LongTensor", "dataloader.Dataloader.items", "val.cuda", "dataloader.Dataloader.items"], "methods", ["None"], ["", "", "def", "get_indexed_data", "(", "self", ",", "indices", ")", ":", "\n", "        ", "text_labels", "=", "[", "]", "\n", "text_inputs", "=", "[", "]", "\n", "dialog_ids", "=", "[", "]", "\n", "turn_ids", "=", "[", "]", "\n", "for", "index", "in", "indices", ":", "\n", "# Add <USER> and <SYS> tokens.", "\n", "            ", "dialog_datum", "=", "self", ".", "_raw_data", "[", "index", "]", "\n", "dialog", "=", "self", ".", "_raw_data", "[", "index", "]", "[", "\"input_text\"", "]", "\n", "for", "turn_id", ",", "turn", "in", "enumerate", "(", "dialog", ")", ":", "\n", "                ", "if", "turn_id", "%", "2", "==", "0", ":", "\n", "                    ", "dialog", "[", "turn_id", "]", "=", "\"<USER> \"", "+", "turn", "\n", "", "else", ":", "\n", "                    ", "dialog", "[", "turn_id", "]", "=", "\"<SYS> \"", "+", "turn", "\n", "", "", "text", "=", "\" \"", ".", "join", "(", "dialog", "[", "-", "self", ".", "num_utterances", ":", "]", ")", "\n", "text_inputs", ".", "append", "(", "text", ")", "\n", "text_labels", ".", "append", "(", "dialog_datum", "[", "\"disambiguation_label_gt\"", "]", ")", "\n", "dialog_ids", ".", "append", "(", "dialog_datum", "[", "\"dialog_id\"", "]", ")", "\n", "turn_ids", ".", "append", "(", "dialog_datum", "[", "\"turn_id\"", "]", ")", "\n", "\n", "", "encoded_inputs", "=", "self", ".", "_tokenizer", "(", "\n", "text_inputs", ",", "\n", "padding", "=", "True", ",", "\n", "max_length", "=", "self", ".", "_args", "[", "\"max_length\"", "]", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", "truncation", "=", "True", ",", "\n", ")", "\n", "encoded_inputs", "=", "{", "key", ":", "val", ".", "detach", "(", ")", "for", "key", ",", "val", "in", "encoded_inputs", ".", "items", "(", ")", "}", "\n", "if", "self", ".", "_args", "[", "\"use_gpu\"", "]", ":", "\n", "            ", "encoded_inputs", "=", "{", "key", ":", "val", ".", "cuda", "(", ")", "for", "key", ",", "val", "in", "encoded_inputs", ".", "items", "(", ")", "}", "\n", "", "if", "self", ".", "_hidden_labels", ":", "\n", "# Reset all the text_labels to 0.", "\n", "            ", "text_labels", "=", "[", "0", "for", "ii", "in", "text_labels", "]", "\n", "# Pack the batch.", "\n", "", "batch", "=", "{", "\n", "\"text_in\"", ":", "encoded_inputs", ",", "\n", "\"gt_label\"", ":", "self", ".", "device", ".", "LongTensor", "(", "text_labels", ")", ",", "\n", "\"dialog_id\"", ":", "dialog_ids", ",", "\n", "\"turn_id\"", ":", "turn_ids", ",", "\n", "}", "\n", "return", "batch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.evaluate_response.normalize_sentence": [[22, 25], ["nltk.tokenize.word_tokenize", "sentence.lower"], "function", ["None"], ["def", "normalize_sentence", "(", "sentence", ")", ":", "\n", "    ", "\"\"\"Normalize the sentences and tokenize.\"\"\"", "\n", "return", "nltk", ".", "tokenize", ".", "word_tokenize", "(", "sentence", ".", "lower", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.evaluate_response.parse_response_from_file": [[27, 41], ["open", "file_id.readlines", "ii.split", "lines.append", "split_line[].strip", "split_line[].strip().strip", "split_line[].strip"], "function", ["None"], ["", "def", "parse_response_from_file", "(", "input_path", ")", ":", "\n", "    ", "\"\"\"Parses the response from a flattened file.\n\n    Args:\n        input_path: Path to read the responses from.\n    \"\"\"", "\n", "lines", "=", "[", "]", "\n", "with", "open", "(", "input_path", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "        ", "for", "ii", "in", "file_id", ".", "readlines", "(", ")", ":", "\n", "            ", "split_line", "=", "ii", ".", "split", "(", "\"<SOR>\"", ",", "1", ")", "\n", "lines", ".", "append", "(", "\n", "(", "split_line", "[", "0", "]", ".", "strip", "(", "\"\\n\"", ")", ",", "split_line", "[", "1", "]", ".", "strip", "(", "\"\\n\"", ")", ".", "strip", "(", "\"<EOS>\"", ")", ")", "\n", ")", "\n", "", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.TextDataset.__init__": [[72, 93], ["os.path.isfile", "tokenizer.convert_tokens_to_ids", "range", "open", "f.read", "tokenizer.tokenize", "run_language_modeling.TextDataset.examples.append", "tokenizer.build_inputs_with_special_tokens", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ",", "file_path", ":", "str", ",", "block_size", "=", "512", "\n", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "\n", "block_size", "=", "block_size", "-", "(", "\n", "tokenizer", ".", "model_max_length", "-", "tokenizer", ".", "max_len_single_sentence", "\n", ")", "\n", "\n", "self", ".", "examples", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "text", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "tokenized_text", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "tokenize", "(", "text", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "\n", "0", ",", "len", "(", "tokenized_text", ")", "-", "block_size", "+", "1", ",", "block_size", "\n", ")", ":", "# Truncate in block of block_size", "\n", "            ", "self", ".", "examples", ".", "append", "(", "\n", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "\n", "tokenized_text", "[", "i", ":", "i", "+", "block_size", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.TextDataset.__len__": [[96, 98], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.TextDataset.__getitem__": [[99, 101], ["torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.LineByLineTextDataset.__init__": [[104, 124], ["print", "os.path.isfile", "logger.info", "open", "tokenizer.batch_encode_plus", "f.read().splitlines", "f.read", "len", "line.isspace"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", ",", "file_path", ":", "str", ",", "block_size", "=", "512", "\n", ")", ":", "\n", "        ", "print", "(", "file_path", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "file_path", ")", "\n", "# Here, we do not cache the features, operating under the assumption", "\n", "# that we will soon use fast multithreaded tokenizers from the", "\n", "# `tokenizers` repo everywhere =)", "\n", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "[", "\n", "line", "\n", "for", "line", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "if", "(", "len", "(", "line", ")", ">", "0", "and", "not", "line", ".", "isspace", "(", ")", ")", "\n", "]", "\n", "\n", "", "self", ".", "examples", "=", "tokenizer", ".", "batch_encode_plus", "(", "\n", "lines", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "block_size", "\n", ")", "[", "\"input_ids\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.LineByLineTextDataset.__len__": [[125, 127], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.LineByLineTextDataset.__getitem__": [[128, 130], ["torch.tensor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "i", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.load_and_cache_examples": [[132, 153], ["run_language_modeling.LineByLineTextDataset", "run_language_modeling.TextDataset", "len", "print", "print", "len", "len"], "function", ["None"], ["", "", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", ":", "\n", "    ", "file_path", "=", "args", ".", "eval_data_file", "if", "evaluate", "else", "args", ".", "train_data_file", "\n", "if", "args", ".", "line_by_line", ":", "\n", "        ", "dataset", "=", "LineByLineTextDataset", "(", "\n", "tokenizer", ",", "args", ",", "file_path", "=", "file_path", ",", "block_size", "=", "args", ".", "block_size", "\n", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "TextDataset", "(", "\n", "tokenizer", ",", "args", ",", "file_path", "=", "file_path", ",", "block_size", "=", "args", ".", "block_size", "\n", ")", "\n", "\n", "# Unknown issues have been reported around not being able to handle incomplete batches (e.g. w/ older CUDA 9.2)", "\n", "# Below is a workaround in case you encounter this issue.", "\n", "# Alternatively, --nocuda could avoid this issue too.", "\n", "# Comment out the following if you do not encounuter this issue or if you are not using any GPU.", "\n", "", "n", "=", "len", "(", "dataset", ")", "%", "args", ".", "per_gpu_train_batch_size", "\n", "if", "n", "!=", "0", ":", "\n", "        ", "print", "(", "\"Truncating from %d examples\"", "%", "len", "(", "dataset", ".", "examples", ")", ")", "\n", "dataset", ".", "examples", "=", "dataset", ".", "examples", "[", ":", "-", "n", "]", "\n", "print", "(", "\"Truncating to %d examples\"", "%", "len", "(", "dataset", ".", "examples", ")", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.set_seed": [[155, 161], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["", "def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling._sorted_checkpoints": [[163, 185], ["glob.glob", "sorted", "os.path.join", "ordering_and_checkpoint_path.append", "re.match", "re.match.groups", "ordering_and_checkpoint_path.append", "os.path.getmtime", "int", "re.match.groups"], "function", ["None"], ["", "", "def", "_sorted_checkpoints", "(", "\n", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "ordering_and_checkpoint_path", "=", "[", "]", "\n", "\n", "glob_checkpoints", "=", "glob", ".", "glob", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-*\"", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", ")", "\n", "\n", "for", "path", "in", "glob_checkpoints", ":", "\n", "        ", "if", "use_mtime", ":", "\n", "            ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "os", ".", "path", ".", "getmtime", "(", "path", ")", ",", "path", ")", ")", "\n", "", "else", ":", "\n", "            ", "regex_match", "=", "re", ".", "match", "(", "\".*{}-([0-9]+)\"", ".", "format", "(", "checkpoint_prefix", ")", ",", "path", ")", "\n", "if", "regex_match", "and", "regex_match", ".", "groups", "(", ")", ":", "\n", "                ", "ordering_and_checkpoint_path", ".", "append", "(", "\n", "(", "int", "(", "regex_match", ".", "groups", "(", ")", "[", "0", "]", ")", ",", "path", ")", "\n", ")", "\n", "\n", "", "", "", "checkpoints_sorted", "=", "sorted", "(", "ordering_and_checkpoint_path", ")", "\n", "checkpoints_sorted", "=", "[", "checkpoint", "[", "1", "]", "for", "checkpoint", "in", "checkpoints_sorted", "]", "\n", "return", "checkpoints_sorted", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling._rotate_checkpoints": [[187, 209], ["run_language_modeling._sorted_checkpoints", "max", "len", "logger.info", "shutil.rmtree", "len"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling._sorted_checkpoints"], ["", "def", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", "->", "None", ":", "\n", "    ", "if", "not", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "", "if", "args", ".", "save_total_limit", "<=", "0", ":", "\n", "        ", "return", "\n", "\n", "# Check if we should delete older checkpoint(s)", "\n", "", "checkpoints_sorted", "=", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", ",", "use_mtime", ")", "\n", "if", "len", "(", "checkpoints_sorted", ")", "<=", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "\n", "", "number_of_checkpoints_to_delete", "=", "max", "(", "\n", "0", ",", "len", "(", "checkpoints_sorted", ")", "-", "args", ".", "save_total_limit", "\n", ")", "\n", "checkpoints_to_be_deleted", "=", "checkpoints_sorted", "[", ":", "number_of_checkpoints_to_delete", "]", "\n", "for", "checkpoint", "in", "checkpoints_to_be_deleted", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Deleting older checkpoint [{}] due to args.save_total_limit\"", ".", "format", "(", "\n", "checkpoint", "\n", ")", "\n", ")", "\n", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.mask_tokens": [[211, 254], ["inputs.clone", "torch.full", "torch.full.masked_fill_", "torch.bernoulli().bool", "tokenizer.convert_tokens_to_ids", "torch.randint", "ValueError", "tokenizer.get_special_tokens_mask", "torch.tensor", "inputs.clone.eq", "torch.full.masked_fill_", "torch.bernoulli().bool", "len", "inputs.clone.tolist", "torch.bernoulli", "torch.bernoulli().bool", "torch.bernoulli", "torch.full", "torch.bernoulli", "torch.full"], "function", ["None"], ["", "", "def", "mask_tokens", "(", "\n", "inputs", ":", "torch", ".", "Tensor", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "args", "\n", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original.\"\"\"", "\n", "\n", "if", "tokenizer", ".", "mask_token", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"", "\n", ")", "\n", "\n", "", "labels", "=", "inputs", ".", "clone", "(", ")", "\n", "# We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)", "\n", "probability_matrix", "=", "torch", ".", "full", "(", "labels", ".", "shape", ",", "args", ".", "mlm_probability", ")", "\n", "special_tokens_mask", "=", "[", "\n", "tokenizer", ".", "get_special_tokens_mask", "(", "val", ",", "already_has_special_tokens", "=", "True", ")", "\n", "for", "val", "in", "labels", ".", "tolist", "(", ")", "\n", "]", "\n", "probability_matrix", ".", "masked_fill_", "(", "\n", "torch", ".", "tensor", "(", "special_tokens_mask", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "value", "=", "0.0", "\n", ")", "\n", "if", "tokenizer", ".", "_pad_token", "is", "not", "None", ":", "\n", "        ", "padding_mask", "=", "labels", ".", "eq", "(", "tokenizer", ".", "pad_token_id", ")", "\n", "probability_matrix", ".", "masked_fill_", "(", "padding_mask", ",", "value", "=", "0.0", ")", "\n", "", "masked_indices", "=", "torch", ".", "bernoulli", "(", "probability_matrix", ")", ".", "bool", "(", ")", "\n", "labels", "[", "~", "masked_indices", "]", "=", "-", "100", "# We only compute loss on masked tokens", "\n", "\n", "# 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])", "\n", "indices_replaced", "=", "(", "\n", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "0.8", ")", ")", ".", "bool", "(", ")", "&", "masked_indices", "\n", ")", "\n", "inputs", "[", "indices_replaced", "]", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokenizer", ".", "mask_token", ")", "\n", "\n", "# 10% of the time, we replace masked input tokens with random word", "\n", "indices_random", "=", "(", "\n", "torch", ".", "bernoulli", "(", "torch", ".", "full", "(", "labels", ".", "shape", ",", "0.5", ")", ")", ".", "bool", "(", ")", "\n", "&", "masked_indices", "\n", "&", "~", "indices_replaced", "\n", ")", "\n", "random_words", "=", "torch", ".", "randint", "(", "len", "(", "tokenizer", ")", ",", "labels", ".", "shape", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "inputs", "[", "indices_random", "]", "=", "random_words", "[", "indices_random", "]", "\n", "\n", "# The rest of the time (10% of the time) we keep the masked input tokens unchanged", "\n", "return", "inputs", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.train": [[256, 539], ["torch.utils.data.DataLoader", "torch.nn.parallel.DistributedDataParallel.resize_token_embeddings", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_language_modeling.set_seed", "SummaryWriter", "max", "torch.nn.utils.rnn.pad_sequence", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "hasattr", "len", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "os.path.exists", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "torch.nn.utils.rnn.pad_sequence", "os.path.join", "os.path.join", "torch.load", "torch.load", "int", "logger.info", "logger.info", "logger.info", "logger.info", "inputs.to.to", "labels.to.to", "torch.nn.parallel.DistributedDataParallel.train", "loss.mean.item", "tqdm.trange.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "[].split", "logger.info", "run_language_modeling.mask_tokens", "torch.nn.parallel.DistributedDataParallel.", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "len", "len", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "os.path.join", "os.makedirs", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "run_language_modeling._rotate_checkpoints", "torch.save", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_language_modeling.evaluate", "evaluate.items", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "args.model_name_or_path.split", "SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.set_seed", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.train", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.mask_tokens", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling._rotate_checkpoints", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.evaluate"], ["", "def", "train", "(", "\n", "args", ",", "train_dataset", ",", "model", ":", "PreTrainedModel", ",", "tokenizer", ":", "PreTrainedTokenizer", "\n", ")", "->", "Tuple", "[", "int", ",", "float", "]", ":", "\n", "    ", "\"\"\"Train the model\"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "if", "tokenizer", ".", "_pad_token", "is", "None", ":", "\n", "            ", "return", "pad_sequence", "(", "examples", ",", "batch_first", "=", "True", ")", "\n", "", "return", "pad_sequence", "(", "\n", "examples", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", "\n", ")", "\n", "\n", "", "train_sampler", "=", "(", "\n", "RandomSampler", "(", "train_dataset", ")", "\n", "if", "args", ".", "local_rank", "==", "-", "1", "\n", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ",", "\n", "collate_fn", "=", "collate", ",", "\n", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "(", "\n", "args", ".", "max_steps", "\n", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "+", "1", "\n", ")", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "(", "\n", "len", "(", "train_dataloader", ")", "\n", "//", "args", ".", "gradient_accumulation_steps", "\n", "*", "args", ".", "num_train_epochs", "\n", ")", "\n", "\n", "", "model", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "\n", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", "\n", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "(", "\n", "args", ".", "model_name_or_path", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "\n", ")", "\n", "scheduler", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", "\n", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", "\n", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "\n", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", "\n", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "\n", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ",", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "args", ".", "model_name_or_path", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "        ", "try", ":", "\n", "# set global_step to gobal_step of last saved checkpoint from model path", "\n", "            ", "checkpoint_suffix", "=", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "global_step", "=", "int", "(", "checkpoint_suffix", ")", "\n", "epochs_trained", "=", "global_step", "//", "(", "\n", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "\n", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "\n", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "\"  Continuing training from checkpoint, will skip to saved global_step\"", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Will skip the first %d steps in the first epoch\"", ",", "\n", "steps_trained_in_current_epoch", ",", "\n", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Starting fine-tuning.\"", ")", "\n", "\n", "", "", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "\n", "int", "(", "args", ".", "num_train_epochs", ")", ",", "\n", "desc", "=", "\"Epoch\"", ",", "\n", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "\n", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproducibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "\n", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "\n", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "inputs", ",", "labels", "=", "(", "\n", "mask_tokens", "(", "batch", ",", "tokenizer", ",", "args", ")", "if", "args", ".", "mlm", "else", "(", "batch", ",", "batch", ")", "\n", ")", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "outputs", "=", "(", "\n", "model", "(", "inputs", ",", "masked_lm_labels", "=", "labels", ")", "\n", "if", "args", ".", "mlm", "\n", "else", "model", "(", "inputs", ",", "labels", "=", "labels", ")", "\n", ")", "\n", "loss", "=", "outputs", "[", "\n", "0", "\n", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", "\n", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "(", "\n", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "\n", "and", "args", ".", "logging_steps", ">", "0", "\n", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", "\n", ")", ":", "\n", "# Log metrics", "\n", "                    ", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\n", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", "\n", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\n", "\"loss\"", ",", "\n", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "\n", "global_step", ",", "\n", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "if", "(", "\n", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "\n", "and", "args", ".", "save_steps", ">", "0", "\n", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", "\n", ")", ":", "\n", "                    ", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "# Save model checkpoint", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "global_step", ")", "\n", ")", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ")", "\n", "\n", "torch", ".", "save", "(", "\n", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", "\n", ")", "\n", "torch", ".", "save", "(", "\n", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", "\n", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.evaluate": [[541, 612], ["run_language_modeling.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "tqdm.tqdm", "torch.exp", "os.path.join", "os.makedirs", "max", "torch.nn.utils.rnn.pad_sequence", "torch.nn.DataParallel", "len", "inputs.to.to", "labels.to.to", "torch.tensor", "open", "logger.info", "sorted", "torch.nn.utils.rnn.pad_sequence", "run_language_modeling.mask_tokens", "torch.no_grad", "lm_loss.mean().item", "result.keys", "logger.info", "writer.write", "torch.nn.DataParallel.", "torch.nn.DataParallel.", "str", "lm_loss.mean", "str"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.load_and_cache_examples", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.mask_tokens"], ["", "def", "evaluate", "(", "\n", "args", ",", "model", ":", "PreTrainedModel", ",", "tokenizer", ":", "PreTrainedTokenizer", ",", "prefix", "=", "\"\"", "\n", ")", "->", "Dict", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "\n", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ")", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "\n", "def", "collate", "(", "examples", ":", "List", "[", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "if", "tokenizer", ".", "_pad_token", "is", "None", ":", "\n", "            ", "return", "pad_sequence", "(", "examples", ",", "batch_first", "=", "True", ")", "\n", "", "return", "pad_sequence", "(", "\n", "examples", ",", "batch_first", "=", "True", ",", "padding_value", "=", "tokenizer", ".", "pad_token_id", "\n", ")", "\n", "\n", "", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_dataset", ",", "\n", "sampler", "=", "eval_sampler", ",", "\n", "batch_size", "=", "args", ".", "eval_batch_size", ",", "\n", "collate_fn", "=", "collate", ",", "\n", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "inputs", ",", "labels", "=", "(", "\n", "mask_tokens", "(", "batch", ",", "tokenizer", ",", "args", ")", "if", "args", ".", "mlm", "else", "(", "batch", ",", "batch", ")", "\n", ")", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "(", "\n", "model", "(", "inputs", ",", "masked_lm_labels", "=", "labels", ")", "\n", "if", "args", ".", "mlm", "\n", "else", "model", "(", "inputs", ",", "labels", "=", "labels", ")", "\n", ")", "\n", "lm_loss", "=", "outputs", "[", "0", "]", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "eval_loss", ")", ")", "\n", "\n", "result", "=", "{", "\"perplexity\"", ":", "perplexity", "}", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.main": [[614, 1043], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_language_modeling.set_seed", "AutoModelWithLMHead.from_pretrained.to", "logger.info", "ValueError", "ValueError", "run_language_modeling._sorted_checkpoints", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "AutoTokenizer.from_pretrained.add_special_tokens", "logger.info", "logger.info", "min", "transformers.AutoModelWithLMHead.from_pretrained", "logger.info", "transformers.AutoModelWithLMHead.from_config", "AutoModelWithLMHead.from_pretrained.resize_token_embeddings", "torch.distributed.barrier", "run_language_modeling.load_and_cache_examples", "run_language_modeling.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "AutoTokenizer.from_pretrained.save_pretrained", "torch.save", "transformers.AutoModelWithLMHead.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "AutoModelWithLMHead.from_pretrained.to", "logger.info", "len", "ValueError", "torch.cuda.device_count", "transformers.AutoConfig.from_pretrained", "ValueError", "transformers.AutoTokenizer.from_pretrained", "ValueError", "os.path.exists", "ValueError", "open", "json.load", "len", "torch.distributed.barrier", "torch.distributed.barrier", "os.makedirs", "hasattr", "os.path.join", "logging.getLogger().setLevel", "transformers.AutoModelWithLMHead.from_pretrained", "AutoModelWithLMHead.from_pretrained.to", "run_language_modeling.evaluate", "results.update", "bool", "torch.distributed.get_rank", "os.path.dirname", "torch.cuda.is_available", "sorted", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "evaluate.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.set_seed", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling._sorted_checkpoints", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.load_and_cache_examples", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.train", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_language_modeling.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_data_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file (a text file).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The model architecture to be trained or fine-tuned.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_data_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--line_by_line\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether distinct lines of text in the dataset are to be handled as distinct sequences.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--should_continue\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to continue from latest checkpoint in output_dir\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization. Leave None if you want to train a model from scratch.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Train with masked-language modeling loss instead of language modeling.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mlm_probability\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.15", ",", "\n", "help", "=", "\"Ratio of tokens to mask for masked language modeling loss\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path. If both are None, initialize a new config.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path. If both are None, initialize a new tokenizer.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--add_special_tokens\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional file containing a JSON dictionary of special tokens that should be added to the tokenizer.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instead of the default one)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_size\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Run evaluation during training at each logging step.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_train_batch_size\"", ",", "\n", "default", "=", "4", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "\n", "default", "=", "4", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--learning_rate\"", ",", "\n", "default", "=", "5e-5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "\n", "default", "=", "1.0", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "500", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_total_limit\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--local_rank\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"For distributed training: local_rank\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "(", "\n", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"roberta\"", ",", "\"distilbert\"", ",", "\"camembert\"", "]", "\n", "and", "not", "args", ".", "mlm", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"BERT and RoBERTa-like models do not have LM heads but masked LM heads. They must be run using the --mlm \"", "\n", "\"flag (masked language modeling).\"", "\n", ")", "\n", "", "if", "args", ".", "eval_data_file", "is", "None", "and", "args", ".", "do_eval", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Cannot do evaluation without an evaluation data file. Either supply a file to --eval_data_file \"", "\n", "\"or remove the --do_eval argument.\"", "\n", ")", "\n", "", "if", "args", ".", "should_continue", ":", "\n", "        ", "sorted_checkpoints", "=", "_sorted_checkpoints", "(", "args", ")", "\n", "if", "len", "(", "sorted_checkpoints", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Used --should_continue but no checkpoint was found in --output_dir.\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "args", ".", "model_name_or_path", "=", "sorted_checkpoints", "[", "-", "1", "]", "\n", "\n", "", "", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", "and", "not", "args", ".", "should_continue", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "\n", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", "\n", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\n", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", "\n", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "if", "args", ".", "config_name", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "args", ".", "config_name", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", "\n", ")", "\n", "", "else", ":", "\n", "# When we release a pip version exposing CONFIG_MAPPING,", "\n", "# we can do `config = CONFIG_MAPPING[args.model_type]()`.", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new config instance from scratch. This is not supported, but you can do it from another script, save it,\"", "\n", "\"and load it from here, using --config_name\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", ",", "cache_dir", "=", "args", ".", "cache_dir", "\n", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new tokenizer from scratch. This is not supported, but you can do it from another script, save it,\"", "\n", "\"and load it from here, using --tokenizer_name\"", "\n", ")", "\n", "\n", "", "if", "args", ".", "add_special_tokens", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "add_special_tokens", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Additional special tokens file {args.add_special_tokens} not found}\"", "\n", ")", "\n", "", "with", "open", "(", "args", ".", "add_special_tokens", ",", "\"rb\"", ")", "as", "handle", ":", "\n", "            ", "special_tokens_dict", "=", "json", ".", "load", "(", "handle", ")", "\n", "", "num_added_toks", "=", "tokenizer", ".", "add_special_tokens", "(", "special_tokens_dict", ")", "\n", "logger", ".", "info", "(", "f\"Added {num_added_toks} tokens\"", ")", "\n", "logger", ".", "info", "(", "f\"All special tokens: {tokenizer.all_special_tokens}\"", ")", "\n", "\n", "", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "        ", "args", ".", "block_size", "=", "tokenizer", ".", "model_max_length", "\n", "# Our input block size will be the max possible for the model", "\n", "", "else", ":", "\n", "        ", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "", "if", "args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Training new model from scratch\"", ")", "\n", "model", "=", "AutoModelWithLMHead", ".", "from_config", "(", "config", ")", "\n", "\n", "# ensure model aligns with any addition of special tokens", "\n", "# (unclear if this step is needed for a new model)", "\n", "", "if", "args", ".", "add_special_tokens", ":", "\n", "        ", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# End of barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use save_pretrained for the model and tokenizer, you can reload them using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "[", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "\n", "for", "c", "in", "sorted", "(", "\n", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", "\n", ")", "\n", "]", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "\n", "logging", ".", "WARN", "\n", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "(", "\n", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", ")", "\n", "\n", "model", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "prefix", ")", "\n", "result", "=", "{", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ":", "v", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", "}", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.format_retrieval_results.main": [[17, 52], ["print", "print", "sum", "print", "open", "json.load", "open", "len", "enumerate", "formatted_result.append", "open", "json.dump", "float", "len", "new_entry[].append", "file_id.readlines"], "function", ["None"], ["def", "main", "(", "args", ")", ":", "\n", "    ", "print", "(", "f\"\"\"Reading dialogs: {args[\"dialog_json_file\"]}\"\"\"", ")", "\n", "with", "open", "(", "args", "[", "\"dialog_json_file\"", "]", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "        ", "dialogs", "=", "json", ".", "load", "(", "file_id", ")", "\n", "\n", "", "print", "(", "f\"\"\"Reading outputs: {args[\"model_output_file\"]}\"\"\"", ")", "\n", "with", "open", "(", "args", "[", "\"model_output_file\"", "]", ",", "\"r\"", ")", "as", "file_id", ":", "\n", "        ", "scores", "=", "[", "float", "(", "ii", ")", "for", "ii", "in", "file_id", ".", "readlines", "(", ")", "]", "\n", "\n", "# Number of scores should match number of instances.", "\n", "", "num_turns", "=", "sum", "(", "len", "(", "ii", "[", "\"dialogue\"", "]", ")", "for", "ii", "in", "dialogs", "[", "\"dialogue_data\"", "]", ")", "\n", "assert", "len", "(", "scores", ")", "==", "NUM_OPTIONS", "*", "num_turns", ",", "\"#turns do not match!\"", "\n", "\n", "formatted_result", "=", "[", "]", "\n", "num_turns", "=", "0", "\n", "for", "dialog_datum", "in", "dialogs", "[", "\"dialogue_data\"", "]", ":", "\n", "        ", "dialog_id", "=", "dialog_datum", "[", "\"dialogue_idx\"", "]", "\n", "new_entry", "=", "{", "\"dialog_id\"", ":", "dialog_id", ",", "\"candidate_scores\"", ":", "[", "]", "}", "\n", "for", "turn_id", ",", "turn_datum", "in", "enumerate", "(", "dialog_datum", "[", "\"dialogue\"", "]", ")", ":", "\n", "            ", "start_ind", "=", "num_turns", "*", "NUM_OPTIONS", "\n", "end_ind", "=", "(", "num_turns", "+", "1", ")", "*", "NUM_OPTIONS", "\n", "\n", "# Scores are NLL, lower is better, hence -1.", "\n", "new_turn_entry", "=", "{", "\n", "\"turn_id\"", ":", "turn_id", ",", "\n", "\"scores\"", ":", "[", "-", "1", "*", "ii", "for", "ii", "in", "scores", "[", "start_ind", ":", "end_ind", "]", "]", ",", "\n", "}", "\n", "num_turns", "+=", "1", "\n", "new_entry", "[", "\"candidate_scores\"", "]", ".", "append", "(", "new_turn_entry", ")", "\n", "", "formatted_result", ".", "append", "(", "new_entry", ")", "\n", "\n", "# Write the result back.", "\n", "", "print", "(", "f\"\"\"Saving: {args[\"formatted_output_file\"]}\"\"\"", ")", "\n", "with", "open", "(", "args", "[", "\"formatted_output_file\"", "]", ",", "\"w\"", ")", "as", "file_id", ":", "\n", "        ", "json", ".", "dump", "(", "formatted_result", ",", "file_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_retrieval.set_seed": [[79, 84], ["numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_retrieval.prepare_ctrl_input": [[91, 103], ["tokenizer.encode", "logger.info", "any", "logger.info", "tokenizer.control_codes.values"], "function", ["None"], ["", "", "def", "prepare_ctrl_input", "(", "args", ",", "_", ",", "tokenizer", ",", "prompt_text", ")", ":", "\n", "    ", "if", "args", ".", "temperature", ">", "0.7", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"CTRL typically works better with lower temperatures (and lower top_k).\"", "\n", ")", "\n", "\n", "", "encoded_prompt", "=", "tokenizer", ".", "encode", "(", "prompt_text", ",", "add_special_tokens", "=", "True", ")", "\n", "if", "not", "any", "(", "encoded_prompt", "[", "0", "]", "==", "x", "for", "x", "in", "tokenizer", ".", "control_codes", ".", "values", "(", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"WARNING! You are not starting your generation from a control code so you won't get good results\"", "\n", ")", "\n", "", "return", "prompt_text", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_retrieval.prepare_xlm_input": [[105, 133], ["hasattr", "hasattr", "model.config.lang2id.keys", "input", "str", "list"], "function", ["None"], ["", "def", "prepare_xlm_input", "(", "args", ",", "model", ",", "tokenizer", ",", "prompt_text", ")", ":", "\n", "# kwargs = {\"language\": None, \"mask_token_id\": None}", "\n", "\n", "# Set the language", "\n", "    ", "use_lang_emb", "=", "hasattr", "(", "model", ".", "config", ",", "\"use_lang_emb\"", ")", "and", "model", ".", "config", ".", "use_lang_emb", "\n", "if", "hasattr", "(", "model", ".", "config", ",", "\"lang2id\"", ")", "and", "use_lang_emb", ":", "\n", "        ", "available_languages", "=", "model", ".", "config", ".", "lang2id", ".", "keys", "(", ")", "\n", "if", "args", ".", "xlm_language", "in", "available_languages", ":", "\n", "            ", "language", "=", "args", ".", "xlm_language", "\n", "", "else", ":", "\n", "            ", "language", "=", "None", "\n", "while", "language", "not", "in", "available_languages", ":", "\n", "                ", "language", "=", "input", "(", "\n", "\"Using XLM. Select language in \"", "\n", "+", "str", "(", "list", "(", "available_languages", ")", ")", "\n", "+", "\" >>> \"", "\n", ")", "\n", "\n", "", "", "model", ".", "config", ".", "lang_id", "=", "model", ".", "config", ".", "lang2id", "[", "language", "]", "\n", "# kwargs[\"language\"] = tokenizer.lang2id[language]", "\n", "\n", "# TODO fix mask_token_id setup when configurations will be synchronized between models and tokenizers", "\n", "# XLM masked-language modeling (MLM) models need masked token", "\n", "# is_xlm_mlm = \"mlm\" in args.model_name_or_path", "\n", "# if is_xlm_mlm:", "\n", "#     kwargs[\"mask_token_id\"] = tokenizer.mask_token_id", "\n", "\n", "", "return", "prompt_text", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_retrieval.prepare_xlnet_input": [[135, 140], ["None"], "function", ["None"], ["", "def", "prepare_xlnet_input", "(", "args", ",", "_", ",", "tokenizer", ",", "prompt_text", ")", ":", "\n", "    ", "prompt_text", "=", "(", "\n", "args", ".", "padding_text", "if", "args", ".", "padding_text", "else", "PADDING_TEXT", "\n", ")", "+", "prompt_text", "\n", "return", "prompt_text", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_retrieval.prepare_transfoxl_input": [[142, 147], ["None"], "function", ["None"], ["", "def", "prepare_transfoxl_input", "(", "args", ",", "_", ",", "tokenizer", ",", "prompt_text", ")", ":", "\n", "    ", "prompt_text", "=", "(", "\n", "args", ".", "padding_text", "if", "args", ".", "padding_text", "else", "PADDING_TEXT", "\n", ")", "+", "prompt_text", "\n", "return", "prompt_text", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_retrieval.adjust_length_to_model": [[157, 165], ["None"], "function", ["None"], ["def", "adjust_length_to_model", "(", "length", ",", "max_sequence_length", ")", ":", "\n", "    ", "if", "length", "<", "0", "and", "max_sequence_length", ">", "0", ":", "\n", "        ", "length", "=", "max_sequence_length", "\n", "", "elif", "0", "<", "max_sequence_length", "<", "length", ":", "\n", "        ", "length", "=", "max_sequence_length", "# No generation bigger than model size", "\n", "", "elif", "length", "<", "0", ":", "\n", "        ", "length", "=", "MAX_LENGTH", "# avoid infinite loop", "\n", "", "return", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_retrieval.main": [[167, 308], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.device", "run_retrieval.set_seed", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_retrieval.adjust_length_to_model", "logger.info", "torch.cuda.device_count", "Exception", "parser.parse_args.model_type.lower", "os.path.dirname", "os.path.exists", "KeyError", "open", "handle.readlines", "torch.no_grad", "len", "tqdm.tqdm", "os.path.exists", "os.makedirs", "open", "torch.cuda.is_available", "enumerate", "prompt_text.strip.strip", "tokenizer.encode.to", "model_class.from_pretrained.", "results.append", "f_out.write", "MODEL_CLASSES.keys", "MODEL_CLASSES.keys", "input", "PREPROCESSING_FUNCTIONS.keys", "PREPROCESSING_FUNCTIONS.get", "PREPROCESSING_FUNCTIONS.get.", "tokenizer_class.from_pretrained.encode", "tokenizer_class.from_pretrained.encode", "float", "len", "prompts[].strip", "prompts[].lower", "outputs[].cpu().item", "outputs[].cpu"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.set_seed", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.adjust_length_to_model"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", "\n", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--prompt\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--prompts_from_file\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"\"\"\nread prompts from a file and generate, overrides any prompt given on the\ncommand line\"\"\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--length\"", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--padding_text\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Padding text for Transfo-XL and XLNet.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--xlm_language\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Optional language when used with the XLM model.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--path_output\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Path to output predictions in a line separated text file.\"", ",", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "args", ".", "device", "=", "torch", ".", "device", "(", "\n", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", "\n", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "set_seed", "(", "args", ")", "\n", "\n", "if", "args", ".", "prompts_from_file", "and", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "prompts_from_file", ")", ":", "\n", "        ", "raise", "Exception", "(", "f\"prompt file '{args.prompts_from_file}' not found\"", ")", "\n", "\n", "# Initialize the model and tokenizer", "\n", "", "try", ":", "\n", "        ", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "", "except", "KeyError", ":", "\n", "        ", "raise", "KeyError", "(", "\n", "\"the model {} you specified is not supported. You are welcome to add it and open a PR :)\"", "\n", ")", "\n", "\n", "", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "args", ".", "length", "=", "adjust_length_to_model", "(", "\n", "args", ".", "length", ",", "max_sequence_length", "=", "model", ".", "config", ".", "max_position_embeddings", "\n", ")", "\n", "logger", ".", "info", "(", "args", ")", "\n", "\n", "results", "=", "[", "]", "\n", "prompts", "=", "[", "]", "\n", "if", "args", ".", "prompts_from_file", ":", "\n", "        ", "with", "open", "(", "args", ".", "prompts_from_file", ")", "as", "handle", ":", "\n", "            ", "prompts", "=", "handle", ".", "readlines", "(", ")", "\n", "\n", "", "", "while", "True", ":", "\n", "        ", "if", "not", "prompts", ":", "\n", "            ", "prompts", "=", "[", "args", ".", "prompt", "if", "args", ".", "prompt", "else", "input", "(", "\"Model prompt >>> \"", ")", "]", "\n", "if", "not", "args", ".", "prompt", "and", "(", "\n", "len", "(", "prompts", ")", "==", "0", "\n", "or", "prompts", "[", "0", "]", ".", "strip", "(", ")", "==", "\"\"", "\n", "or", "prompts", "[", "0", "]", ".", "lower", "(", ")", "==", "\"quit\"", "\n", ")", ":", "\n", "                ", "break", "# break while True loop", "\n", "\n", "", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "n_prompts", "=", "len", "(", "prompts", ")", "\n", "for", "i", ",", "prompt_text", "in", "progressbar", "(", "enumerate", "(", "prompts", ")", ",", "total", "=", "n_prompts", ")", ":", "\n", "# Strip any trailing \\n if provided", "\n", "                ", "prompt_text", "=", "prompt_text", ".", "strip", "(", "\"\\n\"", ")", "\n", "\n", "# Different models need different input formatting and/or extra arguments", "\n", "requires_preprocessing", "=", "args", ".", "model_type", "in", "PREPROCESSING_FUNCTIONS", ".", "keys", "(", ")", "\n", "if", "requires_preprocessing", ":", "\n", "                    ", "prepare_input", "=", "PREPROCESSING_FUNCTIONS", ".", "get", "(", "args", ".", "model_type", ")", "\n", "preprocessed_prompt_text", "=", "prepare_input", "(", "\n", "args", ",", "model", ",", "tokenizer", ",", "prompt_text", "\n", ")", "\n", "encoded_prompt", "=", "tokenizer", ".", "encode", "(", "\n", "preprocessed_prompt_text", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", "add_space_before_punct_symbol", "=", "True", ",", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "encoded_prompt", "=", "tokenizer", ".", "encode", "(", "\n", "prompt_text", ",", "add_special_tokens", "=", "True", ",", "return_tensors", "=", "\"pt\"", "\n", ")", "\n", "", "encoded_prompt", "=", "encoded_prompt", ".", "to", "(", "args", ".", "device", ")", "\n", "outputs", "=", "model", "(", "encoded_prompt", ",", "labels", "=", "encoded_prompt", ")", "\n", "results", ".", "append", "(", "float", "(", "outputs", "[", "0", "]", ".", "cpu", "(", ")", ".", "item", "(", ")", ")", ")", "\n", "\n", "", "", "prompts", "=", "[", "]", "\n", "if", "args", ".", "prompt", "or", "args", ".", "prompts_from_file", ":", "\n", "            ", "break", "# break while True loop", "\n", "\n", "", "", "if", "args", ".", "path_output", "is", "not", "None", ":", "\n", "# Create a directory if it does not exist", "\n", "        ", "directory", "=", "os", ".", "path", ".", "dirname", "(", "args", ".", "path_output", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "directory", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Save to a file", "\n", "", "with", "open", "(", "args", ".", "path_output", ",", "\"w\"", ")", "as", "f_out", ":", "\n", "            ", "for", "ii", "in", "results", ":", "\n", "                ", "f_out", ".", "write", "(", "f\"{ii}\\n\"", ")", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.set_seed": [[78, 83], ["numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.prepare_ctrl_input": [[90, 102], ["tokenizer.encode", "logger.info", "any", "logger.info", "tokenizer.control_codes.values"], "function", ["None"], ["", "", "def", "prepare_ctrl_input", "(", "args", ",", "_", ",", "tokenizer", ",", "prompt_text", ")", ":", "\n", "    ", "if", "args", ".", "temperature", ">", "0.7", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"CTRL typically works better with lower temperatures (and lower top_k).\"", "\n", ")", "\n", "\n", "", "encoded_prompt", "=", "tokenizer", ".", "encode", "(", "prompt_text", ",", "add_special_tokens", "=", "True", ")", "\n", "if", "not", "any", "(", "encoded_prompt", "[", "0", "]", "==", "x", "for", "x", "in", "tokenizer", ".", "control_codes", ".", "values", "(", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"WARNING! You are not starting your generation from a control code so you won't get good results\"", "\n", ")", "\n", "", "return", "prompt_text", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.prepare_xlm_input": [[104, 132], ["hasattr", "hasattr", "model.config.lang2id.keys", "input", "str", "list"], "function", ["None"], ["", "def", "prepare_xlm_input", "(", "args", ",", "model", ",", "tokenizer", ",", "prompt_text", ")", ":", "\n", "# kwargs = {\"language\": None, \"mask_token_id\": None}", "\n", "\n", "# Set the language", "\n", "    ", "use_lang_emb", "=", "hasattr", "(", "model", ".", "config", ",", "\"use_lang_emb\"", ")", "and", "model", ".", "config", ".", "use_lang_emb", "\n", "if", "hasattr", "(", "model", ".", "config", ",", "\"lang2id\"", ")", "and", "use_lang_emb", ":", "\n", "        ", "available_languages", "=", "model", ".", "config", ".", "lang2id", ".", "keys", "(", ")", "\n", "if", "args", ".", "xlm_language", "in", "available_languages", ":", "\n", "            ", "language", "=", "args", ".", "xlm_language", "\n", "", "else", ":", "\n", "            ", "language", "=", "None", "\n", "while", "language", "not", "in", "available_languages", ":", "\n", "                ", "language", "=", "input", "(", "\n", "\"Using XLM. Select language in \"", "\n", "+", "str", "(", "list", "(", "available_languages", ")", ")", "\n", "+", "\" >>> \"", "\n", ")", "\n", "\n", "", "", "model", ".", "config", ".", "lang_id", "=", "model", ".", "config", ".", "lang2id", "[", "language", "]", "\n", "# kwargs[\"language\"] = tokenizer.lang2id[language]", "\n", "\n", "# TODO fix mask_token_id setup when configurations will be synchronized between models and tokenizers", "\n", "# XLM masked-language modeling (MLM) models need masked token", "\n", "# is_xlm_mlm = \"mlm\" in args.model_name_or_path", "\n", "# if is_xlm_mlm:", "\n", "#     kwargs[\"mask_token_id\"] = tokenizer.mask_token_id", "\n", "\n", "", "return", "prompt_text", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.prepare_xlnet_input": [[134, 139], ["None"], "function", ["None"], ["", "def", "prepare_xlnet_input", "(", "args", ",", "_", ",", "tokenizer", ",", "prompt_text", ")", ":", "\n", "    ", "prompt_text", "=", "(", "\n", "args", ".", "padding_text", "if", "args", ".", "padding_text", "else", "PADDING_TEXT", "\n", ")", "+", "prompt_text", "\n", "return", "prompt_text", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.prepare_transfoxl_input": [[141, 146], ["None"], "function", ["None"], ["", "def", "prepare_transfoxl_input", "(", "args", ",", "_", ",", "tokenizer", ",", "prompt_text", ")", ":", "\n", "    ", "prompt_text", "=", "(", "\n", "args", ".", "padding_text", "if", "args", ".", "padding_text", "else", "PADDING_TEXT", "\n", ")", "+", "prompt_text", "\n", "return", "prompt_text", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.adjust_length_to_model": [[156, 164], ["None"], "function", ["None"], ["def", "adjust_length_to_model", "(", "length", ",", "max_sequence_length", ")", ":", "\n", "    ", "if", "length", "<", "0", "and", "max_sequence_length", ">", "0", ":", "\n", "        ", "length", "=", "max_sequence_length", "\n", "", "elif", "0", "<", "max_sequence_length", "<", "length", ":", "\n", "        ", "length", "=", "max_sequence_length", "# No generation bigger than model size", "\n", "", "elif", "length", "<", "0", ":", "\n", "        ", "length", "=", "MAX_LENGTH", "# avoid infinite loop", "\n", "", "return", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.main": [[166, 393], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.device", "run_generation.set_seed", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_generation.adjust_length_to_model", "logger.info", "torch.cuda.device_count", "Exception", "parser.parse_args.model_type.lower", "len", "enumerate", "os.path.dirname", "os.path.exists", "KeyError", "open", "handle.readlines", "prompt_text.strip.strip", "tokenizer.encode.to", "model_class.from_pretrained.generate", "enumerate", "results.append", "os.path.exists", "os.makedirs", "open", "f_out.write", "torch.cuda.is_available", "PREPROCESSING_FUNCTIONS.keys", "PREPROCESSING_FUNCTIONS.get", "PREPROCESSING_FUNCTIONS.get.", "tokenizer_class.from_pretrained.encode", "tokenizer_class.from_pretrained.encode", "len", "model.generate.squeeze_", "print", "generated_sequence.tolist.tolist", "tokenizer_class.from_pretrained.decode", "generated_sequences.append", "print", "MODEL_CLASSES.keys", "MODEL_CLASSES.keys", "input", "len", "prompts[].strip", "prompts[].lower", "len", "tokenizer.decode.find", "len", "tokenizer_class.from_pretrained.decode"], "function", ["home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.set_seed", "home.repos.pwc.inspect_result.facebookresearch_simmc2.scripts.run_generation.adjust_length_to_model"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", "\n", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--prompt\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--prompts_from_file\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"\"\"\nread prompts from a file and generate, overrides any prompt given on the\ncommand line\"\"\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--length\"", ",", "type", "=", "int", ",", "default", "=", "20", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--stop_token\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Token at which text generation is stopped\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--temperature\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1.0", ",", "\n", "help", "=", "\"temperature of 1.0 has no effect, lower tend toward greedy sampling\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--repetition_penalty\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "1.0", ",", "\n", "help", "=", "\"primarily useful for CTRL model; in that case, use 1.2\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--k\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--p\"", ",", "type", "=", "float", ",", "default", "=", "0.9", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--padding_text\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Padding text for Transfo-XL and XLNet.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--xlm_language\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Optional language when used with the XLM model.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_return_sequences\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"The number of samples to generate.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--path_output\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Path to output predictions in a line separated text file.\"", ",", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "args", ".", "device", "=", "torch", ".", "device", "(", "\n", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", "\n", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "set_seed", "(", "args", ")", "\n", "\n", "if", "args", ".", "prompts_from_file", "and", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "prompts_from_file", ")", ":", "\n", "        ", "raise", "Exception", "(", "f\"prompt file '{args.prompts_from_file}' not found\"", ")", "\n", "\n", "# Initialize the model and tokenizer", "\n", "", "try", ":", "\n", "        ", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "", "except", "KeyError", ":", "\n", "        ", "raise", "KeyError", "(", "\n", "\"the model {} you specified is not supported. You are welcome to add it and open a PR :)\"", "\n", ")", "\n", "\n", "", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "args", ".", "length", "=", "adjust_length_to_model", "(", "\n", "args", ".", "length", ",", "max_sequence_length", "=", "model", ".", "config", ".", "max_position_embeddings", "\n", ")", "\n", "logger", ".", "info", "(", "args", ")", "\n", "\n", "results", "=", "[", "]", "\n", "prompts", "=", "[", "]", "\n", "if", "args", ".", "prompts_from_file", ":", "\n", "        ", "with", "open", "(", "args", ".", "prompts_from_file", ")", "as", "handle", ":", "\n", "            ", "prompts", "=", "handle", ".", "readlines", "(", ")", "\n", "\n", "", "", "while", "True", ":", "\n", "        ", "if", "not", "prompts", ":", "\n", "            ", "prompts", "=", "[", "args", ".", "prompt", "if", "args", ".", "prompt", "else", "input", "(", "\"Model prompt >>> \"", ")", "]", "\n", "if", "not", "args", ".", "prompt", "and", "(", "\n", "len", "(", "prompts", ")", "==", "0", "\n", "or", "prompts", "[", "0", "]", ".", "strip", "(", ")", "==", "\"\"", "\n", "or", "prompts", "[", "0", "]", ".", "lower", "(", ")", "==", "\"quit\"", "\n", ")", ":", "\n", "                ", "break", "# break while True loop", "\n", "\n", "", "", "n_prompts", "=", "len", "(", "prompts", ")", "\n", "for", "i", ",", "prompt_text", "in", "enumerate", "(", "prompts", ")", ":", "\n", "# Strip any trailing \\n if provided", "\n", "            ", "prompt_text", "=", "prompt_text", ".", "strip", "(", "\"\\n\"", ")", "\n", "\n", "# Different models need different input formatting and/or extra arguments", "\n", "requires_preprocessing", "=", "args", ".", "model_type", "in", "PREPROCESSING_FUNCTIONS", ".", "keys", "(", ")", "\n", "if", "requires_preprocessing", ":", "\n", "                ", "prepare_input", "=", "PREPROCESSING_FUNCTIONS", ".", "get", "(", "args", ".", "model_type", ")", "\n", "preprocessed_prompt_text", "=", "prepare_input", "(", "\n", "args", ",", "model", ",", "tokenizer", ",", "prompt_text", "\n", ")", "\n", "encoded_prompt", "=", "tokenizer", ".", "encode", "(", "\n", "preprocessed_prompt_text", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", "add_space_before_punct_symbol", "=", "True", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "encoded_prompt", "=", "tokenizer", ".", "encode", "(", "\n", "prompt_text", ",", "add_special_tokens", "=", "True", ",", "return_tensors", "=", "\"pt\"", "\n", ")", "\n", "", "encoded_prompt", "=", "encoded_prompt", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "output_sequences", "=", "model", ".", "generate", "(", "\n", "input_ids", "=", "encoded_prompt", ",", "\n", "max_length", "=", "args", ".", "length", "+", "len", "(", "encoded_prompt", "[", "0", "]", ")", ",", "\n", "temperature", "=", "args", ".", "temperature", ",", "\n", "top_k", "=", "args", ".", "k", ",", "\n", "top_p", "=", "args", ".", "p", ",", "\n", "repetition_penalty", "=", "args", ".", "repetition_penalty", ",", "\n", "do_sample", "=", "True", ",", "\n", "num_return_sequences", "=", "args", ".", "num_return_sequences", ",", "\n", ")", "\n", "\n", "# Remove the batch dimension when returning multiple sequences", "\n", "if", "len", "(", "output_sequences", ".", "shape", ")", ">", "2", ":", "\n", "                ", "output_sequences", ".", "squeeze_", "(", ")", "\n", "\n", "", "generated_sequences", "=", "[", "]", "\n", "\n", "for", "generated_sequence_idx", ",", "generated_sequence", "in", "enumerate", "(", "\n", "output_sequences", "\n", ")", ":", "\n", "                ", "print", "(", "\n", "\"=== GENERATED SEQUENCE {sequence_idx}, {promt_idx}/{n_prompts} ===\"", ".", "format", "(", "\n", "sequence_idx", "=", "generated_sequence_idx", "+", "1", ",", "\n", "promt_idx", "=", "i", "+", "1", ",", "\n", "n_prompts", "=", "n_prompts", ",", "\n", ")", "\n", ")", "\n", "generated_sequence", "=", "generated_sequence", ".", "tolist", "(", ")", "\n", "\n", "# Decode text", "\n", "text", "=", "tokenizer", ".", "decode", "(", "\n", "generated_sequence", ",", "clean_up_tokenization_spaces", "=", "True", "\n", ")", "\n", "\n", "# Remove all text after the stop token", "\n", "text", "=", "text", "[", ":", "text", ".", "find", "(", "args", ".", "stop_token", ")", "if", "args", ".", "stop_token", "else", "None", "]", "\n", "\n", "# Add the prompt at the beginning of the sequence. Remove the", "\n", "# excess text that was used for pre-processing", "\n", "total_sequence", "=", "(", "\n", "prompt_text", "\n", "+", "text", "[", "\n", "len", "(", "\n", "tokenizer", ".", "decode", "(", "\n", "encoded_prompt", "[", "0", "]", ",", "clean_up_tokenization_spaces", "=", "True", "\n", ")", "\n", ")", ":", "\n", "]", "\n", ")", "\n", "\n", "generated_sequences", ".", "append", "(", "total_sequence", ")", "\n", "print", "(", "total_sequence", ")", "\n", "\n", "", "results", ".", "append", "(", "generated_sequences", ")", "\n", "\n", "", "prompts", "=", "[", "]", "\n", "if", "args", ".", "prompt", "or", "args", ".", "prompts_from_file", ":", "\n", "            ", "break", "# break while True loop", "\n", "\n", "", "", "if", "args", ".", "path_output", "is", "not", "None", ":", "\n", "\n", "# Create a directory if it does not exist", "\n", "        ", "directory", "=", "os", ".", "path", ".", "dirname", "(", "args", ".", "path_output", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "directory", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Format results into a line-separated string file", "\n", "", "str_results", "=", "\"\\n\"", ".", "join", "(", "\n", "[", "\" || \"", ".", "join", "(", "generated_sequences", ")", "for", "generated_sequences", "in", "results", "]", "\n", ")", "\n", "\n", "# Save to a file", "\n", "with", "open", "(", "args", ".", "path_output", ",", "\"w\"", ")", "as", "f_out", ":", "\n", "            ", "f_out", ".", "write", "(", "str_results", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]]}